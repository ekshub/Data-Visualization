[
    {
        "title": "Designing organizations for bottom-up task allocation: The role of   incentives",
        "authors": [
            "Stephan Leitner"
        ],
        "summary": "In recent years, various decentralized organizational forms have emerged, posing a challenge for organizational design. Some design elements, such as task allocation, become emergent properties that cannot be fully controlled from the top down. The central question that arises in this context is: How can bottom-up task allocation be guided towards an effective organizational structure? To address this question, this paper presents a novel agent-based model of an organization that features bottom-up task allocation that can be motivated by either long-term or short-term orientation on the agents' side. The model also includes an incentive mechanism to guide the bottom-up task allocation process and create incentives that range from altruistic to individualistic. Our analysis shows that when bottom-up task allocation is driven by short-term orientation and aligned with the incentive mechanisms, it leads to improved organizational performance that surpasses that of traditionally designed organizations. Additionally, we find that the presence of altruistic incentive mechanisms within the organization reduces the importance of mirroring in task allocation.",
        "published": "2023-01-01T14:21:11Z",
        "link": "http://arxiv.org/abs/2301.00410v1",
        "categories": [
            "econ.GN",
            "cs.MA",
            "q-fin.EC",
            "68U20, 62P20, 90B70",
            "I.6.3; I.6.5; J.4"
        ]
    },
    {
        "title": "Large-Scale Traffic Signal Control by a Nash Deep Q-network Approach",
        "authors": [
            "Yuli. Zhang",
            "Shangbo. Wang",
            "Ruiyuan. Jiang"
        ],
        "summary": "Reinforcement Learning (RL) is currently one of the most commonly used techniques for traffic signal control (TSC), which can adaptively adjusted traffic signal phase and duration according to real-time traffic data. However, a fully centralized RL approach is beset with difficulties in a multi-network scenario because of exponential growth in state-action space with increasing intersections. Multi-agent reinforcement learning (MARL) can overcome the high-dimension problem by employing the global control of each local RL agent, but it also brings new challenges, such as the failure of convergence caused by the non-stationary Markov Decision Process (MDP). In this paper, we introduce an off-policy nash deep Q-Network (OPNDQN) algorithm, which mitigates the weakness of both fully centralized and MARL approaches. The OPNDQN algorithm solves the problem that traditional algorithms cannot be used in large state-action space traffic models by utilizing a fictitious game approach at each iteration to find the nash equilibrium among neighboring intersections, from which no intersection has incentive to unilaterally deviate. One of main advantages of OPNDQN is to mitigate the non-stationarity of multi-agent Markov process because it considers the mutual influence among neighboring intersections by sharing their actions. On the other hand, for training a large traffic network, the convergence rate of OPNDQN is higher than that of existing MARL approaches because it does not incorporate all state information of each agent. We conduct an extensive experiments by using Simulation of Urban MObility simulator (SUMO), and show the dominant superiority of OPNDQN over several existing MARL approaches in terms of average queue length, episode training reward and average waiting time.",
        "published": "2023-01-02T12:58:51Z",
        "link": "http://arxiv.org/abs/2301.00637v1",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Timely Opportunistic Gossiping in Dense Networks",
        "authors": [
            "Purbesh Mitra",
            "Sennur Ulukus"
        ],
        "summary": "We consider gossiping in a fully-connected wireless network consisting of $n$ nodes. The network receives Poisson updates from a source, which generates new information. The nodes gossip their available information with the neighboring nodes to maintain network timeliness. In this work, we propose two gossiping schemes, one semi-distributed and the other one fully-distributed. In the semi-distributed scheme, the freshest nodes use pilot signals to interact with the network and gossip with the full available update rate $B$. In the fully-distributed scheme, each node gossips for a fixed amount of time duration with the full update rate $B$. Both schemes achieve $O(1)$ age scaling, and the semi-distributed scheme has the best age performance for any symmetric randomized gossiping policy. We compare the results with the recently proposed ASUMAN scheme, which also gives $O(1)$ age performance, but the nodes need to be age-aware.",
        "published": "2023-01-02T18:43:42Z",
        "link": "http://arxiv.org/abs/2301.00798v2",
        "categories": [
            "cs.IT",
            "cs.MA",
            "cs.NI",
            "eess.SP",
            "math.IT"
        ]
    },
    {
        "title": "Optimizing Agent Collaboration through Heuristic Multi-Agent Planning",
        "authors": [
            "Nitsan Soffair"
        ],
        "summary": "The SOTA algorithms for addressing QDec-POMDP issues, QDec-FP and QDec-FPS, are unable to effectively tackle problems that involve different types of sensing agents. We propose a new algorithm that addresses this issue by requiring agents to adopt the same plan if one agent is unable to take a sensing action but the other can. Our algorithm performs significantly better than both QDec-FP and QDec-FPS in these types of situations.",
        "published": "2023-01-03T17:43:26Z",
        "link": "http://arxiv.org/abs/2301.01246v5",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Optimal Decoy Resource Allocation for Proactive Defense in Probabilistic   Attack Graphs",
        "authors": [
            "Haoxiang Ma",
            "Shuo Han",
            "Nandi Leslie",
            "Charles Kamhoua",
            "Jie Fu"
        ],
        "summary": "This paper investigates the problem of synthesizing proactive defense systems in which the defender can allocate deceptive targets and modify the cost of actions for the attacker who aims to compromise security assets in this system. We model the interaction of the attacker and the system using a formal security model -- a probabilistic attack graph. By allocating fake targets/decoys, the defender aims to distract the attacker from compromising true targets. By increasing the cost of some attack actions, the defender aims to discourage the attacker from committing to certain policies and thereby improve the defense. To optimize the defense given limited decoy resources and operational constraints, we formulate the synthesis problem as a bi-level optimization problem, while the defender designs the system, in anticipation of the attacker's best response given that the attacker has disinformation about the system due to the use of deception. Though the general formulation with bi-level optimization is NP-hard, we show that under certain assumptions, the problem can be transformed into a constrained optimization problem. We proposed an algorithm to approximately solve this constrained optimization problem using a novel incentive-design method for projected gradient ascent. We demonstrate the effectiveness of the proposed method using extensive numerical experiments.",
        "published": "2023-01-03T19:59:29Z",
        "link": "http://arxiv.org/abs/2301.01336v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Cost Inference for Feedback Dynamic Games from Noisy Partial State   Observations and Incomplete Trajectories",
        "authors": [
            "Jingqi Li",
            "Chih-Yuan Chiu",
            "Lasse Peters",
            "Somayeh Sojoudi",
            "Claire Tomlin",
            "David Fridovich-Keil"
        ],
        "summary": "In multi-agent dynamic games, the Nash equilibrium state trajectory of each agent is determined by its cost function and the information pattern of the game. However, the cost and trajectory of each agent may be unavailable to the other agents. Prior work on using partial observations to infer the costs in dynamic games assumes an open-loop information pattern. In this work, we demonstrate that the feedback Nash equilibrium concept is more expressive and encodes more complex behavior. It is desirable to develop specific tools for inferring players' objectives in feedback games. Therefore, we consider the dynamic game cost inference problem under the feedback information pattern, using only partial state observations and incomplete trajectory data. To this end, we first propose an inverse feedback game loss function, whose minimizer yields a feedback Nash equilibrium state trajectory closest to the observation data. We characterize the landscape and differentiability of the loss function. Given the difficulty of obtaining the exact gradient, our main contribution is an efficient gradient approximator, which enables a novel inverse feedback game solver that minimizes the loss using first-order optimization. In thorough empirical evaluations, we demonstrate that our algorithm converges reliably and has better robustness and generalization performance than the open-loop baseline method when the observation data reflects a group of players acting in a feedback Nash game.",
        "published": "2023-01-04T01:25:49Z",
        "link": "http://arxiv.org/abs/2301.01398v1",
        "categories": [
            "cs.MA",
            "cs.RO",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Quantum Multi-Agent Actor-Critic Neural Networks for Internet-Connected   Multi-Robot Coordination in Smart Factory Management",
        "authors": [
            "Won Joon Yun",
            "Jae Pyoung Kim",
            "Soyi Jung",
            "Jae-Hyun Kim",
            "Joongheon Kim"
        ],
        "summary": "As one of the latest fields of interest in both academia and industry, quantum computing has garnered significant attention. Among various topics in quantum computing, variational quantum circuits (VQC) have been noticed for their ability to carry out quantum deep reinforcement learning (QRL). This paper verifies the potential of QRL, which will be further realized by implementing quantum multi-agent reinforcement learning (QMARL) from QRL, especially for Internet-connected autonomous multi-robot control and coordination in smart factory applications. However, the extension is not straightforward due to the non-stationarity of classical MARL. To cope with this, the centralized training and decentralized execution (CTDE) QMARL framework is proposed under the Internet connection. A smart factory environment with the Internet of Things (IoT)-based multiple agents is used to show the efficacy of the proposed algorithm. The simulation corroborates that the proposed QMARL-based autonomous multi-robot control and coordination performs better than the other frameworks.",
        "published": "2023-01-04T04:28:39Z",
        "link": "http://arxiv.org/abs/2301.04012v1",
        "categories": [
            "quant-ph",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Emergent collective intelligence from massive-agent cooperation and   competition",
        "authors": [
            "Hanmo Chen",
            "Stone Tao",
            "Jiaxin Chen",
            "Weihan Shen",
            "Xihui Li",
            "Chenghui Yu",
            "Sikai Cheng",
            "Xiaolong Zhu",
            "Xiu Li"
        ],
        "summary": "Inspired by organisms evolving through cooperation and competition between different populations on Earth, we study the emergence of artificial collective intelligence through massive-agent reinforcement learning. To this end, We propose a new massive-agent reinforcement learning environment, Lux, where dynamic and massive agents in two teams scramble for limited resources and fight off the darkness. In Lux, we build our agents through the standard reinforcement learning algorithm in curriculum learning phases and leverage centralized control via a pixel-to-pixel policy network. As agents co-evolve through self-play, we observe several stages of intelligence, from the acquisition of atomic skills to the development of group strategies. Since these learned group strategies arise from individual decisions without an explicit coordination mechanism, we claim that artificial collective intelligence emerges from massive-agent cooperation and competition. We further analyze the emergence of various learned strategies through metrics and ablation studies, aiming to provide insights for reinforcement learning implementations in massive-agent environments.",
        "published": "2023-01-04T13:23:12Z",
        "link": "http://arxiv.org/abs/2301.01609v2",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Task-Effective Compression of Observations for the Centralized Control   of a Multi-agent System Over Bit-Budgeted Channels",
        "authors": [
            "Arsham Mostaani",
            "Thang X. Vu",
            "Symeon Chatzinotas",
            "Bjorn Ottersten"
        ],
        "summary": "We consider a task-effective quantization problem that arises when multiple agents are controlled via a centralized controller (CC). While agents have to communicate their observations to the CC for decision-making, the bit-budgeted communications of agent-CC links may limit the task-effectiveness of the system which is measured by the system's average sum of stage costs/rewards. As a result, each agent should compress/quantize its observation such that the average sum of stage costs/rewards of the control task is minimally impacted. We address the problem of maximizing the average sum of stage rewards by proposing two different Action-Based State Aggregation (ABSA) algorithms that carry out the indirect and joint design of control and communication policies in the multi-agent system. While the applicability of ABSA-1 is limited to single-agent systems, it provides an analytical framework that acts as a stepping stone to the design of ABSA-2. ABSA-2 carries out the joint design of control and communication for a multi-agent system. We evaluate the algorithms - with average return as the performance metric - using numerical experiments performed to solve a multi-agent geometric consensus problem. The numerical results are concluded by introducing a new metric that measures the effectiveness of communications in a multi-agent system.",
        "published": "2023-01-04T14:00:48Z",
        "link": "http://arxiv.org/abs/2301.01628v1",
        "categories": [
            "cs.IT",
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "math.IT"
        ]
    },
    {
        "title": "Attention-Based Recurrence for Multi-Agent Reinforcement Learning under   Stochastic Partial Observability",
        "authors": [
            "Thomy Phan",
            "Fabian Ritz",
            "Philipp Altmann",
            "Maximilian Zorn",
            "Jonas Nüßlein",
            "Michael Kölle",
            "Thomas Gabor",
            "Claudia Linnhoff-Popien"
        ],
        "summary": "Stochastic partial observability poses a major challenge for decentralized coordination in multi-agent reinforcement learning but is largely neglected in state-of-the-art research due to a strong focus on state-based centralized training for decentralized execution (CTDE) and benchmarks that lack sufficient stochasticity like StarCraft Multi-Agent Challenge (SMAC). In this paper, we propose Attention-based Embeddings of Recurrence In multi-Agent Learning (AERIAL) to approximate value functions under stochastic partial observability. AERIAL replaces the true state with a learned representation of multi-agent recurrence, considering more accurate information about decentralized agent decisions than state-based CTDE. We then introduce MessySMAC, a modified version of SMAC with stochastic observations and higher variance in initial states, to provide a more general and configurable benchmark regarding stochastic partial observability. We evaluate AERIAL in Dec-Tiger as well as in a variety of SMAC and MessySMAC maps, and compare the results with state-based CTDE. Furthermore, we evaluate the robustness of AERIAL and state-based CTDE against various stochasticity configurations in MessySMAC.",
        "published": "2023-01-04T14:48:25Z",
        "link": "http://arxiv.org/abs/2301.01649v6",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "fintech-kMC: Agent based simulations of financial platforms for design   and testing of machine learning systems",
        "authors": [
            "Isaac Tamblyn",
            "Tengkai Yu",
            "Ian Benlolo"
        ],
        "summary": "We discuss our simulation tool, fintech-kMC, which is designed to generate synthetic data for machine learning model development and testing. fintech-kMC is an agent-based model driven by a kinetic Monte Carlo (a.k.a. continuous time Monte Carlo) engine which simulates the behaviour of customers using an online digital financial platform. The tool provides an interpretable, reproducible, and realistic way of generating synthetic data which can be used to validate and test AI/ML models and pipelines to be used in real-world customer-facing financial applications.",
        "published": "2023-01-04T20:09:40Z",
        "link": "http://arxiv.org/abs/2301.01807v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "q-fin.CP"
        ]
    },
    {
        "title": "Scalable Communication for Multi-Agent Reinforcement Learning via   Transformer-Based Email Mechanism",
        "authors": [
            "Xudong Guo",
            "Daming Shi",
            "Wenhui Fan"
        ],
        "summary": "Communication can impressively improve cooperation in multi-agent reinforcement learning (MARL), especially for partially-observed tasks. However, existing works either broadcast the messages leading to information redundancy, or learn targeted communication by modeling all the other agents as targets, which is not scalable when the number of agents varies. In this work, to tackle the scalability problem of MARL communication for partially-observed tasks, we propose a novel framework Transformer-based Email Mechanism (TEM). The agents adopt local communication to send messages only to the ones that can be observed without modeling all the agents. Inspired by human cooperation with email forwarding, we design message chains to forward information to cooperate with the agents outside the observation range. We introduce Transformer to encode and decode the message chain to choose the next receiver selectively. Empirically, TEM outperforms the baselines on multiple cooperative MARL benchmarks. When the number of agents varies, TEM maintains superior performance without further training.",
        "published": "2023-01-05T05:34:30Z",
        "link": "http://arxiv.org/abs/2301.01919v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Self-Motivated Multi-Agent Exploration",
        "authors": [
            "Shaowei Zhang",
            "Jiahan Cao",
            "Lei Yuan",
            "Yang Yu",
            "De-Chuan Zhan"
        ],
        "summary": "In cooperative multi-agent reinforcement learning (CMARL), it is critical for agents to achieve a balance between self-exploration and team collaboration. However, agents can hardly accomplish the team task without coordination and they would be trapped in a local optimum where easy cooperation is accessed without enough individual exploration. Recent works mainly concentrate on agents' coordinated exploration, which brings about the exponentially grown exploration of the state space. To address this issue, we propose Self-Motivated Multi-Agent Exploration (SMMAE), which aims to achieve success in team tasks by adaptively finding a trade-off between self-exploration and team cooperation. In SMMAE, we train an independent exploration policy for each agent to maximize their own visited state space. Each agent learns an adjustable exploration probability based on the stability of the joint team policy. The experiments on highly cooperative tasks in StarCraft II micromanagement benchmark (SMAC) demonstrate that SMMAE can explore task-related states more efficiently, accomplish coordinated behaviours and boost the learning performance.",
        "published": "2023-01-05T14:42:39Z",
        "link": "http://arxiv.org/abs/2301.02083v2",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "A compositional game to fairly divide homogeneous cake",
        "authors": [
            "Abel Jansma"
        ],
        "summary": "The central question in the game theory of cake-cutting is how to fairly distribute a finite resource among multiple players. Most research has focused on how to do this for a heterogeneous cake in a situation where the players do not have access to each other's valuation function, but I argue that even sharing homogeneous cake can have interesting mechanism design. Here, I introduce a new game, based on the compositional structure of iterated cake-cutting, that in the case of a homogeneous cake has a Nash equilibrium where each of $n$ players gets $1/n$ of the cake. Furthermore, the equilibrium distribution is the result of just $n-1$ cuts, so each player gets a contiguous piece of cake. Naive composition of the `I cut you choose' rule leads to an exponentially unfair cake distribution with a Gini-coefficient that approaches 1, and suffers from a high Price of Anarchy. This cost is completely eliminated by the proposed \\textit{Biggest Player} rule for composition which achieves decentralised and asynchronous fairness at linear Robertson-Webb complexity. After introducing the game, proving the fairness of the equilibrium, and analysing the incentive structure, the game is implemented in Haskell and the Open Game engine to make the compositional structure explicit.",
        "published": "2023-01-05T19:53:14Z",
        "link": "http://arxiv.org/abs/2301.02281v3",
        "categories": [
            "cs.GT",
            "cs.MA",
            "91A06"
        ]
    },
    {
        "title": "Reasoning about Causality in Games",
        "authors": [
            "Lewis Hammond",
            "James Fox",
            "Tom Everitt",
            "Ryan Carey",
            "Alessandro Abate",
            "Michael Wooldridge"
        ],
        "summary": "Causal reasoning and game-theoretic reasoning are fundamental topics in artificial intelligence, among many other disciplines: this paper is concerned with their intersection. Despite their importance, a formal framework that supports both these forms of reasoning has, until now, been lacking. We offer a solution in the form of (structural) causal games, which can be seen as extending Pearl's causal hierarchy to the game-theoretic domain, or as extending Koller and Milch's multi-agent influence diagrams to the causal domain. We then consider three key questions: i) How can the (causal) dependencies in games - either between variables, or between strategies - be modelled in a uniform, principled manner? ii) How may causal queries be computed in causal games, and what assumptions does this require? iii) How do causal games compare to existing formalisms? To address question i), we introduce mechanised games, which encode dependencies between agents' decision rules and the distributions governing the game. In response to question ii), we present definitions of predictions, interventions, and counterfactuals, and discuss the assumptions required for each. Regarding question iii), we describe correspondences between causal games and other formalisms, and explain how causal games can be used to answer queries that other causal or game-theoretic models do not support. Finally, we highlight possible applications of causal games, aided by an extensive open-source Python library.",
        "published": "2023-01-05T22:47:28Z",
        "link": "http://arxiv.org/abs/2301.02324v2",
        "categories": [
            "cs.AI",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Measuring a Priori Voting Power -- Taking Delegations Seriously",
        "authors": [
            "Rachael Colley",
            "Théo Delemazure",
            "Hugo Gilbert"
        ],
        "summary": "We introduce new power indices to measure the a priori voting power of voters in liquid democracy elections where an underlying network restricts delegations. We argue that our power indices are natural extensions of the standard Penrose-Banzhaf index in simple voting games. We show that computing the criticality of a voter is #P-hard even when voting weights are polynomially-bounded in the size of the instance. However, for specific settings, such as when the underlying network is a bipartite or complete graph, recursive formulas can compute these indices for weighted voting games in pseudo-polynomial time. We highlight their theoretical properties and provide numerical results to illustrate how restricting the possible delegations can alter voters' voting power.",
        "published": "2023-01-06T11:16:57Z",
        "link": "http://arxiv.org/abs/2301.02462v4",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.CC"
        ]
    },
    {
        "title": "Multi-Agent Reinforcement Learning for Fast-Timescale Demand Response of   Residential Loads",
        "authors": [
            "Vincent Mai",
            "Philippe Maisonneuve",
            "Tianyu Zhang",
            "Hadi Nekoei",
            "Liam Paull",
            "Antoine Lesage-Landry"
        ],
        "summary": "To integrate high amounts of renewable energy resources, electrical power grids must be able to cope with high amplitude, fast timescale variations in power generation. Frequency regulation through demand response has the potential to coordinate temporally flexible loads, such as air conditioners, to counteract these variations. Existing approaches for discrete control with dynamic constraints struggle to provide satisfactory performance for fast timescale action selection with hundreds of agents. We propose a decentralized agent trained with multi-agent proximal policy optimization with localized communication. We explore two communication frameworks: hand-engineered, or learned through targeted multi-agent communication. The resulting policies perform well and robustly for frequency regulation, and scale seamlessly to arbitrary numbers of houses for constant processing times.",
        "published": "2023-01-06T16:41:51Z",
        "link": "http://arxiv.org/abs/2301.02593v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Platoon Leader Selection, User Association and Resource Allocation on a   C-V2X based highway: A Reinforcement Learning Approach",
        "authors": [
            "Mohammad Farzanullah",
            "Tho Le-Ngoc"
        ],
        "summary": "We consider the problem of dynamic platoon leader selection, user association, channel assignment, and power allocation on a cellular vehicle-to-everything (C-V2X) based highway, where multiple vehicle-to-vehicle (V2V) and vehicle-to-infrastructure (V2I) links share the frequency resources. There are multiple roadside units (RSUs) on a highway, and vehicles can form platoons, which has been identified as an advanced use case to increase road efficiency. The traditional optimization methods, requiring global channel information at a central controller, are not viable for high-mobility vehicular networks. To deal with this challenge, we propose a distributed multi-agent reinforcement learning (MARL) for resource allocation (RA). Each platoon leader, acting as an agent, can collaborate with other agents for joint sub-band selection and power allocation for its V2V links, and joint user association and power control for its V2I links. Moreover, each platoon can dynamically select the vehicle most suitable to be the platoon leader. We aim to maximize the V2V and V2I packet delivery probability in the desired latency using the deep Q-learning algorithm. Simulation results indicate that our proposed MARL outperforms the centralized hill-climbing algorithm, and platoon leader selection helps to improve both V2V and V2I performance.",
        "published": "2023-01-09T02:07:22Z",
        "link": "http://arxiv.org/abs/2301.03145v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Network Slicing via Transfer Learning aided Distributed Deep   Reinforcement Learning",
        "authors": [
            "Tianlun Hu",
            "Qi Liao",
            "Qiang Liu",
            "Georg Carle"
        ],
        "summary": "Deep reinforcement learning (DRL) has been increasingly employed to handle the dynamic and complex resource management in network slicing. The deployment of DRL policies in real networks, however, is complicated by heterogeneous cell conditions. In this paper, we propose a novel transfer learning (TL) aided multi-agent deep reinforcement learning (MADRL) approach with inter-agent similarity analysis for inter-cell inter-slice resource partitioning. First, we design a coordinated MADRL method with information sharing to intelligently partition resource to slices and manage inter-cell interference. Second, we propose an integrated TL method to transfer the learned DRL policies among different local agents for accelerating the policy deployment. The method is composed of a new domain and task similarity measurement approach and a new knowledge transfer approach, which resolves the problem of from whom to transfer and how to transfer. We evaluated the proposed solution with extensive simulations in a system-level simulator and show that our approach outperforms the state-of-the-art solutions in terms of performance, convergence speed and sample efficiency. Moreover, by applying TL, we achieve an additional gain over 27% higher than the coordinate MADRL approach without TL.",
        "published": "2023-01-09T10:55:13Z",
        "link": "http://arxiv.org/abs/2301.03262v2",
        "categories": [
            "cs.NI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "A Rolling Horizon Game Considering Network Effect in Cluster Forming for   Dynamic Resilient Multiagent Systems",
        "authors": [
            "Yurid Nugraha",
            "Ahmet Cetinkaya",
            "Tomohisa Hayakawa",
            "Hideaki Ishii",
            "Quanyan Zhu"
        ],
        "summary": "A two-player game-theoretic problem on resilient graphs in a multiagent consensus setting is formulated. An attacker is capable to disable some of the edges of the network with the objective to divide the agents into clusters by emitting jamming signals while, in response, the defender recovers some of the edges by increasing the transmission power for the communication signals. Specifically, we consider repeated games between the attacker and the defender where the optimal strategies for the two players are derived in a rolling horizon fashion based on utility functions that take both the agents' states and the sizes of clusters (known as network effect) into account. The players' actions at each discrete-time step are constrained by their energy for transmissions of the signals, with a less strict constraint for the attacker. Necessary conditions and sufficient conditions of agent consensus are derived, which are influenced by the energy constraints. The number of clusters of agents at infinite time in the face of attacks and recoveries are also characterized. Simulation results are provided to demonstrate the effects of players' actions on the cluster forming and to illustrate the players' performance for different horizon parameters.",
        "published": "2023-01-09T12:44:33Z",
        "link": "http://arxiv.org/abs/2301.03302v1",
        "categories": [
            "eess.SY",
            "cs.GT",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Proportional Fairness in Obnoxious Facility Location",
        "authors": [
            "Alexander Lam",
            "Haris Aziz",
            "Bo Li",
            "Fahimeh Ramezani",
            "Toby Walsh"
        ],
        "summary": "We consider the obnoxious facility location problem (in which agents prefer the facility location to be far from them) and propose a hierarchy of distance-based proportional fairness concepts for the problem. These fairness axioms ensure that groups of agents at the same location are guaranteed to be a distance from the facility proportional to their group size. We consider deterministic and randomized mechanisms, and compute tight bounds on the price of proportional fairness. In the deterministic setting, we show that our proportional fairness axioms are incompatible with strategyproofness, and prove asymptotically tight $\\epsilon$-price of anarchy and stability bounds for proportionally fair welfare-optimal mechanisms. In the randomized setting, we identify proportionally fair and strategyproof mechanisms that give an expected welfare within a constant factor of the optimal welfare. Finally, we prove existence results for two extensions to our model.",
        "published": "2023-01-11T07:30:35Z",
        "link": "http://arxiv.org/abs/2301.04340v2",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.MA",
            "econ.TH"
        ]
    },
    {
        "title": "Decentralized iLQR for Cooperative Trajectory Planning of Connected   Autonomous Vehicles via Dual Consensus ADMM",
        "authors": [
            "Zhenmin Huang",
            "Shaojie Shen",
            "Jun Ma"
        ],
        "summary": "Developments in cooperative trajectory planning of connected autonomous vehicles (CAVs) have gathered considerable momentum and research attention. Generally, such problems present strong non-linearity and non-convexity, rendering great difficulties in finding the optimal solution. Existing methods typically suffer from low computational efficiency, and this hinders the appropriate applications in large-scale scenarios involving an increasing number of vehicles. To tackle this problem, we propose a novel decentralized iterative linear quadratic regulator (iLQR) algorithm by leveraging the dual consensus alternating direction method of multipliers (ADMM). First, the original non-convex optimization problem is reformulated into a series of convex optimization problems through iterative neighbourhood approximation. Then, the dual of each convex optimization problem is shown to have a consensus structure, which facilitates the use of consensus ADMM to solve for the dual solution in a fully decentralized and parallel architecture. Finally, the primal solution corresponding to the trajectory of each vehicle is recovered by solving a linear quadratic regulator (LQR) problem iteratively, and a novel trajectory update strategy is proposed to ensure the dynamic feasibility of vehicles. With the proposed development, the computation burden is significantly alleviated such that real-time performance is attainable. Two traffic scenarios are presented to validate the proposed algorithm, and thorough comparisons between our proposed method and baseline methods (including centralized iLQR, IPOPT, and SQP) are conducted to demonstrate the scalability of the proposed approach.",
        "published": "2023-01-11T10:18:01Z",
        "link": "http://arxiv.org/abs/2301.04386v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Grassroots Systems: Concept, Examples, Implementation and Applications",
        "authors": [
            "Ehud Shapiro"
        ],
        "summary": "Informally, a grassroots system is a distributed system that can have multiple instances, independent of each other and of any global resources, that can interoperate once interconnected. Grassroots applications are potentially important as they may allow people to conduct their social, economic, civic, and political lives in the digital realm solely using the networked computing devices they own and operate (e.g., smartphones), free of third-party control, surveillance, manipulation, coercion, or rent seeking (e.g., by global digital platforms such as Facebook or Bitcoin).   Here, we formalize the notion of grassroots systems and grassroots implementations; specify an abstract grassroots dissemination protocol; describe and prove an implementation of grassroots dissemination for the model of asynchrony; extend the implementation to mobile (address-changing) devices that communicate via an unreliable network (e.g. smartphones using UDP); and discuss how grassroots dissemination can realize applications that support digital sovereignty -- grassroots social networking and grassroots currencies. The mathematical construction employs distributed multiagent transition systems to define the notions of grassroots protocols and grassroots implementations, to specify grassroots dissemination protocols and their implementation, and to prove their correctness. The implementation uses the blocklace -- a generalization of the blockchain that functions as a fault-tolerant, conflict-free replicated data type.",
        "published": "2023-01-11T10:31:53Z",
        "link": "http://arxiv.org/abs/2301.04391v4",
        "categories": [
            "cs.NI",
            "cs.DC",
            "cs.MA",
            "cs.SI"
        ]
    },
    {
        "title": "An Efficient Approach to the Online Multi-Agent Path Finding Problem by   Using Sustainable Information",
        "authors": [
            "Mingkai Tang",
            "Boyi Liu",
            "Yuanhang Li",
            "Hongji Liu",
            "Ming Liu",
            "Lujia Wang"
        ],
        "summary": "Multi-agent path finding (MAPF) is the problem of moving agents to the goal vertex without collision. In the online MAPF problem, new agents may be added to the environment at any time, and the current agents have no information about future agents. The inability of existing online methods to reuse previous planning contexts results in redundant computation and reduces algorithm efficiency. Hence, we propose a three-level approach to solve online MAPF utilizing sustainable information, which can decrease its redundant calculations. The high-level solver, the Sustainable Replan algorithm (SR), manages the planning context and simulates the environment. The middle-level solver, the Sustainable Conflict-Based Search algorithm (SCBS), builds a conflict tree and maintains the planning context. The low-level solver, the Sustainable Reverse Safe Interval Path Planning algorithm (SRSIPP), is an efficient single-agent solver that uses previous planning context to reduce duplicate calculations. Experiments show that our proposed method has significant improvement in terms of computational efficiency. In one of the test scenarios, our algorithm can be 1.48 times faster than SOTA on average under different agent number settings.",
        "published": "2023-01-11T13:04:35Z",
        "link": "http://arxiv.org/abs/2301.04446v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.RO"
        ]
    },
    {
        "title": "Thou Shalt not Pick all Items if Thou are First: of Strategyproof and   Fair Picking Sequences",
        "authors": [
            "Sylvain Bouveret",
            "Hugo Gilbert",
            "Jérôme Lang",
            "Guillaume Méroué"
        ],
        "summary": "When allocating indivisible items to agents, it is known that the only strategyproof mechanisms that satisfy a set of rather mild conditions are constrained serial dictatorships: given a fixed order over agents, at each step the designated agent chooses a given number of items (depending on her position in the sequence). With these rules, also known as non-interleaving picking sequences, agents who come earlier in the sequence have a larger choice of items. However, this advantage can be compensated by a higher number of items received by those who come later. How to balance priority in the sequence and number of items received is a nontrivial question. We use a previous model, parameterized by a mapping from ranks to scores, a social welfare functional, and a distribution over preference profiles. For several meaningful choices of parameters, we show that the optimal sequence can be computed in polynomial time. Last, we give a simple procedure for eliciting scoring vectors and we study the impact of the assignment from agents to positions on the ex-post social welfare.",
        "published": "2023-01-11T13:04:51Z",
        "link": "http://arxiv.org/abs/2301.06086v1",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Heterogeneous Beliefs and Multi-Population Learning in Network Games",
        "authors": [
            "Shuyue Hu",
            "Harold Soh",
            "Georgios Piliouras"
        ],
        "summary": "The effect of population heterogeneity in multi-agent learning is practically relevant but remains far from being well-understood. Motivated by this, we introduce a model of multi-population learning that allows for heterogeneous beliefs within each population and where agents respond to their beliefs via smooth fictitious play (SFP).We show that the system state -- a probability distribution over beliefs -- evolves according to a system of partial differential equations akin to the continuity equations that commonly desccribe transport phenomena in physical systems. We establish the convergence of SFP to Quantal Response Equilibria in different classes of games capturing both network competition as well as network coordination. We also prove that the beliefs will eventually homogenize in all network games. Although the initial belief heterogeneity disappears in the limit, we show that it plays a crucial role for equilibrium selection in the case of coordination games as it helps select highly desirable equilibria. Contrary, in the case of network competition, the resulting limit behavior is independent of the initialization of beliefs, even when the underlying game has many distinct Nash equilibria.",
        "published": "2023-01-12T10:53:36Z",
        "link": "http://arxiv.org/abs/2301.04929v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "NOPA: Neurally-guided Online Probabilistic Assistance for Building   Socially Intelligent Home Assistants",
        "authors": [
            "Xavier Puig",
            "Tianmin Shu",
            "Joshua B. Tenenbaum",
            "Antonio Torralba"
        ],
        "summary": "In this work, we study how to build socially intelligent robots to assist people in their homes. In particular, we focus on assistance with online goal inference, where robots must simultaneously infer humans' goals and how to help them achieve those goals. Prior assistance methods either lack the adaptivity to adjust helping strategies (i.e., when and how to help) in response to uncertainty about goals or the scalability to conduct fast inference in a large goal space. Our NOPA (Neurally-guided Online Probabilistic Assistance) method addresses both of these challenges. NOPA consists of (1) an online goal inference module combining neural goal proposals with inverse planning and particle filtering for robust inference under uncertainty, and (2) a helping planner that discovers valuable subgoals to help with and is aware of the uncertainty in goal inference. We compare NOPA against multiple baselines in a new embodied AI assistance challenge: Online Watch-And-Help, in which a helper agent needs to simultaneously watch a main agent's action, infer its goal, and help perform a common household task faster in realistic virtual home environments. Experiments show that our helper agent robustly updates its goal inference and adapts its helping plans to the changing level of uncertainty.",
        "published": "2023-01-12T18:59:34Z",
        "link": "http://arxiv.org/abs/2301.05223v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "An Approach to Stochastic Dynamic Games with Asymmetric Information and   Hidden Actions",
        "authors": [
            "Yi Ouyang",
            "Hamidreza Tavafoghi",
            "Demosthenis Teneketzis"
        ],
        "summary": "We consider in discrete time, a general class of sequential stochastic dynamic games with asymmetric information with the following features. The underlying system has Markovian dynamics controlled by the agents' joint actions. Each agent's instantaneous utility depends on the current system state and the agents' joint actions. At each time instant each agent makes a private noisy observation of the current system state and the agents' actions in the previous time instant. In addition, at each time instant all agents have a common noisy observation of the current system state and their actions in the previous time instant. Each agent's actions are part of his private information. The objective is to determine Bayesian Nash Equilibrium (BNE) strategy profiles that are based on a compressed version of the agents' information and can be sequentially computed; such BNE strategy profiles may not always exist. We present an approach/methodology that achieves the above-stated objective, along with an instance of a game where BNE strategy profiles with the above-mentioned characteristics exist. We show that the methodology also works for the case where the agents have no common observations.",
        "published": "2023-01-12T20:51:44Z",
        "link": "http://arxiv.org/abs/2301.05288v1",
        "categories": [
            "cs.MA",
            "cs.GT",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Learning to Control and Coordinate Mixed Traffic Through Robot Vehicles   at Complex and Unsignalized Intersections",
        "authors": [
            "Dawei Wang",
            "Weizi Li",
            "Lei Zhu",
            "Jia Pan"
        ],
        "summary": "Intersections are essential road infrastructures for traffic in modern metropolises. However, they can also be the bottleneck of traffic flows as a result of traffic incidents or the absence of traffic coordination mechanisms such as traffic lights. Recently, various control and coordination mechanisms that are beyond traditional control methods have been proposed to improve the efficiency of intersection traffic by leveraging the ability of autonomous vehicles. Amongst these methods, the control of foreseeable mixed traffic that consists of human-driven vehicles (HVs) and robot vehicles (RVs) has emerged. We propose a decentralized multi-agent reinforcement learning approach for the control and coordination of mixed traffic by RVs at real-world, complex intersections -- an open challenge to date. We design comprehensive experiments to evaluate the effectiveness, robustness, generalizablility, and adaptability of our approach. In particular, our method can prevent congestion formation via merely 5% RVs under a real-world traffic demand of 700 vehicles per hour. In contrast, without RVs, congestion will form when the traffic demand reaches as low as 200 vehicles per hour. Moreover, when the RV penetration rate exceeds 60%, our method starts to outperform traffic signal control in terms of the average waiting time of all vehicles. Our method is not only robust against blackout events, sudden RV percentage drops, and V2V communication error, but also enjoys excellent generalizablility, evidenced by its successful deployment in five unseen intersections. Lastly, our method performs well under various traffic rules, demonstrating its adaptability to diverse scenarios. Videos and code of our work are available at https://sites.google.com/view/mixedtrafficcontrol",
        "published": "2023-01-12T21:09:58Z",
        "link": "http://arxiv.org/abs/2301.05294v4",
        "categories": [
            "cs.LG",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "TransfQMix: Transformers for Leveraging the Graph Structure of   Multi-Agent Reinforcement Learning Problems",
        "authors": [
            "Matteo Gallici",
            "Mario Martin",
            "Ivan Masmitja"
        ],
        "summary": "Coordination is one of the most difficult aspects of multi-agent reinforcement learning (MARL). One reason is that agents normally choose their actions independently of one another. In order to see coordination strategies emerging from the combination of independent policies, the recent research has focused on the use of a centralized function (CF) that learns each agent's contribution to the team reward. However, the structure in which the environment is presented to the agents and to the CF is typically overlooked. We have observed that the features used to describe the coordination problem can be represented as vertex features of a latent graph structure. Here, we present TransfQMix, a new approach that uses transformers to leverage this latent structure and learn better coordination policies. Our transformer agents perform a graph reasoning over the state of the observable entities. Our transformer Q-mixer learns a monotonic mixing-function from a larger graph that includes the internal and external states of the agents. TransfQMix is designed to be entirely transferable, meaning that same parameters can be used to control and train larger or smaller teams of agents. This enables to deploy promising approaches to save training time and derive general policies in MARL, such as transfer learning, zero-shot transfer, and curriculum learning. We report TransfQMix's performances in the Spread and StarCraft II environments. In both settings, it outperforms state-of-the-art Q-Learning models, and it demonstrates effectiveness in solving problems that other methods can not solve.",
        "published": "2023-01-13T00:07:08Z",
        "link": "http://arxiv.org/abs/2301.05334v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Decentralized model-free reinforcement learning in stochastic games with   average-reward objective",
        "authors": [
            "Romain Cravic",
            "Nicolas Gast",
            "Bruno Gaujal"
        ],
        "summary": "We propose the first model-free algorithm that achieves low regret performance for decentralized learning in two-player zero-sum tabular stochastic games with infinite-horizon average-reward objective. In decentralized learning, the learning agent controls only one player and tries to achieve low regret performances against an arbitrary opponent. This contrasts with centralized learning where the agent tries to approximate the Nash equilibrium by controlling both players. In our infinite-horizon undiscounted setting, additional structure assumptions is needed to provide good behaviors of learning processes : here we assume for every strategy of the opponent, the agent has a way to go from any state to any other. This assumption is the analogous to the \"communicating\" assumption in the MDP setting. We show that our Decentralized Optimistic Nash Q-Learning (DONQ-learning) algorithm achieves both sublinear high probability regret of order $T^{3/4}$ and sublinear expected regret of order $T^{2/3}$. Moreover, our algorithm enjoys a low computational complexity and low memory space requirement compared to the previous works of (Wei et al. 2017) and (Jafarnia-Jahromi et al. 2021) in the same setting.",
        "published": "2023-01-13T15:59:53Z",
        "link": "http://arxiv.org/abs/2301.05630v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Mean-Field Control based Approximation of Multi-Agent Reinforcement   Learning in Presence of a Non-decomposable Shared Global State",
        "authors": [
            "Washim Uddin Mondal",
            "Vaneet Aggarwal",
            "Satish V. Ukkusuri"
        ],
        "summary": "Mean Field Control (MFC) is a powerful approximation tool to solve large-scale Multi-Agent Reinforcement Learning (MARL) problems. However, the success of MFC relies on the presumption that given the local states and actions of all the agents, the next (local) states of the agents evolve conditionally independent of each other. Here we demonstrate that even in a MARL setting where agents share a common global state in addition to their local states evolving conditionally independently (thus introducing a correlation between the state transition processes of individual agents), the MFC can still be applied as a good approximation tool. The global state is assumed to be non-decomposable i.e., it cannot be expressed as a collection of local states of the agents. We compute the approximation error as $\\mathcal{O}(e)$ where $e=\\frac{1}{\\sqrt{N}}\\left[\\sqrt{|\\mathcal{X}|} +\\sqrt{|\\mathcal{U}|}\\right]$. The size of the agent population is denoted by the term $N$, and $|\\mathcal{X}|, |\\mathcal{U}|$ respectively indicate the sizes of (local) state and action spaces of individual agents. The approximation error is found to be independent of the size of the shared global state space. We further demonstrate that in a special case if the reward and state transition functions are independent of the action distribution of the population, then the error can be improved to $e=\\frac{\\sqrt{|\\mathcal{X}|}}{\\sqrt{N}}$. Finally, we devise a Natural Policy Gradient based algorithm that solves the MFC problem with $\\mathcal{O}(\\epsilon^{-3})$ sample complexity and obtains a policy that is within $\\mathcal{O}(\\max\\{e,\\epsilon\\})$ error of the optimal MARL policy for any $\\epsilon>0$.",
        "published": "2023-01-13T18:55:58Z",
        "link": "http://arxiv.org/abs/2301.06889v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Distributed Optimal Formation Control for an Uncertain Multiagent System   in the Plane",
        "authors": [
            "Clinton Enwerem",
            "John Baras",
            "Danilo Romero"
        ],
        "summary": "In this paper, we present a distributed optimal multiagent control scheme for quadrotor formation tracking under localization errors. Our control architecture is based on a leader-follower approach, where a single leader quadrotor tracks a desired trajectory while the followers maintain their relative positions in a triangular formation. We begin by modeling the quadrotors as particles in the YZ-plane evolving under dynamics with uncertain state information. Next, by formulating the formation tracking task as an optimization problem -- with a constraint-augmented Lagrangian subject to dynamic constraints -- we solve for the control law that leads to an optimal solution in the control and trajectory error cost-minimizing sense. Results from numerical simulations show that for the planar quadrotor model considered -- with uncertainty in sensor measurements modeled as Gaussian noise -- the resulting optimal control is able to drive each agent to achieve the desired global objective: leader trajectory tracking with formation maintenance. Finally, we evaluate the performance of the control law using the tracking and formation errors of the multiagent system.",
        "published": "2023-01-14T07:26:18Z",
        "link": "http://arxiv.org/abs/2301.05841v2",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "CEDAS: A Compressed Decentralized Stochastic Gradient Method with   Improved Convergence",
        "authors": [
            "Kun Huang",
            "Shi Pu"
        ],
        "summary": "In this paper, we consider solving the distributed optimization problem over a multi-agent network under the communication restricted setting. We study a compressed decentralized stochastic gradient method, termed ``compressed exact diffusion with adaptive stepsizes (CEDAS)\", and show the method asymptotically achieves comparable convergence rate as centralized { stochastic gradient descent (SGD)} for both smooth strongly convex objective functions and smooth nonconvex objective functions under unbiased compression operators. In particular, to our knowledge, CEDAS enjoys so far the shortest transient time (with respect to the graph specifics) for achieving the convergence rate of centralized SGD, which behaves as $\\mathcal{O}(n{C^3}/(1-\\lambda_2)^{2})$ under smooth strongly convex objective functions, and $\\mathcal{O}(n^3{C^6}/(1-\\lambda_2)^4)$ under smooth nonconvex objective functions, where $(1-\\lambda_2)$ denotes the spectral gap of the mixing matrix, and $C>0$ is the compression-related parameter. In particular, CEDAS exhibits the shortest transient times when $C < \\mathcal{O}(1/(1 - \\lambda_2)^2)$, which is common in practice. Numerical experiments further demonstrate the effectiveness of the proposed algorithm.",
        "published": "2023-01-14T09:49:15Z",
        "link": "http://arxiv.org/abs/2301.05872v3",
        "categories": [
            "math.OC",
            "cs.DC",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Opponent-aware Role-based Learning in Team Competitive Markov Games",
        "authors": [
            "Paramita Koley",
            "Aurghya Maiti",
            "Niloy Ganguly",
            "Sourangshu Bhattacharya"
        ],
        "summary": "Team competition in multi-agent Markov games is an increasingly important setting for multi-agent reinforcement learning, due to its general applicability in modeling many real-life situations. Multi-agent actor-critic methods are the most suitable class of techniques for learning optimal policies in the team competition setting, due to their flexibility in learning agent-specific critic functions, which can also learn from other agents. In many real-world team competitive scenarios, the roles of the agents naturally emerge, in order to aid in coordination and collaboration within members of the teams. However, existing methods for learning emergent roles rely heavily on the Q-learning setup which does not allow learning of agent-specific Q-functions. In this paper, we propose RAC, a novel technique for learning the emergent roles of agents within a team that are diverse and dynamic. In the proposed method, agents also benefit from predicting the roles of the agents in the opponent team. RAC uses the actor-critic framework with role encoder and opponent role predictors for learning an optimal policy. Experimentation using 2 games demonstrates that the policies learned by RAC achieve higher rewards than those learned using state-of-the-art baselines. Moreover, experiments suggest that the agents in a team learn diverse and opponent-aware policies.",
        "published": "2023-01-14T09:50:48Z",
        "link": "http://arxiv.org/abs/2301.05873v1",
        "categories": [
            "cs.MA",
            "I.2.6"
        ]
    },
    {
        "title": "Collective Privacy Recovery: Data-sharing Coordination via Decentralized   Artificial Intelligence",
        "authors": [
            "Evangelos Pournaras",
            "Mark Christopher Ballandies",
            "Stefano Bennati",
            "Chien-fei Chen"
        ],
        "summary": "Collective privacy loss becomes a colossal problem, an emergency for personal freedoms and democracy. But, are we prepared to handle personal data as scarce resource and collectively share data under the doctrine: as little as possible, as much as necessary? We hypothesize a significant privacy recovery if a population of individuals, the data collective, coordinates to share minimum data for running online services with the required quality. Here we show how to automate and scale-up complex collective arrangements for privacy recovery using decentralized artificial intelligence. For this, we compare for first time attitudinal, intrinsic, rewarded and coordinated data sharing in a rigorous living-lab experiment of high realism involving >27,000 real data disclosures. Using causal inference and cluster analysis, we differentiate criteria predicting privacy and five key data-sharing behaviors. Strikingly, data-sharing coordination proves to be a win-win for all: remarkable privacy recovery for people with evident costs reduction for service providers.",
        "published": "2023-01-15T01:36:46Z",
        "link": "http://arxiv.org/abs/2301.05995v2",
        "categories": [
            "cs.AI",
            "cs.CY",
            "cs.DC",
            "cs.IR",
            "cs.MA"
        ]
    },
    {
        "title": "Cooperative Concurrent Games",
        "authors": [
            "Julian Gutierrez",
            "Szymon Kowara",
            "Sarit Kraus",
            "Thomas Steeples",
            "Michael Wooldridge"
        ],
        "summary": "In rational verification, the aim is to verify which temporal logic properties will obtain in a multi-agent system, under the assumption that agents (\"players\") in the system choose strategies for acting that form a game theoretic equilibrium. Preferences are typically defined by assuming that agents act in pursuit of individual goals, specified as temporal logic formulae. To date, rational verification has been studied using non-cooperative solution concepts - Nash equilibrium and refinements thereof. Such non-cooperative solution concepts assume that there is no possibility of agents forming binding agreements to cooperate, and as such they are restricted in their applicability. In this article, we extend rational verification to cooperative solution concepts, as studied in the field of cooperative game theory. We focus on the core, as this is the most fundamental (and most widely studied) cooperative solution concept. We begin by presenting a variant of the core that seems well-suited to the concurrent game setting, and we show that this version of the core can be characterised using ATL*. We then study the computational complexity of key decision problems associated with the core, which range from problems in PSPACE to problems in 3EXPTIME. We also investigate conditions that are sufficient to ensure that the core is non-empty, and explore when it is invariant under bisimilarity. We then introduce and study a number of variants of the main definition of the core, leading to the issue of credible deviations, and to stronger notions of collective stable behaviour. Finally, we study cooperative rational verification using an alternative model of preferences, in which players seek to maximise the mean-payoff they obtain over an infinite play in games where quantitative information is allowed.",
        "published": "2023-01-15T18:45:13Z",
        "link": "http://arxiv.org/abs/2301.06157v1",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Enforcing Privacy in Distributed Learning with Performance Guarantees",
        "authors": [
            "Elsa Rizk",
            "Stefan Vlaski",
            "Ali H. Sayed"
        ],
        "summary": "We study the privatization of distributed learning and optimization strategies. We focus on differential privacy schemes and study their effect on performance. We show that the popular additive random perturbation scheme degrades performance because it is not well-tuned to the graph structure. For this reason, we exploit two alternative graph-homomorphic constructions and show that they improve performance while guaranteeing privacy. Moreover, contrary to most earlier studies, the gradient of the risks is not assumed to be bounded (a condition that rarely holds in practice; e.g., quadratic risk). We avoid this condition and still devise a differentially private scheme with high probability. We examine optimization and learning scenarios and illustrate the theoretical findings through simulations.",
        "published": "2023-01-16T13:03:27Z",
        "link": "http://arxiv.org/abs/2301.06412v1",
        "categories": [
            "cs.LG",
            "cs.CR",
            "cs.MA"
        ]
    },
    {
        "title": "Does Spending More Always Ensure Higher Cooperation? An Analysis of   Institutional Incentives on Heterogeneous Networks",
        "authors": [
            "Theodor Cimpeanu",
            "Francisco C Santos",
            "The Anh Han"
        ],
        "summary": "Humans have developed considerable machinery used at scale to create policies and to distribute incentives, yet we are forever seeking ways in which to improve upon these, our institutions. Especially when funding is limited, it is imperative to optimise spending without sacrificing positive outcomes, a challenge which has often been approached within several areas of social, life and engineering sciences. These studies often neglect the availability of information, cost restraints, or the underlying complex network structures, which define real-world populations. Here, we have extended these models, including the aforementioned concerns, but also tested the robustness of their findings to stochastic social learning paradigms. Akin to real-world decisions on how best to distribute endowments, we study several incentive schemes, which consider information about the overall population, local neighbourhoods, or the level of influence which a cooperative node has in the network, selectively rewarding cooperative behaviour if certain criteria are met. Following a transition towards a more realistic network setting and stochastic behavioural update rule, we found that carelessly promoting cooperators can often lead to their downfall in socially diverse settings. These emergent cyclic patterns not only damage cooperation, but also decimate the budgets of external investors. Our findings highlight the complexity of designing effective and cogent investment policies in socially diverse populations.",
        "published": "2023-01-16T21:57:22Z",
        "link": "http://arxiv.org/abs/2301.06620v1",
        "categories": [
            "cs.MA",
            "cs.GT",
            "math.DS",
            "math.OC",
            "nlin.AO"
        ]
    },
    {
        "title": "Event-Triggered Optimal Formation Tracking Control Using Reinforcement   Learning for Large-Scale UAV Systems",
        "authors": [
            "Ziwei Yan",
            "Liang Han",
            "Xiaoduo Li",
            "Jinjie Li",
            "Zhang Ren"
        ],
        "summary": "Large-scale UAV switching formation tracking control has been widely applied in many fields such as search and rescue, cooperative transportation, and UAV light shows. In order to optimize the control performance and reduce the computational burden of the system, this study proposes an event-triggered optimal formation tracking controller for discrete-time large-scale UAV systems (UASs). And an optimal decision - optimal control framework is completed by introducing the Hungarian algorithm and actor-critic neural networks (NNs) implementation. Finally, a large-scale mixed reality experimental platform is built to verify the effectiveness of the proposed algorithm, which includes large-scale virtual UAV nodes and limited physical UAV nodes. This compensates for the limitations of the experimental field and equipment in realworld scenario, ensures the experimental safety, significantly reduces the experimental cost, and is suitable for realizing largescale UAV formation light shows.",
        "published": "2023-01-17T08:24:54Z",
        "link": "http://arxiv.org/abs/2301.06749v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Byzantine Resilience at Swarm Scale: A Decentralized Blocklist Protocol   from Inter-robot Accusations",
        "authors": [
            "Kacper Wardega",
            "Max von Hippel",
            "Roberto Tron",
            "Cristina Nita-Rotaru",
            "Wenchao Li"
        ],
        "summary": "The Weighted-Mean Subsequence Reduced (W-MSR) algorithm, the state-of-the-art method for Byzantine-resilient design of decentralized multi-robot systems, is based on discarding outliers received over Linear Consensus Protocol (LCP). Although W-MSR provides well-understood theoretical guarantees relating robust network connectivity to the convergence of the underlying consensus, the method comes with several limitations preventing its use at scale: (1) the number of Byzantine robots, F, to tolerate should be known a priori, (2) the requirement that each robot maintains 2F+1 neighbors is impractical for large F, (3) information propagation is hindered by the requirement that F+1 robots independently make local measurements of the consensus property in order for the swarm's decision to change, and (4) W-MSR is specific to LCP and does not generalize to applications not implemented over LCP. In this work, we propose a Decentralized Blocklist Protocol (DBP) based on inter-robot accusations. Accusations are made on the basis of locally-made observations of misbehavior, and once shared by cooperative robots across the network are used as input to a graph matching algorithm that computes a blocklist. DBP generalizes to applications not implemented via LCP, is adaptive to the number of Byzantine robots, and allows for fast information propagation through the multi-robot system while simultaneously reducing the required network connectivity relative to W-MSR. On LCP-type applications, DBP reduces the worst-case connectivity requirement of W-MSR from (2F+1)-connected to (F+1)-connected and the number of cooperative observers required to propagate new information from F+1 to just 1 observer. We demonstrate empirically that our approach to Byzantine resilience scales to hundreds of robots on cooperative target tracking, time synchronization, and localization case studies.",
        "published": "2023-01-17T16:02:44Z",
        "link": "http://arxiv.org/abs/2301.06977v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Heterogeneous Multi-Robot Reinforcement Learning",
        "authors": [
            "Matteo Bettini",
            "Ajay Shankar",
            "Amanda Prorok"
        ],
        "summary": "Cooperative multi-robot tasks can benefit from heterogeneity in the robots' physical and behavioral traits. In spite of this, traditional Multi-Agent Reinforcement Learning (MARL) frameworks lack the ability to explicitly accommodate policy heterogeneity, and typically constrain agents to share neural network parameters. This enforced homogeneity limits application in cases where the tasks benefit from heterogeneous behaviors. In this paper, we crystallize the role of heterogeneity in MARL policies. Towards this end, we introduce Heterogeneous Graph Neural Network Proximal Policy Optimization (HetGPPO), a paradigm for training heterogeneous MARL policies that leverages a Graph Neural Network for differentiable inter-agent communication. HetGPPO allows communicating agents to learn heterogeneous behaviors while enabling fully decentralized training in partially observable environments. We complement this with a taxonomical overview that exposes more heterogeneity classes than previously identified. To motivate the need for our model, we present a characterization of techniques that homogeneous models can leverage to emulate heterogeneous behavior, and show how this \"apparent heterogeneity\" is brittle in real-world conditions. Through simulations and real-world experiments, we show that: (i) when homogeneous methods fail due to strong heterogeneous requirements, HetGPPO succeeds, and, (ii) when homogeneous methods are able to learn apparently heterogeneous behaviors, HetGPPO achieves higher resilience to both training and deployment noise.",
        "published": "2023-01-17T19:05:17Z",
        "link": "http://arxiv.org/abs/2301.07137v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "COVINS-G: A Generic Back-end for Collaborative Visual-Inertial SLAM",
        "authors": [
            "Manthan Patel",
            "Marco Karrer",
            "Philipp Bänninger",
            "Margarita Chli"
        ],
        "summary": "Collaborative SLAM is at the core of perception in multi-robot systems as it enables the co-localization of the team of robots in a common reference frame, which is of vital importance for any coordination amongst them. The paradigm of a centralized architecture is well established, with the robots (i.e. agents) running Visual-Inertial Odometry (VIO) onboard while communicating relevant data, such as e.g. Keyframes (KFs), to a central back-end (i.e. server), which then merges and optimizes the joint maps of the agents. While these frameworks have proven to be successful, their capability and performance are highly dependent on the choice of the VIO front-end, thus limiting their flexibility. In this work, we present COVINS-G, a generalized back-end building upon the COVINS framework, enabling the compatibility of the server-back-end with any arbitrary VIO front-end, including, for example, off-the-shelf cameras with odometry capabilities, such as the Realsense T265. The COVINS-G back-end deploys a multi-camera relative pose estimation algorithm for computing the loop-closure constraints allowing the system to work purely on 2D image data. In the experimental evaluation, we show on-par accuracy with state-of-the-art multi-session and collaborative SLAM systems, while demonstrating the flexibility and generality of our approach by employing different front-ends onboard collaborating agents within the same mission. The COVINS-G codebase along with a generalized front-end wrapper to allow any existing VIO front-end to be readily used in combination with the proposed collaborative back-end is open-sourced. Video: https://youtu.be/FoJfXCfaYDw",
        "published": "2023-01-17T19:23:54Z",
        "link": "http://arxiv.org/abs/2301.07147v3",
        "categories": [
            "cs.RO",
            "cs.CV",
            "cs.MA"
        ]
    },
    {
        "title": "Learning to Participate through Trading of Reward Shares",
        "authors": [
            "Michael Kölle",
            "Tim Matheis",
            "Philipp Altmann",
            "Kyrill Schmid"
        ],
        "summary": "Enabling autonomous agents to act cooperatively is an important step to integrate artificial intelligence in our daily lives. While some methods seek to stimulate cooperation by letting agents give rewards to others, in this paper we propose a method inspired by the stock market, where agents have the opportunity to participate in other agents' returns by acquiring reward shares. Intuitively, an agent may learn to act according to the common interest when being directly affected by the other agents' rewards. The empirical results of the tested general-sum Markov games show that this mechanism promotes cooperative policies among independently trained agents in social dilemma situations. Moreover, as demonstrated in a temporally and spatially extended domain, participation can lead to the development of roles and the division of subtasks between the agents.",
        "published": "2023-01-18T10:25:55Z",
        "link": "http://arxiv.org/abs/2301.07416v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "An Ergonomic Role Allocation Framework for Dynamic Human-Robot   Collaborative Tasks",
        "authors": [
            "Elena Merlo",
            "Edoardo Lamon",
            "Fabio Fusaro",
            "Marta Lorenzini",
            "Alessandro Carfì",
            "Fulvio Mastrogiovanni",
            "Arash Ajoudani"
        ],
        "summary": "By incorporating ergonomics principles into the task allocation processes, human-robot collaboration (HRC) frameworks can favour the prevention of work-related musculoskeletal disorders (WMSDs). In this context, existing offline methodologies do not account for the variability of human actions and states; therefore, planning and dynamically assigning roles in human-robot teams remains an unaddressed challenge.This study aims to create an ergonomic role allocation framework that optimises the HRC, taking into account task features and human state measurements. The presented framework consists of two main modules: the first provides the HRC task model, exploiting AND/OR Graphs (AOG)s, which we adapted to solve the allocation problem; the second module describes the ergonomic risk assessment during task execution through a risk indicator and updates the AOG-related variables to influence future task allocation. The proposed framework can be combined with any time-varying ergonomic risk indicator that evaluates human cognitive and physical burden. In this work, we tested our framework in an assembly scenario, introducing a risk index named Kinematic Wear.The overall framework has been tested with a multi-subject experiment. The task allocation results and subjective evaluations, measured with questionnaires, show that high-risk actions are correctly recognised and not assigned to humans, reducing fatigue and frustration in collaborative tasks.",
        "published": "2023-01-19T10:59:06Z",
        "link": "http://arxiv.org/abs/2301.07999v1",
        "categories": [
            "cs.RO",
            "cs.HC",
            "cs.MA"
        ]
    },
    {
        "title": "Multi-Agent Interplay in a Competitive Survival Environment",
        "authors": [
            "Andrea Fanti"
        ],
        "summary": "Solving hard-exploration environments in an important challenge in Reinforcement Learning. Several approaches have been proposed and studied, such as Intrinsic Motivation, co-evolution of agents and tasks, and multi-agent competition. In particular, the interplay between multiple agents has proven to be capable of generating human-relevant emergent behaviour that would be difficult or impossible to learn in single-agent settings. In this work, an extensible competitive environment for multi-agent interplay was developed, which features realistic physics and human-relevant semantics. Moreover, several experiments on different variants of this environment were performed, resulting in some simple emergent strategies and concrete directions for future improvement. The content presented here is part of the author's thesis \"Multi-Agent Interplay in a Competitive Survival Environment\" for the Master's Degree in Artificial Intelligence and Robotics at Sapienza University of Rome, 2022.",
        "published": "2023-01-19T12:04:03Z",
        "link": "http://arxiv.org/abs/2301.08030v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "A Unified Architecture for Dynamic Role Allocation and Collaborative   Task Planning in Mixed Human-Robot Teams",
        "authors": [
            "Edoardo Lamon",
            "Fabio Fusaro",
            "Elena De Momi",
            "Arash Ajoudani"
        ],
        "summary": "The growing deployment of human-robot collaborative processes in several industrial applications, such as handling, welding, and assembly, unfolds the pursuit of systems which are able to manage large heterogeneous teams and, at the same time, monitor the execution of complex tasks. In this paper, we present a novel architecture for dynamic role allocation and collaborative task planning in a mixed human-robot team of arbitrary size. The architecture capitalizes on a centralized reactive and modular task-agnostic planning method based on Behavior Trees (BTs), in charge of actions scheduling, while the allocation problem is formulated through a Mixed-Integer Linear Program (MILP), that assigns dynamically individual roles or collaborations to the agents of the team. Different metrics used as MILP cost allow the architecture to favor various aspects of the collaboration (e.g. makespan, ergonomics, human preferences). Human preference are identified through a negotiation phase, in which, an human agent can accept/refuse to execute the assigned task.In addition, bilateral communication between humans and the system is achieved through an Augmented Reality (AR) custom user interface that provides intuitive functionalities to assist and coordinate workers in different action phases. The computational complexity of the proposed methodology outperforms literature approaches in industrial sized jobs and teams (problems up to 50 actions and 20 agents in the team with collaborations are solved within 1 s). The different allocated roles, as the cost functions change, highlights the flexibility of the architecture to several production requirements. Finally, the subjective evaluation demonstrating the high usability level and the suitability for the targeted scenario.",
        "published": "2023-01-19T12:30:56Z",
        "link": "http://arxiv.org/abs/2301.08038v2",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.HC",
            "cs.MA"
        ]
    },
    {
        "title": "Individual Fairness for Social Media Influencers",
        "authors": [
            "Stefania Ionescu",
            "Nicolo Pagan",
            "Aniko Hannak"
        ],
        "summary": "Nowadays, many social media platforms are centered around content creators (CC). On these platforms, the tie formation process depends on two factors: (a) the exposure of users to CCs (decided by, e.g., a recommender system), and (b) the following decision-making process of users. Recent research studies underlined the importance of content quality by showing that under exploratory recommendation strategies, the network eventually converges to a state where the higher the quality of the CC, the higher their expected number of followers. In this paper, we extend prior work by (a) looking beyond averages to assess the fairness of the process and (b) investigating the importance of exploratory recommendations for achieving fair outcomes. Using an analytical approach, we show that non-exploratory recommendations converge fast but usually lead to unfair outcomes. Moreover, even with exploration, we are only guaranteed fair outcomes for the highest (and lowest) quality CCs.",
        "published": "2023-01-19T17:07:46Z",
        "link": "http://arxiv.org/abs/2301.08177v1",
        "categories": [
            "cs.SI",
            "cs.MA"
        ]
    },
    {
        "title": "Investigating the Impact of Direct Punishment on the Emergence of   Cooperation in Multi-Agent Reinforcement Learning Systems",
        "authors": [
            "Nayana Dasgupta",
            "Mirco Musolesi"
        ],
        "summary": "Solving the problem of cooperation is fundamentally important for the creation and maintenance of functional societies. Problems of cooperation are omnipresent within human society, with examples ranging from navigating busy road junctions to negotiating treaties. As the use of AI becomes more pervasive throughout society, the need for socially intelligent agents capable of navigating these complex cooperative dilemmas is becoming increasingly evident. Direct punishment is a ubiquitous social mechanism that has been shown to foster the emergence of cooperation in both humans and non-humans. In the natural world, direct punishment is often strongly coupled with partner selection and reputation and used in conjunction with third-party punishment. The interactions between these mechanisms could potentially enhance the emergence of cooperation within populations. However, no previous work has evaluated the learning dynamics and outcomes emerging from Multi-Agent Reinforcement Learning (MARL) populations that combine these mechanisms. This paper addresses this gap. It presents a comprehensive analysis and evaluation of the behaviors and learning dynamics associated with direct punishment, third-party punishment, partner selection, and reputation. Finally, we discuss the implications of using these mechanisms on the design of cooperative AI systems.",
        "published": "2023-01-19T19:33:54Z",
        "link": "http://arxiv.org/abs/2301.08278v3",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Accelerating Multi-Agent Planning Using Graph Transformers with Bounded   Suboptimality",
        "authors": [
            "Chenning Yu",
            "Qingbiao Li",
            "Sicun Gao",
            "Amanda Prorok"
        ],
        "summary": "Conflict-Based Search is one of the most popular methods for multi-agent path finding. Though it is complete and optimal, it does not scale well. Recent works have been proposed to accelerate it by introducing various heuristics. However, whether these heuristics can apply to non-grid-based problem settings while maintaining their effectiveness remains an open question. In this work, we find that the answer is prone to be no. To this end, we propose a learning-based component, i.e., the Graph Transformer, as a heuristic function to accelerate the planning. The proposed method is provably complete and bounded-suboptimal with any desired factor. We conduct extensive experiments on two environments with dense graphs. Results show that the proposed Graph Transformer can be trained in problem instances with relatively few agents and generalizes well to a larger number of agents, while achieving better performance than state-of-the-art methods.",
        "published": "2023-01-20T07:22:24Z",
        "link": "http://arxiv.org/abs/2301.08451v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Modeling Moral Choices in Social Dilemmas with Multi-Agent Reinforcement   Learning",
        "authors": [
            "Elizaveta Tennant",
            "Stephen Hailes",
            "Mirco Musolesi"
        ],
        "summary": "Practical uses of Artificial Intelligence (AI) in the real world have demonstrated the importance of embedding moral choices into intelligent agents. They have also highlighted that defining top-down ethical constraints on AI according to any one type of morality is extremely challenging and can pose risks. A bottom-up learning approach may be more appropriate for studying and developing ethical behavior in AI agents. In particular, we believe that an interesting and insightful starting point is the analysis of emergent behavior of Reinforcement Learning (RL) agents that act according to a predefined set of moral rewards in social dilemmas.   In this work, we present a systematic analysis of the choices made by intrinsically-motivated RL agents whose rewards are based on moral theories. We aim to design reward structures that are simplified yet representative of a set of key ethical systems. Therefore, we first define moral reward functions that distinguish between consequence- and norm-based agents, between morality based on societal norms or internal virtues, and between single- and mixed-virtue (e.g., multi-objective) methodologies. Then, we evaluate our approach by modeling repeated dyadic interactions between learning moral agents in three iterated social dilemma games (Prisoner's Dilemma, Volunteer's Dilemma and Stag Hunt). We analyze the impact of different types of morality on the emergence of cooperation, defection or exploitation, and the corresponding social outcomes. Finally, we discuss the implications of these findings for the development of moral agents in artificial and mixed human-AI societies.",
        "published": "2023-01-20T09:36:42Z",
        "link": "http://arxiv.org/abs/2301.08491v3",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Towards Multi-robot Exploration: A Decentralized Strategy for UAV Forest   Exploration",
        "authors": [
            "Luca Bartolomei",
            "Lucas Teixeira",
            "Margarita Chli"
        ],
        "summary": "Efficient exploration strategies are vital in tasks such as search-and-rescue missions and disaster surveying. Unmanned Aerial Vehicles (UAVs) have become particularly popular in such applications, promising to cover large areas at high speeds. Moreover, with the increasing maturity of onboard UAV perception, research focus has been shifting toward higher-level reasoning for single- and multi-robot missions. However, autonomous navigation and exploration of previously unknown large spaces still constitutes an open challenge, especially when the environment is cluttered and exhibits large and frequent occlusions due to high obstacle density, as is the case of forests. Moreover, the problem of long-distance wireless communication in such scenes can become a limiting factor, especially when automating the navigation of a UAV swarm. In this spirit, this work proposes an exploration strategy that enables UAVs, both individually and in small swarms, to quickly explore complex scenes in a decentralized fashion. By providing the decision-making capabilities to each UAV to switch between different execution modes, the proposed strategy strikes a great balance between cautious exploration of yet completely unknown regions and more aggressive exploration of smaller areas of unknown space. This results in full coverage of forest areas of variable density, consistently faster than the state of the art. Demonstrating successful deployment with a single UAV as well as a swarm of up to three UAVs, this work sets out the basic principles for multi-root exploration of cluttered scenes, with up to 65% speed up in the single UAV case and 40% increase in explored area for the same mission time in multi-UAV setups.",
        "published": "2023-01-20T12:47:52Z",
        "link": "http://arxiv.org/abs/2301.08537v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Verse: A Python library for reasoning about multi-agent hybrid system   scenarios",
        "authors": [
            "Yangge Li",
            "Haoqing Zhu",
            "Katherine Braught",
            "Keyi Shen",
            "Sayan Mitra"
        ],
        "summary": "We present the Verse library with the aim of making hybrid system verification more usable for multi-agent scenarios. In Verse, decision making agents move in a map and interact with each other through sensors. The decision logic for each agent is written in a subset of Python and the continuous dynamics is given by a black-box simulator. Multiple agents can be instantiated and they can be ported to different maps for creating scenarios. Verse provides functions for simulating and verifying such scenarios using existing reachability analysis algorithms. We illustrate several capabilities and use cases of the library with heterogeneous agents, incremental verification, different sensor models, and the flexibility of plugging in different subroutines for post computations.",
        "published": "2023-01-20T18:18:09Z",
        "link": "http://arxiv.org/abs/2301.08714v2",
        "categories": [
            "cs.SE",
            "cs.FL",
            "cs.MA"
        ]
    },
    {
        "title": "Differential Privacy in Cooperative Multiagent Planning",
        "authors": [
            "Bo Chen",
            "Calvin Hawkins",
            "Mustafa O. Karabag",
            "Cyrus Neary",
            "Matthew Hale",
            "Ufuk Topcu"
        ],
        "summary": "Privacy-aware multiagent systems must protect agents' sensitive data while simultaneously ensuring that agents accomplish their shared objectives. Towards this goal, we propose a framework to privatize inter-agent communications in cooperative multiagent decision-making problems. We study sequential decision-making problems formulated as cooperative Markov games with reach-avoid objectives. We apply a differential privacy mechanism to privatize agents' communicated symbolic state trajectories, and then we analyze tradeoffs between the strength of privacy and the team's performance. For a given level of privacy, this tradeoff is shown to depend critically upon the total correlation among agents' state-action processes. We synthesize policies that are robust to privacy by reducing the value of the total correlation. Numerical experiments demonstrate that the team's performance under these policies decreases by only 3 percent when comparing private versus non-private implementations of communication. By contrast, the team's performance decreases by roughly 86 percent when using baseline policies that ignore total correlation and only optimize team performance.",
        "published": "2023-01-20T21:36:57Z",
        "link": "http://arxiv.org/abs/2301.08811v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.CR"
        ]
    },
    {
        "title": "ApproxED: Approximate exploitability descent via learned best responses",
        "authors": [
            "Carlos Martin",
            "Tuomas Sandholm"
        ],
        "summary": "There has been substantial progress on finding game-theoretic equilibria. Most of that work has focused on games with finite, discrete action spaces. However, many games involving space, time, money, and other fine-grained quantities have continuous action spaces (or are best modeled as having such). We study the problem of finding an approximate Nash equilibrium of games with continuous action sets. The standard measure of closeness to Nash equilibrium is exploitability, which measures how much players can benefit from unilaterally changing their strategy. We propose two new methods that minimize an approximation of exploitability with respect to the strategy profile. The first method uses a learned best-response function, which takes the current strategy profile as input and outputs candidate best responses for each player. The strategy profile and best-response functions are trained simultaneously, with the former trying to minimize exploitability while the latter tries to maximize it. The second method maintains an ensemble of candidate best responses for each player. In each iteration, the best-performing elements of each ensemble are used to update the current strategy profile. The strategy profile and ensembles are simultaneously trained to minimize and maximize the approximate exploitability, respectively. We evaluate our methods on various continuous games and GAN training, showing that they outperform prior methods.",
        "published": "2023-01-20T23:55:30Z",
        "link": "http://arxiv.org/abs/2301.08830v3",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Decentralized Multi-agent Filtering",
        "authors": [
            "Dom Huh",
            "Prasant Mohapatra"
        ],
        "summary": "This paper addresses the considerations that comes along with adopting decentralized communication for multi-agent localization applications in discrete state spaces. In this framework, we extend the original formulation of the Bayes filter, a foundational probabilistic tool for discrete state estimation, by appending a step of greedy belief sharing as a method to propagate information and improve local estimates' posteriors. We apply our work in a model-based multi-agent grid-world setting, where each agent maintains a belief distribution for every agents' state. Our results affirm the utility of our proposed extensions for decentralized collaborative tasks. The code base for this work is available in the following repo",
        "published": "2023-01-21T02:41:32Z",
        "link": "http://arxiv.org/abs/2301.08864v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Doubly Adversarial Federated Bandits",
        "authors": [
            "Jialin Yi",
            "Milan Vojnović"
        ],
        "summary": "We study a new non-stochastic federated multi-armed bandit problem with multiple agents collaborating via a communication network. The losses of the arms are assigned by an oblivious adversary that specifies the loss of each arm not only for each time step but also for each agent, which we call ``doubly adversarial\". In this setting, different agents may choose the same arm in the same time step but observe different feedback. The goal of each agent is to find a globally best arm in hindsight that has the lowest cumulative loss averaged over all agents, which necessities the communication among agents. We provide regret lower bounds for any federated bandit algorithm under different settings, when agents have access to full-information feedback, or the bandit feedback. For the bandit feedback setting, we propose a near-optimal federated bandit algorithm called FEDEXP3. Our algorithm gives a positive answer to an open question proposed in Cesa-Bianchi et al. (2016): FEDEXP3 can guarantee a sub-linear regret without exchanging sequences of selected arm identities or loss sequences among agents. We also provide numerical evaluations of our algorithm to validate our theoretical results and demonstrate its effectiveness on synthetic and real-world datasets",
        "published": "2023-01-22T22:36:43Z",
        "link": "http://arxiv.org/abs/2301.09223v2",
        "categories": [
            "stat.ML",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Asymptotic Convergence and Performance of Multi-Agent Q-Learning   Dynamics",
        "authors": [
            "Aamal Abbas Hussain",
            "Francesco Belardinelli",
            "Georgios Piliouras"
        ],
        "summary": "Achieving convergence of multiple learning agents in general $N$-player games is imperative for the development of safe and reliable machine learning (ML) algorithms and their application to autonomous systems. Yet it is known that, outside the bounds of simple two-player games, convergence cannot be taken for granted.   To make progress in resolving this problem, we study the dynamics of smooth Q-Learning, a popular reinforcement learning algorithm which quantifies the tendency for learning agents to explore their state space or exploit their payoffs. We show a sufficient condition on the rate of exploration such that the Q-Learning dynamics is guaranteed to converge to a unique equilibrium in any game. We connect this result to games for which Q-Learning is known to converge with arbitrary exploration rates, including weighted Potential games and weighted zero sum polymatrix games.   Finally, we examine the performance of the Q-Learning dynamic as measured by the Time Averaged Social Welfare, and comparing this with the Social Welfare achieved by the equilibrium. We provide a sufficient condition whereby the Q-Learning dynamic will outperform the equilibrium even if the dynamics do not converge.",
        "published": "2023-01-23T18:39:11Z",
        "link": "http://arxiv.org/abs/2301.09619v1",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.MA",
            "math.DS",
            "93A16, 91A26, 91A68, 58K35",
            "G.3; J.4; F.2.2"
        ]
    },
    {
        "title": "Graph Neural Networks for Decentralized Multi-Agent Perimeter Defense",
        "authors": [
            "Elijah S. Lee",
            "Lifeng Zhou",
            "Alejandro Ribeiro",
            "Vijay Kumar"
        ],
        "summary": "In this work, we study the problem of decentralized multi-agent perimeter defense that asks for computing actions for defenders with local perceptions and communications to maximize the capture of intruders. One major challenge for practical implementations is to make perimeter defense strategies scalable for large-scale problem instances. To this end, we leverage graph neural networks (GNNs) to develop an imitation learning framework that learns a mapping from defenders' local perceptions and their communication graph to their actions. The proposed GNN-based learning network is trained by imitating a centralized expert algorithm such that the learned actions are close to that generated by the expert algorithm. We demonstrate that our proposed network performs closer to the expert algorithm and is superior to other baseline algorithms by capturing more intruders. Our GNN-based network is trained at a small scale and can be generalized to large-scale cases. We run perimeter defense games in scenarios with different team sizes and configurations to demonstrate the performance of the learned network.",
        "published": "2023-01-23T19:35:59Z",
        "link": "http://arxiv.org/abs/2301.09689v1",
        "categories": [
            "cs.MA",
            "cs.LG"
        ]
    },
    {
        "title": "Two-sided Competing Matching Recommendation Markets With Quota and   Complementary Preferences Constraints",
        "authors": [
            "Yuantong Li",
            "Guang Cheng",
            "Xiaowu Dai"
        ],
        "summary": "In this paper, we propose a new recommendation algorithm for addressing the problem of two-sided online matching markets with complementary preferences and quota constraints, where agents' preferences are unknown a priori and must be learned from data. The presence of mixed quota and complementary preferences constraints can lead to instability in the matching process, making this problem challenging to solve. To overcome this challenge, we formulate the problem as a bandit learning framework and propose the Multi-agent Multi-type Thompson Sampling (MMTS) algorithm. The algorithm combines the strengths of Thompson Sampling for exploration with a new double matching technique to provide a stable matching outcome. Our theoretical analysis demonstrates the effectiveness of MMTS as it can achieve stability and has a total $\\widetilde{\\mathcal{O}}(Q{\\sqrt{K_{\\max}T}})$-Bayesian regret with high probability, which exhibits linearity with respect to the total firm's quota $Q$, the square root of the maximum size of available type workers $\\sqrt{K_{\\max}}$ and time horizon $T$. In addition, simulation studies also demonstrate MMTS's effectiveness in various settings. We provide code used in our experiments \\url{https://github.com/Likelyt/Double-Matching}.",
        "published": "2023-01-24T18:54:29Z",
        "link": "http://arxiv.org/abs/2301.10230v3",
        "categories": [
            "stat.ML",
            "cs.GT",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "In Which Graph Structures Can We Efficiently Find Temporally Disjoint   Paths and Walks?",
        "authors": [
            "Pascal Kunz",
            "Hendrik Molter",
            "Meirav Zehavi"
        ],
        "summary": "A temporal graph has an edge set that may change over discrete time steps, and a temporal path (or walk) must traverse edges that appear at increasing time steps. Accordingly, two temporal paths (or walks) are temporally disjoint if they do not visit any vertex at the same time. The study of the computational complexity of finding temporally disjoint paths or walks in temporal graphs has recently been initiated by Klobas et al. [IJCAI '21]. This problem is motivated by applications in multi-agent path finding (MAPF), which include robotics, warehouse management, aircraft management, and traffic routing.   We extend Klobas et al.'s research by providing parameterized hardness results for very restricted cases, with a focus on structural parameters of the so-called underlying graph. On the positive side, we identify sufficiently simple cases where we can solve the problem efficiently. Our results reveal some surprising differences between the \"path version\" and the \"walk version\" (where vertices may be visited multiple times) of the problem, and answer several open questions posed by Klobas et al.",
        "published": "2023-01-25T10:27:11Z",
        "link": "http://arxiv.org/abs/2301.10503v1",
        "categories": [
            "cs.DS",
            "cs.DM",
            "cs.MA"
        ]
    },
    {
        "title": "AI Tool for Exploring How Economic Activities Impact Local Ecosystems",
        "authors": [
            "Claes Strannegård",
            "Niklas Engsner",
            "Rasmus Lindgren",
            "Simon Olsson",
            "John Endler"
        ],
        "summary": "We present an AI-based ecosystem simulator that uses three-dimensional models of the terrain and animal models controlled by deep reinforcement learning. The simulations take place in a game engine environment, which enables continuous visual observation of the ecosystem model. The terrain models are generated from geographic data with altitudes and land cover type. The animal models combine three-dimensional conformation models with animation schemes and decision-making mechanisms trained with deep reinforcement learning in increasingly complex environments (curriculum learning). We show how AI tools of this kind can be used for modeling the development of specific ecosystems with and without different forms of economic activities. In particular, we show how they might be used for modeling local biodiversity effects of land cover change, exploitation of natural resources, pollution, invasive species, and climate change.",
        "published": "2023-01-25T10:34:17Z",
        "link": "http://arxiv.org/abs/2301.10507v2",
        "categories": [
            "cs.MA",
            "92B20",
            "I.2.6; J.3"
        ]
    },
    {
        "title": "DIFFER: Decomposing Individual Reward for Fair Experience Replay in   Multi-Agent Reinforcement Learning",
        "authors": [
            "Xunhan Hu",
            "Jian Zhao",
            "Wengang Zhou",
            "Ruili Feng",
            "Houqiang Li"
        ],
        "summary": "Cooperative multi-agent reinforcement learning (MARL) is a challenging task, as agents must learn complex and diverse individual strategies from a shared team reward. However, existing methods struggle to distinguish and exploit important individual experiences, as they lack an effective way to decompose the team reward into individual rewards. To address this challenge, we propose DIFFER, a powerful theoretical framework for decomposing individual rewards to enable fair experience replay in MARL. By enforcing the invariance of network gradients, we establish a partial differential equation whose solution yields the underlying individual reward function. The individual TD-error can then be computed from the solved closed-form individual rewards, indicating the importance of each piece of experience in the learning task and guiding the training process. Our method elegantly achieves an equivalence to the original learning framework when individual experiences are homogeneous, while also adapting to achieve more muscular efficiency and fairness when diversity is observed.Our extensive experiments on popular benchmarks validate the effectiveness of our theory and method, demonstrating significant improvements in learning efficiency and fairness.",
        "published": "2023-01-25T13:27:05Z",
        "link": "http://arxiv.org/abs/2301.10574v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "EFX Exists for Four Agents with Three Types of Valuations",
        "authors": [
            "Pratik Ghosal",
            "Vishwa Prakash H. V.",
            "Prajakta Nimbhorkar",
            "Nithin Varma"
        ],
        "summary": "In this paper, we address the problem of determining an envy-free allocation of indivisible goods among multiple agents. EFX, which stands for envy-free up to any good, is a well-studied problem that has been shown to exist for specific scenarios, such as when there are only three agents with MMS valuations, as demonstrated by Chaudhury et al(2020), and for any number of agents when there are only two types of valuations as shown by Mahara(2020). Our contribution is to extend these results by showing that EFX exists for four agents with three distinct valuations. We further generalize this to show the existance of EFX allocations for n agents when n-2 of them have identical valuations.",
        "published": "2023-01-25T15:15:59Z",
        "link": "http://arxiv.org/abs/2301.10632v1",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Effect of Swarm Density on Collective Tracking Performance",
        "authors": [
            "Hian Lee Kwa",
            "Julien Philippot",
            "Roland Bouffanais"
        ],
        "summary": "How does the size of a swarm affect its collective action? Despite being arguably a key parameter, no systematic and satisfactory guiding principles exist to select the number of units required for a given task and environment. Even when limited by practical considerations, system designers should endeavor to identify what a reasonable swarm size should be. Here, we show that this fundamental question is closely linked to that of selecting an appropriate swarm density. Our analysis of the influence of density on the collective performance of a target tracking task reveals different `phases' corresponding to markedly distinct group dynamics. We identify a `transition' phase, in which a complex emergent collective response arises. Interestingly, the collective dynamics within this transition phase exhibit a clear trade-off between exploratory actions and exploitative ones. We show that at any density, the exploration-exploitation balance can be adjusted to maximize the system's performance through various means, such as by changing the level of connectivity between agents. While the density is the primary factor to be considered, it should not be the sole one to be accounted for when sizing the system. Due to the inherent finite-size effects present in physical systems, we establish that the number of constituents primarily affects system-level properties such as exploitation in the transition phase. These results illustrate that instead of learning and optimizing a swarm's behavior for a specific set of task parameters, further work should instead concentrate on learning to be adaptive, thereby endowing the swarm with the highly desirable feature of being able to operate effectively over a wide range of circumstances.",
        "published": "2023-01-25T16:54:26Z",
        "link": "http://arxiv.org/abs/2301.10692v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "HoLA Robots: Mitigating Plan-Deviation Attacks in Multi-Robot Systems   with Co-Observations and Horizon-Limiting Announcements",
        "authors": [
            "Kacper Wardega",
            "Max von Hippel",
            "Roberto Tron",
            "Cristina Nita-Rotaru",
            "Wenchao Li"
        ],
        "summary": "Emerging multi-robot systems rely on cooperation between humans and robots, with robots following automatically generated motion plans to service application-level tasks. Given the safety requirements associated with operating in proximity to humans and expensive infrastructure, it is important to understand and mitigate the security vulnerabilities of such systems caused by compromised robots who diverge from their assigned plans. We focus on centralized systems, where a *central entity* (CE) is responsible for determining and transmitting the motion plans to the robots, which report their location as they move following the plan. The CE checks that robots follow their assigned plans by comparing their expected location to the location they self-report. We show that this self-reporting monitoring mechanism is vulnerable to *plan-deviation attacks* where compromised robots don't follow their assigned plans while trying to conceal their movement by mis-reporting their location. We propose a two-pronged mitigation for plan-deviation attacks: (1) an attack detection technique leveraging both the robots' local sensing capabilities to report observations of other robots and *co-observation schedules* generated by the CE, and (2) a prevention technique where the CE issues *horizon-limiting announcements* to the robots, reducing their instantaneous knowledge of forward lookahead steps in the global motion plan. On a large-scale automated warehouse benchmark, we show that our solution enables attack prevention guarantees from a stealthy attacker that has compromised multiple robots.",
        "published": "2023-01-25T17:11:14Z",
        "link": "http://arxiv.org/abs/2301.10704v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Periodic Multi-Agent Path Planning",
        "authors": [
            "Kazumi Kasaura",
            "Ryo Yonetani",
            "Mai Nishimura"
        ],
        "summary": "Multi-agent path planning (MAPP) is the problem of planning collision-free trajectories from start to goal locations for a team of agents. This work explores a relatively unexplored setting of MAPP where streams of agents have to go through the starts and goals with high throughput. We tackle this problem by formulating a new variant of MAPP called periodic MAPP in which the timing of agent appearances is periodic. The objective with periodic MAPP is to find a periodic plan, a set of collision-free trajectories that the agent streams can use repeatedly over periods, with periods that are as small as possible. To meet this objective, we propose a solution method that is based on constraint relaxation and optimization. We show that the periodic plans once found can be used for a more practical case in which agents in a stream can appear at random times. We confirm the effectiveness of our method compared with baseline methods in terms of throughput in several scenarios that abstract autonomous intersection management tasks.",
        "published": "2023-01-26T02:40:56Z",
        "link": "http://arxiv.org/abs/2301.10910v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Multi-Agent Congestion Cost Minimization With Linear Function   Approximations",
        "authors": [
            "Prashant Trivedi",
            "Nandyala Hemachandra"
        ],
        "summary": "This work considers multiple agents traversing a network from a source node to the goal node. The cost to an agent for traveling a link has a private as well as a congestion component. The agent's objective is to find a path to the goal node with minimum overall cost in a decentralized way. We model this as a fully decentralized multi-agent reinforcement learning problem and propose a novel multi-agent congestion cost minimization (MACCM) algorithm. Our MACCM algorithm uses linear function approximations of transition probabilities and the global cost function. In the absence of a central controller and to preserve privacy, agents communicate the cost function parameters to their neighbors via a time-varying communication network. Moreover, each agent maintains its estimate of the global state-action value, which is updated via a multi-agent extended value iteration (MAEVI) sub-routine. We show that our MACCM algorithm achieves a sub-linear regret. The proof requires the convergence of cost function parameters, the MAEVI algorithm, and analysis of the regret bounds induced by the MAEVI triggering condition for each agent. We implement our algorithm on a two node network with multiple links to validate it. We first identify the optimal policy, the optimal number of agents going to the goal node in each period. We observe that the average regret is close to zero for 2 and 3 agents. The optimal policy captures the trade-off between the minimum cost of staying at a node and the congestion cost of going to the goal node. Our work is a generalization of learning the stochastic shortest path problem.",
        "published": "2023-01-26T08:45:44Z",
        "link": "http://arxiv.org/abs/2301.10993v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Cluster Forming of Multiagent Systems in Rolling Horizon Games with   Non-uniform Horizons",
        "authors": [
            "Yurid Nugraha",
            "Ahmet Cetinkaya",
            "Tomohisa Hayakawa",
            "Hideaki Ishii",
            "Quanyan Zhu"
        ],
        "summary": "Consensus and cluster forming of multiagent systems in the face of jamming attacks along with reactive recovery actions by a defender are discussed. The attacker is capable to disable some of the edges of the network with the objective to divide the agents into a smaller size of clusters while, in response, the defender recovers some of the edges by increasing the transmission power. We consider repeated games where the resulting optimal strategies for the two players are derived in a rolling horizon fashion. The attacker and the defender possess different computational abilities to calculate their strategies. This aspect is represented by the non-uniform values of the horizon lengths and the game periods. Theoretical and simulation based results demonstrate the effects of the horizon lengths and the game periods on the agents' states.",
        "published": "2023-01-26T14:59:43Z",
        "link": "http://arxiv.org/abs/2301.11152v1",
        "categories": [
            "eess.SY",
            "cs.GT",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Learning from Multiple Independent Advisors in Multi-agent Reinforcement   Learning",
        "authors": [
            "Sriram Ganapathi Subramanian",
            "Matthew E. Taylor",
            "Kate Larson",
            "Mark Crowley"
        ],
        "summary": "Multi-agent reinforcement learning typically suffers from the problem of sample inefficiency, where learning suitable policies involves the use of many data samples. Learning from external demonstrators is a possible solution that mitigates this problem. However, most prior approaches in this area assume the presence of a single demonstrator. Leveraging multiple knowledge sources (i.e., advisors) with expertise in distinct aspects of the environment could substantially speed up learning in complex environments. This paper considers the problem of simultaneously learning from multiple independent advisors in multi-agent reinforcement learning. The approach leverages a two-level Q-learning architecture, and extends this framework from single-agent to multi-agent settings. We provide principled algorithms that incorporate a set of advisors by both evaluating the advisors at each state and subsequently using the advisors to guide action selection. We also provide theoretical convergence and sample complexity guarantees. Experimentally, we validate our approach in three different test-beds and show that our algorithms give better performances than baselines, can effectively integrate the combined expertise of different advisors, and learn to ignore bad advice.",
        "published": "2023-01-26T15:00:23Z",
        "link": "http://arxiv.org/abs/2301.11153v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Distributed Optimization Methods for Multi-Robot Systems: Part I -- A   Tutorial",
        "authors": [
            "Ola Shorinwa",
            "Trevor Halsted",
            "Javier Yu",
            "Mac Schwager"
        ],
        "summary": "Distributed optimization provides a framework for deriving distributed algorithms for a variety of multi-robot problems. This tutorial constitutes the first part of a two-part series on distributed optimization applied to multi-robot problems, which seeks to advance the application of distributed optimization in robotics. In this tutorial, we demonstrate that many canonical multi-robot problems can be cast within the distributed optimization framework, such as multi-robot simultaneous localization and planning (SLAM), multi-robot target tracking, and multi-robot task assignment problems. We identify three broad categories of distributed optimization algorithms: distributed first-order methods, distributed sequential convex programming, and the alternating direction method of multipliers (ADMM). We describe the basic structure of each category and provide representative algorithms within each category. We then work through a simulation case study of multiple drones collaboratively tracking a ground vehicle. We compare solutions to this problem using a number of different distributed optimization algorithms. In addition, we implement a distributed optimization algorithm in hardware on a network of Rasberry Pis communicating with XBee modules to illustrate robustness to the challenges of real-world communication networks.",
        "published": "2023-01-26T18:52:07Z",
        "link": "http://arxiv.org/abs/2301.11313v3",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Distributed Optimization Methods for Multi-Robot Systems: Part II -- A   Survey",
        "authors": [
            "Ola Shorinwa",
            "Trevor Halsted",
            "Javier Yu",
            "Mac Schwager"
        ],
        "summary": "Although the field of distributed optimization is well-developed, relevant literature focused on the application of distributed optimization to multi-robot problems is limited. This survey constitutes the second part of a two-part series on distributed optimization applied to multi-robot problems. In this paper, we survey three main classes of distributed optimization algorithms -- distributed first-order methods, distributed sequential convex programming methods, and alternating direction method of multipliers (ADMM) methods -- focusing on fully-distributed methods that do not require coordination or computation by a central computer. We describe the fundamental structure of each category and note important variations around this structure, designed to address its associated drawbacks. Further, we provide practical implications of noteworthy assumptions made by distributed optimization algorithms, noting the classes of robotics problems suitable for these algorithms. Moreover, we identify important open research challenges in distributed optimization, specifically for robotics problems.",
        "published": "2023-01-26T19:17:41Z",
        "link": "http://arxiv.org/abs/2301.11361v3",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Are Equivariant Equilibrium Approximators Beneficial?",
        "authors": [
            "Zhijian Duan",
            "Yunxuan Ma",
            "Xiaotie Deng"
        ],
        "summary": "Recently, remarkable progress has been made by approximating Nash equilibrium (NE), correlated equilibrium (CE), and coarse correlated equilibrium (CCE) through function approximation that trains a neural network to predict equilibria from game representations. Furthermore, equivariant architectures are widely adopted in designing such equilibrium approximators in normal-form games. In this paper, we theoretically characterize benefits and limitations of equivariant equilibrium approximators. For the benefits, we show that they enjoy better generalizability than general ones and can achieve better approximations when the payoff distribution is permutation-invariant. For the limitations, we discuss their drawbacks in terms of equilibrium selection and social welfare. Together, our results help to understand the role of equivariance in equilibrium approximators.",
        "published": "2023-01-27T01:11:41Z",
        "link": "http://arxiv.org/abs/2301.11481v2",
        "categories": [
            "cs.GT",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Distributed Consensus in Wireless Networks with Probabilistic Broadcast   Scheduling",
        "authors": [
            "Daniel Pérez Herrera",
            "Zheng Chen",
            "Erik G. Larsson"
        ],
        "summary": "We consider distributed average consensus in a wireless network with partial communication to reduce the number of transmissions in every iteration/round. Considering the broadcast nature of wireless channels, we propose a probabilistic approach that schedules a subset of nodes for broadcasting information to their neighbors in every round. We compare several heuristic methods for assigning the node broadcast probabilities under a fixed number of transmissions per round. Furthermore, we introduce a pre-compensation method to correct the bias between the consensus value and the average of the initial values, and suggest possible extensions for our design. Our results are particularly relevant for developing communication-efficient consensus protocols in a wireless environment with limited frequency/time resources.",
        "published": "2023-01-27T13:53:56Z",
        "link": "http://arxiv.org/abs/2301.11714v1",
        "categories": [
            "cs.MA",
            "cs.IT",
            "cs.SY",
            "eess.SY",
            "math.IT"
        ]
    },
    {
        "title": "Policy-Value Alignment and Robustness in Search-based Multi-Agent   Learning",
        "authors": [
            "Niko A. Grupen",
            "Michael Hanlon",
            "Alexis Hao",
            "Daniel D. Lee",
            "Bart Selman"
        ],
        "summary": "Large-scale AI systems that combine search and learning have reached super-human levels of performance in game-playing, but have also been shown to fail in surprising ways. The brittleness of such models limits their efficacy and trustworthiness in real-world deployments. In this work, we systematically study one such algorithm, AlphaZero, and identify two phenomena related to the nature of exploration. First, we find evidence of policy-value misalignment -- for many states, AlphaZero's policy and value predictions contradict each other, revealing a tension between accurate move-selection and value estimation in AlphaZero's objective. Further, we find inconsistency within AlphaZero's value function, which causes it to generalize poorly, despite its policy playing an optimal strategy. From these insights we derive VISA-VIS: a novel method that improves policy-value alignment and value robustness in AlphaZero. Experimentally, we show that our method reduces policy-value misalignment by up to 76%, reduces value generalization error by up to 50%, and reduces average value error by up to 55%.",
        "published": "2023-01-27T17:05:29Z",
        "link": "http://arxiv.org/abs/2301.11857v2",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Privacy and Bias Analysis of Disclosure Avoidance Systems",
        "authors": [
            "Keyu Zhu",
            "Ferdinando Fioretto",
            "Pascal Van Hentenryck",
            "Saswat Das",
            "Christine Task"
        ],
        "summary": "Disclosure avoidance (DA) systems are used to safeguard the confidentiality of data while allowing it to be analyzed and disseminated for analytic purposes. These methods, e.g., cell suppression, swapping, and k-anonymity, are commonly applied and may have significant societal and economic implications. However, a formal analysis of their privacy and bias guarantees has been lacking. This paper presents a framework that addresses this gap: it proposes differentially private versions of these mechanisms and derives their privacy bounds. In addition, the paper compares their performance with traditional differential privacy mechanisms in terms of accuracy and fairness on US Census data release and classification tasks. The results show that, contrary to popular beliefs, traditional differential privacy techniques may be superior in terms of accuracy and fairness to differential private counterparts of widely used DA mechanisms.",
        "published": "2023-01-28T13:58:25Z",
        "link": "http://arxiv.org/abs/2301.12204v1",
        "categories": [
            "cs.CR",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "A Quantification Approach for Transferability in Lifelike Computing   Systems",
        "authors": [
            "Martin Goller",
            "Sven Tomforde"
        ],
        "summary": "The basic idea of lifelike computing systems is the transfer of concepts in living systems to technical use that goes even beyond existing concepts of self-adaptation and self-organisation (SASO). As a result, these systems become even more autonomous and changeable - up to a runtime transfer of the actual target function. Maintaining controllability requires a complete and dynamic (self-)quantification of the system behaviour with regard to aspects of SASO but also, in particular, lifelike properties. In this article, we discuss possible approaches for such metrics and establish a first metric for transferability. We analyse the behaviour of the metric using example applications and show that it is suitable for describing the system's behaviour at runtime.",
        "published": "2023-01-30T13:05:47Z",
        "link": "http://arxiv.org/abs/2301.12854v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Learning Coordination Policies over Heterogeneous Graphs for Human-Robot   Teams via Recurrent Neural Schedule Propagation",
        "authors": [
            "Batuhan Altundas",
            "Zheyuan Wang",
            "Joshua Bishop",
            "Matthew Gombolay"
        ],
        "summary": "As human-robot collaboration increases in the workforce, it becomes essential for human-robot teams to coordinate efficiently and intuitively. Traditional approaches for human-robot scheduling either utilize exact methods that are intractable for large-scale problems and struggle to account for stochastic, time varying human task performance, or application-specific heuristics that require expert domain knowledge to develop. We propose a deep learning-based framework, called HybridNet, combining a heterogeneous graph-based encoder with a recurrent schedule propagator for scheduling stochastic human-robot teams under upper- and lower-bound temporal constraints. The HybridNet's encoder leverages Heterogeneous Graph Attention Networks to model the initial environment and team dynamics while accounting for the constraints. By formulating task scheduling as a sequential decision-making process, the HybridNet's recurrent neural schedule propagator leverages Long Short-Term Memory (LSTM) models to propagate forward consequences of actions to carry out fast schedule generation, removing the need to interact with the environment between every task-agent pair selection. The resulting scheduling policy network provides a computationally lightweight yet highly expressive model that is end-to-end trainable via Reinforcement Learning algorithms. We develop a virtual task scheduling environment for mixed human-robot teams in a multi-round setting, capable of modeling the stochastic learning behaviors of human workers. Experimental results showed that HybridNet outperformed other human-robot scheduling solutions across problem sizes for both deterministic and stochastic human performance, with faster runtime compared to pure-GNN-based schedulers.",
        "published": "2023-01-30T20:42:06Z",
        "link": "http://arxiv.org/abs/2301.13279v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Team Plan Recognition: A Review of the State of the Art",
        "authors": [
            "Loren Rieffer-Champlin"
        ],
        "summary": "There is an increasing need to develop artificial intelligence systems that assist groups of humans working on coordinated tasks. These systems must recognize and understand the plans and relationships between actions for a team of humans working toward a common objective. This article reviews the literature on team plan recognition and surveys the most recent logic-based approaches for implementing it. First, we provide some background knowledge, including a general definition of plan recognition in a team setting and a discussion of implementation challenges. Next, we explain our reasoning for focusing on logic-based methods. Finally, we survey recent approaches from two primary classes of logic-based methods (plan library-based and domain theory-based). We aim to bring more attention to this sparse but vital topic and inspire new directions for implementing team plan recognition.",
        "published": "2023-01-30T21:01:14Z",
        "link": "http://arxiv.org/abs/2301.13288v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Sequential Strategic Screening",
        "authors": [
            "Lee Cohen",
            "Saeed Sharifi-Malvajerdi",
            "Kevin Stangl",
            "Ali Vakilian",
            "Juba Ziani"
        ],
        "summary": "We initiate the study of strategic behavior in screening processes with multiple classifiers. We focus on two contrasting settings: a conjunctive setting in which an individual must satisfy all classifiers simultaneously, and a sequential setting in which an individual to succeed must satisfy classifiers one at a time. In other words, we introduce the combination of strategic classification with screening processes.   We show that sequential screening pipelines exhibit new and surprising behavior where individuals can exploit the sequential ordering of the tests to zig-zag between classifiers without having to simultaneously satisfy all of them. We demonstrate an individual can obtain a positive outcome using a limited manipulation budget even when far from the intersection of the positive regions of every classifier. Finally, we consider a learner whose goal is to design a sequential screening process that is robust to such manipulations, and provide a construction for the learner that optimizes a natural objective.",
        "published": "2023-01-31T04:08:18Z",
        "link": "http://arxiv.org/abs/2301.13397v2",
        "categories": [
            "cs.LG",
            "cs.CY",
            "cs.GT",
            "cs.MA",
            "91",
            "I.2; J.4"
        ]
    },
    {
        "title": "Round-Robin Beyond Additive Agents: Existence and Fairness of   Approximate Equilibria",
        "authors": [
            "Georgios Amanatidis",
            "Georgios Birmpas",
            "Philip Lazos",
            "Stefano Leonardi",
            "Rebecca Reiffenhäuser"
        ],
        "summary": "Fair allocation of indivisible goods has attracted extensive attention over the last two decades, yielding numerous elegant algorithmic results and producing challenging open questions. The problem becomes much harder in the presence of strategic agents. Ideally, one would want to design truthful mechanisms that produce allocations with fairness guarantees. However, in the standard setting without monetary transfers, it is generally impossible to have truthful mechanisms that provide non-trivial fairness guarantees. Recently, Amanatidis et al. [2021] suggested the study of mechanisms that produce fair allocations in their equilibria. Specifically, when the agents have additive valuation functions, the simple Round-Robin algorithm always has pure Nash equilibria and the corresponding allocations are envy-free up to one good (EF1) with respect to the agents' true valuation functions. Following this agenda, we show that this outstanding property of the Round-Robin mechanism extends much beyond the above default assumption of additivity. In particular, we prove that for agents with cancelable valuation functions (a natural class that contains, e.g., additive and budget-additive functions), this simple mechanism always has equilibria and even its approximate equilibria correspond to approximately EF1 allocations with respect to the agents' true valuation functions. Further, we show that the approximate EF1 fairness of approximate equilibria surprisingly holds for the important class of submodular valuation functions as well, even though exact equilibria fail to exist!",
        "published": "2023-01-31T14:09:22Z",
        "link": "http://arxiv.org/abs/2301.13652v1",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Learning Roles with Emergent Social Value Orientations",
        "authors": [
            "Wenhao Li",
            "Xiangfeng Wang",
            "Bo Jin",
            "Jingyi Lu",
            "Hongyuan Zha"
        ],
        "summary": "Social dilemmas can be considered situations where individual rationality leads to collective irrationality. The multi-agent reinforcement learning community has leveraged ideas from social science, such as social value orientations (SVO), to solve social dilemmas in complex cooperative tasks. In this paper, by first introducing the typical \"division of labor or roles\" mechanism in human society, we provide a promising solution for intertemporal social dilemmas (ISD) with SVOs. A novel learning framework, called Learning Roles with Emergent SVOs (RESVO), is proposed to transform the learning of roles into the social value orientation emergence, which is symmetrically solved by endowing agents with altruism to share rewards with other agents. An SVO-based role embedding space is then constructed by individual conditioning policies on roles with a novel rank regularizer and mutual information maximizer. Experiments show that RESVO achieves a stable division of labor and cooperation in ISDs with different complexity.",
        "published": "2023-01-31T17:54:09Z",
        "link": "http://arxiv.org/abs/2301.13812v1",
        "categories": [
            "cs.CY",
            "cs.AI",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Off-the-Grid MARL: Datasets with Baselines for Offline Multi-Agent   Reinforcement Learning",
        "authors": [
            "Claude Formanek",
            "Asad Jeewa",
            "Jonathan Shock",
            "Arnu Pretorius"
        ],
        "summary": "Being able to harness the power of large datasets for developing cooperative multi-agent controllers promises to unlock enormous value for real-world applications. Many important industrial systems are multi-agent in nature and are difficult to model using bespoke simulators. However, in industry, distributed processes can often be recorded during operation, and large quantities of demonstrative data stored. Offline multi-agent reinforcement learning (MARL) provides a promising paradigm for building effective decentralised controllers from such datasets. However, offline MARL is still in its infancy and therefore lacks standardised benchmark datasets and baselines typically found in more mature subfields of reinforcement learning (RL). These deficiencies make it difficult for the community to sensibly measure progress. In this work, we aim to fill this gap by releasing off-the-grid MARL (OG-MARL): a growing repository of high-quality datasets with baselines for cooperative offline MARL research. Our datasets provide settings that are characteristic of real-world systems, including complex environment dynamics, heterogeneous agents, non-stationarity, many agents, partial observability, suboptimality, sparse rewards and demonstrated coordination. For each setting, we provide a range of different dataset types (e.g. Good, Medium, Poor, and Replay) and profile the composition of experiences for each dataset. We hope that OG-MARL will serve the community as a reliable source of datasets and help drive progress, while also providing an accessible entry point for researchers new to the field.",
        "published": "2023-02-01T15:41:27Z",
        "link": "http://arxiv.org/abs/2302.00521v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Task Placement and Resource Allocation for Edge Machine Learning: A   GNN-based Multi-Agent Reinforcement Learning Paradigm",
        "authors": [
            "Yihong Li",
            "Xiaoxi Zhang",
            "Tianyu Zeng",
            "Jingpu Duan",
            "Chuan Wu",
            "Di Wu",
            "Xu Chen"
        ],
        "summary": "Machine learning (ML) tasks are one of the major workloads in today's edge computing networks. Existing edge-cloud schedulers allocate the requested amounts of resources to each task, falling short of best utilizing the limited edge resources for ML tasks. This paper proposes TapFinger, a distributed scheduler for edge clusters that minimizes the total completion time of ML tasks through co-optimizing task placement and fine-grained multi-resource allocation. To learn the tasks' uncertain resource sensitivity and enable distributed scheduling, we adopt multi-agent reinforcement learning (MARL) and propose several techniques to make it efficient, including a heterogeneous graph attention network as the MARL backbone, a tailored task selection phase in the actor network, and the integration of Bayes' theorem and masking schemes. We first implement a single-task scheduling version, which schedules at most one task each time. Then we generalize to the multi-task scheduling case, in which a sequence of tasks is scheduled simultaneously. Our design can mitigate the expanded decision space and yield fast convergence to optimal scheduling solutions. Extensive experiments using synthetic and test-bed ML task traces show that TapFinger can achieve up to 54.9% reduction in the average task completion time and improve resource efficiency as compared to state-of-the-art schedulers.",
        "published": "2023-02-01T16:45:26Z",
        "link": "http://arxiv.org/abs/2302.00571v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Autonomous Local Catalog Maintenance of Close Proximity Satellite   Systems on Closed Natural Motion Trajectories",
        "authors": [
            "Christopher W. Hays",
            "Kristina Miller",
            "Alexander Soderlund",
            "Sean Phillips",
            "Troy Henderson"
        ],
        "summary": "To enable space mission sets like on-orbit servicing and manufacturing, agents in close proximity maybe operating too close to yield resolved localization solutions to operators from ground sensors. This leads to a requirement on the systems need to maintain a catalog of their local neighborhood, however, this may impose a large burden on each agent by requiring updating and maintenance of this catalog at each node. To alleviate this burden, this paper considers the case of a single satellite agent (a chief) updating a single catalog. More specifically, we consider the case of numerous satellite deputy agents in a local neighborhood of a chief, the goal of the chief satellite is to maintain and update a catalog of all agents within this neighborhood through onboard measurements. We consider the agents having relative translational and attitude motion dynamics between the chief and deputy, with the chief centered at the origin of the frame. We provide an end-to-end solution of the this problem through providing both a supervisory control method coupled with a Bayesian Filter that propagates the belief state and provides the catalog solutions to the supervisor. The goal of the supervisory controller is to determine which agent to look at and at which times while adhering to constraints of the chief satellite. We provide a numerical validation to this problem with three agents.",
        "published": "2023-02-01T17:09:55Z",
        "link": "http://arxiv.org/abs/2302.00601v2",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "J.2"
        ]
    },
    {
        "title": "Combining Tree-Search, Generative Models, and Nash Bargaining Concepts   in Game-Theoretic Reinforcement Learning",
        "authors": [
            "Zun Li",
            "Marc Lanctot",
            "Kevin R. McKee",
            "Luke Marris",
            "Ian Gemp",
            "Daniel Hennes",
            "Paul Muller",
            "Kate Larson",
            "Yoram Bachrach",
            "Michael P. Wellman"
        ],
        "summary": "Multiagent reinforcement learning (MARL) has benefited significantly from population-based and game-theoretic training regimes. One approach, Policy-Space Response Oracles (PSRO), employs standard reinforcement learning to compute response policies via approximate best responses and combines them via meta-strategy selection. We augment PSRO by adding a novel search procedure with generative sampling of world states, and introduce two new meta-strategy solvers based on the Nash bargaining solution. We evaluate PSRO's ability to compute approximate Nash equilibrium, and its performance in two negotiation games: Colored Trails, and Deal or No Deal. We conduct behavioral studies where human participants negotiate with our agents ($N = 346$). We find that search with generative modeling finds stronger policies during both training time and test time, enables online Bayesian co-player prediction, and can produce agents that achieve comparable social welfare negotiating with humans as humans trading among themselves.",
        "published": "2023-02-01T23:06:23Z",
        "link": "http://arxiv.org/abs/2302.00797v1",
        "categories": [
            "cs.AI",
            "cs.GT",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Towards Modelling and Verification of Social Explainable AI",
        "authors": [
            "Damian Kurpiewski",
            "Wojciech Jamroga",
            "Teofil Sidoruk"
        ],
        "summary": "Social Explainable AI (SAI) is a new direction in artificial intelligence that emphasises decentralisation, transparency, social context, and focus on the human users. SAI research is still at an early stage. Consequently, it concentrates on delivering the intended functionalities, but largely ignores the possibility of unwelcome behaviours due to malicious or erroneous activity. We propose that, in order to capture the breadth of relevant aspects, one can use models and logics of strategic ability, that have been developed in multi-agent systems. Using the STV model checker, we take the first step towards the formal modelling and verification of SAI environments, in particular of their resistance to various types of attacks by compromised AI modules.",
        "published": "2023-02-02T12:48:31Z",
        "link": "http://arxiv.org/abs/2302.01063v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Learning in Multi-Memory Games Triggers Complex Dynamics Diverging from   Nash Equilibrium",
        "authors": [
            "Yuma Fujimoto",
            "Kaito Ariu",
            "Kenshi Abe"
        ],
        "summary": "Repeated games consider a situation where multiple agents are motivated by their independent rewards throughout learning. In general, the dynamics of their learning become complex. Especially when their rewards compete with each other like zero-sum games, the dynamics often do not converge to their optimum, i.e., the Nash equilibrium. To tackle such complexity, many studies have understood various learning algorithms as dynamical systems and discovered qualitative insights among the algorithms. However, such studies have yet to handle multi-memory games (where agents can memorize actions they played in the past and choose their actions based on their memories), even though memorization plays a pivotal role in artificial intelligence and interpersonal relationship. This study extends two major learning algorithms in games, i.e., replicator dynamics and gradient ascent, into multi-memory games. Then, we prove their dynamics are identical. Furthermore, theoretically and experimentally, we clarify that the learning dynamics diverge from the Nash equilibrium in multi-memory zero-sum games and reach heteroclinic cycles (sojourn longer around the boundary of the strategy space), providing a fundamental advance in learning in games.",
        "published": "2023-02-02T13:02:55Z",
        "link": "http://arxiv.org/abs/2302.01073v2",
        "categories": [
            "cs.GT",
            "cs.MA",
            "math.OC",
            "nlin.CD"
        ]
    },
    {
        "title": "Best Possible Q-Learning",
        "authors": [
            "Jiechuan Jiang",
            "Zongqing Lu"
        ],
        "summary": "Fully decentralized learning, where the global information, i.e., the actions of other agents, is inaccessible, is a fundamental challenge in cooperative multi-agent reinforcement learning. However, the convergence and optimality of most decentralized algorithms are not theoretically guaranteed, since the transition probabilities are non-stationary as all agents are updating policies simultaneously. To tackle this challenge, we propose best possible operator, a novel decentralized operator, and prove that the policies of agents will converge to the optimal joint policy if each agent independently updates its individual state-action value by the operator. Further, to make the update more efficient and practical, we simplify the operator and prove that the convergence and optimality still hold with the simplified one. By instantiating the simplified operator, the derived fully decentralized algorithm, best possible Q-learning (BQL), does not suffer from non-stationarity. Empirically, we show that BQL achieves remarkable improvement over baselines in a variety of cooperative multi-agent tasks.",
        "published": "2023-02-02T16:14:19Z",
        "link": "http://arxiv.org/abs/2302.01188v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Towards Evology: a Market Ecology Agent-Based Model of US Equity Mutual   Funds II",
        "authors": [
            "Aymeric Vie",
            "J. Doyne Farmer"
        ],
        "summary": "Agent-based models (ABMs) are fit to model heterogeneous, interacting systems like financial markets. We present the latest advances in Evology: a heterogeneous, empirically calibrated market ecology agent-based model of the US stock market. Prices emerge endogenously from the interactions of market participants with diverse investment behaviours and their reactions to fundamentals. This approach allows testing trading strategies while accounting for the interactions of this strategy with other market participants and conditions. Those early results encourage a closer association between ABMs and ML algorithms for testing and optimising investment strategies using machine learning algorithms.",
        "published": "2023-02-02T16:53:28Z",
        "link": "http://arxiv.org/abs/2302.01216v1",
        "categories": [
            "cs.MA",
            "q-fin.GN"
        ]
    },
    {
        "title": "Online Re-Planning and Adaptive Parameter Update for Multi-Agent Path   Finding with Stochastic Travel Times",
        "authors": [
            "Atsuyoshi Kita",
            "Nobuhiro Suenari",
            "Masashi Okada",
            "Tadahiro Taniguchi"
        ],
        "summary": "This study explores the problem of Multi-Agent Path Finding with continuous and stochastic travel times whose probability distribution is unknown. Our purpose is to manage a group of automated robots that provide package delivery services in a building where pedestrians and a wide variety of robots coexist, such as delivery services in office buildings, hospitals, and apartments. It is often the case with these real-world applications that the time required for the robots to traverse a corridor takes a continuous value and is randomly distributed, and the prior knowledge of the probability distribution of the travel time is limited. Multi-Agent Path Finding has been widely studied and applied to robot management systems; however, automating the robot operation in such environments remains difficult. We propose 1) online re-planning to update the action plan of robots while it is executed, and 2) parameter update to estimate the probability distribution of travel time using Bayesian inference as the delay is observed. We use a greedy heuristic to obtain solutions in a limited computation time. Through simulations, we empirically compare the performance of our method to those of existing methods in terms of the conflict probability and the actual travel time of robots. The simulation results indicate that the proposed method can find travel paths with at least 50% fewer conflicts and a shorter actual total travel time than existing methods. The proposed method requires a small number of trials to achieve the performance because the parameter update is prioritized on the important edges for path planning, thereby satisfying the requirements of quick implementation of robust planning of automated delivery services.",
        "published": "2023-02-03T01:52:18Z",
        "link": "http://arxiv.org/abs/2302.01489v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Deep Reinforcement Learning for Cyber System Defense under Dynamic   Adversarial Uncertainties",
        "authors": [
            "Ashutosh Dutta",
            "Samrat Chatterjee",
            "Arnab Bhattacharya",
            "Mahantesh Halappanavar"
        ],
        "summary": "Development of autonomous cyber system defense strategies and action recommendations in the real-world is challenging, and includes characterizing system state uncertainties and attack-defense dynamics. We propose a data-driven deep reinforcement learning (DRL) framework to learn proactive, context-aware, defense countermeasures that dynamically adapt to evolving adversarial behaviors while minimizing loss of cyber system operations. A dynamic defense optimization problem is formulated with multiple protective postures against different types of adversaries with varying levels of skill and persistence. A custom simulation environment was developed and experiments were devised to systematically evaluate the performance of four model-free DRL algorithms against realistic, multi-stage attack sequences. Our results suggest the efficacy of DRL algorithms for proactive cyber defense under multi-stage attack profiles and system uncertainties.",
        "published": "2023-02-03T08:33:33Z",
        "link": "http://arxiv.org/abs/2302.01595v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Optimal Capacity Modification for Many-To-One Matching Problems",
        "authors": [
            "Jiehua Chen",
            "Gergely Csáji"
        ],
        "summary": "We consider many-to-one matching problems, where one side consists of students and the other side of schools with capacity constraints. We study how to optimally increase the capacities of the schools so as to obtain a stable and perfect matching (i.e., every student is matched) or a matching that is stable and Pareto-efficient for the students. We consider two common optimality criteria, one aiming to minimize the sum of capacity increases of all schools (abbrv. as MinSum) and the other aiming to minimize the maximum capacity increase of any school (abbrv. as MinMax). We obtain a complete picture in terms of computational complexity: Except for stable and perfect matchings using the MinMax criteria which is polynomial-time solvable, all three remaining problems are NP-hard. We further investigate the parameterized complexity and approximability and find that achieving stable and Pareto-efficient matchings via minimal capacity increases is much harder than achieving stable and perfect matchings.",
        "published": "2023-02-03T15:37:53Z",
        "link": "http://arxiv.org/abs/2302.01815v2",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Concave Pro-rata Games",
        "authors": [
            "Nicholas A. G Johnson",
            "Theo Diamandis",
            "Alex Evans",
            "Henry de Valence",
            "Guillermo Angeris"
        ],
        "summary": "In this paper, we introduce a family of games called concave pro-rata games. In such a game, players place their assets into a pool, and the pool pays out some concave function of all assets placed into it. Each player then receives a pro-rata share of the payout; i.e., each player receives an amount proportional to how much they placed in the pool. Such games appear in a number of practical scenarios, including as a simplified version of batched decentralized exchanges, such as those proposed by Penumbra. We show that this game has a number of interesting properties, including a symmetric pure equilibrium that is the unique equilibrium of this game, and we prove that its price of anarchy is $\\Omega(n)$ in the number of players. We also show some numerical results in the iterated setting which suggest that players quickly converge to an equilibrium in iterated play.",
        "published": "2023-02-04T07:57:28Z",
        "link": "http://arxiv.org/abs/2302.02126v1",
        "categories": [
            "cs.GT",
            "cs.CR",
            "cs.MA"
        ]
    },
    {
        "title": "Dual Self-Awareness Value Decomposition Framework without Individual   Global Max for Cooperative Multi-Agent Reinforcement Learning",
        "authors": [
            "Zhiwei Xu",
            "Bin Zhang",
            "Dapeng Li",
            "Guangchong Zhou",
            "Zeren Zhang",
            "Guoliang Fan"
        ],
        "summary": "Value decomposition methods have gained popularity in the field of cooperative multi-agent reinforcement learning. However, almost all existing methods follow the principle of Individual Global Max (IGM) or its variants, which limits their problem-solving capabilities. To address this, we propose a dual self-awareness value decomposition framework, inspired by the notion of dual self-awareness in psychology, that entirely rejects the IGM premise. Each agent consists of an ego policy for action selection and an alter ego value function to solve the credit assignment problem. The value function factorization can ignore the IGM assumption by utilizing an explicit search procedure. On the basis of the above, we also suggest a novel anti-ego exploration mechanism to avoid the algorithm becoming stuck in a local optimum. As the first fully IGM-free value decomposition method, our proposed framework achieves desirable performance in various cooperative tasks.",
        "published": "2023-02-04T15:13:20Z",
        "link": "http://arxiv.org/abs/2302.02180v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Offline Learning in Markov Games with General Function Approximation",
        "authors": [
            "Yuheng Zhang",
            "Yu Bai",
            "Nan Jiang"
        ],
        "summary": "We study offline multi-agent reinforcement learning (RL) in Markov games, where the goal is to learn an approximate equilibrium -- such as Nash equilibrium and (Coarse) Correlated Equilibrium -- from an offline dataset pre-collected from the game. Existing works consider relatively restricted tabular or linear models and handle each equilibria separately. In this work, we provide the first framework for sample-efficient offline learning in Markov games under general function approximation, handling all 3 equilibria in a unified manner. By using Bellman-consistent pessimism, we obtain interval estimation for policies' returns, and use both the upper and the lower bounds to obtain a relaxation on the gap of a candidate policy, which becomes our optimization objective. Our results generalize prior works and provide several additional insights. Importantly, we require a data coverage condition that improves over the recently proposed \"unilateral concentrability\". Our condition allows selective coverage of deviation policies that optimally trade-off between their greediness (as approximate best responses) and coverage, and we show scenarios where this leads to significantly better guarantees. As a new connection, we also show how our algorithmic framework can subsume seemingly different solution concepts designed for the special case of two-player zero-sum games.",
        "published": "2023-02-06T05:22:27Z",
        "link": "http://arxiv.org/abs/2302.02571v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Simulation algorithms for Markovian and non-Markovian epidemics",
        "authors": [
            "Guohao Dou"
        ],
        "summary": "Researchers have employed stochastic simulations to determine the validity of their theoretical findings and to study analytically intractable spreading dynamics. In both cases, the correctness and efficiency of the simulation algorithm are of paramount importance. We prove in this article that the Next Reaction Method and the non-Markovian Gillespie algorithm, two algorithms for simulating non-Markovian epidemics, are statistically equivalent. We also study the performance and applicability under various circumstances through complexity analyses and numerical experiments. In our numerical simulations, we apply the Next Reaction Method and the Gillespie algorithm to epidemic simulations on time-varying networks and epidemic simulations with cooperative infections. Both tasks have only been done using the Gillespie algorithm, while we show that the Next Reaction Method is a good alternative. We believe this article may also serve as a guide for choosing simulation algorithms that are both correct and efficient for researchers from epidemiology and beyond.",
        "published": "2023-02-06T14:36:23Z",
        "link": "http://arxiv.org/abs/2302.02812v1",
        "categories": [
            "q-bio.PE",
            "cs.MA",
            "physics.bio-ph"
        ]
    },
    {
        "title": "Cooperverse: A Mobile-Edge-Cloud Framework for Universal Cooperative   Perception with Mixed Connectivity and Automation",
        "authors": [
            "Zhengwei Bai",
            "Guoyuan Wu",
            "Matthew J. Barth",
            "Yongkang Liu",
            "Emrah Akin Sisbot",
            "Kentaro Oguchi"
        ],
        "summary": "Cooperative perception (CP) is attracting increasing attention and is regarded as the core foundation to support cooperative driving automation, a potential key solution to addressing the safety, mobility, and sustainability issues of contemporary transportation systems. However, current research on CP is still at the beginning stages where a systematic problem formulation of CP is still missing, acting as the essential guideline of the system design of a CP system under real-world situations. In this paper, we formulate a universal CP system into an optimization problem and a mobile-edge-cloud framework called Cooperverse. This system addresses CP in a mixed connectivity and automation environment. A Dynamic Feature Sharing (DFS) methodology is introduced to support this CP system under certain constraints and a Random Priority Filtering (RPF) method is proposed to conduct DFS with high performance. Experiments have been conducted based on a high-fidelity CP platform, and the results show that the Cooperverse framework is effective for dynamic node engagement and the proposed DFS methodology can improve system CP performance by 14.5% and the RPF method can reduce the communication cost for mobile nodes by 90% with only 1.7% drop for average precision.",
        "published": "2023-02-06T21:30:08Z",
        "link": "http://arxiv.org/abs/2302.03128v1",
        "categories": [
            "cs.CV",
            "cs.MA"
        ]
    },
    {
        "title": "Traffic Shaping and Hysteresis Mitigation Using Deep Reinforcement   Learning in a Connected Driving Environment",
        "authors": [
            "Rami Ammourah",
            "Alireza Talebpour"
        ],
        "summary": "A multi-agent deep reinforcement learning-based framework for traffic shaping. The proposed framework offers a key advantage over existing congestion management strategies which is the ability to mitigate hysteresis phenomena. Unlike existing congestion management strategies that focus on breakdown prevention, the proposed framework is extremely effective after breakdown formation. The proposed framework assumes partial connectivity between the automated vehicles which share information. The framework requires a basic level of autonomy defined by one-dimensional longitudinal control. This framework is primarily built using a centralized training, centralized execution multi-agent deep reinforcement learning approach, where longitudinal control is defined by signals of acceleration or deceleration commands which are then executed by all agents uniformly. The model undertaken for training and testing of the framework is based on the well-known Double Deep Q-Learning algorithm which takes the average state of flow within the traffic stream as the model input and outputs actions in the form of acceleration or deceleration values. We demonstrate the ability of the model to shape the state of traffic, mitigate the negative effects of hysteresis, and even improve traffic flow beyond its original level. This paper also identifies the minimum percentage of CAVs required to successfully shape the traffic under an assumption of uniformly distributed CAVs within the loop system. The framework illustrated in this work doesnt just show the theoretical applicability of reinforcement learning to tackle such challenges but also proposes a realistic solution that only requires partial connectivity and continuous monitoring of the average speed of the system, which can be achieved using readily available sensors that measure the speeds of vehicles in reasonable proximity to the CAVs.",
        "published": "2023-02-06T22:07:30Z",
        "link": "http://arxiv.org/abs/2302.03141v1",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Evolutionary stability of cooperation in indirect reciprocity under   noisy and private assessment",
        "authors": [
            "Yuma Fujimoto",
            "Hisashi Ohtsuki"
        ],
        "summary": "Indirect reciprocity is a mechanism that explains large-scale cooperation in humans. In indirect reciprocity, individuals use reputations to choose whether or not to cooperate with a partner and update others' reputations. A major question is how the rules to choose their actions and the rules to update reputations evolve. In the public reputation case, where all individuals share the evaluation of others, social norms called Simple Standing (SS) and Stern Judging (SJ) have been known to maintain cooperation. However, in the case of private assessment where individuals independently evaluate others, the mechanism of maintenance of cooperation is still largely unknown. This study theoretically shows for the first time that cooperation by indirect reciprocity can be evolutionarily stable under private assessment. Specifically, we find that SS can be stable, but SJ can never be. This is intuitive because SS can correct interpersonal discrepancies in reputations through its simplicity. On the other hand, SJ is too complicated to avoid an accumulation of errors, which leads to the collapse of cooperation. We conclude that moderate simplicity is a key to success in maintaining cooperation under the private assessment. Our result provides a theoretical basis for evolution of human cooperation.",
        "published": "2023-02-07T05:31:08Z",
        "link": "http://arxiv.org/abs/2302.03265v1",
        "categories": [
            "cs.GT",
            "cs.MA",
            "math.OC",
            "physics.soc-ph"
        ]
    },
    {
        "title": "Towards Skilled Population Curriculum for Multi-Agent Reinforcement   Learning",
        "authors": [
            "Rundong Wang",
            "Longtao Zheng",
            "Wei Qiu",
            "Bowei He",
            "Bo An",
            "Zinovi Rabinovich",
            "Yujing Hu",
            "Yingfeng Chen",
            "Tangjie Lv",
            "Changjie Fan"
        ],
        "summary": "Recent advances in multi-agent reinforcement learning (MARL) allow agents to coordinate their behaviors in complex environments. However, common MARL algorithms still suffer from scalability and sparse reward issues. One promising approach to resolving them is automatic curriculum learning (ACL). ACL involves a student (curriculum learner) training on tasks of increasing difficulty controlled by a teacher (curriculum generator). Despite its success, ACL's applicability is limited by (1) the lack of a general student framework for dealing with the varying number of agents across tasks and the sparse reward problem, and (2) the non-stationarity of the teacher's task due to ever-changing student strategies. As a remedy for ACL, we introduce a novel automatic curriculum learning framework, Skilled Population Curriculum (SPC), which adapts curriculum learning to multi-agent coordination. Specifically, we endow the student with population-invariant communication and a hierarchical skill set, allowing it to learn cooperation and behavior skills from distinct tasks with varying numbers of agents. In addition, we model the teacher as a contextual bandit conditioned by student policies, enabling a team of agents to change its size while still retaining previously acquired skills. We also analyze the inherent non-stationarity of this multi-agent automatic curriculum teaching problem and provide a corresponding regret bound. Empirical results show that our method improves the performance, scalability and sample efficiency in several MARL environments.",
        "published": "2023-02-07T12:30:52Z",
        "link": "http://arxiv.org/abs/2302.03429v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Uncoupled Learning of Differential Stackelberg Equilibria with   Commitments",
        "authors": [
            "Robert Loftin",
            "Mustafa Mert Çelikok",
            "Herke van Hoof",
            "Samuel Kaski",
            "Frans A. Oliehoek"
        ],
        "summary": "In multi-agent problems requiring a high degree of cooperation, success often depends on the ability of the agents to adapt to each other's behavior. A natural solution concept in such settings is the Stackelberg equilibrium, in which the ``leader'' agent selects the strategy that maximizes its own payoff given that the ``follower'' agent will choose their best response to this strategy. Recent work has extended this solution concept to two-player differentiable games, such as those arising from multi-agent deep reinforcement learning, in the form of the \\textit{differential} Stackelberg equilibrium. While this previous work has presented learning dynamics which converge to such equilibria, these dynamics are ``coupled'' in the sense that the learning updates for the leader's strategy require some information about the follower's payoff function. As such, these methods cannot be applied to truly decentralised multi-agent settings, particularly ad hoc cooperation, where each agent only has access to its own payoff function. In this work we present ``uncoupled'' learning dynamics based on zeroth-order gradient estimators, in which each agent's strategy update depends only on their observations of the other's behavior. We analyze the convergence of these dynamics in general-sum games, and prove that they converge to differential Stackelberg equilibria under the same conditions as previous coupled methods. Furthermore, we present an online mechanism by which symmetric learners can negotiate leader-follower roles. We conclude with a discussion of the implications of our work for multi-agent reinforcement learning and ad hoc collaboration more generally.",
        "published": "2023-02-07T12:46:54Z",
        "link": "http://arxiv.org/abs/2302.03438v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Ensemble Value Functions for Efficient Exploration in Multi-Agent   Reinforcement Learning",
        "authors": [
            "Lukas Schäfer",
            "Oliver Slumbers",
            "Stephen McAleer",
            "Yali Du",
            "Stefano V. Albrecht",
            "David Mguni"
        ],
        "summary": "Existing value-based algorithms for cooperative multi-agent reinforcement learning (MARL) commonly rely on random exploration, such as $\\epsilon$-greedy, to explore the environment. However, such exploration is inefficient at finding effective joint actions in states that require cooperation of multiple agents. In this work, we propose ensemble value functions for multi-agent exploration (EMAX), a general framework to seamlessly extend value-based MARL algorithms with ensembles of value functions. EMAX leverages the ensemble of value functions to guide the exploration of agents, stabilises their optimisation, and makes their policies more robust to miscoordination. These benefits are achieved by using a combination of three techniques. (1) EMAX uses the uncertainty of value estimates across the ensemble in a UCB policy to guide the exploration. This exploration policy focuses on parts of the environment which require cooperation across agents and, thus, enables agents to more efficiently learn how to cooperate. (2) During the optimisation, EMAX computes target values as average value estimates across the ensemble. These targets exhibit lower variance compared to commonly applied target networks, leading to significant benefits in MARL which commonly suffers from high variance caused by the exploration and non-stationary policies of other agents. (3) During evaluation, EMAX selects actions following a majority vote across the ensemble, which reduces the likelihood of selecting sub-optimal actions. We instantiate three value-based MARL algorithms with EMAX, independent DQN, VDN and QMIX, and evaluate them in 21 tasks across four environments. Using ensembles of five value functions, EMAX improves sample efficiency and final evaluation returns of these algorithms by 60%, 47%, and 539%, respectively, averaged across 21 tasks.",
        "published": "2023-02-07T12:51:20Z",
        "link": "http://arxiv.org/abs/2302.03439v6",
        "categories": [
            "cs.MA",
            "cs.LG"
        ]
    },
    {
        "title": "Stand Up Indulgent Gathering",
        "authors": [
            "Quentin Bramas",
            "Anissa Lamani",
            "Sébastien Tixeuil"
        ],
        "summary": "We consider a swarm of mobile robots evolving in a bidimensional Euclidean space. We study a variant of the crash-tolerant gathering problem: if no robot crashes, robots have to meet at the same arbitrary location, not known beforehand, in finite time; if one or several robots crash at the same location, the remaining correct robots gather at the crash location to rescue them. Motivated by impossibility results in the semi-synchronous setting, we present the first solution to the problem for the fully synchronous setting that operates in the vanilla Look-Compute-Move model with no additional hypotheses: robots are oblivious, disoriented, have no multiplicity detection capacity, and may start from arbitrary positions (including those with multiplicity points). We furthermore show that robots gather in a time that is proportional to the initial maximum distance between robots.",
        "published": "2023-02-07T13:42:01Z",
        "link": "http://arxiv.org/abs/2302.03466v1",
        "categories": [
            "cs.DC",
            "cs.MA"
        ]
    },
    {
        "title": "Simulating the impact of cognitive biases on the mobility transition",
        "authors": [
            "Carole Adam"
        ],
        "summary": "Climate change is becoming more visible, and human adaptation is required urgently to prevent greater damage. One particular domain of adaptation concerns daily mobility (work commute), with a significant portion of these trips being done in individual cars. Yet, their impact on pollution, noise, or accidents is well-known. This paper explores various cognitive biases that can explain such lack of adaptation. Our approach is to design simple interactive simulators that users can play with in order to understand biases. The idea is that awareness of such cognitive biases is often a first step towards more rational decision making, even though things are not that simple. This paper reports on three simulators, each focused on a particular factor of resistance. Various scenarios are simulated to demonstrate their explanatory power. These simulators are already available to play online, with the goal to provide users with food for thought about how mobility could evolve in the future. Work is still ongoing to design a user survey to evaluate their impact.",
        "published": "2023-02-07T16:06:26Z",
        "link": "http://arxiv.org/abs/2302.03554v1",
        "categories": [
            "cs.CY",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Proportionality in Approval-Based Participatory Budgeting",
        "authors": [
            "Markus Brill",
            "Stefan Forster",
            "Martin Lackner",
            "Jan Maly",
            "Jannik Peters"
        ],
        "summary": "The ability to measure the satisfaction of (groups of) voters is a crucial prerequisite for formulating proportionality axioms in approval-based participatory budgeting elections. Two common - but very different - ways to measure the satisfaction of a voter consider (i) the number of approved projects and (ii) the total cost of approved projects, respectively. In general, it is difficult to decide which measure of satisfaction best reflects the voters' true utilities. In this paper, we study proportionality axioms with respect to large classes of approval-based satisfaction functions. We establish logical implications among our axioms and related notions from the literature, and we ask whether outcomes can be achieved that are proportional with respect to more than one satisfaction function. We show that this is impossible for the two commonly used satisfaction functions when considering proportionality notions based on extended justified representation, but achievable for a notion based on proportional justified representation. For the latter result, we introduce a strengthening of priceability and show that it is satisfied by several polynomial-time computable rules, including the Method of Equal Shares and Phragm\\`en's sequential rule.",
        "published": "2023-02-07T18:46:10Z",
        "link": "http://arxiv.org/abs/2302.03672v2",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Breaking the Curse of Multiagents in a Large State Space: RL in Markov   Games with Independent Linear Function Approximation",
        "authors": [
            "Qiwen Cui",
            "Kaiqing Zhang",
            "Simon S. Du"
        ],
        "summary": "We propose a new model, independent linear Markov game, for multi-agent reinforcement learning with a large state space and a large number of agents. This is a class of Markov games with independent linear function approximation, where each agent has its own function approximation for the state-action value functions that are marginalized by other players' policies. We design new algorithms for learning the Markov coarse correlated equilibria (CCE) and Markov correlated equilibria (CE) with sample complexity bounds that only scale polynomially with each agent's own function class complexity, thus breaking the curse of multiagents. In contrast, existing works for Markov games with function approximation have sample complexity bounds scale with the size of the \\emph{joint action space} when specialized to the canonical tabular Markov game setting, which is exponentially large in the number of agents. Our algorithms rely on two key technical innovations: (1) utilizing policy replay to tackle non-stationarity incurred by multiple agents and the use of function approximation; (2) separating learning Markov equilibria and exploration in the Markov games, which allows us to use the full-information no-regret learning oracle instead of the stronger bandit-feedback no-regret learning oracle used in the tabular setting. Furthermore, we propose an iterative-best-response type algorithm that can learn pure Markov Nash equilibria in independent linear Markov potential games. In the tabular case, by adapting the policy replay mechanism for independent linear Markov games, we propose an algorithm with $\\widetilde{O}(\\epsilon^{-2})$ sample complexity to learn Markov CCE, which improves the state-of-the-art result $\\widetilde{O}(\\epsilon^{-3})$ in Daskalakis et al. 2022, where $\\epsilon$ is the desired accuracy, and also significantly improves other problem parameters.",
        "published": "2023-02-07T18:47:48Z",
        "link": "http://arxiv.org/abs/2302.03673v3",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.GT",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Catch Me If You Can: Improving Adversaries in Cyber-Security With   Q-Learning Algorithms",
        "authors": [
            "Arti Bandhana",
            "Ondřej Lukáš",
            "Sebastian Garcia",
            "Tomáš Kroupa"
        ],
        "summary": "The ongoing rise in cyberattacks and the lack of skilled professionals in the cybersecurity domain to combat these attacks show the need for automated tools capable of detecting an attack with good performance. Attackers disguise their actions and launch attacks that consist of multiple actions, which are difficult to detect. Therefore, improving defensive tools requires their calibration against a well-trained attacker. In this work, we propose a model of an attacking agent and environment and evaluate its performance using basic Q-Learning, Naive Q-learning, and DoubleQ-Learning, all of which are variants of Q-Learning. The attacking agent is trained with the goal of exfiltrating data whereby all the hosts in the network have a non-zero detection probability. Results show that the DoubleQ-Learning agent has the best overall performance rate by successfully achieving the goal in $70\\%$ of the interactions.",
        "published": "2023-02-07T21:57:59Z",
        "link": "http://arxiv.org/abs/2302.03768v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Learning Graph-Enhanced Commander-Executor for Multi-Agent Navigation",
        "authors": [
            "Xinyi Yang",
            "Shiyu Huang",
            "Yiwen Sun",
            "Yuxiang Yang",
            "Chao Yu",
            "Wei-Wei Tu",
            "Huazhong Yang",
            "Yu Wang"
        ],
        "summary": "This paper investigates the multi-agent navigation problem, which requires multiple agents to reach the target goals in a limited time. Multi-agent reinforcement learning (MARL) has shown promising results for solving this issue. However, it is inefficient for MARL to directly explore the (nearly) optimal policy in the large search space, which is exacerbated as the agent number increases (e.g., 10+ agents) or the environment is more complex (e.g., 3D simulator). Goal-conditioned hierarchical reinforcement learning (HRL) provides a promising direction to tackle this challenge by introducing a hierarchical structure to decompose the search space, where the low-level policy predicts primitive actions in the guidance of the goals derived from the high-level policy. In this paper, we propose Multi-Agent Graph-Enhanced Commander-Executor (MAGE-X), a graph-based goal-conditioned hierarchical method for multi-agent navigation tasks. MAGE-X comprises a high-level Goal Commander and a low-level Action Executor. The Goal Commander predicts the probability distribution of goals and leverages them to assign each agent the most appropriate final target. The Action Executor utilizes graph neural networks (GNN) to construct a subgraph for each agent that only contains crucial partners to improve cooperation. Additionally, the Goal Encoder in the Action Executor captures the relationship between the agent and the designated goal to encourage the agent to reach the final target. The results show that MAGE-X outperforms the state-of-the-art MARL baselines with a 100% success rate with only 3 million training steps in multi-agent particle environments (MPE) with 50 agents, and at least a 12% higher success rate and 2x higher data efficiency in a more complicated quadrotor 3D navigation task.",
        "published": "2023-02-08T14:44:21Z",
        "link": "http://arxiv.org/abs/2302.04094v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Policy Evaluation in Decentralized POMDPs with Belief Sharing",
        "authors": [
            "Mert Kayaalp",
            "Fatima Ghadieh",
            "Ali H. Sayed"
        ],
        "summary": "Most works on multi-agent reinforcement learning focus on scenarios where the state of the environment is fully observable. In this work, we consider a cooperative policy evaluation task in which agents are not assumed to observe the environment state directly. Instead, agents can only have access to noisy observations and to belief vectors. It is well-known that finding global posterior distributions under multi-agent settings is generally NP-hard. As a remedy, we propose a fully decentralized belief forming strategy that relies on individual updates and on localized interactions over a communication network. In addition to the exchange of the beliefs, agents exploit the communication network by exchanging value function parameter estimates as well. We analytically show that the proposed strategy allows information to diffuse over the network, which in turn allows the agents' parameters to have a bounded difference with a centralized baseline. A multi-sensor target tracking application is considered in the simulations.",
        "published": "2023-02-08T15:54:15Z",
        "link": "http://arxiv.org/abs/2302.04151v2",
        "categories": [
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "eess.SP",
            "eess.SY"
        ]
    },
    {
        "title": "Quantum Multi-Agent Actor-Critic Networks for Cooperative Mobile Access   in Multi-UAV Systems",
        "authors": [
            "Chanyoung Park",
            "Won Joon Yun",
            "Jae Pyoung Kim",
            "Tiago Koketsu Rodrigues",
            "Soohyun Park",
            "Soyi Jung",
            "Joongheon Kim"
        ],
        "summary": "This paper proposes a novel algorithm, named quantum multi-agent actor-critic networks (QMACN) for autonomously constructing a robust mobile access system employing multiple unmanned aerial vehicles (UAVs). In the context of facilitating collaboration among multiple unmanned aerial vehicles (UAVs), the application of multi-agent reinforcement learning (MARL) techniques is regarded as a promising approach. These methods enable UAVs to learn collectively, optimizing their actions within a shared environment, ultimately leading to more efficient cooperative behavior. Furthermore, the principles of a quantum computing (QC) are employed in our study to enhance the training process and inference capabilities of the UAVs involved. By leveraging the unique computational advantages of quantum computing, our approach aims to boost the overall effectiveness of the UAV system. However, employing a QC introduces scalability challenges due to the near intermediate-scale quantum (NISQ) limitation associated with qubit usage. The proposed algorithm addresses this issue by implementing a quantum centralized critic, effectively mitigating the constraints imposed by NISQ limitations. Additionally, the advantages of the QMACN with performance improvements in terms of training speed and wireless service quality are verified via various data-intensive evaluations. Furthermore, this paper validates that a noise injection scheme can be used for handling environmental uncertainties in order to realize robust mobile access.",
        "published": "2023-02-09T05:31:57Z",
        "link": "http://arxiv.org/abs/2302.04445v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Power Line Inspection Tasks with Multi-Aerial Robot Systems via Signal   Temporal Logic Specifications",
        "authors": [
            "Giuseppe Silano",
            "Tomas Baca",
            "Robert Penicka",
            "Davide Liuzza",
            "Martin Saska"
        ],
        "summary": "A framework for computing feasible and constrained trajectories for a fleet of quad-rotors leveraging on Signal Temporal Logic (STL) specifications for power line inspection tasks is proposed in this paper. The planner allows the formulation of complex missions that avoid obstacles and maintain a safe distance between drones while performing the planned mission. An optimization problem is set to generate optimal strategies that satisfy these specifications and also take vehicle constraints into account. Further, an event-triggered replanner is proposed to reply to unforeseen events and external disturbances. An energy minimization term is also considered to implicitly save quad-rotors battery life while carrying out the mission. Numerical simulations in MATLAB and experimental results show the validity and the effectiveness of the proposed approach, and demonstrate its applicability in real-world scenarios.",
        "published": "2023-02-09T15:18:14Z",
        "link": "http://arxiv.org/abs/2302.04691v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "PACNav: A collective navigation approach for UAV swarms deprived of   communication and external localization",
        "authors": [
            "Afzal Ahmad",
            "Daniel Bonilla Licea",
            "Giuseppe Silano",
            "Tomas Baca",
            "Martin Saska"
        ],
        "summary": "This article proposes Persistence Administered Collective Navigation (PACNav) as an approach for achieving decentralized collective navigation of Unmanned Aerial Vehicle (UAV) swarms. The technique is based on the flocking and collective navigation behavior observed in natural swarms, such as cattle herds, bird flocks, and even large groups of humans. As global and concurrent information of all swarm members is not available in natural swarms, these systems use local observations to achieve the desired behavior. Similarly, PACNav relies only on local observations of relative positions of UAVs, making it suitable for large swarms deprived of communication capabilities and external localization systems. We introduce the novel concepts of path persistence and path similarity that allow each swarm member to analyze the motion of other members in order to determine its own future motion. PACNav is based on two main principles: (1) UAVs with little variation in motion direction have high path persistence, and are considered by other UAVs to be reliable leaders; (2) groups of UAVs that move in a similar direction have high path similarity, and such groups are assumed to contain a reliable leader. The proposed approach also embeds a reactive collision avoidance mechanism to avoid collisions with swarm members and environmental obstacles. This collision avoidance ensures safety while reducing deviations from the assigned path. Along with several simulated experiments, we present a real-world experiment in a natural forest, showcasing the validity and effectiveness of the proposed collective navigation approach in challenging environments. The source code is released as open-source, making it possible to replicate the obtained results and facilitate the continuation of research by the community.",
        "published": "2023-02-09T15:32:42Z",
        "link": "http://arxiv.org/abs/2302.05258v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Designing Fairness in Autonomous Peer-to-peer Energy Trading",
        "authors": [
            "Varsha Behrunani",
            "Andrew Irvine",
            "Giuseppe Belgioioso",
            "Philipp Heer",
            "John Lygeros",
            "Florian Dörfler"
        ],
        "summary": "Several autonomous energy management and peer-to-peer trading mechanisms for future energy markets have been recently proposed based on optimization and game theory. In this paper, we study the impact of trading prices on the outcome of these market designs for energy-hub networks. We prove that, for a generic choice of trading prices, autonomous peer-to-peer trading is always network-wide beneficial but not necessarily individually beneficial for each hub. Therefore, we leverage hierarchical game theory to formalize the problem of designing locally-beneficial and network-wide fair peer-to-peer trading prices. Then, we propose a scalable and privacy-preserving price-mediation algorithm that provably converges to a profile of such prices. Numerical simulations on a 3-hub network show that the proposed algorithm can indeed incentivize active participation of energy hubs in autonomous peer-to-peer trading schemes.",
        "published": "2023-02-09T17:03:17Z",
        "link": "http://arxiv.org/abs/2302.04771v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Regularization for Strategy Exploration in Empirical Game-Theoretic   Analysis",
        "authors": [
            "Yongzhao Wang",
            "Michael P. Wellman"
        ],
        "summary": "In iterative approaches to empirical game-theoretic analysis (EGTA), the strategy space is expanded incrementally based on analysis of intermediate game models. A common approach to strategy exploration, represented by the double oracle algorithm, is to add strategies that best-respond to a current equilibrium. This approach may suffer from overfitting and other limitations, leading the developers of the policy-space response oracle (PSRO) framework for iterative EGTA to generalize the target of best response, employing what they term meta-strategy solvers (MSSs). Noting that many MSSs can be viewed as perturbed or approximated versions of Nash equilibrium, we adopt an explicit regularization perspective to the specification and analysis of MSSs. We propose a novel MSS called regularized replicator dynamics (RRD), which simply truncates the process based on a regret criterion. We show that RRD is more adaptive than existing MSSs and outperforms them in various games. We extend our study to three-player games, for which the payoff matrix is cubic in the number of strategies and so exhaustively evaluating profiles may not be feasible. We propose a profile search method that can identify solutions from incomplete models, and combine this with iterative model construction using a regularized MSS. Finally, and most importantly, we reveal that the regret of best response targets has a tremendous influence on the performance of strategy exploration through experiments, which provides an explanation for the effectiveness of regularization in PSRO.",
        "published": "2023-02-09T20:45:54Z",
        "link": "http://arxiv.org/abs/2302.04928v1",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Learning Complex Teamwork Tasks Using a Given Sub-task Decomposition",
        "authors": [
            "Elliot Fosong",
            "Arrasy Rahman",
            "Ignacio Carlucho",
            "Stefano V. Albrecht"
        ],
        "summary": "Training a team to complete a complex task via multi-agent reinforcement learning can be difficult due to challenges such as policy search in a large joint policy space, and non-stationarity caused by mutually adapting agents. To facilitate efficient learning of complex multi-agent tasks, we propose an approach which uses an expert-provided decomposition of a task into simpler multi-agent sub-tasks. In each sub-task, a subset of the entire team is trained to acquire sub-task-specific policies. The sub-teams are then merged and transferred to the target task, where their policies are collectively fine-tuned to solve the more complex target task. We show empirically that such approaches can greatly reduce the number of timesteps required to solve a complex target task relative to training from-scratch. However, we also identify and investigate two problems with naive implementations of approaches based on sub-task decomposition, and propose a simple and scalable method to address these problems which augments existing actor-critic algorithms. We demonstrate the empirical benefits of our proposed method, enabling sub-task decomposition approaches to be deployed in diverse multi-agent tasks.",
        "published": "2023-02-09T21:24:56Z",
        "link": "http://arxiv.org/abs/2302.04944v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Scalability Bottlenecks in Multi-Agent Reinforcement Learning Systems",
        "authors": [
            "Kailash Gogineni",
            "Peng Wei",
            "Tian Lan",
            "Guru Venkataramani"
        ],
        "summary": "Multi-Agent Reinforcement Learning (MARL) is a promising area of research that can model and control multiple, autonomous decision-making agents. During online training, MARL algorithms involve performance-intensive computations such as exploration and exploitation phases originating from large observation-action space belonging to multiple agents. In this article, we seek to characterize the scalability bottlenecks in several popular classes of MARL algorithms during their training phases. Our experimental results reveal new insights into the key modules of MARL algorithms that limit the scalability, and outline potential strategies that may help address these performance issues.",
        "published": "2023-02-10T01:30:01Z",
        "link": "http://arxiv.org/abs/2302.05007v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Low Entropy Communication in Multi-Agent Reinforcement Learning",
        "authors": [
            "Lebin Yu",
            "Yunbo Qiu",
            "Qiexiang Wang",
            "Xudong Zhang",
            "Jian Wang"
        ],
        "summary": "Communication in multi-agent reinforcement learning has been drawing attention recently for its significant role in cooperation. However, multi-agent systems may suffer from limitations on communication resources and thus need efficient communication techniques in real-world scenarios. According to the Shannon-Hartley theorem, messages to be transmitted reliably in worse channels require lower entropy. Therefore, we aim to reduce message entropy in multi-agent communication. A fundamental challenge is that the gradients of entropy are either 0 or infinity, disabling gradient-based methods. To handle it, we propose a pseudo gradient descent scheme, which reduces entropy by adjusting the distributions of messages wisely. We conduct experiments on two base communication frameworks with six environment settings and find that our scheme can reduce message entropy by up to 90% with nearly no loss of cooperation performance.",
        "published": "2023-02-10T05:24:20Z",
        "link": "http://arxiv.org/abs/2302.05055v1",
        "categories": [
            "cs.MA",
            "cs.LG"
        ]
    },
    {
        "title": "Improving Zero-Shot Coordination Performance Based on Policy Similarity",
        "authors": [
            "Lebin Yu",
            "Yunbo Qiu",
            "Quanming Yao",
            "Xudong Zhang",
            "Jian Wang"
        ],
        "summary": "Over these years, multi-agent reinforcement learning has achieved remarkable performance in multi-agent planning and scheduling tasks. It typically follows the self-play setting, where agents are trained by playing with a fixed group of agents. However, in the face of zero-shot coordination, where an agent must coordinate with unseen partners, self-play agents may fail. Several methods have been proposed to handle this problem, but they either take a lot of time or lack generalizability. In this paper, we firstly reveal an important phenomenon: the zero-shot coordination performance is strongly linearly correlated with the similarity between an agent's training partner and testing partner. Inspired by it, we put forward a Similarity-Based Robust Training (SBRT) scheme that improves agents' zero-shot coordination performance by disturbing their partners' actions during training according to a pre-defined policy similarity value. To validate its effectiveness, we apply our scheme to three multi-agent reinforcement learning frameworks and achieve better performance compared with previous methods.",
        "published": "2023-02-10T05:42:52Z",
        "link": "http://arxiv.org/abs/2302.05063v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Reinforcement Learning Aided Sequential Optimization for Unsignalized   Intersection Management of Robot Traffic",
        "authors": [
            "Nishchal Hoysal G.",
            "Pavankumar Tallapragada"
        ],
        "summary": "We consider the problem of optimal unsignalized intersection management, wherein we seek to obtain safe and optimal trajectories, for a set of robots that arrive randomly and continually. This problem involves repeatedly solving a mixed integer program (with robot acceleration trajectories as decision variables) with different parameters, for which the computation time using a naive optimization algorithm scales exponentially with the number of robots and lanes. Hence, such an approach is not suitable for real-time implementation. In this paper, we propose a solution framework that combines learning and sequential optimization. In particular, we propose an algorithm for learning a shared policy that given the traffic state information, determines the crossing order of the robots. Then, we optimize the trajectories of the robots sequentially according to that crossing order. This approach inherently guarantees safety at all times. We validate the performance of this approach using extensive simulations and compare our approach against $5$ different heuristics from the literature in $9$ different simulation settings. Our approach, on average, significantly outperforms the heuristics from the literature in various metrics like objective function, weighted average of crossing times and computation time. For example, in some scenarios, we have observed that our approach offers up to $150\\%$ improvement in objective value over the first come first serve heuristic. Even on untrained scenarios, our approach shows a consistent improvement (in objective value) of more than $30\\%$ over all heuristics under consideration. We also show through simulations that the computation time for our approach scales linearly with the number of robots (assuming all other factors are constant). Learnt policies are implemented on physical robots with slightly modified framework to address real-world challenges.",
        "published": "2023-02-10T06:51:00Z",
        "link": "http://arxiv.org/abs/2302.05082v3",
        "categories": [
            "cs.RO",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Learning cooperative behaviours in adversarial multi-agent systems",
        "authors": [
            "Ni Wang",
            "Gautham P. Das",
            "Alan G. Millard"
        ],
        "summary": "This work extends an existing virtual multi-agent platform called RoboSumo to create TripleSumo -- a platform for investigating multi-agent cooperative behaviors in continuous action spaces, with physical contact in an adversarial environment. In this paper we investigate a scenario in which two agents, namely `Bug' and `Ant', must team up and push another agent `Spider' out of the arena. To tackle this goal, the newly added agent `Bug' is trained during an ongoing match between `Ant' and `Spider'. `Bug' must develop awareness of the other agents' actions, infer the strategy of both sides, and eventually learn an action policy to cooperate. The reinforcement learning algorithm Deep Deterministic Policy Gradient (DDPG) is implemented with a hybrid reward structure combining dense and sparse rewards. The cooperative behavior is quantitatively evaluated by the mean probability of winning the match and mean number of steps needed to win.",
        "published": "2023-02-10T22:12:29Z",
        "link": "http://arxiv.org/abs/2302.05528v1",
        "categories": [
            "cs.AI",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Graph Learning Based Decision Support for Multi-Aircraft Take-Off and   Landing at Urban Air Mobility Vertiports",
        "authors": [
            "Prajit KrisshnaKumar",
            "Jhoel Witter",
            "Steve Paul",
            "Karthik Dantu",
            "Souma Chowdhury"
        ],
        "summary": "Majority of aircraft under the Urban Air Mobility (UAM) concept are expected to be of the electric vertical takeoff and landing (eVTOL) vehicle type, which will operate out of vertiports. While this is akin to the relationship between general aviation aircraft and airports, the conceived location of vertiports within dense urban environments presents unique challenges in managing the air traffic served by a vertiport. This challenge becomes pronounced within increasing frequency of scheduled landings and take-offs. This paper assumes a centralized air traffic controller (ATC) to explore the performance of a new AI driven ATC approach to manage the eVTOLs served by the vertiport. Minimum separation-driven safety and delays are the two important considerations in this case. The ATC problem is modeled as a task allocation problem, and uncertainties due to communication disruptions (e.g., poor link quality) and inclement weather (e.g., high gust effects) are added as a small probability of action failures. To learn the vertiport ATC policy, a novel graph-based reinforcement learning (RL) solution called \"Urban Air Mobility- Vertiport Schedule Management (UAM-VSM)\" is developed. This approach uses graph convolutional networks (GCNs) to abstract the vertiport space and eVTOL space as graphs, and aggregate information for a centralized ATC agent to help generalize the environment. Unreal Engine combined with Airsim is used as the simulation environment over which training and testing occurs. Uncertainties are considered only during testing, due to the high cost of Mc sampling over such realistic simulations. The proposed graph RL method demonstrates significantly better performance on the test scenarios when compared against a feasible random decision-making baseline and a first come first serve (FCFS) baseline, including the ability to generalize to unseen scenarios and with uncertainties.",
        "published": "2023-02-12T04:11:44Z",
        "link": "http://arxiv.org/abs/2302.05849v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "MANSA: Learning Fast and Slow in Multi-Agent Systems",
        "authors": [
            "David Mguni",
            "Haojun Chen",
            "Taher Jafferjee",
            "Jianhong Wang",
            "Long Fei",
            "Xidong Feng",
            "Stephen McAleer",
            "Feifei Tong",
            "Jun Wang",
            "Yaodong Yang"
        ],
        "summary": "In multi-agent reinforcement learning (MARL), independent learning (IL) often shows remarkable performance and easily scales with the number of agents. Yet, using IL can be inefficient and runs the risk of failing to successfully train, particularly in scenarios that require agents to coordinate their actions. Using centralised learning (CL) enables MARL agents to quickly learn how to coordinate their behaviour but employing CL everywhere is often prohibitively expensive in real-world applications. Besides, using CL in value-based methods often needs strong representational constraints (e.g. individual-global-max condition) that can lead to poor performance if violated. In this paper, we introduce a novel plug & play IL framework named Multi-Agent Network Selection Algorithm (MANSA) which selectively employs CL only at states that require coordination. At its core, MANSA has an additional agent that uses switching controls to quickly learn the best states to activate CL during training, using CL only where necessary and vastly reducing the computational burden of CL. Our theory proves MANSA preserves cooperative MARL convergence properties, boosts IL performance and can optimally make use of a fixed budget on the number CL calls. We show empirically in Level-based Foraging (LBF) and StarCraft Multi-agent Challenge (SMAC) that MANSA achieves fast, superior and more reliable performance while making 40% fewer CL calls in SMAC and using CL at only 1% CL calls in LBF.",
        "published": "2023-02-12T13:23:39Z",
        "link": "http://arxiv.org/abs/2302.05910v3",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Improving Quantal Cognitive Hierarchy Model Through Iterative Population   Learning",
        "authors": [
            "Yuhong Xu",
            "Shih-Fen Cheng",
            "Xinyu Chen"
        ],
        "summary": "In domains where agents interact strategically, game theory is applied widely to predict how agents would behave. However, game-theoretic predictions are based on the assumption that agents are fully rational and believe in equilibrium plays, which unfortunately are mostly not true when human decision makers are involved. To address this limitation, a number of behavioral game-theoretic models are defined to account for the limited rationality of human decision makers. The \"quantal cognitive hierarchy\" (QCH) model, which is one of the more recent models, is demonstrated to be the state-of-art model for predicting human behaviors in normal-form games. The QCH model assumes that agents in games can be both non-strategic (level-0) and strategic (level-$k$). For level-0 agents, they choose their strategies irrespective of other agents. For level-$k$ agents, they assume that other agents would be behaving at levels less than $k$ and best respond against them. However, an important assumption of the QCH model is that the distribution of agents' levels follows a Poisson distribution. In this paper, we relax this assumption and design a learning-based method at the population level to iteratively estimate the empirical distribution of agents' reasoning levels. By using a real-world dataset from the Swedish lowest unique positive integer game, we demonstrate how our refined QCH model and the iterative solution-seeking process can be used in providing a more accurate behavioral model for agents. This leads to better performance in fitting the real data and allows us to track an agent's progress in learning to play strategically over multiple rounds.",
        "published": "2023-02-13T00:23:26Z",
        "link": "http://arxiv.org/abs/2302.06033v2",
        "categories": [
            "cs.GT",
            "cs.MA",
            "econ.TH"
        ]
    },
    {
        "title": "Converging to Stability in Two-Sided Bandits: The Case of Unknown   Preferences on Both Sides of a Matching Market",
        "authors": [
            "Gaurab Pokharel",
            "Sanmay Das"
        ],
        "summary": "We study the problem of repeated two-sided matching with uncertain preferences (two-sided bandits), and no explicit communication between agents. Recent work has developed algorithms that converge to stable matchings when one side (the proposers or agents) must learn their preferences, but the preferences of the other side (the proposees or arms) are common knowledge, and the matching mechanism uses simultaneous proposals at each round. We develop new algorithms that converge to stable matchings for two more challenging settings: one where the arm preferences are no longer common knowledge, and a second, more general one where the arms are also uncertain about their own preferences. In our algorithms, agents start with optimistic beliefs about arms' preferences, updating these preferences over time, and combining beliefs about preferences with beliefs about the value of matching when choosing whom to propose to.",
        "published": "2023-02-13T08:24:24Z",
        "link": "http://arxiv.org/abs/2302.06176v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Order Matters: Agent-by-agent Policy Optimization",
        "authors": [
            "Xihuai Wang",
            "Zheng Tian",
            "Ziyu Wan",
            "Ying Wen",
            "Jun Wang",
            "Weinan Zhang"
        ],
        "summary": "While multi-agent trust region algorithms have achieved great success empirically in solving coordination tasks, most of them, however, suffer from a non-stationarity problem since agents update their policies simultaneously. In contrast, a sequential scheme that updates policies agent-by-agent provides another perspective and shows strong performance. However, sample inefficiency and lack of monotonic improvement guarantees for each agent are still the two significant challenges for the sequential scheme. In this paper, we propose the \\textbf{A}gent-by-\\textbf{a}gent \\textbf{P}olicy \\textbf{O}ptimization (A2PO) algorithm to improve the sample efficiency and retain the guarantees of monotonic improvement for each agent during training. We justify the tightness of the monotonic improvement bound compared with other trust region algorithms. From the perspective of sequentially updating agents, we further consider the effect of agent updating order and extend the theory of non-stationarity into the sequential update scheme. To evaluate A2PO, we conduct a comprehensive empirical study on four benchmarks: StarCraftII, Multi-agent MuJoCo, Multi-agent Particle Environment, and Google Research Football full game scenarios. A2PO consistently outperforms strong baselines.",
        "published": "2023-02-13T09:24:34Z",
        "link": "http://arxiv.org/abs/2302.06205v2",
        "categories": [
            "cs.AI",
            "cs.GT",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Imitation from Observation With Bootstrapped Contrastive Learning",
        "authors": [
            "Medric Sonwa",
            "Johanna Hansen",
            "Eugene Belilovsky"
        ],
        "summary": "Imitation from observation (IfO) is a learning paradigm that consists of training autonomous agents in a Markov Decision Process (MDP) by observing expert demonstrations without access to its actions. These demonstrations could be sequences of environment states or raw visual observations of the environment. Recent work in IfO has focused on this problem in the case of observations of low-dimensional environment states, however, access to these highly-specific observations is unlikely in practice. In this paper, we adopt a challenging, but more realistic problem formulation, learning control policies that operate on a learned latent space with access only to visual demonstrations of an expert completing a task. We present BootIfOL, an IfO algorithm that aims to learn a reward function that takes an agent trajectory and compares it to an expert, providing rewards based on similarity to agent behavior and implicit goal. We consider this reward function to be a distance metric between trajectories of agent behavior and learn it via contrastive learning. The contrastive learning objective aims to closely represent expert trajectories and to distance them from non-expert trajectories. The set of non-expert trajectories used in contrastive learning is made progressively more complex by bootstrapping from roll-outs of the agent learned through RL using the current reward function. We evaluate our approach on a variety of control tasks showing that we can train effective policies using a limited number of demonstrative trajectories, greatly improving on prior approaches that consider raw observations.",
        "published": "2023-02-13T17:32:17Z",
        "link": "http://arxiv.org/abs/2302.06540v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Inferring Player Location in Sports Matches: Multi-Agent Spatial   Imputation from Limited Observations",
        "authors": [
            "Gregory Everett",
            "Ryan J. Beal",
            "Tim Matthews",
            "Joseph Early",
            "Timothy J. Norman",
            "Sarvapali D. Ramchurn"
        ],
        "summary": "Understanding agent behaviour in Multi-Agent Systems (MAS) is an important problem in domains such as autonomous driving, disaster response, and sports analytics. Existing MAS problems typically use uniform timesteps with observations for all agents. In this work, we analyse the problem of agent location imputation, specifically posed in environments with non-uniform timesteps and limited agent observability (~95% missing values). Our approach uses Long Short-Term Memory and Graph Neural Network components to learn temporal and inter-agent patterns to predict the location of all agents at every timestep. We apply this to the domain of football (soccer) by imputing the location of all players in a game from sparse event data (e.g., shots and passes). Our model estimates player locations to within ~6.9m; a ~62% reduction in error from the best performing baseline. This approach facilitates downstream analysis tasks such as player physical metrics, player coverage, and team pitch control. Existing solutions to these tasks often require optical tracking data, which is expensive to obtain and only available to elite clubs. By imputing player locations from easy to obtain event data, we increase the accessibility of downstream tasks.",
        "published": "2023-02-13T18:13:29Z",
        "link": "http://arxiv.org/abs/2302.06569v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Breaking the Curse of Multiagency: Provably Efficient Decentralized   Multi-Agent RL with Function Approximation",
        "authors": [
            "Yuanhao Wang",
            "Qinghua Liu",
            "Yu Bai",
            "Chi Jin"
        ],
        "summary": "A unique challenge in Multi-Agent Reinforcement Learning (MARL) is the curse of multiagency, where the description length of the game as well as the complexity of many existing learning algorithms scale exponentially with the number of agents. While recent works successfully address this challenge under the model of tabular Markov Games, their mechanisms critically rely on the number of states being finite and small, and do not extend to practical scenarios with enormous state spaces where function approximation must be used to approximate value functions or policies.   This paper presents the first line of MARL algorithms that provably resolve the curse of multiagency under function approximation. We design a new decentralized algorithm -- V-Learning with Policy Replay, which gives the first polynomial sample complexity results for learning approximate Coarse Correlated Equilibria (CCEs) of Markov Games under decentralized linear function approximation. Our algorithm always outputs Markov CCEs, and achieves an optimal rate of $\\widetilde{\\mathcal{O}}(\\epsilon^{-2})$ for finding $\\epsilon$-optimal solutions. Also, when restricted to the tabular case, our result improves over the current best decentralized result $\\widetilde{\\mathcal{O}}(\\epsilon^{-3})$ for finding Markov CCEs. We further present an alternative algorithm -- Decentralized Optimistic Policy Mirror Descent, which finds policy-class-restricted CCEs using a polynomial number of samples. In exchange for learning a weaker version of CCEs, this algorithm applies to a wider range of problems under generic function approximation, such as linear quadratic games and MARL problems with low ''marginal'' Eluder dimension.",
        "published": "2023-02-13T18:59:25Z",
        "link": "http://arxiv.org/abs/2302.06606v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.GT",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Achieving Better Regret against Strategic Adversaries",
        "authors": [
            "Le Cong Dinh",
            "Tri-Dung Nguyen",
            "Alain Zemkoho",
            "Long Tran-Thanh"
        ],
        "summary": "We study online learning problems in which the learner has extra knowledge about the adversary's behaviour, i.e., in game-theoretic settings where opponents typically follow some no-external regret learning algorithms. Under this assumption, we propose two new online learning algorithms, Accurate Follow the Regularized Leader (AFTRL) and Prod-Best Response (Prod-BR), that intensively exploit this extra knowledge while maintaining the no-regret property in the worst-case scenario of having inaccurate extra information. Specifically, AFTRL achieves $O(1)$ external regret or $O(1)$ \\emph{forward regret} against no-external regret adversary in comparison with $O(\\sqrt{T})$ \\emph{dynamic regret} of Prod-BR. To the best of our knowledge, our algorithm is the first to consider forward regret that achieves $O(1)$ regret against strategic adversaries. When playing zero-sum games with Accurate Multiplicative Weights Update (AMWU), a special case of AFTRL, we achieve \\emph{last round convergence} to the Nash Equilibrium. We also provide numerical experiments to further support our theoretical results. In particular, we demonstrate that our methods achieve significantly better regret bounds and rate of last round convergence, compared to the state of the art (e.g., Multiplicative Weights Update (MWU) and its optimistic counterpart, OMWU).",
        "published": "2023-02-13T19:34:36Z",
        "link": "http://arxiv.org/abs/2302.06652v1",
        "categories": [
            "cs.LG",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Random Majority Opinion Diffusion: Stabilization Time, Absorbing States,   and Influential Nodes",
        "authors": [
            "Ahad N. Zehmakan"
        ],
        "summary": "Consider a graph G with n nodes and m edges, which represents a social network, and assume that initially each node is blue or white. In each round, all nodes simultaneously update their color to the most frequent color in their neighborhood. This is called the Majority Model (MM) if a node keeps its color in case of a tie and the Random Majority Model (RMM) if it chooses blue with probability 1/2 and white otherwise.   We prove that there are graphs for which RMM needs exponentially many rounds to reach a stable configuration in expectation, and such a configuration can have exponentially many states (i.e., colorings). This is in contrast to MM, which is known to always reach a stable configuration with one or two states in $O(m)$ rounds. For the special case of a cycle graph C_n, we prove the stronger and tight bounds of $\\lceil n/2\\rceil-1$ and $O(n^2)$ in MM and RMM, respectively. Furthermore, we show that the number of stable colorings in MM on C_n is equal to $\\Theta(\\Phi^n)$, where $\\Phi = (1+\\sqrt{5})/2$ is the golden ratio, while it is equal to 2 for RMM.   We also study the minimum size of a winning set, which is a set of nodes whose agreement on a color in the initial coloring enforces the process to end in a coloring where all nodes share that color. We present tight bounds on the minimum size of a winning set for both MM and RMM.   Furthermore, we analyze our models for a random initial coloring, where each node is colored blue independently with some probability $p$ and white otherwise. Using some martingale analysis and counting arguments, we prove that the expected final number of blue nodes is respectively equal to $(2p^2-p^3)n/(1-p+p^2)$ and pn in MM and RMM on a cycle graph C_n.   Finally, we conduct some experiments which complement our theoretical findings and also lead to the proposal of some intriguing open problems and conjectures to be tackled in future work.",
        "published": "2023-02-14T00:14:22Z",
        "link": "http://arxiv.org/abs/2302.06760v1",
        "categories": [
            "cs.DS",
            "cs.AI",
            "cs.DM",
            "cs.MA",
            "cs.SI"
        ]
    },
    {
        "title": "Bringing Diversity to Autonomous Vehicles: An Interpretable   Multi-vehicle Decision-making and Planning Framework",
        "authors": [
            "Licheng Wen",
            "Pinlong Cai",
            "Daocheng Fu",
            "Song Mao",
            "Yikang Li"
        ],
        "summary": "With the development of autonomous driving, it is becoming increasingly common for autonomous vehicles (AVs) and human-driven vehicles (HVs) to travel on the same roads. Existing single-vehicle planning algorithms on board struggle to handle sophisticated social interactions in the real world. Decisions made by these methods are difficult to understand for humans, raising the risk of crashes and making them unlikely to be applied in practice. Moreover, vehicle flows produced by open-source traffic simulators suffer from being overly conservative and lacking behavioral diversity. We propose a hierarchical multi-vehicle decision-making and planning framework with several advantages. The framework jointly makes decisions for all vehicles within the flow and reacts promptly to the dynamic environment through a high-frequency planning module. The decision module produces interpretable action sequences that can explicitly communicate self-intent to the surrounding HVs. We also present the cooperation factor and trajectory weight set, bringing diversity to autonomous vehicles in traffic at both the social and individual levels. The superiority of our proposed framework is validated through experiments with multiple scenarios, and the diverse behaviors in the generated vehicle trajectories are demonstrated through closed-loop simulations.",
        "published": "2023-02-14T03:11:21Z",
        "link": "http://arxiv.org/abs/2302.06803v1",
        "categories": [
            "cs.RO",
            "cs.MA",
            "I.2.9"
        ]
    },
    {
        "title": "Adaptive Value Decomposition with Greedy Marginal Contribution   Computation for Cooperative Multi-Agent Reinforcement Learning",
        "authors": [
            "Shanqi Liu",
            "Yujing Hu",
            "Runze Wu",
            "Dong Xing",
            "Yu Xiong",
            "Changjie Fan",
            "Kun Kuang",
            "Yong Liu"
        ],
        "summary": "Real-world cooperation often requires intensive coordination among agents simultaneously. This task has been extensively studied within the framework of cooperative multi-agent reinforcement learning (MARL), and value decomposition methods are among those cutting-edge solutions. However, traditional methods that learn the value function as a monotonic mixing of per-agent utilities cannot solve the tasks with non-monotonic returns. This hinders their application in generic scenarios. Recent methods tackle this problem from the perspective of implicit credit assignment by learning value functions with complete expressiveness or using additional structures to improve cooperation. However, they are either difficult to learn due to large joint action spaces or insufficient to capture the complicated interactions among agents which are essential to solving tasks with non-monotonic returns. To address these problems, we propose a novel explicit credit assignment method to address the non-monotonic problem. Our method, Adaptive Value decomposition with Greedy Marginal contribution (AVGM), is based on an adaptive value decomposition that learns the cooperative value of a group of dynamically changing agents. We first illustrate that the proposed value decomposition can consider the complicated interactions among agents and is feasible to learn in large-scale scenarios. Then, our method uses a greedy marginal contribution computed from the value decomposition as an individual credit to incentivize agents to learn the optimal cooperative policy. We further extend the module with an action encoder to guarantee the linear time complexity for computing the greedy marginal contribution. Experimental results demonstrate that our method achieves significant performance improvements in several non-monotonic domains.",
        "published": "2023-02-14T07:23:59Z",
        "link": "http://arxiv.org/abs/2302.06872v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Signifiers as a First-class Abstraction in Hypermedia Multi-Agent   Systems",
        "authors": [
            "Danai Vachtsevanou",
            "Andrei Ciortea",
            "Simon Mayer",
            "Jérémy Lemée"
        ],
        "summary": "Hypermedia APIs enable the design of reusable hypermedia clients that discover and exploit affordances on the Web. However, the reusability of such clients remains limited since they cannot plan and reason about interaction. This paper provides a conceptual bridge between hypermedia-driven affordance exploitation on the Web and methods for representing and reasoning about actions that have been extensively explored for Multi-Agent Systems (MAS) and, more broadly, Artificial Intelligence. We build on concepts and methods from Affordance Theory and Human-Computer Interaction that support interaction efficiency in open and evolvable environments to introduce signifiers as a first-class abstraction in Web-based MAS: Signifiers are designed with respect to the agent-environment context of their usage and enable agents with heterogeneous abilities to act and to reason about action. We define a formal model for the contextual exposure of signifiers in hypermedia environments that aims to drive affordance exploitation. We demonstrate our approach with a prototypical Web-based MAS where two agents with different reasoning abilities proactively discover how to interact with their environment by perceiving only the signifiers that fit their abilities. We show that signifier exposure can be inherently managed based on the dynamic agent-environment context towards facilitating effective and efficient interactions on the Web.",
        "published": "2023-02-14T10:54:46Z",
        "link": "http://arxiv.org/abs/2302.06970v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "A Theory of Mind Approach as Test-Time Mitigation Against Emergent   Adversarial Communication",
        "authors": [
            "Nancirose Piazza",
            "Vahid Behzadan"
        ],
        "summary": "Multi-Agent Systems (MAS) is the study of multi-agent interactions in a shared environment. Communication for cooperation is a fundamental construct for sharing information in partially observable environments. Cooperative Multi-Agent Reinforcement Learning (CoMARL) is a learning framework where we learn agent policies either with cooperative mechanisms or policies that exhibit cooperative behavior. Explicitly, there are works on learning to communicate messages from CoMARL agents; however, non-cooperative agents, when capable of access a cooperative team's communication channel, have been shown to learn adversarial communication messages, sabotaging the cooperative team's performance particularly when objectives depend on finite resources. To address this issue, we propose a technique which leverages local formulations of Theory-of-Mind (ToM) to distinguish exhibited cooperative behavior from non-cooperative behavior before accepting messages from any agent. We demonstrate the efficacy and feasibility of the proposed technique in empirical evaluations in a centralized training, decentralized execution (CTDE) CoMARL benchmark. Furthermore, while we propose our explicit ToM defense for test-time, we emphasize that ToM is a construct for designing a cognitive defense rather than be the objective of the defense.",
        "published": "2023-02-14T16:40:51Z",
        "link": "http://arxiv.org/abs/2302.07176v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Graph Attention Multi-Agent Fleet Autonomy for Advanced Air Mobility",
        "authors": [
            "Malintha Fernando",
            "Ransalu Senanayake",
            "Heeyoul Choi",
            "Martin Swany"
        ],
        "summary": "Autonomous mobility is emerging as a new disruptive mode of urban transportation for moving cargo and passengers. However, designing scalable autonomous fleet coordination schemes to accommodate fast-growing mobility systems is challenging primarily due to the increasing heterogeneity of the fleets, time-varying demand patterns, service area expansions, and communication limitations. We introduce the concept of partially observable advanced air mobility games to coordinate a fleet of aerial vehicles by accounting for the heterogeneity of the interacting agents and the self-interested nature inherent to commercial mobility fleets. To model the complex interactions among the agents and the observation uncertainty in the mobility networks, we propose a novel heterogeneous graph attention encoder-decoder (HetGAT Enc-Dec) neural network-based stochastic policy. We train the policy by leveraging deep multi-agent reinforcement learning, allowing decentralized decision-making for the agents using their local observations. Through extensive experimentation, we show that the learned policy generalizes to various fleet compositions, demand patterns, and observation topologies. Further, fleets operating under the HetGAT Enc-Dec policy outperform other state-of-the-art graph neural network policies by achieving the highest fleet reward and fulfillment ratios in on-demand mobility networks.",
        "published": "2023-02-14T20:48:00Z",
        "link": "http://arxiv.org/abs/2302.07337v3",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "On-Demand Communication for Asynchronous Multi-Agent Bandits",
        "authors": [
            "Yu-Zhen Janice Chen",
            "Lin Yang",
            "Xuchuang Wang",
            "Xutong Liu",
            "Mohammad Hajiesmaili",
            "John C. S. Lui",
            "Don Towsley"
        ],
        "summary": "This paper studies a cooperative multi-agent multi-armed stochastic bandit problem where agents operate asynchronously -- agent pull times and rates are unknown, irregular, and heterogeneous -- and face the same instance of a K-armed bandit problem. Agents can share reward information to speed up the learning process at additional communication costs. We propose ODC, an on-demand communication protocol that tailors the communication of each pair of agents based on their empirical pull times. ODC is efficient when the pull times of agents are highly heterogeneous, and its communication complexity depends on the empirical pull times of agents. ODC is a generic protocol that can be integrated into most cooperative bandit algorithms without degrading their performance. We then incorporate ODC into the natural extensions of UCB and AAE algorithms and propose two communication-efficient cooperative algorithms. Our analysis shows that both algorithms are near-optimal in regret.",
        "published": "2023-02-15T03:32:33Z",
        "link": "http://arxiv.org/abs/2302.07446v2",
        "categories": [
            "cs.LG",
            "cs.DC",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "TiZero: Mastering Multi-Agent Football with Curriculum Learning and   Self-Play",
        "authors": [
            "Fanqi Lin",
            "Shiyu Huang",
            "Tim Pearce",
            "Wenze Chen",
            "Wei-Wei Tu"
        ],
        "summary": "Multi-agent football poses an unsolved challenge in AI research. Existing work has focused on tackling simplified scenarios of the game, or else leveraging expert demonstrations. In this paper, we develop a multi-agent system to play the full 11 vs. 11 game mode, without demonstrations. This game mode contains aspects that present major challenges to modern reinforcement learning algorithms; multi-agent coordination, long-term planning, and non-transitivity. To address these challenges, we present TiZero; a self-evolving, multi-agent system that learns from scratch. TiZero introduces several innovations, including adaptive curriculum learning, a novel self-play strategy, and an objective that optimizes the policies of multiple agents jointly. Experimentally, it outperforms previous systems by a large margin on the Google Research Football environment, increasing win rates by over 30%. To demonstrate the generality of TiZero's innovations, they are assessed on several environments beyond football; Overcooked, Multi-agent Particle-Environment, Tic-Tac-Toe and Connect-Four.",
        "published": "2023-02-15T08:19:18Z",
        "link": "http://arxiv.org/abs/2302.07515v2",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Learning Hierarchical Resource Allocation and Multi-agent Coordination   of 5G mobile IAB Nodes",
        "authors": [
            "Mohamed Sana",
            "Benoit Miscopein"
        ],
        "summary": "We consider a dynamic millimeter-wave network with integrated access and backhaul, where mobile relay nodes move to auto-reconfigure the wireless backhaul. Specifically, we focus on in-band relaying networks, which conduct access and backhaul links on the same frequency band with severe constraints on co-channel interference. In this context, we jointly study the complex problem of dynamic relay node positioning, user association, and backhaul capacity allocation. To address this problem, with limited complexity, we adopt a hierarchical multi-agent reinforcement with a two-level structure. A high-level policy dynamically coordinates mobile relay nodes, defining the backhaul configuration for a low-level policy, which jointly assigns user equipment to each relay and allocates the backhaul capacity accordingly. The resulting solution automatically adapts the access and backhaul network to changes in the number of users, the traffic distribution, and the variations of the channels. Numerical results show the effectiveness of our proposed solution in terms of convergence of the hierarchical learning procedure. It also provides a significant backhaul capacity and network sum-rate increase (up to 3.5x) compared to baseline approaches.",
        "published": "2023-02-15T10:30:53Z",
        "link": "http://arxiv.org/abs/2302.07573v1",
        "categories": [
            "cs.MA",
            "cs.NI"
        ]
    },
    {
        "title": "ForceFormer: Exploring Social Force and Transformer for Pedestrian   Trajectory Prediction",
        "authors": [
            "Weicheng Zhang",
            "Hao Cheng",
            "Fatema T. Johora",
            "Monika Sester"
        ],
        "summary": "Predicting trajectories of pedestrians based on goal information in highly interactive scenes is a crucial step toward Intelligent Transportation Systems and Autonomous Driving. The challenges of this task come from two key sources: (1) complex social interactions in high pedestrian density scenarios and (2) limited utilization of goal information to effectively associate with past motion information. To address these difficulties, we integrate social forces into a Transformer-based stochastic generative model backbone and propose a new goal-based trajectory predictor called ForceFormer. Differentiating from most prior works that simply use the destination position as an input feature, we leverage the driving force from the destination to efficiently simulate the guidance of a target on a pedestrian. Additionally, repulsive forces are used as another input feature to describe the avoidance action among neighboring pedestrians. Extensive experiments show that our proposed method achieves on-par performance measured by distance errors with the state-of-the-art models but evidently decreases collisions, especially in dense pedestrian scenarios on widely used pedestrian datasets.",
        "published": "2023-02-15T10:54:14Z",
        "link": "http://arxiv.org/abs/2302.07583v1",
        "categories": [
            "cs.CV",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Scalable Multi-Agent Reinforcement Learning with General Utilities",
        "authors": [
            "Donghao Ying",
            "Yuhao Ding",
            "Alec Koppel",
            "Javad Lavaei"
        ],
        "summary": "We study the scalable multi-agent reinforcement learning (MARL) with general utilities, defined as nonlinear functions of the team's long-term state-action occupancy measure. The objective is to find a localized policy that maximizes the average of the team's local utility functions without the full observability of each agent in the team. By exploiting the spatial correlation decay property of the network structure, we propose a scalable distributed policy gradient algorithm with shadow reward and localized policy that consists of three steps: (1) shadow reward estimation, (2) truncated shadow Q-function estimation, and (3) truncated policy gradient estimation and policy update. Our algorithm converges, with high probability, to $\\epsilon$-stationarity with $\\widetilde{\\mathcal{O}}(\\epsilon^{-2})$ samples up to some approximation error that decreases exponentially in the communication radius. This is the first result in the literature on multi-agent RL with general utilities that does not require the full observability.",
        "published": "2023-02-15T20:47:43Z",
        "link": "http://arxiv.org/abs/2302.07938v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Learning Density-Based Correlated Equilibria for Markov Games",
        "authors": [
            "Libo Zhang",
            "Yang Chen",
            "Toru Takisaka",
            "Bakh Khoussainov",
            "Michael Witbrock",
            "Jiamou Liu"
        ],
        "summary": "Correlated Equilibrium (CE) is a well-established solution concept that captures coordination among agents and enjoys good algorithmic properties. In real-world multi-agent systems, in addition to being in an equilibrium, agents' policies are often expected to meet requirements with respect to safety, and fairness. Such additional requirements can often be expressed in terms of the state density which measures the state-visitation frequencies during the course of a game. However, existing CE notions or CE-finding approaches cannot explicitly specify a CE with particular properties concerning state density; they do so implicitly by either modifying reward functions or using value functions as the selection criteria. The resulting CE may thus not fully fulfil the state-density requirements. In this paper, we propose Density-Based Correlated Equilibria (DBCE), a new notion of CE that explicitly takes state density as selection criterion. Concretely, we instantiate DBCE by specifying different state-density requirements motivated by real-world applications. To compute DBCE, we put forward the Density Based Correlated Policy Iteration algorithm for the underlying control problem. We perform experiments on various games where results demonstrate the advantage of our CE-finding approach over existing methods in scenarios with state-density concerns.",
        "published": "2023-02-16T00:19:53Z",
        "link": "http://arxiv.org/abs/2302.08001v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "On the Role of Memory in Robust Opinion Dynamics",
        "authors": [
            "Luca Becchetti",
            "Andrea Clementi",
            "Amos Korman",
            "Francesco Pasquale",
            "Luca Trevisan",
            "Robin Vacus"
        ],
        "summary": "We investigate opinion dynamics in a fully-connected system, consisting of $n$ identical and anonymous agents, where one of the opinions (which is called correct) represents a piece of information to disseminate. In more detail, one source agent initially holds the correct opinion and remains with this opinion throughout the execution. The goal for non-source agents is to quickly agree on this correct opinion, and do that robustly, i.e., from any initial configuration. The system evolves in rounds. In each round, one agent chosen uniformly at random is activated: unless it is the source, the agent pulls the opinions of $\\ell$ random agents and then updates its opinion according to some rule. We consider a restricted setting, in which agents have no memory and they only revise their opinions on the basis of those of the agents they currently sample. As restricted as it is, this setting encompasses very popular opinion dynamics, such as the voter model and best-of-$k$ majority rules.   Qualitatively speaking, we show that lack of memory prevents efficient convergence. Specifically, we prove that no dynamics can achieve correct convergence in an expected number of steps that is sub-quadratic in $n$, even under a strong version of the model in which activated agents have complete access to the current configuration of the entire system, i.e., the case $\\ell=n$. Conversely, we prove that the simple voter model (in which $\\ell=1$) correctly solves the problem, while almost matching the aforementioned lower bound.   These results suggest that, in contrast to symmetric consensus problems (that do not involve a notion of correct opinion), fast convergence on the correct opinion using stochastic opinion dynamics may indeed require the use of memory. This insight may reflect on natural information dissemination processes that rely on a few knowledgeable individuals.",
        "published": "2023-02-16T21:53:14Z",
        "link": "http://arxiv.org/abs/2302.08600v1",
        "categories": [
            "cs.DC",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Value Engineering for Autonomous Agents",
        "authors": [
            "Nieves Montes",
            "Nardine Osman",
            "Carles Sierra",
            "Marija Slavkovik"
        ],
        "summary": "Machine Ethics (ME) is concerned with the design of Artificial Moral Agents (AMAs), i.e. autonomous agents capable of reasoning and behaving according to moral values. Previous approaches have treated values as labels associated with some actions or states of the world, rather than as integral components of agent reasoning. It is also common to disregard that a value-guided agent operates alongside other value-guided agents in an environment governed by norms, thus omitting the social dimension of AMAs. In this blue sky paper, we propose a new AMA paradigm grounded in moral and social psychology, where values are instilled into agents as context-dependent goals. These goals intricately connect values at individual levels to norms at a collective level by evaluating the outcomes most incentivized by the norms in place. We argue that this type of normative reasoning, where agents are endowed with an understanding of norms' moral implications, leads to value-awareness in autonomous agents. Additionally, this capability paves the way for agents to align the norms enforced in their societies with respect to the human values instilled in them, by complementing the value-based reasoning on norms with agreement mechanisms to help agents collectively agree on the best set of norms that suit their human values. Overall, our agent model goes beyond the treatment of values as inert labels by connecting them to normative reasoning and to the social functionalities needed to integrate value-aware agents into our modern hybrid human-computer societies.",
        "published": "2023-02-17T08:52:15Z",
        "link": "http://arxiv.org/abs/2302.08759v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Mixed Traffic Control and Coordination from Pixels",
        "authors": [
            "Michael Villarreal",
            "Bibek Poudel",
            "Jia Pan",
            "Weizi Li"
        ],
        "summary": "Traffic congestion is a persistent problem in our society. Previous methods for traffic control have proven futile in alleviating current congestion levels leading researchers to explore ideas with robot vehicles given the increased emergence of vehicles with different levels of autonomy on our roads. This gives rise to mixed traffic control, where robot vehicles regulate human-driven vehicles through reinforcement learning (RL). However, most existing studies use precise observations that require domain expertise and hand engineering for each road network's observation space. Additionally, precise observations use global information, such as environment outflow, and local information, i.e., vehicle positions and velocities. Obtaining this information requires updating existing road infrastructure with vast sensor environments and communication to potentially unwilling human drivers. We consider image observations, a modality that has not been extensively explored for mixed traffic control via RL, as the alternative: 1) images do not require a complete re-imagination of the observation space from environment to environment; 2) images are ubiquitous through satellite imagery, in-car camera systems, and traffic monitoring systems; and 3) images only require communication to equipment. In this work, we show robot vehicles using image observations can achieve competitive performance to using precise information on environments, including ring, figure eight, intersection, merge, and bottleneck. In certain scenarios, our approach even outperforms using precision observations, e.g., up to 8% increase in average vehicle velocity in the merge environment, despite only using local traffic information as opposed to global traffic information.",
        "published": "2023-02-17T22:40:07Z",
        "link": "http://arxiv.org/abs/2302.09167v4",
        "categories": [
            "cs.MA",
            "cs.LG",
            "cs.RO"
        ]
    },
    {
        "title": "HOPE: Human-Centric Off-Policy Evaluation for E-Learning and Healthcare",
        "authors": [
            "Ge Gao",
            "Song Ju",
            "Markel Sanz Ausin",
            "Min Chi"
        ],
        "summary": "Reinforcement learning (RL) has been extensively researched for enhancing human-environment interactions in various human-centric tasks, including e-learning and healthcare. Since deploying and evaluating policies online are high-stakes in such tasks, off-policy evaluation (OPE) is crucial for inducing effective policies. In human-centric environments, however, OPE is challenging because the underlying state is often unobservable, while only aggregate rewards can be observed (students' test scores or whether a patient is released from the hospital eventually). In this work, we propose a human-centric OPE (HOPE) to handle partial observability and aggregated rewards in such environments. Specifically, we reconstruct immediate rewards from the aggregated rewards considering partial observability to estimate expected total returns. We provide a theoretical bound for the proposed method, and we have conducted extensive experiments in real-world human-centric tasks, including sepsis treatments and an intelligent tutoring system. Our approach reliably predicts the returns of different policies and outperforms state-of-the-art benchmarks using both standard validation methods and human-centric significance tests.",
        "published": "2023-02-18T02:33:30Z",
        "link": "http://arxiv.org/abs/2302.09212v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Distributed Planning with Asynchronous Execution with Local Navigation   for Multi-agent Pickup and Delivery Problem",
        "authors": [
            "Yuki Miyashita",
            "Tomoki Yamauchi",
            "Toshiharu Sugawara"
        ],
        "summary": "We propose a distributed planning method with asynchronous execution for multi-agent pickup and delivery (MAPD) problems for environments with occasional delays in agents' activities and flexible endpoints. MAPD is a crucial problem framework with many applications; however, most existing studies assume ideal agent behaviors and environments, such as a fixed speed of agents, synchronized movements, and a well-designed environment with many short detours for multiple agents to perform tasks easily. However, such an environment is often infeasible; for example, the moving speed of agents may be affected by weather and floor conditions and is often prone to delays. The proposed method can relax some infeasible conditions to apply MAPD in more realistic environments by allowing fluctuated speed in agents' actions and flexible working locations (endpoints). Our experiments showed that our method enables agents to perform MAPD in such an environment efficiently, compared to the baseline methods. We also analyzed the behaviors of agents using our method and discuss the limitations.",
        "published": "2023-02-18T07:02:03Z",
        "link": "http://arxiv.org/abs/2302.09250v1",
        "categories": [
            "cs.MA",
            "cs.RO",
            "I.2.11"
        ]
    },
    {
        "title": "Promoting Cooperation in Multi-Agent Reinforcement Learning via Mutual   Help",
        "authors": [
            "Yunbo Qiu",
            "Yue Jin",
            "Lebin Yu",
            "Jian Wang",
            "Xudong Zhang"
        ],
        "summary": "Multi-agent reinforcement learning (MARL) has achieved great progress in cooperative tasks in recent years. However, in the local reward scheme, where only local rewards for each agent are given without global rewards shared by all the agents, traditional MARL algorithms lack sufficient consideration of agents' mutual influence. In cooperative tasks, agents' mutual influence is especially important since agents are supposed to coordinate to achieve better performance. In this paper, we propose a novel algorithm Mutual-Help-based MARL (MH-MARL) to instruct agents to help each other in order to promote cooperation. MH-MARL utilizes an expected action module to generate expected other agents' actions for each particular agent. Then, the expected actions are delivered to other agents for selective imitation during training. Experimental results show that MH-MARL improves the performance of MARL both in success rate and cumulative reward.",
        "published": "2023-02-18T10:07:01Z",
        "link": "http://arxiv.org/abs/2302.09277v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "AIIR-MIX: Multi-Agent Reinforcement Learning Meets Attention Individual   Intrinsic Reward Mixing Network",
        "authors": [
            "Wei Li",
            "Weiyan Liu",
            "Shitong Shao",
            "Shiyi Huang"
        ],
        "summary": "Deducing the contribution of each agent and assigning the corresponding reward to them is a crucial problem in cooperative Multi-Agent Reinforcement Learning (MARL). Previous studies try to resolve the issue through designing an intrinsic reward function, but the intrinsic reward is simply combined with the environment reward by summation in these studies, which makes the performance of their MARL framework unsatisfactory. We propose a novel method named Attention Individual Intrinsic Reward Mixing Network (AIIR-MIX) in MARL, and the contributions of AIIR-MIX are listed as follows:(a) we construct a novel intrinsic reward network based on the attention mechanism to make teamwork more effective. (b) we propose a Mixing network that is able to combine intrinsic and extrinsic rewards non-linearly and dynamically in response to changing conditions of the environment. We compare AIIR-MIX with many State-Of-The-Art (SOTA) MARL methods on battle games in StarCraft II. And the results demonstrate that AIIR-MIX performs admirably and can defeat the current advanced methods on average test win rate. To validate the effectiveness of AIIR-MIX, we conduct additional ablation studies. The results show that AIIR-MIX can dynamically assign each agent a real-time intrinsic reward in accordance with their actual contribution.",
        "published": "2023-02-19T10:25:25Z",
        "link": "http://arxiv.org/abs/2302.09531v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Efficient Communication via Self-supervised Information Aggregation for   Online and Offline Multi-agent Reinforcement Learning",
        "authors": [
            "Cong Guan",
            "Feng Chen",
            "Lei Yuan",
            "Zongzhang Zhang",
            "Yang Yu"
        ],
        "summary": "Utilizing messages from teammates can improve coordination in cooperative Multi-agent Reinforcement Learning (MARL). Previous works typically combine raw messages of teammates with local information as inputs for policy. However, neglecting message aggregation poses significant inefficiency for policy learning. Motivated by recent advances in representation learning, we argue that efficient message aggregation is essential for good coordination in cooperative MARL. In this paper, we propose Multi-Agent communication via Self-supervised Information Aggregation (MASIA), where agents can aggregate the received messages into compact representations with high relevance to augment the local policy. Specifically, we design a permutation invariant message encoder to generate common information-aggregated representation from messages and optimize it via reconstructing and shooting future information in a self-supervised manner. Hence, each agent would utilize the most relevant parts of the aggregated representation for decision-making by a novel message extraction mechanism. Furthermore, considering the potential of offline learning for real-world applications, we build offline benchmarks for multi-agent communication, which is the first as we know. Empirical results demonstrate the superiority of our method in both online and offline settings. We also release the built offline benchmarks in this paper as a testbed for communication ability validation to facilitate further future research.",
        "published": "2023-02-19T16:02:16Z",
        "link": "http://arxiv.org/abs/2302.09605v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Achieving Hierarchy-Free Approximation for Bilevel Programs With   Equilibrium Constraints",
        "authors": [
            "Jiayang Li",
            "Jing Yu",
            "Boyi Liu",
            "Zhaoran Wang",
            "Yu Marco Nie"
        ],
        "summary": "In this paper, we develop an approximation scheme for solving bilevel programs with equilibrium constraints, which are generally difficult to solve. Among other things, calculating the first-order derivative in such a problem requires differentiation across the hierarchy, which is computationally intensive, if not prohibitive. To bypass the hierarchy, we propose to bound such bilevel programs, equivalent to multiple-followers Stackelberg games, with two new hierarchy-free problems: a $T$-step Cournot game and a $T$-step monopoly model. Since they are standard equilibrium or optimization problems, both can be efficiently solved via first-order methods. Importantly, we show that the bounds provided by these problems -- the upper bound by the $T$-step Cournot game and the lower bound by the $T$-step monopoly model -- can be made arbitrarily tight by increasing the step parameter $T$ for a wide range of problems. We prove that a small $T$ usually suffices under appropriate conditions to reach an approximation acceptable for most practical purposes. Eventually, the analytical insights are highlighted through numerical examples.",
        "published": "2023-02-20T03:13:10Z",
        "link": "http://arxiv.org/abs/2302.09734v1",
        "categories": [
            "math.OC",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Co-evolution of Social and Non-Social Guilt",
        "authors": [
            "Theodor Cimpeanu",
            "Luis Moniz Pereira",
            "The Anh Han"
        ],
        "summary": "Building ethical machines may involve bestowing upon them the emotional capacity to self-evaluate and repent on their actions. While reparative measures, such as apologies, are often considered as possible strategic interactions, the explicit evolution of the emotion of guilt as a behavioural phenotype is not yet well understood. Here, we study the co-evolution of social and non-social guilt of homogeneous or heterogeneous populations, including well-mixed, lattice and scale-free networks. Socially aware guilt comes at a cost, as it requires agents to make demanding efforts to observe and understand the internal state and behaviour of others, while non-social guilt only requires the awareness of the agents' own state and hence incurs no social cost. Those choosing to be non-social are however more sensitive to exploitation by other agents due to their social unawareness. Resorting to methods from evolutionary game theory, we study analytically, and through extensive numerical and agent-based simulations, whether and how such social and non-social guilt can evolve and deploy, depending on the underlying structure of the populations, or systems, of agents. The results show that, in both lattice and scale-free networks, emotional guilt prone strategies are dominant for a larger range of the guilt and social costs incurred, compared to the well-mixed population setting, leading therefore to significantly higher levels of cooperation for a wider range of the costs. In structured population settings, both social and non-social guilt can evolve and deploy through clustering with emotional prone strategies, allowing them to be protected from exploiters, especially in case of non-social (less costly) strategies. Overall, our findings provide important insights into the design and engineering of self-organised and distributed cooperative multi-agent systems.",
        "published": "2023-02-20T09:40:49Z",
        "link": "http://arxiv.org/abs/2302.09859v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.CY",
            "math.DS",
            "nlin.AO"
        ]
    },
    {
        "title": "Price of Anarchy in a Double-Sided Critical Distribution System",
        "authors": [
            "David Sychrovský",
            "Jakub Černý",
            "Sylvain Lichau",
            "Martin Loebl"
        ],
        "summary": "Measures of allocation optimality differ significantly when distributing standard tradable goods in peaceful times and scarce resources in crises. While realistic markets offer asymptotic efficiency, they may not necessarily guarantee fair allocation desirable when distributing the critical resources. To achieve fairness, mechanisms often rely on a central authority, which may act inefficiently in times of need when swiftness and good organization are crucial. In this work, we study a hybrid trading system called Crisdis, introduced by Jedli\\v{c}kov\\'{a} et al., which combines fair allocation of buying rights with a market - leveraging the best of both worlds. A frustration of a buyer in Crisdis is defined as a difference between the amount of goods they are entitled to according to the assigned buying rights and the amount of goods they are able to acquire by trading. We define a Price of Anarchy (PoA) in this system as a conceptual analogue of the original definition in the context of frustration. Our main contribution is a study of PoA in realistic complex double-sided market mechanisms for Crisdis. The performed empirical analysis suggests that in contrast to market free of governmental interventions, the PoA in our system decreases.",
        "published": "2023-02-20T13:04:17Z",
        "link": "http://arxiv.org/abs/2302.09959v1",
        "categories": [
            "cs.MA",
            "cs.GT"
        ]
    },
    {
        "title": "Differentiable Arbitrating in Zero-sum Markov Games",
        "authors": [
            "Jing Wang",
            "Meichen Song",
            "Feng Gao",
            "Boyi Liu",
            "Zhaoran Wang",
            "Yi Wu"
        ],
        "summary": "We initiate the study of how to perturb the reward in a zero-sum Markov game with two players to induce a desirable Nash equilibrium, namely arbitrating. Such a problem admits a bi-level optimization formulation. The lower level requires solving the Nash equilibrium under a given reward function, which makes the overall problem challenging to optimize in an end-to-end way. We propose a backpropagation scheme that differentiates through the Nash equilibrium, which provides the gradient feedback for the upper level. In particular, our method only requires a black-box solver for the (regularized) Nash equilibrium (NE). We develop the convergence analysis for the proposed framework with proper black-box NE solvers and demonstrate the empirical successes in two multi-agent reinforcement learning (MARL) environments.",
        "published": "2023-02-20T16:05:04Z",
        "link": "http://arxiv.org/abs/2302.10058v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Multiagent Inverse Reinforcement Learning via Theory of Mind Reasoning",
        "authors": [
            "Haochen Wu",
            "Pedro Sequeira",
            "David V. Pynadath"
        ],
        "summary": "We approach the problem of understanding how people interact with each other in collaborative settings, especially when individuals know little about their teammates, via Multiagent Inverse Reinforcement Learning (MIRL), where the goal is to infer the reward functions guiding the behavior of each individual given trajectories of a team's behavior during some task. Unlike current MIRL approaches, we do not assume that team members know each other's goals a priori; rather, that they collaborate by adapting to the goals of others perceived by observing their behavior, all while jointly performing a task. To address this problem, we propose a novel approach to MIRL via Theory of Mind (MIRL-ToM). For each agent, we first use ToM reasoning to estimate a posterior distribution over baseline reward profiles given their demonstrated behavior. We then perform MIRL via decentralized equilibrium by employing single-agent Maximum Entropy IRL to infer a reward function for each agent, where we simulate the behavior of other teammates according to the time-varying distribution over profiles. We evaluate our approach in a simulated 2-player search-and-rescue operation where the goal of the agents, playing different roles, is to search for and evacuate victims in the environment. Our results show that the choice of baseline profiles is paramount to the recovery of the ground-truth rewards, and that MIRL-ToM is able to recover the rewards used by agents interacting both with known and unknown teammates.",
        "published": "2023-02-20T19:07:42Z",
        "link": "http://arxiv.org/abs/2302.10238v2",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "68T01"
        ]
    },
    {
        "title": "MAC-PO: Multi-Agent Experience Replay via Collective Priority   Optimization",
        "authors": [
            "Yongsheng Mei",
            "Hanhan Zhou",
            "Tian Lan",
            "Guru Venkataramani",
            "Peng Wei"
        ],
        "summary": "Experience replay is crucial for off-policy reinforcement learning (RL) methods. By remembering and reusing the experiences from past different policies, experience replay significantly improves the training efficiency and stability of RL algorithms. Many decision-making problems in practice naturally involve multiple agents and require multi-agent reinforcement learning (MARL) under centralized training decentralized execution paradigm. Nevertheless, existing MARL algorithms often adopt standard experience replay where the transitions are uniformly sampled regardless of their importance. Finding prioritized sampling weights that are optimized for MARL experience replay has yet to be explored. To this end, we propose MAC-PO, which formulates optimal prioritized experience replay for multi-agent problems as a regret minimization over the sampling weights of transitions. Such optimization is relaxed and solved using the Lagrangian multiplier approach to obtain the close-form optimal sampling weights. By minimizing the resulting policy regret, we can narrow the gap between the current policy and a nominal optimal policy, thus acquiring an improved prioritization scheme for multi-agent tasks. Our experimental results on Predator-Prey and StarCraft Multi-Agent Challenge environments demonstrate the effectiveness of our method, having a better ability to replay important transitions and outperforming other state-of-the-art baselines.",
        "published": "2023-02-21T03:11:21Z",
        "link": "http://arxiv.org/abs/2302.10418v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Crowd simulation incorporating a route choice model and similarity   evaluation using real large-scale data",
        "authors": [
            "Ryo Nishida",
            "Masaki Onishi",
            "Koichi Hashimoto"
        ],
        "summary": "Modeling and simulation approaches that express crowd movement with mathematical models are widely and actively studied to understand crowd movement and resolve crowd accidents. Existing literature on crowd modeling focuses on only the decision-making of walking behavior. However, the decision-making of route choice, which is a higher-level decision, should also be modeled for constructing more practical simulations. Furthermore, the reproducibility evaluation of the crowd simulation incorporating the route choice model using real data is insufficient. Therefore, we generalize and propose a crowd simulation framework that includes actual crowd movement measurements, route choice model estimation, and crowd simulator construction. We use the Discrete choice model as the route choice model and the Social force model as the walking model. In experiments, we measure crowd movements during an evacuation drill in a theater and a firework event where tens of thousands of people moved and prove that the crowd simulation incorporating the route choice model can reproduce the real large-scale crowd movement more accurately.",
        "published": "2023-02-21T03:16:53Z",
        "link": "http://arxiv.org/abs/2302.10421v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Future Aware Pricing and Matching for Sustainable On-demand Ride Pooling",
        "authors": [
            "Xianjie Zhang",
            "Pradeep Varakantham",
            "Hao Jiang"
        ],
        "summary": "The popularity of on-demand ride pooling is owing to the benefits offered to customers (lower prices), taxi drivers (higher revenue), environment (lower carbon footprint due to fewer vehicles) and aggregation companies like Uber (higher revenue). To achieve these benefits, two key interlinked challenges have to be solved effectively: (a) pricing -- setting prices to customer requests for taxis; and (b) matching -- assignment of customers (that accepted the prices) to taxis/cars. Traditionally, both these challenges have been studied individually and using myopic approaches (considering only current requests), without considering the impact of current matching on addressing future requests. In this paper, we develop a novel framework that handles the pricing and matching problems together, while also considering the future impact of the pricing and matching decisions. In our experimental results on a real-world taxi dataset, we demonstrate that our framework can significantly improve revenue (up to 17% and on average 6.4%) in a sustainable manner by reducing the number of vehicles (up to 14% and on average 10.6%) required to obtain a given fixed revenue and the overall distance travelled by vehicles (up to 11.1% and on average 3.7%). That is to say, we are able to provide an ideal win-win scenario for all stakeholders (customers, drivers, aggregator, environment) involved by obtaining higher revenue for customers, drivers, aggregator (ride pooling company) while being good for the environment (due to fewer number of vehicles on the road and lesser fuel consumed).",
        "published": "2023-02-21T08:24:35Z",
        "link": "http://arxiv.org/abs/2302.10510v3",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "The Swiss Gambit",
        "authors": [
            "Ágnes Cseh",
            "Pascal Führlich",
            "Pascal Lenzner"
        ],
        "summary": "In each round of a Swiss-system tournament, players of similar score are paired against each other. An intentional early loss therefore might lead to weaker opponents in later rounds and thus to a better final tournament result - a phenomenon known as the Swiss Gambit. To the best of our knowledge it is an open question whether this strategy can actually work.   This paper provides answers based on an empirical agent-based analysis for the most prominent application area of the Swiss-system format, namely chess tournaments. We simulate realistic tournaments by employing the official FIDE pairing system for computing the player pairings in each round. We show that even though gambits are widely possible in Swiss-system chess tournaments, profiting from them requires a high degree of predictability of match results. Moreover, even if a Swiss Gambit succeeds, the obtained improvement in the final ranking is limited. Our experiments prove that counting on a Swiss Gambit is indeed a lot more of a risky gambit than a reliable strategy to improve the final rank.",
        "published": "2023-02-21T10:56:33Z",
        "link": "http://arxiv.org/abs/2302.10595v1",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Inferring Implicit Trait Preferences for Task Allocation in   Heterogeneous Teams",
        "authors": [
            "Vivek Mallampati",
            "Harish Ravichandar"
        ],
        "summary": "Task allocation in heterogeneous multi-agent teams often requires reasoning about multi-dimensional agent traits (i.e., capabilities) and the demands placed on them by tasks. However, existing methods tend to ignore the fact that not all traits equally contribute to a given task. Ignoring such inherent preferences or relative importance can lead to unintended sub-optimal allocations of limited agent resources that do not necessarily contribute to task success. Further, reasoning over a large number of traits can incur a hefty computational burden. To alleviate these concerns, we propose an algorithm to infer task-specific trait preferences implicit in expert demonstrations. We leverage the insight that the consistency with which an expert allocates a trait to a task across demonstrations reflects the trait's importance to that task. Inspired by findings in psychology, we account for the fact that the inherent diversity of a trait in the dataset influences the dataset's informativeness and, thereby, the extent of the inferred preference or the lack thereof. Through detailed numerical simulations and evaluations of a publicly-available soccer dataset (FIFA 20), we demonstrate that we can successfully infer implicit trait preferences and that accounting for the inferred preferences leads to more computationally efficient and effective task allocation, compared to a baseline approach that treats all traits equally.",
        "published": "2023-02-21T16:53:57Z",
        "link": "http://arxiv.org/abs/2302.10817v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "MultiVehicle Simulator (MVSim): lightweight dynamics simulator for   multiagents and mobile robotics research",
        "authors": [
            "José-Luis Blanco-Claraco",
            "Borys Tymchenko",
            "Francisco José Mañas-Alvarez",
            "Fernando Cañadas-Aránega",
            "Ángel López-Gázquez",
            "José Carlos Moreno"
        ],
        "summary": "Development of applications related to closed-loop control requires either testing on the field or on a realistic simulator, with the latter being more convenient, inexpensive, safe, and leading to shorter development cycles. To address that need, the present work introduces MVSim, a simulator for multiple vehicles or robots capable of running dozens of agents in simple scenarios, or a handful of them in complex scenarios. MVSim employs realistic physics-grounded friction models for tire-ground interaction, and aims at accurate and GPU-accelerated simulation of most common modern sensors employed in mobile robotics and autonomous vehicle research, such as depth and RGB cameras, or 2D and 3D LiDAR scanners. All depth-related sensors are able to accurately measure distances to 3D models provided by the user to define custom world elements. Efficient simulation is achieved by means of focusing on ground vehicles, which allows the use of a simplified 2D physics engine for body collisions while solving wheel-ground interaction forces separately. The core parts of the system are written in C++ for maximum efficiency, while Python, ROS 1, and ROS 2 wrappers are also offered for easy integration into user systems. A custom publish/subscribe protocol based on ZeroMQ (ZMQ) is defined to allow for multiprocess applications to access or modify a running simulation. This simulator enables and makes easier to do research and development on vehicular dynamics, autonomous navigation algorithms, and simultaneous localization and mapping (SLAM) methods.",
        "published": "2023-02-21T22:22:21Z",
        "link": "http://arxiv.org/abs/2302.11033v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "CrowdLogo: crowd simulation in NetLogo",
        "authors": [
            "Davide Foini",
            "Magdalena Rzyska",
            "Katharina Baschmakov",
            "Sergio Murino"
        ],
        "summary": "Planning the evacuation of people from crowded places, such as squares, stadiums, or indoor arenas during emergency scenarios is a fundamental task that authorities must deal with. This article summarizes the work of the authors to simulate an emergency scenario in a square using NetLogo, a multi-agent programmable modeling environment. The emergency scenario is based on a real event, which took place in Piazza San Carlo, Turin, on the 3rd of June 2017. The authors have developed a model and conducted various experiments, the results of which are presented, discussed and analyzed. The article concludes by offering suggestions for further research and summarizing the key takeaways.",
        "published": "2023-02-21T22:38:04Z",
        "link": "http://arxiv.org/abs/2302.11036v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "An agent-based model of the 2020 international policy diffusion in   response to the COVID-19 pandemic with particle filter",
        "authors": [
            "Yannick Oswald",
            "Nick Malleson",
            "Keiran Suchak"
        ],
        "summary": "Global problems, such as pandemics and climate change, require rapid international coordination and diffusion of policy. These phenomena are rare however, with one notable example being the international policy response to the COVID-19 pandemic in early 2020. Here we build an agent-based model of this rapid policy diffusion, where countries constitute the agents and with the principal mechanism for diffusion being peer mimicry. Since it is challenging to predict accurately the policy diffusion curve, we utilize data assimilation, that is an ``on-line'' feed of data to constrain the model against observations. The specific data assimilation algorithm we apply is a particle filter because of its convenient implementation, its ability to handle categorical variables and because the model is not overly computationally expensive, hence a more efficient algorithm is not required. We find that the model alone is able to predict the policy diffusion relatively well with an ensemble of at least 100 simulation runs. The particle filter however improves the fit to the data, reliably so from 500 runs upwards, and increasing filtering frequency results in improved prediction.",
        "published": "2023-02-22T10:52:48Z",
        "link": "http://arxiv.org/abs/2302.11277v1",
        "categories": [
            "cs.MA",
            "physics.soc-ph"
        ]
    },
    {
        "title": "Revisiting the Gumbel-Softmax in MADDPG",
        "authors": [
            "Callum Rhys Tilbury",
            "Filippos Christianos",
            "Stefano V. Albrecht"
        ],
        "summary": "MADDPG is an algorithm in multi-agent reinforcement learning (MARL) that extends the popular single-agent method, DDPG, to multi-agent scenarios. Importantly, DDPG is an algorithm designed for continuous action spaces, where the gradient of the state-action value function exists. For this algorithm to work in discrete action spaces, discrete gradient estimation must be performed. For MADDPG, the Gumbel-Softmax (GS) estimator is used -- a reparameterisation which relaxes a discrete distribution into a similar continuous one. This method, however, is statistically biased, and a recent MARL benchmarking paper suggests that this bias makes MADDPG perform poorly in grid-world situations, where the action space is discrete. Fortunately, many alternatives to the GS exist, boasting a wide range of properties. This paper explores several of these alternatives and integrates them into MADDPG for discrete grid-world scenarios. The corresponding impact on various performance metrics is then measured and analysed. It is found that one of the proposed estimators performs significantly better than the original GS in several tasks, achieving up to 55% higher returns, along with faster convergence.",
        "published": "2023-02-23T06:13:51Z",
        "link": "http://arxiv.org/abs/2302.11793v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Reinforcement Learning for Combining Search Methods in the Calibration   of Economic ABMs",
        "authors": [
            "Aldo Glielmo",
            "Marco Favorito",
            "Debmallya Chanda",
            "Domenico Delli Gatti"
        ],
        "summary": "Calibrating agent-based models (ABMs) in economics and finance typically involves a derivative-free search in a very large parameter space. In this work, we benchmark a number of search methods in the calibration of a well-known macroeconomic ABM on real data, and further assess the performance of \"mixed strategies\" made by combining different methods. We find that methods based on random-forest surrogates are particularly efficient, and that combining search methods generally increases performance since the biases of any single method are mitigated. Moving from these observations, we propose a reinforcement learning (RL) scheme to automatically select and combine search methods on-the-fly during a calibration run. The RL agent keeps exploiting a specific method only as long as this keeps performing well, but explores new strategies when the specific method reaches a performance plateau. The resulting RL search scheme outperforms any other method or method combination tested, and does not rely on any prior information or trial and error procedure.",
        "published": "2023-02-23T07:51:00Z",
        "link": "http://arxiv.org/abs/2302.11835v3",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "econ.GN",
            "q-fin.EC",
            "J.4; I.6.3"
        ]
    },
    {
        "title": "Inequity aversion reduces travel time in the traffic light control   problem",
        "authors": [
            "Mersad Hassanjani",
            "Farinaz Alamiyan-Harandi",
            "Pouria Ramazi"
        ],
        "summary": "The traffic light control problem is to improve the traffic flow by coordinating between the traffic lights. Recently, a successful deep reinforcement learning model, CoLight, was developed to capture the influences of neighboring intersections by a graph attention network. We propose IACoLight that boosts up to 11.4% the performance of CoLight by incorporating the Inequity Aversion (IA) model that reshapes each agent's reward by adding or subtracting advantageous or disadvantageous reward inequities compared to other agents. Unlike in the other applications of IA, where both advantageous and disadvantageous inequities are punished by considering negative coefficients, we allowed them to be also rewarded and explored a range of both positive and negative coefficients. Our experiments demonstrated that making CoLight agents averse to inequities improved the vehicles' average travel time and rewarding rather than punishing advantageous inequities enhanced the results.",
        "published": "2023-02-23T14:26:27Z",
        "link": "http://arxiv.org/abs/2302.12053v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Single-Peaked Jump Schelling Games",
        "authors": [
            "Tobias Friedrich",
            "Pascal Lenzner",
            "Louise Molitor",
            "Lars Seifert"
        ],
        "summary": "Schelling games model the wide-spread phenomenon of residential segregation in metropolitan areas from a game-theoretic point of view. In these games agents of different types each strategically select a node on a given graph that models the residential area to maximize their individual utility. The latter solely depends on the types of the agents on neighboring nodes and it has been a standard assumption to consider utility functions that are monotone in the number of same-type neighbors. This simplifying assumption has recently been challenged since sociological poll results suggest that real-world agents actually favor diverse neighborhoods.   We contribute to the recent endeavor of investigating residential segregation models with realistic agent behavior by studying Jump Schelling Games with agents having a single-peaked utility function. In such games, there are empty nodes in the graph and agents can strategically jump to such nodes to improve their utility. We investigate the existence of equilibria and show that they exist under specific conditions. Contrasting this, we prove that even on simple topologies like paths or rings such stable states are not guaranteed to exist. Regarding the game dynamics, we show that improving response cycles exist independently of the position of the peak in the utility function. Moreover, we show high almost tight bounds on the Price of Anarchy and the Price of Stability with respect to the recently proposed degree of integration, which counts the number of agents with a diverse neighborhood and which serves as a proxy for measuring the segregation strength. Last but not least, we show that computing a beneficial state with high integration is NP-complete and, as a novel conceptual contribution, we also show that it is NP-hard to decide if an equilibrium state can be found via improving response dynamics starting from a given initial state.",
        "published": "2023-02-23T15:46:26Z",
        "link": "http://arxiv.org/abs/2302.12107v1",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.MA",
            "math.DS"
        ]
    },
    {
        "title": "Decentralized core-periphery structure in social networks accelerates   cultural innovation in agent-based model",
        "authors": [
            "Jesse Milzman",
            "Cody Moser"
        ],
        "summary": "Previous investigations into creative and innovation networks have suggested that innovations often occurs at the boundary between the network's core and periphery. In this work, we investigate the effect of global core-periphery network structure on the speed and quality of cultural innovation. Drawing on differing notions of core-periphery structure from [arXiv:1808.07801] and [doi:10.1016/S0378-8733(99)00019-2], we distinguish decentralized core-periphery, centralized core-periphery, and affinity network structure. We generate networks of these three classes from stochastic block models (SBMs), and use them to run an agent-based model (ABM) of collective cultural innovation, in which agents can only directly interact with their network neighbors. In order to discover the highest-scoring innovation, agents must discover and combine the highest innovations from two completely parallel technology trees. We find that decentralized core-periphery networks outperform the others by finding the final crossover innovation more quickly on average. We hypothesize that decentralized core-periphery network structure accelerates collective problem-solving by shielding peripheral nodes from the local optima known by the core community at any given time. We then build upon the \"Two Truths\" hypothesis regarding community structure in spectral graph embeddings, first articulated in [arXiv:1808.07801], which suggests that the adjacency spectral embedding (ASE) captures core-periphery structure, while the Laplacian spectral embedding (LSE) captures affinity. We find that, for core-periphery networks, ASE-based resampling best recreates networks with similar performance on the innovation SBM, compared to LSE-based resampling. Since the Two Truths hypothesis suggests that ASE captures core-periphery structure, this result further supports our hypothesis.",
        "published": "2023-02-23T16:00:51Z",
        "link": "http://arxiv.org/abs/2302.12121v1",
        "categories": [
            "cs.MA",
            "q-bio.PE",
            "05C90 (Primary) 91D10, 91D30 (Secondary)",
            "J.4; G.2.2; G.2.3"
        ]
    },
    {
        "title": "Communication and Control in Collaborative UAVs: Recent Advances and   Future Trends",
        "authors": [
            "Shumaila Javaid",
            "Nasir Saeed",
            "Zakria Qadir",
            "Hamza Fahim",
            "Bin He",
            "Houbing Song",
            "Muhammad Bilal"
        ],
        "summary": "The recent progress in unmanned aerial vehicles (UAV) technology has significantly advanced UAV-based applications for military, civil, and commercial domains. Nevertheless, the challenges of establishing high-speed communication links, flexible control strategies, and developing efficient collaborative decision-making algorithms for a swarm of UAVs limit their autonomy, robustness, and reliability. Thus, a growing focus has been witnessed on collaborative communication to allow a swarm of UAVs to coordinate and communicate autonomously for the cooperative completion of tasks in a short time with improved efficiency and reliability. This work presents a comprehensive review of collaborative communication in a multi-UAV system. We thoroughly discuss the characteristics of intelligent UAVs and their communication and control requirements for autonomous collaboration and coordination. Moreover, we review various UAV collaboration tasks, summarize the applications of UAV swarm networks for dense urban environments and present the use case scenarios to highlight the current developments of UAV-based applications in various domains. Finally, we identify several exciting future research direction that needs attention for advancing the research in collaborative UAVs.",
        "published": "2023-02-23T17:17:20Z",
        "link": "http://arxiv.org/abs/2302.12175v1",
        "categories": [
            "eess.SP",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "AC2C: Adaptively Controlled Two-Hop Communication for Multi-Agent   Reinforcement Learning",
        "authors": [
            "Xuefeng Wang",
            "Xinran Li",
            "Jiawei Shao",
            "Jun Zhang"
        ],
        "summary": "Learning communication strategies in cooperative multi-agent reinforcement learning (MARL) has recently attracted intensive attention. Early studies typically assumed a fully-connected communication topology among agents, which induces high communication costs and may not be feasible. Some recent works have developed adaptive communication strategies to reduce communication overhead, but these methods cannot effectively obtain valuable information from agents that are beyond the communication range. In this paper, we consider a realistic communication model where each agent has a limited communication range, and the communication topology dynamically changes. To facilitate effective agent communication, we propose a novel communication protocol called Adaptively Controlled Two-Hop Communication (AC2C). After an initial local communication round, AC2C employs an adaptive two-hop communication strategy to enable long-range information exchange among agents to boost performance, which is implemented by a communication controller. This controller determines whether each agent should ask for two-hop messages and thus helps to reduce the communication overhead during distributed execution. We evaluate AC2C on three cooperative multi-agent tasks, and the experimental results show that it outperforms relevant baselines with lower communication costs.",
        "published": "2023-02-24T09:00:34Z",
        "link": "http://arxiv.org/abs/2302.12515v2",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Permutation-Invariant Set Autoencoders with Fixed-Size Embeddings for   Multi-Agent Learning",
        "authors": [
            "Ryan Kortvelesy",
            "Steven Morad",
            "Amanda Prorok"
        ],
        "summary": "The problem of permutation-invariant learning over set representations is particularly relevant in the field of multi-agent systems -- a few potential applications include unsupervised training of aggregation functions in graph neural networks (GNNs), neural cellular automata on graphs, and prediction of scenes with multiple objects. Yet existing approaches to set encoding and decoding tasks present a host of issues, including non-permutation-invariance, fixed-length outputs, reliance on iterative methods, non-deterministic outputs, computationally expensive loss functions, and poor reconstruction accuracy. In this paper we introduce a Permutation-Invariant Set Autoencoder (PISA), which tackles these problems and produces encodings with significantly lower reconstruction error than existing baselines. PISA also provides other desirable properties, including a similarity-preserving latent space, and the ability to insert or remove elements from the encoding. After evaluating PISA against baseline methods, we demonstrate its usefulness in a multi-agent application. Using PISA as a subcomponent, we introduce a novel GNN architecture which serves as a generalised communication scheme, allowing agents to use communication to gain full observability of a system.",
        "published": "2023-02-24T18:59:13Z",
        "link": "http://arxiv.org/abs/2302.12826v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Multi-Agent Reinforcement Learning with Common Policy for Antenna Tilt   Optimization",
        "authors": [
            "Adriano Mendo",
            "Jose Outes-Carnero",
            "Yak Ng-Molina",
            "Juan Ramiro-Moreno"
        ],
        "summary": "This paper presents a method for optimizing wireless networks by adjusting cell parameters that affect both the performance of the cell being optimized and the surrounding cells. The method uses multiple reinforcement learning agents that share a common policy and take into account information from neighboring cells to determine the state and reward. In order to avoid impairing network performance during the initial stages of learning, agents are pre-trained in an earlier phase of offline learning. During this phase, an initial policy is obtained using feedback from a static network simulator and considering a wide variety of scenarios. Finally, agents can intelligently tune the cell parameters of a test network by suggesting small incremental changes, slowly guiding the network toward an optimal configuration. The agents propose optimal changes using the experience gained with the simulator in the pre-training phase, but they can also continue to learn from current network readings after each change. The results show how the proposed approach significantly improves the performance gains already provided by expert system-based methods when applied to remote antenna tilt optimization. The significant gains of this approach have truly been observed when compared with a similar method in which the state and reward do not incorporate information from neighboring cells.",
        "published": "2023-02-24T21:19:26Z",
        "link": "http://arxiv.org/abs/2302.12899v2",
        "categories": [
            "eess.SY",
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Hierarchical Needs-driven Agent Learning Systems: From Deep   Reinforcement Learning To Diverse Strategies",
        "authors": [
            "Qin Yang"
        ],
        "summary": "The needs describe the necessities for a system to survive and evolve, which arouses an agent to action toward a goal, giving purpose and direction to behavior. Based on Maslow hierarchy of needs, an agent needs to satisfy a certain amount of needs at the current level as a condition to arise at the next stage -- upgrade and evolution. Especially, Deep Reinforcement Learning (DAL) can help AI agents (like robots) organize and optimize their behaviors and strategies to develop diverse Strategies based on their current state and needs (expected utilities or rewards). This paper introduces the new hierarchical needs-driven Learning systems based on DAL and investigates the implementation in the single-robot with a novel approach termed Bayesian Soft Actor-Critic (BSAC). Then, we extend this topic to the Multi-Agent systems (MAS), discussing the potential research fields and directions.",
        "published": "2023-02-25T18:18:10Z",
        "link": "http://arxiv.org/abs/2302.13132v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "cs.RO",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Strategic (Timed) Computation Tree Logic",
        "authors": [
            "Jaime Arias",
            "Wojciech Jamroga",
            "Wojciech Penczek",
            "Laure Petrucci",
            "Teofil Sidoruk"
        ],
        "summary": "We define extensions of CTL and TCTL with strategic operators, called Strategic CTL (SCTL) and Strategic TCTL (STCTL), respectively. For each of the above logics we give a synchronous and asynchronous semantics, i.e., STCTL is interpreted over networks of extended Timed Automata (TA) that either make synchronous moves or synchronise via joint actions. We consider several semantics regarding information: imperfect (i) and perfect (I), and recall: imperfect (r) and perfect (R). We prove that SCTL is more expressive than ATL for all semantics, and this holds for the timed versions as well. Moreover, the model checking problem for SCTL[ir] is of the same complexity as for ATL[ir], the model checking problem for STCTL[ir] is of the same complexity as for TCTL, while for STCTL[iR] it is undecidable as for ATL[iR]. The above results suggest to use SCTL[ir] and STCTL[ir] in practical applications. Therefore, we use the tool IMITATOR to support model checking of STCTL[ir].",
        "published": "2023-02-26T21:00:38Z",
        "link": "http://arxiv.org/abs/2302.13405v2",
        "categories": [
            "cs.LO",
            "cs.MA"
        ]
    },
    {
        "title": "Estimation of continuous environments by robot swarms: Correlated   networks and decision-making",
        "authors": [
            "Mohsen Raoufi",
            "Pawel Romanczuk",
            "Heiko Hamann"
        ],
        "summary": "Collective decision-making is an essential capability of large-scale multi-robot systems to establish autonomy on the swarm level. A large portion of literature on collective decision-making in swarm robotics focuses on discrete decisions selecting from a limited number of options. Here we assign a decentralized robot system with the task of exploring an unbounded environment, finding consensus on the mean of a measurable environmental feature, and aggregating at areas where that value is measured (e.g., a contour line). A unique quality of this task is a causal loop between the robots' dynamic network topology and their decision-making. For example, the network's mean node degree influences time to convergence while the currently agreed-on mean value influences the swarm's aggregation location, hence, also the network structure as well as the precision error. We propose a control algorithm and study it in real-world robot swarm experiments in different environments. We show that our approach is effective and achieves higher precision than a control experiment. We anticipate applications, for example, in containing pollution with surface vehicles.",
        "published": "2023-02-27T09:57:15Z",
        "link": "http://arxiv.org/abs/2302.13629v2",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "On the Connection between Greedy Algorithms and Imperfect Rationality",
        "authors": [
            "Diodato Ferraioli",
            "Carmine Ventre"
        ],
        "summary": "The design of algorithms or protocols that are able to align the goals of the planner with the selfish interests of the agents involved in these protocols is of paramount importance in almost every decentralized setting (such as, computer networks, markets, etc.) as shown by the rich literature in Mechanism Design. Recently, huge interest has been devoted to the design of mechanisms for imperfectly rational agents, i.e., mechanisms for which agents are able to easily grasp that there is no action different from following the protocol that would satisfy their interests better. This work has culminated in the definition of Obviously Strategyproof (OSP) Mechanisms, that have been shown to capture the incentives of agents without contingent reasoning skills.   Without an understanding of the algorithmic nature of OSP mechanisms, it is hard to assess how well these mechanisms can satisfy the goals of the planner. For the case of binary allocation problems and agents whose private type is a single number, recent work has shown that a generalization of greedy completely characterizes OSP. In this work, we strengthen the connection between greedy and OSP by providing a characterization of OSP mechanisms for all optimization problems involving these single-parameter agents. Specifically, we prove that OSP mechanisms must essentially work as follows: they either greedily look for agents with ``better'' types and allocate them larger outcomes; or reverse greedily look for agents with ``worse'' types and allocate them smaller outcomes; or, finally, split the domain of agents in ``good'' and ``bad'' types, and subsequently proceed in a reverse greedy fashion for the former and greedily for the latter. We further demonstrate how to use this characterization to give bounds on the approximation guarantee of OSP mechanisms for the well known scheduling related machines problem.",
        "published": "2023-02-27T10:18:18Z",
        "link": "http://arxiv.org/abs/2302.13641v1",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "PACCART: Reinforcing Trust in Multiuser Privacy Agreement Systems",
        "authors": [
            "Daan Di Scala",
            "Pınar Yolum"
        ],
        "summary": "Collaborative systems, such as Online Social Networks and the Internet of Things, enable users to share privacy sensitive content. Content in these systems is often co-owned by multiple users with different privacy expectations, leading to possible multiuser privacy conflicts. In order to resolve these conflicts, various agreement mechanisms have been designed and agents that could participate in such mechanisms have been proposed. However, research shows that users hesitate to use software tools for managing their privacy. To remedy this, we argue that users should be supported by trustworthy agents that adhere to the following criteria: (i) concealment of privacy preferences, such that only necessary information is shared with others, (ii) equity of treatment, such that different kinds of users are supported equally, (iii) collaboration of users, such that a group of users can support each other in agreement and (iv) explainability of actions, such that users know why certain information about them was shared to reach a decision. Accordingly, this paper proposes PACCART, an open-source agent that satisfies these criteria. Our experiments over simulations and user study indicate that PACCART increases user trust significantly.",
        "published": "2023-02-27T10:36:45Z",
        "link": "http://arxiv.org/abs/2302.13650v1",
        "categories": [
            "cs.CR",
            "cs.MA"
        ]
    },
    {
        "title": "Equilibrium Bandits: Learning Optimal Equilibria of Unknown Dynamics",
        "authors": [
            "Siddharth Chandak",
            "Ilai Bistritz",
            "Nicholas Bambos"
        ],
        "summary": "Consider a decision-maker that can pick one out of $K$ actions to control an unknown system, for $T$ turns. The actions are interpreted as different configurations or policies. Holding the same action fixed, the system asymptotically converges to a unique equilibrium, as a function of this action. The dynamics of the system are unknown to the decision-maker, which can only observe a noisy reward at the end of every turn. The decision-maker wants to maximize its accumulated reward over the $T$ turns. Learning what equilibria are better results in higher rewards, but waiting for the system to converge to equilibrium costs valuable time. Existing bandit algorithms, either stochastic or adversarial, achieve linear (trivial) regret for this problem. We present a novel algorithm, termed Upper Equilibrium Concentration Bound (UECB), that knows to switch an action quickly if it is not worth it to wait until the equilibrium is reached. This is enabled by employing convergence bounds to determine how far the system is from equilibrium. We prove that UECB achieves a regret of $\\mathcal{O}(\\log(T)+\\tau_c\\log(\\tau_c)+\\tau_c\\log\\log(T))$ for this equilibrium bandit problem where $\\tau_c$ is the worst case approximate convergence time to equilibrium. We then show that both epidemic control and game control are special cases of equilibrium bandits, where $\\tau_c\\log \\tau_c$ typically dominates the regret. We then test UECB numerically for both of these applications.",
        "published": "2023-02-27T10:47:15Z",
        "link": "http://arxiv.org/abs/2302.13653v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Neuroadaptive Distributed Event-triggered Control of Networked Uncertain   Pure-feedback Systems with Polluted Feedback",
        "authors": [
            "Libei Sun",
            "Zhirong Zhang",
            "Xinjian Huang",
            "Xiucai Huang"
        ],
        "summary": "This paper investigates the distributed event-triggered control problem for a class of uncertain pure-feedback nonlinear multi-agent systems (MASs) with polluted feedback. Under the setting of event-triggered control, substantial challenges exist in both control design and stability analysis for systems in more general non-affine pure-feedback forms wherein all state variables are not directly and continuously available or even polluted due to sensor failures, and thus far very limited results are available in literature. In this work, a nominal control strategy under regular state feedback is firstly developed by combining neural network (NN) approximating with dynamic filtering technique, and then a NN-based distributed event-triggered control strategy is proposed by resorting to a novel replacement policy, making the non-differentiability issue arising from event-triggering setting completely circumvented. Besides, the sensor ineffectiveness is accommodated automatically without using fault detection and diagnosis unit or controller reconfiguration. It is shown that all the internal signals are semi-globally uniformly ultimately bounded (SGUUB) with the aid of several vital lemmas, while the outputs of all the subsystems reaching a consensus without infinitely fast execution. Finally, the efficiency of the developed algorithm are verified via numerical simulation.",
        "published": "2023-02-27T13:34:31Z",
        "link": "http://arxiv.org/abs/2302.13755v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Safe Multi-agent Learning via Trapping Regions",
        "authors": [
            "Aleksander Czechowski",
            "Frans A. Oliehoek"
        ],
        "summary": "One of the main challenges of multi-agent learning lies in establishing convergence of the algorithms, as, in general, a collection of individual, self-serving agents is not guaranteed to converge with their joint policy, when learning concurrently. This is in stark contrast to most single-agent environments, and sets a prohibitive barrier for deployment in practical applications, as it induces uncertainty in long term behavior of the system. In this work, we apply the concept of trapping regions, known from qualitative theory of dynamical systems, to create safety sets in the joint strategy space for decentralized learning. We propose a binary partitioning algorithm for verification that candidate sets form trapping regions in systems with known learning dynamics, and a heuristic sampling algorithm for scenarios where learning dynamics are not known. We demonstrate the applications to a regularized version of Dirac Generative Adversarial Network, a four-intersection traffic control scenario run in a state of the art open-source microscopic traffic simulator SUMO, and a mathematical model of economic competition.",
        "published": "2023-02-27T14:47:52Z",
        "link": "http://arxiv.org/abs/2302.13844v2",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Implicit Poisoning Attacks in Two-Agent Reinforcement Learning:   Adversarial Policies for Training-Time Attacks",
        "authors": [
            "Mohammad Mohammadi",
            "Jonathan Nöther",
            "Debmalya Mandal",
            "Adish Singla",
            "Goran Radanovic"
        ],
        "summary": "In targeted poisoning attacks, an attacker manipulates an agent-environment interaction to force the agent into adopting a policy of interest, called target policy. Prior work has primarily focused on attacks that modify standard MDP primitives, such as rewards or transitions. In this paper, we study targeted poisoning attacks in a two-agent setting where an attacker implicitly poisons the effective environment of one of the agents by modifying the policy of its peer. We develop an optimization framework for designing optimal attacks, where the cost of the attack measures how much the solution deviates from the assumed default policy of the peer agent. We further study the computational properties of this optimization framework. Focusing on a tabular setting, we show that in contrast to poisoning attacks based on MDP primitives (transitions and (unbounded) rewards), which are always feasible, it is NP-hard to determine the feasibility of implicit poisoning attacks. We provide characterization results that establish sufficient conditions for the feasibility of the attack problem, as well as an upper and a lower bound on the optimal cost of the attack. We propose two algorithmic approaches for finding an optimal adversarial policy: a model-based approach with tabular policies and a model-free approach with parametric/neural policies. We showcase the efficacy of the proposed algorithms through experiments.",
        "published": "2023-02-27T14:52:15Z",
        "link": "http://arxiv.org/abs/2302.13851v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.CR",
            "cs.MA"
        ]
    },
    {
        "title": "Combating Uncertainties in Wind and Distributed PV Energy Sources Using   Integrated Reinforcement Learning and Time-Series Forecasting",
        "authors": [
            "Arman Ghasemi",
            "Amin Shojaeighadikolaei",
            "Morteza Hashemi"
        ],
        "summary": "Renewable energy sources, such as wind and solar power, are increasingly being integrated into smart grid systems. However, when compared to traditional energy resources, the unpredictability of renewable energy generation poses significant challenges for both electricity providers and utility companies. Furthermore, the large-scale integration of distributed energy resources (such as PV systems) creates new challenges for energy management in microgrids. To tackle these issues, we propose a novel framework with two objectives: (i) combating uncertainty of renewable energy in smart grid by leveraging time-series forecasting with Long-Short Term Memory (LSTM) solutions, and (ii) establishing distributed and dynamic decision-making framework with multi-agent reinforcement learning using Deep Deterministic Policy Gradient (DDPG) algorithm. The proposed framework considers both objectives concurrently to fully integrate them, while considering both wholesale and retail markets, thereby enabling efficient energy management in the presence of uncertain and distributed renewable energy sources. Through extensive numerical simulations, we demonstrate that the proposed solution significantly improves the profit of load serving entities (LSE) by providing a more accurate wind generation forecast. Furthermore, our results demonstrate that households with PV and battery installations can increase their profits by using intelligent battery charge/discharge actions determined by the DDPG agents.",
        "published": "2023-02-27T19:12:50Z",
        "link": "http://arxiv.org/abs/2302.14094v1",
        "categories": [
            "eess.SY",
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "On the Role of Emergent Communication for Social Learning in Multi-Agent   Reinforcement Learning",
        "authors": [
            "Seth Karten",
            "Siva Kailas",
            "Huao Li",
            "Katia Sycara"
        ],
        "summary": "Explicit communication among humans is key to coordinating and learning. Social learning, which uses cues from experts, can greatly benefit from the usage of explicit communication to align heterogeneous policies, reduce sample complexity, and solve partially observable tasks. Emergent communication, a type of explicit communication, studies the creation of an artificial language to encode a high task-utility message directly from data. However, in most cases, emergent communication sends insufficiently compressed messages with little or null information, which also may not be understandable to a third-party listener. This paper proposes an unsupervised method based on the information bottleneck to capture both referential complexity and task-specific utility to adequately explore sparse social communication scenarios in multi-agent reinforcement learning (MARL). We show that our model is able to i) develop a natural-language-inspired lexicon of messages that is independently composed of a set of emergent concepts, which span the observations and intents with minimal bits, ii) develop communication to align the action policies of heterogeneous agents with dissimilar feature models, and iii) learn a communication policy from watching an expert's action policy, which we term `social shadowing'.",
        "published": "2023-02-28T03:23:27Z",
        "link": "http://arxiv.org/abs/2302.14276v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "DrMaMP: Distributed Real-time Multi-agent Mission Planning in Cluttered   Environment",
        "authors": [
            "Zehui Lu",
            "Tianyu Zhou",
            "Shaoshuai Mou"
        ],
        "summary": "Solving a collision-aware multi-agent mission planning (task allocation and path finding) problem is challenging due to the requirement of real-time computational performance, scalability, and capability of handling static/dynamic obstacles and tasks in a cluttered environment. This paper proposes a distributed real-time (on the order of millisecond) algorithm DrMaMP, which partitions the entire unassigned task set into subsets via approximation and decomposes the original problem into several single-agent mission planning problems. This paper presents experiments with dynamic obstacles and tasks and conducts optimality and scalability comparisons with an existing method, where DrMaMP outperforms the existing method in both indices. Finally, this paper analyzes the computational burden of DrMaMP which is consistent with the observations from comparisons, and presents the optimality gap in small-size problems.",
        "published": "2023-02-28T03:49:35Z",
        "link": "http://arxiv.org/abs/2302.14289v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Scenarios and branch points to future machine intelligence",
        "authors": [
            "Koichi Takahashi"
        ],
        "summary": "We discuss scenarios and branch points to four major possible consequences regarding future machine intelligence; 1) the singleton scenario where the first and only super-intelligence acquires a decisive strategic advantage, 2) the multipolar scenario where the singleton scenario is not technically denied but political or other factors in human society or multi-agent interactions between the intelligent agents prevent a single agent from gaining a decisive strategic advantage, 3) the ecosystem scenario where the singleton scenario is denied and many autonomous intelligent agents operate in such a way that they are interdependent and virtually unstoppable, and 4) the upper-bound scenario where cognitive capabilities that can be achieved by human-designed intelligent agents or their descendants are inherently limited to the sub-human level. We identify six major constraints that can form branch points to these scenarios; (1) constraints on autonomy, (2) constraints on the ability to improve self-structure, (3) constraints related to thermodynamic efficiency, (4) constraints on updating physical infrastructure, (5) constraints on relative advantage, and (6) constraints on locality.",
        "published": "2023-02-28T10:36:41Z",
        "link": "http://arxiv.org/abs/2302.14478v3",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.CY"
        ]
    },
    {
        "title": "Ask and You Shall be Served: Representing and Solving Multi-agent   Optimization Problems with Service Requesters and Providers",
        "authors": [
            "Maya Lavie",
            "Tehila Caspi",
            "Omer Lev",
            "Roei Zivan"
        ],
        "summary": "In scenarios with numerous emergencies that arise and require the assistance of various rescue units (e.g., medical, fire, \\& police forces), the rescue units would ideally be allocated quickly and distributedly while aiming to minimize casualties. This is one of many examples of distributed settings with service providers (the rescue units) and service requesters (the emergencies) which we term \\textit{service oriented settings}. Allocating the service providers in a distributed manner while aiming for a global optimum is hard to model, let alone achieve, using the existing Distributed Constraint Optimization Problem (DCOP) framework. Hence, the need for a novel approach and corresponding algorithms.   We present the Service Oriented Multi-Agent Optimization Problem (SOMAOP), a new framework that overcomes the shortcomings of DCOP in service oriented settings. We evaluate the framework using various algorithms based on auctions and matching algorithms (e.g., Gale Shapely). We empirically show that algorithms based on repeated auctions converge to a high quality solution very fast, while repeated matching problems converge slower, but produce higher quality solutions. We demonstrate the advantages of our approach over standard incomplete DCOP algorithms and a greedy centralized algorithm.",
        "published": "2023-02-28T11:53:33Z",
        "link": "http://arxiv.org/abs/2302.14507v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "IQ-Flow: Mechanism Design for Inducing Cooperative Behavior to   Self-Interested Agents in Sequential Social Dilemmas",
        "authors": [
            "Bengisu Guresti",
            "Abdullah Vanlioglu",
            "Nazim Kemal Ure"
        ],
        "summary": "Achieving and maintaining cooperation between agents to accomplish a common objective is one of the central goals of Multi-Agent Reinforcement Learning (MARL). Nevertheless in many real-world scenarios, separately trained and specialized agents are deployed into a shared environment, or the environment requires multiple objectives to be achieved by different coexisting parties. These variations among specialties and objectives are likely to cause mixed motives that eventually result in a social dilemma where all the parties are at a loss. In order to resolve this issue, we propose the Incentive Q-Flow (IQ-Flow) algorithm, which modifies the system's reward setup with an incentive regulator agent such that the cooperative policy also corresponds to the self-interested policy for the agents. Unlike the existing methods that learn to incentivize self-interested agents, IQ-Flow does not make any assumptions about agents' policies or learning algorithms, which enables the generalization of the developed framework to a wider array of applications. IQ-Flow performs an offline evaluation of the optimality of the learned policies using the data provided by other agents to determine cooperative and self-interested policies. Next, IQ-Flow uses meta-gradient learning to estimate how policy evaluation changes according to given incentives and modifies the incentive such that the greedy policy for cooperative objective and self-interested objective yield the same actions. We present the operational characteristics of IQ-Flow in Iterated Matrix Games. We demonstrate that IQ-Flow outperforms the state-of-the-art incentive design algorithm in Escape Room and 2-Player Cleanup environments. We further demonstrate that the pretrained IQ-Flow mechanism significantly outperforms the performance of the shared reward setup in the 2-Player Cleanup environment.",
        "published": "2023-02-28T14:44:29Z",
        "link": "http://arxiv.org/abs/2302.14604v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.GT",
            "cs.LG"
        ]
    },
    {
        "title": "Playing to Learn, or to Keep Secret: Alternating-Time Logic Meets   Information Theory",
        "authors": [
            "Masoud Tabatabaei",
            "Wojciech Jamroga"
        ],
        "summary": "Many important properties of multi-agent systems refer to the participants' ability to achieve a given goal, or to prevent the system from an undesirable event. Among intelligent agents, the goals are often of epistemic nature, i.e., concern the ability to obtain knowledge about an important fact \\phi. Such properties can be e.g. expressed in ATLK, that is, alternating-time temporal logic ATL extended with epistemic operators. In many realistic scenarios, however, players do not need to fully learn the truth value of \\phi. They may be almost as well off by gaining some knowledge; in other words, by reducing their uncertainty about \\phi. Similarly, in order to keep \\phi secret, it is often insufficient that the intruder never fully learns its truth value. Instead, one needs to require that his uncertainty about \\phi never drops below a reasonable threshold.   With this motivation in mind, we introduce the logic ATLH, extending ATL with quantitative modalities based on the Hartley measure of uncertainty. The new logic enables to specify agents' abilities w.r.t. the uncertainty of a given player about a given set of statements. It turns out that ATLH has the same expressivity and model checking complexity as ATLK. However, the new logic is exponentially more succinct than ATLK, which is the main technical result of this paper.",
        "published": "2023-02-28T20:09:50Z",
        "link": "http://arxiv.org/abs/2303.00067v3",
        "categories": [
            "cs.MA",
            "cs.LO"
        ]
    },
    {
        "title": "Neural Stochastic Agent-Based Limit Order Book Simulation: A Hybrid   Methodology",
        "authors": [
            "Zijian Shi",
            "John Cartlidge"
        ],
        "summary": "Modern financial exchanges use an electronic limit order book (LOB) to store bid and ask orders for a specific financial asset. As the most fine-grained information depicting the demand and supply of an asset, LOB data is essential in understanding market dynamics. Therefore, realistic LOB simulations offer a valuable methodology for explaining empirical properties of markets. Mainstream simulation models include agent-based models (ABMs) and stochastic models (SMs). However, ABMs tend not to be grounded on real historical data, while SMs tend not to enable dynamic agent-interaction. To overcome these limitations, we propose a novel hybrid LOB simulation paradigm characterised by: (1) representing the aggregation of market events' logic by a neural stochastic background trader that is pre-trained on historical LOB data through a neural point process model; and (2) embedding the background trader in a multi-agent simulation with other trading agents. We instantiate this hybrid NS-ABM model using the ABIDES platform. We first run the background trader in isolation and show that the simulated LOB can recreate a comprehensive list of stylised facts that demonstrate realistic market behaviour. We then introduce a population of `trend' and `value' trading agents, which interact with the background trader. We show that the stylised facts remain and we demonstrate order flow impact and financial herding behaviours that are in accordance with empirical observations of real markets.",
        "published": "2023-02-28T20:53:39Z",
        "link": "http://arxiv.org/abs/2303.00080v1",
        "categories": [
            "q-fin.TR",
            "cs.CE",
            "cs.MA",
            "cs.NE",
            "q-fin.CP"
        ]
    },
    {
        "title": "Automated Task-Time Interventions to Improve Teamwork using Imitation   Learning",
        "authors": [
            "Sangwon Seo",
            "Bing Han",
            "Vaibhav Unhelkar"
        ],
        "summary": "Effective human-human and human-autonomy teamwork is critical but often challenging to perfect. The challenge is particularly relevant in time-critical domains, such as healthcare and disaster response, where the time pressures can make coordination increasingly difficult to achieve and the consequences of imperfect coordination can be severe. To improve teamwork in these and other domains, we present TIC: an automated intervention approach for improving coordination between team members. Using BTIL, a multi-agent imitation learning algorithm, our approach first learns a generative model of team behavior from past task execution data. Next, it utilizes the learned generative model and team's task objective (shared reward) to algorithmically generate execution-time interventions. We evaluate our approach in synthetic multi-agent teaming scenarios, where team members make decentralized decisions without full observability of the environment. The experiments demonstrate that the automated interventions can successfully improve team performance and shed light on the design of autonomous agents for improving teamwork.",
        "published": "2023-03-01T11:09:06Z",
        "link": "http://arxiv.org/abs/2303.00413v2",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Mitigating Skewed Bidding for Conference Paper Assignment",
        "authors": [
            "Inbal Rozencweig",
            "Reshef Meir",
            "Nick Mattei",
            "Ofra Amir"
        ],
        "summary": "The explosion of conference paper submissions in AI and related fields, has underscored the need to improve many aspects of the peer review process, especially the matching of papers and reviewers. Recent work argues that the key to improve this matching is to modify aspects of the \\emph{bidding phase} itself, to ensure that the set of bids over papers is balanced, and in particular to avoid \\emph{orphan papers}, i.e., those papers that receive no bids. In an attempt to understand and mitigate this problem, we have developed a flexible bidding platform to test adaptations to the bidding process. Using this platform, we performed a field experiment during the bidding phase of a medium-size international workshop that compared two bidding methods. We further examined via controlled experiments on Amazon Mechanical Turk various factors that affect bidding, in particular the order in which papers are presented \\cite{cabanac2013capitalizing,fiez2020super}; and information on paper demand \\cite{meir2021market}. Our results suggest that several simple adaptations, that can be added to any existing platform, may significantly reduce the skew in bids, thereby improving the allocation for both reviewers and conference organizers.",
        "published": "2023-03-01T11:49:24Z",
        "link": "http://arxiv.org/abs/2303.00435v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "A Variational Approach to Mutual Information-Based Coordination for   Multi-Agent Reinforcement Learning",
        "authors": [
            "Woojun Kim",
            "Whiyoung Jung",
            "Myungsik Cho",
            "Youngchul Sung"
        ],
        "summary": "In this paper, we propose a new mutual information framework for multi-agent reinforcement learning to enable multiple agents to learn coordinated behaviors by regularizing the accumulated return with the simultaneous mutual information between multi-agent actions. By introducing a latent variable to induce nonzero mutual information between multi-agent actions and applying a variational bound, we derive a tractable lower bound on the considered MMI-regularized objective function. The derived tractable objective can be interpreted as maximum entropy reinforcement learning combined with uncertainty reduction of other agents actions. Applying policy iteration to maximize the derived lower bound, we propose a practical algorithm named variational maximum mutual information multi-agent actor-critic, which follows centralized learning with decentralized execution. We evaluated VM3-AC for several games requiring coordination, and numerical results show that VM3-AC outperforms other MARL algorithms in multi-agent tasks requiring high-quality coordination.",
        "published": "2023-03-01T12:21:30Z",
        "link": "http://arxiv.org/abs/2303.00451v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Fast and Interpretable Dynamics for Fisher Markets via Block-Coordinate   Updates",
        "authors": [
            "Tianlong Nan",
            "Yuan Gao",
            "Christian Kroer"
        ],
        "summary": "We consider the problem of large-scale Fisher market equilibrium computation through scalable first-order optimization methods. It is well-known that market equilibria can be captured using structured convex programs such as the Eisenberg-Gale and Shmyrev convex programs. Highly performant deterministic full-gradient first-order methods have been developed for these programs. In this paper, we develop new block-coordinate first-order methods for computing Fisher market equilibria, and show that these methods have interpretations as t\\^atonnement-style or proportional response-style dynamics where either buyers or items show up one at a time. We reformulate these convex programs and solve them using proximal block coordinate descent methods, a class of methods that update only a small number of coordinates of the decision variable in each iteration. Leveraging recent advances in the convergence analysis of these methods and structures of the equilibrium-capturing convex programs, we establish fast convergence rates of these methods.",
        "published": "2023-03-01T13:41:51Z",
        "link": "http://arxiv.org/abs/2303.00506v1",
        "categories": [
            "cs.GT",
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "The (Computational) Social Choice Take on Indivisible Participatory   Budgeting",
        "authors": [
            "Simon Rey",
            "Jan Maly"
        ],
        "summary": "In this survey, we review the literature investigating participatory budgeting as a social choice problem. Participatory Budgeting (PB) is a democratic process in which citizens are asked to vote on how to allocate a given amount of public money to a set of projects. From a social choice perspective, it corresponds then to the problem of aggregating opinions about which projects should be funded, into a budget allocation satisfying a budget constraint. This problem has received substantial attention in recent years and the literature is growing at a fast pace. In this survey, we present the most important research directions from the literature, each time presenting a large set of representative results. We only focus on the indivisible case, that is, PB problems in which projects can either be fully funded or not at all.   The aim of the survey is to present a comprehensive overview of the state of the research on PB. We aim at providing both a general overview of the main research questions that are being investigated, and formal and unified definitions of the most important technical concepts from the literature.",
        "published": "2023-03-01T16:22:26Z",
        "link": "http://arxiv.org/abs/2303.00621v8",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Coordination of Multiple Robots along Given Paths with Bounded Junction   Complexity",
        "authors": [
            "Mikkel Abrahamsen",
            "Tzvika Geft",
            "Dan Halperin",
            "Barak Ugav"
        ],
        "summary": "We study a fundamental NP-hard motion coordination problem for multi-robot/multi-agent systems: We are given a graph $G$ and set of agents, where each agent has a given directed path in $G$. Each agent is initially located on the first vertex of its path. At each time step an agent can move to the next vertex on its path, provided that the vertex is not occupied by another agent. The goal is to find a sequence of such moves along the given paths so that each reaches its target, or to report that no such sequence exists. The problem models guidepath-based transport systems, which is a pertinent abstraction for traffic in a variety of contemporary applications, ranging from train networks or Automated Guided Vehicles (AGVs) in factories, through computer game animations, to qubit transport in quantum computing. It also arises as a sub-problem in the more general multi-robot motion-planning problem.   We provide a fine-grained tractability analysis of the problem by considering new assumptions and identifying minimal values of key parameters for which the problem remains NP-hard. Our analysis identifies a critical parameter called vertex multiplicity (VM), defined as the maximum number of paths passing through the same vertex. We show that a prevalent variant of the problem, which is equivalent to Sequential Resource Allocation (concerning deadlock prevention for concurrent processes), is NP-hard even when VM is 3. On the positive side, for VM $\\le$ 2 we give an efficient algorithm that iteratively resolves cycles of blocking relations among agents. We also present a variant that is NP-hard when the VM is 2 even when $G$ is a 2D grid and each path lies in a single grid row or column. By studying highly distilled yet NP-hard variants, we deepen the understanding of what makes the problem intractable and thereby guide the search for efficient solutions under practical assumptions.",
        "published": "2023-03-01T18:58:06Z",
        "link": "http://arxiv.org/abs/2303.00745v1",
        "categories": [
            "cs.RO",
            "cs.CG",
            "cs.DS",
            "cs.MA"
        ]
    },
    {
        "title": "Fairness for Workers Who Pull the Arms: An Index Based Policy for   Allocation of Restless Bandit Tasks",
        "authors": [
            "Arpita Biswas",
            "Jackson A. Killian",
            "Paula Rodriguez Diaz",
            "Susobhan Ghosh",
            "Milind Tambe"
        ],
        "summary": "Motivated by applications such as machine repair, project monitoring, and anti-poaching patrol scheduling, we study intervention planning of stochastic processes under resource constraints. This planning problem has previously been modeled as restless multi-armed bandits (RMAB), where each arm is an intervention-dependent Markov Decision Process. However, the existing literature assumes all intervention resources belong to a single uniform pool, limiting their applicability to real-world settings where interventions are carried out by a set of workers, each with their own costs, budgets, and intervention effects. In this work, we consider a novel RMAB setting, called multi-worker restless bandits (MWRMAB) with heterogeneous workers. The goal is to plan an intervention schedule that maximizes the expected reward while satisfying budget constraints on each worker as well as fairness in terms of the load assigned to each worker. Our contributions are two-fold: (1) we provide a multi-worker extension of the Whittle index to tackle heterogeneous costs and per-worker budget and (2) we develop an index-based scheduling policy to achieve fairness. Further, we evaluate our method on various cost structures and show that our method significantly outperforms other baselines in terms of fairness without sacrificing much in reward accumulated.",
        "published": "2023-03-01T19:59:42Z",
        "link": "http://arxiv.org/abs/2303.00799v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Parameter Sharing with Network Pruning for Scalable Multi-Agent Deep   Reinforcement Learning",
        "authors": [
            "Woojun Kim",
            "Youngchul Sung"
        ],
        "summary": "Handling the problem of scalability is one of the essential issues for multi-agent reinforcement learning (MARL) algorithms to be applied to real-world problems typically involving massively many agents. For this, parameter sharing across multiple agents has widely been used since it reduces the training time by decreasing the number of parameters and increasing the sample efficiency. However, using the same parameters across agents limits the representational capacity of the joint policy and consequently, the performance can be degraded in multi-agent tasks that require different behaviors for different agents. In this paper, we propose a simple method that adopts structured pruning for a deep neural network to increase the representational capacity of the joint policy without introducing additional parameters. We evaluate the proposed method on several benchmark tasks, and numerical results show that the proposed method significantly outperforms other parameter-sharing methods.",
        "published": "2023-03-02T02:17:14Z",
        "link": "http://arxiv.org/abs/2303.00912v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Beacon-based Distributed Structure Formation in Multi-agent Systems",
        "authors": [
            "Tamzidul Mina",
            "Wonse Jo",
            "Shyam S. Kannan",
            "Byung-Cheol Min"
        ],
        "summary": "Autonomous shape and structure formation is an important problem in the domain of large-scale multi-agent systems. In this paper, we propose a 3D structure representation method and a distributed structure formation strategy where settled agents guide free moving agents to a prescribed location to settle in the structure. Agents at the structure formation frontier looking for neighbors to settle act as beacons, generating a surface gradient throughout the formed structure propagated by settled agents. Free-moving agents follow the surface gradient along the formed structure surface to the formation frontier, where they eventually reach the closest beacon and settle to continue the structure formation following a local bidding process. Agent behavior is governed by a finite state machine implementation, along with potential field-based motion control laws. We also discuss appropriate rules for recovering from stagnation points. Simulation experiments are presented to show planar and 3D structure formations with continuous and discontinuous boundary/surfaces, which validate the proposed strategy, followed by a scalability analysis.",
        "published": "2023-03-02T02:40:29Z",
        "link": "http://arxiv.org/abs/2303.00920v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "GHQ: Grouped Hybrid Q Learning for Heterogeneous Cooperative Multi-agent   Reinforcement Learning",
        "authors": [
            "Xiaoyang Yu",
            "Youfang Lin",
            "Xiangsen Wang",
            "Sheng Han",
            "Kai Lv"
        ],
        "summary": "Previous deep multi-agent reinforcement learning (MARL) algorithms have achieved impressive results, typically in homogeneous scenarios. However, heterogeneous scenarios are also very common and usually harder to solve. In this paper, we mainly discuss cooperative heterogeneous MARL problems in Starcraft Multi-Agent Challenges (SMAC) environment. We firstly define and describe the heterogeneous problems in SMAC. In order to comprehensively reveal and study the problem, we make new maps added to the original SMAC maps. We find that baseline algorithms fail to perform well in those heterogeneous maps. To address this issue, we propose the Grouped Individual-Global-Max Consistency (GIGM) and a novel MARL algorithm, Grouped Hybrid Q Learning (GHQ). GHQ separates agents into several groups and keeps individual parameters for each group, along with a novel hybrid structure for factorization. To enhance coordination between groups, we maximize the Inter-group Mutual Information (IGMI) between groups' trajectories. Experiments on original and new heterogeneous maps show the fabulous performance of GHQ compared to other state-of-the-art algorithms.",
        "published": "2023-03-02T08:45:49Z",
        "link": "http://arxiv.org/abs/2303.01070v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Expert-Free Online Transfer Learning in Multi-Agent Reinforcement   Learning",
        "authors": [
            "Alberto Castagna",
            "Ivana Dusparic"
        ],
        "summary": "Transfer learning in Reinforcement Learning (RL) has been widely studied to overcome training issues of Deep-RL, i.e., exploration cost, data availability and convergence time, by introducing a way to enhance training phase with external knowledge. Generally, knowledge is transferred from expert-agents to novices. While this fixes the issue for a novice agent, a good understanding of the task on expert agent is required for such transfer to be effective. As an alternative, in this paper we propose Expert-Free Online Transfer Learning (EF-OnTL), an algorithm that enables expert-free real-time dynamic transfer learning in multi-agent system. No dedicated expert exists, and transfer source agent and knowledge to be transferred are dynamically selected at each transfer step based on agents' performance and uncertainty. To improve uncertainty estimation, we also propose State Action Reward Next-State Random Network Distillation (sars-RND), an extension of RND that estimates uncertainty from RL agent-environment interaction. We demonstrate EF-OnTL effectiveness against a no-transfer scenario and advice-based baselines, with and without expert agents, in three benchmark tasks: Cart-Pole, a grid-based Multi-Team Predator-Prey (mt-pp) and Half Field Offense (HFO). Our results show that EF-OnTL achieve overall comparable performance when compared against advice-based baselines while not requiring any external input nor threshold tuning. EF-OnTL outperforms no-transfer with an improvement related to the complexity of the task addressed.",
        "published": "2023-03-02T11:21:03Z",
        "link": "http://arxiv.org/abs/2303.01170v3",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Population-based Evaluation in Repeated Rock-Paper-Scissors as a   Benchmark for Multiagent Reinforcement Learning",
        "authors": [
            "Marc Lanctot",
            "John Schultz",
            "Neil Burch",
            "Max Olan Smith",
            "Daniel Hennes",
            "Thomas Anthony",
            "Julien Perolat"
        ],
        "summary": "Progress in fields of machine learning and adversarial planning has benefited significantly from benchmark domains, from checkers and the classic UCI data sets to Go and Diplomacy. In sequential decision-making, agent evaluation has largely been restricted to few interactions against experts, with the aim to reach some desired level of performance (e.g. beating a human professional player). We propose a benchmark for multiagent learning based on repeated play of the simple game Rock, Paper, Scissors along with a population of forty-three tournament entries, some of which are intentionally sub-optimal. We describe metrics to measure the quality of agents based both on average returns and exploitability. We then show that several RL, online learning, and language model approaches can learn good counter-strategies and generalize well, but ultimately lose to the top-performing bots, creating an opportunity for research in multiagent learning.",
        "published": "2023-03-02T15:06:52Z",
        "link": "http://arxiv.org/abs/2303.03196v2",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Conflict-Based Model Predictive Control for Scalable Multi-Robot Motion   Planning",
        "authors": [
            "Ardalan Tajbakhsh",
            "Lorenz T. Biegler",
            "Aaron M. Johnson"
        ],
        "summary": "This paper presents a scalable multi-robot motion planning algorithm called Conflict-Based Model Predictive Control (CB-MPC). Inspired by Conflict-Based Search (CBS), the planner leverages a similar high-level conflict tree to efficiently resolve robot-robot conflicts in the continuous space, while reasoning about each agent's kinematic and dynamic constraints and actuation limits using MPC as the low-level planner. We show that tracking high-level multi-robot plans with a vanilla MPC controller is insufficient, and results in unexpected collisions in tight navigation scenarios. Compared to other variations of multi-robot MPC like joint, prioritized, and distributed, we demonstrate that CB-MPC improves the executability and success rate, allows for closer robot-robot interactions, and reduces the computational cost significantly without compromising the solution quality across a variety of environments. Furthermore, we show that CB-MPC combined with a high-level path planner can effectively substitute computationally expensive full-horizon multi-robot kinodynamic planners.",
        "published": "2023-03-02T22:48:06Z",
        "link": "http://arxiv.org/abs/2303.01619v3",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Toward Risk-based Optimistic Exploration for Cooperative Multi-Agent   Reinforcement Learning",
        "authors": [
            "Jihwan Oh",
            "Joonkee Kim",
            "Minchan Jeong",
            "Se-Young Yun"
        ],
        "summary": "The multi-agent setting is intricate and unpredictable since the behaviors of multiple agents influence one another. To address this environmental uncertainty, distributional reinforcement learning algorithms that incorporate uncertainty via distributional output have been integrated with multi-agent reinforcement learning (MARL) methods, achieving state-of-the-art performance. However, distributional MARL algorithms still rely on the traditional $\\epsilon$-greedy, which does not take cooperative strategy into account. In this paper, we present a risk-based exploration that leads to collaboratively optimistic behavior by shifting the sampling region of distribution. Initially, we take expectations from the upper quantiles of state-action values for exploration, which are optimistic actions, and gradually shift the sampling region of quantiles to the full distribution for exploitation. By ensuring that each agent is exposed to the same level of risk, we can force them to take cooperatively optimistic actions. Our method shows remarkable performance in multi-agent settings requiring cooperative exploration based on quantile regression appropriately controlling the level of risk.",
        "published": "2023-03-03T08:17:57Z",
        "link": "http://arxiv.org/abs/2303.01768v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Multi-Agent Adversarial Training Using Diffusion Learning",
        "authors": [
            "Ying Cao",
            "Elsa Rizk",
            "Stefan Vlaski",
            "Ali H. Sayed"
        ],
        "summary": "This work focuses on adversarial learning over graphs. We propose a general adversarial training framework for multi-agent systems using diffusion learning. We analyze the convergence properties of the proposed scheme for convex optimization problems, and illustrate its enhanced robustness to adversarial attacks.",
        "published": "2023-03-03T14:05:59Z",
        "link": "http://arxiv.org/abs/2303.01936v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Proximal Exploration of Venus Volcanism with Teams of Autonomous   Buoyancy-Controlled Balloons",
        "authors": [
            "Federico Rossi",
            "Maira Saboia",
            "Siddharth Krishnamoorthy",
            "Joshua Vander Hook"
        ],
        "summary": "Altitude-controlled balloons hold great promise for performing high-priority scientific investigations of Venus's atmosphere and geological phenomena, including tectonic and volcanic activity, as demonstrated by a number of recent Earth-based experiments. In this paper, we explore a concept of operations where multiple autonomous, altitude-controlled balloons monitor explosive volcanic activity on Venus through infrasound microbarometers, and autonomously navigate the uncertain wind field to perform follow-on observations of detected events of interest. We propose a novel autonomous guidance technique for altitude-controlled balloons in Venus's uncertain wind field, and show the approach can result in an increase of up to 63% in the number of close-up observations of volcanic events compared to passive drifters, and a 16% increase compared to ground-in-the-loop guidance. The results are robust to uncertainty in the wind field, and hold across large changes in the frequency of explosive volcanic events, sensitivity of the microbarometer detectors, and numbers of aerial platforms.",
        "published": "2023-03-03T17:43:40Z",
        "link": "http://arxiv.org/abs/2303.02104v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Agent-based Collaborative Random Search for Hyper-parameter Tuning and   Global Function Optimization",
        "authors": [
            "Ahmad Esmaeili",
            "Zahra Ghorrati",
            "Eric T. Matson"
        ],
        "summary": "Hyper-parameter optimization is one of the most tedious yet crucial steps in training machine learning models. There are numerous methods for this vital model-building stage, ranging from domain-specific manual tuning guidelines suggested by the oracles to the utilization of general-purpose black-box optimization techniques. This paper proposes an agent-based collaborative technique for finding near-optimal values for any arbitrary set of hyper-parameters (or decision variables) in a machine learning model (or general function optimization problem). The developed method forms a hierarchical agent-based architecture for the distribution of the searching operations at different dimensions and employs a cooperative searching procedure based on an adaptive width-based random sampling technique to locate the optima. The behavior of the presented model, specifically against the changes in its design parameters, is investigated in both machine learning and global function optimization applications, and its performance is compared with that of two randomized tuning strategies that are commonly used in practice. According to the empirical results, the proposed model outperformed the compared methods in the experimented classification, regression, and multi-dimensional function optimization tasks, notably in a higher number of dimensions and in the presence of limited on-device computational resources.",
        "published": "2023-03-03T21:10:17Z",
        "link": "http://arxiv.org/abs/2303.03394v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Graph-based Simultaneous Coverage and Exploration Planning for Fast   Multi-robot Search",
        "authors": [
            "Indraneel Patil",
            "Rachel Zheng",
            "Charvi Gupta",
            "Jaekyung Song",
            "Narendar Sriram",
            "Katia Sycara"
        ],
        "summary": "In large unknown environments, search operations can be much more time-efficient with the use of multi-robot fleets by parallelizing efforts. This means robots must efficiently perform collaborative mapping (exploration) while simultaneously searching an area for victims (coverage). Previous simultaneous mapping and planning techniques treat these problems as separate and do not take advantage of the possibility for a unified approach. We propose a novel exploration-coverage planner which bridges the mapping and search domains by growing sets of random trees rooted upon a pose graph produced through mapping to generate points of interest, or tasks. Furthermore, it is important for the robots to first prioritize high information tasks to locate the greatest number of victims in minimum time by balancing coverage and exploration, which current methods do not address. Towards this goal, we also present a new multi-robot task allocator that formulates a notion of a hierarchical information heuristic for time-critical collaborative search. Our results show that our algorithm produces 20% more coverage efficiency, defined as average covered area per second, compared to the existing state-of-the-art. Our algorithms and the rest of our multi-robot search stack is based in ROS and made open source",
        "published": "2023-03-03T23:19:19Z",
        "link": "http://arxiv.org/abs/2303.02259v1",
        "categories": [
            "cs.RO",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Adaptive Predictive Portfolio Management Agent",
        "authors": [
            "Anton Kolonin",
            "Alexey Glushchenko",
            "Arseniy Fokin",
            "Marcello Mari",
            "Mario Casiraghi",
            "Mukul Vishwas"
        ],
        "summary": "The paper presents an advanced version of an adaptive market-making agent capable of performing experiential learning, exploiting a \"try and fail\" approach relying on a swarm of subordinate agents executed in a virtual environment to determine optimal strategies. The problem is treated as a \"Narrow AGI\" problem with the scope of goals and environments bound to financial markets, specifically crypto-markets. Such an agent is called an \"adaptive multi-strategy agent\" as it executes multiple strategies virtually and selects only a few for real execution. The presented version of the agent is extended to solve portfolio optimization and re-balancing across multiple assets so the problem of active portfolio management is being addressed. Also, an attempt is made to apply an experiential learning approach executed in the virtual environment of multi-agent simulation and backtesting based on historical market data, so the agent can learn mappings between specific market conditions and optimal strategies corresponding to these conditions. Additionally, the agent is equipped with the capacity to predict price movements based on social media data, which increases its financial performance.",
        "published": "2023-03-04T06:54:15Z",
        "link": "http://arxiv.org/abs/2303.02342v1",
        "categories": [
            "cs.CE",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "D-HAL: Distributed Hierarchical Adversarial Learning for Multi-Agent   Interaction in Autonomous Intersection Management",
        "authors": [
            "Guanzhou Li",
            "Jianping Wu",
            "Yujing He"
        ],
        "summary": "Autonomous Intersection Management (AIM) provides a signal-free intersection scheduling paradigm for Connected Autonomous Vehicles (CAVs). Distributed learning method has emerged as an attractive branch of AIM research. Compared with centralized AIM, distributed AIM can be deployed to CAVs at a lower cost, and compared with rule-based and optimization-based method, learning-based method can treat various complicated real-time intersection scenarios more flexibly. Deep reinforcement learning (DRL) is the mainstream approach in distributed learning to address AIM problems. However, the large-scale simultaneous interactive decision of multiple agents and the rapid changes of environment caused by interactions pose challenges for DRL, making its reward curve oscillating and hard to converge, and ultimately leading to a compromise in safety and computing efficiency. For this, we propose a non-RL learning framework, called Distributed Hierarchical Adversarial Learning (D-HAL). The framework includes an actor network that generates the actions of each CAV at each step. The immediate discriminator evaluates the interaction performance of the actor network at the current step, while the final discriminator makes the final evaluation of the overall trajectory from a series of interactions. In this framework, the long-term outcome of the behavior no longer motivates the actor network in terms of discounted rewards, but rather through a designed adversarial loss function with discriminative labels. The proposed model is evaluated at a four-way-six-lane intersection, and outperforms several state-of-the-art methods on ensuring safety and reducing travel time.",
        "published": "2023-03-05T10:10:56Z",
        "link": "http://arxiv.org/abs/2303.02630v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "New Era in Cultural Heritage Preservation: Cooperative Aerial Autonomy",
        "authors": [
            "Pavel Petracek",
            "Vit Kratky",
            "Tomas Baca",
            "Matej Petrlik",
            "Martin Saska"
        ],
        "summary": "Digital documentation of large interiors of historical buildings is an exhausting task since most of the areas of interest are beyond typical human reach. We advocate the use of autonomous teams of multi-rotor Unmanned Aerial Vehicles (UAVs) to speed up the documentation process by several orders of magnitude while allowing for a repeatable, accurate, and condition-independent solution capable of precise collision-free operation at great heights. The proposed multi-robot approach allows for performing tasks requiring dynamic scene illumination in large-scale real-world scenarios, a process previously applicable only in small-scale laboratory-like conditions. Extensive experimental analyses range from single-UAV imaging to specialized lighting techniques requiring accurate coordination of multiple UAVs. The system's robustness is demonstrated in more than two hundred autonomous flights in fifteen historical monuments requiring superior safety while lacking access to external localization. This unique experimental campaign, cooperated with restorers and conservators, brought numerous lessons transferable to other safety-critical robotic missions in documentation and inspection tasks.",
        "published": "2023-03-06T08:33:04Z",
        "link": "http://arxiv.org/abs/2303.02962v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Large-Scale Exploration of Cave Environments by Unmanned Aerial Vehicles",
        "authors": [
            "Pavel Petracek",
            "Vit Kratky",
            "Matej Petrlik",
            "Tomas Baca",
            "Radim Kratochvil",
            "Martin Saska"
        ],
        "summary": "This paper presents a self-contained system for the robust utilization of aerial robots in the autonomous exploration of cave environments to help human explorers, first responders, and speleologists. The proposed system is generally applicable to an arbitrary exploration task within an unknown and unstructured subterranean environment and interconnects crucial robotic subsystems to provide full autonomy of the robots. Such subsystems primarily include mapping, path and trajectory planning, localization, control, and decision making. Due to the diversity, complexity, and structural uncertainty of natural cave environments, the proposed system allows for the possible use of any arbitrary exploration strategy for a single robot, as well as for a cooperating team. A multi-robot cooperation strategy that maximizes the limited flight time of each aerial robot is proposed for exploration and search & rescue scenarios where the homing of all deployed robots back to an initial location is not required The entire system is validated in a comprehensive experimental analysis comprising of hours of flight time in a real-world cave environment, as well as by hundreds of hours within a state-of-the-art virtual testbed that was developed for the DARPA Subterranean Challenge robotic competition. Among others, experimental results include multiple real-world exploration flights traveling over 470 meters on a single battery in a demanding unknown cave environment.",
        "published": "2023-03-06T09:00:24Z",
        "link": "http://arxiv.org/abs/2303.02972v1",
        "categories": [
            "cs.RO",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Bio-Inspired Compact Swarms of Unmanned Aerial Vehicles without   Communication and External Localization",
        "authors": [
            "Pavel Petracek",
            "Viktor Walter",
            "Tomas Baca",
            "Martin Saska"
        ],
        "summary": "This article presents a unique framework for deploying decentralized and infrastructure-independent swarms of homogeneous aerial vehicles in the real world without explicit communication. This is a requirement in swarm research, which anticipates that global knowledge and communication will not scale well with the number of robots. The system architecture proposed in this article employs the UVDAR technique to directly perceive the local neighborhood for direct mutual localization of swarm members. The technique allows for decentralization and high scalability of swarm systems, such as can be observed in fish schools, bird flocks, or cattle herds. The bio-inspired swarming model that has been developed is suited for real-world deployment of large particle groups in outdoor and indoor environments with obstacles. The collective behavior of the model emerges from a set of local rules based on direct observation of the neighborhood using onboard sensors only. The model is scalable, requires only local perception of agents and the environment, and requires no communication among the agents. Apart from simulated scenarios, the performance and usability of the entire framework is analyzed in several real-world experiments with a fully-decentralized swarm of UAVs deployed in outdoor conditions. To the best of our knowledge, these experiments are the first deployment of decentralized bio-inspired compact swarms of UAVs without the use of a communication network or shared absolute localization. The entire system is available as open-source at https://github.com/ctu-mrs.",
        "published": "2023-03-06T09:33:21Z",
        "link": "http://arxiv.org/abs/2303.02989v1",
        "categories": [
            "cs.RO",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Parallel Optimization with Hard Safety Constraints for Cooperative   Planning of Connected Autonomous Vehicles",
        "authors": [
            "Zhenmin Huang",
            "Haichao Liu",
            "Shaojie Shen",
            "Jun Ma"
        ],
        "summary": "The development of connected autonomous vehicles (CAVs) facilitates the enhancement of traffic efficiency in complicated scenarios. In unsignalized roundabout scenarios, difficulties remain unsolved in developing an effective and efficient coordination strategy for CAVs. In this paper, we formulate the cooperative autonomous driving problem of CAVs in the roundabout scenario as a constrained optimal control problem, and propose a computationally-efficient parallel optimization framework to generate strategies for CAVs such that the travel efficiency is improved with hard safety guarantees. All constraints involved in the roundabout scenario are addressed appropriately with convex approximation, such that the convexity property of the reformulated optimization problem is exhibited. Then, a parallel optimization algorithm is presented to solve the reformulated optimization problem, where an embodied iterative nearest neighbor search strategy to determine the optimal passing sequence in the roundabout scenario. It is noteworthy that the travel efficiency in the roundabout scenario is enhanced and the computation burden is considerably alleviated with the innovation development. We also examine the proposed method in CARLA simulator and perform thorough comparisons with a rule-based baseline and the commonly used IPOPT optimization solver to demonstrate the effectiveness and efficiency of the proposed approach.",
        "published": "2023-03-06T13:05:00Z",
        "link": "http://arxiv.org/abs/2303.03090v2",
        "categories": [
            "cs.RO",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Both eyes open: Vigilant Incentives help Regulatory Markets improve AI   Safety",
        "authors": [
            "Paolo Bova",
            "Alessandro Di Stefano",
            "The Anh Han"
        ],
        "summary": "In the context of rapid discoveries by leaders in AI, governments must consider how to design regulation that matches the increasing pace of new AI capabilities. Regulatory Markets for AI is a proposal designed with adaptability in mind. It involves governments setting outcome-based targets for AI companies to achieve, which they can show by purchasing services from a market of private regulators. We use an evolutionary game theory model to explore the role governments can play in building a Regulatory Market for AI systems that deters reckless behaviour. We warn that it is alarmingly easy to stumble on incentives which would prevent Regulatory Markets from achieving this goal. These 'Bounty Incentives' only reward private regulators for catching unsafe behaviour. We argue that AI companies will likely learn to tailor their behaviour to how much effort regulators invest, discouraging regulators from innovating. Instead, we recommend that governments always reward regulators, except when they find that those regulators failed to detect unsafe behaviour that they should have. These 'Vigilant Incentives' could encourage private regulators to find innovative ways to evaluate cutting-edge AI systems.",
        "published": "2023-03-06T14:42:05Z",
        "link": "http://arxiv.org/abs/2303.03174v1",
        "categories": [
            "cs.AI",
            "cs.CY",
            "cs.GT",
            "cs.MA",
            "econ.GN",
            "q-fin.EC"
        ]
    },
    {
        "title": "Impact of baggage collection behaviour on aircraft evacuation",
        "authors": [
            "Dan Hodgson",
            "Christian Tonge",
            "Martyn Amos"
        ],
        "summary": "Recent reports of emergency aircraft evacuations have highlighted an increasing tendency amongst evacuees to ignore clear safety warnings and to collect and carry personal items of baggage during egress. However, relatively little work has so far been done on quantifying the impact of such behaviour on the evacuation process. In this paper, we report the results of validated simulation experiments (using the Boeing 777 wide-body aircraft), which confirm that even a relatively low level of baggage collection can significantly delay evacuation. Our platform provides one possible framework for the investigation of processes and mitigation tactics to minimise the impact of baggage collection behaviour in future.",
        "published": "2023-03-06T16:33:33Z",
        "link": "http://arxiv.org/abs/2303.03264v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "MAESTRO: Open-Ended Environment Design for Multi-Agent Reinforcement   Learning",
        "authors": [
            "Mikayel Samvelyan",
            "Akbir Khan",
            "Michael Dennis",
            "Minqi Jiang",
            "Jack Parker-Holder",
            "Jakob Foerster",
            "Roberta Raileanu",
            "Tim Rocktäschel"
        ],
        "summary": "Open-ended learning methods that automatically generate a curriculum of increasingly challenging tasks serve as a promising avenue toward generally capable reinforcement learning agents. Existing methods adapt curricula independently over either environment parameters (in single-agent settings) or co-player policies (in multi-agent settings). However, the strengths and weaknesses of co-players can manifest themselves differently depending on environmental features. It is thus crucial to consider the dependency between the environment and co-player when shaping a curriculum in multi-agent domains. In this work, we use this insight and extend Unsupervised Environment Design (UED) to multi-agent environments. We then introduce Multi-Agent Environment Design Strategist for Open-Ended Learning (MAESTRO), the first multi-agent UED approach for two-player zero-sum settings. MAESTRO efficiently produces adversarial, joint curricula over both environments and co-players and attains minimax-regret guarantees at Nash equilibrium. Our experiments show that MAESTRO outperforms a number of strong baselines on competitive two-player games, spanning discrete and continuous control settings.",
        "published": "2023-03-06T18:57:41Z",
        "link": "http://arxiv.org/abs/2303.03376v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Rolling Horizon based Temporal Decomposition for the Offline Pickup and   Delivery Problem with Time Windows",
        "authors": [
            "Youngseo Kim",
            "Danushka Edirimanna",
            "Michael Wilbur",
            "Philip Pugliese",
            "Aron Laszka",
            "Abhishek Dubey",
            "Samitha Samaranayake"
        ],
        "summary": "The offline pickup and delivery problem with time windows (PDPTW) is a classical combinatorial optimization problem in the transportation community, which has proven to be very challenging computationally. Due to the complexity of the problem, practical problem instances can be solved only via heuristics, which trade-off solution quality for computational tractability. Among the various heuristics, a common strategy is problem decomposition, that is, the reduction of a large-scale problem into a collection of smaller sub-problems, with spatial and temporal decompositions being two natural approaches. While spatial decomposition has been successful in certain settings, effective temporal decomposition has been challenging due to the difficulty of stitching together the sub-problem solutions across the decomposition boundaries. In this work, we introduce a novel temporal decomposition scheme for solving a class of PDPTWs that have narrow time windows, for which it is able to provide both fast and high-quality solutions. We utilize techniques that have been popularized recently in the context of online dial-a-ride problems along with the general idea of rolling horizon optimization. To the best of our knowledge, this is the first attempt to solve offline PDPTWs using such an approach. To show the performance and scalability of our framework, we use the optimization of paratransit services as a motivating example. We compare our results with an offline heuristic algorithm using Google OR-Tools. In smaller problem instances, the baseline approach is as competitive as our framework. However, in larger problem instances, our framework is more scalable and can provide good solutions to problem instances of varying degrees of difficulty, while the baseline algorithm often fails to find a feasible solution within comparable compute times.",
        "published": "2023-03-06T20:07:05Z",
        "link": "http://arxiv.org/abs/2303.03475v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "SailFFish: A Lightweight, Parallelised Fast Poisson Solver Library",
        "authors": [
            "Joseph Saverin"
        ],
        "summary": "A solver for the Poisson equation for 1D, 2D and 3D regular grids is presented. The solver applies the convolution theorem in order to efficiently solve the Poisson equation in spectral space over a rectangular computational domain. Conversion to and from the spectral space is achieved through the use of discrete Fourier transforms, allowing for the application of highly optimised O(NlogN) algorithms. The data structure is configured to be modular such that the underlying interface for operations to, from and within the spectral space may be interchanged. For computationally demanding tasks, the library is optimised by making use of parallel processing architectures. A range of boundary conditions can be applied to the domain including periodic, Dirichlet, Neumann and fully unbounded. In the case of Neumann and Dirichlet boundary conditions, arbitrary inhomogeneous boundary conditions may be specified. The desired solution may be found either on regular (cell-boundary) or staggered (cell-centre) grid configurations. For problems with periodic, Dirichlet or Neumann boundary conditions either a pseudo-spectral or a second-order finite difference operator may be applied. For unbounded boundary conditions a range of Green's functions are available. In addition to this, a range of differential operators may be applied in the spectral space in order to treat different forms of the Poisson equation or to extract highly accurate gradients of the input fields. The underlying framework of the solver is first detailed, followed by a range of validations for each of the available boundary condition types. Finally, the performance of the library is investigated. The code is free and publicly available under a GNU v3.0 license.",
        "published": "2023-01-01T23:02:19Z",
        "link": "http://arxiv.org/abs/2301.01145v1",
        "categories": [
            "cs.MS",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Implementation of hyperbolic complex numbers in Julia language",
        "authors": [
            "Anna V. Korolkova",
            "Migran N. Gevorkyan",
            "Dmitry S. Kulyabov"
        ],
        "summary": "Background: Hyperbolic complex numbers are used in the description of hyperbolic spaces. One of the well-known examples of such spaces is the Minkowski space, which plays a leading role in the problems of the special theory of relativity and electrodynamics. However, such numbers are not very common in different programming languages. Purpose: Of interest is the implementation of hyperbolic complex in scientific programming languages, in particular, in the Julia language. Methods: The Julia language is based on the concept of multiple dispatch. This concept is an extension of the concept of polymorphism for object-oriented programming languages. To implement hyperbolic complex numbers, the multiple dispatching approach of the Julia language was used. Results: The result is a library that implements hyperbolic numbers. Conclusions: Based on the results of the study, we can conclude that the concept of multiple dispatching in scientific programming languages is convenient and natural.",
        "published": "2023-01-04T17:10:39Z",
        "link": "http://arxiv.org/abs/2301.01707v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "Smooth forecasting with the smooth package in R",
        "authors": [
            "Ivan Svetunkov"
        ],
        "summary": "There are many forecasting related packages in R with varied popularity, the most famous of all being \\texttt{forecast}, which implements several important forecasting approaches, such as ARIMA, ETS, TBATS and others. However, the main issue with the existing functionality is the lack of flexibility for research purposes, when it comes to modifying the implemented models. The R package \\texttt{smooth} introduces a new approach to univariate forecasting, implementing ETS and ARIMA models in Single Source of Error (SSOE) state space form and implementing an advanced functionality for experiments and time series analysis. It builds upon the SSOE model and extends it by including explanatory variables, multiple frequencies, and introducing advanced forecasting instruments. In this paper, we explain the philosophy behind the package and show how the main functions work.",
        "published": "2023-01-04T19:12:38Z",
        "link": "http://arxiv.org/abs/2301.01790v1",
        "categories": [
            "stat.ME",
            "cs.MS",
            "stat.AP",
            "G.3"
        ]
    },
    {
        "title": "An Automatic Method for Generating Symbolic Expressions of Zernike   Circular Polynomials",
        "authors": [
            "Hong-Yan Zhang",
            "Yu Zhou",
            "Fu-Yun Li"
        ],
        "summary": "Zernike circular polynomials (ZCP) play a significant role in optics engineering. The symbolic expressions for ZCP are valuable for theoretic analysis and engineering designs. However, there are still two problems which remain open: firstly, there is a lack of sufficient mathematical formulas of the ZCP for optics designers; secondly the formulas for inter-conversion of Noll's single index and Born-Wolf's double indices of ZCP are neither uniquely determinate nor satisfactory. An automatic method for generating symbolic expressions for ZCP is proposed based on five essential factors: the new theorems for converting the single/double indices of the ZCP, the robust and effective numeric algorithms for computing key parameters of ZCP, the symbolic algorithms for generating mathematical expressions of ZCP, and meta-programming \\& \\LaTeX{} programming for generating the table of ZCP. The theorems, method, algorithms and system architecture proposed are beneficial to both optics design process, optics software, computer-output typesetting in publishing industry as well as STEM education.",
        "published": "2023-01-05T00:33:55Z",
        "link": "http://arxiv.org/abs/2301.01859v3",
        "categories": [
            "cs.SC",
            "cs.MS"
        ]
    },
    {
        "title": "DarSIA: An open-source Python toolbox for two-scale image processing of   dynamics in porous media",
        "authors": [
            "Jan Martin Nordbotten",
            "Benyamine Benali",
            "Jakub Wiktor Both",
            "Bergit Brattekås",
            "Erlend Storvik",
            "Martin A. Fernø"
        ],
        "summary": "Understanding porous media flow is inherently a multi-scale challenge, where at the core lies the aggregation of pore-level processes to a continuum, or Darcy-scale, description. This challenge is directly mirrored in image processing, where grains and interfaces may be clearly visible, yet continuous parameters are desirable to measure. Classical image processing is poorly adapted to this setting, as most techniques do not explicitly utilize the fact that the image contains explicit physical processes.   Here, we adapt classical image processing concepts to what we define as physical images of porous materials and processes within them. This is realized through the development of a new open-source image analysis toolbox specifically adapted to time-series of images of porous materials.",
        "published": "2023-01-13T09:48:36Z",
        "link": "http://arxiv.org/abs/2301.05455v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "Multi-output multilevel best linear unbiased estimators via semidefinite   programming",
        "authors": [
            "M. Croci",
            "K. E. Willcox",
            "S. J. Wright"
        ],
        "summary": "Multifidelity forward uncertainty quantification (UQ) problems often involve multiple quantities of interest and heterogeneous models (e.g., different grids, equations, dimensions, physics, surrogate and reduced-order models). While computational efficiency is key in this context, multi-output strategies in multilevel/multifidelity methods are either sub-optimal or non-existent. In this paper we extend multilevel best linear unbiased estimators (MLBLUE) to multi-output forward UQ problems and we present new semidefinite programming formulations for their optimal setup. Not only do these formulations yield the optimal number of samples required, but also the optimal selection of low-fidelity models to use. While existing MLBLUE approaches are single-output only and require a non-trivial nonlinear optimization procedure, the new multi-output formulations can be solved reliably and efficiently. We demonstrate the efficacy of the new methods and formulations in practical UQ problems with model heterogeneity.",
        "published": "2023-01-19T00:21:01Z",
        "link": "http://arxiv.org/abs/2301.07831v2",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "stat.CO"
        ]
    },
    {
        "title": "Parallel two-stage reduction to Hessenberg-triangular form",
        "authors": [
            "Thijs Steel",
            "Raf Vandebril"
        ],
        "summary": "We present a two-stage algorithm for the parallel reduction of a pencil to Hessenberg-triangular form. Traditionally, two-stage Hessenberg-triangular reduction algorithms achieve high performance in the first stage, but struggle to achieve high performance in the second stage. Our algorithm extends techniques described by Karlsson et al. to also achieve high performance in the second stage. Experiments in a shared memory environment demonstrate that the algorithm can outperform state-of-the-art implementations.",
        "published": "2023-01-19T09:40:15Z",
        "link": "http://arxiv.org/abs/2301.07964v1",
        "categories": [
            "cs.DC",
            "cs.MS",
            "65F15, 65Y05"
        ]
    },
    {
        "title": "PyOED: An Extensible Suite for Data Assimilation and Model-Constrained   Optimal Design of Experiments",
        "authors": [
            "Abhijit Chowdhary",
            "Shady E. Ahmed",
            "Ahmed Attia"
        ],
        "summary": "This paper describes PyOED, a highly extensible scientific package that enables developing and testing model-constrained optimal experimental design (OED) for inverse problems. Specifically, PyOED aims to be a comprehensive Python toolkit for model-constrained OED. The package targets scientists and researchers interested in understanding the details of OED formulations and approaches. It is also meant to enable researchers to experiment with standard and innovative OED technologies with a wide range of test problems (e.g., simulation models). OED, inverse problems (e.g., Bayesian inversion), and data assimilation (DA) are closely related research fields, and their formulations overlap significantly. Thus, PyOED is continuously being expanded with a plethora of Bayesian inversion, DA, and OED methods as well as new scientific simulation models, observation error models, and observation operators. These pieces are added such that they can be permuted to enable testing OED methods in various settings of varying complexities. The PyOED core is completely written in Python and utilizes the inherent object-oriented capabilities; however, the current version of PyOED is meant to be extensible rather than scalable. Specifically, PyOED is developed to enable rapid development and benchmarking of OED methods with minimal coding effort and to maximize code reutilization. This paper provides a brief description of the PyOED layout and philosophy and provides a set of exemplary test cases and tutorials to demonstrate the potential of the package.",
        "published": "2023-01-19T21:51:58Z",
        "link": "http://arxiv.org/abs/2301.08336v3",
        "categories": [
            "cs.MS",
            "68Vxx"
        ]
    },
    {
        "title": "Ananke: A Python Package For Causal Inference Using Graphical Models",
        "authors": [
            "Jaron J. R. Lee",
            "Rohit Bhattacharya",
            "Razieh Nabi",
            "Ilya Shpitser"
        ],
        "summary": "We implement Ananke: an object-oriented Python package for causal inference with graphical models. At the top of our inheritance structure is an easily extensible Graph class that provides an interface to several broadly useful graph-based algorithms and methods for visualization. We use best practices of object-oriented programming to implement subclasses of the Graph superclass that correspond to types of causal graphs that are popular in the current literature. This includes directed acyclic graphs for modeling causally sufficient systems, acyclic directed mixed graphs for modeling unmeasured confounding, and chain graphs for modeling data dependence and interference.   Within these subclasses, we implement specialized algorithms for common statistical and causal modeling tasks, such as separation criteria for reading conditional independence, nonparametric identification, and parametric and semiparametric estimation of model parameters. Here, we present a broad overview of the package and example usage for a problem with unmeasured confounding. Up to date documentation is available at \\url{https://ananke.readthedocs.io/en/latest/}.",
        "published": "2023-01-27T00:46:38Z",
        "link": "http://arxiv.org/abs/2301.11477v1",
        "categories": [
            "stat.ME",
            "cs.MS"
        ]
    },
    {
        "title": "Exact hierarchical reductions of dynamical models via linear   transformations",
        "authors": [
            "Alexander Demin",
            "Elizaveta Demitraki",
            "Gleb Pogudin"
        ],
        "summary": "Dynamical models described by ordinary differential equations (ODEs) are a fundamental tool in the sciences and engineering. Exact reduction aims at producing a lower-dimensional model in which each macro-variable can be directly related to the original variables, and it is thus a natural step towards the model's formal analysis and mechanistic understanding. We present an algorithm which, given a polynomial ODE model, computes a longest possible chain of exact linear reductions of the model such that each reduction refines the previous one, thus giving a user control of the level of detail preserved by the reduction. This significantly generalizes over the existing approaches which compute only the reduction of the lowest dimension subject to an approach-specific constraint. The algorithm reduces finding exact linear reductions to a question about representations of finite-dimensional algebras. We provide an implementation of the algorithm, demonstrate its performance on a set of benchmarks, and illustrate the applicability via case studies. Our implementation is freely available at https://github.com/x3042/ExactODEReduction.jl",
        "published": "2023-01-27T11:08:55Z",
        "link": "http://arxiv.org/abs/2301.11653v2",
        "categories": [
            "eess.SY",
            "cs.MS",
            "cs.SC",
            "cs.SY",
            "math.DS",
            "34C20, 34-04, 16G10"
        ]
    },
    {
        "title": "GPU Accelerated Newton for Taylor Series Solutions of Polynomial   Homotopies in Multiple Double Precision",
        "authors": [
            "Jan Verschelde"
        ],
        "summary": "A polynomial homotopy is a family of polynomial systems, typically in one parameter $t$. Our problem is to compute power series expansions of the coordinates of the solutions in the parameter $t$, accurately, using multiple double arithmetic. One application of this problem is the location of the nearest singular solution in a polynomial homotopy, via the theorem of Fabry. Power series serve as input to construct Pad\\'{e} approximations.   Exploiting the massive parallelism of Graphics Processing Units capable of performing several trillions floating-point operations per second, the objective is to compensate for the cost overhead caused by arithmetic with power series in multiple double precision. The application of Newton's method for this problem requires the evaluation and differentiation of polynomials, followed by solving a blocked lower triangular linear system. Experimental results are obtained on NVIDIA GPUs, in particular the RTX 2080, RTX 4080, P100, V100, and A100.   Code generated by the CAMPARY software is used to obtain results in double double, quad double, and octo double precision. The programs in this study are self contained, available in a public github repository under the GPL-v3.0 License.",
        "published": "2023-01-30T04:41:28Z",
        "link": "http://arxiv.org/abs/2301.12659v2",
        "categories": [
            "math.NA",
            "cs.DC",
            "cs.MS",
            "cs.NA",
            "math.AG"
        ]
    },
    {
        "title": "Disciplined Saddle Programming",
        "authors": [
            "Philipp Schiele",
            "Eric Luxenberg",
            "Stephen Boyd"
        ],
        "summary": "We consider convex-concave saddle point problems, and more generally convex optimization problems we refer to as $\\textit{saddle problems}$, which include the partial supremum or infimum of convex-concave saddle functions. Saddle problems arise in a wide range of applications, including game theory, machine learning, and finance. It is well known that a saddle problem can be reduced to a single convex optimization problem by dualizing either the convex (min) or concave (max) objectives, reducing a min-max problem into a min-min (or max-max) problem. Carrying out this conversion by hand can be tedious and error prone. In this paper we introduce $\\textit{disciplined saddle programming}$ (DSP), a domain specific language (DSL) for specifying saddle problems, for which the dualizing trick can be automated. The language and methods are based on recent work by Juditsky and Nemirovski arXiv:2102.01002 [math.OC], who developed the idea of conic-representable saddle point programs, and showed how to carry out the required dualization automatically using conic duality. Juditsky and Nemirovski's conic representation of saddle problems extends Nesterov and Nemirovski's earlier development of conic representable convex problems; DSP can be thought of as extending disciplined convex programming (DCP) to saddle problems. Just as DCP makes it easy for users to formulate and solve complex convex problems, DSP allows users to easily formulate and solve saddle problems. Our method is implemented in an open-source package, also called DSP.",
        "published": "2023-01-31T05:48:22Z",
        "link": "http://arxiv.org/abs/2301.13427v2",
        "categories": [
            "math.OC",
            "cs.MS",
            "G.4"
        ]
    },
    {
        "title": "mlpack 4: a fast, header-only C++ machine learning library",
        "authors": [
            "Ryan R. Curtin",
            "Marcus Edel",
            "Omar Shrit",
            "Shubham Agrawal",
            "Suryoday Basak",
            "James J. Balamuta",
            "Ryan Birmingham",
            "Kartik Dutt",
            "Dirk Eddelbuettel",
            "Rishabh Garg",
            "Shikhar Jaiswal",
            "Aakash Kaushik",
            "Sangyeon Kim",
            "Anjishnu Mukherjee",
            "Nanubala Gnana Sai",
            "Nippun Sharma",
            "Yashwant Singh Parihar",
            "Roshan Swain",
            "Conrad Sanderson"
        ],
        "summary": "For over 15 years, the mlpack machine learning library has served as a \"swiss army knife\" for C++-based machine learning. Its efficient implementations of common and cutting-edge machine learning algorithms have been used in a wide variety of scientific and industrial applications. This paper overviews mlpack 4, a significant upgrade over its predecessor. The library has been significantly refactored and redesigned to facilitate an easier prototyping-to-deployment pipeline, including bindings to other languages (Python, Julia, R, Go, and the command line) that allow prototyping to be seamlessly performed in environments other than C++. mlpack is open-source software, distributed under the permissive 3-clause BSD license; it can be obtained at https://mlpack.org",
        "published": "2023-02-02T02:03:22Z",
        "link": "http://arxiv.org/abs/2302.00820v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "Trimpack: Unstructured Triangular Mesh Generation Library",
        "authors": [
            "Juan M. Tizón",
            "Nicolás Becerra",
            "Daniel Bercebal",
            "Claus P. Grabowsky"
        ],
        "summary": "Trimpack is a library of routines written in Fortran that allow to create unstructured triangular meshes in any domain and with an user-defined size distribution. The user must write a program that uses the elements of the library as if it were a mathematical tool. First, the domain must be defined, using point-defined boundaries, which the user provides. The library internally uses splines to mesh the boundaries with the node distribution function provided by the user. Several meshing methods are available, from simple Dalaunay mesh creation from a point cloud, an incremental Steiner-type algorithm that also generates Dalaunay meshes to an efficient advancing-front type algorithm. This report carries out a bibliographic review of the state of the art in mesh generation corresponding to the period in which Trimpack was written for the first time, which is a very fruitful period in the development of this type of algorithms. Next, MeshGen is described in detail, which is a program written in C ++ that exploits the possibilities of the Trimpack library for the generation of unstructured triangular meshes and that has a powerful graphical interface. Finally, it also explains in detail the content of the Trimpack library that is available under GNU Public license for anyone who wants to use or improve it.",
        "published": "2023-02-03T15:49:38Z",
        "link": "http://arxiv.org/abs/2302.02795v1",
        "categories": [
            "cs.MS",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Modern Methods for Signal Analysis: Empirical Mode Decomposition Theory   and Hybrid Operator-Based Methods Using B-Splines",
        "authors": [
            "Laslo Hunhold"
        ],
        "summary": "This thesis examines the empirical mode decomposition (EMD), a method for decomposing multicomponent signals, from a modern, both theoretical and practical, perspective. The motivation is to further formalize the concept and develop new methods to approach it numerically.   The theoretical part introduces a new formalization of the method as an optimization problem over ordered function vector spaces. Using the theory of 'convex-like' optimization and B-splines, Slater-regularity and thus strong duality of this optimization problem is shown. This results in a theoretical justification for the modern null-space-pursuit (NSP) operator-based signal-separation (OSS) EMD-approach for signal decomposition and spectral analysis.   The practical part considers the identified strengths and weaknesses in OSS and NSP and proposes a hybrid EMD method that utilizes these modern, but also classic, methods, implementing them in a toolbox called ETHOS (EMD Toolbox using Hybrid Operator-Based Methods and B-splines) and applying them to comparative examples. In the course of this part a new envelope estimation method called 'iterative slope envelope estimation' is proposed.",
        "published": "2023-02-07T09:16:54Z",
        "link": "http://arxiv.org/abs/2302.03334v1",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "94A12 (Primary) 65D05, 65D07, 65D10, 65D15 (Secondary)"
        ]
    },
    {
        "title": "A note on the standard diffusion curve of TAP analysis",
        "authors": [
            "Toby Isaac"
        ],
        "summary": "The standard diffusion curve used in models of TAP reactors, as it is usually defined, is numerically unstable for small values. We use a functional equation satisfied by the curve to define a numerically stable way of computing it for all values.",
        "published": "2023-02-07T22:05:26Z",
        "link": "http://arxiv.org/abs/2302.03772v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "General framework for re-assuring numerical reliability in parallel   Krylov solvers: A case of BiCGStab methods",
        "authors": [
            "Roman Iakymchuk",
            "Jose I. Aliaga"
        ],
        "summary": "Parallel implementations of Krylov subspace methods often help to accelerate the procedure of finding an approximate solution of a linear system. However, such parallelization coupled with asynchronous and out-of-order execution often enlarge the non-associativity impact in floating-point operations. These problems are even amplified when communication-hiding pipelined algorithms are used to improve the parallelization of Krylov subspace methods. Introducing reproducibility in the implementations avoids these problems by getting more robust and correct solutions. This paper proposes a general framework for deriving reproducible and accurate variants of Krylov subspace methods. The proposed algorithmic strategies are reinforced by programmability suggestions to assure deterministic and accurate executions. The framework is illustrated on the preconditioned BiCGStab method and its pipelined modification, which in fact is a distinctive method from the Krylov subspace family, for the solution of non-symmetric linear systems with message-passing. Finally, we verify the numerical behaviour of the two reproducible variants of BiCGStab on a set of matrices from the SuiteSparse Matrix Collection and a 3D Poisson's equation.",
        "published": "2023-02-08T16:39:01Z",
        "link": "http://arxiv.org/abs/2302.04180v1",
        "categories": [
            "cs.MS",
            "cs.DC"
        ]
    },
    {
        "title": "Unique Compact Representation of Magnetic Fields using Truncated Solid   Harmonic Expansions",
        "authors": [
            "Marija Boberg",
            "Tobias Knopp",
            "Martin Möddel"
        ],
        "summary": "Precise knowledge of magnetic fields is crucial in many medical imaging applications like magnetic resonance imaging or magnetic particle imaging (MPI) as they are the foundation of these imaging systems. For the investigation of the influence of field imperfections on imaging, a compact and unique representation of the magnetic fields using real solid spherical harmonics, which can be obtained by measuring a few points of the magnetic field only, is of great assistance. In this manuscript, we review real solid harmonic expansions as a general solution of Laplace's equation including an efficient calculation of their coefficients using spherical t-designs. We also provide a method to shift the reference point of an expansion by calculating the coefficients of the shifted expansion from the initial ones. These methods are used to obtain the magnetic fields of an MPI system. Here, the field-free-point of the spatial encoding field serves as unique expansion point. Lastly, we quantify the severity of the distortions of the static and dynamic fields in MPI by analyzing the expansion coefficients.",
        "published": "2023-02-15T11:09:19Z",
        "link": "http://arxiv.org/abs/2302.07591v1",
        "categories": [
            "physics.med-ph",
            "cs.MS",
            "33C55, 35Q60, 41A30, 41A55, 41A58, 41-04"
        ]
    },
    {
        "title": "GEMMFIP: Unifying GEMM in BLIS",
        "authors": [
            "RuQing G. Xu",
            "Field G. Van Zee",
            "Robert A. van de Geijn"
        ],
        "summary": "Matrix libraries often focus on achieving high performance for problems considered to be either \"small\" or \"large\", as these two scenarios tend to respond best to different optimization strategies. We propose a unified technique for implementing matrix operations like general matrix multiplication (GEMM) that can achieve high performance for both small and large problem sizes. The key is to fuse packing -- an operation that copies data to a contiguous layout in memory and which is critical for large matrix performance -- with the first computational \"pass\" over that data. This boosts performance across the problem size spectrum. As a result, tuning general-purpose libraries becomes simpler since it obviates the need to carefully express and parameterize logic that chooses between a \"small matrix\" strategy and a \"large matrix\" strategy. A prototype implementation of the technique built with the BLAS-like Library Instantiation Software (BLIS) framework is described and performance on a range of architectures is reported.",
        "published": "2023-02-16T16:52:49Z",
        "link": "http://arxiv.org/abs/2302.08417v2",
        "categories": [
            "cs.MS",
            "G.4"
        ]
    },
    {
        "title": "GPU Offloading in ExaHyPE Through C++ Standard Algorithms",
        "authors": [
            "Uzmar Gomez",
            "Gonzalo Brito Gadeschi",
            "Tobias Weinzierl"
        ],
        "summary": "The ISO C++17 standard introduces \\emph{parallel algorithms}, a parallel programming model promising portability across a wide variety of parallel hardware including multi-core CPUs, GPUs, and FPGAs. Since 2019, the NVIDIA HPC SDK compiler suite supports this programming model for multi-core CPUs and GPUs. ExaHyPE is a solver engine for hyperbolic partial differential equations for complex wave phenomena. It supports multiple numerical methods including Finite Volumes and ADER-DG, and employs adaptive mesh refinement with dynamic load balancing via space-filling curves as well as task-based parallelism and offloading to GPUs. This study ports ExaHyPE's tasks over blocks of Finite Volumes to the ISO C++ parallel algorithms programming model, and compares its performance and usability against an OpenMP implementation with offloading via OpenMP target directives. It shows that ISO C++ is a feasible programming model for non-trivial applications like our task-based AMR code. The realisation is bare of vendor-specific or non-C++ extensions. It however is slower than its OpenMP counterpart. \\vspace{-1cm}",
        "published": "2023-02-17T17:19:41Z",
        "link": "http://arxiv.org/abs/2302.09005v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "An Incremental Singular Value Decomposition Approach for Large-Scale   Spatially Parallel & Distributed but Temporally Serial Data -- Applied to   Technical Flows",
        "authors": [
            "Niklas Kühl",
            "Hendrik Fischer",
            "Michael Hinze",
            "Thomas Rung"
        ],
        "summary": "The paper presents a strategy to construct an incremental Singular Value Decomposition (SVD) for time-evolving, spatially 3D discrete data sets. A low memory access procedure for reducing and deploying the snapshot data is presented. Considered examples refer to Computational Fluid Dynamic (CFD) results extracted from unsteady flow simulations, which are computed spatially parallel using domain decomposition strategies. The framework addresses state of the art PDE-solvers dedicated to practical applications. Although the approach is applied to technical flows, it is applicable in similar applications under the umbrella of Computational Science and Engineering (CSE). To this end, we introduce a bunch matrix that allows the aggregation of multiple time steps and SVD updates, and significantly increases the computational efficiency. The incremental SVD strategy is initially verified and validated by simulating the 2D laminar single-phase flow around a circular cylinder. Subsequent studies analyze the proposed strategy for a 2D submerged hydrofoil located in turbulent two-phase flows. Attention is directed to the accuracy of the SVD-based reconstruction based on local and global flow quantities, their physical realizability, the independence of the domain partitioning, and related implementation aspects. Moreover, the influence of lower and (adaptive) upper construction rank thresholds on both the effort and the accuracy are assessed. The incremental SVD process is applied to analyze and compress the predicted flow field around a Kriso container ship in harmonic head waves at Fn = 0.26 and ReL = 1.4E+07. With a numerical overhead of O(10%), the snapshot matrix of size O(R10E+08 x 10E+04) computed on approximately 3000 processors can be incrementally compressed by O(95%). The storage reduction is accompanied by errors in integral force and local wave elevation quantities of O(1E-02%).",
        "published": "2023-02-17T21:19:54Z",
        "link": "http://arxiv.org/abs/2302.09149v1",
        "categories": [
            "cs.MS",
            "cs.DC",
            "physics.comp-ph",
            "physics.flu-dyn"
        ]
    },
    {
        "title": "SurvLIMEpy: A Python package implementing SurvLIME",
        "authors": [
            "Cristian Pachón-García",
            "Carlos Hernández-Pérez",
            "Pedro Delicado",
            "Verónica Vilaplana"
        ],
        "summary": "In this paper we present SurvLIMEpy, an open-source Python package that implements the SurvLIME algorithm. This method allows to compute local feature importance for machine learning algorithms designed for modelling Survival Analysis data. Our implementation takes advantage of the parallelisation paradigm as all computations are performed in a matrix-wise fashion which speeds up execution time. Additionally, SurvLIMEpy assists the user with visualization tools to better understand the result of the algorithm. The package supports a wide variety of survival models, from the Cox Proportional Hazards Model to deep learning models such as DeepHit or DeepSurv. Two types of experiments are presented in this paper. First, by means of simulated data, we study the ability of the algorithm to capture the importance of the features. Second, we use three open source survival datasets together with a set of survival algorithms in order to demonstrate how SurvLIMEpy behaves when applied to different models.",
        "published": "2023-02-21T09:54:32Z",
        "link": "http://arxiv.org/abs/2302.10571v2",
        "categories": [
            "stat.ML",
            "cs.AI",
            "cs.LG",
            "cs.MS"
        ]
    },
    {
        "title": "Randomized Numerical Linear Algebra : A Perspective on the Field With an   Eye to Software",
        "authors": [
            "Riley Murray",
            "James Demmel",
            "Michael W. Mahoney",
            "N. Benjamin Erichson",
            "Maksim Melnichenko",
            "Osman Asif Malik",
            "Laura Grigori",
            "Piotr Luszczek",
            "Michał Dereziński",
            "Miles E. Lopes",
            "Tianyu Liang",
            "Hengrui Luo",
            "Jack Dongarra"
        ],
        "summary": "Randomized numerical linear algebra - RandNLA, for short - concerns the use of randomization as a resource to develop improved algorithms for large-scale linear algebra computations.   The origins of contemporary RandNLA lay in theoretical computer science, where it blossomed from a simple idea: randomization provides an avenue for computing approximate solutions to linear algebra problems more efficiently than deterministic algorithms. This idea proved fruitful in the development of scalable algorithms for machine learning and statistical data analysis applications. However, RandNLA's true potential only came into focus upon integration with the fields of numerical analysis and \"classical\" numerical linear algebra. Through the efforts of many individuals, randomized algorithms have been developed that provide full control over the accuracy of their solutions and that can be every bit as reliable as algorithms that might be found in libraries such as LAPACK. Recent years have even seen the incorporation of certain RandNLA methods into MATLAB, the NAG Library, NVIDIA's cuSOLVER, and SciKit-Learn.   For all its success, we believe that RandNLA has yet to realize its full potential. In particular, we believe the scientific community stands to benefit significantly from suitably defined \"RandBLAS\" and \"RandLAPACK\" libraries, to serve as standards conceptually analogous to BLAS and LAPACK. This 200-page monograph represents a step toward defining such standards. In it, we cover topics spanning basic sketching, least squares and optimization, low-rank approximation, full matrix decompositions, leverage score sampling, and sketching data with tensor product structures (among others). Much of the provided pseudo-code has been tested via publicly available MATLAB and Python implementations.",
        "published": "2023-02-22T16:21:37Z",
        "link": "http://arxiv.org/abs/2302.11474v2",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "math.OC"
        ]
    },
    {
        "title": "PNet: A Python Library for Petri Net Modeling and Simulation",
        "authors": [
            "Zhu En Chay",
            "Bing Feng Goh",
            "Maurice HT Ling"
        ],
        "summary": "Petri Net is a formalism to describe changes between 2 or more states across discrete time and has been used to model many systems. We present PNet - a pure Python library for Petri Net modeling and simulation in Python programming language. The design of PNet focuses on reducing the learning curve needed to define a Petri Net by using a text-based language rather than programming constructs to define transition rules. Complex transition rules can be refined as regular Python functions. To demonstrate the simplicity of PNet, we present 2 examples - bread baking, and epidemiological models.",
        "published": "2023-02-23T14:27:50Z",
        "link": "http://arxiv.org/abs/2302.12054v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "TAPPS Release 1: Plugin-Extensible Platform for Technical Analysis and   Applied Statistics",
        "authors": [
            "Justin Sam Chew",
            "Maurice HT Ling"
        ],
        "summary": "We present the first release of TAPPS (Technical Analysis and Applied Statistics System); a Python implementation of a thin software platform aimed towards technical analyses and applied statistics. The core of TAPPS is a container for 2-dimensional data frame objects and a TAPPS command language. TAPPS language is not meant to be a programming language for script and plugin development but for the operational purposes. In this aspect, TAPPS language takes on the flavor of SQL rather than R, resulting in a shallower learning curve. All analytical functions are implemented as plugins. This results in a defined plugin system, which enables rapid development and incorporation of analysis functions. TAPPS Release 1 is released under GNU General Public License 3 for academic and non-commercial use. TAPPS code repository can be found at http://github.com/mauriceling/tapps.",
        "published": "2023-02-23T14:30:20Z",
        "link": "http://arxiv.org/abs/2302.12056v1",
        "categories": [
            "cs.MS",
            "stat.AP"
        ]
    },
    {
        "title": "SubalgebraBases in Macaulay2",
        "authors": [
            "Michael Burr",
            "Oliver Clarke",
            "Timothy Duff",
            "Jackson Leaman",
            "Nathan Nichols",
            "Elise Walker"
        ],
        "summary": "We describe a recently revived version of the software package SubalgberaBases, which is distributed in the Macaulay2 computer algebra system. The package allows the user to compute and manipulate subagebra bases -- which are also known as SAGBI bases or canonical bases and form a special class of Khovanskii bases -- for polynomial rings and their quotients. We provide an overview of the design and functionality of SubalgberaBases and demonstrate how the package works on several motivating examples.",
        "published": "2023-02-24T06:16:21Z",
        "link": "http://arxiv.org/abs/2302.12473v2",
        "categories": [
            "math.AC",
            "cs.MS",
            "68W30"
        ]
    },
    {
        "title": "QCLAB++: Simulating Quantum Circuits on GPUs",
        "authors": [
            "Roel Van Beeumen",
            "Daan Camps",
            "Neil Mehta"
        ],
        "summary": "We introduce qclab++, a light-weight, fully-templated C++ package for GPU-accelerated quantum circuit simulations. The code offers a high degree of portability as it has no external dependencies and the GPU kernels are generated through OpenMP offloading. qclab++ is designed for performance and numerical stability through highly optimized gate simulation algorithms for 1-qubit, controlled 1-qubit, and 2-qubit gates. Furthermore, we also introduce qclab, a quantum circuit toolbox for Matlab with a syntax that mimics qclab++. This provides users the flexibility and ease of use of a scripting language like Matlab for studying their quantum algorithms, while offering high-performance GPU acceleration when required. As such, the qclab++ library offers a unique combination of features. We compare the CPU simulator in qclab++ with the GPU kernels generated by OpenMP and observe a speedup of over $40\\times$. Furthermore, we also compare qclab++ to other circuit simulation packages, such as cirq-qsim and qibo, in a series of benchmarks conducted on NERSC's Perlmutter system and illustrate its competitiveness.",
        "published": "2023-02-28T22:56:48Z",
        "link": "http://arxiv.org/abs/2303.00123v1",
        "categories": [
            "quant-ph",
            "cs.MS",
            "cs.PF"
        ]
    },
    {
        "title": "Robust and Practical Solution of Laplacian Equations by Approximate   Elimination",
        "authors": [
            "Yuan Gao",
            "Rasmus Kyng",
            "Daniel A. Spielman"
        ],
        "summary": "We introduce a new algorithm and software for solving linear equations in symmetric diagonally dominant matrices with non-positive off-diagonal entries (SDDM matrices), including Laplacian matrices. We use pre-conditioned conjugate gradient (PCG) to solve the system of linear equations. Our preconditioner is a variant of the Approximate Cholesky factorization of Kyng and Sachdeva (FOCS 2016). Our factorization approach is simple: we eliminate matrix rows/columns one at a time and update the remaining matrix using sampling to approximate the outcome of complete Cholesky factorization. Unlike earlier approaches, our sampling always maintains a connectivity in the remaining non-zero structure. Our algorithm comes with a tuning parameter that upper bounds the number of samples made per original entry. We implement our algorithm in Julia, providing two versions, AC and AC2, that respectively use 1 and 2 samples per original entry. We compare their single-threaded performance to that of current state-of-the-art solvers Combinatorial Multigrid (CMG), BoomerAMG-preconditioned Krylov solvers from HyPre and PETSc, Lean Algebraic Multigrid (LAMG), and MATLAB's with Incomplete Cholesky Factorization (ICC). Our evaluation uses a broad class of problems, including all large SDDM matrices from the SuiteSparse collection and diverse programmatically generated instances. Our experiments suggest that our algorithm attains a level of robustness and reliability not seen before in SDDM solvers, while retaining good performance across all instances. Our code and data are public, and we provide a tutorial on how to replicate our tests. We hope that others will adopt this suite of tests as a benchmark, which we refer to as SDDM2023. Our solver code is available at: https://github.com/danspielman/Laplacians.jl/ Our benchmarking data and tutorial are available at: https://rjkyng.github.io/SDDM2023/",
        "published": "2023-03-01T18:07:51Z",
        "link": "http://arxiv.org/abs/2303.00709v2",
        "categories": [
            "math.NA",
            "cs.DS",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "Robust Parameter Estimation for Rational Ordinary Differential Equations",
        "authors": [
            "Oren Bassik",
            "Yosef Berman",
            "Soo Go",
            "Hoon Hong",
            "Ilia Ilmer",
            "Alexey Ovchinnikov",
            "Chris Rackauckas",
            "Pedro Soto",
            "Chee Yap"
        ],
        "summary": "We present a new approach for estimating parameters in rational ODE models from given (measured) time series data.   In typical existing approaches, an initial guess for the parameter values is made from a given search interval. Then, in a loop, the corresponding outputs are computed by solving the ODE numerically, followed by computing the error from the given time series data. If the error is small, the loop terminates and the parameter values are returned. Otherwise, heuristics/theories are used to possibly improve the guess and continue the loop.   These approaches tend to be non-robust in the sense that their accuracy depend on the search interval and the true parameter values; furthermore, they cannot handle the case where the parameters are locally identifiable.   In this paper, we propose a new approach, which does not suffer from the above non-robustness. In particular, it does not require making good initial guesses for the parameter values or specifying search intervals. Instead, it uses differential algebra, interpolation of the data using rational functions, and multivariate polynomial system solving. We also compare the performance of the resulting software with several other estimation software packages.",
        "published": "2023-03-02T14:33:06Z",
        "link": "http://arxiv.org/abs/2303.02159v3",
        "categories": [
            "cs.MS",
            "cs.SC",
            "math.DS",
            "q-bio.QM"
        ]
    },
    {
        "title": "EZtune: A Package for Automated Hyperparameter Tuning in R",
        "authors": [
            "Jill Lundell"
        ],
        "summary": "Statistical learning models have been growing in popularity in recent years. Many of these models have hyperparameters that must be tuned for models to perform well. Tuning these parameters is not trivial. EZtune is an R package with a simple user interface that can tune support vector machines, adaboost, gradient boosting machines, and elastic net. We first provide a brief summary of the the models that EZtune can tune, including a discussion of each of their hyperparameters. We then compare the ease of using EZtune, caret, and tidymodels. This is followed with a comparison of the accuracy and computation times for models tuned with EZtune and tidymodels. We conclude with a demonstration of how how EZtune can be used to help select a final model with optimal predictive power. Our comparison shows that EZtune can tune support vector machines and gradient boosting machines with EZtune also provides a user interface that is easy to use for a novice to statistical learning models or R.",
        "published": "2023-03-03T03:38:31Z",
        "link": "http://arxiv.org/abs/2303.12177v1",
        "categories": [
            "cs.LG",
            "cs.MS",
            "stat.CO"
        ]
    },
    {
        "title": "The Awkward World of Python and C++",
        "authors": [
            "Manasvi Goyal",
            "Ianna Osborne",
            "Jim Pivarski"
        ],
        "summary": "There are undeniable benefits of binding Python and C++ to take advantage of the best features of both languages. This is especially relevant to the HEP and other scientific communities that have invested heavily in the C++ frameworks and are rapidly moving their data analyses to Python. Version 2 of Awkward Array, a Scikit-HEP Python library, introduces a set of header-only C++ libraries that do not depend on any application binary interface. Users can directly include these libraries in their compilation instead of linking against platform-specific libraries. This new development makes the integration of Awkward Arrays into other projects easier and more portable, as the implementation is easily separable from the rest of the Awkward Array codebase. The code is minimal; it does not include all of the code needed to use Awkward Arrays in Python, nor does it include references to Python or pybind11. The C++ users can use it to make arrays and then copy them to Python without any specialized data types - only raw buffers, strings, and integers. This C++ code also simplifies the process of just-in-time (JIT) compilation in ROOT. This implementation approach solves some of the drawbacks, like packaging projects where native dependencies can be challenging. In this paper, we demonstrate the technique to integrate C++ and Python using a header-only approach. We also describe the implementation of a new LayoutBuilder and a GrowableBuffer. Furthermore, examples of wrapping the C++ data into Awkward Arrays and exposing Awkward Arrays to C++ without copying them are discussed.",
        "published": "2023-03-03T20:33:50Z",
        "link": "http://arxiv.org/abs/2303.02205v2",
        "categories": [
            "cs.MS",
            "hep-ex"
        ]
    },
    {
        "title": "Multi-GPU aggregation-based AMG preconditioner for iterative linear   solvers",
        "authors": [
            "Massimo Bernaschi",
            "Alessandro Celestini",
            "Pasqua D'Ambra",
            "Flavio Vella"
        ],
        "summary": "We present and release in open source format a sparse linear solver which efficiently exploits heterogeneous parallel computers. The solver can be easily integrated into scientific applications that need to solve large and sparse linear systems on modern parallel computers made of hybrid nodes hosting NVIDIA Graphics Processing Unit (GPU) accelerators.   The work extends our previous efforts in the exploitation of a single GPU accelerator and proposes an implementation, based on the hybrid MPI-CUDA software environment, of a Krylov-type linear solver relying on an efficient Algebraic MultiGrid (AMG) preconditioner already available in the BootCMatchG library. Our design for the hybrid implementation has been driven by the best practices for minimizing data communication overhead when multiple GPUs are employed, yet preserving the efficiency of the single GPU kernels. Strong and weak scalability results on well-known benchmark test cases of the new version of the library are discussed. Comparisons with the Nvidia AmgX solution show an improvement of up to 2.0x in the solve phase.",
        "published": "2023-03-04T08:29:54Z",
        "link": "http://arxiv.org/abs/2303.02352v1",
        "categories": [
            "cs.DC",
            "cs.MS"
        ]
    },
    {
        "title": "Acceleration of a production Solar MHD code with Fortran standard   parallelism: From OpenACC to `do concurrent'",
        "authors": [
            "Ronald M. Caplan",
            "Miko M. Stulajter",
            "Jon A. Linker"
        ],
        "summary": "There is growing interest in using standard language constructs for accelerated computing, avoiding the need for (often vendor-specific) external APIs. These constructs hold the potential to be more portable and much more `future-proof'. For Fortran codes, the current focus is on the {\\tt do concurrent} (DC) loop. While there have been some successful examples of GPU-acceleration using DC for benchmark and/or small codes, its widespread adoption will require demonstrations of its use in full-size applications. Here, we look at the current capabilities and performance of using DC in a production application called Magnetohydrodynamic Algorithm outside a Sphere (MAS). MAS is a state-of-the-art model for studying coronal and heliospheric dynamics, is over 70,000 lines long, and has previously been ported to GPUs using MPI+OpenACC. We attempt to eliminate as many of its OpenACC directives as possible in favor of DC. We show that using the NVIDIA {\\tt nvfortran} compiler's Fortran 202X preview implementation, unified managed memory, and modified MPI launch methods, we can achieve GPU acceleration across multiple GPUs without using a single OpenACC directive. However, doing so results in a slowdown between 1.25x and 3x. We discuss what future improvements are needed to avoid this loss, and show how we can still retain close",
        "published": "2023-03-05T21:37:34Z",
        "link": "http://arxiv.org/abs/2303.03398v2",
        "categories": [
            "cs.MS",
            "astro-ph.IM",
            "cs.DC",
            "cs.PL",
            "65Y05"
        ]
    },
    {
        "title": "Cascading GEMM: High Precision from Low Precision",
        "authors": [
            "Devangi N. Parikh",
            "Robert A. van de Geijn",
            "Greg M. Henry"
        ],
        "summary": "This paper lays out insights and opportunities for implementing higher-precision matrix-matrix multiplication (GEMM) from (in terms of) lower-precision high-performance GEMM. The driving case study approximates double-double precision (FP64x2) GEMM in terms of double precision (FP64) GEMM, leveraging how the BLAS-like Library Instantiation Software (BLIS) framework refactors the Goto Algorithm. With this, it is shown how approximate FP64x2 GEMM accuracy can be cast in terms of ten ``cascading'' FP64 GEMMs. Promising results from preliminary performance and accuracy experiments are reported. The demonstrated techniques open up new research directions for more general cascading of higher-precision computation in terms of lower-precision computation for GEMM-like functionality.",
        "published": "2023-03-08T03:26:12Z",
        "link": "http://arxiv.org/abs/2303.04353v1",
        "categories": [
            "cs.MS",
            "G.4"
        ]
    },
    {
        "title": "DisjunctiveProgramming.jl: Generalized Disjunctive Programming Models   and Algorithms for JuMP",
        "authors": [
            "Hector D. Perez",
            "Shivank Joshi",
            "Ignacio E. Grossmann"
        ],
        "summary": "We present a Julia package, DisjunctiveProgramming.jl, that extends the functionality in JuMP.jl to allow modeling problems via logical propositions and disjunctive constraints. Such models can then be reformulated into Mixed-Integer Programs (MIPs) that can be solved with the various MIP solvers supported by JuMP. To do so, logical propositions are converted to Conjunctive Normal Form (CNF) and reformulated into equivalent algebraic constraints. Disjunctions are reformulated into mixed-integer constraints via the reformulation technique specified by the user (Big-M or Hull reformulations). The package supports reformulations for disjunctions containing linear, quadratic, and nonlinear constraints.",
        "published": "2023-03-08T05:30:40Z",
        "link": "http://arxiv.org/abs/2304.10492v1",
        "categories": [
            "cs.LO",
            "cs.MS"
        ]
    },
    {
        "title": "PyGenStability: Multiscale community detection with generalized Markov   Stability",
        "authors": [
            "Alexis Arnaudon",
            "Dominik J. Schindler",
            "Robert L. Peach",
            "Adam Gosztolai",
            "Maxwell Hodges",
            "Michael T. Schaub",
            "Mauricio Barahona"
        ],
        "summary": "We present PyGenStability, a general-use Python software package that provides a suite of analysis and visualisation tools for unsupervised multiscale community detection in graphs. PyGenStability finds optimized partitions of a graph at different levels of resolution by maximizing the generalized Markov Stability quality function with the Louvain or Leiden algorithms. The package includes automatic detection of robust graph partitions and allows the flexibility to choose quality functions for weighted undirected, directed and signed graphs, and to include other user-defined quality functions.",
        "published": "2023-03-08T16:22:03Z",
        "link": "http://arxiv.org/abs/2303.05385v2",
        "categories": [
            "cs.SI",
            "cs.MS",
            "G.4; I.5.3"
        ]
    },
    {
        "title": "RANG: Reconstructing reproducible R computational environments",
        "authors": [
            "Chung-hong Chan",
            "David Schoch"
        ],
        "summary": "A complete declarative description of the computational environment is often missing when researchers share their materials. Without such description, software obsolescence and missing system components can jeopardize computational reproducibility in the future, even when data and computer code are available. The R package rang is a complete solution for generating the declarative description for other researchers to automatically reconstruct the computational environment at a specific time point. The reconstruction process, based on Docker, has been tested for R code as old as 2001. The declarative description generated by rang satisfies the definition of a reproducible research compendium and can be shared as such. In this contribution, we show how rang can be used to make otherwise unexecutable code, spanning from fields such as computational social science and bioinformatics, executable again. We also provide instructions on how to use rang to construct reproducible and shareable research compendia of current research. The package is currently available from CRAN (https://cran.r-project.org/web/packages/rang/index.html) and GitHub (https://github.com/chainsawriot/rang).",
        "published": "2023-03-08T17:51:05Z",
        "link": "http://arxiv.org/abs/2303.04758v1",
        "categories": [
            "stat.CO",
            "cs.MS"
        ]
    },
    {
        "title": "SMaLL: A Software Framework for portable Machine Learning Libraries",
        "authors": [
            "Upasana Sridhar",
            "Nicholai Tukanov",
            "Elliott Binder",
            "Tze Meng Low",
            "Scott McMillan",
            "Martin D. Schatz"
        ],
        "summary": "Interest in deploying Deep Neural Network (DNN) inference on edge devices has resulted in an explosion of the number and types of hardware platforms to use. While the high-level programming interface, such as TensorFlow, can be readily ported across different devices, high-performance inference implementations rely on a good mapping of the high-level interface to the target hardware platform. Commonly, this mapping may use optimizing compilers to generate code at compile time or high-performance vendor libraries that have been specialized to the target platform. Both approaches rely on expert knowledge to produce the mapping, which may be time-consuming and difficult to extend to new architectures.   In this work, we present a DNN library framework, SMaLL, that is easily extensible to new architectures. The framework uses a unified loop structure and shared, cache-friendly data format across all intermediate layers, eliminating the time and memory overheads incurred by data transformation between layers. Layers are implemented by simply specifying the layer's dimensions and a kernel -- the key computing operations of each layer. The unified loop structure and kernel abstraction allows us to reuse code across layers and computing platforms. New architectures only require the 100s of lines in the kernel to be redesigned. To show the benefits of our approach, we have developed software that supports a range of layer types and computing platforms, which is easily extensible for rapidly instantiating high performance DNN libraries.   We evaluate our software by instantiating networks from the TinyMLPerf benchmark suite on 5 ARM platforms and 1 x86 platform ( an AMD Zen 2). Our framework shows end-to-end performance that is comparable to or better than ML Frameworks such as TensorFlow, TVM and LibTorch.",
        "published": "2023-03-08T18:07:55Z",
        "link": "http://arxiv.org/abs/2303.04769v1",
        "categories": [
            "cs.MS",
            "cs.PF"
        ]
    },
    {
        "title": "Efficient simulation of individual-based population models: the R   Package IBMPopSim",
        "authors": [
            "Daphné Giorgi",
            "Sarah Kaakai",
            "Vincent Lemaire"
        ],
        "summary": "The R Package IBMPopSim aims to simulate the random evolution of heterogeneous populations using stochastic Individual-Based Models (IBMs).   The package enables users to simulate population evolution, in which individuals are characterized by their age and some characteristics, and the population is modified by different types of events, including births/arrivals, death/exit events, or changes of characteristics. The frequency at which an event can occur to an individual can depend on their age and characteristics, but also on the characteristics of other individuals (interactions). Such models have a wide range of applications in fields including actuarial science, biology, ecology or epidemiology.   IBMPopSim overcomes the limitations of time-consuming IBMs simulations by implementing new efficient algorithms based on thinning methods, which are compiled using the Rcpp package while providing a user-friendly interface.",
        "published": "2023-03-10T19:31:50Z",
        "link": "http://arxiv.org/abs/2303.06183v2",
        "categories": [
            "q-bio.PE",
            "cs.MS",
            "math.PR",
            "60-08, 60-04, 92D25, 60G55, 60G57, 65C30, 91G05",
            "G.3; G.4; I.6"
        ]
    },
    {
        "title": "AutoOptLib: Tailoring Metaheuristic Optimizers via Automated Algorithm   Design",
        "authors": [
            "Qi Zhao",
            "Bai Yan",
            "Taiwei Hu",
            "Xianglong Chen",
            "Qiqi Duan",
            "Jian Yang",
            "Yuhui Shi"
        ],
        "summary": "Metaheuristics are prominent gradient-free optimizers for solving hard problems that do not meet the rigorous mathematical assumptions of analytical solvers. The canonical manual optimizer design could be laborious, untraceable and error-prone, let alone human experts are not always available. This arises increasing interest and demand in automating the optimizer design process. In response, this paper proposes AutoOptLib, the first platform for accessible automated design of metaheuristic optimizers. AutoOptLib leverages computing resources to conceive, build up, and verify the design choices of the optimizers. It requires much less labor resources and expertise than manual design, democratizing satisfactory metaheuristic optimizers to a much broader range of researchers and practitioners. Furthermore, by fully exploring the design choices with computing resources, AutoOptLib has the potential to surpass human experience, subsequently gaining enhanced performance compared with human problem-solving. To realize the automated design, AutoOptLib provides 1) a rich library of metaheuristic components for continuous, discrete, and permutation problems; 2) a flexible algorithm representation for evolving diverse algorithm structures; 3) different design objectives and techniques for different optimization scenarios; and 4) a graphic user interface for accessibility and practicability. AutoOptLib is fully written in Matlab/Octave; its source code and documentation are available at https://github.com/qz89/AutoOpt and https://AutoOpt.readthedocs.io/, respectively.",
        "published": "2023-03-12T01:45:05Z",
        "link": "http://arxiv.org/abs/2303.06536v2",
        "categories": [
            "cs.NE",
            "cs.LG",
            "cs.MS"
        ]
    },
    {
        "title": "Physics-driven machine learning models coupling PyTorch and Firedrake",
        "authors": [
            "Nacime Bouziani",
            "David A. Ham"
        ],
        "summary": "Partial differential equations (PDEs) are central to describing and modelling complex physical systems that arise in many disciplines across science and engineering. However, in many realistic applications PDE modelling provides an incomplete description of the physics of interest. PDE-based machine learning techniques are designed to address this limitation. In this approach, the PDE is used as an inductive bias enabling the coupled model to rely on fundamental physical laws while requiring less training data. The deployment of high-performance simulations coupling PDEs and machine learning to complex problems necessitates the composition of capabilities provided by machine learning and PDE-based frameworks. We present a simple yet effective coupling between the machine learning framework PyTorch and the PDE system Firedrake that provides researchers, engineers and domain specialists with a high productive way of specifying coupled models while only requiring trivial changes to existing code.",
        "published": "2023-03-13T05:42:58Z",
        "link": "http://arxiv.org/abs/2303.06871v3",
        "categories": [
            "cs.LG",
            "cs.MS",
            "cs.NA",
            "math.NA",
            "physics.comp-ph"
        ]
    },
    {
        "title": "$\\nabla$SD: Differentiable Programming for Sparse Tensors",
        "authors": [
            "Amir Shaikhha",
            "Mathieu Huot",
            "Shideh Hashemian"
        ],
        "summary": "Sparse tensors are prevalent in many data-intensive applications, yet existing differentiable programming frameworks are tailored towards dense tensors. This presents a significant challenge for efficiently computing gradients through sparse tensor operations, as their irregular sparsity patterns can result in substantial memory and computational overheads. In this work, we introduce a novel framework that enables the efficient and automatic differentiation of sparse tensors, addressing this fundamental issue. Our experiments demonstrate the effectiveness of the proposed framework in terms of performance and scalability, outperforming state-of-the-art frameworks across a range of synthetic and real-world datasets. Our approach offers a promising direction for enabling efficient and scalable differentiable programming with sparse tensors, which has significant implications for numerous applications in machine learning, natural language processing, and scientific computing.",
        "published": "2023-03-13T11:45:48Z",
        "link": "http://arxiv.org/abs/2303.07030v1",
        "categories": [
            "cs.PL",
            "cs.LG",
            "cs.MS"
        ]
    },
    {
        "title": "waywiser: Ergonomic Methods for Assessing Spatial Models",
        "authors": [
            "Michael J Mahoney"
        ],
        "summary": "Assessing predictive models can be challenging. Modelers must navigate a wide array of evaluation methodologies implemented with incompatible interfaces across multiple packages which may give different or even contradictory results, while ensuring that their chosen approach properly estimates the performance of their model when generalizing to new observations. Assessing models fit to spatial data can be particularly difficult, given that model errors may exhibit spatial autocorrelation, model predictions are often aggregated to multiple spatial scales by end users, and models are often tasked with generalizing into spatial regions outside the boundaries of their initial training data.   The waywiser package for the R language attempts to make assessing spatial models easier by providing an ergonomic toolkit for model evaluation tasks, with functions for multiple assessment methodologies sharing a unified interface. Functions from waywiser share standardized argument names and default values, making the user-facing interface simple and easy to learn. These functions are additionally designed to be easy to integrate into a wide variety of modeling workflows, accepting standard classes as inputs and returning size- and type-stable outputs, ensuring that their results are of consistent and predictable data types and dimensions. Additional features make it particularly easy to use waywiser along packages and workflows in the tidymodels ecosystem.",
        "published": "2023-03-20T17:51:36Z",
        "link": "http://arxiv.org/abs/2303.11312v1",
        "categories": [
            "cs.MS",
            "stat.CO",
            "stat.ME"
        ]
    },
    {
        "title": "TOPress: a MATLAB implementation for topology optimization of structures   subjected to design-dependent pressure loads",
        "authors": [
            "Prabhat Kumar"
        ],
        "summary": "In a topology optimization setting, design-dependent fluidic pressure loads pose several challenges as their direction, magnitude, and location alter with topology evolution. This paper offers a compact 100-line MATLAB code, TOPress, for topology optimization of structures subjected to fluidic pressure loads using the method of moving asymptotes. The code is intended for pedagogical purposes and aims to ease the beginners' and students' learning toward topology optimization with design-dependent fluidic pressure loads. TOPress is developed per the approach first reported in Kumar et al. (Struct Multidisc Optim 61(4):1637-1655, 2020). The Darcy law, in conjunction with the drainage term, is used to model the applied pressure load. The consistent nodal loads are determined from the obtained pressure field. The employed approach facilitates inexpensive computation of the load sensitivities using the adjoint-variable method. Compliance minimization subject to volume constraint optimization problems are solved. The success and efficacy of the code are demonstrated by solving benchmark numerical examples involving pressure loads, wherein the importance of load sensitivities is also demonstrated. TOPress contains six main parts, is described in detail, and is extended to solve different problems. Steps to include a projection filter are provided to achieve loadbearing designs close to~0-1. The code is provided in Appendix~B and can also be downloaded along with its extensions from \\url{https://github.com/PrabhatIn/TOPress}.",
        "published": "2023-03-26T11:31:22Z",
        "link": "http://arxiv.org/abs/2303.14690v4",
        "categories": [
            "cs.MS",
            "cs.CE"
        ]
    },
    {
        "title": "The regularization continuation method for optimization problems with   nonlinear equality constraints",
        "authors": [
            "Xin-long Luo",
            "Hang Xiao",
            "Sen Zhang"
        ],
        "summary": "This paper considers the regularization continuation method and the trust-region updating strategy for the nonlinearly equality-constrained optimization problem. Namely, it uses the inverse of the regularization quasi-Newton matrix as the pre-conditioner to improve its computational efficiency in the well-posed phase, and it adopts the inverse of the regularization two-sided projection of the Hessian as the pre-conditioner to improve its robustness in the ill-conditioned phase. Since it only solves a linear system of equations at every iteration and the sequential quadratic programming (SQP) needs to solve a quadratic programming subproblem at every iteration, it is faster than SQP. Numerical results also show that it is more robust and faster than SQP (the built-in subroutine fmincon.m of the MATLAB2020a environment and the subroutine SNOPT executed in GAMS v28.2 (2019) environment). The computational time of the new method is about one third of that of fmincon.m for the large-scale problem. Finally, the global convergence analysis of the new method is also given.",
        "published": "2023-03-26T11:40:42Z",
        "link": "http://arxiv.org/abs/2303.14692v2",
        "categories": [
            "math.OC",
            "cs.CE",
            "cs.MS",
            "cs.NA",
            "math.DS",
            "math.NA"
        ]
    },
    {
        "title": "A Practitioner's Guide to Bayesian Inference in Pharmacometrics using   Pumas",
        "authors": [
            "Mohamed Tarek",
            "Jose Storopoli",
            "Casey Davis",
            "Chris Elrod",
            "Julius Krumbiegel",
            "Chris Rackauckas",
            "Vijay Ivaturi"
        ],
        "summary": "This paper provides a comprehensive tutorial for Bayesian practitioners in pharmacometrics using Pumas workflows. We start by giving a brief motivation of Bayesian inference for pharmacometrics highlighting limitations in existing software that Pumas addresses. We then follow by a description of all the steps of a standard Bayesian workflow for pharmacometrics using code snippets and examples. This includes: model definition, prior selection, sampling from the posterior, prior and posterior simulations and predictions, counter-factual simulations and predictions, convergence diagnostics, visual predictive checks, and finally model comparison with cross-validation. Finally, the background and intuition behind many advanced concepts in Bayesian statistics are explained in simple language. This includes many important ideas and precautions that users need to keep in mind when performing Bayesian analysis. Many of the algorithms, codes, and ideas presented in this paper are highly applicable to clinical research and statistical learning at large but we chose to focus our discussions on pharmacometrics in this paper to have a narrower scope in mind and given the nature of Pumas as a software primarily for pharmacometricians.",
        "published": "2023-03-31T04:00:53Z",
        "link": "http://arxiv.org/abs/2304.04752v1",
        "categories": [
            "stat.AP",
            "cs.LG",
            "cs.MS",
            "stat.CO"
        ]
    },
    {
        "title": "TransPimLib: A Library for Efficient Transcendental Functions on   Processing-in-Memory Systems",
        "authors": [
            "Maurus Item",
            "Juan Gómez-Luna",
            "Yuxin Guo",
            "Geraldo F. Oliveira",
            "Mohammad Sadrosadati",
            "Onur Mutlu"
        ],
        "summary": "Processing-in-memory (PIM) promises to alleviate the data movement bottleneck in modern computing systems. However, current real-world PIM systems have the inherent disadvantage that their hardware is more constrained than in conventional processors (CPU, GPU), due to the difficulty and cost of building processing elements near or inside the memory. As a result, general-purpose PIM architectures support fairly limited instruction sets and struggle to execute complex operations such as transcendental functions and other hard-to-calculate operations (e.g., square root). These operations are particularly important for some modern workloads, e.g., activation functions in machine learning applications.   In order to provide support for transcendental (and other hard-to-calculate) functions in general-purpose PIM systems, we present \\emph{TransPimLib}, a library that provides CORDIC-based and LUT-based methods for trigonometric functions, hyperbolic functions, exponentiation, logarithm, square root, etc. We develop an implementation of TransPimLib for the UPMEM PIM architecture and perform a thorough evaluation of TransPimLib's methods in terms of performance and accuracy, using microbenchmarks and three full workloads (Blackscholes, Sigmoid, Softmax). We open-source all our code and datasets at~\\url{https://github.com/CMU-SAFARI/transpimlib}.",
        "published": "2023-04-03T12:41:46Z",
        "link": "http://arxiv.org/abs/2304.01951v5",
        "categories": [
            "cs.MS",
            "cs.AR",
            "cs.DC",
            "cs.LG"
        ]
    },
    {
        "title": "Monotonicity of Multi-Term Floating-Point Adders",
        "authors": [
            "Mantas Mikaitis"
        ],
        "summary": "In the literature on algorithms for performing the multi-term addition $s_n=\\sum_{i=1}^n x_i$ using floating-point arithmetic it is often shown that a hardware unit that has single normalization and rounding improves precision, area, latency, and power consumption, compared with the use of standard add or fused multiply-add units. However, non-monotonicity can appear when computing sums with a subclass of multi-term addition units, which currently is not explored in the literature. We demonstrate that common techniques for performing multi-term addition with $n\\geq 4$, without normalization of intermediate quantities, can result in non-monotonicity -- increasing one of the addends $x_i$ decreases the sum $s_n$. Summation is required in dot product and matrix multiplication operations, operations that have increasingly started appearing in the hardware of supercomputers, thus knowing where monotonicity is preserved can be of interest to the users of these machines. Our results suggest that non-monotonicity of summation, in some of the commercial hardware devices that implement a specific class of multi-term adders, is a feature that may have appeared unintentionally as a consequence of design choices that reduce circuit area and other metrics. To demonstrate our findings, we use formal proofs as well as a numerical simulation of non-monotonic multi-term adders in MATLAB.",
        "published": "2023-04-03T22:45:14Z",
        "link": "http://arxiv.org/abs/2304.01407v2",
        "categories": [
            "cs.MS",
            "cs.AR",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Automatic Differentiation of Binned Likelihoods With Roofit and Clad",
        "authors": [
            "Garima Singh",
            "Jonas Rembser",
            "Lorenzo Moneta",
            "David Lange",
            "Vassil Vassilev"
        ],
        "summary": "RooFit is a toolkit for statistical modeling and fitting used by most experiments in particle physics. Just as data sets from next-generation experiments grow, processing requirements for physics analysis become more computationally demanding, necessitating performance optimizations for RooFit. One possibility to speed-up minimization and add stability is the use of Automatic Differentiation (AD). Unlike for numerical differentiation, the computation cost scales linearly with the number of parameters, making AD particularly appealing for statistical models with many parameters. In this paper, we report on one possible way to implement AD in RooFit. Our approach is to add a facility to generate C++ code for a full RooFit model automatically. Unlike the original RooFit model, this generated code is free of virtual function calls and other RooFit-specific overhead. In particular, this code is then used to produce the gradient automatically with Clad. Clad is a source transformation AD tool implemented as a plugin to the clang compiler, which automatically generates the derivative code for input C++ functions. We show results demonstrating the improvements observed when applying this code generation strategy to HistFactory and other commonly used RooFit models. HistFactory is the subcomponent of RooFit that implements binned likelihood models with probability densities based on histogram templates. These models frequently have a very large number of free parameters and are thus an interesting first target for AD support in RooFit.",
        "published": "2023-04-04T14:23:40Z",
        "link": "http://arxiv.org/abs/2304.02650v1",
        "categories": [
            "cs.MS",
            "stat.CO",
            "G.4; J.2"
        ]
    },
    {
        "title": "Torch-Choice: A PyTorch Package for Large-Scale Choice Modelling with   Python",
        "authors": [
            "Tianyu Du",
            "Ayush Kanodia",
            "Susan Athey"
        ],
        "summary": "The $\\texttt{torch-choice}$ is an open-source library for flexible, fast choice modeling with Python and PyTorch. $\\texttt{torch-choice}$ provides a $\\texttt{ChoiceDataset}$ data structure to manage databases flexibly and memory-efficiently. The paper demonstrates constructing a $\\texttt{ChoiceDataset}$ from databases of various formats and functionalities of $\\texttt{ChoiceDataset}$. The package implements two widely used models, namely the multinomial logit and nested logit models, and supports regularization during model estimation. The package incorporates the option to take advantage of GPUs for estimation, allowing it to scale to massive datasets while being computationally efficient. Models can be initialized using either R-style formula strings or Python dictionaries. We conclude with a comparison of the computational efficiencies of $\\texttt{torch-choice}$ and $\\texttt{mlogit}$ in R as (1) the number of observations increases, (2) the number of covariates increases, and (3) the expansion of item sets. Finally, we demonstrate the scalability of $\\texttt{torch-choice}$ on large-scale datasets.",
        "published": "2023-04-04T16:00:48Z",
        "link": "http://arxiv.org/abs/2304.01906v3",
        "categories": [
            "cs.LG",
            "cs.MS",
            "econ.EM"
        ]
    },
    {
        "title": "Spectral Toolkit of Algorithms for Graphs: Technical Report (1)",
        "authors": [
            "Peter Macgregor",
            "He Sun"
        ],
        "summary": "Spectral Toolkit of Algorithms for Graphs (STAG) is an open-source library for efficient spectral graph algorithms, and its development starts in September 2022. We have so far finished the component on local graph clustering, and this technical report presents a user's guide to STAG, showcase studies, and several technical considerations behind our development.",
        "published": "2023-04-05T10:39:39Z",
        "link": "http://arxiv.org/abs/2304.03170v1",
        "categories": [
            "cs.SI",
            "cs.DS",
            "cs.LG",
            "cs.MS"
        ]
    },
    {
        "title": "Formal Derivation of LU Factorization with Pivoting",
        "authors": [
            "Robert van de Geijn",
            "Maggie Myers"
        ],
        "summary": "The FLAME methodology for deriving linear algebra algorithms from specification, first introduced around 2000, has been successfully applied to a broad cross section of operations. An open question has been whether it can yield algorithms for the best-known operation in linear algebra, LU factorization with partial pivoting (Gaussian elimination with row swapping). This paper shows that it can.",
        "published": "2023-04-06T13:36:20Z",
        "link": "http://arxiv.org/abs/2304.03068v1",
        "categories": [
            "cs.MS",
            "G.4"
        ]
    },
    {
        "title": "An Experimental Study of Two-Level Schwarz Domain Decomposition   Preconditioners on GPUs",
        "authors": [
            "Ichitaro Yamazaki",
            "Alexander Heinlein",
            "Sivasankaran Rajamanickam"
        ],
        "summary": "The generalized Dryja--Smith--Widlund (GDSW) preconditioner is a two-level overlapping Schwarz domain decomposition (DD) preconditioner that couples a classical one-level overlapping Schwarz preconditioner with an energy-minimizing coarse space. When used to accelerate the convergence rate of Krylov subspace iterative methods, the GDSW preconditioner provides robustness and scalability for the solution of sparse linear systems arising from the discretization of a wide range of partial different equations. In this paper, we present FROSch (Fast and Robust Schwarz), a domain decomposition solver package which implements GDSW-type preconditioners for both CPU and GPU clusters. To improve the solver performance on GPUs, we use a novel decomposition to run multiple MPI processes on each GPU, reducing both solver's computational and storage costs and potentially improving the convergence rate. This allowed us to obtain competitive or faster performance using GPUs compared to using CPUs alone. We demonstrate the performance of FROSch on the Summit supercomputer with NVIDIA V100 GPUs, where we used NVIDIA Multi-Process Service (MPS) to implement our decomposition strategy.   The solver has a wide variety of algorithmic and implementation choices, which poses both opportunities and challenges for its GPU implementation. We conduct a thorough experimental study with different solver options including the exact or inexact solution of the local overlapping subdomain problems on a GPU. We also discuss the effect of using the iterative variant of the incomplete LU factorization and sparse-triangular solve as the approximate local solver, and using lower precision for computing the whole FROSch preconditioner. Overall, the solve time was reduced by factors of about $2\\times$ using GPUs, while the GPU acceleration of the numerical setup time depend on the solver options and the local matrix sizes.",
        "published": "2023-04-10T21:57:13Z",
        "link": "http://arxiv.org/abs/2304.04876v1",
        "categories": [
            "math.NA",
            "cs.DC",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "Learned multiphysics inversion with differentiable programming and   machine learning",
        "authors": [
            "Mathias Louboutin",
            "Ziyi Yin",
            "Rafael Orozco",
            "Thomas J. Grady II",
            "Ali Siahkoohi",
            "Gabrio Rizzuti",
            "Philipp A. Witte",
            "Olav Møyner",
            "Gerard J. Gorman",
            "Felix J. Herrmann"
        ],
        "summary": "We present the Seismic Laboratory for Imaging and Modeling/Monitoring (SLIM) open-source software framework for computational geophysics and, more generally, inverse problems involving the wave-equation (e.g., seismic and medical ultrasound), regularization with learned priors, and learned neural surrogates for multiphase flow simulations. By integrating multiple layers of abstraction, our software is designed to be both readable and scalable. This allows researchers to easily formulate their problems in an abstract fashion while exploiting the latest developments in high-performance computing. We illustrate and demonstrate our design principles and their benefits by means of building a scalable prototype for permeability inversion from time-lapse crosswell seismic data, which aside from coupling of wave physics and multiphase flow, involves machine learning.",
        "published": "2023-04-12T03:38:22Z",
        "link": "http://arxiv.org/abs/2304.05592v1",
        "categories": [
            "cs.MS",
            "cs.DC",
            "cs.LG",
            "physics.comp-ph",
            "physics.geo-ph"
        ]
    },
    {
        "title": "Consistent Point Data Assimilation in Firedrake and Icepack",
        "authors": [
            "Reuben W. Nixon-Hill",
            "Daniel Shapero",
            "Colin J. Cotter",
            "David A. Ham"
        ],
        "summary": "When estimating quantities and fields that are difficult to measure directly, such as the fluidity of ice, from point data sources, such as satellite altimetry, it is important to solve a numerical inverse problem that is formulated with Bayesian consistency. Otherwise, the resultant probability density function for the difficult to measure quantity or field will not be appropriately clustered around the truth. In particular, the inverse problem should be formulated by evaluating the numerical solution at the true point locations for direct comparison with the point data source. If the data are first fitted to a gridded or meshed field on the computational grid or mesh, and the inverse problem formulated by comparing the numerical solution to the fitted field, the benefits of additional point data values below the grid density will be lost. We demonstrate, with examples in the fields of groundwater hydrology and glaciology, that a consistent formulation can increase the accuracy of results and aid discourse between modellers and observationalists.   To do this, we bring point data into the finite element method ecosystem as discontinuous fields on meshes of disconnected vertices. Point evaluation can then be formulated as a finite element interpolation operation (dual-evaluation). This new abstraction is well-suited to automation, including automatic differentiation. We demonstrate this through implementation in Firedrake, which generates highly optimised code for solving Partial Differential Equations (PDEs) with the finite element method. Our solution integrates with dolfin-adjoint/pyadjoint, allowing PDE-constrained optimisation problems, such as data assimilation, to be solved through forward and adjoint mode automatic differentiation.",
        "published": "2023-04-12T13:26:41Z",
        "link": "http://arxiv.org/abs/2304.06058v5",
        "categories": [
            "cs.MS",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "R-Shiny Applications for Local Clustering to be Included in the   growclusters for R Package",
        "authors": [
            "Randall Powers",
            "Wendy Martinez",
            "Terrance Savitsky"
        ],
        "summary": "growclusters for R is a package that estimates a partition structure for multivariate data. It does this by implementing a hierarchical version of k-means clustering that accounts for possible known dependencies in a collection of datasets, where each set draws its cluster means from a single, global partition. Each component data set in the collection corresponds to a known group in the data. This paper focuses on R Shiny applications that implement the clustering methodology and simulate data sets with known group structures. These Shiny applications implement novel ways of visualizing the results of the clustering. These visualizations include scatterplots of individual data sets in the context of the entire collection and cluster distributions versus component (or sub-domain) datasets. Data obtained from a collection of 2000-2013 articles from the Bureau of Labor Statistics (BLS) Monthly Labor Review (MLR) will be used to illustrate the R-Shiny applications. Here, the known grouping in the collection is the year of publication.",
        "published": "2023-04-12T20:03:44Z",
        "link": "http://arxiv.org/abs/2304.06145v2",
        "categories": [
            "cs.MS",
            "cs.LG",
            "I.5.3; I.3.8; J.0"
        ]
    },
    {
        "title": "Automated Translation and Accelerated Solving of Differential Equations   on Multiple GPU Platforms",
        "authors": [
            "Utkarsh Utkarsh",
            "Valentin Churavy",
            "Yingbo Ma",
            "Tim Besard",
            "Prakitr Srisuma",
            "Tim Gymnich",
            "Adam R. Gerlach",
            "Alan Edelman",
            "George Barbastathis",
            "Richard D. Braatz",
            "Christopher Rackauckas"
        ],
        "summary": "We demonstrate a high-performance vendor-agnostic method for massively parallel solving of ensembles of ordinary differential equations (ODEs) and stochastic differential equations (SDEs) on GPUs. The method is integrated with a widely used differential equation solver library in a high-level language (Julia's DifferentialEquations.jl) and enables GPU acceleration without requiring code changes by the user. Our approach achieves state-of-the-art performance compared to hand-optimized CUDA-C++ kernels while performing 20--100$\\times$ faster than the vectorizing map (vmap) approach implemented in JAX and PyTorch. Performance evaluation on NVIDIA, AMD, Intel, and Apple GPUs demonstrates performance portability and vendor-agnosticism. We show composability with MPI to enable distributed multi-GPU workflows. The implemented solvers are fully featured -- supporting event handling, automatic differentiation, and incorporation of datasets via the GPU's texture memory -- allowing scientists to take advantage of GPU acceleration on all major current architectures without changing their model code and without loss of performance. We distribute the software as an open-source library https://github.com/SciML/DiffEqGPU.jl",
        "published": "2023-04-13T21:57:51Z",
        "link": "http://arxiv.org/abs/2304.06835v3",
        "categories": [
            "cs.DC",
            "cs.MS",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Designing a Framework for Solving Multiobjective Simulation Optimization   Problems",
        "authors": [
            "Tyler H. Chang",
            "Stefan M. Wild"
        ],
        "summary": "Multiobjective simulation optimization (MOSO) problems are optimization problems with multiple conflicting objectives, where evaluation of at least one of the objectives depends on a black-box numerical code or real-world experiment, which we refer to as a simulation. This paper describes the design goals driving the development of the parallel MOSO library ParMOO. We derive these goals from the research trends and real-world requirements that arise when designing and deploying solvers for generic MOSO problems. Our specific design goals were to provide a customizable MOSO framework that allows for exploitation of simulation-based problem structures, ease of deployment in scientific workflows, maintainability, and flexibility in our support for many problem types. We explain how we have achieved these goals in the ParMOO library and provide two examples demonstrating how customized ParMOO solvers can be quickly built and deployed in real-world MOSO problems.",
        "published": "2023-04-14T01:16:53Z",
        "link": "http://arxiv.org/abs/2304.06881v2",
        "categories": [
            "math.OC",
            "cs.MS"
        ]
    },
    {
        "title": "Groebner.jl: A package for Gröbner bases computations in Julia",
        "authors": [
            "Alexander Demin",
            "Shashi Gowda"
        ],
        "summary": "We present Groebner.jl, a Julia package for computing Groebner bases with the F4 algorithm. Groebner.jl is an efficient, portable, and open-source software. Groebner.jl works over integers modulo a prime and over the rationals, supports basic multi-threading, and specializes in computation in the degree reverse lexicographical monomial ordering. The implementation incorporates various symbolic computation techniques and leverages the Julia type system and tooling, which allows Groebner.jl to compete with the existing state of the art, in many instances outperform it, and exceed them in extensibility. Groebner.jl is freely available at https://github.com/sumiya11/Groebner.jl.",
        "published": "2023-04-14T05:47:34Z",
        "link": "http://arxiv.org/abs/2304.06935v3",
        "categories": [
            "cs.MS",
            "cs.SC",
            "math.AC"
        ]
    },
    {
        "title": "An open-source pipeline for solving continuous reaction-diffusion models   in image-based geometries of porous media",
        "authors": [
            "Justina Stark",
            "Ivo F. Sbalzarini"
        ],
        "summary": "We present a versatile open-source pipeline for simulating inhomogeneous reaction-diffusion processes in highly resolved, image-based geometries of porous media with reactive boundaries. Resolving realistic pore-scale geometries in numerical models is challenging and computationally demanding, as the scale differences between the sizes of the interstitia and the whole system can lead to prohibitive memory requirements. The present pipeline combines a level-set method with geometry-adapted sparse block grids on GPUs to efficiently simulate reaction-diffusion processes in image-based geometries. We showcase the method by applying it to fertilizer diffusion in soil, heat transfer in porous ceramics, and determining effective diffusion coefficients and tortuosity. The present approach enables solving reaction-diffusion partial differential equations in real-world geometries applicable to porous media across fields such as engineering, environmental science, and biology.",
        "published": "2023-04-17T13:34:11Z",
        "link": "http://arxiv.org/abs/2304.11165v2",
        "categories": [
            "cs.MS",
            "physics.comp-ph"
        ]
    },
    {
        "title": "clotFoam: An Open-Source Framework to Simulate Blood Clot Formation   Under Arterial Flow",
        "authors": [
            "David Montgomery",
            "Federico Municchi",
            "Karin Leiderman"
        ],
        "summary": "Blood clotting involves the coupled processes of platelet aggregation and coagulation. Simulating clotting under flow in complex geometries is challenging due to multiple temporal and spatial scales and high computational cost. clotFoam is an open-source software developed in OpenFOAM that employs a continuum model of platelet advection, diffusion, and aggregation in a dynamic fluid environment and a simplified coagulation model with proteins that advect, diffuse, and react within the fluid and with wall-bound species through reactive boundary conditions. Our framework provides the foundation on which one can build more complex models and perform reliable simulations in almost any computational domain.",
        "published": "2023-04-17T20:22:15Z",
        "link": "http://arxiv.org/abs/2304.09180v3",
        "categories": [
            "physics.flu-dyn",
            "cs.MS",
            "physics.bio-ph"
        ]
    },
    {
        "title": "tomoCAM: Fast Model-based Iterative Reconstruction via GPU Acceleration   and Non-Uniform Fast Fourier Transforms",
        "authors": [
            "Dinesh Kumar",
            "Dilworth Y. Parkinson",
            "Jeffrey J. Donatelli"
        ],
        "summary": "X-Ray based computed tomography (CT) is a well-established technique for determining the three-dimensional structure of an object from its two-dimensional projections. In the past few decades, there have been significant advancements in the brightness and detector technology of tomography instruments at synchrotron sources. These advancements have led to the emergence of new observations and discoveries, with improved capabilities such as faster frame rates, larger fields of view, higher resolution, and higher dimensionality. These advancements have enabled the material science community to expand the scope of tomographic measurements towards increasingly in-situ and in-operando measurements. In these new experiments, samples can be rapidly evolving, have complex geometries, and restrictions on the field of view, limiting the number of projections that can be collected. In such cases, standard filtered back-projections (FBP) for the reconstructions often result in poor-quality reconstructions. Iterative reconstruction algorithms, such as model-based iterative reconstructions (MBIR), have demonstrated considerable success in producing high-quality reconstructions under such restrictions, but typically require high-performance computing resources with hundreds of compute nodes to solve the problem in a reasonable time.",
        "published": "2023-04-18T04:50:18Z",
        "link": "http://arxiv.org/abs/2304.12934v1",
        "categories": [
            "physics.med-ph",
            "cs.MS"
        ]
    },
    {
        "title": "Massively Distributed Finite-Volume Flux Computation",
        "authors": [
            "Ryuichi Sai",
            "Mathias Jacquelin",
            "François P. Hamon",
            "Mauricio Araya-Polo",
            "Randolph R. Settgast"
        ],
        "summary": "Designing large-scale geological carbon capture and storage projects and ensuring safe long-term CO2 containment - as a climate change mitigation strategy - requires fast and accurate numerical simulations. These simulations involve solving complex PDEs governing subsurface fluid flow using implicit finite-volume schemes widely based on Two-Point Flux Approximation (TPFA). This task is computationally and memory expensive, especially when performed on highly detailed geomodels. In most current HPC architectures, memory hierarchy and data management mechanism are insufficient to overcome the challenges of large scale numerical simulations. Therefore, it is crucial to design algorithms that can exploit alternative and more balanced paradigms, such as dataflow and in-memory computing. This work introduces an algorithm for TPFA computations that leverages effectively a dataflow architecture, such as Cerebras CS2, which helps to significantly minimize memory bottlenecks. Our implementation achieves two orders of magnitude speedup compared to multiple reference implementations running on NVIDIA A100 GPUs.",
        "published": "2023-04-21T23:41:22Z",
        "link": "http://arxiv.org/abs/2304.11274v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "lifex-cfd: an open-source computational fluid dynamics solver for   cardiovascular applications",
        "authors": [
            "Pasquale Claudio Africa",
            "Ivan Fumagalli",
            "Michele Bucelli",
            "Alberto Zingaro",
            "Marco Fedele",
            "Luca Dede'",
            "Alfio Quarteroni"
        ],
        "summary": "Computational fluid dynamics (CFD) is an important tool for the simulation of the cardiovascular function and dysfunction. Due to the complexity of the anatomy, the transitional regime of blood flow in the heart, and the strong mutual influence between the flow and the physical processes involved in the heart function, the development of accurate and efficient CFD solvers for cardiovascular flows is still a challenging task. In this paper we present lifex-cfd, an open-source CFD solver for cardiovascular simulations based on the lifex finite element library, written in modern C++ and exploiting distributed memory parallelism. We model blood flow in both physiological and pathological conditions via the incompressible Navier-Stokes equations, accounting for moving cardiac valves, moving domains, and transition-to-turbulence regimes. In this paper, we provide an overview of the underlying mathematical formulation, numerical discretization, implementation details and examples on how to use lifex-cfd. We verify the code through rigorous convergence analyses, and we show its almost ideal parallel speedup. We demonstrate the accuracy and reliability of the numerical methods implemented through a series of idealized and patient-specific vascular and cardiac simulations, in different physiological flow regimes. The lifex-cfd source code is available under the LGPLv3 license, to ensure its accessibility and transparency to the scientific community, and to facilitate collaboration and further developments.",
        "published": "2023-04-24T12:11:20Z",
        "link": "http://arxiv.org/abs/2304.12032v5",
        "categories": [
            "physics.flu-dyn",
            "cs.MS",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Exponentially Convergent Numerical Method for Abstract Cauchy Problem   with Fractional Derivative of Caputo Type",
        "authors": [
            "Dmytro Sytnyk",
            "Barbara Wohlmuth"
        ],
        "summary": "We present an exponentially convergent numerical method to approximate the solution of the Cauchy problem for the inhomogeneous fractional differential equation with an unbounded operator coefficient and Caputo fractional derivative in time. The numerical method is based on the newly obtained solution formula that consolidates the mild solution representations of sub-parabolic, parabolic and sub-hyperbolic equations with sectorial operator coefficient $A$ and non-zero initial data. The involved integral operators are approximated using the sinc-quadrature formulas that are tailored to the spectral parameters of $A$, fractional order $\\alpha$ and the smoothness of the first initial condition, as well as to the properties of the equation's right-hand side $f(t)$. The resulting method possesses exponential convergence for positive sectorial $A$, any finite $t$, including $t = 0$ and the whole range $\\alpha \\in (0,2)$. It is suitable for a practically important case, when no knowledge of $f(t)$ is available outside the considered interval $t \\in [0, T]$. The algorithm of the method is capable of multi-level parallelism. We provide numerical examples that confirm the theoretical error estimates.",
        "published": "2023-04-25T19:10:58Z",
        "link": "http://arxiv.org/abs/2304.13099v4",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "math.AP",
            "math.CA",
            "34A08, 35R11, 34G10, 35R20, 65L05, 65J08, 65J1"
        ]
    },
    {
        "title": "LLT: An R package for Linear Law-based Feature Space Transformation",
        "authors": [
            "Marcell T. Kurbucz",
            "Péter Pósfay",
            "Antal Jakovác"
        ],
        "summary": "The goal of the linear law-based feature space transformation (LLT) algorithm is to assist with the classification of univariate and multivariate time series. The presented R package, called LLT, implements this algorithm in a flexible yet user-friendly way. This package first splits the instances into training and test sets. It then utilizes time-delay embedding and spectral decomposition techniques to identify the governing patterns (called linear laws) of each input sequence (initial feature) within the training set. Finally, it applies the linear laws of the training set to transform the initial features of the test set. These steps are performed by three separate functions called trainTest, trainLaw, and testTrans. Their application requires a predefined data structure; however, for fast calculation, they use only built-in functions. The LLT R package and a sample dataset with the appropriate data structure are publicly available on GitHub.",
        "published": "2023-04-27T14:18:29Z",
        "link": "http://arxiv.org/abs/2304.14211v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.CV",
            "cs.MS",
            "stat.ML",
            "62H30, 68T10, 62M10, 60-04",
            "I.5; G.3; J.0; I.2.0"
        ]
    },
    {
        "title": "A framework for rigorous computational methods using Haar wavelets for   differential equations",
        "authors": [
            "Guilherme Nakassima",
            "Marcio Gameiro"
        ],
        "summary": "This work presents a framework for a-posteriori error-estimating algorithms for differential equations which combines the radii polynomial approach with Haar wavelets. By using Haar wavelets, we obtain recursive structures for the matrix representations of the differential operators and quadratic nonlinearities, which can be exploited for the radii polynomial method in order to get error estimates in the $L^2$ sense. This allows the method to be applicable when the system or solution is not continuous, which is a limitation of other radii-polynomial-based methods. Numerical examples show how the method is implemented in practice.",
        "published": "2023-04-27T21:08:17Z",
        "link": "http://arxiv.org/abs/2304.14536v1",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "math.DS",
            "34A34, 34L30, 65G20, 65H10, 65T60"
        ]
    },
    {
        "title": "Diddy: a Python toolbox for infinite discrete dynamical systems",
        "authors": [
            "Ville Salo",
            "Ilkka Törmä"
        ],
        "summary": "We introduce Diddy, a collection of Python scripts for analyzing infinite discrete dynamical systems. The main focus is on generalized multidimensional shifts of finite type (SFTs). We show how Diddy can be used to easily define SFTs and cellular automata, and analyze their basic properties. We also showcase how to verify or rediscover some results from coding theory and cellular automata theory.",
        "published": "2023-05-02T12:51:25Z",
        "link": "http://arxiv.org/abs/2305.01375v1",
        "categories": [
            "cs.MS",
            "cs.DM",
            "math.DS",
            "37-04"
        ]
    },
    {
        "title": "A Matrix-Free Newton Method",
        "authors": [
            "Uwe Naumann"
        ],
        "summary": "A modification of Newton's method for solving systems of $n$ nonlinear equations is presented. The new matrix-free method relies on a given decomposition of the invertible Jacobian of the residual into invertible sparse local Jacobians according to the chain rule of differentiation. It is motivated in the context of local Jacobians with bandwidth $2m+1$ for $m\\ll n$. A reduction of the computational cost by $\\mathcal{O}(\\frac{n}{m})$ can be observed. Supporting run time measurements are presented for the tridiagonal case showing a reduction of the computational cost by $\\mathcal{O}(n).$   Generalization yields the combinatorial Matrix-Free Newton Step problem. We prove NP-completeness and we present algorithmic components for building methods for the approximate solution. Inspired by adjoint Algorithmic Differentiation, the new method shares several challenges for the latter including the DAG Reversal problem. Further challenges are due to combinatorial problems in sparse linear algebra such as Bandwidth or Directed Elimination Ordering.",
        "published": "2023-05-02T14:40:13Z",
        "link": "http://arxiv.org/abs/2305.01669v2",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "49M15, 47A05, 68N99"
        ]
    },
    {
        "title": "Using Hierarchical Parallelism to Accelerate the Solution of Many Small   Partial Differential Equations",
        "authors": [
            "Jacob Merson",
            "Mark S. Shephard"
        ],
        "summary": "This paper presents efforts to improve the hierarchical parallelism of a two scale simulation code. Two methods to improve the GPU parallel performance were developed and compared. The first used the NVIDIA Multi-Process Service and the second moved the entire sub-problem loop into a single kernel using Kokkos hierarchical parallelism and a PackedView data structure. Both approaches improved parallel performance with the second method providing the greatest improvements.",
        "published": "2023-05-05T05:42:03Z",
        "link": "http://arxiv.org/abs/2305.07030v1",
        "categories": [
            "cs.DC",
            "cs.MS"
        ]
    },
    {
        "title": "NUBO: A Transparent Python Package for Bayesian Optimization",
        "authors": [
            "Mike Diessner",
            "Kevin J. Wilson",
            "Richard D. Whalley"
        ],
        "summary": "NUBO, short for Newcastle University Bayesian Optimization, is a Bayesian optimization framework for optimizing expensive-to-evaluate black-box functions, such as physical experiments and computer simulators. Bayesian optimization is a cost-efficient optimization strategy that uses surrogate modeling via Gaussian processes to represent an objective function and acquisition functions to guide the selection of candidate points to approximate the global optimum of the objective function. NUBO focuses on transparency and user experience to make Bayesian optimization accessible to researchers from all disciplines. Clean and understandable code, precise references, and thorough documentation ensure transparency, while a modular and flexible design, easy-to-write syntax, and careful selection of Bayesian optimization algorithms ensure a good user experience. NUBO allows users to tailor Bayesian optimization to their problem by writing a custom optimization loop using the provided building blocks. It supports sequential single-point, parallel multi-point, and asynchronous optimization of bounded, constrained, and mixed (discrete and continuous) parameter input spaces. Only algorithms and methods extensively tested and validated to perform well are included in NUBO. This ensures that the package remains compact and does not overwhelm the user with an unnecessarily large number of options. The package is written in Python but does not require expert knowledge of Python to optimize simulators and experiments. NUBO is distributed as open-source software under the BSD 3-Clause license.",
        "published": "2023-05-11T10:34:27Z",
        "link": "http://arxiv.org/abs/2305.06709v2",
        "categories": [
            "cs.LG",
            "cs.MS",
            "stat.ML"
        ]
    },
    {
        "title": "Power Grid Transient Analysis via Open-Source Circuit Simulator: A Case   Study of HVDC",
        "authors": [
            "Yongli Zhu",
            "Xiang Zhang",
            "Renchang Dai"
        ],
        "summary": "This paper proposes an electronic circuit simulator-based method to accelerate the power system transient simulation, where the modeling of a generic HVDC (High Voltage Direct Current) system is focused. The electronic circuit simulation equations and the backward differentiation formula for numerical solving are described. Then, the circuit modeling process for power system components such as slack bus, constant power load, and HVDC are respectively illustrated. Finally, a case study is conducted on a four-bus power system to demonstrate the effectiveness of the proposed modeling and simulation method.",
        "published": "2023-05-16T03:08:45Z",
        "link": "http://arxiv.org/abs/2305.09122v1",
        "categories": [
            "eess.SY",
            "cs.MS",
            "cs.SY",
            "math.DS"
        ]
    },
    {
        "title": "OpenLB User Guide: Associated with Release 1.6 of the Code",
        "authors": [
            "Adrian Kummerländer",
            "Samuel J. Avis",
            "Halim Kusumaatmaja",
            "Fedor Bukreev",
            "Michael Crocoll",
            "Davide Dapelo",
            "Simon Großmann",
            "Nicolas Hafen",
            "Shota Ito",
            "Julius Jeßberger",
            "Eliane Kummer",
            "Jan E. Marquardt",
            "Johanna Mödl",
            "Tim Pertzel",
            "František Prinz",
            "Florian Raichle",
            "Martin Sadric",
            "Maximilian Schecher",
            "Dennis Teutscher",
            "Stephan Simonis",
            "Mathias J. Krause"
        ],
        "summary": "OpenLB is an object-oriented implementation of LBM. It is the first implementation of a generic platform for LBM programming, which is shared with the open source community (GPLv2). Since the first release in 2007, the code has been continuously improved and extended which is documented by thirteen releases as well as the corresponding release notes which are available on the OpenLB website (https://www.openlb.net). The OpenLB code is written in C++ and is used by application programmers as well as developers, with the ability to implement custom models OpenLB supports complex data structures that allow simulations in complex geometries and parallel execution using MPI, OpenMP and CUDA on high-performance computers. The source code uses the concepts of interfaces and templates, so that efficient, direct and intuitive implementations of the LBM become possible. The efficiency and scalability has been checked and proved by code reviews. This user manual and a source code documentation by DoxyGen are available on the OpenLB project website.",
        "published": "2023-05-17T22:47:34Z",
        "link": "http://arxiv.org/abs/2307.11752v2",
        "categories": [
            "cs.MS",
            "cs.DC",
            "cs.NA",
            "math.NA",
            "97N80, 74S30, 76M25, 80M25, 82C80,",
            "G.4"
        ]
    },
    {
        "title": "Blendstrings: an environment for computing with smooth functions",
        "authors": [
            "Robert M. Corless"
        ],
        "summary": "A \"blendstring\" is a piecewise polynomial interpolant with high-degree two-point Hermite interpolational polynomials on each piece, analogous to a cubic spline. Blendstrings are smoother and can be more accurate than cubic splines, and can be used to represent smooth functions on a line segment or polygonal path in the complex plane. I sketch some properties of blendstrings, including efficient methods for evaluation, differentiation, and integration, as well as a prototype Maple implementation. Blendstrings can be differentiated and integrated exactly and can be combined algebraically. I also show applications of blendstrings to solving differential equations and computing Mathieu functions and generalized Mathieu eigenfunctions.",
        "published": "2023-05-18T16:03:32Z",
        "link": "http://arxiv.org/abs/2305.11076v1",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "65D15"
        ]
    },
    {
        "title": "CUQIpy: I. Computational uncertainty quantification for inverse problems   in Python",
        "authors": [
            "Nicolai A B Riis",
            "Amal M A Alghamdi",
            "Felipe Uribe",
            "Silja L Christensen",
            "Babak M Afkham",
            "Per Christian Hansen",
            "Jakob S Jørgensen"
        ],
        "summary": "This paper introduces CUQIpy, a versatile open-source Python package for computational uncertainty quantification (UQ) in inverse problems, presented as Part I of a two-part series. CUQIpy employs a Bayesian framework, integrating prior knowledge with observed data to produce posterior probability distributions that characterize the uncertainty in computed solutions to inverse problems. The package offers a high-level modeling framework with concise syntax, allowing users to easily specify their inverse problems, prior information, and statistical assumptions. CUQIpy supports a range of efficient sampling strategies and is designed to handle large-scale problems. Notably, the automatic sampler selection feature analyzes the problem structure and chooses a suitable sampler without user intervention, streamlining the process. With a selection of probability distributions, test problems, computational methods, and visualization tools, CUQIpy serves as a powerful, flexible, and adaptable tool for UQ in a wide selection of inverse problems. Part II of the series focuses on the use of CUQIpy for UQ in inverse problems with partial differential equations (PDEs).",
        "published": "2023-05-26T14:01:09Z",
        "link": "http://arxiv.org/abs/2305.16949v2",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "65R32, 65C20, 94A08, 65K10",
            "G.3; I.4; G.1.0"
        ]
    },
    {
        "title": "CUQIpy: II. Computational uncertainty quantification for PDE-based   inverse problems in Python",
        "authors": [
            "Amal M A Alghamdi",
            "Nicolai A B Riis",
            "Babak M Afkham",
            "Felipe Uribe",
            "Silja L Christensen",
            "Per Christian Hansen",
            "Jakob S Jørgensen"
        ],
        "summary": "Inverse problems, particularly those governed by Partial Differential Equations (PDEs), are prevalent in various scientific and engineering applications, and uncertainty quantification (UQ) of solutions to these problems is essential for informed decision-making. This second part of a two-paper series builds upon the foundation set by the first part, which introduced CUQIpy, a Python software package for computational UQ in inverse problems using a Bayesian framework. In this paper, we extend CUQIpy's capabilities to solve PDE-based Bayesian inverse problems through a general framework that allows the integration of PDEs in CUQIpy, whether expressed natively or using third-party libraries such as FEniCS. CUQIpy offers concise syntax that closely matches mathematical expressions, streamlining the modeling process and enhancing the user experience. The versatility and applicability of CUQIpy to PDE-based Bayesian inverse problems are demonstrated on examples covering parabolic, elliptic and hyperbolic PDEs. This includes problems involving the heat and Poisson equations and application case studies in electrical impedance tomography and photo-acoustic tomography, showcasing the software's efficiency, consistency, and intuitive interface. This comprehensive approach to UQ in PDE-based inverse problems provides accessibility for non-experts and advanced features for experts.",
        "published": "2023-05-26T14:03:04Z",
        "link": "http://arxiv.org/abs/2305.16951v2",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "65R32, 65C20, 94A08, 65K10, 65M32",
            "G.3; G.1.8"
        ]
    },
    {
        "title": "Accelerating 128-bit Floating-Point Matrix Multiplication on FPGAs",
        "authors": [
            "Fumiya Kono",
            "Naohito Nakasato",
            "Maho Nakata"
        ],
        "summary": "General Matrix Multiplication (GEMM) is a fundamental operation widely used in scientific computations. Its performance and accuracy significantly impact the performance and accuracy of applications that depend on it. One such application is semidefinite programming (SDP), and it often requires binary128 or higher precision arithmetic to solve problems involving SDP stably. However, only some processors support binary128 arithmetic, which makes SDP solvers generally slow. In this study, we focused on accelerating GEMM with binary128 arithmetic on field-programmable gate arrays (FPGAs) to enable the flexible design of accelerators for the desired computations. Our binary128 GEMM designs on a recent high-performance FPGA achieved approximately 90GFlops, 147x faster than the computation executed on a recent CPU with 20 threads for large matrices. Using our binary128 GEMM design on the FPGA, we successfully accelerated two numerical applications: LU decomposition and SDP problems, for the first time.",
        "published": "2023-06-07T01:16:50Z",
        "link": "http://arxiv.org/abs/2306.04087v1",
        "categories": [
            "cs.DC",
            "cs.AR",
            "cs.MS",
            "cs.PF",
            "math.OC"
        ]
    },
    {
        "title": "Comparison of SeDuMi and SDPT3 Solvers for Stability of Continuous-time   Linear System",
        "authors": [
            "Guangda Xu"
        ],
        "summary": "SeDuMi and SDPT3 are two solvers for solving Semi-definite Programming (SDP) or Linear Matrix Inequality (LMI) problems. A computational performance comparison of these two are undertaken in this paper regarding the Stability of Continuous-time Linear Systems. The comparison mainly focuses on computational times and memory requirements for different scales of problems. To implement and compare the two solvers on a set of well-posed problems, we employ YALMIP, a widely used toolbox for modeling and optimization in MATLAB. The primary goal of this study is to provide an empirical assessment of the relative computational efficiency of SeDuMi and SDPT3 under varying problem conditions. Our evaluation indicates that SDPT3 performs much better in large-scale, high-precision calculations.",
        "published": "2023-06-07T15:40:15Z",
        "link": "http://arxiv.org/abs/2306.04531v1",
        "categories": [
            "math.OC",
            "cs.MS",
            "cs.PF",
            "68N30 (Primary) 90C22 (Secondary)",
            "G.4"
        ]
    },
    {
        "title": "Extending JumpProcess.jl for fast point process simulation with   time-varying intensities",
        "authors": [
            "Guilherme Augusto Zagatti",
            "Samuel A. Isaacson",
            "Christopher Rackauckas",
            "Vasily Ilin",
            "See-Kiong Ng",
            "Stéphane Bressan"
        ],
        "summary": "Point processes model the occurrence of a countable number of random points over some support. They can model diverse phenomena, such as chemical reactions, stock market transactions and social interactions. We show that JumpProcesses.jl is a fast, general-purpose library for simulating point processes. JumpProcesses.jl was first developed for simulating jump processes via stochastic simulation algorithms (SSAs) (including Doob's method, Gillespie's methods, and Kinetic Monte Carlo methods). Historically, jump processes have been developed in the context of dynamical systems to describe dynamics with discrete jumps. In contrast, the development of point processes has been more focused on describing the occurrence of random events. In this paper, we bridge the gap between the treatment of point and jump process simulation. The algorithms previously included in JumpProcesses.jl can be mapped to three general methods developed in statistics for simulating evolutionary point processes. Our comparative exercise revealed that the library initially lacked an efficient algorithm for simulating processes with variable intensity rates. We, therefore, extended JumpProcesses.jl with a new simulation algorithm, Coevolve, that enables the rapid simulation of processes with locally-bounded variable intensity rates. It is now possible to efficiently simulate any point process on the real line with a non-negative, left-continuous, history-adapted and locally bounded intensity rate coupled or not with differential equations. This extension significantly improves the computational performance of JumpProcesses.jl when simulating such processes, enabling it to become one of the few readily available, fast, general-purpose libraries for simulating evolutionary point processes.",
        "published": "2023-06-12T09:39:20Z",
        "link": "http://arxiv.org/abs/2306.06992v3",
        "categories": [
            "stat.CO",
            "cs.MS",
            "60G55",
            "G.3; G.4"
        ]
    },
    {
        "title": "A new open source framework for multiscale modeling of fibrous materials   on heterogeneous supercomputers",
        "authors": [
            "Jacob Merson",
            "Catalin Picu",
            "Mark S. Shephard"
        ],
        "summary": "This article presents MuMFiM, an open source application for multiscale modeling of fibrous materials on massively parallel computers. MuMFiM uses two scales to represent fibrous materials such as biological network materials (extracellular matrix, connective tissue, etc.). It is designed to make use of multiple levels of parallelism, including distributed parallelism of the macro and microscales as well as GPU accelerated data-parallelism of the microscale. Scaling results of the GPU accelerated microscale show that solving microscale problems concurrently on the GPU can lead to a 1000x speedup over the solution of a single RVE on the GPU. In addition, we show nearly optimal strong and weak scaling results of MuMFiM on up to 128 nodes of AiMOS (Rensselaer Polytechnic Institute) which is composed of IBM AC922 nodes with 6 Volta V100 GPU and 2 20 core Power 9 CPUs each. We also show how MuMFiM can be used to solve problems of interest to the broader engineering community, in particular providing an example of the facet capsule ligament (FCL) of the human spine undergoing uniaxial extension.",
        "published": "2023-06-15T18:21:02Z",
        "link": "http://arxiv.org/abs/2306.09427v2",
        "categories": [
            "cs.DC",
            "cs.MS"
        ]
    },
    {
        "title": "Calculating the matrix profile from noisy data",
        "authors": [
            "Colin Hehir",
            "Alan F. Smeaton"
        ],
        "summary": "The matrix profile (MP) is a data structure computed from a time series which encodes the data required to locate motifs and discords, corresponding to recurring patterns and outliers respectively. When the time series contains noisy data then the conventional approach is to pre-filter it in order to remove noise but this cannot apply in unsupervised settings where patterns and outliers are not annotated. The resilience of the algorithm used to generate the MP when faced with noisy data remains unknown. We measure the similarities between the MP from original time series data with MPs generated from the same data with noisy data added under a range of parameter settings including adding duplicates and adding irrelevant data. We use three real world data sets drawn from diverse domains for these experiments Based on dissimilarities between the MPs, our results suggest that MP generation is resilient to a small amount of noise being introduced into the data but as the amount of noise increases this resilience disappears",
        "published": "2023-06-16T19:41:07Z",
        "link": "http://arxiv.org/abs/2306.10151v1",
        "categories": [
            "cs.LG",
            "cs.MS",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "From array algebra to energy efficiency on GPUs: Data and hardware   shapes with dimension-lifting to optimize memory-processor layouts",
        "authors": [
            "Lenore M. R. Mullin"
        ],
        "summary": "We present a new formulation for parallel matrix multiplication (MM) to out-perform the standard row-column code design. This algorithm is formulated in the MoA formalism (A Mathematics of Arrays) and combines an array view of hardware (dimension-lifting) to extend indexing to physical memory/processing units, with a contiguous data layout derived from static transformations. This view of a hardware-software model is thus a bridging model in the sense of Valiant's BSP. OpenACCcode was derived from the MoA expressions's normal form, producing optimal block sizes using the static information of types and shapes. Experiments were run on Nvidia V100 GPUs and reveal energy consumption which is quadratic in N, i.e. linear in the size of matrix. More generally this approach may be an ideal way of formulating, optimizing, and mapping array algorithms to embedded hardware. This work builds upon recently published results of NREL scientists.   .",
        "published": "2023-06-19T20:10:23Z",
        "link": "http://arxiv.org/abs/2306.11148v1",
        "categories": [
            "cs.DC",
            "cs.MS"
        ]
    },
    {
        "title": "An algorithm to approximate the real trilogarithm for a real argument",
        "authors": [
            "Alexander Voigt"
        ],
        "summary": "We present an algorithm to approximate the real trilogarithm for a real argument with IEEE 754-1985 double precision accuracy. The approximation is structured such that it can make use of instruction-level parallelism when executed on appropriate CPUs.",
        "published": "2023-06-21T15:53:14Z",
        "link": "http://arxiv.org/abs/2308.11619v2",
        "categories": [
            "cs.MS",
            "cs.NA",
            "hep-ph",
            "math.NA",
            "33-04, 33E20, 33F05, 65D20"
        ]
    },
    {
        "title": "SparseOptimizer: Sparsify Language Models through Moreau-Yosida   Regularization and Accelerate via Compiler Co-design",
        "authors": [
            "Fu-Ming Guo"
        ],
        "summary": "This paper introduces SparseOptimizer, a novel deep learning optimizer that exploits Moreau-Yosida regularization to naturally induce sparsity in large language models such as BERT, ALBERT and GPT. Key to the design of SparseOptimizer is an embedded shrinkage operator, which imparts sparsity directly within the optimization process. This operator, backed by a sound theoretical framework, includes an analytical solution, thereby reinforcing the optimizer's robustness and efficacy. Crucially, SparseOptimizer's plug-and-play functionality eradicates the need for code modifications, making it a universally adaptable tool for a wide array of large language models. Empirical evaluations on benchmark datasets such as GLUE, RACE, SQuAD1, and SQuAD2 confirm that SparseBERT and SparseALBERT, when sparsified using SparseOptimizer, achieve performance comparable to their dense counterparts, BERT and ALBERT, while significantly reducing their parameter count. Further, this work proposes an innovative optimizer-compiler co-design strategy, demonstrating the potential of inference acceleration (\\textbf{3.37x}, \\textbf{6.30x}, and \\textbf{7.15x} in comparison with Pytorch, TensorFlow, and LLVM generic compile, respectively) in SparseBERT when paired with an appropriately designed compiler. This study represents a significant step forward in the evolution of efficient, scalable, and high-performing large language models, setting a precedent for future exploration and optimization in this domain. The SparseOptimizer code and SparseALBERT model will be publicly available upon paper acceptance.",
        "published": "2023-06-27T17:50:26Z",
        "link": "http://arxiv.org/abs/2306.15656v3",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.CC",
            "cs.CL",
            "cs.MS"
        ]
    },
    {
        "title": "Collective-Optimized FFTs",
        "authors": [
            "Evelyn Namugwanya",
            "Amanda Bienz",
            "Derek Schafer",
            "Anthony Skjellum"
        ],
        "summary": "This paper measures the impact of the various alltoallv methods. Results are analyzed within Beatnik, a Z-model solver that is bottlenecked by HeFFTe and representative of applications that rely on FFTs.",
        "published": "2023-06-28T22:41:14Z",
        "link": "http://arxiv.org/abs/2306.16589v2",
        "categories": [
            "cs.MS",
            "cs.PF"
        ]
    },
    {
        "title": "SYCL compute kernels for ExaHyPE",
        "authors": [
            "Chung Ming Loi",
            "Heinrich Bockhorst",
            "Tobias Weinzierl"
        ],
        "summary": "We discuss three SYCL realisations of a simple Finite Volume scheme over multiple Cartesian patches. The realisation flavours differ in the way how they map the compute steps onto loops and tasks: We compare an implementation that is exclusively using a sequence of for-loops to a version that uses nested parallelism, and finally benchmark these against a version modelling the calculations as task graph. Our work proposes realisation idioms to realise these flavours within SYCL. The results suggest that a mixture of classic task and data parallelism performs if we map this hybrid onto a solely data-parallel SYCL implementation, taking into account SYCL specifics and the problem size.",
        "published": "2023-06-29T07:14:17Z",
        "link": "http://arxiv.org/abs/2306.16731v5",
        "categories": [
            "cs.MS",
            "cs.DC"
        ]
    },
    {
        "title": "Rigorous Function Calculi in Ariadne",
        "authors": [
            "Pieter Collins",
            "Luca Geretti",
            "Sanja Zivanovic Gonzalez",
            "Davide Bresolin",
            "Tiziano Villa"
        ],
        "summary": "Almost all problems in applied mathematics, including the analysis of dynamical systems, deal with spaces of real-valued functions on Euclidean domains in their formulation and solution. In this paper, we describe the the tool Ariadne, which provides a rigorous calculus for working with Euclidean functions. We first introduce the Ariadne framework, which is based on a clean separation of objects as providing exact, effective, validated and approximate information. We then discuss the function calculus as implemented in \\Ariadne, including polynomial function models which are the fundamental class for concrete computations. We then consider solution of some core problems of functional analysis, namely solution of algebraic equations and differential equations, and briefly discuss their use for the analysis of hybrid systems. We will give examples of C++ and Python code for performing the various calculations. Finally, we will discuss progress on extensions, including improvements to the function calculus and extensions to more complicated classes of system.",
        "published": "2023-06-30T10:53:27Z",
        "link": "http://arxiv.org/abs/2306.17541v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "Towards a Benchmark Framework for Model Order Reduction in the   Mathematical Research Data Initiative (MaRDI)",
        "authors": [
            "Peter Benner",
            "Kathryn Lund",
            "Jens Saak"
        ],
        "summary": "The race for the most efficient, accurate, and universal algorithm in scientific computing drives innovation. At the same time, this healthy competition is only beneficial if the research output is actually comparable to prior results. Fairly comparing algorithms can be a complex endeavor, as the implementation, configuration, compute environment, and test problems need to be well-defined. Due to the increase in computer-based experiments, new infrastructure for facilitating the exchange and comparison of new algorithms is also needed. To this end, we propose a benchmark framework, as a set of generic specifications for comparing implementations of algorithms using test cases native to a community. Its value lies in its ability to fairly compare and validate existing methods for new applications, as well as compare newly developed methods with existing ones. As a prototype for a more general framework, we have begun building a benchmark tool for the model order reduction (MOR) community. The data basis of the tool is the collection of the Model Order Reduction Wiki (MORWiki). The wiki features three main categories: benchmarks, methods, and software. An editorial board curates submissions and patrols edited entries. Data sets for linear and parametric-linear models are already well represented in the existing collection. Data sets for non-linear or procedural models, for which only evaluation data, or codes / algorithmic descriptions, rather than equations, are available, are being added and extended. Properties and interesting characteristics used for benchmark selection and later assessments are recorded in the model metadata. Our tool, the Model Order Reduction Benchmarker (MORB) is under active development for linear time-invariant systems and solvers.",
        "published": "2023-06-30T21:05:58Z",
        "link": "http://arxiv.org/abs/2307.00137v1",
        "categories": [
            "cs.MS",
            "65-04, 93-04, 93-11, 93C05"
        ]
    },
    {
        "title": "SpComp: A Sparsity Structure-Specific Compilation of Matrix Operations",
        "authors": [
            "Barnali Basak",
            "Uday P. Khedker",
            "Supratim Biswas"
        ],
        "summary": "Sparse matrix operations involve a large number of zero operands which makes most of the operations redundant. The amount of redundancy magnifies when a matrix operation repeatedly executes on sparse data. Optimizing matrix operations for sparsity involves either reorganization of data or reorganization of computations, performed either at compile-time or run-time. Although compile-time techniques avert from introducing run-time overhead, their application either is limited to simple sparse matrix operations generating dense output and handling immutable sparse matrices or requires manual intervention to customize the technique to different matrix operations. We contribute a compile time technique called SpComp that optimizes a sparse matrix operation by automatically customizing its computations to the positions of non-zero values of the data. Our approach neither incurs any run-time overhead nor requires any manual intervention. It is also applicable to complex matrix operations generating sparse output and handling mutable sparse matrices. We introduce a data-flow analysis, named Essential Indices Analysis, that statically collects the symbolic information about the computations and helps the code generator to reorganize the computations. The generated code includes piecewise-regular loops, free from indirect references and amenable to further optimization. We see a substantial performance gain by SpComp-generated SpMSpV code when compared against the state-of-the-art TACO compiler and piecewise-regular code generator. On average, we achieve 79% performance gain against TACO and 83% performance gain against the piecewise-regular code generator. When compared against the CHOLMOD library, SpComp generated sparse Cholesky decomposition code showcases 65% performance gain on average.",
        "published": "2023-07-04T12:44:28Z",
        "link": "http://arxiv.org/abs/2307.06109v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "RamanSPy: An open-source Python package for integrative Raman   spectroscopy data analysis",
        "authors": [
            "Dimitar Georgiev",
            "Simon Vilms Pedersen",
            "Ruoxiao Xie",
            "Álvaro Fernández-Galiana",
            "Molly M. Stevens",
            "Mauricio Barahona"
        ],
        "summary": "Raman spectroscopy is a non-destructive and label-free chemical analysis technique, which plays a key role in the analysis and discovery cycle of various branches of science. Nonetheless, progress in Raman spectroscopic analysis is still impeded by the lack of software, methodological and data standardisation, and the ensuing fragmentation and lack of reproducibility of analysis workflows thereof. To address these issues, we introduce RamanSPy, an open-source Python package for Raman spectroscopic research and analysis. RamanSPy provides a comprehensive library of ready-to-use tools for spectroscopic analysis, which streamlines day-to-day tasks, integrative analyses, as well as novel research and algorithmic development. RamanSPy is modular and open source, not tied to a particular technology or data format, and can be readily interfaced with the burgeoning ecosystem for data science, statistical analysis and machine learning in Python.",
        "published": "2023-07-05T08:56:45Z",
        "link": "http://arxiv.org/abs/2307.13650v1",
        "categories": [
            "cond-mat.mtrl-sci",
            "cs.MS",
            "physics.data-an"
        ]
    },
    {
        "title": "Scylla: a matrix-free fix-propagate-and-project heuristic for   mixed-integer optimization",
        "authors": [
            "Gioni Mexi",
            "Mathieu Besançon",
            "Suresh Bolusani",
            "Antonia Chmiela",
            "Alexander Hoen",
            "Ambros Gleixner"
        ],
        "summary": "We introduce Scylla, a primal heuristic for mixed-integer optimization problems. It exploits approximate solves of the Linear Programming relaxations through the matrix-free Primal-Dual Hybrid Gradient algorithm with specialized termination criteria, and derives integer-feasible solutions via fix-and-propagate procedures and feasibility-pump-like updates to the objective function. Computational experiments show that the method is particularly suited to instances with hard linear relaxations.",
        "published": "2023-07-07T09:00:14Z",
        "link": "http://arxiv.org/abs/2307.03466v2",
        "categories": [
            "math.OC",
            "cs.MS"
        ]
    },
    {
        "title": "SigOpt Mulch: An Intelligent System for AutoML of Gradient Boosted Trees",
        "authors": [
            "Aleksei Sorokin",
            "Xinran Zhu",
            "Eric Hans Lee",
            "Bolong Cheng"
        ],
        "summary": "Gradient boosted trees (GBTs) are ubiquitous models used by researchers, machine learning (ML) practitioners, and data scientists because of their robust performance, interpretable behavior, and ease-of-use. One critical challenge in training GBTs is the tuning of their hyperparameters. In practice, selecting these hyperparameters is often done manually. Recently, the ML community has advocated for tuning hyperparameters through black-box optimization and developed state-of-the-art systems to do so. However, applying such systems to tune GBTs suffers from two drawbacks. First, these systems are not \\textit{model-aware}, rather they are designed to apply to a \\textit{generic} model; this leaves significant optimization performance on the table. Second, using these systems requires \\textit{domain knowledge} such as the choice of hyperparameter search space, which is an antithesis to the automatic experimentation that black-box optimization aims to provide. In this paper, we present SigOpt Mulch, a model-aware hyperparameter tuning system specifically designed for automated tuning of GBTs that provides two improvements over existing systems. First, Mulch leverages powerful techniques in metalearning and multifidelity optimization to perform model-aware hyperparameter optimization. Second, it automates the process of learning performant hyperparameters by making intelligent decisions about the optimization search space, thus reducing the need for user domain knowledge. These innovations allow Mulch to identify good GBT hyperparameters far more efficiently -- and in a more seamless and user-friendly way -- than existing black-box hyperparameter tuning systems.",
        "published": "2023-07-10T18:40:25Z",
        "link": "http://arxiv.org/abs/2307.04849v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MS"
        ]
    },
    {
        "title": "Minimum Cost Loop Nests for Contraction of a Sparse Tensor with a Tensor   Network",
        "authors": [
            "Raghavendra Kanakagiri",
            "Edgar Solomonik"
        ],
        "summary": "Sparse tensor decomposition and completion are common in numerous applications, ranging from machine learning to computational quantum chemistry. Typically, the main bottleneck in optimization of these models are contractions of a single large sparse tensor with a network of several dense matrices or tensors (SpTTN). Prior works on high-performance tensor decomposition and completion have focused on performance and scalability optimizations for specific SpTTN kernels. We present algorithms and a runtime system for identifying and executing the most efficient loop nest for any SpTTN kernel. We consider both enumeration of such loop nests for autotuning and efficient algorithms for finding the lowest cost loop-nest for simpler metrics, such as buffer size or cache miss models. Our runtime system identifies the best choice of loop nest without user guidance, and also provides a distributed-memory parallelization of SpTTN kernels. We evaluate our framework using both real-world and synthetic tensors. Our results demonstrate that our approach outperforms available generalized state-of-the-art libraries and matches the performance of specialized codes.",
        "published": "2023-07-11T19:08:06Z",
        "link": "http://arxiv.org/abs/2307.05740v2",
        "categories": [
            "cs.DC",
            "cs.MS",
            "cs.PF",
            "cs.PL",
            "G.1.3; D.1.3"
        ]
    },
    {
        "title": "Differentiable Forward Projector for X-ray Computed Tomography",
        "authors": [
            "Hyojin Kim",
            "Kyle Champley"
        ],
        "summary": "Data-driven deep learning has been successfully applied to various computed tomographic reconstruction problems. The deep inference models may outperform existing analytical and iterative algorithms, especially in ill-posed CT reconstruction. However, those methods often predict images that do not agree with the measured projection data. This paper presents an accurate differentiable forward and back projection software library to ensure the consistency between the predicted images and the original measurements. The software library efficiently supports various projection geometry types while minimizing the GPU memory footprint requirement, which facilitates seamless integration with existing deep learning training and inference pipelines. The proposed software is available as open source: https://github.com/LLNL/LEAP.",
        "published": "2023-07-11T20:52:46Z",
        "link": "http://arxiv.org/abs/2307.05801v1",
        "categories": [
            "cs.LG",
            "cs.CV",
            "cs.MS"
        ]
    },
    {
        "title": "AsaPy: A Python Library for Aerospace Simulation Analysis",
        "authors": [
            "Joao P. A. Dantas",
            "Samara R. Silva",
            "Vitor C. F. Gomes",
            "Andre N. Costa",
            "Adrisson R. Samersla",
            "Diego Geraldo",
            "Marcos R. O. A. Maximo",
            "Takashi Yoneyama"
        ],
        "summary": "AsaPy is a custom-made Python library designed to simplify and optimize the analysis of aerospace simulation data. Instead of introducing new methodologies, it excels in combining various established techniques, creating a unified, specialized platform. It offers a range of features, including the design of experiment methods, statistical analysis techniques, machine learning algorithms, and data visualization tools. AsaPy's flexibility and customizability make it a viable solution for engineers and researchers who need to quickly gain insights into aerospace simulations. AsaPy is built on top of popular scientific computing libraries, ensuring high performance and scalability. In this work, we provide an overview of the key features and capabilities of AsaPy, followed by an exposition of its architecture and demonstrations of its effectiveness through some use cases applied in military operational simulations. We also evaluate how other simulation tools deal with data science, highlighting AsaPy's strengths and advantages. Finally, we discuss potential use cases and applications of AsaPy and outline future directions for the development and improvement of the library.",
        "published": "2023-07-12T00:02:37Z",
        "link": "http://arxiv.org/abs/2310.00001v2",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "Integrating Enzyme-generated functions into CoDiPack",
        "authors": [
            "M. Sagebaum",
            "M. Aehle",
            "N. R. Gauger"
        ],
        "summary": "In operator overloading algorithmic differentiation, it can be beneficial to create custom derivative functions for some parts of the code base. For manual implementations of the derivative functions, it can be quite cumbersome to derive, implement, test, and maintain these. The process can be automated with source transformation algorithmic differentiation tools like Tapenade or compiler-based algorithmic differentiation tools like Enzyme. This eliminates most of the work required from a manual implementation but usually has the same efficiency with respect to timing and memory. We present a new helper in CoDiPack that allows Enzyme-generated derivative functions to be automatically added during the recording process of CoDiPack. The validity of the approach is demonstrated on a synthetic benchmark, which shows promising results.",
        "published": "2023-07-12T10:53:02Z",
        "link": "http://arxiv.org/abs/2307.06075v1",
        "categories": [
            "cs.MS",
            "65D25 (Primary), 68N30 (Secondary)",
            "G.1.4; G.4; D.2.2"
        ]
    },
    {
        "title": "A framework to test interval arithmetic libraries and their IEEE   1788-2015 compliance",
        "authors": [
            "Luis Benet",
            "Luca Ferranti",
            "Nathalie Revol"
        ],
        "summary": "As developers of libraries implementing interval arithmetic, we faced the same difficulties when it comes to testing our libraries. What must be tested? How can we devise relevant test cases for unit testing? How can we ensure a high (and possibly 100%) test coverage? Before considering these questions, we briefly recall the main features of interval arithmetic and of the IEEE 1788-2015 standard for interval arithmetic. After listing the different aspects that, in our opinion, must be tested, we contribute a first step towards offering a test suite for an interval arithmetic library. First we define a format that enables the exchange of test cases, so that they can be read and tried easily. Then we offer a first set of test cases, for a selected set of mathematical functions. Next, we examine how the Julia interval arithmetic library, IntervalArithmetic.jl, actually performs to these tests. As this is an ongoing work, we list extra tests that we deem important to perform.",
        "published": "2023-07-12T19:48:29Z",
        "link": "http://arxiv.org/abs/2307.06953v1",
        "categories": [
            "cs.MS",
            "65G99",
            "G.0"
        ]
    },
    {
        "title": "scda: A Minimal, Serial-Equivalent Format for Parallel I/O",
        "authors": [
            "Tim Griesbach",
            "Carsten Burstedde"
        ],
        "summary": "We specify a file-oriented data format suitable for parallel, partition-independent disk I/O. Here, a partition refers to a disjoint and ordered distribution of the data elements between one or more processes. The format is designed such that the file contents are invariant under linear (i. e., unpermuted), parallel repartition of the data prior to writing. The file contents are indistinguishable from writing in serial. In the same vein, the file can be read on any number of processes that agree on any partition of the number of elements stored.   In addition to the format specification we propose an optional convention to implement transparent per-element data compression. The compressed data and metadata is layered inside ordinary format elements. Overall, we pay special attention to both human and machine readability. If pure ASCII data is written, or compressed data is reencoded to ASCII, the entire file including its header and sectioning metadata remains entirely in ASCII. If binary data is written, the metadata stays easy on the human eye.   We refer to this format as scda. Conceptually, it lies one layer below and is oblivious to the definition of variables, the binary representation of numbers, considerations of endianness, and self-describing headers, which may all be specified on top of scda. The main purpose of the format is to abstract any parallelism and provide sufficient structure as a foundation for a generic and flexible archival and checkpoint/restart. A documented reference implementation is available as part of the general-purpose libsc free software library.",
        "published": "2023-07-13T14:59:22Z",
        "link": "http://arxiv.org/abs/2307.06789v1",
        "categories": [
            "cs.DC",
            "cs.MS",
            "H.3.2; I.6.7; G.4"
        ]
    },
    {
        "title": "ProtoX: A First Look",
        "authors": [
            "Het Mankad",
            "Sanil Rao",
            "Brian Van Straalen",
            "Phillip Colella",
            "Franz Franchetti"
        ],
        "summary": "We present a first look at ProtoX, a code generation framework for stencil and pointwise operations that occur frequently in the numerical solution of partial differential equations. ProtoX has Proto as its library frontend and SPIRAL as the backend. Proto is a C++ based domain specific library which optimizes the algorithms used to compute the numerical solution of partial differential equations. Meanwhile, SPIRAL is a code generation system that focuses on generating highly optimized target code. Although the current design layout of Proto and its high level of abstractions provide a user friendly set up, there is still a room for improving it's performance by applying various techniques either at a compiler level or at an algorithmic level. Hence, in this paper we propose adding SPIRAL as the library backend for Proto enabling abstraction fusion, which is usually difficult to perform by any compiler. We demonstrate the construction of ProtoX by considering the 2D Poisson equation as a model problem from Proto. We provide the final generated code for CPU, Multi-core CPU, and GPU as well as some performance numbers for CPU.",
        "published": "2023-07-16T03:33:19Z",
        "link": "http://arxiv.org/abs/2307.07931v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "MindOpt Tuner: Boost the Performance of Numerical Software by Automatic   Parameter Tuning",
        "authors": [
            "Mengyuan Zhang",
            "Wotao Yin",
            "Mengchang Wang",
            "Yangbin Shen",
            "Peng Xiang",
            "You Wu",
            "Liang Zhao",
            "Junqiu Pan",
            "Hu Jiang",
            "KuoLing Huang"
        ],
        "summary": "Numerical software is usually shipped with built-in hyperparameters. By carefully tuning those hyperparameters, significant performance enhancements can be achieved for specific applications. We developed MindOpt Tuner, a new automatic tuning tool that supports a wide range of numerical software, including optimization and other solvers. MindOpt Tuner uses elastic cloud resources, features a web-based task management panel and integration with ipython notebook with both command-line tools and Python APIs. Our experiments with COIN-OR Cbc, an open-source mixed-integer optimization solver, demonstrate remarkable improvements with the tuned parameters compared to the default ones on the MIPLIB2017 test set, resulting in over 100x acceleration on several problem instances. Additionally, the results demonstrate that Tuner has a higher tuning efficiency compared to the state-of-the-art automatic tuning tool SMAC3.",
        "published": "2023-07-16T15:57:25Z",
        "link": "http://arxiv.org/abs/2307.08085v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "An R package for parametric estimation of causal effects",
        "authors": [
            "Joshua Wolff Anderson",
            "Cyril Rakovski"
        ],
        "summary": "This article explains the usage of R package CausalModels, which is publicly available on the Comprehensive R Archive Network. While packages are available for sufficiently estimating causal effects, there lacks a package that provides a collection of structural models using the conventional statistical approach developed by Hernan and Robins (2020). CausalModels addresses this deficiency of software in R concerning causal inference by offering tools for methods that account for biases in observational data without requiring extensive statistical knowledge. These methods should not be ignored and may be more appropriate or efficient in solving particular problems. While implementations of these statistical models are distributed among a number of causal packages, CausalModels introduces a simple and accessible framework for a consistent modeling pipeline among a variety of statistical methods for estimating causal effects in a single R package. It consists of common methods including standardization, IP weighting, G-estimation, outcome regression, instrumental variables and propensity matching.",
        "published": "2023-07-17T17:47:50Z",
        "link": "http://arxiv.org/abs/2307.08686v2",
        "categories": [
            "stat.ME",
            "cs.LG",
            "cs.MS",
            "stat.AP"
        ]
    },
    {
        "title": "Automatic Conversion of MiniZinc Programs to QUBO",
        "authors": [
            "Armin Wolf",
            "Cristian Grozea"
        ],
        "summary": "Obtaining Quadratic Unconstrained Binary Optimisation models for various optimisation problems, in order to solve those on physical quantum computers (such as the the DWave annealers) is nowadays a lengthy and tedious process that requires one to remodel all problem variables as binary variables and squeeze the target function and the constraints into a single quadratic polynomial into these new variables.   We report here on the basis of our automatic converter from MiniZinc to QUBO, which is able to process a large set of constraint optimisation and constraint satisfaction problems and turn them into equivalent QUBOs, effectively optimising the whole process.",
        "published": "2023-07-19T15:16:01Z",
        "link": "http://arxiv.org/abs/2307.10032v1",
        "categories": [
            "cs.MS",
            "cs.AI"
        ]
    },
    {
        "title": "GPU-accelerated Parallel Solutions to the Quadratic Assignment Problem",
        "authors": [
            "Clara Novoa",
            "Apan Qasem"
        ],
        "summary": "The Quadratic Assignment Problem (QAP) is an important combinatorial optimization problem with applications in many areas including logistics and manufacturing. QAP is known to be NP-hard, a computationally challenging problem, which requires the use of sophisticated heuristics in finding acceptable solutions for most real-world data sets.   In this paper, we present GPU-accelerated implementations of a 2opt and a tabu search algorithm for solving the QAP. For both algorithms, we extract parallelism at multiple levels and implement novel code optimization techniques that fully utilize the GPU hardware. On a series of experiments on the well-known QAPLIB data sets, our solutions, on average run an order-of-magnitude faster than previous implementations and deliver up to a factor of 63 speedup on specific instances. The quality of the solutions produced by our implementations of 2opt and tabu is within 1.03% and 0.15% of the best known values. The experimental results also provide key insight into the performance characteristics of accelerated QAP solvers. In particular, the results reveal that both algorithmic choice and the shape of the input data sets are key factors in finding efficient implementations.",
        "published": "2023-07-20T21:38:52Z",
        "link": "http://arxiv.org/abs/2307.11248v1",
        "categories": [
            "cs.DC",
            "cs.MS"
        ]
    },
    {
        "title": "Leveraging MLIR for Loop Vectorization and GPU Porting of FFT Libraries",
        "authors": [
            "Yifei He",
            "Artur Podobas",
            "Stefano Markidis"
        ],
        "summary": "FFTc is a Domain-Specific Language (DSL) for designing and generating Fast Fourier Transforms (FFT) libraries. The FFTc uniqueness is that it leverages and extend Multi-Level Intermediate Representation (MLIR) dialects to optimize FFT code generation. In this work, we present FFTc extensions and improvements such as the possibility of using different data layout for complex-value arrays, and sparsification to enable efficient vectorization, and a seamless porting of FFT libraries to GPU systems. We show that, on CPUs, thanks to vectorization, the performance of the FFTc-generated FFT is comparable to performance of FFTW, a state-of-the-art FFT libraries. We also present the initial performance results for FFTc on Nvidia GPUs.",
        "published": "2023-08-01T12:32:26Z",
        "link": "http://arxiv.org/abs/2308.00497v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "PyPartMC: A Pythonic interface to a particle-resolved, Monte Carlo   aerosol simulation framework",
        "authors": [
            "Zachary D'Aquino",
            "Sylwester Arabas",
            "Jeffrey Curtis",
            "Akshunna Vaishnav",
            "Nicole Riemer",
            "Matthew West"
        ],
        "summary": "PyPartMC is a Pythonic interface to PartMC, a stochastic, particle-resolved aerosol model implemented in Fortran. Both PyPartMC and PartMC are free, libre, and open-source. PyPartMC reduces the number of steps and mitigates the effort necessary to install and utilize the resources of PartMC. Without PyPartMC, setting up PartMC requires: working with UNIX shell, providing Fortran and C libraries, and performing standard Fortran and C source code configuration, compilation and linking. This can be challenging for those less experienced with computational research or those intending to use PartMC in environments where provision of UNIX tools is less straightforward (e.g., on Windows). PyPartMC offers a single-step installation/upgrade process of PartMC and all dependencies through the pip Python package manager on Linux, macOS, and Windows. This allows streamlined access to the unmodified and versioned Fortran internals of the PartMC codebase from both Python and other interoperable environments (e.g., Julia through PyCall). Consequently, users of PyPartMC can setup, run, process and visualize output of PartMC simulations using a single general-purpose programming language.",
        "published": "2023-08-03T21:10:44Z",
        "link": "http://arxiv.org/abs/2308.02052v3",
        "categories": [
            "cs.MS",
            "physics.ao-ph"
        ]
    },
    {
        "title": "Bandicoot: C++ Library for GPU Linear Algebra and Scientific Computing",
        "authors": [
            "Ryan R. Curtin",
            "Marcus Edel",
            "Conrad Sanderson"
        ],
        "summary": "This report provides an introduction to the Bandicoot C++ library for linear algebra and scientific computing on GPUs, overviewing its user interface and performance characteristics, as well as the technical details of its internal design. Bandicoot is the GPU-enabled counterpart to the well-known Armadillo C++ linear algebra library, aiming to allow users to take advantage of GPU-accelerated computation for their existing codebases without significant changes. Adapting the same internal template meta-programming techniques that Armadillo uses, Bandicoot is able to provide compile-time optimisation of mathematical expressions within user code. The library is ready for production use and is available at https://coot.sourceforge.io. Bandicoot is distributed under the Apache 2.0 License.",
        "published": "2023-08-06T14:01:12Z",
        "link": "http://arxiv.org/abs/2308.03120v1",
        "categories": [
            "cs.MS",
            "65Y05, 65F45, 15-04",
            "G.1.3; G.4; I.3.1; I.3.6"
        ]
    },
    {
        "title": "Comparative analysis of mathematical formulations for the   two-dimensional guillotine cutting problem",
        "authors": [
            "Henrique Becker",
            "Mateus Martin",
            "Olinto Araujo",
            "Luciana S. Buriol",
            "Reinaldo Morabito"
        ],
        "summary": "About ten years ago, a paper proposed the first integer linear programming formulation for the constrained two-dimensional guillotine cutting problem (with unlimited cutting stages). Since, six other formulations followed, five of them in the last two years. This spike of interest gave no opportunity for a comprehensive comparison between the formulations. We review each formulation and compare their empirical results over instance datasets of the literature. We adapt most formulations to allow for piece rotation. The possibility of adaptation was already predicted but not realized by the prior work. The results show the dominance of pseudo-polynomial formulations until the point instances become intractable by them, while more compact formulations keep achieving good primal solutions. Our study also reveals a small but consistent advantage of the Gurobi solver over the CPLEX solver in our context; that the choice of solver hardly benefits one formulation over another; and a mistake in the generation of the T instances, which should have the same optima with or without guillotine cuts. Our study also proposes hybridising the most recent formulation with a prior formulation for a restricted version of the problem. The hybridisations show a reduction of about 20% of the branch-and-bound time thanks to the symmetries broken by the hybridisation.",
        "published": "2023-08-09T14:01:32Z",
        "link": "http://arxiv.org/abs/2308.04965v1",
        "categories": [
            "math.OC",
            "cs.DM",
            "cs.DS",
            "cs.MS",
            "90-02",
            "G.2.0"
        ]
    },
    {
        "title": "Hybrid approach to the joint spectral radius computation",
        "authors": [
            "Thomas Mejstrik",
            "Ulrich Reif"
        ],
        "summary": "In this paper we propose a modification to the invariant polytope algorithm (ipa) using ideas of the finite expressible tree algorithm (feta) by M\\\"oller and Reif. We show that our new feta-flavoured-ipa applies to a wider range of matrix families.",
        "published": "2023-08-09T22:31:17Z",
        "link": "http://arxiv.org/abs/2308.05244v2",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "15A18 15A60 15-04 90C90"
        ]
    },
    {
        "title": "Py-Tetrad and RPy-Tetrad: A New Python Interface with R Support for   Tetrad Causal Search",
        "authors": [
            "Joseph D. Ramsey",
            "Bryan Andrews"
        ],
        "summary": "We give novel Python and R interfaces for the (Java) Tetrad project for causal modeling, search, and estimation. The Tetrad project is a mainstay in the literature, having been under consistent development for over 30 years. Some of its algorithms are now classics, like PC and FCI; others are recent developments. It is increasingly the case, however, that researchers need to access the underlying Java code from Python or R. Existing methods for doing this are inadequate. We provide new, up-to-date methods using the JPype Python-Java interface and the Reticulate Python-R interface, directly solving these issues. With the addition of some simple tools and the provision of working examples for both Python and R, using JPype and Reticulate to interface Python and R with Tetrad is straightforward and intuitive.",
        "published": "2023-08-13T16:29:05Z",
        "link": "http://arxiv.org/abs/2308.07346v1",
        "categories": [
            "cs.MS",
            "cs.AI",
            "cs.PL",
            "62D20",
            "I.2.5; D.1.m"
        ]
    },
    {
        "title": "Computation of GIT quotients of semisimple groups",
        "authors": [
            "Patricio Gallardo",
            "Jesus Martinez-Garcia",
            "Han-Bom Moon",
            "David Swinarski"
        ],
        "summary": "We describe three algorithms to determine the stable, semistable, and torus-polystable loci of the GIT quotient of a projective variety by a reductive group. The algorithms are efficient when the group is semisimple. By using an implementation of our algorithms for simple groups, we provide several applications to the moduli theory of algebraic varieties, including the K-moduli of algebraic varieties, the moduli of algebraic curves and the Mukai models of the moduli space of curves for low genus. We also discuss a number of potential improvements and some natural open problems arising from this work.",
        "published": "2023-08-15T21:29:22Z",
        "link": "http://arxiv.org/abs/2308.08049v1",
        "categories": [
            "math.AG",
            "cs.MS",
            "14L24, 14Q20, 14-04, 13A50"
        ]
    },
    {
        "title": "Performant low-order matrix-free finite element kernels on GPU   architectures",
        "authors": [
            "Randolph R. Settgast",
            "Yohann Dudouit",
            "Nicola Castelletto",
            "William R. Tobin",
            "Benjamin C. Corbett",
            "Sergey Klevtsov"
        ],
        "summary": "Numerical methods such as the Finite Element Method (FEM) have been successfully adapted to utilize the computational power of GPU accelerators. However, much of the effort around applying FEM to GPU's has been focused on high-order FEM due to higher arithmetic intensity and order of accuracy. For applications such as the simulation of subsurface processes, high levels of heterogeneity results in high-resolution grids characterized by highly discontinuous (cell-wise) material property fields. Moreover, due to the significant uncertainties in the characterization of the domain of interest, e.g. geologic reservoirs, the benefits of high order accuracy are reduced, and low-order methods are typically employed. In this study, we present a strategy for implementing highly performant low-order matrix-free FEM operator kernels in the context of the conjugate gradient (CG) method. Performance results of matrix-free Laplace and isotropic elasticity operator kernels are presented and are shown to compare favorably to matrix-based SpMV operators on V100, A100, and MI250X GPUs.",
        "published": "2023-08-18T22:21:54Z",
        "link": "http://arxiv.org/abs/2308.09839v2",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "Graph4J -- A computationally efficient Java library for graph algorithms",
        "authors": [
            "Cristian Frăsinaru",
            "Emanuel Florentin Olariu"
        ],
        "summary": "Graph algorithms play an important role in many computer science areas. In order to solve problems that can be modeled using graphs, it is necessary to use a data structure that can represent those graphs in an efficient manner. On top of this, an infrastructure should be build that will assist in implementing common algorithms or developing specialized ones. Here, a new Java library is introduced, called Graph4J, that uses a different approach when compared to existing, well-known Java libraries such as JGraphT, JUNG and Guava Graph. Instead of using object-oriented data structures for graph representation, a lower-level model based on arrays of primitive values is utilized, that drastically reduces the required memory and the running times of the algorithm implementations. The design of the library, the space complexity of the graph structures and the time complexity of the most common graph operations are presented in detail, along with an experimental study that evaluates its performance, when compared to the other libraries. Emphasis is given to infrastructure related aspects, that is graph creation, inspection, alteration and traversal. The improvements obtained for other implemented algorithms are also analyzed and it is shown that the proposed library significantly outperforms the existing ones.",
        "published": "2023-08-19T06:08:24Z",
        "link": "http://arxiv.org/abs/2308.09920v1",
        "categories": [
            "cs.MS",
            "cs.DS"
        ]
    },
    {
        "title": "Hierarchical Lowrank Arithmetic with Binary Compression",
        "authors": [
            "Ronald Kriemann"
        ],
        "summary": "With lowrank approximation the storage requirements for dense data are reduced down to linear complexity and with the addition of hierarchy this also works for data without global lowrank properties. However, the lowrank factors itself are often still stored using double precision numbers. Newer approaches exploit the different IEEE754 floating point formats available nowadays in a mixed precision approach. However, these formats show a significant gap in storage (and accuracy), e.g. between half, single and double precision. We therefore look beyond these standard formats and use adaptive compression for storing the lowrank and dense data and investigate how that affects the arithmetic of such matrices.",
        "published": "2023-08-21T18:15:05Z",
        "link": "http://arxiv.org/abs/2308.10960v1",
        "categories": [
            "cs.MS",
            "cs.DS",
            "65Y05, 65Y20, 68W10, 68W25, 68P30"
        ]
    },
    {
        "title": "EDOLAB: An Open-Source Platform for Education and Experimentation with   Evolutionary Dynamic Optimization Algorithms",
        "authors": [
            "Mai Peng",
            "Delaram Yazdani",
            "Zeneng She",
            "Danial Yazdani",
            "Wenjian Luo",
            "Changhe Li",
            "Juergen Branke",
            "Trung Thanh Nguyen",
            "Amir H. Gandomi",
            "Shengxiang Yang",
            "Yaochu Jin",
            "Xin Yao"
        ],
        "summary": "Many real-world optimization problems exhibit dynamic characteristics, posing significant challenges for traditional optimization techniques. Evolutionary Dynamic Optimization Algorithms (EDOAs) are designed to address these challenges effectively. However, in existing literature, the reported results for a given EDOA can vary significantly. This inconsistency often arises because the source codes for many EDOAs, which are typically complex, have not been made publicly available, leading to error-prone re-implementations. To support researchers in conducting experiments and comparing their algorithms with various EDOAs, we have developed an open-source MATLAB platform called the Evolutionary Dynamic Optimization LABoratory (EDOLAB). This platform not only facilitates research but also includes an educational module designed for instructional purposes. The education module allows users to observe: a) a 2-dimensional problem space and its morphological changes following each environmental change, b) the behaviors of individuals over time, and c) how the EDOA responds to environmental changes and tracks the moving optimum. The current version of EDOLAB features 25 EDOAs and four fully parametric benchmark generators. The MATLAB source code for EDOLAB is publicly available and can be accessed from [https://github.com/Danial-Yazdani/EDOLAB-MATLAB].",
        "published": "2023-08-24T08:37:32Z",
        "link": "http://arxiv.org/abs/2308.12644v2",
        "categories": [
            "cs.NE",
            "cs.MS"
        ]
    },
    {
        "title": "Alternative quadrant representations with Morton index and AVX2   vectorization for AMR algorithms within the p4est software library",
        "authors": [
            "Mikhail Kirilin",
            "Carsten Burstedde"
        ],
        "summary": "We present a technical enhancement within the p4est software for parallel adaptive mesh refinement. In p4est primitives are stored as octants in three and quadrants in two dimensions. While, classically, they are encoded by the native approach using its spatial and refinement level, any other mathematically equivalent encoding might be used instead.   Recognizing this, we add two alternative representations to the classical, explicit version, based on a long monotonic index and 128-bit AVX quad integers, respectively. The first one requires changes in logic for low-level quadrant manipulating algorithms, while the other exploits data level parallelism and requires algorithms to be adapted to SIMD instructions. The resultant algorithms and data structures lead to higher performance and lesser memory usage in comparison with the standard baseline.   We benchmark selected algorithms on a cluster with two Intel(R) Xeon(R) Gold 6130 Skylake family CPUs per node, which provides support for AVX2 extensions, 192 GB RAM per node, and up to 512 computational cores in total.",
        "published": "2023-08-24T14:05:05Z",
        "link": "http://arxiv.org/abs/2308.13615v1",
        "categories": [
            "cs.MS",
            "G.4; I.6.8; E.2"
        ]
    },
    {
        "title": "Accurate complex Jacobi rotations",
        "authors": [
            "Vedran Novaković"
        ],
        "summary": "This note shows how to compute, to high relative accuracy under mild assumptions, complex Jacobi rotations for diagonalization of Hermitian matrices of order two, using the correctly rounded functions $\\mathtt{cr\\_hypot}$ and $\\mathtt{cr\\_rsqrt}$, proposed for standardization in the C programming language as recommended by the IEEE-754 floating-point standard. The rounding to nearest (ties to even) and the non-stop arithmetic are assumed. The numerical examples compare the observed with theoretical bounds on the relative errors in the rotations' elements, and show that the maximal observed departure of the rotations' determinants from unity is smaller than that of the transformations computed by LAPACK.",
        "published": "2023-08-27T22:46:18Z",
        "link": "http://arxiv.org/abs/2308.14222v3",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "65F15 (Primary) 65-04, 65G50 (Secondary)",
            "G.1.3"
        ]
    },
    {
        "title": "Bringing PDEs to JAX with forward and reverse modes automatic   differentiation",
        "authors": [
            "Ivan Yashchuk"
        ],
        "summary": "Partial differential equations (PDEs) are used to describe a variety of physical phenomena. Often these equations do not have analytical solutions and numerical approximations are used instead. One of the common methods to solve PDEs is the finite element method. Computing derivative information of the solution with respect to the input parameters is important in many tasks in scientific computing. We extend JAX automatic differentiation library with an interface to Firedrake finite element library. High-level symbolic representation of PDEs allows bypassing differentiating through low-level possibly many iterations of the underlying nonlinear solvers. Differentiating through Firedrake solvers is done using tangent-linear and adjoint equations. This enables the efficient composition of finite element solvers with arbitrary differentiable programs. The code is available at github.com/IvanYashchuk/jax-firedrake.",
        "published": "2023-08-31T10:35:24Z",
        "link": "http://arxiv.org/abs/2309.07137v1",
        "categories": [
            "cs.MS",
            "cs.LG",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "An Efficient Framework for Global Non-Convex Polynomial Optimization   over the Hypercube",
        "authors": [
            "Pierre-David Letourneau",
            "Dalton Jones",
            "Matthew Morse",
            "M. Harper Langston"
        ],
        "summary": "We present a novel efficient theoretical and numerical framework for solving global non-convex polynomial optimization problems. We analytically demonstrate that such problems can be efficiently reformulated using a non-linear objective over a convex set; further, these reformulated problems possess no spurious local minima (i.e., every local minimum is a global minimum). We introduce an algorithm for solving these resulting problems using the augmented Lagrangian and the method of Burer and Monteiro. We show through numerical experiments that polynomial scaling in dimension and degree is achievable for computing the optimal value and location of previously intractable global polynomial optimization problems in high dimension.",
        "published": "2023-08-31T13:49:47Z",
        "link": "http://arxiv.org/abs/2308.16731v2",
        "categories": [
            "math.OC",
            "cs.MS",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Segmentação e contagem de troncos de madeira utilizando deep   learning e processamento de imagens",
        "authors": [
            "João V. C. Mazzochin",
            "Gustavo Tiecker",
            "Erick O. Rodrigues"
        ],
        "summary": "Counting objects in images is a pattern recognition problem that focuses on identifying an element to determine its incidence and is approached in the literature as Visual Object Counting (VOC). In this work, we propose a methodology to count wood logs. First, wood logs are segmented from the image background. This first segmentation step is obtained using the Pix2Pix framework that implements Conditional Generative Adversarial Networks (CGANs). Second, the clusters are counted using Connected Components. The average accuracy of the segmentation exceeds 89% while the average amount of wood logs identified based on total accounted is over 97%.",
        "published": "2023-08-31T20:24:14Z",
        "link": "http://arxiv.org/abs/2309.00123v1",
        "categories": [
            "cs.CV",
            "cs.GR",
            "cs.MS",
            "cs.RO"
        ]
    },
    {
        "title": "A FAIR File Format for Mathematical Software",
        "authors": [
            "Antony Della Vecchia",
            "Michael Joswig",
            "Benjamin Lorenz"
        ],
        "summary": "We describe a generic JSON based file format which is suitable for computations in computer algebra. This is implemented in the computer algebra system OSCAR, but we also indicate how it can be used in a different context.",
        "published": "2023-09-01T14:03:44Z",
        "link": "http://arxiv.org/abs/2309.00465v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "A Novel Immersed Boundary Approach for Irregular Topography with   Acoustic Wave Equations",
        "authors": [
            "Edward Caunt",
            "Rhodri Nelson",
            "Fabio Luporini",
            "Gerard Gorman"
        ],
        "summary": "Irregular terrain has a pronounced effect on the propagation of seismic and acoustic wavefields but is not straightforwardly reconciled with structured finite-difference (FD) methods used to model such phenomena. Methods currently detailed in the literature are generally limited in scope application-wise or non-trivial to apply to real-world geometries. With this in mind, a general immersed boundary treatment capable of imposing a range of boundary conditions in a relatively equation-agnostic manner has been developed, alongside a framework implementing this approach, intending to complement emerging code-generation paradigms. The approach is distinguished by the use of N-dimensional Taylor-series extrapolants constrained by boundary conditions imposed at some suitably-distributed set of surface points. The extrapolation process is encapsulated in modified derivative stencils applied in the vicinity of the boundary, utilizing hyperspherical support regions. This method ensures boundary representation is consistent with the FD discretization: both must be considered in tandem. Furthermore, high-dimensional and vector boundary conditions can be applied without approximation prior to discretization. A consistent methodology can thus be applied across free and rigid surfaces with the first and second-order acoustic wave equation formulations. Application to both equations is demonstrated, and numerical examples based on analytic and real-world topography implementing free and rigid surfaces in 2D and 3D are presented.",
        "published": "2023-09-07T09:51:05Z",
        "link": "http://arxiv.org/abs/2309.03600v1",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "Enhancing Missing Data Imputation of Non-stationary Signals with   Harmonic Decomposition",
        "authors": [
            "Joaquin Ruiz",
            "Hau-tieng Wu",
            "Marcelo A. Colominas"
        ],
        "summary": "Dealing with time series with missing values, including those afflicted by low quality or over-saturation, presents a significant signal processing challenge. The task of recovering these missing values, known as imputation, has led to the development of several algorithms. However, we have observed that the efficacy of these algorithms tends to diminish when the time series exhibit non-stationary oscillatory behavior. In this paper, we introduce a novel algorithm, coined Harmonic Level Interpolation (HaLI), which enhances the performance of existing imputation algorithms for oscillatory time series. After running any chosen imputation algorithm, HaLI leverages the harmonic decomposition based on the adaptive nonharmonic model of the initial imputation to improve the imputation accuracy for oscillatory time series. Experimental assessments conducted on synthetic and real signals consistently highlight that HaLI enhances the performance of existing imputation algorithms. The algorithm is made publicly available as a readily employable Matlab code for other researchers to use.",
        "published": "2023-09-08T22:45:54Z",
        "link": "http://arxiv.org/abs/2309.04630v1",
        "categories": [
            "eess.SP",
            "cs.MS"
        ]
    },
    {
        "title": "A Distributed Algebra System for Time Integration on Parallel Computers",
        "authors": [
            "Abhinav Singh",
            "Landfried Kraatz",
            "Pietro Incardona",
            "Ivo F. Sbalzarini"
        ],
        "summary": "We present a distributed algebra system for efficient and compact implementation of numerical time integration schemes on parallel computers and graphics processing units (GPU). The software implementation combines the time integration library Odeint from Boost with the OpenFPM framework for scalable scientific computing. Implementing multi-stage, multi-step, or adaptive time integration methods in distributed-memory parallel codes or on GPUs is challenging. The present algebra system addresses this by making the time integration methods from Odeint available in a concise template-expression language for numerical simulations distributed and parallelized using OpenFPM. This allows using state-of-the-art time integration schemes, or switching between schemes, by changing one line of code, while maintaining parallel scalability. This enables scalable time integration with compact code and facilitates rapid rewriting and deployment of simulation algorithms. We benchmark the present software for exponential and sigmoidal dynamics and present an application example to the 3D Gray-Scott reaction-diffusion problem on both CPUs and GPUs in only 60 lines of code.",
        "published": "2023-09-11T09:26:37Z",
        "link": "http://arxiv.org/abs/2309.05331v1",
        "categories": [
            "cs.MS",
            "cs.DC"
        ]
    },
    {
        "title": "Integration of Quantum Accelerators with High Performance Computing -- A   Review of Quantum Programming Tools",
        "authors": [
            "Amr Elsharkawy",
            "Xiao-Ting Michelle To",
            "Philipp Seitz",
            "Yanbin Chen",
            "Yannick Stade",
            "Manuel Geiger",
            "Qunsheng Huang",
            "Xiaorang Guo",
            "Muhammad Arslan Ansari",
            "Christian B. Mendl",
            "Dieter Kranzlmüller",
            "Martin Schulz"
        ],
        "summary": "Quantum computing (QC) introduces a novel mode of computation with the possibility of greater computational power that remains to be exploited - presenting exciting opportunities for high performance computing (HPC) applications. However, recent advancements in the field have made clear that QC does not supplant conventional HPC, but can rather be incorporated into current heterogeneous HPC infrastructures as an additional accelerator, thereby enabling the optimal utilization of both paradigms. The desire for such integration significantly affects the development of software for quantum computers, which in turn influences the necessary software infrastructure. To date, previous review papers have investigated various quantum programming tools (QPTs) (such as languages, libraries, frameworks) in their ability to program, compile, and execute quantum circuits. However, the integration effort with classical HPC frameworks or systems has not been addressed. This study aims to characterize existing QPTs from an HPC perspective, investigating if existing QPTs have the potential to be efficiently integrated with classical computing models and determining where work is still required. This work structures a set of criteria into an analysis blueprint that enables HPC scientists to assess whether a QPT is suitable for the quantum-accelerated classical application at hand.",
        "published": "2023-09-12T12:24:12Z",
        "link": "http://arxiv.org/abs/2309.06167v2",
        "categories": [
            "cs.ET",
            "cs.MS",
            "quant-ph"
        ]
    },
    {
        "title": "CDL: A fast and flexible library for the study of permutation sets with   structural restrictions",
        "authors": [
            "Bei Zhou",
            "Klas Markstrōm",
            "Søren Riis"
        ],
        "summary": "In this paper, we introduce CDL, a software library designed for the analysis of permutations and linear orders subject to various structural restrictions. Prominent examples of these restrictions include pattern avoidance, a topic of interest in both computer science and combinatorics, and \"never conditions\" utilized in social choice and voting theory.   CDL offers a range of fundamental functionalities, including identifying the permutations that meet specific restrictions and determining the isomorphism of such sets. To facilitate exploration of large permutation sets or domains, CDL incorporates multiple search strategies and heuristics.",
        "published": "2023-09-12T15:17:16Z",
        "link": "http://arxiv.org/abs/2309.06306v2",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "A Distributed Data-Parallel PyTorch Implementation of the Distributed   Shampoo Optimizer for Training Neural Networks At-Scale",
        "authors": [
            "Hao-Jun Michael Shi",
            "Tsung-Hsien Lee",
            "Shintaro Iwasaki",
            "Jose Gallego-Posada",
            "Zhijing Li",
            "Kaushik Rangadurai",
            "Dheevatsa Mudigere",
            "Michael Rabbat"
        ],
        "summary": "Shampoo is an online and stochastic optimization algorithm belonging to the AdaGrad family of methods for training neural networks. It constructs a block-diagonal preconditioner where each block consists of a coarse Kronecker product approximation to full-matrix AdaGrad for each parameter of the neural network. In this work, we provide a complete description of the algorithm as well as the performance optimizations that our implementation leverages to train deep networks at-scale in PyTorch. Our implementation enables fast multi-GPU distributed data-parallel training by distributing the memory and computation associated with blocks of each parameter via PyTorch's DTensor data structure and performing an AllGather primitive on the computed search directions at each iteration. This major performance enhancement enables us to achieve at most a 10% performance reduction in per-step wall-clock time compared against standard diagonal-scaling-based adaptive gradient methods. We validate our implementation by performing an ablation study on training ImageNet ResNet50, demonstrating Shampoo's superiority over standard training recipes with minimal hyperparameter tuning.",
        "published": "2023-09-12T18:11:10Z",
        "link": "http://arxiv.org/abs/2309.06497v1",
        "categories": [
            "cs.LG",
            "cs.DC",
            "cs.MS",
            "math.OC"
        ]
    },
    {
        "title": "$\\texttt{ChisholmD.wl}$- Automated rational approximant for bi-variate   series",
        "authors": [
            "Souvik Bera",
            "Tanay Pathak"
        ],
        "summary": "The Chisholm rational approximant is a natural generalization to two variables of the well-known single variable Pad\\'e approximant, and has the advantage of reducing to the latter when one of the variables is set equals to 0. We present, to our knowledge, the first automated Mathematica package to evaluate diagonal Chisholm approximants of two variable series. For the moment, the package can only be used to evaluate diagonal approximants i.e. the maximum powers of both the variables, in both the numerator and the denominator, is equal to some integer $M$. We further modify the original method so as to allow us to evaluate the approximants around some general point $(x,y)$ not necessarily $(0,0)$. Using the approximants around general point $(x,y)$, allows us to get a better estimate of the result when the point of evaluation is far from $(0,0)$. Several examples of the elementary functions have been studied which shows that the approximants can be useful for analytic continuation and convergence acceleration purposes. We continue our study using various examples of two variable hypergeometric series, $\\mathrm{Li}_{2,2}(x,y)$ etc that arise in particle physics and in the study of critical phenomena in condensed matter physics. The demonstration of the package is discussed in detail and the Mathematica package is provided as an ancillary file.",
        "published": "2023-09-14T13:03:24Z",
        "link": "http://arxiv.org/abs/2309.07687v1",
        "categories": [
            "cs.MS",
            "cs.NA",
            "hep-ph",
            "math-ph",
            "math.MP",
            "math.NA"
        ]
    },
    {
        "title": "Satisfiability.jl: Satisfiability Modulo Theories in Julia",
        "authors": [
            "Emiko Soroka",
            "Mykel J. Kochenderfer",
            "Sanjay Lall"
        ],
        "summary": "Satisfiability modulo theories (SMT) is a core tool in formal verification. While the SMT-LIB specification language can be used to interact with theorem proving software, a high-level interface allows for faster and easier specifications of complex SMT formulae. In this paper we present a novel open-source package for interacting with SMT-LIB compliant solvers in the Julia programming language.",
        "published": "2023-09-15T21:44:49Z",
        "link": "http://arxiv.org/abs/2309.08778v2",
        "categories": [
            "cs.LO",
            "cs.MS",
            "D.2.4"
        ]
    },
    {
        "title": "Unlocking massively parallel spectral proper orthogonal decompositions   in the PySPOD package",
        "authors": [
            "Marcin Rogowski",
            "Brandon C. Y. Yeung",
            "Oliver T. Schmidt",
            "Romit Maulik",
            "Lisandro Dalcin",
            "Matteo Parsani",
            "Gianmarco Mengaldo"
        ],
        "summary": "We propose a parallel (distributed) version of the spectral proper orthogonal decomposition (SPOD) technique. The parallel SPOD algorithm distributes the spatial dimension of the dataset preserving time. This approach is adopted to preserve the non-distributed fast Fourier transform of the data in time, thereby avoiding the associated bottlenecks. The parallel SPOD algorithm is implemented in the PySPOD (https://github.com/MathEXLab/PySPOD) library and makes use of the standard message passing interface (MPI) library, implemented in Python via mpi4py (https://mpi4py.readthedocs.io/en/stable/). An extensive performance evaluation of the parallel package is provided, including strong and weak scalability analyses. The open-source library allows the analysis of large datasets of interest across the scientific community. Here, we present applications in fluid dynamics and geophysics, that are extremely difficult (if not impossible) to achieve without a parallel algorithm. This work opens the path toward modal analyses of big quasi-stationary data, helping to uncover new unexplored spatio-temporal patterns.",
        "published": "2023-09-21T06:28:07Z",
        "link": "http://arxiv.org/abs/2309.11808v2",
        "categories": [
            "physics.comp-ph",
            "cs.DC",
            "cs.MS"
        ]
    },
    {
        "title": "Physics Informed Neural Network Code for 2D Transient Problems   (PINN-2DT) Compatible with Google Colab",
        "authors": [
            "Paweł Maczuga",
            "Maciej Sikora",
            "Maciej Skoczeń",
            "Przemysław Rożnawski",
            "Filip Tłuszcz",
            "Marcin Szubert",
            "Marcin Łoś",
            "Witold Dzwinel",
            "Keshav Pingali",
            "Maciej Paszyński"
        ],
        "summary": "We present an open-source Physics Informed Neural Network environment for simulations of transient phenomena on two-dimensional rectangular domains, with the following features: (1) it is compatible with Google Colab which allows automatic execution on cloud environment; (2) it supports two dimensional time-dependent PDEs; (3) it provides simple interface for definition of the residual loss, boundary condition and initial loss, together with their weights; (4) it support Neumann and Dirichlet boundary conditions; (5) it allows for customizing the number of layers and neurons per layer, as well as for arbitrary activation function; (6) the learning rate and number of epochs are available as parameters; (7) it automatically differentiates PINN with respect to spatial and temporal variables; (8) it provides routines for plotting the convergence (with running average), initial conditions learnt, 2D and 3D snapshots from the simulation and movies (9) it includes a library of problems: (a) non-stationary heat transfer; (b) wave equation modeling a tsunami; (c) atmospheric simulations including thermal inversion; (d) tumor growth simulations.",
        "published": "2023-09-24T07:08:36Z",
        "link": "http://arxiv.org/abs/2310.03755v2",
        "categories": [
            "cs.CE",
            "cs.LG",
            "cs.MS",
            "cs.NA",
            "math.NA",
            "G.1.8; G.1.10; J.2; J.3; G.4; I.6.4; I.m"
        ]
    },
    {
        "title": "pyPPG: A Python toolbox for comprehensive photoplethysmography signal   analysis",
        "authors": [
            "Marton A. Goda",
            "Peter H. Charlton",
            "Joachim A. Behar"
        ],
        "summary": "Photoplethysmography is a non-invasive optical technique that measures changes in blood volume within tissues. It is commonly and increasingly used for in a variety of research and clinical application to assess vascular dynamics and physiological parameters. Yet, contrary to heart rate variability measures, a field which has seen the development of stable standards and advanced toolboxes and software, no such standards and open tools exist for continuous photoplethysmogram (PPG) analysis. Consequently, the primary objective of this research was to identify, standardize, implement and validate key digital PPG biomarkers. This work describes the creation of a standard Python toolbox, denoted pyPPG, for long-term continuous PPG time series analysis recorded using a standard finger-based transmission pulse oximeter. The improved PPG peak detector had an F1-score of 88.19% for the state-of-the-art benchmark when evaluated on 2,054 adult polysomnography recordings totaling over 91 million reference beats. This algorithm outperformed the open-source original Matlab implementation by ~5% when benchmarked on a subset of 100 randomly selected MESA recordings. More than 3,000 fiducial points were manually annotated by two annotators in order to validate the fiducial points detector. The detector consistently demonstrated high performance, with a mean absolute error of less than 10 ms for all fiducial points. Based on these fiducial points, pyPPG engineers a set of 74 PPG biomarkers. Studying the PPG time series variability using pyPPG can enhance our understanding of the manifestations and etiology of diseases. This toolbox can also be used for biomarker engineering in training data-driven models. pyPPG is available on physiozoo.org",
        "published": "2023-09-24T22:37:49Z",
        "link": "http://arxiv.org/abs/2309.13767v1",
        "categories": [
            "physics.med-ph",
            "cs.MS"
        ]
    },
    {
        "title": "A Sparse Fast Chebyshev Transform for High-Dimensional Approximation",
        "authors": [
            "Dalton Jones",
            "Pierre-David Letourneau",
            "Matthew J. Morse",
            "M. Harper Langston"
        ],
        "summary": "We present the Fast Chebyshev Transform (FCT), a fast, randomized algorithm to compute a Chebyshev approximation of functions in high-dimensions from the knowledge of the location of its nonzero Chebyshev coefficients. Rather than sampling a full-resolution Chebyshev grid in each dimension, we randomly sample several grids with varied resolutions and solve a least-squares problem in coefficient space in order to compute a polynomial approximating the function of interest across all grids simultaneously. We theoretically and empirically show that the FCT exhibits quasi-linear scaling and high numerical accuracy on challenging and complex high-dimensional problems. We demonstrate the effectiveness of our approach compared to alternative Chebyshev approximation schemes. In particular, we highlight our algorithm's effectiveness in high dimensions, demonstrating significant speedups over commonly-used alternative techniques.",
        "published": "2023-09-26T00:15:09Z",
        "link": "http://arxiv.org/abs/2309.14584v2",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "math.OC",
            "90C23, 41A50, 65Y20, 65D15, 93E24, 65T50, 14Q15"
        ]
    },
    {
        "title": "Parallel local time stepping for rigid bodies represented by   triangulated meshes",
        "authors": [
            "Peter Noble",
            "Tobias Weinzierl"
        ],
        "summary": "Discrete Element Methods (DEM), i.e.~the simulation of many rigid particles, suffer from very stiff differential equations plus multiscale challenges in space and time. The particles move smoothly through space until they interact almost instantaneously due to collisions. Dense particle packings hence require tiny time step sizes, while free particles can advance with large time steps. Admissible time step sizes can span multiple orders of magnitudes. We propose an adaptive local time stepping algorithm which identifies clusters of particles that can be updated independently, advances them optimistically and independently in time, determines collision time stamps in space-time such that we maximise the time step sizes used, and resolves the momentum exchange implicitly. It is combined with various acceleration techniques which exploit multiscale geometry representations and multiscale behaviour in time. The collision time stamp detection in space-time in combination with the implicit solve of the actual collision equations avoids that particles get locked into tiny time step sizes, the clustering yields a high concurrency level, and the acceleration techniques plus local time stepping avoid unnecessary computations. This brings a scaling, adaptive time stepping for DEM for real-world challenges into reach.",
        "published": "2023-09-27T05:46:57Z",
        "link": "http://arxiv.org/abs/2309.15417v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "Implicit Gaussian process representation of vector fields over arbitrary   latent manifolds",
        "authors": [
            "Robert L. Peach",
            "Matteo Vinao-Carl",
            "Nir Grossman",
            "Michael David",
            "Emma Mallas",
            "David Sharp",
            "Paresh A. Malhotra",
            "Pierre Vandergheynst",
            "Adam Gosztolai"
        ],
        "summary": "Gaussian processes (GPs) are popular nonparametric statistical models for learning unknown functions and quantifying the spatiotemporal uncertainty in data. Recent works have extended GPs to model scalar and vector quantities distributed over non-Euclidean domains, including smooth manifolds appearing in numerous fields such as computer vision, dynamical systems, and neuroscience. However, these approaches assume that the manifold underlying the data is known, limiting their practical utility. We introduce RVGP, a generalisation of GPs for learning vector signals over latent Riemannian manifolds. Our method uses positional encoding with eigenfunctions of the connection Laplacian, associated with the tangent bundle, readily derived from common graph-based approximation of data. We demonstrate that RVGP possesses global regularity over the manifold, which allows it to super-resolve and inpaint vector fields while preserving singularities. Furthermore, we use RVGP to reconstruct high-density neural dynamics derived from low-density EEG recordings in healthy individuals and Alzheimer's patients. We show that vector field singularities are important disease markers and that their reconstruction leads to a comparable classification accuracy of disease states to high-density recordings. Thus, our method overcomes a significant practical limitation in experimental and clinical applications.",
        "published": "2023-09-28T16:02:39Z",
        "link": "http://arxiv.org/abs/2309.16746v2",
        "categories": [
            "cs.LG",
            "cs.MS",
            "physics.data-an",
            "q-bio.QM",
            "stat.ML"
        ]
    },
    {
        "title": "Asymptote-based scientific animation",
        "authors": [
            "Migran N. Gevorkyan",
            "Anna V. Korolkova",
            "Dmitry S. Kulyabov"
        ],
        "summary": "This article discusses a universal way to create animation using Asymptote the language for vector graphics. The Asymptote language itself has a built-in library for creating animations, but its practical use is complicated by an extremely brief description in the official documentation and unstable execution of existing examples. The purpose of this article is to eliminate this gap. The method we describe is based on creating a PDF file with frames using Asymptote, with further converting it into a set of PNG images and merging them into a video using FFmpeg. All stages are described in detail, which allows the reader to use the described method without being familiar with the used utilities.",
        "published": "2023-09-30T16:12:30Z",
        "link": "http://arxiv.org/abs/2310.06860v1",
        "categories": [
            "cs.GR",
            "cs.MS"
        ]
    },
    {
        "title": "CausalGPS: An R Package for Causal Inference With Continuous Exposures",
        "authors": [
            "Naeem Khoshnevis",
            "Xiao Wu",
            "Danielle Braun"
        ],
        "summary": "Quantifying the causal effects of continuous exposures on outcomes of interest is critical for social, economic, health, and medical research. However, most existing software packages focus on binary exposures. We develop the CausalGPS R package that implements a collection of algorithms to provide algorithmic solutions for causal inference with continuous exposures. CausalGPS implements a causal inference workflow, with algorithms based on generalized propensity scores (GPS) as the core, extending propensity scores (the probability of a unit being exposed given pre-exposure covariates) from binary to continuous exposures. As the first step, the package implements efficient and flexible estimations of the GPS, allowing multiple user-specified modeling options. As the second step, the package provides two ways to adjust for confounding: weighting and matching, generating weighted and matched data sets, respectively. Lastly, the package provides built-in functions to fit flexible parametric, semi-parametric, or non-parametric regression models on the weighted or matched data to estimate the exposure-response function relating the outcome with the exposures. The computationally intensive tasks are implemented in C++, and efficient shared-memory parallelization is achieved by OpenMP API. This paper outlines the main components of the CausalGPS R package and demonstrates its application to assess the effect of long-term exposure to PM2.5 on educational attainment using zip code-level data from the contiguous United States from 2000-2016.",
        "published": "2023-10-01T03:31:01Z",
        "link": "http://arxiv.org/abs/2310.00561v1",
        "categories": [
            "stat.CO",
            "cs.MS",
            "econ.EM"
        ]
    },
    {
        "title": "A directional regularization method for the limited-angle Helsinki   Tomography Challenge using the Core Imaging Library (CIL)",
        "authors": [
            "Jakob Sauer Jørgensen",
            "Evangelos Papoutsellis",
            "Laura Murgatroyd",
            "Gemma Fardell",
            "Edoardo Pasca"
        ],
        "summary": "This article presents the algorithms developed by the Core Imaging Library (CIL) developer team for the Helsinki Tomography Challenge 2022. The challenge focused on reconstructing 2D phantom shapes from limited-angle computed tomography (CT) data. The CIL team designed and implemented five reconstruction methods using CIL (https://ccpi.ac.uk/cil/), an open-source Python package for tomographic imaging. The CIL team adopted a model-based reconstruction strategy, unique to this challenge with all other teams relying on deep-learning techniques. The CIL algorithms showcased exceptional performance, with one algorithm securing the third place in the competition. The best-performing algorithm employed careful CT data pre-processing and an optimization problem with single-sided directional total variation regularization combined with isotropic total variation and tailored lower and upper bounds. The reconstructions and segmentations achieved high quality for data with angular ranges down to 50 degrees, and in some cases acceptable performance even at 40 and 30 degrees. This study highlights the effectiveness of model-based approaches in limited-angle tomography and emphasizes the importance of proper algorithmic design leveraging on available prior knowledge to overcome data limitations. Finally, this study highlights the flexibility of CIL for prototyping and comparison of different optimization methods.",
        "published": "2023-10-02T22:02:29Z",
        "link": "http://arxiv.org/abs/2310.01671v1",
        "categories": [
            "physics.med-ph",
            "cs.MS",
            "cs.NA",
            "math.NA",
            "math.OC",
            "65R32, 94A08, 65K10",
            "G.1.6; G.1.10; G.4"
        ]
    },
    {
        "title": "Smoothing Methods for Automatic Differentiation Across Conditional   Branches",
        "authors": [
            "Justin N. Kreikemeyer",
            "Philipp Andelfinger"
        ],
        "summary": "Programs involving discontinuities introduced by control flow constructs such as conditional branches pose challenges to mathematical optimization methods that assume a degree of smoothness in the objective function's response surface. Smooth interpretation (SI) is a form of abstract interpretation that approximates the convolution of a program's output with a Gaussian kernel, thus smoothing its output in a principled manner. Here, we combine SI with automatic differentiation (AD) to efficiently compute gradients of smoothed programs. In contrast to AD across a regular program execution, these gradients also capture the effects of alternative control flow paths. The combination of SI with AD enables the direct gradient-based parameter synthesis for branching programs, allowing for instance the calibration of simulation models or their combination with neural network models in machine learning pipelines. We detail the effects of the approximations made for tractability in SI and propose a novel Monte Carlo estimator that avoids the underlying assumptions by estimating the smoothed programs' gradients through a combination of AD and sampling. Using DiscoGrad, our tool for automatically translating simple C++ programs to a smooth differentiable form, we perform an extensive evaluation. We compare the combination of SI with AD and our Monte Carlo estimator to existing gradient-free and stochastic methods on four non-trivial and originally discontinuous problems ranging from classical simulation-based optimization to neural network-driven control. While the optimization progress with the SI-based estimator depends on the complexity of the program's control flow, our Monte Carlo estimator is competitive in all problems, exhibiting the fastest convergence by a substantial margin in our highest-dimensional problem.",
        "published": "2023-10-05T15:08:37Z",
        "link": "http://arxiv.org/abs/2310.03585v2",
        "categories": [
            "cs.LG",
            "cs.MS",
            "math.OC"
        ]
    },
    {
        "title": "TTK is Getting MPI-Ready",
        "authors": [
            "Eve Le Guillou",
            "Michael Will",
            "Pierre Guillou",
            "Jonas Lukasczyk",
            "Pierre Fortin",
            "Christoph Garth",
            "Julien Tierny"
        ],
        "summary": "This system paper documents the technical foundations for the extension of the Topology ToolKit (TTK) to distributed-memory parallelism with the Message Passing Interface (MPI). While several recent papers introduced topology-based approaches for distributed-memory environments, these were reporting experiments obtained with tailored, mono-algorithm implementations. In contrast, we describe in this paper a versatile approach (supporting both triangulated domains and regular grids) for the support of topological analysis pipelines, i.e. a sequence of topological algorithms interacting together. While developing this extension, we faced several algorithmic and software engineering challenges, which we document in this paper. We describe an MPI extension of TTK's data structure for triangulation representation and traversal, a central component to the global performance and generality of TTK's topological implementations. We also introduce an intermediate interface between TTK and MPI, both at the global pipeline level, and at the fine-grain algorithmic level. We provide a taxonomy for the distributed-memory topological algorithms supported by TTK, depending on their communication needs and provide examples of hybrid MPI+thread parallelizations. Performance analyses show that parallel efficiencies range from 20% to 80% (depending on the algorithms), and that the MPI-specific preconditioning introduced by our framework induces a negligible computation time overhead. We illustrate the new distributed-memory capabilities of TTK with an example of advanced analysis pipeline, combining multiple algorithms, run on the largest publicly available dataset we have found (120 billion vertices) on a cluster with 64 nodes (for a total of 1536 cores). Finally, we provide a roadmap for the completion of TTK's MPI extension, along with generic recommendations for each algorithm communication category.",
        "published": "2023-10-12T13:57:32Z",
        "link": "http://arxiv.org/abs/2310.08339v2",
        "categories": [
            "cs.DC",
            "cs.CG",
            "cs.CV",
            "cs.LG",
            "cs.MS"
        ]
    },
    {
        "title": "Algorithm xxxx: HiPPIS A High-Order Positivity-Preserving Mapping   Software for Structured Meshes",
        "authors": [
            "Timbwaoga A. J. Ouermi",
            "Robert M Kirby",
            "Martin Berzins"
        ],
        "summary": "Polynomial interpolation is an important component of many computational problems. In several of these computational problems, failure to preserve positivity when using polynomials to approximate or map data values between meshes can lead to negative unphysical quantities. Currently, most polynomial-based methods for enforcing positivity are based on splines and polynomial rescaling. The spline-based approaches build interpolants that are positive over the intervals in which they are defined and may require solving a minimization problem and/or system of equations. The linear polynomial rescaling methods allow for high-degree polynomials but enforce positivity only at limited locations (e.g., quadrature nodes). This work introduces open-source software (HiPPIS) for high-order data-bounded interpolation (DBI) and positivity-preserving interpolation (PPI) that addresses the limitations of both the spline and polynomial rescaling methods. HiPPIS is suitable for approximating and mapping physical quantities such as mass, density, and concentration between meshes while preserving positivity. This work provides Fortran and Matlab implementations of the DBI and PPI methods, presents an analysis of the mapping error in the context of PDEs, and uses several 1D and 2D numerical examples to demonstrate the benefits and limitations of HiPPIS.",
        "published": "2023-10-13T02:12:16Z",
        "link": "http://arxiv.org/abs/2310.08818v1",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "65D05, 65D15"
        ]
    },
    {
        "title": "A Number Representation Systems Library Supporting New Representations   Based on Morris Tapered Floating-point with Hidden Exponent Bit",
        "authors": [
            "Stefan-Dan Ciocirlan",
            "Dumitrel Loghin"
        ],
        "summary": "The introduction of posit reopened the debate about the utility of IEEE754 in specific domains. In this context, we propose a high-level language (Scala) library that aims to reduce the effort of designing and testing new number representation systems (NRSs). The library's efficiency is tested with three new NRSs derived from Morris Tapered Floating-Point by adding a hidden exponent bit. We call these NRSs MorrisHEB, MorrisBiasHEB, and MorrisUnaryHEB, respectively. We show that they offer a better dynamic range, better decimal accuracy for unary operations, more exact results for addition (37.61% in the case of MorrisUnaryHEB), and better average decimal accuracy for inexact results on binary operations than posit and IEEE754. Going through existing benchmarks in the literature, and favorable/unfavorable examples for IEEE754/posit, we show that these new NRSs produce similar (less than one decimal accuracy difference) or even better results than IEEE754 and posit. Given the entire spectrum of results, there are arguments for MorrisBiasHEB to be used as a replacement for IEEE754 in general computations. MorrisUnaryHEB has a more populated ``golden zone'' (+13.6%) and a better dynamic range (149X) than posit, making it a candidate for machine learning computations.",
        "published": "2023-10-15T10:59:41Z",
        "link": "http://arxiv.org/abs/2310.09797v1",
        "categories": [
            "cs.MS",
            "cs.IT",
            "math.IT"
        ]
    },
    {
        "title": "HyperNetX: A Python package for modeling complex network data as   hypergraphs",
        "authors": [
            "Brenda Praggastis",
            "Sinan Aksoy",
            "Dustin Arendt",
            "Mark Bonicillo",
            "Cliff Joslyn",
            "Emilie Purvine",
            "Madelyn Shapiro",
            "Ji Young Yun"
        ],
        "summary": "HyperNetX (HNX) is an open source Python library for the analysis and visualization of complex network data modeled as hypergraphs. Initially released in 2019, HNX facilitates exploratory data analysis of complex networks using algebraic topology, combinatorics, and generalized hypergraph and graph theoretical methods on structured data inputs. With its 2023 release, the library supports attaching metadata, numerical and categorical, to nodes (vertices) and hyperedges, as well as to node-hyperedge pairings (incidences). HNX has a customizable Matplotlib-based visualization module as well as HypernetX-Widget, its JavaScript addon for interactive exploration and visualization of hypergraphs within Jupyter Notebooks. Both packages are available on GitHub and PyPI. With a growing community of users and collaborators, HNX has become a preeminent tool for hypergraph analysis.",
        "published": "2023-10-17T23:24:11Z",
        "link": "http://arxiv.org/abs/2310.11626v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "Tackling the Matrix Multiplication Micro-kernel Generation with Exo",
        "authors": [
            "Adrián Castelló",
            "Julian Bellavita",
            "Grace Dinh",
            "Yuka Ikarashi",
            "Héctor Martínez"
        ],
        "summary": "The optimization of the matrix multiplication (or GEMM) has been a need during the last decades. This operation is considered the flagship of current linear algebra libraries such as BLIS, OpenBLAS, or Intel OneAPI because of its widespread use in a large variety of scientific applications. The GEMM is usually implemented following the GotoBLAS philosophy, which tiles the GEMM operands and uses a series of nested loops for performance improvement. These approaches extract the maximum computational power of the architectures through small pieces of hardware-oriented, high-performance code called micro-kernel. However, this approach forces developers to generate, with a non-negligible effort, a dedicated micro-kernel for each new hardware.   In this work, we present a step-by-step procedure for generating micro-kernels with the Exo compiler that performs close to (or even better than) manually developed microkernels written with intrinsic functions or assembly language. Our solution also improves the portability of the generated code, since a hardware target is fully specified by a concise library-based description of its instructions.",
        "published": "2023-10-26T14:09:57Z",
        "link": "http://arxiv.org/abs/2310.17408v2",
        "categories": [
            "cs.MS",
            "cs.CL",
            "cs.PF"
        ]
    },
    {
        "title": "Typical Algorithms for Estimating Hurst Exponent of Time Sequence: A   Data Analyst's Perspective",
        "authors": [
            "Hong-Yan Zhang",
            "Zhi-Qiang Feng",
            "Si-Yu Feng",
            "Yu Zhou"
        ],
        "summary": "The Hurst exponent is a significant indicator for characterizing the self-similarity and long-term memory properties of time sequences. It has wide applications in physics, technologies, engineering, mathematics, statistics, economics, psychology and so on. Currently, available methods for estimating the Hurst exponent of time sequences can be divided into different categories: time-domain methods and spectrum-domain methods based on the representation of time sequence, linear regression methods and Bayesian methods based on parameter estimation methods. Although various methods are discussed in literature, there are still some deficiencies: the descriptions of the estimation algorithms are just mathematics-oriented and the pseudo-codes are missing; the effectiveness and accuracy of the estimation algorithms are not clear; the classification of estimation methods is not considered and there is a lack of guidance for selecting the estimation methods. In this work, the emphasis is put on thirteen dominant methods for estimating the Hurst exponent. For the purpose of decreasing the difficulty of implementing the estimation methods with computer programs, the mathematical principles are discussed briefly and the pseudo-codes of algorithms are presented with necessary details. It is expected that the survey could help the researchers to select, implement and apply the estimation algorithms of interest in practical situations in an easy way.",
        "published": "2023-10-29T15:56:53Z",
        "link": "http://arxiv.org/abs/2310.19051v3",
        "categories": [
            "stat.ME",
            "cs.MS"
        ]
    },
    {
        "title": "Factor Fitting, Rank Allocation, and Partitioning in Multilevel Low Rank   Matrices",
        "authors": [
            "Tetiana Parshakova",
            "Trevor Hastie",
            "Eric Darve",
            "Stephen Boyd"
        ],
        "summary": "We consider multilevel low rank (MLR) matrices, defined as a row and column permutation of a sum of matrices, each one a block diagonal refinement of the previous one, with all blocks low rank given in factored form. MLR matrices extend low rank matrices but share many of their properties, such as the total storage required and complexity of matrix-vector multiplication. We address three problems that arise in fitting a given matrix by an MLR matrix in the Frobenius norm. The first problem is factor fitting, where we adjust the factors of the MLR matrix. The second is rank allocation, where we choose the ranks of the blocks in each level, subject to the total rank having a given value, which preserves the total storage needed for the MLR matrix. The final problem is to choose the hierarchical partition of rows and columns, along with the ranks and factors. This paper is accompanied by an open source package that implements the proposed methods.",
        "published": "2023-10-30T00:52:17Z",
        "link": "http://arxiv.org/abs/2310.19214v1",
        "categories": [
            "stat.ML",
            "cs.LG",
            "cs.MS",
            "math.OC"
        ]
    },
    {
        "title": "NoMoPy: Noise Modeling in Python",
        "authors": [
            "Dylan Albrecht",
            "N. Tobias Jacobson"
        ],
        "summary": "NoMoPy is a code for fitting, analyzing, and generating noise modeled as a hidden Markov model (HMM) or, more generally, factorial hidden Markov model (FHMM). This code, written in Python, implements approximate and exact expectation maximization (EM) algorithms for performing the parameter estimation process, model selection procedures via cross-validation, and parameter confidence region estimation. Here, we describe in detail the functionality implemented in NoMoPy and provide examples of its use and performance on example problems.",
        "published": "2023-10-31T18:52:05Z",
        "link": "http://arxiv.org/abs/2311.00084v1",
        "categories": [
            "stat.CO",
            "cs.CE",
            "cs.MS",
            "stat.ML"
        ]
    },
    {
        "title": "Performance Optimization of Deep Learning Sparse Matrix Kernels on Intel   Max Series GPU",
        "authors": [
            "Mohammad Zubair",
            "Christoph Bauinger"
        ],
        "summary": "In this paper, we focus on three sparse matrix operations that are relevant for machine learning applications, namely, the sparse-dense matrix multiplication (SPMM), the sampled dense-dense matrix multiplication (SDDMM), and the composition of the SDDMM with SPMM, also termed as FusedMM. We develop optimized implementations for SPMM, SDDMM, and FusedMM operations utilizing Intel oneAPI's Explicit SIMD (ESIMD) SYCL extension API. In contrast to CUDA or SYCL, the ESIMD API enables the writing of explicitly vectorized kernel code. Sparse matrix algorithms implemented with the ESIMD API achieved performance close to the peak of the targeted Intel Data Center GPU. We compare our performance results to Intel's oneMKL library on Intel GPUs and to a recent CUDA implementation for the sparse matrix operations on NVIDIA's V100 GPU and demonstrate that our implementations for sparse matrix operations outperform either.",
        "published": "2023-11-01T08:43:59Z",
        "link": "http://arxiv.org/abs/2311.00368v1",
        "categories": [
            "cs.LG",
            "cs.MS",
            "68-04 (Primary) 68T07, 68W10 (Secondary)",
            "I.2.5; G.4"
        ]
    },
    {
        "title": "$O(N)$ distributed direct factorization of structured dense matrices   using runtime systems",
        "authors": [
            "Sameer Deshmukh",
            "Qinxiang Ma",
            "Rio Yokota",
            "George Bosilca"
        ],
        "summary": "Structured dense matrices result from boundary integral problems in electrostatics and geostatistics, and also Schur complements in sparse preconditioners such as multi-frontal methods. Exploiting the structure of such matrices can reduce the time for dense direct factorization from $O(N^3)$ to $O(N)$. The Hierarchically Semi-Separable (HSS) matrix is one such low rank matrix format that can be factorized using a Cholesky-like algorithm called ULV factorization. The HSS-ULV algorithm is highly parallel because it removes the dependency on trailing sub-matrices at each HSS level. However, a key merge step that links two successive HSS levels remains a challenge for efficient parallelization. In this paper, we use an asynchronous runtime system PaRSEC with the HSS-ULV algorithm. We compare our work with STRUMPACK and LORAPO, both state-of-the-art implementations of dense direct low rank factorization, and achieve up to 2x better factorization time for matrices arising from a diverse set of applications on up to 128 nodes of Fugaku for similar or better accuracy for all the problems that we survey.",
        "published": "2023-11-02T01:28:47Z",
        "link": "http://arxiv.org/abs/2311.00921v1",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "An Efficient Framework for Global Non-Convex Polynomial Optimization   with Algebraic Constraints",
        "authors": [
            "Mitchell Tong Harris",
            "Pierre-David Letourneau",
            "Dalton Jones",
            "M. Harper Langston"
        ],
        "summary": "We present an efficient framework for solving algebraically-constrained global non-convex polynomial optimization problems over subsets of the hypercube. We prove the existence of an equivalent nonlinear reformulation of such problems that possesses essentially no spurious local minima. Through numerical experiments on previously intractable global constrained polynomial optimization problems in high dimension, we show that polynomial scaling in dimension and degree is achievable when computing the optimal value and location.",
        "published": "2023-11-03T17:10:26Z",
        "link": "http://arxiv.org/abs/2311.02037v2",
        "categories": [
            "math.OC",
            "cs.MS",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Cache Optimization and Performance Modeling of Batched, Small, and   Rectangular Matrix Multiplication on Intel, AMD, and Fujitsu Processors",
        "authors": [
            "Sameer Deshmukh",
            "Rio Yokota",
            "George Bosilca"
        ],
        "summary": "Factorization and multiplication of dense matrices and tensors are critical, yet extremely expensive pieces of the scientific toolbox. Careful use of low rank approximation can drastically reduce the computation and memory requirements of these operations. In addition to a lower arithmetic complexity, such methods can, by their structure, be designed to efficiently exploit modern hardware architectures. The majority of existing work relies on batched BLAS libraries to handle the computation of many small dense matrices. We show that through careful analysis of the cache utilization, register accumulation using SIMD registers and a redesign of the implementation, one can achieve significantly higher throughput for these types of batched low-rank matrices across a large range of block and batch sizes. We test our algorithm on 3 CPUs using diverse ISAs -- the Fujitsu A64FX using ARM SVE, the Intel Xeon 6148 using AVX-512 and AMD EPYC 7502 using AVX-2, and show that our new batching methodology is able to obtain more than twice the throughput of vendor optimized libraries for all CPU architectures and problem sizes.",
        "published": "2023-11-11T02:33:10Z",
        "link": "http://arxiv.org/abs/2311.07602v1",
        "categories": [
            "cs.PF",
            "cs.MS"
        ]
    },
    {
        "title": "A Case Study in Analytic Protocol Analysis in ACL2",
        "authors": [
            "Max von Hippel",
            "Panagiotis Manolios",
            "Kenneth L. McMillan",
            "Cristina Nita-Rotaru",
            "Lenore Zuck"
        ],
        "summary": "When verifying computer systems we sometimes want to study their asymptotic behaviors, i.e., how they behave in the long run. In such cases, we need real analysis, the area of mathematics that deals with limits and the foundations of calculus. In a prior work, we used real analysis in ACL2s to study the asymptotic behavior of the RTO computation, commonly used in congestion control algorithms across the Internet. One key component in our RTO computation analysis was proving in ACL2s that for all alpha in [0, 1), the limit as n approaches infinity of alpha raised to n is zero. Whereas the most obvious proof strategy involves the logarithm, whose codomain includes irrationals, by default ACL2 only supports rationals, which forced us to take a non-standard approach. In this paper, we explore different approaches to proving the above result in ACL2(r) and ACL2s, from the perspective of a relatively new user to each. We also contextualize the theorem by showing how it allowed us to prove important asymptotic properties of the RTO computation. Finally, we discuss tradeoffs between the various proof strategies and directions for future research.",
        "published": "2023-11-15T10:46:33Z",
        "link": "http://arxiv.org/abs/2311.08855v1",
        "categories": [
            "cs.LO",
            "cs.MS"
        ]
    },
    {
        "title": "Semidefinite Programming by Projective Cutting Planes",
        "authors": [
            "Daniel Porumbel"
        ],
        "summary": "Seeking tighter relaxations of combinatorial optimization problems, semidefinite programming is a generalization of linear programming that offers better bounds and is still polynomially solvable. Yet, in practice, a semidefinite program is still significantly harder to solve than a similar-size Linear Program (LP). It is well-known that a semidefinite program can be written as an LP with infinitely-many cuts that could be solved by repeated separation in a Cutting-Planes scheme; this approach is likely to end up in failure. We proposed in [Projective Cutting-Planes, Daniel Porumbel, Siam Journal on Optimization, 2020] the Projective Cutting-Planes method that upgrades t he well-known separation sub-problem to the projection sub-problem: given a feasible $y$ inside a polytope $P$ and a direction $d$, find the maximum $t^*$ so that $y+t^*d\\in P$. Using this new sub-problem, one can generate a sequence of both inner and outer solutions that converge to the optimum over $P$. This paper shows that the projection sub-problem can be solved very efficiently in a semidefinite programming context, enabling the resulting method to compete very well with state-of-the-art semidefinite optimization software (refined over decades). Results suggest it may the fastest method for matrix sizes larger than $2000\\times 2000$.",
        "published": "2023-11-15T20:57:43Z",
        "link": "http://arxiv.org/abs/2311.09365v1",
        "categories": [
            "math.OC",
            "cs.MS",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Fast multiplication by two's complement addition of numbers represented   as a set of polynomial radix 2 indexes, stored as an integer list for   massively parallel computation",
        "authors": [
            "Mark Stocks"
        ],
        "summary": "We demonstrate a multiplication method based on numbers represented as set of polynomial radix 2 indices stored as an integer list. The 'polynomial integer index multiplication' method is a set of algorithms implemented in python code. We demonstrate the method to be faster than both the Number Theoretic Transform (NTT) and Karatsuba for multiplication within a certain bit range. Also implemented in python code for comparison purposes with the polynomial radix 2 integer method. We demonstrate that it is possible to express any integer or real number as a list of integer indices, representing a finite series in base two. The finite series of integer index representation of a number can then be stored and distributed across multiple CPUs / GPUs. We show that operations of addition and multiplication can be applied as two's complement additions operating on the index integer representations and can be fully distributed across a given CPU / GPU architecture. We demonstrate fully distributed arithmetic operations such that the 'polynomial integer index multiplication' method overcomes the current limitation of parallel multiplication methods. Ie, the need to share common core memory and common disk for the calculation of results and intermediate results.",
        "published": "2023-11-16T14:21:13Z",
        "link": "http://arxiv.org/abs/2311.09922v3",
        "categories": [
            "cs.MS",
            "cs.DC",
            "cs.DS",
            "cs.LG"
        ]
    },
    {
        "title": "DisCoPy: the Hierarchy of Graphical Languages in Python",
        "authors": [
            "Alexis Toumi",
            "Richie Yeung",
            "Boldizsár Poór",
            "Giovanni de Felice"
        ],
        "summary": "DisCoPy is a Python toolkit for computing with monoidal categories. It comes with two flexible data structures for string diagrams: the first one for planar monoidal categories based on lists of layers, the second one for symmetric monoidal categories based on cospans of hypergraphs. Algorithms for functor application then allow to translate string diagrams into code for numerical computation, be it differentiable, probabilistic or quantum. This report gives an overview of the library and the new developments released in its version 1.0. In particular, we showcase the implementation of diagram equality for a large fragment of the hierarchy of graphical languages for monoidal categories, as well as a new syntax for defining string diagrams as Python functions.",
        "published": "2023-11-17T16:03:08Z",
        "link": "http://arxiv.org/abs/2311.10608v1",
        "categories": [
            "math.CT",
            "cs.MS"
        ]
    },
    {
        "title": "Deriving Algorithms for Triangular Tridiagonalization a (Skew-)Symmetric   Matrix",
        "authors": [
            "Robert van de Geijn",
            "Maggie Myers",
            "RuQing G. Xu",
            "Devin Matthews"
        ],
        "summary": "We apply the FLAME methodology to derive algorithms hand in hand with their proofs of correctness for the computation of the $ L T L^T $ decomposition (with and without pivoting) of a skew-symmetric matrix. The approach yields known as well as new algorithms, presented using the FLAME notation. A number of BLAS-like primitives are exposed at the core of blocked algorithms that can attain high performance. The insights can be easily extended to yield algorithms for computing the $ L T L^T $ decomposition of a symmetric matrix.",
        "published": "2023-11-17T18:44:40Z",
        "link": "http://arxiv.org/abs/2311.10700v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "p-adaptive discontinuous Galerkin method for the shallow water equations   on heterogeneous computing architectures",
        "authors": [
            "Sara Faghih-Naini",
            "Vadym Aizinger",
            "Sebastian Kuckuk",
            "Richard Angersbach",
            "Harald Köstler"
        ],
        "summary": "Heterogeneous computing and exploiting integrated CPU-GPU architectures has become a clear current trend since the flattening of Moore's Law. In this work, we propose a numerical and algorithmic re-design of a p-adaptive quadrature-free discontinuous Galerkin method (DG) for the shallow water equations (SWE). Our new approach separates the computations of the non-adaptive (lower-order) and adaptive (higher-order) parts of the discretization form each other. Thereby, we can overlap computations of the lower-order and the higher-order DG solution components. Furthermore, we investigate execution times of main computational kernels and use automatic code generation to optimize their distribution between the CPU and GPU. Several setups, including a prototype of a tsunami simulation in a tide-driven flow scenario, are investigated, and the results show that significant performance improvements can be achieved in suitable setups.",
        "published": "2023-11-19T15:19:59Z",
        "link": "http://arxiv.org/abs/2311.11348v1",
        "categories": [
            "cs.MS",
            "cs.DC"
        ]
    },
    {
        "title": "An Assessment of PC-mer's Performance in Alignment-Free Phylogenetic   Tree Construction",
        "authors": [
            "Saeedeh Akbari Rokn Abadi",
            "Melika Honarmand",
            "Ali Hajialinaghi",
            "Somayyeh Koohi"
        ],
        "summary": "Background: Sequence comparison is essential in bioinformatics, serving various purposes such as taxonomy, functional inference, and drug discovery. The traditional method of aligning sequences for comparison is time-consuming, especially with large datasets. To overcome this, alignment-free methods have emerged as an alternative approach, prioritizing comparison scores over alignment itself. These methods directly compare sequences without the need for alignment. However, accurately representing the relationships between sequences is a significant challenge in the design of these tools. Methods:One of the alignment-free comparison approaches utilizes the frequency of fixed-length substrings, known as K-mers, which serves as the foundation for many sequence comparison methods. However, a challenge arises in these methods when increasing the length of the substring (K), as it leads to an exponential growth in the number of possible states. In this work, we explore the PC-mer method, which utilizes a more limited set of words that experience slower growth 2^k instead of 4^k compared to K. We conducted a comparison of sequences and evaluated how the reduced input vector size influenced the performance of the PC-mer method. Results: For the evaluation, we selected the Clustal Omega method as our reference approach, alongside three alignment-free methods: kmacs, FFP, and alfpy (word count). These methods also leverage the frequency of K-mers. We applied all five methods to 9 datasets for comprehensive analysis. The results were compared using phylogenetic trees and metrics such as Robinson-Foulds and normalized quartet distance (nQD). Conclusion: Our findings indicate that, unlike reducing the input features in other alignment-independent methods, the PC-mer method exhibits competitive performance when compared to the aforementioned methods especially when input sequences are very varied.",
        "published": "2023-11-21T09:19:45Z",
        "link": "http://arxiv.org/abs/2311.12898v1",
        "categories": [
            "q-bio.QM",
            "cs.MS"
        ]
    },
    {
        "title": "Exact Combinatorial Optimization with Temporo-Attentional Graph Neural   Networks",
        "authors": [
            "Mehdi Seyfi",
            "Amin Banitalebi-Dehkordi",
            "Zirui Zhou",
            "Yong Zhang"
        ],
        "summary": "Combinatorial optimization finds an optimal solution within a discrete set of variables and constraints. The field has seen tremendous progress both in research and industry. With the success of deep learning in the past decade, a recent trend in combinatorial optimization has been to improve state-of-the-art combinatorial optimization solvers by replacing key heuristic components with machine learning (ML) models. In this paper, we investigate two essential aspects of machine learning algorithms for combinatorial optimization: temporal characteristics and attention. We argue that for the task of variable selection in the branch-and-bound (B&B) algorithm, incorporating the temporal information as well as the bipartite graph attention improves the solver's performance. We support our claims with intuitions and numerical results over several standard datasets used in the literature and competitions. Code is available at: https://developer.huaweicloud.com/develop/aigallery/notebook/detail?id=047c6cf2-8463-40d7-b92f-7b2ca998e935",
        "published": "2023-11-23T08:07:15Z",
        "link": "http://arxiv.org/abs/2311.13843v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MS"
        ]
    },
    {
        "title": "Mathematical Modelling and a Numerical Solution for High Precision   Satellite Ephemeris Determination",
        "authors": [
            "Aravind Gundakaram",
            "Abhirath Sangala",
            "Aditya Sai Ellendula",
            "Prachi Kansal",
            "Lanii Lakshitaa",
            "Suchir Reddy Punuru",
            "Nethra Naveen",
            "Sanjitha Jaggumantri"
        ],
        "summary": "In this paper, we develop a high-precision satellite orbit determination model for satellites orbiting the Earth. Solving this model entails numerically integrating the differential equation of motion governing a two-body system, employing Fehlberg's formulation and the Runge-Kutta class of embedded integrators with adaptive stepsize control. Relevant primary perturbing forces included in this mathematical model are the full force gravitational field model, Earth's atmospheric drag, third body gravitational effects and solar radiation pressure. Development of the high-precision model required accounting for the perturbing influences of Earth radiation pressure, Earth tides and relativistic effects. The model is then implemented to obtain a high-fidelity Earth orbiting satellite propagator, namely the Satellite Ephemeris Determiner (SED), which is comparable to the popular High Precision Orbit Propagator (HPOP). The architecture of SED, the methodology employed, and the numerical results obtained are presented.",
        "published": "2023-11-25T13:47:10Z",
        "link": "http://arxiv.org/abs/2311.15028v1",
        "categories": [
            "astro-ph.EP",
            "cs.MS",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Lineax: unified linear solves and linear least-squares in JAX and   Equinox",
        "authors": [
            "Jason Rader",
            "Terry Lyons",
            "Patrick Kidger"
        ],
        "summary": "We introduce Lineax, a library bringing linear solves and linear least-squares to the JAX+Equinox scientific computing ecosystem. Lineax uses general linear operators, and unifies linear solves and least-squares into a single, autodifferentiable API. Solvers and operators are user-extensible, without requiring the user to implement any custom derivative rules to get differentiability. Lineax is available at https://github.com/google/lineax.",
        "published": "2023-11-28T23:50:08Z",
        "link": "http://arxiv.org/abs/2311.17283v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "A New Challenging Curve Fitting Benchmark Test Set for Global   Optimization",
        "authors": [
            "Peicong Cheng",
            "Peicheng Cheng"
        ],
        "summary": "Benchmark sets are extremely important for evaluating and developing global optimization algorithms and related solvers. A new test set named PCC benchmark is proposed especially for optimization problems of nonlinear curve fitting for the first time, with the aspiration of helping developers to investigate and compare the performance of different global optimization solvers, as well as more effective optimization algorithms could be developed. Compared with the well-known classical nonlinear curve fitting benchmark set given by the National Institute of Standards and Technology (NIST) of USA, the most distinguishable features of the PCC benchmark are small problem dimensions, unconstrained with free search domain and high level of difficulty for obtaining global optimization solutions, which make the PCC benchmark be not only suitable for validating the effectiveness of different global optimization algorithms, but also more ideal for verifying and comparing various related solvers. Seven of the world's leading global optimization solvers, including Baron, Antigone, Couenne, Lingo, Scip, Matlab-GA and 1stOpt, are employed to test NIST and PCC benchmark thoroughly in terms of both effectiveness and efficiency. The results showed that the NIST benchmark is relatively simple and not suitable for global optimization testing, meanwhile the PCC benchmark is a unique, challenging and effective test dataset for global optimization.",
        "published": "2023-12-04T07:52:42Z",
        "link": "http://arxiv.org/abs/2312.01709v4",
        "categories": [
            "math.OC",
            "cs.MS",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "A Framework for Symmetric Self-Intersecting Surfaces",
        "authors": [
            "Christian Amend",
            "Tom Goertzen"
        ],
        "summary": "3D printing of surfaces has become an established method for prototyping and visualisation. However, surfaces often contain certain degenerations, such as self-intersecting faces or non-manifold parts, which pose problems in obtaining a 3D printable file. Therefore, it is necessary to examine these degenerations beforehand. Surfaces in three-dimensional space can be represented as embedded simplicial complexes describing a triangulation of the surface. We use this combinatorial description, and the notion of embedded simplicial surfaces (which can be understood as well-behaved surfaces) to give a framework for obtaining 3D printable files. This provides a new perspective on self-intersecting triangulated surfaces in three-dimensional space. Our method first retriangulates a surface using a minimal number of triangles, then computes its outer hull, and finally treats non-manifold parts. To this end, we prove an initialisation criterion for the computation of the outer hull. We also show how symmetry properties can be used to simplify computations. Implementations of the proposed algorithms are given in the computer algebra system GAP4. To verify our methods, we use a dataset of self-intersecting symmetric icosahedra. Exploiting the symmetry of the underlying embedded complex leads to a notable speed-up and enhanced numerical robustness when computing a retriangulation, compared to methods that do not take advantage of symmetry.",
        "published": "2023-12-04T18:46:42Z",
        "link": "http://arxiv.org/abs/2312.02113v2",
        "categories": [
            "cs.CG",
            "cs.MS",
            "math.CO"
        ]
    },
    {
        "title": "Mathematical Supplement for the $\\texttt{gsplat}$ Library",
        "authors": [
            "Vickie Ye",
            "Angjoo Kanazawa"
        ],
        "summary": "This report provides the mathematical details of the gsplat library, a modular toolbox for efficient differentiable Gaussian splatting, as proposed by Kerbl et al. It provides a self-contained reference for the computations involved in the forward and backward passes of differentiable Gaussian splatting. To facilitate practical usage and development, we provide a user friendly Python API that exposes each component of the forward and backward passes in rasterization at github.com/nerfstudio-project/gsplat .",
        "published": "2023-12-04T18:50:41Z",
        "link": "http://arxiv.org/abs/2312.02121v1",
        "categories": [
            "cs.MS",
            "cs.CV",
            "cs.GR",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Impact of parallel code optimization on computer power consumption",
        "authors": [
            "E. A. Kiselev",
            "P. N. Telegin",
            "A. V. Baranov"
        ],
        "summary": "The increase in performance and power of computing systems requires the wider use of program optimizations. The goal of performing optimizations is not only to reduce program runtime, but also to reduce other computer resources including power consumption. The goal of the study was to evaluate the impact of different optimization levels and various optimization strategies on power consumption. In a series of experiments, it was established that the average power consumption tends to peak for the programs with optimized source code. The articles also describes the impact of changing computer architecture on power consumption graphs. The relationships between the average and median values of power consumption by example programs are considered. The possibility of creating program energy consumption profile for a parallel program is shown.",
        "published": "2023-12-06T06:48:16Z",
        "link": "http://arxiv.org/abs/2312.03315v1",
        "categories": [
            "cs.MS",
            "cs.DC",
            "68M20"
        ]
    },
    {
        "title": "Ricci-Notation Tensor Framework for Model-based Approaches to Imaging",
        "authors": [
            "Dileepan Joseph"
        ],
        "summary": "Model-based approaches to imaging, like specialized image enhancements in astronomy, facilitate explanations of relationships between observed inputs and computed outputs. These models may be expressed with extended matrix-vector (EMV) algebra, especially when they involve only scalars, vectors, and matrices, and with n-mode or index notations, when they involve multidimensional arrays, also called numeric tensors or, simply, tensors. While this paper features an example, inspired by exoplanet imaging, that employs tensors to reveal (inverse) 2D fast Fourier transforms in an image enhancement model, the work is actually about the tensor algebra and software, or tensor frameworks, available for model-based imaging. The paper proposes a Ricci-notation tensor (RT) framework, comprising a dual-variant index notation, with Einstein summation convention, and codesigned object-oriented software, called the RTToolbox for MATLAB. Extensions to Ricci notation offer novel representations for entrywise, pagewise, and broadcasting operations popular in EMV frameworks for imaging. Complementing the EMV algebra computable with MATLAB, the RTToolbox demonstrates programmatic and computational efficiency via careful design of numeric tensor and dual-variant index classes. Compared to its closest competitor, also a numeric tensor framework that uses index notation, the RT framework enables superior ways to model imaging problems and, thereby, to develop solutions.",
        "published": "2023-12-07T03:25:40Z",
        "link": "http://arxiv.org/abs/2312.04018v3",
        "categories": [
            "cs.MS",
            "astro-ph.IM",
            "eess.IV",
            "G.4; I.4.3"
        ]
    },
    {
        "title": "Efficient Implementation of Interior-Point Methods for Quantum Relative   Entropy",
        "authors": [
            "Mehdi Karimi",
            "Levent Tuncel"
        ],
        "summary": "Quantum Relative Entropy (QRE) programming is a recently popular and challenging class of convex optimization problems with significant applications in quantum computing and quantum information theory. We are interested in modern interior point (IP) methods based on optimal self-concordant barriers for the QRE cone. A range of theoretical and numerical challenges associated with such barrier functions and the QRE cones have hindered the scalability of IP methods. To address these challenges, we propose a series of numerical and linear algebraic techniques and heuristics aimed at enhancing the efficiency of gradient and Hessian computations for the self-concordant barrier function, solving linear systems, and performing matrix-vector products. We also introduce and deliberate about some interesting concepts related to QRE such as symmetric quantum relative entropy (SQRE). We also introduce a two-phase method for performing facial reduction that can significantly improve the performance of QRE programming. Our new techniques have been implemented in the latest version (DDS 2.2) of the software package DDS. In addition to handling QRE constraints, DDS accepts any combination of several other conic and non-conic convex constraints. Our comprehensive numerical experiments encompass several parts including 1) a comparison of DDS 2.2 with Hypatia for the nearest correlation matrix problem, 2) using DDS for combining QRE constraints with various other constraint types, and 3) calculating the key rate for quantum key distribution (QKD) channels and presenting results for several QKD protocols.",
        "published": "2023-12-12T17:05:38Z",
        "link": "http://arxiv.org/abs/2312.07438v3",
        "categories": [
            "quant-ph",
            "cs.MS",
            "math.OC"
        ]
    },
    {
        "title": "Performance of linear solvers in tensor-train format on current   multicore architectures",
        "authors": [
            "Melven Röhrig-Zöllner",
            "Manuel Joey Becklas",
            "Jonas Thies",
            "Achim Basermann"
        ],
        "summary": "Tensor networks are a class of algorithms aimed at reducing the computational complexity of high-dimensional problems. They are used in an increasing number of applications, from quantum simulations to machine learning. Exploiting data parallelism in these algorithms is key to using modern hardware. However, there are several ways to map required tensor operations onto linear algebra routines (\"building blocks\"). Optimizing this mapping impacts the numerical behavior, so computational and numerical aspects must be considered hand-in-hand. In this paper we discuss the performance of solvers for low-rank linear systems in the tensor-train format (also known as matrix-product states). We consider three popular algorithms: TT-GMRES, MALS, and AMEn. We illustrate their computational complexity based on the example of discretizing a simple high-dimensional PDE in, e.g., $50^{10}$ grid points. This shows that the projection to smaller sub-problems for MALS and AMEn reduces the number of floating-point operations by orders of magnitude. We suggest optimizations regarding orthogonalization steps, singular value decompositions, and tensor contractions. In addition, we propose a generic preconditioner based on a TT-rank-1 approximation of the linear operator. Overall, we obtain roughly a 5x speedup over the reference algorithm for the fastest method (AMEn) on a current multicore CPU.",
        "published": "2023-12-13T09:28:09Z",
        "link": "http://arxiv.org/abs/2312.08006v2",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "Adaptive Improvements of Multi-Objective Branch and Bound",
        "authors": [
            "Julius Bauß",
            "Sophie N. Parragh",
            "Michael Stiglmayr"
        ],
        "summary": "Branch and bound methods which are based on the principle \"divide and conquer\" are a well established solution approach in single-objective integer programming. In multi-objective optimization branch and bound algorithms are increasingly attracting interest. However, the larger number of objectives raises additional difficulties for implicit enumeration approaches like branch and bound. Since bounding and pruning is considerably weaker in multiple objectives, many branches have to be (partially) searched and may not be pruned directly. The adaptive use of objective space information can guide the search in promising directions to determine a good approximation of the Pareto front already in early stages of the algorithm. In particular we focus in this article on improving the branching and queuing of subproblems and the handling of lower bound sets.   In our numerical test we evaluate the impact of the proposed methods in comparison to a standard implementation of multiobjective branch and bound on knapsack problems, generalized assignment problems and (un)capacitated facility location problems.",
        "published": "2023-12-19T14:27:13Z",
        "link": "http://arxiv.org/abs/2312.12192v1",
        "categories": [
            "math.OC",
            "cs.DM",
            "cs.MS",
            "90C29"
        ]
    },
    {
        "title": "Using monodromy to recover symmetries of polynomial systems",
        "authors": [
            "Timothy Duff",
            "Viktor Korotynskiy",
            "Tomas Pajdla",
            "Margaret Regan"
        ],
        "summary": "Galois/monodromy groups attached to parametric systems of polynomial equations provide a method for detecting the existence of symmetries in solution sets. Beyond the question of existence, one would like to compute formulas for these symmetries, towards the eventual goal of solving the systems more efficiently. We describe and implement one possible approach to this task using numerical homotopy continuation and multivariate rational function interpolation. We describe additional methods that detect and exploit a priori unknown quasi-homogeneous structure in symmetries. These methods extend the range of interpolation to larger examples, including applications with nonlinear symmetries drawn from vision and robotics.",
        "published": "2023-12-20T01:05:00Z",
        "link": "http://arxiv.org/abs/2312.12685v1",
        "categories": [
            "math.AG",
            "cs.MS"
        ]
    },
    {
        "title": "Strassen's Matrix Multiplication Algorithm Is Still Faster",
        "authors": [
            "Paolo D'Alberto"
        ],
        "summary": "Recently, reinforcement algorithms discovered new algorithms that really jump-started a wave of excitements and a flourishing of publications. However, there is little on implementations, applications, and, especially, no absolute performance and, we show here they are not here to replace Strassen's original fast matrix multiplication yet. We present Matrix Flow, this is a simple Python project for the automatic formulation, design, implementation, code generation, and execution of fast matrix multiplication algorithms for CPUs, using BLAS interface GPUs, and in the future other accelerators. We shall not play with module-2 (Z2) algorithms and, for simplicity, we present only square double-precision matrices. By means of factorizing the operand matrices we can express many algorithms and prove them correct. These algorithms are represented by Data Flows and matrix data partitions: a Directed Acyclic Graph. We show that Strassen's original algorithm is still the top choice even for modern GPUs. We also address error analysis in double precision, because integer computations are correct, always",
        "published": "2023-12-20T03:09:50Z",
        "link": "http://arxiv.org/abs/2312.12732v1",
        "categories": [
            "cs.MS",
            "cs.PF",
            "97N80",
            "G.4"
        ]
    },
    {
        "title": "Implementation of the Emulator-based Component Analysis",
        "authors": [
            "Anton Vladyka",
            "Eemeli A. Eronen",
            "Johannes Niskanen"
        ],
        "summary": "We present a PyTorch-powered implementation of the emulator-based component analysis used for ill-posed numerical non-linear inverse problems, where an approximate emulator for the forward problem is known. This emulator may be a numerical model, an interpolating function, or a fitting function such as a neural network. With the help of the emulator and a data set, the method seeks dimensionality reduction by projection in the variable space so that maximal variance of the target (response) values of the data is covered. The obtained basis set for projection in the variable space defines a subspace of the greatest response for the outcome of the forward problem. The method allows for the reconstruction of the coordinates in this subspace for an approximate solution to the inverse problem. We present an example of using the code provided as a Python class.",
        "published": "2023-12-20T12:14:25Z",
        "link": "http://arxiv.org/abs/2312.12967v2",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "Automated MPI-X code generation for scalable finite-difference solvers",
        "authors": [
            "George Bisbas",
            "Rhodri Nelson",
            "Mathias Louboutin",
            "Fabio Luporini",
            "Paul H. J. Kelly",
            "Gerard Gorman"
        ],
        "summary": "Partial differential equations (PDEs) are crucial in modeling diverse phenomena across scientific disciplines, including seismic and medical imaging, computational fluid dynamics, image processing, and neural networks. Solving these PDEs at scale is an intricate and time-intensive process that demands careful tuning. This paper introduces automated code-generation techniques specifically tailored for distributed memory parallelism (DMP) to execute explicit finite-difference (FD) stencils at scale, a fundamental challenge in numerous scientific applications. These techniques are implemented and integrated into the Devito DSL and compiler framework, a well-established solution for automating the generation of FD solvers based on a high-level symbolic math input. Users benefit from modeling simulations for real-world applications at a high-level symbolic abstraction and effortlessly harnessing HPC-ready distributed-memory parallelism without altering their source code. This results in drastic reductions both in execution time and developer effort. A comprehensive performance evaluation of Devito's DMP via MPI demonstrates highly competitive strong and weak scaling on CPU and GPU clusters, proving its effectiveness and capability to meet the demands of large-scale scientific simulations.",
        "published": "2023-12-20T15:15:56Z",
        "link": "http://arxiv.org/abs/2312.13094v4",
        "categories": [
            "cs.DC",
            "cs.MS",
            "cs.PF"
        ]
    },
    {
        "title": "MindOpt Adapter for CPLEX Benchmarking Performance Analysis",
        "authors": [
            "Mou Sun",
            "Tao Li",
            "Wotao Yin"
        ],
        "summary": "This report provides a comprehensive analysis of the performance of MindOpt Adapter for CPLEX 12.9 in benchmark testing. CPLEX, recognized as a robust Mixed Integer Programming (MIP) solver, has faced some scrutiny regarding its performance on MIPLIB 2017 when configured to default settings. MindOpt Adapter aims to enhance CPLEX's performance by automatically applying improved configurations for solving optimization problems. Our testing demonstrates that MindOpt Adapter for CPLEX yields successfully solved 232 of the 240 problems in the MIPLIB 2017 benchmark set. This performance surpasses all the other solvers in terms of the number of problems solved and the geometric mean of running times. The report provides a comparison of the benchmark results against the outcomes achieved by CPLEX under its default configuration.",
        "published": "2023-12-21T01:59:33Z",
        "link": "http://arxiv.org/abs/2312.13527v4",
        "categories": [
            "cs.MS",
            "math.OC"
        ]
    },
    {
        "title": "Parametric \"Non-nested\" Discriminants for Multiplicities of Univariate   Polynomials",
        "authors": [
            "Hoon Hong",
            "Jing Yang"
        ],
        "summary": "We consider the problem of complex root classification, i.e., finding the conditions on the coefficients of a univariate polynomial for all possible multiplicity structures on its complex roots. It is well known that such conditions can be written as conjunctions of several polynomial equations and one inequation in the coefficients. Those polynomials in the coefficients are called discriminants for multiplicities. It is well known that discriminants can be obtained by using repeated parametric gcd's. The resulting discriminants are usually nested determinants, that is, determinants of matrices whose entries are determinants, and so son. In this paper, we give a new type of discriminants which are not based on repeated gcd's. The new discriminants are simpler in that they are non-nested determinants and have smaller maximum degrees.",
        "published": "2023-01-01T00:57:32Z",
        "link": "http://arxiv.org/abs/2301.00315v3",
        "categories": [
            "cs.SC",
            "math.AC",
            "12D10, 68W30"
        ]
    },
    {
        "title": "Computing square roots in quaternion algebras",
        "authors": [
            "Przemysław Koprowski"
        ],
        "summary": "We present an explicit algorithmic method for computing square roots in quaternion algebras over global fields of characteristic different from 2.",
        "published": "2023-01-02T16:34:52Z",
        "link": "http://arxiv.org/abs/2301.00743v4",
        "categories": [
            "cs.SC",
            "math.RA",
            "68W30, 11Y40, 11R52",
            "I.1.2"
        ]
    },
    {
        "title": "Proofs of Modulo 11 and 13 Cylindric Kanade-Russell Conjectures for   $A_2$ Rogers-Ramanujan Type Identities",
        "authors": [
            "Ali Kemal Uncu"
        ],
        "summary": "We present proofs of two new families of sum-product identities arising from the cylindric partitions paradigm. Most of the presented expressions, the related sum-product identities, and the ingredients for the proofs were first conjectured by Kanade-Russell in the spirit of Andrews-Schilling-Warnaar identities of the $A_2$ Rogers-Ramanujan type. We follow the footsteps of Kanade-Russell while we alter the computations heavily to accomplish our goals.",
        "published": "2023-01-03T21:25:23Z",
        "link": "http://arxiv.org/abs/2301.01359v1",
        "categories": [
            "math.NT",
            "cs.SC",
            "math.CO",
            "math.RT",
            "05A15, 05A17, 05A19, 11B65, 11P84, 17B65, 68R05"
        ]
    },
    {
        "title": "An Automatic Method for Generating Symbolic Expressions of Zernike   Circular Polynomials",
        "authors": [
            "Hong-Yan Zhang",
            "Yu Zhou",
            "Fu-Yun Li"
        ],
        "summary": "Zernike circular polynomials (ZCP) play a significant role in optics engineering. The symbolic expressions for ZCP are valuable for theoretic analysis and engineering designs. However, there are still two problems which remain open: firstly, there is a lack of sufficient mathematical formulas of the ZCP for optics designers; secondly the formulas for inter-conversion of Noll's single index and Born-Wolf's double indices of ZCP are neither uniquely determinate nor satisfactory. An automatic method for generating symbolic expressions for ZCP is proposed based on five essential factors: the new theorems for converting the single/double indices of the ZCP, the robust and effective numeric algorithms for computing key parameters of ZCP, the symbolic algorithms for generating mathematical expressions of ZCP, and meta-programming \\& \\LaTeX{} programming for generating the table of ZCP. The theorems, method, algorithms and system architecture proposed are beneficial to both optics design process, optics software, computer-output typesetting in publishing industry as well as STEM education.",
        "published": "2023-01-05T00:33:55Z",
        "link": "http://arxiv.org/abs/2301.01859v3",
        "categories": [
            "cs.SC",
            "cs.MS"
        ]
    },
    {
        "title": "D-Algebraic Functions",
        "authors": [
            "Rida Ait El Manssour",
            "Anna-Laura Sattelberger",
            "Bertrand Teguia Tabuguia"
        ],
        "summary": "Differentially-algebraic (D-algebraic) functions are solutions of polynomial equations in the function, its derivatives, and the independent variables. We revisit closure properties of these functions by providing constructive proofs. We present algorithms to compute algebraic differential equations for compositions and arithmetic manipulations of univariate D-algebraic functions and derive bounds for the order of the resulting differential equations. We apply our methods to examples in the sciences.",
        "published": "2023-01-06T13:55:45Z",
        "link": "http://arxiv.org/abs/2301.02512v3",
        "categories": [
            "math.AG",
            "cs.SC",
            "math.CA",
            "12H05, 68W30 (primary), 34-04 (secondary)"
        ]
    },
    {
        "title": "Isolating Bounded and Unbounded Real Roots of a Mixed   Trigonometric-Polynomial",
        "authors": [
            "Rizeng Chen",
            "Haokun Li",
            "Bican Xia",
            "Tianqi Zhao",
            "Tao Zheng"
        ],
        "summary": "Mixed trigonometric-polynomials (MTPs) are functions of the form $f(x,\\sin{x}, \\cos{x})$ with $f\\in\\mathbb{Q}[x_1,x_2,x_3]$. In this paper, an algorithm ``isolating\" all the real roots of an MTP is provided and implemented. It automatically divides the real roots into two parts: one consists of finitely many ``bounded\" roots in an interval $[\\mu_-,\\mu_+]$ while the other consists of probably countably many ``periodic\" roots in $\\mathbb{R}\\backslash[\\mu_-,\\mu_+]$. For bounded roots, the algorithm returns isolating intervals and corresponding multiplicities while for periodic roots, it returns finitely many mutually disjoint small intervals $I_i\\subset[-\\pi,\\pi]$, integers $c_i>0$ and multisets of root multiplicity $\\{m_{j,i}\\}_{j=1}^{c_i}$ such that any periodic root $t>\\mu_+$ is in the set $(\\sqcup_i\\cup_{k\\in\\mathbb{N}}(I_i+2k\\pi))$ and any interval $I_i+2k\\pi\\subset(\\mu_+,\\infty)$ contains exactly $c_i$ periodic roots with multiplicities $m_{1,i},...,m_{c_i,i}$, respectively. The effectiveness and efficiency of the algorithm are shown by experiments. %In particular, our results indicate that the ``distributions\" of the roots of an MTP in the ``periods\" $(-\\pi,\\pi]+2k\\pi$ sufficiently far from $0$ share a same pattern. Besides, the method used to isolate the roots in $[\\mu_-,\\mu_+]$ is applicable to any other bounded interval as well. The algorithm takes advantages of the weak Fourier sequence technique and deals with the intervals period-by-period without scaling the coordinate so to keep the length of the sequence short. The new approaches can easily be modified to decide whether there is any root, or whether there are infinitely many roots in unbounded intervals of the form $(-\\infty,a)$ or $(a,\\infty)$ with $a\\in\\mathbb{Q}$.",
        "published": "2023-01-14T07:48:25Z",
        "link": "http://arxiv.org/abs/2301.05847v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Symbolic expression generation via Variational Auto-Encoder",
        "authors": [
            "Sergei Popov",
            "Mikhail Lazarev",
            "Vladislav Belavin",
            "Denis Derkach",
            "Andrey Ustyuzhanin"
        ],
        "summary": "There are many problems in physics, biology, and other natural sciences in which symbolic regression can provide valuable insights and discover new laws of nature. A widespread Deep Neural Networks do not provide interpretable solutions. Meanwhile, symbolic expressions give us a clear relation between observations and the target variable. However, at the moment, there is no dominant solution for the symbolic regression task, and we aim to reduce this gap with our algorithm. In this work, we propose a novel deep learning framework for symbolic expression generation via variational autoencoder (VAE). In a nutshell, we suggest using a VAE to generate mathematical expressions, and our training strategy forces generated formulas to fit a given dataset. Our framework allows encoding apriori knowledge of the formulas into fast-check predicates that speed up the optimization process. We compare our method to modern symbolic regression benchmarks and show that our method outperforms the competitors under noisy conditions. The recovery rate of SEGVAE is 65% on the Ngyuen dataset with a noise level of 10%, which is better than the previously reported SOTA by 20%. We demonstrate that this value depends on the dataset and can be even higher.",
        "published": "2023-01-15T10:23:53Z",
        "link": "http://arxiv.org/abs/2301.06064v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.SC"
        ]
    },
    {
        "title": "Neuro-Symbolic World Models for Adapting to Open World Novelty",
        "authors": [
            "Jonathan Balloch",
            "Zhiyu Lin",
            "Robert Wright",
            "Xiangyu Peng",
            "Mustafa Hussain",
            "Aarun Srinivas",
            "Julia Kim",
            "Mark O. Riedl"
        ],
        "summary": "Open-world novelty--a sudden change in the mechanics or properties of an environment--is a common occurrence in the real world. Novelty adaptation is an agent's ability to improve its policy performance post-novelty. Most reinforcement learning (RL) methods assume that the world is a closed, fixed process. Consequentially, RL policies adapt inefficiently to novelties. To address this, we introduce WorldCloner, an end-to-end trainable neuro-symbolic world model for rapid novelty adaptation. WorldCloner learns an efficient symbolic representation of the pre-novelty environment transitions, and uses this transition model to detect novelty and efficiently adapt to novelty in a single-shot fashion. Additionally, WorldCloner augments the policy learning process using imagination-based adaptation, where the world model simulates transitions of the post-novelty environment to help the policy adapt. By blending ''imagined'' transitions with interactions in the post-novelty environment, performance can be recovered with fewer total environment interactions. Using environments designed for studying novelty in sequential decision-making problems, we show that the symbolic world model helps its neural policy adapt more efficiently than model-based and model-based neural-only reinforcement learning methods.",
        "published": "2023-01-16T07:49:12Z",
        "link": "http://arxiv.org/abs/2301.06294v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.SC"
        ]
    },
    {
        "title": "Federated Automatic Differentiation",
        "authors": [
            "Keith Rush",
            "Zachary Charles",
            "Zachary Garrett"
        ],
        "summary": "Federated learning (FL) is a general framework for learning across an axis of group partitioned data (heterogeneous clients) while preserving data privacy, under the orchestration of a central server. FL methods often compute gradients of loss functions purely locally (ie. entirely at each client, or entirely at the server), typically using automatic differentiation (AD) techniques. We propose a federated automatic differentiation (FAD) framework that 1) enables computing derivatives of functions involving client and server computation as well as communication between them and 2) operates in a manner compatible with existing federated technology. In other words, FAD computes derivatives across communication boundaries. We show, in analogy with traditional AD, that FAD may be implemented using various accumulation modes, which introduce distinct computation-communication trade-offs and systems requirements. Further, we show that a broad class of federated computations is closed under these various modes of FAD, implying in particular that if the original computation can be implemented using privacy-preserving primitives, its derivative may be computed using only these same primitives. We then show how FAD can be used to create algorithms that dynamically learn components of the algorithm itself. In particular, we show that FedAvg-style algorithms can exhibit significantly improved performance by using FAD to adjust the server optimization step automatically, or by using FAD to learn weighting schemes for computing weighted averages across clients.",
        "published": "2023-01-18T22:28:49Z",
        "link": "http://arxiv.org/abs/2301.07806v2",
        "categories": [
            "cs.LG",
            "cs.DC",
            "cs.SC"
        ]
    },
    {
        "title": "Discover governing differential equations from evolving systems",
        "authors": [
            "Yuanyuan Li",
            "Kai Wu",
            "Jing Liu"
        ],
        "summary": "Discovering the governing equations of evolving systems from available observations is essential and challenging. In this paper, we consider a new scenario: discovering governing equations from streaming data. Current methods struggle to discover governing differential equations with considering measurements as a whole, leading to failure to handle this task. We propose an online modeling method capable of handling samples one by one sequentially by modeling streaming data instead of processing the entire dataset. The proposed method performs well in discovering ordinary differential equations (ODEs) and partial differential equations (PDEs) from streaming data. Evolving systems are changing over time, which invariably changes with system status. Thus, finding the exact change points is critical. The measurement generated from a changed system is distributed dissimilarly to before; hence, the difference can be identified by the proposed method. Our proposal is competitive in identifying the change points and discovering governing differential equations in three hybrid systems and two switching linear systems.",
        "published": "2023-01-19T03:18:54Z",
        "link": "http://arxiv.org/abs/2301.07863v3",
        "categories": [
            "physics.comp-ph",
            "cs.LG",
            "cs.SC",
            "math.DS",
            "nlin.CD"
        ]
    },
    {
        "title": "Towards Rigorous Understanding of Neural Networks via   Semantics-preserving Transformations",
        "authors": [
            "Maximilian Schlüter",
            "Gerrit Nolte",
            "Alnis Murtovi",
            "Bernhard Steffen"
        ],
        "summary": "In this paper we present an algebraic approach to the precise and global verification and explanation of Rectifier Neural Networks, a subclass of Piece-wise Linear Neural Networks (PLNNs), i.e., networks that semantically represent piece-wise affine functions. Key to our approach is the symbolic execution of these networks that allows the construction of semantically equivalent Typed Affine Decision Structures (TADS). Due to their deterministic and sequential nature, TADS can, similarly to decision trees, be considered as white-box models and therefore as precise solutions to the model and outcome explanation problem. TADS are linear algebras which allows one to elegantly compare Rectifier Networks for equivalence or similarity, both with precise diagnostic information in case of failure, and to characterize their classification potential by precisely characterizing the set of inputs that are specifically classified or the set of inputs where two network-based classifiers differ. All phenomena are illustrated along a detailed discussion of a minimal, illustrative example: the continuous XOR function.",
        "published": "2023-01-19T11:35:07Z",
        "link": "http://arxiv.org/abs/2301.08013v2",
        "categories": [
            "cs.NE",
            "cs.SC"
        ]
    },
    {
        "title": "Logarithmically Sparse Symmetric Matrices",
        "authors": [
            "Dmitrii Pavlov"
        ],
        "summary": "A positive definite matrix is called logarithmically sparse if its matrix logarithm has many zero entries. Such matrices play a significant role in high-dimensional statistics and semidefinite optimization. In this paper, logarithmically sparse matrices are studied from the point of view of computational algebraic geometry: we present a formula for the dimension of the Zariski closure of a set of matrices with a given logarithmic sparsity pattern, give a degree bound for this variety and develop implicitization algorithms that allow to find its defining equations. We illustrate our approach with numerous examples.",
        "published": "2023-01-24T14:34:21Z",
        "link": "http://arxiv.org/abs/2301.10042v1",
        "categories": [
            "math.AG",
            "cs.SC"
        ]
    },
    {
        "title": "Differential Elimination and Algebraic Invariants of Polynomial   Dynamical Systems",
        "authors": [
            "William Simmons",
            "André Platzer"
        ],
        "summary": "Invariant sets are a key ingredient for verifying safety and other properties of cyber-physical systems that mix discrete and continuous dynamics. We adapt the elimination-theoretic Rosenfeld-Gr\\\"{o}bner algorithm to systematically obtain algebraic invariants of polynomial dynamical systems without using Gr\\\"{o}bner bases or quantifier elimination. We identify totally real varieties as an important class for efficient invariance checking.",
        "published": "2023-01-26T04:47:38Z",
        "link": "http://arxiv.org/abs/2301.10935v1",
        "categories": [
            "cs.SC",
            "cs.LO",
            "math.AG",
            "math.DS"
        ]
    },
    {
        "title": "The Automated Discovery of Kinetic Rate Models -- Methodological   Frameworks",
        "authors": [
            "Miguel Ángel de Carvalho Servia",
            "Ilya Orson Sandoval",
            "Klaus Hellgardt",
            "King Kuok",
            "Hii",
            "Dongda Zhang",
            "Ehecatl Antonio del Rio Chanona"
        ],
        "summary": "The industrialization of catalytic processes requires reliable kinetic models for their design, optimization and control. Mechanistic models require significant domain knowledge, while data-driven and hybrid models lack interpretability. Automated knowledge discovery methods, such as ALAMO (Automated Learning of Algebraic Models for Optimization), SINDy (Sparse Identification of Nonlinear Dynamics), and genetic programming, have gained popularity but suffer from limitations such as needing model structure assumptions, exhibiting poor scalability, and displaying sensitivity to noise. To overcome these challenges, we propose two methodological frameworks, ADoK-S and ADoK-W (Automated Discovery of Kinetic rate models using a Strong/Weak formulation of symbolic regression), for the automated generation of catalytic kinetic models using a robust criterion for model selection. We leverage genetic programming for model generation and a sequential optimization routine for model refinement. The frameworks are tested against three case studies of increasing complexity, demonstrating their ability to retrieve the underlying kinetic rate model with limited noisy data from the catalytic systems, showcasing their potential for chemical reaction engineering applications.",
        "published": "2023-01-26T19:09:47Z",
        "link": "http://arxiv.org/abs/2301.11356v2",
        "categories": [
            "cs.SC",
            "cs.CE",
            "q-bio.QM"
        ]
    },
    {
        "title": "Learning Modulo Theories",
        "authors": [
            "Matt Fredrikson",
            "Kaiji Lu",
            "Saranya Vijayakumar",
            "Somesh Jha",
            "Vijay Ganesh",
            "Zifan Wang"
        ],
        "summary": "Recent techniques that integrate \\emph{solver layers} into Deep Neural Networks (DNNs) have shown promise in bridging a long-standing gap between inductive learning and symbolic reasoning techniques. In this paper we present a set of techniques for integrating \\emph{Satisfiability Modulo Theories} (SMT) solvers into the forward and backward passes of a deep network layer, called SMTLayer. Using this approach, one can encode rich domain knowledge into the network in the form of mathematical formulas. In the forward pass, the solver uses symbols produced by prior layers, along with these formulas, to construct inferences; in the backward pass, the solver informs updates to the network, driving it towards representations that are compatible with the solver's theory. Notably, the solver need not be differentiable. We implement \\layername as a Pytorch module, and our empirical results show that it leads to models that \\emph{1)} require fewer training samples than conventional models, \\emph{2)} that are robust to certain types of covariate shift, and \\emph{3)} that ultimately learn representations that are consistent with symbolic knowledge, and thus naturally interpretable.",
        "published": "2023-01-26T21:46:23Z",
        "link": "http://arxiv.org/abs/2301.11435v1",
        "categories": [
            "cs.LG",
            "cs.SC"
        ]
    },
    {
        "title": "Exact hierarchical reductions of dynamical models via linear   transformations",
        "authors": [
            "Alexander Demin",
            "Elizaveta Demitraki",
            "Gleb Pogudin"
        ],
        "summary": "Dynamical models described by ordinary differential equations (ODEs) are a fundamental tool in the sciences and engineering. Exact reduction aims at producing a lower-dimensional model in which each macro-variable can be directly related to the original variables, and it is thus a natural step towards the model's formal analysis and mechanistic understanding. We present an algorithm which, given a polynomial ODE model, computes a longest possible chain of exact linear reductions of the model such that each reduction refines the previous one, thus giving a user control of the level of detail preserved by the reduction. This significantly generalizes over the existing approaches which compute only the reduction of the lowest dimension subject to an approach-specific constraint. The algorithm reduces finding exact linear reductions to a question about representations of finite-dimensional algebras. We provide an implementation of the algorithm, demonstrate its performance on a set of benchmarks, and illustrate the applicability via case studies. Our implementation is freely available at https://github.com/x3042/ExactODEReduction.jl",
        "published": "2023-01-27T11:08:55Z",
        "link": "http://arxiv.org/abs/2301.11653v2",
        "categories": [
            "eess.SY",
            "cs.MS",
            "cs.SC",
            "cs.SY",
            "math.DS",
            "34C20, 34-04, 16G10"
        ]
    },
    {
        "title": "Incorporating Background Knowledge in Symbolic Regression using a   Computer Algebra System",
        "authors": [
            "Charles Fox",
            "Neil Tran",
            "Nikki Nacion",
            "Samiha Sharlin",
            "Tyler R. Josephson"
        ],
        "summary": "Symbolic Regression (SR) can generate interpretable, concise expressions that fit a given dataset, allowing for more human understanding of the structure than black-box approaches. The addition of background knowledge (in the form of symbolic mathematical constraints) allows for the generation of expressions that are meaningful with respect to theory while also being consistent with data. We specifically examine the addition of constraints to traditional genetic algorithm (GA) based SR (PySR) as well as a Markov-chain Monte Carlo (MCMC) based Bayesian SR architecture (Bayesian Machine Scientist), and apply these to rediscovering adsorption equations from experimental, historical datasets. We find that, while hard constraints prevent GA and MCMC SR from searching, soft constraints can lead to improved performance both in terms of search effectiveness and model meaningfulness, with computational costs increasing by about an order-of-magnitude. If the constraints do not correlate well with the dataset or expected models, they can hinder the search of expressions. We find Bayesian SR is better these constraints (as the Bayesian prior) than by modifying the fitness function in the GA",
        "published": "2023-01-27T18:59:25Z",
        "link": "http://arxiv.org/abs/2301.11919v2",
        "categories": [
            "cs.LG",
            "cs.SC",
            "physics.chem-ph"
        ]
    },
    {
        "title": "A Survey on Compositional Generalization in Applications",
        "authors": [
            "Baihan Lin",
            "Djallel Bouneffouf",
            "Irina Rish"
        ],
        "summary": "The field of compositional generalization is currently experiencing a renaissance in AI, as novel problem settings and algorithms motivated by various practical applications are being introduced, building on top of the classical compositional generalization problem. This article aims to provide a comprehensive review of top recent developments in multiple real-life applications of the compositional generalization. Specifically, we introduce a taxonomy of common applications and summarize the state-of-the-art for each of those domains. Furthermore, we identify important current trends and provide new perspectives pertaining to the future of this burgeoning field.",
        "published": "2023-02-02T12:56:26Z",
        "link": "http://arxiv.org/abs/2302.01067v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.SC"
        ]
    },
    {
        "title": "PyGlove: Efficiently Exchanging ML Ideas as Code",
        "authors": [
            "Daiyi Peng",
            "Xuanyi Dong",
            "Esteban Real",
            "Yifeng Lu",
            "Quoc V. Le"
        ],
        "summary": "The increasing complexity and scale of machine learning (ML) has led to the need for more efficient collaboration among multiple teams. For example, when a research team invents a new architecture like \"ResNet,\" it is desirable for multiple engineering teams to adopt it. However, the effort required for each team to study and understand the invention does not scale well with the number of teams or inventions. In this paper, we present an extension of our PyGlove library to easily and scalably share ML ideas. PyGlove represents ideas as symbolic rule-based patches, enabling researchers to write down the rules for models they have not seen. For example, an inventor can write rules that will \"add skip-connections.\" This permits a network effect among teams: at once, any team can issue patches to all other teams. Such a network effect allows users to quickly surmount the cost of adopting PyGlove by writing less code quicker, providing a benefit that scales with time. We describe the new paradigm of organizing ML through symbolic patches and compare it to existing approaches. We also perform a case study of a large codebase where PyGlove led to an 80% reduction in the number of lines of code.",
        "published": "2023-02-03T18:52:09Z",
        "link": "http://arxiv.org/abs/2302.01918v1",
        "categories": [
            "cs.LG",
            "cs.SC"
        ]
    },
    {
        "title": "Invariants for neural automata",
        "authors": [
            "Jone Uria-Albizuri",
            "Giovanni Sirio Carmantini",
            "Peter beim Graben",
            "Serafim Rodrigues"
        ],
        "summary": "Computational modeling of neurodynamical systems often deploys neural networks and symbolic dynamics. A particular way for combining these approaches within a framework called vector symbolic architectures leads to neural automata. An interesting research direction we have pursued under this framework has been to consider mapping symbolic dynamics onto neurodynamics, represented as neural automata. This representation theory, enables us to ask questions, such as, how does the brain implement Turing computations. Specifically, in this representation theory, neural automata result from the assignment of symbols and symbol strings to numbers, known as G\\\"odel encoding. Under this assignment symbolic computation becomes represented by trajectories of state vectors in a real phase space, that allows for statistical correlation analyses with real-world measurements and experimental data. However, these assignments are usually completely arbitrary. Hence, it makes sense to address the problem question of, which aspects of the dynamics observed under such a representation is intrinsic to the dynamics and which are not. In this study, we develop a formally rigorous mathematical framework for the investigation of symmetries and invariants of neural automata under different encodings. As a central concept we define patterns of equality for such systems. We consider different macroscopic observables, such as the mean activation level of the neural network, and ask for their invariance properties. Our main result shows that only step functions that are defined over those patterns of equality are invariant under recodings, while the mean activation is not. Our work could be of substantial importance for related regression studies of real-world measurements with neurosymbolic processors for avoiding confounding results that are dependant on a particular encoding and not intrinsic to the dynamics.",
        "published": "2023-02-04T11:40:40Z",
        "link": "http://arxiv.org/abs/2302.02149v1",
        "categories": [
            "cs.NE",
            "cs.CL",
            "cs.FL",
            "cs.SC"
        ]
    },
    {
        "title": "Pourchet's theorem in action: decomposing univariate nonnegative   polynomials as sums of five squares",
        "authors": [
            "Victor Magron",
            "Przemysław Koprowski",
            "Tristan Vaccon"
        ],
        "summary": "Pourchet proved in 1971 that every nonnegative univariate polynomial with rational coefficients is a sum of five or fewer squares. Nonetheless, there are no known algorithms for constructing such a decomposition. The sole purpose of the present paper is to present a set of algorithms that decompose a given nonnegative polynomial into a sum of six (five under some unproven conjecture or when allowing weights) squares of polynomials. Moreover, we prove that the binary complexity can be expressed polynomially in terms of classical operations of computer algebra and algorithmic number theory.",
        "published": "2023-02-04T17:02:17Z",
        "link": "http://arxiv.org/abs/2302.02202v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Short proofs of ideal membership",
        "authors": [
            "Clemens Hofstadler",
            "Thibaut Verron"
        ],
        "summary": "A cofactor representation of an ideal element, that is, a representation in terms of the generators, can be considered as a certificate for ideal membership. Such a representation is typically not unique, and some can be a lot more complicated than others. In this work, we consider the problem of computing sparsest cofactor representations, i.e., representations with a minimal number of terms, of a given element in a polynomial ideal. While we focus on the more general case of noncommutative polynomials, all results also apply to the commutative setting. We show that the problem of computing cofactor representations with a bounded number of terms is decidable and NP-complete. Moreover, we provide a practical algorithm for computing sparse (not necessarily optimal) representations by translating the problem into a linear optimization problem and by exploiting properties of signature-based Gr\\\"obner basis algorithms. We show that for a certain class of ideals, representations computed by this method are actually optimal, and we present experimental data illustrating that it can lead to noticeably sparser cofactor representations.",
        "published": "2023-02-06T14:50:49Z",
        "link": "http://arxiv.org/abs/2302.02832v3",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Techniques to Improve Neural Math Word Problem Solvers",
        "authors": [
            "Youyuan Zhang"
        ],
        "summary": "Developing automatic Math Word Problem (MWP) solvers is a challenging task that demands the ability of understanding and mathematical reasoning over the natural language. Recent neural-based approaches mainly encode the problem text using a language model and decode a mathematical expression over quantities and operators iteratively. Note the problem text of a MWP consists of a context part and a question part, a recent work finds these neural solvers may only perform shallow pattern matching between the context text and the golden expression, where question text is not well used. Meanwhile, existing decoding processes fail to enforce the mathematical laws into the design, where the representations for mathematical equivalent expressions are different. To address these two issues, we propose a new encoder-decoder architecture that fully leverages the question text and preserves step-wise commutative law. Besides generating quantity embeddings, our encoder further encodes the question text and uses it to guide the decoding process. At each step, our decoder uses Deep Sets to compute expression representations so that these embeddings are invariant under any permutation of quantities. Experiments on four established benchmarks demonstrate that our framework outperforms state-of-the-art neural MWP solvers, showing the effectiveness of our techniques. We also conduct a detailed analysis of the results to show the limitations of our approach and further discuss the potential future work. Code is available at https://github.com/sophistz/Question-Aware-Deductive-MWP.",
        "published": "2023-02-06T22:41:51Z",
        "link": "http://arxiv.org/abs/2302.03145v1",
        "categories": [
            "cs.CL",
            "cs.SC"
        ]
    },
    {
        "title": "Refined telescoping algorithms in $RΠΣ$-extensions to reduce the   degrees of the denominators",
        "authors": [
            "Carsten Schneider"
        ],
        "summary": "We present a general framework in the setting of difference ring extensions that enables one to find improved representations of indefinite nested sums such that the arising denominators within the summands have reduced degrees. The underlying (parameterized) telescoping algorithms can be executed in $R\\Pi\\Sigma$-ring extensions that are built over general $\\Pi\\Sigma$-fields. An important application of this toolbox is the simplification of d'Alembertian and Liouvillian solutions coming from recurrence relations where the denominators of the arising sums do not factor nicely.",
        "published": "2023-02-07T16:19:28Z",
        "link": "http://arxiv.org/abs/2302.03563v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Newton iteration for lexicographic Gröbner bases in two variables",
        "authors": [
            "Éric Schost",
            "Catherine St-Pierre"
        ],
        "summary": "We present an $m$-adic Newton iteration with quadratic convergence for lexicographic Gr\\\"obner basis of zero dimensional ideals in two variables. We rely on a structural result about the syzygies in such a basis due to Conca and Valla, that allowed them to explicitly describe these Gr\\\"obner bases by affine parameters; our Newton iteration works directly with these parameters.",
        "published": "2023-02-07T21:54:59Z",
        "link": "http://arxiv.org/abs/2302.03766v1",
        "categories": [
            "math.AC",
            "cs.SC",
            "math.AG"
        ]
    },
    {
        "title": "A Unified Approach to Unimodality of Gaussian Polynomials",
        "authors": [
            "Christoph Koutschan",
            "Ali K. Uncu",
            "Elaine Wong"
        ],
        "summary": "In 2013, Pak and Panova proved the strict unimodality property of $q$-binomial coefficients $\\binom{\\ell+m}{m}_q$ (as polynomials in $q$) based on the combinatorics of Young tableaux and the semigroup property of Kronecker coefficients. They showed it to be true for all $\\ell,m\\geq 8$ and a few other cases. We propose a different approach to this problem based on computer algebra, where we establish a closed form for the coefficients of these polynomials and then use cylindrical algebraic decomposition to identify exactly the range of coefficients where strict unimodality holds. This strategy allows us to tackle generalizations of the problem, e.g., to show unimodality with larger gaps or unimodality of related sequences. In particular, we present proofs of two additional cases of a conjecture by Stanley and Zanello.",
        "published": "2023-02-08T14:08:56Z",
        "link": "http://arxiv.org/abs/2302.04067v2",
        "categories": [
            "cs.SC",
            "math.CO"
        ]
    },
    {
        "title": "Order bounds for $C^2$-finite sequences",
        "authors": [
            "Manuel Kauers",
            "Philipp Nuspl",
            "Veronika Pillwein"
        ],
        "summary": "A sequence is called $C$-finite if it satisfies a linear recurrence with constant coefficients. We study sequences which satisfy a linear recurrence with $C$-finite coefficients. Recently, it was shown that such $C^2$-finite sequences satisfy similar closure properties as $C$-finite sequences. In particular, they form a difference ring.   In this paper we present new techniques for performing these closure properties of $C^2$-finite sequences. These methods also allow us to derive order bounds which were not known before. Additionally, they provide more insight in the effectiveness of these computations.   The results are based on the exponent lattice of algebraic numbers. We present an iterative algorithm which can be used to compute bases of such lattices.",
        "published": "2023-02-08T14:17:44Z",
        "link": "http://arxiv.org/abs/2302.04070v1",
        "categories": [
            "math.RA",
            "cs.SC"
        ]
    },
    {
        "title": "Beating binary powering for polynomial matrices",
        "authors": [
            "Alin Bostan",
            "Vincent Neiger",
            "Sergey Yurkevich"
        ],
        "summary": "The $N$th power of a polynomial matrix of fixed size and degree can be computed by binary powering as fast as multiplying two polynomials of linear degree in~$N$. When Fast Fourier Transform (FFT) is available, the resulting complexity is \\emph{softly linear} in~$N$, i.e.~linear in~$N$ with extra logarithmic factors. We show that it is possible to beat binary powering, by an algorithm whose complexity is \\emph{purely linear} in~$N$, even in absence of FFT. The key result making this improvement possible is that the entries of the $N$th power of a polynomial matrix satisfy linear differential equations with polynomial coefficients whose orders and degrees are independent of~$N$. Similar algorithms are proposed for two related problems: computing the $N$th term of a C-finite sequence of polynomials, and modular exponentiation to the power $N$ for bivariate polynomials.",
        "published": "2023-02-08T19:28:20Z",
        "link": "http://arxiv.org/abs/2302.04299v2",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Symbolic Quantum Simulation with Quasimodo",
        "authors": [
            "Meghana Sistla",
            "Swarat Chaudhuri",
            "Thomas Reps"
        ],
        "summary": "The simulation of quantum circuits on classical computers is an important problem in quantum computing. Such simulation requires representations of distributions over very large sets of basis vectors, and recent work has used symbolic data-structures such as Binary Decision Diagrams (BDDs) for this purpose. In this tool paper, we present Quasimodo, an extensible, open-source Python library for symbolic simulation of quantum circuits. Quasimodo is specifically designed for easy extensibility to other backends. Quasimodo allows simulations of quantum circuits, checking properties of the outputs of quantum circuits, and debugging quantum circuits. It also allows the user to choose from among several symbolic data-structures -- both unweighted and weighted BDDs, and a recent structure called Context-Free-Language Ordered Binary Decision Diagrams (CFLOBDDs) -- and can be easily extended to support other symbolic data-structures.",
        "published": "2023-02-08T21:45:10Z",
        "link": "http://arxiv.org/abs/2302.04349v2",
        "categories": [
            "cs.FL",
            "cs.SC",
            "quant-ph"
        ]
    },
    {
        "title": "Exact computations with quasiseparable matrices",
        "authors": [
            "Clément Pernet",
            "Hippolyte Signargout",
            "Gilles Villard"
        ],
        "summary": "Quasi-separable matrices are a class of rank-structured matriceswidely used in numerical linear algebra and of growing interestin computer algebra, with applications in e.g. the linearization ofpolynomial matrices. Various representation formats exist for thesematrices that have rarely been compared.We show how the most central formats SSS and HSS can beadapted to symbolic computation, where the exact rank replacesthreshold based numerical ranks. We clarify their links and comparethem with the Bruhat format. To this end, we state their space andtime cost estimates based on fast matrix multiplication, and comparethem, with their leading constants. The comparison is supportedby software experiments.We make further progresses for the Bruhat format, for which wegive a generation algorithm, following a Crout elimination scheme,which specializes into fast algorithms for the construction from asparse matrix or from the sum of Bruhat representations.",
        "published": "2023-02-09T09:17:18Z",
        "link": "http://arxiv.org/abs/2302.04515v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Hermite Reduction for D-finite Functions via Integral Bases",
        "authors": [
            "Shaoshi Chen",
            "Lixin Du",
            "Manuel Kauers"
        ],
        "summary": "Trager's Hermite reduction solves the integration problem for algebraic functions via integral bases. A generalization of this algorithm to D-finite functions has so far been limited to the Fuchsian case. In the present paper, we remove this restriction and propose a reduction algorithm based on integral bases that is applicable to arbitrary D-finite functions.",
        "published": "2023-02-09T14:07:26Z",
        "link": "http://arxiv.org/abs/2302.04652v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Isolating clusters of zeros of analytic systems using arbitrary-degree   inflation",
        "authors": [
            "Michael Burr",
            "Kisun Lee",
            "Anton Leykin"
        ],
        "summary": "Given a system of analytic functions and an approximation to a cluster of zeros, we wish to construct two regions containing the cluster and no other zeros of the system. The smaller region tightly contains the cluster while the larger region separates it from the other zeros of the system. We achieve this using the method of inflation which, counterintuitively, relates it to another system that is more amenable to our task but whose associated cluster of zeros is larger.",
        "published": "2023-02-09T17:10:12Z",
        "link": "http://arxiv.org/abs/2302.04776v1",
        "categories": [
            "math.AG",
            "cs.SC"
        ]
    },
    {
        "title": "Certified simultaneous isotopic approximation of curves via subdivision",
        "authors": [
            "Michael Burr",
            "Michael Byrd"
        ],
        "summary": "We present a certified algorithm based on subdivision for computing an isotopic approximation to any number of curves in the plane. Our algorithm is based on the certified curve approximation algorithm of Plantinga and Vegter. The main challenge in this algorithm is to correctly and efficiently identify and isolate all intersections between the curves. To overcome this challenge, we introduce a new and simple test that guarantees the global correctness of our output. A main step in our algorithm for approximating any number of curves is to correctly approximate a pair of curves. In addition to developing the details of this special case, we provide complexity analyses for both the number of steps and the bit-complexity of this algorithm using both worst-case bounds as well as those based on continuous amortization.",
        "published": "2023-02-09T19:30:05Z",
        "link": "http://arxiv.org/abs/2302.04908v2",
        "categories": [
            "cs.CG",
            "cs.SC",
            "math.AG",
            "68W30, 13P15, 14Q05, 14Q20, 14Q30, 14P25"
        ]
    },
    {
        "title": "Refined $F_5$ Algorithms for Ideals of Minors of Square Matrices",
        "authors": [
            "Sriram Gopalakrishnan",
            "Vincent Neiger",
            "Mohab Safey El Din"
        ],
        "summary": "We consider the problem of computing a grevlex Gr\\\"obner basis for the set $F_r(M)$ of minors of size $r$ of an $n\\times n$ matrix $M$ of generic linear forms over a field of characteristic zero or large enough. Such sets are not regular sequences; in fact, the ideal $\\langle F_r(M) \\rangle$ cannot be generated by a regular sequence. As such, when using the general-purpose algorithm $F_5$ to find the sought Gr\\\"obner basis, some computing time is wasted on reductions to zero. We use known results about the first syzygy module of $F_r(M)$ to refine the $F_5$ algorithm in order to detect more reductions to zero. In practice, our approach avoids a significant number of reductions to zero. In particular, in the case $r=n-2$, we prove that our new algorithm avoids all reductions to zero, and we provide a corresponding complexity analysis which improves upon the previously known estimates.",
        "published": "2023-02-10T16:53:50Z",
        "link": "http://arxiv.org/abs/2302.05375v2",
        "categories": [
            "cs.SC",
            "math.AC"
        ]
    },
    {
        "title": "Lazard-style CAD and Equational Constraints",
        "authors": [
            "James H. Davenport",
            "Akshar S. Nair",
            "Gregory K. Sankaran",
            "Ali K. Uncu"
        ],
        "summary": "McCallum-style Cylindrical Algebra Decomposition (CAD) is a major improvement on the original Collins version, and has had many subsequent advances, notably for total or partial equational constraints. But it suffers from a problem with nullification. The recently-justified Lazard-style CAD does not have this problem. However, transporting the equational constraints work to Lazard-style does reintroduce nullification issues. This paper explains the problem, and the solutions to it, based on the second author's Ph.D. thesis and the Brown--McCallum improvement to Lazard.   With a single equational constraint, we can gain the same improvements in Lazard-style as in McCallum-style CAD . Moreover, our approach does not fail where McCallum would due to nullification. Unsurprisingly, it does not achieve the same level of improvement as it does in the non-nullified cases. We also consider the case of multiple equational constraints.",
        "published": "2023-02-11T23:24:07Z",
        "link": "http://arxiv.org/abs/2302.05813v2",
        "categories": [
            "cs.SC",
            "68W30",
            "I.1.2"
        ]
    },
    {
        "title": "SCL(FOL) Revisited",
        "authors": [
            "Martin Bromberger",
            "Simon Schwarz",
            "Christoph Weidenbach"
        ],
        "summary": "This paper presents an up-to-date and refined version of the SCL calculus for first-order logic without equality. The refinement mainly consists of the following two parts: First, we incorporate a stronger notion of regularity into SCL(FOL). Our regularity definition is adapted from the SCL(T) calculus. This adapted definition guarantees non-redundant clause learning during a run of SCL. However, in contrast to the original presentation, it does not require exhaustive propagation. Second, we introduce trail and model bounding to achieve termination guarantees. In previous versions, no termination guarantees about SCL were achieved. Last, we give rigorous proofs for soundness, completeness and clause learning guarantees of SCL(FOL) and put SCL(FOL) into context of existing first-order calculi.",
        "published": "2023-02-12T16:52:56Z",
        "link": "http://arxiv.org/abs/2302.05954v2",
        "categories": [
            "cs.LO",
            "cs.SC"
        ]
    },
    {
        "title": "Fast Algorithms for Discrete Differential Equations",
        "authors": [
            "Alin Bostan",
            "Hadrien Notarantonio",
            "Mohab Safey El Din"
        ],
        "summary": "Discrete Differential Equations (DDEs) are functional equations that relate polynomially a power series $F(t,u)$ in $t$ with polynomial coefficients in a \"catalytic\" variable $u$ and the specializations, say at $u=1$, of $F(t,u)$ and of some of its partial derivatives in $u$. DDEs occur frequently in combinatorics, especially in map enumeration. If a DDE is of fixed-point type then its solution $F(t,u)$ is unique, and a general result by Popescu (1986) implies that $F(t,u)$ is an algebraic power series. Constructive proofs of algebraicity for solutions of fixed-point type DDEs were proposed by Bousquet-M\\'elou and Jehanne (2006). Bostan et. al (2022) initiated a systematic algorithmic study of such DDEs of order 1.   We generalize this study to DDEs of arbitrary order. First, we propose nontrivial extensions of algorithms based on polynomial elimination and on the guess-and-prove paradigm. Second, we design two brand-new algorithms that exploit the special structure of the underlying polynomial systems. Last, but not least, we report on implementations that are able to solve highly challenging DDEs with a combinatorial origin.",
        "published": "2023-02-13T09:21:05Z",
        "link": "http://arxiv.org/abs/2302.06203v2",
        "categories": [
            "cs.SC",
            "math.AG",
            "math.CO"
        ]
    },
    {
        "title": "Fast evaluation and root finding for polynomials with floating-point   coefficients",
        "authors": [
            "Rémi Imbach",
            "Guillaume Moroz"
        ],
        "summary": "Evaluating or finding the roots of a polynomial $f(z) = f_0 + \\cdots + f_d z^d$ with floating-point number coefficients is a ubiquitous problem. By using a piecewise approximation of $f$ obtained with a careful use of the Newton polygon of $f$, we improve state-of-the-art upper bounds on the number of operations to evaluate and find the roots of a polynomial. In particular, if the coefficients of $f$ are given with $m$ significant bits, we provide for the first time an algorithm that finds all the roots of $f$ with a relative condition number lower than $2^m$, using a number of bit operations quasi-linear in the bit-size of the floating-point representation of $f$. Notably, our new approach handles efficiently polynomials with coefficients ranging from $2^{-d}$ to $2^d$, both in theory and in practice.",
        "published": "2023-02-13T10:29:31Z",
        "link": "http://arxiv.org/abs/2302.06244v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Transcendence Certificates for D-finite Functions",
        "authors": [
            "Manuel Kauers",
            "Christoph Koutschan",
            "Thibaut Verron"
        ],
        "summary": "Although in theory we can decide whether a given D-finite function is transcendental, transcendence proofs remain a challenge in practice. Typically, transcendence is certified by checking certain incomplete sufficient conditions. In this paper we propose an additional such condition which catches some cases on which other tests fail.",
        "published": "2023-02-13T14:36:20Z",
        "link": "http://arxiv.org/abs/2302.06396v2",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Signature Gröbner bases in free algebras over rings",
        "authors": [
            "Clemens Hofstadler",
            "Thibaut Verron"
        ],
        "summary": "We generalize signature Gr\\\"obner bases, previously studied in the free algebra over a field or polynomial rings over a ring, to ideals in the mixed algebra $R[x_1,...,x_k]\\langle y_1,\\dots,y_n \\rangle$ where $R$ is a principal ideal domain. We give an algorithm for computing them, combining elements from the theory of commutative and noncommutative (signature) Gr\\\"obner bases, and prove its correctness.   Applications include extensions of the free algebra with commutative variables, e.g., for homogenization purposes or for performing ideal theoretic operations such as intersections, and computations over $\\mathbb{Z}$ as universal proofs over fields of arbitrary characteristic.   By extending the signature cover criterion to our setting, our algorithm also lifts some technical restrictions from previous noncommutative signature-based algorithms, now allowing, e.g., elimination orderings. We provide a prototype implementation for the case when $R$ is a field, and show that our algorithm for the mixed algebra is more efficient than classical approaches using existing algorithms.",
        "published": "2023-02-13T16:04:09Z",
        "link": "http://arxiv.org/abs/2302.06483v2",
        "categories": [
            "math.AC",
            "cs.SC",
            "math.RA"
        ]
    },
    {
        "title": "A Poly-algorithmic Approach to Quantifier Elimination",
        "authors": [
            "James H. Davenport",
            "Zak P. Tonks",
            "Ali K. Uncu"
        ],
        "summary": "Cylindrical Algebraic Decomposition (CAD) was the first practical means for doing real quantifier elimination (QE), and is still a major method, with many improvements since Collins' original method. Nevertheless, its complexity is inherently doubly exponential in the number of variables. Where applicable, virtual term substitution (VTS) is more effective, turning a QE problem in $n$ variables to one in $n-1$ variables in one application, and so on. Hence there is scope for hybrid methods: doing VTS where possible then using CAD.   This paper describes such a poly-algorithmic implementation, based on the second author's Ph.D. thesis. The version of CAD used is based on a new implementation of Lazard's recently-justified method, with some improvements to handle equational constraints.",
        "published": "2023-02-14T03:49:24Z",
        "link": "http://arxiv.org/abs/2302.06814v2",
        "categories": [
            "cs.SC",
            "68W30",
            "I.1.2"
        ]
    },
    {
        "title": "The Role of Semantic Parsing in Understanding Procedural Text",
        "authors": [
            "Hossein Rajaby Faghihi",
            "Parisa Kordjamshidi",
            "Choh Man Teng",
            "James Allen"
        ],
        "summary": "In this paper, we investigate whether symbolic semantic representations, extracted from deep semantic parsers, can help reasoning over the states of involved entities in a procedural text. We consider a deep semantic parser~(TRIPS) and semantic role labeling as two sources of semantic parsing knowledge. First, we propose PROPOLIS, a symbolic parsing-based procedural reasoning framework. Second, we integrate semantic parsing information into state-of-the-art neural models to conduct procedural reasoning. Our experiments indicate that explicitly incorporating such semantic knowledge improves procedural understanding. This paper presents new metrics for evaluating procedural reasoning tasks that clarify the challenges and identify differences among neural, symbolic, and integrated models.",
        "published": "2023-02-14T04:59:33Z",
        "link": "http://arxiv.org/abs/2302.06829v2",
        "categories": [
            "cs.CL",
            "cs.SC"
        ]
    },
    {
        "title": "A Direttissimo Algorithm for Equidimensional Decomposition",
        "authors": [
            "Christian Eder",
            "Pierre Lairez",
            "Rafael Mohr",
            "Mohab Safey El Din"
        ],
        "summary": "We describe a recursive algorithm that decomposes an algebraic set into locally closed equidimensional sets, i.e. sets which each have irreducible components of the same dimension. At the core of this algorithm, we combine ideas from the theory of triangular sets, a.k.a. regular chains, with Gr\\\"obner bases to encode and work with locally closed algebraic sets. Equipped with this, our algorithm avoids projections of the algebraic sets that are decomposed and certain genericity assumptions frequently made when decomposing polynomial systems, such as assumptions about Noether position. This makes it produce fine decompositions on more structured systems where ensuring genericity assumptions often destroys the structure of the system at hand. Practical experiments demonstrate its efficiency compared to state-of-the-art implementations.",
        "published": "2023-02-16T09:42:55Z",
        "link": "http://arxiv.org/abs/2302.08174v2",
        "categories": [
            "cs.SC",
            "math.AC"
        ]
    },
    {
        "title": "Computing the Characteristic Polynomial of Endomorphisms of a finite   Drinfeld Module using Crystalline Cohomology",
        "authors": [
            "Yossef Musleh",
            "Éric Schost"
        ],
        "summary": "We present a new algorithm for computing the characteristic polynomial of an arbitrary endomorphism of a finite Drinfeld module using its associated crystalline cohomology. Our approach takes inspiration from Kedlaya's p-adic algorithm for computing the characteristic polynomial of the Frobenius endomorphism on a hyperelliptic curve using Monsky-Washnitzer cohomology. The method is specialized using a baby-step giant-step algorithm for the particular case of the Frobenius endomorphism, and in this case we include a complexity analysis that demonstrates asymptotic gains over previously existing approaches",
        "published": "2023-02-16T22:33:12Z",
        "link": "http://arxiv.org/abs/2302.08611v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Elimination ideal and bivariate resultant over finite fields",
        "authors": [
            "Gilles Villard"
        ],
        "summary": "A new algorithm is presented for computing the largest degree invariant factor of the Sylvester matrix (with respect either to $x$ or $y$) associated to two polynomials $a$ and $b$ in $\\mathbb F_q[x,y]$ which have no non-trivial common divisors. The algorithm is randomized of the Monte Carlo type and requires $O((de)^{1+\\epsilon}\\log(q) ^{1+o(1)})$ bit operations, where $d$ an $e$ respectively bound the input degrees in $x$ and in $y$. It follows that the same complexity estimate is valid for computing: a generator of the elimination ideal $\\langle a,b \\rangle \\cap \\mathbb F_q[x]$ (or $\\mathbb F_q[y]$), as soon as the polynomial system $a=b=0$ has not roots at infinity; the resultant of $a$ and $b$ when they are sufficiently generic, especially so that the Sylvester matrix has a unique non-trivial invariant factor. Our approach is to use the reduction of the problem to a problem of minimal polynomial in the quotient algebra $\\mathbb F_q[x,y]/\\langle a,b \\rangle$. By proposing a new method based on structured polynomial matrix division for computing with the elements in the quotient, we manage to improve the best known complexity bounds.",
        "published": "2023-02-17T14:20:59Z",
        "link": "http://arxiv.org/abs/2302.08891v1",
        "categories": [
            "cs.SC",
            "I.1.2"
        ]
    },
    {
        "title": "Jordan algebra in R",
        "authors": [
            "Robin K. S. Hankin"
        ],
        "summary": "In this short article I introduce the \"jordan\" package which provides functionality for working with different types of Jordan algebra. I give some numerical verification of the Jordan identity for the five types of Jordan algebras. The package is available on CRAN at https://CRAN.R-project.org/package=stokes.",
        "published": "2023-02-21T01:02:40Z",
        "link": "http://arxiv.org/abs/2303.06062v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Co-Driven Recognition of Semantic Consistency via the Fusion of   Transformer and HowNet Sememes Knowledge",
        "authors": [
            "Fan Chen",
            "Yan Huang",
            "Xinfang Zhang",
            "Kang Luo",
            "Jinxuan Zhu",
            "Ruixian He"
        ],
        "summary": "Semantic consistency recognition aims to detect and judge whether the semantics of two text sentences are consistent with each other. However, the existing methods usually encounter the challenges of synonyms, polysemy and difficulty to understand long text. To solve the above problems, this paper proposes a co-driven semantic consistency recognition method based on the fusion of Transformer and HowNet sememes knowledge. Multi-level encoding of internal sentence structures via data-driven is carried out firstly by Transformer, sememes knowledge base HowNet is introduced for knowledge-driven to model the semantic knowledge association among sentence pairs. Then, interactive attention calculation is carried out utilizing soft-attention and fusion the knowledge with sememes matrix. Finally, bidirectional long short-term memory network (BiLSTM) is exploited to encode the conceptual semantic information and infer the semantic consistency. Experiments are conducted on two financial text matching datasets (BQ, AFQMC) and a cross-lingual adversarial dataset (PAWSX) for paraphrase identification. Compared with lightweight models including DSSM, MwAN, DRCN, and pre-training models such as ERNIE etc., the proposed model can not only improve the accuracy of semantic consistency recognition effectively (by 2.19%, 5.57% and 6.51% compared with the DSSM, MWAN and DRCN models on the BQ dataset), but also reduce the number of model parameters (to about 16M). In addition, driven by the HowNet sememes knowledge, the proposed method is promising to adapt to scenarios with long text.",
        "published": "2023-02-21T09:53:19Z",
        "link": "http://arxiv.org/abs/2302.10570v1",
        "categories": [
            "cs.CL",
            "cs.AI",
            "cs.SC"
        ]
    },
    {
        "title": "Algorithm for connectivity queries on real algebraic curves",
        "authors": [
            "Md Nazrul Islam",
            "Adrien Poteaux",
            "Rémi Prébet"
        ],
        "summary": "We consider the problem of answering connectivity queries on a real algebraic curve. The curve is given as the real trace of an algebraic curve, assumed to be in generic position, and being defined by some rational parametrizations. The query points are given by a zero-dimensional parametrization. We design an algorithm which counts the number of connected components of the real curve under study, and decides which query point lie in which connected component, in time log-linear in $N^6$, where $N$ is the maximum of the degrees and coefficient bit-sizes of the polynomials given as input. This matches the currently best-known bound for computing the topology of real plane curves. The main novelty of this algorithm is the avoidance of the computation of the complete topology of the curve.",
        "published": "2023-02-22T12:40:48Z",
        "link": "http://arxiv.org/abs/2302.11347v3",
        "categories": [
            "cs.SC",
            "math.AG"
        ]
    },
    {
        "title": "In-place fast polynomial modular remainder",
        "authors": [
            "Jean-Guillaume Dumas",
            "Bruno Grenet"
        ],
        "summary": "We consider the simultaneously fast and in-place computation of the Euclidean polynomial modular remainder $R(X) $\\not\\equiv$ A(X) \\mod B(X)$ with $A$ and $B$ of respective degrees $n$ and $m $\\le$ n$. But fast algorithms for this usually come at the expense of (potentially large) extra temporary space. To remain in-place a further issue is to avoid the storage of the whole quotient $Q(X)$ such that $A=BQ+R$. If the multiplication of two polynomials of degree $k$ can be performed with $M(k)$ operations and $O(k)$ extra space, and if it is allowed to use the input space of $A$ or $B$ for intermediate computations, but putting $A$ and $B$ back to their initial states after the completion of the remainder computation, we here propose an in-place algorithm (that is with its extra required space reduced to $O(1)$ only) using at most $O(n/m M(m)\\log(m)$ arithmetic operations, if $\\M(m)$ is quasi-linear, or $O(n/m M(m)}$ otherwise. We also propose variants that compute -- still in-place and with the same kind of complexity bounds -- the over-place remainder $A(X) $\\not\\equiv$ A(X) \\mod B(X)$, the accumulated remainder $R(X) += A(X) \\mod B(X)$ and the accumulated modular multiplication $R(X) += A(X)C(X) \\mod B(X)$. To achieve this, we develop techniques for Toeplitz matrix operations which output is also part of the input. Fast and in-place accumulating versions are obtained for the latter, and thus for convolutions, and then used for polynomial remaindering. This is realized via further reductions to accumulated polynomial multiplication, for which fast in-place algorithms have recently been developed.",
        "published": "2023-02-27T09:08:34Z",
        "link": "http://arxiv.org/abs/2302.13600v6",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Sufficient conditions for the surjectivity of radical curve   parametrizations",
        "authors": [
            "Jorce Caravantes",
            "J. Rafael Sendra",
            "David Sevilla",
            "Carlos Villarino"
        ],
        "summary": "In this paper, we introduce the notion of surjective radical parametrization and we prove sufficient conditions for a radical curve parametrization to be surjective.",
        "published": "2023-03-01T09:50:34Z",
        "link": "http://arxiv.org/abs/2303.00368v2",
        "categories": [
            "math.AG",
            "cs.SC",
            "14Q05, 68W30"
        ]
    },
    {
        "title": "That's All Folks: a KG of Values as Commonsense Social Norms and   Behaviors",
        "authors": [
            "Stefano De Giorgis",
            "Aldo Gangemi"
        ],
        "summary": "Values, as intended in ethics, determine the shape and validity of moral and social norms, grounding our everyday individual and community behavior on commonsense knowledge. Formalising latent moral content in human interaction is an appealing perspective that would enable a deeper understanding of both social dynamics and individual cognitive and behavioral dimension. To tackle this problem, several theoretical frameworks offer different values models, and organize them into different taxonomies. The problem of the most used theories is that they adopt a cultural-independent perspective while many entities that are considered \"values\" are grounded in commonsense knowledge and expressed in everyday life interaction. We propose here two ontological modules, FOLK, an ontology for values intended in their broad sense, and That's All Folks, a module for lexical and factual folk value triggers, whose purpose is to complement the main theories, providing a method for identifying the values that are not contemplated by the major value theories, but which nonetheless play a key role in daily human interactions, and shape social structures, cultural biases, and personal beliefs. The resource is tested via performing automatic detection of values from text with a frame-based approach.",
        "published": "2023-03-01T16:35:46Z",
        "link": "http://arxiv.org/abs/2303.00632v1",
        "categories": [
            "cs.CY",
            "cs.AI",
            "cs.SC"
        ]
    },
    {
        "title": "Robust Parameter Estimation for Rational Ordinary Differential Equations",
        "authors": [
            "Oren Bassik",
            "Yosef Berman",
            "Soo Go",
            "Hoon Hong",
            "Ilia Ilmer",
            "Alexey Ovchinnikov",
            "Chris Rackauckas",
            "Pedro Soto",
            "Chee Yap"
        ],
        "summary": "We present a new approach for estimating parameters in rational ODE models from given (measured) time series data.   In typical existing approaches, an initial guess for the parameter values is made from a given search interval. Then, in a loop, the corresponding outputs are computed by solving the ODE numerically, followed by computing the error from the given time series data. If the error is small, the loop terminates and the parameter values are returned. Otherwise, heuristics/theories are used to possibly improve the guess and continue the loop.   These approaches tend to be non-robust in the sense that their accuracy depend on the search interval and the true parameter values; furthermore, they cannot handle the case where the parameters are locally identifiable.   In this paper, we propose a new approach, which does not suffer from the above non-robustness. In particular, it does not require making good initial guesses for the parameter values or specifying search intervals. Instead, it uses differential algebra, interpolation of the data using rational functions, and multivariate polynomial system solving. We also compare the performance of the resulting software with several other estimation software packages.",
        "published": "2023-03-02T14:33:06Z",
        "link": "http://arxiv.org/abs/2303.02159v3",
        "categories": [
            "cs.MS",
            "cs.SC",
            "math.DS",
            "q-bio.QM"
        ]
    },
    {
        "title": "Leveraging Symbolic Algebra Systems to Simulate Contact Dynamics in   Rigid Body Systems",
        "authors": [
            "Simone Asci",
            "Angadh Nanjangud"
        ],
        "summary": "Collision detection plays a key role in the simulation of interacting rigid bodies. However, owing to its computational complexity current methods typically prioritize either maximizing processing speed or fidelity to real-world behaviors. Fast real-time detection is achieved by simulating collisions with simple geometric shapes whereas incorporating more realistic geometries with multiple points of contact requires considerable computing power which slows down collision detection. In this work, we present a new approach to modeling and simulating collision-inclusive multibody dynamics by leveraging computer algebra system (CAS). This approach offers flexibility in modeling a diverse set of multibody systems applications ranging from human biomechanics to space manipulators with docking interfaces, since the geometric relationships between points and rigid bodies are handled in a generalizable manner. We also analyze the performance of integrating this symbolic modeling approach with collision detection formulated either as a traditional overlap test or as a convex optimization problem. We compare these two collision detection methods in different scenarios and collision resolution using a penalty-based method to simulate dynamics. This work demonstrates an effective simplification in solving collision dynamics problems using a symbolic approach, especially for the algorithm based on convex optimization, which is simpler to implement and, in complex collision scenarios, faster than the overlap test.",
        "published": "2023-03-02T16:15:14Z",
        "link": "http://arxiv.org/abs/2303.01387v1",
        "categories": [
            "cs.RO",
            "cs.SC"
        ]
    },
    {
        "title": "Some D-finite and Some Possibly D-finite Sequences in the OEIS",
        "authors": [
            "Manuel Kauers",
            "Christoph Koutschan"
        ],
        "summary": "In an automatic search, we found conjectural recurrences for some sequences in the OEIS that were not previously recognized as being D-finite. In some cases, we are able to prove the conjectured recurrence. In some cases, we are not able to prove the conjectured recurrence, but we can prove that a recurrence exists. In some remaining cases, we do not know where the recurrence might come from.",
        "published": "2023-03-05T23:00:22Z",
        "link": "http://arxiv.org/abs/2303.02793v2",
        "categories": [
            "cs.SC",
            "math.CO",
            "05A15 (Primary) 68W30, 33F10 (Secondary)"
        ]
    },
    {
        "title": "Efficient Symbolic Approaches for Quantitative Reactive Synthesis with   Finite Tasks",
        "authors": [
            "Karan Muvvala",
            "Morteza Lahijanian"
        ],
        "summary": "This work introduces efficient symbolic algorithms for quantitative reactive synthesis. We consider resource-constrained robotic manipulators that need to interact with a human to achieve a complex task expressed in linear temporal logic. Our framework generates reactive strategies that not only guarantee task completion but also seek cooperation with the human when possible. We model the interaction as a two-player game and consider regret-minimizing strategies to encourage cooperation. We use symbolic representation of the game to enable scalability. For synthesis, we first introduce value iteration algorithms for such games with min-max objectives. Then, we extend our method to the regret-minimizing objectives. Our benchmarks reveal that our symbolic framework not only significantly improves computation time (up to an order of magnitude) but also can scale up to much larger instances of manipulation problems with up to 2x number of objects and locations than the state of the art.",
        "published": "2023-03-07T07:08:20Z",
        "link": "http://arxiv.org/abs/2303.03686v3",
        "categories": [
            "cs.RO",
            "cs.FL",
            "cs.GT",
            "cs.SC"
        ]
    },
    {
        "title": "Neural Probabilistic Logic Programming in Discrete-Continuous Domains",
        "authors": [
            "Lennert De Smet",
            "Pedro Zuidberg Dos Martires",
            "Robin Manhaeve",
            "Giuseppe Marra",
            "Angelika Kimmig",
            "Luc De Raedt"
        ],
        "summary": "Neural-symbolic AI (NeSy) allows neural networks to exploit symbolic background knowledge in the form of logic. It has been shown to aid learning in the limited data regime and to facilitate inference on out-of-distribution data. Probabilistic NeSy focuses on integrating neural networks with both logic and probability theory, which additionally allows learning under uncertainty. A major limitation of current probabilistic NeSy systems, such as DeepProbLog, is their restriction to finite probability distributions, i.e., discrete random variables. In contrast, deep probabilistic programming (DPP) excels in modelling and optimising continuous probability distributions. Hence, we introduce DeepSeaProbLog, a neural probabilistic logic programming language that incorporates DPP techniques into NeSy. Doing so results in the support of inference and learning of both discrete and continuous probability distributions under logical constraints. Our main contributions are 1) the semantics of DeepSeaProbLog and its corresponding inference algorithm, 2) a proven asymptotically unbiased learning algorithm, and 3) a series of experiments that illustrate the versatility of our approach.",
        "published": "2023-03-08T15:27:29Z",
        "link": "http://arxiv.org/abs/2303.04660v2",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.LO",
            "cs.PL",
            "cs.SC",
            "D.3.1; I.2.4; I.2.6"
        ]
    },
    {
        "title": "Automated Grading of Automata with ACL2s",
        "authors": [
            "Ankit Kumar",
            "Andrew Walter",
            "Panagiotis Manolios"
        ],
        "summary": "Almost all Computer Science programs require students to take a course on the Theory of Computation (ToC) which covers various models of computation such as finite automata, push-down automata and Turing machines. ToC courses tend to give assignments that require paper-and-pencil solutions. Grading such assignments takes time, so students typically receive feedback for their solutions more than a week after they complete them. We present the Automatic Automata Checker (A2C), an open source library that enables one to construct executable automata using definitions that mimic those found in standard textbooks. Such constructions are easy to reason about using semantic equivalence checks, properties and test cases. Instructors can conveniently specify solutions in the form of their own constructions. A2C can check for semantic equivalence between student and instructor solutions and can immediately generate actionable feedback, which helps students better understand the material. A2C can be downloaded and used locally by students as well as integrated into Learning Management Systems (LMS) like Gradescope to automatically grade student submissions and generate feedback. A2C is based on the ACL2s interactive theorem prover, which provides advanced methods for stating, proving and disproving properties. Since feedback is automatic, A2C can be deployed at scale and integrated into massively open online courses.",
        "published": "2023-03-10T11:37:27Z",
        "link": "http://arxiv.org/abs/2303.05867v1",
        "categories": [
            "cs.LO",
            "cs.FL",
            "cs.SC"
        ]
    },
    {
        "title": "MizAR 60 for Mizar 50",
        "authors": [
            "Jan Jakubův",
            "Karel Chvalovský",
            "Zarathustra Goertzel",
            "Cezary Kaliszyk",
            "Mirek Olšák",
            "Bartosz Piotrowski",
            "Stephan Schulz",
            "Martin Suda",
            "Josef Urban"
        ],
        "summary": "As a present to Mizar on its 50th anniversary, we develop an AI/TP system that automatically proves about 60\\% of the Mizar theorems in the hammer setting. We also automatically prove 75\\% of the Mizar theorems when the automated provers are helped by using only the premises used in the human-written Mizar proofs. We describe the methods and large-scale experiments leading to these results. This includes in particular the E and Vampire provers, their ENIGMA and Deepire learning modifications, a number of learning-based premise selection methods, and the incremental loop that interleaves growing a corpus of millions of ATP proofs with training increasingly strong AI/TP systems on them. We also present a selection of Mizar problems that were proved automatically.",
        "published": "2023-03-12T15:13:05Z",
        "link": "http://arxiv.org/abs/2303.06686v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.LO",
            "cs.SC"
        ]
    },
    {
        "title": "Distance Evaluation to the Set of Defective Matrices",
        "authors": [
            "Alexei Yu. Uteshev",
            "Elizaveta A. Kalinina",
            "Marina V. Goncharova"
        ],
        "summary": "We treat the problem of the Frobenius distance evaluation from a given matrix $ A \\in \\mathbb R^{n\\times n} $ with distinct eigenvalues to the manifold of matrices with multiple eigenvalues. On restricting considerations to the rank $ 1 $ real perturbation matrices, we prove that the distance in question equals $ \\sqrt{z_{\\ast}} $ where $ z_{\\ast} $ is a positive (generically, the least positive) zero of the algebraic equation $$ \\mathcal F(z) = 0, \\ \\mbox{where} \\ \\mathcal F(z):= \\mathcal D_{\\lambda} \\left( \\det \\left[ (\\lambda I - A)(\\lambda I - A^{\\top})-z I_n \\right] \\right)/z^n $$ and $ \\mathcal D_{\\lambda} $ stands for the discriminant of the polynomial treated with respect to $\\lambda $. In the framework of this approach we also provide the procedure for finding the nearest to $ A $ matrix with multiple eigenvalue. Generalization of the problem to the case of complex perturbations is also discussed. Several examples are presented clarifying the computational aspects of the approach.",
        "published": "2023-03-13T16:07:41Z",
        "link": "http://arxiv.org/abs/2303.07235v1",
        "categories": [
            "cs.SC",
            "68W30, 15A18, 12D10, 58C40",
            "I.1.4; G.1.3; G.1.5"
        ]
    },
    {
        "title": "Transformer Models for Type Inference in the Simply Typed Lambda   Calculus: A Case Study in Deep Learning for Code",
        "authors": [
            "Brando Miranda",
            "Avi Shinnar",
            "Vasily Pestun",
            "Barry Trager"
        ],
        "summary": "Despite a growing body of work at the intersection of deep learning and formal languages, there has been relatively little systematic exploration of transformer models for reasoning about typed lambda calculi. This is an interesting area of inquiry for two reasons. First, typed lambda calculi are the lingua franc of programming languages. A set of heuristics that relate various typed lambda calculi to effective neural architectures would provide a systematic method for mapping language features (e.g., polymorphism, subtyping, inheritance, etc.) to architecture choices. Second, transformer models are widely used in deep learning architectures applied to code, but the design and hyperparameter space for them is large and relatively unexplored in programming language applications. Therefore, we suggest a benchmark that allows us to explore exactly this through perhaps the simplest and most fundamental property of a programming language: the relationship between terms and types. Consequently, we begin this inquiry of transformer architectures for typed lambda calculi by exploring the effect of transformer warm-up and optimizer selection in the task of type inference: i.e., predicting the types of lambda calculus terms using only transformers. We find that the optimization landscape is difficult even in this simple setting. One particular experimental finding is that optimization by Adafactor converges much faster compared to the optimization by Adam and RAdam. We conjecture that such different performance of optimizers might be related to the difficulties of generalization over formally generated dataset.",
        "published": "2023-03-15T17:44:39Z",
        "link": "http://arxiv.org/abs/2304.10500v1",
        "categories": [
            "cs.PL",
            "cs.AI",
            "cs.LG",
            "cs.LO",
            "cs.SC"
        ]
    },
    {
        "title": "Local Search for Solving Satisfiability of Polynomial Formulas",
        "authors": [
            "Haokun Li",
            "Bican Xia",
            "Tianqi Zhao"
        ],
        "summary": "Satisfiability Modulo the Theory of Nonlinear Real Arithmetic, SMT(NRA) for short, concerns the satisfiability of polynomial formulas, which are quantifier-free Boolean combinations of polynomial equations and inequalities with integer coefficients and real variables. In this paper, we propose a local search algorithm for a special subclass of SMT(NRA), where all constraints are strict inequalities. An important fact is that, given a polynomial formula with $n$ variables, the zero level set of the polynomials in the formula decomposes the $n$-dimensional real space into finitely many components (cells) and every polynomial has constant sign in each cell. The key point of our algorithm is a new operation based on real root isolation, called cell-jump, which updates the current assignment along a given direction such that the assignment can `jump' from one cell to another. One cell-jump may adjust the values of several variables while traditional local search operations, such as flip for SAT and critical move for SMT(LIA), only change that of one variable. We also design a two-level operation selection to balance the success rate and efficiency. Furthermore, our algorithm can be easily generalized to a wider subclass of SMT(NRA) where polynomial equations linear with respect to some variable are allowed. Experiments show the algorithm is competitive with state-of-the-art SMT solvers, and performs particularly well on those formulas with high-degree polynomials.",
        "published": "2023-03-16T04:08:31Z",
        "link": "http://arxiv.org/abs/2303.09072v2",
        "categories": [
            "cs.LO",
            "cs.SC"
        ]
    },
    {
        "title": "Rigorous Analytic Combinatorics in Several Variables in SageMath",
        "authors": [
            "Benjamin Hackl",
            "Andrew Luo",
            "Stephen Melczer",
            "Jesse Selover",
            "Elaine Wong"
        ],
        "summary": "We introduce the new sage_acsv package for the SageMath computer algebra system, allowing users to rigorously compute asymptotics for a large variety of multivariate sequences with rational generating functions. Using Sage's support for exact computations over the algebraic number field, this package provides the first rigorous implementation of algorithms from the theory of analytic combinatorics in several variables.",
        "published": "2023-03-16T19:08:17Z",
        "link": "http://arxiv.org/abs/2303.09603v2",
        "categories": [
            "math.CO",
            "cs.SC"
        ]
    },
    {
        "title": "Machine-Learned Premise Selection for Lean",
        "authors": [
            "Bartosz Piotrowski",
            "Ramon Fernández Mir",
            "Edward Ayers"
        ],
        "summary": "We introduce a machine-learning-based tool for the Lean proof assistant that suggests relevant premises for theorems being proved by a user. The design principles for the tool are (1) tight integration with the proof assistant, (2) ease of use and installation, (3) a lightweight and fast approach. For this purpose, we designed a custom version of the random forest model, trained in an online fashion. It is implemented directly in Lean, which was possible thanks to the rich and efficient metaprogramming features of Lean 4. The random forest is trained on data extracted from mathlib -- Lean's mathematics library. We experiment with various options for producing training features and labels. The advice from a trained model is accessible to the user via the suggest_premises tactic which can be called in an editor while constructing a proof interactively.",
        "published": "2023-03-17T10:37:34Z",
        "link": "http://arxiv.org/abs/2304.00994v2",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.LO",
            "cs.SC"
        ]
    },
    {
        "title": "Exact and optimal quadratization of nonlinear finite-dimensional   non-autonomous dynamical systems",
        "authors": [
            "Andrey Bychkov",
            "Opal Issan",
            "Gleb Pogudin",
            "Boris Kramer"
        ],
        "summary": "Quadratization of polynomial and nonpolynomial systems of ordinary differential equations is advantageous in a variety of disciplines, such as systems theory, fluid mechanics, chemical reaction modeling and mathematical analysis. A quadratization reveals new variables and structures of a model, which may be easier to analyze, simulate, control, and provides a convenient parametrization for learning. This paper presents novel theory, algorithms and software capabilities for quadratization of non-autonomous ODEs. We provide existence results, depending on the regularity of the input function, for cases when a quadratic-bilinear system can be obtained through quadratization. We further develop existence results and an algorithm that generalizes the process of quadratization for systems with arbitrary dimension that retain the nonlinear structure when the dimension grows. For such systems, we provide dimension-agnostic quadratization. An example is semi-discretized PDEs, where the nonlinear terms remain symbolically identical when the discretization size increases. As an important aspect for practical adoption of this research, we extended the capabilities of the QBee software towards both non-autonomous systems of ODEs and ODEs with arbitrary dimension. We present several examples of ODEs that were previously reported in the literature, and where our new algorithms find quadratized ODE systems with lower dimension than the previously reported lifting transformations. We further highlight an important area of quadratization: reduced-order model learning. This area can benefit significantly from working in the optimal lifting variables, where quadratic models provide a direct parametrization of the model that also avoids additional hyperreduction for the nonlinear terms. A solar wind example highlights these advantages.",
        "published": "2023-03-17T23:52:35Z",
        "link": "http://arxiv.org/abs/2303.10285v4",
        "categories": [
            "cs.SC",
            "cs.NA",
            "math.DS",
            "math.NA"
        ]
    },
    {
        "title": "Supercomputer Environment for Recursive Matrix Algorithms",
        "authors": [
            "Gennadi Malaschonok",
            "Alla Sidko"
        ],
        "summary": "A new runtime environment for the execution of recursive matrix algorithms on a supercomputer with distributed memory is proposed. It is designed both for dense and sparse matrices. The environment ensures decentralized control of the computation process. As an example of a block recursive algorithm, the Cholesky factorization of a symmetric positive definite matrix in the form of a block dichotomous algorithm is described. The results of experiments with different numbers of cores are presented, demonstrating good scalability of the proposed solution.",
        "published": "2023-03-20T10:52:02Z",
        "link": "http://arxiv.org/abs/2303.11017v1",
        "categories": [
            "cs.SC",
            "15Axx, 15Bxx",
            "G.4; I.1; J.7; C.3.4"
        ]
    },
    {
        "title": "$D$-Module Techniques for Solving Differential Equations in the Context   of Feynman Integrals",
        "authors": [
            "Johannes Henn",
            "Elizabeth Pratt",
            "Anna-Laura Sattelberger",
            "Simone Zoia"
        ],
        "summary": "Feynman integrals are solutions to linear partial differential equations with polynomial coefficients. Using a triangle integral with general exponents as a case in point, we compare $D$-module methods to dedicated methods developed for solving differential equations appearing in the context of Feynman integrals, and provide a dictionary of the relevant concepts. In particular, we implement an algorithm due to Saito, Sturmfels, and Takayama to derive canonical series solutions of regular holonomic $D$-ideals, and compare them to asymptotic series derived by the respective Fuchsian systems.",
        "published": "2023-03-20T13:41:20Z",
        "link": "http://arxiv.org/abs/2303.11105v3",
        "categories": [
            "hep-th",
            "cs.SC",
            "math.AG",
            "math.CA"
        ]
    },
    {
        "title": "Abstract Visual Reasoning: An Algebraic Approach for Solving Raven's   Progressive Matrices",
        "authors": [
            "Jingyi Xu",
            "Tushar Vaidya",
            "Yufei Wu",
            "Saket Chandra",
            "Zhangsheng Lai",
            "Kai Fong Ernest Chong"
        ],
        "summary": "We introduce algebraic machine reasoning, a new reasoning framework that is well-suited for abstract reasoning. Effectively, algebraic machine reasoning reduces the difficult process of novel problem-solving to routine algebraic computation. The fundamental algebraic objects of interest are the ideals of some suitably initialized polynomial ring. We shall explain how solving Raven's Progressive Matrices (RPMs) can be realized as computational problems in algebra, which combine various well-known algebraic subroutines that include: Computing the Gr\\\"obner basis of an ideal, checking for ideal containment, etc. Crucially, the additional algebraic structure satisfied by ideals allows for more operations on ideals beyond set-theoretic operations.   Our algebraic machine reasoning framework is not only able to select the correct answer from a given answer set, but also able to generate the correct answer with only the question matrix given. Experiments on the I-RAVEN dataset yield an overall $93.2\\%$ accuracy, which significantly outperforms the current state-of-the-art accuracy of $77.0\\%$ and exceeds human performance at $84.4\\%$ accuracy.",
        "published": "2023-03-21T10:34:39Z",
        "link": "http://arxiv.org/abs/2303.11730v1",
        "categories": [
            "cs.CV",
            "cs.AI",
            "cs.SC",
            "math.AC",
            "13P25, 68W30",
            "I.1; I.2.4; I.2.6; I.5.1"
        ]
    },
    {
        "title": "Efficient Symbolic Reasoning for Neural-Network Verification",
        "authors": [
            "Zi Wang",
            "Somesh Jha",
            "Krishnamurthy",
            "Dvijotham"
        ],
        "summary": "The neural network has become an integral part of modern software systems. However, they still suffer from various problems, in particular, vulnerability to adversarial attacks. In this work, we present a novel program reasoning framework for neural-network verification, which we refer to as symbolic reasoning. The key components of our framework are the use of the symbolic domain and the quadratic relation. The symbolic domain has very flexible semantics, and the quadratic relation is quite expressive. They allow us to encode many verification problems for neural networks as quadratic programs. Our scheme then relaxes the quadratic programs to semidefinite programs, which can be efficiently solved. This framework allows us to verify various neural-network properties under different scenarios, especially those that appear challenging for non-symbolic domains. Moreover, it introduces new representations and perspectives for the verification tasks. We believe that our framework can bring new theoretical insights and practical tools to verification problems for neural networks.",
        "published": "2023-03-23T18:08:11Z",
        "link": "http://arxiv.org/abs/2303.13588v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.SC"
        ]
    },
    {
        "title": "Learning Reward Machines in Cooperative Multi-Agent Tasks",
        "authors": [
            "Leo Ardon",
            "Daniel Furelos-Blanco",
            "Alessandra Russo"
        ],
        "summary": "This paper presents a novel approach to Multi-Agent Reinforcement Learning (MARL) that combines cooperative task decomposition with the learning of reward machines (RMs) encoding the structure of the sub-tasks. The proposed method helps deal with the non-Markovian nature of the rewards in partially observable environments and improves the interpretability of the learnt policies required to complete the cooperative task. The RMs associated with each sub-task are learnt in a decentralised manner and then used to guide the behaviour of each agent. By doing so, the complexity of a cooperative multi-agent problem is reduced, allowing for more effective learning. The results suggest that our approach is a promising direction for future research in MARL, especially in complex environments with large state spaces and multiple agents.",
        "published": "2023-03-24T15:12:28Z",
        "link": "http://arxiv.org/abs/2303.14061v4",
        "categories": [
            "cs.AI",
            "cs.MA",
            "cs.SC"
        ]
    },
    {
        "title": "Learning to Operate in Open Worlds by Adapting Planning Models",
        "authors": [
            "Wiktor Piotrowski",
            "Roni Stern",
            "Yoni Sher",
            "Jacob Le",
            "Matthew Klenk",
            "Johan deKleer",
            "Shiwali Mohan"
        ],
        "summary": "Planning agents are ill-equipped to act in novel situations in which their domain model no longer accurately represents the world. We introduce an approach for such agents operating in open worlds that detects the presence of novelties and effectively adapts their domain models and consequent action selection. It uses observations of action execution and measures their divergence from what is expected, according to the environment model, to infer existence of a novelty. Then, it revises the model through a heuristics-guided search over model changes. We report empirical evaluations on the CartPole problem, a standard Reinforcement Learning (RL) benchmark. The results show that our approach can deal with a class of novelties very quickly and in an interpretable fashion.",
        "published": "2023-03-24T21:04:16Z",
        "link": "http://arxiv.org/abs/2303.14272v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.SC",
            "I.2.6; I.2.8"
        ]
    },
    {
        "title": "Knowledge Enhanced Graph Neural Networks for Graph Completion",
        "authors": [
            "Luisa Werner",
            "Nabil Layaïda",
            "Pierre Genevès",
            "Sarah Chlyah"
        ],
        "summary": "Graph data is omnipresent and has a wide variety of applications, such as in natural science, social networks, or the semantic web. However, while being rich in information, graphs are often noisy and incomplete. As a result, graph completion tasks, such as node classification or link prediction, have gained attention. On one hand, neural methods, such as graph neural networks, have proven to be robust tools for learning rich representations of noisy graphs. On the other hand, symbolic methods enable exact reasoning on graphs.We propose Knowledge Enhanced Graph Neural Networks (KeGNN), a neuro-symbolic framework for graph completion that combines both paradigms as it allows for the integration of prior knowledge into a graph neural network model.Essentially, KeGNN consists of a graph neural network as a base upon which knowledge enhancement layers are stacked with the goal of refining predictions with respect to prior knowledge.We instantiate KeGNN in conjunction with two state-of-the-art graph neural networks, Graph Convolutional Networks and Graph Attention Networks, and evaluate KeGNN on multiple benchmark datasets for node classification.",
        "published": "2023-03-27T07:53:43Z",
        "link": "http://arxiv.org/abs/2303.15487v3",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.LO",
            "cs.SC"
        ]
    },
    {
        "title": "On real and observable realizations of input-output equations",
        "authors": [
            "Sebastian Falkensteiner",
            "Dmitrii Pavlov",
            "Rafael Sendra"
        ],
        "summary": "Given a single algebraic input-output equation, we present a method for finding different representations of the associated system in the form of rational realizations; these are dynamical systems with rational right-hand sides. It has been shown that in the case where the input-output equation is of order one, rational realizations can be computed, if they exist. In this work, we focus first on the existence and actual computation of the so-called observable rational realizations, and secondly on rational realizations with real coefficients. The study of observable realizations allows to find every rational realization of a given first order input-output equation, and the necessary field extensions in this process. We show that for first order input-output equations the existence of a rational realization is equivalent to the existence of an observable rational realization. Moreover, we give a criterion to decide the existence of real rational realizations. The computation of observable and real realizations of first order input-output equations is fully algorithmic. We also present partial results for the case of higher order input-output equations.",
        "published": "2023-03-29T15:42:01Z",
        "link": "http://arxiv.org/abs/2303.16799v1",
        "categories": [
            "cs.SC",
            "math.AG",
            "math.DS",
            "math.OC",
            "93B15, 93B07, 14H50, 34H05"
        ]
    },
    {
        "title": "Two Variants of Bezout Subresultants for Several Univariate Polynomials",
        "authors": [
            "Weidong Wang",
            "Jing Yang"
        ],
        "summary": "In this paper, we develop two variants of Bezout subresultant formulas for several polynomials, i.e., hybrid Bezout subresultant polynomial and non-homogeneous Bezout subresultant polynomial. Rather than simply extending the variants of Bezout subresultant formulas developed by Diaz-Toca and Gonzalez-Vega in 2004 for two polynomials to arbitrary number of polynomials, we propose a new approach to formulating two variants of the Bezout-type subresultant polynomials for a set of univariate polynomials. Experimental results show that the Bezout-type subresultant formulas behave better than other known formulas when used to compute multi-polynomial subresultants, among which the non-homogeneous Bezout-type formula shows the best performance.",
        "published": "2023-04-01T08:38:06Z",
        "link": "http://arxiv.org/abs/2304.00262v2",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Taylor Polynomials of Rational Functions",
        "authors": [
            "Aldo Conca",
            "Simone Naldi",
            "Giorgio Ottaviani",
            "Bernd Sturmfels"
        ],
        "summary": "A Taylor variety consists of all fixed order Taylor polynomials of rational functions, where the number of variables and degrees of numerators and denominators are fixed. In one variable, Taylor varieties are given by rank constraints on Hankel matrices. Inversion of the natural parametrization is known as Pad\\'e approximation. We study the dimension and defining ideals of Taylor varieties. Taylor hypersurfaces are interesting for projective geometry, since their Hessians tend to vanish. In three and more variables, there exist defective Taylor varieties whose dimension is smaller than the number of parameters. We explain this with Fr\\\"oberg's Conjecture in commutative algebra.",
        "published": "2023-04-03T04:07:58Z",
        "link": "http://arxiv.org/abs/2304.00712v1",
        "categories": [
            "math.AG",
            "cs.SC",
            "math.AC"
        ]
    },
    {
        "title": "Efficient Generic Quotients Using Exact Arithmetic",
        "authors": [
            "Stephen M. Watt"
        ],
        "summary": "The usual formulation of efficient division uses Newton iteration to compute an inverse in a related domain where multiplicative inverses exist. On one hand, Newton iteration allows quotients to be calculated using an efficient multiplication method. On the other hand, working in another domain is not always desirable and can lead to a library structure where arithmetic domains are interdependent. This paper uses the concept of a whole shifted inverse and modified Newton iteration to compute quotients efficiently without leaving the original domain. The iteration is generic to domains having a suitable shift operation, such as integers or polynomials with coefficients that do not necessarily commute.",
        "published": "2023-04-04T12:43:37Z",
        "link": "http://arxiv.org/abs/2304.01753v5",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Stability and chaos of the duopoly model of Kopel: A study based on   symbolic computations",
        "authors": [
            "Xiaoliang Li",
            "Kongyan Chen",
            "Wei Niu",
            "Bo Huang"
        ],
        "summary": "Since Kopel's duopoly model was proposed about three decades ago, there are almost no analytical results on the equilibria and their stability in the asymmetric case. The first objective of our study is to fill this gap. This paper analyzes the asymmetric duopoly model of Kopel analytically by using several tools based on symbolic computations. We discuss the possibility of the existence of multiple positive equilibria and establish necessary and sufficient conditions for a given number of positive equilibria to exist. The possible positions of the equilibria in Kopel's model are also explored. Furthermore, in the asymmetric model of Kopel, if the duopolists adopt the best response reactions or homogeneous adaptive expectations, we establish rigorous conditions for the local stability of equilibria for the first time. The occurrence of chaos in Kopel's model seems to be supported by observations through numerical simulations, which, however, is challenging to prove rigorously. The second objective is to prove the existence of snapback repellers in Kopel's map, which implies the existence of chaos in the sense of Li-Yorke according to Marotto's theorem.",
        "published": "2023-04-04T21:35:38Z",
        "link": "http://arxiv.org/abs/2304.02136v2",
        "categories": [
            "math.DS",
            "cs.SC",
            "econ.TH"
        ]
    },
    {
        "title": "Classifying sequences by combining context-free grammars and OWL   ontologies",
        "authors": [
            "Nicolas Lazzari",
            "Andrea Poltronieri",
            "Valentina Presutti"
        ],
        "summary": "This paper describes a pattern to formalise context-free grammars in OWL and its use for sequence classification. The proposed approach is compared to existing methods in terms of computational complexity as well as pragmatic applicability, with examples in the music domain.",
        "published": "2023-04-06T14:16:46Z",
        "link": "http://arxiv.org/abs/2304.03089v1",
        "categories": [
            "cs.SC",
            "cs.FL"
        ]
    },
    {
        "title": "Algebraic solutions of linear differential equations: an arithmetic   approach",
        "authors": [
            "Alin Bostan",
            "Xavier Caruso",
            "Julien Roques"
        ],
        "summary": "Given a linear differential equation with coefficients in $\\mathbb{Q}(x)$, an important question is to know whether its full space of solutions consists of algebraic functions, or at least if one of its specific solutions is algebraic. After presenting motivating examples coming from various branches of mathematics, we advertise in an elementary way a beautiful local-global arithmetic approach to these questions, initiated by Grothendieck in the late sixties. This approach has deep ramifications and leads to the still unsolved Grothendieck-Katz $p$-curvature conjecture.",
        "published": "2023-04-11T08:45:17Z",
        "link": "http://arxiv.org/abs/2304.05061v2",
        "categories": [
            "math.NT",
            "cs.SC",
            "math.CA",
            "math.CO",
            "Primary: 11-02, Secondary: 12H05, 33C20. 12H25, 34A20, 34A30, 34M15,\n  05A15, 68W30"
        ]
    },
    {
        "title": "Emergence of Symbols in Neural Networks for Semantic Understanding and   Communication",
        "authors": [
            "Yang Chen",
            "Liangxuan Guo",
            "Shan Yu"
        ],
        "summary": "The capacity to generate meaningful symbols and effectively employ them for advanced cognitive processes, such as communication, reasoning, and planning, constitutes a fundamental and distinctive aspect of human intelligence. Existing deep neural networks still notably lag human capabilities in terms of generating symbols for higher cognitive functions. Here, we propose a solution (symbol emergence artificial network (SEA-net)) to endow neural networks with the ability to create symbols, understand semantics, and achieve communication. SEA-net generates symbols that dynamically configure the network to perform specific tasks. These symbols capture compositional semantic information that allows the system to acquire new functions purely by symbolic manipulation or communication. In addition, these self-generated symbols exhibit an intrinsic structure resembling that of natural language, suggesting a common framework underlying the generation and understanding of symbols in both human brains and artificial neural networks. We believe that the proposed framework will be instrumental in producing more capable systems that can synergize the strengths of connectionist and symbolic approaches for artificial intelligence (AI).",
        "published": "2023-04-13T10:13:00Z",
        "link": "http://arxiv.org/abs/2304.06377v3",
        "categories": [
            "cs.AI",
            "cs.CL",
            "cs.SC",
            "q-bio.NC"
        ]
    },
    {
        "title": "Groebner.jl: A package for Gröbner bases computations in Julia",
        "authors": [
            "Alexander Demin",
            "Shashi Gowda"
        ],
        "summary": "We present Groebner.jl, a Julia package for computing Groebner bases with the F4 algorithm. Groebner.jl is an efficient, portable, and open-source software. Groebner.jl works over integers modulo a prime and over the rationals, supports basic multi-threading, and specializes in computation in the degree reverse lexicographical monomial ordering. The implementation incorporates various symbolic computation techniques and leverages the Julia type system and tooling, which allows Groebner.jl to compete with the existing state of the art, in many instances outperform it, and exceed them in extensibility. Groebner.jl is freely available at https://github.com/sumiya11/Groebner.jl.",
        "published": "2023-04-14T05:47:34Z",
        "link": "http://arxiv.org/abs/2304.06935v3",
        "categories": [
            "cs.MS",
            "cs.SC",
            "math.AC"
        ]
    },
    {
        "title": "Faster List Decoding of AG Codes",
        "authors": [
            "Peter Beelen",
            "Vincent Neiger"
        ],
        "summary": "In this article, we present a fast algorithm performing an instance of the Guruswami-Sudan list decoder for algebraic geometry codes. We show that any such code can be decoded in $\\tilde{O}(s^2\\ell^{\\omega-1}\\mu^{\\omega-1}(n+g) + \\ell^\\omega \\mu^\\omega)$ operations in the underlying finite field, where $n$ is the code length, $g$ is the genus of the function field used to construct the code, $s$ is the multiplicity parameter, $\\ell$ is the designed list size and $\\mu$ is the smallest positive element in the Weierstrass semigroup of some chosen place.",
        "published": "2023-04-14T12:18:35Z",
        "link": "http://arxiv.org/abs/2304.07083v1",
        "categories": [
            "cs.IT",
            "cs.SC",
            "math.IT"
        ]
    },
    {
        "title": "Computer-assisted proofs of \"Kariya's theorem\" with computer algebra",
        "authors": [
            "Ayane Ito",
            "Takefumi Kasai",
            "Akira Terui"
        ],
        "summary": "We demonstrate computer-assisted proofs of \"Kariya's theorem,\" a theorem in elementary geometry, with computer algebra. In the proof of geometry theorem with computer algebra, vertices of geometric figures that are subjects for the proof are expressed as variables. The variables are classified into two classes: arbitrarily given points and the points defined from the former points by constraints. We show proofs of Kariya's theorem with two formulations according to two ways for giving the arbitrary points: one is called \"vertex formulation,\" and the other is called \"incenter formulation,\" with two methods: one is Gr\\\"obner basis computation, and the other is Wu's method. Furthermore, we show computer-assisted proofs of the property that the point so-called \"Kariya point\" is located on the hyperbola so-called \"Feuerbach's hyperbola\", with two formulations and two methods.",
        "published": "2023-04-15T06:56:55Z",
        "link": "http://arxiv.org/abs/2304.07491v1",
        "categories": [
            "cs.SC",
            "math.AC",
            "13P10, 68W30"
        ]
    },
    {
        "title": "A multistep strategy for polynomial system solving over finite fields   and a new algebraic attack on the stream cipher Trivium",
        "authors": [
            "Roberto La Scala",
            "Federico Pintore",
            "Sharwan K. Tiwari",
            "Andrea Visconti"
        ],
        "summary": "In this paper we introduce a multistep generalization of the guess-and-determine or hybrid strategy for solving a system of multivariate polynomial equations over a finite field. In particular, we propose performing the exhaustive evaluation of a subset of variables stepwise, that is, by incrementing the size of such subset each time that an evaluation leads to a polynomial system which is possibly unfeasible to solve. The decision about which evaluation to extend is based on a preprocessing consisting in computing an incomplete Grobner basis after the current evaluation, which possibly generates linear polynomials that are used to eliminate further variables. If the number of remaining variables in the system is deemed still too high, the evaluation is extended and the preprocessing is iterated. Otherwise, we solve the system by a complete Grobner basis computation.   Having in mind cryptanalytic applications, we present an implementation of this strategy in an algorithm called MultiSolve which is designed for polynomial systems having at most one solution. We prove explicit formulas for its complexity which are based on probability distributions that can be easily estimated by performing the proposed preprocessing on a testset of evaluations for different subsets of variables. We prove that an optimal complexity of MultiSolve is achieved by using a full multistep strategy with a maximum number of steps and in turn the standard guess-and-determine strategy, which essentially is a strategy consisting of a single step, is the worst choice. Finally, we extensively study the behaviour of MultiSolve when performing an algebraic attack on the well-known stream cipher Trivium.",
        "published": "2023-04-16T16:09:14Z",
        "link": "http://arxiv.org/abs/2304.07820v2",
        "categories": [
            "cs.SC",
            "cs.CR",
            "math.AC"
        ]
    },
    {
        "title": "Density Elicitation with applications in Probabilistic Loops",
        "authors": [
            "Andrey Kofnov",
            "Ezio Bartocci",
            "Efstathia Bura"
        ],
        "summary": "Probabilistic loops can be employed to implement and to model different processes ranging from software to cyber-physical systems. One main challenge is how to automatically estimate the distribution of the underlying continuous random variables symbolically and without sampling. We develop an approach, which we call K-series estimation, to approximate statically the joint and marginal distributions of a vector of random variables updated in a probabilistic non-nested loop with polynomial and non-polynomial assignments. Our approach is a general estimation method for an unknown probability density function with bounded support. It naturally complements algorithms for automatic derivation of moments in probabilistic loops such as~\\cite{BartocciKS19,Moosbruggeretal2022}. Its only requirement is a finite number of moments of the unknown density. We show that Gram-Charlier (GC) series, a widely used estimation method, is a special case of K-series when the normal probability density function is used as reference distribution. We provide also a formulation suitable for estimating both univariate and multivariate distributions. We demonstrate the feasibility of our approach using multiple examples from the literature.",
        "published": "2023-04-17T14:46:38Z",
        "link": "http://arxiv.org/abs/2304.09094v1",
        "categories": [
            "stat.ME",
            "cs.NA",
            "cs.SC",
            "cs.SY",
            "eess.SY",
            "math.NA",
            "stat.AP",
            "62G07, 60E05 (Primary) 60B10 (Secondary)",
            "G.3; I.1.1"
        ]
    },
    {
        "title": "Operations for D-Algebraic Functions",
        "authors": [
            "Bertrand Teguia Tabuguia"
        ],
        "summary": "A function is differentially algebraic (or simply D-algebraic) if there is a polynomial relationship between some of its derivatives and the indeterminate variable. Many functions in the sciences, such as Mathieu functions, the Weierstrass elliptic functions, and holonomic or D-finite functions are D-algebraic. These functions form a field, and are closed under composition, taking functional inverse, and derivation. We present implementation for each underlying operation. We also give a systematic way for computing an algebraic differential equation from a linear differential equation with D-finite function coefficients. Each command is a feature of our Maple package $NLDE$ available at https://mathrepo.mis.mpg.de/OperationsForDAlgebraicFunctions.",
        "published": "2023-04-19T14:06:19Z",
        "link": "http://arxiv.org/abs/2304.09675v2",
        "categories": [
            "cs.SC",
            "68W30, 12H05 (Primary), 34-04 (Secondary)"
        ]
    },
    {
        "title": "Deterministic identity testing paradigms for bounded top-fanin depth-4   circuits",
        "authors": [
            "Pranjal Dutta",
            "Prateek Dwivedi",
            "Nitin Saxena"
        ],
        "summary": "Polynomial Identity Testing (PIT) is a fundamental computational problem. The famous depth-$4$ reduction result by Agrawal and Vinay (FOCS 2008) has made PIT for depth-$4$ circuits an enticing pursuit. A restricted depth-4 circuit computing a $n$-variate degree-$d$ polynomial of the form $\\sum_{i = 1}^{k} \\prod_{j} g_{ij}$, where $\\deg g_{ij} \\leq \\delta$ is called $\\Sigma^{[k]}\\Pi\\Sigma\\Pi^{[\\delta]}$ circuit. On further restricting $g_{ij}$ to be sum of univariates we obtain $\\Sigma^{[k]}\\Pi\\Sigma\\wedge$ circuits. The largely open, special-cases of $\\Sigma^{[k]}\\Pi\\Sigma\\Pi^{[\\delta]}$ for constant $k$ and $\\delta$, and $\\Sigma^{[k]}\\Pi\\Sigma\\wedge$ have been a source of many great ideas in the last two decades. For eg. depth-$3$ ideas of Dvir and Shpilka (STOC 2005), Kayal and Saxena (CCC 2006), and Saxena and Seshadhri (FOCS 2010 and STOC 2011). Further, depth-$4$ ideas of Beecken, Mittmann and Saxena (ICALP 2011), Saha, Saxena and Saptharishi (Comput.Compl. 2013), Forbes (FOCS 2015), and Kumar and Saraf (CCC 2016). Additionally, geometric Sylvester-Gallai ideas of Kayal and Saraf (FOCS 2009), Shpilka (STOC 2019), and Peleg and Shpilka (CCC 2020, STOC 2021). Very recently, a subexponential-time blackbox PIT algorithm for constant-depth circuits was obtained via lower bound breakthrough of Limaye, Srinivasan, Tavenas (FOCS 2021). We solve two of the basic underlying open problems in this work.   We give the first polynomial-time PIT for $\\Sigma^{[k]}\\Pi\\Sigma\\wedge$. We also give the first quasipolynomial time blackbox PIT for both $\\Sigma^{[k]}\\Pi\\Sigma\\wedge$ and $\\Sigma^{[k]}\\Pi\\Sigma\\Pi^{[\\delta]}$. A key technical ingredient in all the three algorithms is how the logarithmic derivative, and its power-series, modify the top $\\Pi$-gate to $\\wedge$.",
        "published": "2023-04-22T05:36:12Z",
        "link": "http://arxiv.org/abs/2304.11325v1",
        "categories": [
            "cs.CC",
            "cs.SC",
            "math.AC",
            "F.2.1"
        ]
    },
    {
        "title": "Explainable AI Insights for Symbolic Computation: A case study on   selecting the variable ordering for cylindrical algebraic decomposition",
        "authors": [
            "Lynn Pickering",
            "Tereso Del Rio Almajano",
            "Matthew England",
            "Kelly Cohen"
        ],
        "summary": "In recent years there has been increased use of machine learning (ML) techniques within mathematics, including symbolic computation where it may be applied safely to optimise or select algorithms. This paper explores whether using explainable AI (XAI) techniques on such ML models can offer new insight for symbolic computation, inspiring new implementations within computer algebra systems that do not directly call upon AI tools. We present a case study on the use of ML to select the variable ordering for cylindrical algebraic decomposition. It has already been demonstrated that ML can make the choice well, but here we show how the SHAP tool for explainability can be used to inform new heuristics of a size and complexity similar to those human-designed heuristics currently commonly used in symbolic computation.",
        "published": "2023-04-24T15:05:04Z",
        "link": "http://arxiv.org/abs/2304.12154v2",
        "categories": [
            "cs.SC",
            "cs.LG",
            "68W30, 68T05, 03C10",
            "I.2.6; I.1.0"
        ]
    },
    {
        "title": "Computing Circuit Polynomials in the Algebraic Rigidity Matroid",
        "authors": [
            "Goran Malic",
            "Ileana Streinu"
        ],
        "summary": "We present an algorithm for computing circuit polynomials in the algebraic rigidity matroid $\\mathcal{A}(\\text{CM}_n)$ associated to the Cayley-Menger ideal CM$_n$ for $n$ points in 2D. It relies on combinatorial resultants, a new operation on graphs that captures properties of the Sylvester resultant of two polynomials in this ideal. We show that every rigidity circuit has a construction tree from K4 graphs based on this operation. Our algorithm performs an algebraic elimination guided by such a construction tree, and uses classical resultants, factorization and ideal membership. To highlight its effectiveness, we implemented the algorithm in Mathematica: it took less than 15 seconds on an example where a Gr\\\"obner Basis calculation took 5 days and 6 hrs. Additional speed-ups are obtained using non-$K_4$ generators of the Cayley-Menger ideal and simple variations on our main algorithm.",
        "published": "2023-04-24T20:20:03Z",
        "link": "http://arxiv.org/abs/2304.12435v1",
        "categories": [
            "math.CO",
            "cs.CG",
            "cs.DM",
            "cs.SC",
            "math.AG"
        ]
    },
    {
        "title": "Towards a generalizable simulation framework to study collisions between   spacecraft and debris",
        "authors": [
            "Simone Asci",
            "Angadh Nanjangud"
        ],
        "summary": "In recent years, computer simulators of rigid-body systems have been successfully used to improve and expand the field of developing new space robots, becoming a leading tool for the preliminary investigation and evaluation of space robotic missions. However, the impressive progress in performance has not been matched yet by an improvement in modelling capabilities, which remain limited to very basic representations of real systems. We present a new approach to modelling and simulation of collision-inclusive multibody dynamics by leveraging symbolic models generated by a computer algebra system (CAS). While similar investigations into contact dynamics on other domains exploit pre-existing models of common multibody systems (e.g., industrial robot arms, humanoids, and wheeled robots), our focus is on allowing researchers to develop models of novel designs of systems that are not as common or yet to be fabricated: e.g., small spacecraft manipulators. In this paper, we demonstrate the usefulness of our approach to investigate spacecraft-debris collision dynamics.",
        "published": "2023-04-25T13:18:17Z",
        "link": "http://arxiv.org/abs/2304.12799v1",
        "categories": [
            "cs.RO",
            "cs.SC"
        ]
    },
    {
        "title": "On the Order of Power Series and the Sum of Square Roots Problem",
        "authors": [
            "Louis Gaillard",
            "Gorav Jindal"
        ],
        "summary": "This paper focuses on the study of the order of power series that are linear combinations of a given finite set of power series. The order of a formal power series, known as $\\textrm{ord}(f)$, is defined as the minimum exponent of $x$ that has a non-zero coefficient in $f(x)$. Our first result is that the order of the Wronskian of these power series is equivalent up to a polynomial factor, to the maximum order which occurs in the linear combination of these power series. This implies that the Wronskian approach used in (Kayal and Saha, TOCT'2012) to upper bound the order of sum of square roots is optimal up to a polynomial blowup. We also demonstrate similar upper bounds, similar to those of (Kayal and Saha, TOCT'2012), for the order of power series in a variety of other scenarios. We also solve a special case of the inequality testing problem outlined in (Etessami et al., TOCT'2014).   In the second part of the paper, we study the equality variant of the sum of square roots problem, which is decidable in polynomial time due to (Bl\\\"omer, FOCS'1991). We investigate a natural generalization of this problem when the input integers are given as straight line programs. Under the assumption of the Generalized Riemann Hypothesis (GRH), we show that this problem can be reduced to the so-called ``one dimensional'' variant. We identify the key mathematical challenges for solving this ``one dimensional'' variant.",
        "published": "2023-04-26T14:59:42Z",
        "link": "http://arxiv.org/abs/2304.13605v1",
        "categories": [
            "cs.CC",
            "cs.SC"
        ]
    },
    {
        "title": "On Rueppel's Linear Complexity Conjecture",
        "authors": [
            "Graham H. Norton"
        ],
        "summary": "Rueppel's conjecture on the linear complexity of the first $n$ terms of the sequence $(1,1,0,1,0^3,1,0^7,1,0^{15},\\ldots)$ was first proved by Dai using the Euclidean algorithm. We have previously shown that we can attach a homogeneous (annihilator) ideal of $F[x,z]$ to the first $n$ terms of a sequence over a field $F$ and construct a pair of generating forms for it. This approach gives another proof of Rueppel's conjecture. We also prove additional properties of these forms and deduce the outputs of the LFSR synthesis algorithm applied to the first $n$ terms. Further, dehomogenising the leading generators yields the minimal polynomials of Dai.",
        "published": "2023-04-30T06:39:29Z",
        "link": "http://arxiv.org/abs/2305.00405v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Drinfeld modules in SageMath",
        "authors": [
            "David Ayotte",
            "Xavier Caruso",
            "Antoine Leudière",
            "Joseph Musleh"
        ],
        "summary": "We present the first implementation of Drinfeld modules fully integrated in the SageMath ecosystem. First features will be released with SageMath 10.0.",
        "published": "2023-04-30T08:03:19Z",
        "link": "http://arxiv.org/abs/2305.00422v1",
        "categories": [
            "cs.SC",
            "math.NT"
        ]
    },
    {
        "title": "Arithmetic of D-Algebraic Functions",
        "authors": [
            "Bertrand Teguia Tabuguia"
        ],
        "summary": "We are concerned with the arithmetic of solutions to ordinary or partial nonlinear differential equations which are algebraic in the indeterminates and their derivatives. We call these solutions D-algebraic functions, and their equations are algebraic (ordinary or partial) differential equations (ADEs). The general purpose is to find ADEs whose solutions contain specified rational expressions of solutions to given ADEs. For univariate D-algebraic functions, we show how to derive an ADE of smallest possible order. In the multivariate case, we introduce a general algorithm for these computations and derive conclusions on the order bound of the resulting algebraic PDE. Using our accompanying Maple software, we discuss applications in physics, statistics, and symbolic integration.",
        "published": "2023-05-01T08:01:34Z",
        "link": "http://arxiv.org/abs/2305.00702v3",
        "categories": [
            "cs.SC",
            "math.AC",
            "12H05, 68W30, 13P10 (Primary), 34-04, 35-04 (Secondary)"
        ]
    },
    {
        "title": "Chronosymbolic Learning: Efficient CHC Solving with Symbolic Reasoning   and Inductive Learning",
        "authors": [
            "Ziyan Luo",
            "Xujie Si"
        ],
        "summary": "Solving Constrained Horn Clauses (CHCs) is a fundamental challenge behind a wide range of verification and analysis tasks. Data-driven approaches show great promise in improving CHC solving without the painstaking manual effort of creating and tuning various heuristics. However, a large performance gap exists between data-driven CHC solvers and symbolic reasoning-based solvers. In this work, we develop a simple but effective framework, \"Chronosymbolic Learning\", which unifies symbolic information and numerical data points to solve a CHC system efficiently. We also present a simple instance of Chronosymbolic Learning with a data-driven learner and a BMC-styled reasoner. Despite its relative simplicity, experimental results show the efficacy and robustness of our tool. It outperforms state-of-the-art CHC solvers on a dataset consisting of 288 benchmarks, including many instances with non-linear integer arithmetics.",
        "published": "2023-05-02T05:12:48Z",
        "link": "http://arxiv.org/abs/2305.01206v4",
        "categories": [
            "cs.LO",
            "cs.AI",
            "cs.LG",
            "cs.PL",
            "cs.SC"
        ]
    },
    {
        "title": "Interpretable Machine Learning for Science with PySR and   SymbolicRegression.jl",
        "authors": [
            "Miles Cranmer"
        ],
        "summary": "PySR is an open-source library for practical symbolic regression, a type of machine learning which aims to discover human-interpretable symbolic models. PySR was developed to democratize and popularize symbolic regression for the sciences, and is built on a high-performance distributed back-end, a flexible search algorithm, and interfaces with several deep learning packages. PySR's internal search algorithm is a multi-population evolutionary algorithm, which consists of a unique evolve-simplify-optimize loop, designed for optimization of unknown scalar constants in newly-discovered empirical expressions. PySR's backend is the extremely optimized Julia library SymbolicRegression.jl, which can be used directly from Julia. It is capable of fusing user-defined operators into SIMD kernels at runtime, performing automatic differentiation, and distributing populations of expressions to thousands of cores across a cluster. In describing this software, we also introduce a new benchmark, \"EmpiricalBench,\" to quantify the applicability of symbolic regression algorithms in science. This benchmark measures recovery of historical empirical equations from original and synthetic datasets.",
        "published": "2023-05-02T16:31:35Z",
        "link": "http://arxiv.org/abs/2305.01582v3",
        "categories": [
            "astro-ph.IM",
            "cs.LG",
            "cs.NE",
            "cs.SC",
            "physics.data-an"
        ]
    },
    {
        "title": "Factorization and root-finding for polynomials over division quaternion   algebras",
        "authors": [
            "Przemysław Koprowski"
        ],
        "summary": "Polynomial factorization and root finding are among the most standard themes of computational mathematics. Yet still, little has been done for polynomials over quaternion algebras, with the single exception of Hamiltonian quaternions for which there are known numerical methods for polynomial root approximation. The sole purpose of the present paper is to present a polynomial factorization algorithm for division quaternion algebras over number fields, together with its adaptation for root finding.",
        "published": "2023-05-03T12:18:51Z",
        "link": "http://arxiv.org/abs/2305.02072v1",
        "categories": [
            "cs.SC",
            "math.RA",
            "11R52, 11Y40, 11Y05, 68W30",
            "I.1.2"
        ]
    },
    {
        "title": "G-MATT: Single-step Retrosynthesis Prediction using Molecular Grammar   Tree Transformer",
        "authors": [
            "Kevin Zhang",
            "Vipul Mann",
            "Venkat Venkatasubramanian"
        ],
        "summary": "Various template-based and template-free approaches have been proposed for single-step retrosynthesis prediction in recent years. While these approaches demonstrate strong performance from a data-driven metrics standpoint, many model architectures do not incorporate underlying chemistry principles. Here, we propose a novel chemistry-aware retrosynthesis prediction framework that combines powerful data-driven models with prior domain knowledge. We present a tree-to-sequence transformer architecture that utilizes hierarchical SMILES grammar-based trees, incorporating crucial chemistry information that is often overlooked by SMILES text-based representations, such as local structures and functional groups. The proposed framework, grammar-based molecular attention tree transformer (G-MATT), achieves significant performance improvements compared to baseline retrosynthesis models. G-MATT achieves a promising top-1 accuracy of 51% (top-10 accuracy of 79.1%), invalid rate of 1.5%, and bioactive similarity rate of 74.8% on the USPTO- 50K dataset. Additional analyses of G-MATT attention maps demonstrate the ability to retain chemistry knowledge without relying on excessively complex model architectures.",
        "published": "2023-05-04T21:04:19Z",
        "link": "http://arxiv.org/abs/2305.03153v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.FL",
            "cs.SC",
            "q-bio.QM"
        ]
    },
    {
        "title": "Bézout Subresultants for Univariate Polynomials in General Basis",
        "authors": [
            "Jing Yang",
            "Wei Yang"
        ],
        "summary": "Subresultant is a powerful tool for developing various algorithms in computer algebra. Subresultants for polynomials in standard basis (i.e., power basis) have been well studied so far. With the popularity of basis-preserving algorithms, resultants and subresultants in non-standard basis are drawing more and more attention. In this paper, we develop a formula for B\\'ezout subresultants of univariate polynomials in general basis, which covers a broad range of non-standard bases. More explicitly, the input polynomials are provided in a given general basis and the resulting subresultants are B\\'ezout-type expressions in the same basis. It is shown that the subresultants share the essential properties as the subresultants in standard basis.",
        "published": "2023-05-06T02:51:06Z",
        "link": "http://arxiv.org/abs/2305.03906v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Score: A Rule Engine for the Scone Knowledge Base System",
        "authors": [
            "Jeffrey Chen",
            "Scott E. Fahlman"
        ],
        "summary": "We present Score, a rule engine designed and implemented for the Scone knowledge base system. Scone is a knowledge base system designed for storing and manipulating rich representations of general knowledge in symbolic form. It represents knowledge in the form of nodes and links in a network structure, and it can perform basic inference about the relationships between different elements efficiently. On its own, Scone acts as a sort of \"smart memory\" that can interface with other software systems. One area of improvement for Scone is how useful it can be in supplying knowledge to an intelligent agent that can use the knowledge to perform actions and update the knowledge base with its observations.   We augment the Scone system with a production rule engine that automatically performs simple inference based on existing and newly-added structures in Scone's knowledge base, potentially improving the capabilities of any planning systems built on top of Scone. Production rule systems consist of \"if-then\" production rules that try to match their predicates to existing knowledge and fire their actions when their predicates are satisfied. We propose two kinds of production rules, if-added and if-needed rules, that differ in how they are checked and fired to cover multiple use cases. We then implement methods to efficiently check and fire these rules in a large knowledge base. The new rule engine is not meant to be a complex stand-alone planner, so we discuss how it fits into the context of Scone and future work on planning systems.",
        "published": "2023-05-07T00:50:05Z",
        "link": "http://arxiv.org/abs/2305.04154v1",
        "categories": [
            "cs.AI",
            "cs.SC"
        ]
    },
    {
        "title": "Infinite matroids in tropical differential algebra",
        "authors": [
            "F. Aroca",
            "L. Bossinger",
            "S. Falkensteiner",
            "C. Garay Lopez",
            "L. R. Gonzalez-Ramirez",
            "C. V. Valencia Negrete"
        ],
        "summary": "We consider a finite-dimensional vector space $W\\subset K^E$ over an arbitrary field $K$ and an arbitrary set $E$. We show that the set $C(W)\\subset 2^E$ consisting of the minimal supports of $W$ are the circuits of a matroid on $E$. In particular, we show that this matroid is cofinitary (hence, tame). When the cardinality of $K$ is large enough (with respect to the cardinality of $E$), then the set $trop(W)\\subset 2^E$ consisting of all the supports of $W$ is a matroid itself.   Afterwards we apply these results to tropical differential algebraic geometry and study the set of supports $trop(Sol(\\Sigma))\\subset (2^{\\mathbb{N}^{m}})^n$ of spaces of formal power series solutions $\\text{Sol}(\\Sigma)$ of systems of linear differential equations $\\Sigma$ in differential variables $x_1,\\ldots,x_n$ having coefficients in the ring ${K}[\\![t_1,\\ldots,t_m]\\!]$. If $\\Sigma$ is of differential type zero, then the set $C(Sol(\\Sigma))\\subset (2^{\\mathbb{N}^{m}})^n$ of minimal supports defines a matroid on $E=\\mathbb{N}^{mn}$, and if the cardinality of $K$ is large enough, then the set of supports $trop(Sol(\\Sigma))$ itself is a matroid on $E$ as well. By applying the fundamental theorem of tropical differential algebraic geometry (fttdag), we give a necessary condition under which the set of solutions $Sol(U)$ of a system $U$ of tropical linear differential equations to be a matroid.   We also give a counterexample to the fttdag for systems $\\Sigma$ of linear differential equations over countable fields. In this case, the set $trop(Sol(\\Sigma))$ may not form a matroid.",
        "published": "2023-05-08T15:35:20Z",
        "link": "http://arxiv.org/abs/2305.04784v2",
        "categories": [
            "math.AG",
            "cs.SC",
            "math.CO",
            "14T99, 34A30, 13N99, 05B35"
        ]
    },
    {
        "title": "Dimension Results for Extremal-Generic Polynomial Systems over Complete   Toric Varieties",
        "authors": [
            "Matías Bender",
            "Pierre-Jean Spaenlehauer"
        ],
        "summary": "We study polynomial systems with prescribed monomial supports in the Cox rings of toric varieties built from complete polyhedral fans. We present combinatorial formulas for the dimensions of their associated subvarieties under genericity assumptions on the coefficients of the polynomials. Using these formulas, we identify at which degrees generic systems in polytopal algebras form regular sequences. Our motivation comes from sparse elimination theory, where knowing the expected dimension of these subvarieties leads to specialized algorithms and to large speed-ups for solving sparse polynomial systems. As a special case, we classify the degrees at which regular sequences defined by weighted homogeneous polynomials can be found, answering an open question in the Gr\\\"obner bases literature. We also show that deciding whether a sparse system is generically a regular sequence in a polytopal algebra is hard from the point of view of theoretical computational complexity.",
        "published": "2023-05-12T13:01:36Z",
        "link": "http://arxiv.org/abs/2305.07439v3",
        "categories": [
            "cs.SC",
            "math.AG"
        ]
    },
    {
        "title": "Log-concavity and log-convexity of series containing multiple Pochhammer   symbols",
        "authors": [
            "Dmitrii Karp",
            "Yi Zhang"
        ],
        "summary": "In this paper, we study power series with coefficients equal to a product of a generic sequence and an explicitly given function of a positive parameter expressible in terms of the Pochhammer symbols. Four types of such series are treated. We show that logarithmic concavity (convexity) of the generic sequence leads to logarithmic concavity (convexity) of the sum of the series with respect to the argument of the explicitly given function. The logarithmic concavity (convexity) is derived from a stronger property, namely, positivity (negativity) of the power series coefficients of the so-called generalized Tur\\'{a}nian. Applications to special functions such as the generalized hypergeometric function and the Fox-Wright function are also discussed.",
        "published": "2023-05-15T21:31:10Z",
        "link": "http://arxiv.org/abs/2305.09029v3",
        "categories": [
            "math.CA",
            "cs.SC",
            "26A51, 33C20, 33C60, 33F10"
        ]
    },
    {
        "title": "Bézout identities and control of the heat equation",
        "authors": [
            "François Ollivier"
        ],
        "summary": "Computing analytic B\\'ezout identities remains a difficult task, which has many applications in control theory. Flat PDE systems have cast a new light on this problem. We consider here a simple case of special interest: a rod of length $a+b$, insulated at both ends and heated at point $x=a$. The case $a=0$ is classical, the temperature of the other end $\\theta(b,t)$ being then a flat output, with parametrization $\\theta(x,t)=\\cosh((b-x)(\\partial/\\partial t)^{1/2}\\theta(b,t)$.   When $a$ and $b$ are integers, with $a$ odd and $b$ even, the system is flat and the flat output is obtained from the B\\'ezout identity $f(x)\\cosh(ax)+g(x)\\cosh(bx)=1$, the omputation of which boils down to a B\\'ezout identity of Chebyshev polynomials. But this form is not the most efficient and a smaller expression $f(x)=\\sum_{k=1}^{n} c_{k}\\cosh(kx)$ may be computed in linear time.   These results are compared with an approximations by a finite system, using a classical discretization.   We provide experimental computations, approximating a non rational value $r$ by a sequence of fractions $b/a$, showing that the power series for the B\\'ezout relation seems to converge.",
        "published": "2023-05-16T10:39:29Z",
        "link": "http://arxiv.org/abs/2305.09340v1",
        "categories": [
            "cs.SC",
            "math.OC",
            "68W30, 35Q97, 30D20",
            "G.1.8"
        ]
    },
    {
        "title": "How to automatise proofs of operator statements: Moore-Penrose inverse   -- a case study",
        "authors": [
            "Klara Bernauer",
            "Clemens Hofstadler",
            "Georg Regensburger"
        ],
        "summary": "We describe a recently developed algebraic framework for proving first-order statements about linear operators by computations with noncommutative polynomials. Furthermore, we present our new SageMath package operator_gb, which offers functionality for automatising such computations. We aim to provide a practical understanding of our approach and the software through examples, while also explaining the completeness of the method in the sense that it allows to find algebraic proofs for every true first-order operator statement. We illustrate the capability of the framework in combination with our software by a case study on statements about the Moore-Penrose inverse, including classical facts and recent results, presented in an online notebook.",
        "published": "2023-05-16T14:11:13Z",
        "link": "http://arxiv.org/abs/2305.09448v2",
        "categories": [
            "cs.SC",
            "cs.LO"
        ]
    },
    {
        "title": "The Complexity of Diagonalization",
        "authors": [
            "Nikhil Srivastava"
        ],
        "summary": "We survey recent progress on efficient algorithms for approximately diagonalizing a square complex matrix in the models of rational (variable precision) and finite (floating point) arithmetic. This question has been studied across several research communities for decades, but many mysteries remain. We present several open problems which we hope will be of broad interest.",
        "published": "2023-05-17T21:21:11Z",
        "link": "http://arxiv.org/abs/2305.10575v1",
        "categories": [
            "cs.SC",
            "cs.CC",
            "cs.DS",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Two-step Newton's method for deflation-one singular zeros of analytic   systems",
        "authors": [
            "Kisun Lee",
            "Nan Li",
            "Lihong Zhi"
        ],
        "summary": "We propose a two-step Newton's method for refining an approximation of a singular zero whose deflation process terminates after one step, also known as a deflation-one singularity. Given an isolated singular zero of a square analytic system, our algorithm exploits an invertible linear operator obtained by combining the Jacobian and a projection of the Hessian in the direction of the kernel of the Jacobian. We prove the quadratic convergence of the two-step Newton method when it is applied to an approximation of a deflation-one singular zero. Also, the algorithm requires a smaller size of matrices than the existing methods, making it more efficient. We demonstrate examples and experiments to show the efficiency of the method.",
        "published": "2023-05-18T08:31:45Z",
        "link": "http://arxiv.org/abs/2305.10803v2",
        "categories": [
            "math.NA",
            "cs.NA",
            "cs.SC",
            "math.AG",
            "65D18, 14Q99"
        ]
    },
    {
        "title": "Using Symbolic Computation to Analyze Zero-Hopf Bifurcations of   Polynomial Differential Systems",
        "authors": [
            "Bo Huang"
        ],
        "summary": "This paper is devoted to the study of infinitesimal limit cycles that can bifurcate from zero-Hopf equilibria of differential systems based on the averaging method. We develop an efficient symbolic program using Maple for computing the averaged functions of any order for continuous differential systems in arbitrary dimension. The program allows us to systematically analyze zero-Hopf bifurcations of polynomial differential systems using symbolic computation methods. We show that for the first-order averaging, $\\ell\\in\\{0,1,\\ldots,2^{n-3}\\}$ limit cycles can bifurcate from the zero-Hopf equilibrium for the general class of perturbed differential systems and up to the second-order averaging, the maximum number of limit cycles can be determined by computing the mixed volume of a polynomial system obtained from the averaged functions. A number of examples are presented to demonstrate the effectiveness of the proposed algorithmic approach.",
        "published": "2023-05-18T16:52:56Z",
        "link": "http://arxiv.org/abs/2305.11109v1",
        "categories": [
            "cs.SC",
            "math.DS"
        ]
    },
    {
        "title": "Inverse kinematics and path planning of manipulator using real   quantifier elimination based on Comprehensive Gröbner Systems",
        "authors": [
            "Mizuki Yoshizawa",
            "Akira Terui",
            "Masahiko Mikawa"
        ],
        "summary": "Methods for inverse kinematics computation and path planning of a three degree-of-freedom (DOF) manipulator using the algorithm for quantifier elimination based on Comprehensive Gr\\\"obner Systems (CGS), called CGS-QE method, are proposed. The first method for solving the inverse kinematics problem employs counting the real roots of a system of polynomial equations to verify the solution's existence. In the second method for trajectory planning of the manipulator, the use of CGS guarantees the existence of an inverse kinematics solution. Moreover, it makes the algorithm more efficient by preventing repeated computation of Gr\\\"obner basis. In the third method for path planning of the manipulator, for a path of the motion given as a function of a parameter, the CGS-QE method verifies the whole path's feasibility. Computational examples and an experiment are provided to illustrate the effectiveness of the proposed methods.",
        "published": "2023-05-21T13:09:44Z",
        "link": "http://arxiv.org/abs/2305.12451v2",
        "categories": [
            "cs.RO",
            "cs.SC",
            "math.AC",
            "13P15, 68W30"
        ]
    },
    {
        "title": "SCL(FOL) Can Simulate Non-Redundant Superposition Clause Learning",
        "authors": [
            "Martin Bromberger",
            "Chaahat Jain",
            "Christoph Weidenbach"
        ],
        "summary": "We show that SCL(FOL) can simulate the derivation of non-redundant clauses by superposition for first-order logic without equality. Superposition-based reasoning is performed with respect to a fixed reduction ordering. The completeness proof of superposition relies on the grounding of the clause set. It builds a ground partial model according to the fixed ordering, where minimal false ground instances of clauses then trigger non-redundant superposition inferences. We define a respective strategy for the SCL calculus such that clauses learned by SCL and superposition inferences coincide. From this perspective the SCL calculus can be viewed as a generalization of the superposition calculus.",
        "published": "2023-05-22T11:12:39Z",
        "link": "http://arxiv.org/abs/2305.12926v1",
        "categories": [
            "cs.LO",
            "cs.AI",
            "cs.SC",
            "I.2.3"
        ]
    },
    {
        "title": "RSRM: Reinforcement Symbolic Regression Machine",
        "authors": [
            "Yilong Xu",
            "Yang Liu",
            "Hao Sun"
        ],
        "summary": "In nature, the behaviors of many complex systems can be described by parsimonious math equations. Automatically distilling these equations from limited data is cast as a symbolic regression process which hitherto remains a grand challenge. Keen efforts in recent years have been placed on tackling this issue and demonstrated success in symbolic regression. However, there still exist bottlenecks that current methods struggle to break when the discrete search space tends toward infinity and especially when the underlying math formula is intricate. To this end, we propose a novel Reinforcement Symbolic Regression Machine (RSRM) that masters the capability of uncovering complex math equations from only scarce data. The RSRM model is composed of three key modules: (1) a Monte Carlo tree search (MCTS) agent that explores optimal math expression trees consisting of pre-defined math operators and variables, (2) a Double Q-learning block that helps reduce the feasible search space of MCTS via properly understanding the distribution of reward, and (3) a modulated sub-tree discovery block that heuristically learns and defines new math operators to improve representation ability of math expression trees. Biding of these modules yields the state-of-the-art performance of RSRM in symbolic regression as demonstrated by multiple sets of benchmark examples. The RSRM model shows clear superiority over several representative baseline models.",
        "published": "2023-05-24T02:51:45Z",
        "link": "http://arxiv.org/abs/2305.14656v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.SC"
        ]
    },
    {
        "title": "Neural Machine Translation for Mathematical Formulae",
        "authors": [
            "Felix Petersen",
            "Moritz Schubotz",
            "Andre Greiner-Petter",
            "Bela Gipp"
        ],
        "summary": "We tackle the problem of neural machine translation of mathematical formulae between ambiguous presentation languages and unambiguous content languages. Compared to neural machine translation on natural language, mathematical formulae have a much smaller vocabulary and much longer sequences of symbols, while their translation requires extreme precision to satisfy mathematical information needs. In this work, we perform the tasks of translating from LaTeX to Mathematica as well as from LaTeX to semantic LaTeX. While recurrent, recursive, and transformer networks struggle with preserving all contained information, we find that convolutional sequence-to-sequence networks achieve 95.1% and 90.7% exact matches, respectively.",
        "published": "2023-05-25T19:15:06Z",
        "link": "http://arxiv.org/abs/2305.16433v1",
        "categories": [
            "cs.CL",
            "cs.SC",
            "stat.AP"
        ]
    },
    {
        "title": "Representing Piecewise Linear Functions by Functions with Small Arity",
        "authors": [
            "Christoph Koutschan",
            "Bernhard Moser",
            "Anton Ponomarchuk",
            "Josef Schicho"
        ],
        "summary": "A piecewise linear function can be described in different forms: as an arbitrarily nested expression of $\\min$- and $\\max$-functions, as a difference of two convex piecewise linear functions, or as a linear combination of maxima of affine-linear functions. In this paper, we provide two main results: first, we show that for every piecewise linear function there exists a linear combination of $\\max$-functions with at most $n+1$ arguments, and give an algorithm for its computation. Moreover, these arguments are contained in the finite set of affine-linear functions that coincide with the given function in some open set. Second, we prove that the piecewise linear function $\\max(0, x_{1}, \\ldots, x_{n})$ cannot be represented as a linear combination of maxima of less than $n+1$ affine-linear arguments. This was conjectured by Wang and Sun in 2005 in a paper on representations of piecewise linear functions as linear combination of maxima.",
        "published": "2023-05-26T13:48:37Z",
        "link": "http://arxiv.org/abs/2305.16933v1",
        "categories": [
            "cs.SC",
            "cs.DM",
            "cs.LG",
            "math.CO"
        ]
    },
    {
        "title": "Efficient Quotients of Non-Commutative Polynomials",
        "authors": [
            "Stephen M. Watt"
        ],
        "summary": "It is shown how to compute quotients efficiently in non-commutative univariate polynomial rings. This extends earlier work where efficient generic quotients were studied with a primary focus on commutative domains. Fast algorithms are given for left and right quotients of polynomials where the variable commutes with coefficients. These algorithms are based on the concept of the ``whole shifted inverse'', which is a specialized quotient where the dividend is a power of the polynomial variable. It is also shown that when the variable does not commute with coefficients, that is for skew polynomials, left and right whole shifted inverses are defined and may be used to compute right and left quotients. In this case their computation is not asymptotically fast, but once obtained, they may be used to compute multiple quotients, each with one multiplication. Examples are shown of polynomials with matrix coefficients, differential operators and difference operators. In addition, a proof-of-concept generic Maple implementations is given.",
        "published": "2023-05-29T04:15:57Z",
        "link": "http://arxiv.org/abs/2305.17877v4",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Reason to explain: Interactive contrastive explanations (REASONX)",
        "authors": [
            "Laura State",
            "Salvatore Ruggieri",
            "Franco Turini"
        ],
        "summary": "Many high-performing machine learning models are not interpretable. As they are increasingly used in decision scenarios that can critically affect individuals, it is necessary to develop tools to better understand their outputs. Popular explanation methods include contrastive explanations. However, they suffer several shortcomings, among others an insufficient incorporation of background knowledge, and a lack of interactivity. While (dialogue-like) interactivity is important to better communicate an explanation, background knowledge has the potential to significantly improve their quality, e.g., by adapting the explanation to the needs of the end-user. To close this gap, we present REASONX, an explanation tool based on Constraint Logic Programming (CLP). REASONX provides interactive contrastive explanations that can be augmented by background knowledge, and allows to operate under a setting of under-specified information, leading to increased flexibility in the provided explanations. REASONX computes factual and constrative decision rules, as well as closest constrative examples. It provides explanations for decision trees, which can be the ML models under analysis, or global/local surrogate models of any ML model. While the core part of REASONX is built on CLP, we also provide a program layer that allows to compute the explanations via Python, making the tool accessible to a wider audience. We illustrate the capability of REASONX on a synthetic data set, and on a a well-developed example in the credit domain. In both cases, we can show how REASONX can be flexibly used and tailored to the needs of the user.",
        "published": "2023-05-29T15:13:46Z",
        "link": "http://arxiv.org/abs/2305.18143v1",
        "categories": [
            "cs.AI",
            "cs.CY",
            "cs.LG",
            "cs.SC"
        ]
    },
    {
        "title": "A family of Counterexamples on Inequality among Symmetric Functions",
        "authors": [
            "Jia Xu",
            "Yong Yao"
        ],
        "summary": "Inequalities among symmetric functions are fundamental questions in mathematics and have various applications in science and engineering. In this paper, we tackle a conjecture about inequalities among the complete homogeneous symmetric function $H_{n,\\lambda}$, that is, the inequality $H_{n,\\lambda}\\leq H_{n,\\mu}$ implies majorization order $\\lambda\\preceq\\mu$. This conjecture was proposed by Cuttler, Greene and Skandera in 2011. The conjecture is a close analogy with other known results on Muirhead-type inequalities. In 2021, Heaton and Shankar disproved the conjecture by showing a counterexample for degree $d=8$ and number of variables $n=3$. They then asked whether the conjecture is true when~ the number of variables, $n$, is large enough? In this paper, we answer the question by proving that the conjecture does not hold when $d\\geq8$ and $n\\geq2$. A crucial step of the proof relies on variables reduction. Inspired by this, we propose a new conjecture for $H_{n,\\lambda}\\leq H_{n,\\mu}$.",
        "published": "2023-05-31T13:14:06Z",
        "link": "http://arxiv.org/abs/2305.19830v1",
        "categories": [
            "math.CO",
            "cs.SC",
            "05E05 14P99 90C22"
        ]
    },
    {
        "title": "Information Fusion via Symbolic Regression: A Tutorial in the Context of   Human Health",
        "authors": [
            "Jennifer J. Schnur",
            "Nitesh V. Chawla"
        ],
        "summary": "This tutorial paper provides a general overview of symbolic regression (SR) with specific focus on standards of interpretability. We posit that interpretable modeling, although its definition is still disputed in the literature, is a practical way to support the evaluation of successful information fusion. In order to convey the benefits of SR as a modeling technique, we demonstrate an application within the field of health and nutrition using publicly available National Health and Nutrition Examination Survey (NHANES) data from the Centers for Disease Control and Prevention (CDC), fusing together anthropometric markers into a simple mathematical expression to estimate body fat percentage. We discuss the advantages and challenges associated with SR modeling and provide qualitative and quantitative analyses of the learned models.",
        "published": "2023-05-31T19:52:17Z",
        "link": "http://arxiv.org/abs/2306.00153v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.SC"
        ]
    },
    {
        "title": "Some New Non-Commutative Matrix Multiplication Algorithms of Size   $(n,m,6)$",
        "authors": [
            "Manuel Kauers",
            "Jakob Moosbauer"
        ],
        "summary": "For various $2\\leq n,m \\leq 6$, we propose some new algorithms for multiplying an $n\\times m$ matrix with an $m \\times 6$ matrix over a possibly noncommutative coefficient ring.",
        "published": "2023-06-01T16:41:55Z",
        "link": "http://arxiv.org/abs/2306.00882v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Interpretable and Explainable Logical Policies via Neurally Guided   Symbolic Abstraction",
        "authors": [
            "Quentin Delfosse",
            "Hikaru Shindo",
            "Devendra Dhami",
            "Kristian Kersting"
        ],
        "summary": "The limited priors required by neural networks make them the dominating choice to encode and learn policies using reinforcement learning (RL). However, they are also black-boxes, making it hard to understand the agent's behaviour, especially when working on the image level. Therefore, neuro-symbolic RL aims at creating policies that are interpretable in the first place. Unfortunately, interpretability is not explainability. To achieve both, we introduce Neurally gUided Differentiable loGic policiEs (NUDGE). NUDGE exploits trained neural network-based agents to guide the search of candidate-weighted logic rules, then uses differentiable logic to train the logic agents. Our experimental evaluation demonstrates that NUDGE agents can induce interpretable and explainable policies while outperforming purely neural ones and showing good flexibility to environments of different initial states and problem sizes.",
        "published": "2023-06-02T10:59:44Z",
        "link": "http://arxiv.org/abs/2306.01439v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.CL",
            "cs.LO",
            "cs.SC"
        ]
    },
    {
        "title": "Towards Efficient Controller Synthesis Techniques for Logical LTL Games",
        "authors": [
            "Stanly Samuel",
            "Deepak D'Souza",
            "Raghavan Komondoor"
        ],
        "summary": "Two-player games are a fruitful way to represent and reason about several important synthesis tasks. These tasks include controller synthesis (where one asks for a controller for a given plant such that the controlled plant satisfies a given temporal specification), program repair (setting values of variables to avoid exceptions), and synchronization synthesis (adding lock/unlock statements in multi-threaded programs to satisfy safety assertions). In all these applications, a solution directly corresponds to a winning strategy for one of the players in the induced game. In turn, \\emph{logically-specified} games offer a powerful way to model these tasks for large or infinite-state systems. Much of the techniques proposed for solving such games typically rely on abstraction-refinement or template-based solutions. In this paper, we show how to apply classical fixpoint algorithms, that have hitherto been used in explicit, finite-state, settings, to a symbolic logical setting. We implement our techniques in a tool called GenSys-LTL and show that they are not only effective in synthesizing valid controllers for a variety of challenging benchmarks from the literature, but often compute maximal winning regions and maximally-permissive controllers. We achieve \\textbf{46.38X speed-up} over the state of the art and also scale well for non-trivial LTL specifications.",
        "published": "2023-06-04T18:19:04Z",
        "link": "http://arxiv.org/abs/2306.02427v2",
        "categories": [
            "cs.LO",
            "cs.FL",
            "cs.SC",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "A sharper multivariate Christol's theorem with applications to diagonals   and Hadamard products",
        "authors": [
            "Boris Adamczewski",
            "Alin Bostan",
            "Xavier Caruso"
        ],
        "summary": "We provide a new proof of the multivariate version of Christol's theorem about algebraic power series with coefficients in finite fields, as well as of its extension to perfect ground fields of positive characteristic obtained independently by Denef and Lipshitz, Sharif and Woodcok, and Harase. Our proof is elementary, effective, and allows for much sharper estimates. We discuss various applications of such estimates, in particular to a problem raised by Deligne concerning the algebraicity degree of reductions modulo $p$ of diagonals of multivariate algebraic power series with integer coefficients.",
        "published": "2023-06-05T07:23:26Z",
        "link": "http://arxiv.org/abs/2306.02640v1",
        "categories": [
            "math.NT",
            "cs.SC"
        ]
    },
    {
        "title": "Faster real root decision algorithm for symmetric polynomials",
        "authors": [
            "George Labahn",
            "Cordian Riener",
            "Mohab Safey El Din",
            "Éric Schost",
            "Thi Xuan Vu"
        ],
        "summary": "In this paper, we consider the problem of deciding the existence of real solutions to a system of polynomial equations having real coefficients, and which are invariant under the action of the symmetric group. We construct and analyze a Monte Carlo probabilistic algorithm which solves this problem, under some regularity assumptions on the input, by taking advantage of the symmetry invariance property. The complexity of our algorithm is polynomial in $d^s, {{n+d} \\choose d}$, and ${{n} \\choose {s+1}}$, where $n$ is the number of variables and $d$ is the maximal degree of $s$ input polynomials defining the real algebraic set under study. In particular, this complexity is polynomial in $n$ when $d$ and $s$ are fixed and is equal to $n^{O(1)}2^n$ when $d=n$.",
        "published": "2023-06-06T16:49:15Z",
        "link": "http://arxiv.org/abs/2306.03855v1",
        "categories": [
            "cs.SC",
            "math.AG"
        ]
    },
    {
        "title": "On Isolating Roots in a Multiple Field Extension",
        "authors": [
            "Christina Katsamaki",
            "Fabrice Rouillier"
        ],
        "summary": "We address univariate root isolation when the polynomial's coefficients are in a multiple field extension. We consider a polynomial $F \\in L[Y]$, where $L$ is a multiple algebraic extension of $\\mathbb{Q}$. We provide aggregate bounds for $F$ and algorithmic and bit-complexity results for the problem of isolating its roots. For the latter problem we follow a common approach based on univariate root isolation algorithms. For the particular case where $F$ does not have multiple roots, we achieve a bit-complexity in $\\tilde{\\mathcal{O}}_B(n d^{2n+2}(d+n\\tau))$, where $d$ is the total degree and $\\tau$ is the bitsize of the involved polynomials.In the general case we need to enhance our algorithm with a preprocessing step that determines the number of distinct roots of $F$. We follow a numerical, yet certified, approach that has bit-complexity $\\tilde{\\mathcal{O}}_B(n^2d^{3n+3}\\tau + n^3 d^{2n+4}\\tau)$.",
        "published": "2023-06-07T09:12:05Z",
        "link": "http://arxiv.org/abs/2306.04271v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Effective homology and periods of complex projective hypersurfaces",
        "authors": [
            "Pierre Lairez",
            "Eric Pichon-Pharabod",
            "Pierre Vanhove"
        ],
        "summary": "We introduce a new algorithm for computing the periods of a smooth complex projective hypersurface. The algorithm intertwine with a new method for computing an explicit basis of the singular homology of the hypersurface. It is based on Picard-Lefschetz theory and relies on the computation of the monodromy action induced by a one-parameter family of hyperplane sections on the homology of a given section. We provide a SageMath implementation. For example, on a laptop, it makes it possible to compute the periods of a smooth complex quartic surface with hundreds of digits of precision in typically an hour.",
        "published": "2023-06-08T15:08:46Z",
        "link": "http://arxiv.org/abs/2306.05263v2",
        "categories": [
            "math.AG",
            "cs.SC",
            "Primary 14Q15, Secondary 32G20, 14D05"
        ]
    },
    {
        "title": "Positivity certificates for linear recurrences",
        "authors": [
            "Alaa Ibrahim",
            "Bruno Salvy"
        ],
        "summary": "We consider linear recurrences with polynomial coefficients of Poincar\\'e type and with a unique simple dominant eigenvalue. We give an algorithm that proves or disproves positivity of solutions provided the initial conditions satisfy a precisely defined genericity condition. For positive sequences, the algorithm produces a certificate of positivity that is a data-structure for a proof by induction. This induction works by showing that an explicitly computed cone is contracted by the iteration of the recurrence.",
        "published": "2023-06-09T14:44:38Z",
        "link": "http://arxiv.org/abs/2306.05930v2",
        "categories": [
            "cs.SC",
            "cs.DM",
            "05A20, 11B37, 39A06, 68V05",
            "F.2.2; G.2.1; I.1.2"
        ]
    },
    {
        "title": "Exact and Approximate Moment Derivation for Probabilistic Loops With   Non-Polynomial Assignments",
        "authors": [
            "Andrey Kofnov",
            "Marcel Moosbrugger",
            "Miroslav Stankovič",
            "Ezio Bartocci",
            "Efstathia Bura"
        ],
        "summary": "Many stochastic continuous-state dynamical systems can be modeled as probabilistic programs with nonlinear non-polynomial updates in non-nested loops. We present two methods, one approximate and one exact, to automatically compute, without sampling, moment-based invariants for such probabilistic programs as closed-form solutions parameterized by the loop iteration. The exact method applies to probabilistic programs with trigonometric and exponential updates and is embedded in the Polar tool. The approximate method for moment computation applies to any nonlinear random function as it exploits the theory of polynomial chaos expansion to approximate non-polynomial updates as the sum of orthogonal polynomials. This translates the dynamical system to a non-nested loop with polynomial updates, and thus renders it conformable with the Polar tool that computes the moments of any order of the state variables. We evaluate our methods on an extensive number of examples ranging from modeling monetary policy to several physical motion systems in uncertain environments. The experimental results demonstrate the advantages of our approach with respect to the current state-of-the-art.",
        "published": "2023-06-12T12:38:01Z",
        "link": "http://arxiv.org/abs/2306.07072v2",
        "categories": [
            "stat.AP",
            "cs.NA",
            "cs.SC",
            "math.NA",
            "math.ST",
            "stat.TH",
            "62G05, 62P30",
            "G.3"
        ]
    },
    {
        "title": "Existence and Construction of a Gröbner Basis for a Polynomial Ideal",
        "authors": [
            "Deepak Kapur",
            "Paliath Narendran"
        ],
        "summary": "This extended abstract gives a construction for lifting a Gr\\\"obner basis algorithm for an ideal in a polynomial ring over a commutative ring R under the condition that R also admits a Gr\\\"obner basis for every ideal in R.",
        "published": "2023-06-16T03:13:42Z",
        "link": "http://arxiv.org/abs/2306.09602v1",
        "categories": [
            "math.AC",
            "cs.SC",
            "math.AG"
        ]
    },
    {
        "title": "A Finite Expression Method for Solving High-Dimensional Committor   Problems",
        "authors": [
            "Zezheng Song",
            "Maria K. Cameron",
            "Haizhao Yang"
        ],
        "summary": "Transition path theory (TPT) is a mathematical framework for quantifying rare transition events between a pair of selected metastable states $A$ and $B$. Central to TPT is the committor function, which describes the probability to hit the metastable state $B$ prior to $A$ from any given starting point of the phase space. Once the committor is computed, the transition channels and the transition rate can be readily found. The committor is the solution to the backward Kolmogorov equation with appropriate boundary conditions. However, solving it is a challenging task in high dimensions due to the need to mesh a whole region of the ambient space. In this work, we explore the finite expression method (FEX, Liang and Yang (2022)) as a tool for computing the committor. FEX approximates the committor by an algebraic expression involving a fixed finite number of nonlinear functions and binary arithmetic operations. The optimal nonlinear functions, the binary operations, and the numerical coefficients in the expression template are found via reinforcement learning. The FEX-based committor solver is tested on several high-dimensional benchmark problems. It gives comparable or better results than neural network-based solvers. Most importantly, FEX is capable of correctly identifying the algebraic structure of the solution which allows one to reduce the committor problem to a low-dimensional one and find the committor with any desired accuracy.",
        "published": "2023-06-21T13:43:59Z",
        "link": "http://arxiv.org/abs/2306.12268v2",
        "categories": [
            "math.NA",
            "cs.LG",
            "cs.NA",
            "cs.SC"
        ]
    },
    {
        "title": "From Word Models to World Models: Translating from Natural Language to   the Probabilistic Language of Thought",
        "authors": [
            "Lionel Wong",
            "Gabriel Grand",
            "Alexander K. Lew",
            "Noah D. Goodman",
            "Vikash K. Mansinghka",
            "Jacob Andreas",
            "Joshua B. Tenenbaum"
        ],
        "summary": "How does language inform our downstream thinking? In particular, how do humans make meaning from language--and how can we leverage a theory of linguistic meaning to build machines that think in more human-like ways? In this paper, we propose rational meaning construction, a computational framework for language-informed thinking that combines neural language models with probabilistic models for rational inference. We frame linguistic meaning as a context-sensitive mapping from natural language into a probabilistic language of thought (PLoT)--a general-purpose symbolic substrate for generative world modeling. Our architecture integrates two computational tools that have not previously come together: we model thinking with probabilistic programs, an expressive representation for commonsense reasoning; and we model meaning construction with large language models (LLMs), which support broad-coverage translation from natural language utterances to code expressions in a probabilistic programming language. We illustrate our framework through examples covering four core domains from cognitive science: probabilistic reasoning, logical and relational reasoning, visual and physical reasoning, and social reasoning. In each, we show that LLMs can generate context-sensitive translations that capture pragmatically-appropriate linguistic meanings, while Bayesian inference with the generated programs supports coherent and robust commonsense reasoning. We extend our framework to integrate cognitively-motivated symbolic modules (physics simulators, graphics engines, and planning algorithms) to provide a unified commonsense thinking interface from language. Finally, we explore how language can drive the construction of world models themselves. We hope this work will provide a roadmap towards cognitive models and AI systems that synthesize the insights of both modern and classical computational perspectives.",
        "published": "2023-06-22T05:14:00Z",
        "link": "http://arxiv.org/abs/2306.12672v2",
        "categories": [
            "cs.CL",
            "cs.AI",
            "cs.SC"
        ]
    },
    {
        "title": "PhD Thesis: Exploring the role of (self-)attention in cognitive and   computer vision architecture",
        "authors": [
            "Mohit Vaishnav"
        ],
        "summary": "We investigate the role of attention and memory in complex reasoning tasks. We analyze Transformer-based self-attention as a model and extend it with memory. By studying a synthetic visual reasoning test, we refine the taxonomy of reasoning tasks. Incorporating self-attention with ResNet50, we enhance feature maps using feature-based and spatial attention, achieving efficient solving of challenging visual reasoning tasks. Our findings contribute to understanding the attentional needs of SVRT tasks. Additionally, we propose GAMR, a cognitive architecture combining attention and memory, inspired by active vision theory. GAMR outperforms other architectures in sample efficiency, robustness, and compositionality, and shows zero-shot generalization on new reasoning tasks.",
        "published": "2023-06-26T12:40:12Z",
        "link": "http://arxiv.org/abs/2306.14650v2",
        "categories": [
            "cs.AI",
            "cs.CV",
            "cs.LG",
            "cs.SC"
        ]
    },
    {
        "title": "Frex: dependently-typed algebraic simplification",
        "authors": [
            "Guillaume Allais",
            "Edwin Brady",
            "Nathan Corbyn",
            "Ohad Kammar",
            "Jeremy Yallop"
        ],
        "summary": "We present an extensible, mathematically-structured algebraic simplification library design. We structure the library using universal algebraic concepts: a free algebra -- fral -- and a free extension -- frex -- of an algebra by a set of variables. The library's dependently-typed API guarantees simplification modules, even user-defined ones, are terminating, sound, and complete with respect to a well-specified class of equations. Completeness offers intangible benefits in practice -- our main contribution is the novel design. Cleanly separating between the interface and implementation of simplification modules provides two new modularity axes. First, simplification modules share thousands of lines of infrastructure code dealing with term-representation, pretty-printing, certification, and macros/reflection. Second, new simplification modules can reuse existing ones. We demonstrate this design by developing simplification modules for monoid varieties: ordinary, commutative, and involutive. We implemented this design in the new Idris2 dependently-typed programming language, and in Agda.",
        "published": "2023-06-27T10:47:22Z",
        "link": "http://arxiv.org/abs/2306.15375v1",
        "categories": [
            "cs.PL",
            "cs.LO",
            "cs.SC"
        ]
    },
    {
        "title": "Generating Elementary Integrable Expressions",
        "authors": [
            "Rashid Barket",
            "Matthew England",
            "Jürgen Gerhard"
        ],
        "summary": "There has been an increasing number of applications of machine learning to the field of Computer Algebra in recent years, including to the prominent sub-field of Symbolic Integration. However, machine learning models require an abundance of data for them to be successful and there exist few benchmarks on the scale required. While methods to generate new data already exist, they are flawed in several ways which may lead to bias in machine learning models trained upon them. In this paper, we describe how to use the Risch Algorithm for symbolic integration to create a dataset of elementary integrable expressions. Further, we show that data generated this way alleviates some of the flaws found in earlier methods.",
        "published": "2023-06-27T15:48:40Z",
        "link": "http://arxiv.org/abs/2306.15572v1",
        "categories": [
            "cs.SC",
            "cs.LG",
            "68W30, 68T05",
            "I.2.6; I.1.1"
        ]
    },
    {
        "title": "Exploiting Strict Constraints in the Cylindrical Algebraic Covering",
        "authors": [
            "Philipp Bär",
            "Jasper Nalbach",
            "Erika Ábrahám",
            "Christopher W. Brown"
        ],
        "summary": "One of the few available complete methods for checking the satisfiability of sets of polynomial constraints over the reals is the cylindrical algebraic covering (CAlC) method. In this paper, we propose an extension for this method to exploit the strictness of input constraints for reducing the computational effort. We illustrate the concepts on a multidimensional example and provide experimental results to evaluate the usefulness of our proposed extension.",
        "published": "2023-06-29T07:54:58Z",
        "link": "http://arxiv.org/abs/2306.16757v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "An ML approach to resolution of singularities",
        "authors": [
            "Gergely Bérczi",
            "Honglu Fan",
            "Mingcong Zeng"
        ],
        "summary": "The solution set of a system of polynomial equations typically contains ill-behaved, singular points. Resolution is a fundamental process in geometry in which we replace singular points with smooth points, while keeping the rest of the solution set unchanged. Resolutions are not unique: the usual way to describe them involves repeatedly performing a fundamental operation known as \"blowing-up\", and the complexity of the resolution highly depends on certain choices. The process can be translated into various versions of a 2-player game, the so-called Hironaka game, and a winning strategy for the first player provides a solution to the resolution problem. In this paper we introduce a new approach to the Hironaka game that uses reinforcement learning agents to find optimal resolutions of singularities. In certain domains, the trained model outperforms state-of-the-art selection heuristics in total number of polynomial additions performed, which provides a proof-of-concept that recent developments in machine learning have the potential to improve performance of algorithms in symbolic computation.",
        "published": "2023-07-01T07:17:33Z",
        "link": "http://arxiv.org/abs/2307.00252v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.SC",
            "math.AG"
        ]
    },
    {
        "title": "Fuchs' theorem on linear differential equations in arbitrary   characteristic",
        "authors": [
            "Florian Fürnsinn",
            "Herwig Hauser"
        ],
        "summary": "The paper generalizes Lazarus Fuchs' theorem on the solutions of complex ordinary linear differential equations with regular singularities to the case of ground fields of arbitrary characteristic, giving a precise description of the shape of each solution. This completes partial investigations started by Taira Honda and Bernard Dwork.   The main features are the introduction of a differential ring $\\mathcal{R}$ in infinitely many variables mimicking the role of the (complex) iterated logarithms, and the proof that adding these \"logarithms\" already provides sufficiently many primitives so as to solve any differential equation with regular singularity in $\\mathcal{R}$. A key step in the proof is the reduction of the involved differential operator to an Euler operator, its normal form, to solve Euler equations in $\\mathcal{R}$ and to lift their (monomial) solutions to solutions of the original equation.   The first (and already very striking) example of this outset is the exponential function $\\exp_p$ in positive characteristic, solution of $y' = y$. We prove that it necessarily involves all variables and we construct its explicit (and quite mysterious) power series expansion. Additionally, relations of our results to the Grothendieck-Katz $p$-curvature conjecture and related conjectures will be discussed.",
        "published": "2023-07-04T13:31:20Z",
        "link": "http://arxiv.org/abs/2307.01712v2",
        "categories": [
            "math.CA",
            "cs.SC",
            "math.AC",
            "math.NT",
            "12H20 (Primary), 14G17, 34A05, 34M03, 47E05 (Secondary)"
        ]
    },
    {
        "title": "Discovering Asymptotic Expansions Using Symbolic Regression",
        "authors": [
            "Rasul Abdusalamov",
            "Julius Kaplunov",
            "Mikhail Itskov"
        ],
        "summary": "Recently, symbolic regression (SR) has demonstrated its efficiency for discovering basic governing relations in physical systems. A major impact can be potentially achieved by coupling symbolic regression with asymptotic methodology. The main advantage of asymptotic approach involves the robust approximation to the sought for solution bringing a clear idea of the effect of problem parameters. However, the analytic derivation of the asymptotic series is often highly nontrivial especially, when the exact solution is not available. In this paper, we adapt SR methodology to discover asymptotic series. As an illustration we consider three problem in mechanics, including two-mass collision, viscoelastic behavior of a Kelvin-Voigt solid and propagation of Rayleigh-Lamb waves. The training data is generated from the explicit exact solutions of these problems. The obtained SR results are compared to the benchmark asymptotic expansions of the above mentioned exact solutions. Both convergent and divergent asymptotic series are considered. A good agreement between SR expansions and analytical results is observed. It is demonstrated that the proposed approach can be used to identify material parameters, e.g. Poisson's ratio, and has high prospects for utilizing experimental and numerical data.",
        "published": "2023-07-04T18:37:20Z",
        "link": "http://arxiv.org/abs/2307.01876v1",
        "categories": [
            "cs.SC",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Concept2Box: Joint Geometric Embeddings for Learning Two-View Knowledge   Graphs",
        "authors": [
            "Zijie Huang",
            "Daheng Wang",
            "Binxuan Huang",
            "Chenwei Zhang",
            "Jingbo Shang",
            "Yan Liang",
            "Zhengyang Wang",
            "Xian Li",
            "Christos Faloutsos",
            "Yizhou Sun",
            "Wei Wang"
        ],
        "summary": "Knowledge graph embeddings (KGE) have been extensively studied to embed large-scale relational data for many real-world applications. Existing methods have long ignored the fact many KGs contain two fundamentally different views: high-level ontology-view concepts and fine-grained instance-view entities. They usually embed all nodes as vectors in one latent space. However, a single geometric representation fails to capture the structural differences between two views and lacks probabilistic semantics towards concepts' granularity. We propose Concept2Box, a novel approach that jointly embeds the two views of a KG using dual geometric representations. We model concepts with box embeddings, which learn the hierarchy structure and complex relations such as overlap and disjoint among them. Box volumes can be interpreted as concepts' granularity. Different from concepts, we model entities as vectors. To bridge the gap between concept box embeddings and entity vector embeddings, we propose a novel vector-to-box distance metric and learn both embeddings jointly. Experiments on both the public DBpedia KG and a newly-created industrial KG showed the effectiveness of Concept2Box.",
        "published": "2023-07-04T21:37:39Z",
        "link": "http://arxiv.org/abs/2307.01933v1",
        "categories": [
            "cs.AI",
            "cs.CG",
            "cs.CL",
            "cs.SC"
        ]
    },
    {
        "title": "Runtime Repeated Recursion Unfolding in CHR: A Just-In-Time Online   Program Optimization Strategy That Can Achieve Super-Linear Speedup",
        "authors": [
            "Thom Fruehwirth"
        ],
        "summary": "We introduce a just-in-time runtime program transformation strategy based on repeated recursion unfolding. Our online program optimization generates several versions of a recursion differentiated by the minimal number of recursive steps covered. The base case of the recursion is ignored in our technique.   Our method is introduced here on the basis of single linear direct recursive rules. When a recursive call is encountered at runtime, first an unfolder creates specializations of the associated recursive rule on-the-fly and then an interpreter applies these rules to the call. Our approach reduces the number of recursive rule applications to its logarithm at the expense of introducing a logarithmic number of generic unfolded rules.   We prove correctness of our online optimization technique and determine its time complexity. For recursions which have enough simplifyable unfoldings, a super-linear is possible, i.e. speedup by more than a constant factor.The necessary simplification is problem-specific and has to be provided at compile-time. In our speedup analysis, we prove a sufficient condition as well as a sufficient and necessary condition for super-linear speedup relating the complexity of the recursive steps of the original rule and the unfolded rules.   We have implemented an unfolder and meta-interpreter for runtime repeated recursion unfolding with just five rules in Constraint Handling Rules (CHR) embedded in Prolog. We illustrate the feasibility of our approach with simplifications, time complexity results and benchmarks for some basic tractable algorithms. The simplifications require some insight and were derived manually. The runtime improvement quickly reaches several orders of magnitude, consistent with the super-linear speedup predicted by our theorems.",
        "published": "2023-07-05T10:18:51Z",
        "link": "http://arxiv.org/abs/2307.02180v4",
        "categories": [
            "cs.PL",
            "cs.CC",
            "cs.PF",
            "cs.SC"
        ]
    },
    {
        "title": "RecallM: An Adaptable Memory Mechanism with Temporal Understanding for   Large Language Models",
        "authors": [
            "Brandon Kynoch",
            "Hugo Latapie",
            "Dwane van der Sluis"
        ],
        "summary": "Large Language Models (LLMs) have made extraordinary progress in the field of Artificial Intelligence and have demonstrated remarkable capabilities across a large variety of tasks and domains. However, as we venture closer to creating Artificial General Intelligence (AGI) systems, we recognize the need to supplement LLMs with long-term memory to overcome the context window limitation and more importantly, to create a foundation for sustained reasoning, cumulative learning and long-term user interaction. In this paper we propose RecallM, a novel architecture for providing LLMs with an adaptable and updatable long-term memory mechanism. Unlike previous methods, the RecallM architecture is particularly effective at belief updating and maintaining a temporal understanding of the knowledge provided to it. We demonstrate through various experiments the effectiveness of this architecture. Furthermore, through our own temporal understanding and belief updating experiments, we show that RecallM is four times more effective than using a vector database for updating knowledge previously stored in long-term memory. We also demonstrate that RecallM shows competitive performance on general question-answering and in-context learning tasks.",
        "published": "2023-07-06T02:51:54Z",
        "link": "http://arxiv.org/abs/2307.02738v3",
        "categories": [
            "cs.AI",
            "cs.CL",
            "cs.SC"
        ]
    },
    {
        "title": "Algorithms for computing norms and characteristic polynomials on general   Drinfeld modules",
        "authors": [
            "Xavier Caruso",
            "Antoine Leudière"
        ],
        "summary": "We provide two families of algorithms to compute characteristic polynomials of endomorphisms and norms of isogenies of Drinfeld modules. Our algorithms work for Drinfeld modules of any rank, defined over any base curve. When the base curve is $\\mathbb P^1_{\\mathbb F_q}$, we do a thorough study of the complexity, demonstrating that our algorithms are, in many cases, the most asymptotically performant. The first family of algorithms relies on the correspondence between Drinfeld modules and Anderson motives, reducing the computation to linear algebra over a polynomial ring. The second family, available only for the Frobenius endomorphism, is based on a formula expressing the characteristic polynomial of the Frobenius as a reduced norm in a central simple algebra.",
        "published": "2023-07-06T09:33:36Z",
        "link": "http://arxiv.org/abs/2307.02879v4",
        "categories": [
            "cs.SC",
            "math.NT"
        ]
    },
    {
        "title": "Reasoning over the Behaviour of Objects in Video-Clips for Adverb-Type   Recognition",
        "authors": [
            "Amrit Diggavi Seshadri",
            "Alessandra Russo"
        ],
        "summary": "In this work, following the intuition that adverbs describing scene-sequences are best identified by reasoning over high-level concepts of object-behavior, we propose the design of a new framework that reasons over object-behaviours extracted from raw-video-clips to recognize the clip's corresponding adverb-types. Importantly, while previous works for general scene adverb-recognition assume knowledge of the clips underlying action-types, our method is directly applicable in the more general problem setting where the action-type of a video-clip is unknown. Specifically, we propose a novel pipeline that extracts human-interpretable object-behaviour-facts from raw video clips and propose novel symbolic and transformer based reasoning methods that operate over these extracted facts to identify adverb-types. Experiment results demonstrate that our proposed methods perform favourably against the previous state-of-the-art. Additionally, to support efforts in symbolic video-processing, we release two new datasets of object-behaviour-facts extracted from raw video clips - the MSR-VTT-ASP and ActivityNet-ASP datasets.",
        "published": "2023-07-09T09:04:26Z",
        "link": "http://arxiv.org/abs/2307.04132v3",
        "categories": [
            "cs.CV",
            "cs.AI",
            "cs.SC"
        ]
    },
    {
        "title": "Rational Solutions of Parametric First-Order Algebraic Differential   Equations",
        "authors": [
            "Sebastian Falkensteiner",
            "Rafael Sendra"
        ],
        "summary": "In this paper we give a procedure for finding rational solutions of a given first-order ODE with functional and constant coefficients which occur in a rational way. We derive an associated system with the same solvability, and sufficient and necessary conditions for the existence of rational solutions are given. In the case where all parametric coefficients are constant, we give an algorithm to compute the rational solutions. In the case where one functional coefficient appears, we algorithmically find rational general solutions which rationally depend on the appearing transcendental constant. In the other cases, the presented procedure is not completely algorithmic.",
        "published": "2023-07-11T08:24:25Z",
        "link": "http://arxiv.org/abs/2307.05102v1",
        "categories": [
            "cs.SC",
            "34A05, 14H50, 34A34, 30C15, 35B30"
        ]
    },
    {
        "title": "An Efficient Canonical Narrowing Implementation with Irreducibility and   SMT Constraints for Generic Symbolic Protocol Analysis",
        "authors": [
            "Raúl López-Rueda",
            "Santiago Escobar",
            "Julia Sapiña"
        ],
        "summary": "Narrowing and unification are very useful tools for symbolic analysis of rewrite theories, and thus for any model that can be specified in that way. A very clear example of their application is the field of formal cryptographic protocol analysis, which is why narrowing and unification are used in tools such as Maude-NPA, Tamarin and Akiss. In this work we present the implementation of a canonical narrowing algorithm, which improves the standard narrowing algorithm, extended to be able to process rewrite theories with conditional rules. The conditions of the rules will contain SMT constraints, which will be carried throughout the execution of the algorithm to determine if the solutions have associated satisfiable or unsatisfiable constraints, and in the latter case, discard them.",
        "published": "2023-07-12T17:52:00Z",
        "link": "http://arxiv.org/abs/2307.06348v1",
        "categories": [
            "cs.SC",
            "cs.LO"
        ]
    },
    {
        "title": "A Program That Simplifies Regular Expressions (Tool paper)",
        "authors": [
            "Baudouin Le Charlier"
        ],
        "summary": "This paper presents the main features of a system that aims to transform regular expressions into shorter equivalent expressions. The system is also capable of computing other operations useful for simplification, such as checking the inclusion of regular languages. The main novelty of this work is that it combines known but distinct ways of representing regular languages into a global unified data structure that makes the operations more efficient. In addition, representations of regular languages are dynamically reduced as operations are performed on them. Expressions are normalized and represented by a unique identifier (an integer). Expressions found to be equivalent (i.e. denoting the same regular language) are grouped into equivalence classes from which a shortest representative is chosen. The article briefly describes the main algorithms working on the global data structure. Some of them are direct adaptations of well-known algorithms, but most of them incorporate new ideas, which are really necessary to make the system efficient. Finally, to show its usefulness, the system is applied to some examples from the literature. Statistics on randomly generated sets of expressions are also provided.",
        "published": "2023-07-12T20:03:22Z",
        "link": "http://arxiv.org/abs/2307.06436v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Faster Rectangular Matrix Multiplication by Combination Loss Analysis",
        "authors": [
            "François Le Gall"
        ],
        "summary": "Duan, Wu and Zhou (FOCS 2023) recently obtained the improved upper bound on the exponent of square matrix multiplication $\\omega<2.3719$ by introducing a new approach to quantify and compensate the ``combination loss\" in prior analyses of powers of the Coppersmith-Winograd tensor. In this paper we show how to use this new approach to improve the exponent of rectangular matrix multiplication as well. Our main technical contribution is showing how to combine this analysis of the combination loss and the analysis of the fourth power of the Coppersmith-Winograd tensor in the context of rectangular matrix multiplication developed by Le Gall and Urrutia (SODA 2018).",
        "published": "2023-07-13T02:47:27Z",
        "link": "http://arxiv.org/abs/2307.06535v2",
        "categories": [
            "cs.DS",
            "cs.CC",
            "cs.SC"
        ]
    },
    {
        "title": "Data Augmentation for Mathematical Objects",
        "authors": [
            "Tereso del Rio",
            "Matthew England"
        ],
        "summary": "This paper discusses and evaluates ideas of data balancing and data augmentation in the context of mathematical objects: an important topic for both the symbolic computation and satisfiability checking communities, when they are making use of machine learning techniques to optimise their tools. We consider a dataset of non-linear polynomial problems and the problem of selecting a variable ordering for cylindrical algebraic decomposition to tackle these with. By swapping the variable names in already labelled problems, we generate new problem instances that do not require any further labelling when viewing the selection as a classification problem. We find this augmentation increases the accuracy of ML models by 63% on average. We study what part of this improvement is due to the balancing of the dataset and what is achieved thanks to further increasing the size of the dataset, concluding that both have a very significant effect. We finish the paper by reflecting on how this idea could be applied in other uses of machine learning in mathematics.",
        "published": "2023-07-13T16:02:45Z",
        "link": "http://arxiv.org/abs/2307.06984v1",
        "categories": [
            "cs.SC",
            "cs.LG",
            "68W30, 68T05, 03C10",
            "I.2.6; I.1.1"
        ]
    },
    {
        "title": "Reduction-Based Creative Telescoping for Definite Summation of D-finite   Functions",
        "authors": [
            "Hadrien Brochet",
            "Bruno Salvy"
        ],
        "summary": "Creative telescoping is an algorithmic method initiated by Zeilberger to compute definite sums by synthesizing summands that telescope, called certificates. We describe a creative telescoping algorithm that computes telescopers for definite sums of D-finite functions as well as the associated certificates in a compact form. The algorithm relies on a discrete analogue of the generalized Hermite reduction, or equivalently, a generalization of the Abramov-Petkov\\v{s}ek reduction. We provide a Maple implementation with good timings on a variety of examples.",
        "published": "2023-07-14T08:20:15Z",
        "link": "http://arxiv.org/abs/2307.07216v2",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Coupling Large Language Models with Logic Programming for Robust and   General Reasoning from Text",
        "authors": [
            "Zhun Yang",
            "Adam Ishay",
            "Joohyung Lee"
        ],
        "summary": "While large language models (LLMs), such as GPT-3, appear to be robust and general, their reasoning ability is not at a level to compete with the best models trained for specific natural language reasoning problems. In this study, we observe that a large language model can serve as a highly effective few-shot semantic parser. It can convert natural language sentences into a logical form that serves as input for answer set programs, a logic-based declarative knowledge representation formalism. The combination results in a robust and general system that can handle multiple question-answering tasks without requiring retraining for each new task. It only needs a few examples to guide the LLM's adaptation to a specific task, along with reusable ASP knowledge modules that can be applied to multiple tasks. We demonstrate that this method achieves state-of-the-art performance on several NLP benchmarks, including bAbI, StepGame, CLUTRR, and gSCAN. Additionally, it successfully tackles robot planning tasks that an LLM alone fails to solve.",
        "published": "2023-07-15T03:29:59Z",
        "link": "http://arxiv.org/abs/2307.07696v1",
        "categories": [
            "cs.CL",
            "cs.AI",
            "cs.SC"
        ]
    },
    {
        "title": "Leveraging Large Language Models to Generate Answer Set Programs",
        "authors": [
            "Adam Ishay",
            "Zhun Yang",
            "Joohyung Lee"
        ],
        "summary": "Large language models (LLMs), such as GPT-3 and GPT-4, have demonstrated exceptional performance in various natural language processing tasks and have shown the ability to solve certain reasoning problems. However, their reasoning capabilities are limited and relatively shallow, despite the application of various prompting techniques. In contrast, formal logic is adept at handling complex reasoning, but translating natural language descriptions into formal logic is a challenging task that non-experts struggle with. This paper proposes a neuro-symbolic method that combines the strengths of large language models and answer set programming. Specifically, we employ an LLM to transform natural language descriptions of logic puzzles into answer set programs. We carefully design prompts for an LLM to convert natural language descriptions into answer set programs in a step by step manner. Surprisingly, with just a few in-context learning examples, LLMs can generate reasonably complex answer set programs. The majority of errors made are relatively simple and can be easily corrected by humans, thus enabling LLMs to effectively assist in the creation of answer set programs.",
        "published": "2023-07-15T03:40:55Z",
        "link": "http://arxiv.org/abs/2307.07699v1",
        "categories": [
            "cs.AI",
            "cs.CL",
            "cs.SC"
        ]
    },
    {
        "title": "NeurASP: Embracing Neural Networks into Answer Set Programming",
        "authors": [
            "Zhun Yang",
            "Adam Ishay",
            "Joohyung Lee"
        ],
        "summary": "We present NeurASP, a simple extension of answer set programs by embracing neural networks. By treating the neural network output as the probability distribution over atomic facts in answer set programs, NeurASP provides a simple and effective way to integrate sub-symbolic and symbolic computation. We demonstrate how NeurASP can make use of a pre-trained neural network in symbolic computation and how it can improve the neural network's perception result by applying symbolic reasoning in answer set programming. Also, NeurASP can be used to train a neural network better by training with ASP rules so that a neural network not only learns from implicit correlations from the data but also from the explicit complex semantic constraints expressed by the rules.",
        "published": "2023-07-15T04:03:17Z",
        "link": "http://arxiv.org/abs/2307.07700v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.SC"
        ]
    },
    {
        "title": "First-Order Stable Model Semantics with Intensional Functions",
        "authors": [
            "Michael Bartholomew",
            "Joohyung Lee"
        ],
        "summary": "In classical logic, nonBoolean fluents, such as the location of an object, can be naturally described by functions. However, this is not the case in answer set programs, where the values of functions are pre-defined, and nonmonotonicity of the semantics is related to minimizing the extents of predicates but has nothing to do with functions. We extend the first-order stable model semantics by Ferraris, Lee, and Lifschitz to allow intensional functions -- functions that are specified by a logic program just like predicates are specified. We show that many known properties of the stable model semantics are naturally extended to this formalism and compare it with other related approaches to incorporating intensional functions. Furthermore, we use this extension as a basis for defining Answer Set Programming Modulo Theories (ASPMT), analogous to the way that Satisfiability Modulo Theories (SMT) is defined, allowing for SMT-like effective first-order reasoning in the context of ASP. Using SMT solving techniques involving functions, ASPMT can be applied to domains containing real numbers and alleviates the grounding problem. We show that other approaches to integrating ASP and CSP/SMT can be related to special cases of ASPMT in which functions are limited to non-intensional ones.",
        "published": "2023-07-15T06:03:35Z",
        "link": "http://arxiv.org/abs/2307.10225v1",
        "categories": [
            "cs.AI",
            "cs.SC"
        ]
    },
    {
        "title": "Deciding One to One property of Boolean maps: Condition and algorithm in   terms of implicants",
        "authors": [
            "Virendra Sule"
        ],
        "summary": "This paper addresses the computational problem of deciding invertibility (or one to one-ness) of a Boolean map $F$ in $n$-Boolean variables. This problem has a special case of deciding invertibilty of a map $F:\\mathbb{F}_{2}^n\\rightarrow\\mathbb{F}_{2}^n$ over the binary field $\\mathbb{F}_2$. Further the problem can be extended and stated over a finite field $\\mathbb{F}$ instead of $\\mathbb{F}_2$. Algebraic condition for invertibility of $F$ in this special case over a finite field is well known to be equivalent to invertibility of the Koopman operator of $F$ as shown in \\cite{RamSule}. In this paper a condition for invertibility is derived in the special case of Boolean maps $F:B_0^n\\rightarrow B_0^n$ where $B_0$ is the two element Boolean algebra in terms of \\emph{implicants} of Boolean equations. This condition is then extended to the case of general maps in $n$ variables. Hence this condition answers the special case of invertibility of the map $F$ defined over the binary field $\\mathbb{F}_2$ alternatively, in terms of implicants instead of the Koopman operator. The problem of deciding invertibility of a map $F$ (or that of finding its $GOE$) over finite fields appears to be distinct from the satisfiability problem (SAT) or the problem of deciding consistency of polynomial equations over finite fields. Hence the well known algorithms for deciding SAT or of solvability using Grobner basis for checking membership in an ideal generated by polynomials is not known to answer the question of invertibility of a map. Similarly it appears that algorithms for satisfiability or polynomial solvability are not useful for computation of $GOE(F)$ even for maps over the binary field $\\mathbb{F}_2$.",
        "published": "2023-07-15T12:25:11Z",
        "link": "http://arxiv.org/abs/2307.07788v3",
        "categories": [
            "cs.SC",
            "cs.CC",
            "F.2.1; I.1.1; I.1.2"
        ]
    },
    {
        "title": "In-place accumulation of fast multiplication formulae",
        "authors": [
            "Jean-Guillaume Dumas",
            "Bruno Grenet"
        ],
        "summary": "This paper deals with simultaneously fast and in-place algorithms for formulae where the result has to be linearly accumulated: some of the output variables are also input variables, linked by a linear dependency. Fundamental examples include the in-place accumulated multiplication of polynomials or matrices, C+=AB. The difficulty is to combine in-place computations with fast algorithms: those usually come at the expense of (potentially large) extra temporary space, but with accumulation the output variables are not even available to store intermediate values. We first propose a novel automatic design of fast and in-place accumulating algorithms for any bilinear formulae (and thus for polynomial and matrix multiplication) and then extend it to any linear accumulation of a collection of functions. For this, we relax the in-place model to any algorithm allowed to modify its inputs, provided that those are restored to their initial state afterwards. This allows us, in fine, to derive unprecedented in-place accumulating algorithms for fast polynomial multiplications and for Strassen-like matrix multiplications.",
        "published": "2023-07-24T11:47:29Z",
        "link": "http://arxiv.org/abs/2307.12712v3",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "The free Abelian group in R: the frab package",
        "authors": [
            "Robin K. S. Hankin"
        ],
        "summary": "In this short article I introduce the frab package which provides an alternative interpretation of named vectors in the R programming language; it is available on CRAN. The underlying mathematical object is the free Abelian group.",
        "published": "2023-07-25T00:31:40Z",
        "link": "http://arxiv.org/abs/2307.13184v1",
        "categories": [
            "cs.SC",
            "08.04",
            "G.4"
        ]
    },
    {
        "title": "Iterated Resultants in CAD",
        "authors": [
            "James H. Davenport",
            "Matthew England"
        ],
        "summary": "Cylindrical Algebraic Decomposition (CAD) by projection and lifting requires many iterated univariate resultants. It has been observed that these often factor, but to date this has not been used to optimise implementations of CAD. We continue the investigation into such factorisations, writing in the specific context of SC-Square.",
        "published": "2023-07-31T15:16:48Z",
        "link": "http://arxiv.org/abs/2307.16750v1",
        "categories": [
            "cs.SC",
            "68W30, 13P10",
            "I.1.1"
        ]
    },
    {
        "title": "SMT-Solving Induction Proofs of Inequalities",
        "authors": [
            "Ali K. Uncu",
            "James H. Davenport",
            "Matthew England"
        ],
        "summary": "This paper accompanies a new dataset of non-linear real arithmetic problems for the SMT-LIB benchmark collection. The problems come from an automated proof procedure of Gerhold--Kauers, which is well suited for solution by SMT. The problems of this type have not been tackled by SMT-solvers before. We describe the proof technique and give one new such proof to illustrate it. We then describe the dataset and the results of benchmarking. The benchmarks on the new dataset are quite different to the existing ones. The benchmarking also brings forward some interesting debate on the use/inclusion of rational functions and algebraic numbers in the SMT-LIB.",
        "published": "2023-07-31T15:32:16Z",
        "link": "http://arxiv.org/abs/2307.16761v1",
        "categories": [
            "cs.SC",
            "cs.LO",
            "68W30",
            "I.1.4; G.4"
        ]
    },
    {
        "title": "Algoritmos para Multiplicação Matricial",
        "authors": [
            "M. S. O. Poloi",
            "T. O. Quinelato"
        ],
        "summary": "The goal of this article is to study algorithms that compute the product between two matrixes, specifically using the ingenuous methods of Strassen and Strassen-Winograd, which will be presented in Section 2. At present, the cited methods are not the most optimal considering the arithmetic complexity of these algorithms (see Table 1). However, changes to the Strassen and Strassen-Winograd methods will be exposed which will result in a reduction in their memory allocation and/or execution time. The algorithms in this study were implemented using the Julia programming language, version 1.9.1, with the aid of the packages Pluto (notebooks), Plots (graphic visualization of the results) and BenchmarkTools (measurement of memory allocation and execution time of the algorithms).   --   O objetivo deste artigo \\'e estudar algoritmos que computam o produto entre duas matrizes, mais especificamente utilizando os m\\'etodos ing\\^enuo, de Strassen e de Strassen-Winograd, que ser\\~ao apresentados na Se\\c{c}\\~ao 2. Atualmente, os m\\'etodos citados n\\~ao s\\~ao os mais otimizados considerando a complexidade aritm\\'etica de seus algoritmos (vide Tabela 1). No entanto, ser\\~ao expostas modifica\\c{c}\\~oes dos m\\'etodos de Strassen e Strassen-Winograd que conseguem reduzir sua aloca\\c{c}\\~ao de mem\\'oria e/ou tempo de execu\\c{c}\\~ao. Os algoritmos do problema em estudo foram implementados utilizando a linguagem de programa\\c{c}\\~ao Julia, na vers\\~ao 1.9.1, com o aux\\'ilio dos pacotes Pluto (notebooks), Plots (visualiza\\c{c}\\~ao gr\\'afica dos resultados) e BenchmarkTools (medi\\c{c}\\~ao de aloca\\c{c}\\~ao de mem\\'oria e tempo de execu\\c{c}\\~ao dos algoritmos).",
        "published": "2023-08-03T23:20:20Z",
        "link": "http://arxiv.org/abs/2309.00628v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Algorithmic computation of multivector inverses and characteristic   polynomials in non-degenerate Clifford algebras",
        "authors": [
            "Dimiter Prodanov"
        ],
        "summary": "The power of Clifford or, geometric, algebra lies in its ability to represent geometric operations in a concise and elegant manner. Clifford algebras provide the natural generalizations of complex, dual numbers and quaternions into non-commutative multivectors. The paper demonstrates an algorithm for the computation of inverses of such numbers in a non-degenerate Clifford algebra of an arbitrary dimension. The algorithm is a variation of the Faddeev-LeVerrier-Souriau algorithm and is implemented in the open-source Computer Algebra System Maxima. Symbolic and numerical examples in different Clifford algebras are presented.",
        "published": "2023-08-04T12:51:55Z",
        "link": "http://arxiv.org/abs/2308.02291v1",
        "categories": [
            "math.NA",
            "cs.NA",
            "cs.SC",
            "15A66"
        ]
    },
    {
        "title": "New Bounds on Quotient Polynomials with Applications to Exact   Divisibility and Divisibility Testing of Sparse Polynomials",
        "authors": [
            "Ido Nahshon",
            "Amir Shpilka"
        ],
        "summary": "We prove that for monic polynomials $f, g \\in \\mathbb{C}[x]$ such that $g$ divides $f$, the $\\ell_2$-norm of the quotient polynomial $f/g$ is bounded by $\\lVert f \\rVert_1 \\cdot \\tilde{O}(\\lVert{g}\\rVert_0^3\\text{deg}^2{ f})^{\\lVert{g}\\rVert_0 - 1}$. This improves upon the previously known exponential (in $\\text{deg}{ f}$) bounds for general polynomials. Our results implies that the trivial long division algorithm runs in quasi-linear time relative to the input size and number of terms of the quotient polynomial $f/g$, thus solving a long-standing problem on exact divisibility of sparse polynomials.   We also study the problem of bounding the number of terms of $f/g$ in some special cases. When $f, g \\in \\mathbb{Z}[x]$ and $g$ is a cyclotomic-free (i.e., it has no cyclotomic factors) trinomial, we prove that $\\lVert{f/g}\\rVert_0 \\leq O(\\lVert{f}\\rVert_0 \\text{size}({f})^2 \\cdot \\log^6{\\text{deg}{ g}})$. When $g$ is a cyclotomic-free binomial, we prove that the sparsity is at most $O(\\lVert{f}\\rVert_0 ( \\log{\\lVert{f}\\rVert_0} + \\log{\\lVert{f}\\rVert_{\\infty}}))$. Both upper bounds are polynomial in the input-size. We leverage these results and give a polynomial time algorithm for deciding whether a cyclotomic-free trinomial divides a sparse polynomial over the integers.   As our last result, we present a polynomial time algorithm for testing divisibility by pentanomials over small finite fields when $\\text{deg}{ f} = \\tilde{O}(\\text{deg}{ g})$.",
        "published": "2023-08-07T19:33:53Z",
        "link": "http://arxiv.org/abs/2308.03885v3",
        "categories": [
            "cs.SC",
            "cs.CC",
            "math.NT"
        ]
    },
    {
        "title": "Model of models -- Part 1",
        "authors": [
            "Shimon Komarovsky"
        ],
        "summary": "This paper proposes a new cognitive model, acting as the main component of an AGI agent. The model is introduced in its mature intelligence state, and as an extension of previous models, DENN, and especially AKREM, by including operational models (frames/classes) and will. This model's core assumption is that cognition is about operating on accumulated knowledge, with the guidance of an appropriate will. Also, we assume that the actions, part of knowledge, are learning to be aligned with will, during the evolution phase that precedes the mature intelligence state. In addition, this model is mainly based on the duality principle in every known intelligent aspect, such as exhibiting both top-down and bottom-up model learning, generalization verse specialization, and more. Furthermore, a holistic approach is advocated for AGI designing, and cognition under constraints or efficiency is proposed, in the form of reusability and simplicity. Finally, reaching this mature state is described via a cognitive evolution from infancy to adulthood, utilizing a consolidation principle. The final product of this cognitive model is a dynamic operational memory of models and instances. Lastly, some examples and preliminary ideas for the evolution phase to reach the mature state are presented.",
        "published": "2023-08-08T21:56:52Z",
        "link": "http://arxiv.org/abs/2308.04600v2",
        "categories": [
            "cs.AI",
            "cs.LO",
            "cs.SC"
        ]
    },
    {
        "title": "Computing Mellin representations and asymptotics of nested binomial sums   in a symbolic way: the RICA package",
        "authors": [
            "Johannes Bluemlein",
            "Nikolai Fadeev",
            "Carsten Schneider"
        ],
        "summary": "Nested binomial sums form a particular class of sums that arise in the context of particle physics computations at higher orders in perturbation theory within QCD and QED, but that are also mathematically relevant, e.g., in combinatorics. We present the package RICA (Rule Induced Convolutions for Asymptotics), which aims at calculating Mellin representations and asymptotic expansions at infinity of those objects. These representations are of particular interest to perform analytic continuations of such sums.",
        "published": "2023-08-11T09:43:05Z",
        "link": "http://arxiv.org/abs/2308.06042v1",
        "categories": [
            "hep-ph",
            "cs.SC"
        ]
    },
    {
        "title": "Computational General Relativity in the Wolfram Language using Gravitas   I: Symbolic and Analytic Computation",
        "authors": [
            "Jonathan Gorard"
        ],
        "summary": "We introduce a new, open-source computational general relativity framework for the Wolfram Language called Gravitas, which boasts a number of novel and distinctive features as compared to the many pre-existing computational and numerical relativity frameworks currently available within the open-source community. These include, but are not limited to: seamless integration of its powerful symbolic and numerical subsystems, and, by extension, seamless transition between analytic/continuous representations and numerical/discrete representations of arbitrary spacetime geometries; highly modular, general and extensible representations of spacetime geometries, spacetime topologies, gauge conditions, coordinate systems, matter fields, evolution equations and initial data; ability to set up and run complex numerical relativity simulations, and to perform 2D and 3D visualizations, symbolic computations and numerical analysis (including the extraction of gravitational wave signals) on the resulting data, all from within a single notebook environment; and a totally-unstructured adaptive refinement scheme based on hypergraph rewriting, allowing for exceedingly efficient discretization and numerical evolution of Cauchy initial data for a wide range of challenging computational problems involving strong relativistic field dynamics. In this first in a series of two articles covering the framework, we focus on the design and capabilities of Gravitas's symbolic subsystem, including its general and flexible handling of arbitrary geometries parametrized by arbitrary curvilinear coordinate systems (along with an in-built library of standard metrics and coordinate conditions), as well as its various high-level tensor calculus and differential geometry features. We proceed to show how this subsystem can be used to solve the Einstein field equations both analytically and numerically.",
        "published": "2023-08-15T00:24:06Z",
        "link": "http://arxiv.org/abs/2308.07508v1",
        "categories": [
            "gr-qc",
            "cs.SC"
        ]
    },
    {
        "title": "Evolving Scientific Discovery by Unifying Data and Background Knowledge   with AI Hilbert",
        "authors": [
            "Ryan Cory-Wright",
            "Cristina Cornelio",
            "Sanjeeb Dash",
            "Bachir El Khadir",
            "Lior Horesh"
        ],
        "summary": "The discovery of scientific formulae that parsimoniously explain natural phenomena and align with existing background theory is a key goal in science. Historically, scientists have derived natural laws by manipulating equations based on existing knowledge, forming new equations, and verifying them experimentally. In recent years, data-driven scientific discovery has emerged as a viable competitor in settings with large amounts of experimental data. Unfortunately, data-driven methods often fail to discover valid laws when data is noisy or scarce. Accordingly, recent works combine regression and reasoning to eliminate formulae inconsistent with background theory. However, the problem of searching over the space of formulae consistent with background theory to find one that best fits the data is not well-solved. We propose a solution to this problem when all axioms and scientific laws are expressible via polynomial equalities and inequalities and argue that our approach is widely applicable. We model notions of minimal complexity using binary variables and logical constraints, solve polynomial optimization problems via mixed-integer linear or semidefinite optimization, and prove the validity of our scientific discoveries in a principled manner using Positivstellensatz certificates. The optimization techniques leveraged in this paper allow our approach to run in polynomial time with fully correct background theory under an assumption that the complexity of our derivation is bounded), or non-deterministic polynomial (NP) time with partially correct background theory. We demonstrate that some famous scientific laws, including Kepler's Third Law of Planetary Motion, the Hagen-Poiseuille Equation, and the Radiated Gravitational Wave Power equation, can be derived in a principled manner from axioms and experimental data.",
        "published": "2023-08-18T11:19:41Z",
        "link": "http://arxiv.org/abs/2308.09474v3",
        "categories": [
            "cs.AI",
            "cs.SC",
            "math.OC"
        ]
    },
    {
        "title": "Field theory with the Maxima computer algebra system",
        "authors": [
            "Viktor T. Toth"
        ],
        "summary": "The Maxima computer algebra system, the open-source successor to MACSYMA, the first general-purpose computer algebra system that was initially developed at the Massachusetts Institute of Technology in the late 1960s and later distributed by the United States Department of Energy, has some remarkable capabilities, some of which are implemented in the form of add-on, \"share\" packages that are distributed along with the core Maxima system. One such share package is itensor, for indicial tensor manipulation. One of the more remarkable features of itensor is functional differentiation. Through this, it is possible to use itensor to develop a Lagrangian field theory and derive the corresponding field equations. In the present note, we demonstrate this capability by deriving Maxwell's equations from the Maxwell Lagrangian, and exploring the properties of the system, including current conservation.",
        "published": "2023-08-18T22:12:18Z",
        "link": "http://arxiv.org/abs/2308.09837v1",
        "categories": [
            "cs.SC",
            "gr-qc",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Normative Conditional Reasoning as a Fragment of HOL",
        "authors": [
            "Xavier Parent",
            "Christoph Benzmüller"
        ],
        "summary": "We report on the mechanization of (preference-based) conditional normative reasoning. Our focus is on Aqvist's system E for conditional obligation, and its extensions. Our mechanization is achieved via a shallow semantical embedding in Isabelle/HOL. We consider two possible uses of the framework. The first one is as a tool for meta-reasoning about the considered logic. We employ it for the automated verification of deontic correspondences (broadly conceived) and related matters, analogous to what has been previously achieved for the modal logic cube. The equivalence is automatically verified in one direction, leading from the property to the axiom. The second use is as a tool for assessing ethical arguments. We provide a computer encoding of a well-known paradox (or impossibility theorem) in population ethics, Parfit's repugnant conclusion. While some have proposed overcoming the impossibility theorem by abandoning the presupposed transitivity of ''better than'', our formalisation unveils a less extreme approach, suggesting among other things the option of weakening transitivity suitably rather than discarding it entirely. Whether the presented encoding increases or decreases the attractiveness and persuasiveness of the repugnant conclusion is a question we would like to pass on to philosophy and ethics.",
        "published": "2023-08-21T12:47:30Z",
        "link": "http://arxiv.org/abs/2308.10686v4",
        "categories": [
            "cs.LO",
            "cs.AI",
            "cs.SC",
            "03B60, 03B15, 68T27, 68T30, 68T15",
            "I.2.3; I.2.4; I.2.0; F.4"
        ]
    },
    {
        "title": "Algebraic power series and their automatic complexity I: finite fields",
        "authors": [
            "Eric Rowland",
            "Manon Stipulanti",
            "Reem Yassawi"
        ],
        "summary": "Christol's theorem states that a power series with coefficients in a finite field is algebraic if and only if its coefficient sequence is automatic. A natural question is how the size of a polynomial describing such a sequence relates to the size of an automaton describing the same sequence. Bridy used tools from algebraic geometry to bound the size of the minimal automaton for a sequence, given its minimal polynomial. We produce a new proof of Bridy's bound by embedding algebraic sequences as diagonals of rational functions. Crucially for our interests, our approach can be adapted to work not just over a finite field but over the integers modulo $p^\\alpha$.",
        "published": "2023-08-21T18:48:24Z",
        "link": "http://arxiv.org/abs/2308.10977v1",
        "categories": [
            "math.NT",
            "cs.FL",
            "cs.SC",
            "11B85, 13F25"
        ]
    },
    {
        "title": "Incremental Property Directed Reachability",
        "authors": [
            "Max Blankestijn",
            "Alfons Laarman"
        ],
        "summary": "Property Directed Reachability (PDR) is a widely used technique for formal verification of hardware and software systems. This paper presents an incremental version of PDR (IPDR), which enables the automatic verification of system instances of incremental complexity. The proposed algorithm leverages the concept of incremental SAT solvers to reuse verification results from previously verified system instances, thereby accelerating the verification process. The new algorithm supports both incremental constraining and relaxing; i.e., starting from an over-constrained instance that is gradually relaxed.   To validate the effectiveness of the proposed algorithm, we implemented IPDR and experimentally evaluate it on two different problem domains. First, we consider a circuit pebbling problem, where the number of pebbles is both constrained and relaxed. Second, we explore parallel program instances, progressively increasing the allowed number of interleavings. The experimental results demonstrate significant performance improvements compared to Z3's PDR implementation SPACER. Experiments also show that the incremental approach succeeds in reusing a substantial amount of clauses between instances, for both the constraining and relaxing algorithm.",
        "published": "2023-08-23T14:23:48Z",
        "link": "http://arxiv.org/abs/2308.12162v1",
        "categories": [
            "cs.SC",
            "cs.LO",
            "B.8.1; I.1.2"
        ]
    },
    {
        "title": "Proceedings 39th International Conference on Logic Programming",
        "authors": [
            "Enrico Pontelli",
            "Stefania Costantini",
            "Carmine Dodaro",
            "Sarah Gaggl",
            "Roberta Calegari",
            "Artur D'Avila Garcez",
            "Francesco Fabiano",
            "Alessandra Mileo",
            "Alessandra Russo",
            "Francesca Toni"
        ],
        "summary": "This volume contains the Technical Communications presented at the 39th International Conference on Logic Programming (ICLP 2023), held at Imperial College London, UK from July 9 to July 15, 2023. Technical Communications included here concern the Main Track, the Doctoral Consortium, the Application and Systems/Demo track, the Recently Published Research Track, the Birds-of-a-Feather track, the Thematic Tracks on Logic Programming and Machine Learning, and Logic Programming and Explainability, Ethics, and Trustworthiness.",
        "published": "2023-08-28T20:46:59Z",
        "link": "http://arxiv.org/abs/2308.14898v1",
        "categories": [
            "cs.AI",
            "cs.LO",
            "cs.PL",
            "cs.SC"
        ]
    },
    {
        "title": "Deep Inductive Logic Programming meets Reinforcement Learning",
        "authors": [
            "Andreas Bueff",
            "Vaishak Belle"
        ],
        "summary": "One approach to explaining the hierarchical levels of understanding within a machine learning model is the symbolic method of inductive logic programming (ILP), which is data efficient and capable of learning first-order logic rules that can entail data behaviour. A differentiable extension to ILP, so-called differentiable Neural Logic (dNL) networks, are able to learn Boolean functions as their neural architecture includes symbolic reasoning. We propose an application of dNL in the field of Relational Reinforcement Learning (RRL) to address dynamic continuous environments. This represents an extension of previous work in applying dNL-based ILP in RRL settings, as our proposed model updates the architecture to enable it to solve problems in continuous RL environments. The goal of this research is to improve upon current ILP methods for use in RRL by incorporating non-linear continuous predicates, allowing RRL agents to reason and make decisions in dynamic and continuous environments.",
        "published": "2023-08-30T09:08:46Z",
        "link": "http://arxiv.org/abs/2308.16210v1",
        "categories": [
            "cs.LG",
            "cs.LO",
            "cs.SC"
        ]
    },
    {
        "title": "Inferring Compensatory Kinase Networks in Yeast using Prolog",
        "authors": [
            "George A. Elder",
            "Conrad Bessant"
        ],
        "summary": "Signalling pathways are conserved across different species, therefore making yeast a model organism to study these via disruption of kinase activity. Yeast has 159 genes that encode protein kinases and phosphatases, and 136 of these have counterparts in humans. Therefore any insight in this model organism could potentially offer indications of mechanisms of action in the human kinome. The study utilises a Prolog-based approach, data from a yeast kinase deletions strains study and publicly available kinase-protein associations. Prolog, a programming language that is well-suited for symbolic reasoning is used to reason over the data and infer compensatory kinase networks. This approach is based on the idea that when a kinase is knocked out, other kinases may compensate for this loss of activity. Background knowledge on kinases targeting proteins is used to guide the analysis. This knowledge is used to infer the potential compensatory interactions between kinases based on the changes in phosphorylation observed in the phosphoproteomics data from the yeast study. The results demonstrate the effectiveness of the Prolog-based approach in analysing complex cell signalling mechanisms in yeast. The inferred compensatory kinase networks provide new insights into the regulation of cell signalling in yeast and may aid in the identification of potential therapeutic targets for modulating signalling pathways in yeast and other organisms.",
        "published": "2023-08-30T20:29:41Z",
        "link": "http://arxiv.org/abs/2308.16309v1",
        "categories": [
            "q-bio.MN",
            "cs.SC"
        ]
    },
    {
        "title": "Declarative Reasoning on Explanations Using Constraint Logic Programming",
        "authors": [
            "Laura State",
            "Salvatore Ruggieri",
            "Franco Turini"
        ],
        "summary": "Explaining opaque Machine Learning (ML) models is an increasingly relevant problem. Current explanation in AI (XAI) methods suffer several shortcomings, among others an insufficient incorporation of background knowledge, and a lack of abstraction and interactivity with the user. We propose REASONX, an explanation method based on Constraint Logic Programming (CLP). REASONX can provide declarative, interactive explanations for decision trees, which can be the ML models under analysis or global/local surrogate models of any black-box model. Users can express background or common sense knowledge using linear constraints and MILP optimization over features of factual and contrastive instances, and interact with the answer constraints at different levels of abstraction through constraint projection. We present here the architecture of REASONX, which consists of a Python layer, closer to the user, and a CLP layer. REASONX's core execution engine is a Prolog meta-program with declarative semantics in terms of logic theories.",
        "published": "2023-09-01T12:31:39Z",
        "link": "http://arxiv.org/abs/2309.00422v1",
        "categories": [
            "cs.AI",
            "cs.CY",
            "cs.LG",
            "cs.SC"
        ]
    },
    {
        "title": "Verifying the Unknown: Correct-by-Design Control Synthesis for Networks   of Stochastic Uncertain Systems",
        "authors": [
            "Oliver Schön",
            "Birgit van Huijgevoort",
            "Sofie Haesaert",
            "Sadegh Soudjani"
        ],
        "summary": "In this paper, we present an approach for designing correct-by-design controllers for cyber-physical systems composed of multiple dynamically interconnected uncertain systems. We consider networked discrete-time uncertain nonlinear systems with additive stochastic noise and model parametric uncertainty. Such settings arise when multiple systems interact in an uncertain environment and only observational data is available. We address two limitations of existing approaches for formal synthesis of controllers for networks of uncertain systems satisfying complex temporal specifications. Firstly, whilst existing approaches rely on the stochasticity to be Gaussian, the heterogeneous nature of composed systems typically yields a more complex stochastic behavior. Secondly, exact models of the systems involved are generally not available or difficult to acquire. To address these challenges, we show how abstraction-based control synthesis for uncertain systems based on sub-probability couplings can be extended to networked systems. We design controllers based on parameter uncertainty sets identified from observational data and approximate possibly arbitrary noise distributions using Gaussian mixture models whilst quantifying the incurred stochastic coupling. Finally, we demonstrate the effectiveness of our approach on a nonlinear package delivery case study with a complex specification, and a platoon of cars.",
        "published": "2023-09-03T21:57:34Z",
        "link": "http://arxiv.org/abs/2309.01276v1",
        "categories": [
            "eess.SY",
            "cs.LO",
            "cs.SC",
            "cs.SY"
        ]
    },
    {
        "title": "Partial Proof of a Conjecture with Implications for Spectral   Majorization",
        "authors": [
            "Jeffrey Uhlmann"
        ],
        "summary": "In this paper we report on new results relating to a conjecture regarding properties of $n\\times n$, $n\\leq 6$, positive definite matrices. The conjecture has been proven for $n\\leq 4$ using computer-assisted sum of squares (SoS) methods for proving polynomial nonnegativity. Based on these proven cases, we report on the recent identification of a new family of matrices with the property that their diagonals majorize their spectrum. We then present new results showing that this family can extended via Kronecker composition to $n>6$ while retaining the special majorization property. We conclude with general considerations on the future of computer-assisted and AI-based proofs.",
        "published": "2023-09-04T01:02:19Z",
        "link": "http://arxiv.org/abs/2309.01302v1",
        "categories": [
            "cs.SC",
            "cs.AI"
        ]
    },
    {
        "title": "Cognitive Architectures for Language Agents",
        "authors": [
            "Theodore R. Sumers",
            "Shunyu Yao",
            "Karthik Narasimhan",
            "Thomas L. Griffiths"
        ],
        "summary": "Recent efforts have augmented large language models (LLMs) with external resources (e.g., the Internet) or internal control flows (e.g., prompt chaining) for tasks requiring grounding or reasoning, leading to a new class of language agents. While these agents have achieved substantial empirical success, we lack a systematic framework to organize existing agents and plan future developments. In this paper, we draw on the rich history of cognitive science and symbolic artificial intelligence to propose Cognitive Architectures for Language Agents (CoALA). CoALA describes a language agent with modular memory components, a structured action space to interact with internal memory and external environments, and a generalized decision-making process to choose actions. We use CoALA to retrospectively survey and organize a large body of recent work, and prospectively identify actionable directions towards more capable agents. Taken together, CoALA contextualizes today's language agents within the broader history of AI and outlines a path towards language-based general intelligence.",
        "published": "2023-09-05T17:56:20Z",
        "link": "http://arxiv.org/abs/2309.02427v3",
        "categories": [
            "cs.AI",
            "cs.CL",
            "cs.LG",
            "cs.SC"
        ]
    },
    {
        "title": "FMplex: Exploring a Bridge between Fourier-Motzkin and Simplex",
        "authors": [
            "Valentin Promies",
            "Jasper Nalbach",
            "Erika Ábrahám",
            "Paul Kobialka"
        ],
        "summary": "In this paper we present a quantifier elimination method for conjunctions of linear real arithmetic constraints. Our algorithm is based on the Fourier-Motzkin variable elimination procedure, but by case splitting we are able to reduce the worst-case complexity from doubly to singly exponential. The adaption of the procedure for SMT solving has strong correspondence to the simplex algorithm, therefore we name it FMplex. Besides the theoretical foundations, we provide an experimental evaluation in the context of SMT solving. This is an extended version of the authors' work previously published at the fourteenth International Symposium on Games, Automata, Logics, and Formal Verification (GandALF 2023).",
        "published": "2023-09-06T16:22:01Z",
        "link": "http://arxiv.org/abs/2309.03138v4",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Presenting the SWTC: A Symbolic Corpus of Themes from John Williams'   Star Wars Episodes I-IX",
        "authors": [
            "Claire Arthur",
            "Frank Lehman",
            "John McNamara"
        ],
        "summary": "This paper presents a new symbolic corpus of musical themes from the complete Star Wars trilogies (Episodes I-IX) by John Williams. The corpus files are made available in multiple formats (.krn, .sib, and .musicxml) and include melodic, harmonic, and formal information. The Star Wars Thematic Corpus (SWTC) contains a total of 64 distinctive, recurring, and symbolically meaningful themes and motifs, commonly referred to as leitmotifs. Through this corpus we also introduce a new humdrum standard for non-functional harmony encodings, **harte, based on Harte (2005, 2010). This report details the motivation, describes the transcription and encoding processes, and provides some brief summary statistics. While relatively small in scale, the SWTC represents a unified collection from one of the most prolific and influential composers of the 20th century, and the under-studied subset of film and multimedia musical material in general. We hope the SWTC will provide insights into John Williams' compositional style, as well as prove useful in comparisons against other thematic corpora from film and beyond.",
        "published": "2023-09-06T18:21:55Z",
        "link": "http://arxiv.org/abs/2309.03298v1",
        "categories": [
            "cs.SD",
            "cs.SC",
            "eess.AS"
        ]
    },
    {
        "title": "HIVE: Scalable Hardware-Firmware Co-Verification using Scenario-based   Decomposition and Automated Hint Extraction",
        "authors": [
            "Aruna Jayasena",
            "Prabhat Mishra"
        ],
        "summary": "Hardware-firmware co-verification is critical to design trustworthy systems. While formal methods can provide verification guarantees, due to the complexity of firmware and hardware, it can lead to state space explosion. There are promising avenues to reduce the state space during firmware verification through manual abstraction of hardware or manual generation of hints. Manual development of abstraction or hints requires domain expertise and can be time-consuming and error-prone, leading to incorrect proofs or inaccurate results. In this paper, we effectively combine the scalability of simulation-based validation and the completeness of formal verification. Our proposed approach is applicable to actual firmware and hardware implementations without requiring any manual intervention during formal model generation or hint extraction. To reduce the state space complexity, we utilize both static module-level analysis and dynamic execution of verification scenarios to automatically generate system-level hints. These hints guide the underlying solver to perform scalable equivalence checking using proofs. The extracted hints are validated against the implementation before using them in the proofs. Experimental evaluation on RISC-V based systems demonstrates that our proposed framework is scalable due to scenario-based decomposition and automated hint extraction. Moreover, our fully automated framework can identify complex bugs in actual firmware-hardware implementations.",
        "published": "2023-09-14T19:24:57Z",
        "link": "http://arxiv.org/abs/2309.08002v2",
        "categories": [
            "cs.SC",
            "cs.SE"
        ]
    },
    {
        "title": "When to Trust AI: Advances and Challenges for Certification of Neural   Networks",
        "authors": [
            "Marta Kwiatkowska",
            "Xiyue Zhang"
        ],
        "summary": "Artificial intelligence (AI) has been advancing at a fast pace and it is now poised for deployment in a wide range of applications, such as autonomous systems, medical diagnosis and natural language processing. Early adoption of AI technology for real-world applications has not been without problems, particularly for neural networks, which may be unstable and susceptible to adversarial examples. In the longer term, appropriate safety assurance techniques need to be developed to reduce potential harm due to avoidable system failures and ensure trustworthiness. Focusing on certification and explainability, this paper provides an overview of techniques that have been developed to ensure safety of AI decisions and discusses future challenges.",
        "published": "2023-09-20T10:31:09Z",
        "link": "http://arxiv.org/abs/2309.11196v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.CR",
            "cs.SC"
        ]
    },
    {
        "title": "Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models   through Logic",
        "authors": [
            "Xufeng Zhao",
            "Mengdi Li",
            "Wenhao Lu",
            "Cornelius Weber",
            "Jae Hee Lee",
            "Kun Chu",
            "Stefan Wermter"
        ],
        "summary": "Recent advancements in large language models have showcased their remarkable generalizability across various domains. However, their reasoning abilities still have significant room for improvement, especially when confronted with scenarios requiring multi-step reasoning. Although large language models possess extensive knowledge, their reasoning often fails to effectively utilize this knowledge to establish a coherent thinking paradigm. These models sometimes show hallucinations as their reasoning procedures are unconstrained by logical principles. Aiming at improving the zero-shot chain-of-thought reasoning ability of large language models, we propose LoT (Logical Thoughts), a self-improvement prompting framework that leverages principles rooted in symbolic logic, particularly Reductio ad Absurdum, to systematically verify and rectify the reasoning processes step by step. Experimental evaluations conducted on language tasks in diverse domains, including arithmetic, commonsense, symbolic, causal inference, and social problems, demonstrate the efficacy of enhanced reasoning by logic. The implementation code for LoT can be accessed at: https://github.com/xf-zhao/LoT.",
        "published": "2023-09-23T11:21:12Z",
        "link": "http://arxiv.org/abs/2309.13339v4",
        "categories": [
            "cs.CL",
            "cs.AI",
            "cs.LG",
            "cs.SC"
        ]
    },
    {
        "title": "Symmetric Functions over Finite Fields",
        "authors": [
            "Mihai Prunescu"
        ],
        "summary": "The number of linear independent algebraic relations among elementary symmetric polynomial functions over finite fields is computed. An algorithm able to find all such relations is described. It is proved that the basis of the ideal of algebraic relations found by the algorithm consists of polynomials having coefficients in the prime field F_p.",
        "published": "2023-09-25T01:17:38Z",
        "link": "http://arxiv.org/abs/2309.13804v1",
        "categories": [
            "cs.SC",
            "cs.DM",
            "math.CO",
            "I.1.2"
        ]
    },
    {
        "title": "Real-Time Emergency Vehicle Detection using Mel Spectrograms and Regular   Expressions",
        "authors": [
            "Alberto Pacheco-Gonzalez",
            "Raymundo Torres",
            "Raul Chacon",
            "Isidro Robledo"
        ],
        "summary": "In emergency situations, the high-speed movement of an ambulance through the city streets can be hindered by vehicular traffic. This work presents a method for detecting emergency vehicle sirens in real time. To obtain the audio fingerprint of a Hi-Lo siren, DSP and signal symbolization techniques were applied, which were contrasted against an audio classifier based on a deep neural network, using the same 280 audios of ambient sounds and 52 Hi-Lo siren audios dataset. In both methods, some classification accuracy metrics were evaluated based on its confusion matrix, resulting in the DSP algorithm having a slightly lower accuracy than the DNN model, however, it offers a self-explanatory, adjustable, portable, high performance and lower energy and consumption that makes it a more viable lower cost ADAS implementation to identify Hi-Lo sirens in real time.",
        "published": "2023-09-25T07:40:19Z",
        "link": "http://arxiv.org/abs/2309.13920v3",
        "categories": [
            "cs.SD",
            "cs.FL",
            "cs.SC",
            "eess.AS",
            "I.5.5"
        ]
    },
    {
        "title": "On the Reduced Gröbner Bases of Blockwise Determinantal Ideals",
        "authors": [
            "Chenqi Mou",
            "Qiuye Song"
        ],
        "summary": "Blockwise determinantal ideals are those generated by the union of all the minors of specified sizes in certain blocks of a generic matrix, and they are the natural generalization of many existing determinantal ideals like the Schubert and ladder ones. In this paper we establish several criteria to verify whether the Gr\\\"obner bases of blockwise determinantal ideals with respect to (anti-)diagonal term orders are minimal or reduced. In particular, for Schubert determinantal ideals, while all the elusive minors form the reduced Gr\\\"obner bases when the defining permutations are vexillary, in the non-vexillary case we derive an explicit formula for computing the reduced Gr\\\"obner basis from elusive minors which avoids all algebraic operations. The fundamental properties of being normal and strong for W-characteristic sets and characteristic pairs, which are heavily connected to the reduced Gr\\\"obner bases, of Schubert determinantal ideals are also proven.",
        "published": "2023-09-26T16:03:36Z",
        "link": "http://arxiv.org/abs/2309.15035v2",
        "categories": [
            "math.AC",
            "cs.SC",
            "math.CO",
            "13P10 (Primary) 13C40, 05E14 (Secondary)"
        ]
    },
    {
        "title": "LogicMP: A Neuro-symbolic Approach for Encoding First-order Logic   Constraints",
        "authors": [
            "Weidi Xu",
            "Jingwei Wang",
            "Lele Xie",
            "Jianshan He",
            "Hongting Zhou",
            "Taifeng Wang",
            "Xiaopei Wan",
            "Jingdong Chen",
            "Chao Qu",
            "Wei Chu"
        ],
        "summary": "Integrating first-order logic constraints (FOLCs) with neural networks is a crucial but challenging problem since it involves modeling intricate correlations to satisfy the constraints. This paper proposes a novel neural layer, LogicMP, whose layers perform mean-field variational inference over an MLN. It can be plugged into any off-the-shelf neural network to encode FOLCs while retaining modularity and efficiency. By exploiting the structure and symmetries in MLNs, we theoretically demonstrate that our well-designed, efficient mean-field iterations effectively mitigate the difficulty of MLN inference, reducing the inference from sequential calculation to a series of parallel tensor operations. Empirical results in three kinds of tasks over graphs, images, and text show that LogicMP outperforms advanced competitors in both performance and efficiency.",
        "published": "2023-09-27T07:52:30Z",
        "link": "http://arxiv.org/abs/2309.15458v3",
        "categories": [
            "cs.AI",
            "cs.SC"
        ]
    },
    {
        "title": "FMplex: A Novel Method for Solving Linear Real Arithmetic Problems",
        "authors": [
            "Jasper Nalbach",
            "Valentin Promies",
            "Erika Ábrahám",
            "Paul Kobialka"
        ],
        "summary": "In this paper we introduce a novel quantifier elimination method for conjunctions of linear real arithmetic constraints. Our algorithm is based on the Fourier-Motzkin variable elimination procedure, but by case splitting we are able to reduce the worst-case complexity from doubly to singly exponential. The adaption of the procedure for SMT solving has strong correspondence to the simplex algorithm, therefore we name it FMplex. Besides the theoretical foundations, we provide an experimental evaluation in the context of SMT solving.",
        "published": "2023-10-02T08:58:04Z",
        "link": "http://arxiv.org/abs/2310.00995v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Reducing Hyperexponential Functions over Monomial Extensions",
        "authors": [
            "Shaoshi Chen",
            "Hao Du",
            "Yiman Gao",
            "Ziming Li"
        ],
        "summary": "We extend the shell and kernel reductions for hyperexponential functions over the field of rational functions to a monomial extension. Both of the reductions are incorporated into one algorithm. As an application, we present an additive decomposition in rationally hyperexponential towers. The decomposition yields an alternative algorithm for computing elementary integrals over such towers. The alternative can find some elementary integrals that are unevaluated by the integrators in the latest versions of Maple and Mathematica.",
        "published": "2023-10-02T13:30:23Z",
        "link": "http://arxiv.org/abs/2310.01194v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Quantifying the information lost in optimal covariance matrix cleaning",
        "authors": [
            "Christian Bongiorno",
            "Lamia Lamrani"
        ],
        "summary": "Obtaining an accurate estimate of the underlying covariance matrix from finite sample size data is challenging due to sample size noise. In recent years, sophisticated covariance-cleaning techniques based on random matrix theory have been proposed to address this issue. Most of these methods aim to achieve an optimal covariance matrix estimator by minimizing the Frobenius norm distance as a measure of the discrepancy between the true covariance matrix and the estimator. However, this practice offers limited interpretability in terms of information theory. To better understand this relationship, we focus on the Kullback-Leibler divergence to quantify the information lost by the estimator. Our analysis centers on rotationally invariant estimators, which are state-of-art in random matrix theory, and we derive an analytical expression for their Kullback-Leibler divergence. Due to the intricate nature of the calculations, we use genetic programming regressors paired with human intuition. Ultimately, using this approach, we formulate a conjecture validated through extensive simulations, showing that the Frobenius distance corresponds to a first-order expansion term of the Kullback-Leibler divergence, thus establishing a more defined link between the two measures.",
        "published": "2023-10-03T11:18:01Z",
        "link": "http://arxiv.org/abs/2310.01963v2",
        "categories": [
            "stat.CO",
            "cs.IT",
            "cs.SC",
            "math.IT",
            "62H12, 15B52, 68V99"
        ]
    },
    {
        "title": "Divide, Conquer and Verify: Improving Symbolic Execution Performance",
        "authors": [
            "Christopher Scherb",
            "Luc Bryan Heitz",
            "Hermann Grieder",
            "Olivier Mattmann"
        ],
        "summary": "Symbolic Execution is a formal method that can be used to verify the behavior of computer programs and detect software vulnerabilities. Compared to other testing methods such as fuzzing, Symbolic Execution has the advantage of providing formal guarantees about the program. However, despite advances in performance in recent years, Symbolic Execution is too slow to be applied to real-world software. This is primarily caused by the \\emph{path explosion problem} as well as by the computational complexity of SMT solving. In this paper, we present a divide-and-conquer approach for symbolic execution by executing individual slices and later combining the side effects. This way, the overall problem size is kept small, reducing the impact of computational complexity on large problems.",
        "published": "2023-10-05T15:21:10Z",
        "link": "http://arxiv.org/abs/2310.03598v2",
        "categories": [
            "cs.CR",
            "cs.SC",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Geometry of the signed support of a multivariate polynomial and   Descartes' rule of signs",
        "authors": [
            "Máté L. Telek"
        ],
        "summary": "We investigate the signed support, that is, the set of the exponent vectors and the signs of the coefficients, of a multivariate polynomial $f$. We describe conditions on the signed support ensuring that the semi-algebraic set, denoted as $\\{ f < 0 \\}$, containing points in the positive real orthant where $f$ takes negative values, has at most one connected component. These results generalize Descartes' rule of signs in the sense that they provide a bound which is independent of the values of the coefficients and the degree of the polynomial. Based on how the exponent vectors lie on the faces of the Newton polytope, we give a recursive algorithm that verifies a sufficient condition for the set $\\{ f < 0 \\}$ to have one connected component. We apply the algorithm to reaction networks in order to prove that the parameter region of multistationarity of a ubiquitous network comprising phosphorylation cycles is connected.",
        "published": "2023-10-09T07:22:21Z",
        "link": "http://arxiv.org/abs/2310.05466v2",
        "categories": [
            "math.AG",
            "cs.SC"
        ]
    },
    {
        "title": "What can knowledge graph alignment gain with Neuro-Symbolic learning   approaches?",
        "authors": [
            "Pedro Giesteira Cotovio",
            "Ernesto Jimenez-Ruiz",
            "Catia Pesquita"
        ],
        "summary": "Knowledge Graphs (KG) are the backbone of many data-intensive applications since they can represent data coupled with its meaning and context. Aligning KGs across different domains and providers is necessary to afford a fuller and integrated representation. A severe limitation of current KG alignment (KGA) algorithms is that they fail to articulate logical thinking and reasoning with lexical, structural, and semantic data learning. Deep learning models are increasingly popular for KGA inspired by their good performance in other tasks, but they suffer from limitations in explainability, reasoning, and data efficiency. Hybrid neurosymbolic learning models hold the promise of integrating logical and data perspectives to produce high-quality alignments that are explainable and support validation through human-centric approaches. This paper examines the current state of the art in KGA and explores the potential for neurosymbolic integration, highlighting promising research directions for combining these fields.",
        "published": "2023-10-11T12:03:19Z",
        "link": "http://arxiv.org/abs/2310.07417v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.SC"
        ]
    },
    {
        "title": "Three Paths to Rational Curves with Rational Arc Length",
        "authors": [
            "Hans-Peter Schröcker",
            "Zbyněk Šìr"
        ],
        "summary": "We solve the so far open problem of constructing all spatial rational curves with rational arc length functions. More precisely, we present three different methods for this construction. The first method adapts a recent approach of (Kalkan et al. 2022) to rational PH curves and requires solving a modestly sized system of linear equations. The second constructs the curve by imposing zero-residue conditions, thus extending ideas of previous papers by (Farouki and Sakkalis 2019) and the authors themselves (Schr\\\"ocker and \\v{S}\\'ir 2023). The third method generalizes the dual approach of (Pottmann 1995) from planar to spatial curves. The three methods share the same quaternion based representation in which not only the PH curve but also its arc length function are compactly expressed. We also present a new proof based on the quaternion polynomial factorization theory of the well known characterization of the Pythagorean quadruples.",
        "published": "2023-10-12T05:39:56Z",
        "link": "http://arxiv.org/abs/2310.08047v2",
        "categories": [
            "cs.SC",
            "cs.NA",
            "math.DG",
            "math.NA",
            "65D17"
        ]
    },
    {
        "title": "A computational model of serial and parallel processing in visual search",
        "authors": [
            "Rachel F. Heaton"
        ],
        "summary": "The following is a dissertation aimed at understanding what the various phenomena in visual search teach us about the nature of human visual representations and processes. I first review some of the major empirical findings in the study of visual search. I next present a theory of visual search in terms of what I believe these findings suggest about the representations and processes underlying ventral visual processing. These principles are instantiated in a computational model called CASPER (Concurrent Attention: Serial and Parallel Evaluation with Relations), originally developed by Hummel, that I have adapted to account for a range of phenomena in visual search. I then describe an extension of the CASPER model to account for our ability to search for visual items defined not simply by the features composing those items but by the spatial relations among those features. Seven experiments (four main experiments and three replications) are described that test CASPER's predictions about relational search. Finally, I evaluate the fit between CASPER's predictions and the empirical findings and show with three additional simulations that CASPER can account for negative acceleration in search functions for relational stimuli if one postulates that the visual system is leveraging an emergent feature that bypasses relational processing.",
        "published": "2023-10-16T04:51:13Z",
        "link": "http://arxiv.org/abs/2310.10061v1",
        "categories": [
            "cs.CV",
            "cs.SC"
        ]
    },
    {
        "title": "Accurate prediction of international trade flows: Leveraging knowledge   graphs and their embeddings",
        "authors": [
            "Diego Rincon-Yanez",
            "Chahinez Ounoughi",
            "Bassem Sellami",
            "Tarmo Kalvet",
            "Marek Tiits",
            "Sabrina Senatore",
            "Sadok Ben Yahia"
        ],
        "summary": "Knowledge representation (KR) is vital in designing symbolic notations to represent real-world facts and facilitate automated decision-making tasks. Knowledge graphs (KGs) have emerged so far as a popular form of KR, offering a contextual and human-like representation of knowledge. In international economics, KGs have proven valuable in capturing complex interactions between commodities, companies, and countries. By putting the gravity model, which is a common economic framework, into the process of building KGs, important factors that affect trade relationships can be taken into account, making it possible to predict international trade patterns. This paper proposes an approach that leverages Knowledge Graph embeddings for modeling international trade, focusing on link prediction using embeddings. Thus, valuable insights are offered to policymakers, businesses, and economists, enabling them to anticipate the effects of changes in the international trade system. Moreover, the integration of traditional machine learning methods with KG embeddings, such as decision trees and graph neural networks are also explored. The research findings demonstrate the potential for improving prediction accuracy and provide insights into embedding explainability in knowledge representation. The paper also presents a comprehensive analysis of the influence of embedding methods on other intelligent algorithms.",
        "published": "2023-10-17T11:28:30Z",
        "link": "http://arxiv.org/abs/2310.11161v1",
        "categories": [
            "cs.AI",
            "cs.SC"
        ]
    },
    {
        "title": "Dimensionally Homogeneous Jacobian using Extended Selection Matrix for   Performance Evaluation and Optimization of Parallel Manipulators",
        "authors": [
            "Hassen Nigatu",
            "Doik Kim"
        ],
        "summary": "This paper proposes a new methodology for deriving a point-based dimensionally homogeneous Jacobian, intended for performance evaluation and optimization of parallel manipulators with mixed degrees of freedom. Optimal manipulator often rely on performance indices obtained from the Jacobian matrix. However, when manipulators exhibit mixed translational and rotational freedoms, the conventional Jacobian's inconsistency of units lead to unbalanced optimal result. Addressing this issue, a point-based dimensionally homogeneous Jacobian has appeared as a prominent solution. However, existing point-based approaches for formulating dimensionally homogeneous Jacobian are applicable to a limited variety of parallel manipulators. Moreover, they are complicated and less intuitive. This paper introduces an extended selection matrix that combines component velocities from different points to describe the entire motion of moving plate. This proposed approach enables us to formulate an intuitive point-based, dimensionally homogeneous Jacobian, which can be applied to a wide variety of constrained parallel manipulators. To prove the validity of proposed method, a numerical example is provided utilizing a four-degree-of-freedom parallel manipulator.",
        "published": "2023-10-27T02:37:15Z",
        "link": "http://arxiv.org/abs/2310.17863v1",
        "categories": [
            "cs.RO",
            "cs.SC"
        ]
    },
    {
        "title": "A Novel Application of Polynomial Solvers in mmWave Analog Radio   Beamforming",
        "authors": [
            "Snehal Bhayani",
            "Praneeth Susarla",
            "S. S. Krishna Chaitanya Bulusu",
            "Olli Silven",
            "Markku Juntti",
            "Janne Heikkila"
        ],
        "summary": "Beamforming is a signal processing technique where an array of antenna elements can be steered to transmit and receive radio signals in a specific direction. The usage of millimeter wave (mmWave) frequencies and multiple input multiple output (MIMO) beamforming are considered as the key innovations of 5th Generation (5G) and beyond communication systems. The technique initially performs a beam alignment procedure, followed by data transfer in the aligned directions between the transmitter and the receiver. Traditionally, beam alignment involves periodical and exhaustive beam sweeping at both transmitter and the receiver, which is a slow process causing extra communication overhead with MIMO and massive MIMO radio units. In applications such as beam tracking, angular velocity, beam steering etc., the beam alignment procedure is optimized by estimating the beam directions using first order polynomial approximations. Recent learning-based SOTA strategies for fast mmWave beam alignment also require exploration over exhaustive beam pairs during the training procedure, causing overhead to learning strategies for higher antenna configurations. In this work, we first optimize the beam alignment cost functions e.g. the data rate, to reduce the beam sweeping overhead by applying polynomial approximations of its partial derivatives which can then be solved as a system of polynomial equations using well-known tools from algebraic geometry. At this point, a question arises: 'what is a good polynomial approximation?' In this work, we attempt to obtain a 'good polynomial approximation'. Preliminary experiments indicate that our estimated polynomial approximations attain a so-called sweet-spot in terms of the solver speed and accuracy, when evaluated on test beamforming problems.",
        "published": "2023-10-27T12:41:41Z",
        "link": "http://arxiv.org/abs/2310.18103v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Optimizing Logical Execution Time Model for Both Determinism and Low   Latency",
        "authors": [
            "Sen Wang",
            "Dong Li",
            "Ashrarul H. Sifat",
            "Shao-Yu Huang",
            "Xuanliang Deng",
            "Changhee Jung",
            "Ryan Williams",
            "Haibo Zeng"
        ],
        "summary": "The Logical Execution Time (LET) programming model has recently received considerable attention, particularly because of its timing and dataflow determinism. In LET, task computation appears always to take the same amount of time (called the task's LET interval), and the task reads (resp. writes) at the beginning (resp. end) of the interval. Compared to other communication mechanisms, such as implicit communication and Dynamic Buffer Protocol (DBP), LET performs worse on many metrics, such as end-to-end latency (including reaction time and data age) and time disparity jitter. Compared with the default LET setting, the flexible LET (fLET) model shrinks the LET interval while still guaranteeing schedulability by introducing the virtual offset to defer the read operation and using the virtual deadline to move up the write operation. Therefore, fLET has the potential to significantly improve the end-to-end timing performance while keeping the benefits of deterministic behavior on timing and dataflow.   To fully realize the potential of fLET, we consider the problem of optimizing the assignments of its virtual offsets and deadlines. We propose new abstractions to describe the task communication pattern and new optimization algorithms to explore the solution space efficiently. The algorithms leverage the linearizability of communication patterns and utilize symbolic operations to achieve efficient optimization while providing a theoretical guarantee. The framework supports optimizing multiple performance metrics and guarantees bounded suboptimality when optimizing end-to-end latency. Experimental results show that our optimization algorithms improve upon the default LET and its existing extensions and significantly outperform implicit communication and DBP in terms of various metrics, such as end-to-end latency, time disparity, and its jitter.",
        "published": "2023-10-30T16:21:49Z",
        "link": "http://arxiv.org/abs/2310.19699v3",
        "categories": [
            "eess.SY",
            "cs.OS",
            "cs.SC",
            "cs.SY"
        ]
    },
    {
        "title": "Multi-Operational Mathematical Derivations in Latent Space",
        "authors": [
            "Marco Valentino",
            "Jordan Meadows",
            "Lan Zhang",
            "André Freitas"
        ],
        "summary": "This paper investigates the possibility of approximating multiple mathematical operations in latent space for expression derivation. To this end, we introduce different multi-operational representation paradigms, modelling mathematical operations as explicit geometric transformations. By leveraging a symbolic engine, we construct a large-scale dataset comprising 1.7M derivation steps stemming from 61K premises and 6 operators, analysing the properties of each paradigm when instantiated with state-of-the-art neural encoders. Specifically, we investigate how different encoding mechanisms can approximate expression manipulation in latent space, exploring the trade-off between learning different operators and specialising within single operations, as well as the ability to support multi-step derivations and out-of-distribution generalisation. Our empirical analysis reveals that the multi-operational paradigm is crucial for disentangling different operators, while discriminating the conclusions for a single operation is achievable in the original expression encoder. Moreover, we show that architectural choices can heavily affect the training dynamics, structural organisation, and generalisation of the latent space, resulting in significant variations across paradigms and classes of encoders.",
        "published": "2023-11-02T13:33:07Z",
        "link": "http://arxiv.org/abs/2311.01230v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.SC"
        ]
    },
    {
        "title": "Linear difference operators with sequence coefficients having   infinite-dimentional solution spaces",
        "authors": [
            "Sergei Abramov",
            "Gleb Pogudin"
        ],
        "summary": "The notion of lacunary infinite numerical sequence is introduced. It is shown that for an arbitrary linear difference operator L with coefficients belonging to the set R of infinite numerical sequences, a criterion (i.e., a necessary and sufficient condition) for the infinite dimensionality of its space $V_L$ of solutions belonging to R is the presence of a lacunary sequence in $V_L$.",
        "published": "2023-11-03T20:08:02Z",
        "link": "http://arxiv.org/abs/2311.02217v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "On the dimension of the solution space of linear difference equations   over the ring of infinite sequences",
        "authors": [
            "Sergei Abramov",
            "Gleb Pogudin"
        ],
        "summary": "For a linear difference equation with the coefficients being computable sequences, we establish algorithmic undecidability of the problem of determining the dimension of the solution space including the case when some additional prior information on the dimension is available.",
        "published": "2023-11-03T20:13:55Z",
        "link": "http://arxiv.org/abs/2311.02219v2",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Dissipative quadratizations of polynomial ODE systems",
        "authors": [
            "Yubo Cai",
            "Gleb Pogudin"
        ],
        "summary": "Quadratization refers to a transformation of an arbitrary system of polynomial ordinary differential equations to a system with at most quadratic right-hand side. Such a transformation unveils new variables and model structures that facilitate model analysis, simulation, and control and offers a convenient parameterization for data-driven approaches. Quadratization techniques have found applications in diverse fields, including systems theory, fluid mechanics, chemical reaction modeling, and mathematical analysis.   In this study, we focus on quadratizations that preserve the stability properties of the original model, specifically dissipativity at given equilibria. This preservation is desirable in many applications of quadratization including reachability analysis and synthetic biology. We establish the existence of dissipativity-preserving quadratizations, develop an algorithm for their computation, and demonstrate it in several case studies.",
        "published": "2023-11-04T21:00:51Z",
        "link": "http://arxiv.org/abs/2311.02508v2",
        "categories": [
            "eess.SY",
            "cs.NA",
            "cs.SC",
            "cs.SY",
            "math.NA"
        ]
    },
    {
        "title": "Scene-Driven Multimodal Knowledge Graph Construction for Embodied AI",
        "authors": [
            "Song Yaoxian",
            "Sun Penglei",
            "Liu Haoyu",
            "Li Zhixu",
            "Song Wei",
            "Xiao Yanghua",
            "Zhou Xiaofang"
        ],
        "summary": "Embodied AI is one of the most popular studies in artificial intelligence and robotics, which can effectively improve the intelligence of real-world agents (i.e. robots) serving human beings. Scene knowledge is important for an agent to understand the surroundings and make correct decisions in the varied open world. Currently, knowledge base for embodied tasks is missing and most existing work use general knowledge base or pre-trained models to enhance the intelligence of an agent. For conventional knowledge base, it is sparse, insufficient in capacity and cost in data collection. For pre-trained models, they face the uncertainty of knowledge and hard maintenance. To overcome the challenges of scene knowledge, we propose a scene-driven multimodal knowledge graph (Scene-MMKG) construction method combining conventional knowledge engineering and large language models. A unified scene knowledge injection framework is introduced for knowledge representation. To evaluate the advantages of our proposed method, we instantiate Scene-MMKG considering typical indoor robotic functionalities (Manipulation and Mobility), named ManipMob-MMKG. Comparisons in characteristics indicate our instantiated ManipMob-MMKG has broad superiority in data-collection efficiency and knowledge quality. Experimental results on typical embodied tasks show that knowledge-enhanced methods using our instantiated ManipMob-MMKG can improve the performance obviously without re-designing model structures complexly. Our project can be found at https://sites.google.com/view/manipmob-mmkg",
        "published": "2023-11-07T08:06:27Z",
        "link": "http://arxiv.org/abs/2311.03783v2",
        "categories": [
            "cs.AI",
            "cs.RO",
            "cs.SC"
        ]
    },
    {
        "title": "Reduction-based Creative Telescoping for P-recursive Sequences via   Integral Bases",
        "authors": [
            "Shaoshi Chen",
            "Lixin Du",
            "Manuel Kauers",
            "Rong-Hua Wang"
        ],
        "summary": "We propose a way to split a given bivariate P-recursive sequence into a summable part and a non-summable part in such a way that the non-summable part is minimal in some sense. This decomposition gives rise to a new reduction-based creative telescoping algorithm based on the concept of integral bases.",
        "published": "2023-11-09T10:01:32Z",
        "link": "http://arxiv.org/abs/2311.05246v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Stability Problems on D-finite Functions",
        "authors": [
            "Shaoshi Chen",
            "Ruyong Feng",
            "Zewang Guo",
            "Wei Lu"
        ],
        "summary": "This paper continues the studies of symbolic integration by focusing on the stability problems on D-finite functions. We introduce the notion of stability index in order to investigate the order growth of the differential operators satisfied by iterated integrals of D-finite functions and determine bounds and exact formula for stability indices of several special classes of differential operators. With the basic properties of stability index, we completely solve the stability problem on general hyperexponential functions.",
        "published": "2023-11-10T07:06:07Z",
        "link": "http://arxiv.org/abs/2311.05897v1",
        "categories": [
            "cs.SC",
            "math.CA",
            "math.DS",
            "12H05, 37P15, 33F10",
            "I.1.2"
        ]
    },
    {
        "title": "On the Existence of Telescopers for P-recursive Sequences",
        "authors": [
            "Lixin Du"
        ],
        "summary": "We extend the criterion on the existence of telescopers for hypergeometric terms to the case of P-recursive sequences. This criterion is based on the concept of integral bases and the generalized Abramov-Petkovsek reduction for P-recursive sequences.",
        "published": "2023-11-10T14:00:50Z",
        "link": "http://arxiv.org/abs/2311.06065v1",
        "categories": [
            "cs.SC",
            "68W30, 12H10, 33F10, 39A06, 68W40"
        ]
    },
    {
        "title": "Computing Implicitizations of Multi-Graded Polynomial Maps",
        "authors": [
            "Joseph Cummings",
            "Benjamin Hollering"
        ],
        "summary": "In this paper, we focus on computing the kernel of a map of polynomial rings $\\varphi$. This core problem in symbolic computation is known as implicitization. While there are extremely effective Gr\\\"obner basis methods used to solve this problem, these methods can become infeasible as the number of variables increases. In the case when the map $\\varphi$ is multigraded, we consider an alternative approach. We demonstrate how to quickly compute a matrix of maximal rank for which $\\varphi$ has a positive multigrading. Then in each graded component we compute the minimal generators of the kernel in that multidegree with linear algebra. We have implemented our techniques in Macaulay2 and show that our implementation can compute many generators of low degree in examples where Gr\\\"obner techniques have failed. This includes several examples coming from phylogenetics where even a complete list of quadrics and cubics were unknown. When the multigrading refines total degree, our algorithm is \\emph{embarassingly parallel} and a fully parallelized version of our algorithm will be forthcoming in OSCAR.",
        "published": "2023-11-13T19:01:48Z",
        "link": "http://arxiv.org/abs/2311.07678v1",
        "categories": [
            "math.AG",
            "cs.SC",
            "math.AC",
            "math.ST",
            "stat.TH",
            "68W3068W30 68W30 68W30 68W30, 13P25, 62R01"
        ]
    },
    {
        "title": "Formal Verification of Zero-Knowledge Circuits",
        "authors": [
            "Alessandro Coglio",
            "Eric McCarthy",
            "Eric W. Smith"
        ],
        "summary": "Zero-knowledge circuits are sets of equality constraints over arithmetic expressions interpreted in a prime field; they are used to encode computations in cryptographic zero-knowledge proofs. We make the following contributions to the problem of ensuring that a circuit correctly encodes a computation: a formal framework for circuit correctness; an ACL2 library for prime fields; an ACL2 model of the existing R1CS (Rank-1 Constraint Systems) formalism to represent circuits, along with ACL2 and Axe tools to verify circuits of this form; a novel PFCS (Prime Field Constraint Systems) formalism to represent hierarchically structured circuits, along with an ACL2 model of it and ACL2 tools to verify circuits of this form in a compositional and scalable way; verification of circuits, ranging from simple to complex; and discovery of bugs and optimizations in existing zero-knowledge systems.",
        "published": "2023-11-15T10:47:28Z",
        "link": "http://arxiv.org/abs/2311.08858v1",
        "categories": [
            "cs.LO",
            "cs.CR",
            "cs.SC"
        ]
    },
    {
        "title": "ACL2 Proofs of Nonlinear Inequalities with Imandra",
        "authors": [
            "Grant Passmore"
        ],
        "summary": "We present a proof-producing integration of ACL2 and Imandra for proving nonlinear inequalities. This leverages a new Imandra interface exposing its nonlinear decision procedures. The reasoning takes place over the reals, but the proofs produced are valid over the rationals and may be run in both ACL2 and ACL2(r). The ACL2 proofs Imandra constructs are extracted from Positivstellensatz refutations, a real algebraic analogue of the Nullstellensatz, and are found using convex optimization.",
        "published": "2023-11-15T10:48:30Z",
        "link": "http://arxiv.org/abs/2311.08861v1",
        "categories": [
            "cs.LO",
            "cs.SC"
        ]
    },
    {
        "title": "A Geometric Approach to Cylindrical Algebraic Decomposition",
        "authors": [
            "Rizeng Chen"
        ],
        "summary": "Cylindrical algebraic decomposition is a classical construction in real algebraic geometry. Although there are many algorithms to compute a cylindrical algebraic decomposition, their practical performance is still very limited. In this paper, we revisit this problem from a more geometric perspective, where the construction of cylindrical algebraic decomposition is related to the study of morphisms between real varieties. It is showed that the geometric fiber cardinality (geometric property) decides the existence of semi-algebraic continuous sections (semi-algebraic property). As a result, all equations can be systematically exploited in the projection phase, leading to a new simple algorithm whose efficiency is demonstrated by experimental results.",
        "published": "2023-11-17T13:36:57Z",
        "link": "http://arxiv.org/abs/2311.10515v4",
        "categories": [
            "math.AG",
            "cs.SC",
            "math.AC",
            "14Q30 (Primary) 14P10, 14Q20, 68W30 (Secondary)"
        ]
    },
    {
        "title": "Efficient Local Search for Nonlinear Real Arithmetic",
        "authors": [
            "Zhonghan Wang",
            "Bohua Zhan",
            "Bohan Li",
            "Shaowei Cai"
        ],
        "summary": "Local search has recently been applied to SMT problems over various arithmetic theories. Among these, nonlinear real arithmetic poses special challenges due to its uncountable solution space and potential need to solve higher-degree polynomials. As a consequence, existing work on local search only considered fragments of the theory. In this work, we analyze the difficulties and propose ways to address them, resulting in an efficient search algorithm that covers the full theory of nonlinear real arithmetic. In particular, we present two algorithmic improvements: incremental computation of variable scores and temporary relaxation of equality constraints. We also discuss choice of candidate moves and a look-ahead mechanism in case when no critical moves are available. The resulting implementation is competitive on satisfiable problem instances against complete methods such as MCSAT in existing SMT solvers.",
        "published": "2023-11-24T01:59:22Z",
        "link": "http://arxiv.org/abs/2311.14249v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Hybrid Intervals and Symbolic Block Matrices",
        "authors": [
            "Mike Ghesquiere",
            "Stephen M. Watt"
        ],
        "summary": "Structured matrices with symbolic sizes appear frequently in the literature, especially in the description of algorithms for linear algebra. Recent work has treated these symbolic structured matrices themselves as computational objects, showing how to add matrices with blocks of different symbolic sizes in a general way while avoiding a combinatorial explosion of cases. The present article introduces the concept of hybrid intervals, in which points may have negative multiplicity. Various operations on hybrid intervals have compact and elegant formulations that do not require cases to handle different orders of the end points. This makes them useful to represent symbolic block matrix structures and to express arithmetic on symbolic block matrices compactly. We use these ideas to formulate symbolic block matrix addition and multiplication in a compact and uniform way.",
        "published": "2023-11-28T07:28:44Z",
        "link": "http://arxiv.org/abs/2311.16571v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "The Inverse of the Complex Gamma Function",
        "authors": [
            "David J. Jeffrey",
            "Stephen M. Watt"
        ],
        "summary": "We consider the functional inverse of the Gamma function in the complex plane, where it is multi-valued, and define a set of suitable branches by proposing a natural extension from the real case.",
        "published": "2023-11-28T08:00:38Z",
        "link": "http://arxiv.org/abs/2311.16583v1",
        "categories": [
            "math.CV",
            "cs.SC"
        ]
    },
    {
        "title": "Nested Integrals and Rationalizing Transformations",
        "authors": [
            "Clemens G. Raab"
        ],
        "summary": "A brief overview of some computer algebra methods for computations with nested integrals is given. The focus is on nested integrals over integrands involving square roots. Rewrite rules for conversion to and from associated nested sums are discussed. We also include a short discussion comparing the holonomic systems approach and the differential field approach. For simplification to rational integrands, we give a comprehensive list of univariate rationalizing transformations, including transformations tuned to map the interval $[0,1]$ bijectively to itself.",
        "published": "2023-11-28T17:46:57Z",
        "link": "http://arxiv.org/abs/2311.16992v1",
        "categories": [
            "cs.SC",
            "math-ph",
            "math.MP"
        ]
    },
    {
        "title": "${L}^{\\infty}$-norm computation for linear time-invariant systems   depending on parameters",
        "authors": [
            "Alban Quadrat",
            "Fabrice Rouillier",
            "Grace Younes"
        ],
        "summary": "This paper focuses on representing the $L^{\\infty}$-norm of finite-dimensional linear time-invariant systems with parameter-dependent coefficients. Previous studies tackled the problem in a non-parametric scenario by simplifying it to finding the maximum $y$-projection of real solutions $(x, y)$ of a system of the form $\\Sigma=\\{P=0, \\, \\partial P/\\partial x=0\\}$, where $P \\in \\Z[x, y]$. To solve this problem, standard computer algebra methods were employed and analyzed \\cite{bouzidi2021computation}.   In this paper, we extend our approach to address the parametric case. We aim to represent the \"maximal\" $y$-projection of real solutions of $\\Sigma$ as a function of the given parameters. %a set of parameters $\\alpha$. To accomplish this, we utilize cylindrical algebraic decomposition. This method allows us to determine the desired value as a function of the parameters within specific regions of parameter space.",
        "published": "2023-12-01T18:27:40Z",
        "link": "http://arxiv.org/abs/2312.00760v2",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Here Is Not There: Measuring Entailment-Based Trajectory Similarity for   Location-Privacy Protection and Beyond",
        "authors": [
            "Zilong Liu",
            "Krzysztof Janowicz",
            "Kitty Currier",
            "Meilin Shi",
            "Jinmeng Rao",
            "Song Gao",
            "Ling Cai",
            "Anita Graser"
        ],
        "summary": "While the paths humans take play out in social as well as physical space, measures to describe and compare their trajectories are carried out in abstract, typically Euclidean, space. When these measures are applied to trajectories of actual individuals in an application area, alterations that are inconsequential in abstract space may suddenly become problematic once overlaid with geographic reality. In this work, we present a different view on trajectory similarity by introducing a measure that utilizes logical entailment. This is an inferential perspective that considers facts as triple statements deduced from the social and environmental context in which the travel takes place, and their practical implications. We suggest a formalization of entailment-based trajectory similarity, measured as the overlapping proportion of facts, which are spatial relation statements in our case study. With the proposed measure, we evaluate LSTM-TrajGAN, a privacy-preserving trajectory-generation model. The entailment-based model evaluation reveals potential consequences of disregarding the rich structure of geographic space (e.g., miscalculated insurance risk due to regional shifts in our toy example). Our work highlights the advantage of applying logical entailment to trajectory-similarity reasoning for location-privacy protection and beyond.",
        "published": "2023-12-02T14:41:01Z",
        "link": "http://arxiv.org/abs/2312.01151v1",
        "categories": [
            "cs.CY",
            "cs.CL",
            "cs.SC"
        ]
    },
    {
        "title": "Robust Clustering using Hyperdimensional Computing",
        "authors": [
            "Lulu Ge",
            "Keshab K. Parhi"
        ],
        "summary": "This paper addresses the clustering of data in the hyperdimensional computing (HDC) domain. In prior work, an HDC-based clustering framework, referred to as HDCluster, has been proposed. However, the performance of the existing HDCluster is not robust. The performance of HDCluster is degraded as the hypervectors for the clusters are chosen at random during the initialization step. To overcome this bottleneck, we assign the initial cluster hypervectors by exploring the similarity of the encoded data, referred to as \\textit{query} hypervectors. Intra-cluster hypervectors have a higher similarity than inter-cluster hypervectors. Harnessing the similarity results among query hypervectors, this paper proposes four HDC-based clustering algorithms: similarity-based k-means, equal bin-width histogram, equal bin-height histogram, and similarity-based affinity propagation. Experimental results illustrate that: (i) Compared to the existing HDCluster, our proposed HDC-based clustering algorithms can achieve better accuracy, more robust performance, fewer iterations, and less execution time. Similarity-based affinity propagation outperforms the other three HDC-based clustering algorithms on eight datasets by 2~38% in clustering accuracy. (ii) Even for one-pass clustering, i.e., without any iterative update of the cluster hypervectors, our proposed algorithms can provide more robust clustering accuracy than HDCluster. (iii) Over eight datasets, five out of eight can achieve higher or comparable accuracy when projected onto the hyperdimensional space. Traditional clustering is more desirable than HDC when the number of clusters, $k$, is large.",
        "published": "2023-12-05T00:46:29Z",
        "link": "http://arxiv.org/abs/2312.02407v1",
        "categories": [
            "cs.LG",
            "cs.DB",
            "cs.SC"
        ]
    },
    {
        "title": "Physical Symbolic Optimization",
        "authors": [
            "Wassim Tenachi",
            "Rodrigo Ibata",
            "Foivos I. Diakogiannis"
        ],
        "summary": "We present a framework for constraining the automatic sequential generation of equations to obey the rules of dimensional analysis by construction. Combining this approach with reinforcement learning, we built $\\Phi$-SO, a Physical Symbolic Optimization method for recovering analytical functions from physical data leveraging units constraints. Our symbolic regression algorithm achieves state-of-the-art results in contexts in which variables and constants have known physical units, outperforming all other methods on SRBench's Feynman benchmark in the presence of noise (exceeding 0.1%) and showing resilience even in the presence of significant (10%) levels of noise.",
        "published": "2023-12-06T16:56:28Z",
        "link": "http://arxiv.org/abs/2312.03612v1",
        "categories": [
            "cs.LG",
            "astro-ph.IM",
            "cs.SC",
            "physics.comp-ph",
            "physics.data-an"
        ]
    },
    {
        "title": "Learning for CasADi: Data-driven Models in Numerical Optimization",
        "authors": [
            "Tim Salzmann",
            "Jon Arrizabalaga",
            "Joel Andersson",
            "Marco Pavone",
            "Markus Ryll"
        ],
        "summary": "While real-world problems are often challenging to analyze analytically, deep learning excels in modeling complex processes from data. Existing optimization frameworks like CasADi facilitate seamless usage of solvers but face challenges when integrating learned process models into numerical optimizations. To address this gap, we present the Learning for CasADi (L4CasADi) framework, enabling the seamless integration of PyTorch-learned models with CasADi for efficient and potentially hardware-accelerated numerical optimization. The applicability of L4CasADi is demonstrated with two tutorial examples: First, we optimize a fish's trajectory in a turbulent river for energy efficiency where the turbulent flow is represented by a PyTorch model. Second, we demonstrate how an implicit Neural Radiance Field environment representation can be easily leveraged for optimal control with L4CasADi. L4CasADi, along with examples and documentation, is available under MIT license at https://github.com/Tim-Salzmann/l4casadi",
        "published": "2023-12-10T13:03:58Z",
        "link": "http://arxiv.org/abs/2312.05873v1",
        "categories": [
            "eess.SY",
            "cs.AI",
            "cs.LG",
            "cs.RO",
            "cs.SC",
            "cs.SY"
        ]
    },
    {
        "title": "LoKit (revisited): A Toolkit for Building Distributed Collaborative   Applications",
        "authors": [
            "Uwe M. Borghoff"
        ],
        "summary": "LoKit is a toolkit based on the coordination language LO. It allows to build distributed collaborative applications by providing a set of generic tools. This paper briefly introduces the concept of the toolkit, presents a subset of the LoKit tools, and finally demonstrates its power by discussing a sample application built with the toolkit.",
        "published": "2023-12-19T13:31:17Z",
        "link": "http://arxiv.org/abs/2312.12147v1",
        "categories": [
            "cs.PL",
            "cs.SC"
        ]
    },
    {
        "title": "Symbolic Security Verification of Mesh Commissioning Protocol in Thread   (extended version)",
        "authors": [
            "Pankaj Upadhyay",
            "Subodh Sharma",
            "Guangdong Bai"
        ],
        "summary": "The Thread protocol (or simply Thread ) is a popular networking protocol for the Internet of Things (IoT). It allows seamless integration of a set of applications and protocols, hence reducing the risk of incompatibility among different applications or user protocols. Thread has been deployed in many popular smart home products by the majority of IoT manufacturers, such as Apple TV, Apple HomePod mini, eero 6, Nest Hub, and Nest Wifi. Despite a few empirical analyses on the security of Thread, there is still a lack of formal analysis on this infrastructure of the booming IoT ecosystem. In this work, we performed a formal symbolic analysis of the security properties of Thread. Our main focus is on MeshCoP (Mesh Commissioning Protocol), the main subprotocol in Thread for secure authentication and commissioning of new, untrusted devices inside an existing Thread network. This case study presents the challenges and proposed solutions in modeling MeshCoP. We use ProVerif, a symbolic verification tool of {\\pi}-calculus models, for verifying the security properties of MeshCoP.",
        "published": "2023-12-20T12:00:06Z",
        "link": "http://arxiv.org/abs/2312.12958v1",
        "categories": [
            "cs.CR",
            "cs.SC",
            "68Q60",
            "I.6.5"
        ]
    },
    {
        "title": "$p$-adic algorithm for bivariate Gröbner bases",
        "authors": [
            "Eric Schost",
            "Catherine St-Pierre"
        ],
        "summary": "We present a $p$-adic algorithm to recover the lexicographic Gr\\\"obner basis $\\mathcal G$ of an ideal in $\\mathbb Q[x,y]$ with a generating set in $\\mathbb Z[x,y]$, with a complexity that is less than cubic in terms of the dimension of $\\mathbb Q[x,y]/\\langle \\mathcal G \\rangle$ and softly linear in the height of its coefficients. We observe that previous results of Lazard's that use Hermite normal forms to compute Gr\\\"obner bases for ideals with two generators can be generalized to a set of $t\\in \\mathbb N^+$ generators. We use this result to obtain a bound on the height of the coefficients of $\\mathcal G$, and to control the probability of choosing a \\textit{good} prime $p$ to build the $p$-adic expansion of $\\mathcal G$.",
        "published": "2023-12-21T18:40:50Z",
        "link": "http://arxiv.org/abs/2312.14116v1",
        "categories": [
            "math.AC",
            "cs.SC"
        ]
    },
    {
        "title": "An F5 Algorithm for Tropical Gröbner Bases in the Weyl Algebras",
        "authors": [
            "Ari Dwi Hartanto",
            "Katsuyoshi Ohara"
        ],
        "summary": "A Gr\\\"obner basis computation for the Weyl algebra with respect to a tropical term order and by using a homogenization-dehomogenization technique is sufficiently sluggish. A significant number of reductions to zero occur. To improve the computation, a tropical F5 algorithm is developed for this context. As a member of the family of signature-based algorithms, this algorithm keeps track of where Weyl algebra elements come from to anticipate reductions to zero. The total order for ordering module monomials or signatures in this paper is designed as close as possible to the definition of the tropical term order. As in Vaccon et al. (2021), this total order is not compatible with the tropical term order.",
        "published": "2023-12-22T03:54:15Z",
        "link": "http://arxiv.org/abs/2312.14419v1",
        "categories": [
            "cs.SC",
            "math.RA"
        ]
    },
    {
        "title": "Iterated Resultants and Rational Functions in Real Quantifier   Elimination",
        "authors": [
            "James H. Davenport",
            "Matthew England",
            "Scott McCallum",
            "Ali K. Uncu"
        ],
        "summary": "This paper builds and extends on the authors previous work related to the algorithmic tool, Cylindrical Algebraic Decomposition (CAD), and one of its core applications, Real Quantifier Elimination (QE). These topics are at the heart of symbolic computation and were first implemented in computer algebra systems decades ago, but have recently received renewed interest as part of the ongoing development of SMT solvers for non-linear real arithmetic.   First, we consider the use of iterated univariate resultants in traditional CAD, and how this leads to inefficiencies, especially in the case of an input with multiple equational constraints. We reproduce the workshop paper [Davenport \\& England, 2023], adding important clarifications to our suggestions first made there to make use of multivariate resultants in the projection phase of CAD. We then consider an alternative approach to this problem first documented in [McCallum \\& Brown, 2009] which redefines the actual object under construction, albeit only in the case of two equational constraints. We correct an important typo and provide a missing proof in that paper.   We finish by revising the topic of how to deal with SMT or Real QE problems expressed using rational functions (as opposed to the usual polynomial ones) noting that these are often found in industrial applications. We revisit a proposal made in [Uncu, Davenport and England, 2023] for doing this in the case of satisfiability, explaining why such an approach does not trivially extend to more complicated quantification structure and giving a suitable alternative.",
        "published": "2023-12-23T17:32:45Z",
        "link": "http://arxiv.org/abs/2312.16210v1",
        "categories": [
            "cs.SC",
            "math.AG",
            "14W30 (primary) 68W30 (secondary)",
            "I.1.2"
        ]
    },
    {
        "title": "Computing superspecial hyperelliptic curves of genus 4 with automorphism   group properly containing the Klein 4-group",
        "authors": [
            "Ryo Ohashi",
            "Momonari Kudo"
        ],
        "summary": "In algebraic geometry, enumerating or finding superspecial curves in positive characteristic $p$ is important both in theory and in computation. In this paper, we propose feasible algorithms to enumerate or find superspecial hyperelliptic curves of genus $4$ with automorphism group properly containing the Klein $4$-group. Executing the algorithms on Magma, we succeeded in enumerating such superspecial curves for every $p$ with $19 \\leq p < 500$, and in finding a single one for every $p$ with $19 \\leq p < 7000$.",
        "published": "2023-12-28T07:02:07Z",
        "link": "http://arxiv.org/abs/2312.16858v1",
        "categories": [
            "math.AG",
            "cs.SC",
            "math.NT"
        ]
    },
    {
        "title": "Adaptive Flip Graph Algorithm for Matrix Multiplication",
        "authors": [
            "Yamato Arai",
            "Yuma Ichikawa",
            "Koji Hukushima"
        ],
        "summary": "This study proposes the \"adaptive flip graph algorithm\", which combines adaptive searches with the flip graph algorithm for finding fast and efficient methods for matrix multiplication. The adaptive flip graph algorithm addresses the inherent limitations of exploration and inefficient search encountered in the original flip graph algorithm, particularly when dealing with large matrix multiplication. For the limitation of exploration, the proposed algorithm adaptively transitions over the flip graph, introducing a flexibility that does not strictly reduce the number of multiplications. Concerning the issue of inefficient search in large instances, the proposed algorithm adaptively constraints the search range instead of relying on a completely random search, facilitating more effective exploration. Numerical experimental results demonstrate the effectiveness of the adaptive flip graph algorithm, showing a reduction in the number of multiplications for a $4\\times 5$ matrix multiplied by a $5\\times 5$ matrix from $76$ to $73$, and that from $95$ to $94$ for a $5 \\times 5$ matrix multiplied by another $5\\times 5$ matrix. These results are obtained in characteristic two.",
        "published": "2023-12-28T11:05:55Z",
        "link": "http://arxiv.org/abs/2312.16960v2",
        "categories": [
            "cs.SC",
            "cs.DS"
        ]
    },
    {
        "title": "Factoring sparse polynomials fast",
        "authors": [
            "Alexander Demin",
            "Joris van der Hoeven"
        ],
        "summary": "Consider a sparse polynomial in several variables given explicitly as a sum of non-zero terms with coefficients in an effective field. In this paper, we present several algorithms for factoring such polynomials and related tasks (such as gcd computation, square-free factorization, content-free factorization, and root extraction). Our methods are all based on sparse interpolation, but follow two main lines of attack: iteration on the number of variables and more direct reductions to the univariate or bivariate case. We present detailed probabilistic complexity bounds in terms of the complexity of sparse interpolation and evaluation.",
        "published": "2023-12-28T22:06:11Z",
        "link": "http://arxiv.org/abs/2312.17380v1",
        "categories": [
            "cs.SC",
            "math.AC"
        ]
    },
    {
        "title": "Fast interpolation of sparse multivariate polynomials",
        "authors": [
            "Joris van der Hoeven",
            "Grégoire Lecerf"
        ],
        "summary": "Consider a sparse multivariate polynomial f with integer coefficients. Assume that f is represented as a \"modular black box polynomial\", e.g. via an algorithm to evaluate f at arbitrary integer points, modulo arbitrary positive integers. The problem of sparse interpolation is to recover f in its usual sparse representation, as a sum of coefficients times monomials. For the first time we present a quasi-optimal algorithm for this task.",
        "published": "2023-12-29T16:06:31Z",
        "link": "http://arxiv.org/abs/2312.17664v1",
        "categories": [
            "cs.SC",
            "math.AC"
        ]
    },
    {
        "title": "Conditions for eigenvalue configurations of two real symmetric matrices:   a symmetric function approach",
        "authors": [
            "Hoon Hong",
            "Daniel Profili",
            "J. Rafael Sendra"
        ],
        "summary": "For two real symmetric matrices, their eigenvalue configuration is the arrangement of their eigenvalues on the real line. We study the problem of determining a quantifier-free necessary and sufficient condition for two real symmetric matrices to realize a given eigenvalue configuration as a generalization of Descartes' rule of signs. We exploit the combinatorial properties of our definition for eigenvalue configuration to reduce a two-polynomial root counting problem into several single-polynomial root counting problems of symmetric polynomials. We then leverage the fundamental theorem of symmetric polynomials to derive a final quantifier-free necessary and sufficient condition for two real symmetric matrices to realize a given eigenvalue configuration.",
        "published": "2023-12-29T22:18:37Z",
        "link": "http://arxiv.org/abs/2401.00089v2",
        "categories": [
            "math.AG",
            "cs.SC"
        ]
    },
    {
        "title": "Conditions for eigenvalue configurations of two real symmetric matrices:   a signature approach",
        "authors": [
            "Hoon Hong",
            "Daniel Profili",
            "J. Rafael Sendra"
        ],
        "summary": "For two real symmetric matrices, their eigenvalue configuration is the arrangement of their eigenvalues on the real line. In this paper, we provide quantifier-free necessary and sufficient conditions for two symmetric matrices to realize a given eigenvalue configuration. The basic idea is to generate a set of polynomials in the entries of the two matrices whose roots can be counted to uniquely determine the eigenvalue configuration. This result can be seen as ageneralization of Descartes' rule of signs to the case of two real univariate polynomials.",
        "published": "2023-12-29T22:24:29Z",
        "link": "http://arxiv.org/abs/2401.00866v2",
        "categories": [
            "math.AG",
            "cs.SC"
        ]
    },
    {
        "title": "Joint symbolic aggregate approximation of time series",
        "authors": [
            "Xinye Chen"
        ],
        "summary": "The increasing availability of temporal data poses a challenge to time-series and signal-processing domains due to its high numerosity and complexity. Symbolic representation outperforms raw data in a variety of engineering applications due to its storage efficiency, reduced numerosity, and noise reduction. The most recent symbolic aggregate approximation technique called ABBA demonstrates outstanding performance in preserving essential shape information of time series and enhancing the downstream applications. However, ABBA cannot handle multiple time series with consistent symbols, i.e., the same symbols from distinct time series are not identical. Also, working with appropriate ABBA digitization involves the tedious task of tuning the hyperparameters, such as the number of symbols or tolerance. Therefore, we present a joint symbolic aggregate approximation that has symbolic consistency, and show how the hyperparameter of digitization can itself be optimized alongside the compression tolerance ahead of time. Besides, we propose a novel computing paradigm that enables parallel computing of symbolic approximation. The extensive experiments demonstrate its superb performance and outstanding speed regarding symbolic approximation and reconstruction.",
        "published": "2023-12-30T01:16:22Z",
        "link": "http://arxiv.org/abs/2401.00109v2",
        "categories": [
            "cs.DS",
            "cs.DB",
            "cs.DC",
            "cs.SC"
        ]
    },
    {
        "title": "Hypergeometric-Type Sequences",
        "authors": [
            "Bertrand Teguia Tabuguia"
        ],
        "summary": "We introduce hypergeometric-type sequences. They are linear combinations of interlaced hypergeometric sequences (of arbitrary interlacements). We prove that they form a subring of the ring of holonomic sequences. An interesting family of sequences in this class are those defined by trigonometric functions with linear arguments in the index and $\\pi$, such as Chebyshev polynomials, $\\left(\\sin^2\\left(n\\,\\pi/4\\right)\\cdot\\cos\\left(n\\,\\pi/6\\right)\\right)_n$, and compositions like $\\left(\\sin\\left(\\cos(n\\pi/3)\\pi\\right)\\right)_n$.   We describe an algorithm that computes a hypergeometric-type normal form of a given holonomic $n\\text{th}$ term whenever it exists. Our implementation enables us to generate several identities for terms defined via trigonometric functions.",
        "published": "2023-12-30T15:00:54Z",
        "link": "http://arxiv.org/abs/2401.00256v2",
        "categories": [
            "cs.SC",
            "cs.DM",
            "33F10, 39A06 (Primary), 68R01, 05A19 (Secondary)",
            "I.1.1; I.1.2; G.2.1; G.4"
        ]
    },
    {
        "title": "Computing greatest common divisor of several parametric univariate   polynomials via generalized subresultant polynomials",
        "authors": [
            "Hoon Hong",
            "Jing Yang"
        ],
        "summary": "In this paper, we tackle the following problem: compute the gcd for several univariate polynomials with parametric coefficients. It amounts to partitioning the parameter space into ``cells'' so that the gcd has a uniform expression over each cell and constructing a uniform expression of gcd in each cell. We tackle the problem as follows. We begin by making a natural and obvious extension of subresultant polynomials of two polynomials to several polynomials. Then we develop the following structural theories about them.   1. We generalize Sylvester's theory to several polynomials, in order to obtain an elegant relationship between generalized subresultant polynomials and the gcd of several polynomials, yielding an elegant algorithm.   2. We generalize Habicht's theory to several polynomials, in order to obtain a systematic relationship between generalized subresultant polynomials and pseudo-remainders, yielding an efficient algorithm.   Using the generalized theories, we present a simple (structurally elegant) algorithm which is significantly more efficient (both in the output size and computing time) than algorithms based on previous approaches.",
        "published": "2023-12-31T06:32:54Z",
        "link": "http://arxiv.org/abs/2401.00408v2",
        "categories": [
            "cs.SC"
        ]
    }
]