[
    {
        "title": "Single-Bit Consensus with Finite-Time Convergence: Theory and   Applications",
        "authors": [
            "Mohammadreza Doostmohammadian"
        ],
        "summary": "In this brief paper, a new consensus protocol based on the sign of innovations is proposed. Based on this protocol each agent only requires single-bit of information about its relative state to its neighboring agents. This is significant in real-time applications, since it requires less computation and/or communication load on agents. Using Lyapunov stability theorem the convergence is proved for networks having a spanning tree. Further, the convergence is shown to be in finite-time, which is significant as compared to most asymptotic protocols in the literature. Time-variant network topologies are also considered in this paper, and final consensus value is derived for undirected networks. Applications of the proposed consensus protocol in (i) 2D/3D rendezvous task, (ii) distributed estimation, (iii) distributed optimization, and (iv) formation control are considered and significance of applying this protocol is discussed. Numerical simulations are provided to compare the protocol with the existing protocols in the literature.",
        "published": "2020-01-01T05:09:29Z",
        "link": "http://arxiv.org/abs/2001.00141v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "From Drinking Philosophers to Asynchronous Path-Following Robots",
        "authors": [
            "Yunus Emre Sahin",
            "Necmiye Ozay"
        ],
        "summary": "In this paper, we consider the multi-robot path execution problem where a group of robots move on predefined paths from their initial to target positions while avoiding collisions and deadlocks in the face of asynchrony. We first show that this problem can be reformulated as a distributed resource allocation problem and, in particular, as an instance of the well-known Drinking Philosophers Problem (DrPP). By careful construction of the drinking sessions capturing shared resources, we show that any existing solutions to DrPP can be used to design robot control policies that are collectively collision and deadlock-free. We then propose modifications to an existing DrPP algorithm to allow more concurrent behavior, and provide conditions under which our method is deadlock-free. Our method does not require robots to know or to estimate the speed profiles of other robots and results in distributed control policies. We demonstrate the efficacy of our method on simulation examples, which show competitive performance against the state-of-the-art.",
        "published": "2020-01-02T13:59:26Z",
        "link": "http://arxiv.org/abs/2001.00440v2",
        "categories": [
            "cs.RO",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Open Challenges and Issues: Artificial Intelligence for Transactive   Management",
        "authors": [
            "Asma Khatun",
            "Sk. Golam Sarowar Hossain"
        ],
        "summary": "The advancement of Artificial Intelligence (AI) has improved the automation of energy managements. In smart energy management or in a smart grid framework, all the devices and the distributed resources and renewable resources are embedded which leads to reduce cost. A smart energy management system, Transactive management (TM) is a concept to improve the efficiency and reliability of the power system. The aim of this article is to look for the current development of TM methods based on AI and Machine Learning (ML) technology. In AI paradigm, MultiAgent System (MAS) based method is an active research area and are still in evolution. Hence this article describes how MAS based method applied in TM. This paper also finds that MAS based method faces major difficulty to design or set up goal to various agents and describes how ML technique can contribute to that solution. A brief comparison analysis between MAS and ML techniques are also presented. At the end, this article summarizes the most relevant open challenges and issues on the AI based methods for transactive energy management.",
        "published": "2020-01-02T17:33:07Z",
        "link": "http://arxiv.org/abs/2001.03238v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Toward Optimal Adversarial Policies in the Multiplicative Learning   System with a Malicious Expert",
        "authors": [
            "S. Rasoul Etesami",
            "Negar Kiyavash",
            "Vincent Leon",
            "H. Vincent Poor"
        ],
        "summary": "We consider a learning system based on the conventional multiplicative weight (MW) rule that combines experts' advice to predict a sequence of true outcomes. It is assumed that one of the experts is malicious and aims to impose the maximum loss on the system. The loss of the system is naturally defined to be the aggregate absolute difference between the sequence of predicted outcomes and the true outcomes. We consider this problem under both offline and online settings. In the offline setting where the malicious expert must choose its entire sequence of decisions a priori, we show somewhat surprisingly that a simple greedy policy of always reporting false prediction is asymptotically optimal with an approximation ratio of $1+O(\\sqrt{\\frac{\\ln N}{N}})$, where $N$ is the total number of prediction stages. In particular, we describe a policy that closely resembles the structure of the optimal offline policy. For the online setting where the malicious expert can adaptively make its decisions, we show that the optimal online policy can be efficiently computed by solving a dynamic program in $O(N^3)$. Our results provide a new direction for vulnerability assessment of commonly used learning algorithms to adversarial attacks where the threat is an integral part of the system.",
        "published": "2020-01-02T18:04:46Z",
        "link": "http://arxiv.org/abs/2001.00543v2",
        "categories": [
            "cs.LG",
            "cs.CR",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Vehicle Platooning Impact on Drag Coefficients and Energy/Fuel Saving   Implications",
        "authors": [
            "Ahmed A. Hussein",
            "Hesham A. Rakha"
        ],
        "summary": "In this paper, empirical data from the literature are used to develop general power models that capture the impact of a vehicle position, in a platoon of homogeneous vehicles, and the distance gap to its lead (and following) vehicle on its drag coefficient. These models are developed for light duty vehicles, buses, and heavy duty trucks. The models were fit using a constrained optimization framework to fit a general power function using either direct drag force or fuel measurements. The model is then used to extrapolate the empirical measurements to a wide range of vehicle distance gaps within a platoon. Using these models we estimate the potential fuel reduction associated with homogeneous platoons of light duty vehicles, buses, and heavy duty trucks. The results show a significant reduction in the vehicle fuel consumption when compared with those based on a constant drag coefficient assumption. Specifically, considering a minimum time gap between vehicles of $0.5 \\; secs$ (which is typical considering state-of-practice communication and mechanical system latencies) running at a speed of $100 \\; km/hr$, the optimum fuel reduction that is achieved is $4.5 \\%$, $15.5 \\%$, and $7.0 \\%$ for light duty vehicle, bus, and heavy duty truck platoons, respectively. For longer time gaps, the bus and heavy duty truck platoons still produce fuel reductions in the order of $9.0 \\%$ and $4.5 \\%$, whereas light duty vehicles produce negligible fuel savings.",
        "published": "2020-01-02T18:53:07Z",
        "link": "http://arxiv.org/abs/2001.00560v2",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Let's Share: A Game-Theoretic Framework for Resource Sharing in Mobile   Edge Clouds",
        "authors": [
            "Faheem Zafari",
            "Kin K. Leung",
            "Don Towsley",
            "Prithwish Basu",
            "Ananthram Swami",
            "Jian Li"
        ],
        "summary": "Mobile edge computing seeks to provide resources to different delay-sensitive applications. This is a challenging problem as an edge cloud-service provider may not have sufficient resources to satisfy all resource requests. Furthermore, allocating available resources optimally to different applications is also challenging. Resource sharing among different edge cloud-service providers can address the aforementioned limitation as certain service providers may have resources available that can be ``rented'' by other service providers. However, edge cloud service providers can have different objectives or \\emph{utilities}. Therefore, there is a need for an efficient and effective mechanism to share resources among service providers, while considering the different objectives of various providers. We model resource sharing as a multi-objective optimization problem and present a solution framework based on \\emph{Cooperative Game Theory} (CGT). We consider the strategy where each service provider allocates resources to its native applications first and shares the remaining resources with applications from other service providers. We prove that for a monotonic, non-decreasing utility function, the game is canonical and convex. Hence, the \\emph{core} is not empty and the grand coalition is stable. We propose two algorithms \\emph{Game-theoretic Pareto optimal allocation} (GPOA) and \\emph{Polyandrous-Polygamous Matching based Pareto Optimal Allocation} (PPMPOA) that provide allocations from the core. Hence the obtained allocations are \\emph{Pareto} optimal and the grand coalition of all the service providers is stable. Experimental results confirm that our proposed resource sharing framework improves utilities of edge cloud-service providers and application request satisfaction.",
        "published": "2020-01-02T18:58:26Z",
        "link": "http://arxiv.org/abs/2001.00567v1",
        "categories": [
            "cs.NI",
            "cs.DC",
            "cs.MA"
        ]
    },
    {
        "title": "Intelligent Roundabout Insertion using Deep Reinforcement Learning",
        "authors": [
            "Alessandro Paolo Capasso",
            "Giulio Bacchiani",
            "Daniele Molinari"
        ],
        "summary": "An important topic in the autonomous driving research is the development of maneuver planning systems. Vehicles have to interact and negotiate with each other so that optimal choices, in terms of time and safety, are taken. For this purpose, we present a maneuver planning module able to negotiate the entering in busy roundabouts. The proposed module is based on a neural network trained to predict when and how entering the roundabout throughout the whole duration of the maneuver. Our model is trained with a novel implementation of A3C, which we will call Delayed A3C (D-A3C), in a synthetic environment where vehicles move in a realistic manner with interaction capabilities. In addition, the system is trained such that agents feature a unique tunable behavior, emulating real world scenarios where drivers have their own driving styles. Similarly, the maneuver can be performed using different aggressiveness levels, which is particularly useful to manage busy scenarios where conservative rule-based policies would result in undefined waits.",
        "published": "2020-01-03T11:16:41Z",
        "link": "http://arxiv.org/abs/2001.00786v3",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Selfish Algorithm and Emergence of Collective Intelligence",
        "authors": [
            "Korosh Mahmoodi",
            "Bruce J. West",
            "Cleotilde Gonzalez"
        ],
        "summary": "We propose a model for demonstrating spontaneous emergence of collective intelligent behavior from selfish individual agents. Agents' behavior is modeled using our proposed selfish algorithm ($SA$) with three learning mechanisms: reinforced learning ($SAL$), trust ($SAT$) and connection ($SAC$). Each of these mechanisms provides a distinctly different way an agent can increase the individual benefit accrued through playing the prisoner's dilemma game ($PDG$) with other agents. The $SA$ provides a generalization of the self-organized temporal criticality ($SOTC$) model and shows that self-interested individuals can simultaneously produce maximum social benefit from their decisions. The mechanisms in the $SA$ are self-tuned by the internal dynamics and without having a pre-established network structure. Our results demonstrate emergence of mutual cooperation, emergence of dynamic networks, and adaptation and resilience of social systems after perturbations. The implications and applications of the $SA$ are discussed.",
        "published": "2020-01-03T17:42:26Z",
        "link": "http://arxiv.org/abs/2001.00907v1",
        "categories": [
            "nlin.AO",
            "cs.MA"
        ]
    },
    {
        "title": "Represented Value Function Approach for Large Scale Multi Agent   Reinforcement Learning",
        "authors": [
            "Weiya Ren"
        ],
        "summary": "In this paper, we consider the problem of large scale multi agent reinforcement learning. Firstly, we studied the representation problem of the pairwise value function to reduce the complexity of the interactions among agents. Secondly, we adopt a l2-norm trick to ensure the trivial term of the approximated value function is bounded. Thirdly, experimental results on battle game demonstrate the effectiveness of the proposed approach.",
        "published": "2020-01-04T16:29:13Z",
        "link": "http://arxiv.org/abs/2001.01096v2",
        "categories": [
            "cs.LG",
            "cs.CV",
            "cs.MA"
        ]
    },
    {
        "title": "Multi-Agent Interactions Modeling with Correlated Policies",
        "authors": [
            "Minghuan Liu",
            "Ming Zhou",
            "Weinan Zhang",
            "Yuzheng Zhuang",
            "Jun Wang",
            "Wulong Liu",
            "Yong Yu"
        ],
        "summary": "In multi-agent systems, complex interacting behaviors arise due to the high correlations among agents. However, previous work on modeling multi-agent interactions from demonstrations is primarily constrained by assuming the independence among policies and their reward structures. In this paper, we cast the multi-agent interactions modeling problem into a multi-agent imitation learning framework with explicit modeling of correlated policies by approximating opponents' policies, which can recover agents' policies that can regenerate similar interactions. Consequently, we develop a Decentralized Adversarial Imitation Learning algorithm with Correlated policies (CoDAIL), which allows for decentralized training and execution. Various experiments demonstrate that CoDAIL can better regenerate complex interactions close to the demonstrators and outperforms state-of-the-art multi-agent imitation learning methods. Our code is available at \\url{https://github.com/apexrl/CoDAIL}.",
        "published": "2020-01-04T17:31:53Z",
        "link": "http://arxiv.org/abs/2001.03415v3",
        "categories": [
            "cs.MA",
            "cs.LG"
        ]
    },
    {
        "title": "Context-Aware Design of Cyber-Physical Human Systems (CPHS)",
        "authors": [
            "Supratik Mukhopadhyay",
            "Qun Liu",
            "Edward Collier",
            "Yimin Zhu",
            "Ravindra Gudishala",
            "Chanachok Chokwitthaya",
            "Robert DiBiano",
            "Alimire Nabijiang",
            "Sanaz Saeidi",
            "Subhajit Sidhanta",
            "Arnab Ganguly"
        ],
        "summary": "Recently, it has been widely accepted by the research community that interactions between humans and cyber-physical infrastructures have played a significant role in determining the performance of the latter. The existing paradigm for designing cyber-physical systems for optimal performance focuses on developing models based on historical data. The impacts of context factors driving human system interaction are challenging and are difficult to capture and replicate in existing design models. As a result, many existing models do not or only partially address those context factors of a new design owing to the lack of capabilities to capture the context factors. This limitation in many existing models often causes performance gaps between predicted and measured results. We envision a new design environment, a cyber-physical human system (CPHS) where decision-making processes for physical infrastructures under design are intelligently connected to distributed resources over cyberinfrastructure such as experiments on design features and empirical evidence from operations of existing instances. The framework combines existing design models with context-aware design-specific data involving human-infrastructure interactions in new designs, using a machine learning approach to create augmented design models with improved predictive powers.",
        "published": "2020-01-07T07:31:36Z",
        "link": "http://arxiv.org/abs/2001.01918v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Multitask learning over graphs: An Approach for Distributed, Streaming   Machine Learning",
        "authors": [
            "Roula Nassif",
            "Stefan Vlaski",
            "Cedric Richard",
            "Jie Chen",
            "Ali H. Sayed"
        ],
        "summary": "The problem of learning simultaneously several related tasks has received considerable attention in several domains, especially in machine learning with the so-called multitask learning problem or learning to learn problem [1], [2]. Multitask learning is an approach to inductive transfer learning (using what is learned for one problem to assist in another problem) and helps improve generalization performance relative to learning each task separately by using the domain information contained in the training signals of related tasks as an inductive bias. Several strategies have been derived within this community under the assumption that all data are available beforehand at a fusion center. However, recent years have witnessed an increasing ability to collect data in a distributed and streaming manner. This requires the design of new strategies for learning jointly multiple tasks from streaming data over distributed (or networked) systems. This article provides an overview of multitask strategies for learning and adaptation over networks. The working hypothesis for these strategies is that agents are allowed to cooperate with each other in order to learn distinct, though related tasks. The article shows how cooperation steers the network limiting point and how different cooperation rules allow to promote different task relatedness models. It also explains how and when cooperation over multitask networks outperforms non-cooperative strategies.",
        "published": "2020-01-07T15:32:57Z",
        "link": "http://arxiv.org/abs/2001.02112v2",
        "categories": [
            "eess.SP",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Coordination of Autonomous Vehicles: Taxonomy and Survey",
        "authors": [
            "Stefano Mariani",
            "Giacomo Cabri",
            "Franco Zambonelli"
        ],
        "summary": "In the near future, our streets will be populated by myriads of autonomous self-driving vehicles to serve our diverse mobility needs. This will raise the need to coordinate their movements in order to properly handle both access to shared resources (e.g., intersections and parking slots) and the execution of mobility tasks (e.g., platooning and ramp merging). In this paper, we firstly introduce the general issues associated to coordination of autonomous vehicles, by identifying and framing the key classes of coordination problems. Following, we overview the different approaches that can be adopted to manage such coordination problems, by classifying them in terms of the degree of autonomy in decision making that is left to autonomous vehicles during coordination. Finally, we overview some further peculiar challenges that research will have to address before autonomously coordinated vehicles can safely hit our streets.",
        "published": "2020-01-08T10:47:47Z",
        "link": "http://arxiv.org/abs/2001.02443v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Evidence Based Decision Making in Blockchain Economic Systems: From   Theory to Practice",
        "authors": [
            "Marek Laskowski",
            "Michael Zargham",
            "Hjalmar Turesson",
            "Matt Barlin",
            "Danil Kabanov",
            "Eden Dhaliwal"
        ],
        "summary": "We present a methodology for evidence based design of cryptoeconomic systems, and elucidate a real-world example of how this methodology was used in the design of a blockchain network. This work provides a rare insight into the application of Data Science and Stochastic Simulation and Modelling to Token Engineering. We demonstrate how the described process has the ability to uncover previously unexpected system level behaviors. Furthermore, it is observed that the process itself creates opportunities for the discovery of new knowledge and business understanding while developing the system from a high level specification to one precise enough to be executed as a computational model. Discovery of performance issues during design time can spare costly emergency interventions that would be necessary if issues instead became apparent in a production network. For this reason, network designers are increasingly adopting evidence-based design practices, such as the one described herein.",
        "published": "2020-01-08T12:47:43Z",
        "link": "http://arxiv.org/abs/2001.03020v2",
        "categories": [
            "cs.CR",
            "cs.MA"
        ]
    },
    {
        "title": "Multirobot Coverage of Linear Modular Environments",
        "authors": [
            "Mirko Salaris",
            "Alessandro Riva",
            "Francesco Amigoni"
        ],
        "summary": "Multirobot systems for covering environments are increasingly used in applications like cleaning, industrial inspection, patrolling, and precision agriculture. The problem of covering a given environment using multiple robots can be naturally formulated and studied as a multi-Traveling Salesperson Problem (mTSP). In a mTSP, the environment is represented as a graph and the goal is to find tours (starting and ending at the same depot) for the robots in order to visit all the vertices with minimum global cost, namely the length of the longest tour. The mTSP is an NP-hard problem for which several approximation algorithms have been proposed. These algorithms usually assume generic environments, but tighter approximation bounds can be reached focusing on specific environments. In this paper, we address the case of environments composed of sub-parts, called modules, that can be reached from each other only through some linking structures. Examples are multi-floor buildings, in which the modules are the floors and the linking structures are the staircases or the elevators, and floors of large hotels or hospitals, in which the modules are the rooms and the linking structures are the corridors. We focus on linear modular environments, with the modules organized sequentially, presenting an efficient (with polynomial worst-case time complexity) algorithm that finds a solution for the mTSP whose cost is within a bounded distance from the cost of the optimal solution. The main idea of our algorithm is to allocate disjoint \"blocks\" of adjacent modules to the robots, in such a way that each module is covered by only one robot. We experimentally compare our algorithm against some state-of-the-art algorithms for solving mTSPs in generic environments and show that it is able to provide solutions with lower makespan and spending a computing time several orders of magnitude shorter.",
        "published": "2020-01-09T10:03:24Z",
        "link": "http://arxiv.org/abs/2001.02906v1",
        "categories": [
            "cs.MA",
            "cs.RO",
            "I.2.11; I.2.9"
        ]
    },
    {
        "title": "A Generalization of Teo and Sethuraman's Median Stable Marriage Theorem",
        "authors": [
            "Vijay K. Garg"
        ],
        "summary": "Let $L$ be any finite distributive lattice and $B$ be any boolean predicate defined on $L$ such that the set of elements satisfying $B$ is a sublattice of $L$. Consider any subset $M$ of $L$ of size $k$ of elements of $L$ that satisfy $B$. Then, we show that $k$ generalized median elements generated from $M$ also satisfy $B$. We call this result generalized median theorem on finite distributive lattices. When this result is applied to the stable matching, we get Teo and Sethuraman's median stable matching theorem. Our proof is much simpler than that of Teo and Sethuraman. When the generalized median theorem is applied to the assignment problem, we get an analogous result for market clearing price vectors.",
        "published": "2020-01-09T17:51:32Z",
        "link": "http://arxiv.org/abs/2001.03133v1",
        "categories": [
            "cs.DM",
            "cs.MA"
        ]
    },
    {
        "title": "Decentralized Optimization of Vehicle Route Planning -- A Cross-City   Comparative Study",
        "authors": [
            "Brionna Davis",
            "Grace Jennings",
            "Taylor Pothast",
            "Ilias Gerostathopoulos",
            "Evangelos Pournaras",
            "Raphael E. Stern"
        ],
        "summary": "New mobility concepts are at the forefront of research and innovation in smart cities. The introduction of connected and autonomous vehicles enables new possibilities in vehicle routing. Specifically, knowing the origin and destination of each agent in the network can allow for real-time routing of the vehicles to optimize network performance. However, this relies on individual vehicles being \"altruistic\" i.e., being willing to accept an alternative non-preferred route in order to achieve a network-level performance goal. In this work, we conduct a study to compare different levels of agent altruism and the resulting effect on the network-level traffic performance. Specifically, this study compares the effects of different underlying urban structures on the overall network performance, and investigates which characteristics of the network make it possible to realize routing improvements using a decentralized optimization router. The main finding is that, with increased vehicle altruism, it is possible to balance traffic flow among the links of the network. We show evidence that the decentralized optimization router is more effective with networks of high load while we study the influence of cities characteristics, in particular: networks with a higher number of nodes (intersections) or edges (roads) per unit area allow for more possible alternate routes, and thus higher potential to improve network performance.",
        "published": "2020-01-10T11:02:51Z",
        "link": "http://arxiv.org/abs/2001.03384v1",
        "categories": [
            "eess.SY",
            "cs.AI",
            "cs.DC",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "A Policy-oriented Agent-based Model of Recruitment into Organized Crime",
        "authors": [
            "Gian Maria Campedelli",
            "Francesco Calderoni",
            "Mario Paolucci",
            "Tommaso Comunale",
            "Daniele Vilone",
            "Federico Cecconi",
            "Giulia Andrighetto"
        ],
        "summary": "Criminal organizations exploit their presence on territories and local communities to recruit new workforce in order to carry out their criminal activities and business. The ability to attract individuals is crucial for maintaining power and control over the territories in which these groups are settled. This study proposes the formalization, development and analysis of an agent-based model (ABM) that simulates a neighborhood of Palermo (Sicily) with the aim to understand the pathways that lead individuals to recruitment into organized crime groups (OCGs). Using empirical data on social, economic and criminal conditions of the area under analysis, we use a multi-layer network approach to simulate this scenario. As the final goal, we test different policies to counter recruitment into OCGs. These scenarios are based on two different dimensions of prevention and intervention: (i) primary and secondary socialization and (ii) law enforcement targeting strategies.",
        "published": "2020-01-10T15:06:52Z",
        "link": "http://arxiv.org/abs/2001.03494v1",
        "categories": [
            "cs.MA",
            "cs.CY",
            "cs.SI",
            "nlin.CD"
        ]
    },
    {
        "title": "Resource Sharing in the Edge: A Distributed Bargaining-Theoretic   Approach",
        "authors": [
            "Faheem Zafari",
            "Prithwish Basu",
            "Kin K. Leung",
            "Jian Li",
            "Ananthram Swami",
            "Don Towsley"
        ],
        "summary": "The growing demand for edge computing resources, particularly due to increasing popularity of Internet of Things (IoT), and distributed machine/deep learning applications poses a significant challenge. On the one hand, certain edge service providers (ESPs) may not have sufficient resources to satisfy their applications according to the associated service-level agreements. On the other hand, some ESPs may have additional unused resources. In this paper, we propose a resource-sharing framework that allows different ESPs to optimally utilize their resources and improve the satisfaction level of applications subject to constraints such as communication cost for sharing resources across ESPs. Our framework considers that different ESPs have their own objectives for utilizing their resources, thus resulting in a multi-objective optimization problem. We present an $N$-person \\emph{Nash Bargaining Solution} (NBS) for resource allocation and sharing among ESPs with \\emph{Pareto} optimality guarantee. Furthermore, we propose a \\emph{distributed}, primal-dual algorithm to obtain the NBS by proving that the strong-duality property holds for the resultant resource sharing optimization problem.   Using synthetic and real-world data traces, we show numerically that the proposed NBS based framework not only enhances the ability to satisfy applications' resource demands, but also improves utilities of different ESPs.",
        "published": "2020-01-13T13:26:05Z",
        "link": "http://arxiv.org/abs/2001.04229v3",
        "categories": [
            "cs.GT",
            "cs.DC",
            "cs.MA",
            "cs.NI"
        ]
    },
    {
        "title": "Dynamic Radar Network of UAVs: A Joint Navigation and Tracking Approach",
        "authors": [
            "Anna Guerra",
            "Davide Dardari",
            "Petar M. Djuric"
        ],
        "summary": "Nowadays there is a growing research interest on the possibility of enriching small flying robots with autonomous sensing and online navigation capabilities. This will enable a large number of applications spanning from remote surveillance to logistics, smarter cities and emergency aid in hazardous environments. In this context, an emerging problem is to track unauthorized small unmanned aerial vehicles (UAVs) hiding behind buildings or concealing in large UAV networks. In contrast with current solutions mainly based on static and on-ground radars, this paper proposes the idea of a dynamic radar network of UAVs for real-time and high-accuracy tracking of malicious targets. To this end, we describe a solution for real-time navigation of UAVs to track a dynamic target using heterogeneously sensed information. Such information is shared by the UAVs with their neighbors via multi-hops, allowing tracking the target by a local Bayesian estimator running at each agent. Since not all the paths are equal in terms of information gathering point-of-view, the UAVs plan their own trajectory by minimizing the posterior covariance matrix of the target state under UAV kinematic and anti-collision constraints. Our results show how a dynamic network of radars attains better localization results compared to a fixed configuration and how the on-board sensor technology impacts the accuracy in tracking a target with different radar cross sections, especially in non line-of-sight (NLOS) situations.",
        "published": "2020-01-13T23:23:09Z",
        "link": "http://arxiv.org/abs/2001.04560v1",
        "categories": [
            "cs.IT",
            "cs.LG",
            "cs.MA",
            "math.IT"
        ]
    },
    {
        "title": "Smooth markets: A basic mechanism for organizing gradient-based learners",
        "authors": [
            "David Balduzzi",
            "Wojciech M Czarnecki",
            "Thomas W Anthony",
            "Ian M Gemp",
            "Edward Hughes",
            "Joel Z Leibo",
            "Georgios Piliouras",
            "Thore Graepel"
        ],
        "summary": "With the success of modern machine learning, it is becoming increasingly important to understand and control how learning algorithms interact. Unfortunately, negative results from game theory show there is little hope of understanding or controlling general n-player games. We therefore introduce smooth markets (SM-games), a class of n-player games with pairwise zero sum interactions. SM-games codify a common design pattern in machine learning that includes (some) GANs, adversarial training, and other recent algorithms. We show that SM-games are amenable to analysis and optimization using first-order methods.",
        "published": "2020-01-14T09:19:39Z",
        "link": "http://arxiv.org/abs/2001.04678v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.GT",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Pose-Assisted Multi-Camera Collaboration for Active Object Tracking",
        "authors": [
            "Jing Li",
            "Jing Xu",
            "Fangwei Zhong",
            "Xiangyu Kong",
            "Yu Qiao",
            "Yizhou Wang"
        ],
        "summary": "Active Object Tracking (AOT) is crucial to many visionbased applications, e.g., mobile robot, intelligent surveillance. However, there are a number of challenges when deploying active tracking in complex scenarios, e.g., target is frequently occluded by obstacles. In this paper, we extend the single-camera AOT to a multi-camera setting, where cameras tracking a target in a collaborative fashion. To achieve effective collaboration among cameras, we propose a novel Pose-Assisted Multi-Camera Collaboration System, which enables a camera to cooperate with the others by sharing camera poses for active object tracking. In the system, each camera is equipped with two controllers and a switcher: The vision-based controller tracks targets based on observed images. The pose-based controller moves the camera in accordance to the poses of the other cameras. At each step, the switcher decides which action to take from the two controllers according to the visibility of the target. The experimental results demonstrate that our system outperforms all the baselines and is capable of generalizing to unseen environments. The code and demo videos are available on our website https://sites.google.com/view/pose-assistedcollaboration.",
        "published": "2020-01-15T07:49:49Z",
        "link": "http://arxiv.org/abs/2001.05161v1",
        "categories": [
            "cs.CV",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Distributed Artificial Intelligence Solution for D2D Communication in 5G   Networks",
        "authors": [
            "Iacovos Ioannou",
            "Vasos Vassiliou",
            "Christophoros Christophorou",
            "Andreas Pitsillides"
        ],
        "summary": "Device to Device (D2D) Communication is one of the technology components of the evolving 5G architecture, as it promises improvements in energy efficiency, spectral efficiency, overall system capacity, and higher data rates. The above noted improvements in network performance spearheaded a vast amount of research in D2D, which have identified significant challenges that need to be addressed before realizing their full potential in emerging 5G Networks. Towards this end, this paper proposes the use of a distributed intelligent approach to control the generation of D2D networks. More precisely, the proposed approach uses Belief-Desire-Intention (BDI) intelligent agents with extended capabilities (BDIx) to manage each D2D node independently and autonomously, without the help of the Base Station. The paper includes detailed algorithmic description for the decision of transmission mode, which maximizes the data rate, minimizes the power consumptions, while taking into consideration the computational load. Simulations show the applicability of BDI agents in jointly solving D2D challenges.",
        "published": "2020-01-15T11:02:58Z",
        "link": "http://arxiv.org/abs/2001.05232v2",
        "categories": [
            "cs.NI",
            "cs.MA"
        ]
    },
    {
        "title": "Safe Voting: Resilience to Abstention and Sybils",
        "authors": [
            "Reshef Meir",
            "Gal Shahaf",
            "Ehud Shapiro",
            "Nimrod Talmon"
        ],
        "summary": "Voting rules may implement the will of the society when all eligible voters vote, and only them. However, they may fail to do so when sybil (fake or duplicate) votes are present and when only some honest (non sybil) voters actively participate. As, unfortunately, sometimes this is the case, our aim here is to address social choice in the presence of sybils and voter abstention. To do so we build upon the framework of Reality-aware Social Choice: we assume the status-quo as an ever-present distinguished alternative, and study Status-Quo Enforcing voting rules, which add virtual votes in support of the status-quo. We characterize the tradeoff between safety and liveness (the ability of active honest voters to maintain/change the status-quo, respectively) in several domains, and show that the Status-Quo Enforcing voting rules are often optimal. We comment on the applicability of our methods and analyses to the governance of digital communities.",
        "published": "2020-01-15T12:31:32Z",
        "link": "http://arxiv.org/abs/2001.05271v3",
        "categories": [
            "cs.MA",
            "cs.SI"
        ]
    },
    {
        "title": "Model-based Multi-Agent Reinforcement Learning with Cooperative   Prioritized Sweeping",
        "authors": [
            "Eugenio Bargiacchi",
            "Timothy Verstraeten",
            "Diederik M. Roijers",
            "Ann Nowé"
        ],
        "summary": "We present a new model-based reinforcement learning algorithm, Cooperative Prioritized Sweeping, for efficient learning in multi-agent Markov decision processes. The algorithm allows for sample-efficient learning on large problems by exploiting a factorization to approximate the value function. Our approach only requires knowledge about the structure of the problem in the form of a dynamic decision network. Using this information, our method learns a model of the environment and performs temporal difference updates which affect multiple joint states and actions at once. Batch updates are additionally performed which efficiently back-propagate knowledge throughout the factored Q-function. Our method outperforms the state-of-the-art algorithm sparse cooperative Q-learning algorithm, both on the well-known SysAdmin benchmark and randomized environments.",
        "published": "2020-01-15T19:13:44Z",
        "link": "http://arxiv.org/abs/2001.07527v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Optimal by Design: Model-Driven Synthesis of Adaptation Strategies for   Autonomous Systems",
        "authors": [
            "Yehia Elrakaiby",
            "Paola Spoletini",
            "Bashar Nuseibeh"
        ],
        "summary": "Many software systems have become too large and complex to be managed efficiently by human administrators, particularly when they operate in uncertain and dynamic environments and require frequent changes. Requirements-driven adaptation techniques have been proposed to endow systems with the necessary means to autonomously decide ways to satisfy their requirements. However, many current approaches rely on general-purpose languages, models and/or frameworks to design, develop and analyze autonomous systems. Unfortunately, these tools are not tailored towards the characteristics of adaptation problems in autonomous systems. In this paper, we present Optimal by Design (ObD ), a framework for model-based requirements-driven synthesis of optimal adaptation strategies for autonomous systems. ObD proposes a model (and a language) for the high-level description of the basic elements of self-adaptive systems, namely the system, capabilities, requirements and environment. Based on those elements, a Markov Decision Process (MDP) is constructed to compute the optimal strategy or the most rewarding system behaviour. Furthermore, this defines a reflex controller that can ensure timely responses to changes. One novel feature of the framework is that it benefits both from goal-oriented techniques, developed for requirement elicitation, refinement and analysis, and synthesis capabilities and extensive research around MDPs, their extensions and tools. Our preliminary evaluation results demonstrate the practicality and advantages of the framework.",
        "published": "2020-01-16T12:49:55Z",
        "link": "http://arxiv.org/abs/2001.08525v1",
        "categories": [
            "cs.SE",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Adversarially Guided Self-Play for Adopting Social Conventions",
        "authors": [
            "Mycal Tucker",
            "Yilun Zhou",
            "Julie Shah"
        ],
        "summary": "Robotic agents must adopt existing social conventions in order to be effective teammates. These social conventions, such as driving on the right or left side of the road, are arbitrary choices among optimal policies, but all agents on a successful team must use the same convention. Prior work has identified a method of combining self-play with paired input-output data gathered from existing agents in order to learn their social convention without interacting with them. We build upon this work by introducing a technique called Adversarial Self-Play (ASP) that uses adversarial training to shape the space of possible learned policies and substantially improves learning efficiency. ASP only requires the addition of unpaired data: a dataset of outputs produced by the social convention without associated inputs. Theoretical analysis reveals how ASP shapes the policy space and the circumstances (when behaviors are clustered or exhibit some other structure) under which it offers the greatest benefits. Empirical results across three domains confirm ASP's advantages: it produces models that more closely match the desired social convention when given as few as two paired datapoints.",
        "published": "2020-01-16T18:51:42Z",
        "link": "http://arxiv.org/abs/2001.05994v2",
        "categories": [
            "cs.AI",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Nodal cooperation equilibrium analysis in multihop wireless ad hoc   networks with a reputation system",
        "authors": [
            "Jerzy Konorski",
            "Karol Rydzewski"
        ],
        "summary": "Motivated by the concerns of cooperation security, this work examines selected principles of state-of-the-art reputation systems for multihop adhoc networks and their impact upon optimal strategies for rational nodes. An analytic framework is proposed and used for identification of effective cooperation-enforcement schemes. It is pointed out that an optimum rather than high reputation can be expected to be sought by rational nodes.",
        "published": "2020-01-16T20:08:15Z",
        "link": "http://arxiv.org/abs/2001.06056v1",
        "categories": [
            "cs.NI",
            "cs.MA"
        ]
    },
    {
        "title": "Algorithms in Multi-Agent Systems: A Holistic Perspective from   Reinforcement Learning and Game Theory",
        "authors": [
            "Yunlong Lu",
            "Kai Yan"
        ],
        "summary": "Deep reinforcement learning (RL) has achieved outstanding results in recent years, which has led a dramatic increase in the number of methods and applications. Recent works are exploring learning beyond single-agent scenarios and considering multi-agent scenarios. However, they are faced with lots of challenges and are seeking for help from traditional game-theoretic algorithms, which, in turn, show bright application promise combined with modern algorithms and boosting computing power. In this survey, we first introduce basic concepts and algorithms in single agent RL and multi-agent systems; then, we summarize the related algorithms from three aspects. Solution concepts from game theory give inspiration to algorithms which try to evaluate the agents or find better solutions in multi-agent systems. Fictitious self-play becomes popular and has a great impact on the algorithm of multi-agent reinforcement learning. Counterfactual regret minimization is an important tool to solve games with incomplete information, and has shown great strength when combined with deep learning.",
        "published": "2020-01-17T15:08:04Z",
        "link": "http://arxiv.org/abs/2001.06487v3",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "A utility-based analysis of equilibria in multi-objective normal form   games",
        "authors": [
            "Roxana Rădulescu",
            "Patrick Mannion",
            "Yijie Zhang",
            "Diederik M. Roijers",
            "Ann Nowé"
        ],
        "summary": "In multi-objective multi-agent systems (MOMAS), agents explicitly consider the possible tradeoffs between conflicting objective functions. We argue that compromises between competing objectives in MOMAS should be analysed on the basis of the utility that these compromises have for the users of a system, where an agent's utility function maps their payoff vectors to scalar utility values. This utility-based approach naturally leads to two different optimisation criteria for agents in a MOMAS: expected scalarised returns (ESR) and scalarised expected returns (SER). In this article, we explore the differences between these two criteria using the framework of multi-objective normal form games (MONFGs). We demonstrate that the choice of optimisation criterion (ESR or SER) can radically alter the set of equilibria in a MONFG when non-linear utility functions are used.",
        "published": "2020-01-17T22:27:38Z",
        "link": "http://arxiv.org/abs/2001.08177v1",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "True Nonlinear Dynamics from Incomplete Networks",
        "authors": [
            "Chunheng Jiang",
            "Jianxi Gao",
            "Malik Magdon-Ismail"
        ],
        "summary": "We study nonlinear dynamics on complex networks. Each vertex $i$ has a state $x_i$ which evolves according to a networked dynamics to a steady-state $x_i^*$. We develop fundamental tools to learn the true steady-state of a small part of the network, without knowing the full network. A naive approach and the current state-of-the-art is to follow the dynamics of the observed partial network to local equilibrium. This dramatically fails to extract the true steady state. We use a mean-field approach to map the dynamics of the unseen part of the network to a single node, which allows us to recover accurate estimates of steady-state on as few as 5 observed vertices in domains ranging from ecology to social networks to gene regulation. Incomplete networks are the norm in practice, and we offer new ways to think about nonlinear dynamics when only sparse information is available.",
        "published": "2020-01-18T20:36:47Z",
        "link": "http://arxiv.org/abs/2001.06722v1",
        "categories": [
            "cs.SI",
            "cs.MA"
        ]
    },
    {
        "title": "Peer-to-Peer Trading in Electricity Networks: An Overview",
        "authors": [
            "Wayes Tushar",
            "Tapan K. Saha",
            "Chau Yuen",
            "David Smith",
            "H. Vincent Poor"
        ],
        "summary": "Peer-to-peer trading is a next-generation energy management technique that economically benefits proactive consumers (prosumers) transacting their energy as goods and services. At the same time, peer-to-peer energy trading is also expected to help the grid by reducing peak demand, lowering reserve requirements, and curtailing network loss. However, large-scale deployment of peer-to-peer trading in electricity networks poses a number of challenges in modeling transactions in both the virtual and physical layers of the network. As such, this article provides a comprehensive review of the state-of-the-art in research on peer-to-peer energy trading techniques. By doing so, we provide an overview of the key features of peer-to-peer trading and its benefits of relevance to the grid and prosumers. Then, we systematically classify the existing research in terms of the challenges that the studies address in the virtual and the physical layers. We then further identify and discuss those technical approaches that have been extensively used to address the challenges in peer-to-peer transactions. Finally, the paper is concluded with potential future research directions.",
        "published": "2020-01-19T18:41:23Z",
        "link": "http://arxiv.org/abs/2001.06882v1",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Dynamic Epistemic Logic Games with Epistemic Temporal Goals",
        "authors": [
            "Bastien Maubert",
            "Aniello Murano",
            "Sophie Pinchinat",
            "François Schwarzentruber",
            "Silvia Stranieri"
        ],
        "summary": "Dynamic Epistemic Logic (DEL) is a logical framework in which one can describe in great detail how actions are perceived by the agents, and how they affect the world. DEL games were recently introduced as a way to define classes of games with imperfect information where the actions available to the players are described very precisely. This framework makes it possible to define easily, for instance, classes of games where players can only use public actions or public announcements. These games have been studied for reachability objectives, where the aim is to reach a situation satisfying some epistemic property expressed in epistemic logic; several (un)decidability results have been established. In this work we show that the decidability results obtained for reachability objectives extend to a much more general class of winning conditions, namely those expressible in the epistemic temporal logic LTLK. To do so we establish that the infinite game structures generated by DEL public actions are regular, and we describe how to obtain finite representations on which we rely to solve them.",
        "published": "2020-01-20T15:27:23Z",
        "link": "http://arxiv.org/abs/2001.07141v1",
        "categories": [
            "cs.LO",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Distributed Possibilistic Learning in Multi-Agent Systems",
        "authors": [
            "Jonathan Lawry",
            "Michael Crosscombe",
            "David Harvey"
        ],
        "summary": "Possibility theory is proposed as an uncertainty representation framework for distributed learning in multi-agent systems and robot swarms. In particular, we investigate its application to the best-of-n problem where the aim is for a population of agents to identify the highest quality out of n options through local interactions between individuals and limited direct feedback from the environment. In this context we claim that possibility theory provides efficient mechanisms by which an agent can learn about the state of the world, and which can allow them to handle inconsistencies between what they and others believe by varying the level of imprecision of their own beliefs. We introduce a discrete time model of a population of agents applying possibility theory to the best-of-n problem. Simulation experiments are then used to investigate the accuracy of possibility theory in this context as well as its robustness to noise under varying amounts of direct evidence. Finally, we compare possibility theory in this context with a similar probabilistic approach.",
        "published": "2020-01-20T15:31:05Z",
        "link": "http://arxiv.org/abs/2001.07145v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Emergence of Pragmatics from Referential Game between Theory of Mind   Agents",
        "authors": [
            "Luyao Yuan",
            "Zipeng Fu",
            "Jingyue Shen",
            "Lu Xu",
            "Junhong Shen",
            "Song-Chun Zhu"
        ],
        "summary": "Pragmatics studies how context can contribute to language meanings. In human communication, language is never interpreted out of context, and sentences can usually convey more information than their literal meanings. However, this mechanism is missing in most multi-agent systems, restricting the communication efficiency and the capability of human-agent interaction. In this paper, we propose an algorithm, using which agents can spontaneously learn the ability to \"read between lines\" without any explicit hand-designed rules. We integrate the theory of mind (ToM) in a cooperative multi-agent pedagogical situation and propose an adaptive reinforcement learning (RL) algorithm to develop a communication protocol. ToM is a profound cognitive science concept, claiming that people regularly reason about other's mental states, including beliefs, goals, and intentions, to obtain performance advantage in competition, cooperation or coalition. With this ability, agents consider language as not only messages but also rational acts reflecting others' hidden states. Our experiments demonstrate the advantage of pragmatic protocols over non-pragmatic protocols. We also show the teaching complexity following the pragmatic protocol empirically approximates to recursive teaching dimension (RTD).",
        "published": "2020-01-21T19:37:33Z",
        "link": "http://arxiv.org/abs/2001.07752v2",
        "categories": [
            "cs.AI",
            "cs.CL",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "On Solving Cooperative MARL Problems with a Few Good Experiences",
        "authors": [
            "Rajiv Ranjan Kumar",
            "Pradeep Varakantham"
        ],
        "summary": "Cooperative Multi-agent Reinforcement Learning (MARL) is crucial for cooperative decentralized decision learning in many domains such as search and rescue, drone surveillance, package delivery and fire fighting problems. In these domains, a key challenge is learning with a few good experiences, i.e., positive reinforcements are obtained only in a few situations (e.g., on extinguishing a fire or tracking a crime or delivering a package) and in most other situations there is zero or negative reinforcement. Learning decisions with a few good experiences is extremely challenging in cooperative MARL problems due to three reasons. First, compared to the single agent case, exploration is harder as multiple agents have to be coordinated to receive a good experience. Second, environment is not stationary as all the agents are learning at the same time (and hence change policies). Third, scale of problem increases significantly with every additional agent.   Relevant existing work is extensive and has focussed on dealing with a few good experiences in single-agent RL problems or on scalable approaches for handling non-stationarity in MARL problems. Unfortunately, neither of these approaches (or their extensions) are able to address the problem of sparse good experiences effectively. Therefore, we provide a novel fictitious self imitation approach that is able to simultaneously handle non-stationarity and sparse good experiences in a scalable manner. Finally, we provide a thorough comparison (experimental or descriptive) against relevant cooperative MARL algorithms to demonstrate the utility of our approach.",
        "published": "2020-01-22T12:53:53Z",
        "link": "http://arxiv.org/abs/2001.07993v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Subjective Knowledge and Reasoning about Agents in Multi-Agent Systems",
        "authors": [
            "Shikha Singh",
            "Deepak Khemani"
        ],
        "summary": "Though a lot of work in multi-agent systems is focused on reasoning about knowledge and beliefs of artificial agents, an explicit representation and reasoning about the presence/absence of agents, especially in the scenarios where agents may be unaware of other agents joining in or going offline in a multi-agent system, leading to partial knowledge/asymmetric knowledge of the agents is mostly overlooked by the MAS community. Such scenarios lay the foundations of cases where an agent can influence other agents' mental states by (mis)informing them about the presence/absence of collaborators or adversaries. In this paper, we investigate how Kripke structure-based epistemic models can be extended to express the above notion based on an agent's subjective knowledge and we discuss the challenges that come along.",
        "published": "2020-01-22T13:50:26Z",
        "link": "http://arxiv.org/abs/2001.08016v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "United for Change: Deliberative Coalition Formation to Change the Status   Quo",
        "authors": [
            "Edith Elkind",
            "Davide Grossi",
            "Ehud Shapiro",
            "Nimrod Talmon"
        ],
        "summary": "We study a setting in which a community wishes to identify a strongly supported proposal from a space of alternatives, in order to change the status quo. We describe a deliberation process in which agents dynamically form coalitions around proposals that they prefer over the status quo. We formulate conditions on the space of proposals and on the ways in which coalitions are formed that guarantee deliberation to succeed, that is, to terminate by identifying a proposal with the largest possible support. Our results provide theoretical foundations for the analysis of deliberative processes such as the ones that take place in online systems for democratic deliberation support.",
        "published": "2020-01-22T14:27:43Z",
        "link": "http://arxiv.org/abs/2001.08031v5",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Making an Example: Signalling Threat in the Evolution of Cooperation",
        "authors": [
            "Theodor Cimpeanu",
            "The Anh Han"
        ],
        "summary": "Social punishment has been suggested as a key approach to ensuring high levels of cooperation and norm compliance in one-shot (i.e. non-repeated) interactions. However, it has been shown that it only works when punishment is highly cost-efficient. On the other hand, signalling retribution hearkens back to medieval sovereignty, insofar as the very word for gallows in French stems from the Latin word for power and serves as a grim symbol of the ruthlessness of high justice. Here we introduce the mechanism of signalling an act of punishment and a special type of defector emerges, one who can recognise this signal and avoid punishment by way of fear. We describe the analytical conditions under which threat signalling can maintain high levels of cooperation. Moreover, we perform extensive agent-based simulations so as to confirm and expand our understanding of the external factors that influence the success of social punishment. We show that our suggested mechanism catalyses cooperation, even when signalling is costly or when punishment would be impractical. We observe the preventive nature of advertising retributive acts and we contend that the resulting social prosperity is a desirable outcome in the contexts of AI and multi-agent systems. To conclude, we argue that fear acts as an effective stimulus to pro-social behaviour.",
        "published": "2020-01-22T19:42:56Z",
        "link": "http://arxiv.org/abs/2001.08245v2",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Dynamics of extended Schelling models",
        "authors": [
            "A. P. Vieira",
            "E. Goles",
            "H. J. Herrmann"
        ],
        "summary": "We explore extensions of Schelling's model of social dynamics, in which two types of agents live on a checkerboard lattice and move in order to optimize their own satisfaction, which depends on how many agents among their neighbors are of their same type. For each number $n$ of same-type nearest neighbors we independently assign a binary satisfaction variable $s_{k}$ which is equal to one only if the agent is satisfied with that condition, and is equal to zero otherwise. This defines 32 different satisfaction rules, which we investigate in detail, focusing on pattern formation and measuring segregation with the help of an \"energy\" function which is related to the number of neighboring agents of different types and plays no role in the dynamics. We consider the checkerboard lattice to be fully occupied and the dynamics consists of switching the locations of randomly selected unsatisfied agents of opposite types. We show that, starting from a random distribution of agents, only a small number of rules lead to (nearly) fully segregated patterns in the long run, with many rules leading to chaotic steady-state behavior. Nevertheless, other interesting patterns may also be dynamically generated, such as \"anti-segregate d\" patterns as well as patterns resembling sponges.",
        "published": "2020-01-22T21:23:20Z",
        "link": "http://arxiv.org/abs/2001.08284v1",
        "categories": [
            "cond-mat.stat-mech",
            "cs.MA",
            "nlin.CG"
        ]
    },
    {
        "title": "Numerical Abstract Persuasion Argumentation for Expressing Concurrent   Multi-Agent Negotiations",
        "authors": [
            "Ryuta Arisaka",
            "Takayuki Ito"
        ],
        "summary": "A negotiation process by 2 agents e1 and e2 can be interleaved by another negotiation process between, say, e1 and e3. The interleaving may alter the resource allocation assumed at the inception of the first negotiation process. Existing proposals for argumentation-based negotiations have focused primarily on two-agent bilateral negotiations, but scarcely on the concurrency of multi-agent negotiations. To fill the gap, we present a novel argumentation theory, basing its development on abstract persuasion argumentation (which is an abstract argumentation formalism with a dynamic relation). Incorporating into it numerical information and a mechanism of handshakes among members of the dynamic relation, we show that the extended theory adapts well to concurrent multi-agent negotiations over scarce resources.",
        "published": "2020-01-23T01:46:58Z",
        "link": "http://arxiv.org/abs/2001.08335v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Mechanism Design for Multi-Party Machine Learning",
        "authors": [
            "Mengjing Chen",
            "Yang Liu",
            "Weiran Shen",
            "Yiheng Shen",
            "Pingzhong Tang",
            "Qiang Yang"
        ],
        "summary": "In a multi-party machine learning system, different parties cooperate on optimizing towards better models by sharing data in a privacy-preserving way. A major challenge in learning is the incentive issue. For example, if there is competition among the parties, one may strategically hide his data to prevent other parties from getting better models.   In this paper, we study the problem through the lens of mechanism design and incorporate the features of multi-party learning in our setting. First, each agent's valuation has externalities that depend on others' types and actions. Second, each agent can only misreport a type lower than his true type, but not the other way round. We call this setting interdependent value with type-dependent action spaces. We provide the optimal truthful mechanism in the quasi-monotone utility setting. We also provide necessary and sufficient conditions for truthful mechanisms in the most general case. Finally, we show the existence of such mechanisms is highly affected by the market growth rate and provide empirical analysis.",
        "published": "2020-01-24T13:38:08Z",
        "link": "http://arxiv.org/abs/2001.08996v3",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "MagNet: Discovering Multi-agent Interaction Dynamics using Neural   Network",
        "authors": [
            "Priyabrata Saha",
            "Arslan Ali",
            "Burhan A. Mudassar",
            "Yun Long",
            "Saibal Mukhopadhyay"
        ],
        "summary": "We present the MagNet, a neural network-based multi-agent interaction model to discover the governing dynamics and predict evolution of a complex multi-agent system from observations. We formulate a multi-agent system as a coupled non-linear network with a generic ordinary differential equation (ODE) based state evolution, and develop a neural network-based realization of its time-discretized model. MagNet is trained to discover the core dynamics of a multi-agent system from observations, and tuned on-line to learn agent-specific parameters of the dynamics to ensure accurate prediction even when physical or relational attributes of agents, or number of agents change. We evaluate MagNet on a point-mass system in two-dimensional space, Kuramoto phase synchronization dynamics and predator-swarm interaction dynamics demonstrating orders of magnitude improvement in prediction accuracy over traditional deep learning models.",
        "published": "2020-01-24T13:41:01Z",
        "link": "http://arxiv.org/abs/2001.09001v2",
        "categories": [
            "cs.LG",
            "cs.MA",
            "cs.RO",
            "stat.ML"
        ]
    },
    {
        "title": "Towards Graph Representation Learning in Emergent Communication",
        "authors": [
            "Agnieszka Słowik",
            "Abhinav Gupta",
            "William L. Hamilton",
            "Mateja Jamnik",
            "Sean B. Holden"
        ],
        "summary": "Recent findings in neuroscience suggest that the human brain represents information in a geometric structure (for instance, through conceptual spaces). In order to communicate, we flatten the complex representation of entities and their attributes into a single word or a sentence. In this paper we use graph convolutional networks to support the evolution of language and cooperation in multi-agent systems. Motivated by an image-based referential game, we propose a graph referential game with varying degrees of complexity, and we provide strong baseline models that exhibit desirable properties in terms of language emergence and cooperation. We show that the emerged communication protocol is robust, that the agents uncover the true factors of variation in the game, and that they learn to generalize beyond the samples encountered during training.",
        "published": "2020-01-24T15:55:59Z",
        "link": "http://arxiv.org/abs/2001.09063v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.CL",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Policy Synthesis for Factored MDPs with Graph Temporal Logic   Specifications",
        "authors": [
            "Murat Cubuktepe",
            "Zhe Xu",
            "Ufuk Topcu"
        ],
        "summary": "We study the synthesis of policies for multi-agent systems to implement spatial-temporal tasks. We formalize the problem as a factored Markov decision process subject to so-called graph temporal logic specifications. The transition function and the spatial-temporal task of each agent depend on the agent itself and its neighboring agents. The structure in the model and the specifications enable to develop a distributed algorithm that, given a factored Markov decision process and a graph temporal logic formula, decomposes the synthesis problem into a set of smaller synthesis problems, one for each agent. We prove that the algorithm runs in time linear in the total number of agents. The size of the synthesis problem for each agent is exponential only in the number of neighboring agents, which is typically much smaller than the number of agents. We demonstrate the algorithm in case studies on disease control and urban security. The numerical examples show that the algorithm can scale to hundreds of agents.",
        "published": "2020-01-24T16:03:34Z",
        "link": "http://arxiv.org/abs/2001.09066v1",
        "categories": [
            "cs.MA",
            "cs.LO",
            "math.OC"
        ]
    },
    {
        "title": "Vehicle Scheduling Problem",
        "authors": [
            "Mirmojtaba Gharibi",
            "Steven L. Waslander",
            "Raouf Boutaba"
        ],
        "summary": "We define a new problem called the Vehicle Scheduling Problem (VSP). The goal is to minimize an objective function, such as the number of tardy vehicles over a transportation network subject to maintaining safety distances, meeting hard deadlines, and maintaining speeds on each link between the allowed minimums and maximums. We prove VSP is an NP-hard problem for multiple objective functions that are commonly used in the context of job shop scheduling. With the number of tardy vehicles as the objective function, we formulate VSP in terms of a Mixed Integer Linear Programming (MIP) and design a heuristic algorithm. We analyze the complexity of our algorithm and compare the quality of the solutions to the optimal solution for the MIP formulation in the small cases. Our main motivation for defining VSP is the upcoming integration of Unmanned Aerial Vehicles (UAVs) into the airspace for which this novel scheduling framework is of paramount importance.",
        "published": "2020-01-25T11:45:25Z",
        "link": "http://arxiv.org/abs/2001.09297v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Silly rules improve the capacity of agents to learn stable enforcement   and compliance behaviors",
        "authors": [
            "Raphael Köster",
            "Dylan Hadfield-Menell",
            "Gillian K. Hadfield",
            "Joel Z. Leibo"
        ],
        "summary": "How can societies learn to enforce and comply with social norms? Here we investigate the learning dynamics and emergence of compliance and enforcement of social norms in a foraging game, implemented in a multi-agent reinforcement learning setting. In this spatiotemporally extended game, individuals are incentivized to implement complex berry-foraging policies and punish transgressions against social taboos covering specific berry types. We show that agents benefit when eating poisonous berries is taboo, meaning the behavior is punished by other agents, as this helps overcome a credit-assignment problem in discovering delayed health effects. Critically, however, we also show that introducing an additional taboo, which results in punishment for eating a harmless berry, improves the rate and stability with which agents learn to punish taboo violations and comply with taboos. Counterintuitively, our results show that an arbitrary taboo (a \"silly rule\") can enhance social learning dynamics and achieve better outcomes in the middle stages of learning. We discuss the results in the context of studying normativity as a group-level emergent phenomenon.",
        "published": "2020-01-25T14:00:33Z",
        "link": "http://arxiv.org/abs/2001.09318v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Prediction diversity and selective attention in the wisdom of crowds",
        "authors": [
            "Davi A. Nobre",
            "José F. Fontanari"
        ],
        "summary": "The wisdom of crowds is the idea that the combination of independent estimates of the magnitude of some quantity yields a remarkably accurate prediction, which is always more accurate than the average individual estimate. In addition, it is largely believed that the accuracy of the crowd can be improved by increasing the diversity of the estimates. Here we report the results of three experiments to probe the current understanding of the wisdom of crowds, namely, the estimates of the number of candies in a jar, the length of a paper strip, and the number of pages of a book. We find that the collective estimate is better than the majority of the individual estimates in all three experiments. In disagreement with the prediction diversity theorem, we find no significant correlation between the prediction diversity and the collective error. The poor accuracy of the crowd on some experiments lead us to conjecture that its alleged accuracy is most likely an artifice of selective attention.",
        "published": "2020-01-27T19:53:41Z",
        "link": "http://arxiv.org/abs/2001.10039v2",
        "categories": [
            "cs.IT",
            "cs.MA",
            "math.IT",
            "physics.data-an"
        ]
    },
    {
        "title": "Objective Social Choice: Using Auxiliary Information to Improve Voting   Outcomes",
        "authors": [
            "Silviu Pitis",
            "Michael R. Zhang"
        ],
        "summary": "How should one combine noisy information from diverse sources to make an inference about an objective ground truth? This frequently recurring, normative question lies at the core of statistics, machine learning, policy-making, and everyday life. It has been called \"combining forecasts\", \"meta-analysis\", \"ensembling\", and the \"MLE approach to voting\", among other names. Past studies typically assume that noisy votes are identically and independently distributed (i.i.d.), but this assumption is often unrealistic. Instead, we assume that votes are independent but not necessarily identically distributed and that our ensembling algorithm has access to certain auxiliary information related to the underlying model governing the noise in each vote. In our present work, we: (1) define our problem and argue that it reflects common and socially relevant real world scenarios, (2) propose a multi-arm bandit noise model and count-based auxiliary information set, (3) derive maximum likelihood aggregation rules for ranked and cardinal votes under our noise model, (4) propose, alternatively, to learn an aggregation rule using an order-invariant neural network, and (5) empirically compare our rules to common voting rules and naive experience-weighted modifications. We find that our rules successfully use auxiliary information to outperform the naive baselines.",
        "published": "2020-01-27T21:21:19Z",
        "link": "http://arxiv.org/abs/2001.10092v1",
        "categories": [
            "cs.MA",
            "cs.LG",
            "econ.TH"
        ]
    },
    {
        "title": "Regret Bounds for Decentralized Learning in Cooperative Multi-Agent   Dynamical Systems",
        "authors": [
            "Seyed Mohammad Asghari",
            "Yi Ouyang",
            "Ashutosh Nayyar"
        ],
        "summary": "Regret analysis is challenging in Multi-Agent Reinforcement Learning (MARL) primarily due to the dynamical environments and the decentralized information among agents. We attempt to solve this challenge in the context of decentralized learning in multi-agent linear-quadratic (LQ) dynamical systems. We begin with a simple setup consisting of two agents and two dynamically decoupled stochastic linear systems, each system controlled by an agent. The systems are coupled through a quadratic cost function. When both systems' dynamics are unknown and there is no communication among the agents, we show that no learning policy can generate sub-linear in $T$ regret, where $T$ is the time horizon. When only one system's dynamics are unknown and there is one-directional communication from the agent controlling the unknown system to the other agent, we propose a MARL algorithm based on the construction of an auxiliary single-agent LQ problem. The auxiliary single-agent problem in the proposed MARL algorithm serves as an implicit coordination mechanism among the two learning agents. This allows the agents to achieve a regret within $O(\\sqrt{T})$ of the regret of the auxiliary single-agent problem. Consequently, using existing results for single-agent LQ regret, our algorithm provides a $\\tilde{O}(\\sqrt{T})$ regret bound. (Here $\\tilde{O}(\\cdot)$ hides constants and logarithmic factors). Our numerical experiments indicate that this bound is matched in practice. From the two-agent problem, we extend our results to multi-agent LQ systems with certain communication patterns.",
        "published": "2020-01-27T23:37:41Z",
        "link": "http://arxiv.org/abs/2001.10122v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "math.OC",
            "stat.ML"
        ]
    },
    {
        "title": "Distributed Optimization for Energy-efficient Fog Computing in the   Tactile Internet",
        "authors": [
            "Yong Xiao",
            "Marwan Krunz"
        ],
        "summary": "Tactile Internet is an emerging concept that focuses on supporting high-fidelity, ultra-responsive, and widely available human-to-machine interactions. To reduce the transmission latency and alleviate Internet congestion, fog computing has been advocated as an important component of the Tactile Internet. In this paper, we focus on energy-efficient design of fog computing networks that support low-latency Tactile Internet applications. We investigate two performance metrics: Service response time of end-users and power usage efficiency of fog nodes. We quantify the fundamental tradeoff between these two metrics and then extend our analysis to fog computing networks involving cooperation between fog nodes. We introduce a novel cooperative fog computing concept, referred to as offload forwarding, in which a set of fog nodes with different computing and energy resources can cooperate with each other. The objective of this cooperation is to balance the workload processed by different fog nodes, further reduce the service response time, and improve the efficiency of power usage. We develop a distributed optimization framework based on dual decomposition to achieve the optimal tradeoff. Our framework does not require fog nodes to disclose their private information nor conduct back-and-forth negotiations with each other. Two distributed optimization algorithms are proposed. One is based on the subgradient method with dual decomposition and the other is based on distributed ADMM-VS. We prove that both algorithms can achieve the optimal workload allocation that minimizes the response time under the given power efficiency constraints of fog nodes.",
        "published": "2020-01-28T07:44:10Z",
        "link": "http://arxiv.org/abs/2001.10199v1",
        "categories": [
            "cs.NI",
            "cs.DC",
            "cs.MA"
        ]
    },
    {
        "title": "Towards Learning Multi-agent Negotiations via Self-Play",
        "authors": [
            "Yichuan Charlie Tang"
        ],
        "summary": "Making sophisticated, robust, and safe sequential decisions is at the heart of intelligent systems. This is especially critical for planning in complex multi-agent environments, where agents need to anticipate other agents' intentions and possible future actions. Traditional methods formulate the problem as a Markov Decision Process, but the solutions often rely on various assumptions and become brittle when presented with corner cases. In contrast, deep reinforcement learning (Deep RL) has been very effective at finding policies by simultaneously exploring, interacting, and learning from environments. Leveraging the powerful Deep RL paradigm, we demonstrate that an iterative procedure of self-play can create progressively more diverse environments, leading to the learning of sophisticated and robust multi-agent policies. We demonstrate this in a challenging multi-agent simulation of merging traffic, where agents must interact and negotiate with others in order to successfully merge on or off the road. While the environment starts off simple, we increase its complexity by iteratively adding an increasingly diverse set of agents to the agent \"zoo\" as training progresses. Qualitatively, we find that through self-play, our policies automatically learn interesting behaviors such as defensive driving, overtaking, yielding, and the use of signal lights to communicate intentions to other agents. In addition, quantitatively, we show a dramatic improvement of the success rate of merging maneuvers from 63% to over 98%.",
        "published": "2020-01-28T08:37:33Z",
        "link": "http://arxiv.org/abs/2001.10208v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Parameter Calibration in Crowd Simulation Models using Approximate   Bayesian Computation",
        "authors": [
            "Nikolai Bode"
        ],
        "summary": "Simulation models for pedestrian crowds are a ubiquitous tool in research and industry. It is crucial that the parameters of these models are calibrated carefully and ultimately it will be of interest to compare competing models to decide which model is best suited for a particular purpose. In this contribution, I demonstrate how Approximate Bayesian Computation (ABC), which is already a popular tool in other areas of science, can be used for model fitting and model selection in a pedestrian dynamics context. I fit two different models for pedestrian dynamics to data on a crowd passing in one direction through a bottleneck. One model describes movement in continuous-space, the other model is a cellular automaton and thus describes movement in discrete-space. In addition, I compare models to data using two metrics. The first is based on egress times and the second on the velocity of pedestrians in front of the bottleneck. My results show that while model fitting is successful, a substantial degree of uncertainty about the value of some model parameters remains after model fitting. Importantly, the choice of metric in model fitting can influence parameter estimates. Model selection is inconclusive for the egress time metric but supports the continuous-space model for the velocity-based metric. These findings show that ABC is a flexible approach and highlight the difficulties associated with model fitting and model selection for pedestrian dynamics. ABC requires many simulation runs and choosing appropriate metrics for comparing data to simulations requires careful attention. Despite this, I suggest ABC is a promising tool, because it is versatile and easily implemented for the growing number of openly available crowd simulators and data sets.",
        "published": "2020-01-28T14:08:53Z",
        "link": "http://arxiv.org/abs/2001.10330v1",
        "categories": [
            "cs.MA",
            "stat.AP"
        ]
    },
    {
        "title": "Industry 4.0: contributions of holonic manufacturing control   architectures and future challenges",
        "authors": [
            "William Derigent",
            "Olivier Cardin",
            "Damien Trentesaux"
        ],
        "summary": "The flexibility claimed by the next generation production systems induces a deep modification of the behaviour and the core itself of the control systems. Over-connectivity and data management abilities targeted by Industry 4.0 paradigm enable the emergence of more flexible and reactive control systems, based on the cooperation of autonomous and connected entities in the decision-making process. From most relevant articles extracted from existing literature, a list of 10 key enablers for Industry 4.0 is first presented. During the last 20 years, the holonic paradigm has become a major paradigm of Intelligent Manufacturing Systems. After the presentation of the holonic paradigm and holon properties, this article highlights how historical and current holonic control architectures can partly fulfil I4.0 key enablers. The remaining unfulfilled key enablers are then the subject of an extensive discussion on the remaining research perspectives on holonic architectures needed to achieve a complete support of Industry4.0.",
        "published": "2020-01-28T15:39:39Z",
        "link": "http://arxiv.org/abs/2002.04525v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Bounded Incentives in Manipulating the Probabilistic Serial Rule",
        "authors": [
            "Zihe Wang",
            "Zhide Wei",
            "Jie Zhang"
        ],
        "summary": "The Probabilistic Serial mechanism is well-known for its desirable fairness and efficiency properties. It is one of the most prominent protocols for the random assignment problem. However, Probabilistic Serial is not incentive-compatible, thereby these desirable properties only hold for the agents' declared preferences, rather than their genuine preferences. A substantial utility gain through strategic behaviors would trigger self-interested agents to manipulate the mechanism and would subvert the very foundation of adopting the mechanism in practice. In this paper, we characterize the extent to which an individual agent can increase its utility by strategic manipulation. We show that the incentive ratio of the mechanism is $\\frac{3}{2}$. That is, no agent can misreport its preferences such that its utility becomes more than 1.5 times of what it is when reports truthfully. This ratio is a worst-case guarantee by allowing an agent to have complete information about other agents' reports and to figure out the best response strategy even if it is computationally intractable in general. To complement this worst-case study, we further evaluate an agent's utility gain on average by experiments. The experiments show that an agent' incentive in manipulating the rule is very limited. These results shed some light on the robustness of Probabilistic Serial against strategic manipulation, which is one step further than knowing that it is not incentive-compatible.",
        "published": "2020-01-28T23:53:37Z",
        "link": "http://arxiv.org/abs/2001.10640v1",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "A Repeated Game Freeway Lane Changing Model",
        "authors": [
            "Kyungwon Kang",
            "Hesham A Rakha"
        ],
        "summary": "Lane changes are complex safety and throughput critical driver actions. Most lane changing models deal with lane-changing maneuvers solely from the merging driver's standpoint and thus ignore driver interaction. To overcome this shortcoming, we develop a game-theoretical decision-making model and validate the model using empirical merging maneuver data at a freeway on-ramp. Specifically, this paper advances our repeated game model in a previous paper by using updated payoff functions. Validation results using the NGSIM empirical data show that the developed game-theoretical model provides better prediction accuracy compared to previous work, with correct predictions approximately 86 percent of the time. In addition, a sensitivity analysis demonstrates the rationality and sensitivity of the model to variations in various factors. To provide evidence of the benefits of the repeated game approach, which takes into account previous decision-making results, a case study is conducted using an agent-based simulation model. The proposed repeated game model produces superior performance to a one-shot game model, when simulating actual freeway merging behaviors. Finally, this lane change model, which captures the collective decision-making between human drivers, can be used to develop automated vehicle driving strategies.",
        "published": "2020-01-29T18:09:09Z",
        "link": "http://arxiv.org/abs/2002.02529v1",
        "categories": [
            "physics.soc-ph",
            "cs.MA"
        ]
    },
    {
        "title": "Empirical Analysis of Fictitious Play for Nash Equilibrium Computation   in Multiplayer Games",
        "authors": [
            "Sam Ganzfried"
        ],
        "summary": "While fictitious play is guaranteed to converge to Nash equilibrium in certain game classes, such as two-player zero-sum games, it is not guaranteed to converge in non-zero-sum and multiplayer games. We show that fictitious play in fact leads to improved Nash equilibrium approximation over a variety of game classes and sizes than (counterfactual) regret minimization, which has recently produced superhuman play for multiplayer poker. We also show that when fictitious play is run several times using random initializations it is able to solve several known challenge problems in which the standard version is known to not converge, including Shapley's classic counterexample. These provide some of the first positive results for fictitious play in these settings, despite the fact that worst-case theoretical results are negative.",
        "published": "2020-01-30T03:47:09Z",
        "link": "http://arxiv.org/abs/2001.11165v10",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.MA",
            "econ.TH"
        ]
    },
    {
        "title": "Context-Aware Deep Q-Network for Decentralized Cooperative   Reconnaissance by a Robotic Swarm",
        "authors": [
            "Nishant Mohanty",
            "Mohitvishnu S. Gadde",
            "Suresh Sundaram",
            "Narasimhan Sundararajan",
            "P. B. Sujit"
        ],
        "summary": "One of the crucial problems in robotic swarm-based operation is to search and neutralize heterogeneous targets in an unknown and uncertain environment, without any communication within the swarm. Here, some targets can be neutralized by a single robot, while others need multiple robots in a particular sequence to neutralize them. The complexity in the problem arises due to the scalability and information uncertainty, which restricts the robot's awareness of the swarm and the target distribution. In this paper, this problem is addressed by proposing a novel Context-Aware Deep Q-Network (CA-DQN) framework to obtain communication free cooperation between the robots in the swarm. Each robot maintains an adaptive grid representation of the vicinity with the context information embedded into it to keep the swarm intact while searching and neutralizing the targets. The problem formulation uses a reinforcement learning framework where two Deep Q-Networks (DQNs) handle 'conflict' and 'conflict-free' scenarios separately. The self-play-in-based approach is used to determine the optimal policy for the DQNs. Monte-Carlo simulations and comparison studies with a state-of-the-art coalition formation algorithm are performed to verify the performance of CA-DQN with varying environmental parameters. The results show that the approach is invariant to the number of detected targets and the number of robots in the swarm. The paper also presents the real-time implementation of CA-DQN for different scenarios using ground robots in a laboratory environment to demonstrate the working of CA-DQN with low-power computing devices.",
        "published": "2020-01-31T08:50:22Z",
        "link": "http://arxiv.org/abs/2001.11710v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "A Deep Reinforcement Learning Approach to Concurrent Bilateral   Negotiation",
        "authors": [
            "Pallavi Bagga",
            "Nicola Paoletti",
            "Bedour Alrayes",
            "Kostas Stathis"
        ],
        "summary": "We present a novel negotiation model that allows an agent to learn how to negotiate during concurrent bilateral negotiations in unknown and dynamic e-markets. The agent uses an actor-critic architecture with model-free reinforcement learning to learn a strategy expressed as a deep neural network. We pre-train the strategy by supervision from synthetic market data, thereby decreasing the exploration time required for learning during negotiation. As a result, we can build automated agents for concurrent negotiations that can adapt to different e-market settings without the need to be pre-programmed. Our experimental evaluation shows that our deep reinforcement learning-based agents outperform two existing well-known negotiation strategies in one-to-many concurrent bilateral negotiations for a range of e-market settings.",
        "published": "2020-01-31T12:05:46Z",
        "link": "http://arxiv.org/abs/2001.11785v2",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Hierarchy and co-evolution processes in urban systems",
        "authors": [
            "Juste Raimbault"
        ],
        "summary": "The concept of hierarchy in complex systems is tightly linked to co-evolutionary processes. We propose here to explore it in the case of the co-evolution between transportation networks and territories. More precisely, we extend a co-evolution model for systems of cities and infrastructure networks, and systematically study its behavior following specific hierarchy indicators we introduce. We show that population hierarchy and network hierarchy are tightly linked, but that a broad range of regimes can exist. Model exploration furthermore yields non-trivial stylized facts which can be taken into account for territorial planning on such long time scales with co-evolutionary processes.",
        "published": "2020-01-31T18:23:55Z",
        "link": "http://arxiv.org/abs/2001.11989v1",
        "categories": [
            "physics.soc-ph",
            "cs.MA"
        ]
    },
    {
        "title": "Neural MMO v1.3: A Massively Multiagent Game Environment for Training   and Evaluating Neural Networks",
        "authors": [
            "Joseph Suarez",
            "Yilun Du",
            "Igor Mordatch",
            "Phillip Isola"
        ],
        "summary": "Progress in multiagent intelligence research is fundamentally limited by the number and quality of environments available for study. In recent years, simulated games have become a dominant research platform within reinforcement learning, in part due to their accessibility and interpretability. Previous works have targeted and demonstrated success on arcade, first person shooter (FPS), real-time strategy (RTS), and massive online battle arena (MOBA) games. Our work considers massively multiplayer online role-playing games (MMORPGs or MMOs), which capture several complexities of real-world learning that are not well modeled by any other game genre. We present Neural MMO, a massively multiagent game environment inspired by MMOs and discuss our progress on two more general challenges in multiagent systems engineering for AI research: distributed infrastructure and game IO. We further demonstrate that standard policy gradient methods and simple baseline models can learn interesting emergent exploration and specialization behaviors in this setting.",
        "published": "2020-01-31T18:50:02Z",
        "link": "http://arxiv.org/abs/2001.12004v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Accelerating Cooperative Planning for Automated Vehicles with Learned   Heuristics and Monte Carlo Tree Search",
        "authors": [
            "Karl Kurzer",
            "Marcus Fechner",
            "J. Marius Zöllner"
        ],
        "summary": "Efficient driving in urban traffic scenarios requires foresight. The observation of other traffic participants and the inference of their possible next actions depending on the own action is considered cooperative prediction and planning. Humans are well equipped with the capability to predict the actions of multiple interacting traffic participants and plan accordingly, without the need to directly communicate with others. Prior work has shown that it is possible to achieve effective cooperative planning without the need for explicit communication. However, the search space for cooperative plans is so large that most of the computational budget is spent on exploring the search space in unpromising regions that are far away from the solution. To accelerate the planning process, we combined learned heuristics with a cooperative planning method to guide the search towards regions with promising actions, yielding better solutions at lower computational costs.",
        "published": "2020-02-02T21:41:35Z",
        "link": "http://arxiv.org/abs/2002.00497v2",
        "categories": [
            "cs.LG",
            "cs.MA",
            "cs.RO",
            "stat.ML"
        ]
    },
    {
        "title": "On the Complexity of Destructive Bribery in Approval-Based Multi-winner   Voting",
        "authors": [
            "Yongjie Yang"
        ],
        "summary": "A variety of constructive manipulation, control, and bribery for approval-based multi-winner voting have been extensively studied very recently. However, their destructive counterparts seem to be less studied in the literature so far. This paper aims to fill this gap by exploring the complexity of several destructive bribery problems under five prestigious approval-based multi-winner voting rules. Generally speaking, these problems are to determine if a number of given candidates can be excluded from any winning committees by performing a series of modification operations yet without exceeding a given budget. We consider five operations. We offer a complete landscape of the complexity of the problems studied in this paper, and for NP-hard problems we study their parameterized complexity with respect to meaningful parameters.",
        "published": "2020-02-03T15:49:26Z",
        "link": "http://arxiv.org/abs/2002.00836v2",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "On the interaction between supervision and self-play in emergent   communication",
        "authors": [
            "Ryan Lowe",
            "Abhinav Gupta",
            "Jakob Foerster",
            "Douwe Kiela",
            "Joelle Pineau"
        ],
        "summary": "A promising approach for teaching artificial agents to use natural language involves using human-in-the-loop training. However, recent work suggests that current machine learning methods are too data inefficient to be trained in this way from scratch. In this paper, we investigate the relationship between two categories of learning signals with the ultimate goal of improving sample efficiency: imitating human language data via supervised learning, and maximizing reward in a simulated multi-agent environment via self-play (as done in emergent communication), and introduce the term supervised self-play (S2P) for algorithms using both of these signals. We find that first training agents via supervised learning on human data followed by self-play outperforms the converse, suggesting that it is not beneficial to emerge languages from scratch. We then empirically investigate various S2P schedules that begin with supervised learning in two environments: a Lewis signaling game with symbolic inputs, and an image-based referential game with natural language descriptions. Lastly, we introduce population based approaches to S2P, which further improves the performance over single-agent methods.",
        "published": "2020-02-04T02:35:19Z",
        "link": "http://arxiv.org/abs/2002.01093v2",
        "categories": [
            "cs.CL",
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Structural Inductive Biases in Emergent Communication",
        "authors": [
            "Agnieszka Słowik",
            "Abhinav Gupta",
            "William L. Hamilton",
            "Mateja Jamnik",
            "Sean B. Holden",
            "Christopher Pal"
        ],
        "summary": "In order to communicate, humans flatten a complex representation of ideas and their attributes into a single word or a sentence. We investigate the impact of representation learning in artificial agents by developing graph referential games. We empirically show that agents parametrized by graph neural networks develop a more compositional language compared to bag-of-words and sequence models, which allows them to systematically generalize to new combinations of familiar features.",
        "published": "2020-02-04T14:59:08Z",
        "link": "http://arxiv.org/abs/2002.01335v4",
        "categories": [
            "cs.CL",
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Partially Observable Games for Secure Autonomy",
        "authors": [
            "Mohamadreza Ahmadi",
            "Arun A. Viswanathan",
            "Michel D. Ingham",
            "Kymie Tan",
            "Aaron D. Ames"
        ],
        "summary": "Technology development efforts in autonomy and cyber-defense have been evolving independently of each other, over the past decade. In this paper, we report our ongoing effort to integrate these two presently distinct areas into a single framework. To this end, we propose the two-player partially observable stochastic game formalism to capture both high-level autonomous mission planning under uncertainty and adversarial decision making subject to imperfect information. We show that synthesizing sub-optimal strategies for such games is possible under finite-memory assumptions for both the autonomous decision maker and the cyber-adversary. We then describe an experimental testbed to evaluate the efficacy of the proposed framework.",
        "published": "2020-02-05T19:31:56Z",
        "link": "http://arxiv.org/abs/2002.01969v1",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.CR",
            "cs.FL",
            "cs.MA"
        ]
    },
    {
        "title": "A Self-Integration Testbed for Decentralized Socio-technical Systems",
        "authors": [
            "Farzam Fanitabasi",
            "Edward Gaere",
            "Evangelos Pournaras"
        ],
        "summary": "The Internet of Things comes along with new challenges for experimenting, testing, and operating decentralized socio-technical systems at large-scale. In such systems, autonomous agents interact locally with their users, and remotely with other agents to make intelligent collective choices. Via these interactions they self-regulate the consumption and production of distributed resources. While such complex systems are often deployed and operated using centralized computing infrastructures, the socio-technical nature of these decentralized systems requires new value-sensitive design paradigms; empowering trust, transparency, and alignment with citizens' social values, such as privacy preservation, autonomy, and fairness among citizens' choices. Currently, instruments and tools to study such systems and guide the prototyping process from simulation to live deployment are missing, or not practical in this distributed socio-technical context. This paper bridges this gap by introducing a novel testbed architecture for decentralized socio-technical systems running on IoT. This new architecture is designed for a seamless reusability of (i) application-independent decentralized services by an IoT application, and (ii) different IoT applications by the same decentralized service. This dual self-integration promises IoT applications that are simpler to prototype, and can interoperate with decentralized services during runtime to self-integrate more complex functionality. Such integration provides stronger validation of IoT applications, and improves resource utilization. Pressure and crash tests during continuous operations of several weeks, with more than 80K network joining and leaving of agents, 2.4M parameter changes, and 100M communicated messages, confirm the robustness and practicality of the testbed architecture.",
        "published": "2020-02-06T12:18:28Z",
        "link": "http://arxiv.org/abs/2002.02219v2",
        "categories": [
            "cs.MA",
            "cs.CY"
        ]
    },
    {
        "title": "Social diversity and social preferences in mixed-motive reinforcement   learning",
        "authors": [
            "Kevin R. McKee",
            "Ian Gemp",
            "Brian McWilliams",
            "Edgar A. Duéñez-Guzmán",
            "Edward Hughes",
            "Joel Z. Leibo"
        ],
        "summary": "Recent research on reinforcement learning in pure-conflict and pure-common interest games has emphasized the importance of population heterogeneity. In contrast, studies of reinforcement learning in mixed-motive games have primarily leveraged homogeneous approaches. Given the defining characteristic of mixed-motive games--the imperfect correlation of incentives between group members--we study the effect of population heterogeneity on mixed-motive reinforcement learning. We draw on interdependence theory from social psychology and imbue reinforcement learning agents with Social Value Orientation (SVO), a flexible formalization of preferences over group outcome distributions. We subsequently explore the effects of diversity in SVO on populations of reinforcement learning agents in two mixed-motive Markov games. We demonstrate that heterogeneity in SVO generates meaningful and complex behavioral variation among agents similar to that suggested by interdependence theory. Empirical results in these mixed-motive dilemmas suggest agents trained in heterogeneous populations develop particularly generalized, high-performing policies relative to those trained in homogeneous populations.",
        "published": "2020-02-06T16:07:02Z",
        "link": "http://arxiv.org/abs/2002.02325v2",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Situating Agent-Based Modelling in Population Health Research",
        "authors": [
            "Eric Silverman",
            "Umberto Gostoli",
            "Stefano Picascia",
            "Jonatan Almagor",
            "Mark McCann",
            "Richard Shaw",
            "Claudio Angione"
        ],
        "summary": "Today's most troublesome population health challenges are often driven by social and environmental determinants, which are difficult to model using traditional epidemiological methods. We agree with those who have argued for the wider adoption of agent-based modelling (ABM) in taking on these challenges. However, while ABM has been used occasionally in population health, we argue that for ABM to be most effective in the field it should be used as a means for answering questions normally inaccessible to the traditional epidemiological toolkit. In an effort to clearly illustrate the utility of ABM for population health research, and to clear up persistent misunderstandings regarding the method's conceptual underpinnings, we offer a detailed presentation of the core concepts of complex systems theory, and summarise why simulations are essential to the study of complex systems. We then examine the current state of the art in ABM for population health, and propose they are well-suited for the study of the `wicked' problems in population health, and could make significant contributions to theory and intervention development in these areas.",
        "published": "2020-02-06T16:45:40Z",
        "link": "http://arxiv.org/abs/2002.02345v1",
        "categories": [
            "cs.MA",
            "I.6.0; J.3"
        ]
    },
    {
        "title": "Multi Type Mean Field Reinforcement Learning",
        "authors": [
            "Sriram Ganapathi Subramanian",
            "Pascal Poupart",
            "Matthew E. Taylor",
            "Nidhi Hegde"
        ],
        "summary": "Mean field theory provides an effective way of scaling multiagent reinforcement learning algorithms to environments with many agents that can be abstracted by a virtual mean agent. In this paper, we extend mean field multiagent algorithms to multiple types. The types enable the relaxation of a core assumption in mean field reinforcement learning, which is that all agents in the environment are playing almost similar strategies and have the same goal. We conduct experiments on three different testbeds for the field of many agent reinforcement learning, based on the standard MAgents framework. We consider two different kinds of mean field environments: a) Games where agents belong to predefined types that are known a priori and b) Games where the type of each agent is unknown and therefore must be learned based on observations. We introduce new algorithms for each type of game and demonstrate their superior performance over state of the art algorithms that assume that all agents belong to the same type and other baseline algorithms in the MAgent framework.",
        "published": "2020-02-06T20:58:58Z",
        "link": "http://arxiv.org/abs/2002.02513v7",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Impact of the Interaction Network on the Dynamics of Word-of-Mouth with   Information Seeking",
        "authors": [
            "Samuel Thiriot"
        ],
        "summary": "Word-of-Mouth refers to the dynamics of interpersonal communication occurring during the diffusion of innovations (novel practices, ideas or products). According to field studies, word-of-mouth is made of both information seeking and proactive communication: individuals first become aware of the existence of an innovation, then start actively seeking out for the expert knowledge required to evaluate the innovation; when they hold the expert knowledge, they might start promoting it pro-actively. Successful diffusion of innovation requires the individuals to hold both awareness and expert knowledge, so they can evaluate the innovation and use it properly. A computational model \"USA/IPK\" was recently proposed to study the role and impact of information seeking on the dynamics of word-of-mouth. We propose here an analysis of the impact of the network of interaction on the dynamics of this model. We compare the dynamics of the model over networks generated with different algorithms with the original dynamics. The results demonstrate the dynamics of the model are similar across tested networks, with the noticeable exception of the efficiency of the diffusion which varies between networks having similar densities and sizes.",
        "published": "2020-02-07T11:56:15Z",
        "link": "http://arxiv.org/abs/2002.02728v1",
        "categories": [
            "cs.SI",
            "cs.CC",
            "cs.MA"
        ]
    },
    {
        "title": "SAT-Based ATL Satisfiability Checking",
        "authors": [
            "Magdalena Kacprzak",
            "Artur Niewiadomski",
            "Wojciech Penczek"
        ],
        "summary": "Synthesis of models and strategies is a very important problem in software engineering. The main element here is checking the satisfiability of formulae expressing the specification of a system to be implemented. This paper puts forward a novel method for deciding the satisfiability of formulae of Alternating-time Temporal Logic (ATL). The method presented expands on one for CTL exploit ing SAT Modulo Monotonic Theories solvers. Similarly to the CTL case, our approach appears to be very efficient. The experimental results show that we can quickly test the satisfiability of large ATL formulae that have been out of reach of the existing approaches.",
        "published": "2020-02-08T08:48:51Z",
        "link": "http://arxiv.org/abs/2002.03117v1",
        "categories": [
            "cs.LO",
            "cs.MA"
        ]
    },
    {
        "title": "SPA: Verbal Interactions between Agents and Avatars in Shared Virtual   Environments using Propositional Planning",
        "authors": [
            "Andrew Best",
            "Sahil Narang",
            "Dinesh Manocha"
        ],
        "summary": "We present a novel approach for generating plausible verbal interactions between virtual human-like agents and user avatars in shared virtual environments. Sense-Plan-Ask, or SPA, extends prior work in propositional planning and natural language processing to enable agents to plan with uncertain information, and leverage question and answer dialogue with other agents and avatars to obtain the needed information and complete their goals. The agents are additionally able to respond to questions from the avatars and other agents using natural-language enabling real-time multi-agent multi-avatar communication environments.   Our algorithm can simulate tens of virtual agents at interactive rates interacting, moving, communicating, planning, and replanning. We find that our algorithm creates a small runtime cost and enables agents to complete their goals more effectively than agents without the ability to leverage natural-language communication. We demonstrate quantitative results on a set of simulated benchmarks and detail the results of a preliminary user-study conducted to evaluate the plausibility of the virtual interactions generated by SPA. Overall, we find that participants prefer SPA to prior techniques in 84\\% of responses including significant benefits in terms of the plausibility of natural-language interactions and the positive impact of those interactions.",
        "published": "2020-02-08T23:15:06Z",
        "link": "http://arxiv.org/abs/2002.03246v1",
        "categories": [
            "cs.MA",
            "cs.CL"
        ]
    },
    {
        "title": "Evolution of a Complex Predator-Prey Ecosystem on Large-scale   Multi-Agent Deep Reinforcement Learning",
        "authors": [
            "Jun Yamada",
            "John Shawe-Taylor",
            "Zafeirios Fountas"
        ],
        "summary": "Simulation of population dynamics is a central research theme in computational biology, which contributes to understanding the interactions between predators and preys. Conventional mathematical tools of this theme, however, are incapable of accounting for several important attributes of such systems, such as the intelligent and adaptive behavior exhibited by individual agents. This unrealistic setting is often insufficient to simulate properties of population dynamics found in the real-world. In this work, we leverage multi-agent deep reinforcement learning, and we propose a new model of large-scale predator-prey ecosystems. Using different variants of our proposed environment, we show that multi-agent simulations can exhibit key real-world dynamical properties. To obtain this behavior, we firstly define a mating mechanism such that existing agents reproduce new individuals bound by the conditions of the environment. Furthermore, we incorporate a real-time evolutionary algorithm and show that reinforcement learning enhances the evolution of the agents' physical properties such as speed, attack and resilience against attacks.",
        "published": "2020-02-09T02:33:24Z",
        "link": "http://arxiv.org/abs/2002.03267v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Linearly Convergent Algorithm with Variance Reduction for Distributed   Stochastic Optimization",
        "authors": [
            "Jinlong Lei",
            "Peng Yi",
            "Jie Chen",
            "Yiguang Hong"
        ],
        "summary": "This paper considers a distributed stochastic strongly convex optimization, where agents connected over a network aim to cooperatively minimize the average of all agents' local cost functions. Due to the stochasticity of gradient estimation and distributedness of local objective, fast linearly convergent distributed algorithms have not been achieved yet. This work proposes a novel distributed stochastic gradient tracking algorithm with variance reduction, where the local gradients are estimated by an increasing batch-size of sampled gradients. With an undirected connected communication graph and a geometrically increasing batch-size, the iterates are shown to converge in mean to the optimal solution at a geometric rate (achieving linear convergence). The iteration, communication, and oracle complexity for obtaining an $\\epsilon$-optimal solution are established as well. Particulary, the communication complexity is $\\mathcal{O}(\\ln (1/\\epsilon))$ while the oracle complexity (number of sampled gradients) is $\\mathcal{O}(1/\\epsilon^2)$, which is of the same order as that of centralized approaches.   Hence, the proposed scheme is communication-efficient without requiring extra sampled gradients. Numerical simulations are given to demonstrate the theoretic results.",
        "published": "2020-02-09T02:57:58Z",
        "link": "http://arxiv.org/abs/2002.03269v2",
        "categories": [
            "math.OC",
            "cs.MA",
            "90Cxx"
        ]
    },
    {
        "title": "Resilient Consensus via Weight Learning and Its Application in   Fault-Tolerant Clock Synchronization",
        "authors": [
            "Jian Hou",
            "Zhiyong Chen",
            "ZhiyunLin",
            "Mengfan Xiang"
        ],
        "summary": "This paper addresses the distributed consensus problem in the presence of faulty nodes. A novel weight learning algorithm is introduced such that neither network connectivity nor a sequence of history records is required to achieve resilient consensus. The critical idea is to dynamically update the interaction weights among neighbors learnt from their credibility measurement. Basically, we define a reward function that is inversely proportional to the distance to its neighbor, and then adjust the credibility based on the reward derived at the present step and the previous credibility. In such a way, the interaction weights are updated at every step, which integrates the historic information and degrades the influences from faulty nodes. Both fixed and stochastic topologies are considered in this paper. Furthermore, we apply this novel approach in clock synchronization problem. By updating the logical clock skew and offset via the corresponding weight learning algorithms, respectively, the logical clock synchronization is eventually achieved regardless of faulty nodes. Simulations are provided to illustrate the effectiveness of the strategy.",
        "published": "2020-02-10T04:47:04Z",
        "link": "http://arxiv.org/abs/2002.03541v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Qatten: A General Framework for Cooperative Multiagent Reinforcement   Learning",
        "authors": [
            "Yaodong Yang",
            "Jianye Hao",
            "Ben Liao",
            "Kun Shao",
            "Guangyong Chen",
            "Wulong Liu",
            "Hongyao Tang"
        ],
        "summary": "In many real-world tasks, multiple agents must learn to coordinate with each other given their private observations and limited communication ability. Deep multiagent reinforcement learning (Deep-MARL) algorithms have shown superior performance in such challenging settings. One representative class of work is multiagent value decomposition, which decomposes the global shared multiagent Q-value $Q_{tot}$ into individual Q-values $Q^{i}$ to guide individuals' behaviors, i.e. VDN imposing an additive formation and QMIX adopting a monotonic assumption using an implicit mixing method. However, most of the previous efforts impose certain assumptions between $Q_{tot}$ and $Q^{i}$ and lack theoretical groundings. Besides, they do not explicitly consider the agent-level impact of individuals to the whole system when transforming individual $Q^{i}$s into $Q_{tot}$. In this paper, we theoretically derive a general formula of $Q_{tot}$ in terms of $Q^{i}$, based on which we can naturally implement a multi-head attention formation to approximate $Q_{tot}$, resulting in not only a refined representation of $Q_{tot}$ with an agent-level attention mechanism, but also a tractable maximization algorithm of decentralized policies. Extensive experiments demonstrate that our method outperforms state-of-the-art MARL methods on the widely adopted StarCraft benchmark across different scenarios, and attention analysis is further conducted with valuable insights.",
        "published": "2020-02-10T16:48:03Z",
        "link": "http://arxiv.org/abs/2002.03939v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Q-value Path Decomposition for Deep Multiagent Reinforcement Learning",
        "authors": [
            "Yaodong Yang",
            "Jianye Hao",
            "Guangyong Chen",
            "Hongyao Tang",
            "Yingfeng Chen",
            "Yujing Hu",
            "Changjie Fan",
            "Zhongyu Wei"
        ],
        "summary": "Recently, deep multiagent reinforcement learning (MARL) has become a highly active research area as many real-world problems can be inherently viewed as multiagent systems. A particularly interesting and widely applicable class of problems is the partially observable cooperative multiagent setting, in which a team of agents learns to coordinate their behaviors conditioning on their private observations and commonly shared global reward signals. One natural solution is to resort to the centralized training and decentralized execution paradigm. During centralized training, one key challenge is the multiagent credit assignment: how to allocate the global rewards for individual agent policies for better coordination towards maximizing system-level's benefits. In this paper, we propose a new method called Q-value Path Decomposition (QPD) to decompose the system's global Q-values into individual agents' Q-values. Unlike previous works which restrict the representation relation of the individual Q-values and the global one, we leverage the integrated gradient attribution technique into deep MARL to directly decompose global Q-values along trajectory paths to assign credits for agents. We evaluate QPD on the challenging StarCraft II micromanagement tasks and show that QPD achieves the state-of-the-art performance in both homogeneous and heterogeneous multiagent scenarios compared with existing cooperative MARL algorithms.",
        "published": "2020-02-10T17:03:58Z",
        "link": "http://arxiv.org/abs/2002.03950v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Trust dynamics and user attitudes on recommendation errors: preliminary   results",
        "authors": [
            "David A. Pelta",
            "Jose L. Verdegay",
            "Maria T. Lamata",
            "Carlos Cruz Corona"
        ],
        "summary": "Artificial Intelligence based systems may be used as digital nudging techniques that can steer or coerce users to make decisions not always aligned with their true interests. When such systems properly address the issues of Fairness, Accountability, Transparency, and Ethics, then the trust of the user in the system would just depend on the system's output. The aim of this paper is to propose a model for exploring how good and bad recommendations affect the overall trust in an idealized recommender system that issues recommendations over a resource with limited capacity. The impact of different users attitudes on trust dynamics is also considered. Using simulations, we ran a large set of experiments that allowed to observe that: 1) under certain circumstances, all the users ended accepting the recommendations; and 2) the user attitude (controlled by a single parameter balancing the gain/loss of trust after a good/bad recommendation) has a great impact in the trust dynamics.",
        "published": "2020-02-11T10:52:53Z",
        "link": "http://arxiv.org/abs/2002.04302v1",
        "categories": [
            "cs.SI",
            "cs.GT",
            "cs.IR",
            "cs.MA"
        ]
    },
    {
        "title": "A Versatile Multi-Robot Monte Carlo Tree Search Planner for On-Line   Coverage Path Planning",
        "authors": [
            "Phillip Hyatt",
            "Zachary Brock",
            "Marc D. Killpack"
        ],
        "summary": "Mobile robots hold great promise in reducing the need for humans to perform jobs such as vacuuming, seeding,harvesting, painting, search and rescue, and inspection. In practice, these tasks must often be done without an exact map of the area and could be completed more quickly through the use of multiple robots working together. The task of simultaneously covering and mapping an area with multiple robots is known as multi-robot on-line coverage and is a growing area of research. Many multi-robot on-line coverage path planning algorithms have been developed as extensions of well established off-line coverage algorithms. In this work we introduce a novel approach to multi-robot on-line coverage path planning based on a method borrowed from game theory and machine learning- Monte Carlo Tree Search. We implement a Monte Carlo Tree Search planner and compare completion times against a Boustrophedon-based on-line multi-robot planner. The MCTS planner is shown to perform on par with the conventional Boustrophedon algorithm in simulations varying the number of robots and the density of obstacles in the map. The versatility of the MCTS planner is demonstrated by incorporating secondary objectives such as turn minimization while performing the same coverage task. The versatility of the MCTS planner suggests it is well suited to many multi-objective tasks that arise in mobile robotics.",
        "published": "2020-02-11T16:18:09Z",
        "link": "http://arxiv.org/abs/2002.04517v1",
        "categories": [
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Fast Complete Algorithm for Multiplayer Nash Equilibrium",
        "authors": [
            "Sam Ganzfried"
        ],
        "summary": "We describe a new complete algorithm for computing Nash equilibrium in multiplayer general-sum games, based on a quadratically-constrained feasibility program formulation. We demonstrate that the algorithm runs significantly faster than the prior fastest complete algorithm on several game classes previously studied and that its runtimes even outperform the best incomplete algorithms.",
        "published": "2020-02-11T23:42:14Z",
        "link": "http://arxiv.org/abs/2002.04734v10",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.MA",
            "econ.TH",
            "math.OC"
        ]
    },
    {
        "title": "Learning Graph Influence from Social Interactions",
        "authors": [
            "Vincenzo Matta",
            "Virginia Bordignon",
            "Augusto Santos",
            "Ali H. Sayed"
        ],
        "summary": "In social learning, agents form their opinions or beliefs about certain hypotheses by exchanging local information. This work considers the recent paradigm of weak graphs, where the network is partitioned into sending and receiving components, with the former having the possibility of exerting a domineering effect on the latter. Such graph structures are prevalent over social platforms. We will not be focusing on the direct social learning problem (which examines what agents learn), but rather on the dual or reverse learning problem (which examines how agents learned). Specifically, from observations of the stream of beliefs at certain agents, we would like to examine whether it is possible to learn the strength of the connections (influences) from sending components in the network to these receiving agents.",
        "published": "2020-02-12T12:27:07Z",
        "link": "http://arxiv.org/abs/2002.04946v1",
        "categories": [
            "cs.MA",
            "cs.SI"
        ]
    },
    {
        "title": "Multi-Agent Reinforcement Learning and Human Social Factors in Climate   Change Mitigation",
        "authors": [
            "Kyle Tilbury",
            "Jesse Hoey"
        ],
        "summary": "Many complex real-world problems, such as climate change mitigation, are intertwined with human social factors. Climate change mitigation, a social dilemma made difficult by the inherent complexities of human behavior, has an impact at a global scale. We propose applying multi-agent reinforcement learning (MARL) in this setting to develop intelligent agents that can influence the social factors at play in climate change mitigation. There are ethical, practical, and technical challenges that must be addressed when deploying MARL in this way. In this paper, we present these challenges and outline an approach to address them. Understanding how intelligent agents can be used to impact human social factors is important to prevent their abuse and can be beneficial in furthering our knowledge of these complex problems as a whole. The challenges we present are not limited to our specific application but are applicable to broader MARL. Thus, developing MARL for social factors in climate change mitigation helps address general problems hindering MARL's applicability to other real-world problems while also motivating discussion on the social implications of MARL deployment.",
        "published": "2020-02-12T18:46:48Z",
        "link": "http://arxiv.org/abs/2002.05147v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Social and Child Care Provision in Kinship Networks: an Agent-Based   Model",
        "authors": [
            "Umberto Gostoli",
            "Eric Silverman"
        ],
        "summary": "Providing for the needs of the vulnerable is a critical component of social and health policy-making. In particular, caring for children and for vulnerable older people is vital to the wellbeing of millions of families throughout the world. In most developed countries, this care is provided through both formal and informal means, and is therefore governed by complex policies that interact in non-obvious ways with other areas of policy-making. In this paper we present an agent-based model of social and child care provision in the UK, in which agents can provide informal care or pay for private care for their relatives. Agents make care decisions based on numerous factors including their health status, employment, financial situation, and social and physical distance to those in need. Simulation results show that the model can produce plausible patterns of care need and availability, and therefore can provide an important aid to this complex area of policy-making. We conclude that the model's use of kinship networks for distributing care and the explicit modelling of interactions between social care and child care will enable policy-makers to develop more informed policy interventions in these critical areas.",
        "published": "2020-02-12T19:31:39Z",
        "link": "http://arxiv.org/abs/2002.05188v2",
        "categories": [
            "cs.CY",
            "cs.MA",
            "I.6.0; J.3"
        ]
    },
    {
        "title": "Learning Multi-Agent Coordination through Connectivity-driven   Communication",
        "authors": [
            "Emanuele Pesce",
            "Giovanni Montana"
        ],
        "summary": "In artificial multi-agent systems, the ability to learn collaborative policies is predicated upon the agents' communication skills: they must be able to encode the information received from the environment and learn how to share it with other agents as required by the task at hand. We present a deep reinforcement learning approach, Connectivity Driven Communication (CDC), that facilitates the emergence of multi-agent collaborative behaviour only through experience. The agents are modelled as nodes of a weighted graph whose state-dependent edges encode pair-wise messages that can be exchanged. We introduce a graph-dependent attention mechanisms that controls how the agents' incoming messages are weighted. This mechanism takes into full account the current state of the system as represented by the graph, and builds upon a diffusion process that captures how the information flows on the graph. The graph topology is not assumed to be known a priori, but depends dynamically on the agents' observations, and is learnt concurrently with the attention mechanism and policy in an end-to-end fashion. Our empirical results show that CDC is able to learn effective collaborative policies and can over-perform competing learning algorithms on cooperative navigation tasks.",
        "published": "2020-02-12T20:58:33Z",
        "link": "http://arxiv.org/abs/2002.05233v4",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Gradient tracking and variance reduction for decentralized optimization   and machine learning",
        "authors": [
            "Ran Xin",
            "Soummya Kar",
            "Usman A. Khan"
        ],
        "summary": "Decentralized methods to solve finite-sum minimization problems are important in many signal processing and machine learning tasks where the data is distributed over a network of nodes and raw data sharing is not permitted due to privacy and/or resource constraints. In this article, we review decentralized stochastic first-order methods and provide a unified algorithmic framework that combines variance-reduction with gradient tracking to achieve both robust performance and fast convergence. We provide explicit theoretical guarantees of the corresponding methods when the objective functions are smooth and strongly-convex, and show their applicability to non-convex problems via numerical experiments. Throughout the article, we provide intuitive illustrations of the main technical ideas by casting appropriate tradeoffs and comparisons among the methods of interest and by highlighting applications to decentralized training of machine learning models.",
        "published": "2020-02-13T07:17:07Z",
        "link": "http://arxiv.org/abs/2002.05373v1",
        "categories": [
            "cs.LG",
            "cs.DC",
            "cs.MA",
            "math.OC",
            "stat.ML"
        ]
    },
    {
        "title": "Internet of Smart-Cameras for Traffic Lights Optimization in Smart   Cities",
        "authors": [
            "Willy Carlos Tchuitcheu",
            "Christophe Bobda",
            "Md Jubaer Hossain Pantho"
        ],
        "summary": "Smart and decentralized control systems have recently been proposed to handle the growing traffic congestion in urban cities. Proposed smart traffic light solutions based on Wireless Sensor Network and Vehicular Ad-hoc NETwork are either unreliable and inflexible or complex and costly. Furthermore, the handling of special vehicles such as emergency is still not viable, especially during busy hours. Inspired by the emergence of distributed smart cameras, we present a novel approach to traffic control at intersections. Our approach uses smart cameras at intersections along with image understanding for real-time traffic monitoring and assessment. Besides understanding the traffic flow, the cameras can detect and track special vehicles and help prioritize emergency cases. Traffic violations can be identified as well and traffic statistics collected. In this paper, we introduce a flexible, adaptive and distributed control algorithm that uses the information provided by distributed smart cameras to efficiently control traffic signals. Experimental results show that our collision-free approach outperforms the state-of-the-art of the average user's waiting time in the queue and improves the routing of emergency vehicles in a cross congestion area.",
        "published": "2020-02-13T09:51:34Z",
        "link": "http://arxiv.org/abs/2002.05410v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Sequential Cooperative Bayesian Inference",
        "authors": [
            "Junqi Wang",
            "Pei Wang",
            "Patrick Shafto"
        ],
        "summary": "Cooperation is often implicitly assumed when learning from other agents. Cooperation implies that the agent selecting the data, and the agent learning from the data, have the same goal, that the learner infer the intended hypothesis. Recent models in human and machine learning have demonstrated the possibility of cooperation. We seek foundational theoretical results for cooperative inference by Bayesian agents through sequential data. We develop novel approaches analyzing consistency, rate of convergence and stability of Sequential Cooperative Bayesian Inference (SCBI). Our analysis of the effectiveness, sample efficiency and robustness show that cooperation is not only possible in specific instances but theoretically well-founded in general. We discuss implications for human-human and human-machine cooperation.",
        "published": "2020-02-13T18:48:06Z",
        "link": "http://arxiv.org/abs/2002.05706v3",
        "categories": [
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Vision-Based Real-Time Indoor Positioning System for Multiple Vehicles",
        "authors": [
            "Maximilian Kloock",
            "Patrick Scheffe",
            "Isabelle Tülleners",
            "Janis Maczijewski",
            "Stefan Kowalewski",
            "Bassam Alrifaee"
        ],
        "summary": "We propose a novel external indoor positioning system that computes the position and orientation of multiple model-scale vehicles. For this purpose, we use a camera mounted at a height of 3.3m and LEDs attached to each vehicle. We reach an accuracy of about 1.1 cm for the position and around 0.6 {\\deg} for the orientation in the mean. Our system is real-time capable with a soft deadline of 20 ms. Moreover, it is robust against changing lighting conditions and reflections.",
        "published": "2020-02-13T19:35:30Z",
        "link": "http://arxiv.org/abs/2002.05755v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "MCENET: Multi-Context Encoder Network for Homogeneous Agent Trajectory   Prediction in Mixed Traffic",
        "authors": [
            "Hao Cheng",
            "Wentong Liao",
            "Michael Ying Yang",
            "Monika Sester",
            "Bodo Rosenhahn"
        ],
        "summary": "Trajectory prediction in urban mixed-traffic zones (a.k.a. shared spaces) is critical for many intelligent transportation systems, such as intent detection for autonomous driving. However, there are many challenges to predict the trajectories of heterogeneous road agents (pedestrians, cyclists and vehicles) at a microscopical level. For example, an agent might be able to choose multiple plausible paths in complex interactions with other agents in varying environments. To this end, we propose an approach named Multi-Context Encoder Network (MCENET) that is trained by encoding both past and future scene context, interaction context and motion information to capture the patterns and variations of the future trajectories using a set of stochastic latent variables. In inference time, we combine the past context and motion information of the target agent with samplings of the latent variables to predict multiple realistic trajectories in the future. Through experiments on several datasets of varying scenes, our method outperforms some of the recent state-of-the-art methods for mixed traffic trajectory prediction by a large margin and more robust in a very challenging environment. The impact of each context is justified via ablation studies.",
        "published": "2020-02-14T11:04:41Z",
        "link": "http://arxiv.org/abs/2002.05966v5",
        "categories": [
            "cs.CV",
            "cs.CY",
            "cs.MA"
        ]
    },
    {
        "title": "Extended Markov Games to Learn Multiple Tasks in Multi-Agent   Reinforcement Learning",
        "authors": [
            "Borja G. León",
            "Francesco Belardinelli"
        ],
        "summary": "The combination of Formal Methods with Reinforcement Learning (RL) has recently attracted interest as a way for single-agent RL to learn multiple-task specifications. In this paper we extend this convergence to multi-agent settings and formally define Extended Markov Games as a general mathematical model that allows multiple RL agents to concurrently learn various non-Markovian specifications. To introduce this new model we provide formal definitions and proofs as well as empirical tests of RL algorithms running on this framework. Specifically, we use our model to train two different logic-based multi-agent RL algorithms to solve diverse settings of non-Markovian co-safe LTL specifications.",
        "published": "2020-02-14T12:37:41Z",
        "link": "http://arxiv.org/abs/2002.06000v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.LO",
            "cs.MA"
        ]
    },
    {
        "title": "Resource-Aware Control via Dynamic Pricing for Congestion Game with   Finite-Time Guarantees",
        "authors": [
            "Ezra Tampubolon",
            "Haris Ceribasic",
            "Holger Boche"
        ],
        "summary": "Congestion game is a widely used model for modern networked applications. A central issue in such applications is that the selfish behavior of the participants may result in resource overloading and negative externalities for the system participants. In this work, we propose a pricing mechanism that guarantees the sub-linear increase of the time-cumulative violation of the resource load constraints. The feature of our method is that it is resource-centric in the sense that it depends on the congestion state of the resources and not on specific characteristics of the system participants. This feature makes our mechanism scalable, flexible, and privacy-preserving. Moreover, we show by numerical simulations that our pricing mechanism has no significant effect on the agents' welfare in contrast to the improvement of the capacity violation.",
        "published": "2020-02-14T15:36:04Z",
        "link": "http://arxiv.org/abs/2002.06080v1",
        "categories": [
            "eess.SY",
            "cs.GT",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Coordination without communication: optimal regret in two players   multi-armed bandits",
        "authors": [
            "Sébastien Bubeck",
            "Thomas Budzinski"
        ],
        "summary": "We consider two agents playing simultaneously the same stochastic three-armed bandit problem. The two agents are cooperating but they cannot communicate. We propose a strategy with no collisions at all between the players (with very high probability), and with near-optimal regret $O(\\sqrt{T \\log(T)})$. We also argue that the extra logarithmic term $\\sqrt{\\log(T)}$ should be necessary by proving a lower bound for a full information variant of the problem.",
        "published": "2020-02-14T17:35:42Z",
        "link": "http://arxiv.org/abs/2002.07596v2",
        "categories": [
            "cs.GT",
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Resource Management in Wireless Networks via Multi-Agent Deep   Reinforcement Learning",
        "authors": [
            "Navid Naderializadeh",
            "Jaroslaw Sydir",
            "Meryem Simsek",
            "Hosein Nikopour"
        ],
        "summary": "We propose a mechanism for distributed resource management and interference mitigation in wireless networks using multi-agent deep reinforcement learning (RL). We equip each transmitter in the network with a deep RL agent that receives delayed observations from its associated users, while also exchanging observations with its neighboring agents, and decides on which user to serve and what transmit power to use at each scheduling interval. Our proposed framework enables agents to make decisions simultaneously and in a distributed manner, unaware of the concurrent decisions of other agents. Moreover, our design of the agents' observation and action spaces is scalable, in the sense that an agent trained on a scenario with a specific number of transmitters and users can be applied to scenarios with different numbers of transmitters and/or users. Simulation results demonstrate the superiority of our proposed approach compared to decentralized baselines in terms of the tradeoff between average and $5^{th}$ percentile user rates, while achieving performance close to, and even in certain cases outperforming, that of a centralized information-theoretic baseline. We also show that our trained agents are robust and maintain their performance gains when experiencing mismatches between train and test deployments.",
        "published": "2020-02-14T19:01:07Z",
        "link": "http://arxiv.org/abs/2002.06215v2",
        "categories": [
            "cs.LG",
            "cs.IT",
            "cs.MA",
            "eess.SP",
            "math.IT",
            "stat.ML"
        ]
    },
    {
        "title": "Social-WaGDAT: Interaction-aware Trajectory Prediction via Wasserstein   Graph Double-Attention Network",
        "authors": [
            "Jiachen Li",
            "Hengbo Ma",
            "Zhihao Zhang",
            "Masayoshi Tomizuka"
        ],
        "summary": "Effective understanding of the environment and accurate trajectory prediction of surrounding dynamic obstacles are indispensable for intelligent mobile systems (like autonomous vehicles and social robots) to achieve safe and high-quality planning when they navigate in highly interactive and crowded scenarios. Due to the existence of frequent interactions and uncertainty in the scene evolution, it is desired for the prediction system to enable relational reasoning on different entities and provide a distribution of future trajectories for each agent. In this paper, we propose a generic generative neural system (called Social-WaGDAT) for multi-agent trajectory prediction, which makes a step forward to explicit interaction modeling by incorporating relational inductive biases with a dynamic graph representation and leverages both trajectory and scene context information. We also employ an efficient kinematic constraint layer applied to vehicle trajectory prediction which not only ensures physical feasibility but also enhances model performance. The proposed system is evaluated on three public benchmark datasets for trajectory prediction, where the agents cover pedestrians, cyclists and on-road vehicles. The experimental results demonstrate that our model achieves better performance than various baseline approaches in terms of prediction accuracy.",
        "published": "2020-02-14T20:11:13Z",
        "link": "http://arxiv.org/abs/2002.06241v1",
        "categories": [
            "cs.CV",
            "cs.LG",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Jelly Bean World: A Testbed for Never-Ending Learning",
        "authors": [
            "Emmanouil Antonios Platanios",
            "Abulhair Saparov",
            "Tom Mitchell"
        ],
        "summary": "Machine learning has shown growing success in recent years. However, current machine learning systems are highly specialized, trained for particular problems or domains, and typically on a single narrow dataset. Human learning, on the other hand, is highly general and adaptable. Never-ending learning is a machine learning paradigm that aims to bridge this gap, with the goal of encouraging researchers to design machine learning systems that can learn to perform a wider variety of inter-related tasks in more complex environments. To date, there is no environment or testbed to facilitate the development and evaluation of never-ending learning systems. To this end, we propose the Jelly Bean World testbed. The Jelly Bean World allows experimentation over two-dimensional grid worlds which are filled with items and in which agents can navigate. This testbed provides environments that are sufficiently complex and where more generally intelligent algorithms ought to perform better than current state-of-the-art reinforcement learning approaches. It does so by producing non-stationary environments and facilitating experimentation with multi-task, multi-agent, multi-modal, and curriculum learning settings. We hope that this new freely-available software will prompt new research and interest in the development and evaluation of never-ending learning systems and more broadly, general intelligence systems.",
        "published": "2020-02-15T02:43:16Z",
        "link": "http://arxiv.org/abs/2002.06306v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Designing Interaction for Multi-agent Cooperative System in an Office   Environment",
        "authors": [
            "Chao Wang",
            "Stephan Hasler",
            "Manuel Muehlig",
            "Frank Joublin",
            "Antonello Ceravola",
            "Joerg Deigmoeller",
            "Lydia Fischer"
        ],
        "summary": "Future intelligent system will involve very various types of artificial agents, such as mobile robots, smart home infrastructure or personal devices, which share data and collaborate with each other to execute certain tasks.Designing an efficient human-machine interface, which can support users to express needs to the system, supervise the collaboration progress of different entities and evaluate the result, will be challengeable. This paper presents the design and implementation of the human-machine interface of Intelligent Cyber-Physical system (ICPS),which is a multi-entity coordination system of robots and other smart devices in a working environment. ICPS gathers sensory data from entities and then receives users' command, then optimizes plans to utilize the capability of different entities to serve people. Using multi-model interaction methods, e.g. graphical interfaces, speech interaction, gestures and facial expressions, ICPS is able to receive inputs from users through different entities, keep users aware of the progress and accomplish the task efficiently",
        "published": "2020-02-15T17:36:00Z",
        "link": "http://arxiv.org/abs/2002.06417v1",
        "categories": [
            "cs.HC",
            "cs.AI",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "R-MADDPG for Partially Observable Environments and Limited Communication",
        "authors": [
            "Rose E. Wang",
            "Michael Everett",
            "Jonathan P. How"
        ],
        "summary": "There are several real-world tasks that would benefit from applying multiagent reinforcement learning (MARL) algorithms, including the coordination among self-driving cars. The real world has challenging conditions for multiagent learning systems, such as its partial observable and nonstationary nature. Moreover, if agents must share a limited resource (e.g. network bandwidth) they must all learn how to coordinate resource use. This paper introduces a deep recurrent multiagent actor-critic framework (R-MADDPG) for handling multiagent coordination under partial observable set-tings and limited communication. We investigate recurrency effects on performance and communication use of a team of agents. We demonstrate that the resulting framework learns time dependencies for sharing missing observations, handling resource limitations, and developing different communication patterns among agents.",
        "published": "2020-02-16T21:25:44Z",
        "link": "http://arxiv.org/abs/2002.06684v2",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Reward Design for Driver Repositioning Using Multi-Agent Reinforcement   Learning",
        "authors": [
            "Zhenyu Shou",
            "Xuan Di"
        ],
        "summary": "A large portion of passenger requests is reportedly unserviced, partially due to vacant for-hire drivers' cruising behavior during the passenger seeking process. This paper aims to model the multi-driver repositioning task through a mean field multi-agent reinforcement learning (MARL) approach that captures competition among multiple agents. Because the direct application of MARL to the multi-driver system under a given reward mechanism will likely yield a suboptimal equilibrium due to the selfishness of drivers, this study proposes a reward design scheme with which a more desired equilibrium can be reached. To effectively solve the bilevel optimization problem with upper level as the reward design and the lower level as a multi-agent system, a Bayesian optimization (BO) algorithm is adopted to speed up the learning process. We then apply the bilevel optimization model to two case studies, namely, e-hailing driver repositioning under service charge and multiclass taxi driver repositioning under NYC congestion pricing. In the first case study, the model is validated by the agreement between the derived optimal control from BO and that from an analytical solution. With a simple piecewise linear service charge, the objective of the e-hailing platform can be increased by 8.4%. In the second case study, an optimal toll charge of $5.1 is solved using BO, which improves the objective of city planners by 7.9%, compared to that without any toll charge. Under this optimal toll charge, the number of taxis in the NYC central business district is decreased, indicating a better traffic condition, without substantially increasing the crowdedness of the subway system.",
        "published": "2020-02-17T00:10:58Z",
        "link": "http://arxiv.org/abs/2002.06723v3",
        "categories": [
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Learning Zero-Sum Simultaneous-Move Markov Games Using Function   Approximation and Correlated Equilibrium",
        "authors": [
            "Qiaomin Xie",
            "Yudong Chen",
            "Zhaoran Wang",
            "Zhuoran Yang"
        ],
        "summary": "We develop provably efficient reinforcement learning algorithms for two-player zero-sum finite-horizon Markov games with simultaneous moves. To incorporate function approximation, we consider a family of Markov games where the reward function and transition kernel possess a linear structure. Both the offline and online settings of the problems are considered. In the offline setting, we control both players and aim to find the Nash Equilibrium by minimizing the duality gap. In the online setting, we control a single player playing against an arbitrary opponent and aim to minimize the regret. For both settings, we propose an optimistic variant of the least-squares minimax value iteration algorithm. We show that our algorithm is computationally efficient and provably achieves an $\\tilde O(\\sqrt{d^3 H^3 T} )$ upper bound on the duality gap and regret, where $d$ is the linear dimension, $H$ the horizon and $T$ the total number of timesteps. Our results do not require additional assumptions on the sampling model.   Our setting requires overcoming several new challenges that are absent in Markov decision processes or turn-based Markov games. In particular, to achieve optimism with simultaneous moves, we construct both upper and lower confidence bounds of the value function, and then compute the optimistic policy by solving a general-sum matrix game with these bounds as the payoff matrices. As finding the Nash Equilibrium of a general-sum game is computationally hard, our algorithm instead solves for a Coarse Correlated Equilibrium (CCE), which can be obtained efficiently. To our best knowledge, such a CCE-based scheme for optimism has not appeared in the literature and might be of interest in its own right.",
        "published": "2020-02-17T17:04:16Z",
        "link": "http://arxiv.org/abs/2002.07066v3",
        "categories": [
            "cs.LG",
            "cs.GT",
            "cs.MA",
            "math.OC",
            "stat.ML"
        ]
    },
    {
        "title": "Distributed Adaptive Newton Methods with Global Superlinear Convergence",
        "authors": [
            "Jiaqi Zhang",
            "Keyou You",
            "Tamer Başar"
        ],
        "summary": "This paper considers the distributed optimization problem where each node of a peer-to-peer network minimizes a finite sum of objective functions by communicating with its neighboring nodes. In sharp contrast to the existing literature where the fastest distributed algorithms converge either with a global linear or a local superlinear rate, we propose a distributed adaptive Newton (DAN) algorithm with a global quadratic convergence rate. Our key idea lies in the design of a finite-time set-consensus method with Polyak's adaptive stepsize. Moreover, we introduce a low-rank matrix approximation (LA) technique to compress the innovation of Hessian matrix so that each node only needs to transmit message of dimension $\\mathcal{O}(p)$ (where $p$ is the dimension of decision vectors) per iteration, which is essentially the same as that of first-order methods. Nevertheless, the resulting DAN-LA converges to an optimal solution with a global superlinear rate. Numerical experiments on logistic regression problems are conducted to validate their advantages over existing methods.",
        "published": "2020-02-18T05:29:30Z",
        "link": "http://arxiv.org/abs/2002.07378v3",
        "categories": [
            "math.OC",
            "cs.DC",
            "cs.MA",
            "cs.SY",
            "eess.SP",
            "eess.SY"
        ]
    },
    {
        "title": "Multi-Issue Bargaining With Deep Reinforcement Learning",
        "authors": [
            "Ho-Chun Herbert Chang"
        ],
        "summary": "Negotiation is a process where agents aim to work through disputes and maximize their surplus. As the use of deep reinforcement learning in bargaining games is unexplored, this paper evaluates its ability to exploit, adapt, and cooperate to produce fair outcomes. Two actor-critic networks were trained for the bidding and acceptance strategy, against time-based agents, behavior-based agents, and through self-play. Gameplay against these agents reveals three key findings. 1) Neural agents learn to exploit time-based agents, achieving clear transitions in decision preference values. The Cauchy distribution emerges as suitable for sampling offers, due to its peaky center and heavy tails. The kurtosis and variance sensitivity of the probability distributions used for continuous control produce trade-offs in exploration and exploitation. 2) Neural agents demonstrate adaptive behavior against different combinations of concession, discount factors, and behavior-based strategies. 3) Most importantly, neural agents learn to cooperate with other behavior-based agents, in certain cases utilizing non-credible threats to force fairer results. This bears similarities with reputation-based strategies in the evolutionary dynamics, and departs from equilibria in classical game theory.",
        "published": "2020-02-18T18:33:46Z",
        "link": "http://arxiv.org/abs/2002.07788v1",
        "categories": [
            "cs.MA",
            "cs.GT",
            "cs.LG"
        ]
    },
    {
        "title": "An Efficient Transfer Learning Framework for Multiagent Reinforcement   Learning",
        "authors": [
            "Tianpei Yang",
            "Weixun Wang",
            "Hongyao Tang",
            "Jianye Hao",
            "Zhaopeng Meng",
            "Hangyu Mao",
            "Dong Li",
            "Wulong Liu",
            "Chengwei Zhang",
            "Yujing Hu",
            "Yingfeng Chen",
            "Changjie Fan"
        ],
        "summary": "Transfer Learning has shown great potential to enhance single-agent Reinforcement Learning (RL) efficiency. Similarly, Multiagent RL (MARL) can also be accelerated if agents can share knowledge with each other. However, it remains a problem of how an agent should learn from other agents. In this paper, we propose a novel Multiagent Policy Transfer Framework (MAPTF) to improve MARL efficiency. MAPTF learns which agent's policy is the best to reuse for each agent and when to terminate it by modeling multiagent policy transfer as the option learning problem. Furthermore, in practice, the option module can only collect all agent's local experiences for update due to the partial observability of the environment. While in this setting, each agent's experience may be inconsistent with each other, which may cause the inaccuracy and oscillation of the option-value's estimation. Therefore, we propose a novel option learning algorithm, the successor representation option learning to solve it by decoupling the environment dynamics from rewards and learning the option-value under each agent's preference. MAPTF can be easily combined with existing deep RL and MARL approaches, and experimental results show it significantly boosts the performance of existing methods in both discrete and continuous state spaces.",
        "published": "2020-02-19T07:01:38Z",
        "link": "http://arxiv.org/abs/2002.08030v4",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Multi-Agent Meta-Reinforcement Learning for Self-Powered and Sustainable   Edge Computing Systems",
        "authors": [
            "Md. Shirajum Munir",
            "Nguyen H. Tran",
            "Walid Saad",
            "Choong Seon Hong"
        ],
        "summary": "The stringent requirements of mobile edge computing (MEC) applications and functions fathom the high capacity and dense deployment of MEC hosts to the upcoming wireless networks. However, operating such high capacity MEC hosts can significantly increase energy consumption. Thus, a base station (BS) unit can act as a self-powered BS. In this paper, an effective energy dispatch mechanism for self-powered wireless networks with edge computing capabilities is studied. First, a two-stage linear stochastic programming problem is formulated with the goal of minimizing the total energy consumption cost of the system while fulfilling the energy demand. Second, a semi-distributed data-driven solution is proposed by developing a novel multi-agent meta-reinforcement learning (MAMRL) framework to solve the formulated problem. In particular, each BS plays the role of a local agent that explores a Markovian behavior for both energy consumption and generation while each BS transfers time-varying features to a meta-agent. Sequentially, the meta-agent optimizes (i.e., exploits) the energy dispatch decision by accepting only the observations from each local agent with its own state information. Meanwhile, each BS agent estimates its own energy dispatch policy by applying the learned parameters from meta-agent. Finally, the proposed MAMRL framework is benchmarked by analyzing deterministic, asymmetric, and stochastic environments in terms of non-renewable energy usages, energy cost, and accuracy. Experimental results show that the proposed MAMRL model can reduce up to 11% non-renewable energy usage and by 22.4% the energy cost (with 95.8% prediction accuracy), compared to other baseline methods.",
        "published": "2020-02-20T04:58:07Z",
        "link": "http://arxiv.org/abs/2002.08567v3",
        "categories": [
            "cs.LG",
            "cs.MA",
            "eess.SP",
            "stat.ML"
        ]
    },
    {
        "title": "Semantic Web Environments for Multi-Agent Systems: Enabling agents to   use Web of Things via semantic web",
        "authors": [
            "Alaa Daoud"
        ],
        "summary": "The Web is ubiquitous, increasingly populated with interconnected data, services, people, and objects. Semantic web technologies (SWT) promote uniformity of data formats, as well as modularization and reuse of specifications (e.g., ontologies), by allowing them to include and refer to information provided by other ontologies. In such a context, multi-agent system (MAS) technologies are the right abstraction for developing decentralized and open Web applications in which agents discover, reason and act on Web resources and cooperate with each other and with people. The aim of the project is to propose an approach to transform \"Agent and artifact (A&A) meta-model\" into a Web-readable format with ontologies in line with semantic web formats and to reuse already existing ontologies in order to provide uniform access for agents to things.",
        "published": "2020-02-20T11:18:29Z",
        "link": "http://arxiv.org/abs/2003.02054v1",
        "categories": [
            "cs.SE",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Stochastic Decision-Making Model for Aggregation of Residential Units   with PV-Systems and Storages",
        "authors": [
            "Hossein Khazaei",
            "Ramin Moslemi",
            "Ratnesh Sharma"
        ],
        "summary": "Many residential energy consumers have installed photovoltaic (PV) panels and energy storage systems. These residential users can aggregate and participate in the energy markets. A stochastic decision making model for an aggregation of these residential units for participation in two-settlement markets is proposed in this paper. Scenarios are generated using Seasonal Autoregressive Integrated Moving Average (SARIMA) model and joint probability distribution function of the forecast errors to model the uncertainties of the real-time prices, PV generations and demands. The proposed scenario generation model of this paper treats forecast errors as random variable, which allows to reflect new information observed in the real-time market into scenario generation process without retraining SARIMA or re-fitting probability distribution functions over the forecast errors. This approach significantly improves the computational time of the proposed model. A simulation study is conducted for an aggregation of 6 residential units, and the results highlights the benefits of aggregation as well as the proposed stochastic decision-making model.",
        "published": "2020-02-20T13:23:31Z",
        "link": "http://arxiv.org/abs/2002.08720v1",
        "categories": [
            "math.OC",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Multi-Agent Reinforcement Learning as a Computational Tool for Language   Evolution Research: Historical Context and Future Challenges",
        "authors": [
            "Clément Moulin-Frier",
            "Pierre-Yves Oudeyer"
        ],
        "summary": "Computational models of emergent communication in agent populations are currently gaining interest in the machine learning community due to recent advances in Multi-Agent Reinforcement Learning (MARL). Current contributions are however still relatively disconnected from the earlier theoretical and computational literature aiming at understanding how language might have emerged from a prelinguistic substance. The goal of this paper is to position recent MARL contributions within the historical context of language evolution research, as well as to extract from this theoretical and computational background a few challenges for future research.",
        "published": "2020-02-20T17:26:46Z",
        "link": "http://arxiv.org/abs/2002.08878v2",
        "categories": [
            "cs.MA",
            "cs.CL",
            "cs.LG"
        ]
    },
    {
        "title": "Distributed No-Regret Learning in Multi-Agent Systems",
        "authors": [
            "Xiao Xu",
            "Qing Zhao"
        ],
        "summary": "In this tutorial article, we give an overview of new challenges and representative results on distributed no-regret learning in multi-agent systems modeled as repeated unknown games. Four emerging game characteristics---dynamicity, incomplete and imperfect feedback, bounded rationality, and heterogeneity---that challenge canonical game models are explored. For each of the four characteristics, we illuminate its implications and ramifications in game modeling, notions of regret, feasible game outcomes, and the design and analysis of distributed learning algorithms.",
        "published": "2020-02-20T22:30:17Z",
        "link": "http://arxiv.org/abs/2002.09047v1",
        "categories": [
            "cs.GT",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Adversarial Impacts on Autonomous Decentralized Lightweight Swarms",
        "authors": [
            "Shaya Wolf",
            "Rafer Cooley",
            "Mike Borowczak"
        ],
        "summary": "The decreased size and cost of Unmanned Aerial Vehicles (UAVs) and Unmanned Ground Vehicles (UGVs) has enabled the use of swarms of unmanned autonomous vehicles to accomplish a variety of tasks. By utilizing swarming behaviors, it is possible to efficiently accomplish coordinated tasks while minimizing per-drone computational requirements. Some drones rely on decentralized protocols that exhibit emergent behavior across the swarm. While fully decentralized algorithms remove obvious attack vectors their susceptibility to external influence is less understood. This work investigates the influences that can compromise the functionality of an autonomous swarm leading to hazardous situations and cascading vulnerabilities. When a swarm is tasked with missions involving the safety or health of humans, external influences could have serious consequences. The adversarial swarm in this work utilizes an attack vector embedded within the decentralized movement algorithm of a previously defined autonomous swarm designed to create a perimeter sentry swarm. Various simulations confirm the adversarial swarm's ability to capture significant portions (6-23%) of the perimeter.",
        "published": "2020-02-21T03:31:04Z",
        "link": "http://arxiv.org/abs/2002.09109v1",
        "categories": [
            "cs.MA",
            "68T42",
            "I.2.8; I.2.9"
        ]
    },
    {
        "title": "Hysteresis and disorder-induced order in continuous kinetic-like opinion   dynamics in complex networks",
        "authors": [
            "A. L. Oestereich",
            "M. A. Pires",
            "S. M. Duarte Queirós",
            "N. Crokidakis"
        ],
        "summary": "In this work we tackle a kinetic-like model of opinions dynamics in a networked population endued with a quenched plurality and polarization. Additionally, we consider pairwise interactions that are restrictive, which is modeled with a smooth bounded confidence. Our results show the interesting emergence of nonequilibrium hysteresis and heterogeneity-assisted ordering. Such counterintuitive phenomena are robust to different types of network architectures such as random, small-world and scale-free.",
        "published": "2020-02-21T15:47:37Z",
        "link": "http://arxiv.org/abs/2002.09366v1",
        "categories": [
            "physics.soc-ph",
            "cond-mat.stat-mech",
            "cs.MA",
            "cs.SI"
        ]
    },
    {
        "title": "A characterization of proportionally representative committees",
        "authors": [
            "Haris Aziz",
            "Barton E. Lee"
        ],
        "summary": "A well-known axiom for proportional representation is Proportionality of Solid Coalitions (PSC). We characterize committees satisfying PSC as possible outcomes of the Minimal Demand rule, which generalizes an approach pioneered by Michael Dummett.",
        "published": "2020-02-22T01:48:56Z",
        "link": "http://arxiv.org/abs/2002.09598v2",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.MA",
            "econ.TH"
        ]
    },
    {
        "title": "My Fair Bandit: Distributed Learning of Max-Min Fairness with   Multi-player Bandits",
        "authors": [
            "Ilai Bistritz",
            "Tavor Z. Baharav",
            "Amir Leshem",
            "Nicholas Bambos"
        ],
        "summary": "Consider N cooperative but non-communicating players where each plays one out of M arms for T turns. Players have different utilities for each arm, representable as an NxM matrix. These utilities are unknown to the players. In each turn players select an arm and receive a noisy observation of their utility for it. However, if any other players selected the same arm that turn, all colliding players will all receive zero utility due to the conflict. No other communication or coordination between the players is possible. Our goal is to design a distributed algorithm that learns the matching between players and arms that achieves max-min fairness while minimizing the regret. We present an algorithm and prove that it is regret optimal up to a $\\log\\log T$ factor. This is the first max-min fairness multi-player bandit algorithm with (near) order optimal regret.",
        "published": "2020-02-23T02:05:55Z",
        "link": "http://arxiv.org/abs/2002.09808v4",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "A Formal Treatment of Contract Signature",
        "authors": [
            "Ron van der Meyden"
        ],
        "summary": "The paper develops a logical understanding of processes for signature of legal contracts, motivated by applications to legal recognition of smart contracts on blockchain platforms. A number of axioms and rules of inference are developed that can be used to justify a ``meeting of the minds'' precondition for contract formation from the fact that certain content has been signed. In addition to an ``offer and acceptance'' process, the paper considers ``signature in counterparts'', a legal process that permits a contract between two or more parties to be brought into force by having the parties independently (possibly, remotely) sign different copies of the contract, rather than placing their signatures on a common copy at a physical meeting. It is argued that a satisfactory account of signature in counterparts benefits from a logic with syntactic self-reference. The axioms used are supported by a formal semantics, and a number of further properties of the logic are investigated. In particular, it is shown that the logic implies that when a contract has been signed, the parties do not just agree, but are in mutual agreement (a common-knowledge-like notion) about the terms of the contract.",
        "published": "2020-02-23T04:39:56Z",
        "link": "http://arxiv.org/abs/2002.09827v3",
        "categories": [
            "cs.AI",
            "cs.LO",
            "cs.MA",
            "F.4.1; I.2.4; J.1"
        ]
    },
    {
        "title": "A Simulation Model Demonstrating the Impact of Social Aspects on Social   Internet of Things",
        "authors": [
            "Kashif Zia"
        ],
        "summary": "In addition to seamless connectivity and smartness, the objects in the Internet of Things (IoT) are expected to have the social capabilities -- these objects are termed as ``social objects''. In this paper, an intuitive paradigm of social interactions between these objects are argued and modeled. The impact of social behavior on the interaction pattern of social objects is studied taking Peer-to-Peer (P2P) resource sharing as an example application. The model proposed in this paper studies the implications of competitive vs. cooperative social paradigm, while peers attempt to attain the shared resources / services. The simulation results divulge that the social capabilities of the peers impart a significant increase in the quality of interactions between social objects. Through an agent-based simulation study, it is proved that cooperative strategy is more efficient than competitive strategy. Moreover, cooperation with an underpinning on real-life networking structure and mobility does not negatively impact the efficiency of the system at all; rather it helps.",
        "published": "2020-02-23T07:18:39Z",
        "link": "http://arxiv.org/abs/2002.11507v1",
        "categories": [
            "cs.AI",
            "cs.MA",
            "cs.SI"
        ]
    },
    {
        "title": "Optimizing Traffic Lights with Multi-agent Deep Reinforcement Learning   and V2X communication",
        "authors": [
            "Azhar Hussain",
            "Tong Wang",
            "Cao Jiahua"
        ],
        "summary": "We consider a system to optimize duration of traffic signals using multi-agent deep reinforcement learning and Vehicle-to-Everything (V2X) communication. This system aims at analyzing independent and shared rewards for multi-agents to control duration of traffic lights. A learning agent traffic light gets information along its lanes within a circular V2X coverage. The duration cycles of traffic light are modeled as Markov decision Processes. We investigate four variations of reward functions. The first two are unshared-rewards: based on waiting number, and waiting time of vehicles between two cycles of traffic light. The third and fourth functions are: shared-rewards based on waiting cars, and waiting time for all agents. Each agent has a memory for optimization through target network and prioritized experience replay. We evaluate multi-agents through the Simulation of Urban MObility (SUMO) simulator. The results prove effectiveness of the proposed system to optimize traffic signals and reduce average waiting cars to 41.5 % as compared to the traditional periodic traffic control system.",
        "published": "2020-02-23T07:43:12Z",
        "link": "http://arxiv.org/abs/2002.09853v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Toward dynamical crowd control to prevent hazardous situations",
        "authors": [
            "Tomoichi Takahashi"
        ],
        "summary": "It is common for large crowds to gather to attend games, exhibitions, political rallies, and other events. Thus, careful designs and operational plans are made to ensure the safe, secure, and efficient movement of people in these crowded environments. However, the congestion created by large crowds has resulted in hazardous incidents across the world. Developments in information technology can provide new means to disseminate public information, thus changing human behavior in situations of danger and duress. In this paper, we propose a crowd control and evacuation guidance management system using digital promotional signage to demonstrate the effects of crowd control via simulations.",
        "published": "2020-02-23T09:52:05Z",
        "link": "http://arxiv.org/abs/2002.10860v1",
        "categories": [
            "cs.HC",
            "cs.MA"
        ]
    },
    {
        "title": "Quantized Decentralized Stochastic Learning over Directed Graphs",
        "authors": [
            "Hossein Taheri",
            "Aryan Mokhtari",
            "Hamed Hassani",
            "Ramtin Pedarsani"
        ],
        "summary": "We consider a decentralized stochastic learning problem where data points are distributed among computing nodes communicating over a directed graph. As the model size gets large, decentralized learning faces a major bottleneck that is the heavy communication load due to each node transmitting large messages (model updates) to its neighbors. To tackle this bottleneck, we propose the quantized decentralized stochastic learning algorithm over directed graphs that is based on the push-sum algorithm in decentralized consensus optimization. More importantly, we prove that our algorithm achieves the same convergence rates of the decentralized stochastic learning algorithm with exact-communication for both convex and non-convex losses. Numerical evaluations corroborate our main theoretical results and illustrate significant speed-up compared to the exact-communication methods.",
        "published": "2020-02-23T18:25:39Z",
        "link": "http://arxiv.org/abs/2002.09964v5",
        "categories": [
            "cs.DC",
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "eess.SP",
            "eess.SY"
        ]
    },
    {
        "title": "Alternating the Population and Control Neural Networks to Solve   High-Dimensional Stochastic Mean-Field Games",
        "authors": [
            "Alex Tong Lin",
            "Samy Wu Fung",
            "Wuchen Li",
            "Levon Nurbekyan",
            "Stanley J. Osher"
        ],
        "summary": "We present APAC-Net, an alternating population and agent control neural network for solving stochastic mean field games (MFGs). Our algorithm is geared toward high-dimensional instances of MFGs that are beyond reach with existing solution methods. We achieve this in two steps. First, we take advantage of the underlying variational primal-dual structure that MFGs exhibit and phrase it as a convex-concave saddle point problem. Second, we parameterize the value and density functions by two neural networks, respectively. By phrasing the problem in this manner, solving the MFG can be interpreted as a special case of training a generative adversarial network (GAN). We show the potential of our method on up to 100-dimensional MFG problems.",
        "published": "2020-02-24T08:24:52Z",
        "link": "http://arxiv.org/abs/2002.10113v4",
        "categories": [
            "cs.LG",
            "cs.MA",
            "math.OC",
            "stat.ML"
        ]
    },
    {
        "title": "Optimal strategies in the Fighting Fantasy gaming system: influencing   stochastic dynamics by gambling with limited resource",
        "authors": [
            "Iain G. Johnston"
        ],
        "summary": "Fighting Fantasy is a popular recreational fantasy gaming system worldwide. Combat in this system progresses through a stochastic game involving a series of rounds, each of which may be won or lost. Each round, a limited resource (`luck') may be spent on a gamble to amplify the benefit from a win or mitigate the deficit from a loss. However, the success of this gamble depends on the amount of remaining resource, and if the gamble is unsuccessful, benefits are reduced and deficits increased. Players thus dynamically choose to expend resource to attempt to influence the stochastic dynamics of the game, with diminishing probability of positive return. The identification of the optimal strategy for victory is a Markov decision problem that has not yet been solved. Here, we combine stochastic analysis and simulation with dynamic programming to characterise the dynamical behaviour of the system in the absence and presence of gambling policy. We derive a simple expression for the victory probability without luck-based strategy. We use a backward induction approach to solve the Bellman equation for the system and identify the optimal strategy for any given state during the game. The optimal control strategies can dramatically enhance success probabilities, but take detailed forms; we use stochastic simulation to approximate these optimal strategies with simple heuristics that can be practically employed. Our findings provide a roadmap to improving success in the games that millions of people play worldwide, and inform a class of resource allocation problems with diminishing returns in stochastic games.",
        "published": "2020-02-24T11:31:25Z",
        "link": "http://arxiv.org/abs/2002.10172v1",
        "categories": [
            "cs.AI",
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "iLQGames.jl: Rapidly Designing and Solving Differential Games in Julia",
        "authors": [
            "Lasse Peters",
            "Zachary N. Sunberg"
        ],
        "summary": "In many problems that involve multiple decision making agents, optimal choices for each agent depend on the choices of others. Differential game theory provides a principled formalism for expressing these coupled interactions and recent work offers efficient approximations to solve these problems to non-cooperative equilibria. iLQGames.jl is a framework for designing and solving differential games, built around the iterative linear-quadratic method. It is written in the Julia programming language to allow flexible prototyping and integration with other research software, while leveraging the high-performance nature of the language to allow real-time execution. The open-source software package can be found at https://github.com/lassepe/iLQGames.jl.",
        "published": "2020-02-24T12:01:05Z",
        "link": "http://arxiv.org/abs/2002.10185v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Bio-inspired Optimization: metaheuristic algorithms for optimization",
        "authors": [
            "Pravin S Game",
            "Vinod Vaze",
            "Emmanuel M"
        ],
        "summary": "In today's day and time solving real-world complex problems has become fundamentally vital and critical task. Many of these are combinatorial problems, where optimal solutions are sought rather than exact solutions. Traditional optimization methods are found to be effective for small scale problems. However, for real-world large scale problems, traditional methods either do not scale up or fail to obtain optimal solutions or they end-up giving solutions after a long running time. Even earlier artificial intelligence based techniques used to solve these problems could not give acceptable results. However, last two decades have seen many new methods in AI based on the characteristics and behaviors of the living organisms in the nature which are categorized as bio-inspired or nature inspired optimization algorithms. These methods, are also termed meta-heuristic optimization methods, have been proved theoretically and implemented using simulation as well used to create many useful applications. They have been used extensively to solve many industrial and engineering complex problems due to being easy to understand, flexible, simple to adapt to the problem at hand and most importantly their ability to come out of local optima traps. This local optima avoidance property helps in finding global optimal solutions. This paper is aimed at understanding how nature has inspired many optimization algorithms, basic categorization of them, major bio-inspired optimization algorithms invented in recent time with their applications.",
        "published": "2020-02-24T13:26:34Z",
        "link": "http://arxiv.org/abs/2003.11637v1",
        "categories": [
            "cs.NE",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Efficient exploration of zero-sum stochastic games",
        "authors": [
            "Carlos Martin",
            "Tuomas Sandholm"
        ],
        "summary": "We investigate the increasingly important and common game-solving setting where we do not have an explicit description of the game but only oracle access to it through gameplay, such as in financial or military simulations and computer games. During a limited-duration learning phase, the algorithm can control the actions of both players in order to try to learn the game and how to play it well. After that, the algorithm has to produce a strategy that has low exploitability. Our motivation is to quickly learn strategies that have low exploitability in situations where evaluating the payoffs of a queried strategy profile is costly. For the stochastic game setting, we propose using the distribution of state-action value functions induced by a belief distribution over possible environments. We compare the performance of various exploration strategies for this task, including generalizations of Thompson sampling and Bayes-UCB to this new setting. These two consistently outperform other strategies.",
        "published": "2020-02-24T20:30:38Z",
        "link": "http://arxiv.org/abs/2002.10524v1",
        "categories": [
            "cs.AI",
            "cs.GT",
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Scalable Multi-Agent Inverse Reinforcement Learning via   Actor-Attention-Critic",
        "authors": [
            "Wonseok Jeon",
            "Paul Barde",
            "Derek Nowrouzezahrai",
            "Joelle Pineau"
        ],
        "summary": "Multi-agent adversarial inverse reinforcement learning (MA-AIRL) is a recent approach that applies single-agent AIRL to multi-agent problems where we seek to recover both policies for our agents and reward functions that promote expert-like behavior. While MA-AIRL has promising results on cooperative and competitive tasks, it is sample-inefficient and has only been validated empirically for small numbers of agents -- its ability to scale to many agents remains an open question. We propose a multi-agent inverse RL algorithm that is more sample-efficient and scalable than previous works. Specifically, we employ multi-agent actor-attention-critic (MAAC) -- an off-policy multi-agent RL (MARL) method -- for the RL inner loop of the inverse RL procedure. In doing so, we are able to increase sample efficiency compared to state-of-the-art baselines, across both small- and large-scale tasks. Moreover, the RL agents trained on the rewards recovered by our method better match the experts than those trained on the rewards derived from the baselines. Finally, our method requires far fewer agent-environment interactions, particularly as the number of agents increases.",
        "published": "2020-02-24T20:30:45Z",
        "link": "http://arxiv.org/abs/2002.10525v1",
        "categories": [
            "cs.MA",
            "cs.LG"
        ]
    },
    {
        "title": "Inducing Equilibria in Networked Public Goods Games through Network   Structure Modification",
        "authors": [
            "David Kempe",
            "Sixie Yu",
            "Yevgeniy Vorobeychik"
        ],
        "summary": "Networked public goods games model scenarios in which self-interested agents decide whether or how much to invest in an action that benefits not only themselves, but also their network neighbors. Examples include vaccination, security investment, and crime reporting. While every agent's utility is increasing in their neighbors' joint investment, the specific form can vary widely depending on the scenario. A principal, such as a policymaker, may wish to induce large investment from the agents. Besides direct incentives, an important lever here is the network structure itself: by adding and removing edges, for example, through community meetings, the principal can change the nature of the utility functions, resulting in different, and perhaps socially preferable, equilibrium outcomes. We initiate an algorithmic study of targeted network modifications with the goal of inducing equilibria of a particular form. We study this question for a variety of equilibrium forms (induce all agents to invest, at least a given set $S$, exactly a given set $S$, at least $k$ agents), and for a variety of utility functions. While we show that the problem is NP-complete for a number of these scenarios, we exhibit a broad array of scenarios in which the problem can be solved in polynomial time by non-trivial reductions to (minimum-cost) matching problems.",
        "published": "2020-02-25T02:30:52Z",
        "link": "http://arxiv.org/abs/2002.10627v2",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "RMB-DPOP: Refining MB-DPOP by Reducing Redundant Inferences",
        "authors": [
            "Ziyu Chen",
            "Wenxin Zhang",
            "Yanchen Deng",
            "Dingding Chen",
            "Qing Li"
        ],
        "summary": "MB-DPOP is an important complete algorithm for solving Distributed Constraint Optimization Problems (DCOPs) by exploiting a cycle-cut idea to implement memory-bounded inference. However, each cluster root in the algorithm is responsible for enumerating all the instantiations of its cycle-cut nodes, which would cause redundant inferences when its branches do not have the same cycle-cut nodes. Additionally, a large number of cycle-cut nodes and the iterative nature of MB-DPOP further exacerbate the pathology. As a result, MB-DPOP could suffer from huge coordination overheads and cannot scale up well. Therefore, we present RMB-DPOP which incorporates several novel mechanisms to reduce redundant inferences and improve the scalability of MB-DPOP. First, using the independence among the cycle-cut nodes in different branches, we distribute the enumeration of instantiations into different branches whereby the number of nonconcurrent instantiations reduces significantly and each branch can perform memory bounded inference asynchronously. Then, taking the topology into the consideration, we propose an iterative allocation mechanism to choose the cycle-cut nodes that cover a maximum of active nodes in a cluster and break ties according to their relative positions in a pseudo-tree. Finally, a caching mechanism is proposed to further reduce unnecessary inferences when the historical results are compatible with the current instantiations. We theoretically show that with the same number of cycle-cut nodes RMB-DPOP requires as many messages as MB-DPOP in the worst case and the experimental results show our superiorities over the state-of-the-art.",
        "published": "2020-02-25T03:19:29Z",
        "link": "http://arxiv.org/abs/2002.10641v1",
        "categories": [
            "cs.MA",
            "cs.DC"
        ]
    },
    {
        "title": "Distributed Algorithms for Composite Optimization: Unified Framework and   Convergence Analysis",
        "authors": [
            "Jinming Xu",
            "Ye Tian",
            "Ying Sun",
            "Gesualdo Scutari"
        ],
        "summary": "We study distributed composite optimization over networks: agents minimize a sum of smooth (strongly) convex functions, the agents' sum-utility, plus a nonsmooth (extended-valued) convex one. We propose a general unified algorithmic framework for such a class of problems and provide a unified convergence analysis leveraging the theory of operator splitting. Distinguishing features of our scheme are: (i) When the agents' functions are strongly convex, the algorithm converges at a linear rate, whose dependence on the agents' functions and network topology is decoupled, matching the typical rates of centralized optimization; the rate expression improves on existing results; (ii) When the objective function is convex (but not strongly convex), similar separation as in (i) is established for the coefficient of the proved sublinear rate; (iii) The algorithm can adjust the ratio between the number of communications and computations to achieve a rate (in terms of computations) independent on the network connectivity; and (iv) A by-product of our analysis is a tuning recommendation for several existing (non accelerated) distributed algorithms yielding the fastest provably (worst-case) convergence rate. This is the first time that a general distributed algorithmic framework applicable to composite optimization enjoys all such properties.",
        "published": "2020-02-25T07:34:40Z",
        "link": "http://arxiv.org/abs/2002.11534v2",
        "categories": [
            "math.OC",
            "cs.DC",
            "cs.MA"
        ]
    },
    {
        "title": "TanksWorld: A Multi-Agent Environment for AI Safety Research",
        "authors": [
            "Corban G. Rivera",
            "Olivia Lyons",
            "Arielle Summitt",
            "Ayman Fatima",
            "Ji Pak",
            "William Shao",
            "Robert Chalmers",
            "Aryeh Englander",
            "Edward W. Staley",
            "I-Jeng Wang",
            "Ashley J. Llorens"
        ],
        "summary": "The ability to create artificial intelligence (AI) capable of performing complex tasks is rapidly outpacing our ability to ensure the safe and assured operation of AI-enabled systems. Fortunately, a landscape of AI safety research is emerging in response to this asymmetry and yet there is a long way to go. In particular, recent simulation environments created to illustrate AI safety risks are relatively simple or narrowly-focused on a particular issue. Hence, we see a critical need for AI safety research environments that abstract essential aspects of complex real-world applications. In this work, we introduce the AI safety TanksWorld as an environment for AI safety research with three essential aspects: competing performance objectives, human-machine teaming, and multi-agent competition. The AI safety TanksWorld aims to accelerate the advancement of safe multi-agent decision-making algorithms by providing a software framework to support competitions with both system performance and safety objectives. As a work in progress, this paper introduces our research objectives and learning environment with reference code and baseline performance metrics to follow in a future work.",
        "published": "2020-02-25T21:00:52Z",
        "link": "http://arxiv.org/abs/2002.11174v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Simulation of Real-time Routing for UAS traffic Management with   Communication and Airspace Safety Considerations",
        "authors": [
            "Zhao Jin",
            "Ziyi Zhao",
            "Chen Luo",
            "Franco Basti",
            "Adrian Solomon",
            "M. Cenk Gursoy",
            "Carlos Caicedo",
            "Qinru Qiu"
        ],
        "summary": "Small Unmanned Aircraft Systems (sUAS) will be an important component of the smart city and intelligent transportation environments of the near future. The demand for sUAS related applications, such as commercial delivery and land surveying, is expected to grow rapidly in next few years. In general, sUAS traffic routing and management functions are needed to coordinate the launching of sUAS from different launch sites and determine their trajectories to avoid conflict while considering several other constraints such as expected arrival time, minimum flight energy, and availability of communication resources. However, as the airborne sUAS density grows in a certain area, it is difficult to foresee the potential airspace and communications resource conflicts and make immediate decisions to avoid them. To address this challenge, we present a temporal and spatial routing algorithm and simulation platform for sUAS trajectory management in a high density urban area that plans sUAS movements in a spatial and temporal maze taking into account obstacles that are either static or dynamic in time. The routing allows the sUAS to avoid static no-fly areas (i.e. static obstacles) or other in-flight sUAS and areas that have congested communication resources (i.e. dynamic obstacles). The algorithm is evaluated using an agent-based simulation platform. The simulation results show that the proposed algorithm outperforms other route management algorithms in many areas, especially in processing speed and memory efficiency. Detailed comparisons are provided for the sUAS flight time, the overall throughput, conflict rate and communication resource utilization. The results demonstrate that our proposed algorithm can be used to address the airspace and communication resource utilization needs for a next generation smart city and smart transportation.",
        "published": "2020-02-27T00:54:11Z",
        "link": "http://arxiv.org/abs/2002.11861v1",
        "categories": [
            "cs.MA",
            "eess.SP"
        ]
    },
    {
        "title": "Learning Scalable Multi-Agent Coordination by Spatial Differentiation   for Traffic Signal Control",
        "authors": [
            "Junjia Liu",
            "Huimin Zhang",
            "Zhuang Fu",
            "Yao Wang"
        ],
        "summary": "The intelligent control of the traffic signal is critical to the optimization of transportation systems. To achieve global optimal traffic efficiency in large-scale road networks, recent works have focused on coordination among intersections, which have shown promising results. However, existing studies paid more attention to observations sharing among intersections (both explicit and implicit) and did not care about the consequences after decisions. In this paper, we design a multiagent coordination framework based on Deep Reinforcement Learning methods for traffic signal control, defined as {\\gamma}-Reward that includes both original {\\gamma}-Reward and {\\gamma}-Attention-Reward. Specifically, we propose the Spatial Differentiation method for coordination which uses the temporal-spatial information in the replay buffer to amend the reward of each action. A concise theoretical analysis that proves the proposed model can converge to Nash equilibrium is given. By extending the idea of Markov Chain to the dimension of space-time, this truly decentralized coordination mechanism replaces the graph attention method and realizes the decoupling of the road network, which is more scalable and more in line with practice. The simulation results show that the proposed model remains a state-of-the-art performance even not use a centralized setting. Code is available in https://github.com/Skylark0924/Gamma Reward.",
        "published": "2020-02-27T02:16:00Z",
        "link": "http://arxiv.org/abs/2002.11874v3",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "A Visual Communication Map for Multi-Agent Deep Reinforcement Learning",
        "authors": [
            "Ngoc Duy Nguyen",
            "Thanh Thi Nguyen",
            "Doug Creighton",
            "Saeid Nahavandi"
        ],
        "summary": "Deep reinforcement learning has been applied successfully to solve various real-world problems and the number of its applications in the multi-agent settings has been increasing. Multi-agent learning distinctly poses significant challenges in the effort to allocate a concealed communication medium. Agents receive thorough knowledge from the medium to determine subsequent actions in a distributed nature. Apparently, the goal is to leverage the cooperation of multiple agents to achieve a designated objective efficiently. Recent studies typically combine a specialized neural network with reinforcement learning to enable communication between agents. This approach, however, limits the number of agents or necessitates the homogeneity of the system. In this paper, we have proposed a more scalable approach that not only deals with a great number of agents but also enables collaboration between dissimilar functional agents and compatibly combined with any deep reinforcement learning methods. Specifically, we create a global communication map to represent the status of each agent in the system visually. The visual map and the environmental state are fed to a shared-parameter network to train multiple agents concurrently. Finally, we select the Asynchronous Advantage Actor-Critic (A3C) algorithm to demonstrate our proposed scheme, namely Visual communication map for Multi-agent A3C (VMA3C). Simulation results show that the use of visual communication map improves the performance of A3C regarding learning speed, reward achievement, and robustness in multi-agent problems.",
        "published": "2020-02-27T02:38:21Z",
        "link": "http://arxiv.org/abs/2002.11882v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.GT",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Learning Optimal Temperature Region for Solving Mixed Integer Functional   DCOPs",
        "authors": [
            "Saaduddin Mahmud",
            "Md. Mosaddek Khan",
            "Moumita Choudhury",
            "Long Tran-Thanh",
            "Nicholas R. Jennings"
        ],
        "summary": "Distributed Constraint Optimization Problems (DCOPs) are an important framework for modeling coordinated decision-making problems in multi-agent systems with a set of discrete variables. Later works have extended DCOPs to model problems with a set of continuous variables, named Functional DCOPs (F-DCOPs). In this paper, we combine both of these frameworks into the Mixed Integer Functional DCOP (MIF-DCOP) framework that can deal with problems regardless of their variables' type. We then propose a novel algorithm $-$ Distributed Parallel Simulated Annealing (DPSA), where agents cooperatively learn the optimal parameter configuration for the algorithm while also solving the given problem using the learned knowledge. Finally, we empirically evaluate our approach in DCOP, F-DCOP, and MIF-DCOP settings and show that DPSA produces solutions of significantly better quality than the state-of-the-art non-exact algorithms in their corresponding settings.",
        "published": "2020-02-27T09:46:40Z",
        "link": "http://arxiv.org/abs/2002.12001v2",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Learning to Resolve Alliance Dilemmas in Many-Player Zero-Sum Games",
        "authors": [
            "Edward Hughes",
            "Thomas W. Anthony",
            "Tom Eccles",
            "Joel Z. Leibo",
            "David Balduzzi",
            "Yoram Bachrach"
        ],
        "summary": "Zero-sum games have long guided artificial intelligence research, since they possess both a rich strategy space of best-responses and a clear evaluation metric. What's more, competition is a vital mechanism in many real-world multi-agent systems capable of generating intelligent innovations: Darwinian evolution, the market economy and the AlphaZero algorithm, to name a few. In two-player zero-sum games, the challenge is usually viewed as finding Nash equilibrium strategies, safeguarding against exploitation regardless of the opponent. While this captures the intricacies of chess or Go, it avoids the notion of cooperation with co-players, a hallmark of the major transitions leading from unicellular organisms to human civilization. Beyond two players, alliance formation often confers an advantage; however this requires trust, namely the promise of mutual cooperation in the face of incentives to defect. Successful play therefore requires adaptation to co-players rather than the pursuit of non-exploitability. Here we argue that a systematic study of many-player zero-sum games is a crucial element of artificial intelligence research. Using symmetric zero-sum matrix games, we demonstrate formally that alliance formation may be seen as a social dilemma, and empirically that na\\\"ive multi-agent reinforcement learning therefore fails to form alliances. We introduce a toy model of economic competition, and show how reinforcement learning may be augmented with a peer-to-peer contract mechanism to discover and enforce alliances. Finally, we generalize our agent model to incorporate temporally-extended contracts, presenting opportunities for further work.",
        "published": "2020-02-27T10:32:31Z",
        "link": "http://arxiv.org/abs/2003.00799v1",
        "categories": [
            "cs.GT",
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Multi-agent maintenance scheduling based on the coordination between   central operator and decentralized producers in an electricity market",
        "authors": [
            "Pegah Rokhforoz",
            "Blazhe Gjorgiev",
            "Giovanni Sansavini",
            "Olga Fink"
        ],
        "summary": "Condition-based and predictive maintenance enable early detection of critical system conditions and thereby enable decision makers to forestall faults and mitigate them. However, decision makers also need to take the operational and production needs into consideration for optimal decision-making when scheduling maintenance activities. Particularly in network systems, such as power grids, decisions on the maintenance of single assets can affect the entire network and are, therefore, more complex. This paper proposes a two-level multi-agent decision support systems for the generation maintenance decision (GMS) of power grids in an electricity markets. The aim of the GMS is to minimize the generation cost while maximizing the system reliability. The proposed framework integrates a central coordination system, i.e. the transmission system operator (TSO), and distributed agents representing power generation units that act to maximize their profit and decide about the optimal maintenance time slots while ensuring the fulfilment of the energy demand. The objective function of agents (power generation companies) is based on the reward and the penalty that they obtain from the interplay between power production and loss of production due to failure, respectively. The optimal strategy of agents is then derived using a distributed algorithm, where agents choose their optimal maintenance decision and send their decisions to the central coordinating system. The TSO decides whether to accept the agents' decisions by considering the market reliability aspects and power supply constraints. To solve this coordination problem, we propose a negotiation algorithm using an incentive signal to coordinate the agents' and central system's decisions such that all the agents' decisions can be accepted by the central system. We demonstrate the efficiency of our proposed algorithm using a IEEE 39 bus system.",
        "published": "2020-02-27T16:04:36Z",
        "link": "http://arxiv.org/abs/2002.12217v3",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "On Local Computation for Optimization in Multi-Agent Systems",
        "authors": [
            "Robin Brown",
            "Federico Rossi",
            "Kiril Solovey",
            "Michael T. Wolf",
            "Marco Pavone"
        ],
        "summary": "A number of prototypical optimization problems in multi-agent systems (e.g., task allocation and network load-sharing) exhibit a highly local structure: that is, each agent's decision variables are only directly coupled to few other agent's variables through the objective function or the constraints. Nevertheless, existing algorithms for distributed optimization generally do not exploit the locality structure of the problem, requiring all agents to compute or exchange the full set of decision variables. In this paper, we develop a rigorous notion of \"locality\" that quantifies the degree to which agents can compute their portion of the global solution based solely on information in their local neighborhood. This notion provides a theoretical basis for a rather simple algorithm in which agents individually solve a truncated sub-problem of the global problem, where the size of the sub-problem used depends on the locality of the problem, and the desired accuracy. Numerical results show that the proposed theoretical bounds are remarkably tight for well-conditioned problems.",
        "published": "2020-02-27T18:31:00Z",
        "link": "http://arxiv.org/abs/2002.12313v2",
        "categories": [
            "cs.MA",
            "cs.RO",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "C-CoCoA: A Continuous Cooperative Constraint Approximation Algorithm to   Solve Functional DCOPs",
        "authors": [
            "Amit Sarker",
            "Abdullahil Baki Arif",
            "Moumita Choudhury",
            "Md. Mosaddek Khan"
        ],
        "summary": "Distributed Constraint Optimization Problems (DCOPs) have been widely used to coordinate interactions (i.e. constraints) in cooperative multi-agent systems. The traditional DCOP model assumes that variables owned by the agents can take only discrete values and constraints' cost functions are defined for every possible value assignment of a set of variables. While this formulation is often reasonable, there are many applications where the variables are continuous decision variables and constraints are in functional form. To overcome this limitation, Functional DCOP (F-DCOP) model is proposed that is able to model problems with continuous variables. The existing F-DCOPs algorithms experience huge computation and communication overhead. This paper applies continuous non-linear optimization methods on Cooperative Constraint Approximation (CoCoA) algorithm. We empirically show that our algorithm is able to provide high-quality solutions at the expense of smaller communication cost and execution time compared to the existing F-DCOP algorithms.",
        "published": "2020-02-27T20:44:25Z",
        "link": "http://arxiv.org/abs/2002.12427v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "SCALE-Net: Scalable Vehicle Trajectory Prediction Network under Random   Number of Interacting Vehicles via Edge-enhanced Graph Convolutional Neural   Network",
        "authors": [
            "Hyeongseok Jeon",
            "Junwon Choi",
            "Dongsuk Kum"
        ],
        "summary": "Predicting the future trajectory of surrounding vehicles in a randomly varying traffic level is one of the most challenging problems in developing an autonomous vehicle. Since there is no pre-defined number of interacting vehicles participate in, the prediction network has to be scalable with respect to the vehicle number in order to guarantee the consistency in terms of both accuracy and computational load. In this paper, the first fully scalable trajectory prediction network, SCALE-Net, is proposed that can ensure both higher prediction performance and consistent computational load regardless of the number of surrounding vehicles. The SCALE-Net employs the Edge-enhance Graph Convolutional Neural Network (EGCN) for the inter-vehicular interaction embedding network. Since the proposed EGCN is inherently scalable with respect to the graph node (an agent in this study), the model can be operated independently from the total number of vehicles considered. We evaluated the scalability of the SCALE-Net on the publically available NGSIM datasets by comparing variations on computation time and prediction accuracy per single driving scene with respect to the varying vehicle number. The experimental test shows that both computation time and prediction performance of the SCALE-Net consistently outperform those of previous models regardless of the level of traffic complexities.",
        "published": "2020-02-28T09:25:01Z",
        "link": "http://arxiv.org/abs/2002.12609v1",
        "categories": [
            "cs.CV",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Real time Smart Contracts for IoT using Blockchain and Collaborative   Intelligence based Dynamic Pricing for the next generation Smart Toll   Application",
        "authors": [
            "Misha Abraham",
            "Himajit Aithal",
            "Krishnan Mohan"
        ],
        "summary": "The confluence of Internet of Things(IoT) , Blockchain(BC) and Artificial Intelligence(AI) acts as a key accelerator for enabling Machine Economy. To be ready for future businesses these technologies needs to be adapted by extending the IoT capabilities to Economy of Things (EoT) capabilities. In this paper we focus on one such implementation experience for Smart Toll Transaction application in the domain of mobility. Our paper showcases a possible solution by leveraging negotiations, decision making, distributed learning capabilities at the devices level using AI-enabled Multi-Agent Systems and the real-time smart contracts between the Cars and Tolls using Blockchain. This solution also showcases the monetization of real time data coming from various IoT devices which are part of vehicles and infrastructure. While blockchain secures the privacy of the participants it also acts as an economic transactional layer and governance layer between the devices in the networ",
        "published": "2020-02-28T11:16:26Z",
        "link": "http://arxiv.org/abs/2002.12654v1",
        "categories": [
            "cs.DC",
            "cs.MA",
            "cs.SE"
        ]
    },
    {
        "title": "Cities as they could be: Artificial Life and Urban Systems",
        "authors": [
            "Juste Raimbault"
        ],
        "summary": "The metaphor of cities as organisms has a long history in urban planning, and a few urban modeling approaches have explicitly been linked to Artificial Life. We propose in that paper to explore the extent of Artificial Life and Artificial Intelligence application to urban issues, by constructing and exploring a citation network of around 225,000 papers. It shows that most of the literature is indeed application of methodologies and a rather strong modularity of approaches. We finally develop ALife concepts which have a strong potential for the development of new urban theories.",
        "published": "2020-02-28T18:54:37Z",
        "link": "http://arxiv.org/abs/2002.12926v1",
        "categories": [
            "cs.CY",
            "cs.MA",
            "physics.soc-ph"
        ]
    },
    {
        "title": "Fully Asynchronous Policy Evaluation in Distributed Reinforcement   Learning over Networks",
        "authors": [
            "Xingyu Sha",
            "Jiaqi Zhang",
            "Keyou You",
            "Kaiqing Zhang",
            "Tamer Başar"
        ],
        "summary": "This paper proposes a \\emph{fully asynchronous} scheme for the policy evaluation problem of distributed reinforcement learning (DisRL) over directed peer-to-peer networks. Without waiting for any other node of the network, each node can locally update its value function at any time by using (possibly delayed) information from its neighbors. This is in sharp contrast to the gossip-based scheme where a pair of nodes concurrently update. Though the fully asynchronous setting involves a difficult multi-timescale decision problem, we design a novel stochastic average gradient (SAG) based distributed algorithm and develop a push-pull augmented graph approach to prove its exact convergence at a linear rate of $\\mathcal{O}(c^k)$ where $c\\in(0,1)$ and $k$ increases by one no matter on which node updates. Finally, numerical experiments validate that our method speeds up linearly with respect to the number of nodes, and is robust to straggler nodes.",
        "published": "2020-03-01T08:12:08Z",
        "link": "http://arxiv.org/abs/2003.00433v3",
        "categories": [
            "cs.LG",
            "cs.MA",
            "math.OC",
            "stat.ML"
        ]
    },
    {
        "title": "Scaling Up Multiagent Reinforcement Learning for Robotic Systems: Learn   an Adaptive Sparse Communication Graph",
        "authors": [
            "Chuangchuang Sun",
            "Macheng Shen",
            "Jonathan P. How"
        ],
        "summary": "The complexity of multiagent reinforcement learning (MARL) in multiagent systems increases exponentially with respect to the agent number. This scalability issue prevents MARL from being applied in large-scale multiagent systems. However, one critical feature in MARL that is often neglected is that the interactions between agents are quite sparse. Without exploiting this sparsity structure, existing works aggregate information from all of the agents and thus have a high sample complexity. To address this issue, we propose an adaptive sparse attention mechanism by generalizing a sparsity-inducing activation function. Then a sparse communication graph in MARL is learned by graph neural networks based on this new attention mechanism. Through this sparsity structure, the agents can communicate in an effective as well as efficient way via only selectively attending to agents that matter the most and thus the scale of the MARL problem is reduced with little optimality compromised. Comparative results show that our algorithm can learn an interpretable sparse structure and outperforms previous works by a significant margin on applications involving a large-scale multiagent system.",
        "published": "2020-03-02T17:18:25Z",
        "link": "http://arxiv.org/abs/2003.01040v2",
        "categories": [
            "cs.MA",
            "cs.LG"
        ]
    },
    {
        "title": "Anchor Attention for Hybrid Crowd Forecasts Aggregation",
        "authors": [
            "Yuzhong Huang",
            "Andres Abeliuk",
            "Fred Morstatter",
            "Pavel Atanasov",
            "Aram Galstyan"
        ],
        "summary": "In a crowd forecasting system, aggregation is an algorithm that returns aggregated probabilities for each question based on the probabilities provided per question by each individual in the crowd. Various aggregation methods have been proposed, but simple strategies like linear averaging or selecting the best-performing individual remain competitive. With the recent advance in neural networks, we model forecasts aggregation as a machine translation task, that translates from a sequence of individual forecasts into aggregated forecasts, based on proposed Anchor Attention between questions and forecasters. We evaluate our approach using data collected on our forecasting platform and publicly available Good Judgement Project dataset, and show that our method outperforms current state-of-the-art aggregation approaches by learning a good representation of forecaster and question.",
        "published": "2020-03-03T23:39:02Z",
        "link": "http://arxiv.org/abs/2003.12447v2",
        "categories": [
            "stat.AP",
            "cs.MA"
        ]
    },
    {
        "title": "On Emergent Communication in Competitive Multi-Agent Teams",
        "authors": [
            "Paul Pu Liang",
            "Jeffrey Chen",
            "Ruslan Salakhutdinov",
            "Louis-Philippe Morency",
            "Satwik Kottur"
        ],
        "summary": "Several recent works have found the emergence of grounded compositional language in the communication protocols developed by mostly cooperative multi-agent systems when learned end-to-end to maximize performance on a downstream task. However, human populations learn to solve complex tasks involving communicative behaviors not only in fully cooperative settings but also in scenarios where competition acts as an additional external pressure for improvement. In this work, we investigate whether competition for performance from an external, similar agent team could act as a social influence that encourages multi-agent populations to develop better communication protocols for improved performance, compositionality, and convergence speed. We start from Task & Talk, a previously proposed referential game between two cooperative agents as our testbed and extend it into Task, Talk & Compete, a game involving two competitive teams each consisting of two aforementioned cooperative agents. Using this new setting, we provide an empirical study demonstrating the impact of competitive influence on multi-agent teams. Our results show that an external competitive influence leads to improved accuracy and generalization, as well as faster emergence of communicative languages that are more informative and compositional.",
        "published": "2020-03-04T01:14:27Z",
        "link": "http://arxiv.org/abs/2003.01848v2",
        "categories": [
            "cs.AI",
            "cs.CL",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "A Distributed Pipeline for Scalable, Deconflicted Formation Flying",
        "authors": [
            "Parker C. Lusk",
            "Xiaoyi Cai",
            "Samir Wadhwania",
            "Aleix Paris",
            "Kaveh Fathian",
            "Jonathan P. How"
        ],
        "summary": "Reliance on external localization infrastructure and centralized coordination are main limiting factors for formation flying of vehicles in large numbers and in unprepared environments. While solutions using onboard localization address the dependency on external infrastructure, the associated coordination strategies typically lack collision avoidance and scalability. To address these shortcomings, we present a unified pipeline with onboard localization and a distributed, collision-free motion planning strategy that scales to a large number of vehicles. Since distributed collision avoidance strategies are known to result in gridlock, we also present a decentralized task assignment solution to deconflict vehicles. We experimentally validate our pipeline in simulation and hardware. The results show that our approach for solving the optimization problem associated with motion planning gives solutions within seconds in cases where general purpose solvers fail due to high complexity. In addition, our lightweight assignment strategy leads to successful and quicker formation convergence in 96-100% of all trials, whereas indefinite gridlocks occur without it for 33-50% of trials. By enabling large-scale, deconflicted coordination, this pipeline should help pave the way for anytime, anywhere deployment of aerial swarms.",
        "published": "2020-03-04T01:36:02Z",
        "link": "http://arxiv.org/abs/2003.01851v2",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Adaptive Online Distributed Optimal Control of Very-Large-Scale Robotic   Systems",
        "authors": [
            "Pingping Zhu",
            "Chang Liu",
            "Silvia Ferrari"
        ],
        "summary": "This paper presents an adaptive online distributed optimal control approach that is applicable to optimal planning for very-large-scale robotics systems in highly uncertain environments. This approach is developed based on the optimal mass transport theory. It is also viewed as an online reinforcement learning and approximate dynamic programming approach in the Wasserstein-GMM space, where a novel value functional is defined based on the probability density functions of robots and the time-varying obstacle map functions describing the changing environmental information. The proposed approach is demonstrated on the path planning problem of very-largescale robotic systems where the approximated layout of obstacles in the workspace is incrementally updated by the observations of robots, and compared with some existing state-of-the-art approaches. The numerical simulation results show that the proposed approach outperforms these approaches in aspects of the average traveling distance and the energy cost.",
        "published": "2020-03-04T04:49:11Z",
        "link": "http://arxiv.org/abs/2003.01891v2",
        "categories": [
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "Adaptation in Online Social Learning",
        "authors": [
            "Virginia Bordignon",
            "Vincenzo Matta",
            "Ali H. Sayed"
        ],
        "summary": "This work studies social learning under non-stationary conditions. Although designed for online inference, classic social learning algorithms perform poorly under drifting conditions. To mitigate this drawback, we propose the Adaptive Social Learning (ASL) strategy. This strategy leverages an adaptive Bayesian update, where the adaptation degree can be modulated by tuning a suitable step-size parameter. The learning performance of the ASL algorithm is examined by means of a steady-state analysis. It is shown that, under the regime of small step-sizes: i) consistent learning is possible; ii) an accurate prediction of the performance can be furnished in terms of a Gaussian approximation.",
        "published": "2020-03-04T08:43:31Z",
        "link": "http://arxiv.org/abs/2003.01948v1",
        "categories": [
            "eess.SP",
            "cs.MA"
        ]
    },
    {
        "title": "Reward Design in Cooperative Multi-agent Reinforcement Learning for   Packet Routing",
        "authors": [
            "Hangyu Mao",
            "Zhibo Gong",
            "Zhen Xiao"
        ],
        "summary": "In cooperative multi-agent reinforcement learning (MARL), how to design a suitable reward signal to accelerate learning and stabilize convergence is a critical problem. The global reward signal assigns the same global reward to all agents without distinguishing their contributions, while the local reward signal provides different local rewards to each agent based solely on individual behavior. Both of the two reward assignment approaches have some shortcomings: the former might encourage lazy agents, while the latter might produce selfish agents.   In this paper, we study reward design problem in cooperative MARL based on packet routing environments. Firstly, we show that the above two reward signals are prone to produce suboptimal policies. Then, inspired by some observations and considerations, we design some mixed reward signals, which are off-the-shelf to learn better policies. Finally, we turn the mixed reward signals into the adaptive counterparts, which achieve best results in our experiments. Other reward signals are also discussed in this paper. As reward design is a very fundamental problem in RL and especially in MARL, we hope that MARL researchers can rethink the rewards used in their systems.",
        "published": "2020-03-05T02:27:46Z",
        "link": "http://arxiv.org/abs/2003.03433v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "BARK: Open Behavior Benchmarking in Multi-Agent Environments",
        "authors": [
            "Julian Bernhard",
            "Klemens Esterle",
            "Patrick Hart",
            "Tobias Kessler"
        ],
        "summary": "Predicting and planning interactive behaviors in complex traffic situations presents a challenging task. Especially in scenarios involving multiple traffic participants that interact densely, autonomous vehicles still struggle to interpret situations and to eventually achieve their own mission goal. As driving tests are costly and challenging scenarios are hard to find and reproduce, simulation is widely used to develop, test, and benchmark behavior models. However, most simulations rely on datasets and simplistic behavior models for traffic participants and do not cover the full variety of real-world, interactive human behaviors. In this work, we introduce BARK, an open-source behavior benchmarking environment designed to mitigate the shortcomings stated above. In BARK, behavior models are (re-)used for planning, prediction, and simulation. A range of models is currently available, such as Monte-Carlo Tree Search and Reinforcement Learning-based behavior models. We use a public dataset and sampling-based scenario generation to show the inter-exchangeability of behavior models in BARK. We evaluate how well the models used cope with interactions and how robust they are towards exchanging behavior models. Our evaluation shows that BARK provides a suitable framework for a systematic development of behavior models.",
        "published": "2020-03-05T13:32:43Z",
        "link": "http://arxiv.org/abs/2003.02604v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Lane-Merging Using Policy-based Reinforcement Learning and   Post-Optimization",
        "authors": [
            "Patrick Hart",
            "Leonard Rychly",
            "Alois Knol"
        ],
        "summary": "Many current behavior generation methods struggle to handle real-world traffic situations as they do not scale well with complexity. However, behaviors can be learned off-line using data-driven approaches. Especially, reinforcement learning is promising as it implicitly learns how to behave utilizing collected experiences. In this work, we combine policy-based reinforcement learning with local optimization to foster and synthesize the best of the two methodologies. The policy-based reinforcement learning algorithm provides an initial solution and guiding reference for the post-optimization. Therefore, the optimizer only has to compute a single homotopy class, e.g.\\ drive behind or in front of the other vehicle. By storing the state-history during reinforcement learning, it can be used for constraint checking and the optimizer can account for interactions. The post-optimization additionally acts as a safety-layer and the novel method, thus, can be applied in safety-critical applications. We evaluate the proposed method using lane-change scenarios with a varying number of vehicles.",
        "published": "2020-03-06T12:57:25Z",
        "link": "http://arxiv.org/abs/2003.03168v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Asynchronous and Parallel Distributed Pose Graph Optimization",
        "authors": [
            "Yulun Tian",
            "Alec Koppel",
            "Amrit Singh Bedi",
            "Jonathan P. How"
        ],
        "summary": "We present Asynchronous Stochastic Parallel Pose Graph Optimization (ASAPP), the first asynchronous algorithm for distributed pose graph optimization (PGO) in multi-robot simultaneous localization and mapping. By enabling robots to optimize their local trajectory estimates without synchronization, ASAPP offers resiliency against communication delays and alleviates the need to wait for stragglers in the network. Furthermore, ASAPP can be applied on the rank-restricted relaxations of PGO, a crucial class of non-convex Riemannian optimization problems that underlies recent breakthroughs on globally optimal PGO. Under bounded delay, we establish the global first-order convergence of ASAPP using a sufficiently small stepsize. The derived stepsize depends on the worst-case delay and inherent problem sparsity, and furthermore matches known result for synchronous algorithms when there is no delay. Numerical evaluations on simulated and real-world datasets demonstrate favorable performance compared to state-of-the-art synchronous approach, and show ASAPP's resilience against a wide range of delays in practice.",
        "published": "2020-03-06T15:33:42Z",
        "link": "http://arxiv.org/abs/2003.03281v4",
        "categories": [
            "math.OC",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Keeping Your Friends Close: Land Allocation with Friends",
        "authors": [
            "Edith Elkind",
            "Neel Patel",
            "Alan Tsang",
            "Yair Zick"
        ],
        "summary": "We examine the problem of assigning plots of land to prospective buyers who prefer living next to their friends. They care not only about the plot they receive, but also about their neighbors. This externality results in a highly non-trivial problem structure, as both friendship and land value play a role in determining agent behavior. We examine mechanisms that guarantee truthful reporting of both land values and friendships. We propose variants of random serial dictatorship (RSD) that can offer both truthfulness and welfare guarantees. Interestingly, our social welfare guarantees are parameterized by the value of friendship: if these values are low, enforcing truthful behavior results in poor welfare guarantees and imposes significant constraints on agents' choices; if they are high, we achieve good approximation to the optimal social welfare.",
        "published": "2020-03-07T11:28:36Z",
        "link": "http://arxiv.org/abs/2003.03558v2",
        "categories": [
            "cs.GT",
            "cs.MA",
            "91A80 Applications of game theory",
            "I.2.11; J.4"
        ]
    },
    {
        "title": "Module checking of pushdown multi-agent systems",
        "authors": [
            "Laura Bozzelli",
            "Aniello Murano",
            "Adriano Peron"
        ],
        "summary": "In this paper, we investigate the module-checking problem of pushdown multi-agent systems (PMS) against ATL and ATL* specifications. We establish that for ATL, module checking of PMS is 2EXPTIME-complete, which is the same complexity as pushdown module-checking for CTL. On the other hand, we show that ATL* module-checking of PMS turns out to be 4EXPTIME-complete, hence exponentially harder than both CTL* pushdown module-checking and ATL* model-checking of PMS. Our result for ATL* provides a rare example of a natural decision problem that is elementary yet but with a complexity that is higher than triply exponential-time.",
        "published": "2020-03-07T13:42:10Z",
        "link": "http://arxiv.org/abs/2003.04728v3",
        "categories": [
            "cs.LO",
            "cs.FL",
            "cs.MA"
        ]
    },
    {
        "title": "Strategic Abilities of Asynchronous Agents: Semantic Side Effects and   How to Tame Them",
        "authors": [
            "Wojciech Jamroga",
            "Wojciech Penczek",
            "Teofil Sidoruk"
        ],
        "summary": "Recently, we have proposed a framework for verification of agents' abilities in asynchronous multi-agent systems, together with an algorithm for automated reduction of models. The semantics was built on the modeling tradition of distributed systems. As we show here, this can sometimes lead to counterintuitive interpretation of formulas when reasoning about the outcome of strategies. First, the semantics disregards finite paths, and thus yields unnatural evaluation of strategies with deadlocks. Secondly, the semantic representations do not allow to capture the asymmetry between proactive agents and the recipients of their choices. We propose how to avoid the problems by a suitable extension of the representations and change of the execution semantics for asynchronous MAS. We also prove that the model reduction scheme still works in the modified framework.",
        "published": "2020-03-08T23:23:31Z",
        "link": "http://arxiv.org/abs/2003.03867v5",
        "categories": [
            "cs.LO",
            "cs.MA"
        ]
    },
    {
        "title": "FormulaZero: Distributionally Robust Online Adaptation via Offline   Population Synthesis",
        "authors": [
            "Aman Sinha",
            "Matthew O'Kelly",
            "Hongrui Zheng",
            "Rahul Mangharam",
            "John Duchi",
            "Russ Tedrake"
        ],
        "summary": "Balancing performance and safety is crucial to deploying autonomous vehicles in multi-agent environments. In particular, autonomous racing is a domain that penalizes safe but conservative policies, highlighting the need for robust, adaptive strategies. Current approaches either make simplifying assumptions about other agents or lack robust mechanisms for online adaptation. This work makes algorithmic contributions to both challenges. First, to generate a realistic, diverse set of opponents, we develop a novel method for self-play based on replica-exchange Markov chain Monte Carlo. Second, we propose a distributionally robust bandit optimization procedure that adaptively adjusts risk aversion relative to uncertainty in beliefs about opponents' behaviors. We rigorously quantify the tradeoffs in performance and robustness when approximating these computations in real-time motion-planning, and we demonstrate our methods experimentally on autonomous vehicles that achieve scaled speeds comparable to Formula One racecars.",
        "published": "2020-03-09T03:07:57Z",
        "link": "http://arxiv.org/abs/2003.03900v2",
        "categories": [
            "cs.LG",
            "cs.MA",
            "cs.RO",
            "stat.ML"
        ]
    },
    {
        "title": "BitTensor: A Peer-to-Peer Intelligence Market",
        "authors": [
            "Yuma Rao",
            "Jacob Steeves",
            "Ala Shaabana",
            "Daniel Attevelt",
            "Matthew McAteer"
        ],
        "summary": "As with other commodities, markets could help us efficiently produce machine intelligence. We propose a market where intelligence is priced by other intelligence systems peer-to-peer across the internet. Peers rank each other by training neural networks which learn the value of their neighbors. Scores accumulate on a digital ledger where high ranking peers are monetarily rewarded with additional weight in the network. However, this form of peer-ranking is not resistant to collusion, which could disrupt the accuracy of the mechanism. The solution is a connectivity-based regularization which exponentially rewards trusted peers, making the system resistant to collusion of up to 50 percent of the network weight. The result is a collectively run intelligence market which continual produces newly trained models and pays contributors who create information theoretic value.",
        "published": "2020-03-09T04:04:18Z",
        "link": "http://arxiv.org/abs/2003.03917v3",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "I.2.6; I.2.11; C.2.4"
        ]
    },
    {
        "title": "Distributed Submodular Maximization with Parallel Execution",
        "authors": [
            "Haoyuan Sun",
            "David Grimsman",
            "Jason R Marden"
        ],
        "summary": "The submodular maximization problem is widely applicable in many engineering problems where objectives exhibit diminishing returns. While this problem is known to be NP-hard for certain subclasses of objective functions, there is a greedy algorithm which guarantees approximation at least 1/2 of the optimal solution. This greedy algorithm can be implemented with a set of agents, each making a decision sequentially based on the choices of all prior agents. In this paper, we consider a generalization of the greedy algorithm in which agents can make decisions in parallel, rather than strictly in sequence. In particular, we are interested in partitioning the agents, where a set of agents in the partition all make a decision simultaneously based on the choices of prior agents, so that the algorithm terminates in limited iterations. We provide bounds on the performance of this parallelized version of the greedy algorithm and show that dividing the agents evenly among the sets in the partition yields an optimal structure. We additionally show that this optimal structure is still near-optimal when the objective function exhibits a certain monotone property. Lastly, we show that the same performance guarantees can be achieved in the parallelized greedy algorithm even when agents can only observe the decisions of a subset of prior agents.",
        "published": "2020-03-09T19:08:20Z",
        "link": "http://arxiv.org/abs/2003.04364v2",
        "categories": [
            "cs.DC",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Advancing Renewable Electricity Consumption With Reinforcement Learning",
        "authors": [
            "Filip Tolovski"
        ],
        "summary": "As the share of renewable energy sources in the present electric energy mix rises, their intermittence proves to be the biggest challenge to carbon free electricity generation. To address this challenge, we propose an electricity pricing agent, which sends price signals to the customers and contributes to shifting the customer demand to periods of high renewable energy generation. We propose an implementation of a pricing agent with a reinforcement learning approach where the environment is represented by the customers, the electricity generation utilities and the weather conditions.",
        "published": "2020-03-09T20:57:58Z",
        "link": "http://arxiv.org/abs/2003.04310v1",
        "categories": [
            "eess.SP",
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "stat.ML",
            "I.2.11; I.2.8; I.2.6"
        ]
    },
    {
        "title": "JS-son -- A Lean, Extensible JavaScript Agent Programming Library",
        "authors": [
            "Timotheus Kampik",
            "Juan Carlos Nieves"
        ],
        "summary": "A multitude of agent-oriented software engineering frameworks exist, most of which are developed by the academic multi-agent systems community. However, these frameworks often impose programming paradigms on their users that are challenging to learn for engineers who are used to modern high-level programming languages such as JavaScript and Python. To show how the adoption of agent-oriented programming by the software engineering mainstream can be facilitated, we provide a lean JavaScript library prototype for implementing reasoning-loop agents. The library focuses on core agent programming concepts and refrains from imposing further restrictions on the programming approach. To illustrate its usefulness, we show how the library can be applied to multi-agent systems simulations on the web, deployed to cloud-hosted function-as-a-service environments, and embedded in Python-based data science tools.",
        "published": "2020-03-10T13:27:59Z",
        "link": "http://arxiv.org/abs/2003.04690v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.SE"
        ]
    },
    {
        "title": "The Application of Market-based Multi-Robot Task Allocation to Ambulance   Dispatch",
        "authors": [
            "Eric Schneider",
            "Marcus Poulton",
            "Archie Drake",
            "Leanne Smith",
            "George Roussos",
            "Simon Parsons",
            "Elizabeth I Sklar"
        ],
        "summary": "Multi-Robot Task Allocation (MRTA) is the problem of distributing a set of tasks to a team of robots with the objective of optimising some criteria, such as minimising the amount of time or energy spent to complete all the tasks or maximising the efficiency of the team's joint activity. The exploration of MRTA methods is typically restricted to laboratory and field experimentation. There are few existing real-world models in which teams of autonomous mobile robots are deployed \"in the wild\", e.g., in industrial settings. In the work presented here, a market-based MRTA approach is applied to the problem of ambulance dispatch, where ambulances are allocated in respond to patients' calls for help. Ambulances and robots are limited (and perhaps scarce), specialised mobile resources; incidents and tasks represent time-sensitive, specific, potentially unlimited, precisely-located demands for the services which the resources provide. Historical data from the London Ambulance Service describing a set of more than 1 million (anonymised) incidents are used as the basis for evaluating the predicted performance of the market-based approach versus the current, largely manual, method of allocating ambulances to incidents. Experimental results show statistically significant improvement in response times when using the market-based approach.",
        "published": "2020-03-11T23:01:15Z",
        "link": "http://arxiv.org/abs/2003.05550v1",
        "categories": [
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "A Hamilton-Jacobi Formulation for Optimal Coordination of Heterogeneous   Multiple Vehicle Systems",
        "authors": [
            "Matthew R. Kirchner",
            "Mark J. Debord",
            "João P. Hespanha"
        ],
        "summary": "We present a method for optimal coordination of multiple vehicle teams when multiple endpoint configurations are equally desirable, such as seen in the autonomous assembly of formation flight. The individual vehicles' positions in the formation are not assigned a priori and a key challenge is to find the optimal configuration assignment along with the optimal control and trajectory. Commonly, assignment and trajectory planning problems are solved separately. We introduce a new multi-vehicle coordination paradigm, where the optimal goal assignment and optimal vehicle trajectories are found simultaneously from a viscosity solution of a single Hamilton-Jacobi (HJ) partial differential equation (PDE), which provides a necessary and sufficient condition for global optimality. Intrinsic in this approach is that individual vehicle dynamic models need not be the same, and therefore can be applied to heterogeneous systems. Numerical methods to solve the HJ equation have historically relied on a discrete grid of the solution space and exhibits exponential scaling with system dimension, preventing their applicability to multiple vehicle systems. By utilizing a generalization of the Hopf formula, we avoid the use of grids and present a method that exhibits polynomial scaling in the number of vehicles.",
        "published": "2020-03-12T13:31:23Z",
        "link": "http://arxiv.org/abs/2003.05792v2",
        "categories": [
            "cs.RO",
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "math.OC"
        ]
    },
    {
        "title": "Onboard Ranging-based Relative Localization and Stability for   Lightweight Aerial Swarms",
        "authors": [
            "Shushuai Li",
            "Feng Shan",
            "Jiangpeng Liu",
            "Mario Coppola",
            "Christophe de Wagter",
            "Guido C. H. E. de Croon"
        ],
        "summary": "Lightweight aerial swarms have potential applications in scenarios where larger drones fail to operate efficiently. The primary foundation for lightweight aerial swarms is efficient relative localization, which enables cooperation and collision avoidance. Computing the real-time position is challenging due to extreme resource constraints. This paper presents an autonomous relative localization technique for lightweight aerial swarms without infrastructure by fusing ultra-wideband wireless distance measurements and the shared state information (e.g., velocity, yaw rate, height) from neighbors. This is the first fully autonomous, tiny, fast, and accurate relative localization scheme implemented on a team of 13 lightweight (33 grams) and resource-constrained (168MHz MCU with 192 KB memory) aerial vehicles. The proposed resource-constrained swarm ranging protocol is scalable, and a surprising theoretical result is discovered: the unobservability poses no issues because the state drift leads to control actions that make the state observable again. By experiment, less than 0.2m position error is achieved at the frequency of 16Hz for as many as 13 drones. The code is open-sourced, and the proposed technique is relevant not only for tiny drones but can be readily applied to many other resource-restricted robots. Video and code can be found at \\textnormal{\\url{https://shushuai3.github.io/autonomous-swarm/}}.",
        "published": "2020-03-12T15:34:35Z",
        "link": "http://arxiv.org/abs/2003.05853v3",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "An agent-based model of multi-dimensional opinion dynamics and opinion   alignment",
        "authors": [
            "Simon Schweighofer",
            "David Garcia",
            "Frank Schweitzer"
        ],
        "summary": "It is known that individual opinions on different policy issues often align to a dominant ideological dimension (e.g. \"left\" vs. \"right\") and become increasingly polarized. We provide an agent-based model that reproduces these two stylized facts as emergent properties of an opinion dynamics in a multi-dimensional space of continuous opinions. The mechanisms for the change of agents' opinions in this multi-dimensional space are derived from cognitive dissonance theory and structural balance theory. We test assumptions from proximity voting and from directional voting regarding their ability to reproduce the expected emerging properties. We further study how the emotional involvement of agents, i.e. their individual resistance to change opinions, impacts the dynamics. We identify two regimes for the global and the individual alignment of opinions. If the affective involvement is high and shows a large variance across agents, this fosters the emergence of a dominant ideological dimension. Agents align their opinions along this dimension in opposite directions, i.e. create a state of polarization.",
        "published": "2020-03-12T17:51:19Z",
        "link": "http://arxiv.org/abs/2003.05929v1",
        "categories": [
            "physics.soc-ph",
            "cs.MA",
            "nlin.AO"
        ]
    },
    {
        "title": "Accelerating and Improving AlphaZero Using Population Based Training",
        "authors": [
            "Ti-Rong Wu",
            "Ting-Han Wei",
            "I-Chen Wu"
        ],
        "summary": "AlphaZero has been very successful in many games. Unfortunately, it still consumes a huge amount of computing resources, the majority of which is spent in self-play. Hyperparameter tuning exacerbates the training cost since each hyperparameter configuration requires its own time to train one run, during which it will generate its own self-play records. As a result, multiple runs are usually needed for different hyperparameter configurations. This paper proposes using population based training (PBT) to help tune hyperparameters dynamically and improve strength during training time. Another significant advantage is that this method requires a single run only, while incurring a small additional time cost, since the time for generating self-play records remains unchanged though the time for optimization is increased following the AlphaZero training algorithm. In our experiments for 9x9 Go, the PBT method is able to achieve a higher win rate for 9x9 Go than the baselines, each with its own hyperparameter configuration and trained individually. For 19x19 Go, with PBT, we are able to obtain improvements in playing strength. Specifically, the PBT agent can obtain up to 74% win rate against ELF OpenGo, an open-source state-of-the-art AlphaZero program using a neural network of a comparable capacity. This is compared to a saturated non-PBT agent, which achieves a win rate of 47% against ELF OpenGo under the same circumstances.",
        "published": "2020-03-13T11:56:14Z",
        "link": "http://arxiv.org/abs/2003.06212v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "cs.NE"
        ]
    },
    {
        "title": "Cohesive Networks using Delayed Self Reinforcement",
        "authors": [
            "Santosh Devasia"
        ],
        "summary": "How a network gets to the goal (a consensus value) can be as important as reaching the consensus value. While prior methods focus on rapidly getting to a new consensus value, maintaining cohesion, during the transition between consensus values or during tracking, remains challenging and has not been addressed. The main contributions of this work are to address the problem of maintaining cohesion by: (i) proposing a new delayed self-reinforcement (DSR) approach; (ii) extending it for use with agents that have higher-order, heterogeneous dynamics, and (iii) developing stability conditions for the DSR-based method. With DSR, each agent uses current and past information from neighbors to infer the overall goal and modifies the update law to improve cohesion. The advantages of the proposed DSR approach are that it only requires already-available information from a given network to improve the cohesion and does not require network-connectivity modifications (which might not be always feasible) nor increases in the system's overall response speed (which can require larger input). Moreover, illustrative simulation examples are used to comparatively evaluate the performance with and without DSR. The simulation results show substantial improvement in cohesion with DSR.",
        "published": "2020-03-14T18:09:56Z",
        "link": "http://arxiv.org/abs/2003.06679v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Selecting Voting Locations for Fun and Profit",
        "authors": [
            "Zack Fitzsimmons",
            "Omer Lev"
        ],
        "summary": "While manipulative attacks on elections have been well-studied, only recently has attention turned to attacks that account for geographic information, which are extremely common in the real world. The most well known in the media is gerrymandering, in which district border-lines are changed to increase a party's chance to win, but a different geographical manipulation involves influencing the election by selecting the location of polling places, as many people are not willing to go to any distance to vote. In this paper we initiate the study of this manipulation. We find that while it is easy to manipulate the selection of polling places on the line, it becomes difficult already on the plane or in the case of more than two candidates. Moreover, we show that for more than two candidates the problem is inapproximable. However, we find a few restricted cases on the plane where some algorithms perform well. Finally, we discuss how existing results for standard control actions hold in the geographic setting, consider additional control actions in the geographic setting, and suggest directions for future study.",
        "published": "2020-03-15T17:49:50Z",
        "link": "http://arxiv.org/abs/2003.06879v1",
        "categories": [
            "cs.GT",
            "cs.CC",
            "cs.MA"
        ]
    },
    {
        "title": "Model-based Reinforcement Learning for Decentralized Multiagent   Rendezvous",
        "authors": [
            "Rose E. Wang",
            "J. Chase Kew",
            "Dennis Lee",
            "Tsang-Wei Edward Lee",
            "Tingnan Zhang",
            "Brian Ichter",
            "Jie Tan",
            "Aleksandra Faust"
        ],
        "summary": "Collaboration requires agents to align their goals on the fly. Underlying the human ability to align goals with other agents is their ability to predict the intentions of others and actively update their own plans. We propose hierarchical predictive planning (HPP), a model-based reinforcement learning method for decentralized multiagent rendezvous. Starting with pretrained, single-agent point to point navigation policies and using noisy, high-dimensional sensor inputs like lidar, we first learn via self-supervision motion predictions of all agents on the team. Next, HPP uses the prediction models to propose and evaluate navigation subgoals for completing the rendezvous task without explicit communication among agents. We evaluate HPP in a suite of unseen environments, with increasing complexity and numbers of obstacles. We show that HPP outperforms alternative reinforcement learning, path planning, and heuristic-based baselines on challenging, unseen environments. Experiments in the real world demonstrate successful transfer of the prediction models from sim to real world without any additional fine-tuning. Altogether, HPP removes the need for a centralized operator in multiagent systems by combining model-based RL and inference methods, enabling agents to dynamically align plans.",
        "published": "2020-03-15T19:49:20Z",
        "link": "http://arxiv.org/abs/2003.06906v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG",
            "cs.RO"
        ]
    },
    {
        "title": "Online Algorithms for Dynamic Matching Markets in Power Distribution   Systems",
        "authors": [
            "Deepan Muthirayan",
            "Masood Parvania",
            "Pramod P. Khargonekar"
        ],
        "summary": "This paper proposes online algorithms for dynamic matching markets in power distribution systems, which at any real-time operation instance decides about matching -- or delaying the supply of -- flexible loads with available renewable generation with the objective of maximizing the social welfare of the exchange in the system. More specifically, two online matching algorithms are proposed for the following generation-load scenarios: (i) when the mean of renewable generation is greater than the mean of the flexible load, and (ii) when the condition (i) is reversed. With the intuition that the performance of such algorithms degrades with increasing randomness of the supply and demand, two properties are proposed for assessing the performance of the algorithms. First property is convergence to optimality (CO) as the underlying randomness of renewable generation and customer loads goes to zero. The second property is deviation from optimality, is measured as a function of the standard deviation of the underlying randomness of renewable generation and customer loads. The algorithm proposed for the first scenario is shown to satisfy CO and a deviation from optimal that varies linearly with the variation in the standard deviation. But the same algorithm is shown to not satisfy CO for the second scenario. We then show that the algorithm proposed for the second scenario satisfies CO and a deviation from optimal that varies linearly with the variation in standard deviation plus an offset.",
        "published": "2020-03-16T02:00:20Z",
        "link": "http://arxiv.org/abs/2003.06971v8",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Modeling and Experimental Validation of a Fractal Tetrahedron UAS   Assembly",
        "authors": [
            "Kévin Garanger",
            "Jeremy Epps",
            "Eric Feron"
        ],
        "summary": "This paper presents the foundation of a modular robotic system comprised of several novel modules in the shape of a tetrahedron. Four single-propeller submodules are assembled to create the Tetracopter, a tetrahedron-shaped quad-rotorcraft used as the elementary module of a modular flying system. This modular flying system is built by assembling the different elementary modules in a fractal shape. The fractal tetrahedron structure of the modular flying assembly grants the vehicle more rigidity than a conventional two-dimensional modular robotic flight system while maintaining the relative efficiency of a two-dimensional modular robotic flight system. A prototype of the Tetracopter has been modeled, fabricated, and successfully flight-tested by the Decision and Control Laboratory at the Georgia Institute of Technology. The results of this research set the foundation for the development of Tetrahedron rotorcraft that can maintain controllable flight and assemble in flight to create a Fractal Tetrahedron Assembly.",
        "published": "2020-03-16T03:49:35Z",
        "link": "http://arxiv.org/abs/2003.07007v1",
        "categories": [
            "cs.RO",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "A Job-Assignment Heuristic for Lifelong Multi-Agent Path Finding Problem   with Multiple Delivery Locations",
        "authors": [
            "Fatih Semiz",
            "Faruk Polat"
        ],
        "summary": "In this paper we proposed multiple job-assignment heuristics to generate low-total-cost solutions and determine the best performing method amongst them.",
        "published": "2020-03-16T10:57:13Z",
        "link": "http://arxiv.org/abs/2003.07108v2",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Solving Area Coverage Problem with UAVs: A Vehicle Routing with Time   Windows Variation",
        "authors": [
            "Fatih Semiz",
            "Faruk Polat"
        ],
        "summary": "In real life, providing security for a set of large areas by covering the area with Unmanned Aerial Vehicles (UAVs) is a difficult problem that consist of multiple objectives. These difficulties are even greater if the area coverage must continue throughout a specific time window. We address this by considering a Vehicle Routing Problem with Time Windows (VRPTW) variation in which capacity of agents is one and each customer (target area) must be supplied with more than one vehicles simultaneously without violating time windows. In this problem, our aim is to find a way to cover all areas with the necessary number of UAVs during the time windows, minimize the total distance traveled, and provide a fast solution by satisfying the additional constraint that each agent has limited fuel. We present a novel algorithm that relies on clustering the target areas according to their time windows, and then incrementally generating transportation problems with each cluster and the ready UAVs. Then we solve transportation problems with the simplex algorithm to generate the solution. The performance of the proposed algorithm and other implemented algorithms to compare the solution quality is evaluated on example scenarios with practical problem sizes.",
        "published": "2020-03-16T11:27:21Z",
        "link": "http://arxiv.org/abs/2003.07124v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "İnsansız Araçlarla Düzlemsel Olmayan Araçların   Taranması",
        "authors": [
            "Çağlar Seylan",
            "Özgür Saygın Bican",
            "Fatih Semiz"
        ],
        "summary": "The importance of area coverage with unmanned vehicles, in other words, traveling an area with an unmanned vehicle such as a robot or a UAV completely or partially with minimum cost, is increasing with the increase in usage of such vehicles today. Area coverage with unmanned vehicles is used today in the exploration of an area with UAVs, sweeping mines with robots, cleaning ground with robots in large shopping malls, mowing lawn in a large area etc. The problem has versions such as area coverage with a single unmanned vehicle, area coverage with multiple unmanned vehicles, on-line area coverage (The map of the area that will be covered is not known before starting the coverage) with unmanned vehicles etc. In addition, the area may have obstacles that the vehicles cannot move over. Naturally, many researches are working on the problem and a lot of researches have been done on the problem until today. Spanning tree coverage is one of the major approaches to the problem. In this approach, at the basic level, the planar area is divided into identical squares according to the range of sight of the vehicle, and centers of these squares are assumed to be vertexes of a graph. The vertexes of this graph are connected with the edges with unit costs and after finding the minimum spanning tree of the graph, the vehicle strolls around the spanning tree. The method we propose suggests a way to cover a non-planar area with unmanned vehicles. The method we propose also takes advantage of the spanning-tree coverage approach, but instead of assigning unit costs to the edges, we assigned a weight to each edge using slopes between vertexes those the edges connect. We have gotten noticeably better results than the results we got when we did not consider the slope between two squares and used the classical spanning tree approach.",
        "published": "2020-03-16T14:07:55Z",
        "link": "http://arxiv.org/abs/2003.09310v1",
        "categories": [
            "cs.AI",
            "cs.MA",
            "eess.SP"
        ]
    },
    {
        "title": "Compositional Conformance Checking of Nested Petri Nets and Event Logs   of Multi-Agent Systems",
        "authors": [
            "Khalil Mecheraoui",
            "Julio C. Carrasquel",
            "Irina A. Lomazova"
        ],
        "summary": "This paper presents a compositional conformance checking approach between nested Petri nets and event logs of multi-agent systems. By projecting an event log onto model components, one can perform conformance checking between each projected log and the corresponding component. We formally demonstrate the validity of our approach proving that, to check fitness of a nested Petri net is equivalent to check fitness of each of its components. Leveraging the multi-agent system structure of nested Petri nets, this approach may provide specific conformance diagnostics for each system component as well as to avoid to compute artificial boundaries when decomposing a model for conformance checking.",
        "published": "2020-03-16T15:52:06Z",
        "link": "http://arxiv.org/abs/2003.07291v1",
        "categories": [
            "cs.SE",
            "cs.LO",
            "cs.MA"
        ]
    },
    {
        "title": "Beyond Reynolds: A Constraint-Driven Approach to Cluster Flocking",
        "authors": [
            "Logan E. Beaver",
            "Andreas A. Malikopoulos"
        ],
        "summary": "In this paper, we present an original set of flocking rules using an ecologically-inspired paradigm for control of multi-robot systems. We translate these rules into a constraint-driven optimal control problem where the agents minimize energy consumption subject to safety and task constraints. We prove several properties about the feasible space of the optimal control problem and show that velocity consensus is an optimal solution. We also motivate the inclusion of slack variables in constraint-driven problems when the global state is only partially observable by each agent. Finally, we analyze the case where the communication topology is fixed and connected, and prove that our proposed flocking rules achieve velocity consensus.",
        "published": "2020-03-16T16:26:12Z",
        "link": "http://arxiv.org/abs/2003.07310v2",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "From Sensor to Processing Networks: Optimal Estimation with Computation   and Communication Latency",
        "authors": [
            "Luca Ballotta",
            "Luca Schenato",
            "Luca Carlone"
        ],
        "summary": "This paper investigates the use of a networked system ($e.g.$, swarm of robots, smart grid, sensor network) to monitor a time-varying phenomenon of interest in the presence of communication and computation latency. Recent advances in edge computing have enabled processing to be spread across the network, hence we investigate the fundamental computation-communication trade-off, arising when a sensor has to decide whether to transmit raw data (incurring communication delay) or preprocess them (incurring computational delay) in order to compute an accurate estimate of the state of the phenomenon of interest. We propose two key contributions. First, we formalize the notion of $processing$ $network$. Contrarily to $sensor$ $and$ $communication$ $networks$, where the designer is concerned with the design of a suitable communication policy, in a processing network one can also control when and where the computation occurs in the network. The second contribution is to provide analytical results on the optimal preprocessing delay ($i.e.$, the optimal time spent on computations at each sensor) for the case with a single sensor and multiple homogeneous sensors. Numerical results substantiate our claims that accounting for computation latencies (both at sensor and estimator side) and communication delays can largely impact the estimation accuracy.",
        "published": "2020-03-16T21:03:29Z",
        "link": "http://arxiv.org/abs/2003.08301v1",
        "categories": [
            "math.OC",
            "cs.DC",
            "cs.MA",
            "93C99 (Primary), 93E99 (Secondary)"
        ]
    },
    {
        "title": "Influence of CAV Clustering Strategies on Mixed Traffic Flow   Characteristics: An Analysis of Vehicle Trajectory Data",
        "authors": [
            "Zijia Zhong",
            "Earl E. Lee",
            "Mark Nejad",
            "Joyoung Lee"
        ],
        "summary": "Being one of the most promising applications enabled by connected and automated vehicles (CAV) technology, Cooperative Adaptive Cruise Control (CACC) is expected to be deployed in the near term on public roads.} Thus far, the majority of the CACC studies have been focusing on the overall network performance with limited insights on the potential impacts of CAVs on human-driven vehicles (HVs).This paper aims to quantify such impacts by studying the high-resolution vehicle trajectory data that are obtained from microscopic simulation. Two platoon clustering strategies for CACC- an ad hoc coordination strategy and a local coordination strategy-are implemented. Results show that the local coordination outperforms the ad hoc coordination across all tested market penetration rates (MPRs) in terms of network throughput and productivity. According to the two-sample Kolmogorov-\\textcolor{re}{Smirnov} test, however, the distributions of the hard braking events (as a potential safety impact) for HVs change significantly under local coordination strategy. For both of the clustering strategy, CAVs increase the average lane change frequency for HVs. The break-even point for average lane change frequency between the two strategies is observed at 30% MPR, which decreases from 5.42 to 5.38 per vehicle. The average lane change frequency following a monotonically increasing pattern in response to MPR, and it reaches the highest 5.48 per vehicle at 40% MPR. Lastly, the interaction state of the car-following model for HVs is analyzed. It is revealed that the composition of the interaction state could be influenced by CAVs as well. One of the apparent trends is that the time spent on approaching state declines with the increasing presence of CAVs.",
        "published": "2020-03-16T22:23:59Z",
        "link": "http://arxiv.org/abs/2003.08290v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "The Shapeshifter: a Morphing, Multi-Agent,Multi-Modal Robotic Platform   for the Exploration of Titan (preprint version)",
        "authors": [
            "Ali-akbar Agha-mohammadi",
            "Andrea Tagliabue",
            "Stephanie Schneider",
            "Benjamin Morrell",
            "Marco Pavone",
            "Jason Hofgartner",
            "Issa A. D. Nesnas",
            "Rashied B. Amini",
            "Arash Kalantari",
            "Alessandra Babuscia",
            "Jonathan Lunine"
        ],
        "summary": "In this report for the Nasa NIAC Phase I study, we present a mission architecture and a robotic platform, the Shapeshifter, that allow multi-domain and redundant mobility on Saturn's moon Titan, and potentially other bodies with atmospheres. The Shapeshifter is a collection of simple and affordable robotic units, called Cobots, comparable to personal palm-size quadcopters. By attaching and detaching with each other, multiple Cobots can shape-shift into novel structures, capable of (a) rolling on the surface, to increase the traverse range, (b) flying in a flight array formation, and (c) swimming on or under liquid. A ground station complements the robotic platform, hosting science instrumentation and providing power to recharge the batteries of the Cobots. Our Phase I study had the objective of providing an initial assessment of the feasibility of the proposed robotic platform architecture, and in particular (a) to characterize the expected science return of a mission to the Sotra-Patera region on Titan; (b) to verify the mechanical and algorithmic feasibility of building a multi-agent platform capable of flying, docking, rolling and un-docking; (c) to evaluate the increased range and efficiency of rolling on Titan w.r.t to flying; (d) to define a case-study of a mission for the exploration of the cryovolcano Sotra-Patera on Titan, whose expected variety of geological features challenges conventional mobility platforms.",
        "published": "2020-03-16T23:54:23Z",
        "link": "http://arxiv.org/abs/2003.08293v1",
        "categories": [
            "cs.RO",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "A Deep Multi-Agent Reinforcement Learning Approach to Autonomous   Separation Assurance",
        "authors": [
            "Marc Brittain",
            "Xuxi Yang",
            "Peng Wei"
        ],
        "summary": "A novel deep multi-agent reinforcement learning framework is proposed to identify and resolve conflicts among a variable number of aircraft in a high-density, stochastic, and dynamic sector. Currently the sector capacity is constrained by human air traffic controller's cognitive limitation. We investigate the feasibility of a new concept (autonomous separation assurance) and a new approach to push the sector capacity above human cognitive limitation. We propose the concept of using distributed vehicle autonomy to ensure separation, instead of a centralized sector air traffic controller. Our proposed framework utilizes Proximal Policy Optimization (PPO) that we modify to incorporate an attention network. This allows the agents to have access to variable aircraft information in the sector in a scalable, efficient approach to achieve high traffic throughput under uncertainty. Agents are trained using a centralized learning, decentralized execution scheme where one neural network is learned and shared by all agents. The proposed framework is validated on three challenging case studies in the BlueSky air traffic control environment. Numerical results show the proposed framework significantly reduces offline training time, increases performance, and results in a more efficient policy.",
        "published": "2020-03-17T16:50:34Z",
        "link": "http://arxiv.org/abs/2003.08353v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Ford Multi-AV Seasonal Dataset",
        "authors": [
            "Siddharth Agarwal",
            "Ankit Vora",
            "Gaurav Pandey",
            "Wayne Williams",
            "Helen Kourous",
            "James McBride"
        ],
        "summary": "This paper presents a challenging multi-agent seasonal dataset collected by a fleet of Ford autonomous vehicles at different days and times during 2017-18. The vehicles traversed an average route of 66 km in Michigan that included a mix of driving scenarios such as the Detroit Airport, freeways, city-centers, university campus and suburban neighbourhoods, etc. Each vehicle used in this data collection is a Ford Fusion outfitted with an Applanix POS-LV GNSS system, four HDL-32E Velodyne 3D-lidar scanners, 6 Point Grey 1.3 MP Cameras arranged on the rooftop for 360-degree coverage and 1 Pointgrey 5 MP camera mounted behind the windshield for the forward field of view. We present the seasonal variation in weather, lighting, construction and traffic conditions experienced in dynamic urban environments. This dataset can help design robust algorithms for autonomous vehicles and multi-agent systems. Each log in the dataset is time-stamped and contains raw data from all the sensors, calibration values, pose trajectory, ground truth pose, and 3D maps. All data is available in Rosbag format that can be visualized, modified and applied using the open-source Robot Operating System (ROS). We also provide the output of state-of-the-art reflectivity-based localization for bench-marking purposes. The dataset can be freely downloaded at our website.",
        "published": "2020-03-17T22:33:38Z",
        "link": "http://arxiv.org/abs/2003.07969v1",
        "categories": [
            "cs.RO",
            "cs.CV",
            "cs.MA"
        ]
    },
    {
        "title": "Redistribution Systems and PRAM",
        "authors": [
            "Paul Cohen",
            "Tomasz Loboda"
        ],
        "summary": "Redistribution systems iteratively redistribute mass between groups under the control of rules. PRAM is a framework for building redistribution systems. We discuss the relationships between redistribution systems, agent-based systems, compartmental models and Bayesian models. PRAM puts agent-based models on a sound probabilistic footing by reformulating them as redistribution systems. This provides a basis for integrating agent-based and probabilistic models. \\pram/ extends the themes of probabilistic relational models and lifted inference to incorporate dynamical models and simulation. We illustrate PRAM with an epidemiological example.",
        "published": "2020-03-18T01:36:28Z",
        "link": "http://arxiv.org/abs/2003.08783v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.SI"
        ]
    },
    {
        "title": "ROMA: Multi-Agent Reinforcement Learning with Emergent Roles",
        "authors": [
            "Tonghan Wang",
            "Heng Dong",
            "Victor Lesser",
            "Chongjie Zhang"
        ],
        "summary": "The role concept provides a useful tool to design and understand complex multi-agent systems, which allows agents with a similar role to share similar behaviors. However, existing role-based methods use prior domain knowledge and predefine role structures and behaviors. In contrast, multi-agent reinforcement learning (MARL) provides flexibility and adaptability, but less efficiency in complex tasks. In this paper, we synergize these two paradigms and propose a role-oriented MARL framework (ROMA). In this framework, roles are emergent, and agents with similar roles tend to share their learning and to be specialized on certain sub-tasks. To this end, we construct a stochastic role embedding space by introducing two novel regularizers and conditioning individual policies on roles. Experiments show that our method can learn specialized, dynamic, and identifiable roles, which help our method push forward the state of the art on the StarCraft II micromanagement benchmark. Demonstrative videos are available at https://sites.google.com/view/romarl/.",
        "published": "2020-03-18T04:29:42Z",
        "link": "http://arxiv.org/abs/2003.08039v3",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "How social feedback processing in the brain shapes collective opinion   processes in the era of social media",
        "authors": [
            "Sven Banisch",
            "Felix Gaisbauer",
            "Eckehard Olbrich"
        ],
        "summary": "What are the mechanisms by which groups with certain opinions gain public voice and force others holding a different view into silence? And how does social media play into this? Drawing on recent neuro-scientific insights into the processing of social feedback, we develop a theoretical model that allows to address these questions. The model captures phenomena described by spiral of silence theory of public opinion, provides a mechanism-based foundation for it, and allows in this way more general insight into how different group structures relate to different regimes of collective opinion expression. Even strong majorities can be forced into silence if a minority acts as a cohesive whole. The proposed framework of social feedback theory (SFT) highlights the need for sociological theorising to understand the societal-level implications of findings in social and cognitive neuroscience.",
        "published": "2020-03-18T11:06:34Z",
        "link": "http://arxiv.org/abs/2003.08154v1",
        "categories": [
            "physics.soc-ph",
            "cs.CY",
            "cs.MA",
            "cs.NE",
            "nlin.AO",
            "91D30, 91F10, 00A69"
        ]
    },
    {
        "title": "Social Navigation with Human Empowerment driven Deep Reinforcement   Learning",
        "authors": [
            "Tessa van der Heiden",
            "Florian Mirus",
            "Herke van Hoof"
        ],
        "summary": "Mobile robot navigation has seen extensive research in the last decades. The aspect of collaboration with robots and humans sharing workspaces will become increasingly important in the future. Therefore, the next generation of mobile robots needs to be socially-compliant to be accepted by their human collaborators. However, a formal definition of compliance is not straightforward. On the other hand, empowerment has been used by artificial agents to learn complicated and generalized actions and also has been shown to be a good model for biological behaviors. In this paper, we go beyond the approach of classical \\acf{RL} and provide our agent with intrinsic motivation using empowerment. In contrast to self-empowerment, a robot employing our approach strives for the empowerment of people in its environment, so they are not disturbed by the robot's presence and motion. In our experiments, we show that our approach has a positive influence on humans, as it minimizes its distance to humans and thus decreases human travel time while moving efficiently towards its own goal. An interactive user-study shows that our method is considered more social than other state-of-the-art approaches by the participants.",
        "published": "2020-03-18T11:16:07Z",
        "link": "http://arxiv.org/abs/2003.08158v3",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Inverting the Pose Forecasting Pipeline with SPF2: Sequential Pointcloud   Forecasting for Sequential Pose Forecasting",
        "authors": [
            "Xinshuo Weng",
            "Jianren Wang",
            "Sergey Levine",
            "Kris Kitani",
            "Nicholas Rhinehart"
        ],
        "summary": "Many autonomous systems forecast aspects of the future in order to aid decision-making. For example, self-driving vehicles and robotic manipulation systems often forecast future object poses by first detecting and tracking objects. However, this detect-then-forecast pipeline is expensive to scale, as pose forecasting algorithms typically require labeled sequences of object poses, which are costly to obtain in 3D space. Can we scale performance without requiring additional labels? We hypothesize yes, and propose inverting the detect-then-forecast pipeline. Instead of detecting, tracking and then forecasting the objects, we propose to first forecast 3D sensor data (e.g., point clouds with $100$k points) and then detect/track objects on the predicted point cloud sequences to obtain future poses, i.e., a forecast-then-detect pipeline. This inversion makes it less expensive to scale pose forecasting, as the sensor data forecasting task requires no labels. Part of this work's focus is on the challenging first step -- Sequential Pointcloud Forecasting (SPF), for which we also propose an effective approach, SPFNet. To compare our forecast-then-detect pipeline relative to the detect-then-forecast pipeline, we propose an evaluation procedure and two metrics. Through experiments on a robotic manipulation dataset and two driving datasets, we show that SPFNet is effective for the SPF task, our forecast-then-detect pipeline outperforms the detect-then-forecast approaches to which we compared, and that pose forecasting performance improves with the addition of unlabeled data.",
        "published": "2020-03-18T17:54:28Z",
        "link": "http://arxiv.org/abs/2003.08376v3",
        "categories": [
            "cs.CV",
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Barrier Functions for Multiagent-POMDPs with DTL Specifications",
        "authors": [
            "Mohamadreza Ahmadi",
            "Andrew Singletary",
            "Joel W. Burdick",
            "Aaron D. Ames"
        ],
        "summary": "Multi-agent partially observable Markov decision processes (MPOMDPs) provide a framework to represent heterogeneous autonomous agents subject to uncertainty and partial observation. In this paper, given a nominal policy provided by a human operator or a conventional planning method, we propose a technique based on barrier functions to design a minimally interfering safety-shield ensuring satisfaction of high-level specifications in terms of linear distribution temporal logic (LDTL). To this end, we use sufficient and necessary conditions for the invariance of a given set based on discrete-time barrier functions (DTBFs) and formulate sufficient conditions for finite time DTBF to study finite time convergence to a set. We then show that different LDTL mission/safety specifications can be cast as a set of invariance or finite time reachability problems. We demonstrate that the proposed method for safety-shield synthesis can be implemented online by a sequence of one-step greedy algorithms. We demonstrate the efficacy of the proposed method using experiments involving a team of robots.",
        "published": "2020-03-19T01:27:36Z",
        "link": "http://arxiv.org/abs/2003.09267v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.RO",
            "cs.SY",
            "math.OC"
        ]
    },
    {
        "title": "Modeling limited attention in opinion dynamics by topological   interactions",
        "authors": [
            "Francesca Ceragioli",
            "Paolo Frasca",
            "Wilbert Samuel Rossi"
        ],
        "summary": "This work explores models of opinion dynamics with opinion-dependent connectivity. Our starting point is that individuals have limited capabilities to engage in interactions with their peers. Motivated by this observation, we propose a continuous-time opinion dynamics model such that interactions take place with a limited number of peers: we refer to these interactions as topological, as opposed to metric interactions that are postulated in classical bounded-confidence models. We observe that topological interactions produce equilibria that are very robust to perturbations.",
        "published": "2020-03-19T08:14:38Z",
        "link": "http://arxiv.org/abs/2003.08620v2",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Monotonic Value Function Factorisation for Deep Multi-Agent   Reinforcement Learning",
        "authors": [
            "Tabish Rashid",
            "Mikayel Samvelyan",
            "Christian Schroeder de Witt",
            "Gregory Farquhar",
            "Jakob Foerster",
            "Shimon Whiteson"
        ],
        "summary": "In many real-world settings, a team of agents must coordinate its behaviour while acting in a decentralised fashion. At the same time, it is often possible to train the agents in a centralised fashion where global state information is available and communication constraints are lifted. Learning joint action-values conditioned on extra state information is an attractive way to exploit centralised learning, but the best strategy for then extracting decentralised policies is unclear. Our solution is QMIX, a novel value-based method that can train decentralised policies in a centralised end-to-end fashion. QMIX employs a mixing network that estimates joint action-values as a monotonic combination of per-agent values. We structurally enforce that the joint-action value is monotonic in the per-agent values, through the use of non-negative weights in the mixing network, which guarantees consistency between the centralised and decentralised policies. To evaluate the performance of QMIX, we propose the StarCraft Multi-Agent Challenge (SMAC) as a new benchmark for deep multi-agent reinforcement learning. We evaluate QMIX on a challenging set of SMAC scenarios and show that it significantly outperforms existing multi-agent reinforcement learning methods.",
        "published": "2020-03-19T16:51:51Z",
        "link": "http://arxiv.org/abs/2003.08839v2",
        "categories": [
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Byzantine-Resilient Distributed Optimization of Multi-Dimensional   Functions",
        "authors": [
            "Kananart Kuwaranancharoen",
            "Lei Xin",
            "Shreyas Sundaram"
        ],
        "summary": "The problem of distributed optimization requires a group of agents to reach agreement on a parameter that minimizes the average of their local cost functions using information received from their neighbors. While there are a variety of distributed optimization algorithms that can solve this problem, they are typically vulnerable to malicious (or ``Byzantine'') agents that do not follow the algorithm. Recent attempts to address this issue focus on single dimensional functions, or provide analysis under certain assumptions on the statistical properties of the functions at the agents. In this paper, we propose a resilient distributed optimization algorithm for multi-dimensional convex functions. Our scheme involves two filtering steps at each iteration of the algorithm: (1) distance-based and (2) component-wise removal of extreme states. We show that this algorithm can mitigate the impact of up to $F$ Byzantine agents in the neighborhood of each regular node, without knowing the identities of the Byzantine agents in advance. In particular, we show that if the network topology satisfies certain conditions, all of the regular states are guaranteed to asymptotically converge to a bounded region that contains the global minimizer.",
        "published": "2020-03-19T22:46:41Z",
        "link": "http://arxiv.org/abs/2003.09038v5",
        "categories": [
            "math.OC",
            "cs.MA",
            "93A16 (Primary), 90C25, 68M15 (Secondary)",
            "C.2.4; G.1.6; B.4.5"
        ]
    },
    {
        "title": "Fast generalized Nash equilibrium seeking under partial-decision   information",
        "authors": [
            "Mattia Bianchi",
            "Giuseppe Belgioioso",
            "Sergio Grammatico"
        ],
        "summary": "We address the generalized Nash equilibrium seeking problem in a partial-decision information scenario, where each agent can only exchange information with some neighbors, although its cost function possibly depends on the strategies of all agents. The few existing methods build on projected pseudo-gradient dynamics, and require either double-layer iterations or conservative conditions on the step sizes. To overcome both these flaws and improve efficiency, we design the first fully-distributed single-layer algorithms based on proximal best-response. Our schemes are fixed-step and allow for inexact updates, which is crucial for reducing the computational complexity. Under standard assumptions on the game primitives, we establish convergence to a variational equilibrium (with linear rate for games without coupling constraints) by recasting our algorithms as proximal-point methods, opportunely preconditioned to distribute the computation among the agents. Since our analysis hinges on a restricted monotonicity property, we also provide new general results that significantly extend the domain of applicability of proximal-point methods. Besides, the operator-theoretic approach favors the implementation of provably correct acceleration schemes that can further improve the convergence speed. Finally, the potential of our algorithms is demonstrated numerically, revealing much faster convergence with respect to projected pseudo-gradient methods and validating our theoretical findings.",
        "published": "2020-03-20T15:41:25Z",
        "link": "http://arxiv.org/abs/2003.09335v3",
        "categories": [
            "math.OC",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "A generic ontology and recovery protocols for Human-Robot Collaboration   (HRC) systems",
        "authors": [
            "Kamil Skarzynski",
            "Marcin Stepniak",
            "Waldemar Bartyna",
            "Stanislaw Ambroszkiewicz"
        ],
        "summary": "Humans are considered as integral components of Human-Robot Collaboration (HRC) systems, not only as object (e.g. in health care), but also as operators and service providers in manufacturing. Sophisticated and complex tasks are to be collaboratively executed by devices (robots) and humans. We introduce a generic ontology for HRC systems. Description of humans is a part of the ontology. Critical and hazardous (for humans) situations, as well as corresponding safeguards are defined on the basis of the ontology. The ontology is an extension of the ontology introduced in Skarzynski et al. (2018) arXiv:1709.03300. The architecture of SO-MRS (see arXiv:1709.03300), a software platform for automatic task accomplishment, is extended to HRC systems. Ongoing experiments, carried out in a simulated HRC system, are to verify the ontology and the architecture.",
        "published": "2020-03-20T20:13:06Z",
        "link": "http://arxiv.org/abs/2003.09485v1",
        "categories": [
            "cs.RO",
            "cs.MA",
            "68T40",
            "I.2.9"
        ]
    },
    {
        "title": "Distributed Reinforcement Learning for Cooperative Multi-Robot Object   Manipulation",
        "authors": [
            "Guohui Ding",
            "Joewie J. Koh",
            "Kelly Merckaert",
            "Bram Vanderborght",
            "Marco M. Nicotra",
            "Christoffer Heckman",
            "Alessandro Roncone",
            "Lijun Chen"
        ],
        "summary": "We consider solving a cooperative multi-robot object manipulation task using reinforcement learning (RL). We propose two distributed multi-agent RL approaches: distributed approximate RL (DA-RL), where each agent applies Q-learning with individual reward functions; and game-theoretic RL (GT-RL), where the agents update their Q-values based on the Nash equilibrium of a bimatrix Q-value game. We validate the proposed approaches in the setting of cooperative object manipulation with two simulated robot arms. Although we focus on a small system of two agents in this paper, both DA-RL and GT-RL apply to general multi-agent systems, and are expected to scale well to large systems.",
        "published": "2020-03-21T00:43:54Z",
        "link": "http://arxiv.org/abs/2003.09540v1",
        "categories": [
            "cs.RO",
            "cs.GT",
            "cs.LG",
            "cs.MA",
            "I.2.9; I.2.6; I.2.11"
        ]
    },
    {
        "title": "Who2com: Collaborative Perception via Learnable Handshake Communication",
        "authors": [
            "Yen-Cheng Liu",
            "Junjiao Tian",
            "Chih-Yao Ma",
            "Nathan Glaser",
            "Chia-Wen Kuo",
            "Zsolt Kira"
        ],
        "summary": "In this paper, we propose the problem of collaborative perception, where robots can combine their local observations with those of neighboring agents in a learnable way to improve accuracy on a perception task. Unlike existing work in robotics and multi-agent reinforcement learning, we formulate the problem as one where learned information must be shared across a set of agents in a bandwidth-sensitive manner to optimize for scene understanding tasks such as semantic segmentation. Inspired by networking communication protocols, we propose a multi-stage handshake communication mechanism where the neural network can learn to compress relevant information needed for each stage. Specifically, a target agent with degraded sensor data sends a compressed request, the other agents respond with matching scores, and the target agent determines who to connect with (i.e., receive information from). We additionally develop the AirSim-CP dataset and metrics based on the AirSim simulator where a group of aerial robots perceive diverse landscapes, such as roads, grasslands, buildings, etc. We show that for the semantic segmentation task, our handshake communication method significantly improves accuracy by approximately 20% over decentralized baselines, and is comparable to centralized ones using a quarter of the bandwidth.",
        "published": "2020-03-21T04:16:22Z",
        "link": "http://arxiv.org/abs/2003.09575v1",
        "categories": [
            "cs.CV",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Resilience in Collaborative Optimization: Redundant and Independent Cost   Functions",
        "authors": [
            "Nirupam Gupta",
            "Nitin H. Vaidya"
        ],
        "summary": "This report considers the problem of Byzantine fault-tolerance in multi-agent collaborative optimization. In this problem, each agent has a local cost function. The goal of a collaborative optimization algorithm is to compute a minimum of the aggregate of the agents' cost functions. We consider the case when a certain number of agents may be Byzantine faulty. Such faulty agents may not follow a prescribed algorithm, and they may send arbitrary or incorrect information regarding their local cost functions. A reasonable goal in presence of such faulty agents is to minimize the aggregate cost of the non-faulty agents. In this report, we show that this goal can be achieved if and only if the cost functions of the non-faulty agents have a minimal redundancy property. We present different algorithms that achieve such tolerance against faulty agents, and demonstrate a trade-off between the complexity of an algorithm and the properties of the agents' cost functions.   Further, we also consider the case when the cost functions are independent or do not satisfy the minimal redundancy property. In that case, we quantify the tolerance against faulty agents by introducing a metric called weak resilience. We present an algorithm that attains weak resilience when the faulty agents are in the minority and the cost functions are non-negative.",
        "published": "2020-03-21T15:00:27Z",
        "link": "http://arxiv.org/abs/2003.09675v2",
        "categories": [
            "cs.DC",
            "cs.MA"
        ]
    },
    {
        "title": "A Game-Theoretic Model of Human Driving and Application to Discretionary   Lane-Changes",
        "authors": [
            "Jehong Yoo",
            "Reza Langari"
        ],
        "summary": "In this paper we consider the application of Stackelberg game theory to model discretionary lane-changing in lightly congested highway setting. The fundamental intent of this model, which is parameterized to capture driver disposition (aggressiveness or inattentiveness), is to help with the development of decision-making strategies for autonomous vehicles in ways that are mindful of how human drivers perform the same function on the road (on which have reported elsewhere.) This paper, however, focuses only on the model development and the respective qualitative assessment. This is accomplished in unit test simulations as well as in bulk mode (i.e. using the Monte Carlo methodology), via a limited traffic micro-simulation compared against the NHTSA 100-Car Naturalistic Driving Safety data. In particular, a qualitative comparison shows the relative consistency of the proposed model with human decision-making in terms of producing qualitatively similar proportions of crashes and near crashes as a function of driver inattentiveness (or aggressiveness). While this result by itself does not offer a true quantitative validation of the proposed model, it does demonstrate the utility of the proposed approach in modeling discretionary lane-changing and may therefore be of use in autonomous driving in a manner that is consistent with human decision making on the road.",
        "published": "2020-03-22T02:32:05Z",
        "link": "http://arxiv.org/abs/2003.09783v1",
        "categories": [
            "cs.GT",
            "cs.MA",
            "physics.soc-ph"
        ]
    },
    {
        "title": "Data-based Receding Horizon Control of Linear Network Systems",
        "authors": [
            "Ahmed Allibhoy",
            "Jorge Cortés"
        ],
        "summary": "We propose a distributed data-based predictive control scheme to stabilize a network system described by linear dynamics. Agents cooperate to predict the future system evolution without knowledge of the dynamics, relying instead on learning a data-based representation from a single sample trajectory. We employ this representation to reformulate the finite-horizon Linear Quadratic Regulator problem as a network optimization with separable objective functions and locally expressible constraints. We show that the controller resulting from approximately solving this problem using a distributed optimization algorithm in a receding horizon manner is stabilizing. We validate our results through numerical simulations.",
        "published": "2020-03-22T05:29:57Z",
        "link": "http://arxiv.org/abs/2003.09813v2",
        "categories": [
            "math.OC",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Fully distributed Nash equilibrium seeking over time-varying   communication networks with linear convergence rate",
        "authors": [
            "Mattia Bianchi",
            "Sergio Grammatico"
        ],
        "summary": "We design a distributed algorithm for learning Nash equilibria over time-varying communication networks in a partial-decision information scenario, where each agent can access its own cost function and local feasible set, but can only observe the actions of some neighbors. Our algorithm is based on projected pseudo-gradient dynamics, augmented with consensual terms. Under strong monotonicity and Lipschitz continuity of the game mapping, we provide a very simple proof of linear convergence, based on a contractivity property of the iterates. Compared to similar solutions proposed in literature, we also allow for a time-varying communication and derive tighter bounds on the step sizes that ensure convergence. In fact, in our numerical simulations, our algorithm outperforms the existing gradient-based methods, when the step sizes are set to their theoretical upper bounds. Finally, to relax the assumptions on the network structure, we propose a different pseudo-gradient algorithm, which is guaranteed to converge on time-varying balanced directed graphs.",
        "published": "2020-03-22T10:42:38Z",
        "link": "http://arxiv.org/abs/2003.10871v2",
        "categories": [
            "math.OC",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Modelling transmission and control of the COVID-19 pandemic in Australia",
        "authors": [
            "Sheryl L. Chang",
            "Nathan Harding",
            "Cameron Zachreson",
            "Oliver M. Cliff",
            "Mikhail Prokopenko"
        ],
        "summary": "There is a continuing debate on relative benefits of various mitigation and suppression strategies aimed to control the spread of COVID-19. Here we report the results of agent-based modelling using a fine-grained computational simulation of the ongoing COVID-19 pandemic in Australia. This model is calibrated to match key characteristics of COVID-19 transmission. An important calibration outcome is the age-dependent fraction of symptomatic cases, with this fraction for children found to be one-fifth of such fraction for adults. We apply the model to compare several intervention strategies, including restrictions on international air travel, case isolation, home quarantine, social distancing with varying levels of compliance, and school closures. School closures are not found to bring decisive benefits, unless coupled with high level of social distancing compliance. We report several trade-offs, and an important transition across the levels of social distancing compliance, in the range between 70% and 80% levels, with compliance at the 90% level found to control the disease within 13--14 weeks, when coupled with effective case isolation and international travel restrictions.",
        "published": "2020-03-23T12:31:56Z",
        "link": "http://arxiv.org/abs/2003.10218v4",
        "categories": [
            "q-bio.PE",
            "cs.MA",
            "q-bio.QM"
        ]
    },
    {
        "title": "Optimising Game Tactics for Football",
        "authors": [
            "Ryan Beal",
            "Georgios Chalkiadakis",
            "Timothy J. Norman",
            "Sarvapali D. Ramchurn"
        ],
        "summary": "In this paper we present a novel approach to optimise tactical and strategic decision making in football (soccer). We model the game of football as a multi-stage game which is made up from a Bayesian game to model the pre-match decisions and a stochastic game to model the in-match state transitions and decisions. Using this formulation, we propose a method to predict the probability of game outcomes and the payoffs of team actions. Building upon this, we develop algorithms to optimise team formation and in-game tactics with different objectives. Empirical evaluation of our approach on real-world datasets from 760 matches shows that by using optimised tactics from our Bayesian and stochastic games, we can increase a team chances of winning by up to 16.1\\% and 3.4\\% respectively.",
        "published": "2020-03-23T14:24:45Z",
        "link": "http://arxiv.org/abs/2003.10294v1",
        "categories": [
            "cs.AI",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "AfricaOS: Using a distributed, proposal-based, replicated state machine   towards liberation from the Berlin Conference of 1885",
        "authors": [
            "Jovonni L. Pharr"
        ],
        "summary": "The Berlin Conference of 1885 has influenced the way native Africans, and the African Diaspora live their daily lives. France contractually controls several resources generated by the continent of Africa. Herein lies a technical proposal to free Africa from the financial and economic agreements coerced upon the continent over a century ago by utilizing decentralized collaboration through advanced technology. AfricaOS (AOS) aims to provide a philosophical, and fundamental framework for implementing a simple, distributed, collaborative computer for agreement amongst peers. The work also demonstrates an algebra over transactions, use of the protocol for privatization, a method for tokenizing barter economies, and methods to design mechanisms for use in implementing protocol behavior.",
        "published": "2020-03-23T18:34:52Z",
        "link": "http://arxiv.org/abs/2003.10486v1",
        "categories": [
            "cs.GT",
            "cs.CR",
            "cs.DC",
            "cs.MA"
        ]
    },
    {
        "title": "Resilient Distributed Diffusion in Networks with Adversaries",
        "authors": [
            "Jiani Li",
            "Waseem Abbas",
            "Xenofon Koutsoukos"
        ],
        "summary": "In this paper, we study resilient distributed diffusion for multi-task estimation in the presence of adversaries where networked agents must estimate distinct but correlated states of interest by processing streaming data. We show that in general diffusion strategies are not resilient to malicious agents that do not adhere to the diffusion-based information processing rules. In particular, by exploiting the adaptive weights used for diffusing information, we develop time-dependent attack models that drive normal agents to converge to states selected by the attacker. We show that an attacker that has complete knowledge of the system can always drive its targeted agents to its desired estimates. Moreover, an attacker that does not have complete knowledge of the system including streaming data of targeted agents or the parameters they use in diffusion algorithms, can still be successful in deploying an attack by approximating the needed information. The attack models can be used for both stationary and non-stationary state estimation.In addition, we present and analyze a resilient distributed diffusion algorithm that is resilient to any data falsification attack in which the number of compromised agents in the local neighborhood of a normal agent is bounded. The proposed algorithm guarantees that all normal agents converge to their true target states if appropriate parameters are selected. We also analyze trade-off between the resilience of distributed diffusion and its performance in terms of steady-state mean-square-deviation (MSD) from the correct estimates. Finally, we evaluate the proposed attack models and resilient distributed diffusion algorithm using stationary and non-stationary multi-target localization.",
        "published": "2020-03-23T22:06:34Z",
        "link": "http://arxiv.org/abs/2003.10563v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Resilient Distributed Diffusion for Multi-task Estimation",
        "authors": [
            "Jiani Li",
            "Xenofon Koutsoukos"
        ],
        "summary": "Distributed diffusion is a powerful algorithm for multi-task state estimation which enables networked agents to interact with neighbors to process input data and diffuse information across the network. Compared to a centralized approach, diffusion offers multiple advantages that include robustness to node and link failures. In this paper, we consider distributed diffusion for multi-task estimation where networked agents must estimate distinct but correlated states of interest by processing streaming data. By exploiting the adaptive weights used for diffusing information, we develop attack models that drive normal agents to converge to states selected by the attacker. The attack models can be used for both stationary and non-stationary state estimation. In addition, we develop a resilient distributed diffusion algorithm under the assumption that the number of compromised nodes in the neighborhood of each normal node is bounded by $F$ and we show that resilience may be obtained at the cost of performance degradation. Finally, we evaluate the proposed attack models and resilient distributed diffusion algorithm using stationary and non-stationary multi-target localization.",
        "published": "2020-03-23T22:22:03Z",
        "link": "http://arxiv.org/abs/2003.11911v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Multi-Agent Reinforcement Learning for Problems with Combined Individual   and Team Reward",
        "authors": [
            "Hassam Ullah Sheikh",
            "Ladislau Bölöni"
        ],
        "summary": "Many cooperative multi-agent problems require agents to learn individual tasks while contributing to the collective success of the group. This is a challenging task for current state-of-the-art multi-agent reinforcement algorithms that are designed to either maximize the global reward of the team or the individual local rewards. The problem is exacerbated when either of the rewards is sparse leading to unstable learning. To address this problem, we present Decomposed Multi-Agent Deep Deterministic Policy Gradient (DE-MADDPG): a novel cooperative multi-agent reinforcement learning framework that simultaneously learns to maximize the global and local rewards. We evaluate our solution on the challenging defensive escort team problem and show that our solution achieves a significantly better and more stable performance than the direct adaptation of the MADDPG algorithm.",
        "published": "2020-03-24T00:55:37Z",
        "link": "http://arxiv.org/abs/2003.10598v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Towards Safer Self-Driving Through Great PAIN (Physically Adversarial   Intelligent Networks)",
        "authors": [
            "Piyush Gupta",
            "Demetris Coleman",
            "Joshua E. Siegel"
        ],
        "summary": "Automated vehicles' neural networks suffer from overfit, poor generalizability, and untrained edge cases due to limited data availability. Researchers synthesize randomized edge-case scenarios to assist in the training process, though simulation introduces potential for overfit to latent rules and features. Automating worst-case scenario generation could yield informative data for improving self driving. To this end, we introduce a \"Physically Adversarial Intelligent Network\" (PAIN), wherein self-driving vehicles interact aggressively in the CARLA simulation environment. We train two agents, a protagonist and an adversary, using dueling double deep Q networks (DDDQNs) with prioritized experience replay. The coupled networks alternately seek-to-collide and to avoid collisions such that the \"defensive\" avoidance algorithm increases the mean-time-to-failure and distance traveled under non-hostile operating conditions. The trained protagonist becomes more resilient to environmental uncertainty and less prone to corner case failures resulting in collisions than the agent trained without an adversary.",
        "published": "2020-03-24T05:04:13Z",
        "link": "http://arxiv.org/abs/2003.10662v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "stat.ML"
        ]
    },
    {
        "title": "Distributional Reinforcement Learning with Ensembles",
        "authors": [
            "Björn Lindenberg",
            "Jonas Nordqvist",
            "Karl-Olof Lindahl"
        ],
        "summary": "It is well known that ensemble methods often provide enhanced performance in reinforcement learning. In this paper, we explore this concept further by using group-aided training within the distributional reinforcement learning paradigm. Specifically, we propose an extension to categorical reinforcement learning, where distributional learning targets are implicitly based on the total information gathered by an ensemble. We empirically show that this may lead to much more robust initial learning, a stronger individual performance level, and good efficiency on a per-sample basis.",
        "published": "2020-03-24T14:59:54Z",
        "link": "http://arxiv.org/abs/2003.10903v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "stat.ML",
            "I.2.11; I.2.8"
        ]
    },
    {
        "title": "Driver Modeling through Deep Reinforcement Learning and Behavioral Game   Theory",
        "authors": [
            "Berat Mert Albaba",
            "Yildiray Yildiz"
        ],
        "summary": "In this paper, a synergistic combination of deep reinforcement learning and hierarchical game theory is proposed as a modeling framework for behavioral predictions of drivers in highway driving scenarios. The need for a modeling framework that can address multiple human-human and human-automation interactions, where all the agents can be modeled as decision makers simultaneously, is the main motivation behind this work. Such a modeling framework may be utilized for the validation and verification of autonomous vehicles: It is estimated that for an autonomous vehicle to reach the same safety level of cars with drivers, millions of miles of driving tests are required. The modeling framework presented in this paper may be used in a high-fidelity traffic simulator consisting of multiple human decision makers to reduce the time and effort spent for testing by allowing safe and quick assessment of self-driving algorithms. To demonstrate the fidelity of the proposed modeling framework, game theoretical driver models are compared with real human driver behavior patterns extracted from traffic data.",
        "published": "2020-03-24T18:59:17Z",
        "link": "http://arxiv.org/abs/2003.11071v1",
        "categories": [
            "cs.MA",
            "cs.LG"
        ]
    },
    {
        "title": "Norms and Sanctions as a Basis for Promoting Cybersecurity Practices",
        "authors": [
            "Nirav Ajmeri",
            "Shubham Goyal",
            "Munindar P. Singh"
        ],
        "summary": "Many cybersecurity breaches occur due to users not following good cybersecurity practices, chief among them being regulations for applying software patches to operating systems, updating applications, and maintaining strong passwords.   We capture cybersecurity expectations on users as norms. We empirically investigate sanctioning mechanisms in promoting compliance with those norms as well as the detrimental effect of sanctions on the ability of users to complete their work. We realize these ideas in a game that emulates the decision making of workers in a research lab.   Through a human-subject study, we find that whereas individual sanctions are more effective than group sanctions in achieving compliance and less detrimental on the ability of users to complete their work, individual sanctions offer significantly lower resilience especially for organizations comprising risk seekers. Our findings have implications for workforce training in cybersecurity.",
        "published": "2020-03-25T01:07:06Z",
        "link": "http://arxiv.org/abs/2003.11170v1",
        "categories": [
            "cs.MA",
            "cs.CR"
        ]
    },
    {
        "title": "Robust Stochastic Bayesian Games for Behavior Space Coverage",
        "authors": [
            "Julian Bernhard",
            "Alois Knoll"
        ],
        "summary": "A key challenge in multi-agent systems is the design of intelligent agents solving real-world tasks in close interaction with other agents (e.g. humans), thereby being confronted with a variety of behavioral variations and limited knowledge about the true behaviors of observed agents. The practicability of existing works addressing this challenge is being limited due to using finite sets of hypothesis for behavior prediction, the lack of a hypothesis design process ensuring coverage over all behavioral variations and sample-inefficiency when modeling continuous behavioral variations. In this work, we present an approach to this challenge based on a new framework of Robust Stochastic Bayesian Games (RSBGs). An RSBG defines hypothesis sets by partitioning the physically feasible, continuous behavior space of the other agents. It combines the optimality criteria of the Robust Markov Decision Process (RMDP) and the Stochastic Bayesian Game (SBG) to exponentially reduce the sample complexity for planning with hypothesis sets defined over continuous behavior spaces. Our approach outperforms the baseline algorithms in two experiments modeling time-varying intents and large multidimensional behavior spaces, while achieving the same performance as a planner with knowledge of the true behaviors of other agents.",
        "published": "2020-03-25T09:02:46Z",
        "link": "http://arxiv.org/abs/2003.11281v3",
        "categories": [
            "cs.MA",
            "I.2.8; I.2.11; I.2.9"
        ]
    },
    {
        "title": "Order Effects of Measurements in Multi-Agent Hypothesis Testing",
        "authors": [
            "Aneesh Raghavan",
            "John S. Baras"
        ],
        "summary": "In multi-agent systems, agents observe data, and use them to make inferences and take actions. As a result sensing and control naturally interfere, more so from a real-time perspective. A natural consequence is that in multi-agent systems there are propositions based on the set of observed events that might not be simultaneously verifiable, which leads to the need for probability structures that allow such \\textit{incompatible events}. We revisit the structure of events in a multi-agent system and we introduce the necessary new models that incorporate such incompatible events in the formalism. These models are essential for building non-commutative probability models, which are different than the classical models based on the Kolmogorov construction. From this perspective, we revisit the concepts of \\textit{event-state-operation structure} and the needed \\textit{relationship of incompatibility} from the literature and use them as a tool to study the needed new algebraic structure of the set of events. We present an example from multi-agent hypothesis testing where the set of events does not form a Boolean algebra, but forms an ortholattice. A possible construction of a `noncommutative probability space', accounting for \\textit{incompatible events} is discussed. We formulate and solve the binary hypothesis testing problem in the noncommutative probability space. We illustrate the occurrence of `order effects' in the multi-agent hypothesis testing problem by computing the minimum probability of error that can be achieved with different orders of measurements.",
        "published": "2020-03-26T01:09:25Z",
        "link": "http://arxiv.org/abs/2003.11693v2",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Too many cooks: Bayesian inference for coordinating multi-agent   collaboration",
        "authors": [
            "Rose E. Wang",
            "Sarah A. Wu",
            "James A. Evans",
            "Joshua B. Tenenbaum",
            "David C. Parkes",
            "Max Kleiman-Weiner"
        ],
        "summary": "Collaboration requires agents to coordinate their behavior on the fly, sometimes cooperating to solve a single task together and other times dividing it up into sub-tasks to work on in parallel. Underlying the human ability to collaborate is theory-of-mind, the ability to infer the hidden mental states that drive others to act. Here, we develop Bayesian Delegation, a decentralized multi-agent learning mechanism with these abilities. Bayesian Delegation enables agents to rapidly infer the hidden intentions of others by inverse planning. We test Bayesian Delegation in a suite of multi-agent Markov decision processes inspired by cooking problems. On these tasks, agents with Bayesian Delegation coordinate both their high-level plans (e.g. what sub-task they should work on) and their low-level actions (e.g. avoiding getting in each other's way). In a self-play evaluation, Bayesian Delegation outperforms alternative algorithms. Bayesian Delegation is also a capable ad-hoc collaborator and successfully coordinates with other agent types even in the absence of prior experience. Finally, in a behavioral experiment, we show that Bayesian Delegation makes inferences similar to human observers about the intent of others. Together, these results demonstrate the power of Bayesian Delegation for decentralized multi-agent collaboration.",
        "published": "2020-03-26T07:43:13Z",
        "link": "http://arxiv.org/abs/2003.11778v2",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Is the Juice Worth the Squeeze? Machine Learning (ML) In and For   Agent-Based Modelling (ABM)",
        "authors": [
            "Johannes Dahlke",
            "Kristina Bogner",
            "Matthias Mueller",
            "Thomas Berger",
            "Andreas Pyka",
            "Bernd Ebersberger"
        ],
        "summary": "In recent years, many scholars praised the seemingly endless possibilities of using machine learning (ML) techniques in and for agent-based simulation models (ABM). To get a more comprehensive understanding of these possibilities, we conduct a systematic literature review (SLR) and classify the literature on the application of ML in and for ABM according to a theoretically derived classification scheme. We do so to investigate how exactly machine learning has been utilized in and for agent-based models so far and to critically discuss the combination of these two promising methods. We find that, indeed, there is a broad range of possible applications of ML to support and complement ABMs in many different ways, already applied in many different disciplines. We see that, so far, ML is mainly used in ABM for two broad cases: First, the modelling of adaptive agents equipped with experience learning and, second, the analysis of outcomes produced by a given ABM. While these are the most frequent, there also exist a variety of many more interesting applications. This being the case, researchers should dive deeper into the analysis of when and how which kinds of ML techniques can support ABM, e.g. by conducting a more in-depth analysis and comparison of different use cases. Nonetheless, as the application of ML in and for ABM comes at certain costs, researchers should not use ML for ABMs just for the sake of doing it.",
        "published": "2020-03-26T15:49:01Z",
        "link": "http://arxiv.org/abs/2003.11985v1",
        "categories": [
            "econ.TH",
            "cs.MA"
        ]
    },
    {
        "title": "Robust and Deterministic Scheduling of Power Grid Actors",
        "authors": [
            "Emilie Frost",
            "Eric MSP Veith",
            "Lars Fischer"
        ],
        "summary": "Modern power grids need to cope with increasingly decentralized, volatile energy sources as well as new business models such as virtual power plants constituted from battery swarms. This warrants both, day-ahead planning of larger schedules for power plants, as well as short-term contracting to counter forecast deviations or to accommodate dynamics of the intra-day markets. In addition, the geographic distribution of renewable energy sources forces scheduling algorithms with a hugely different communication link qualities. In this paper, we present an extension to the Lightweight Power Exchange Protocol (LPEP), dubbed LPEP++. It draws on the strength of the LPEP to find the optimal solution of the combinatorial power demand-supply problem with string guarantees in acceptable time and extends it with facilities for long-term planning, parallel negotiations and reduces its memory footprint. We furthermore show its robustness towards volatile communication link quality.",
        "published": "2020-03-27T19:12:58Z",
        "link": "http://arxiv.org/abs/2003.12605v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Distributed and time-varying primal-dual dynamics via contraction   analysis",
        "authors": [
            "Pedro Cisneros-Velarde",
            "Saber Jafarpour",
            "Francesco Bullo"
        ],
        "summary": "In this note, we provide an overarching analysis of primal-dual dynamics associated to linear equality-constrained optimization problems using contraction analysis. For the well-known standard version of the problem: we establish convergence under convexity and the contracting rate under strong convexity. Then, for a canonical distributed optimization problem, we use partial contractivity to establish global exponential convergence of its primal-dual dynamics. As an application, we propose a new distributed solver for the least-squares problem with the same convergence guarantees. Finally, for time-varying versions of both centralized and distributed primal-dual dynamics, we exploit their contractive nature to establish bounds on their tracking error. To support our analyses, we introduce novel results on contraction theory.",
        "published": "2020-03-27T23:11:17Z",
        "link": "http://arxiv.org/abs/2003.12665v3",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY",
            "34H05 (Primary), 34D23, 90C25, 93C95 (Secondary)",
            "G.1.7; G.1.6"
        ]
    },
    {
        "title": "Optimized Directed Roadmap Graph for Multi-Agent Path Finding Using   Stochastic Gradient Descent",
        "authors": [
            "Christian Henkel",
            "Marc Toussaint"
        ],
        "summary": "We present a novel approach called Optimized Directed Roadmap Graph (ODRM). It is a method to build a directed roadmap graph that allows for collision avoidance in multi-robot navigation. This is a highly relevant problem, for example for industrial autonomous guided vehicles. The core idea of ODRM is, that a directed roadmap can encode inherent properties of the environment which are useful when agents have to avoid each other in that same environment. Like Probabilistic Roadmaps (PRMs), ODRM's first step is generating samples from C-space. In a second step, ODRM optimizes vertex positions and edge directions by Stochastic Gradient Descent (SGD). This leads to emergent properties like edges parallel to walls and patterns similar to two-lane streets or roundabouts. Agents can then navigate on this graph by searching their path independently and solving occurring agent-agent collisions at run-time. Using the graphs generated by ODRM compared to a non-optimized graph significantly fewer agent-agent collisions happen. We evaluate our roadmap with both, centralized and decentralized planners. Our experiments show that with ODRM even a simple centralized planner can solve problems with high numbers of agents that other multi-agent planners can not solve. Additionally, we use simulated robots with decentralized planners and online collision avoidance to show how agents are a lot faster on our roadmap than on standard grid maps.",
        "published": "2020-03-29T02:18:31Z",
        "link": "http://arxiv.org/abs/2003.12924v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Parallel Knowledge Transfer in Multi-Agent Reinforcement Learning",
        "authors": [
            "Yongyuan Liang",
            "Bangwei Li"
        ],
        "summary": "Multi-agent reinforcement learning is a standard framework for modeling multi-agent interactions applied in real-world scenarios. Inspired by experience sharing in human groups, learning knowledge parallel reusing between agents can potentially promote team learning performance, especially in multi-task environments. When all agents interact with the environment and learn simultaneously, how each independent agent selectively learns from other agents' behavior knowledge is a problem that we need to solve. This paper proposes a novel knowledge transfer framework in MARL, PAT (Parallel Attentional Transfer). We design two acting modes in PAT, student mode and self-learning mode. Each agent in our approach trains a decentralized student actor-critic to determine its acting mode at each time step. When agents are unfamiliar with the environment, the shared attention mechanism in student mode effectively selects learning knowledge from other agents to decide agents' actions. PAT outperforms state-of-the-art empirical evaluation results against the prior advising approaches. Our approach not only significantly improves team learning rate and global performance, but also is flexible and transferable to be applied in various multi-agent systems.",
        "published": "2020-03-29T17:42:00Z",
        "link": "http://arxiv.org/abs/2003.13085v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Graphical Games and Decomposition",
        "authors": [
            "Laura Arditti",
            "Giacomo Como",
            "Fabio Fagnani"
        ],
        "summary": "We consider graphical games as introduced by Kearns et al. (2001). First we analyse the interaction of graphicality with a notion of strategic equivalence of games, providing a minimal complexity graphical description for games. Then we study the interplay between graphicality and the classical decomposition of games proposed by Candogan et al. (2011), characterizing the graphical properties of each part of the decomposition.",
        "published": "2020-03-29T19:47:48Z",
        "link": "http://arxiv.org/abs/2003.13123v1",
        "categories": [
            "cs.GT",
            "cs.DM",
            "cs.MA",
            "cs.SI",
            "91A43, 91A70, 91A06, 91A10, 91A40",
            "G.2"
        ]
    },
    {
        "title": "Separable games",
        "authors": [
            "Laura Arditti",
            "Giacomo Como",
            "Fabio Fagnani"
        ],
        "summary": "We present the notion of separable game with respect to a forward directed hypergraph (FDH-graph), which refines and generalizes that of graphical game. First, we show that there exists a minimal FDH-graph with respect to which a game is separable, providing a minimal complexity description for the game. Then, we prove a symmetry property of the minimal FDH-graph of potential games and we describe how it reflects to a decomposition of the potential function in terms of local functions. In particular, these last results strengthen the ones recently proved for graphical potential games. Finally, we study the interplay between separability and the decomposition of finite games in their harmonic and potential components, characterizing the separability properties of both such components.",
        "published": "2020-03-29T20:19:35Z",
        "link": "http://arxiv.org/abs/2003.13128v4",
        "categories": [
            "cs.GT",
            "cs.DM",
            "cs.MA",
            "cs.SI",
            "91A43, 91A70, 91A06, 91A10, 91A40",
            "G.2"
        ]
    },
    {
        "title": "Approximate Equilibrium Computation for Discrete-Time Linear-Quadratic   Mean-Field Games",
        "authors": [
            "Muhammad Aneeq uz Zaman",
            "Kaiqing Zhang",
            "Erik Miehling",
            "Tamer Başar"
        ],
        "summary": "While the topic of mean-field games (MFGs) has a relatively long history, heretofore there has been limited work concerning algorithms for the computation of equilibrium control policies. In this paper, we develop a computable policy iteration algorithm for approximating the mean-field equilibrium in linear-quadratic MFGs with discounted cost. Given the mean-field, each agent faces a linear-quadratic tracking problem, the solution of which involves a dynamical system evolving in retrograde time. This makes the development of forward-in-time algorithm updates challenging. By identifying a structural property of the mean-field update operator, namely that it preserves sequences of a particular form, we develop a forward-in-time equilibrium computation algorithm. Bounds that quantify the accuracy of the computed mean-field equilibrium as a function of the algorithm's stopping condition are provided. The optimality of the computed equilibrium is validated numerically. In contrast to the most recent/concurrent results, our algorithm appears to be the first to study infinite-horizon MFGs with non-stationary mean-field equilibria, though with focus on the linear quadratic setting.",
        "published": "2020-03-30T02:53:21Z",
        "link": "http://arxiv.org/abs/2003.13195v2",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Cognitive Production Systems: A Mapping Study",
        "authors": [
            "Bastian Deutschmann",
            "Javad Ghofrani",
            "Dirk Reichelt"
        ],
        "summary": "Production plants today are becoming more and more complicated through more automation and networking. It is becoming more difficult for humans to participate, due to higher speed and decreasing reaction time of these plants. Tendencies to improve production systems with the help of cognitive systems can be identified. The goal is to save resources and time. This mapping study gives an insight into the domain, categorizes different approaches and estimates their progress. Furthermore, it shows achieved optimizations and persisting problems and barriers. These representations should make it easier in the future to address concrete problems in this research field. Human-Machine Interaction and Knowledge Gaining/Sharing represent the largest categories of the domain. Most often, a gain in efficiency and maximized effectiveness can be achieved as optimization. The most common problem is the missing or only difficult generalization of the presented concepts.",
        "published": "2020-03-30T06:30:10Z",
        "link": "http://arxiv.org/abs/2003.13235v3",
        "categories": [
            "cs.MA",
            "cs.HC"
        ]
    },
    {
        "title": "Decentralized Learning for Channel Allocation in IoT Networks over   Unlicensed Bandwidth as a Contextual Multi-player Multi-armed Bandit Game",
        "authors": [
            "Wenbo Wang",
            "Amir Leshem",
            "Dusit Niyato",
            "Zhu Han"
        ],
        "summary": "We study a decentralized channel allocation problem in an ad-hoc Internet of Things network underlaying on the spectrum licensed to a primary cellular network. In the considered network, the impoverished channel sensing/probing capability and computational resource on the IoT devices make them difficult to acquire the detailed Channel State Information (CSI) for the shared multiple channels. In practice, the unknown patterns of the primary users' transmission activities and the time-varying CSI (e.g., due to small-scale fading or device mobility) also cause stochastic changes in the channel quality. Decentralized IoT links are thus expected to learn channel conditions online based on partial observations, while acquiring no information about the channels that they are not operating on. They also have to reach an efficient, collision-free solution of channel allocation with limited coordination. Our study maps this problem into a contextual multi-player, multi-armed bandit game, and proposes a purely decentralized, three-stage policy learning algorithm through trial-and-error. Theoretical analyses shows that the proposed scheme guarantees the IoT links to jointly converge to the social optimal channel allocation with a sub-linear (i.e., polylogarithmic) regret with respect to the operational time. Simulations demonstrate that it strikes a good balance between efficiency and network scalability when compared with the other state-of-the-art decentralized bandit algorithms.",
        "published": "2020-03-30T10:05:35Z",
        "link": "http://arxiv.org/abs/2003.13314v3",
        "categories": [
            "cs.MA",
            "cs.LG",
            "cs.NI"
        ]
    },
    {
        "title": "Deep reinforcement learning for large-scale epidemic control",
        "authors": [
            "Pieter Libin",
            "Arno Moonens",
            "Timothy Verstraeten",
            "Fabian Perez-Sanjines",
            "Niel Hens",
            "Philippe Lemey",
            "Ann Nowé"
        ],
        "summary": "Epidemics of infectious diseases are an important threat to public health and global economies. Yet, the development of prevention strategies remains a challenging process, as epidemics are non-linear and complex processes. For this reason, we investigate a deep reinforcement learning approach to automatically learn prevention strategies in the context of pandemic influenza. Firstly, we construct a new epidemiological meta-population model, with 379 patches (one for each administrative district in Great Britain), that adequately captures the infection process of pandemic influenza. Our model balances complexity and computational efficiency such that the use of reinforcement learning techniques becomes attainable. Secondly, we set up a ground truth such that we can evaluate the performance of the 'Proximal Policy Optimization' algorithm to learn in a single district of this epidemiological model. Finally, we consider a large-scale problem, by conducting an experiment where we aim to learn a joint policy to control the districts in a community of 11 tightly coupled districts, for which no ground truth can be established. This experiment shows that deep reinforcement learning can be used to learn mitigation policies in complex epidemiological models with a large state space. Moreover, through this experiment, we demonstrate that there can be an advantage to consider collaboration between districts when designing prevention strategies.",
        "published": "2020-03-30T17:57:09Z",
        "link": "http://arxiv.org/abs/2003.13676v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Anytime and Efficient Coalition Formation with Spatial and Temporal   Constraints",
        "authors": [
            "Luca Capezzuto",
            "Danesh Tarapore",
            "Sarvapali D. Ramchurn"
        ],
        "summary": "The Coalition Formation with Spatial and Temporal constraints Problem (CFSTP) is a multi-agent task scheduling problem where the tasks are spatially distributed, with deadlines and workloads, and the number of agents is typically much smaller than the number of tasks, thus the agents have to form coalitions in order to maximise the number of completed tasks. The current state-of-the-art CFSTP solver, the Coalition Formation with Look-Ahead (CFLA) algorithm, has two main limitations. First, its time complexity is exponential with the number of agents. Second, as we show, its look-ahead technique is not effective in real-world scenarios, such as open multi-agent systems, where new tasks can appear at any time. In this work, we study its design and define an extension, called Coalition Formation with Improved Look-Ahead (CFLA2), which achieves better performance. Since we cannot eliminate the limitations of CFLA in CFLA2, we also develop a novel algorithm to solve the CFSTP, the first to be anytime, efficient and with provable guarantees, called Cluster-based Coalition Formation (CCF). We empirically show that, in settings where the look-ahead technique is highly effective, CCF completes up to 30% (resp. 10%) more tasks than CFLA (resp. CFLA2) while being up to four orders of magnitude faster. Our results affirm CCF as the new state-of-the-art algorithm to solve the CFSTP.",
        "published": "2020-03-30T20:42:56Z",
        "link": "http://arxiv.org/abs/2003.13806v3",
        "categories": [
            "cs.MA",
            "cs.AI",
            "I.2.11"
        ]
    },
    {
        "title": "The Pluggable Distributed Resource Allocator (PDRA): a Middleware for   Distributed Computing in Mobile Robotic Networks",
        "authors": [
            "Federico Rossi",
            "Tiago Stegun Vaquero",
            "Marc Sanchez Net",
            "Maíra Saboia da Silva",
            "Joshua Vander Hook"
        ],
        "summary": "We present the Pluggable Distributed Resource Allocator (PDRA), a middleware for distributed computing in heterogeneous mobile robotic networks. PDRA enables autonomous robotic agents to share computational resources for computationally expensive tasks such as localization and path planning. It sits between an existing single-agent planner/executor and existing computational resources (e.g. ROS packages), intercepts the executor's requests and, if needed, transparently routes them to other robots for execution. PDRA is pluggable: it can be integrated in an existing single-robot autonomy stack with minimal modifications. Task allocation decisions are performed by a mixed-integer programming algorithm, solved in a shared-world fashion, that models CPU resources, latency requirements, and multi-hop, periodic, bandwidth-limited network communications; the algorithm can minimize overall energy usage or maximize the reward for completing optional tasks. Simulation results show that PDRA can reduce energy and CPU usage by over 50% in representative multi-robot scenarios compared to a naive scheduler; runs on embedded platforms; and performs well in delay- and disruption-tolerant networks (DTNs). PDRA is available to the community under an open-source license.",
        "published": "2020-03-30T20:59:55Z",
        "link": "http://arxiv.org/abs/2003.13813v3",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "EvolveGraph: Multi-Agent Trajectory Prediction with Dynamic Relational   Reasoning",
        "authors": [
            "Jiachen Li",
            "Fan Yang",
            "Masayoshi Tomizuka",
            "Chiho Choi"
        ],
        "summary": "Multi-agent interacting systems are prevalent in the world, from pure physical systems to complicated social dynamic systems. In many applications, effective understanding of the situation and accurate trajectory prediction of interactive agents play a significant role in downstream tasks, such as decision making and planning. In this paper, we propose a generic trajectory forecasting framework (named EvolveGraph) with explicit relational structure recognition and prediction via latent interaction graphs among multiple heterogeneous, interactive agents. Considering the uncertainty of future behaviors, the model is designed to provide multi-modal prediction hypotheses. Since the underlying interactions may evolve even with abrupt changes, and different modalities of evolution may lead to different outcomes, we address the necessity of dynamic relational reasoning and adaptively evolving the interaction graphs. We also introduce a double-stage training pipeline which not only improves training efficiency and accelerates convergence, but also enhances model performance. The proposed framework is evaluated on both synthetic physics simulations and multiple real-world benchmark datasets in various areas. The experimental results illustrate that our approach achieves state-of-the-art performance in terms of prediction accuracy.",
        "published": "2020-03-31T02:49:23Z",
        "link": "http://arxiv.org/abs/2003.13924v4",
        "categories": [
            "cs.CV",
            "cs.LG",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "A Robust Gradient Tracking Method for Distributed Optimization over   Directed Networks",
        "authors": [
            "Shi Pu"
        ],
        "summary": "In this paper, we consider the problem of distributed consensus optimization over multi-agent networks with directed network topology. Assuming each agent has a local cost function that is smooth and strongly convex, the global objective is to minimize the average of all the local cost functions. To solve the problem, we introduce a robust gradient tracking method (R-Push-Pull) adapted from the recently proposed Push-Pull/AB algorithm. R-Push-Pull inherits the advantages of Push-Pull and enjoys linear convergence to the optimal solution with exact communication. Under noisy information exchange, R-Push-Pull is more robust than the existing gradient tracking based algorithms; the solutions obtained by each agent reach a neighborhood of the optimum in expectation exponentially fast under a constant stepsize policy. We provide a numerical example that demonstrate the effectiveness of R-Push-Pull.",
        "published": "2020-03-31T06:48:04Z",
        "link": "http://arxiv.org/abs/2003.13980v3",
        "categories": [
            "math.OC",
            "cs.DC",
            "cs.MA",
            "cs.SI"
        ]
    },
    {
        "title": "Mining International Political Norms from the GDELT Database",
        "authors": [
            "Rohit Murali",
            "Suravi Patnaik",
            "Stephen Cranefield"
        ],
        "summary": "Researchers have long been interested in the role that norms can play in governing agent actions in multi-agent systems. Much work has been done on formalising normative concepts from human society and adapting them for the government of open software systems, and on the simulation of normative processes in human and artificial societies. However, there has been comparatively little work on applying normative MAS mechanisms to understanding the norms in human society.   This work investigates this issue in the context of international politics. Using the GDELT dataset, containing machine-encoded records of international events extracted from news reports, we extracted bilateral sequences of inter-country events and applied a Bayesian norm mining mechanism to identify norms that best explained the observed behaviour. A statistical evaluation showed that the normative model fitted the data significantly better than a probabilistic discrete event model.",
        "published": "2020-03-31T08:48:37Z",
        "link": "http://arxiv.org/abs/2003.14027v2",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "A spatial agent based model for simulating and optimizing networked   eco-industrial systems",
        "authors": [
            "J. Raimbault",
            "J. Broere",
            "M. Somveille",
            "J. M. Serna",
            "E. Strombom",
            "C. Moore",
            "B. Zhu",
            "L. Sugar"
        ],
        "summary": "Industrial symbiosis involves creating integrated cycles of by-products and waste between networks of industrial actors in order to maximize economic value, while at the same time minimizing environmental strain. In such a network, the global environmental strain is no longer equal to the sum of the environmental strain of the individual actors, but it is dependent on how well the network performs as a whole. The development of methods to understand, manage or optimize such networks remains an open issue. In this paper we put forward a simulation model of by-product flow between industrial actors. The goal is to introduce a method for modelling symbiotic exchanges from a macro perspective. The model takes into account the effect of two main mechanisms on a multi-objective optimization of symbiotic processes. First it allows us to study the effect of geographical properties of the economic system, said differently, where actors are divided in space. Second, it allows us to study the effect of clustering complementary actors together as a function of distance, by means of a spatial correlation between the actors' by-products. Our simulations unveil patterns that are relevant for macro-level policy. First, our results show that the geographical properties are an important factor for the macro performance of symbiotic processes. Second, spatial correlations, which can be interpreted as planned clusters such as Eco-industrial parks, can lead to a very effective macro performance, but only if these are strictly implemented. Finally, we provide a proof of concept by comparing the model to real world data from the European Pollutant Release and Transfer Register database using georeferencing of the companies in the dataset. This work opens up research opportunities in interactive data-driven models and platforms to support real-world implementation of industrial symbiosis.",
        "published": "2020-03-31T12:10:37Z",
        "link": "http://arxiv.org/abs/2003.14133v1",
        "categories": [
            "physics.soc-ph",
            "cs.MA",
            "econ.GN",
            "q-fin.EC"
        ]
    },
    {
        "title": "Second-Order Guarantees in Centralized, Federated and Decentralized   Nonconvex Optimization",
        "authors": [
            "Stefan Vlaski",
            "Ali H. Sayed"
        ],
        "summary": "Rapid advances in data collection and processing capabilities have allowed for the use of increasingly complex models that give rise to nonconvex optimization problems. These formulations, however, can be arbitrarily difficult to solve in general, in the sense that even simply verifying that a given point is a local minimum can be NP-hard [1]. Still, some relatively simple algorithms have been shown to lead to surprisingly good empirical results in many contexts of interest. Perhaps the most prominent example is the success of the backpropagation algorithm for training neural networks. Several recent works have pursued rigorous analytical justification for this phenomenon by studying the structure of the nonconvex optimization problems and establishing that simple algorithms, such as gradient descent and its variations, perform well in converging towards local minima and avoiding saddle-points. A key insight in these analyses is that gradient perturbations play a critical role in allowing local descent algorithms to efficiently distinguish desirable from undesirable stationary points and escape from the latter. In this article, we cover recent results on second-order guarantees for stochastic first-order optimization algorithms in centralized, federated, and decentralized architectures.",
        "published": "2020-03-31T16:54:22Z",
        "link": "http://arxiv.org/abs/2003.14366v1",
        "categories": [
            "cs.MA",
            "cs.LG",
            "eess.SP",
            "math.OC",
            "stat.ML"
        ]
    },
    {
        "title": "Automated Configuration of Negotiation Strategies",
        "authors": [
            "Bram M. Renting",
            "Holger H. Hoos",
            "Catholijn M. Jonker"
        ],
        "summary": "Bidding and acceptance strategies have a substantial impact on the outcome of negotiations in scenarios with linear additive and nonlinear utility functions. Over the years, it has become clear that there is no single best strategy for all negotiation settings, yet many fixed strategies are still being developed. We envision a shift in the strategy design question from: What is a good strategy?, towards: What could be a good strategy? For this purpose, we developed a method leveraging automated algorithm configuration to find the best strategies for a specific set of negotiation settings. By empowering automated negotiating agents using automated algorithm configuration, we obtain a flexible negotiation agent that can be configured automatically for a rich space of opponents and negotiation scenarios.   To critically assess our approach, the agent was tested in an ANAC-like bilateral automated negotiation tournament setting against past competitors. We show that our automatically configured agent outperforms all other agents, with a 5.1% increase in negotiation payoff compared to the next-best agent. We note that without our agent in the tournament, the top-ranked agent wins by a margin of only 0.01%.",
        "published": "2020-03-31T20:31:33Z",
        "link": "http://arxiv.org/abs/2004.00094v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Counterfactual Multi-Agent Reinforcement Learning with Graph Convolution   Communication",
        "authors": [
            "Jianyu Su",
            "Stephen Adams",
            "Peter A. Beling"
        ],
        "summary": "We consider a fully cooperative multi-agent system where agents cooperate to maximize a system's utility in a partial-observable environment. We propose that multi-agent systems must have the ability to (1) communicate and understand the inter-plays between agents and (2) correctly distribute rewards based on an individual agent's contribution. In contrast, most work in this setting considers only one of the above abilities. In this study, we develop an architecture that allows for communication among agents and tailors the system's reward for each individual agent. Our architecture represents agent communication through graph convolution and applies an existing credit assignment structure, counterfactual multi-agent policy gradient (COMA), to assist agents to learn communication by back-propagation. The flexibility of the graph structure enables our method to be applicable to a variety of multi-agent systems, e.g. dynamic systems that consist of varying numbers of agents and static systems with a fixed number of agents. We evaluate our method on a range of tasks, demonstrating the advantage of marrying communication with credit assignment. In the experiments, our proposed method yields better performance than the state-of-art methods, including COMA. Moreover, we show that the communication strategies offers us insights and interpretability of the system's cooperative policies.",
        "published": "2020-04-01T14:36:13Z",
        "link": "http://arxiv.org/abs/2004.00470v2",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Generate Country-Scale Networks of Interaction from Scattered Statistics",
        "authors": [
            "Samuel Thiriot",
            "Jean-Daniel Kant"
        ],
        "summary": "It is common to define the structure of interactions among a population of agents by a network. Most of agent-based models were shown highly sensitive to that network, so the relevance of simulation results directely depends on the descriptive power of that network. When studying social dynamics in large populations, that network cannot be collected, and is rather generated by algorithms which aim to fit general properties of social networks. However, more precise data is available at a country scale in the form of socio-demographic studies, census or sociological studies. These \"scattered statistics\" provide rich information, especially on agents' attributes, similar properties of tied agents and affiliations. In this paper, we propose a generic methodology to bring up together these scattered statistics with bayesian networks. We explain how to generate a population of heterogeneous agents, and how to create links by using both scattered statistics and knowledge on social selection processes. The methodology is illustrated by generating an interaction network for rural Kenya which includes familial structure, colleagues and friendship constrained given field studies and statistics.",
        "published": "2020-04-01T14:38:40Z",
        "link": "http://arxiv.org/abs/2004.01031v1",
        "categories": [
            "cs.MA",
            "cs.SI",
            "stat.AP",
            "I.6; J.4; G.3"
        ]
    },
    {
        "title": "No-Regret Learning Dynamics for Extensive-Form Correlated Equilibrium",
        "authors": [
            "Andrea Celli",
            "Alberto Marchesi",
            "Gabriele Farina",
            "Nicola Gatti"
        ],
        "summary": "The existence of simple, uncoupled no-regret dynamics that converge to correlated equilibria in normal-form games is a celebrated result in the theory of multi-agent systems. Specifically, it has been known for more than 20 years that when all players seek to minimize their internal regret in a repeated normal-form game, the empirical frequency of play converges to a normal-form correlated equilibrium. Extensive-form (that is, tree-form) games generalize normal-form games by modeling both sequential and simultaneous moves, as well as private information. Because of the sequential nature and presence of partial information in the game, extensive-form correlation has significantly different properties than the normal-form counterpart, many of which are still open research directions. Extensive-form correlated equilibrium (EFCE) has been proposed as the natural extensive-form counterpart to normal-form correlated equilibrium. However, it was currently unknown whether EFCE emerges as the result of uncoupled agent dynamics. In this paper, we give the first uncoupled no-regret dynamics that converge to the set of EFCEs in $n$-player general-sum extensive-form games with perfect recall. First, we introduce a notion of trigger regret in extensive-form games, which extends that of internal regret in normal-form games. When each player has low trigger regret, the empirical frequency of play is close to an EFCE. Then, we give an efficient no-trigger-regret algorithm. Our algorithm decomposes trigger regret into local subproblems at each decision point for the player, and constructs a global strategy of the player from the local solutions at each decision point.",
        "published": "2020-04-01T17:39:00Z",
        "link": "http://arxiv.org/abs/2004.00603v5",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Improving Confidence in the Estimation of Values and Norms",
        "authors": [
            "Luciano Cavalcante Siebert",
            "Rijk Mercuur",
            "Virginia Dignum",
            "Jeroen van den Hoven",
            "Catholijn Jonker"
        ],
        "summary": "Autonomous agents (AA) will increasingly be interacting with us in our daily lives. While we want the benefits attached to AAs, it is essential that their behavior is aligned with our values and norms. Hence, an AA will need to estimate the values and norms of the humans it interacts with, which is not a straightforward task when solely observing an agent's behavior. This paper analyses to what extent an AA is able to estimate the values and norms of a simulated human agent (SHA) based on its actions in the ultimatum game. We present two methods to reduce ambiguity in profiling the SHAs: one based on search space exploration and another based on counterfactual analysis. We found that both methods are able to increase the confidence in estimating human values and norms, but differ in their applicability, the latter being more efficient when the number of interactions with the agent is to be minimized. These insights are useful to improve the alignment of AAs with human values and norms.",
        "published": "2020-04-02T15:03:03Z",
        "link": "http://arxiv.org/abs/2004.01056v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Learning to cooperate: Emergent communication in multi-agent navigation",
        "authors": [
            "Ivana Kajić",
            "Eser Aygün",
            "Doina Precup"
        ],
        "summary": "Emergent communication in artificial agents has been studied to understand language evolution, as well as to develop artificial systems that learn to communicate with humans. We show that agents performing a cooperative navigation task in various gridworld environments learn an interpretable communication protocol that enables them to efficiently, and in many cases, optimally, solve the task. An analysis of the agents' policies reveals that emergent signals spatially cluster the state space, with signals referring to specific locations and spatial directions such as \"left\", \"up\", or \"upper left room\". Using populations of agents, we show that the emergent protocol has basic compositional structure, thus exhibiting a core property of natural language.",
        "published": "2020-04-02T16:03:17Z",
        "link": "http://arxiv.org/abs/2004.01097v2",
        "categories": [
            "cs.LG",
            "cs.CL",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Information State Embedding in Partially Observable Cooperative   Multi-Agent Reinforcement Learning",
        "authors": [
            "Weichao Mao",
            "Kaiqing Zhang",
            "Erik Miehling",
            "Tamer Başar"
        ],
        "summary": "Multi-agent reinforcement learning (MARL) under partial observability has long been considered challenging, primarily due to the requirement for each agent to maintain a belief over all other agents' local histories -- a domain that generally grows exponentially over time. In this work, we investigate a partially observable MARL problem in which agents are cooperative. To enable the development of tractable algorithms, we introduce the concept of an information state embedding that serves to compress agents' histories. We quantify how the compression error influences the resulting value functions for decentralized control. Furthermore, we propose an instance of the embedding based on recurrent neural networks (RNNs). The embedding is then used as an approximate information state, and can be fed into any MARL algorithm. The proposed embed-then-learn pipeline opens the black-box of existing (partially observable) MARL algorithms, allowing us to establish some theoretical guarantees (error bounds of value functions) while still achieving competitive performance with many end-to-end approaches.",
        "published": "2020-04-02T16:03:42Z",
        "link": "http://arxiv.org/abs/2004.01098v3",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Layer entanglement in multiplex, temporal multiplex, and coupled   multilayer networks",
        "authors": [
            "Blaž Škrlj",
            "Benjamin Renoust"
        ],
        "summary": "Complex networks, such as transportation networks, social networks, or biological networks, capture the complex system they model often by representing only one type of interactions. In real world systems, there may be many different aspects that connect entities together. These can be captured using multilayer networks, which combine different modalities of interactions in a single model. Coupling in multilayer networks may exhibit different properties which can be related to the very nature of the data they model (or to events in time-dependant data). We hypothesise that such properties may be reflected in the way layers are intertwined. In this paper, we investigated these through the prism of layer entanglement in coupled multilayer networks. We test over 30 real-life networks in 6 different disciplines (social, genetic, transport, co-authorship, trade, and neuronal networks). We further propose a random generator, displaying comparable patterns of elementary layer entanglement and transition coupling entanglement across 1,329,696 synthetic coupled multilayer networks. Our experiments demonstrate difference of layer entanglement across disciplines, and even suggest a link between entanglement intensity and homophily. We additionally study entanglement in 3 real world temporal datasets displaying a potential rise in entanglement activity prior to other network activity.",
        "published": "2020-04-02T17:11:34Z",
        "link": "http://arxiv.org/abs/2004.01534v2",
        "categories": [
            "physics.soc-ph",
            "cs.MA",
            "cs.SI",
            "stat.OT"
        ]
    },
    {
        "title": "Distributed Hypothesis Testing and Social Learning in Finite Time with a   Finite Amount of Communication",
        "authors": [
            "Shreyas Sundaram",
            "Aritra Mitra"
        ],
        "summary": "We consider the problem of distributed hypothesis testing (or social learning) where a network of agents seeks to identify the true state of the world from a finite set of hypotheses, based on a series of stochastic signals that each agent receives. Prior work on this problem has provided distributed algorithms that guarantee asymptotic learning of the true state, with corresponding efforts to improve the rate of learning. In this paper, we first argue that one can readily modify existing asymptotic learning algorithms to enable learning in finite time, effectively yielding arbitrarily large (asymptotic) rates. We then provide a simple algorithm for finite-time learning which only requires the agents to exchange a binary vector (of length equal to the number of possible hypotheses) with their neighbors at each time-step. Finally, we show that if the agents know the diameter of the network, our algorithm can be further modified to allow all agents to learn the true state and stop transmitting to their neighbors after a finite number of time-steps.",
        "published": "2020-04-02T23:38:13Z",
        "link": "http://arxiv.org/abs/2004.01306v1",
        "categories": [
            "cs.MA",
            "cs.IT",
            "cs.LG",
            "math.IT"
        ]
    },
    {
        "title": "Tracking Performance of Online Stochastic Learners",
        "authors": [
            "Stefan Vlaski",
            "Elsa Rizk",
            "Ali H. Sayed"
        ],
        "summary": "The utilization of online stochastic algorithms is popular in large-scale learning settings due to their ability to compute updates on the fly, without the need to store and process data in large batches. When a constant step-size is used, these algorithms also have the ability to adapt to drifts in problem parameters, such as data or model properties, and track the optimal solution with reasonable accuracy. Building on analogies with the study of adaptive filters, we establish a link between steady-state performance derived under stationarity assumptions and the tracking performance of online learners under random walk models. The link allows us to infer the tracking performance from steady-state expressions directly and almost by inspection.",
        "published": "2020-04-04T14:16:27Z",
        "link": "http://arxiv.org/abs/2004.01942v1",
        "categories": [
            "math.OC",
            "cs.LG",
            "cs.MA",
            "eess.SP",
            "stat.ML"
        ]
    },
    {
        "title": "Designing and Connectivity Checking of Implicit Social Networks from the   User-Item Rating Data",
        "authors": [
            "Suman Banerjee"
        ],
        "summary": "\\emph{Implicit Social Network} is a connected social structure among a group of persons, where two of them are linked if they have some common interest. One real\\mbox{-}life example of such networks is the implicit social network among the customers of an online commercial house, where there exists an edge between two customers if they like similar items. Such networks are often useful for different commercial applications such as \\textit{target advertisement}, \\textit{viral marketing}, etc. In this article, we study two fundamental problems in this direction. The first one is that, given the user\\mbox{-}item rating data of an E\\mbox{-}Commerce house, how we can design implicit social networks among its users and the second one is at the time of designing itself can we obtain the connectivity information among the users. Formally, we call the first problem as the \\textsc{Implicit User Network Design} Problem and the second one as \\textsc{Implicit User Network Design with Connectivity Checking} Problem. For the first problem, we propose three different algorithms, namely \\emph{`Exhaustive Search Approach'}, \\emph{`Clique Addition Approach'}, and \\textit{`Matrix Multiplication\\mbox{-}Based Approach'}. For the second problem, we propose two different approaches. The first one is the sequential approach: designing and then connectivity checking, and the other one is a concurrent approach, which is basically an incremental algorithm that performs designing and connectivity checking simultaneously. Proposed methodologies have experimented with three publicly available rating network datasets such as \\emph{Flixter}, \\textit{Movielens}, and \\textit{Epinions}.",
        "published": "2020-04-05T11:44:51Z",
        "link": "http://arxiv.org/abs/2004.02166v1",
        "categories": [
            "cs.SI",
            "cs.MA"
        ]
    },
    {
        "title": "A Receding Horizon Scheduling Approach for Search & Rescue Scenarios",
        "authors": [
            "Yousef Emam",
            "Sean Wilson",
            "Mathias Hakenberg",
            "Ulrich Munz",
            "Magnus Egerstedt"
        ],
        "summary": "Many applications involving complex multi-task problems such as disaster relief, logistics and manufacturing necessitate the deployment and coordination of heterogeneous multi-agent systems due to the sheer number of tasks that must be executed simultaneously. A fundamental requirement for the successful coordination of such systems is leveraging the specialization of each agent within the team. This work presents a Receding Horizon Planning (RHP) framework aimed at scheduling tasks for heterogeneous multi-agent teams in a robust manner. In order to allow for the modular addition and removal of different types of agents to the team, the proposed framework accounts for the capabilities that each agent exhibits (e.g. quadrotors are agile and agnostic to rough terrain but are not suited to transport heavy payloads). An instantiation of the proposed RHP is developed and tested for a search and rescue scenario. Moreover, we present an abstracted search and rescue simulation environment, where a heterogeneous team of agents is deployed to simultaneously explore the environment, find and rescue trapped victims, and extinguish spreading fires as quickly as possible. We validate the effectiveness of our approach through extensive simulations comparing the presented framework with various planning horizons to a greedy task allocation scheme.",
        "published": "2020-04-05T23:17:32Z",
        "link": "http://arxiv.org/abs/2004.02347v1",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Split Cycle: A New Condorcet Consistent Voting Method Independent of   Clones and Immune to Spoilers",
        "authors": [
            "Wesley H. Holliday",
            "Eric Pacuit"
        ],
        "summary": "We propose a Condorcet consistent voting method that we call Split Cycle. Split Cycle belongs to the small family of known voting methods satisfying the anti-vote-splitting criterion of independence of clones. In this family, only Split Cycle satisfies a new criterion we call immunity to spoilers, which concerns adding candidates to elections, as well as the known criteria of positive involvement and negative involvement, which concern adding voters to elections. Thus, in contrast to other clone-independent methods, Split Cycle mitigates both \"spoiler effects\" and \"strong no show paradoxes.\"",
        "published": "2020-04-05T23:20:17Z",
        "link": "http://arxiv.org/abs/2004.02350v10",
        "categories": [
            "cs.GT",
            "cs.MA",
            "econ.TH",
            "91B12, 91B14, 91B10",
            "I.2.11"
        ]
    },
    {
        "title": "Trust-based Multiagent Consensus or Weightings Aggregation",
        "authors": [
            "Bruno Yun",
            "Madalina Croitoru"
        ],
        "summary": "We introduce a framework for reaching a consensus amongst several agents communicating via a trust network on conflicting information about their environment. We formalise our approach and provide an empirical and theoretical analysis of its properties.",
        "published": "2020-04-06T08:50:13Z",
        "link": "http://arxiv.org/abs/2004.02490v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Adaptive Social Learning",
        "authors": [
            "Virginia Bordignon",
            "Vincenzo Matta",
            "Ali H. Sayed"
        ],
        "summary": "This work proposes a novel strategy for social learning by introducing the critical feature of adaptation. In social learning, several distributed agents update continually their belief about a phenomenon of interest through: i) direct observation of streaming data that they gather locally; and ii) diffusion of their beliefs through local cooperation with their neighbors. Traditional social learning implementations are known to learn well the underlying hypothesis (which means that the belief of every individual agent peaks at the true hypothesis), achieving steady improvement in the learning accuracy under stationary conditions. However, these algorithms do not perform well under nonstationary conditions commonly encountered in online learning, exhibiting a significant inertia to track drifts in the streaming data. In order to address this gap, we propose an Adaptive Social Learning (ASL) strategy, which relies on a small step-size parameter to tune the adaptation degree. First, we provide a detailed characterization of the learning performance by means of a steady-state analysis. Focusing on the small step-size regime, we establish that the ASL strategy achieves consistent learning under standard global identifiability assumptions. We derive reliable Gaussian approximations for the probability of error (i.e., of choosing a wrong hypothesis) at each individual agent. We carry out a large deviations analysis revealing the universal behavior of adaptive social learning: the error probabilities decrease exponentially fast with the inverse of the step-size, and we characterize the resulting exponential learning rate. Second, we characterize the adaptation performance by means of a detailed transient analysis, which allows us to obtain useful analytical formulas relating the adaptation time to the step-size.",
        "published": "2020-04-06T08:55:37Z",
        "link": "http://arxiv.org/abs/2004.02494v2",
        "categories": [
            "cs.MA",
            "cs.IT",
            "eess.SP",
            "math.IT"
        ]
    },
    {
        "title": "A Norm Emergence Framework for Normative MAS -- Position Paper",
        "authors": [
            "Andreasa Morris-Martin",
            "Marina De Vos",
            "Julian Padget"
        ],
        "summary": "Norm emergence is typically studied in the context of multiagent systems (MAS) where norms are implicit, and participating agents use simplistic decision-making mechanisms. These implicit norms are usually unconsciously shared and adopted through agent interaction. A norm is deemed to have emerged when a threshold or predetermined percentage of agents follow the \"norm\". Conversely, in normative MAS, norms are typically explicit and agents deliberately share norms through communication or are informed about norms by an authority, following which an agent decides whether to adopt the norm or not. The decision to adopt a norm by the agent can happen immediately after recognition or when an applicable situation arises. In this paper, we make the case that, similarly, a norm has emerged in a normative MAS when a percentage of agents adopt the norm. Furthermore, we posit that agents themselves can and should be involved in norm synthesis, and hence influence the norms governing the MAS, in line with Ostrom's eight principles. Consequently, we put forward a framework for the emergence of norms within a normative MAS, that allows participating agents to propose/request changes to the normative system, while special-purpose synthesizer agents formulate new norms or revisions in response to these requests. Synthesizers must collectively agree that the new norm or norm revision should proceed, and then finally be approved by an \"Oracle\". The normative system is then modified to incorporate the norm.",
        "published": "2020-04-06T11:42:01Z",
        "link": "http://arxiv.org/abs/2004.02575v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Using Multi-Agent Reinforcement Learning in Auction Simulations",
        "authors": [
            "Medet Kanmaz",
            "Elif Surer"
        ],
        "summary": "Game theory has been developed by scientists as a theory of strategic interaction among players who are supposed to be perfectly rational. These strategic interactions might have been presented in an auction, a business negotiation, a chess game, or even in a political conflict aroused between different agents. In this study, the strategic (rational) agents created by reinforcement learning algorithms are supposed to be bidder agents in various types of auction mechanisms such as British Auction, Sealed Bid Auction, and Vickrey Auction designs. Next, the equilibrium points determined by the agents are compared with the outcomes of the Nash equilibrium points for these environments. The bidding strategy of the agents is analyzed in terms of individual rationality, truthfulness (strategy-proof), and computational efficiency. The results show that using a multi-agent reinforcement learning strategy improves the outcomes of the auction simulations.",
        "published": "2020-04-06T15:48:28Z",
        "link": "http://arxiv.org/abs/2004.02764v1",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Networked Multi-Agent Reinforcement Learning with Emergent Communication",
        "authors": [
            "Shubham Gupta",
            "Rishi Hazra",
            "Ambedkar Dukkipati"
        ],
        "summary": "Multi-Agent Reinforcement Learning (MARL) methods find optimal policies for agents that operate in the presence of other learning agents. Central to achieving this is how the agents coordinate. One way to coordinate is by learning to communicate with each other. Can the agents develop a language while learning to perform a common task? In this paper, we formulate and study a MARL problem where cooperative agents are connected to each other via a fixed underlying network. These agents can communicate along the edges of this network by exchanging discrete symbols. However, the semantics of these symbols are not predefined and, during training, the agents are required to develop a language that helps them in accomplishing their goals. We propose a method for training these agents using emergent communication. We demonstrate the applicability of the proposed framework by applying it to the problem of managing traffic controllers, where we achieve state-of-the-art performance as compared to a number of strong baselines. More importantly, we perform a detailed analysis of the emergent communication to show, for instance, that the developed language is grounded and demonstrate its relationship with the underlying network topology. To the best of our knowledge, this is the only work that performs an in depth analysis of emergent communication in a networked MARL setting while being applicable to a broad class of problems.",
        "published": "2020-04-06T16:13:23Z",
        "link": "http://arxiv.org/abs/2004.02780v2",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "The Impact of Message Passing in Agent-Based Submodular Maximization",
        "authors": [
            "David Grimsman",
            "Matthew R. Kirchner",
            "João P. Hespanha",
            "Jason R. Marden"
        ],
        "summary": "This paper considers a set of sensors, which as a group are tasked with taking measurements of the environment and sending a small subset of the measurements to a centralized data fusion center, where the measurements will be used to estimate the overall state of the environment. The sensors' goal is to send the most informative set of measurements so that the estimate is as accurate as possible. This problem is formulated as a submodular maximization problem, for which there exists a well-studied greedy algorithm, where each sensor sequentially chooses a set of measurements from its own local set, and communicates its decision to the future sensors in the sequence. In this work, sensors can additionally share measurements with one another, in order to augment the decision set of each sensor. We explore how this increase in communication can be exploited to improve the results of the nominal greedy algorithm. Specifically, we show that this measurement passing can improve the quality of the resulting measurement set by up to a factor of $n+1$, where $n$ is the number of sensors.",
        "published": "2020-04-07T00:24:55Z",
        "link": "http://arxiv.org/abs/2004.03050v3",
        "categories": [
            "cs.MA",
            "cs.DS",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Scenario-Transferable Semantic Graph Reasoning for Interaction-Aware   Probabilistic Prediction",
        "authors": [
            "Yeping Hu",
            "Wei Zhan",
            "Masayoshi Tomizuka"
        ],
        "summary": "Accurately predicting the possible behaviors of traffic participants is an essential capability for autonomous vehicles. Since autonomous vehicles need to navigate in dynamically changing environments, they are expected to make accurate predictions regardless of where they are and what driving circumstances they encountered. Several methodologies have been proposed to solve prediction problems under different traffic situations. These works usually combine agent trajectories with either color-coded or vectorized high definition (HD) map as input representations and encode this information for behavior prediction tasks. However, not all the information is relevant in the scene for the forecasting and such irrelevant information may be even distracting to the forecasting in certain situations. Therefore, in this paper, we propose a novel generic representation for various driving environments by taking the advantage of semantics and domain knowledge. Using semantics enables situations to be modeled in a uniform way and applying domain knowledge filters out unrelated elements to target vehicle's future behaviors. We then propose a general semantic behavior prediction framework to effectively utilize these representations by formulating them into spatial-temporal semantic graphs and reasoning internal relations among these graphs. We theoretically and empirically validate the proposed framework under highly interactive and complex scenarios, demonstrating that our method not only achieves state-of-the-art performance, but also processes desirable zero-shot transferability.",
        "published": "2020-04-07T00:34:36Z",
        "link": "http://arxiv.org/abs/2004.03053v3",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Fully-Heterogeneous Containment Control of a Network of Leader-Follower   Systems",
        "authors": [
            "Majid Mazouchi",
            "Farzaneh Tatari",
            "Bahare Kiumarsi",
            "Hamidreza Modares"
        ],
        "summary": "This paper develops a distributed solution to the fully-heterogeneous containment control problem (CCP), for which not only the followers' dynamics but also the leaders' dynamics are non-identical. A novel formulation of the fully-heterogeneous CCP is first presented in which each follower constructs its virtual exo-system. To build these virtual exo-systems by followers, a novel distributed algorithm is developed to calculate the so-called normalized level of influences (NLIs) of all leaders on each follower and a novel adaptive distributed observer is designed to estimate the dynamics and states of all leaders that have an influence on each follower. Then, a distributed control protocol is proposed based on the cooperative output regulation framework, utilizing this virtual exo-system. Based on estimations of leaders' dynamics and states and NLIs of leaders on each follower, the solutions of the so-called linear regulator equations are calculated in a distributed manner, and consequently, a distributed control protocol is designed for solving the output containment problem. Finally, theoretical results are verified by performing numerical simulations.",
        "published": "2020-04-07T21:53:54Z",
        "link": "http://arxiv.org/abs/2004.03725v3",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Earned Benefit Maximization in Social Networks Under Budget Constraint",
        "authors": [
            "Suman Banerjee",
            "Mamata Jenamani",
            "Dilip Kumar Pratihar"
        ],
        "summary": "Given a social network with nonuniform selection cost of the users, the problem of \\textit{Budgeted Influence Maximization} (BIM in short) asks for selecting a subset of the nodes within an allocated budget for initial activation, such that due to the cascading effect, influence in the network is maximized. In this paper, we study this problem with a variation, where a set of nodes are designated as target nodes, each of them is assigned with a benefit value, that can be earned by influencing them, and our goal is to maximize the earned benefit by initially activating a set of nodes within the budget. We call this problem as the \\textsc{Earned Benefit Maximization Problem}. First, we show that this problem is NP\\mbox{-}Hard and the benefit function is \\textit{monotone}, \\textit{sub\\mbox{-}modular} under the \\textit{Independent Cascade Model} of diffusion. We propose an incremental greedy strategy for this problem and show, with minor modification it gives $(1-\\frac{1}{\\sqrt{e}})$\\mbox{-}factor approximation guarantee on the earned benefit. Next, by exploiting the sub\\mbox{-}modularity property of the benefit function, we improve the efficiency of the proposed greedy algorithm. Then, we propose a hop\\mbox{-}based heuristic method, which works based on the computation of the `expected earned benefit' of the effective neighbors corresponding to the target nodes. Finally, we perform a series of extensive experiments with four real\\mbox{-}life, publicly available social network datasets. From the experiments, we observe that the seed sets selected by the proposed algorithms can achieve more benefit compared to many existing methods. Particularly, the hop\\mbox{-}based approach is found to be more efficient than the other ones for solving this problem.",
        "published": "2020-04-08T14:19:37Z",
        "link": "http://arxiv.org/abs/2004.04003v1",
        "categories": [
            "cs.SI",
            "cs.DS",
            "cs.MA"
        ]
    },
    {
        "title": "Centralized and decentralized isolation strategies and their impact on   the COVID-19 pandemic dynamics",
        "authors": [
            "Alexandru Topirceanu",
            "Mihai Udrescu",
            "Radu Marculescu"
        ],
        "summary": "The infectious diseases are spreading due to human interactions enabled by various social networks. Therefore, when a new pathogen such as SARS-CoV-2 causes an outbreak, the non-pharmaceutical isolation strategies (e.g., social distancing) are the only possible response to disrupt its spreading. To this end, we introduce the new epidemic model (SICARS) and compare the centralized (C), decentralized (D), and combined (C+D) social distancing strategies, and analyze their efficiency to control the dynamics of COVID-19 on heterogeneous complex networks. Our analysis shows that the centralized social distancing is necessary to minimize the pandemic spreading. The decentralized strategy is insufficient when used alone, but offers the best results when combined with the centralized one. Indeed, the (C+D) is the most efficient isolation strategy at mitigating the network superspreaders and reducing the highest node degrees to less than 10% of their initial values. Our results also indicate that stronger social distancing, e.g., cutting 75% of social ties, can reduce the outbreak by 75% for the C isolation, by 33% for the D isolation, and by 87% for the (C+D) isolation strategy. Finally, we study the impact of proactive versus reactive isolation strategies, as well as their delayed enforcement. We find that the reactive response to the pandemic is less efficient, and delaying the adoption of isolation measures by over one month (since the outbreak onset in a region) can have alarming effects; thus, our study contributes to an understanding of the COVID-19 pandemic both in space and time. We believe our investigations have a high social relevance as they provide insights into understanding how different degrees of social distancing can reduce the peak infection ratio substantially; this can make the COVID-19 pandemic easier to understand and control over an extended period of time.",
        "published": "2020-04-08T19:48:12Z",
        "link": "http://arxiv.org/abs/2004.04222v2",
        "categories": [
            "q-bio.PE",
            "cs.MA",
            "cs.SI",
            "physics.soc-ph"
        ]
    },
    {
        "title": "Re-conceptualising the Language Game Paradigm in the Framework of   Multi-Agent Reinforcement Learning",
        "authors": [
            "Paul Van Eecke",
            "Katrien Beuls"
        ],
        "summary": "In this paper, we formulate the challenge of re-conceptualising the language game experimental paradigm in the framework of multi-agent reinforcement learning (MARL). If successful, future language game experiments will benefit from the rapid and promising methodological advances in the MARL community, while future MARL experiments on learning emergent communication will benefit from the insights and results gained from language game experiments. We strongly believe that this cross-pollination has the potential to lead to major breakthroughs in the modelling of how human-like languages can emerge and evolve in multi-agent systems.",
        "published": "2020-04-09T17:55:15Z",
        "link": "http://arxiv.org/abs/2004.04722v1",
        "categories": [
            "cs.AI",
            "cs.CL",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "First Stretch then Shrink and Bulk: A Two Phase Approach for Enumeration   of Maximal $(Δ, γ)$\\mbox{-}Cliques of a Temporal Network",
        "authors": [
            "Suman Banerjee",
            "Bithika Pal"
        ],
        "summary": "A \\emph{Temporal Network} (also known as \\emph{Link Stream} or \\emph{Time-Varying Graph}) is often used to model a time-varying relationship among a group of agents. It is typically represented as a collection of triplets of the form $(u,v,t)$ that denotes the interaction between the agents $u$ and $v$ at time $t$. For analyzing the contact patterns of the agents forming a temporal network, recently the notion of classical \\textit{clique} of a \\textit{static graph} has been generalized as \\textit{$\\Delta$\\mbox{-}Clique} of a Temporal Network. In the same direction, one of our previous studies introduces the notion of \\textit{$(\\Delta, \\gamma)$\\mbox{-}Clique}, which is basically a \\textit{vertex set}, \\textit{time interval} pair, in which every pair of the clique vertices are linked at least $\\gamma$ times in every $\\Delta$ duration of the time interval. In this paper, we propose a different methodology for enumerating all the maximal $(\\Delta, \\gamma)$\\mbox{-}Cliques of a given temporal network. The proposed methodology is broadly divided into two phases. In the first phase, each temporal link is processed for constructing $(\\Delta, \\gamma)$\\mbox{-}Clique(s) with maximum duration. In the second phase, these initial cliques are expanded by vertex addition to form the maximal cliques. From the experimentation carried out on $5$ real\\mbox{-}world temporal network datasets, we observe that the proposed methodology enumerates all the maximal $(\\Delta,\\gamma)$\\mbox{-}Cliques efficiently, particularly when the dataset is sparse. As a special case ($\\gamma=1$), the proposed methodology is also able to enumerate $(\\Delta,1) \\equiv \\Delta$\\mbox{-}cliques with much less time compared to the existing methods.",
        "published": "2020-04-09T18:42:47Z",
        "link": "http://arxiv.org/abs/2004.05935v1",
        "categories": [
            "cs.DS",
            "cs.DB",
            "cs.MA"
        ]
    },
    {
        "title": "Quantifying the Impact of Non-Stationarity in Reinforcement   Learning-Based Traffic Signal Control",
        "authors": [
            "Lucas N. Alegre",
            "Ana L. C. Bazzan",
            "Bruno C. da Silva"
        ],
        "summary": "In reinforcement learning (RL), dealing with non-stationarity is a challenging issue. However, some domains such as traffic optimization are inherently non-stationary. Causes for and effects of this are manifold. In particular, when dealing with traffic signal controls, addressing non-stationarity is key since traffic conditions change over time and as a function of traffic control decisions taken in other parts of a network. In this paper we analyze the effects that different sources of non-stationarity have in a network of traffic signals, in which each signal is modeled as a learning agent. More precisely, we study both the effects of changing the \\textit{context} in which an agent learns (e.g., a change in flow rates experienced by it), as well as the effects of reducing agent observability of the true environment state. Partial observability may cause distinct states (in which distinct actions are optimal) to be seen as the same by the traffic signal agents. This, in turn, may lead to sub-optimal performance. We show that the lack of suitable sensors to provide a representative observation of the real state seems to affect the performance more drastically than the changes to the underlying traffic patterns.",
        "published": "2020-04-09T19:20:43Z",
        "link": "http://arxiv.org/abs/2004.04778v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Policy Gradient using Weak Derivatives for Reinforcement Learning",
        "authors": [
            "Sujay Bhatt",
            "Alec Koppel",
            "Vikram Krishnamurthy"
        ],
        "summary": "This paper considers policy search in continuous state-action reinforcement learning problems. Typically, one computes search directions using a classic expression for the policy gradient called the Policy Gradient Theorem, which decomposes the gradient of the value function into two factors: the score function and the Q-function. This paper presents four results:(i) an alternative policy gradient theorem using weak (measure-valued) derivatives instead of score-function is established; (ii) the stochastic gradient estimates thus derived are shown to be unbiased and to yield algorithms that converge almost surely to stationary points of the non-convex value function of the reinforcement learning problem; (iii) the sample complexity of the algorithm is derived and is shown to be $O(1/\\sqrt(k))$; (iv) finally, the expected variance of the gradient estimates obtained using weak derivatives is shown to be lower than those obtained using the popular score-function approach. Experiments on OpenAI gym pendulum environment show superior performance of the proposed algorithm.",
        "published": "2020-04-09T23:05:18Z",
        "link": "http://arxiv.org/abs/2004.04843v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "math.OC",
            "stat.ML"
        ]
    },
    {
        "title": "Implicit Multiagent Coordination at Unsignalized Intersections via   Multimodal Inference Enabled by Topological Braids",
        "authors": [
            "Christoforos Mavrogiannis",
            "Jonathan A. DeCastro",
            "Siddhartha S. Srinivasa"
        ],
        "summary": "We focus on navigation among rational, non-communicating agents at unsignalized street intersections. Following collision-free motion under such settings demands nuanced implicit coordination among agents. Often, the structure of these domains constrains multiagent trajectories to belong to a finite set of modes. Our key insight is that empowering agents with a model of these modes can enable effective coordination, realized implicitly via intent signals encoded in agents' actions. In this paper, we represent modes of joint behavior in a compact and interpretable fashion using the formalism of topological braids. We design a decentralized planning algorithm that generates actions aimed at reducing the uncertainty over the mode of the emerging multiagent behavior. This mechanism enables agents that individually run our algorithm to collectively reject unsafe intersection crossings. We validate our approach in a simulated case study featuring challenging multiagent scenarios at a four-way unsignalized intersection. Our model is shown to reduce frequency of collisions by >65% over a set of baselines explicitly reasoning over trajectories, while maintaining comparable time efficiency.",
        "published": "2020-04-10T19:01:29Z",
        "link": "http://arxiv.org/abs/2004.05205v2",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Safe Multi-Agent Interaction through Robust Control Barrier Functions   with Learned Uncertainties",
        "authors": [
            "Richard Cheng",
            "Mohammad Javad Khojasteh",
            "Aaron D. Ames",
            "Joel W. Burdick"
        ],
        "summary": "Robots operating in real world settings must navigate and maintain safety while interacting with many heterogeneous agents and obstacles. Multi-Agent Control Barrier Functions (CBF) have emerged as a computationally efficient tool to guarantee safety in multi-agent environments, but they assume perfect knowledge of both the robot dynamics and other agents' dynamics. While knowledge of the robot's dynamics might be reasonably well known, the heterogeneity of agents in real-world environments means there will always be considerable uncertainty in our prediction of other agents' dynamics. This work aims to learn high-confidence bounds for these dynamic uncertainties using Matrix-Variate Gaussian Process models, and incorporates them into a robust multi-agent CBF framework. We transform the resulting min-max robust CBF into a quadratic program, which can be efficiently solved in real time. We verify via simulation results that the nominal multi-agent CBF is often violated during agent interactions, whereas our robust formulation maintains safety with a much higher probability and adapts to learned uncertainties",
        "published": "2020-04-11T00:56:36Z",
        "link": "http://arxiv.org/abs/2004.05273v2",
        "categories": [
            "cs.RO",
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "math.OC"
        ]
    },
    {
        "title": "Social rules for agent systems",
        "authors": [
            "René Mellema",
            "Maarten Jensen",
            "Frank Dignum"
        ],
        "summary": "When creating (open) agent systems it has become common practice to use social concepts such as social practices, norms and conventions to model the way the interactions between the agents are regulated. However, in the literature most papers concentrate on only one of these aspects at the time. Therefore there is hardly any research on how these social concepts relate and when each of them emerges or evolves from another concept. In this paper we will investigate some of the relations between these concepts and also whether they are fundamentally stemming from a single social object or should be seen as different types of objects altogether.",
        "published": "2020-04-11T17:16:28Z",
        "link": "http://arxiv.org/abs/2004.12797v2",
        "categories": [
            "cs.MA",
            "cs.SI",
            "I.2.m"
        ]
    },
    {
        "title": "DLMP-based Coordination Procedure for Decentralized Demand Response   under Distribution Network Constraints",
        "authors": [
            "Paulin Jacquot"
        ],
        "summary": "Load aggregators are independent private entities whose goal is to optimize energy consumption flexibilities offered by multiple residential consumers.   Although aggregators optimize their decisions in a decentralized way, they are indirectly linked together if their respective consumers belong to the same distribution grid.   This is an important issue for a distribution system operator (DSO), in charge of the reliability of the distribution network, it has to ensure that decentralized decisions taken do not violate the grid constraints and do not increase the global system costs.   From the information point of view,the network state and characteristics are confidential to the DSO, which makes a decentralized solution even more relevant.   To address this issue, we propose a decentralized coordination mechanism between the DSO and multiple aggregators that computes the optimal demand response profiles while solving the optimal power flow problem. The procedure, based on distribution locational marginal prices (DLMP), preserves the decentralized structure of information and decisions, and lead to a feasible and optimal solution for both the aggregators and the DSO.   The procedure is analyzed from a mechanism design perspective, and different decentralized methods that could be used to implement this procedure are presented.",
        "published": "2020-04-13T15:23:53Z",
        "link": "http://arxiv.org/abs/2004.06004v2",
        "categories": [
            "math.OC",
            "cs.MA"
        ]
    },
    {
        "title": "An agent-based negotiation model and its implementation in Repast",
        "authors": [
            "S. Bai"
        ],
        "summary": "We propose an agent-based model, MNegoti, for simulating multilateral negotiation process, which can be naturally employed in group decision support system. This model can also be applied to any use case in which negotiation is involved, in order to simulate the negotiation process. In this report, we discuss the implementation of the MNegoti model on the basis of the agent-based simulation platform, Repast Simphony. It is worth pointing out that this model can be used to create a java module for any use of agent-based negotiation simulation.",
        "published": "2020-04-13T18:07:52Z",
        "link": "http://arxiv.org/abs/2004.06135v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "A Demonstration of Issues with Value-Based Multiobjective Reinforcement   Learning Under Stochastic State Transitions",
        "authors": [
            "Peter Vamplew",
            "Cameron Foale",
            "Richard Dazeley"
        ],
        "summary": "We report a previously unidentified issue with model-free, value-based approaches to multiobjective reinforcement learning in the context of environments with stochastic state transitions. An example multiobjective Markov Decision Process (MOMDP) is used to demonstrate that under such conditions these approaches may be unable to discover the policy which maximises the Scalarised Expected Return, and in fact may converge to a Pareto-dominated solution. We discuss several alternative methods which may be more suitable for maximising SER in MOMDPs with stochastic transitions.",
        "published": "2020-04-14T02:55:12Z",
        "link": "http://arxiv.org/abs/2004.06277v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Fundamental Performance Limitations for Average Consensus in Open   Multi-Agent Systems",
        "authors": [
            "Charles Monnoyer de Galland",
            "Julien M. Hendrickx"
        ],
        "summary": "We derive fundamental performance limitations for intrinsic average consensus problems in open multi-agent systems, which are systems subject to frequent arrivals and departures of agents. Each agent holds a value, and the objective of the agents is to collaboratively estimate the average of the values of the agents presently in the system. Algorithms solving such problems in open systems are poised to never converge because of the permanent variations in the composition, size and objective pursued by the agents of the system. We provide lower bounds on the expected Mean Squared Error achievable by any averaging algorithms in open systems of fixed size. Our derivation is based on the analysis of a conceptual algorithm that would achieve optimal performance for a given model of replacements. We obtain a general bound that depends on the properties of the model defining the interactions between the agents, and instantiate that result for all-to-one and one-to-one interaction models. A comparison between those bounds and algorithms implementable with those models is then provided to highlight their validity.",
        "published": "2020-04-14T14:12:43Z",
        "link": "http://arxiv.org/abs/2004.06533v4",
        "categories": [
            "cs.MA",
            "math.DS"
        ]
    },
    {
        "title": "On the Optimal Interaction Range for Multi-Agent Systems Under   Adversarial Attack",
        "authors": [
            "Saad J Saleh"
        ],
        "summary": "Consider a consensus-driven multi-agent dynamic system. The interaction range, which defines the set of neighbors for each agent, plays a key role in influencing connectivity of the underlying network. In this paper, we assume the system is under attack by a predator and explore the question of finding the optimal interaction range that facilitates the most-efficient escape trajectories for the group of agents. We find that for many cases of interest the optimal interaction range is one that forces the network to break up into a handful of disconnected graphs, each containing a subset of agents, thus outperforming the two extreme cases corresponding to fully-connected and fully-disconnected networks. In other words, the results indicate that some connectivity among the agents is helpful because information is effectively transmitted from the agents closest to the predator to others slightly farther away, but also that too much connectivity can be detrimental to the agility of the group, thus hampering efficient and rapid escape.",
        "published": "2020-04-14T14:45:56Z",
        "link": "http://arxiv.org/abs/2004.06562v2",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Composite Travel Generative Adversarial Networks for Tabular and   Sequential Population Synthesis",
        "authors": [
            "Godwin Badu-Marfo",
            "Bilal Farooq",
            "Zachary Paterson"
        ],
        "summary": "Agent-based transportation modelling has become the standard to simulate travel behaviour, mobility choices and activity preferences using disaggregate travel demand data for entire populations, data that are not typically readily available. Various methods have been proposed to synthesize population data for this purpose. We present a Composite Travel Generative Adversarial Network (CTGAN), a novel deep generative model to estimate the underlying joint distribution of a population, that is capable of reconstructing composite synthetic agents having tabular (e.g. age and sex) as well as sequential mobility data (e.g. trip trajectory and sequence). The CTGAN model is compared with other recently proposed methods such as the Variational Autoencoders (VAE) method, which has shown success in high dimensional tabular population synthesis. We evaluate the performance of the synthesized outputs based on distribution similarity, multi-variate correlations and spatio-temporal metrics. The results show the consistent and accurate generation of synthetic populations and their tabular and spatially sequential attributes, generated over varying spatial scales and dimensions.",
        "published": "2020-04-15T00:06:52Z",
        "link": "http://arxiv.org/abs/2004.06838v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Resilience in multi-robot multi-target tracking with unknown number of   targets through reconfiguration",
        "authors": [
            "Ragesh K. Ramachandran",
            "Nicole Fronda",
            "Gaurav S. Sukhatme"
        ],
        "summary": "We address the problem of maintaining resource availability in a networked multi-robot team performing distributed tracking of unknown number of targets in an environment of interest. Based on our model, robots are equipped with sensing and computational resources enabling them to cooperatively track a set of targets in an environment using a distributed Probability Hypothesis Density (PHD) filter. We use the trace of a robot's sensor measurement noise covariance matrix to quantify its sensing quality. While executing the tracking task, if a robot experiences sensor quality degradation, then robot team's communication network is reconfigured such that the robot with the faulty sensor may share information with other robots to improve the team's target tracking ability without enforcing a large change in the number of active communication links. A central system which monitors the team executes all the network reconfiguration computations. We consider two different PHD fusion methods in this paper and propose four different Mixed Integer Semi-Definite Programming (MISDP) formulations (two formulations for each PHD fusion method) to accomplish our objective. All four MISDP formulations are validated in simulation.",
        "published": "2020-04-15T16:54:24Z",
        "link": "http://arxiv.org/abs/2004.07197v1",
        "categories": [
            "cs.RO",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Should I tear down this wall? Optimizing social metrics by evaluating   novel actions",
        "authors": [
            "János Kramár",
            "Neil Rabinowitz",
            "Tom Eccles",
            "Andrea Tacchetti"
        ],
        "summary": "One of the fundamental challenges of governance is deciding when and how to intervene in multi-agent systems in order to impact group-wide metrics of success. This is particularly challenging when proposed interventions are novel and expensive. For example, one may wish to modify a building's layout to improve the efficiency of its escape route. Evaluating such interventions would generally require access to an elaborate simulator, which must be constructed ad-hoc for each environment, and can be prohibitively costly or inaccurate. Here we examine a simple alternative: Optimize By Observational Extrapolation (OBOE). The idea is to use observed behavioural trajectories, without any interventions, to learn predictive models mapping environment states to individual agent outcomes, and then use these to evaluate and select changes. We evaluate OBOE in socially complex gridworld environments and consider novel physical interventions that our models were not trained on. We show that neural network models trained to predict agent returns on baseline environments are effective at selecting among the interventions. Thus, OBOE can provide guidance for challenging questions like: \"which wall should I tear down in order to minimize the Gini index of this group?\"",
        "published": "2020-04-16T12:24:40Z",
        "link": "http://arxiv.org/abs/2004.07625v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Analyzing Reinforcement Learning Benchmarks with Random Weight Guessing",
        "authors": [
            "Declan Oller",
            "Tobias Glasmachers",
            "Giuseppe Cuccu"
        ],
        "summary": "We propose a novel method for analyzing and visualizing the complexity of standard reinforcement learning (RL) benchmarks based on score distributions. A large number of policy networks are generated by randomly guessing their parameters, and then evaluated on the benchmark task; the study of their aggregated results provide insights into the benchmark complexity. Our method guarantees objectivity of evaluation by sidestepping learning altogether: the policy network parameters are generated using Random Weight Guessing (RWG), making our method agnostic to (i) the classic RL setup, (ii) any learning algorithm, and (iii) hyperparameter tuning. We show that this approach isolates the environment complexity, highlights specific types of challenges, and provides a proper foundation for the statistical analysis of the task's difficulty. We test our approach on a variety of classic control benchmarks from the OpenAI Gym, where we show that small untrained networks can provide a robust baseline for a variety of tasks. The networks generated often show good performance even without gradual learning, incidentally highlighting the triviality of a few popular benchmarks.",
        "published": "2020-04-16T15:32:52Z",
        "link": "http://arxiv.org/abs/2004.07707v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "cs.NE",
            "stat.ML"
        ]
    },
    {
        "title": "STT-CBS: A Conflict-Based Search Algorithm for Multi-Agent Path Finding   with Stochastic Travel Times",
        "authors": [
            "Oriana Peltzer",
            "Kyle Brown",
            "Mac Schwager",
            "Mykel J. Kochenderfer",
            "Martin Sehr"
        ],
        "summary": "We present an algorithm for finding optimal paths for multiple stochastic agents in a graph to reach their destinations with a user-specified maximum pairwise collision probability. Our algorithm, called STT-CBS, uses Conflict-Based Search (CBS) with a stochastic travel time (STT) model for the agents. We model robot travel time along each edge of the graph by independent gamma-distributed random variables, and propose probabilistic collision identification and constraint creation methods to robustly handle travel time uncertainty. We show that under reasonable assumptions our algorithm is optimal in terms of expected sum of travel times, while ensuring an upper bound on each pairwise conflict probability. Simulations and hardware experiments show that STT-CBS is able to significantly decrease conflict probability over CBS, while remaining within the same complexity class.",
        "published": "2020-04-17T01:50:18Z",
        "link": "http://arxiv.org/abs/2004.08025v2",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "\"Perchance to dream?\": Assessing effect of dispersal strategies on the   fitness of expanding populations",
        "authors": [
            "Nikolay Markov",
            "Evgeny Ivanko"
        ],
        "summary": "Unraveling patterns of animals' movements is important for understanding the fundamental basics of biogeography, tracking range shifts resulting from climate change, predicting and preventing biological invansions. Many researchers have modeled animals' dispersal studying their behavior under the assumptions of some movement strategies pre-determined or affected by some external factor(s) but none of them have compared the efficiency of different dispersal strategies in providing population survival and fitness. We hypothesize that 1) successful expansion could result from some evolutionary stable strategy (ESS) and 2) such strategy could be based particularly on deferred gain, when animals invest in travel to reach some high-quality habitat (\"habitat of dream\"). Using simulation model we compare the ecological success of three strategies: i) \"Smart\" - choosing the locally optimal cell; ii) \"Random\" - random movement between cells without taking into account the quality of the environment; iii) \"Dreamer\" - movements that aims to find \"a habitat of dream\" with quality much higher than that of the initial and neighboring cells. The population fitness was measured as survival rate, dispersal distance, accumulated energy and quality of settled habitat. The most general conclusion is that while survival and wealth of the population is affected presumably by overall habitat quality, the dispersal depends mainly on the behavioral strategy. The \"Dreamer\" strategy or the strategy of deferred gain belongs to the Pareto frontier in the Fitness$\\times$Dispersal space but only in optimal and suboptimal habitat and in the relatively mild climate.",
        "published": "2020-04-17T12:40:58Z",
        "link": "http://arxiv.org/abs/2004.08216v1",
        "categories": [
            "q-bio.PE",
            "cs.MA"
        ]
    },
    {
        "title": "F2A2: Flexible Fully-decentralized Approximate Actor-critic for   Cooperative Multi-agent Reinforcement Learning",
        "authors": [
            "Wenhao Li",
            "Bo Jin",
            "Xiangfeng Wang",
            "Junchi Yan",
            "Hongyuan Zha"
        ],
        "summary": "Traditional centralized multi-agent reinforcement learning (MARL) algorithms are sometimes unpractical in complicated applications, due to non-interactivity between agents, curse of dimensionality and computation complexity. Hence, several decentralized MARL algorithms are motivated. However, existing decentralized methods only handle the fully cooperative setting where massive information needs to be transmitted in training. The block coordinate gradient descent scheme they used for successive independent actor and critic steps can simplify the calculation, but it causes serious bias. In this paper, we propose a flexible fully decentralized actor-critic MARL framework, which can combine most of actor-critic methods, and handle large-scale general cooperative multi-agent setting. A primal-dual hybrid gradient descent type algorithm framework is designed to learn individual agents separately for decentralization. From the perspective of each agent, policy improvement and value evaluation are jointly optimized, which can stabilize multi-agent policy learning. Furthermore, our framework can achieve scalability and stability for large-scale environment and reduce information transmission, by the parameter sharing mechanism and a novel modeling-other-agents methods based on theory-of-mind and online supervised learning. Sufficient experiments in cooperative Multi-agent Particle Environment and StarCraft II show that our decentralized MARL instantiation algorithms perform competitively against conventional centralized and decentralized methods.",
        "published": "2020-04-17T14:56:29Z",
        "link": "http://arxiv.org/abs/2004.11145v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Networked and Autonomous Model-scale Vehicles for Experiments in   Research and Education",
        "authors": [
            "Patrick Scheffe",
            "Janis Maczijewski",
            "Maximilian Kloock",
            "Alexandru Kampmann",
            "Andreas Derks",
            "Stefan Kowalewski",
            "Bassam Alrifaee"
        ],
        "summary": "This paper presents the $\\mathrm{\\mu}$Car, a 1:18 model-scale vehicle with Ackermann steering geometry developed for experiments in networked and autonomous driving in research and education. The vehicle is open source, moderately costed and highly flexible, which allows for many applications. It is equipped with an inertial measurement unit and an odometer and obtains its pose via WLAN from an indoor positioning system. The two supported operating modes for controlling the vehicle are (1) computing control inputs on external hardware, transmitting them via WLAN and applying received inputs to the actuators and (2) transmitting a reference trajectory via WLAN, which is then followed by a controller running on the onboard Raspberry Pi Zero W. The design allows identical vehicles to be used at the same time in order to conduct experiments with a large amount of networked agents.",
        "published": "2020-04-17T17:39:57Z",
        "link": "http://arxiv.org/abs/2004.08364v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Towards Non-I.I.D. and Invisible Data with FedNAS: Federated Deep   Learning via Neural Architecture Search",
        "authors": [
            "Chaoyang He",
            "Murali Annavaram",
            "Salman Avestimehr"
        ],
        "summary": "Federated Learning (FL) has been proved to be an effective learning framework when data cannot be centralized due to privacy, communication costs, and regulatory restrictions. When training deep learning models under an FL setting, people employ the predefined model architecture discovered in the centralized environment. However, this predefined architecture may not be the optimal choice because it may not fit data with non-identical and independent distribution (non-IID). Thus, we advocate automating federated learning (AutoFL) to improve model accuracy and reduce the manual design effort. We specifically study AutoFL via Neural Architecture Search (NAS), which can automate the design process. We propose a Federated NAS (FedNAS) algorithm to help scattered workers collaboratively searching for a better architecture with higher accuracy. We also build a system based on FedNAS. Our experiments on non-IID dataset show that the architecture searched by FedNAS can outperform the manually predefined architecture.",
        "published": "2020-04-18T08:04:44Z",
        "link": "http://arxiv.org/abs/2004.08546v4",
        "categories": [
            "cs.LG",
            "cs.CV",
            "cs.DC",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Variational Policy Propagation for Multi-agent Reinforcement Learning",
        "authors": [
            "Chao Qu",
            "Hui Li",
            "Chang Liu",
            "Junwu Xiong",
            "James Zhang",
            "Wei Chu",
            "Weiqiang Wang",
            "Yuan Qi",
            "Le Song"
        ],
        "summary": "We propose a \\emph{collaborative} multi-agent reinforcement learning algorithm named variational policy propagation (VPP) to learn a \\emph{joint} policy through the interactions over agents. We prove that the joint policy is a Markov Random Field under some mild conditions, which in turn reduces the policy space effectively. We integrate the variational inference as special differentiable layers in policy such that the actions can be efficiently sampled from the Markov Random Field and the overall policy is differentiable. We evaluate our algorithm on several large scale challenging tasks and demonstrate that it outperforms previous state-of-the-arts.",
        "published": "2020-04-19T15:42:55Z",
        "link": "http://arxiv.org/abs/2004.08883v4",
        "categories": [
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "A Practical Guide to Studying Emergent Communication through Grounded   Language Games",
        "authors": [
            "Jens Nevens",
            "Paul Van Eecke",
            "Katrien Beuls"
        ],
        "summary": "The question of how an effective and efficient communication system can emerge in a population of agents that need to solve a particular task attracts more and more attention from researchers in many fields, including artificial intelligence, linguistics and statistical physics. A common methodology for studying this question consists of carrying out multi-agent experiments in which a population of agents takes part in a series of scripted and task-oriented communicative interactions, called 'language games'. While each individual language game is typically played by two agents in the population, a large series of games allows the population to converge on a shared communication system. Setting up an experiment in which a rich system for communicating about the real world emerges is a major enterprise, as it requires a variety of software components for running multi-agent experiments, for interacting with sensors and actuators, for conceptualising and interpreting semantic structures, and for mapping between these semantic structures and linguistic utterances. The aim of this paper is twofold. On the one hand, it introduces a high-level robot interface that extends the Babel software system, presenting for the first time a toolkit that provides flexible modules for dealing with each subtask involved in running advanced grounded language game experiments. On the other hand, it provides a practical guide to using the toolkit for implementing such experiments, taking a grounded colour naming game experiment as a didactic example.",
        "published": "2020-04-20T11:48:24Z",
        "link": "http://arxiv.org/abs/2004.09218v1",
        "categories": [
            "cs.AI",
            "cs.CL",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "A Novel Multi-Agent System for Complex Scheduling Problems",
        "authors": [
            "Peter Hillmann",
            "Tobias Uhlig",
            "Gabi Dreo Rodosek",
            "Oliver Rose"
        ],
        "summary": "Complex scheduling problems require a large amount computation power and innovative solution methods. The objective of this paper is the conception and implementation of a multi-agent system that is applicable in various problem domains. Independent specialized agents handle small tasks, to reach a superordinate target. Effective coordination is therefore required to achieve productive cooperation. Role models and distributed artificial intelligence are employed to tackle the resulting challenges. We simulate a NP-hard scheduling problem to demonstrate the validity of our approach. In addition to the general agent based framework we propose new simulation-based optimization heuristics to given scheduling problems. Two of the described optimization algorithms are implemented using agents. This paper highlights the advantages of the agent-based approach, like the reduction in layout complexity, improved control of complicated systems, and extendability.",
        "published": "2020-04-20T14:04:58Z",
        "link": "http://arxiv.org/abs/2004.09312v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.CC",
            "cs.DC"
        ]
    },
    {
        "title": "On the Evaluation of Military Simulations: Towards A Taxonomy of   Assessment Criteria",
        "authors": [
            "Mario Golling",
            "Robert Koch",
            "Peter Hillmann",
            "Volker Eiseler",
            "Lars Stiemert",
            "Andres Rekker"
        ],
        "summary": "In the area of military simulations, a multitude of different approaches is available. Close Combat Tactical Trainer, Joint Tactical Combat Training System, Battle Force Tactical Training or Warfighter's Simulation 2000 are just some examples within the history of the large DoD Development Program in Modelling and Simulation, representing just a small piece of the variety of diverse solutions. Very often, individual simulators are very unique and so it is often difficult to classify military simulations even for experienced users. This circumstance is further boosted due to the fact that in the field of military simulations - unlike in other areas - no general classification for military simulations exists. To address this shortcoming, this publication is dedicated to the idea of providing a first contribution to the development of a commonly accepted taxonomy in the area of military simulations. To this end, the problem field is structured into three main categories (general functional requirements for simulators, special military requirements for simulators and non-functional requirements for simulators). Based upon that, individual categories are provided with appropriate classes. For a better understanding, the taxonomy is also applied to a concrete example (NetLogo Rebellion).",
        "published": "2020-04-20T14:39:59Z",
        "link": "http://arxiv.org/abs/2004.09340v1",
        "categories": [
            "cs.CY",
            "cs.MA"
        ]
    },
    {
        "title": "Human-Collective Collaborative Site Selection",
        "authors": [
            "Jason R. Cody",
            "Karina A. Roundtree",
            "Julie A. Adams"
        ],
        "summary": "Robotic collectives are large groups (at least 50) of locally sensing and communicating robots that encompass characteristics of swarms and colonies, whose emergent behaviors accomplish complex tasks. Future human-collective teams will extend the ability of operators to monitor, respond, and make decisions in disaster response, search and rescue, and environmental monitoring problems. This manuscript evaluates two collective best-of-n decision models for enabling collectives to identify and choose the highest valued target from a finite set of n targets. Two challenges impede the future use of human-collective shared decisions: 1) environmental bias reduces collective decision accuracy when poorer targets are easier to evaluate than higher quality targets, and 2) little is understood about shared human-collective decision making interaction strategies. The two evaluated collective best-of-n models include an existing insect colony decision model and an extended bias-reducing model that attempts to reduce environmental bias in order to improve accuracy. Collectives using these two strategies are compared independently and as members of human-collective teams. Independently, the extended model is slower than the original model, but the extended algorithm is 57% more accurate in decisions where the optimal option is more difficult to evaluate. Human-collective teams using the bias-reducing model require less operator influence and achieve 25% higher accuracy with difficult decisions, than the human-collective teams using the original model. Further, a novel human-collective interaction strategy enables operators to adjust collective autonomy while making multiple simultaneous decisions.",
        "published": "2020-04-20T19:16:30Z",
        "link": "http://arxiv.org/abs/2004.09581v1",
        "categories": [
            "cs.HC",
            "cs.MA"
        ]
    },
    {
        "title": "Inferring Degrees from Incomplete Networks and Nonlinear Dynamics",
        "authors": [
            "Chunheng Jiang",
            "Jianxi Gao",
            "Malik Magdon-Ismail"
        ],
        "summary": "Inferring topological characteristics of complex networks from observed data is critical to understand the dynamical behavior of networked systems, ranging from the Internet and the World Wide Web to biological networks and social networks. Prior studies usually focus on the structure-based estimation to infer network sizes, degree distributions, average degrees, and more. Little effort attempted to estimate the specific degree of each vertex from a sampled induced graph, which prevents us from measuring the lethality of nodes in protein networks and influencers in social networks. The current approaches dramatically fail for a tiny sampled induced graph and require a specific sampling method and a large sample size. These approaches neglect information of the vertex state, representing the dynamical behavior of the networked system, such as the biomass of species or expression of a gene, which is useful for degree estimation. We fill this gap by developing a framework to infer individual vertex degrees using both information of the sampled topology and vertex state. We combine the mean-field theory with combinatorial optimization to learn vertex degrees. Experimental results on real networks with a variety of dynamics demonstrate that our framework can produce reliable degree estimates and dramatically improve existing link prediction methods by replacing the sampled degrees with our estimated degrees.",
        "published": "2020-04-21T07:39:31Z",
        "link": "http://arxiv.org/abs/2004.10546v2",
        "categories": [
            "cs.MA",
            "physics.soc-ph"
        ]
    },
    {
        "title": "Cyber-Physical Mobility Lab: An Open-Source Platform for Networked and   Autonomous Vehicles",
        "authors": [
            "Maximilian Kloock",
            "Patrick Scheffe",
            "Janis Maczijewski",
            "Alexandru Kampmann",
            "Armin Mokhtarian",
            "Stefan Kowalewski",
            "Bassam Alrifaee"
        ],
        "summary": "This paper introduces our Cyber-Physical Mobility Lab (CPM Lab). It is an open-source development environment for networked and autonomous vehicles with focus on networked decision-making, trajectory planning, and control. The CPM Lab hosts 20 physical model-scale vehicles ({\\mu}Cars) which we can seamlessly extend by unlimited simulated vehicles. The code and construction plans are publicly available to enable rebuilding the CPM Lab.   Our four-layered architecture enables the seamless use of the same software in simulations and in experiments without any further adaptions. A Data Distribution Service (DDS) based middleware allows adapting the number of vehicles during experiments in a seamless manner. The middleware is also responsible for synchronizing all entities following a logical execution time approach to achieve determinism and reproducibility of experiments. This approach makes the CPM Lab a unique platform for rapid functional prototyping of networked decision-making algorithms.   The CPM Lab allows researchers as well as students from different disciplines to see their ideas developing into reality. We demonstrate its capabilities using two example experiments. We are working on a remote access to the CPM Lab via a webinterface.",
        "published": "2020-04-21T14:54:30Z",
        "link": "http://arxiv.org/abs/2004.10063v4",
        "categories": [
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Evolving Dyadic Strategies for a Cooperative Physical Task",
        "authors": [
            "Saber Sheybani",
            "Eduardo J. Izquierdo",
            "Eatai Roth"
        ],
        "summary": "Many cooperative physical tasks require that individuals play specialized roles (e.g., leader-follower). Humans are adept cooperators, negotiating these roles and transitions between roles innately. Yet how roles are delegated and reassigned is not well understood. Using a genetic algorithm, we evolve simulated agents to explore a space of feasible role-switching policies. Applying these switching policies in a cooperative manual task, agents process visual and haptic cues to decide when to switch roles. We then analyze the evolved virtual population for attributes typically associated with cooperation: load sharing and temporal coordination. We find that the best performing dyads exhibit high temporal coordination (anti-synchrony). And in turn, anti-synchrony is correlated to symmetry between the parameters of the cooperative agents. These simulations furnish hypotheses as to how human cooperators might mediate roles in dyadic tasks.",
        "published": "2020-04-22T13:23:12Z",
        "link": "http://arxiv.org/abs/2004.10558v1",
        "categories": [
            "cs.NE",
            "cs.MA"
        ]
    },
    {
        "title": "Agent-based modelling of pedestrian responses during flood emergency:   mobility behavioural rules and implications for flood risk analysis",
        "authors": [
            "Mohammad Shirvani",
            "Georges Kesserwani",
            "Paul Richmond"
        ],
        "summary": "An agent-based model (ABM) for simulating flood-pedestrian interaction is augmented to particularly explore more realistic responses of evacuating pedestrians during flooding. Pedestrian agents within the ABM follow navigation rules of governing their movement in dry areas. When in floodwater, pedestrian agents are assigned extra behavioural rules to factor in their states of stability and walking speed, and their different body height and weight. The ABM is applied to replicate a synthetic test case of a flooded shopping centre, considering increasingly sophisticated configuration modes for the behavioural rules of the evacuating pedestrians. Simulation results are analysed based on spatial and temporal indicators informing on the dynamic variations of flood risk states of flooded pedestrians in terms of a commonly used flood Hazard Rating (HR) metric, variable walking speed, and instability due to toppling and/or sliding. Our analysis reveal significantly prolonged evacuation times and risk exposure levels as stability and walking speed behavioural rules become more sophisticated. It also allows to identify more conservative HR thresholds due to unstable pedestrians, and a new formula to directly estimate walking speed states as function of HR for stable pedestrian in floodwater. Accompanying details for software accessibility are provided.",
        "published": "2020-04-22T14:19:27Z",
        "link": "http://arxiv.org/abs/2004.10589v2",
        "categories": [
            "physics.soc-ph",
            "cs.MA"
        ]
    },
    {
        "title": "Tension Space Analysis for Emergent Narrative",
        "authors": [
            "Ben Kybartas",
            "Clark Verbrugge",
            "Jonathan Lessard"
        ],
        "summary": "Emergent narratives provide a unique and compelling approach to interactive storytelling through simulation, and have applications in games, narrative generation, and virtual agents. However the inherent complexity of simulation makes understanding the expressive potential of emergent narratives difficult, particularly at the design phase of development. In this paper, we present a novel approach to emergent narrative using the narratological theory of possible worlds and demonstrate how the design of works in such a system can be understood through a formal means of analysis inspired by expressive range analysis. Lastly, we propose a novel way through which content may be authored for the emergent narrative system using a sketch-based interface.",
        "published": "2020-04-22T19:26:09Z",
        "link": "http://arxiv.org/abs/2004.10808v1",
        "categories": [
            "cs.AI",
            "cs.MA",
            "cs.MM"
        ]
    },
    {
        "title": "A Game-Theoretic Utility Network for Cooperative Multi-Agent Decisions   in Adversarial Environments",
        "authors": [
            "Qin Yang",
            "Ramviyas Parasuraman"
        ],
        "summary": "Underlying relationships among multi-agent systems (MAS) in hazardous scenarios can be represented as Game-theoretic models. We measure the performance of MAS achieving tasks from the perspective of balancing success probability and system costs. This paper proposes a new network-based model called Game-theoretic Utility Tree (GUT), which decomposes high-level strategies into executable low-level actions for cooperative MAS decisions. This is combined with a new payoff measure based on agent needs for real-time strategy games. We present an Explore game domain to evaluate GUT against the state-of-the-art QMIX decision-making method. Conclusive results on extensive numerical simulations indicate that GUT can organize more complex relationships among MAS cooperation, helping the group achieve challenging tasks with lower costs and a higher winning rate.",
        "published": "2020-04-23T03:02:28Z",
        "link": "http://arxiv.org/abs/2004.10950v3",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Analysing the combined health, social and economic impacts of the   corovanvirus pandemic using agent-based social simulation",
        "authors": [
            "Frank Dignum",
            "Virginia Dignum",
            "Paul Davidsson",
            "Amineh Ghorbani",
            "Mijke van der Hurk",
            "Maarten Jensen",
            "Christian Kammler",
            "Fabian Lorig",
            "Luis Gustavo Ludescher",
            "Alexander Melchior",
            "René Mellema",
            "Cezara Pastrav",
            "Loïs Vanhee",
            "Harko Verhagen"
        ],
        "summary": "During the COVID-19 crisis there have been many difficult decisions governments and other decision makers had to make. E.g. do we go for a total lock down or keep schools open? How many people and which people should be tested? Although there are many good models from e.g. epidemiologists on the spread of the virus under certain conditions, these models do not directly translate into the interventions that can be taken by government. Neither can these models contribute to understand the economic and/or social consequences of the interventions. However, effective and sustainable solutions need to take into account this combination of factors. In this paper, we propose an agent-based social simulation tool, ASSOCC, that supports decision makers understand possible consequences of policy interventions, bu exploring the combined social, health and economic consequences of these interventions.",
        "published": "2020-04-23T14:46:01Z",
        "link": "http://arxiv.org/abs/2004.12809v1",
        "categories": [
            "cs.MA",
            "cs.SI",
            "physics.soc-ph"
        ]
    },
    {
        "title": "Cloud Deployment Tradeoffs for the Analysis of Spatially-Distributed   Systems of Internet-of-Things",
        "authors": [
            "Christos Tsigkanos",
            "Martin Garriga",
            "Luciano Baresi",
            "Carlo Ghezzi"
        ],
        "summary": "Internet-enabled things and devices operating in the physical world are increasingly integrated in modern distributed systems, supporting functionalities that require assurances that certain critical requirements are satisfied by the overall system. We focus here on spatially-distributed Internet-of-Things systems such as smart environments, where the dynamics of spatial distribution of entities in the system is crucial to requirements satisfaction. Analysis techniques need to be in place while systems operate to ensure that requirements are fulfilled. This may be achieved by keeping a model of the system at runtime, monitoring events that lead to changes in the spatial environment, and performing analysis. This computationally-intensive runtime assurance method cannot be supported by resource-constrained devices that populate the space and must be offloaded to the cloud. However, challenges arise regarding resource allocation and cost, especially when the workload is unknown at the system's design time. As such, it may be difficult or even impossible to guarantee application service level agreements, e.g., on response times. To this end, we instantiate spatial verification processes, integrating them to the service layer of an IoT-cloud architecture based on microservices. We propose several cloud deployments for such an architecture for assurance of spatial requirements -- based on virtual machines, containers, and the recent Functions-as-a-Service paradigm. Then, we assess deployments' tradeoffs in terms of elasticity, performance and cost by using a workload scenario from a known dataset of taxis roaming in Beijing. We argue that the approach can be replicated in the design process of similar kinds of spatially distributed Internet-of-Things systems.",
        "published": "2020-04-23T19:05:45Z",
        "link": "http://arxiv.org/abs/2004.11428v1",
        "categories": [
            "cs.DC",
            "cs.MA",
            "cs.NI"
        ]
    },
    {
        "title": "Continuous Deep Hierarchical Reinforcement Learning for Ground-Air Swarm   Shepherding",
        "authors": [
            "Hung The Nguyen",
            "Tung Duy Nguyen",
            "Vu Phi Tran",
            "Matthew Garratt",
            "Kathryn Kasmarik",
            "Sreenatha Anavatti",
            "Michael Barlow",
            "Hussein A. Abbass"
        ],
        "summary": "The control and guidance of multi-robots (swarm) is a non-trivial problem due to the complexity inherent in the coupled interaction among the group. Whether the swarm is cooperative or non-cooperative, lessons can be learnt from sheepdogs herding sheep. Biomimicry of shepherding offers computational methods for swarm control with the potential to generalize and scale in different environments. However, learning to shepherd is complex due to the large search space that a machine learner is faced with. We present a deep hierarchical reinforcement learning approach for shepherding, whereby an unmanned aerial vehicle (UAV) learns to act as an aerial sheepdog to control and guide a swarm of unmanned ground vehicles (UGVs). The approach extends our previous work on machine education to decompose the search space into a hierarchically organized curriculum. Each lesson in the curriculum is learnt by a deep reinforcement learning model. The hierarchy is formed by fusing the outputs of the model. The approach is demonstrated first in a high-fidelity robotic-operating-system (ROS)-based simulation environment, then with physical UGVs and a UAV in an in-door testing facility. We investigate the ability of the method to generalize as the models move from simulation to the real-world and as the models move from one scale to another.",
        "published": "2020-04-24T05:56:19Z",
        "link": "http://arxiv.org/abs/2004.11543v4",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Decentralized linear quadratic systems with major and minor agents and   non-Gaussian noise",
        "authors": [
            "Mohammad Afshari",
            "Aditya Mahajan"
        ],
        "summary": "A decentralized linear quadratic system with a major agent and a collection of minor agents is considered. The major agent affects the minor agents, but not vice versa. The state of the major agent is observed by all agents. In addition, the minor agents have a noisy observation of their local state. The noise processes is \\emph{not} assumed to be Gaussian. The structures of the optimal strategy and the best linear strategy are characterized. It is shown that major agent's optimal control action is a linear function of the major agent's MMSE (minimum mean squared error) estimate of the system state while the minor agent's optimal control action is a linear function of the major agent's MMSE estimate of the system state and a \"correction term\" which depends on the difference of the minor agent's MMSE estimate of its local state and the major agent's MMSE estimate of the minor agent's local state. Since the noise is non-Gaussian, the minor agent's MMSE estimate is a non-linear function of its observation. It is shown that replacing the minor agent's MMSE estimate by its LLMS (linear least mean square) estimate gives the best linear control strategy. The results are proved using a direct method based on conditional independence, common-information-based splitting of state and control actions, and simplifying the per-step cost based on conditional independence, orthogonality principle, and completion of squares.",
        "published": "2020-04-24T17:02:23Z",
        "link": "http://arxiv.org/abs/2004.11856v2",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.RO",
            "cs.SY"
        ]
    },
    {
        "title": "Predicting Plans and Actions in Two-Player Repeated Games",
        "authors": [
            "Najma Mathema",
            "Michael A. Goodrich",
            "Jacob W. Crandall"
        ],
        "summary": "Artificial intelligence (AI) agents will need to interact with both other AI agents and humans. Creating models of associates help to predict the modeled agents' actions, plans, and intentions. This work introduces algorithms that predict actions, plans and intentions in repeated play games, with providing an exploration of algorithms. We form a generative Bayesian approach to model S#. S# is designed as a robust algorithm that learns to cooperate with its associate in 2 by 2 matrix games. The actions, plans and intentions associated with each S# expert are identified from the literature, grouping the S# experts accordingly, and thus predicting actions, plans, and intentions based on their state probabilities. Two prediction methods are explored for Prisoners Dilemma: the Maximum A Posteriori (MAP) and an Aggregation approach. MAP (~89% accuracy) performed the best for action prediction. Both methods predicted plans of S# with ~88% accuracy. Paired T-test shows that MAP performs significantly better than Aggregation for predicting S#'s actions without cheap talk. Intention is explored based on the goals of the S# experts; results show that goals are predicted precisely when modeling S#. The obtained results show that the proposed Bayesian approach is well suited for modeling agents in two-player repeated games.",
        "published": "2020-04-26T21:03:28Z",
        "link": "http://arxiv.org/abs/2004.12480v1",
        "categories": [
            "cs.AI",
            "cs.GT",
            "cs.HC",
            "cs.MA"
        ]
    },
    {
        "title": "GymFG: A Framework with a Gym Interface for FlightGear",
        "authors": [
            "Andrew Wood",
            "Ali Sydney",
            "Peter Chin",
            "Bishal Thapa",
            "Ryan Ross"
        ],
        "summary": "Over the past decades, progress in deployable autonomous flight systems has slowly stagnated. This is reflected in today's production air-crafts, where pilots only enable simple physics-based systems such as autopilot for takeoff, landing, navigation, and terrain/traffic avoidance. Evidently, autonomy has not gained the trust of the community where higher problem complexity and cognitive workload are required. To address trust, we must revisit the process for developing autonomous capabilities: modeling and simulation. Given the prohibitive costs for live tests, we need to prototype and evaluate autonomous aerial agents in a high fidelity flight simulator with autonomous learning capabilities applicable to flight systems: such a open-source development platform is not available. As a result, we have developed GymFG: GymFG couples and extends a high fidelity, open-source flight simulator and a robust agent learning framework to facilitate learning of more complex tasks. Furthermore, we have demonstrated the use of GymFG to train an autonomous aerial agent using Imitation Learning. With GymFG, we can now deploy innovative ideas to address complex problems and build the trust necessary to move prototypes to the real-world.",
        "published": "2020-04-26T21:06:20Z",
        "link": "http://arxiv.org/abs/2004.12481v1",
        "categories": [
            "cs.AI",
            "cs.MA",
            "cs.RO",
            "I.2.1; I.6.5"
        ]
    },
    {
        "title": "Information and Causality in Promise Theory",
        "authors": [
            "Mark Burgess"
        ],
        "summary": "The explicit link between Promise Theory and Information Theory, while perhaps obvious, is laid out explicitly here. It's shown how causally related observations of promised behaviours relate to the probabilistic formulation of causal information in Shannon's theory, and thus clarify the meaning of autonomy or causal independence, and further the connection between information and causal sets. Promise Theory helps to make clear a number of assumptions which are commonly taken for granted in causal descriptions. The concept of a promise is hard to escape. It serves as proxy for intent, whether a priori or by inference, and it is intrinsic to the interpretations of observations in the latter.",
        "published": "2020-04-27T09:18:42Z",
        "link": "http://arxiv.org/abs/2004.12661v1",
        "categories": [
            "cs.MA",
            "cs.DC",
            "C.2.1; F.1; H.1; K.6.1; I.6; I.2.2"
        ]
    },
    {
        "title": "Robustness of Nash Equilibria in Network Games",
        "authors": [
            "Laura Arditti",
            "Giacomo Como",
            "Fabio Fagnani",
            "Martina Vanelli"
        ],
        "summary": "We analyze the robustness of (pure strategy) Nash equilibria for network games against perturbations of the players' utility functions. We first derive a simple characterization of the margin of robustness, defined as the minimum magnitude of a perturbation that makes a Nash equilibrium of the original game stop being so in the perturbed game. Then, we investigate what the maximally robust equilibria are in some standard network games such as the coordination and the anti-coordination game. Finally, as an application, we provide some sufficient conditions for the existence of Nash equilibria in network games with a mixture of coordinating and anticoordinating games.",
        "published": "2020-04-27T15:26:11Z",
        "link": "http://arxiv.org/abs/2004.12869v1",
        "categories": [
            "cs.GT",
            "cs.DM",
            "cs.MA",
            "cs.SI",
            "91A43, 91A06, 91A10, 91A40, 05C57",
            "G.2"
        ]
    },
    {
        "title": "How to restart? An agent-based simulation model towards the definition   of strategies for COVID-19 \"second phase\" in public buildings",
        "authors": [
            "Marco D'Orazio",
            "Gabriele Bernardini",
            "Enrico Quagliarini"
        ],
        "summary": "Restarting public buildings activities in the \"second phase\" of COVID-19 emergency should be supported by operational measures to avoid a second virus spreading. Buildings hosting the continuous presence of the same users and significant overcrowd conditions over space/time (e.g. large offices, universities) are critical scenarios due to the prolonged contact with infectors. Beside individual's risk-mitigation strategies performed (facial masks), stakeholders should promote additional strategies, i.e. occupants' load limitation (towards \"social distancing\") and access control. Simulators could support the measures effectiveness evaluation. This work provides an Agent-Based Model to estimate the virus spreading in the closed built environment. The model adopts a probabilistic approach to jointly simulate occupants' movement and virus transmission according to proximity-based and exposure-time-based rules proposed by international health organizations. Scenarios can be defined in terms of building occupancy, mitigation strategies and virus-related aspects. The model is calibrated on experimental data (\"Diamond Princess\" cruise) and then applied to a relevant case-study (a part of a university campus). Results demonstrate the model capabilities. Concerning the case-study, adopting facial masks seems to be a paramount strategy to reduce virus spreading in each initial condition, by maintaining an acceptable infected people's number. The building capacity limitation could support such measure by potentially moving from FFPk masks to surgical masks use by occupants (thus improving users' comfort issues). A preliminary model to combine acceptable mask filters-occupants' density combination is proposed. The model could be modified to consider other recurring scenarios in other public buildings (e.g. tourist facilities, cultural buildings).",
        "published": "2020-04-27T16:40:22Z",
        "link": "http://arxiv.org/abs/2004.12927v1",
        "categories": [
            "physics.soc-ph",
            "cs.CY",
            "cs.MA",
            "physics.data-an",
            "J.2; J.3; J.4; I.6.5; I.6.8"
        ]
    },
    {
        "title": "A Microscopic Epidemic Model and Pandemic Prediction Using Multi-Agent   Reinforcement Learning",
        "authors": [
            "Changliu Liu"
        ],
        "summary": "This paper introduces a microscopic approach to model epidemics, which can explicitly consider the consequences of individual's decisions on the spread of the disease. We first formulate a microscopic multi-agent epidemic model where every agent can choose its activity level that affects the spread of the disease. Then by minimizing agents' cost functions, we solve for the optimal decisions for individual agents in the framework of game theory and multi-agent reinforcement learning. Given the optimal decisions of all agents, we can make predictions about the spread of the disease. We show that there are negative externalities in the sense that infected agents do not have enough incentives to protect others, which then necessitates external interventions to regulate agents' behaviors. In the discussion section, future directions are pointed out to make the model more realistic.",
        "published": "2020-04-27T17:17:29Z",
        "link": "http://arxiv.org/abs/2004.12959v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Improving Sample Efficiency and Multi-Agent Communication in RL-based   Train Rescheduling",
        "authors": [
            "Dano Roost",
            "Ralph Meier",
            "Stephan Huschauer",
            "Erik Nygren",
            "Adrian Egli",
            "Andreas Weiler",
            "Thilo Stadelmann"
        ],
        "summary": "We present preliminary results from our sixth placed entry to the Flatland international competition for train rescheduling, including two improvements for optimized reinforcement learning (RL) training efficiency, and two hypotheses with respect to the prospect of deep RL for complex real-world control tasks: first, that current state of the art policy gradient methods seem inappropriate in the domain of high-consequence environments; second, that learning explicit communication actions (an emerging machine-to-machine language, so to speak) might offer a remedy. These hypotheses need to be confirmed by future work. If confirmed, they hold promises with respect to optimizing highly efficient logistics ecosystems like the Swiss Federal Railways railway network.",
        "published": "2020-04-28T11:46:58Z",
        "link": "http://arxiv.org/abs/2004.13439v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "MultiMBNN: Matched and Balanced Causal Inference with Neural Networks",
        "authors": [
            "Ankit Sharma",
            "Garima Gupta",
            "Ranjitha Prasad",
            "Arnab Chatterjee",
            "Lovekesh Vig",
            "Gautam Shroff"
        ],
        "summary": "Causal inference (CI) in observational studies has received a lot of attention in healthcare, education, ad attribution, policy evaluation, etc. Confounding is a typical hazard, where the context affects both, the treatment assignment and response. In a multiple treatment scenario, we propose the neural network based MultiMBNN, where we overcome confounding by employing generalized propensity score based matching, and learning balanced representations. We benchmark the performance on synthetic and real-world datasets using PEHE, and mean absolute percentage error over ATE as metrics. MultiMBNN outperforms the state-of-the-art algorithms for CI such as TARNet and Perfect Match (PM).",
        "published": "2020-04-28T11:58:38Z",
        "link": "http://arxiv.org/abs/2004.13446v4",
        "categories": [
            "stat.ME",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Dynamic Quantized Consensus of General Linear Multi-agent Systems under   Denial-of-Service Attacks",
        "authors": [
            "Shuai Feng",
            "Hideaki Ishii"
        ],
        "summary": "In this paper, we study multi-agent consensus problems under Denial-of-Service (DoS) attacks with data rate constraints. We first consider the leaderless consensus problem and after that we briefly present the analysis of leader-follower consensus. The dynamics of the agents take general forms modeled as homogeneous linear time-invariant systems. In our analysis, we derive lower bounds on the data rate for the multi-agent systems to achieve leaderless and leader-follower consensus in the presence of DoS attacks, under which the issue of overflow of quantizer is prevented. The main contribution of the paper is the characterization of the trade-off between the tolerable DoS attack levels for leaderless and leader-follower consensus and the required data rates for the quantizers during the communication attempts among the agents. To mitigate the influence of DoS attacks, we employ dynamic quantization with zooming-in and zooming-out capabilities for avoiding quantizer saturation.",
        "published": "2020-04-28T21:06:08Z",
        "link": "http://arxiv.org/abs/2004.13815v3",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "End-to-End Design for Self-Reconfigurable Heterogeneous Robotic Swarms",
        "authors": [
            "Jorge Peña Queralta",
            "Li Qingqing",
            "Tuan Nguyen Gia",
            "Hong-Linh Truong",
            "Tomi Westerlund"
        ],
        "summary": "More widespread adoption requires swarms of robots to be more flexible for real-world applications. Multiple challenges remain in complex scenarios where a large amount of data needs to be processed in real-time and high degrees of situational awareness are required. The options in this direction are limited in existing robotic swarms, mostly homogeneous robots with limited operational and reconfiguration flexibility. We address this by bringing elastic computing techniques and dynamic resource management from the edge-cloud computing domain to the swarm robotics domain. This enables the dynamic provisioning of collective capabilities in the swarm for different applications. Therefore, we transform a swarm into a distributed sensing and computing platform capable of complex data processing tasks, which can then be offered as a service. In particular, we discuss how this can be applied to adaptive resource management in a heterogeneous swarm of drones, and how we are implementing the dynamic deployment of distributed data processing algorithms. With an elastic drone swarm built on reconfigurable hardware and containerized services, it will be possible to raise the self-awareness, degree of intelligence, and level of autonomy of heterogeneous swarms of robots. We describe novel directions for collaborative perception, and new ways of interacting with a robotic swarm.",
        "published": "2020-04-29T07:35:11Z",
        "link": "http://arxiv.org/abs/2004.13997v1",
        "categories": [
            "cs.RO",
            "cs.DC",
            "cs.MA"
        ]
    },
    {
        "title": "Informative Scene Decomposition for Crowd Analysis, Comparison and   Simulation Guidance",
        "authors": [
            "Feixiang He",
            "Yuanhang Xiang",
            "Xi Zhao",
            "He Wang"
        ],
        "summary": "Crowd simulation is a central topic in several fields including graphics. To achieve high-fidelity simulations, data has been increasingly relied upon for analysis and simulation guidance. However, the information in real-world data is often noisy, mixed and unstructured, making it difficult for effective analysis, therefore has not been fully utilized. With the fast-growing volume of crowd data, such a bottleneck needs to be addressed. In this paper, we propose a new framework which comprehensively tackles this problem. It centers at an unsupervised method for analysis. The method takes as input raw and noisy data with highly mixed multi-dimensional (space, time and dynamics) information, and automatically structure it by learning the correlations among these dimensions. The dimensions together with their correlations fully describe the scene semantics which consists of recurring activity patterns in a scene, manifested as space flows with temporal and dynamics profiles. The effectiveness and robustness of the analysis have been tested on datasets with great variations in volume, duration, environment and crowd dynamics. Based on the analysis, new methods for data visualization, simulation evaluation and simulation guidance are also proposed. Together, our framework establishes a highly automated pipeline from raw data to crowd analysis, comparison and simulation guidance. Extensive experiments and evaluations have been conducted to show the flexibility, versatility and intuitiveness of our framework.",
        "published": "2020-04-29T12:03:32Z",
        "link": "http://arxiv.org/abs/2004.14107v1",
        "categories": [
            "cs.GR",
            "cs.CV",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Search strategy in a complex and dynamic environment: the MH370 case",
        "authors": [
            "Stefan Ivić",
            "Bojan Crnković",
            "Hassan Arbabi",
            "Sophie Loire",
            "Patrick Clary",
            "Igor Mezić"
        ],
        "summary": "Search and detection of objects on the ocean surface is a challenging task due to the complexity of the drift dynamics and lack of known optimal solutions for the path of the search agents. This challenge was highlighted by the unsuccessful search for Malaysian Flight 370 (MH370) which disappeared on March 8, 2014. In this paper, we propose an improvement of a search algorithm rooted in the ergodic theory of dynamical systems which can accommodate complex geometries and uncertainties of the drifting search areas on the ocean surface. We illustrate the effectiveness of this algorithm in a computational replication of the conducted search for MH370. In comparison to conventional search methods, the proposed algorithm leads to an order of magnitude improvement in success rate over the time period of the actual search operation. Simulations of the proposed search control also indicate that the initial success rate of finding debris increases in the event of delayed search commencement. This is due to the existence of convergence zones in the search area which leads to local aggregation of debris in those zones and hence reduction of the effective size of the area to be searched.",
        "published": "2020-04-29T12:08:26Z",
        "link": "http://arxiv.org/abs/2004.14110v2",
        "categories": [
            "math.OC",
            "cs.MA",
            "cs.RO",
            "eess.SP"
        ]
    },
    {
        "title": "Extremism definitions in opinion dynamics models",
        "authors": [
            "André C. R. Martins"
        ],
        "summary": "There are several opinion dynamics models where extremism is defined as part of their characteristics. However, the way extremism is implemented in each model does not correspond to equivalent definitions. While some models focus on one aspect of the problem, others focus on different characteristics. This paper shows how each model only captures part of the problem and how Bayesian inspired opinion models can help put those differences in perspective. That discussion suggests new ways to introduce variables that can represent the problem of extremism better than we do today.   Keywords: Extremism, Opinion dynamics, CODA, Sociophysics",
        "published": "2020-04-30T02:23:31Z",
        "link": "http://arxiv.org/abs/2004.14548v1",
        "categories": [
            "physics.soc-ph",
            "cs.MA",
            "nlin.AO"
        ]
    },
    {
        "title": "PeerNomination: Relaxing Exactness for Increased Accuracy in Peer   Selection",
        "authors": [
            "Nicholas Mattei",
            "Paolo Turrini",
            "Stanislav Zhydkov"
        ],
        "summary": "In peer selection agents must choose a subset of themselves for an award or a prize. As agents are self-interested, we want to design algorithms that are impartial, so that an individual agent cannot affect their own chance of being selected. This problem has broad application in resource allocation and mechanism design and has received substantial attention in the artificial intelligence literature. Here, we present a novel algorithm for impartial peer selection, PeerNomination, and provide a theoretical analysis of its accuracy. Our algorithm possesses various desirable features. In particular, it does not require an explicit partitioning of the agents, as previous algorithms in the literature. We show empirically that it achieves higher accuracy than the exiting algorithms over several metrics.",
        "published": "2020-04-30T16:39:47Z",
        "link": "http://arxiv.org/abs/2004.14939v1",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.MA",
            "91A80, 91B10, 91B12, 91B14",
            "J.4; I.2"
        ]
    },
    {
        "title": "A model of urban evolution based on innovation diffusion",
        "authors": [
            "Juste Raimbault"
        ],
        "summary": "The dynamics of urban systems can be understood from an evolutionary perspective, in some sense extending biological and cultural evolution. Models for systems of cities implementing elementary evolutionary processes remain however to be investigated. We propose here such a model for urban dynamics at the macroscopic scale, in which the diffusion of innovations between cities captures transformation processes (mutations) and transmission processes (diffusion), using two coupled spatial interaction models. Explorations of the model on synthetic systems of cities show the role of spatial interaction and innovation diffusion ranges on measures of diversity and utility, and the existence of intermediate ranges yielding an optimal utility. Multi-objective optimization shows how the model produces a compromise between utility and diversity. This model paves the way towards more elaborated formalizations of urban evolution.",
        "published": "2020-04-30T17:59:38Z",
        "link": "http://arxiv.org/abs/2004.15023v1",
        "categories": [
            "physics.soc-ph",
            "cs.MA"
        ]
    },
    {
        "title": "On the Spontaneous Emergence of Discrete and Compositional Signals",
        "authors": [
            "Nur Geffen Lan",
            "Emmanuel Chemla",
            "Shane Steinert-Threlkeld"
        ],
        "summary": "We propose a general framework to study language emergence through signaling games with neural agents. Using a continuous latent space, we are able to (i) train using backpropagation, (ii) show that discrete messages nonetheless naturally emerge. We explore whether categorical perception effects follow and show that the messages are not compositional.",
        "published": "2020-04-30T21:15:19Z",
        "link": "http://arxiv.org/abs/2005.00110v1",
        "categories": [
            "cs.CL",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Smart Containers With Bidding Capacity: A Policy Gradient Algorithm for   Semi-Cooperative Learning",
        "authors": [
            "Wouter van Heeswijk"
        ],
        "summary": "Smart modular freight containers -- as propagated in the Physical Internet paradigm -- are equipped with sensors, data storage capability and intelligence that enable them to route themselves from origin to destination without manual intervention or central governance. In this self-organizing setting, containers can autonomously place bids on transport services in a spot market setting. However, for individual containers it may be difficult to learn good bidding policies due to limited observations. By sharing information and costs between one another, smart containers can jointly learn bidding policies, even though simultaneously competing for the same transport capacity. We replicate this behavior by learning stochastic bidding policies in a semi-cooperative multi agent setting. To this end, we develop a reinforcement learning algorithm based on the policy gradient framework. Numerical experiments show that sharing solely bids and acceptance decisions leads to stable bidding policies. Additional system information only marginally improves performance; individual job properties suffice to place appropriate bids. Furthermore, we find that carriers may have incentives not to share information with the smart containers. The experiments give rise to several directions for follow-up research, in particular the interaction between smart containers and transport services in self-organizing logistics.",
        "published": "2020-05-01T18:37:38Z",
        "link": "http://arxiv.org/abs/2005.00565v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Multi-Objective Eco-Routing for Dynamic Control of Connected & Automated   Vehicles",
        "authors": [
            "Shadi Djavadian",
            "Ran Tu",
            "Bilal Farooq",
            "Marianne Hatzopoulou"
        ],
        "summary": "The advent of intelligent vehicles that can communicate with infrastructure as well as automate the movement provides a range of new options to address key urban traffic issues such as congestion and pollution, without the need for centralized traffic control. Furthermore, the advances in the information, communication, and sensing technologies have provided access to real-time traffic and emission data. Leveraging these advancements, a dynamic multi-objective eco-routing strategy for connected & automated vehicles (CAVs) is proposed and implemented in a distributed traffic management system. It is applied to the road network of downtown Toronto in an in-house agent-based traffic simulation platform. The performance of the proposed system is compared to various single-objective optimizations. Simulation results show the significance of incorporating real-time emission and traffic state into the dynamic routing, along with considering the expected delays at the downstream intersections. The proposed multi-objective eco-routing has the potential of reducing GHG and NOx emissions by 43% and 18.58%, respectively, while reducing average travel time by 40%.",
        "published": "2020-05-02T12:28:44Z",
        "link": "http://arxiv.org/abs/2005.00815v3",
        "categories": [
            "math.OC",
            "cs.MA"
        ]
    },
    {
        "title": "Deep Reinforcement Learning for Intelligent Transportation Systems: A   Survey",
        "authors": [
            "Ammar Haydari",
            "Yasin Yilmaz"
        ],
        "summary": "Latest technological improvements increased the quality of transportation. New data-driven approaches bring out a new research direction for all control-based systems, e.g., in transportation, robotics, IoT and power systems. Combining data-driven applications with transportation systems plays a key role in recent transportation applications. In this paper, the latest deep reinforcement learning (RL) based traffic control applications are surveyed. Specifically, traffic signal control (TSC) applications based on (deep) RL, which have been studied extensively in the literature, are discussed in detail. Different problem formulations, RL parameters, and simulation environments for TSC are discussed comprehensively. In the literature, there are also several autonomous driving applications studied with deep RL models. Our survey extensively summarizes existing works in this field by categorizing them with respect to application types, control models and studied algorithms. In the end, we discuss the challenges and open questions regarding deep RL-based transportation applications.",
        "published": "2020-05-02T22:44:50Z",
        "link": "http://arxiv.org/abs/2005.00935v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "eess.SP",
            "eess.SY",
            "stat.ML"
        ]
    },
    {
        "title": "Search for Smart Evaders with Swarms of Sweeping Agents",
        "authors": [
            "Roee M. Francos",
            "Alfred M. Bruckstein"
        ],
        "summary": "Suppose that in a given planar circular region, there are some smart mobile evaders and we would like to find them using sweeping agents. We assume that each agent has a line sensor of length 2r. We propose procedures for designing cooperative sweeping processes that ensure the successful completion of the task, thereby deriving conditions on the sweeping velocity of the agents and their paths. Successful completion of the task means that evaders with a given limit on their velocity cannot escape the sweeping agents. A simpler task for the sweeping swarm is the confinement of the evaders to their initial domain. The feasibility of completing these tasks depends on geometric and dynamic constraints that impose a lower bound on the velocity that the sweeper swarm must have. This critical velocity is derived to ensure the satisfaction of the confinement task. Increasing the velocity above the lower bound enables the agents to complete the search task as well. We present results on the total search time as a function of the sweeping velocity of the swarm's agents given the initial conditions on the size of the search region and the maximal velocity of the evaders.",
        "published": "2020-05-03T07:21:34Z",
        "link": "http://arxiv.org/abs/2005.01011v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Multi-agent Reinforcement Learning for Decentralized Stable Matching",
        "authors": [
            "Kshitija Taywade",
            "Judy Goldsmith",
            "Brent Harrison"
        ],
        "summary": "In the real world, people/entities usually find matches independently and autonomously, such as finding jobs, partners, roommates, etc. It is possible that this search for matches starts with no initial knowledge of the environment. We propose the use of a multi-agent reinforcement learning (MARL) paradigm for a spatially formulated decentralized two-sided matching market with independent and autonomous agents. Having autonomous agents acting independently makes our environment very dynamic and uncertain. Moreover, agents lack the knowledge of preferences of other agents and have to explore the environment and interact with other agents to discover their own preferences through noisy rewards. We think such a setting better approximates the real world and we study the usefulness of our MARL approach for it. Along with conventional stable matching case where agents have strictly ordered preferences, we check the applicability of our approach for stable matching with incomplete lists and ties. We investigate our results for stability, level of instability (for unstable results), and fairness. Our MARL approach mostly yields stable and fair outcomes.",
        "published": "2020-05-03T15:28:41Z",
        "link": "http://arxiv.org/abs/2005.01117v3",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Multiagent Value Iteration Algorithms in Dynamic Programming and   Reinforcement Learning",
        "authors": [
            "Dimitri Bertsekas"
        ],
        "summary": "We consider infinite horizon dynamic programming problems, where the control at each stage consists of several distinct decisions, each one made by one of several agents. In an earlier work we introduced a policy iteration algorithm, where the policy improvement is done one-agent-at-a-time in a given order, with knowledge of the choices of the preceding agents in the order. As a result, the amount of computation for each policy improvement grows linearly with the number of agents, as opposed to exponentially for the standard all-agents-at-once method. For the case of a finite-state discounted problem, we showed convergence to an agent-by-agent optimal policy. In this paper, this result is extended to value iteration and optimistic versions of policy iteration, as well as to more general DP problems where the Bellman operator is a contraction mapping, such as stochastic shortest path problems with all policies being proper.",
        "published": "2020-05-04T16:34:24Z",
        "link": "http://arxiv.org/abs/2005.01627v1",
        "categories": [
            "math.OC",
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Navigating the Landscape of Multiplayer Games",
        "authors": [
            "Shayegan Omidshafiei",
            "Karl Tuyls",
            "Wojciech M. Czarnecki",
            "Francisco C. Santos",
            "Mark Rowland",
            "Jerome Connor",
            "Daniel Hennes",
            "Paul Muller",
            "Julien Perolat",
            "Bart De Vylder",
            "Audrunas Gruslys",
            "Remi Munos"
        ],
        "summary": "Multiplayer games have long been used as testbeds in artificial intelligence research, aptly referred to as the Drosophila of artificial intelligence. Traditionally, researchers have focused on using well-known games to build strong agents. This progress, however, can be better informed by characterizing games and their topological landscape. Tackling this latter question can facilitate understanding of agents and help determine what game an agent should target next as part of its training. Here, we show how network measures applied to response graphs of large-scale games enable the creation of a landscape of games, quantifying relationships between games of varying sizes and characteristics. We illustrate our findings in domains ranging from canonical games to complex empirical games capturing the performance of trained agents pitted against one another. Our results culminate in a demonstration leveraging this information to generate new and interesting games, including mixtures of empirical games synthesized from real world games.",
        "published": "2020-05-04T16:58:17Z",
        "link": "http://arxiv.org/abs/2005.01642v3",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Can gender inequality be created without inter-group discrimination?",
        "authors": [
            "Sylvie Huet1",
            "Floriana Gargiulo",
            "Felicia Pratto"
        ],
        "summary": "Understanding human societies requires knowing how they develop gender hierarchies which are ubiquitous. We test whether a simple agent-based dynamic process could create gender inequality. Relying on evidence of gendered status concerns, self-construals, and cognitive habits, our model included a gender difference in how responsive male-like and female-like agents are to others' opinions about the level of esteem for someone. We simulate a population who interact in pairs of randomly selected agents to influence each other about their esteem judgments of self and others. Half the agents are more influenced by their relative status rank during the interaction than the others. Without prejudice, stereotypes, segregation, or categorization, our model produces inter-group inequality of self-esteem and status that is stable, consensual, and exhibits characteristics of glass ceiling effects. Outcomes are not affected by relative group size. We discuss implications for group orientation to dominance and individuals' motivations to exchange.",
        "published": "2020-05-05T07:33:27Z",
        "link": "http://arxiv.org/abs/2005.01980v1",
        "categories": [
            "physics.soc-ph",
            "cs.CY",
            "cs.MA"
        ]
    },
    {
        "title": "Envy-free cake cutting: A polynomial number of queries with high   probability",
        "authors": [
            "Guillaume Chèze"
        ],
        "summary": "In this article we propose a probabilistic framework in order to study the fair division of a divisible good, e.g., a cake, between n players. Our framework follows the same idea than the ''Full independence model'' used in the study of fair division of indivisible goods. We show that, in this framework, there exists an envy-free division algorithm satisfying the following probability estimate:$$\\mathbb{P}\\big( C(\\mu_1, \\ldots,\\mu_n) \\geq n^{7+b}\\big) = \\mathcal{O}\\Big(n^{-\\frac{b-1}{3}+1+o(1)}\\Big),$$where $\\mu_1,\\ldots, \\mu_n$ correspond to the preferences of the $n$ players,$C(\\mu_1, \\ldots,\\mu_n)$ is the number of queries used by the algorithm and $b>4$. In particular, this gives$$\\lim_{n \\rightarrow + \\infty}\\mathbb{P}\\big( C(\\mu_1, \\ldots,\\mu_n) \\geq n^{12}\\big) = 0.$$ It must be noticed that nowadays few things are known about the complexity of envy-free division algorithms. Indeed, Procaccia has given a lower bound in $\\Omega(n^2)$ and Aziz and Mackenzie have given an upper bound in $n^{n^{n^{n^{n^{n}}}}}$. As our estimate means that we have $C(\\mu_1, \\ldots, \\mu_n)<n^{12}$ with a high probability, this gives a new insight on the complexity of envy-free cake cutting algorithms. Our result follows from a study of Webb's algorithm and a theorem of Tao and Vu about the smallest singular value of a random matrix.",
        "published": "2020-05-05T07:35:18Z",
        "link": "http://arxiv.org/abs/2005.01982v2",
        "categories": [
            "cs.CC",
            "cs.MA",
            "math.PR"
        ]
    },
    {
        "title": "Using Machine Learning to Emulate Agent-Based Simulations",
        "authors": [
            "Claudio Angione",
            "Eric Silverman",
            "Elisabeth Yaneske"
        ],
        "summary": "In this proof-of-concept work, we evaluate the performance of multiple machine-learning methods as statistical emulators for use in the analysis of agent-based models (ABMs). Analysing ABM outputs can be challenging, as the relationships between input parameters can be non-linear or even chaotic even in relatively simple models, and each model run can require significant CPU time. Statistical emulation, in which a statistical model of the ABM is constructed to facilitate detailed model analyses, has been proposed as an alternative to computationally costly Monte Carlo methods. Here we compare multiple machine-learning methods for ABM emulation in order to determine the approaches best suited to emulating the complex behaviour of ABMs. Our results suggest that, in most scenarios, artificial neural networks (ANNs) and gradient-boosted trees outperform Gaussian process emulators, currently the most commonly used method for the emulation of complex computational models. ANNs produced the most accurate model replications in scenarios with high numbers of model runs, although training times were longer than the other methods. We propose that agent-based modelling would benefit from using machine-learning methods for emulation, as this can facilitate more robust sensitivity analyses for the models while also reducing CPU time consumption when calibrating and analysing the simulation.",
        "published": "2020-05-05T11:48:36Z",
        "link": "http://arxiv.org/abs/2005.02077v2",
        "categories": [
            "cs.MA",
            "cs.LG",
            "68U20",
            "I.6.4; I.2.6"
        ]
    },
    {
        "title": "Finding the maximum-a-posteriori behaviour of agents in an agent-based   model",
        "authors": [
            "Daniel Tang"
        ],
        "summary": "In this paper we consider the problem of finding the most probable set of events that could have led to a set of partial, noisy observations of some dynamical system. In particular, we consider the case of a dynamical system that is a (possibly stochastic) time-stepping agent-based model with a discrete state space, the (possibly noisy) observations are the number of agents that have some given property and the events we're interested in are the decisions made by the agents (their ``expressed behaviours'') as the model evolves.   We show that this problem can be reduced to an integer linear programming problem which can subsequently be solved numerically using a standard branch-and-cut algorithm. We describe two implementations, an ``offline'' algorithm that finds the maximum-a-posteriori expressed behaviours given a set of observations over a finite time window, and an ``online'' algorithm that incrementally builds a feasible set of behaviours from a stream of observations that may have no natural beginning or end.   We demonstrate both algorithms on a spatial predator-prey model on a 32x32 grid with an initial population of 100 agents.",
        "published": "2020-05-05T12:16:29Z",
        "link": "http://arxiv.org/abs/2005.02096v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "On Reachable Assignments in Cycles and Cliques",
        "authors": [
            "Luis Müller",
            "Matthias Bentert"
        ],
        "summary": "The efficient and fair distribution of indivisible resources among agents is a common problem in the field of \\emph{Multi-Agent-Systems}. We consider a graph-based version of this problem called Reachable Assignments, introduced by Gourves, Lesca, and Wilczynski [AAAI, 2017]. The input for this problem consists of a set of agents, a set of objects, the agent's preferences over the objects, a graph with the agents as vertices and edges encoding which agents can trade resources with each other, and an initial and a target distribution of the objects, where each agent owns exactly one object in each distribution. The question is then whether the target distribution is reachable via a sequence of rational trades. A trade is rational when the two participating agents are neighbors in the graph and both obtain an object they prefer over the object they previously held. We show that Reachable Assignments is NP-hard even when restricting the input graph to be a clique and develop an $O(n^3)$-time algorithm for the case where the input graph is a cycle with $n$ vertices.",
        "published": "2020-05-05T14:23:55Z",
        "link": "http://arxiv.org/abs/2005.02218v1",
        "categories": [
            "cs.MA",
            "cs.DM",
            "cs.DS"
        ]
    },
    {
        "title": "In Silico Trial to test COVID-19 candidate vaccines: a case study with   UISS platform",
        "authors": [
            "Giulia Russo",
            "Marzio Pennisi",
            "Marco Viceconti",
            "Francesco Pappalardo"
        ],
        "summary": "SARS-CoV-2 is a severe respiratory infection that infects humans. Its outburst entitled it as a pandemic emergence. To get a grip on this, outbreak specific preventive and therapeutic interventions are urgently needed. It must be said that, until now, there are no existing vaccines for coronaviruses. To promptly and rapidly respond to pandemic events, the application of in silico trials can be used for designing and testing medicines against SARS-CoV-2 and speed-up the vaccine discovery pipeline, predicting any therapeutic failure and minimizing undesired effects. Here, we present an in silico platform that showed to be in very good agreement with the latest literature in predicting SARS- CoV-2 dynamics and related immune system host response. Moreover, it has been used to predict the outcome of one of the latest suggested approach to design an effective vaccine, based on monoclonal antibody. UISS is then potentially ready to be used as an in silico trial platform to predict the outcome of vaccination strategy against SARS-CoV-2.",
        "published": "2020-05-05T15:42:56Z",
        "link": "http://arxiv.org/abs/2005.02289v1",
        "categories": [
            "q-bio.QM",
            "cs.MA",
            "q-bio.PE",
            "q-bio.TO"
        ]
    },
    {
        "title": "Reducing Uncertainty by Fusing Dynamic Occupancy Grid Maps in a   Cloud-based Collective Environment Model",
        "authors": [
            "Bastian Lampe",
            "Raphael van Kempen",
            "Timo Woopen",
            "Alexandru Kampmann",
            "Bassam Alrifaee",
            "Lutz Eckstein"
        ],
        "summary": "Accurate environment perception is essential for automated vehicles. Since occlusions and inaccuracies regularly occur, the exchange and combination of perception data of multiple vehicles seems promising. This paper describes a method to combine perception data of automated and connected vehicles in the form of evidential Dynamic Occupany Grid Maps (DOGMas) in a cloud-based system. This system is called the Collective Environment Model and is part of the cloud system developed in the project UNICARagil. The presented concept extends existing approaches that fuse evidential grid maps representing static environments of a single vehicle to evidential grid maps computed by multiple vehicles in dynamic environments. The developed fusion process additionally incorporates self-reported data provided by connected vehicles instead of only relying on perception data. We show that the uncertainty in a DOGMa described by Shannon entropy as well as the uncertainty described by a non-specificity measure can be reduced. This enables automated and connected vehicles to behave in ways not before possible due to unknown but relevant information about the environment.",
        "published": "2020-05-05T15:53:36Z",
        "link": "http://arxiv.org/abs/2005.02298v1",
        "categories": [
            "eess.SP",
            "cs.MA"
        ]
    },
    {
        "title": "Approximation Algorithms for Distributed Multi-Robot Coverage in   Non-Convex Environments",
        "authors": [
            "Armin Sadeghi",
            "Ahmad Bilal Asghar",
            "Stephen L. Smith"
        ],
        "summary": "In this paper, we revisit the distributed coverage control problem with multiple robots on both metric graphs and in non-convex continuous environments. Traditionally, the solutions provided for this problem converge to a locally optimal solution with no guarantees on the quality of the solution. We consider sub-additive sensing functions, which capture the scenarios where sensing an event requires the robot to visit the event location. For these sensing functions, we provide the first constant factor approximation algorithms for the distributed coverage problem. The approximation results require twice the conventional communication range in the existing coverage algorithms. However, we show through extensive simulation results that the proposed approximation algorithms outperform several existing algorithms in convex, non-convex continuous, and discrete environments even with the conventional communication ranges. Moreover, the proposed algorithms match the state-of-the-art centralized algorithms in the solution quality.",
        "published": "2020-05-05T20:21:36Z",
        "link": "http://arxiv.org/abs/2005.02471v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Approximation Algorithms for Multi-Robot Patrol-Scheduling with Min-Max   Latency",
        "authors": [
            "Peyman Afshani",
            "Mark De Berg",
            "Kevin Buchin",
            "Jie Gao",
            "Maarten Loffler",
            "Amir Nayyeri",
            "Benjamin Raichel",
            "Rik Sarkar",
            "Haotian Wang",
            "Hao-Tsung Yang"
        ],
        "summary": "We consider the problem of finding patrol schedules for $k$ robots to visit a given set of $n$ sites in a metric space. Each robot has the same maximum speed and the goal is to minimize the weighted maximum latency of any site, where the latency of a site is defined as the maximum time duration between consecutive visits of that site. The problem is NP-hard, as it has the traveling salesman problem as a special case (when $k=1$ and all sites have the same weight). We present a polynomial-time algorithm with an approximation factor of $O(k^2 \\log \\frac{w_{\\max}}{w_{\\min}})$ to the optimal solution, where $w_{\\max}$ and $w_{\\min}$ are the maximum and minimum weight of the sites respectively. Further, we consider the special case where the sites are in 1D. When all sites have the same weight, we present a polynomial-time algorithm to solve the problem exactly. If the sites may have different weights, we present a $12$-approximate solution, which runs in polynomial time when the number of robots, $k$, is a constant.",
        "published": "2020-05-05T23:18:53Z",
        "link": "http://arxiv.org/abs/2005.02530v3",
        "categories": [
            "cs.DS",
            "cs.AI",
            "cs.CG",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "A Separation Theorem for Joint Sensor and Actuator Scheduling with   Guaranteed Performance Bounds",
        "authors": [
            "Milad Siami",
            "Ali Jadbabaie"
        ],
        "summary": "We study the problem of jointly designing a sparse sensor and actuator schedule for linear dynamical systems while guaranteeing a control/estimation performance that approximates the fully sensed/actuated setting. We further prove a separation principle, showing that the problem can be decomposed into finding sensor and actuator schedules separately. However, it is shown that this problem cannot be efficiently solved or approximated in polynomial, or even quasi-polynomial time for time-invariant sensor/actuator schedules; instead, we develop deterministic polynomial-time algorithms for a time-varying sensor/actuator schedule with guaranteed approximation bounds. Our main result is to provide a polynomial-time joint actuator and sensor schedule that on average selects only a constant number of sensors and actuators at each time step, irrespective of the dimension of the system. The key idea is to sparsify the controllability and observability Gramians while providing approximation guarantees for Hankel singular values. This idea is inspired by recent results in theoretical computer science literature on sparsification.",
        "published": "2020-05-06T21:25:38Z",
        "link": "http://arxiv.org/abs/2005.03143v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY",
            "math.DS"
        ]
    },
    {
        "title": "Optimized Travel to Meetings on a Common Location of Geographical   Distributed Participants",
        "authors": [
            "Peter Hillmann",
            "Bastian Kühnel",
            "Tobias Uhlig",
            "Gabi Dreo Rodosek",
            "Oliver Rose"
        ],
        "summary": "Members of international organizations often meet in person at a common location for discussions. There is frequently disagreement over the place and time of the meeting due to the different travel efforts of the members. They usually travel by plane and their travel expenses depend on the flight connections. This paper presents an approach to calculate the optimized location and time, where and when distributed partners should meet. The presented system considers the requirements and specifications of each individual member. It respects earliest starting time of an event and non night flights. The optimized result is evaluated with regard to multiple objectives. We focus on the minimization of costs and travel time. Our search algorithm identifies individual travel data for all members for a potential event. The output provides recommendations for the global best appointments and offers further information for the partners. Our system saves expenses and time for all members and allows adjustment as well as compensation.",
        "published": "2020-05-07T07:54:28Z",
        "link": "http://arxiv.org/abs/2005.08633v1",
        "categories": [
            "physics.soc-ph",
            "cs.CY",
            "cs.MA"
        ]
    },
    {
        "title": "Pricing under a multinomial logit model with non linear network effects",
        "authors": [
            "Felipe Maldonado",
            "Gerardo Berbeglia",
            "Pascal Van Hentenryck"
        ],
        "summary": "We study the problem of pricing under a Multinomial Logit model where we incorporate network effects over the consumer's decisions. We analyse both cases, when sellers compete or collaborate. In particular, we pay special attention to the overall expected revenue and how the behaviour of the no purchase option is affected under variations of a network effect parameter. Where for example we prove that the market share for the no purchase option, is decreasing in terms of the value of the network effect, meaning that stronger communication among costumers increases the expected amount of sales. We also analyse how the customer's utility is altered when network effects are incorporated into the market, comparing the cases where both competitive and monopolistic prices are displayed. We use tools from stochastic approximation algorithms to prove that the probability of purchasing the available products converges to a unique stationary distribution. We model that the sellers can use this stationary distribution to establish their strategies. Finding that under those settings, a pure Nash Equilibrium represents the pricing strategies in the case of competition, and an optimal (that maximises the total revenue) fixed price characterise the case of collaboration.",
        "published": "2020-05-07T09:37:56Z",
        "link": "http://arxiv.org/abs/2005.03352v1",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "EXPOSED: An occupant exposure model for confined spaces to retrofit   crowd models during a pandemic",
        "authors": [
            "Enrico Ronchi",
            "Ruggiero Lovreglio"
        ],
        "summary": "Crowd models can be used for the simulation of people movement in the built environment. Crowd model outputs have been used for evaluating safety and comfort of pedestrians, inform crowd management and perform forensic investigations. Microscopic crowd models allow the representation of each person and the obtainment of information concerning their location over time and interactions with the physical space/other people. Pandemics such as COVID-19 have posed several questions on safe building usage, given the risk of disease transmission among building occupants. Here we show how crowd modelling can be used to assess occupant exposure in confined spaces. The policies adopted concerning building usage and social distancing during a pandemic can vary greatly, and they are mostly based on the macroscopic analysis of the spread of disease rather than a safety assessment performed at a building level. The proposed model allows the investigation of occupant exposure in buildings based on the analysis of microscopic people movement. Risk assessment is performed by retrofitting crowd models with a universal model for exposure assessment which can account for different types of disease transmissions. This work allows policy makers to perform informed decisions concerning building usage during a pandemic.",
        "published": "2020-05-08T13:00:19Z",
        "link": "http://arxiv.org/abs/2005.04007v1",
        "categories": [
            "physics.soc-ph",
            "cs.CY",
            "cs.MA",
            "J.2; J.3; J.4; I.6.5; I.6.6"
        ]
    },
    {
        "title": "Multi-Party Campaigning",
        "authors": [
            "Martin Koutecký",
            "Nimrod Talmon"
        ],
        "summary": "We study a social choice setting of manipulation in elections and extend the usual model in two major ways: first, instead of considering a single manipulating agent, in our setting there are several, possibly competing ones; second, instead of evaluating an election after the first manipulative action, we allow several back-and-forth rounds to take place. We show that in certain situations, such as in elections with only a few candidates, optimal strategies for each of the manipulating agents can be computed efficiently.   Our algorithmic results rely on formulating the problem of finding an optimal strategy as sentences of Presburger arithmetic that are short and only involve small coefficients, which we show is fixed-parameter tractable -- indeed, one of our contributions is a general result regarding fixed-parameter tractability of Presburger arithmetic that might be useful in other settings. Following our general theorem, we design quite general algorithms; in particular, we describe how to design efficient algorithms for various settings, including settings in which we model diffusion of opinions in a social network, complex budgeting schemes available to the manipulating agents, and various realistic restrictions on adversary actions.",
        "published": "2020-05-09T14:45:01Z",
        "link": "http://arxiv.org/abs/2005.04455v1",
        "categories": [
            "cs.MA",
            "cs.DS",
            "cs.SI"
        ]
    },
    {
        "title": "Angle-Constrained Formation Control for Circular Mobile Robots",
        "authors": [
            "Nelson P. K. Chan",
            "Bayu Jayawardhana",
            "Hector Garcia de Marina"
        ],
        "summary": "In this letter, we investigate the formation control problem of mobile robots moving in the plane where, instead of assuming robots to be simple points, each robot is assumed to have the form of a disk with equal radius. Based on interior angle measurements of the neighboring robots' disk, which can be obtained from low-cost vision sensors, we propose a gradient-based distributed control law and show the exponential convergence property of the associated error system. By construction, the proposed control law has the appealing property of ensuring collision avoidance between neighboring robots. We also present simulation results for {a team} of four circular mobile robots forming a rectangular shape.",
        "published": "2020-05-10T15:20:52Z",
        "link": "http://arxiv.org/abs/2005.04694v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.RO",
            "cs.SY",
            "math.OC",
            "34H05, 70E60, 93C10, 93C85"
        ]
    },
    {
        "title": "Fair Division: The Computer Scientist's Perspective",
        "authors": [
            "Toby Walsh"
        ],
        "summary": "I survey recent progress on a classic and challenging problem in social choice: the fair division of indivisible items. I discuss how a computational perspective has provided interesting insights into and understanding of how to divide items fairly and efficiently. This has involved bringing to bear tools such as those used in knowledge representation, computational complexity, approximation methods, game theory, online analysis and communication complexity",
        "published": "2020-05-11T04:19:38Z",
        "link": "http://arxiv.org/abs/2005.04855v1",
        "categories": [
            "cs.AI",
            "cs.GT",
            "cs.MA",
            "91B14",
            "I.2.0"
        ]
    },
    {
        "title": "Mobile Robot Path Planning in Dynamic Environments through Globally   Guided Reinforcement Learning",
        "authors": [
            "Binyu Wang",
            "Zhe Liu",
            "Qingbiao Li",
            "Amanda Prorok"
        ],
        "summary": "Path planning for mobile robots in large dynamic environments is a challenging problem, as the robots are required to efficiently reach their given goals while simultaneously avoiding potential conflicts with other robots or dynamic objects. In the presence of dynamic obstacles, traditional solutions usually employ re-planning strategies, which re-call a planning algorithm to search for an alternative path whenever the robot encounters a conflict. However, such re-planning strategies often cause unnecessary detours. To address this issue, we propose a learning-based technique that exploits environmental spatio-temporal information. Different from existing learning-based methods, we introduce a globally guided reinforcement learning approach (G2RL), which incorporates a novel reward structure that generalizes to arbitrary environments. We apply G2RL to solve the multi-robot path planning problem in a fully distributed reactive manner. We evaluate our method across different map types, obstacle densities, and the number of robots. Experimental results show that G2RL generalizes well, outperforming existing distributed methods, and performing very similarly to fully centralized state-of-the-art benchmarks.",
        "published": "2020-05-11T20:42:29Z",
        "link": "http://arxiv.org/abs/2005.05420v2",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Delay-Aware Multi-Agent Reinforcement Learning for Cooperative and   Competitive Environments",
        "authors": [
            "Baiming Chen",
            "Mengdi Xu",
            "Zuxin Liu",
            "Liang Li",
            "Ding Zhao"
        ],
        "summary": "Action and observation delays exist prevalently in the real-world cyber-physical systems which may pose challenges in reinforcement learning design. It is particularly an arduous task when handling multi-agent systems where the delay of one agent could spread to other agents. To resolve this problem, this paper proposes a novel framework to deal with delays as well as the non-stationary training issue of multi-agent tasks with model-free deep reinforcement learning. We formally define the Delay-Aware Markov Game that incorporates the delays of all agents in the environment. To solve Delay-Aware Markov Games, we apply centralized training and decentralized execution that allows agents to use extra information to ease the non-stationarity issue of the multi-agent systems during training, without the need of a centralized controller during execution. Experiments are conducted in multi-agent particle environments including cooperative communication, cooperative navigation, and competitive experiments. We also test the proposed algorithm in traffic scenarios that require coordination of all autonomous vehicles to show the practical value of delay-awareness. Results show that the proposed delay-aware multi-agent reinforcement learning algorithm greatly alleviates the performance degradation introduced by delay. Codes and demo videos are available at: https://github.com/baimingc/delay-aware-MARL.",
        "published": "2020-05-11T21:21:50Z",
        "link": "http://arxiv.org/abs/2005.05441v2",
        "categories": [
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Framing Effects on Strategic Information Design under Receiver Distrust   and Unknown State",
        "authors": [
            "Doris E. M. Brown",
            "Venkata Sriram Siddhardh Nadendla"
        ],
        "summary": "Strategic information design is a framework where a sender designs information strategically to steer its receiver's decision towards a desired choice. Traditionally, such frameworks have always assumed that the sender and the receiver comprehends the state of the choice environment, and that the receiver always trusts the sender's signal. This paper deviates from these assumptions and re-investigates strategic information design in the presence of distrustful receiver and when both sender and receiver cannot observe/comprehend the environment state space. Specifically, we assume that both sender and receiver has access to non-identical beliefs about choice rewards (with sender's belief being more accurate), but not the environment state that determines these rewards. Furthermore, given that the receiver does not trust the sender, we also assume that the receiver updates its prior in a non-Bayesian manner. We evaluate the Stackelberg equilibrium and investigate effects of information framing (i.e. send complete signal, or just expected value of the signal) on the equilibrium. Furthermore, we also investigate trust dynamics at the receiver, under the assumption that the receiver minimizes regret in hindsight. Simulation results are presented to illustrate signaling effects and trust dynamics in strategic information design.",
        "published": "2020-05-12T01:55:56Z",
        "link": "http://arxiv.org/abs/2005.05516v2",
        "categories": [
            "cs.GT",
            "cs.IR",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "A Difficulty in Controlling Blockchain Mining Costs via Cryptopuzzle   Difficulty",
        "authors": [
            "Venkata Sriram Siddhardh Nadendla",
            "Lav R. Varshney"
        ],
        "summary": "Blockchain systems often employ proof-of-work consensus protocols to validate and add transactions into hashchains. These protocols stimulate competition among miners in solving cryptopuzzles (e.g. SHA-256 hash computation in Bitcoin) in exchange for a monetary reward. Here, we model mining as an all-pay auction, where miners' computational efforts are interpreted as bids, and the allocation function is the probability of solving the cryptopuzzle in a single attempt with unit (normalized) computational capability. Such an allocation function captures how blockchain systems control the difficulty of the cryptopuzzle as a function of miners' computational abilities (bids). In an attempt to reduce mining costs, we investigate designing a mining auction mechanism which induces a logit equilibrium amongst the miners with choice distributions that are unilaterally decreasing with costs at each miner. We show it is impossible to design a lenient allocation function that does this. Specifically, we show that there exists no allocation function that discourages miners to bid higher costs at logit equilibrium, if the rate of change of difficulty with respect to each miner's cost is bounded by the inverse of the sum of costs at all the miners.",
        "published": "2020-05-12T02:07:06Z",
        "link": "http://arxiv.org/abs/2005.05521v1",
        "categories": [
            "cs.GT",
            "cs.CR",
            "cs.MA"
        ]
    },
    {
        "title": "Fair Resource Allocation in Optical Networks under Tidal Traffic",
        "authors": [
            "Tania Panayiotou",
            "Georgios Ellinas"
        ],
        "summary": "We propose an alpha-fair routing and spectrum allocation (RSA) framework for reconfigurable elastic optical networks under modeled tidal traffic, that is based on the maximization of the social welfare function parameterized by a scalar alpha (the inequality aversion parameter). The objective is to approximate an egalitarian spectrum allocation (SA) that maximizes the minimum possible SA over all connections contending for the network resources, shifting from the widely used utilitarian SA that merely maximizes the network efficiency. A set of existing metrics are examined (i.e., connection blocking, resource utilization, coefficient of variation (CV) of utilities), and a set of new measures are also introduced (i.e., improvement on connection over- (COP) and under-provisioning (CUP), CV of unserved traffic), allowing a network operator to derive and evaluate in advance a set of alpha-fair RSA solutions and select the one that best fits the performance requirements of both the individual connections and the overall network. We show that an egalitarian SA better utilizes the network resources by significantly improving both COP (up to 20%) and CUP (up to 80%), compared to the utilitarian allocation, while attaining zero blocking. Importantly, the CVs of utilities and unserved traffic indicate that a SA that is fairest with respect to the amount of utilities allocated to the connections does not imply that the SA is also fairest with respect to the achievable QoS of the connections, while an egalitarian SA better approximates a fairest QoS-based SA.",
        "published": "2020-05-12T15:48:44Z",
        "link": "http://arxiv.org/abs/2005.05874v4",
        "categories": [
            "cs.NI",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Digital Social Contracts: A Foundation for an Egalitarian and Just   Digital Society",
        "authors": [
            "Luca Cardelli",
            "Liav Orgad",
            "Gal Shahaf",
            "Ehud Shapiro",
            "Nimrod Talmon"
        ],
        "summary": "Almost two centuries ago Pierre-Joseph Proudhon proposed social contracts -- voluntary agreements among free people -- as a foundation from which an egalitarian and just society can emerge. A \\emph{digital social contract} is the novel incarnation of this concept for the digital age: a voluntary agreement between people that is specified, undertaken, and fulfilled in the digital realm. It embodies the notion of \"code-is-law\" in its purest form, in that a digital social contract is in fact a program -- code in a social contracts programming language, which specifies the digital actions parties to the social contract may take; and the parties to the contract are entrusted, equally, with the task of ensuring that each party abides by the contract. Parties to a social contract are identified via their public keys, and the one and only type of action a party to a digital social contract may take is a \"digital speech act\" -- signing an utterance with her private key and sending it to the other parties to the contract. Here, we present a formal definition of a digital social contract as agents that communicate asynchronously via crypto-speech acts, where the output of each agent is the input of all the other agents. We outline an abstract design for a social contracts programming language and show, via programming examples, that key application areas, including social community; simple sharing-economy applications; egalitarian currency networks; and democratic community governance, can all be expressed elegantly and efficiently as digital social contracts.",
        "published": "2020-05-13T11:45:49Z",
        "link": "http://arxiv.org/abs/2005.06261v6",
        "categories": [
            "cs.CY",
            "cs.MA",
            "cs.PL",
            "cs.SI"
        ]
    },
    {
        "title": "Competing in a Complex Hidden Role Game with Information Set Monte Carlo   Tree Search",
        "authors": [
            "Jack Reinhardt"
        ],
        "summary": "Advances in intelligent game playing agents have led to successes in perfect information games like Go and imperfect information games like Poker. The Information Set Monte Carlo Tree Search (ISMCTS) family of algorithms outperforms previous algorithms using Monte Carlo methods in imperfect information games. In this paper, Single Observer Information Set Monte Carlo Tree Search (SO-ISMCTS) is applied to Secret Hitler, a popular social deduction board game that combines traditional hidden role mechanics with the randomness of a card deck. This combination leads to a more complex information model than the hidden role and card deck mechanics alone. It is shown in 10108 simulated games that SO-ISMCTS plays as well as simpler rule based agents, and demonstrates the potential of ISMCTS algorithms in complicated information set domains.",
        "published": "2020-05-14T17:21:10Z",
        "link": "http://arxiv.org/abs/2005.07156v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "A Minimum Energy Filter for Distributed Multirobot Localisation",
        "authors": [
            "Jack Henderson",
            "Jochen Trumpf",
            "Mohammad Zamani"
        ],
        "summary": "We present a new approach to the cooperative localisation problem by applying the theory of minimum energy filtering. We consider the problem of estimating the pose of a group of mobile robots in an environment where robots can perceive fixed landmarks and neighbouring robots as well as share information with others over a communication channel. Whereas the vast majority of the existing literature applies some variant of a Kalman Filter, we derive a set of filter equations for the global state estimate based on the principle of minimum energy filtering. We show how the filter equations can be decoupled and the calculations distributed among the robots in the network without requiring a central processing node. Finally, we provide a demonstration of the filter's performance in simulation.",
        "published": "2020-05-15T00:21:10Z",
        "link": "http://arxiv.org/abs/2005.07303v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.RO",
            "cs.SY"
        ]
    },
    {
        "title": "Safety Constrained Multi-UAV Time Coordination: A Bi-level Control   Framework in GPS Denied Environment",
        "authors": [
            "Wenbin Wan",
            "Hunmin Kim",
            "Yikun Cheng",
            "Naira Hovakimyan",
            "Petros G. Voulgaris",
            "Lui Sha"
        ],
        "summary": "Unmanned aerial vehicles (UAVs) suffer from sensor drifts in GPS denied environments, which can cause safety issues. To avoid intolerable sensor drifts while completing the time-critical coordination task for multi-UAV systems, we propose a safety constrained bi-level control framework. The first level is the time-critical coordination level that achieves a consensus of coordination states and provides a virtual target which is a function of the coordination state. The second level is the safety-critical control level that is designed to follow the virtual target while adapting the attacked UAV(s) at a path re-planning level to support resilient state estimation. In particular, the time-critical coordination level framework generates the desired speed and position profile of the virtual target based on the multi-UAV cooperative mission by the proposed consensus protocol algorithm. The safety-critical control level is able to make each UAV follow its assigned path while detecting the attacks, estimating the state resiliently, and driving the UAV(s) outside the effective range of the spoofing device within the escape time. The numerical simulations of a three-UAV system demonstrate the effectiveness of the proposed safety constrained bi-level control framework.",
        "published": "2020-05-15T01:06:31Z",
        "link": "http://arxiv.org/abs/2005.07697v2",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Lifelong Multi-Agent Path Finding in Large-Scale Warehouses",
        "authors": [
            "Jiaoyang Li",
            "Andrew Tinka",
            "Scott Kiesel",
            "Joseph W. Durham",
            "T. K. Satish Kumar",
            "Sven Koenig"
        ],
        "summary": "Multi-Agent Path Finding (MAPF) is the problem of moving a team of agents to their goal locations without collisions. In this paper, we study the lifelong variant of MAPF, where agents are constantly engaged with new goal locations, such as in large-scale automated warehouses. We propose a new framework Rolling-Horizon Collision Resolution (RHCR) for solving lifelong MAPF by decomposing the problem into a sequence of Windowed MAPF instances, where a Windowed MAPF solver resolves collisions among the paths of the agents only within a bounded time horizon and ignores collisions beyond it. RHCR is particularly well suited to generating pliable plans that adapt to continually arriving new goal locations. We empirically evaluate RHCR with a variety of MAPF solvers and show that it can produce high-quality solutions for up to 1,000 agents (= 38.9\\% of the empty cells on the map) for simulated warehouse instances, significantly outperforming existing work.",
        "published": "2020-05-15T06:07:15Z",
        "link": "http://arxiv.org/abs/2005.07371v2",
        "categories": [
            "cs.AI",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Coordinated Coverage and Fault Tolerance using Fixed-Wing Unmanned   Aerial Vehicles",
        "authors": [
            "Sachin Shriwastav",
            "Zhuoyuan Song"
        ],
        "summary": "This paper presents an approach for deploying and maintaining a fleet of homogeneous fixed-wing unmanned aerial vehicles (UAVs) for all-time coverage of an area. Two approaches for loiter circle packing have been presented: square and hexagon packing, and the benefits of hexagon packing for minimizing the number of deployed UAVs have been shown. Based on the number of UAVs available and the desired loitering altitude, the proposed algorithm solves an optimization problem to calculate the centres of the loitering circles and the loitering radius for that altitude. The algorithm also incorporates fault recovery capacity in case of simultaneous multiple UAV failures. These failures could form clusters of survivor (active) UAVs over the area with no overall survivor information. The algorithm deploys a super-agent with a larger communication capacity at a higher altitude to recover from the failure. The super-agent collects the information of survivors, and updates the homogeneous radius and the locations of the loitering circles at the same altitude to restore the full coverage. The individual survivor UAVs are then informed and transit to the new loitering circles using Dubin's paths. The relationship with the extent of recoverable loss fractions of the deployed UAVs have been analysed for varying the initial loiter radii. Simulation results have been presented to demonstrate the applicability of the approach and compare the two presented packing approaches.",
        "published": "2020-05-17T03:03:30Z",
        "link": "http://arxiv.org/abs/2005.08153v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Long-term electricity market agent based model validation using genetic   algorithm based optimization",
        "authors": [
            "Alexander J. M. Kell",
            "Matthew Forshaw",
            "A. Stephen McGough"
        ],
        "summary": "Electricity market modelling is often used by governments, industry and agencies to explore the development of scenarios over differing timeframes. For example, how would the reduction in cost of renewable energy impact investments in gas power plants or what would be an optimum strategy for carbon tax or subsidies? Cost optimization based solutions are the dominant approach for understanding different long-term energy scenarios. However, these types of models have certain limitations such as the need to be interpreted in a normative manner, and the assumption that the electricity market remains in equilibrium throughout. Through this work, we show that agent-based models are a viable technique to simulate decentralised electricity markets. The aim of this paper is to validate an agent-based modelling framework to increase confidence in its ability to be used in policy and decision making. Our framework can model heterogeneous agents with imperfect information. The model uses a rules-based approach to approximate the underlying dynamics of a real world, decentralised electricity market. We use the UK as a case study, however, our framework is generalisable to other countries. We increase the temporal granularity of the model by selecting representative days of electricity demand and weather using a $k$-means clustering approach. We show that our framework can model the transition from coal to gas observed in the UK between 2013 and 2018. We are also able to simulate a future scenario to 2035 which is similar to the UK Government, Department for Business and Industrial Strategy (BEIS) projections. We show a more realistic increase in nuclear power over this time period. This is due to the fact that with current nuclear technology, electricity is generated almost instantaneously and has a low short-run marginal cost \\cite{Department2016}.",
        "published": "2020-05-17T10:30:58Z",
        "link": "http://arxiv.org/abs/2005.10346v1",
        "categories": [
            "cs.MA",
            "physics.soc-ph"
        ]
    },
    {
        "title": "On the robustness of equilibria in generalized aggregative games",
        "authors": [
            "Filippo Fabiani",
            "Kostas Margellos",
            "Paul J. Goulart"
        ],
        "summary": "We address the problem of assessing the robustness of the equilibria in uncertain, multi-agent games. Specifically, we focus on generalized Nash equilibrium problems in aggregative form subject to linear coupling constraints affected by uncertainty with a possibly unknown probability distribution. Within a data-driven context, we apply the scenario approach paradigm to provide a-posteriori feasibility certificates for the entire set of generalized Nash equilibria of the game. Then, we show that assessing the violation probability of such set merely requires to enumerate the constraints that ``shape'' it. For the class of aggregative games, this results in solving a feasibility problem on each active facet of the feasibility region, for which we propose a semi-decentralized algorithm. We demonstrate our theoretical results by means of an academic example.",
        "published": "2020-05-19T13:05:51Z",
        "link": "http://arxiv.org/abs/2005.09408v1",
        "categories": [
            "math.OC",
            "cs.GT",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Experience Augmentation: Boosting and Accelerating Off-Policy   Multi-Agent Reinforcement Learning",
        "authors": [
            "Zhenhui Ye",
            "Yining Chen",
            "Guanghua Song",
            "Bowei Yang",
            "Shen Fan"
        ],
        "summary": "Exploration of the high-dimensional state action space is one of the biggest challenges in Reinforcement Learning (RL), especially in multi-agent domain. We present a novel technique called Experience Augmentation, which enables a time-efficient and boosted learning based on a fast, fair and thorough exploration to the environment. It can be combined with arbitrary off-policy MARL algorithms and is applicable to either homogeneous or heterogeneous environments. We demonstrate our approach by combining it with MADDPG and verifing the performance in two homogeneous and one heterogeneous environments. In the best performing scenario, the MADDPG with experience augmentation reaches to the convergence reward of vanilla MADDPG with 1/4 realistic time, and its convergence beats the original model by a significant margin. Our ablation studies show that experience augmentation is a crucial ingredient which accelerates the training process and boosts the convergence.",
        "published": "2020-05-19T13:57:11Z",
        "link": "http://arxiv.org/abs/2005.09453v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "VigiFlood: evaluating the impact of a change of perspective on flood   vigilance",
        "authors": [
            "Carole Adam"
        ],
        "summary": "Emergency managers receive communication training about the importance of being 'first, right and credible', and taking into account the psychology of their audience and their particular reasoning under stress and risk. But we believe that citizens should be similarly trained about how to deal with risk communication. In particular, such messages necessarily carry a part of uncertainty since most natural risks are difficult to accurately forecast ahead of time. Yet, citizens should keep trusting the emergency communicators even after they made forecasting errors in the past.   We have designed a serious game called Vigiflood, based on a real case study of flash floods hitting the South West of France in October 2018. In this game, the user changes perspective by taking the role of an emergency communicator, having to set the level of vigilance to alert the population, based on uncertain clues. Our hypothesis is that this change of perspective can improve the player's awareness and response to future flood vigilance announcements. We evaluated this game through an online survey where people were asked to answer a questionnaire about flood risk awareness and behavioural intentions before and after playing the game, in order to assess its impact.",
        "published": "2020-05-19T14:05:11Z",
        "link": "http://arxiv.org/abs/2005.09460v1",
        "categories": [
            "cs.CY",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Empowering Urban Governance through Urban Science: Multi-scale Dynamics   of Urban Systems Worldwide",
        "authors": [
            "Juste Raimbault",
            "Eric Denis",
            "Denise Pumain"
        ],
        "summary": "The current science of cities can provide a useful foundation for future urban policies, provided that these proposals have been validated by correct observations of the diversity of situations in the world. However, international comparisons of the evolution of cities often produce uncertain results because national territorial frameworks are not always in strict correspondence with the dynamics of urban systems. We propose to provide various compositions of systems of cities to better take into account the dynamic networking of cities that go beyond regional and national territorial boundaries. Different models conceived for explaining city size and urban growth distributions enable to establish a correspondence between urban trajectories when observed at the level of cities and systems of cities. We test the validity and representativeness of several dynamic models of complex urban systems and their variations across regions of the world, at the macroscopic scale of systems of cities. The originality of the approach is in considering spatial interaction and evolutionary path dependence as major features in the general behavior of urban entities. The models studied include diverse and complementary processes, such as economic exchanges, diffusion of innovations and physical network flows. Complex systems' dynamics is in principle unpredictable, but contextualizing it regarding demographic, income and resource components may help in minimizing the forecasting errors.",
        "published": "2020-05-20T12:47:40Z",
        "link": "http://arxiv.org/abs/2005.10007v1",
        "categories": [
            "physics.soc-ph",
            "cs.CY",
            "cs.MA"
        ]
    },
    {
        "title": "User Attention and Behaviour in Virtual Reality Art Encounter",
        "authors": [
            "Mu Mu",
            "Murtada Dohan",
            "Alison Goodyear",
            "Gary Hill",
            "Cleyon Johns",
            "Andreas Mauthe"
        ],
        "summary": "With the proliferation of consumer virtual reality (VR) headsets and creative tools, content creators have started to experiment with new forms of interactive audience experience using immersive media. Understanding user attention and behaviours in virtual environment can greatly inform creative processes in VR. We developed an abstract VR painting and an experimentation system to study audience encounters through eye gaze and movement tracking. The data from a user experiment with 35 participants reveal a range of user activity patterns in art exploration. Deep learning models are used to study the connections between behavioural data and audience background. New integrated methods to visualise user attention as part of the artwork are also developed as a feedback loop to the content creator.",
        "published": "2020-05-20T16:09:57Z",
        "link": "http://arxiv.org/abs/2005.10161v1",
        "categories": [
            "cs.HC",
            "cs.MA",
            "cs.MM"
        ]
    },
    {
        "title": "Causality, Responsibility and Blame in Team Plans",
        "authors": [
            "Natasha Alechina",
            "Joseph Y. Halpern",
            "Brian Logan"
        ],
        "summary": "Many objectives can be achieved (or may be achieved more effectively) only by a group of agents executing a team plan. If a team plan fails, it is often of interest to determine what caused the failure, the degree of responsibility of each agent for the failure, and the degree of blame attached to each agent. We show how team plans can be represented in terms of structural equations, and then apply the definitions of causality introduced by Halpern [2015] and degree of responsibility and blame introduced by Chockler and Halpern [2004] to determine the agent(s) who caused the failure and what their degree of responsibility/blame is. We also prove new results on the complexity of computing causality and degree of responsibility and blame, showing that they can be determined in polynomial time for many team plans of interest.",
        "published": "2020-05-20T18:21:19Z",
        "link": "http://arxiv.org/abs/2005.10297v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Multi-agent model for risk prediction in surgery",
        "authors": [
            "Bruno Perez",
            "Julien Henriet",
            "Christophe Lang",
            "Laurent Philippe"
        ],
        "summary": "Risk management resulting from the actions and states of the different elements making up a operating room is a major concern during a surgical procedure. Agent-based simulation shows an interest through its interaction concepts, interactivity and autonomy of different simulator entities. We want in our study to implement a generator of alerts to listen the evolution of different settings applied to the simulator of agents (human fatigue, material efficiency, infection rate ...). This article presents our model, its implementation and the first results obtained. It should be noted that this study also made it possible to identify several scientific obstacles, such as the integration of different levels of abstraction, the coupling of species, the coexistence of several scales in the same environment and the deduction of unpredictable alerts. Case-based reasoning (CBR) is a beginning of response relative to the last lock mentioned and will be discussed in this paper.",
        "published": "2020-05-21T15:45:27Z",
        "link": "http://arxiv.org/abs/2005.10738v2",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Metaheuristic macro scale traffic flow optimisation from urban movement   data",
        "authors": [
            "Laurens Arp",
            "Dyon van Vreumingen",
            "Daniela Gawehns",
            "Mitra Baratchi"
        ],
        "summary": "How can urban movement data be exploited in order to improve the flow of traffic within a city? Movement data provides valuable information about routes and specific roads that people are likely to drive on. This allows us to pinpoint roads that occur in many routes and are thus sensitive to congestion. Redistributing some of the traffic to avoid unnecessary use of these roads could be a key factor in improving traffic flow. Many proposed approaches to combat congestion are either static or do not incorporate any movement data. In this work, we present a method to redistribute traffic through the introduction of externally imposed variable costs to each road segment, assuming that all drivers seek to drive the cheapest route. We use a metaheuristic optimisation approach to minimise total travel times by optimising a set of road-specific variable cost parameters, which are used as input for an objective function based on traffic flow theory. The optimisation scenario for the city centre of Tokyo considered in this paper was defined using public spatial road network data, and movement data acquired from Foursquare. Experimental results show that our proposed scenario has the potential to achieve a 62.6\\% improvement of total travel time in Tokyo compared to that of a currently operational road network configuration, with no imposed variable costs.",
        "published": "2020-05-22T21:28:38Z",
        "link": "http://arxiv.org/abs/2006.02214v1",
        "categories": [
            "physics.soc-ph",
            "cs.MA",
            "I.2.1; I.5.4"
        ]
    },
    {
        "title": "Mechanisms for Outsourcing Computation via a Decentralized Market",
        "authors": [
            "Scott Eisele",
            "Taha Eghtesad",
            "Nicholas Troutman",
            "Aron Laszka",
            "Abhishek Dubey"
        ],
        "summary": "As the number of personal computing and IoT devices grows rapidly, so does the amount of computational power that is available at the edge. Since many of these devices are often idle, there is a vast amount of computational power that is currently untapped, and which could be used for outsourcing computation. Existing solutions for harnessing this power, such as volunteer computing (e.g., BOINC), are centralized platforms in which a single organization or company can control participation and pricing. By contrast, an open market of computational resources, where resource owners and resource users trade directly with each other, could lead to greater participation and more competitive pricing. To provide an open market, we introduce MODiCuM, a decentralized system for outsourcing computation. MODiCuM deters participants from misbehaving-which is a key problem in decentralized systems-by resolving disputes via dedicated mediators and by imposing enforceable fines. However, unlike other decentralized outsourcing solutions, MODiCuM minimizes computational overhead since it does not require global trust in mediation results. We provide analytical results proving that MODiCuM can deter misbehavior, and we evaluate the overhead of MODiCuM using experimental results based on an implementation of our platform.",
        "published": "2020-05-23T00:00:19Z",
        "link": "http://arxiv.org/abs/2005.11429v2",
        "categories": [
            "cs.DC",
            "cs.MA"
        ]
    },
    {
        "title": "Model-free Reinforcement Learning for Stochastic Stackelberg Security   Games",
        "authors": [
            "Rajesh K Mishra",
            "Deepanshu Vasal",
            "Sriram Vishwanath"
        ],
        "summary": "In this paper, we consider a sequential stochastic Stackelberg game with two players, a leader and a follower. The follower has access to the state of the system while the leader does not. Assuming that the players act in their respective best interests, the follower's strategy is to play the best response to the leader's strategy. In such a scenario, the leader has the advantage of committing to a policy which maximizes its own returns given the knowledge that the follower is going to play the best response to its policy. Thus, both players converge to a pair of policies that form the Stackelberg equilibrium of the game. Recently,~[1] provided a sequential decomposition algorithm to compute the Stackelberg equilibrium for such games which allow for the computation of Markovian equilibrium policies in linear time as opposed to double exponential, as before. In this paper, we extend the idea to an MDP whose dynamics are not known to the players, to propose an RL algorithm based on Expected Sarsa that learns the Stackelberg equilibrium policy by simulating a model of the MDP. We use particle filters to estimate the belief update for a common agent which computes the optimal policy based on the information which is common to both the players. We present a security game example to illustrate the policy learned by our algorithm. by simulating a model of the MDP. We use particle filters to estimate the belief update for a common agent which computes the optimal policy based on the information which is common to both the players. We present a security game example to illustrate the policy learned by our algorithm.",
        "published": "2020-05-24T22:34:20Z",
        "link": "http://arxiv.org/abs/2005.11853v1",
        "categories": [
            "math.OC",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Passivity-based distributed acquisition and station-keeping control of a   satellite constellation in areostationary orbit",
        "authors": [
            "Emmanuel Sin",
            "He Yin",
            "Murat Arcak"
        ],
        "summary": "We present a distributed control law to assemble a cluster of satellites into an equally-spaced, planar constellation in a desired circular orbit about a planet. We assume each satellite only uses local information, transmitted through communication links with neighboring satellites. The same control law is used to maintain relative angular positions in the presence of disturbance forces. The stability of the constellation in the desired orbit is proved using a compositional approach. We first show the existence and uniqueness of an equilibrium of the interconnected system. We then certify each satellite and communication link is equilibrium-independent passive with respective storage functions. By leveraging the skew symmetric coupling structure of the constellation and the equilibrium-independent passivity property of each subsystem, we show that the equilibrium of the interconnected system is stable with a Lyapunov function composed of the individual subsystem storage functions. We further prove that the angular velocity of each satellite converges to the desired value necessary to maintain circular, areostationary orbit. Finally, we present simulation results to demonstrate the efficacy of the proposed control law in acquisition and station-keeping of an equally-spaced satellite constellation in areostationary orbit despite the presence of unmodeled disturbance forces.",
        "published": "2020-05-25T16:32:38Z",
        "link": "http://arxiv.org/abs/2005.12214v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Optimal assignment of collaborating agents in multi-body asset-guarding   games",
        "authors": [
            "Emmanuel Sin",
            "Murat Arcak",
            "Andrew Packard",
            "Douglas Philbrick",
            "Peter Seiler"
        ],
        "summary": "We study a multi-body asset-guarding game in missile defense where teams of interceptor missiles collaborate to defend a non-manuevering asset against a group of threat missiles. We approach the problem in two steps. We first formulate an assignment problem where we optimally assign subsets of collaborating interceptors to each threat so that all threats are intercepted as far away from the asset as possible. We assume that each interceptor is controlled by a collaborative guidance law derived from linear quadratic dynamic games. Our results include a 6-DOF simulation of a 5-interceptor versus 3-threat missile engagement where each agent is modeled as a missile airframe controlled by an autopilot. Despite the assumption of linear dynamics in our collaborative guidance law and the unmodeled dynamics in the simulation environment (e.g., varying density and gravity), we show that the simulated trajectories match well with those predicted by our approach. Furthermore, we show that a more agile threat, with greater speed and acceleration, can be intercepted by inferior interceptors when they collaborate. We believe the concepts introduced in this paper may be applied in asymmetric missile defense scenarios, including defense against advanced cruise missiles and hypersonic vehicles.",
        "published": "2020-05-25T16:57:05Z",
        "link": "http://arxiv.org/abs/2005.12226v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Sustainable and resilient strategies for touristic cities against   COVID-19: an agent-based approach",
        "authors": [
            "Marco D'Orazio",
            "Gabriele Bernardini",
            "Enrico Quagliarini"
        ],
        "summary": "Touristic cities will suffer from COVID-19 emergency because of its economic impact on their communities. The first emergency phases involved a wide closure of such areas to support \"social distancing\" measures (i.e. travels limitation; lockdown of (over)crowd-prone activities). In the second phase, individual's risk-mitigation strategies (facial masks) could be properly linked to \"social distancing\" to ensure re-opening touristic cities to visitors. Simulation tools could support the effectiveness evaluation of risk-mitigation measures to look for an economic and social optimum for activities restarting. This work modifies an existing Agent-Based Model to estimate the virus spreading in touristic areas, including tourists and residents' behaviours, movement and virus effects on them according to a probabilistic approach. Consolidated proximity-based and exposure-time-based contagion spreading rules are included according to international health organizations and previous calibration through experimental data. Effects of tourists' capacity (as \"social distancing\"-based measure) and other strategies (i.e. facial mask implementation) are evaluated depending on virus-related conditions (i.e. initial infector percentages). An idealized scenario representing a significant case study has been analysed to demonstrate the tool capabilities and compare the effectiveness of those solutions. Results show that \"social distancing\" seems to be more effective at the highest infectors' rates, although represents an extreme measure with important economic effects. This measure loses its full effectiveness (on the community) as the infectors' rate decreases and individuals' protection measures become predominant (facial masks). The model could be integrated to consider other recurring issues on tourist-related fruition and schedule of urban spaces and facilities (e.g. cultural/leisure buildings).",
        "published": "2020-05-26T07:17:38Z",
        "link": "http://arxiv.org/abs/2005.12547v1",
        "categories": [
            "physics.soc-ph",
            "cs.CY",
            "cs.MA",
            "J.2; J.3; J.4; I.6.5; I.6.8"
        ]
    },
    {
        "title": "Efficient Use of heuristics for accelerating XCS-based Policy Learning   in Markov Games",
        "authors": [
            "Hao Chen",
            "Chang Wang",
            "Jian Huang",
            "Jianxing Gong"
        ],
        "summary": "In Markov games, playing against non-stationary opponents with learning ability is still challenging for reinforcement learning (RL) agents, because the opponents can evolve their policies concurrently. This increases the complexity of the learning task and slows down the learning speed of the RL agents. This paper proposes efficient use of rough heuristics to speed up policy learning when playing against concurrent learners. Specifically, we propose an algorithm that can efficiently learn explainable and generalized action selection rules by taking advantages of the representation of quantitative heuristics and an opponent model with an eXtended classifier system (XCS) in zero-sum Markov games. A neural network is used to model the opponent from their behaviors and the corresponding policy is inferred for action selection and rule evolution. In cases of multiple heuristic policies, we introduce the concept of Pareto optimality for action selection. Besides, taking advantages of the condition representation and matching mechanism of XCS, the heuristic policies and the opponent model can provide guidance for situations with similar feature representation. Furthermore, we introduce an accuracy-based eligibility trace mechanism to speed up rule evolution, i.e., classifiers that can match the historical traces are reinforced according to their accuracy. We demonstrate the advantages of the proposed algorithm over several benchmark algorithms in a soccer and a thief-and-hunter scenarios.",
        "published": "2020-05-26T07:47:27Z",
        "link": "http://arxiv.org/abs/2005.12553v1",
        "categories": [
            "cs.AI",
            "cs.GT",
            "cs.MA",
            "cs.NE"
        ]
    },
    {
        "title": "Tight Bounds for Deterministic High-Dimensional Grid Exploration",
        "authors": [
            "Sebastian Brandt",
            "Julian Portmann",
            "Jara Uitto"
        ],
        "summary": "We study the problem of exploring an oriented grid with autonomous agents governed by finite automata. In the case of a 2-dimensional grid, the question how many agents are required to explore the grid, or equivalently, find a hidden treasure in the grid, is fully understood in both the synchronous and the semi-synchronous setting. For higher dimensions, Dobrev, Narayanan, Opatrny, and Pankratov [ICALP'19] showed very recently that, surprisingly, a (small) constant number of agents suffices to find the treasure, independent of the number of dimensions, thereby disproving a conjecture by Cohen, Emek, Louidor, and Uitto [SODA'17]. Dobrev et al. left as an open question whether their bounds on the number of agents can be improved. We answer this question in the affirmative for deterministic finite automata: we show that 3 synchronous and 4 semi-synchronous agents suffice to explore an $n$-dimensional grid for any constant $n$. The bounds are optimal and notably, the matching lower bounds already hold in the 2-dimensional case.   Our techniques can also be used to make progress on other open questions asked by Dobrev et al.: we prove that 4 synchronous and 5 semi-synchronous agents suffice for polynomial-time exploration, and we show that, under a natural assumption, 3 synchronous and 4 semi-synchronous agents suffice to explore unoriented grids of arbitrary dimension (which, again, is tight).",
        "published": "2020-05-26T10:48:00Z",
        "link": "http://arxiv.org/abs/2005.12623v1",
        "categories": [
            "cs.DC",
            "cs.MA"
        ]
    },
    {
        "title": "On the Impossibility of Global Convergence in Multi-Loss Optimization",
        "authors": [
            "Alistair Letcher"
        ],
        "summary": "Under mild regularity conditions, gradient-based methods converge globally to a critical point in the single-loss setting. This is known to break down for vanilla gradient descent when moving to multi-loss optimization, but can we hope to build some algorithm with global guarantees? We negatively resolve this open problem by proving that desirable convergence properties cannot simultaneously hold for any algorithm. Our result has more to do with the existence of games with no satisfactory outcomes, than with algorithms per se. More explicitly we construct a two-player game with zero-sum interactions whose losses are both coercive and analytic, but whose only simultaneous critical point is a strict maximum. Any 'reasonable' algorithm, defined to avoid strict maxima, will therefore fail to converge. This is fundamentally different from single losses, where coercivity implies existence of a global minimum. Moreover, we prove that a wide range of existing gradient-based methods almost surely have bounded but non-convergent iterates in a constructed zero-sum game for suitably small learning rates. It nonetheless remains an open question whether such behavior can arise in high-dimensional games of interest to ML practitioners, such as GANs or multi-agent RL.",
        "published": "2020-05-26T12:11:18Z",
        "link": "http://arxiv.org/abs/2005.12649v3",
        "categories": [
            "math.OC",
            "cs.GT",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Agent-Based Simulation of Collective Cooperation: From Experiment to   Model",
        "authors": [
            "Benedikt Kleinmeier",
            "Gerta Köster",
            "John Drury"
        ],
        "summary": "Simulation models of pedestrian dynamics have become an invaluable tool for evacuation planning. Typically crowds are assumed to stream unidirectionally towards a safe area. Simulated agents avoid collisions through mechanisms that belong to each individual, such as being repelled from each other by imaginary forces. But classic locomotion models fail when collective cooperation is called for, notably when an agent, say a first-aid attendant, needs to forge a path through a densely packed group. We present a controlled experiment to observe what happens when humans pass through a dense static crowd. We formulate and test hypothesis on salient phenomena. We discuss our observations in a psychological framework. We derive a model that incorporates: agents' perception and cognitive processing of a situation that needs cooperation; selection from a portfolio of behaviours, such as being cooperative; and a suitable action, such as swapping places. Agents' ability to successfully get through a dense crowd emerges as an effect of the psychological model.",
        "published": "2020-05-26T13:29:08Z",
        "link": "http://arxiv.org/abs/2005.12712v2",
        "categories": [
            "cs.MA",
            "cs.CY"
        ]
    },
    {
        "title": "Time-Independent Planning for Multiple Moving Agents",
        "authors": [
            "Keisuke Okumura",
            "Yasumasa Tamura",
            "Xavier Défago"
        ],
        "summary": "Typical Multi-agent Path Finding (MAPF) solvers assume that agents move synchronously, thus neglecting the reality gap in timing assumptions, e.g., delays caused by an imperfect execution of asynchronous moves. So far, two policies enforce a robust execution of MAPF plans taken as input: either by forcing agents to synchronize or by executing plans while preserving temporal dependencies. This paper proposes an alternative approach, called time-independent planning, which is both online and distributed. We represent reality as a transition system that changes configurations according to atomic actions of agents, and use it to generate a time-independent schedule. Empirical results in a simulated environment with stochastic delays of agents' moves support the validity of our proposal.",
        "published": "2020-05-27T06:16:15Z",
        "link": "http://arxiv.org/abs/2005.13187v3",
        "categories": [
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Stochastic Potential Games",
        "authors": [
            "David Mguni"
        ],
        "summary": "Computing the Nash equilibrium (NE) for N-player non-zerosum stochastic games is a formidable challenge. Currently, algorithmic methods in stochastic game theory are unable to compute NE for stochastic games (SGs) for settings in all but extreme cases in which the players either play as a team or have diametrically opposed objectives in a two-player setting. This greatly impedes the application of the SG framework to numerous problems within economics and practical systems of interest. In this paper, we provide a method of computing Nash equilibria in nonzero-sum settings and for populations of players more than two. In particular, we identify a subset of SGs known as stochastic potential games (SPGs) for which the (Markov perfect) Nash equilibrium can be computed tractably and in polynomial time. Unlike SGs for which, in general, computing the NE is PSPACE-hard, we show that SGs with the potential property are P-Complete. We further demonstrate that for each SPG there is a dual Markov decision process whose solution coincides with the MP-NE of the SPG. We lastly provide algorithms that tractably compute the MP-NE for SGs with more than two players.",
        "published": "2020-05-27T17:53:49Z",
        "link": "http://arxiv.org/abs/2005.13527v2",
        "categories": [
            "math.OC",
            "cs.MA"
        ]
    },
    {
        "title": "Revisiting Parameter Sharing in Multi-Agent Deep Reinforcement Learning",
        "authors": [
            "J. K. Terry",
            "Nathaniel Grammel",
            "Sanghyun Son",
            "Benjamin Black",
            "Aakriti Agrawal"
        ],
        "summary": "Parameter sharing, where each agent independently learns a policy with fully shared parameters between all policies, is a popular baseline method for multi-agent deep reinforcement learning. Unfortunately, since all agents share the same policy network, they cannot learn different policies or tasks. This issue has been circumvented experimentally by adding an agent-specific indicator signal to observations, which we term \"agent indication\". Agent indication is limited, however, in that without modification it does not allow parameter sharing to be applied to environments where the action spaces and/or observation spaces are heterogeneous. This work formalizes the notion of agent indication and proves that it enables convergence to optimal policies for the first time. Next, we formally introduce methods to extend parameter sharing to learning in heterogeneous observation and action spaces, and prove that these methods allow for convergence to optimal policies. Finally, we experimentally confirm that the methods we introduce function empirically, and conduct a wide array of experiments studying the empirical efficacy of many different agent indication schemes for image based observation spaces.",
        "published": "2020-05-27T20:14:28Z",
        "link": "http://arxiv.org/abs/2005.13625v8",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Tensor Decomposition for Multi-agent Predictive State Representation",
        "authors": [
            "Bilian Chen",
            "Biyang Ma",
            "Yifeng Zeng",
            "Langcai Cao",
            "Jing Tang"
        ],
        "summary": "Predictive state representation~(PSR) uses a vector of action-observation sequence to represent the system dynamics and subsequently predicts the probability of future events. It is a concise knowledge representation that is well studied in a single-agent planning problem domain. To the best of our knowledge, there is no existing work on using PSR to solve multi-agent planning problems. Learning a multi-agent PSR model is quite difficult especially with the increasing number of agents, not to mention the complexity of a problem domain. In this paper, we resort to tensor techniques to tackle the challenging task of multi-agent PSR model development problems. By first focusing on a two-agent setting, we construct the system dynamics matrix as a high order tensor for a PSR model, learn the prediction parameters and deduce state vectors directly through two different tensor decomposition methods respectively, and derive the transition parameters via linear regression. Subsequently, we generalize the PSR learning approaches in a multi-agent setting. Experimental results show that our methods can effectively solve multi-agent PSR modelling problems in multiple problem domains.",
        "published": "2020-05-27T23:19:18Z",
        "link": "http://arxiv.org/abs/2005.13706v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "OPRA: An Open-Source Online Preference Reporting and Aggregation System",
        "authors": [
            "Yiwei Chen",
            "Jingwen Qian",
            "Junming Wang",
            "Lirong Xia",
            "Gavriel Zahavi"
        ],
        "summary": "We introduce the Online Preference Reporting and Aggregation (OPRA) system, an open-source online system that aims at providing support for group decision-making. We illustrate OPRA's distinctive features: UI for reporting rankings with ties, comprehensive analytics of preferences, and group decision-making in combinatorial domains. We also discuss our work in an automatic mentor matching system. We hope that the open-source nature of OPRA will foster the development of computerized group decision support systems.",
        "published": "2020-05-28T00:16:54Z",
        "link": "http://arxiv.org/abs/2005.13714v1",
        "categories": [
            "cs.MA",
            "cs.HC"
        ]
    },
    {
        "title": "Evaluation of the general applicability of Dragoon for the k-center   problem",
        "authors": [
            "Tobias Uhlig",
            "Peter Hillmann",
            "Oliver Rose"
        ],
        "summary": "The k-center problem is a fundamental problem we often face when considering complex service systems. Typical challenges include the placement of warehouses in logistics or positioning of servers for content delivery networks. We previously have proposed Dragoon as an effective algorithm to approach the k-center problem. This paper evaluates Dragoon with a focus on potential worst case behavior in comparison to other techniques. We use an evolutionary algorithm to generate instances of the k-center problem that are especially challenging for Dragoon. Ultimately, our experiments confirm the previous good results of Dragoon, however, we also can reliably find scenarios where it is clearly outperformed by other approaches.",
        "published": "2020-05-28T16:54:17Z",
        "link": "http://arxiv.org/abs/2006.00917v1",
        "categories": [
            "cs.DC",
            "cs.AI",
            "cs.CC",
            "cs.MA",
            "cs.NE"
        ]
    },
    {
        "title": "Task-Oriented Data Compression for Multi-Agent Communications Over   Bit-Budgeted Channels",
        "authors": [
            "Arsham Mostaani",
            "Thang X. Vu",
            "Symeon Chatzinotas",
            "Björn Ottersten"
        ],
        "summary": "Various applications for inter-machine communications are on the rise. Whether it is for autonomous driving vehicles or the internet of everything, machines are more connected than ever to improve their performance in fulfilling a given task. While in traditional communications the goal has often been to reconstruct the underlying message, under the emerging task-oriented paradigm, the goal of communication is to enable the receiving end to make more informed decisions or more precise estimates/computations. Motivated by these recent developments, in this paper, we perform an indirect design of the communications in a multi-agent system (MAS) in which agents cooperate to maximize the averaged sum of discounted one-stage rewards of a collaborative task. Due to the bit-budgeted communications between the agents, each agent should efficiently represent its local observation and communicate an abstracted version of the observations to improve the collaborative task performance. We first show that this problem can be approximated as a form of data-quantization problem which we call task-oriented data compression (TODC). We then introduce the state-aggregation for information compression algorithm (SAIC) to solve the formulated TODC problem. It is shown that SAIC is able to achieve near-optimal performance in terms of the achieved sum of discounted rewards. The proposed algorithm is applied to a geometric consensus problem and its performance is compared with several benchmarks. Numerical experiments confirm the promise of this indirect design approach for task-oriented multi-agent communications.",
        "published": "2020-05-28T18:29:21Z",
        "link": "http://arxiv.org/abs/2005.14220v5",
        "categories": [
            "cs.IT",
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "math.IT"
        ]
    },
    {
        "title": "A Hierarchical Collision Avoidance Architecture for Multiple Fixed-Wing   UAVs in an Integrated Airspace",
        "authors": [
            "Yajing Wang",
            "Xiangke Wang",
            "Shulong Zhao",
            "Lincheng Shen"
        ],
        "summary": "This paper studies the collision avoidance problem for autonomous multiple fixedwing UAVs in the complex integrated airspace. By studying and combining the online path planning method, the distributed model predictive control algorithm, and the geometric reactive control approach, a three-layered collision avoidance system integrating conflict detection and resolution procedures is developed for multiple fixed-wing UAVs modeled by unicycle kinematics subject to input constraints. The effectiveness of the proposed methodology is evaluated and validated via test results of comparative simulations under both deterministic and probabilistic sensing conditions.",
        "published": "2020-05-29T08:59:43Z",
        "link": "http://arxiv.org/abs/2005.14455v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Egalitarian and Just Digital Currency Networks",
        "authors": [
            "Gal Shahaf",
            "Ehud Shapiro",
            "Nimrod Talmon"
        ],
        "summary": "Cryptocurrencies are a digital medium of exchange with decentralized control that renders the community operating the cryptocurrency its sovereign. Leading cryptocurrencies use proof-of-work or proof-of-stake to reach consensus, thus are inherently plutocratic. This plutocracy is reflected not only in control over execution, but also in the distribution of new wealth, giving rise to ``rich get richer'' phenomena. Here, we explore the possibility of an alternative digital currency that is egalitarian in control and just in the distribution of created wealth. Such currencies can form and grow in grassroots and sybil-resilient way. A single currency community can achieve distributive justice by egalitarian coin minting, whereby each member mints one coin at every time step. Egalitarian minting results, in the limit, in the dilution of any inherited assets and in each member having an equal share of the minted currency, adjusted by the relative productivity of the members. Our main theorem shows that a currency network, where agents can be members of more than one currency community, can achieve distributive justice globally across the network by joint egalitarian minting, whereby each agent mints one coin in only one community at each timestep. Specifically, we show that a sufficiently large intersection between two communities -- relative to the gap in their productivity -- will cause the exchange rates between their currencies to converge to 1:1, resulting in global distributive justice.",
        "published": "2020-05-29T15:49:14Z",
        "link": "http://arxiv.org/abs/2005.14631v3",
        "categories": [
            "q-fin.GN",
            "cs.GT",
            "cs.MA",
            "cs.SI"
        ]
    },
    {
        "title": "When2com: Multi-Agent Perception via Communication Graph Grouping",
        "authors": [
            "Yen-Cheng Liu",
            "Junjiao Tian",
            "Nathaniel Glaser",
            "Zsolt Kira"
        ],
        "summary": "While significant advances have been made for single-agent perception, many applications require multiple sensing agents and cross-agent communication due to benefits such as coverage and robustness. It is therefore critical to develop frameworks which support multi-agent collaborative perception in a distributed and bandwidth-efficient manner. In this paper, we address the collaborative perception problem, where one agent is required to perform a perception task and can communicate and share information with other agents on the same task. Specifically, we propose a communication framework by learning both to construct communication groups and decide when to communicate. We demonstrate the generalizability of our framework on two different perception tasks and show that it significantly reduces communication bandwidth while maintaining superior performance.",
        "published": "2020-05-30T04:41:32Z",
        "link": "http://arxiv.org/abs/2006.00176v2",
        "categories": [
            "cs.CV",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Quantization Games on Social Networks and Language Evolution",
        "authors": [
            "Ankur Mani",
            "Lav R. Varshney",
            "Alex",
            "Pentland"
        ],
        "summary": "We consider a strategic network quantizer design setting where agents must balance fidelity in representing their local source distributions against their ability to successfully communicate with other connected agents. We study the problem as a network game and show existence of Nash equilibrium quantizers. For any agent, under Nash equilibrium, the word representing a given partition region is the conditional expectation of the mixture of local and social source probability distributions within the region. Since having knowledge of the original source of information in the network may not be realistic, we show that under certain conditions, the agents need not know the source origin and yet still settle on a Nash equilibrium using only the observed sources. Further, the network may converge to equilibrium through a distributed version of the Lloyd-Max algorithm. In contrast to traditional results in the evolution of language, we find several vocabularies may coexist in the Nash equilibrium, with each individual having exactly one of these vocabularies. The overlap between vocabularies is high for individuals that communicate frequently and have similar local sources. Finally, we argue that error in translation along a chain of communication does not grow if and only if the chain consists of agents with shared vocabulary. Numerical results are given.",
        "published": "2020-05-31T18:48:22Z",
        "link": "http://arxiv.org/abs/2006.00584v1",
        "categories": [
            "cs.IT",
            "cs.MA",
            "eess.SP",
            "math.IT"
        ]
    },
    {
        "title": "Towards Understanding Cooperative Multi-Agent Q-Learning with Value   Factorization",
        "authors": [
            "Jianhao Wang",
            "Zhizhou Ren",
            "Beining Han",
            "Jianing Ye",
            "Chongjie Zhang"
        ],
        "summary": "Value factorization is a popular and promising approach to scaling up multi-agent reinforcement learning in cooperative settings, which balances the learning scalability and the representational capacity of value functions. However, the theoretical understanding of such methods is limited. In this paper, we formalize a multi-agent fitted Q-iteration framework for analyzing factorized multi-agent Q-learning. Based on this framework, we investigate linear value factorization and reveal that multi-agent Q-learning with this simple decomposition implicitly realizes a powerful counterfactual credit assignment, but may not converge in some settings. Through further analysis, we find that on-policy training or richer joint value function classes can improve its local or global convergence properties, respectively. Finally, to support our theoretical implications in practical realization, we conduct an empirical analysis of state-of-the-art deep multi-agent Q-learning algorithms on didactic examples and a broad set of StarCraft II unit micromanagement tasks.",
        "published": "2020-05-31T19:14:03Z",
        "link": "http://arxiv.org/abs/2006.00587v5",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Learning Distributed Controllers for V-Formation",
        "authors": [
            "Shouvik Roy",
            "Usama Mehmood",
            "Radu Grosu",
            "Scott A. Smolka",
            "Scott D. Stoller",
            "Ashish Tiwari"
        ],
        "summary": "We show how a high-performing, fully distributed and symmetric neural V-formation controller can be synthesized from a Centralized MPC (Model Predictive Control) controller using Deep Learning. This result is significant as we also establish that under very reasonable conditions, it is impossible to achieve V-formation using a deterministic, distributed, and symmetric controller. The learning process we use for the neural V-formation controller is significantly enhanced by CEGkR, a Counterexample-Guided k-fold Retraining technique we introduce, which extends prior work in this direction in important ways. Our experimental results show that our neural V-formation controller generalizes to a significantly larger number of agents than for which it was trained (from 7 to 15), and exhibits substantial speedup over the MPC-based controller. We use a form of statistical model checking to compute confidence intervals for our neural V-formation controller's convergence rate and time to convergence.",
        "published": "2020-06-01T02:56:19Z",
        "link": "http://arxiv.org/abs/2006.00680v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "A novel approach for multi-agent cooperative pursuit to capture grouped   evaders",
        "authors": [
            "Muhammad Zuhair Qadir",
            "Songhao Piao",
            "Haiyang Jiang",
            "Mohammed El Habib Souidi"
        ],
        "summary": "An approach of mobile multi-agent pursuit based on application of self-organizing feature map (SOFM) and along with that reinforcement learning based on agent group role membership function (AGRMF) model is proposed. This method promotes dynamic organization of the pursuers' groups and also makes pursuers' group evader according to their desire based on SOFM and AGRMF techniques. This helps to overcome the shortcomings of the pursuers that they cannot fully reorganize when the goal is too independent in process of AGRMF models operation. Besides, we also discuss a new reward function. After the formation of the group, reinforcement learning is applied to get the optimal solution for each agent. The results of each step in capturing process will finally affect the AGR membership function to speed up the convergence of the competitive neural network. The experiments result shows that this approach is more effective for the mobile agents to capture evaders.",
        "published": "2020-06-01T15:39:58Z",
        "link": "http://arxiv.org/abs/2006.01022v2",
        "categories": [
            "cs.AI",
            "cs.GT",
            "cs.LG",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Fault-Tolerant Distributed-Ledger Implementation of Digital Social   Contracts",
        "authors": [
            "Ouri Poupko",
            "Ehud Shapiro",
            "Nimrod Talmon"
        ],
        "summary": "A companion paper defined the notion of digital social contracts, presented a design for a social-contracts programming language, and demonstrated its potential utility via example social contracts. The envisioned setup consists of people with genuine identifiers, which are unique and singular cryptographic key pairs, that operate software agents thus identified on their mobile device. The abstract model of digital social contracts consists of a transition system specifying concurrent, non-deterministic asynchronous agents that operate on a shared ledger by performing digital speech acts, which are cryptographically-signed sequentially-indexed digital actions. Here, we address the distributed-ledger implementation of digital social contracts in the presence of faulty agents: we present a design of a fault-tolerant distributed-ledger transition system and show that it implements the abstract shared-ledger model of digital social contracts, and discuss its resilience to faulty agents. The result is a novel ledger architecture that is distributed with a blockchain-per-person (as opposed to centralized with one blockchain for all), partially-ordered (as opposed to totally-ordered), locally-replicated (as opposed to globally-replicated), asynchronous (as opposed to globally-synchronized), peer-to-peer with each agent being both an actor and a validator (as opposed to having dedicated miners, validators, and clients), environmentally-friendly (as opposed to the environmentally-harmful Proof-of-Work), self-sufficient (as opposed to the energy-hogging Proof-of-Work or capital-hogging Proof-of-Stake) and egalitarian (as opposed to the plutocratic Proof-of-Work and Proof-of-Stake).",
        "published": "2020-06-01T15:53:25Z",
        "link": "http://arxiv.org/abs/2006.01029v7",
        "categories": [
            "cs.DC",
            "cs.MA"
        ]
    },
    {
        "title": "Crowd simulation for crisis management: the outcomes of the last decade",
        "authors": [
            "George Sidiropoulos",
            "Chairi Kiourt",
            "Lefteris Moussiades"
        ],
        "summary": "The last few decades, crowd simulation for crisis management is highlighted as an important topic of interest for many scientific fields. As the continues evolution of computational resources increases, along with the capabilities of Artificial Intelligence, the demand for better and more realistic simulation has become more attractive and popular to scientists. Along those years, there have been published hundreds of research articles and have been created numerous different systems that aim to simulate crowd behaviors, crisis cases and emergency evacuation scenarios. For better outcomes, recent research has focused on the separation of the problem of crisis management, to multiple research sub-fields (categories), such as the navigation of the simulated pedestrians, their psychology, the group dynamics etc. There have been extended research works suggesting new methods and techniques for those categories of problems. In this paper, we propose three main research categories, each one consist of several sub-categories, relying on crowd simulation for crisis management aspects and we present the outcomes of the last decade, focusing mostly on works exploiting multi-agent technologies. We analyze a number of technologies, methodologies, techniques, tools and systems introduced throughout the last years. A comparative review and discussion of the proposed categories is presented towards the identification of the most efficient aspects of the proposed categories. A general framework, towards the future crowd simulation for crisis management is presented based on the most efficient to yield the most realistic outcomes of the last decades. The paper is concluded with some highlights and open questions for future directions.",
        "published": "2020-06-01T19:38:47Z",
        "link": "http://arxiv.org/abs/2006.01216v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Multi-Agent Determinantal Q-Learning",
        "authors": [
            "Yaodong Yang",
            "Ying Wen",
            "Liheng Chen",
            "Jun Wang",
            "Kun Shao",
            "David Mguni",
            "Weinan Zhang"
        ],
        "summary": "Centralized training with decentralized execution has become an important paradigm in multi-agent learning. Though practical, current methods rely on restrictive assumptions to decompose the centralized value function across agents for execution. In this paper, we eliminate this restriction by proposing multi-agent determinantal Q-learning. Our method is established on Q-DPP, an extension of determinantal point process (DPP) with partition-matroid constraint to multi-agent setting. Q-DPP promotes agents to acquire diverse behavioral models; this allows a natural factorization of the joint Q-functions with no need for \\emph{a priori} structural constraints on the value function or special network architectures. We demonstrate that Q-DPP generalizes major solutions including VDN, QMIX, and QTRAN on decentralizable cooperative tasks. To efficiently draw samples from Q-DPP, we adopt an existing sample-by-projection sampler with theoretical approximation guarantee. The sampler also benefits exploration by coordinating agents to cover orthogonal directions in the state space during multi-agent training. We evaluate our algorithm on various cooperative benchmarks; its effectiveness has been demonstrated when compared with the state-of-the-art.",
        "published": "2020-06-02T09:32:48Z",
        "link": "http://arxiv.org/abs/2006.01482v4",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Coordinating Multiagent Industrial Symbiosis",
        "authors": [
            "Vahid Yazdanpanah",
            "Devrim Murat Yazan",
            "W. Henk M. Zijm"
        ],
        "summary": "We present a formal multiagent framework for coordinating a class of collaborative industrial practices called Industrial Symbiotic Networks (ISNs) as cooperative games. The game-theoretic formulation of ISNs enables systematic reasoning about what we call the ISN implementation problem. Specifically, the characteristics of ISNs may lead to the inapplicability of standard fair and stable benefit allocation methods. Inspired by realistic ISN scenarios and following the literature on normative multiagent systems, we consider regulations and normative socio-economic policies as coordination instruments that in combination with ISN games resolve the situation. In this multiagent system, employing Marginal Contribution Nets (MC-Nets) as rule-based cooperative game representations foster the combination of regulations and ISN games with no loss in expressiveness. We develop algorithmic methods for generating regulations that ensure the implementability of ISNs and as a policy support, present the policy requirements that guarantee the implementability of all the desired ISNs in a balanced-budget way.",
        "published": "2020-06-02T17:05:43Z",
        "link": "http://arxiv.org/abs/2006.01784v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.GT"
        ]
    },
    {
        "title": "ALADIN-$α$ -- An open-source MATLAB toolbox for distributed   non-convex optimization",
        "authors": [
            "Alexander Engelmann",
            "Yuning Jiang",
            "Henrieke Benner",
            "Ruchuan Ou",
            "Boris Houska",
            "Timm Faulwasser"
        ],
        "summary": "This paper introduces an open-source software for distributed and decentralized non-convex optimization named ALADIN-$\\alpha$. ALADIN-$\\alpha$ is a MATLAB implementation of tailored variants of the Augmented Lagrangian Alternating Direction Inexact Newton (ALADIN) algorithm. Its user interface is convenient for rapid prototyping of non-convex distributed optimization algorithms. An improved version of the recently proposed bi-level variant of ALADIN is included enabling decentralized non-convex optimization with reduced information exchange. A collection of examples from different applications fields including chemical engineering, robotics, and power systems underpins the potential of ALADIN-$\\alpha$.",
        "published": "2020-06-02T18:31:07Z",
        "link": "http://arxiv.org/abs/2006.01866v2",
        "categories": [
            "eess.SY",
            "cs.DC",
            "cs.MA",
            "cs.SY",
            "math.OC"
        ]
    },
    {
        "title": "Asynchronous Distributed Averaging: A Switched System Framework for   Average Error Analysis",
        "authors": [
            "Kooktae Lee"
        ],
        "summary": "This paper investigates an expected average error for distributed averaging problems under asynchronous updates. The asynchronism in this context implies no existence of a global clock as well as random characteristics in communication uncertainty such as communication delays and packet drops. Although some previous works contributed to the design of average consensus protocols to guarantee the convergence to an exact average, these methods may increase computational burdens due to extra works. Sometimes it is thus beneficial to make each agent exchange information asynchronously without modifying the algorithm, which causes randomness in the average value as a trade-off. In this study, an expected average error is analyzed based on the switched system framework, to estimate an upper bound of the asynchronous average compared to the exact one in the expectation sense. Numerical examples are provided to validate the proposed results.",
        "published": "2020-06-02T20:17:59Z",
        "link": "http://arxiv.org/abs/2006.01925v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "A Maximum Mutual Information Framework for Multi-Agent Reinforcement   Learning",
        "authors": [
            "Woojun Kim",
            "Whiyoung Jung",
            "Myungsik Cho",
            "Youngchul Sung"
        ],
        "summary": "In this paper, we propose a maximum mutual information (MMI) framework for multi-agent reinforcement learning (MARL) to enable multiple agents to learn coordinated behaviors by regularizing the accumulated return with the mutual information between actions. By introducing a latent variable to induce nonzero mutual information between actions and applying a variational bound, we derive a tractable lower bound on the considered MMI-regularized objective function. Applying policy iteration to maximize the derived lower bound, we propose a practical algorithm named variational maximum mutual information multi-agent actor-critic (VM3-AC), which follows centralized learning with decentralized execution (CTDE). We evaluated VM3-AC for several games requiring coordination, and numerical results show that VM3-AC outperforms MADDPG and other MARL algorithms in multi-agent tasks requiring coordination.",
        "published": "2020-06-04T09:43:52Z",
        "link": "http://arxiv.org/abs/2006.02732v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "LFC: Combining Autonomous Agents and Automated Planning in the   Multi-Agent Programming Contest",
        "authors": [
            "Rafael C. Cardoso",
            "Angelo Ferrando",
            "Fabio Papacchini"
        ],
        "summary": "The 2019 Multi-Agent Programming Contest introduced a new scenario, Agents Assemble, where two teams of agents move around a 2D grid and compete to assemble complex block structures. In this paper, we describe the strategies used by our team that led us to achieve first place in the contest. Our strategies tackle some of the major challenges in the 2019 contest: how to explore and build a map when agents only have access to local vision and no global coordinates; how to move around the map efficiently even though there are dynamic events that can change the cells in the grid; and how to assemble and submit complex block structures given that the opposing team may try to sabotage us. To implement our strategies, we use the multi-agent systems development platform JaCaMo to program our agents and the Fast Downward planner to plan the movement of the agent in the grid. We also provide a brief discussion of our matches in the contest and give our analysis of how our team performed in each match.",
        "published": "2020-06-04T09:48:51Z",
        "link": "http://arxiv.org/abs/2006.02736v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "The Multi-Agent Programming Contest: A résumé",
        "authors": [
            "Tobias Ahlbrecht",
            "Jürgen Dix",
            "Niklas Fiekas",
            "Tabajara Krausburg"
        ],
        "summary": "The Multi-Agent Programming Contest, MAPC, is an annual event organized since 2005 out of Clausthal University of Technology. Its aim is to investigate the potential of using decentralized, autonomously acting intelligent agents, by providing a complex scenario to be solved in a competitive environment. For this we need suitable benchmarks where agent-based systems can shine. We present previous editions of the contest and also its current scenario and results from its use in the 2019 MAPC with a special focus on its suitability. We conclude with lessons learned over the years.",
        "published": "2020-06-04T10:00:51Z",
        "link": "http://arxiv.org/abs/2006.02739v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "The Requirement Gatherers' Approach to the 2019 Multi-Agent Programming   Contest Scenario",
        "authors": [
            "Michael Vezina",
            "Babak Esfandiari"
        ],
        "summary": "The 2019 Multi-Agent Programming Contest (MAPC) scenario poses many challenges for agents participating in the contest. We discuss The Requirement Gatherers' (TRG) approach to handling the various challenges we faced -- including how we designed our system, how we went about debugging our agents, and the strategy we employed to each of our agents. We conclude the paper with remarks about the performance of our agents, and what we should have done differently.",
        "published": "2020-06-04T12:23:41Z",
        "link": "http://arxiv.org/abs/2006.02816v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Simulating COVID-19 in a University Environment",
        "authors": [
            "Philip T. Gressman",
            "Jennifer R. Peck"
        ],
        "summary": "Residential colleges and universities face unique challenges in providing in-person instruction during the COVID-19 pandemic. Administrators are currently faced with decisions about whether to open during the pandemic and what modifications of their normal operations might be necessary to protect students, faculty and staff. There is little information, however, on what measures are likely to be most effective and whether existing interventions could contain the spread of an outbreak on campus. We develop a full-scale stochastic agent-based model to determine whether in-person instruction could safely continue during the pandemic and evaluate the necessity of various interventions. Simulation results indicate that large scale randomized testing, contact-tracing, and quarantining are important components of a successful strategy for containing campus outbreaks. High test specificity is critical for keeping the size of the quarantine population manageable. Moving the largest classes online is also crucial for controlling both the size of outbreaks and the number of students in quarantine. Increased residential exposure can significantly impact the size of an outbreak, but it is likely more important to control non-residential social exposure among students. Finally, necessarily high quarantine rates even in controlled outbreaks imply significant absenteeism, indicating a need to plan for remote instruction of quarantined students.",
        "published": "2020-06-05T00:04:03Z",
        "link": "http://arxiv.org/abs/2006.03175v2",
        "categories": [
            "q-bio.PE",
            "cs.MA",
            "cs.SI",
            "physics.soc-ph"
        ]
    },
    {
        "title": "Conflict-Based Search for Connected Multi-Agent Path Finding",
        "authors": [
            "Arthur Queffelec",
            "Ocan Sankur",
            "François Schwarzentruber"
        ],
        "summary": "We study a variant of the multi-agent path finding problem (MAPF) in which agents are required to remain connected to each other and to a designated base. This problem has applications in search and rescue missions where the entire execution must be monitored by a human operator. We re-visit the conflict-based search algorithm known for MAPF, and define a variant where conflicts arise from disconnections rather than collisions. We study optimizations, and give experimental results in which we compare our algorithms with the literature.",
        "published": "2020-06-05T08:02:36Z",
        "link": "http://arxiv.org/abs/2006.03280v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Logical Team Q-learning: An approach towards factored policies in   cooperative MARL",
        "authors": [
            "Lucas Cassano",
            "Ali H. Sayed"
        ],
        "summary": "We address the challenge of learning factored policies in cooperative MARL scenarios. In particular, we consider the situation in which a team of agents collaborates to optimize a common cost. The goal is to obtain factored policies that determine the individual behavior of each agent so that the resulting joint policy is optimal. The main contribution of this work is the introduction of Logical Team Q-learning (LTQL). LTQL does not rely on assumptions about the environment and hence is generally applicable to any collaborative MARL scenario. We derive LTQL as a stochastic approximation to a dynamic programming method we introduce in this work. We conclude the paper by providing experiments (both in the tabular and deep settings) that illustrate the claims.",
        "published": "2020-06-05T17:02:36Z",
        "link": "http://arxiv.org/abs/2006.03553v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "stat.ML"
        ]
    },
    {
        "title": "Leadership emergence in walking groups",
        "authors": [
            "Maria Lombardi",
            "William H. Warren",
            "M. di Bernardo"
        ],
        "summary": "Understanding the mechanisms underlying the emergence of leadership in multi-agent systems is still under investigation in many areas of research where group coordination is involved. While leadership has been mostly investigated in the case of animal groups, only a few works address the problem of leadership emergence in human ensembles, e.g. pedestrian walking, group dance. In this paper we study the emergence of leadership in the specific scenario of a small walking group. Our aim is to unveil the main mechanisms emerging in a human group when leader or follower roles are not designated a priori. Two groups of participants were asked to walk together and turn or change speed at self-selected times. Data were analysed using time-dependent cross correlation to infer leader-follower interactions between each pair of group members. The results indicate that leadership emergence is due both to contextual factors, such as an individual's position in the group, and to personal factors, such as an individual's characteristic locomotor behaviour. Our approach can easily be extended to larger groups and other scenarios such as team sports and emergency evacuations.",
        "published": "2020-06-05T21:31:43Z",
        "link": "http://arxiv.org/abs/2006.03700v1",
        "categories": [
            "cs.MA",
            "stat.AP"
        ]
    },
    {
        "title": "An Algorithm to find Superior Fitness on NK Landscapes under High   Complexity: Muddling Through",
        "authors": [
            "Sasanka Sekhar Chanda",
            "Sai Yayavaram"
        ],
        "summary": "Under high complexity - given by pervasive interdependence between constituent elements of a decision in an NK landscape - our algorithm obtains fitness superior to that reported in extant research. We distribute the decision elements comprising a decision into clusters. When a change in value of a decision element is considered, a forward move is made if the aggregate fitness of the cluster members residing alongside the decision element is higher. The decision configuration with the highest fitness in the path is selected. Increasing the number of clusters obtains even higher fitness. Further, implementing moves comprising of up to two changes in a cluster also obtains higher fitness. Our algorithm obtains superior outcomes by enabling more extensive search, allowing inspection of more distant configurations. We name this algorithm the muddling through algorithm, in memory of Charles Lindblom who spotted the efficacy of the process long before sophisticated computer simulations came into being.",
        "published": "2020-06-06T11:08:20Z",
        "link": "http://arxiv.org/abs/2006.08333v2",
        "categories": [
            "cs.AI",
            "cs.MA",
            "q-bio.PE",
            "Keywords. algorithm, complexity, fitness, interdependence, muddling\n  through, NK model, policy making, public administration"
        ]
    },
    {
        "title": "Local Stackelberg equilibrium seeking in generalized aggregative games",
        "authors": [
            "Filippo Fabiani",
            "Mohammad Amin Tajeddini",
            "Hamed Kebriaei",
            "Sergio Grammatico"
        ],
        "summary": "We propose a two-layer, semi-decentralized algorithm to compute a local solution to the Stackelberg equilibrium problem in aggregative games with coupling constraints. Specifically, we focus on a single-leader, multiple-follower problem, and after equivalently recasting the Stackelberg game as a mathematical program with complementarity constraints (MPCC), we iteratively convexify a regularized version of the MPCC as inner problem, whose solution generates a sequence of feasible descent directions for the original MPCC. Thus, by pursuing a descent direction at every outer iteration, we establish convergence to a local Stackelberg equilibrium. Finally, the proposed algorithm is tested on a numerical case study involving a hierarchical instance of the charging coordination of Plug-in Electric Vehicles (PEVs).",
        "published": "2020-06-06T16:52:48Z",
        "link": "http://arxiv.org/abs/2006.03916v1",
        "categories": [
            "math.OC",
            "cs.GT",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Learning to Model Opponent Learning",
        "authors": [
            "Ian Davies",
            "Zheng Tian",
            "Jun Wang"
        ],
        "summary": "Multi-Agent Reinforcement Learning (MARL) considers settings in which a set of coexisting agents interact with one another and their environment. The adaptation and learning of other agents induces non-stationarity in the environment dynamics. This poses a great challenge for value function-based algorithms whose convergence usually relies on the assumption of a stationary environment. Policy search algorithms also struggle in multi-agent settings as the partial observability resulting from an opponent's actions not being known introduces high variance to policy training. Modelling an agent's opponent(s) is often pursued as a means of resolving the issues arising from the coexistence of learning opponents. An opponent model provides an agent with some ability to reason about other agents to aid its own decision making. Most prior works learn an opponent model by assuming the opponent is employing a stationary policy or switching between a set of stationary policies. Such an approach can reduce the variance of training signals for policy search algorithms. However, in the multi-agent setting, agents have an incentive to continually adapt and learn. This means that the assumptions concerning opponent stationarity are unrealistic. In this work, we develop a novel approach to modelling an opponent's learning dynamics which we term Learning to Model Opponent Learning (LeMOL). We show our structured opponent model is more accurate and stable than naive behaviour cloning baselines. We further show that opponent modelling can improve the performance of algorithmic agents in multi-agent settings.",
        "published": "2020-06-06T17:19:04Z",
        "link": "http://arxiv.org/abs/2006.03923v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Skill Discovery of Coordination in Multi-agent Reinforcement Learning",
        "authors": [
            "Shuncheng He",
            "Jianzhun Shao",
            "Xiangyang Ji"
        ],
        "summary": "Unsupervised skill discovery drives intelligent agents to explore the unknown environment without task-specific reward signal, and the agents acquire various skills which may be useful when the agents adapt to new tasks. In this paper, we propose \"Multi-agent Skill Discovery\"(MASD), a method for discovering skills for coordination patterns of multiple agents. The proposed method aims to maximize the mutual information between a latent code Z representing skills and the combination of the states of all agents. Meanwhile it suppresses the empowerment of Z on the state of any single agent by adversarial training. In another word, it sets an information bottleneck to avoid empowerment degeneracy. First we show the emergence of various skills on the level of coordination in a general particle multi-agent environment. Second, we reveal that the \"bottleneck\" prevents skills from collapsing to a single agent and enhances the diversity of learned skills. Finally, we show the pretrained policies have better performance on supervised RL tasks.",
        "published": "2020-06-07T02:04:15Z",
        "link": "http://arxiv.org/abs/2006.04021v1",
        "categories": [
            "cs.MA",
            "cs.LG"
        ]
    },
    {
        "title": "Reinforcement Learning for Multi-Product Multi-Node Inventory Management   in Supply Chains",
        "authors": [
            "Nazneen N Sultana",
            "Hardik Meisheri",
            "Vinita Baniwal",
            "Somjit Nath",
            "Balaraman Ravindran",
            "Harshad Khadilkar"
        ],
        "summary": "This paper describes the application of reinforcement learning (RL) to multi-product inventory management in supply chains. The problem description and solution are both adapted from a real-world business solution. The novelty of this problem with respect to supply chain literature is (i) we consider concurrent inventory management of a large number (50 to 1000) of products with shared capacity, (ii) we consider a multi-node supply chain consisting of a warehouse which supplies three stores, (iii) the warehouse, stores, and transportation from warehouse to stores have finite capacities, (iv) warehouse and store replenishment happen at different time scales and with realistic time lags, and (v) demand for products at the stores is stochastic. We describe a novel formulation in a multi-agent (hierarchical) reinforcement learning framework that can be used for parallelised decision-making, and use the advantage actor critic (A2C) algorithm with quantised action spaces to solve the problem. Experiments show that the proposed approach is able to handle a multi-objective reward comprised of maximising product sales and minimising wastage of perishable products.",
        "published": "2020-06-07T04:02:59Z",
        "link": "http://arxiv.org/abs/2006.04037v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Incorporating Pragmatic Reasoning Communication into Emergent Language",
        "authors": [
            "Yipeng Kang",
            "Tonghan Wang",
            "Gerard de Melo"
        ],
        "summary": "Emergentism and pragmatics are two research fields that study the dynamics of linguistic communication along substantially different timescales and intelligence levels. From the perspective of multi-agent reinforcement learning, they correspond to stochastic games with reinforcement training and stage games with opponent awareness. Given that their combination has been explored in linguistics, we propose computational models that combine short-term mutual reasoning-based pragmatics with long-term language emergentism. We explore this for agent communication referential games as well as in Starcraft II, assessing the relative merits of different kinds of mutual reasoning pragmatics models both empirically and theoretically. Our results shed light on their importance for making inroads towards getting more natural, accurate, robust, fine-grained, and succinct utterances.",
        "published": "2020-06-07T10:31:06Z",
        "link": "http://arxiv.org/abs/2006.04109v2",
        "categories": [
            "cs.AI",
            "cs.CL",
            "cs.MA"
        ]
    },
    {
        "title": "Randomized Entity-wise Factorization for Multi-Agent Reinforcement   Learning",
        "authors": [
            "Shariq Iqbal",
            "Christian A. Schroeder de Witt",
            "Bei Peng",
            "Wendelin Böhmer",
            "Shimon Whiteson",
            "Fei Sha"
        ],
        "summary": "Multi-agent settings in the real world often involve tasks with varying types and quantities of agents and non-agent entities; however, common patterns of behavior often emerge among these agents/entities. Our method aims to leverage these commonalities by asking the question: ``What is the expected utility of each agent when only considering a randomly selected sub-group of its observed entities?'' By posing this counterfactual question, we can recognize state-action trajectories within sub-groups of entities that we may have encountered in another task and use what we learned in that task to inform our prediction in the current one. We then reconstruct a prediction of the full returns as a combination of factors considering these disjoint groups of entities and train this ``randomly factorized\" value function as an auxiliary objective for value-based multi-agent reinforcement learning. By doing so, our model can recognize and leverage similarities across tasks to improve learning efficiency in a multi-task setting. Our approach, Randomized Entity-wise Factorization for Imagined Learning (REFIL), outperforms all strong baselines by a significant margin in challenging multi-task StarCraft micromanagement settings.",
        "published": "2020-06-07T18:28:41Z",
        "link": "http://arxiv.org/abs/2006.04222v3",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Learning to Play No-Press Diplomacy with Best Response Policy Iteration",
        "authors": [
            "Thomas Anthony",
            "Tom Eccles",
            "Andrea Tacchetti",
            "János Kramár",
            "Ian Gemp",
            "Thomas C. Hudson",
            "Nicolas Porcel",
            "Marc Lanctot",
            "Julien Pérolat",
            "Richard Everett",
            "Roman Werpachowski",
            "Satinder Singh",
            "Thore Graepel",
            "Yoram Bachrach"
        ],
        "summary": "Recent advances in deep reinforcement learning (RL) have led to considerable progress in many 2-player zero-sum games, such as Go, Poker and Starcraft. The purely adversarial nature of such games allows for conceptually simple and principled application of RL methods. However real-world settings are many-agent, and agent interactions are complex mixtures of common-interest and competitive aspects. We consider Diplomacy, a 7-player board game designed to accentuate dilemmas resulting from many-agent interactions. It also features a large combinatorial action space and simultaneous moves, which are challenging for RL algorithms. We propose a simple yet effective approximate best response operator, designed to handle large combinatorial action spaces and simultaneous moves. We also introduce a family of policy iteration methods that approximate fictitious play. With these methods, we successfully apply RL to Diplomacy: we show that our agents convincingly outperform the previous state-of-the-art, and game theoretic equilibrium analysis shows that the new process yields consistent improvements.",
        "published": "2020-06-08T14:33:31Z",
        "link": "http://arxiv.org/abs/2006.04635v4",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.GT",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Scalability in Computing and Robotics",
        "authors": [
            "Heiko Hamann",
            "Andreagiovanni Reina"
        ],
        "summary": "Efficient engineered systems require scalability. A scalable system has increasing performance with increasing system size. In an ideal case, the increase in performance (e.g., speedup) corresponds to the number of units that are added to the system. However, if multiple units work on the same task, then coordination among these units is required. This coordination can introduce overheads with an impact on system performance. The coordination costs can lead to sublinear improvement or even diminishing performance with increasing system size. However, there are also systems that implement efficient coordination and exploit collaboration of units to attain superlinear improvement. Modeling the scalability dynamics is key to understanding efficient systems. Known laws of scalability, such as Amdahl's law, Gustafson's law, and Gunther's Universal Scalability Law, are minimalistic phenomenological models that explain a rich variety of system behaviors through concise equations. While useful to gain general insights, the phenomenological nature of these models may limit the understanding of the underlying dynamics, as they are detached from first principles that could explain coordination overheads among units. Through a decentralized system approach, we propose a general model based on generic interactions between units that is able to describe, as specific cases, any general pattern of scalability included by previously reported laws. The proposed general model of scalability is built on first principles, or at least on a microscopic description of interaction between units, and therefore has the potential to contribute to a better understanding of system behavior and scalability. We show that this model can be applied to a diverse set of systems, such as parallel supercomputers, robot swarms, or wireless sensor networks, creating a unified view on interdisciplinary design for scalability.",
        "published": "2020-06-08T22:28:59Z",
        "link": "http://arxiv.org/abs/2006.04969v2",
        "categories": [
            "cs.DC",
            "cs.MA",
            "cs.PF",
            "cs.RO"
        ]
    },
    {
        "title": "A two-level solution to fight against dishonest opinions in   recommendation-based trust systems",
        "authors": [
            "Omar Abdel Wahab",
            "Jamal Bentahar",
            "Robin Cohen",
            "Hadi Otrok",
            "Azzam Mourad"
        ],
        "summary": "In this paper, we propose a mechanism to deal with dishonest opinions in recommendation-based trust models, at both the collection and processing levels. We consider a scenario in which an agent requests recommendations from multiple parties to build trust toward another agent. At the collection level, we propose to allow agents to self-assess the accuracy of their recommendations and autonomously decide on whether they would participate in the recommendation process or not. At the processing level, we propose a recommendations aggregation technique that is resilient to collusion attacks, followed by a credibility update mechanism for the participating agents. The originality of our work stems from its consideration of dishonest opinions at both the collection and processing levels, which allows for better and more persistent protection against dishonest recommenders. Experiments conducted on the Epinions dataset show that our solution yields better performance in protecting the recommendation process against Sybil attacks, in comparison with a competing model that derives the optimal network of advisors based on the agents' trust values.",
        "published": "2020-06-09T00:34:11Z",
        "link": "http://arxiv.org/abs/2006.04803v1",
        "categories": [
            "cs.IR",
            "cs.CY",
            "cs.LG",
            "cs.MA",
            "I.2"
        ]
    },
    {
        "title": "Policy-focused Agent-based Modeling using RL Behavioral Models",
        "authors": [
            "Osonde A. Osoba",
            "Raffaele Vardavas",
            "Justin Grana",
            "Rushil Zutshi",
            "Amber Jaycocks"
        ],
        "summary": "Agent-based Models (ABMs) are valuable tools for policy analysis. ABMs help analysts explore the emergent consequences of policy interventions in multi-agent decision-making settings. But the validity of inferences drawn from ABM explorations depends on the quality of the ABM agents' behavioral models. Standard specifications of agent behavioral models rely either on heuristic decision-making rules or on regressions trained on past data. Both prior specification modes have limitations. This paper examines the value of reinforcement learning (RL) models as adaptive, high-performing, and behaviorally-valid models of agent decision-making in ABMs. We test the hypothesis that RL agents are effective as utility-maximizing agents in policy ABMs. We also address the problem of adapting RL algorithms to handle multi-agency in games by adapting and extending methods from recent literature. We evaluate the performance of such RL-based ABM agents via experiments on two policy-relevant ABMs: a minority game ABM, and an ABM of Influenza Transmission. We run some analytic experiments on our AI-equipped ABMs e.g. explorations of the effects of behavioral heterogeneity in a population and the emergence of synchronization in a population. The experiments show that RL behavioral models are effective at producing reward-seeking or reward-maximizing behaviors in ABM agents. Furthermore, RL behavioral models can learn to outperform the default adaptive behavioral models in the two ABMs examined.",
        "published": "2020-06-09T04:55:07Z",
        "link": "http://arxiv.org/abs/2006.05048v3",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Polarization in Attraction-Repulsion Models",
        "authors": [
            "Elisabetta Cornacchia",
            "Neta Singer",
            "Emmanuel Abbe"
        ],
        "summary": "This paper introduces a model for opinion dynamics, where at each time step, randomly selected agents see their opinions - modeled as scalars in [0,1] - evolve depending on a local interaction function. In the classical Bounded Confidence Model, agents opinions get attracted when they are close enough. The proposed model extends this by adding a repulsion component, which models the effect of opinions getting further pushed away when dissimilar enough. With this repulsion component added, and under a repulsion-attraction cleavage assumption, it is shown that a new stable configuration emerges beyond the classical consensus configuration, namely the polarization configuration. More specifically, it is shown that total consensus and total polarization are the only two possible limiting configurations. The paper further provides an analysis of the infinite population regime in dimension 1 and higher, with a phase transition phenomenon conjectured and backed heuristically.",
        "published": "2020-06-09T13:33:40Z",
        "link": "http://arxiv.org/abs/2006.05251v1",
        "categories": [
            "cs.MA",
            "math.PR"
        ]
    },
    {
        "title": "Online Learning in Iterated Prisoner's Dilemma to Mimic Human Behavior",
        "authors": [
            "Baihan Lin",
            "Djallel Bouneffouf",
            "Guillermo Cecchi"
        ],
        "summary": "As an important psychological and social experiment, the Iterated Prisoner's Dilemma (IPD) treats the choice to cooperate or defect as an atomic action. We propose to study the behaviors of online learning algorithms in the Iterated Prisoner's Dilemma (IPD) game, where we investigate the full spectrum of reinforcement learning agents: multi-armed bandits, contextual bandits and reinforcement learning. We evaluate them based on a tournament of iterated prisoner's dilemma where multiple agents can compete in a sequential fashion. This allows us to analyze the dynamics of policies learned by multiple self-interested independent reward-driven agents, and also allows us study the capacity of these algorithms to fit the human behaviors. Results suggest that considering the current situation to make decision is the worst in this kind of social dilemma game. Multiples discoveries on online learning behaviors and clinical validations are stated, as an effort to connect artificial intelligence algorithms with human behaviors and their abnormal states in neuropsychiatric conditions.",
        "published": "2020-06-09T15:58:32Z",
        "link": "http://arxiv.org/abs/2006.06580v3",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "q-bio.NC"
        ]
    },
    {
        "title": "Democratising blockchain: A minimal agency consensus model",
        "authors": [
            "Marcin Abram",
            "David Galindo",
            "Daniel Honerkamp",
            "Jonathan Ward",
            "Jin-Mann Wong"
        ],
        "summary": "We propose a novel consensus protocol based on a hybrid approach, that combines a directed acyclic graph (DAG) and a classical chain of blocks. This architecture allows us to enforce collective block construction, minimising the monopolistic power of the round-leader. In this way, we decrease the possibility for collusion among senders and miners, as well as miners themselves, allowing the use of more incentive compatible and fair pricing strategies. We investigate these possibilities alongside the ability to use the DAG structure to minimise the risk of transaction censoring. We conclude by providing preliminary benchmarks of our protocol and by exploring further research directions.",
        "published": "2020-06-09T16:39:10Z",
        "link": "http://arxiv.org/abs/2006.05390v1",
        "categories": [
            "cs.CR",
            "cs.DC",
            "cs.MA"
        ]
    },
    {
        "title": "Agent Programming for Industrial Applications: Some Advantages and   Drawbacks",
        "authors": [
            "Otávio Arruda Matoso",
            "Luis P. A. Lampert",
            "Jomi Fred Hübner",
            "Mateus Conceição",
            "Sérgio P. Bernardes",
            "Cleber Jorge Amaral",
            "Maicon R. Zatelli",
            "Marcelo L. de Lima"
        ],
        "summary": "Autonomous agents are seen as a prominent technology to be applied in industrial scenarios. Classical automation solutions are struggling with challenges related to high dynamism, prompt actuation, heterogeneous entities, including humans, and decentralised decision-making. Besides promoting concepts, languages, and tools to face such challenges, agents must also provide high reliability. To assess how appropriate and mature are agents for industrial applications, we have investigated its application in two scenarios of the gas and oil industry. This paper presents the development of systems and the initial results highlighting the advantages and drawbacks of the agents approach when compared with the existing automation solutions.",
        "published": "2020-06-10T02:15:33Z",
        "link": "http://arxiv.org/abs/2006.05613v1",
        "categories": [
            "cs.MA",
            "cs.SE",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Towards Jacamo-rest: A Resource-Oriented Abstraction for Managing   Multi-Agent Systems",
        "authors": [
            "Cleber Jorge Amaral",
            "Jomi Fred Hübner",
            "Timotheus Kampik"
        ],
        "summary": "The Multi-Agent Oriented Programming (MAOP) paradigm provides abstractions to model and implements entities of agents, as well as of their organisations and environments. In recent years, researchers have started to explore the integration of MAOP and the resource-oriented web architecture (REST). This paper further advances this line of research by presenting an ongoing work on jacamo-rest, a resource-oriented web-based abstraction for the multi-agent programming platform JaCaMo. Jacamo-rest takes Multi-Agent System (MAS) interoperability to a new level, enabling MAS to not only interact with services or applications of the World Wide Web but also to be managed and updated in their specifications by other applications. To add a developer interface to JaCaMo that is suitable for the Web, we provide a novel conceptual perspective on the management of MAOP specification entities as web resources. We tested jacamo-rest using it as a middleware of a programming interface application that provides modern software engineering facilities such as continuous deployments and iterative software development for MAS.",
        "published": "2020-06-10T02:26:32Z",
        "link": "http://arxiv.org/abs/2006.05619v1",
        "categories": [
            "cs.MA",
            "cs.NI"
        ]
    },
    {
        "title": "A framework for modeling interdependencies among households, businesses,   and infrastructure systems; and their response to disruptions",
        "authors": [
            "Mateusz Iwo Dubaniowski",
            "Hans R. Heinimann"
        ],
        "summary": "Urban systems, composed of households, businesses, and infrastructures, are continuously evolving and expanding. This has several implications because the impacts of disruptions, and the complexity and interdependence of systems, are rapidly increasing. Hence, we face a challenge in how to improve our understanding about the interdependencies among those entities, as well as their responses to disruptions. The aims of this study were to (1) create an agent that mimics the metabolism of a business or household that obtains supplies from and provides output to infrastructure systems; (2) implement a network of agents that exchange resources, as coordinated with a price mechanism; and (3) test the responses of this prototype model to disruptions. Our investigation resulted in the development of a business/household agent and a dynamically self-organizing mechanism of network coordination under disruption based on costs for production and transportation. Simulation experiments confirmed the feasibility of this new model for analyzing responses to disruptions. Among the nine disruption scenarios considered, in line with our expectations, the one combining the failures of infrastructure links and production processes had the most negative impact. We also identified areas for future research that focus on network topologies, mechanisms for resource allocation, and disruption generation.",
        "published": "2020-06-10T06:26:02Z",
        "link": "http://arxiv.org/abs/2006.05678v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SI",
            "cs.SY",
            "econ.GN",
            "q-fin.EC"
        ]
    },
    {
        "title": "A Separation-Based Methodology to Consensus Tracking of Switched   High-Order Nonlinear Multi-Agent Systems",
        "authors": [
            "Maolong Lv",
            "Wenwu Yu",
            "Jinde Cao",
            "Simone Baldi"
        ],
        "summary": "This work investigates a reduced-complexity adaptive methodology to consensus tracking for a team of uncertain high-order nonlinear systems with switched (possibly asynchronous) dynamics. It is well known that high-order nonlinear systems are intrinsically challenging as feedback linearization and backstepping methods successfully developed for low-order systems fail to work. At the same time, even the adding-one power-integrator methodology, well explored for the single-agent high-order case, presents some complexity issues and is unsuited for distributed control. At the core of the proposed distributed methodology is a newly proposed definition for separable functions: this definition allows the formulation of a separation-based lemma to handle the high-order terms with reduced complexity in the control design. Complexity is reduced in a twofold sense: the control gain of each virtual control law does not have to be incorporated in the next virtual control law iteratively, thus leading to a simpler expression of the control laws; the order of the virtual control gains increases only proportionally (rather than exponentially) with the order of the systems, dramatically reducing high-gain issues.",
        "published": "2020-06-10T12:38:06Z",
        "link": "http://arxiv.org/abs/2006.05799v1",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "The Emergence of Individuality",
        "authors": [
            "Jiechuan Jiang",
            "Zongqing Lu"
        ],
        "summary": "Individuality is essential in human society, which induces the division of labor and thus improves the efficiency and productivity. Similarly, it should also be the key to multi-agent cooperation. Inspired by that individuality is of being an individual separate from others, we propose a simple yet efficient method for the emergence of individuality (EOI) in multi-agent reinforcement learning (MARL). EOI learns a probabilistic classifier that predicts a probability distribution over agents given their observation and gives each agent an intrinsic reward of being correctly predicted by the classifier. The intrinsic reward encourages the agents to visit their own familiar observations, and learning the classifier by such observations makes the intrinsic reward signals stronger and the agents more identifiable. To further enhance the intrinsic reward and promote the emergence of individuality, two regularizers are proposed to increase the discriminability of the classifier. We implement EOI on top of popular MARL algorithms. Empirically, we show that EOI significantly outperforms existing methods in a variety of multi-agent cooperative scenarios.",
        "published": "2020-06-10T14:11:21Z",
        "link": "http://arxiv.org/abs/2006.05842v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Efficient democratic decisions via nondeterministic proportional   consensus",
        "authors": [
            "Jobst Heitzig",
            "Forest W. Simmons"
        ],
        "summary": "Are there voting methods which (i) give everyone, including minorities, an equal share of effective power even if voters act strategically, (ii) promote consensus rather than polarization and inequality, and (iii) do not favour the status quo or rely too much on chance?   We show the answer is yes by describing two nondeterministic voting methods, one based on automatic bargaining over lotteries, the other on conditional commitments to approve compromise options. Our theoretical analysis and agent-based simulation experiments suggest that with these, majorities cannot consistently suppress minorities as with deterministic methods, proponents of the status quo cannot block decisions as in consensus-based approaches, the resulting aggregate welfare is comparable to existing methods, and average randomness is lower than for other nondeterministic methods.",
        "published": "2020-06-10T16:13:51Z",
        "link": "http://arxiv.org/abs/2006.06548v1",
        "categories": [
            "econ.GN",
            "cs.GT",
            "cs.MA",
            "q-fin.EC",
            "91B14, 91A80, 91B12",
            "J.4"
        ]
    },
    {
        "title": "Learning to Incentivize Other Learning Agents",
        "authors": [
            "Jiachen Yang",
            "Ang Li",
            "Mehrdad Farajtabar",
            "Peter Sunehag",
            "Edward Hughes",
            "Hongyuan Zha"
        ],
        "summary": "The challenge of developing powerful and general Reinforcement Learning (RL) agents has received increasing attention in recent years. Much of this effort has focused on the single-agent setting, in which an agent maximizes a predefined extrinsic reward function. However, a long-term question inevitably arises: how will such independent agents cooperate when they are continually learning and acting in a shared multi-agent environment? Observing that humans often provide incentives to influence others' behavior, we propose to equip each RL agent in a multi-agent environment with the ability to give rewards directly to other agents, using a learned incentive function. Each agent learns its own incentive function by explicitly accounting for its impact on the learning of recipients and, through them, the impact on its own extrinsic objective. We demonstrate in experiments that such agents significantly outperform standard RL and opponent-shaping agents in challenging general-sum Markov games, often by finding a near-optimal division of labor. Our work points toward more opportunities and challenges along the path to ensure the common good in a multi-agent future.",
        "published": "2020-06-10T20:12:38Z",
        "link": "http://arxiv.org/abs/2006.06051v2",
        "categories": [
            "cs.LG",
            "cs.GT",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Learning Individually Inferred Communication for Multi-Agent Cooperation",
        "authors": [
            "Ziluo Ding",
            "Tiejun Huang",
            "Zongqing Lu"
        ],
        "summary": "Communication lays the foundation for human cooperation. It is also crucial for multi-agent cooperation. However, existing work focuses on broadcast communication, which is not only impractical but also leads to information redundancy that could even impair the learning process. To tackle these difficulties, we propose Individually Inferred Communication (I2C), a simple yet effective model to enable agents to learn a prior for agent-agent communication. The prior knowledge is learned via causal inference and realized by a feed-forward neural network that maps the agent's local observation to a belief about who to communicate with. The influence of one agent on another is inferred via the joint action-value function in multi-agent reinforcement learning and quantified to label the necessity of agent-agent communication. Furthermore, the agent policy is regularized to better exploit communicated messages. Empirically, we show that I2C can not only reduce communication overhead but also improve the performance in a variety of multi-agent cooperative scenarios, comparing to existing methods. The code is available at https://github.com/PKU-AI-Edge/I2C.",
        "published": "2020-06-11T14:07:57Z",
        "link": "http://arxiv.org/abs/2006.06455v2",
        "categories": [
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Multi-Agent Reinforcement Learning in Stochastic Networked Systems",
        "authors": [
            "Yiheng Lin",
            "Guannan Qu",
            "Longbo Huang",
            "Adam Wierman"
        ],
        "summary": "We study multi-agent reinforcement learning (MARL) in a stochastic network of agents. The objective is to find localized policies that maximize the (discounted) global reward. In general, scalability is a challenge in this setting because the size of the global state/action space can be exponential in the number of agents. Scalable algorithms are only known in cases where dependencies are static, fixed and local, e.g., between neighbors in a fixed, time-invariant underlying graph. In this work, we propose a Scalable Actor Critic framework that applies in settings where the dependencies can be non-local and stochastic, and provide a finite-time error bound that shows how the convergence rate depends on the speed of information spread in the network. Additionally, as a byproduct of our analysis, we obtain novel finite-time convergence results for a general stochastic approximation scheme and for temporal difference learning with state aggregation, which apply beyond the setting of MARL in networked systems.",
        "published": "2020-06-11T16:08:16Z",
        "link": "http://arxiv.org/abs/2006.06555v3",
        "categories": [
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Scalable Multi-Agent Reinforcement Learning for Networked Systems with   Average Reward",
        "authors": [
            "Guannan Qu",
            "Yiheng Lin",
            "Adam Wierman",
            "Na Li"
        ],
        "summary": "It has long been recognized that multi-agent reinforcement learning (MARL) faces significant scalability issues due to the fact that the size of the state and action spaces are exponentially large in the number of agents. In this paper, we identify a rich class of networked MARL problems where the model exhibits a local dependence structure that allows it to be solved in a scalable manner. Specifically, we propose a Scalable Actor-Critic (SAC) method that can learn a near optimal localized policy for optimizing the average reward with complexity scaling with the state-action space size of local neighborhoods, as opposed to the entire network. Our result centers around identifying and exploiting an exponential decay property that ensures the effect of agents on each other decays exponentially fast in their graph distance.",
        "published": "2020-06-11T17:23:17Z",
        "link": "http://arxiv.org/abs/2006.06626v1",
        "categories": [
            "math.OC",
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "BioDynaMo: a general platform for scalable agent-based simulation",
        "authors": [
            "Lukas Breitwieser",
            "Ahmad Hesam",
            "Jean de Montigny",
            "Vasileios Vavourakis",
            "Alexandros Iosif",
            "Jack Jennings",
            "Marcus Kaiser",
            "Marco Manca",
            "Alberto Di Meglio",
            "Zaid Al-Ars",
            "Fons Rademakers",
            "Onur Mutlu",
            "Roman Bauer"
        ],
        "summary": "Motivation: Agent-based modeling is an indispensable tool for studying complex biological systems. However, existing simulators do not always take full advantage of modern hardware and often have a field-specific software design.   Results: We present a novel simulation platform called BioDynaMo that alleviates both of these problems. BioDynaMo features a general-purpose and high-performance simulation engine. We demonstrate that BioDynaMo can be used to simulate use cases in: neuroscience, oncology, and epidemiology. For each use case we validate our findings with experimental data or an analytical solution. Our performance results show that BioDynaMo performs up to three orders of magnitude faster than the state-of-the-art baseline. This improvement makes it feasible to simulate each use case with one billion agents on a single server, showcasing the potential BioDynaMo has for computational biology research.   Availability: BioDynaMo is an open-source project under the Apache 2.0 license and is available at www.biodynamo.org. Instructions to reproduce the results are available in supplementary information.   Contact: lukas.breitwieser@inf.ethz.ch, a.s.hesam@tudelft.nl, omutlu@ethz.ch, r.bauer@surrey.ac.uk   Supplementary information: Available at https://doi.org/10.5281/zenodo.4501515",
        "published": "2020-06-11T19:55:02Z",
        "link": "http://arxiv.org/abs/2006.06775v2",
        "categories": [
            "cs.CE",
            "cs.DC",
            "cs.MA"
        ]
    },
    {
        "title": "GOAL-DTU: Development of Distributed Intelligence for the Multi-Agent   Programming Contest",
        "authors": [
            "Alexander Birch Jensen",
            "Jørgen Villadsen"
        ],
        "summary": "We provide a brief description of the GOAL-DTU system for the agent contest, including the overall strategy and how the system is designed to apply this strategy. Our agents are implemented using the GOAL programming language. We evaluate the performance of our agents for the contest, and finally also discuss how to improve the system based on analysis of its strengths and weaknesses.",
        "published": "2020-06-11T21:44:05Z",
        "link": "http://arxiv.org/abs/2006.06844v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Multi-Agent Informational Learning Processes",
        "authors": [
            "J. K. Terry",
            "Nathaniel Grammel"
        ],
        "summary": "We introduce a new mathematical model of multi-agent reinforcement learning, the Multi-Agent Informational Learning Processor \"MAILP\" model. The model is based on the notion that agents have policies for a certain amount of information, models how this information iteratively evolves and propagates through many agents. This model is very general, and the only meaningful assumption made is that learning for individual agents progressively slows over time.",
        "published": "2020-06-11T23:18:50Z",
        "link": "http://arxiv.org/abs/2006.06870v4",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Nefele: Process Orchestration for the Cloud",
        "authors": [
            "Mina Sedaghat",
            "Pontus Sköldström",
            "Daniel Turull",
            "Vinay Yadhav",
            "Joacim Halén",
            "Madhubala Ganesan",
            "Amardeep Mehta",
            "Wolfgang John"
        ],
        "summary": "Virtualization, either at OS- or hardware level, plays an important role in cloud computing. It enables easier automation and faster deployment in distributed environments. While virtualized infrastructures provide a level of management flexibility, they lack practical abstraction of the distributed resources. A developer in such an environment still needs to deal with all the complications of building a distributed software system. Different orchestration systems are built to provide that abstraction; however, they do not solve the inherent challenges of distributed systems, such as synchronization issues or resilience to failures. This paper introduces Nefele, a decentralized process orchestration system that automatically deploys and manages individual processes, rather than containers/VMs, within a cluster. Nefele is inspired by the Single System Image (SSI) vision of mitigating the intricacies of remote execution, yet it maintains the flexibility and performance of virtualized infrastructures. Nefele offers a set of APIs for building cloud-native applications that lets the developer easily build, deploy, and scale applications in a cloud environment. We have implemented and deployed Nefele on a cluster in our datacenter and evaluated its performance. Our evaluations show that Nefele can effectively deploy, scale, and monitor processes across a distributed environment, while it incorporates essential primitives to build a distributed software system.",
        "published": "2020-06-12T13:21:59Z",
        "link": "http://arxiv.org/abs/2006.07163v2",
        "categories": [
            "cs.DC",
            "cs.MA",
            "cs.OS",
            "D.4.7; D.4.8; D.4.1; D.4.3; D.4.4; F.1.2"
        ]
    },
    {
        "title": "Shared Experience Actor-Critic for Multi-Agent Reinforcement Learning",
        "authors": [
            "Filippos Christianos",
            "Lukas Schäfer",
            "Stefano V. Albrecht"
        ],
        "summary": "Exploration in multi-agent reinforcement learning is a challenging problem, especially in environments with sparse rewards. We propose a general method for efficient exploration by sharing experience amongst agents. Our proposed algorithm, called Shared Experience Actor-Critic (SEAC), applies experience sharing in an actor-critic framework. We evaluate SEAC in a collection of sparse-reward multi-agent environments and find that it consistently outperforms two baselines and two state-of-the-art algorithms by learning in fewer steps and converging to higher returns. In some harder environments, experience sharing makes the difference between learning to solve the task and not learning at all.",
        "published": "2020-06-12T13:24:50Z",
        "link": "http://arxiv.org/abs/2006.07169v4",
        "categories": [
            "cs.MA",
            "cs.LG"
        ]
    },
    {
        "title": "Learning to Communicate Using Counterfactual Reasoning",
        "authors": [
            "Simon Vanneste",
            "Astrid Vanneste",
            "Kevin Mets",
            "Tom De Schepper",
            "Ali Anwar",
            "Siegfried Mercelis",
            "Steven Latré",
            "Peter Hellinckx"
        ],
        "summary": "Learning to communicate in order to share state information is an active problem in the area of multi-agent reinforcement learning (MARL). The credit assignment problem, the non-stationarity of the communication environment and the creation of influenceable agents are major challenges within this research field which need to be overcome in order to learn a valid communication protocol. This paper introduces the novel multi-agent counterfactual communication learning (MACC) method which adapts counterfactual reasoning in order to overcome the credit assignment problem for communicating agents. Secondly, the non-stationarity of the communication environment while learning the communication Q-function is overcome by creating the communication Q-function using the action policy of the other agents and the Q-function of the action environment. Additionally, a social loss function is introduced in order to create influenceable agents which is required to learn a valid communication protocol. Our experiments show that MACC is able to outperform the state-of-the-art baselines in four different scenarios in the Particle environment.",
        "published": "2020-06-12T14:02:04Z",
        "link": "http://arxiv.org/abs/2006.07200v4",
        "categories": [
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "FedGAN: Federated Generative Adversarial Networks for Distributed Data",
        "authors": [
            "Mohammad Rasouli",
            "Tao Sun",
            "Ram Rajagopal"
        ],
        "summary": "We propose Federated Generative Adversarial Network (FedGAN) for training a GAN across distributed sources of non-independent-and-identically-distributed data sources subject to communication and privacy constraints. Our algorithm uses local generators and discriminators which are periodically synced via an intermediary that averages and broadcasts the generator and discriminator parameters. We theoretically prove the convergence of FedGAN with both equal and two time-scale updates of generator and discriminator, under standard assumptions, using stochastic approximations and communication efficient stochastic gradient descents. We experiment FedGAN on toy examples (2D system, mixed Gaussian, and Swiss role), image datasets (MNIST, CIFAR-10, and CelebA), and time series datasets (household electricity consumption and electric vehicle charging sessions). We show FedGAN converges and has similar performance to general distributed GAN, while reduces communication complexity. We also show its robustness to reduced communications.",
        "published": "2020-06-12T14:36:43Z",
        "link": "http://arxiv.org/abs/2006.07228v2",
        "categories": [
            "cs.LG",
            "cs.CV",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Human and Multi-Agent collaboration in a human-MARL teaming framework",
        "authors": [
            "Neda Navidi",
            "Francoi Chabo",
            "Saga Kurandwa",
            "Iv Lutigma",
            "Vincent Robt",
            "Gregry Szrftgr",
            "Andea Schuh"
        ],
        "summary": "Reinforcement learning provides effective results with agents learning from their observations, received rewards, and internal interactions between agents. This study proposes a new open-source MARL framework, called COGMENT, to efficiently leverage human and agent interactions as a source of learning. We demonstrate these innovations by using a designed real-time environment with unmanned aerial vehicles driven by RL agents, collaborating with a human. The results of this study show that the proposed collaborative paradigm and the open-source framework leads to significant reductions in both human effort and exploration costs.",
        "published": "2020-06-12T16:32:42Z",
        "link": "http://arxiv.org/abs/2006.07301v2",
        "categories": [
            "cs.AI",
            "cs.HC",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Algorithm for Computing Approximate Nash Equilibrium in Continuous Games   with Application to Continuous Blotto",
        "authors": [
            "Sam Ganzfried"
        ],
        "summary": "Successful algorithms have been developed for computing Nash equilibrium in a variety of finite game classes. However, solving continuous games -- in which the pure strategy space is (potentially uncountably) infinite -- is far more challenging. Nonetheless, many real-world domains have continuous action spaces, e.g., where actions refer to an amount of time, money, or other resource that is naturally modeled as being real-valued as opposed to integral. We present a new algorithm for {approximating} Nash equilibrium strategies in continuous games. In addition to two-player zero-sum games, our algorithm also applies to multiplayer games and games with imperfect information. We experiment with our algorithm on a continuous imperfect-information Blotto game, in which two players distribute resources over multiple battlefields. Blotto games have frequently been used to model national security scenarios and have also been applied to electoral competition and auction theory. Experiments show that our algorithm is able to quickly compute close approximations of Nash equilibrium strategies for this game.",
        "published": "2020-06-12T19:53:18Z",
        "link": "http://arxiv.org/abs/2006.07443v5",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.MA",
            "econ.TH",
            "math.OC"
        ]
    },
    {
        "title": "A Mathematical Negotiation Mechanism for Distributed Procurement   Problems and a Hybrid Algorithm for its Solution",
        "authors": [
            "Zohreh Kaheh",
            "Reza Baradaran Kazemzadeh",
            "Ellips Masehian",
            "Ali Husseinzadeh Kashan"
        ],
        "summary": "In this paper, a mathematical negotiation mechanism is designed to minimize the negotiators' costs in a distributed procurement problem at two echelons of an automotive supply chain. The buyer's costs are procurement cost and shortage penalty in a one-period contract. On the other hand, the suppliers intend to solve a multi-period, multi-product production planning to minimize their costs. Such a mechanism provides an alignment among suppliers' production planning and order allocation, also supports the partnership with the valued suppliers by taking suppliers' capacities into account. Such a circumstance has been modeled via bi-level programming, in which the buyer acts as a leader, and the suppliers individually appear as followers in the lower level. To solve this nonlinear bi-level programming model, a hybrid algorithm by combining the particle swarm optimization (PSO) algorithm with a heuristic algorithm based on A search is proposed. The heuristic A algorithm is embedded to solve the mixed-integer nonlinear programming (MINLP) sub-problems for each supplier according to the received variable values determined by PSO system particles (buyer's request for quotations (RFQs)). The computational analyses have shown that the proposed hybrid algorithm called PSO-A outperforms PSO-SA and PSO-Greedy algorithms.",
        "published": "2020-06-12T21:05:16Z",
        "link": "http://arxiv.org/abs/2006.13140v3",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Benchmarking Multi-Agent Deep Reinforcement Learning Algorithms in   Cooperative Tasks",
        "authors": [
            "Georgios Papoudakis",
            "Filippos Christianos",
            "Lukas Schäfer",
            "Stefano V. Albrecht"
        ],
        "summary": "Multi-agent deep reinforcement learning (MARL) suffers from a lack of commonly-used evaluation tasks and criteria, making comparisons between approaches difficult. In this work, we provide a systematic evaluation and comparison of three different classes of MARL algorithms (independent learning, centralised multi-agent policy gradient, value decomposition) in a diverse range of cooperative multi-agent learning tasks. Our experiments serve as a reference for the expected performance of algorithms across different learning tasks, and we provide insights regarding the effectiveness of different learning approaches. We open-source EPyMARL, which extends the PyMARL codebase to include additional algorithms and allow for flexible configuration of algorithm implementation details such as parameter sharing. Finally, we open-source two environments for multi-agent research which focus on coordination under sparse rewards.",
        "published": "2020-06-14T11:22:53Z",
        "link": "http://arxiv.org/abs/2006.07869v4",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Coordinated Control of UAVs for Human-Centered Active Sensing of   Wildfires",
        "authors": [
            "Esmaeil Seraj",
            "Matthew Gombolay"
        ],
        "summary": "Fighting wildfires is a precarious task, imperiling the lives of engaging firefighters and those who reside in the fire's path. Firefighters need online and dynamic observation of the firefront to anticipate a wildfire's unknown characteristics, such as size, scale, and propagation velocity, and to plan accordingly. In this paper, we propose a distributed control framework to coordinate a team of unmanned aerial vehicles (UAVs) for a human-centered active sensing of wildfires. We develop a dual-criterion objective function based on Kalman uncertainty residual propagation and weighted multi-agent consensus protocol, which enables the UAVs to actively infer the wildfire dynamics and parameters, track and monitor the fire transition, and safely manage human firefighters on the ground using acquired information. We evaluate our approach relative to prior work, showing significant improvements by reducing the environment's cumulative uncertainty residual by more than $ 10^2 $ and $ 10^5 $ times in firefront coverage performance to support human-robot teaming for firefighting. We also demonstrate our method on physical robots in a mock firefighting exercise.",
        "published": "2020-06-14T18:26:32Z",
        "link": "http://arxiv.org/abs/2006.07969v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.RO",
            "cs.SY",
            "eess.SP"
        ]
    },
    {
        "title": "Tight Nonparametric Convergence Rates for Stochastic Gradient Descent   under the Noiseless Linear Model",
        "authors": [
            "Raphaël Berthier",
            "Francis Bach",
            "Pierre Gaillard"
        ],
        "summary": "In the context of statistical supervised learning, the noiseless linear model assumes that there exists a deterministic linear relation $Y = \\langle \\theta_*, X \\rangle$ between the random output $Y$ and the random feature vector $\\Phi(U)$, a potentially non-linear transformation of the inputs $U$. We analyze the convergence of single-pass, fixed step-size stochastic gradient descent on the least-square risk under this model. The convergence of the iterates to the optimum $\\theta_*$ and the decay of the generalization error follow polynomial convergence rates with exponents that both depend on the regularities of the optimum $\\theta_*$ and of the feature vectors $\\Phi(u)$. We interpret our result in the reproducing kernel Hilbert space framework. As a special case, we analyze an online algorithm for estimating a real function on the unit interval from the noiseless observation of its value at randomly sampled points; the convergence depends on the Sobolev smoothness of the function and of a chosen kernel. Finally, we apply our analysis beyond the supervised learning setting to obtain convergence rates for the averaging process (a.k.a. gossip algorithm) on a graph depending on its spectral dimension.",
        "published": "2020-06-15T08:25:50Z",
        "link": "http://arxiv.org/abs/2006.08212v2",
        "categories": [
            "cs.LG",
            "cs.MA",
            "math.OC",
            "stat.ML"
        ]
    },
    {
        "title": "Pipeline PSRO: A Scalable Approach for Finding Approximate Nash   Equilibria in Large Games",
        "authors": [
            "Stephen McAleer",
            "John Lanier",
            "Roy Fox",
            "Pierre Baldi"
        ],
        "summary": "Finding approximate Nash equilibria in zero-sum imperfect-information games is challenging when the number of information states is large. Policy Space Response Oracles (PSRO) is a deep reinforcement learning algorithm grounded in game theory that is guaranteed to converge to an approximate Nash equilibrium. However, PSRO requires training a reinforcement learning policy at each iteration, making it too slow for large games. We show through counterexamples and experiments that DCH and Rectified PSRO, two existing approaches to scaling up PSRO, fail to converge even in small games. We introduce Pipeline PSRO (P2SRO), the first scalable general method for finding approximate Nash equilibria in large zero-sum imperfect-information games. P2SRO is able to parallelize PSRO with convergence guarantees by maintaining a hierarchical pipeline of reinforcement learning workers, each training against the policies generated by lower levels in the hierarchy. We show that unlike existing methods, P2SRO converges to an approximate Nash equilibrium, and does so faster as the number of parallel workers increases, across a variety of imperfect information games. We also introduce an open-source environment for Barrage Stratego, a variant of Stratego with an approximate game tree complexity of $10^{50}$. P2SRO is able to achieve state-of-the-art performance on Barrage Stratego and beats all existing bots. Experiment code is available athttps://github.com/JBLanier/pipeline-psro.",
        "published": "2020-06-15T17:17:17Z",
        "link": "http://arxiv.org/abs/2006.08555v2",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Certifying Strategyproof Auction Networks",
        "authors": [
            "Michael J. Curry",
            "Ping-Yeh Chiang",
            "Tom Goldstein",
            "John Dickerson"
        ],
        "summary": "Optimal auctions maximize a seller's expected revenue subject to individual rationality and strategyproofness for the buyers. Myerson's seminal work in 1981 settled the case of auctioning a single item; however, subsequent decades of work have yielded little progress moving beyond a single item, leaving the design of revenue-maximizing auctions as a central open problem in the field of mechanism design. A recent thread of work in \"differentiable economics\" has used tools from modern deep learning to instead learn good mechanisms. We focus on the RegretNet architecture, which can represent auctions with arbitrary numbers of items and participants; it is trained to be empirically strategyproof, but the property is never exactly verified leaving potential loopholes for market participants to exploit. We propose ways to explicitly verify strategyproofness under a particular valuation profile using techniques from the neural network verification literature. Doing so requires making several modifications to the RegretNet architecture in order to represent it exactly in an integer program. We train our network and produce certificates in several settings, including settings for which the optimal strategyproof mechanism is not known.",
        "published": "2020-06-15T20:22:48Z",
        "link": "http://arxiv.org/abs/2006.08742v1",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Optimal Sequential Task Assignment and Path Finding for Multi-Agent   Robotic Assembly Planning",
        "authors": [
            "Kyle Brown",
            "Oriana Peltzer",
            "Martin A. Sehr",
            "Mac Schwager",
            "Mykel J. Kochenderfer"
        ],
        "summary": "We study the problem of sequential task assignment and collision-free routing for large teams of robots in applications with inter-task precedence constraints (e.g., task $A$ and task $B$ must both be completed before task $C$ may begin). Such problems commonly occur in assembly planning for robotic manufacturing applications, in which sub-assemblies must be completed before they can be combined to form the final product. We propose a hierarchical algorithm for computing makespan-optimal solutions to the problem. The algorithm is evaluated on a set of randomly generated problem instances where robots must transport objects between stations in a \"factory \"grid world environment. In addition, we demonstrate in high-fidelity simulation that the output of our algorithm can be used to generate collision-free trajectories for non-holonomic differential-drive robots.",
        "published": "2020-06-16T00:45:07Z",
        "link": "http://arxiv.org/abs/2006.08845v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "An Agent-based Cloud Service Negotiation in Hybrid Cloud Computing",
        "authors": [
            "Saurabh Deochake",
            "Debajyoti Mukhopadhyay"
        ],
        "summary": "With the advent of evolution of cloud computing, large organizations have been scaling the on-premise IT infrastructure to the cloud. Although this being a popular practice, it lacks comprehensive efforts to study the aspects of automated negotiation of resources among cloud customers and providers. This paper proposes a full-fledged framework for the multi-party, multi-issue negotiation system for cloud resources. It introduces a robust cloud marketplace system to buy and sell cloud resources. The Belief-Desire-Intention (BDI) model-based cloud customer and provider agents concurrently negotiate on multiple issues, pursuing a hybrid tactic of time and resource-based dynamic deadline algorithms to generate offers and counter-offers. The cloud marketplace-based system is further augmented with the assignment of behavior norm score and reputation index to the agents to establish trust among them.",
        "published": "2020-06-16T05:23:38Z",
        "link": "http://arxiv.org/abs/2006.13109v1",
        "categories": [
            "cs.MA",
            "cs.DC",
            "cs.NI"
        ]
    },
    {
        "title": "Multi-Agent Reinforcement Learning for Adaptive User Association in   Dynamic mmWave Networks",
        "authors": [
            "Mohamed Sana",
            "Antonio De Domenico",
            "Wei Yu",
            "Yves Lostanlen",
            "Emilio Calvanese Strinati"
        ],
        "summary": "Network densification and millimeter-wave technologies are key enablers to fulfill the capacity and data rate requirements of the fifth generation (5G) of mobile networks. In this context, designing low-complexity policies with local observations, yet able to adapt the user association with respect to the global network state and to the network dynamics is a challenge. In fact, the frameworks proposed in literature require continuous access to global network information and to recompute the association when the radio environment changes. With the complexity associated to such an approach, these solutions are not well suited to dense 5G networks. In this paper, we address this issue by designing a scalable and flexible algorithm for user association based on multi-agent reinforcement learning. In this approach, users act as independent agents that, based on their local observations only, learn to autonomously coordinate their actions in order to optimize the network sum-rate. Since there is no direct information exchange among the agents, we also limit the signaling overhead. Simulation results show that the proposed algorithm is able to adapt to (fast) changes of radio environment, thus providing large sum-rate gain in comparison to state-of-the-art solutions.",
        "published": "2020-06-16T10:51:27Z",
        "link": "http://arxiv.org/abs/2006.09066v1",
        "categories": [
            "eess.SP",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Agent Modelling under Partial Observability for Deep Reinforcement   Learning",
        "authors": [
            "Georgios Papoudakis",
            "Filippos Christianos",
            "Stefano V. Albrecht"
        ],
        "summary": "Modelling the behaviours of other agents is essential for understanding how agents interact and making effective decisions. Existing methods for agent modelling commonly assume knowledge of the local observations and chosen actions of the modelled agents during execution. To eliminate this assumption, we extract representations from the local information of the controlled agent using encoder-decoder architectures. Using the observations and actions of the modelled agents during training, our models learn to extract representations about the modelled agents conditioned only on the local observations of the controlled agent. The representations are used to augment the controlled agent's decision policy which is trained via deep reinforcement learning; thus, during execution, the policy does not require access to other agents' information. We provide a comprehensive evaluation and ablations studies in cooperative, competitive and mixed multi-agent environments, showing that our method achieves higher returns than baseline methods which do not use the learned representations.",
        "published": "2020-06-16T18:43:42Z",
        "link": "http://arxiv.org/abs/2006.09447v4",
        "categories": [
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Why Stake When You Can Borrow?",
        "authors": [
            "Tarun Chitra",
            "Alex Evans"
        ],
        "summary": "As smart contract platforms autonomously manage billions of dollars of capital, quantifying the portfolio risk that investors engender in these systems is increasingly important. Recent work illustrates that Proof of Stake (PoS) is vulnerable to financial attacks arising from on-chain lending and has worse capital efficiency than Proof of Work (PoW) \\cite{fanti_pos_econ}. Numerous methods for improving capital efficiency have been proposed that allow stakers to create fungible derivative claims on their staked assets. In this paper, we construct a unifying model for studying the security risks of these proposals. This model combines birth-death P\\'olya processes and risk models adapted from the credit derivatives literature to assess token inequality and return profiles. We find that there is a sharp transition between 'safe' and 'unsafe' derivative usage. Surprisingly, we find that contrary to \\cite{fanti2019compounding} there exist conditions where derivatives can \\emph{reduce} concentration of wealth in these networks. This model also applies to Decentralized Finance (DeFi) protocols where staked assets are used as insurance. Our theoretical results are validated using agent-based simulation.",
        "published": "2020-06-16T20:59:36Z",
        "link": "http://arxiv.org/abs/2006.11156v1",
        "categories": [
            "q-fin.GN",
            "cs.MA",
            "q-fin.TR"
        ]
    },
    {
        "title": "Multi-Agent Programming Contest 2019 FIT BUT Team solution",
        "authors": [
            "Vaclav Uhlir",
            "Frantisek Zboril",
            "Frantisek Vidensky"
        ],
        "summary": "During our participation in MAPC 2019, we have developed two multi-agent systems that have been designed specifically for this competition. The first of the systems is pro-active system that works with pre-specified scenarios and tasks agents with generated goals designed for individual agents according to assigned role. The second system is designed as more reactive and employs layered architecture with highly dynamic behaviour, where agents select their own action based on their perception of usefulness of said action.",
        "published": "2020-06-17T08:37:51Z",
        "link": "http://arxiv.org/abs/2006.09718v3",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Towards Auditability Requirements Specification Using an Agent-Based   Approach",
        "authors": [
            "Denis J. S. de Albuquerque",
            "Vanessa Tavares Nunes",
            "Claudia Cappelli",
            "Celia Ghedini Ralha"
        ],
        "summary": "Transparency is an important factor in democratic societies composed of characteristics such as accessibility, usability, informativeness, understandability and auditability. In this research we focus on auditability since it plays an important role for citizens that need to understand and audit public information. Although auditability has been a subject of discussion when designing systems, there is a lack of systematization in its specification. We propose an approach to systematically add auditability requirements specification during the goal-oriented agent-based Tropos methodology. We used the Transparency Softgoal Interdependency Graph that captures the different facets of transparency while considering their operationalization. An empirical evaluation was conducted through the design and implementation of LawDisTrA system that distributes lawsuits among judges in an appellate court. Experiments included the distribution of over 300,000 lawsuits at the Brazilian Superior Labor Court. We theorize that the presented approach for auditability provides adequate techniques to address the cross-organizational nature of transparency.",
        "published": "2020-06-18T01:52:31Z",
        "link": "http://arxiv.org/abs/2006.10232v1",
        "categories": [
            "cs.MA",
            "cs.SE",
            "D.2.1"
        ]
    },
    {
        "title": "Robust Unsupervised Learning of Temporal Dynamic Interactions",
        "authors": [
            "Aritra Guha",
            "Rayleigh Lei",
            "Jiacheng Zhu",
            "XuanLong Nguyen",
            "Ding Zhao"
        ],
        "summary": "Robust representation learning of temporal dynamic interactions is an important problem in robotic learning in general and automated unsupervised learning in particular. Temporal dynamic interactions can be described by (multiple) geometric trajectories in a suitable space over which unsupervised learning techniques may be applied to extract useful features from raw and high-dimensional data measurements. Taking a geometric approach to robust representation learning for temporal dynamic interactions, it is necessary to develop suitable metrics and a systematic methodology for comparison and for assessing the stability of an unsupervised learning method with respect to its tuning parameters. Such metrics must account for the (geometric) constraints in the physical world as well as the uncertainty associated with the learned patterns. In this paper we introduce a model-free metric based on the Procrustes distance for robust representation learning of interactions, and an optimal transport based distance metric for comparing between distributions of interaction primitives. These distance metrics can serve as an objective for assessing the stability of an interaction learning algorithm. They are also used for comparing the outcomes produced by different algorithms. Moreover, they may also be adopted as an objective function to obtain clusters and representative interaction primitives. These concepts and techniques will be introduced, along with mathematical properties, while their usefulness will be demonstrated in unsupervised learning of vehicle-to-vechicle interactions extracted from the Safety Pilot database, the world's largest database for connected vehicles.",
        "published": "2020-06-18T02:39:45Z",
        "link": "http://arxiv.org/abs/2006.10241v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "cs.RO",
            "stat.AP",
            "stat.ML"
        ]
    },
    {
        "title": "Towards Open Ad Hoc Teamwork Using Graph-based Policy Learning",
        "authors": [
            "Arrasy Rahman",
            "Niklas Höpner",
            "Filippos Christianos",
            "Stefano V. Albrecht"
        ],
        "summary": "Ad hoc teamwork is the challenging problem of designing an autonomous agent which can adapt quickly to collaborate with teammates without prior coordination mechanisms, including joint training. Prior work in this area has focused on closed teams in which the number of agents is fixed. In this work, we consider open teams by allowing agents with different fixed policies to enter and leave the environment without prior notification. Our solution builds on graph neural networks to learn agent models and joint-action value models under varying team compositions. We contribute a novel action-value computation that integrates the agent model and joint-action value model to produce action-value estimates. We empirically demonstrate that our approach successfully models the effects other agents have on the learner, leading to policies that robustly adapt to dynamic team compositions and significantly outperform several alternative methods.",
        "published": "2020-06-18T10:39:41Z",
        "link": "http://arxiv.org/abs/2006.10412v4",
        "categories": [
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Train Unit Shunting and Servicing: a Real-Life Application of   Multi-Agent Path Finding",
        "authors": [
            "Jesse Mulderij",
            "Bob Huisman",
            "Denise Tönissen",
            "Koos van der Linden",
            "Mathijs de Weerdt"
        ],
        "summary": "In between transportation services, trains are parked and maintained at shunting yards. The conflict-free routing of trains to and on these yards and the scheduling of service and maintenance tasks is known as the train unit shunting and service problem. Efficient use of the capacity of these yards is becoming increasingly important, because of increasing numbers of trains without proportional extensions of the yards. Efficiently scheduling maintenance activities is extremely challenging: currently only heuristics succeed in finding solutions to the integrated problem at all. Bounds are needed to determine the quality of these heuristics, and also to support investment decisions on increasing the yard capacity. For this, a complete algorithm for a possibly relaxed problem model is required. We analyze the potential of extending the model for multi-agent path finding to be used for such a relaxation.",
        "published": "2020-06-18T10:57:12Z",
        "link": "http://arxiv.org/abs/2006.10422v1",
        "categories": [
            "cs.MA",
            "cs.DM"
        ]
    },
    {
        "title": "Competitive Policy Optimization",
        "authors": [
            "Manish Prajapat",
            "Kamyar Azizzadenesheli",
            "Alexander Liniger",
            "Yisong Yue",
            "Anima Anandkumar"
        ],
        "summary": "A core challenge in policy optimization in competitive Markov decision processes is the design of efficient optimization methods with desirable convergence and stability properties. To tackle this, we propose competitive policy optimization (CoPO), a novel policy gradient approach that exploits the game-theoretic nature of competitive games to derive policy updates. Motivated by the competitive gradient optimization method, we derive a bilinear approximation of the game objective. In contrast, off-the-shelf policy gradient methods utilize only linear approximations, and hence do not capture interactions among the players. We instantiate CoPO in two ways:(i) competitive policy gradient, and (ii) trust-region competitive policy optimization. We theoretically study these methods, and empirically investigate their behavior on a set of comprehensive, yet challenging, competitive games. We observe that they provide stable optimization, convergence to sophisticated strategies, and higher scores when played against baseline policy gradient methods.",
        "published": "2020-06-18T15:31:09Z",
        "link": "http://arxiv.org/abs/2006.10611v1",
        "categories": [
            "cs.LG",
            "cs.GT",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Modeling indoor-level non-pharmaceutical interventions during the   COVID-19 pandemic: a pedestrian dynamics-based microscopic simulation   approach",
        "authors": [
            "Yao Xiao",
            "Mofeng Yang",
            "Zheng Zhu",
            "Hai Yang",
            "Lei Zhang",
            "Sepehr Ghader"
        ],
        "summary": "Mathematical modeling of epidemic spreading has been widely adopted to estimate the threats of epidemic diseases (i.e., the COVID-19 pandemic) as well as to evaluate epidemic control interventions. The indoor place is considered to be a significant epidemic spreading risk origin, but existing widely-used epidemic spreading models are usually limited for indoor places since the dynamic physical distance changes between people are ignored, and the empirical features of the essential and non-essential travel are not differentiated. In this paper, we introduce a pedestrian-based epidemic spreading model that is capable of modeling indoor transmission risks of diseases during people's social activities. Taking advantage of the before-and-after mobility data from the University of Maryland COVID-19 Impact Analysis Platform, it's found that people tend to spend more time in grocery stores once their travel frequencies are restricted to a low level. In other words, an increase in dwell time could balance the decrease in travel frequencies and satisfy people's demand. Based on the pedestrian-based model and the empirical evidence, combined non-pharmaceutical interventions from different operational levels are evaluated. Numerical simulations show that restrictions on people's travel frequency and open-hours of indoor places may not be universally effective in reducing average infection risks for each pedestrian who visit the place. Entry limitations can be a widely effective alternative, whereas the decision-maker needs to balance the decrease in risky contacts and the increase in queue length outside the place that may impede people from fulfilling their travel needs.",
        "published": "2020-06-18T16:47:38Z",
        "link": "http://arxiv.org/abs/2006.10666v1",
        "categories": [
            "physics.soc-ph",
            "cs.MA"
        ]
    },
    {
        "title": "Weighted QMIX: Expanding Monotonic Value Function Factorisation for Deep   Multi-Agent Reinforcement Learning",
        "authors": [
            "Tabish Rashid",
            "Gregory Farquhar",
            "Bei Peng",
            "Shimon Whiteson"
        ],
        "summary": "QMIX is a popular $Q$-learning algorithm for cooperative MARL in the centralised training and decentralised execution paradigm. In order to enable easy decentralisation, QMIX restricts the joint action $Q$-values it can represent to be a monotonic mixing of each agent's utilities. However, this restriction prevents it from representing value functions in which an agent's ordering over its actions can depend on other agents' actions. To analyse this representational limitation, we first formalise the objective QMIX optimises, which allows us to view QMIX as an operator that first computes the $Q$-learning targets and then projects them into the space representable by QMIX. This projection returns a representable $Q$-value that minimises the unweighted squared error across all joint actions. We show in particular that this projection can fail to recover the optimal policy even with access to $Q^*$, which primarily stems from the equal weighting placed on each joint action. We rectify this by introducing a weighting into the projection, in order to place more importance on the better joint actions. We propose two weighting schemes and prove that they recover the correct maximal action for any joint action $Q$-values, and therefore for $Q^*$ as well. Based on our analysis and results in the tabular setting, we introduce two scalable versions of our algorithm, Centrally-Weighted (CW) QMIX and Optimistically-Weighted (OW) QMIX and demonstrate improved performance on both predator-prey and challenging multi-agent StarCraft benchmark tasks.",
        "published": "2020-06-18T18:34:50Z",
        "link": "http://arxiv.org/abs/2006.10800v2",
        "categories": [
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Efficient Ridesharing Dispatch Using Multi-Agent Reinforcement Learning",
        "authors": [
            "Oscar de Lima",
            "Hansal Shah",
            "Ting-Sheng Chu",
            "Brian Fogelson"
        ],
        "summary": "With the advent of ride-sharing services, there is a huge increase in the number of people who rely on them for various needs. Most of the earlier approaches tackling this issue required handcrafted functions for estimating travel times and passenger waiting times. Traditional Reinforcement Learning (RL) based methods attempting to solve the ridesharing problem are unable to accurately model the complex environment in which taxis operate. Prior Multi-Agent Deep RL based methods based on Independent DQN (IDQN) learn decentralized value functions prone to instability due to the concurrent learning and exploring of multiple agents. Our proposed method based on QMIX is able to achieve centralized training with decentralized execution. We show that our model performs better than the IDQN baseline on a fixed grid size and is able to generalize well to smaller or larger grid sizes. Also, our algorithm is able to outperform IDQN baseline in the scenario where we have a variable number of passengers and cars in each episode. Code for our paper is publicly available at: https://github.com/UMich-ML-Group/RL-Ridesharing.",
        "published": "2020-06-18T23:37:53Z",
        "link": "http://arxiv.org/abs/2006.10897v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Contextual and Possibilistic Reasoning for Coalition Formation",
        "authors": [
            "Antonis Bikakis",
            "Patrice Caire"
        ],
        "summary": "In multiagent systems, agents often have to rely on other agents to reach their goals, for example when they lack a needed resource or do not have the capability to perform a required action. Agents therefore need to cooperate. Then, some of the questions raised are: Which agent(s) to cooperate with? What are the potential coalitions in which agents can achieve their goals? As the number of possibilities is potentially quite large, how to automate the process? And then, how to select the most appropriate coalition, taking into account the uncertainty in the agents' abilities to carry out certain tasks? In this article, we address the question of how to find and evaluate coalitions among agents in multiagent systems using MCS tools, while taking into consideration the uncertainty around the agents' actions. Our methodology is the following: We first compute the solution space for the formation of coalitions using a contextual reasoning approach. Second, we model agents as contexts in Multi-Context Systems (MCS), and dependence relations among agents seeking to achieve their goals, as bridge rules. Third, we systematically compute all potential coalitions using algorithms for MCS equilibria, and given a set of functional and non-functional requirements, we propose ways to select the best solutions. Finally, in order to handle the uncertainty in the agents' actions, we extend our approach with features of possibilistic reasoning. We illustrate our approach with an example from robotics.",
        "published": "2020-06-19T11:59:55Z",
        "link": "http://arxiv.org/abs/2006.11097v2",
        "categories": [
            "cs.AI",
            "cs.LO",
            "cs.MA"
        ]
    },
    {
        "title": "Deep Implicit Coordination Graphs for Multi-agent Reinforcement Learning",
        "authors": [
            "Sheng Li",
            "Jayesh K. Gupta",
            "Peter Morales",
            "Ross Allen",
            "Mykel J. Kochenderfer"
        ],
        "summary": "Multi-agent reinforcement learning (MARL) requires coordination to efficiently solve certain tasks. Fully centralized control is often infeasible in such domains due to the size of joint action spaces. Coordination graph based formalization allows reasoning about the joint action based on the structure of interactions. However, they often require domain expertise in their design. This paper introduces the deep implicit coordination graph (DICG) architecture for such scenarios. DICG consists of a module for inferring the dynamic coordination graph structure which is then used by a graph neural network based module to learn to implicitly reason about the joint actions or values. DICG allows learning the tradeoff between full centralization and decentralization via standard actor-critic methods to significantly improve coordination for domains with large number of agents. We apply DICG to both centralized-training-centralized-execution and centralized-training-decentralized-execution regimes. We demonstrate that DICG solves the relative overgeneralization pathology in predatory-prey tasks as well as outperforms various MARL baselines on the challenging StarCraft II Multi-agent Challenge (SMAC) and traffic junction environments.",
        "published": "2020-06-19T23:41:49Z",
        "link": "http://arxiv.org/abs/2006.11438v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Collective Learning by Ensembles of Altruistic Diversifying Neural   Networks",
        "authors": [
            "Benjamin Brazowski",
            "Elad Schneidman"
        ],
        "summary": "Combining the predictions of collections of neural networks often outperforms the best single network. Such ensembles are typically trained independently, and their superior `wisdom of the crowd' originates from the differences between networks. Collective foraging and decision making in socially interacting animal groups is often improved or even optimal thanks to local information sharing between conspecifics. We therefore present a model for co-learning by ensembles of interacting neural networks that aim to maximize their own performance but also their functional relations to other networks. We show that ensembles of interacting networks outperform independent ones, and that optimal ensemble performance is reached when the coupling between networks increases diversity and degrades the performance of individual networks. Thus, even without a global goal for the ensemble, optimal collective behavior emerges from local interactions between networks. We show the scaling of optimal coupling strength with ensemble size, and that networks in these ensembles specialize functionally and become more `confident' in their assessments. Moreover, optimal co-learning networks differ structurally, relying on sparser activity, a wider range of synaptic weights, and higher firing rates - compared to independently trained networks. Finally, we explore interactions-based co-learning as a framework for expanding and boosting ensembles.",
        "published": "2020-06-20T22:53:32Z",
        "link": "http://arxiv.org/abs/2006.11671v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "cs.NE",
            "stat.ML"
        ]
    },
    {
        "title": "Reinforcement Learning for Mean Field Games with Strategic   Complementarities",
        "authors": [
            "Kiyeob Lee",
            "Desik Rengarajan",
            "Dileep Kalathil",
            "Srinivas Shakkottai"
        ],
        "summary": "Mean Field Games (MFG) are the class of games with a very large number of agents and the standard equilibrium concept is a Mean Field Equilibrium (MFE). Algorithms for learning MFE in dynamic MFGs are unknown in general. Our focus is on an important subclass that possess a monotonicity property called Strategic Complementarities (MFG-SC). We introduce a natural refinement to the equilibrium concept that we call Trembling-Hand-Perfect MFE (T-MFE), which allows agents to employ a measure of randomization while accounting for the impact of such randomization on their payoffs. We propose a simple algorithm for computing T-MFE under a known model. We also introduce a model-free and a model-based approach to learning T-MFE and provide sample complexities of both algorithms. We also develop a fully online learning scheme that obviates the need for a simulator. Finally, we empirically evaluate the performance of the proposed algorithms via examples motivated by real-world applications.",
        "published": "2020-06-21T00:31:48Z",
        "link": "http://arxiv.org/abs/2006.11683v3",
        "categories": [
            "math.OC",
            "cs.GT",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Integrating Industrial Artifacts and Agents Through Apache Camel",
        "authors": [
            "Cleber Jorge Amaral",
            "Stephen Cranefield",
            "Jomi Fred Hübner",
            "Mario Lucio Roloff"
        ],
        "summary": "There are many challenges for building up the smart factory, among them to deal with distributed data, high volume of information, and wide diversity of devices and applications. In this sense, Cyber-Physical System (CPS) concept emerges to virtualize and integrate factory resources. Based on studies that use Multi-Agent System as the core of a CPS, in this paper, we show that many resources of the factories can be modelled following the well-known Agents and Artifacts method of integrating agents and their environment. To enhance the interoperability of this system, we use Apache Camel framework, a middleware to define routes allowing the integration with a wide range of endpoints using different protocols. Finally, we present a Camel component for artifacts, designed in this research, illustrating its use.",
        "published": "2020-06-21T02:43:19Z",
        "link": "http://arxiv.org/abs/2006.11694v1",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Emergent cooperation through mutual information maximization",
        "authors": [
            "Santiago Cuervo",
            "Marco Alzate"
        ],
        "summary": "With artificial intelligence systems becoming ubiquitous in our society, its designers will soon have to start to consider its social dimension, as many of these systems will have to interact among them to work efficiently. With this in mind, we propose a decentralized deep reinforcement learning algorithm for the design of cooperative multi-agent systems. The algorithm is based on the hypothesis that highly correlated actions are a feature of cooperative systems, and hence, we propose the insertion of an auxiliary objective of maximization of the mutual information between the actions of agents in the learning problem. Our system is applied to a social dilemma, a problem whose optimal solution requires that agents cooperate to maximize a macroscopic performance function despite the divergent individual objectives of each agent. By comparing the performance of the proposed system to a system without the auxiliary objective, we conclude that the maximization of mutual information among agents promotes the emergence of cooperation in social dilemmas.",
        "published": "2020-06-21T11:15:55Z",
        "link": "http://arxiv.org/abs/2006.11769v1",
        "categories": [
            "cs.AI",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "An Online Algorithm for Computation Offloading in Non-Stationary   Environments",
        "authors": [
            "Aniq Ur Rahman",
            "Gourab Ghatak",
            "Antonio De Domenico"
        ],
        "summary": "We consider the latency minimization problem in a task-offloading scenario, where multiple servers are available to the user equipment for outsourcing computational tasks. To account for the temporally dynamic nature of the wireless links and the availability of the computing resources, we model the server selection as a multi-armed bandit (MAB) problem. In the considered MAB framework, rewards are characterized in terms of the end-to-end latency. We propose a novel online learning algorithm based on the principle of optimism in the face of uncertainty, which outperforms the state-of-the-art algorithms by up to ~1s. Our results highlight the significance of heavily discounting the past rewards in dynamic environments.",
        "published": "2020-06-22T07:00:47Z",
        "link": "http://arxiv.org/abs/2006.12032v1",
        "categories": [
            "eess.SP",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Stablecoins 2.0: Economic Foundations and Risk-based Models",
        "authors": [
            "Ariah Klages-Mundt",
            "Dominik Harz",
            "Lewis Gudgeon",
            "Jun-You Liu",
            "Andreea Minca"
        ],
        "summary": "Stablecoins are one of the most widely capitalized type of cryptocurrency. However, their risks vary significantly according to their design and are often poorly understood. We seek to provide a sound foundation for stablecoin theory, with a risk-based functional characterization of the economic structure of stablecoins. First, we match existing economic models to the disparate set of custodial systems. Next, we characterize the unique risks that emerge in non-custodial stablecoins and develop a model framework that unifies existing models from economics and computer science. We further discuss how this modeling framework is applicable to a wide array of cryptoeconomic systems, including cross-chain protocols, collateralized lending, and decentralized exchanges. These unique risks yield unanswered research questions that will form the crux of research in decentralized finance going forward.",
        "published": "2020-06-22T16:17:58Z",
        "link": "http://arxiv.org/abs/2006.12388v3",
        "categories": [
            "econ.GN",
            "cs.CR",
            "cs.MA",
            "q-fin.EC"
        ]
    },
    {
        "title": "Asymptotic Boundary Shrink Control with Multi-robot Systems",
        "authors": [
            "Shaocheng Luo",
            "Jonghoek Kim",
            "Byung-Cheol Min"
        ],
        "summary": "Harmful marine spills, such as algae blooms and oil spills, damage ecosystems and threaten public health tremendously. Hence, an effective spill coverage and removal strategy will play a significant role in environmental protection. In recent years, low-cost water surface robots have emerged as a solution, with their efficacy verified at small scale. However, practical limitations such as connectivity, scalability, and sensing and operation ranges significantly impair their large-scale use. To circumvent these limitations, we propose a novel asymptotic boundary shrink control strategy that enables collective coverage of a spill by autonomous robots featuring customized operation ranges. For each robot, a novel controller is implemented that relies only on local vision sensors with limited vision range. Moreover, the distributedness of this strategy allows any number of robots to be employed without inter-robot collisions. Finally, features of this approach including the convergence of robot motion during boundary shrink control, spill clearance rate, and the capability to work under limited ranges of vision and wireless connectivity are validated through extensive experiments with simulation.",
        "published": "2020-06-22T17:50:27Z",
        "link": "http://arxiv.org/abs/2006.12470v2",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Online Multi-agent Reinforcement Learning for Decentralized   Inverter-based Volt-VAR Control",
        "authors": [
            "Haotian Liu",
            "Wenchuan Wu"
        ],
        "summary": "The distributed Volt/Var control (VVC) methods have been widely studied for active distribution networks(ADNs), which is based on perfect model and real-time P2P communication. However, the model is always incomplete with significant parameter errors and such P2P communication system is hard to maintain. In this paper, we propose an online multi-agent reinforcement learning and decentralized control framework (OLDC) for VVC. In this framework, the VVC problem is formulated as a constrained Markov game and we propose a novel multi-agent constrained soft actor-critic (MACSAC) reinforcement learning algorithm. MACSAC is used to train the control agents online, so the accurate ADN model is no longer needed. Then, the trained agents can realize decentralized optimal control using local measurements without real-time P2P communication. The OLDC with MACSAC has shown extraordinary flexibility, efficiency and robustness to various computing and communication conditions. Numerical simulations on IEEE test cases not only demonstrate that the proposed MACSAC outperforms the state-of-art learning algorithms, but also support the superiority of our OLDC framework in the online application.",
        "published": "2020-06-23T09:03:46Z",
        "link": "http://arxiv.org/abs/2006.12841v2",
        "categories": [
            "eess.SY",
            "cs.LG",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Calibration of Shared Equilibria in General Sum Partially Observable   Markov Games",
        "authors": [
            "Nelson Vadori",
            "Sumitra Ganesh",
            "Prashant Reddy",
            "Manuela Veloso"
        ],
        "summary": "Training multi-agent systems (MAS) to achieve realistic equilibria gives us a useful tool to understand and model real-world systems. We consider a general sum partially observable Markov game where agents of different types share a single policy network, conditioned on agent-specific information. This paper aims at i) formally understanding equilibria reached by such agents, and ii) matching emergent phenomena of such equilibria to real-world targets. Parameter sharing with decentralized execution has been introduced as an efficient way to train multiple agents using a single policy network. However, the nature of resulting equilibria reached by such agents has not been yet studied: we introduce the novel concept of Shared equilibrium as a symmetric pure Nash equilibrium of a certain Functional Form Game (FFG) and prove convergence to the latter for a certain class of games using self-play. In addition, it is important that such equilibria satisfy certain constraints so that MAS are calibrated to real world data for practical use: we solve this problem by introducing a novel dual-Reinforcement Learning based approach that fits emergent behaviors of agents in a Shared equilibrium to externally-specified targets, and apply our methods to a n-player market example. We do so by calibrating parameters governing distributions of agent types rather than individual agents, which allows both behavior differentiation among agents and coherent scaling of the shared policy network to multiple agents.",
        "published": "2020-06-23T15:14:20Z",
        "link": "http://arxiv.org/abs/2006.13085v5",
        "categories": [
            "cs.MA",
            "cs.LG"
        ]
    },
    {
        "title": "Autonomous and Semi-Autonomous Intersection Management: A Survey",
        "authors": [
            "Zijia Zhong",
            "Mark Nejad",
            "Earl E. Lee"
        ],
        "summary": "Intersection is a major source of traffic delays and accidents within modern transportation systems. Compared to signalized intersection management, autonomous intersection management (AIM) coordinates the intersection crossing at an individual vehicle level with additional flexibility. AIM can potentially eliminate stopping in intersection crossing due to traffic lights while maintaining a safe separation among conflicting movements. In this paper, the state-of-the-art AIM research among various disciplines (e.g., traffic engineering, control engineering) is surveyed from the perspective of three hierarchical layers: corridor coordination layer, intersection management layer, and vehicle control layer. The key aspects of AIM designs are discussed in details, including conflict detection schemes, priority rules, control centralization, computation complexity, etc. The potential improvements for AIM evaluation with the emphasis of realistic scenarios are provided. This survey serves as a comprehensive review of AIM design and provides promising directions for future research.",
        "published": "2020-06-23T16:28:08Z",
        "link": "http://arxiv.org/abs/2006.13133v3",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Joint Object Detection and Multi-Object Tracking with Graph Neural   Networks",
        "authors": [
            "Yongxin Wang",
            "Kris Kitani",
            "Xinshuo Weng"
        ],
        "summary": "Object detection and data association are critical components in multi-object tracking (MOT) systems. Despite the fact that the two components are dependent on each other, prior works often design detection and data association modules separately which are trained with separate objectives. As a result, one cannot back-propagate the gradients and optimize the entire MOT system, which leads to sub-optimal performance. To address this issue, recent works simultaneously optimize detection and data association modules under a joint MOT framework, which has shown improved performance in both modules. In this work, we propose a new instance of joint MOT approach based on Graph Neural Networks (GNNs). The key idea is that GNNs can model relations between variable-sized objects in both the spatial and temporal domains, which is essential for learning discriminative features for detection and data association. Through extensive experiments on the MOT15/16/17/20 datasets, we demonstrate the effectiveness of our GNN-based joint MOT approach and show state-of-the-art performance for both detection and MOT tasks. Our code is available at: https://github.com/yongxinw/GSDT",
        "published": "2020-06-23T17:07:00Z",
        "link": "http://arxiv.org/abs/2006.13164v3",
        "categories": [
            "cs.CV",
            "cs.LG",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Impact of COVID-19 behavioral inertia on reopening strategies for New   York City Transit",
        "authors": [
            "Ding Wang",
            "Brian Yueshuai He",
            "Jingqin Gao",
            "Joseph Y. J. Chow",
            "Kaan Ozbay",
            "Shri Iyer"
        ],
        "summary": "The COVID-19 pandemic has affected travel behaviors and transportation system operations, and cities are grappling with what policies can be effective for a phased reopening shaped by social distancing. A baseline model was previously developed and calibrated for pre-COVID conditions as MATSim-NYC. A new COVID model is calibrated that represents travel behavior during the COVID-19 pandemic by recalibrating the population agendas to include work-from-home and re-estimating the mode choice model for MATSim-NYC to fit observed traffic and transit ridership data. Assuming the change in behavior exhibits inertia during reopening, we analyze the increase in car traffic due to the phased reopen plan guided by the state government of New York. Four reopening phases and two reopening scenarios (with and without transit capacity restrictions) are analyzed. A Phase 4 reopening with 100% transit capacity may only see as much as 73% of pre-COVID ridership and an increase in the number of car trips by as much as 142% of pre-pandemic levels. Limiting transit capacity to 50% would decrease transit ridership further from 73% to 64% while increasing car trips to as much as 143% of pre-pandemic levels. While the increase appears small, the impact on consumer surplus is disproportionately large due to already increased traffic congestion. Many of the trips also get shifted to other modes like micromobility. The findings imply that a transit capacity restriction policy during reopening needs to be accompanied by (1) support for micromobility modes, particularly in non-Manhattan boroughs, and (2) congestion alleviation policies that focus on reducing traffic in Manhattan, such as cordon-based pricing.",
        "published": "2020-06-23T22:46:22Z",
        "link": "http://arxiv.org/abs/2006.13368v2",
        "categories": [
            "econ.GN",
            "cs.MA",
            "physics.soc-ph",
            "q-fin.EC"
        ]
    },
    {
        "title": "Namira Soccer 2D Simulation Team Description Paper 2020",
        "authors": [
            "Ehsan Asali",
            "Farzin Negahbani",
            "Shahriyar Bamaei",
            "Zahra Abbasi"
        ],
        "summary": "In this article, we will discuss methods and ideas which are implemented on Namira 2D Soccer Simulation team in the recent year. Numerous scientific and programming activities were done in the process of code development, but we will mention the most outstanding ones in details. A Kalman filtering method for localization and two helpful software packages will be discussed here. Namira uses agent2d-3.1.1 as base code and librcsc-4.1.0 as library with some deliberate changes.",
        "published": "2020-06-24T07:40:44Z",
        "link": "http://arxiv.org/abs/2006.13534v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Partial Information Sharing over Social Learning Networks",
        "authors": [
            "Virginia Bordignon",
            "Vincenzo Matta",
            "Ali H. Sayed"
        ],
        "summary": "This work addresses the problem of sharing partial information within social learning strategies. In traditional social learning, agents solve a distributed multiple hypothesis testing problem by performing two operations at each instant: first, agents incorporate information from private observations to form their beliefs over a set of hypotheses; second, agents combine the entirety of their beliefs locally among neighbors. Within a sufficiently informative environment and as long as the connectivity of the network allows information to diffuse across agents, these algorithms enable agents to learn the true hypothesis. Instead of sharing the entirety of their beliefs, this work considers the case in which agents will only share their beliefs regarding one hypothesis of interest, with the purpose of evaluating its validity, and draws conditions under which this policy does not affect truth learning. We propose two approaches for sharing partial information, depending on whether agents behave in a self-aware manner or not. The results show how different learning regimes arise, depending on the approach employed and on the inherent characteristics of the inference problem. Furthermore, the analysis interestingly points to the possibility of deceiving the network, as long as the evaluated hypothesis of interest is close enough to the truth.",
        "published": "2020-06-24T12:22:27Z",
        "link": "http://arxiv.org/abs/2006.13659v2",
        "categories": [
            "eess.SP",
            "cs.MA"
        ]
    },
    {
        "title": "Competitive Balance in Team Sports Games",
        "authors": [
            "Sofia M Nikolakaki",
            "Ogheneovo Dibie",
            "Ahmad Beirami",
            "Nicholas Peterson",
            "Navid Aghdaie",
            "Kazi Zaman"
        ],
        "summary": "Competition is a primary driver of player satisfaction and engagement in multiplayer online games. Traditional matchmaking systems aim at creating matches involving teams of similar aggregated individual skill levels, such as Elo score or TrueSkill. However, team dynamics cannot be solely captured using such linear predictors. Recently, it has been shown that nonlinear predictors that target to learn probability of winning as a function of player and team features significantly outperforms these linear skill-based methods. In this paper, we show that using final score difference provides yet a better prediction metric for competitive balance. We also show that a linear model trained on a carefully selected set of team and individual features achieves almost the performance of the more powerful neural network model while offering two orders of magnitude inference speed improvement. This shows significant promise for implementation in online matchmaking systems.",
        "published": "2020-06-24T14:19:07Z",
        "link": "http://arxiv.org/abs/2006.13763v1",
        "categories": [
            "cs.SI",
            "cs.AI",
            "cs.HC",
            "cs.MA"
        ]
    },
    {
        "title": "Unified Reinforcement Q-Learning for Mean Field Game and Control   Problems",
        "authors": [
            "Andrea Angiuli",
            "Jean-Pierre Fouque",
            "Mathieu Laurière"
        ],
        "summary": "We present a Reinforcement Learning (RL) algorithm to solve infinite horizon asymptotic Mean Field Game (MFG) and Mean Field Control (MFC) problems. Our approach can be described as a unified two-timescale Mean Field Q-learning: The \\emph{same} algorithm can learn either the MFG or the MFC solution by simply tuning the ratio of two learning parameters. The algorithm is in discrete time and space where the agent not only provides an action to the environment but also a distribution of the state in order to take into account the mean field feature of the problem. Importantly, we assume that the agent can not observe the population's distribution and needs to estimate it in a model-free manner. The asymptotic MFG and MFC problems are also presented in continuous time and space, and compared with classical (non-asymptotic or stationary) MFG and MFC problems. They lead to explicit solutions in the linear-quadratic (LQ) case that are used as benchmarks for the results of our algorithm.",
        "published": "2020-06-24T17:45:44Z",
        "link": "http://arxiv.org/abs/2006.13912v3",
        "categories": [
            "math.OC",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Distributed Policy Synthesis of Multi-Agent Systems With Graph Temporal   Logic Specifications",
        "authors": [
            "Murat Cubuktepe",
            "Zhe Xu",
            "Ufuk Topcu"
        ],
        "summary": "We study the distributed synthesis of policies for multi-agent systems to perform \\emph{spatial-temporal} tasks. We formalize the synthesis problem as a \\emph{factored} Markov decision process subject to \\emph{graph temporal logic} specifications. The transition function and task of each agent are functions of the agent itself and its neighboring agents. In this work, we develop another distributed synthesis method, which improves the scalability and runtime by two orders of magnitude compared to our prior work. The synthesis method decomposes the problem into a set of smaller problems, one for each agent by leveraging the structure in the model, and the specifications. We show that the running time of the method is linear in the number of agents. The size of the problem for each agent is exponential only in the number of neighboring agents, which is typically much smaller than the number of agents. We demonstrate the applicability of the method in case studies on disease control, urban security, and search and rescue. The numerical examples show that the method scales to hundreds of agents with hundreds of states per agent and can also handle significantly larger state spaces than our prior work.",
        "published": "2020-06-25T00:56:28Z",
        "link": "http://arxiv.org/abs/2006.14947v3",
        "categories": [
            "cs.MA",
            "cs.LO"
        ]
    },
    {
        "title": "Perigee: Efficient Peer-to-Peer Network Design for Blockchains",
        "authors": [
            "Yifan Mao",
            "Soubhik Deb",
            "Shaileshh Bojja Venkatakrishnan",
            "Sreeram Kannan",
            "Kannan Srinivasan"
        ],
        "summary": "A key performance metric in blockchains is the latency between when a transaction is broadcast and when it is confirmed (the so-called, confirmation latency). While improvements in consensus techniques can lead to lower confirmation latency, a fundamental lower bound on confirmation latency is the propagation latency of messages through the underlying peer-to-peer (p2p) network (inBitcoin, the propagation latency is several tens of seconds). The de facto p2p protocol used by Bitcoin and other blockchains is based on random connectivity: each node connects to a random subset of nodes. The induced p2p network topology can be highly suboptimal since it neglects geographical distance, differences in bandwidth, hash-power and computational abilities across peers. We present Perigee, a decentralized algorithm that automatically learns an efficient p2p topology tuned to the aforementioned network heterogeneities, purely based on peers' interactions with their neighbors. Motivated by the literature on the multi-armed bandit problem, Perigee optimally balances the tradeoff between retaining connections to known well-connected neighbors, and exploring new connections to previously-unseen neighbors. Experimental evaluations show that Perigee reduces the latency to broadcast by $33\\%$. Lastly Perigee is simple, computationally lightweight, adversary-resistant, and compatible with the selfish interests of peers, making it an attractive p2p protocol for blockchains.",
        "published": "2020-06-25T05:24:11Z",
        "link": "http://arxiv.org/abs/2006.14186v1",
        "categories": [
            "cs.NI",
            "cs.MA",
            "math.OC",
            "stat.AP"
        ]
    },
    {
        "title": "Intervention scenarios to enhance knowledge transfer in a network of   firm",
        "authors": [
            "Frank Schweitzer",
            "Yan Zhang",
            "Giona Casiraghi"
        ],
        "summary": "We investigate a multi-agent model of firms in an R\\&D network. Each firm is characterized by its knowledge stock $x_{i}(t)$, which follows a non-linear dynamics. It can grow with the input from other firms, i.e., by knowledge transfer, and decays otherwise. Maintaining interactions is costly. Firms can leave the network if their expected knowledge growth is not realized, which may cause other firms to also leave the network. The paper discusses two bottom-up intervention scenarios to prevent, reduce, or delay cascades of firms leaving. The first one is based on the formalism of network controllability, in which driver nodes are identified and subsequently incentivized, by reducing their costs. The second one combines node interventions and network interventions. It proposes the controlled removal of a single firm and the random replacement of firms leaving. This allows to generate small cascades, which prevents the occurrence of large cascades. We find that both approaches successfully mitigate cascades and thus improve the resilience of the R\\&D network.",
        "published": "2020-06-25T08:39:28Z",
        "link": "http://arxiv.org/abs/2006.14249v1",
        "categories": [
            "physics.soc-ph",
            "cs.MA",
            "cs.SI",
            "nlin.AO"
        ]
    },
    {
        "title": "A mechanism to promote social behaviour in household load balancing",
        "authors": [
            "Nathan A. Brooks",
            "Simon T. Powers",
            "James M. Borg"
        ],
        "summary": "Reducing the peak energy consumption of households is essential for the effective use of renewable energy sources, in order to ensure that as much household demand as possible can be met by renewable sources. This entails spreading out the use of high-powered appliances such as dishwashers and washing machines throughout the day. Traditional approaches to this problem have relied on differential pricing set by a centralised utility company. But this mechanism has not been effective in promoting widespread shifting of appliance usage. Here we consider an alternative decentralised mechanism, where agents receive an initial allocation of time-slots to use their appliances and can then exchange these with other agents. If agents are willing to be more flexible in the exchanges they accept, then overall satisfaction, in terms of the percentage of agents time-slot preferences that are satisfied, will increase. This requires a mechanism that can incentivise agents to be more flexible. Building on previous work, we show that a mechanism incorporating social capital - the tracking of favours given and received - can incentivise agents to act flexibly and give favours by accepting exchanges that do not immediately benefit them. We demonstrate that a mechanism that tracks favours increases the overall satisfaction of agents, and crucially allows social agents that give favours to outcompete selfish agents that do not under payoff-biased social learning. Thus, even completely self-interested agents are expected to learn to produce socially beneficial outcomes.",
        "published": "2020-06-25T16:23:02Z",
        "link": "http://arxiv.org/abs/2006.14526v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "A Hennessy-Milner Theorem for ATL with Imperfect Information",
        "authors": [
            "Francesco Belardinelli",
            "Catalin Dima",
            "Vadim Malvone",
            "Ferucio Tiplea"
        ],
        "summary": "We show that a history-based variant of alternating bisimulation with imperfect information allows it to be related to a variant of Alternating-time Temporal Logic (ATL) with imperfect information by a full Hennessy-Milner theorem. The variant of ATL we consider has a common knowledge semantics, which requires that the uniform strategy available for a coalition to accomplish some goal must be common knowledge inside the coalition, while other semantic variants of ATL with imperfect information do not accommodate a Hennessy-Milner theorem. We also show that the existence of a history-based alternating bisimulation between two finite Concurrent Game Structures with imperfect information (iCGS) is undecidable.",
        "published": "2020-06-26T14:12:11Z",
        "link": "http://arxiv.org/abs/2006.15000v1",
        "categories": [
            "cs.LO",
            "cs.MA"
        ]
    },
    {
        "title": "Simulating human interactions in supermarkets to measure the risk of   COVID-19 contagion at scale",
        "authors": [
            "Serge Plata",
            "Sumanas Sarma",
            "Melvin Lancelot",
            "Kristine Bagrova",
            "David Romano-Critchley"
        ],
        "summary": "Taking the context of simulating a retail environment using agent based modelling, a theoretical model is presented that describes the probability distribution of customer \"collisions\" using a novel space transformation to the Torus $Tor^2$. A method for generating the distribution of customer paths based on historical basket data is developed. Finally a calculation of the number of simulations required for statistical significance is developed. An implementation of this modelling approach to run simulations on multiple store geometries at industrial scale is being developed with current progress detailed in the technical appendix.",
        "published": "2020-06-26T21:04:09Z",
        "link": "http://arxiv.org/abs/2006.15213v1",
        "categories": [
            "cs.DC",
            "cs.MA",
            "00A69"
        ]
    },
    {
        "title": "Using Reinforcement Learning to Herd a Robotic Swarm to a Target   Distribution",
        "authors": [
            "Zahi M. Kakish",
            "Karthik Elamvazhuthi",
            "Spring Berman"
        ],
        "summary": "In this paper, we present a reinforcement learning approach to designing a control policy for a \"leader\" agent that herds a swarm of \"follower\" agents, via repulsive interactions, as quickly as possible to a target probability distribution over a strongly connected graph. The leader control policy is a function of the swarm distribution, which evolves over time according to a mean-field model in the form of an ordinary difference equation. The dependence of the policy on agent populations at each graph vertex, rather than on individual agent activity, simplifies the observations required by the leader and enables the control strategy to scale with the number of agents. Two Temporal-Difference learning algorithms, SARSA and Q-Learning, are used to generate the leader control policy based on the follower agent distribution and the leader's location on the graph. A simulation environment corresponding to a grid graph with 4 vertices was used to train and validate the control policies for follower agent populations ranging from 10 to 100. Finally, the control policies trained on 100 simulated agents were used to successfully redistribute a physical swarm of 10 small robots to a target distribution among 4 spatial regions.",
        "published": "2020-06-29T04:55:59Z",
        "link": "http://arxiv.org/abs/2006.15807v2",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "The Evolutionary Dynamics of Independent Learning Agents in Population   Games",
        "authors": [
            "Shuyue Hu",
            "Chin-Wing Leung",
            "Ho-fung Leung",
            "Harold Soh"
        ],
        "summary": "Understanding the evolutionary dynamics of reinforcement learning under multi-agent settings has long remained an open problem. While previous works primarily focus on 2-player games, we consider population games, which model the strategic interactions of a large population comprising small and anonymous agents. This paper presents a formal relation between stochastic processes and the dynamics of independent learning agents who reason based on the reward signals. Using a master equation approach, we provide a novel unified framework for characterising population dynamics via a single partial differential equation (Theorem 1). Through a case study involving Cross learning agents, we illustrate that Theorem 1 allows us to identify qualitatively different evolutionary dynamics, to analyse steady states, and to gain insights into the expected behaviour of a population. In addition, we present extensive experimental results validating that Theorem 1 holds for a variety of learning methods and population games.",
        "published": "2020-06-29T14:22:23Z",
        "link": "http://arxiv.org/abs/2006.16068v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "An agent-based model of interdisciplinary interactions in science",
        "authors": [
            "Juste Raimbault"
        ],
        "summary": "An increased interdisciplinarity in science projects has been highlighted as crucial to tackle complex real-world challenges, but also as beneficial for the development of disciplines themselves. This paper introduces a parcimonious agent-based model of interdisciplinary relationships in collective entreprises of knowledge discovery, to investigate the impact of scientist-level decisions and preferences on global interdisciplinarity patterns. Under the assumption of simple rules for individual researcher project management, such as trade-offs between invested time overhead and knowledge benefit, model simulations show that individual choices influence the distribution of compromise points between emergent level of disciplinary depth and interdisciplinarity in a non-linear way. Different structures for collaboration networks may also yield various outcomes in terms of global interdisciplinarity. We conclude that independently of the research field, the organization of research, and more particularly the local balancing between vertical and horizontal research, already influences the final positioning of research results and the extent of the knowledge front. This suggests direct applications to research policies with a bottom-up leverage on the interactions between disciplines.",
        "published": "2020-06-29T21:28:39Z",
        "link": "http://arxiv.org/abs/2006.16399v1",
        "categories": [
            "physics.soc-ph",
            "cs.DL",
            "cs.MA"
        ]
    },
    {
        "title": "Deep Learning Based Proactive Multi-Objective Eco-Routing Strategies for   Connected and Automated Vehicles",
        "authors": [
            "Lama Alfaseeh",
            "Bilal Farooq"
        ],
        "summary": "This study exploits the advancements in information and communication technology (ICT), connected and automated vehicles (CAVs), and sensing, to develop proactive multi-objective eco-routing strategies. For a robust application, several GHG costing approaches are examined. The predictive models for the link level traffic and emission states are developed using long short term memory deep network with exogenous predictors. It is found that proactive routing strategies outperformed the myopic strategies, regardless of the routing objective. Whether myopic or proactive, the multi-objective routing, with travel time and GHG minimization as objectives, outperformed the single objective routing strategies, causing a reduction in the average travel time (TT), average vehicle kilometre travelled (VKT), total GHG and total NOx by 17%, 21%, 18%, and 20%, respectively. Finally, the additional TT and VKT experienced by the vehicles in the network contributed adversely to the amount of GHG and NOx produced in the network.",
        "published": "2020-06-30T02:07:10Z",
        "link": "http://arxiv.org/abs/2006.16472v2",
        "categories": [
            "math.OC",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Robust Multi-Agent Task Assignment in Failure-Prone and Adversarial   Environments",
        "authors": [
            "Russell Schwartz",
            "Pratap Tokekar"
        ],
        "summary": "The problem of assigning agents to tasks is a central computational challenge in many multi-agent autonomous systems. However, in the real world, agents are not always perfect and may fail due to a number of reasons. A motivating application is where the agents are robots that operate in the physical world and are susceptible to failures. This paper studies the problem of Robust Multi-Agent Task Assignment, which seeks to find an assignment that maximizes overall system performance while accounting for potential failures of the agents. We investigate both, stochastic and adversarial failures under this framework. For both cases, we present efficient algorithms that yield optimal or near-optimal results.",
        "published": "2020-06-30T21:00:17Z",
        "link": "http://arxiv.org/abs/2007.00100v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Allocation of Multi-Robot Tasks with Task Variants",
        "authors": [
            "Zakk Giacometti",
            "Yu Zhang"
        ],
        "summary": "Task allocation has been a well studied problem. In most prior problem formulations, it is assumed that each task is associated with a unique set of resource requirements. In the scope of multi-robot task allocation problem, these requirements can be satisfied by a coalition of robots. In this paper, we introduce a more general formulation of multi-robot task allocation problem that allows more than one option for specifying the set of task requirements--satisfying any one of the options will satisfy the task. We referred to this new problem as the multi-robot task allocation problem with task variants. First, we theoretically show that this extension fortunately does not impact the complexity class, which is still NP-complete. For solution methods, we adapt two previous greedy methods for the task allocation problem without task variants to solve this new problem and analyze their effectiveness. In particular, we \"flatten\" the new problem to the problem without task variants, modify the previous methods to solve the flattened problem, and prove that the bounds still hold. Finally, we thoroughly evaluate these two methods along with a random baseline to demonstrate their efficacy for the new problem.",
        "published": "2020-07-01T21:45:06Z",
        "link": "http://arxiv.org/abs/2007.00777v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Proofs of Useless Work -- Positive and Negative Results for Wasteless   Mining Systems",
        "authors": [
            "Maya Dotan",
            "Saar Tochner"
        ],
        "summary": "Many blockchain systems today, including Bitcoin, rely on Proof of Work (PoW). Proof of work is crucial to the liveness and security of cryptocurrencies. The assumption when using PoW is that a lot of trial and error is required on average before a valid block is generated. One of the main concerns raised with regard to this kind of system is the inherent need to \"waste\" energy on \"meaningless\" problems. In fact, the Bitcoin system is believed to consume more electricity than several small countries.   In this work we formally define three properties that are necessary for wasteless PoW systems: (1) solve \"meaningful\" problems (2) solve them efficiently and (3) be secure against double-spend attacks. These properties aim to create an open market for problem-solving, in which miners produce solutions to problems in the most efficient way (wasteless). The security of the system stems from the economical incentive created by the demand for solutions to these problems.   We analyze these properties, and deduce constraints that must apply to such PoW systems. In our main result, we conclude that under realistic assumptions, the set of allowed problems must be preimage resistant functions in order to keep the system secure and efficient.",
        "published": "2020-07-02T12:07:26Z",
        "link": "http://arxiv.org/abs/2007.01046v2",
        "categories": [
            "cs.CR",
            "cs.DC",
            "cs.MA"
        ]
    },
    {
        "title": "Modelling heterogeneous outcomes in multi-agent systems",
        "authors": [
            "Orowa Sikder"
        ],
        "summary": "A broad set of empirical phenomenon in the study of social, economic and machine behaviour can be modelled as complex systems with averaging dynamics. However many of these models naturally result in consensus or consensus-like outcomes. In reality, empirical phenomenon rarely converge to these and instead are characterized by rich, persistent variation in the agent states. Such heterogeneous outcomes are a natural consequence of a number of models that incorporate external perturbation to the otherwise convex dynamics of the agents. The purpose of this paper is to formalize the notion of heterogeneity and demonstrate which classes of models are able to achieve it as an outcome, and therefore are better suited to modelling important empirical questions. We do so by determining how the topology of (time-varying) interaction networks restrict the space of possible steady-state outcomes for agents, and how this is related to the study of random walks on graphs. We consider a number of intentionally diverse examples to demonstrate how the results can be applied.",
        "published": "2020-07-02T13:09:22Z",
        "link": "http://arxiv.org/abs/2007.01077v1",
        "categories": [
            "cs.MA",
            "cs.SI",
            "math.OC",
            "physics.soc-ph"
        ]
    },
    {
        "title": "A Conceptual Framework for Externally-influenced Agents: An Assisted   Reinforcement Learning Review",
        "authors": [
            "Adam Bignold",
            "Francisco Cruz",
            "Matthew E. Taylor",
            "Tim Brys",
            "Richard Dazeley",
            "Peter Vamplew",
            "Cameron Foale"
        ],
        "summary": "A long-term goal of reinforcement learning agents is to be able to perform tasks in complex real-world scenarios. The use of external information is one way of scaling agents to more complex problems. However, there is a general lack of collaboration or interoperability between different approaches using external information. In this work, while reviewing externally-influenced methods, we propose a conceptual framework and taxonomy for assisted reinforcement learning, aimed at fostering collaboration by classifying and comparing various methods that use external information in the learning process. The proposed taxonomy details the relationship between the external information source and the learner agent, highlighting the process of information decomposition, structure, retention, and how it can be used to influence agent learning. As well as reviewing state-of-the-art methods, we identify current streams of reinforcement learning that use external information in order to improve the agent's performance and its decision-making process. These include heuristic reinforcement learning, interactive reinforcement learning, learning from demonstration, transfer learning, and learning from multiple sources, among others. These streams of reinforcement learning operate with the shared objective of scaffolding the learner agent. Lastly, we discuss further possibilities for future work in the field of assisted reinforcement learning systems.",
        "published": "2020-07-03T08:07:31Z",
        "link": "http://arxiv.org/abs/2007.01544v2",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Social distancing with the Optimal Steps Model",
        "authors": [
            "Christina Maria Mayr",
            "Gerta Köster"
        ],
        "summary": "With the Covid-19 pandemic an urgent need to simulate social distancing arises. The Optimal Steps Model (OSM) is a pedestrian locomotion model that operationalizes an individual's need for personal space. We present new parameter values for personal space in the Optimal Steps Model to simulate social distancing in the pedestrian dynamics simulator Vadere. Our approach is pragmatic. We consider two use cases: in the first we demand that a set social distance must never be violated. In the second the social distance must be kept only on average. For each use case we conduct simulation studies in a typical bottleneck scenario and measure contact times, that is, violations of the social distance rule. We derive rules of thumb for suitable parameter choices in dependency of the desired social distance. We test the rules of thumb for the social distances 1.5m and 2.0m and observe that the new parameter values indeed lead to the desired social distancing. Thus, the rules of thumb will quickly enable Vadere users to conduct their own studies without understanding the intricacies of the OSM implementation and without extensive parameter adjustment.",
        "published": "2020-07-03T12:10:40Z",
        "link": "http://arxiv.org/abs/2007.01634v2",
        "categories": [
            "cs.MA",
            "physics.soc-ph"
        ]
    },
    {
        "title": "The Effects of Taxes on Wealth Inequality in Artificial Chemistry Models   of Economic Activity",
        "authors": [
            "Wolfgang Banzhaf"
        ],
        "summary": "We consider a number of Artificial Chemistry models for economic activity and what consequences they have for the formation of economic inequality. We are particularly interested in what tax measures are effective in dampening economic inequality. By starting from well-known kinetic exchange models, we examine different scenarios for reducing the tendency of economic activity models to form unequal wealth distribution in equilibrium.",
        "published": "2020-07-03T18:00:18Z",
        "link": "http://arxiv.org/abs/2007.02934v1",
        "categories": [
            "q-fin.GN",
            "cs.MA",
            "econ.GN",
            "physics.soc-ph",
            "q-fin.EC"
        ]
    },
    {
        "title": "Reward Machines for Cooperative Multi-Agent Reinforcement Learning",
        "authors": [
            "Cyrus Neary",
            "Zhe Xu",
            "Bo Wu",
            "Ufuk Topcu"
        ],
        "summary": "In cooperative multi-agent reinforcement learning, a collection of agents learns to interact in a shared environment to achieve a common goal. We propose the use of reward machines (RM) -- Mealy machines used as structured representations of reward functions -- to encode the team's task. The proposed novel interpretation of RMs in the multi-agent setting explicitly encodes required teammate interdependencies, allowing the team-level task to be decomposed into sub-tasks for individual agents. We define such a notion of RM decomposition and present algorithmically verifiable conditions guaranteeing that distributed completion of the sub-tasks leads to team behavior accomplishing the original task. This framework for task decomposition provides a natural approach to decentralized learning: agents may learn to accomplish their sub-tasks while observing only their local state and abstracted representations of their teammates. We accordingly propose a decentralized q-learning algorithm. Furthermore, in the case of undiscounted rewards, we use local value functions to derive lower and upper bounds for the global value function corresponding to the team task. Experimental results in three discrete settings exemplify the effectiveness of the proposed RM decomposition approach, which converges to a successful team policy an order of magnitude faster than a centralized learner and significantly outperforms hierarchical and independent q-learning approaches.",
        "published": "2020-07-03T23:08:14Z",
        "link": "http://arxiv.org/abs/2007.01962v2",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Decentralized Reinforcement Learning: Global Decision-Making via Local   Economic Transactions",
        "authors": [
            "Michael Chang",
            "Sidhant Kaushik",
            "S. Matthew Weinberg",
            "Thomas L. Griffiths",
            "Sergey Levine"
        ],
        "summary": "This paper seeks to establish a framework for directing a society of simple, specialized, self-interested agents to solve what traditionally are posed as monolithic single-agent sequential decision problems. What makes it challenging to use a decentralized approach to collectively optimize a central objective is the difficulty in characterizing the equilibrium strategy profile of non-cooperative games. To overcome this challenge, we design a mechanism for defining the learning environment of each agent for which we know that the optimal solution for the global objective coincides with a Nash equilibrium strategy profile of the agents optimizing their own local objectives. The society functions as an economy of agents that learn the credit assignment process itself by buying and selling to each other the right to operate on the environment state. We derive a class of decentralized reinforcement learning algorithms that are broadly applicable not only to standard reinforcement learning but also for selecting options in semi-MDPs and dynamically composing computation graphs. Lastly, we demonstrate the potential advantages of a society's inherent modular structure for more efficient transfer learning.",
        "published": "2020-07-05T16:41:09Z",
        "link": "http://arxiv.org/abs/2007.02382v2",
        "categories": [
            "cs.LG",
            "cs.GT",
            "cs.MA",
            "cs.NE",
            "stat.ML"
        ]
    },
    {
        "title": "Learning Implicit Credit Assignment for Cooperative Multi-Agent   Reinforcement Learning",
        "authors": [
            "Meng Zhou",
            "Ziyu Liu",
            "Pengwei Sui",
            "Yixuan Li",
            "Yuk Ying Chung"
        ],
        "summary": "We present a multi-agent actor-critic method that aims to implicitly address the credit assignment problem under fully cooperative settings. Our key motivation is that credit assignment among agents may not require an explicit formulation as long as (1) the policy gradients derived from a centralized critic carry sufficient information for the decentralized agents to maximize their joint action value through optimal cooperation and (2) a sustained level of exploration is enforced throughout training. Under the centralized training with decentralized execution (CTDE) paradigm, we achieve the former by formulating the centralized critic as a hypernetwork such that a latent state representation is integrated into the policy gradients through its multiplicative association with the stochastic policies; to achieve the latter, we derive a simple technique called adaptive entropy regularization where magnitudes of the entropy gradients are dynamically rescaled based on the current policy stochasticity to encourage consistent levels of exploration. Our algorithm, referred to as LICA, is evaluated on several benchmarks including the multi-agent particle environments and a set of challenging StarCraft II micromanagement tasks, and we show that LICA significantly outperforms previous methods.",
        "published": "2020-07-06T05:25:02Z",
        "link": "http://arxiv.org/abs/2007.02529v2",
        "categories": [
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Decentralized policy learning with partial observation and mechanical   constraints for multiperson modeling",
        "authors": [
            "Keisuke Fujii",
            "Naoya Takeishi",
            "Yoshinobu Kawahara",
            "Kazuya Takeda"
        ],
        "summary": "Extracting the rules of real-world multi-agent behaviors is a current challenge in various scientific and engineering fields. Biological agents independently have limited observation and mechanical constraints; however, most of the conventional data-driven models ignore such assumptions, resulting in lack of biological plausibility and model interpretability for behavioral analyses. Here we propose sequential generative models with partial observation and mechanical constraints in a decentralized manner, which can model agents' cognition and body dynamics, and predict biologically plausible behaviors. We formulate this as a decentralized multi-agent imitation-learning problem, leveraging binary partial observation and decentralized policy models based on hierarchical variational recurrent neural networks with physical and biomechanical penalties. Using real-world basketball and soccer datasets, we show the effectiveness of our method in terms of the constraint violations, long-term trajectory prediction, and partial observation. Our approach can be used as a multi-agent simulator to generate realistic trajectories using real-world data.",
        "published": "2020-07-07T01:24:22Z",
        "link": "http://arxiv.org/abs/2007.03155v2",
        "categories": [
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Deep Reinforcement Learning with Interactive Feedback in a Human-Robot   Environment",
        "authors": [
            "Ithan Moreira",
            "Javier Rivas",
            "Francisco Cruz",
            "Richard Dazeley",
            "Angel Ayala",
            "Bruno Fernandes"
        ],
        "summary": "Robots are extending their presence in domestic environments every day, being more common to see them carrying out tasks in home scenarios. In the future, robots are expected to increasingly perform more complex tasks and, therefore, be able to acquire experience from different sources as quickly as possible. A plausible approach to address this issue is interactive feedback, where a trainer advises a learner on which actions should be taken from specific states to speed up the learning process. Moreover, deep reinforcement learning has been recently widely utilized in robotics to learn the environment and acquire new skills autonomously. However, an open issue when using deep reinforcement learning is the excessive time needed to learn a task from raw input images. In this work, we propose a deep reinforcement learning approach with interactive feedback to learn a domestic task in a human-robot scenario. We compare three different learning methods using a simulated robotic arm for the task of organizing different objects; the proposed methods are (i) deep reinforcement learning (DeepRL); (ii) interactive deep reinforcement learning using a previously trained artificial agent as an advisor (agent-IDeepRL); and (iii) interactive deep reinforcement learning using a human advisor (human-IDeepRL). We demonstrate that interactive approaches provide advantages for the learning process. The obtained results show that a learner agent, using either agent-IDeepRL or human-IDeepRL, completes the given task earlier and has fewer mistakes compared to the autonomous DeepRL approach.",
        "published": "2020-07-07T11:55:27Z",
        "link": "http://arxiv.org/abs/2007.03363v2",
        "categories": [
            "cs.AI",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "A Distributed Cubic-Regularized Newton Method for Smooth Convex   Optimization over Networks",
        "authors": [
            "César A. Uribe",
            "Ali Jadbabaie"
        ],
        "summary": "We propose a distributed, cubic-regularized Newton method for large-scale convex optimization over networks. The proposed method requires only local computations and communications and is suitable for federated learning applications over arbitrary network topologies. We show a $O(k^{{-}3})$ convergence rate when the cost function is convex with Lipschitz gradient and Hessian, with $k$ being the number of iterations. We further provide network-dependent bounds for the communication required in each step of the algorithm. We provide numerical experiments that validate our theoretical results.",
        "published": "2020-07-07T15:38:47Z",
        "link": "http://arxiv.org/abs/2007.03562v1",
        "categories": [
            "math.OC",
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Resolving Head-On Conflicts for Multi-Agent Path Finding with   Conflict-Based Search",
        "authors": [
            "Lun Yang"
        ],
        "summary": "Conflict-Based Search (CBS) is a popular framework for solving the Multi-Agent Path Finding problem. Some of the conflicts incur a foreseeable conflict in one or both of the children nodes when splitting on them. This paper introduces a new technique, namely the head-on technique that finds out such conflicts, so they can be processed more efficiently by resolving the conflict with the potential conflict all together in one split. The proposed technique applies to all CBS-based solvers. Experimental results show that the head-on technique improves the state-of-the-art MAPF solver CBSH.",
        "published": "2020-07-07T15:52:45Z",
        "link": "http://arxiv.org/abs/2007.03575v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Agent-Based Modelling: An Overview with Application to Disease Dynamics",
        "authors": [
            "Affan Shoukat",
            "Seyed M. Moghadas"
        ],
        "summary": "Modelling and computational methods have been essential in advancing quantitative science, especially in the past two decades with the availability of vast amount of complex, voluminous, and heterogeneous data. In particular, there has been a surge of interest in agent-based modelling, largely due to its capabilities to exploit such data and make significant projections. However, any well-established quantitative method relies on theoretical frameworks for both construction and analysis. While the computational aspects of agent-based modelling have been detailed in existing literature, the underlying theoretical basis has rarely been used in its construction. In this exposition, we provide an overview of the theoretical foundation of agent-based modelling and establish a relationship with its computational implementation. In addition to detailing the main characteristics of this computational methodology, we illustrate its application to simulating the spread of an infectious disease in a simple, dynamical process. As the use of agent-based models expands to various disciplines, our review highlights the need for directed research efforts to develop theoretical methods and analytical tools for the analysis of such models.",
        "published": "2020-07-08T15:30:47Z",
        "link": "http://arxiv.org/abs/2007.04192v1",
        "categories": [
            "cs.MA",
            "q-bio.QM"
        ]
    },
    {
        "title": "Herding an Adversarial Swarm in Three-dimensional Spaces",
        "authors": [
            "Weifan Zhang",
            "Vishnu S. Chipade",
            "Dimitra Panagou"
        ],
        "summary": "This paper presents a defense approach to safeguard a protected area against an attack by a swarm of adversarial agents in three-dimensional (3D) space. We extend our 2D `StringNet Herding' approach, in which a closed formation of string-barriers is established around the adversarial swarm to confine their motion and herd them to a safe area, to 3D spaces by introducing 3D-StringNet. 3D-StringNet is a closed 3D formation of triangular net-like barriers. We provide a systematic approach to generate three types of 3D formations that are used in the 3D herding process and modifications to the finite-time convergent control laws developed in \\cite{chipade2020swarmherding} that are required for a 3D environment. Furthermore, for given initial positions of the defenders, we provide conditions on the initial positions of the attackers for which the defenders are guaranteed to gather as a specified formation at a position on the shortest path of the attackers to the protected area before attackers reach there.",
        "published": "2020-07-08T20:19:15Z",
        "link": "http://arxiv.org/abs/2007.04406v2",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Multi-Swarm Herding: Protecting against Adversarial Swarms",
        "authors": [
            "Vishnu S. Chipade",
            "Dimitra Panagou"
        ],
        "summary": "This paper studies a defense approach against one or more swarms of adversarial agents. In our earlier work, we employ a closed formation (`StringNet') of defending agents (defenders) around a swarm of adversarial agents (attackers) to confine their motion within given bounds, and guide them to a safe area. The control design relies on the assumption that the adversarial agents remain close enough to each other, i.e., within a prescribed connectivity region. To handle situations when the attackers no longer stay within such a connectivity region, but rather split into smaller swarms (clusters) to maximize the chance or impact of attack, this paper proposes an approach to learn the attacking sub-swarms and reassign defenders towards the attackers. We use a `Density-based Spatial Clustering of Application with Noise (DBSCAN)' algorithm to identify the spatially distributed swarms of the attackers. Then, the defenders are assigned to each identified swarm of attackers by solving a constrained generalized assignment problem. Simulations are provided to demonstrate the effectiveness of the approach.",
        "published": "2020-07-08T20:20:21Z",
        "link": "http://arxiv.org/abs/2007.04407v1",
        "categories": [
            "cs.MA",
            "cs.RO",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Distributed Energy Trading and Scheduling among Microgrids via   Multiagent Reinforcement Learning",
        "authors": [
            "Guanyu Gao",
            "Yonggang Wen",
            "Xiaohu Wu",
            "Ran Wang"
        ],
        "summary": "The development of renewable energy generation empowers microgrids to generate electricity to supply itself and to trade the surplus on energy markets. To minimize the overall cost, a microgrid must determine how to schedule its energy resources and electrical loads and how to trade with others. The control decisions are influenced by various factors, such as energy storage, renewable energy yield, electrical load, and competition from other microgrids. Making the optimal control decision is challenging, due to the complexity of the interconnected microgrids, the uncertainty of renewable energy generation and consumption, and the interplay among microgrids. The previous works mainly adopted the modeling-based approaches for deriving the control decision, yet they relied on the precise information of future system dynamics, which can be hard to obtain in a complex environment. This work provides a new perspective of obtaining the optimal control policy for distributed energy trading and scheduling by directly interacting with the environment, and proposes a multiagent deep reinforcement learning approach for learning the optimal control policy. Each microgrid is modeled as an agent, and different agents learn collaboratively for maximizing their rewards. The agent of each microgrid can make the local scheduling decision without knowing others' information, which can well maintain the autonomy of each microgrid. We evaluate the performances of our proposed method using real-world datasets. The experimental results show that our method can significantly reduce the cost of the microgrids compared with the baseline methods.",
        "published": "2020-07-09T02:39:37Z",
        "link": "http://arxiv.org/abs/2007.04517v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "A Dynamical Approach to Efficient Eigenvalue Estimation in General   Multiagent Networks",
        "authors": [
            "Mikhail Hayhoe",
            "Francisco Barreras",
            "Victor M. Preciado"
        ],
        "summary": "We propose a method to efficiently estimate the eigenvalues of any arbitrary (potentially weighted and/or directed) network of interacting dynamical agents from dynamical observations. These observations are discrete, temporal measurements about the evolution of the outputs of a subset of agents (potentially one) during a finite time horizon; notably, we do not require knowledge of which agents are contributing to our measurements. We propose an efficient algorithm to exactly recover the (potentially complex) eigenvalues corresponding to network modes that are observable from the output measurements. The length of the sequence of measurements required by our method to generate a full reconstruction of the observable eigenvalue spectrum is, at most, twice the number of agents in the network, but smaller in practice. The proposed technique can be applied to networks of multiagent systems with arbitrary dynamics in both continuous- and discrete-time. Finally, we illustrate our results with numerical simulations.",
        "published": "2020-07-09T03:51:37Z",
        "link": "http://arxiv.org/abs/2007.05340v2",
        "categories": [
            "math.OC",
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "math.DS",
            "math.SP"
        ]
    },
    {
        "title": "Geometric Bounds for Convergence Rates of Averaging Algorithms",
        "authors": [
            "Bernadette Charron-Bost"
        ],
        "summary": "We develop a generic method for bounding the convergence rate of an averaging algorithm running in a multi-agent system with a time-varying network, where the associated stochastic matrices have a time-independent Perron vector. This method provides bounds on convergence rates that unify and refine most of the previously known bounds. They depend on geometric parameters of the dynamic communication graph such as the normalized diameter or the bottleneck measure.   As corollaries of these geometric bounds, we show that the convergence rate of the Metropolis algorithm in a system of $n$ agents is less than $1-1/4n^2$ with any communication graph that may vary in time, but is permanently connected and bidirectional. We prove a similar upper bound for the EqualNeighbor algorithm under the additional assumptions that the number of neighbors of each agent is constant and that the communication graph is not too irregular. Moreover our bounds offer improved convergence rates for several averaging algorithms and specific families of communication graphs.   Finally we extend our methodology to a time-varying Perron vector and show how convergence times may dramatically degrade with even limited variations of Perron vectors.",
        "published": "2020-07-09T14:35:10Z",
        "link": "http://arxiv.org/abs/2007.04837v1",
        "categories": [
            "cs.MA",
            "cs.DM"
        ]
    },
    {
        "title": "A Neuro-inspired Theory of Joint Human-Swarm Interaction",
        "authors": [
            "Jonas D. Hasbach",
            "Maren Bennewitz"
        ],
        "summary": "Human-swarm interaction (HSI) is an active research challenge in the realms of swarm robotics and human-factors engineering. Here we apply a cognitive systems engineering perspective and introduce a neuro-inspired joint systems theory of HSI. The mindset defines predictions for adaptive, robust and scalable HSI dynamics and therefore has the potential to inform human-swarm loop design.",
        "published": "2020-07-09T15:34:22Z",
        "link": "http://arxiv.org/abs/2007.04882v1",
        "categories": [
            "cs.HC",
            "cs.MA",
            "cs.NE",
            "cs.RO",
            "H.1.2; I.2.9"
        ]
    },
    {
        "title": "A Cordial Sync: Going Beyond Marginal Policies for Multi-Agent Embodied   Tasks",
        "authors": [
            "Unnat Jain",
            "Luca Weihs",
            "Eric Kolve",
            "Ali Farhadi",
            "Svetlana Lazebnik",
            "Aniruddha Kembhavi",
            "Alexander Schwing"
        ],
        "summary": "Autonomous agents must learn to collaborate. It is not scalable to develop a new centralized agent every time a task's difficulty outpaces a single agent's abilities. While multi-agent collaboration research has flourished in gridworld-like environments, relatively little work has considered visually rich domains. Addressing this, we introduce the novel task FurnMove in which agents work together to move a piece of furniture through a living room to a goal. Unlike existing tasks, FurnMove requires agents to coordinate at every timestep. We identify two challenges when training agents to complete FurnMove: existing decentralized action sampling procedures do not permit expressive joint action policies and, in tasks requiring close coordination, the number of failed actions dominates successful actions. To confront these challenges we introduce SYNC-policies (synchronize your actions coherently) and CORDIAL (coordination loss). Using SYNC-policies and CORDIAL, our agents achieve a 58% completion rate on FurnMove, an impressive absolute gain of 25 percentage points over competitive decentralized baselines. Our dataset, code, and pretrained models are available at https://unnat.github.io/cordial-sync .",
        "published": "2020-07-09T17:59:57Z",
        "link": "http://arxiv.org/abs/2007.04979v1",
        "categories": [
            "cs.CV",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Multi-Agent Routing Value Iteration Network",
        "authors": [
            "Quinlan Sykora",
            "Mengye Ren",
            "Raquel Urtasun"
        ],
        "summary": "In this paper we tackle the problem of routing multiple agents in a coordinated manner. This is a complex problem that has a wide range of applications in fleet management to achieve a common goal, such as mapping from a swarm of robots and ride sharing. Traditional methods are typically not designed for realistic environments hich contain sparsely connected graphs and unknown traffic, and are often too slow in runtime to be practical. In contrast, we propose a graph neural network based model that is able to perform multi-agent routing based on learned value iteration in a sparsely connected graph with dynamically changing traffic conditions. Moreover, our learned communication module enables the agents to coordinate online and adapt to changes more effectively. We created a simulated environment to mimic realistic mapping performed by autonomous vehicles with unknown minimum edge coverage and traffic conditions; our approach significantly outperforms traditional solvers both in terms of total cost and runtime. We also show that our model trained with only two agents on graphs with a maximum of 25 nodes can easily generalize to situations with more agents and/or nodes.",
        "published": "2020-07-09T22:16:45Z",
        "link": "http://arxiv.org/abs/2007.05096v2",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "cs.RO",
            "stat.ML",
            "I.2.11; I.2.6"
        ]
    },
    {
        "title": "Self-healing Dilemmas in Distributed Systems: Fault Correction vs. Fault   Tolerance",
        "authors": [
            "Jovan Nikolic",
            "Nursultan Jubatyrov",
            "Evangelos Pournaras"
        ],
        "summary": "Large-scale decentralized systems of autonomous agents interacting via asynchronous communication often experience the following self-healing dilemma: fault detection inherits network uncertainties making a remote faulty process indistinguishable from a slow process. In the case of a slow process without fault, fault correction is undesirable as it can trigger new faults that could be prevented with fault tolerance that is a more proactive system maintenance. But in the case of an actual faulty process, fault tolerance alone without eventually correcting persistent faults can make systems underperforming. Measuring, understanding and resolving such self-healing dilemmas is a timely challenge and critical requirement given the rise of distributed ledgers, edge computing, the Internet of Things in several energy, transport and health applications. This paper contributes a novel and general-purpose modeling of fault scenarios during system runtime. They are used to accurately measure and predict inconsistencies generated by the undesirable outcomes of fault correction and fault tolerance as the means to improve self-healing of large-scale decentralized systems at the design phase. A rigorous experimental methodology is designed that evaluates 696 experimental settings of different fault scales, fault profiles and fault detection thresholds in a prototyped decentralized network of 3000 nodes. Almost 9 million measurements of inconsistencies were collected in a network, where each node monitors the health status of another node, while both can defect. The prediction performance of the modeled fault scenarios is validated in a challenging application scenario of decentralized and dynamic in-network data aggregation using real-world data from a Smart Grid pilot project. Findings confirm the origin of inconsistencies at design phase.",
        "published": "2020-07-10T09:10:00Z",
        "link": "http://arxiv.org/abs/2007.05261v3",
        "categories": [
            "cs.DC",
            "cs.MA",
            "cs.NI",
            "cs.PF"
        ]
    },
    {
        "title": "Towards Fast, Flexible and Sensor-Free Control of Standalone PVDG   Systems",
        "authors": [
            "Meher Preetam Korukonda"
        ],
        "summary": "In this thesis, the problem of fast, effective and low cost control of a Standalone Photovoltaic Distributed Generation (SPVDG) system is considered . On-site generation from these systems is more efficient when the power is transmitted via DC due to elimination of transmission losses and needless energy conversions. The inherent low-inertia of these systems added with fluctuation of output power and uncertain load consumption, calls for advanced control techniques to ensure fast and stable operation during various intermittencies. These techniques are expensive since they demand installation of many sophisticated sensors. The computation power provided by the fast growing IC technology can be utilized to estimate different parameters in a system and reduce the need for expensive sensing equipment. This work provides solutions to problems encountered in the development of faster, more stable and sensor-free voltage control and maximum power point tracking(MPPT) for SPVDG systems with PV and battery.",
        "published": "2020-07-10T09:22:03Z",
        "link": "http://arxiv.org/abs/2007.05266v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.NI",
            "cs.SY"
        ]
    },
    {
        "title": "MAPS: Multi-agent Reinforcement Learning-based Portfolio Management   System",
        "authors": [
            "Jinho Lee",
            "Raehyun Kim",
            "Seok-Won Yi",
            "Jaewoo Kang"
        ],
        "summary": "Generating an investment strategy using advanced deep learning methods in stock markets has recently been a topic of interest. Most existing deep learning methods focus on proposing an optimal model or network architecture by maximizing return. However, these models often fail to consider and adapt to the continuously changing market conditions. In this paper, we propose the Multi-Agent reinforcement learning-based Portfolio management System (MAPS). MAPS is a cooperative system in which each agent is an independent \"investor\" creating its own portfolio. In the training procedure, each agent is guided to act as diversely as possible while maximizing its own return with a carefully designed loss function. As a result, MAPS as a system ends up with a diversified portfolio. Experiment results with 12 years of US market data show that MAPS outperforms most of the baselines in terms of Sharpe ratio. Furthermore, our results show that adding more agents to our system would allow us to get a higher Sharpe ratio by lowering risk with a more diversified portfolio.",
        "published": "2020-07-10T14:08:12Z",
        "link": "http://arxiv.org/abs/2007.05402v1",
        "categories": [
            "cs.AI",
            "cs.CE",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Finding Equilibrium in Multi-Agent Games with Payoff Uncertainty",
        "authors": [
            "Wenshuo Guo",
            "Mihaela Curmei",
            "Serena Wang",
            "Benjamin Recht",
            "Michael I. Jordan"
        ],
        "summary": "We study the problem of finding equilibrium strategies in multi-agent games with incomplete payoff information, where the payoff matrices are only known to the players up to some bounded uncertainty sets. In such games, an ex-post equilibrium characterizes equilibrium strategies that are robust to the payoff uncertainty. When the game is one-shot, we show that in zero-sum polymatrix games, an ex-post equilibrium can be computed efficiently using linear programming. We further extend the notion of ex-post equilibrium to stochastic games, where the game is played repeatedly in a sequence of stages and the transition dynamics are governed by an Markov decision process (MDP). We provide sufficient condition for the existence of an ex-post Markov perfect equilibrium (MPE). We show that under bounded payoff uncertainty, the value of any two-player zero-sum stochastic game can be computed up to a tight value interval using dynamic programming.",
        "published": "2020-07-10T23:38:53Z",
        "link": "http://arxiv.org/abs/2007.05647v1",
        "categories": [
            "cs.GT",
            "cs.DS",
            "cs.MA"
        ]
    },
    {
        "title": "A Framework for Automatic Behavior Generation in Multi-Function Swarms",
        "authors": [
            "Sondre A. Engebraaten",
            "Jonas Moen",
            "Oleg A. Yakimenko",
            "Kyrre Glette"
        ],
        "summary": "Multi-function swarms are swarms that solve multiple tasks at once. For example, a quadcopter swarm could be tasked with exploring an area of interest while simultaneously functioning as ad-hoc relays. With this type of multi-function comes the challenge of handling potentially conflicting requirements simultaneously. Using the Quality-Diversity algorithm MAP-elites in combination with a suitable controller structure, a framework for automatic behavior generation in multi-function swarms is proposed. The framework is tested on a scenario with three simultaneous tasks: exploration, communication network creation and geolocation of RF emitters. A repertoire is evolved, consisting of a wide range of controllers, or behavior primitives, with different characteristics and trade-offs in the different tasks. This repertoire would enable the swarm to transition between behavior trade-offs online, according to the situational requirements. Furthermore, the effect of noise on the behavior characteristics in MAP-elites is investigated. A moderate number of re-evaluations is found to increase the robustness while keeping the computational requirements relatively low. A few selected controllers are examined, and the dynamics of transitioning between these controllers are explored. Finally, the study develops a methodology for analyzing the makeup of the resulting controllers. This is done through a parameter variation study where the importance of individual inputs to the swarm controllers is assessed and analyzed.",
        "published": "2020-07-11T20:50:52Z",
        "link": "http://arxiv.org/abs/2007.08656v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.NE"
        ]
    },
    {
        "title": "CellEVAC: An adaptive guidance system for crowd evacuation through   behavioral optimization",
        "authors": [
            "Miguel A. Lopez-Carmona",
            "Alvaro Paricio Garcia"
        ],
        "summary": "A critical aspect of crowds' evacuation processes is the dynamism of individual decision making. Here, we investigate how to favor a coordinated group dynamic through optimal exit-choice instructions using behavioral strategy optimization. We propose and evaluate an adaptive guidance system (Cell-based Crowd Evacuation, CellEVAC) that dynamically allocates colors to cells in a cell-based pedestrian positioning infrastructure, to provide efficient exit-choice indications. The operational module of CellEVAC implements an optimized discrete-choice model that integrates the influential factors that would make evacuees adapt their exit choice. To optimize the model, we used a simulation-optimization modeling framework that integrates microscopic pedestrian simulation based on the classical Social Force Model. We paid particular attention to safety by using Pedestrian Fundamental Diagrams that model the dynamics of the exit gates. CellEVAC has been tested in a simulated real scenario (Madrid Arena) under different external pedestrian flow patterns that simulate complex pedestrian interactions. Results showed that CellEVAC outperforms evacuation processes in which the system is not used, with an exponential improvement as interactions become complex. We compared our system with an existing approach based on Cartesian Genetic Programming. Our system exhibited a better overall performance in terms of safety, evacuation time, and the number of revisions of exit-choice decisions. Further analyses also revealed that Cartesian Genetic Programming generates less natural pedestrian reactions and movements than CellEVAC. The fact that the decision logic module is built upon a behavioral model seems to favor a more natural and effective response. We also found that our proposal has a positive influence on evacuations even for a low compliance rate (40%).",
        "published": "2020-07-12T11:37:53Z",
        "link": "http://arxiv.org/abs/2007.05963v2",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "I.6.4"
        ]
    },
    {
        "title": "On the Effectiveness of Tracking and Testing in SEIR Models",
        "authors": [
            "Yoav Kolumbus",
            "Noam Nisan"
        ],
        "summary": "We study the effectiveness of tracking and testing in mitigating or suppressing epidemic outbreaks, in combination with or as an alternative to quarantines and global lockdowns. We study these intervention methods on a network-based SEIR model, augmented with an additional probability to model symptomatic, asymptomatic and pre-symptomatic cases. Our focus is on the basic trade-offs between economic costs and human lives lost, and how these trade-offs change under different lockdown, quarantine, tracking and testing policies.   Our main findings are as follows: (i) Tests combined with patient quarantines reduce both economic costs and mortality, but require a large-scale testing capacity to achieve a significant improvement; (ii) Tracking significantly reduces both economic costs and mortality; (iii) Tracking combined with a limited number of tests can achieve containment without lockdowns; (iv) If there is a small flow of new incoming infections, dynamic \"On-Off\" lockdowns are more efficient than fixed lockdowns.   Our simulation results underline the extreme effectiveness of tracking and testing policies in reducing both economic costs and mortality and their potential to contain epidemic outbreaks without imposing social distancing restrictions. This highlights the difficult social question of trading-off these gains with the privacy loss that tracking necessarily entails.",
        "published": "2020-07-13T10:19:00Z",
        "link": "http://arxiv.org/abs/2007.06291v1",
        "categories": [
            "q-bio.PE",
            "cs.MA",
            "cs.SI",
            "physics.soc-ph",
            "92D30 (Primary) 92D25, 37M05, 91-10(Secondary)",
            "J.3; J.4; I.6.3; J.2; I.2.11"
        ]
    },
    {
        "title": "AirCapRL: Autonomous Aerial Human Motion Capture using Deep   Reinforcement Learning",
        "authors": [
            "Rahul Tallamraju",
            "Nitin Saini",
            "Elia Bonetto",
            "Michael Pabst",
            "Yu Tang Liu",
            "Michael J. Black",
            "Aamir Ahmad"
        ],
        "summary": "In this letter, we introduce a deep reinforcement learning (RL) based multi-robot formation controller for the task of autonomous aerial human motion capture (MoCap). We focus on vision-based MoCap, where the objective is to estimate the trajectory of body pose and shape of a single moving person using multiple micro aerial vehicles. State-of-the-art solutions to this problem are based on classical control methods, which depend on hand-crafted system and observation models. Such models are difficult to derive and generalize across different systems. Moreover, the non-linearity and non-convexities of these models lead to sub-optimal controls. In our work, we formulate this problem as a sequential decision making task to achieve the vision-based motion capture objectives, and solve it using a deep neural network-based RL method. We leverage proximal policy optimization (PPO) to train a stochastic decentralized control policy for formation control. The neural network is trained in a parallelized setup in synthetic environments. We performed extensive simulation experiments to validate our approach. Finally, real-robot experiments demonstrate that our policies generalize to real world conditions. Video Link: https://bit.ly/38SJfjo Supplementary: https://bit.ly/3evfo1O",
        "published": "2020-07-13T12:30:31Z",
        "link": "http://arxiv.org/abs/2007.06343v2",
        "categories": [
            "cs.RO",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Urban Mobility Swarms: A Scalable Implementation",
        "authors": [
            "Alex Berke",
            "Jason Nawyn",
            "Thomas Sanchez Lengeling",
            "Kent Larson"
        ],
        "summary": "We present a system to coordinate 'urban mobility swarms' in order to promote the use and safety of lightweight, sustainable transit, while enhancing the vibrancy and community fabric of cities. This work draws from behavior exhibited by swarms of nocturnal insects, such as crickets and fireflies, whereby synchrony unifies individuals in a decentralized network. Coordination naturally emerges in these cases and provides a compelling demonstration of 'strength in numbers'. Our work is applied to coordinating lightweight vehicles, such as bicycles, which are automatically inducted into ad-hoc 'swarms', united by the synchronous pulsation of light. We model individual riders as nodes in a decentralized network and synchronize their behavior via a peer-to-peer message protocol and algorithm, which preserves individual privacy. Nodes broadcast over radio with a transmission range tuned to localize swarm membership. Nodes then join or disconnect from others based on proximity, accommodating the dynamically changing topology of urban mobility networks. This paper provides a technical description of our system, including the protocol and algorithm to coordinate the swarming behavior that emerges from it. We also demonstrate its implementation in code, circuity, and hardware, with a system prototype tested on a city bike-share. In doing so, we evince the scalability of our system. Our prototype uses low-cost components, and bike-share programs, which manage bicycle fleets distributed across cities, could deploy the system at city-scale. Our flexible, decentralized design allows additional bikes to then connect with the network, enhancing its scale and impact.",
        "published": "2020-07-13T19:44:16Z",
        "link": "http://arxiv.org/abs/2007.06653v1",
        "categories": [
            "cs.MA",
            "cs.CY"
        ]
    },
    {
        "title": "Altruistic Decision-Making for Autonomous Driving with Sparse Rewards",
        "authors": [
            "Jack Geary",
            "Henry Gouk"
        ],
        "summary": "In order to drive effectively, a driver must be aware of how they can expect other vehicles' behaviour to be affected by their decisions, and also how they are expected to behave by other drivers. One common family of methods for addressing this problem of interaction are those based on Game Theory. Such approaches often make assumptions about leaders and followers in an interaction which can result in conflicts arising when vehicles do not agree on the hierarchy, resulting in sub-optimal behaviour. In this work we define a measurement for the incidence of conflicts, Area of Conflict (AoC), for a given interactive decision-making model. Furthermore, we propose a novel decision-making method that reduces this value compared to an existing approach for incorporating altruistic behaviour. We verify our theoretical analysis empirically using a simulated lane-change scenario.",
        "published": "2020-07-14T16:58:00Z",
        "link": "http://arxiv.org/abs/2007.07182v1",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "On a Competitive Secretary Problem with Deferred Selections",
        "authors": [
            "Tomer Ezra",
            "Michal Feldman",
            "Ron Kupfer"
        ],
        "summary": "We study secretary problems in settings with multiple agents. In the standard secretary problem, a sequence of arbitrary awards arrive online, in a random order, and a single decision maker makes an immediate and irrevocable decision whether to accept each award upon its arrival. The requirement to make immediate decisions arises in many cases due to an implicit assumption regarding competition. Namely, if the decision maker does not take the offered award immediately, it will be taken by someone else. The novelty in this paper is in introducing a multi-agent model in which the competition is endogenous. In our model, multiple agents compete over the arriving awards, but the decisions need not be immediate; instead, agents may select previous awards as long as they are available (i.e., not taken by another agent). If an award is selected by multiple agents, ties are broken either randomly or according to a global ranking. This induces a multi-agent game in which the time of selection is not enforced by the rules of the games, rather it is an important component of the agent's strategy. We study the structure and performance of equilibria in this game. For random tie breaking, we characterize the equilibria of the game, and show that the expected social welfare in equilibrium is nearly optimal, despite competition among the agents. For ranked tie breaking, we give a full characterization of equilibria in the 3-agent game, and show that as the number of agents grows, the winning probability of every agent under non-immediate selections approaches her winning probability under immediate selections.",
        "published": "2020-07-14T17:37:09Z",
        "link": "http://arxiv.org/abs/2007.07216v1",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Disturbance Decoupling for Gradient-based Multi-Agent Learning with   Quadratic Costs",
        "authors": [
            "Sarah H. Q. Li",
            "Lillian Ratliff",
            "Behçet Açıkmeşe"
        ],
        "summary": "Motivated by applications of multi-agent learning in noisy environments, this paper studies the robustness of gradient-based learning dynamics with respect to disturbances. While disturbances injected along a coordinate corresponding to any individual player's actions can always affect the overall learning dynamics, a subset of players can be disturbance decoupled---i.e., such players' actions are completely unaffected by the injected disturbance. We provide necessary and sufficient conditions to guarantee this property for games with quadratic cost functions, which encompass quadratic one-shot continuous games, finite-horizon linear quadratic (LQ) dynamic games, and bilinear games. Specifically, disturbance decoupling is characterized by both algebraic and graph-theoretic conditions on the learning dynamics, the latter is obtained by constructing a game graph based on gradients of players' costs. For LQ games, we show that disturbance decoupling imposes constraints on the controllable and unobservable subspaces of players. For two player bilinear games, we show that disturbance decoupling within a player's action coordinates imposes constraints on the payoff matrices. Illustrative numerical examples are provided.",
        "published": "2020-07-14T17:47:29Z",
        "link": "http://arxiv.org/abs/2007.07228v2",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Model-Based Multi-Agent RL in Zero-Sum Markov Games with Near-Optimal   Sample Complexity",
        "authors": [
            "Kaiqing Zhang",
            "Sham M. Kakade",
            "Tamer Başar",
            "Lin F. Yang"
        ],
        "summary": "Model-based reinforcement learning (RL), which finds an optimal policy using an empirical model, has long been recognized as one of the corner stones of RL. It is especially suitable for multi-agent RL (MARL), as it naturally decouples the learning and the planning phases, and avoids the non-stationarity problem when all agents are improving their policies simultaneously using samples. Though intuitive and widely-used, the sample complexity of model-based MARL algorithms has not been fully investigated. In this paper, our goal is to address the fundamental question about its sample complexity. We study arguably the most basic MARL setting: two-player discounted zero-sum Markov games, given only access to a generative model. We show that model-based MARL achieves a sample complexity of $\\tilde O(|S||A||B|(1-\\gamma)^{-3}\\epsilon^{-2})$ for finding the Nash equilibrium (NE) value up to some $\\epsilon$ error, and the $\\epsilon$-NE policies with a smooth planning oracle, where $\\gamma$ is the discount factor, and $S,A,B$ denote the state space, and the action spaces for the two agents. We further show that such a sample bound is minimax-optimal (up to logarithmic factors) if the algorithm is reward-agnostic, where the algorithm queries state transition samples without reward knowledge, by establishing a matching lower bound. This is in contrast to the usual reward-aware setting, with a $\\tilde\\Omega(|S|(|A|+|B|)(1-\\gamma)^{-3}\\epsilon^{-2})$ lower bound, where this model-based approach is near-optimal with only a gap on the $|A|,|B|$ dependence. Our results not only demonstrate the sample-efficiency of this basic model-based approach in MARL, but also elaborate on the fundamental tradeoff between its power (easily handling the more challenging reward-agnostic case) and limitation (less adaptive and suboptimal in $|A|,|B|$), particularly arises in the multi-agent context.",
        "published": "2020-07-15T03:25:24Z",
        "link": "http://arxiv.org/abs/2007.07461v3",
        "categories": [
            "cs.LG",
            "cs.GT",
            "cs.MA",
            "math.OC",
            "stat.ML"
        ]
    },
    {
        "title": "Cloud-based Privacy-Preserving Collaborative Consumption for Sharing   Economy",
        "authors": [
            "Lingjuan Lyu",
            "Sid Chi-Kin Chau",
            "Nan Wang",
            "Yifeng Zheng"
        ],
        "summary": "Cloud computing has been a dominant paradigm for a variety of information processing platforms, particularly for enabling various popular applications of sharing economy. However, there is a major concern regarding data privacy on these cloud-based platforms. This work presents novel cloud-based privacy-preserving solutions to support collaborative consumption applications for sharing economy. In typical collaborative consumption, information processing platforms need to enable fair cost-sharing among multiple users for utilizing certain shared facilities and communal services. Our cloud-based privacy-preserving protocols, based on homomorphic Paillier cryptosystems, can ensure that the cloud-based operator can only obtain an aggregate schedule of all users in facility sharing, or a service schedule conforming to service provision rule in communal service sharing, but is unable to track the personal schedules or demands of individual users. More importantly, the participating users are still able to settle cost-sharing among themselves in a fair manner for the incurred costs, without knowing each other's private schedules or demands. Our privacy-preserving protocols involve no other third party who may compromise privacy. We also provide an extensive evaluation study and a proof-of-concept system prototype of our protocols.",
        "published": "2020-07-15T06:06:07Z",
        "link": "http://arxiv.org/abs/2007.07499v1",
        "categories": [
            "cs.CR",
            "cs.MA",
            "cs.NI"
        ]
    },
    {
        "title": "Event-triggered Partitioning for Non-centralized   Predictive-Control-based Economic Dispatch of Interconnected Microgrids:   Technical Report",
        "authors": [
            "Wicak Ananduta",
            "Carlos Ocampo-Martinez"
        ],
        "summary": "A non-centralized model predictive control (MPC) scheme for solving an economic dispatch problem of electrical networks is proposed in this paper. The scheme consists of two parts. The first part is an event-triggered repartitioning method that splits the network into a fixed number of non-overlapping sub-systems {(microgrids)}. The objective of the repartitioning procedure is to obtain self-sufficient microgrids, i.e., those that can meet their local loads using their own generation units. However, since the algorithm does not guarantee that all the resulting microgrids are self-sufficient, the microgrids that are not self-sufficient must then form a coalition with some of their neighboring microgrids. This process becomes the second part of the scheme. By performing the coalition formation, we can decompose the economic dispatch problem of the network into coalition-based sub-problems such that each subproblem is feasible. Furthermore, we also show that the solution obtained by solving the coalition-based sub-problems is a feasible but sub-optimal solution to the centralized problem. Additionally, some numerical simulations are also carried out to show the effectiveness of the proposed method.",
        "published": "2020-07-15T16:08:52Z",
        "link": "http://arxiv.org/abs/2007.07786v1",
        "categories": [
            "math.OC",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Frequency Regulation with Heterogeneous Energy Resources: A Realization   using Distributed Control",
        "authors": [
            "Tor Anderson",
            "Manasa Muralidharan",
            "Priyank Srivastava",
            "Hamed Valizadeh Haghi",
            "Jorge Cortes",
            "Jan Kleissl",
            "Sonia Martinez",
            "Byron Washom"
        ],
        "summary": "This paper presents one of the first real-life demonstrations of coordinated and distributed resource control for secondary frequency response in a power distribution grid. We conduct a series of tests with up to 69 heterogeneous active devices consisting of air handling units, unidirectional and bidirectional electric vehicle charging stations, a battery energy storage system, and 107 passive devices consisting of building loads and photovoltaic generators. Actuation commands for the test devices are obtained by solving an economic dispatch problem at every regulation instant using distributed ratio-consensus, primal-dual, and Newton-like algorithms. The distributed control setup consists of a set of Raspberry Pi end-points exchanging messages via an ethernet switch. The problem formulation minimizes the sum of device costs while tracking the setpoints provided by the system operator. We demonstrate accurate and fast real-time distributed computation of the optimization solution and effective tracking of the regulation signal by measuring physical device outputs over 40-minute time horizons. We also perform an economic benefit analysis which confirms eligibility to participate in an ancillary services market and demonstrates up to $53K of potential annual revenue for the selected population of devices.",
        "published": "2020-07-15T19:56:36Z",
        "link": "http://arxiv.org/abs/2007.07971v4",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Decentralized Ride-Sharing and Vehicle-Pooling Based on Fair   Cost-Sharing Mechanisms",
        "authors": [
            "Sid Chi-Kin Chau",
            "Shuning Shen",
            "Yue Zhou"
        ],
        "summary": "Ride-sharing or vehicle-pooling allows commuters to team up spontaneously for transportation cost sharing. This has become a popular trend in the emerging paradigm of sharing economy. One crucial component to support effective ride-sharing is the matching mechanism that pairs up suitable commuters. Traditionally, matching has been performed in a centralized manner, whereby an operator arranges ride-sharing according to a global objective (e.g., total cost of all commuters). However, ride-sharing is a decentralized decision-making paradigm, where commuters are self-interested and only motivated to team up based on individual payments. Particularly, it is not clear how transportation cost should be shared fairly between commuters, and what ramifications of cost-sharing are on decentralized ride-sharing. This paper sheds light on the principles of decentralized ride-sharing and vehicle-pooling mechanisms based on stable matching, such that no one would be better off to deviate from a stable matching outcome. We study various fair cost-sharing mechanisms and the induced stable matching outcomes. We compare the stable matching outcomes with a social optimal outcome (that minimizes total cost) by theoretical bounds of social optimality ratios, and show that several fair cost-sharing mechanisms can achieve high social optimality. We also corroborate our results with an empirical study of taxi sharing under fair cost-sharing mechanisms by a data analysis on New York City taxi trip dataset, and provide useful insights on effective decentralized mechanisms for practical ride-sharing and vehicle-pooling.",
        "published": "2020-07-16T01:37:12Z",
        "link": "http://arxiv.org/abs/2007.08064v2",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Simulating Self-Organization during Strategic Change: Implications for   Organizational Design",
        "authors": [
            "Ananya Sheth",
            "Joseph V. Sinfield"
        ],
        "summary": "Self-organization -- a characteristic of complex adaptive systems (CAS) -- has been explored in organizational research, in management theory [Mihm et al. 2003; von Foerster 1984], firm internationalization [Chandra and Wilkinson 2017], organizational design [Clement and Puranam 2017], and strategic change [Foster 2015]. Newer organizational forms such as networks and zero-hierarchy companies that hold the promise of self-organization are gaining prominence [Puranam et al. 2014], and theoretical organizational modeling is a useful technique to study them proactively via simulation [Puranam et al.2015; Simon 1976]. In this paper, we introduce a nature-inspired model to understand self-organization of collaborative groups in three archetypal organizational designs: i. fully-networked, ii. siloed, and iii.dynamic, where each design controls intra-managerial communication in specific ways, and each member has reactive or perceptive behavioral tendencies.",
        "published": "2020-07-16T04:18:41Z",
        "link": "http://arxiv.org/abs/2007.08521v1",
        "categories": [
            "cs.MA",
            "J.7; J.m; I.6.3"
        ]
    },
    {
        "title": "Real-time Framework for Trust Monitoring in aNetwork of Unmanned Aerial   Vehicles",
        "authors": [
            "Mahsa Keshavarz",
            "Alireza Shamsoshoara",
            "Fatemeh Afghah",
            "Jonathan Ashdown"
        ],
        "summary": "Unmanned aerial vehicles (UAVs) have been increasingly utilized in various civilian and military applications such as remote sensing, border patrolling, disaster monitoring, and communication coverage extension. However, there are still prone to several cyber attacks such as GPS spoofing attacks, distributed denial-of-service (DDoS) attacks, and man-in-the-middle attacks to obtain their collected information or to enforce the UAVs to perform their requested actions which may damage the UAVs or their surrounding environment or even endanger the safety of human in the operation field. In this paper, we propose a trust monitoring mechanism in which a centralized unit (e.g. the ground station) regularly observe the behavior of the UAVs in terms of their motion path, their consumed energy, as well as the number of their completed tasks and measure a relative trust score for the UAVs to detect any abnormal behaviors in a real-time manner. Our simulation results show that the trust model can detect malicious UAVs, which can be under various cyber-security attacks such as flooding attacks, man-in-the-middle attacks, GPS spoofing attack in real-time.",
        "published": "2020-07-16T19:50:41Z",
        "link": "http://arxiv.org/abs/2007.08590v1",
        "categories": [
            "eess.SP",
            "cs.MA"
        ]
    },
    {
        "title": "A Review of Platforms for the Development of Agent Systems",
        "authors": [
            "Constantin-Valentin Pal",
            "Florin Leon",
            "Marcin Paprzycki",
            "Maria Ganzha"
        ],
        "summary": "Agent-based computing is an active field of research with the goal of building autonomous software of hardware entities. This task is often facilitated by the use of dedicated, specialized frameworks. For almost thirty years, many such agent platforms have been developed. Meanwhile, some of them have been abandoned, others continue their development and new platforms are released. This paper presents a up-to-date review of the existing agent platforms and also a historical perspective of this domain. It aims to serve as a reference point for people interested in developing agent systems. This work details the main characteristics of the included agent platforms, together with links to specific projects where they have been used. It distinguishes between the active platforms and those no longer under development or with unclear status. It also classifies the agent platforms as general purpose ones, free or commercial, and specialized ones, which can be used for particular types of applications.",
        "published": "2020-07-17T13:12:16Z",
        "link": "http://arxiv.org/abs/2007.08961v1",
        "categories": [
            "cs.MA",
            "68T42"
        ]
    },
    {
        "title": "Towards Quantum-Secure Authentication and Key Agreement via Abstract   Multi-Agent Interaction",
        "authors": [
            "Ibrahim H. Ahmed",
            "Josiah P. Hanna",
            "Elliot Fosong",
            "Stefano V. Albrecht"
        ],
        "summary": "Current methods for authentication and key agreement based on public-key cryptography are vulnerable to quantum computing. We propose a novel approach based on artificial intelligence research in which communicating parties are viewed as autonomous agents which interact repeatedly using their private decision models. Authentication and key agreement are decided based on the agents' observed behaviors during the interaction. The security of this approach rests upon the difficulty of modeling the decisions of interacting agents from limited observations, a problem which we conjecture is also hard for quantum computing. We release PyAMI, a prototype authentication and key agreement system based on the proposed method. We empirically validate our method for authenticating legitimate users while detecting different types of adversarial attacks. Finally, we show how reinforcement learning techniques can be used to train server models which effectively probe a client's decisions to achieve more sample-efficient authentication.",
        "published": "2020-07-18T04:22:02Z",
        "link": "http://arxiv.org/abs/2007.09327v2",
        "categories": [
            "cs.CR",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Active Deception using Factored Interactive POMDPs to Recognize Cyber   Attacker's Intent",
        "authors": [
            "Aditya Shinde",
            "Prashant Doshi",
            "Omid Setayeshfar"
        ],
        "summary": "This paper presents an intelligent and adaptive agent that employs deception to recognize a cyber adversary's intent. Unlike previous approaches to cyber deception, which mainly focus on delaying or confusing the attackers, we focus on engaging with them to learn their intent. We model cyber deception as a sequential decision-making problem in a two-agent context. We introduce factored finitely nested interactive POMDPs (I-POMDPx) and use this framework to model the problem with multiple attacker types. Our approach models cyber attacks on a single honeypot host across multiple phases from the attacker's initial entry to reaching its adversarial objective. The defending I-POMDPx-based agent uses decoys to engage with the attacker at multiple phases to form increasingly accurate predictions of the attacker's behavior and intent. The use of I-POMDPs also enables us to model the adversary's mental state and investigate how deception affects their beliefs. Our experiments in both simulation and on a real host show that the I-POMDPx-based agent performs significantly better at intent recognition than commonly used deception strategies on honeypots.",
        "published": "2020-07-18T20:09:15Z",
        "link": "http://arxiv.org/abs/2007.09512v1",
        "categories": [
            "cs.MA",
            "cs.CR"
        ]
    },
    {
        "title": "Design and Analysis of a Multi-Agent E-Learning System Using Prometheus   Design Tool",
        "authors": [
            "Kennedy E. Ehimwenma",
            "Sujatha Krishnamoorthy"
        ],
        "summary": "Agent unified modeling languages (AUML) are agent-oriented approaches that supports the specification, design, visualization and documentation of an agent-based system. This paper presents the use of Prometheus AUML approach for the modeling of a Pre-assessment System of five interactive agents. The Pre-assessment System, as previously reported, is a multi-agent based e-learning system that is developed to support the assessment of prior learning skills in students so as to classify their skills and make recommendation for their learning. This paper discusses the detailed design approach of the system in a step-by-step manner; and domain knowledge abstraction and organization in the system. In addition, the analysis of the data collated and models of prediction for future pre-assessment results are also presented.",
        "published": "2020-07-19T10:37:52Z",
        "link": "http://arxiv.org/abs/2007.09645v3",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Election Control by Manipulating Issue Significance",
        "authors": [
            "Andrew Estornell",
            "Sanmay Das",
            "Edith Elkind",
            "Yevgeniy Vorobeychik"
        ],
        "summary": "Integrity of elections is vital to democratic systems, but it is frequently threatened by malicious actors. The study of algorithmic complexity of the problem of manipulating election outcomes by changing its structural features is known as election control. One means of election control that has been proposed is to select a subset of issues that determine voter preferences over candidates. We study a variation of this model in which voters have judgments about relative importance of issues, and a malicious actor can manipulate these judgments. We show that computing effective manipulations in this model is NP-hard even with two candidates or binary issues. However, we demonstrate that the problem is tractable with a constant number of voters or issues. Additionally, while it remains intractable when voters can vote stochastically, we exhibit an important special case in which stochastic voting enables tractable manipulation.",
        "published": "2020-07-19T21:16:47Z",
        "link": "http://arxiv.org/abs/2007.09786v1",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Reinforcement Communication Learning in Different Social Network   Structures",
        "authors": [
            "Marina Dubova",
            "Arseny Moskvichev",
            "Robert Goldstone"
        ],
        "summary": "Social network structure is one of the key determinants of human language evolution. Previous work has shown that the network of social interactions shapes decentralized learning in human groups, leading to the emergence of different kinds of communicative conventions. We examined the effects of social network organization on the properties of communication systems emerging in decentralized, multi-agent reinforcement learning communities. We found that the global connectivity of a social network drives the convergence of populations on shared and symmetric communication systems, preventing the agents from forming many local \"dialects\". Moreover, the agent's degree is inversely related to the consistency of its use of communicative conventions. These results show the importance of the basic properties of social network structure on reinforcement communication learning and suggest a new interpretation of findings on human convergence on word conventions.",
        "published": "2020-07-19T23:57:30Z",
        "link": "http://arxiv.org/abs/2007.09820v1",
        "categories": [
            "cs.AI",
            "cs.CL",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Heterogeneous Task Offloading and Resource Allocations via Deep   Recurrent Reinforcement Learning in Partial Observable Multi-Fog Networks",
        "authors": [
            "Jungyeon Baek",
            "Georges Kaddoum"
        ],
        "summary": "As wireless services and applications become more sophisticated and require faster and higher-capacity networks, there is a need for an efficient management of the execution of increasingly complex tasks based on the requirements of each application. In this regard, fog computing enables the integration of virtualized servers into networks and brings cloud services closer to end devices. In contrast to the cloud server, the computing capacity of fog nodes is limited and thus a single fog node might not be capable of computing-intensive tasks. In this context, task offloading can be particularly useful at the fog nodes by selecting the suitable nodes and proper resource management while guaranteeing the Quality-of-Service (QoS) requirements of the users. This paper studies the design of a joint task offloading and resource allocation control for heterogeneous service tasks in multi-fog nodes systems. This problem is formulated as a partially observable stochastic game, in which each fog node cooperates to maximize the aggregated local rewards while the nodes only have access to local observations. To deal with partial observability, we apply a deep recurrent Q-network (DRQN) approach to approximate the optimal value functions. The solution is then compared to a deep Q-network (DQN) and deep convolutional Q-network (DCQN) approach to evaluate the performance of different neural networks. Moreover, to guarantee the convergence and accuracy of the neural network, an adjusted exploration-exploitation method is adopted. Provided numerical results show that the proposed algorithm can achieve a higher average success rate and lower average overflow than baseline methods.",
        "published": "2020-07-21T03:41:28Z",
        "link": "http://arxiv.org/abs/2007.10581v1",
        "categories": [
            "cs.DC",
            "cs.MA",
            "eess.SP"
        ]
    },
    {
        "title": "Congestion Management for Mobility-on-Demand Schemes that use Electric   Vehicles",
        "authors": [
            "Emmanouil Rigas",
            "Konstantinos Tsompanidis"
        ],
        "summary": "To date the majority of commuters use their privately owned vehicle that uses an internal combustion engine. This transportation model suffers from low vehicle utilization and causes environmental pollution. This paper studies the use of Electric Vehicles (EVs) operating in a Mobility-on-Demand (MoD) scheme and tackles the related management challenges. We assume a number of customers acting as cooperative agents requesting a set of alternative trips and EVs distributed across a number of pick-up and drop-off stations. In this setting, we propose congestion management algorithms which take as input the trip requests and calculate the EV-to-customer assignment aiming to maximize trip execution by keeping the system balanced in terms of matching demand and supply. We propose a Mixed-Integer-Programming (MIP) optimal offline solution which assumes full knowledge of customer demand and an equivalent online greedy algorithm that can operate in real time. The online algorithm uses three alternative heuristic functions in deciding whether to execute a customer request: (a) The sum of squares of all EVs in all stations, (b) the percentage of trips' destination location fullness and (c) a random choice of trip execution. Through a detailed evaluation, we observe that (a) provides an increase of up to 4.8% compared to (b) and up to 11.5% compared to (c) in terms of average trip execution, while all of them achieve close to the optimal performance. At the same time, the optimal scales up to settings consisting of tenths of EVs and a few hundreds of customer requests.",
        "published": "2020-07-21T09:38:10Z",
        "link": "http://arxiv.org/abs/2007.16088v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Output Based Adaptive Distributed Output Observer for Leader-follower   Multiagent Systems",
        "authors": [
            "He Cai",
            "Jie Huang"
        ],
        "summary": "The adaptive distributed observer approach has been an effective tool for synthesizing a distributed control law for solving various control problems of leader-follower multiagent systems. However, the existing adaptive distributed observer needs to make use of the full state of the leader system. This assumption not only precludes many practical applications in which only the output of the leader system is available, but also leads to a high dimension observer. In this communique, we propose an adaptive distributed output observer which only makes use of the output of the leader system, and is thus more practical than the state based adaptive distributed observer. Moreover, the dimension and the information exchange among agents of the proposed adaptive distributed output observer can be significantly smaller than those of the state based adaptive distributed output observer.",
        "published": "2020-07-22T01:21:49Z",
        "link": "http://arxiv.org/abs/2007.11153v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Proceedings of the First Workshop on Agents and Robots for reliable   Engineered Autonomy",
        "authors": [
            "Rafael C. Cardoso",
            "Angelo Ferrando",
            "Daniela Briola",
            "Claudio Menghi",
            "Tobias Ahlbrecht"
        ],
        "summary": "This volume contains the proceedings of the First Workshop on Agents and Robots for reliable Engineered Autonomy (AREA 2020), co-located with the 24th European Conference on Artificial Intelligence (ECAI 2020). AREA brings together researchers from autonomous agents, software engineering and robotic communities, as combining knowledge coming from these research areas may lead to innovative approaches that solve complex problems related with the verification and validation of autonomous robotic systems.",
        "published": "2020-07-22T08:33:36Z",
        "link": "http://arxiv.org/abs/2007.11260v1",
        "categories": [
            "cs.MA",
            "cs.RO",
            "cs.SE"
        ]
    },
    {
        "title": "Exploratory Experiments on Programming Autonomous Robots in Jadescript",
        "authors": [
            "Eleonora Iotti",
            "Giuseppe Petrosino",
            "Stefania Monica",
            "Federico Bergenti"
        ],
        "summary": "This paper describes exploratory experiments to validate the possibility of programming autonomous robots using an agent-oriented programming language. Proper perception of the environment, by means of various types of sensors, and timely reaction to external events, by means of effective actuators, are essential to provide robots with a sufficient level of autonomy. The agent-oriented programming paradigm is relevant with this respect because it offers language-level abstractions to process events and to command actuators. A recent agent-oriented programming language called Jadescript is presented in this paper together with its new features specifically designed to handle events. Exploratory experiments on a simple case-study application are presented to show the validity of the proposed approach and to exemplify the use of the language to program autonomous robots.",
        "published": "2020-07-23T01:31:46Z",
        "link": "http://arxiv.org/abs/2007.11741v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.PL"
        ]
    },
    {
        "title": "Engineering Reliable Interactions in the Reality-Artificiality Continuum",
        "authors": [
            "Davide Ancona",
            "Chiara Bassano",
            "Manuela Chessa",
            "Viviana Mascardi",
            "Fabio Solari"
        ],
        "summary": "Milgram's reality-virtuality continuum applies to interaction in the physical space dimension, going from real to virtual. However, interaction has a social dimension as well, that can go from real to artificial depending on the companion with whom the user interacts. In this paper we present our vision of the Reality-Artificiality bidimensional Continuum (RAC), we identify some challenges in its design and development and we discuss how reliable interactions might be supported inside RAC.",
        "published": "2020-07-23T01:32:00Z",
        "link": "http://arxiv.org/abs/2007.11742v1",
        "categories": [
            "cs.HC",
            "cs.MA"
        ]
    },
    {
        "title": "Adaptable and Verifiable BDI Reasoning",
        "authors": [
            "Peter Stringer",
            "Rafael C. Cardoso",
            "Xiaowei Huang",
            "Louise A. Dennis"
        ],
        "summary": "Long-term autonomy requires autonomous systems to adapt as their capabilities no longer perform as expected. To achieve this, a system must first be capable of detecting such changes. In this position paper, we describe a system architecture for BDI autonomous agents capable of adapting to changes in a dynamic environment and outline the required research. Specifically, we describe an agent-maintained self-model with accompanying theories of durative actions and learning new action descriptions in BDI systems.",
        "published": "2020-07-23T01:32:53Z",
        "link": "http://arxiv.org/abs/2007.11743v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LO"
        ]
    },
    {
        "title": "Toward Campus Mail Delivery Using BDI",
        "authors": [
            "Chidiebere Onyedinma",
            "Patrick Gavigan",
            "Babak Esfandiari"
        ],
        "summary": "Autonomous systems developed with the Belief-Desire-Intention (BDI) architecture are usually mostly implemented in simulated environments. In this project we sought to build a BDI agent for use in the real world for campus mail delivery in the tunnel system at Carleton University. Ideally, the robot should receive a delivery order via a mobile application, pick up the mail at a station, navigate the tunnels to the destination station, and notify the recipient.   We linked the Robot Operating System (ROS) with a BDI reasoning system to achieve a subset of the required use cases. ROS handles the low-level sensing and actuation, while the BDI reasoning system handles the high-level reasoning and decision making. Sensory data is orchestrated and sent from ROS to the reasoning system as perceptions. These perceptions are then deliberated upon, and an action string is sent back to ROS for interpretation and driving of the necessary actuator for the action to be performed.   In this paper we present our current implementation, which closes the loop on the hardware-software integration, and implements a subset of the use cases required for the full system.",
        "published": "2020-07-23T01:33:10Z",
        "link": "http://arxiv.org/abs/2007.16089v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.RO"
        ]
    },
    {
        "title": "Two-way Greedy: Algorithms for Imperfect Rationality",
        "authors": [
            "Diodato Ferraioli",
            "Paolo Penna",
            "Carmine Ventre"
        ],
        "summary": "The realization that selfish interests need to be accounted for in the design of algorithms has produced many contributions in computer science under the umbrella of algorithmic mechanism design. Novel algorithmic properties and paradigms have been identified and studied. Our work stems from the observation that selfishness is different from rationality; agents will attempt to strategize whenever they perceive it to be convenient according to their imperfect rationality. Recent work has focused on a particular notion of imperfect rationality, namely absence of contingent reasoning skills, and defined obvious strategyproofness (OSP) as a way to deal with the selfishness of these agents. Essentially, this definition states that to care for the incentives of these agents, we need not only pay attention about the relationship between input and output, but also about the way the algorithm is run. However, it is not clear what algorithmic approaches must be used for OSP. In this paper, we show that, for binary allocation problems, OSP is fully captured by a combination of two well-known algorithmic techniques: forward and reverse greedy. We call two-way greedy this algorithmic design paradigm. Our main technical contribution establishes the connection between OSP and two-way greedy. We build upon the recently introduced cycle monotonicity technique for OSP. By means of novel structural properties of cycles and queries of OSP mechanisms, we fully characterize these mechanisms in terms of extremal implementations. These are protocols that ask each agent to consistently separate one extreme of their domain at the current history from the rest. Through the connection with the greedy paradigm, we are able to import a host of approximation bounds to OSP and strengthen the strategic properties of this family of algorithms. Finally, we begin exploring the power of two-way greedy for set systems.",
        "published": "2020-07-23T09:10:44Z",
        "link": "http://arxiv.org/abs/2007.11868v1",
        "categories": [
            "cs.GT",
            "cs.DS",
            "cs.MA"
        ]
    },
    {
        "title": "Decentralized Safe Reactive Planning under TWTL Specifications",
        "authors": [
            "Ryan Peterson",
            "Ali Tevfik Buyukkocak",
            "Derya Aksaray",
            "Yasin Yazicioglu"
        ],
        "summary": "We investigate a multi-agent planning problem, where each agent aims to achieve an individual task while avoiding collisions with others. We assume that each agent's task is expressed as a Time-Window Temporal Logic (TWTL) specification defined over a 3D environment. We propose a decentralized receding horizon algorithm for online planning of trajectories. We show that when the environment is sufficiently connected, the resulting agent trajectories are always safe (collision-free) and lead to the satisfaction of the TWTL specifications or their finite temporal relaxations. Accordingly, deadlocks are always avoided and each agent is guaranteed to safely achieve its task with a finite time-delay in the worst case. Performance of the proposed algorithm is demonstrated via numerical simulations and experiments with quadrotors.",
        "published": "2020-07-23T22:04:46Z",
        "link": "http://arxiv.org/abs/2007.12278v1",
        "categories": [
            "cs.RO",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Value-Decomposition Multi-Agent Actor-Critics",
        "authors": [
            "Jianyu Su",
            "Stephen Adams",
            "Peter A. Beling"
        ],
        "summary": "The exploitation of extra state information has been an active research area in multi-agent reinforcement learning (MARL). QMIX represents the joint action-value using a non-negative function approximator and achieves the best performance, by far, on multi-agent benchmarks, StarCraft II micromanagement tasks. However, our experiments show that, in some cases, QMIX is incompatible with A2C, a training paradigm that promotes algorithm training efficiency. To obtain a reasonable trade-off between training efficiency and algorithm performance, we extend value-decomposition to actor-critics that are compatible with A2C and propose a novel actor-critic framework, value-decomposition actor-critics (VDACs). We evaluate VDACs on the testbed of StarCraft II micromanagement tasks and demonstrate that the proposed framework improves median performance over other actor-critic methods. Furthermore, we use a set of ablation experiments to identify the key factors that contribute to the performance of VDACs.",
        "published": "2020-07-24T00:50:02Z",
        "link": "http://arxiv.org/abs/2007.12306v4",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Off-Policy Multi-Agent Decomposed Policy Gradients",
        "authors": [
            "Yihan Wang",
            "Beining Han",
            "Tonghan Wang",
            "Heng Dong",
            "Chongjie Zhang"
        ],
        "summary": "Multi-agent policy gradient (MAPG) methods recently witness vigorous progress. However, there is a significant performance discrepancy between MAPG methods and state-of-the-art multi-agent value-based approaches. In this paper, we investigate causes that hinder the performance of MAPG algorithms and present a multi-agent decomposed policy gradient method (DOP). This method introduces the idea of value function decomposition into the multi-agent actor-critic framework. Based on this idea, DOP supports efficient off-policy learning and addresses the issue of centralized-decentralized mismatch and credit assignment in both discrete and continuous action spaces. We formally show that DOP critics have sufficient representational capability to guarantee convergence. In addition, empirical evaluations on the StarCraft II micromanagement benchmark and multi-agent particle environments demonstrate that DOP significantly outperforms both state-of-the-art value-based and policy-based multi-agent reinforcement learning algorithms. Demonstrative videos are available at https://sites.google.com/view/dop-mapg/.",
        "published": "2020-07-24T02:21:55Z",
        "link": "http://arxiv.org/abs/2007.12322v2",
        "categories": [
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Model Checkers Are Cool: How to Model Check Voting Protocols in Uppaal",
        "authors": [
            "Wojciech Jamroga",
            "Yan Kim",
            "Damian Kurpiewski",
            "Peter Y. A. Ryan"
        ],
        "summary": "The design and implementation of an e-voting system is a challenging task. Formal analysis can be of great help here. In particular, it can lead to a better understanding of how the voting system works, and what requirements on the system are relevant. In this paper, we propose that the state-of-art model checker Uppaal provides a good environment for modelling and preliminary verification of voting protocols. To illustrate this, we present an Uppaal model of Pr\\^et \\`a Voter, together with some natural extensions. We also show how to verify a variant of receipt-freeness, despite the severe limitations of the property specification language in the model checker.",
        "published": "2020-07-24T09:05:06Z",
        "link": "http://arxiv.org/abs/2007.12412v3",
        "categories": [
            "cs.CR",
            "cs.AI",
            "cs.LO",
            "cs.MA"
        ]
    },
    {
        "title": "Natural Strategic Abilities in Voting Protocols",
        "authors": [
            "Wojciech Jamroga",
            "Damian Kurpiewski",
            "Vadim Malvone"
        ],
        "summary": "Security properties are often focused on the technological side of the system. One implicitly assumes that the users will behave in the right way to preserve the property at hand. In real life, this cannot be taken for granted. In particular, security mechanisms that are difficult and costly to use are often ignored by the users, and do not really defend the system against possible attacks.   Here, we propose a graded notion of security based on the complexity of the user's strategic behavior. More precisely, we suggest that the level to which a security property $\\varphi$ is satisfied can be defined in terms of (a) the complexity of the strategy that the voter needs to execute to make $\\varphi$ true, and (b) the resources that the user must employ on the way. The simpler and cheaper to obtain $\\varphi$, the higher the degree of security.   We demonstrate how the idea works in a case study based on an electronic voting scenario. To this end, we model the vVote implementation of the \\Pret voting protocol for coercion-resistant and voter-verifiable elections. Then, we identify \"natural\" strategies for the voter to obtain receipt-freeness, and measure the voter's effort that they require. We also look at how hard it is for the coercer to compromise the election through a randomization attack.",
        "published": "2020-07-24T09:28:07Z",
        "link": "http://arxiv.org/abs/2007.12424v3",
        "categories": [
            "cs.MA",
            "cs.LO"
        ]
    },
    {
        "title": "Convex Decreasing Algorithms: Distributed Synthesis and Finite-time   Termination in Higher Dimension",
        "authors": [
            "James Melbourne",
            "Govind Saraswat",
            "Vivek Khatana",
            "Sourav Patel",
            "Murti V. Salapaka"
        ],
        "summary": "We introduce a general mathematical framework for distributed algorithms, and a monotonicity property frequently satisfied in application. These properties are leveraged to provide finite-time guarantees for converging algorithms, suited for use in the absence of a central authority. A central application is to consensus algorithms in higher dimension. These pursuits motivate a new peer to peer convex hull algorithm which we demonstrate to be an instantiation of the described theory. To address the diversity of convex sets and the potential computation and communication costs of knowing such sets in high dimension, a lightweight norm based stopping criteria is developed. More explicitly, we give a distributed algorithm that terminates in finite time when applied to consensus problems in higher dimensions and guarantees the convergence of the consensus algorithm in norm, within any given tolerance. Applications to consensus least squared estimation and distributed function determination are developed. The practical utility of the algorithm is illustrated through MATLAB simulations.",
        "published": "2020-07-26T04:00:53Z",
        "link": "http://arxiv.org/abs/2007.13050v2",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "CoV-ABM: A stochastic discrete-event agent-based framework to simulate   spatiotemporal dynamics of COVID-19",
        "authors": [
            "Masoud Jalayer",
            "Carlotta Orsenigo",
            "Carlo Vercellis"
        ],
        "summary": "The paper develops a stochastic Agent-Based Model (ABM) mimicking the spread of infectious diseases in geographical domains. The model is designed to simulate the spatiotemporal spread of SARS-CoV2 disease, known as COVID-19. Our SARS-CoV2-based ABM framework (CoV-ABM) simulates the spread at any geographical scale, ranging from a village to a country and considers unique characteristics of SARS-CoV2 viruses such as its persistence in the environment. Therefore, unlike other simulators, CoV-ABM computes the density of active viruses inside each location space to get the virus transmission probability for each agent. It also uses the local census and health data to create health and risk factor profiles for each individual. The proposed model relies on a flexible timestamp scale to optimize the computational speed and the level of detail. In our framework each agent represents a person interacting with the surrounding space and other adjacent agents inside the same space. Moreover, families stochastic daily tasks are formulated to get tracked by the corresponding family members. The model also formulates the possibility of meetings for each subset of friendships and relatives. The main aim of the proposed framework is threefold: to illustrate the dynamics of SARS-CoV diseases, to identify places which have a higher probability to become infection hubs and to provide a decision-support system to design efficient interventions in order to fight against pandemics. The framework employs SEIHRD dynamics of viral diseases with different intervention scenarios. The paper simulates the spread of COVID-19 in the State of Delaware, United States, with near one million stochastic agents. The results achieved over a period of 15 weeks with a timestamp of 1 hour show which places become the hubs of infection. The paper also illustrates how hospitals get overwhelmed as the outbreak reaches its pick.",
        "published": "2020-07-26T22:20:57Z",
        "link": "http://arxiv.org/abs/2007.13231v1",
        "categories": [
            "physics.soc-ph",
            "cs.MA"
        ]
    },
    {
        "title": "Exploring the effectiveness of a COVID-19 contact tracing app using an   agent-based model",
        "authors": [
            "Jonatan Almagor",
            "Stefano Picascia"
        ],
        "summary": "A contact-tracing strategy has been deemed necessary to contain the spread of COVID-19 following the relaxation of lockdown measures. Using an agent-based model, we explore one of the technology-based strategies proposed, a contact-tracing smartphone app. The model simulates the spread of COVID-19 in a population of agents on an urban scale. Agents are heterogeneous in their characteristics and are linked in a multi-layered network representing the social structure - including households, friendships, employment and schools. We explore the interplay of various adoption rates of the contact-tracing app, different levels of testing capacity, and behavioural factors to assess the impact on the epidemic. Results suggest that a contact tracing app can contribute substantially to reducing infection rates in the population when accompanied by a sufficient testing capacity or when the testing policy prioritises symptomatic cases. As user rate increases, prevalence of infection decreases. With that, when symptomatic cases are not prioritised for testing, a high rate of app users can generate an extensive increase in the demand for testing, which, if not met with adequate supply, may render the app counterproductive. This points to the crucial role of an efficient testing policy and the necessity to upscale testing capacity.",
        "published": "2020-07-27T16:58:17Z",
        "link": "http://arxiv.org/abs/2008.07336v2",
        "categories": [
            "cs.CY",
            "cs.MA",
            "cs.SI",
            "physics.soc-ph",
            "q-bio.PE"
        ]
    },
    {
        "title": "FlexPool: A Distributed Model-Free Deep Reinforcement Learning Algorithm   for Joint Passengers & Goods Transportation",
        "authors": [
            "Kaushik Manchella",
            "Abhishek K. Umrawal",
            "Vaneet Aggarwal"
        ],
        "summary": "The growth in online goods delivery is causing a dramatic surge in urban vehicle traffic from last-mile deliveries. On the other hand, ride-sharing has been on the rise with the success of ride-sharing platforms and increased research on using autonomous vehicle technologies for routing and matching. The future of urban mobility for passengers and goods relies on leveraging new methods that minimize operational costs and environmental footprints of transportation systems.   This paper considers combining passenger transportation with goods delivery to improve vehicle-based transportation. Even though the problem has been studied with a defined dynamics model of the transportation system environment, this paper considers a model-free approach that has been demonstrated to be adaptable to new or erratic environment dynamics. We propose FlexPool, a distributed model-free deep reinforcement learning algorithm that jointly serves passengers & goods workloads by learning optimal dispatch policies from its interaction with the environment. The proposed algorithm pools passengers for a ride-sharing service and delivers goods using a multi-hop transit method. These flexibilities decrease the fleet's operational cost and environmental footprint while maintaining service levels for passengers and goods. Through simulations on a realistic multi-agent urban mobility platform, we demonstrate that FlexPool outperforms other model-free settings in serving the demands from passengers & goods. FlexPool achieves 30% higher fleet utilization and 35% higher fuel efficiency in comparison to (i) model-free approaches where vehicles transport a combination of passengers & goods without the use of multi-hop transit, and (ii) model-free approaches where vehicles exclusively transport either passengers or goods.",
        "published": "2020-07-27T17:25:58Z",
        "link": "http://arxiv.org/abs/2007.13699v2",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Adaptive Workload Allocation for Multi-human Multi-robot Teams for   Independent and Homogeneous Tasks",
        "authors": [
            "Tamzidul Mina",
            "Shyam Sundar Kannan",
            "Wonse Jo",
            "Byung-Cheol Min"
        ],
        "summary": "Multi-human multi-robot (MH-MR) systems have the ability to combine the potential advantages of robotic systems with those of having humans in the loop. Robotic systems contribute precision performance and long operation on repetitive tasks without tiring, while humans in the loop improve situational awareness and enhance decision-making abilities. A system's ability to adapt allocated workload to changing conditions and the performance of each individual (human and robot) during the mission is vital to maintaining overall system performance. Previous works from literature including market-based and optimization approaches have attempted to address the task/workload allocation problem with focus on maximizing the system output without regarding individual agent conditions, lacking in real-time processing and have mostly focused exclusively on multi-robot systems. Given the variety of possible combination of teams (autonomous robots and human-operated robots: any number of human operators operating any number of robots at a time) and the operational scale of MH-MR systems, development of a generalized framework of workload allocation has been a particularly challenging task. In this paper, we present such a framework for independent homogeneous missions, capable of adaptively allocating the system workload in relation to health conditions and work performances of human-operated and autonomous robots in real-time. The framework consists of removable modular function blocks ensuring its applicability to different MH-MR scenarios. A new workload transition function block ensures smooth transition without the workload change having adverse effects on individual agents. The effectiveness and scalability of the system's workload adaptability is validated by experiments applying the proposed framework in a MH-MR patrolling scenario with changing human and robot condition, and failing robots.",
        "published": "2020-07-27T22:36:11Z",
        "link": "http://arxiv.org/abs/2007.13897v1",
        "categories": [
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Faster Game Solving via Predictive Blackwell Approachability: Connecting   Regret Matching and Mirror Descent",
        "authors": [
            "Gabriele Farina",
            "Christian Kroer",
            "Tuomas Sandholm"
        ],
        "summary": "Blackwell approachability is a framework for reasoning about repeated games with vector-valued payoffs. We introduce predictive Blackwell approachability, where an estimate of the next payoff vector is given, and the decision maker tries to achieve better performance based on the accuracy of that estimator. In order to derive algorithms that achieve predictive Blackwell approachability, we start by showing a powerful connection between four well-known algorithms. Follow-the-regularized-leader (FTRL) and online mirror descent (OMD) are the most prevalent regret minimizers in online convex optimization. In spite of this prevalence, the regret matching (RM) and regret matching+ (RM+) algorithms have been preferred in the practice of solving large-scale games (as the local regret minimizers within the counterfactual regret minimization framework). We show that RM and RM+ are the algorithms that result from running FTRL and OMD, respectively, to select the halfspace to force at all times in the underlying Blackwell approachability game. By applying the predictive variants of FTRL or OMD to this connection, we obtain predictive Blackwell approachability algorithms, as well as predictive variants of RM and RM+. In experiments across 18 common zero-sum extensive-form benchmark games, we show that predictive RM+ coupled with counterfactual regret minimization converges vastly faster than the fastest prior algorithms (CFR+, DCFR, LCFR) across all games but two of the poker games, sometimes by two or more orders of magnitude.",
        "published": "2020-07-28T16:49:55Z",
        "link": "http://arxiv.org/abs/2007.14358v2",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "Learning enables adaptation in cooperation for multi-player stochastic   games",
        "authors": [
            "Feng Huang",
            "Ming Cao",
            "Long Wang"
        ],
        "summary": "Interactions among individuals in natural populations often occur in a dynamically changing environment. Understanding the role of environmental variation in population dynamics has long been a central topic in theoretical ecology and population biology. However, the key question of how individuals, in the middle of challenging social dilemmas (e.g., the \"tragedy of the commons\"), modulate their behaviors to adapt to the fluctuation of the environment has not yet been addressed satisfactorily. Utilizing evolutionary game theory and stochastic games, we develop a game-theoretical framework that incorporates the adaptive mechanism of reinforcement learning to investigate whether cooperative behaviors can evolve in the ever-changing group interaction environment. When the action choices of players are just slightly influenced by past reinforcements, we construct an analytical condition to determine whether cooperation can be favored over defection. Intuitively, this condition reveals why and how the environment can mediate cooperative dilemmas. Under our model architecture, we also compare this learning mechanism with two non-learning decision rules, and we find that learning significantly improves the propensity for cooperation in weak social dilemmas, and, in sharp contrast, hinders cooperation in strong social dilemmas. Our results suggest that in complex social-ecological dilemmas, learning enables the adaptation of individuals to varying environments.",
        "published": "2020-07-29T17:01:24Z",
        "link": "http://arxiv.org/abs/2007.14957v1",
        "categories": [
            "q-bio.PE",
            "cs.GT",
            "cs.MA",
            "physics.bio-ph",
            "physics.soc-ph"
        ]
    },
    {
        "title": "Moody Learners -- Explaining Competitive Behaviour of Reinforcement   Learning Agents",
        "authors": [
            "Pablo Barros",
            "Ana Tanevska",
            "Francisco Cruz",
            "Alessandra Sciutti"
        ],
        "summary": "Designing the decision-making processes of artificial agents that are involved in competitive interactions is a challenging task. In a competitive scenario, the agent does not only have a dynamic environment but also is directly affected by the opponents' actions. Observing the Q-values of the agent is usually a way of explaining its behavior, however, do not show the temporal-relation between the selected actions. We address this problem by proposing the \\emph{Moody framework}. We evaluate our model by performing a series of experiments using the competitive multiplayer Chef's Hat card game and discuss how our model allows the agents' to obtain a holistic representation of the competitive dynamics within the game.",
        "published": "2020-07-30T11:30:42Z",
        "link": "http://arxiv.org/abs/2007.16045v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "MAPPER: Multi-Agent Path Planning with Evolutionary Reinforcement   Learning in Mixed Dynamic Environments",
        "authors": [
            "Zuxin Liu",
            "Baiming Chen",
            "Hongyi Zhou",
            "Guru Koushik",
            "Martial Hebert",
            "Ding Zhao"
        ],
        "summary": "Multi-agent navigation in dynamic environments is of great industrial value when deploying a large scale fleet of robot to real-world applications. This paper proposes a decentralized partially observable multi-agent path planning with evolutionary reinforcement learning (MAPPER) method to learn an effective local planning policy in mixed dynamic environments. Reinforcement learning-based methods usually suffer performance degradation on long-horizon tasks with goal-conditioned sparse rewards, so we decompose the long-range navigation task into many easier sub-tasks under the guidance of a global planner, which increases agents' performance in large environments. Moreover, most existing multi-agent planning approaches assume either perfect information of the surrounding environment or homogeneity of nearby dynamic agents, which may not hold in practice. Our approach models dynamic obstacles' behavior with an image-based representation and trains a policy in mixed dynamic environments without homogeneity assumption. To ensure multi-agent training stability and performance, we propose an evolutionary training approach that can be easily scaled to large and complex environments. Experiments show that MAPPER is able to achieve higher success rates and more stable performance when exposed to a large number of non-cooperative dynamic obstacles compared with traditional reaction-based planner LRA* and the state-of-the-art learning-based method.",
        "published": "2020-07-30T20:14:42Z",
        "link": "http://arxiv.org/abs/2007.15724v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Possibility conditions for Open Access",
        "authors": [
            "Jacinto Davila"
        ],
        "summary": "This is an attempt to formalize the conditions of possibility for free, libre, open access to scientific knowledge within a game. The challenge is to enunciate the terms under which agents participating in the Grand conversation of science would be willing to open share, exchange, negotiate or surrender their contributions, considering their corresponding intentions, goals, beliefs and expected utilities. Many conclusions can be drawn from the game here described. We have made many simplifying decisions along the modelling process that must be taken into account as a determining context for those conclusions, of course. It can be safely state, however, that under the current conditions of the game, Editors will keep betting on Toll Access, knowledge distribution models even if all the other Academic agent go for Open Access.",
        "published": "2020-07-31T21:03:07Z",
        "link": "http://arxiv.org/abs/2008.00076v2",
        "categories": [
            "cs.GT",
            "cs.MA",
            "91-10 (Primary) 91A80, 91F10 (Secondary)",
            "J.4"
        ]
    },
    {
        "title": "Cooperative Control of Mobile Robots with Stackelberg Learning",
        "authors": [
            "Joewie J. Koh",
            "Guohui Ding",
            "Christoffer Heckman",
            "Lijun Chen",
            "Alessandro Roncone"
        ],
        "summary": "Multi-robot cooperation requires agents to make decisions that are consistent with the shared goal without disregarding action-specific preferences that might arise from asymmetry in capabilities and individual objectives. To accomplish this goal, we propose a method named SLiCC: Stackelberg Learning in Cooperative Control. SLiCC models the problem as a partially observable stochastic game composed of Stackelberg bimatrix games, and uses deep reinforcement learning to obtain the payoff matrices associated with these games. Appropriate cooperative actions are then selected with the derived Stackelberg equilibria. Using a bi-robot cooperative object transportation problem, we validate the performance of SLiCC against centralized multi-agent Q-learning and demonstrate that SLiCC achieves better combined utility.",
        "published": "2020-08-03T07:21:51Z",
        "link": "http://arxiv.org/abs/2008.00679v1",
        "categories": [
            "cs.RO",
            "cs.GT",
            "cs.LG",
            "cs.MA",
            "I.2.9; I.2.6; I.2.11"
        ]
    },
    {
        "title": "Getting to Know One Another: Calibrating Intent, Capabilities and Trust   for Human-Robot Collaboration",
        "authors": [
            "Joshua Lee",
            "Jeffrey Fong",
            "Bing Cai Kok",
            "Harold Soh"
        ],
        "summary": "Common experience suggests that agents who know each other well are better able to work together. In this work, we address the problem of calibrating intention and capabilities in human-robot collaboration. In particular, we focus on scenarios where the robot is attempting to assist a human who is unable to directly communicate her intent. Moreover, both agents may have differing capabilities that are unknown to one another. We adopt a decision-theoretic approach and propose the TICC-POMDP for modeling this setting, with an associated online solver. Experiments show our approach leads to better team performance both in simulation and in a real-world study with human subjects.",
        "published": "2020-08-03T08:04:15Z",
        "link": "http://arxiv.org/abs/2008.00699v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.HC",
            "cs.MA"
        ]
    },
    {
        "title": "QPLEX: Duplex Dueling Multi-Agent Q-Learning",
        "authors": [
            "Jianhao Wang",
            "Zhizhou Ren",
            "Terry Liu",
            "Yang Yu",
            "Chongjie Zhang"
        ],
        "summary": "We explore value-based multi-agent reinforcement learning (MARL) in the popular paradigm of centralized training with decentralized execution (CTDE). CTDE has an important concept, Individual-Global-Max (IGM) principle, which requires the consistency between joint and local action selections to support efficient local decision-making. However, in order to achieve scalability, existing MARL methods either limit representation expressiveness of their value function classes or relax the IGM consistency, which may suffer from instability risk or may not perform well in complex domains. This paper presents a novel MARL approach, called duPLEX dueling multi-agent Q-learning (QPLEX), which takes a duplex dueling network architecture to factorize the joint value function. This duplex dueling structure encodes the IGM principle into the neural network architecture and thus enables efficient value function learning. Theoretical analysis shows that QPLEX achieves a complete IGM function class. Empirical experiments on StarCraft II micromanagement tasks demonstrate that QPLEX significantly outperforms state-of-the-art baselines in both online and offline data collection settings, and also reveal that QPLEX achieves high sample efficiency and can benefit from offline datasets without additional online exploration.",
        "published": "2020-08-03T17:52:09Z",
        "link": "http://arxiv.org/abs/2008.01062v3",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "A Combination of Theta*, ORCA and Push and Rotate for Multi-agent   Navigation",
        "authors": [
            "Stepan Dergachev",
            "Konstantin Yakovlev",
            "Ryhor Prakapovich"
        ],
        "summary": "We study the problem of multi-agent navigation in static environments when no centralized controller is present. Each agent is controlled individually and relies on three algorithmic components to achieve its goal while avoiding collisions with the other agents and the obstacles: i) individual path planning which is done by Theta* algorithm; ii) collision avoidance while path following which is performed by ORCA* algorithm; iii) locally-confined multi-agent path planning done by Push and Rotate algorithm. The latter component is crucial to avoid deadlocks in confined areas, such as narrow passages or doors. We describe how the suggested components interact and form a coherent navigation pipeline. We carry out an extensive empirical evaluation of this pipeline in simulation. The obtained results clearly demonstrate that the number of occurring deadlocks significantly decreases enabling more agents to reach their goals compared to techniques that rely on collision-avoidance only and do not include multi-agent path planning component",
        "published": "2020-08-03T22:22:43Z",
        "link": "http://arxiv.org/abs/2008.01227v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "I.2.11; I.2.8; I.2.9"
        ]
    },
    {
        "title": "Wisdom of crowds: much ado about nothing",
        "authors": [
            "Sandro M. Reia",
            "José F. Fontanari"
        ],
        "summary": "The puzzling idea that the combination of independent estimates of the magnitude of a quantity results in a very accurate prediction, which is superior to any or, at least, to most of the individual estimates is known as the wisdom of crowds. Here we use the Federal Reserve Bank of Philadelphia's Survey of Professional Forecasters database to confront the statistical and psychophysical explanations of this phenomenon. Overall we find that the data do not support any of the proposed explanations of the wisdom of crowds. In particular, we find a positive correlation between the variance (or diversity) of the estimates and the crowd error in disagreement with some interpretations of the diversity prediction theorem. In addition, contra the predictions of the psychophysical augmented quincunx model, we find that the skew of the estimates offers no information about the crowd error. More importantly, we find that the crowd beats all individuals in less than 2% of the forecasts and beats most individuals in less than 70% of the forecasts, which means that there is a sporting chance that an individual selected at random will perform better than the crowd. These results contrast starkly with the performance of non-natural crowds composed of unbiased forecasters which beat most individuals in practically all forecasts. The moderate statistical advantage of a real-world crowd over its members does not justify the ado about its wisdom, which is most likely a product of the selective attention fallacy.",
        "published": "2020-08-04T12:26:15Z",
        "link": "http://arxiv.org/abs/2008.01485v2",
        "categories": [
            "stat.AP",
            "cs.MA",
            "physics.data-an"
        ]
    },
    {
        "title": "Robust Reinforcement Learning using Adversarial Populations",
        "authors": [
            "Eugene Vinitsky",
            "Yuqing Du",
            "Kanaad Parvate",
            "Kathy Jang",
            "Pieter Abbeel",
            "Alexandre Bayen"
        ],
        "summary": "Reinforcement Learning (RL) is an effective tool for controller design but can struggle with issues of robustness, failing catastrophically when the underlying system dynamics are perturbed. The Robust RL formulation tackles this by adding worst-case adversarial noise to the dynamics and constructing the noise distribution as the solution to a zero-sum minimax game. However, existing work on learning solutions to the Robust RL formulation has primarily focused on training a single RL agent against a single adversary. In this work, we demonstrate that using a single adversary does not consistently yield robustness to dynamics variations under standard parametrizations of the adversary; the resulting policy is highly exploitable by new adversaries. We propose a population-based augmentation to the Robust RL formulation in which we randomly initialize a population of adversaries and sample from the population uniformly during training. We empirically validate across robotics benchmarks that the use of an adversarial population results in a more robust policy that also improves out-of-distribution generalization. Finally, we demonstrate that this approach provides comparable robustness and generalization as domain randomization on these benchmarks while avoiding a ubiquitous domain randomization failure mode.",
        "published": "2020-08-04T20:57:32Z",
        "link": "http://arxiv.org/abs/2008.01825v2",
        "categories": [
            "cs.LG",
            "cs.MA",
            "cs.RO",
            "stat.ML"
        ]
    },
    {
        "title": "The Emergence of Adversarial Communication in Multi-Agent Reinforcement   Learning",
        "authors": [
            "Jan Blumenkamp",
            "Amanda Prorok"
        ],
        "summary": "Many real-world problems require the coordination of multiple autonomous agents. Recent work has shown the promise of Graph Neural Networks (GNNs) to learn explicit communication strategies that enable complex multi-agent coordination. These works use models of cooperative multi-agent systems whereby agents strive to achieve a shared global goal. When considering agents with self-interested local objectives, the standard design choice is to model these as separate learning systems (albeit sharing the same environment). Such a design choice, however, precludes the existence of a single, differentiable communication channel, and consequently prohibits the learning of inter-agent communication strategies. In this work, we address this gap by presenting a learning model that accommodates individual non-shared rewards and a differentiable communication channel that is common among all agents. We focus on the case where agents have self-interested objectives, and develop a learning algorithm that elicits the emergence of adversarial communications. We perform experiments on multi-agent coverage and path planning problems, and employ a post-hoc interpretability technique to visualize the messages that agents communicate to each other. We show how a single self-interested agent is capable of learning highly manipulative communication strategies that allows it to significantly outperform a cooperative team of agents.",
        "published": "2020-08-06T12:48:08Z",
        "link": "http://arxiv.org/abs/2008.02616v2",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Deep Q-Network Based Multi-agent Reinforcement Learning with Binary   Action Agents",
        "authors": [
            "Abdul Mueed Hafiz",
            "Ghulam Mohiuddin Bhat"
        ],
        "summary": "Deep Q-Network (DQN) based multi-agent systems (MAS) for reinforcement learning (RL) use various schemes where in the agents have to learn and communicate. The learning is however specific to each agent and communication may be satisfactorily designed for the agents. As more complex Deep QNetworks come to the fore, the overall complexity of the multi-agent system increases leading to issues like difficulty in training, need for higher resources and more training time, difficulty in fine-tuning, etc. To address these issues we propose a simple but efficient DQN based MAS for RL which uses shared state and rewards, but agent-specific actions, for updation of the experience replay pool of the DQNs, where each agent is a DQN. The benefits of the approach are overall simplicity, faster convergence and better performance as compared to conventional DQN based approaches. It should be noted that the method can be extended to any DQN. As such we use simple DQN and DDQN (Double Q-learning) respectively on three separate tasks i.e. Cartpole-v1 (OpenAI Gym environment) , LunarLander-v2 (OpenAI Gym environment) and Maze Traversal (customized environment). The proposed approach outperforms the baseline on these tasks by decent margins respectively.",
        "published": "2020-08-06T15:16:05Z",
        "link": "http://arxiv.org/abs/2008.04109v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "stat.ML"
        ]
    },
    {
        "title": "Competitive Allocation of a Mixed Manna",
        "authors": [
            "Bhaskar Ray Chaudhury",
            "Jugal Garg",
            "Peter McGlaughlin",
            "Ruta Mehta"
        ],
        "summary": "We study the fair division problem of allocating a mixed manna under additively separable piecewise linear concave (SPLC) utilities. A mixed manna contains goods that everyone likes and bads that everyone dislikes, as well as items that some like and others dislike. The seminal work of Bogomolnaia et al. [Econometrica'17] argue why allocating a mixed manna is genuinely more complicated than a good or a bad manna, and why competitive equilibrium is the best mechanism. They also provide the existence of equilibrium and establish its peculiar properties (e.g., non-convex and disconnected set of equilibria even under linear utilities), but leave the problem of computing an equilibrium open. This problem remained unresolved even for only bad manna under linear utilities.   Our main result is a simplex-like algorithm based on Lemke's scheme for computing a competitive allocation of a mixed manna under SPLC utilities, a strict generalization of linear. Experimental results on randomly generated instances suggest that our algorithm will be fast in practice. The problem is known to be PPAD-hard for the case of good manna, and we also show a similar result for the case of bad manna. Given these PPAD-hardness results, designing such an algorithm is the only non-brute-force (non-enumerative) option known, e.g., the classic Lemke-Howson algorithm (1964) for computing a Nash equilibrium in a 2-player game is still one of the most widely used algorithms in practice.   Our algorithm also yields several new structural properties as simple corollaries. We obtain a (constructive) proof of existence for a far more general setting, membership of the problem in PPAD, rational-valued solution, and odd number of solutions property. The last property also settles the conjecture of Bogomolnaia et al. in the affirmative.",
        "published": "2020-08-06T16:38:00Z",
        "link": "http://arxiv.org/abs/2008.02753v1",
        "categories": [
            "cs.GT",
            "cs.CC",
            "cs.DM",
            "cs.DS",
            "cs.MA"
        ]
    },
    {
        "title": "Distributed Deep Reinforcement Learning for Functional Split Control in   Energy Harvesting Virtualized Small Cells",
        "authors": [
            "Dagnachew Azene Temesgene",
            "Marco Miozzo",
            "Deniz Gündüz",
            "Paolo Dini"
        ],
        "summary": "To meet the growing quest for enhanced network capacity, mobile network operators (MNOs) are deploying dense infrastructures of small cells. This, in turn, increases the power consumption of mobile networks, thus impacting the environment. As a result, we have seen a recent trend of powering mobile networks with harvested ambient energy to achieve both environmental and cost benefits. In this paper, we consider a network of virtualized small cells (vSCs) powered by energy harvesters and equipped with rechargeable batteries, which can opportunistically offload baseband (BB) functions to a grid-connected edge server depending on their energy availability. We formulate the corresponding grid energy and traffic drop rate minimization problem, and propose a distributed deep reinforcement learning (DDRL) solution. Coordination among vSCs is enabled via the exchange of battery state information. The evaluation of the network performance in terms of grid energy consumption and traffic drop rate confirms that enabling coordination among the vSCs via knowledge exchange achieves a performance close to the optimal. Numerical results also confirm that the proposed DDRL solution provides higher network performance, better adaptation to the changing environment, and higher cost savings with respect to a tabular multi-agent reinforcement learning (MRL) solution used as a benchmark.",
        "published": "2020-08-07T12:27:01Z",
        "link": "http://arxiv.org/abs/2008.04105v1",
        "categories": [
            "cs.NI",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Explanation Generation for Multi-Modal Multi-Agent Path Finding with   Optimal Resource Utilization using Answer Set Programming",
        "authors": [
            "Aysu Bogatarkan",
            "Esra Erdem"
        ],
        "summary": "The multi-agent path finding (MAPF) problem is a combinatorial search problem that aims at finding paths for multiple agents (e.g., robots) in an environment (e.g., an autonomous warehouse) such that no two agents collide with each other, and subject to some constraints on the lengths of paths. We consider a general version of MAPF, called mMAPF, that involves multi-modal transportation modes (e.g., due to velocity constraints) and consumption of different types of resources (e.g., batteries). The real-world applications of mMAPF require flexibility (e.g., solving variations of mMAPF) as well as explainability. Our earlier studies on mMAPF have focused on the former challenge of flexibility. In this study, we focus on the latter challenge of explainability, and introduce a method for generating explanations for queries regarding the feasibility and optimality of solutions, the nonexistence of solutions, and the observations about solutions. Our method is based on answer set programming. This paper is under consideration for acceptance in TPLP.",
        "published": "2020-08-08T18:34:34Z",
        "link": "http://arxiv.org/abs/2008.03573v1",
        "categories": [
            "cs.AI",
            "cs.LO",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Potential Games for Distributed Constrained Consensus",
        "authors": [
            "Dimitris Ampeliotis",
            "Kostas Berberidis"
        ],
        "summary": "The problem of computing a common point that lies in the intersection of a finite number of closed convex sets, each known to one agent in a network, is studied. This issue, known as the distributed convex feasibility problem or the distributed constrained consensus problem, constitutes an important research goal mainly due to the large number of possible applications. In this work, this issue is treated from a game theoretic viewpoint. In particular, we formulate the problem as a non-cooperative game for which a potential function exists and prove that all Nash equilibria of this game correspond to consensus states. Based upon this analysis, a best-response based distributed algorithm that solves the constrained consensus problem is developed. Furthermore, one more approach to solve the convex feasibility problem is studied based upon a projected gradient type algorithm that seeks the maximum of the considered potential function. A condition for the convergence of this scheme is derived and an exact distributed algorithm is given. Finally, simulation results for a source localization problem are given, that validate the theoretical results and demonstrate the applicability and performance of the derived algorithms.",
        "published": "2020-08-08T18:46:01Z",
        "link": "http://arxiv.org/abs/2008.03577v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Lights and Shadows in Evolutionary Deep Learning: Taxonomy, Critical   Methodological Analysis, Cases of Study, Learned Lessons, Recommendations and   Challenges",
        "authors": [
            "Aritz D. Martinez",
            "Javier Del Ser",
            "Esther Villar-Rodriguez",
            "Eneko Osaba",
            "Javier Poyatos",
            "Siham Tabik",
            "Daniel Molina",
            "Francisco Herrera"
        ],
        "summary": "Much has been said about the fusion of bio-inspired optimization algorithms and Deep Learning models for several purposes: from the discovery of network topologies and hyper-parametric configurations with improved performance for a given task, to the optimization of the model's parameters as a replacement for gradient-based solvers. Indeed, the literature is rich in proposals showcasing the application of assorted nature-inspired approaches for these tasks. In this work we comprehensively review and critically examine contributions made so far based on three axes, each addressing a fundamental question in this research avenue: a) optimization and taxonomy (Why?), including a historical perspective, definitions of optimization problems in Deep Learning, and a taxonomy associated with an in-depth analysis of the literature, b) critical methodological analysis (How?), which together with two case studies, allows us to address learned lessons and recommendations for good practices following the analysis of the literature, and c) challenges and new directions of research (What can be done, and what for?). In summary, three axes - optimization and taxonomy, critical analysis, and challenges - which outline a complete vision of a merger of two technologies drawing up an exciting future for this area of fusion research.",
        "published": "2020-08-09T00:25:06Z",
        "link": "http://arxiv.org/abs/2008.03620v1",
        "categories": [
            "cs.NE",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Navigating Human Language Models with Synthetic Agents",
        "authors": [
            "Philip Feldman",
            "Antonio Bucchiarone"
        ],
        "summary": "Modern natural language models such as the GPT-2/GPT-3 contain tremendous amounts of information about human belief in a consistently testable form. If these models could be shown to accurately reflect the underlying beliefs of the human beings that produced the data used to train these models, then such models become a powerful sociological tool in ways that are distinct from traditional methods, such as interviews and surveys. In this study, We train a version of the GPT-2 on a corpora of historical chess games, and then \"launch\" clusters of synthetic agents into the model, using text strings to create context and orientation. We compare the trajectories contained in the text generated by the agents/model and compare that to the known ground truth of the chess board, move legality, and historical patterns of play. We find that the percentages of moves by piece using the model are substantially similar from human patterns. We further find that the model creates an accurate latent representation of the chessboard, and that it is possible to plot trajectories of legal moves across the board using this knowledge.",
        "published": "2020-08-10T14:39:53Z",
        "link": "http://arxiv.org/abs/2008.04162v7",
        "categories": [
            "cs.AI",
            "cs.CL",
            "cs.MA",
            "I.2; I.6; J.4"
        ]
    },
    {
        "title": "Ride-hailing Impacts on Transit Ridership: Chicago Case Study",
        "authors": [
            "Helena Breuer",
            "Jianhe Du",
            "Hesham A. Rakha"
        ],
        "summary": "Existing literature on the relationship between ride-hailing (RH) and transit services is limited to empirical studies that lack real-time spatial contexts. To fill this gap, we took a novel real-time geospatial analysis approach. With source data on ride-hailing trips in Chicago, Illinois, we computed real-time transit-equivalent trips for all 7,949,902 ride-hailing trips in June 2019; the sheer size of our sample is incomparable to the samples studied in existing literature. An existing Multinomial Nested Logit Model was used to determine the probability of a ride-hailer selecting a transit alternative to serve the specific O-D pair, P(Transit|CTA). We find that 31% of ride-hailing trips are replaceable, whereas 61% of trips are not replaceable. The remaining 8% lie within a buffer zone. We measured the robustness of this probability using a parametric sensitivity analysis and performed a two-tailed t-test. Our results indicate that of the four sensitivity parameters, the probability was most sensitive to the total travel time of a transit trip. The main contribution of our research is our thorough approach and fine-tuned series of real-time spatiotemporal analyses that investigate the replaceability of ride-hailing trips for public transit. The results and discussion intend to provide perspective derived from real trips and we anticipate that this paper will demonstrate the research benefits associated with the recording and release of ride-hailing data.",
        "published": "2020-08-10T14:47:11Z",
        "link": "http://arxiv.org/abs/2011.11130v1",
        "categories": [
            "physics.soc-ph",
            "cs.MA"
        ]
    },
    {
        "title": "An improved convergence analysis for decentralized online stochastic   non-convex optimization",
        "authors": [
            "Ran Xin",
            "Usman A. Khan",
            "Soummya Kar"
        ],
        "summary": "In this paper, we study decentralized online stochastic non-convex optimization over a network of nodes. Integrating a technique called gradient tracking in decentralized stochastic gradient descent, we show that the resulting algorithm, GT-DSGD, enjoys certain desirable characteristics towards minimizing a sum of smooth non-convex functions. In particular, for general smooth non-convex functions, we establish non-asymptotic characterizations of GT-DSGD and derive the conditions under which it achieves network-independent performances that match the centralized minibatch SGD. In contrast, the existing results suggest that GT-DSGD is always network-dependent and is therefore strictly worse than the centralized minibatch SGD. When the global non-convex function additionally satisfies the Polyak-Lojasiewics (PL) condition, we establish the linear convergence of GT-DSGD up to a steady-state error with appropriate constant step-sizes. Moreover, under stochastic approximation step-sizes, we establish, for the first time, the optimal global sublinear convergence rate on almost every sample path, in addition to the asymptotically optimal sublinear rate in expectation. Since strongly convex functions are a special case of the functions satisfying the PL condition, our results are not only immediately applicable but also improve the currently known best convergence rates and their dependence on problem parameters.",
        "published": "2020-08-10T15:29:13Z",
        "link": "http://arxiv.org/abs/2008.04195v2",
        "categories": [
            "math.OC",
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "stat.ML"
        ]
    },
    {
        "title": "Bicycle Longitudinal Motion Modeling",
        "authors": [
            "Karim Fadhloun",
            "Hesham A. Rakha",
            "Archak Mittal"
        ],
        "summary": "This research effort uses vehicular traffic flow techniques to model bicyclist longitudinal motion while accounting for bicycle interactions. Specifically, an existing car-following model, the Fadhloun-Rakha (FR) model is re-parametrized to model bicyclists. Initially, the study evaluates the performance of the proposed model formulation using experimental datasets collected from two ring-road bicycle experiments; one conducted in Germany in 2012, and the second in China in 2016. The validation of the model is achieved through investigating and comparing the proposed model outputs against those obtained from two state-of-the-art models, namely: the Necessary Deceleration Model (NDM), which is a model specifically designed to capture the longitudinal motion of bicyclists; and the Intelligent Driver Model, which is a car-following model that was demonstrated to be suitable for single-file bicycle traffic. Through a quantitative and qualitative evaluation, the proposed model formulation is demonstrated to produce modeling errors that are consistent with the other two models. While all three models generate trajectories that are consistent with empirically observed bicycle-following behavior, only the proposed model allows for an explicit and straightforward tuning of the bicyclist physical characteristics and the road environment. A sensitivity analysis, demonstrates the effect of varying the different model parameters on the produced trajectories, highlighting the robustness and generality of the proposed model.",
        "published": "2020-08-10T15:43:35Z",
        "link": "http://arxiv.org/abs/2008.05908v1",
        "categories": [
            "physics.soc-ph",
            "cs.MA"
        ]
    },
    {
        "title": "Multi-objective Eco-Routing Model Development and Evaluation for Battery   Electric Vehicles",
        "authors": [
            "Kyoungho Ahn",
            "Youssef Bichiou",
            "Mohamed Farag",
            "Hesham A. Rakha"
        ],
        "summary": "This paper develops and investigates the impacts of multi-objective Nash optimum (user equilibrium) traffic assignment on a large-scale network for battery electric vehicles (BEVs) and internal combustion engine vehicles (ICEVs) in a microscopic traffic simulation environment. Eco-routing is a technique that finds the most energy efficient route. ICEV and BEV energy consumption patterns are significantly different with regard to their sensitivity to driving cycles. Unlike ICEVs, BEVs are more energy efficient on low-speed arterial trips compared to highway trips. Different energy consumption patterns require different eco-routing strategies for ICEVs and BEVs. This study found that eco-routing could reduce energy consumption for BEVs but also significantly increases their average travel time. The simulation study found that multi-objective routing could reduce the energy consumption of BEVs by 13.5, 14.2, 12.9, and 10.7 percent, as well as the fuel consumption of ICEVs by 0.1, 4.3, 3.4, and 10.6 percent for \"not congested\", \"slightly congested\", \"moderately congested\", and \"highly congested\" conditions, respectively. The study also found that multi-objective user equilibrium routing reduced the average vehicle travel time by up to 10.1% compared to the standard user equilibrium traffic assignment for the highly congested conditions, producing a solution closer to the system optimum traffic assignment. The results indicate that the multi-objective eco-routing can effectively reduce fuel/energy consumption with minimum impacts on travel times for both BEVs and ICEVs.",
        "published": "2020-08-10T15:55:04Z",
        "link": "http://arxiv.org/abs/2104.09336v1",
        "categories": [
            "physics.soc-ph",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Influence Spread in the Heterogeneous Multiplex Linear Threshold Model",
        "authors": [
            "Yaofeng Desmond Zhong",
            "Vaibhav Srivastava",
            "Naomi Ehrich Leonard"
        ],
        "summary": "The linear threshold model (LTM) has been used to study spread on single-layer networks defined by one inter-agent sensing modality and agents homogeneous in protocol. We define and analyze the heterogeneous multiplex LTM to study spread on multi-layer networks with each layer representing a different sensing modality and agents heterogeneous in protocol. Protocols are designed to distinguish signals from different layers: an agent becomes active if a sufficient number of its neighbors in each of any $a$ of the $m$ layers is active. We focus on Protocol OR, when $a=1$, and Protocol AND, when $a=m$, which model agents that are most and least readily activated, respectively. We develop theory and algorithms to compute the size of the spread at steady state for any set of initially active agents and to analyze the role of distinguished sensing modalities, network structure, and heterogeneity. We show how heterogeneity manages the tension in spreading dynamics between sensitivity to inputs and robustness to disturbances.",
        "published": "2020-08-10T19:41:04Z",
        "link": "http://arxiv.org/abs/2008.04383v1",
        "categories": [
            "math.OC",
            "cs.MA",
            "math.DS"
        ]
    },
    {
        "title": "Multi-Agent Safe Planning with Gaussian Processes",
        "authors": [
            "Zheqing Zhu",
            "Erdem Bıyık",
            "Dorsa Sadigh"
        ],
        "summary": "Multi-agent safe systems have become an increasingly important area of study as we can now easily have multiple AI-powered systems operating together. In such settings, we need to ensure the safety of not only each individual agent, but also the overall system. In this paper, we introduce a novel multi-agent safe learning algorithm that enables decentralized safe navigation when there are multiple different agents in the environment. This algorithm makes mild assumptions about other agents and is trained in a decentralized fashion, i.e. with very little prior knowledge about other agents' policies. Experiments show our algorithm performs well with the robots running other algorithms when optimizing various objectives.",
        "published": "2020-08-10T23:09:05Z",
        "link": "http://arxiv.org/abs/2008.04452v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "SMT-based Safety Verification of Parameterised Multi-Agent Systems",
        "authors": [
            "Paolo Felli",
            "Alessandro Gianola",
            "Marco Montali"
        ],
        "summary": "In this paper we study the verification of parameterised multi-agent systems (MASs), and in particular the task of verifying whether unwanted states, characterised as a given state formula, are reachable in a given MAS, i.e., whether the MAS is unsafe. The MAS is parameterised and the model only describes the finite set of possible agent templates, while the actual number of concrete agent instances for each template is unbounded and cannot be foreseen. This makes the state-space infinite. As safety may of course depend on the number of agent instances in the system, the verification result must be correct irrespective of such number. We solve this problem via infinite-state model checking based on satisfiability modulo theories (SMT), relying on the theory of array-based systems: we present parameterised MASs as particular array-based systems, under two execution semantics for the MAS, which we call concurrent and interleaved. We prove our decidability results under these assumptions and illustrate our implementation approach, called SAFE: the Swarm Safety Detector, based on the third-party model checker MCMT, which we evaluate experimentally. Finally, we discuss how this approach lends itself to richer parameterised and data-aware MAS settings beyond the state-of-the-art solutions in the literature, which we leave as future work.",
        "published": "2020-08-11T15:24:05Z",
        "link": "http://arxiv.org/abs/2008.04774v2",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Analysis of Agricultural Policy Recommendations using Multi-Agent   Systems",
        "authors": [
            "Satyandra Guthula",
            "Sunil Simon",
            "Harish Karnick"
        ],
        "summary": "Despite agriculture being the primary source of livelihood for more than half of India's population, several socio-economic policies are implemented in the Indian agricultural sector without paying enough attention to the possible outcomes of the policies. The negative impact of some policies can be seen in the huge distress suffered by farmers as documented by several studies and reported in the media on a regular basis. In this paper, we model a specific troubled agricultural sub-system in India as a Multi-Agent System and use it to analyse the impact of some policies. Ideally, we should be able to model the entire system, including all the external dependencies from other systems - for example availability of labour or water may depend on other sources of employment, water rights and so on - but for our purpose, we start with a fairly basic model not taking into account such external effects. As per our knowledge there are no available models which considers factors like water levels, availability of information and market simulation in the Indian context. So, we plugged in various entities into the model to make it sufficiently close to observed realities, at least in some selected regions of India. We evaluate some policy options to get an understanding of changes that may happen once such policies are implemented. Then we recommended some policies based on the result of the simulation.",
        "published": "2020-08-11T18:29:25Z",
        "link": "http://arxiv.org/abs/2008.04947v1",
        "categories": [
            "cs.CY",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "REMAX: Relational Representation for Multi-Agent Exploration",
        "authors": [
            "Heechang Ryu",
            "Hayong Shin",
            "Jinkyoo Park"
        ],
        "summary": "Training a multi-agent reinforcement learning (MARL) model with a sparse reward is generally difficult because numerous combinations of interactions among agents induce a certain outcome (i.e., success or failure). Earlier studies have tried to resolve this issue by employing an intrinsic reward to induce interactions that are helpful for learning an effective policy. However, this approach requires extensive prior knowledge for designing an intrinsic reward. To train the MARL model effectively without designing the intrinsic reward, we propose a learning-based exploration strategy to generate the initial states of a game. The proposed method adopts a variational graph autoencoder to represent a game state such that (1) the state can be compactly encoded to a latent representation by considering relationships among agents, and (2) the latent representation can be used as an effective input for a coupled surrogate model to predict an exploration score. The proposed method then finds new latent representations that maximize the exploration scores and decodes these representations to generate initial states from which the MARL model starts training in the game and thus experiences novel and rewardable states. We demonstrate that our method improves the training and performance of the MARL model more than the existing exploration methods.",
        "published": "2020-08-12T10:23:35Z",
        "link": "http://arxiv.org/abs/2008.05214v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Distributed Gradient Flow: Nonsmoothness, Nonconvexity, and Saddle Point   Evasion",
        "authors": [
            "Brian Swenson",
            "Ryan Murray",
            "H. Vincent Poor",
            "Soummya Kar"
        ],
        "summary": "The paper considers distributed gradient flow (DGF) for multi-agent nonconvex optimization. DGF is a continuous-time approximation of distributed gradient descent that is often easier to study than its discrete-time counterpart. The paper has two main contributions. First, the paper considers optimization of nonsmooth, nonconvex objective functions. It is shown that DGF converges to critical points in this setting. The paper then considers the problem of avoiding saddle points. It is shown that if agents' objective functions are assumed to be smooth and nonconvex, then DGF can only converge to a saddle point from a zero-measure set of initial conditions. To establish this result, the paper proves a stable manifold theorem for DGF, which is a fundamental contribution of independent interest. In a companion paper, analogous results are derived for discrete-time algorithms.",
        "published": "2020-08-12T15:32:59Z",
        "link": "http://arxiv.org/abs/2008.05387v1",
        "categories": [
            "math.OC",
            "cs.MA"
        ]
    },
    {
        "title": "Automated Temporal Equilibrium Analysis: Verification and Synthesis of   Multi-Player Games",
        "authors": [
            "Julian Gutierrez",
            "Muhammad Najib",
            "Giuseppe Perelli",
            "Michael Wooldridge"
        ],
        "summary": "In the context of multi-agent systems, the rational verification problem is concerned with checking which temporal logic properties will hold in a system when its constituent agents are assumed to behave rationally and strategically in pursuit of individual objectives. Typically, those objectives are expressed as temporal logic formulae which the relevant agent desires to see satisfied. Unfortunately, rational verification is computationally complex, and requires specialised techniques in order to obtain practically useable implementations. In this paper, we present such a technique. This technique relies on a reduction of the rational verification problem to the solution of a collection of parity games. Our approach has been implemented in the Equilibrium Verification Environment (EVE) system. The EVE system takes as input a model of a concurrent/multi-agent system represented using the Simple Reactive Modules Language (SRML), where agent goals are represented as Linear Temporal Logic (LTL) formulae, together with a claim about the equilibrium behaviour of the system, also expressed as an LTL formula. EVE can then check whether the LTL claim holds on some (or every) computation of the system that could arise through agents choosing Nash equilibrium strategies; it can also check whether a system has a Nash equilibrium, and synthesise individual strategies for players in the multi-player game. After presenting our basic framework, we describe our new technique and prove its correctness. We then describe our implementation in the EVE system, and present experimental results which show that EVE performs favourably in comparison to other existing tools that support rational verification.",
        "published": "2020-08-13T01:43:31Z",
        "link": "http://arxiv.org/abs/2008.05638v1",
        "categories": [
            "cs.LO",
            "cs.AI",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Equilibria for Games with Combined Qualitative and Quantitative   Objectives",
        "authors": [
            "Julian Gutierrez",
            "Aniello Murano",
            "Giuseppe Perelli",
            "Sasha Rubin",
            "Thomas Steeples",
            "Michael Wooldridge"
        ],
        "summary": "The overall aim of our research is to develop techniques to reason about the equilibrium properties of multi-agent systems. We model multi-agent systems as concurrent games, in which each player is a process that is assumed to act independently and strategically in pursuit of personal preferences. In this article, we study these games in the context of finite-memory strategies, and we assume players' preferences are defined by a qualitative and a quantitative objective, which are related by a lexicographic order: a player first prefers to satisfy its qualitative objective (given as a formula of Linear Temporal Logic) and then prefers to minimise costs (given by a mean-payoff function). Our main result is that deciding the existence of a strict epsilon Nash equilibrium in such games is 2ExpTime-complete (and hence decidable), even if players' deviations are implemented as infinite-memory strategies.",
        "published": "2020-08-13T01:56:24Z",
        "link": "http://arxiv.org/abs/2008.05643v1",
        "categories": [
            "cs.LO",
            "cs.AI",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Multi-Player Games with LDL Goals over Finite Traces",
        "authors": [
            "Julian Gutierrez",
            "Giuseppe Perelli",
            "Michael Wooldridge"
        ],
        "summary": "Linear Dynamic Logic on finite traces LDLf is a powerful logic for reasoning about the behaviour of concurrent and multi-agent systems.   In this paper, we investigate techniques for both the characterisation and verification of equilibria in multi-player games with goals/objectives expressed using logics based on LDLf. This study builds upon a generalisation of Boolean games, a logic-based game model of multi-agent systems where players have goals succinctly represented in a logical way.   Because LDLf goals are considered, in the settings we study -- Reactive Modules games and iterated Boolean games with goals over finite traces -- players' goals can be defined to be regular properties while achieved in a finite, but arbitrarily large, trace.   In particular, using alternating automata, the paper investigates automata-theoretic approaches to the characterisation and verification of (pure strategy Nash) equilibria, shows that the set of Nash equilibria in multi-player games with LDLf objectives is regular, and provides complexity results for the associated automata constructions.",
        "published": "2020-08-13T02:11:06Z",
        "link": "http://arxiv.org/abs/2008.05647v1",
        "categories": [
            "cs.LO",
            "cs.AI",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Push-SAGA: A decentralized stochastic algorithm with variance reduction   over directed graphs",
        "authors": [
            "Muhammad I. Qureshi",
            "Ran Xin",
            "Soummya Kar",
            "Usman A. Khan"
        ],
        "summary": "In this paper, we propose Push-SAGA, a decentralized stochastic first-order method for finite-sum minimization over a directed network of nodes. Push-SAGA combines node-level variance reduction to remove the uncertainty caused by stochastic gradients, network-level gradient tracking to address the distributed nature of the data, and push-sum consensus to tackle the challenge of directed communication links. We show that Push-SAGA achieves linear convergence to the exact solution for smooth and strongly convex problems and is thus the first linearly-convergent stochastic algorithm over arbitrary strongly connected directed graphs. We also characterize the regimes in which Push-SAGA achieves a linear speed-up compared to its centralized counterpart and achieves a network-independent convergence rate. We illustrate the behavior and convergence properties of Push-SAGA with the help of numerical experiments on strongly convex and non-convex problems.",
        "published": "2020-08-13T18:52:17Z",
        "link": "http://arxiv.org/abs/2008.06082v2",
        "categories": [
            "cs.LG",
            "cs.DC",
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "stat.ML"
        ]
    },
    {
        "title": "An In-Depth Analysis of Ride-Hailing Travel Using a Large-scale   Trip-Based Dataset",
        "authors": [
            "Jianhe Du",
            "Hesham A. Rakha",
            "Helena Breuer"
        ],
        "summary": "With the rapid increase in ride-hailing (RH) use, a need to better understand and regulate the industry arises. This paper analyzes a year's worth of RH trip data from the Greater Chicago Area to study RH trip patterns. More than 104 million trips were analyzed. For trip rates, the results show that the total number of trips remained stable over the year, with pooled trips steadily decreasing from 20 to 9 percent. People tend to use RH more on weekends compared to weekdays. Specifically, weekend RH trip counts (per day) are, on average, 20 percent higher than weekday trip counts. The results of this work will help policy makers and transportation administrators better understand the nature of RH trips, which in turn allows for the design of a better regulation and guidance system for the ride-hailing industry.",
        "published": "2020-08-13T19:12:01Z",
        "link": "http://arxiv.org/abs/2008.06050v1",
        "categories": [
            "physics.soc-ph",
            "cs.MA"
        ]
    },
    {
        "title": "Kernel Methods for Cooperative Multi-Agent Contextual Bandits",
        "authors": [
            "Abhimanyu Dubey",
            "Alex Pentland"
        ],
        "summary": "Cooperative multi-agent decision making involves a group of agents cooperatively solving learning problems while communicating over a network with delays. In this paper, we consider the kernelised contextual bandit problem, where the reward obtained by an agent is an arbitrary linear function of the contexts' images in the related reproducing kernel Hilbert space (RKHS), and a group of agents must cooperate to collectively solve their unique decision problems. For this problem, we propose \\textsc{Coop-KernelUCB}, an algorithm that provides near-optimal bounds on the per-agent regret, and is both computationally and communicatively efficient. For special cases of the cooperative problem, we also provide variants of \\textsc{Coop-KernelUCB} that provides optimal per-agent regret. In addition, our algorithm generalizes several existing results in the multi-agent bandit setting. Finally, on a series of both synthetic and real-world multi-agent network benchmarks, we demonstrate that our algorithm significantly outperforms existing benchmarks.",
        "published": "2020-08-14T07:37:44Z",
        "link": "http://arxiv.org/abs/2008.06220v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Cooperative Multi-Agent Bandits with Heavy Tails",
        "authors": [
            "Abhimanyu Dubey",
            "Alex Pentland"
        ],
        "summary": "We study the heavy-tailed stochastic bandit problem in the cooperative multi-agent setting, where a group of agents interact with a common bandit problem, while communicating on a network with delays. Existing algorithms for the stochastic bandit in this setting utilize confidence intervals arising from an averaging-based communication protocol known as~\\textit{running consensus}, that does not lend itself to robust estimation for heavy-tailed settings. We propose \\textsc{MP-UCB}, a decentralized multi-agent algorithm for the cooperative stochastic bandit that incorporates robust estimation with a message-passing protocol. We prove optimal regret bounds for \\textsc{MP-UCB} for several problem settings, and also demonstrate its superiority to existing methods. Furthermore, we establish the first lower bounds for the cooperative bandit problem, in addition to providing efficient algorithms for robust bandit estimation of location.",
        "published": "2020-08-14T08:34:32Z",
        "link": "http://arxiv.org/abs/2008.06244v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Multi-Agent Deep Reinforcement Learning enabled Computation Resource   Allocation in a Vehicular Cloud Network",
        "authors": [
            "Shilin Xu",
            "Caili Guo",
            "Rose Qingyang Hu",
            "Yi Qian"
        ],
        "summary": "In this paper, we investigate the computational resource allocation problem in a distributed Ad-Hoc vehicular network with no centralized infrastructure support. To support the ever increasing computational needs in such a vehicular network, the distributed virtual cloud network (VCN) is formed, based on which a computational resource sharing scheme through offloading among nearby vehicles is proposed. In view of the time-varying computational resource in VCN, the statistical distribution characteristics for computational resource are analyzed in detail. Thereby, a resource-aware combinatorial optimization objective mechanism is proposed. To alleviate the non-stationary environment caused by the typically multi-agent environment in VCN, we adopt a centralized training and decentralized execution framework. In addition, for the objective optimization problem, we model it as a Markov game and propose a DRL based multi-agent deep deterministic reinforcement learning (MADDPG) algorithm to solve it. Interestingly, to overcome the dilemma of lacking a real central control unit in VCN, the allocation is actually completed on the vehicles in a distributed manner. The simulation results are presented to demonstrate our scheme's effectiveness.",
        "published": "2020-08-14T17:02:24Z",
        "link": "http://arxiv.org/abs/2008.06464v2",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Joint Policy Search for Multi-agent Collaboration with Imperfect   Information",
        "authors": [
            "Yuandong Tian",
            "Qucheng Gong",
            "Tina Jiang"
        ],
        "summary": "To learn good joint policies for multi-agent collaboration with imperfect information remains a fundamental challenge. While for two-player zero-sum games, coordinate-ascent approaches (optimizing one agent's policy at a time, e.g., self-play) work with guarantees, in multi-agent cooperative setting they often converge to sub-optimal Nash equilibrium. On the other hand, directly modeling joint policy changes in imperfect information game is nontrivial due to complicated interplay of policies (e.g., upstream updates affect downstream state reachability). In this paper, we show global changes of game values can be decomposed to policy changes localized at each information set, with a novel term named policy-change density. Based on this, we propose Joint Policy Search(JPS) that iteratively improves joint policies of collaborative agents in imperfect information games, without re-evaluating the entire game. On multi-agent collaborative tabular games, JPS is proven to never worsen performance and can improve solutions provided by unilateral approaches (e.g, CFR), outperforming algorithms designed for collaborative policy learning (e.g. BAD). Furthermore, for real-world games, JPS has an online form that naturally links with gradient updates. We test it to Contract Bridge, a 4-player imperfect-information game where a team of $2$ collaborates to compete against the other. In its bidding phase, players bid in turn to find a good contract through a limited information channel. Based on a strong baseline agent that bids competitive bridge purely through domain-agnostic self-play, JPS improves collaboration of team players and outperforms WBridge5, a championship-winning software, by $+0.63$ IMPs (International Matching Points) per board over 1k games, substantially better than previous SoTA ($+0.41$ IMPs/b) under Double-Dummy evaluation.",
        "published": "2020-08-14T17:58:47Z",
        "link": "http://arxiv.org/abs/2008.06495v5",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.GT",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Model-Free Optimal Control of Linear Multi-Agent Systems via   Decomposition and Hierarchical Approximation",
        "authors": [
            "Gangshan Jing",
            "He Bai",
            "Jemin George",
            "Aranya Chakrabortty"
        ],
        "summary": "Designing the optimal linear quadratic regulator (LQR) for a large-scale multi-agent system (MAS) is time-consuming since it involves solving a large-size matrix Riccati equation. The situation is further exasperated when the design needs to be done in a model-free way using schemes such as reinforcement learning (RL). To reduce this computational complexity, we decompose the large-scale LQR design problem into multiple smaller-size LQR design problems. We consider the objective function to be specified over an undirected graph, and cast the decomposition as a graph clustering problem. The graph is decomposed into two parts, one consisting of independent clusters of connected components, and the other containing edges that connect different clusters. Accordingly, the resulting controller has a hierarchical structure, consisting of two components. The first component optimizes the performance of each independent cluster by solving the smaller-size LQR design problem in a model-free way using an RL algorithm. The second component accounts for the objective coupling different clusters, which is achieved by solving a least squares problem in one shot. Although suboptimal, the hierarchical controller adheres to a particular structure as specified by inter-agent couplings in the objective function and by the decomposition strategy. Mathematical formulations are established to find a decomposition that minimizes the number of required communication links or reduces the optimality gap. Numerical simulations are provided to highlight the pros and cons of the proposed designs.",
        "published": "2020-08-14T23:39:22Z",
        "link": "http://arxiv.org/abs/2008.06604v2",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY",
            "math.OC"
        ]
    },
    {
        "title": "Axioms for Defeat in Democratic Elections",
        "authors": [
            "Wesley H. Holliday",
            "Eric Pacuit"
        ],
        "summary": "We propose six axioms concerning when one candidate should defeat another in a democratic election involving two or more candidates. Five of the axioms are widely satisfied by known voting procedures. The sixth axiom is a weakening of Kenneth Arrow's famous condition of the Independence of Irrelevant Alternatives (IIA). We call this weakening Coherent IIA. We prove that the five axioms plus Coherent IIA single out a method of determining defeats studied in our recent work: Split Cycle. In particular, Split Cycle provides the most resolute definition of defeat among any satisfying the six axioms for democratic defeat. In addition, we analyze how Split Cycle escapes Arrow's Impossibility Theorem and related impossibility results.",
        "published": "2020-08-15T21:43:51Z",
        "link": "http://arxiv.org/abs/2008.08451v4",
        "categories": [
            "econ.TH",
            "cs.GT",
            "cs.MA",
            "91B12, 91B14, 91B10",
            "I.2.11"
        ]
    },
    {
        "title": "An Architectural Design for Measurement Uncertainty Evaluation in   Cyber-Physical Systems",
        "authors": [
            "Wenzel Pilar von Pilchau",
            "Varun Gowtham",
            "Maximilian Gruber",
            "Matthias Riedl",
            "Nikolaos-Stefanos Koutrakis",
            "Jawad Tayyub",
            "Jörg Hähner",
            "Sascha Eichstädt",
            "Eckart Uhlmann",
            "Julian Polte",
            "Volker Frey",
            "Alexander Willner"
        ],
        "summary": "Several use cases from the areas of manufacturing and process industry, require highly accurate sensor data. As sensors always have some degree of uncertainty, methods are needed to increase their reliability. The common approach is to regularly calibrate the devices to enable traceability according to national standards and Syst\\`eme international (SI) units - which follows costly processes. However, sensor networks can also be represented as Cyber Physical Systems (CPS) and a single sensor can have a digital representation (Digital Twin) to use its data further on. To propagate uncertainty in a reliable way in the network, we present a system architecture to communicate measurement uncertainties in sensor networks utilizing the concept of Asset Administration Shells alongside methods from the domain of Organic Computing. The presented approach contains methods for uncertainty propagation as well as concepts from the Machine Learning domain that combine the need for an accurate uncertainty estimation. The mathematical description of the metrological uncertainty of fused or propagated values can be seen as a first step towards the development of a harmonized approach for uncertainty in distributed CPSs in the context of Industrie 4.0. In this paper, we present basic use cases, conceptual ideas and an agenda of how to proceed further on.",
        "published": "2020-08-17T13:12:24Z",
        "link": "http://arxiv.org/abs/2008.07282v1",
        "categories": [
            "eess.SP",
            "cs.MA",
            "C.2.4"
        ]
    },
    {
        "title": "Learning Game-Theoretic Models of Multiagent Trajectories Using Implicit   Layers",
        "authors": [
            "Philipp Geiger",
            "Christoph-Nikolas Straehle"
        ],
        "summary": "For prediction of interacting agents' trajectories, we propose an end-to-end trainable architecture that hybridizes neural nets with game-theoretic reasoning, has interpretable intermediate representations, and transfers to downstream decision making. It uses a net that reveals preferences from the agents' past joint trajectory, and a differentiable implicit layer that maps these preferences to local Nash equilibria, forming the modes of the predicted future trajectory. Additionally, it learns an equilibrium refinement concept. For tractability, we introduce a new class of continuous potential games and an equilibrium-separating partition of the action space. We provide theoretical results for explicit gradients and soundness. In experiments, we evaluate our approach on two real-world data sets, where we predict highway driver merging trajectories, and on a simple decision-making transfer task.",
        "published": "2020-08-17T13:34:12Z",
        "link": "http://arxiv.org/abs/2008.07303v7",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Fast decentralized non-convex finite-sum optimization with recursive   variance reduction",
        "authors": [
            "Ran Xin",
            "Usman A. Khan",
            "Soummya Kar"
        ],
        "summary": "This paper considers decentralized minimization of $N:=nm$ smooth non-convex cost functions equally divided over a directed network of $n$ nodes. Specifically, we describe a stochastic first-order gradient method, called GT-SARAH, that employs a SARAH-type variance reduction technique and gradient tracking (GT) to address the stochastic and decentralized nature of the problem. We show that GT-SARAH, with appropriate algorithmic parameters, finds an $\\epsilon$-accurate first-order stationary point with $O\\big(\\max\\big\\{N^{\\frac{1}{2}},n(1-\\lambda)^{-2},n^{\\frac{2}{3}}m^{\\frac{1}{3}}(1-\\lambda)^{-1}\\big\\}L\\epsilon^{-2}\\big)$ gradient complexity, where ${(1-\\lambda)\\in(0,1]}$ is the spectral gap of the network weight matrix and $L$ is the smoothness parameter of the cost functions. This gradient complexity outperforms that of the existing decentralized stochastic gradient methods. In particular, in a big-data regime such that ${n = O(N^{\\frac{1}{2}}(1-\\lambda)^{3})}$, this gradient complexity furthers reduces to ${O(N^{\\frac{1}{2}}L\\epsilon^{-2})}$, independent of the network topology, and matches that of the centralized near-optimal variance-reduced methods. Moreover, in this regime GT-SARAH achieves a non-asymptotic linear speedup, in that, the total number of gradient computations at each node is reduced by a factor of $1/n$ compared to the centralized near-optimal algorithms that perform all gradient computations at a single node. To the best of our knowledge, GT-SARAH is the first algorithm that achieves this property. In addition, we show that appropriate choices of local minibatch size balance the trade-offs between the gradient and communication complexity of GT-SARAH. Over infinite time horizon, we establish that all nodes in GT-SARAH asymptotically achieve consensus and converge to a first-order stationary point in the almost sure and mean-squared sense.",
        "published": "2020-08-17T15:51:32Z",
        "link": "http://arxiv.org/abs/2008.07428v6",
        "categories": [
            "math.OC",
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "stat.ML"
        ]
    },
    {
        "title": "Gathering in 1-Interval Connected Graphs",
        "authors": [
            "Othon Michail",
            "Paul G. Spirakis",
            "Michail Theofilatos"
        ],
        "summary": "We examine the problem of gathering $k \\geq 2$ agents (or multi-agent rendezvous) in dynamic graphs which may change in every synchronous round but remain always connected ($1$-interval connectivity) [KLO10]. The agents are identical and without explicit communication capabilities, and are initially positioned at different nodes of the graph. The problem is for the agents to gather at the same node, not fixed in advance. We first show that the problem becomes impossible to solve if the graph has a cycle. In light of this, we study a relaxed version of this problem, called weak gathering. We show that only in unicyclic graphs weak gathering is solvable, and we provide a deterministic algorithm for this problem that runs in polynomial number of rounds.",
        "published": "2020-08-17T16:28:36Z",
        "link": "http://arxiv.org/abs/2008.07455v1",
        "categories": [
            "cs.DC",
            "cs.MA"
        ]
    },
    {
        "title": "Learning Complex Multi-Agent Policies in Presence of an Adversary",
        "authors": [
            "Siddharth Ghiya",
            "Katia Sycara"
        ],
        "summary": "In recent years, there has been some outstanding work on applying deep reinforcement learning to multi-agent settings. Often in such multi-agent scenarios, adversaries can be present. We address the requirements of such a setting by implementing a graph-based multi-agent deep reinforcement learning algorithm. In this work, we consider the scenario of multi-agent deception in which multiple agents need to learn to cooperate and communicate in order to deceive an adversary. We have employed a two-stage learning process to get the cooperating agents to learn such deceptive behaviors. Our experiments show that our approach allows us to employ curriculum learning to increase the number of cooperating agents in the environment and enables a team of agents to learn complex behaviors to successfully deceive an adversary.   Keywords: Multi-agent system, Graph neural network, Reinforcement learning",
        "published": "2020-08-18T02:09:11Z",
        "link": "http://arxiv.org/abs/2008.07698v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Fast Agent-Based Simulation Framework with Applications to Reinforcement   Learning and the Study of Trading Latency Effects",
        "authors": [
            "Peter Belcak",
            "Jan-Peter Calliess",
            "Stefan Zohren"
        ],
        "summary": "We introduce a new software toolbox for agent-based simulation. Facilitating rapid prototyping by offering a user-friendly Python API, its core rests on an efficient C++ implementation to support simulation of large-scale multi-agent systems. Our software environment benefits from a versatile message-driven architecture. Originally developed to support research on financial markets, it offers the flexibility to simulate a wide-range of different (easily customisable) market rules and to study the effect of auxiliary factors, such as delays, on the market dynamics. As a simple illustration, we employ our toolbox to investigate the role of the order processing delay in normal trading and for the scenario of a significant price change. Owing to its general architecture, our toolbox can also be employed as a generic multi-agent system simulator. We provide an example of such a non-financial application by simulating a mechanism for the coordination of no-regret learning agents in a multi-agent network routing scenario previously proposed in the literature.",
        "published": "2020-08-18T11:37:34Z",
        "link": "http://arxiv.org/abs/2008.07871v3",
        "categories": [
            "q-fin.CP",
            "cs.MA",
            "q-fin.TR"
        ]
    },
    {
        "title": "AB3DMOT: A Baseline for 3D Multi-Object Tracking and New Evaluation   Metrics",
        "authors": [
            "Xinshuo Weng",
            "Jianren Wang",
            "David Held",
            "Kris Kitani"
        ],
        "summary": "3D multi-object tracking (MOT) is essential to applications such as autonomous driving. Recent work focuses on developing accurate systems giving less attention to computational cost and system complexity. In contrast, this work proposes a simple real-time 3D MOT system with strong performance. Our system first obtains 3D detections from a LiDAR point cloud. Then, a straightforward combination of a 3D Kalman filter and the Hungarian algorithm is used for state estimation and data association. Additionally, 3D MOT datasets such as KITTI evaluate MOT methods in 2D space and standardized 3D MOT evaluation tools are missing for a fair comparison of 3D MOT methods. We propose a new 3D MOT evaluation tool along with three new metrics to comprehensively evaluate 3D MOT methods. We show that, our proposed method achieves strong 3D MOT performance on KITTI and runs at a rate of $207.4$ FPS on the KITTI dataset, achieving the fastest speed among modern 3D MOT systems. Our code is publicly available at http://www.xinshuoweng.com/projects/AB3DMOT.",
        "published": "2020-08-18T17:45:56Z",
        "link": "http://arxiv.org/abs/2008.08063v1",
        "categories": [
            "cs.CV",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Survey on Cryptocurrency Networking: Context, State-of-the-Art,   Challenges",
        "authors": [
            "Maya Dotan",
            "Yvonne-Anne Pignolet",
            "Stefan Schmid",
            "Saar Tochner",
            "Aviv Zohar"
        ],
        "summary": "Cryptocurrencies such as Bitcoin are realized using distributed systems and hence critically rely on the performance and security of the interconnecting network. The requirements on these networks and their usage, however can differ significantly from traditional communication networks, with implications on all layers of the protocol stack. This paper is motivated by these differences, and in particular by the observation that many fundamental design aspects of these networks are not well-understood today. In order to support the networking community to contribute to this emerging application domain, we present a structured overview of the field, from topology and neighbor discovery to block and transaction propagation. In particular, we provide the context, highlighting differences and commonalities with traditional networks, review the state-of-the-art, and identify open research challenges. Our paper can hence also be seen as a call-to-arms to improve the foundation on top of which cryptocurrencies are built.",
        "published": "2020-08-19T13:02:37Z",
        "link": "http://arxiv.org/abs/2008.08412v1",
        "categories": [
            "cs.NI",
            "cs.MA"
        ]
    },
    {
        "title": "The Curse of Shared Knowledge: Recursive Belief Reasoning in a   Coordination Game with Imperfect Information",
        "authors": [
            "Thomas Bolander",
            "Robin Engelhardt",
            "Thomas S. Nicolet"
        ],
        "summary": "Common knowledge is a necessary condition for safe group coordination. When common knowledge can not be obtained, humans routinely use their ability to attribute beliefs and intentions in order to infer what is known. But such shared knowledge attributions are limited in depth and therefore prone to coordination failures, because any finite-order knowledge attribution allows for an even higher order attribution that may change what is known by whom. In three separate experiments we investigate to which degree human participants (N=802) are able to recognize the difference between common knowledge and nth-order shared knowledge. We use a new two-person coordination game with imperfect information that is able to cast the recursive game structure and higher-order uncertainties into a simple, everyday-like setting. Our results show that participants have a very hard time accepting the fact that common knowledge is not reducible to shared knowledge. Instead, participants try to coordinate even at the shallowest depths of shared knowledge and in spite of huge payoff penalties.",
        "published": "2020-08-20T09:22:08Z",
        "link": "http://arxiv.org/abs/2008.08849v1",
        "categories": [
            "cs.MA",
            "cs.GT",
            "cs.SI",
            "91",
            "I.2"
        ]
    },
    {
        "title": "Institutional Grammar 2.0 Codebook",
        "authors": [
            "Christopher K. Frantz",
            "Saba N. Siddiki"
        ],
        "summary": "The Grammar of Institutions, or Institutional Grammar, is an established approach to encode policy information in terms of institutional statements based on a set of pre-defined syntactic components. This codebook provides coding guidelines for a revised version of the Institutional Grammar, the Institutional Grammar 2.0 (IG 2.0). IG 2.0 is a specification that aims at facilitating the encoding of policy to meet varying analytical objectives. To this end, it revises the grammar with respect to comprehensiveness, flexibility, and specificity by offering multiple levels of expressiveness (IG Core, IG Extended, IG Logico). In addition to the encoding of regulative statements, it further introduces the encoding of constitutive institutional statements, as well as statements that exhibit both constitutive and regulative characteristics. Introducing those aspects, the codebook initially covers fundamental concepts of IG 2.0, before providing an overview of pre-coding steps relevant for document preparation. Detailed coding guidelines are provided for both regulative and constitutive statements across all levels of expressiveness, along with the encoding guidelines for statements of mixed form -- hybrid and polymorphic institutional statements. The document further provides an overview of taxonomies used in the encoding process and referred to throughout the codebook. The codebook concludes with a summary and discussion of relevant considerations to facilitate the coding process. An initial Reader's Guide helps the reader tailor the content to her interest.   Note that this codebook specifically focuses on operational aspects of IG 2.0 in the context of policy coding. Links to additional resources such as the underlying scientific literature (that offers a comprehensive treatment of the underlying theoretical concepts) are referred to in the DOI and the concluding section of the codebook.",
        "published": "2020-08-20T12:38:55Z",
        "link": "http://arxiv.org/abs/2008.08937v5",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.CL",
            "stat.ML",
            "68T30",
            "I.7.2; I.6.5"
        ]
    },
    {
        "title": "Graph Neural Networks for 3D Multi-Object Tracking",
        "authors": [
            "Xinshuo Weng",
            "Yongxin Wang",
            "Yunze Man",
            "Kris Kitani"
        ],
        "summary": "3D Multi-object tracking (MOT) is crucial to autonomous systems. Recent work often uses a tracking-by-detection pipeline, where the feature of each object is extracted independently to compute an affinity matrix. Then, the affinity matrix is passed to the Hungarian algorithm for data association. A key process of this pipeline is to learn discriminative features for different objects in order to reduce confusion during data association. To that end, we propose two innovative techniques: (1) instead of obtaining the features for each object independently, we propose a novel feature interaction mechanism by introducing Graph Neural Networks; (2) instead of obtaining the features from either 2D or 3D space as in prior work, we propose a novel joint feature extractor to learn appearance and motion features from 2D and 3D space. Through experiments on the KITTI dataset, our proposed method achieves state-of-the-art 3D MOT performance. Our project website is at http://www.xinshuoweng.com/projects/GNN3DMOT.",
        "published": "2020-08-20T17:55:41Z",
        "link": "http://arxiv.org/abs/2008.09506v1",
        "categories": [
            "cs.CV",
            "cs.LG",
            "cs.MA",
            "cs.MM",
            "cs.RO"
        ]
    },
    {
        "title": "Learning to Collaborate in Multi-Module Recommendation via Multi-Agent   Reinforcement Learning without Communication",
        "authors": [
            "Xu He",
            "Bo An",
            "Yanghua Li",
            "Haikai Chen",
            "Rundong Wang",
            "Xinrun Wang",
            "Runsheng Yu",
            "Xin Li",
            "Zhirong Wang"
        ],
        "summary": "With the rise of online e-commerce platforms, more and more customers prefer to shop online. To sell more products, online platforms introduce various modules to recommend items with different properties such as huge discounts. A web page often consists of different independent modules. The ranking policies of these modules are decided by different teams and optimized individually without cooperation, which might result in competition between modules. Thus, the global policy of the whole page could be sub-optimal. In this paper, we propose a novel multi-agent cooperative reinforcement learning approach with the restriction that different modules cannot communicate. Our contributions are three-fold. Firstly, inspired by a solution concept in game theory named correlated equilibrium, we design a signal network to promote cooperation of all modules by generating signals (vectors) for different modules. Secondly, an entropy-regularized version of the signal network is proposed to coordinate agents' exploration of the optimal global policy. Furthermore, experiments based on real-world e-commerce data demonstrate that our algorithm obtains superior performance over baselines.",
        "published": "2020-08-21T08:23:33Z",
        "link": "http://arxiv.org/abs/2008.09369v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "The paradox of productivity during quarantine: an agent-based simulation",
        "authors": [
            "Peter Hardy",
            "Leandro Soriano Marcolino",
            "José F. Fontanari"
        ],
        "summary": "Economies across the globe were brought to their knees due to lockdowns and social restriction measures to contain the spread of the SARS-CoV-2, despite the quick switch to remote working. This downfall may be partially explained by the \"water cooler effect\", which holds that higher levels of social interaction lead to higher productivity due to a boost in people's mood. Somewhat paradoxically, however, there are reports of increased productivity in the remote working scenario. Here we address quantitatively this issue using a variety of experimental findings of social psychology that address the interplay between mood, social interaction and productivity to set forth an agent-based model for a workplace composed of extrovert and introvert agent stereotypes that differ solely on their propensities to initiate a social interaction. We find that the effects of curtailing social interactions depend on the proportion of the stereotypes in the working group: while the social restriction measures always have a negative impact on the productivity of groups composed predominantly of introverts, they may actually improve the productivity of groups composed predominantly of extroverts. Our results offer a proof of concept that the paradox of productivity during quarantine can be explained by taking into account the distinct effects of the social distancing measures on extroverts and introverts.",
        "published": "2020-08-21T13:16:42Z",
        "link": "http://arxiv.org/abs/2008.09461v2",
        "categories": [
            "cs.MA",
            "physics.soc-ph"
        ]
    },
    {
        "title": "Evaluation of the cumulated impacts on the marine resource of a   socio-ecological coral system: approach by agent-based modeling",
        "authors": [
            "Olivier Rousselle"
        ],
        "summary": "In the context of climate change and significant changes in human activities around the world, coral reefs are subject to many disruptions. We develop here a tool to help decision-making in Moorea (French Polynesia), based on multi-agent modeling. We model the trophic interactions with a Lotka-Volterra model, and also the interactions between fishermen, trophic groups and tourist operators. The results are generated through global, temporal (time series), and spatial (GIS maps) outputs. The model produced here can be transposed to other ecological and economic situations, and other geographical areas, by modifying the parameters and changing the input map data.",
        "published": "2020-08-21T14:51:14Z",
        "link": "http://arxiv.org/abs/2008.09521v1",
        "categories": [
            "cs.MA",
            "cs.CE",
            "physics.ao-ph"
        ]
    },
    {
        "title": "Robust and Efficient Swarm Communication Topologies for Hostile   Environments",
        "authors": [
            "Vipul Mann",
            "Abhishek Sivaram",
            "Laya Das",
            "Venkat Venkatasubramanian"
        ],
        "summary": "Swarm Intelligence-based optimization techniques combine systematic exploration of the search space with information available from neighbors and rely strongly on communication among agents. These algorithms are typically employed to solve problems where the function landscape is not adequately known and there are multiple local optima that could result in premature convergence for other algorithms. Applications of such algorithms can be found in communication systems involving design of networks for efficient information dissemination to a target group, targeted drug-delivery where drug molecules search for the affected site before diffusing, and high-value target localization with a network of drones. In several of such applications, the agents face a hostile environment that can result in loss of agents during the search. Such a loss changes the communication topology of the agents and hence the information available to agents, ultimately influencing the performance of the algorithm. In this paper, we present a study of the impact of loss of agents on the performance of such algorithms as a function of the initial network configuration. We use particle swarm optimization to optimize an objective function with multiple sub-optimal regions in a hostile environment and study its performance for a range of network topologies with loss of agents. The results reveal interesting trade-offs between efficiency, robustness, and performance for different topologies that are subsequently leveraged to discover general properties of networks that maximize performance. Moreover, networks with small-world properties are seen to maximize performance under hostile conditions.",
        "published": "2020-08-21T16:38:35Z",
        "link": "http://arxiv.org/abs/2008.09575v1",
        "categories": [
            "cs.NE",
            "cs.MA",
            "cs.SI",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Enhanced or distorted wisdom of crowds? An agent-based model of opinion   formation under social influence",
        "authors": [
            "Pavlin Mavrodiev",
            "Frank Schweitzer"
        ],
        "summary": "We propose an agent-based model of collective opinion formation to study the wisdom of crowds under social influence. The opinion of an agent is a continuous positive value, denoting its subjective answer to a factual question. The wisdom of crowds states that the average of all opinions is close to the truth, i.e. the correct answer. But if agents have the chance to adjust their opinion in response to the opinions of others, this effect can be destroyed. Our model investigates this scenario by evaluating two competing effects: (i) agents tend to keep their own opinion (individual conviction $\\beta$), (ii) they tend to adjust their opinion if they have information about the opinions of others (social influence $\\alpha$). For the latter, two different regimes (full information vs. aggregated information) are compared. Our simulations show that social influence only in rare cases enhances the wisdom of crowds. Most often, we find that agents converge to a collective opinion that is even farther away from the true answer. So, under social influence the wisdom of crowds can be systematically wrong.",
        "published": "2020-08-24T13:23:11Z",
        "link": "http://arxiv.org/abs/2008.10423v1",
        "categories": [
            "physics.soc-ph",
            "cs.MA",
            "nlin.AO"
        ]
    },
    {
        "title": "Automated Trajectory Synthesis for UAV Swarms Based on Resilient Data   Collection Objectives",
        "authors": [
            "A H M Jakaria",
            "Mohammad Ashiqur Rahman",
            "Matthew Anderson",
            "Steven Drager"
        ],
        "summary": "The use of Unmanned Aerial Vehicles (UAVs) for collecting data from remotely located sensor systems is emerging. The data can be time-sensitive and require to be transmitted to a data processing center. However, planning the trajectory of a collaborative UAV swarm depends on multi-fold constraints, such as data collection requirements, UAV maneuvering capacity, and budget limitation. Since a UAV may fail or be compromised, it is important to provide necessary resilience to such contingencies, thus ensuring data security. It is important to provide the UAVs with efficient spatio-temporal trajectories so that they can efficiently cover necessary data sources. In this work, we present Synth4UAV, a formal approach for automated synthesis of efficient trajectories for a UAV swarm by logically modeling the aerial space and data point topology, UAV moves, and associated constraints in terms of the turning and climbing angle, fuel usage, data collection point coverage, data freshness, and resiliency properties. We use efficient, logical formulas to encode and solve the complex model. The solution to the model provides the routing and maneuvering plan for each UAV, including the time to visit the points on the paths and corresponding fuel usage such that the necessary data points are visited while satisfying the resiliency requirements. We evaluate the proposed trajectory synthesizer, and the results show that the relationship among different parameters follow the requirements while the tool scales well with the problem size.",
        "published": "2020-08-25T02:05:19Z",
        "link": "http://arxiv.org/abs/2008.10782v1",
        "categories": [
            "cs.FL",
            "cs.MA",
            "eess.SP"
        ]
    },
    {
        "title": "End-to-End 3D Multi-Object Tracking and Trajectory Forecasting",
        "authors": [
            "Xinshuo Weng",
            "Ye Yuan",
            "Kris Kitani"
        ],
        "summary": "3D multi-object tracking (MOT) and trajectory forecasting are two critical components in modern 3D perception systems. We hypothesize that it is beneficial to unify both tasks under one framework to learn a shared feature representation of agent interaction. To evaluate this hypothesis, we propose a unified solution for 3D MOT and trajectory forecasting which also incorporates two additional novel computational units. First, we employ a feature interaction technique by introducing Graph Neural Networks (GNNs) to capture the way in which multiple agents interact with one another. The GNN is able to model complex hierarchical interactions, improve the discriminative feature learning for MOT association, and provide socially-aware context for trajectory forecasting. Second, we use a diversity sampling function to improve the quality and diversity of our forecasted trajectories. The learned sampling function is trained to efficiently extract a variety of outcomes from a generative trajectory distribution and helps avoid the problem of generating many duplicate trajectory samples. We show that our method achieves state-of-the-art performance on the KITTI dataset. Our project website is at http://www.xinshuoweng.com/projects/GNNTrkForecast.",
        "published": "2020-08-25T16:54:46Z",
        "link": "http://arxiv.org/abs/2008.11598v1",
        "categories": [
            "cs.CV",
            "cs.LG",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Integrated Self-Organized Traffic Light Controllers for Signalized   Intersections",
        "authors": [
            "Maythem K. Abbas",
            "Mohd Noh Karsiti",
            "Madzlan Napiah",
            "Samir Brahim"
        ],
        "summary": "Detecting emergency vehicles arrival on roads has been the focus for many researchers. It is quite important to detect the emergency vehicles (e.g; ambulance) arrival to traffic light to give the green light for it to pass through. Many researchers have suggested and patented emergency vehicles detection systems however, according to our knowledge, none of them considered solving the effect of giving extra green time to a road while the queues are being built on others. This paper considers the problem of finding a better traffic light phase plan to stabilize/recover the situation at an effected intersection after solving an emergency vehicle existence. A hardware setup and a novel messaging protocol have been suggested to be set on roads and vehicles to collect roads real time data. In addition, a novel decision making protocol has been created to make the use of the collected data for making a better traffic light phase plan for an intersection. The phase plan has two main decisions to be made; which light has a higher priority to be green in the next phase, and how long the green phase should be. After simulating the proposed system using our customized simulator written in Matlab programing language and comparing its performance with other related works, significant enhancements have been observed in terms of stabilizing the queue lengths at an intersection after solving an emergency case.",
        "published": "2020-08-26T02:41:46Z",
        "link": "http://arxiv.org/abs/2008.11350v1",
        "categories": [
            "cs.MA",
            "cs.LG"
        ]
    },
    {
        "title": "Reputation-driven Decision-making in Networks of Stochastic Agents",
        "authors": [
            "David Maoujoud",
            "Gavin Rens"
        ],
        "summary": "This paper studies multi-agent systems that involve networks of self-interested agents. We propose a Markov Decision Process-derived framework, called RepNet-MDP, tailored to domains in which agent reputation is a key driver of the interactions between agents. The fundamentals are based on the principles of RepNet-POMDP, a framework developed by Rens et al. in 2018, but addresses its mathematical inconsistencies and alleviates its intractability by only considering fully observable environments. We furthermore use an online learning algorithm for finding approximate solutions to RepNet-MDPs. In a series of experiments, RepNet agents are shown to be able to adapt their own behavior to the past behavior and reliability of the remaining agents of the network. Finally, our work identifies a limitation of the framework in its current formulation that prevents its agents from learning in circumstances in which they are not a primary actor.",
        "published": "2020-08-26T20:21:04Z",
        "link": "http://arxiv.org/abs/2008.11791v2",
        "categories": [
            "cs.AI",
            "cs.MA",
            "cs.SI",
            "68T37 (Primary) 68T05 (Secondary)"
        ]
    },
    {
        "title": "SmartSON:A Smart contract driven incentive management framework for   Self-Organizing Networks",
        "authors": [
            "Abdullah Yousafzai",
            "Choong Seon Hong"
        ],
        "summary": "This article proposes a self-organizing collaborative computing network with an approach to enhance the expectation of a collaborating node for joining the self-organizing network. The proposed approach relies on Ethereum cryptocurrency and Smart Contract to enhance the expectation of collaborating nodes by monetizing the services provided to the self-organizing network. Furthermore, an escrow based smart contract is formalized in the proposed framework to sustains the monetary trust issue between collaborating nodes. The proposed scheme can enforce an autonomic incentive management mechanism to any type of self-organizing networks such as self-organizing clouds, ad-hoc networks, self-organizing federated cloud networks, self-organizing federated learning networks, and self-organizing D2D networks to name a few. Considering the distributed nature of these self-organizing networks and the Ethereum blockchain network, a distributed agent-based methodology is materialized in the proposed framework. Following this, a proof of concept implementation for the general case of a self-organizing cloud is presented. Lastly, the article provides some insights into possible future directions using the proposed framework.",
        "published": "2020-08-26T20:41:22Z",
        "link": "http://arxiv.org/abs/2008.11803v1",
        "categories": [
            "cs.DC",
            "cs.MA",
            "cs.NI"
        ]
    },
    {
        "title": "Algorithmic Approaches to Reconfigurable Assembly Systems",
        "authors": [
            "Allan Costa",
            "Benjamin Jenett",
            "Irina Kostitsyna",
            "Amira Abdel-Rahman",
            "Neil Gershenfeld",
            "Kenneth Cheung"
        ],
        "summary": "Assembly of large scale structural systems in space is understood as critical to serving applications that cannot be deployed from a single launch. Recent literature proposes the use of discrete modular structures for in-space assembly and relatively small scale robotics that are able to modify and traverse the structure. This paper addresses the algorithmic problems in scaling reconfigurable space structures built through robotic construction, where reconfiguration is defined as the problem of transforming an initial structure into a different goal configuration. We analyze different algorithmic paradigms and present corresponding abstractions and graph formulations, examining specialized algorithms that consider discretized space and time steps. We then discuss fundamental design trades for different computational architectures, such as centralized versus distributed, and present two representative algorithms as concrete examples for comparison. We analyze how those algorithms achieve different objective functions and goals, such as minimization of total distance traveled, maximization of fault-tolerance, or minimization of total time spent in assembly. This is meant to offer an impression of algorithmic constraints on scalability of corresponding structural and robotic design. From this study, a set of recommendations is developed on where and when to use each paradigm, as well as implications for physical robotic and structural system design.",
        "published": "2020-08-27T05:57:32Z",
        "link": "http://arxiv.org/abs/2008.11925v1",
        "categories": [
            "cs.MA",
            "cs.RO",
            "J.6"
        ]
    },
    {
        "title": "Computational Models of Human Decision-Making with Application to the   Internet of Everything",
        "authors": [
            "Setareh Maghsudi",
            "Max Davy"
        ],
        "summary": "The concept of the Internet of Things (IoT) first appeared a few decades ago. Today, by the ubiquitous wireless connectivity, the boost of machine learning and artificial intelligence, and the advances in big data analytics, it is safe to say that IoT has evolved to a new concept called the Internet of Everything (IoE) or the Internet of All. IoE has four pillars: Things, human, data, and processes, which render it as an inhomogeneous large-scale network. A crucial challenge of such a network is to develop management, analysis, and optimization policies that besides utility-maximizer machines, also take irrational humans into account. We discuss several networking applications in which appropriate modeling of human decision-making is vital. We then provide a brief review of computational models of human decision-making. Based on one such model, we develop a solution for a task offloading problem in fog computing and we analyze the implications of including humans in the loop.",
        "published": "2020-08-27T07:21:47Z",
        "link": "http://arxiv.org/abs/2008.11958v1",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Collaborative Multi-Robot Systems for Search and Rescue: Coordination   and Perception",
        "authors": [
            "Jorge Peña Queralta",
            "Jussi Taipalmaa",
            "Bilge Can Pullinen",
            "Victor Kathan Sarker",
            "Tuan Nguyen Gia",
            "Hannu Tenhunen",
            "Moncef Gabbouj",
            "Jenni Raitoharju",
            "Tomi Westerlund"
        ],
        "summary": "Autonomous or teleoperated robots have been playing increasingly important roles in civil applications in recent years. Across the different civil domains where robots can support human operators, one of the areas where they can have more impact is in search and rescue (SAR) operations. In particular, multi-robot systems have the potential to significantly improve the efficiency of SAR personnel with faster search of victims, initial assessment and mapping of the environment, real-time monitoring and surveillance of SAR operations, or establishing emergency communication networks, among other possibilities. SAR operations encompass a wide variety of environments and situations, and therefore heterogeneous and collaborative multi-robot systems can provide the most advantages. In this paper, we review and analyze the existing approaches to multi-robot SAR support, from an algorithmic perspective and putting an emphasis on the methods enabling collaboration among the robots as well as advanced perception through machine vision and multi-agent active perception. Furthermore, we put these algorithms in the context of the different challenges and constraints that various types of robots (ground, aerial, surface or underwater) encounter in different SAR environments (maritime, urban, wilderness or other post-disaster scenarios). This is, to the best of our knowledge, the first review considering heterogeneous SAR robots across different environments, while giving two complimentary points of view: control mechanisms and machine perception. Based on our review of the state-of-the-art, we discuss the main open research questions, and outline our insights on the current approaches that have potential to improve the real-world performance of multi-robot SAR systems.",
        "published": "2020-08-28T12:28:32Z",
        "link": "http://arxiv.org/abs/2008.12610v1",
        "categories": [
            "cs.RO",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Disturbances in Influence of a Shepherding Agent is More Impactful than   Sensorial Noise During Swarm Guidance",
        "authors": [
            "Hung The Nguyen",
            "Matthew Garratt",
            "Lam Thu Bui",
            "Hussein Abbass"
        ],
        "summary": "The guidance of a large swarm is a challenging control problem. Shepherding offers one approach to guide a large swarm using a few shepherding agents (sheepdogs). While noise is an inherent characteristic in many real-world problems, the impact of noise on shepherding is not a well-studied problem. We study two forms of noise. First, we evaluate noise in the sensorial information received by the shepherd about the location of sheep. Second, we evaluate noise in the ability of the sheepdog to influence sheep due to disturbance forces occurring during actuation. We study both types of noise in this paper, and investigate the performance of Str\\\"{o}mbom's approach under these actuation and perception noises. To ensure that the parameterisation of the algorithm creates a stable performance, we need to run a large number of simulations, while increasing the number of random episodes until stability is achieved. We then systematically study the impact of sensorial and actuation noise on performance. Str\\\"{o}mbom's approach is found to be more sensitive to actuation noise than perception noise. This implies that it is more important for the shepherding agent to influence the sheep more accurately by reducing actuation noise than attempting to reduce noise in its sensors. Moreover, different levels of noise required different parameterisation for the shepherding agent, where the threshold needed by an agent to decide whether or not to collect astray sheep is different for different noise levels.",
        "published": "2020-08-28T15:40:40Z",
        "link": "http://arxiv.org/abs/2008.12708v2",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "AllenAct: A Framework for Embodied AI Research",
        "authors": [
            "Luca Weihs",
            "Jordi Salvador",
            "Klemen Kotar",
            "Unnat Jain",
            "Kuo-Hao Zeng",
            "Roozbeh Mottaghi",
            "Aniruddha Kembhavi"
        ],
        "summary": "The domain of Embodied AI, in which agents learn to complete tasks through interaction with their environment from egocentric observations, has experienced substantial growth with the advent of deep reinforcement learning and increased interest from the computer vision, NLP, and robotics communities. This growth has been facilitated by the creation of a large number of simulated environments (such as AI2-THOR, Habitat and CARLA), tasks (like point navigation, instruction following, and embodied question answering), and associated leaderboards. While this diversity has been beneficial and organic, it has also fragmented the community: a huge amount of effort is required to do something as simple as taking a model trained in one environment and testing it in another. This discourages good science. We introduce AllenAct, a modular and flexible learning framework designed with a focus on the unique requirements of Embodied AI research. AllenAct provides first-class support for a growing collection of embodied environments, tasks and algorithms, provides reproductions of state-of-the-art models and includes extensive documentation, tutorials, start-up code, and pre-trained models. We hope that our framework makes Embodied AI more accessible and encourages new researchers to join this exciting area. The framework can be accessed at: https://allenact.org/",
        "published": "2020-08-28T17:35:22Z",
        "link": "http://arxiv.org/abs/2008.12760v1",
        "categories": [
            "cs.CV",
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Formal Methods for An Iterated Volunteer's Dilemma",
        "authors": [
            "Jacob Dineen",
            "A S M Ahsan-Ul Haque",
            "Matthew Bielskas"
        ],
        "summary": "Game theory provides a paradigm through which we can study the evolving communication and phenomena that occur via rational agent interaction. In this work, we design a model framework and explore The Volunteer's Dilemma with the goals of 1) modeling it as a stochastic concurrent multiplayer game, 2) constructing properties to verify model correctness and reachability, 3) constructing strategy synthesis graphs to understand how the game is iteratively stepped through most optimally and, 4) analyzing a series of parameters to understand correlations with expected local and global rewards over a finite time horizon.",
        "published": "2020-08-28T21:13:36Z",
        "link": "http://arxiv.org/abs/2008.12846v3",
        "categories": [
            "cs.MA",
            "cs.GT"
        ]
    },
    {
        "title": "Corruption and Audit in Strategic Argumentation",
        "authors": [
            "Michael J. Maher"
        ],
        "summary": "Strategic argumentation provides a simple model of disputation and negotiation among agents. Although agents might be expected to act in our best interests, there is little that enforces such behaviour. (Maher, 2016) introduced a model of corruption and resistance to corruption within strategic argumentation. In this paper we identify corrupt behaviours that are not detected in that formulation. We strengthen the model to detect such behaviours, and show that, under the strengthened model, all the strategic aims in (Maher, 2016) are resistant to corruption.",
        "published": "2020-08-30T08:08:26Z",
        "link": "http://arxiv.org/abs/2008.13115v1",
        "categories": [
            "cs.AI",
            "cs.CR",
            "cs.MA",
            "68T30, 68T35, 68T42",
            "I.2.4; F.2.2"
        ]
    },
    {
        "title": "Effectiveness of the COVID-19 Contact-Confirming Application (COCOA)   based on a Multi Agent Simulation",
        "authors": [
            "Yuto Omae",
            "Jun Toyotani",
            "Kazuyuki Hara",
            "Yasuhiro Gon",
            "Hirotaka Takahashi"
        ],
        "summary": "As of Aug. 2020, coronavirus disease 2019 (COVID-19) is still spreading in the world. In Japan, the Ministry of Health, Labor, and Welfare developed \"COVID-19 Contact-Confirming Application (COCOA),\" which was released on Jun. 19, 2020. By utilizing COCOA, users can know whether or not they had contact with infected persons. If those who had contact with infectors keep staying at home, they may not infect those outside. However, effectiveness decreasing the number of infectors depending on the app's various usage parameters is not clear. If it is clear, we could set the objective value of the app's usage parameters (e.g., the usage rate of the total populations) and call for installation of the app. Therefore, we develop a multi-agent simulator that can express COVID-19 spreading and usage of the apps, such as COCOA. In this study, we describe the simulator and the effectiveness of the app in various scenarios. The result obtained in this study supports those of previously conducted studies.",
        "published": "2020-08-30T13:20:45Z",
        "link": "http://arxiv.org/abs/2008.13166v1",
        "categories": [
            "cs.CY",
            "cs.MA",
            "I.2.11; I.6.3; I.6.5; I.6.6"
        ]
    },
    {
        "title": "Finding Core Members of Cooperative Games using Agent-Based Modeling",
        "authors": [
            "Daniele Vernon-Bido",
            "Andrew J. Collins"
        ],
        "summary": "Agent-based modeling (ABM) is a powerful paradigm to gain insight into social phenomena. One area that ABM has rarely been applied is coalition formation. Traditionally, coalition formation is modeled using cooperative game theory. In this paper, a heuristic algorithm is developed that can be embedded into an ABM to allow the agents to find coalition. The resultant coalition structures are comparable to those found by cooperative game theory solution approaches, specifically, the core. A heuristic approach is required due to the computational complexity of finding a cooperative game theory solution which limits its application to about only a score of agents. The ABM paradigm provides a platform in which simple rules and interactions between agents can produce a macro-level effect without the large computational requirements. As such, it can be an effective means for approximating cooperative game solutions for large numbers of agents. Our heuristic algorithm combines agent-based modeling and cooperative game theory to help find agent partitions that are members of a games' core solution. The accuracy of our heuristic algorithm can be determined by comparing its outcomes to the actual core solutions. This comparison achieved by developing an experiment that uses a specific example of a cooperative game called the glove game. The glove game is a type of exchange economy game. Finding the traditional cooperative game theory solutions is computationally intensive for large numbers of players because each possible partition must be compared to each possible coalition to determine the core set; hence our experiment only considers games of up to nine players. The results indicate that our heuristic approach achieves a core solution over 90% of the time for the games considered in our experiment.",
        "published": "2020-08-30T17:38:43Z",
        "link": "http://arxiv.org/abs/2009.00519v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "econ.TH"
        ]
    },
    {
        "title": "A comparison of simple models for urban morphogenesis",
        "authors": [
            "Juste Raimbault"
        ],
        "summary": "The spatial distribution of population and activities within urban areas, or urban form at the mesoscopic scale, is the outcome of multiple antagonist processes. We propose in this paper to benchmark different models of urban morphogenesis, to systematically compare the urban forms they can produce. Different types of approaches are included, such as a reaction-diffusion model, a gravity-based model, and correlated percolation. Applying a diversity search algorithm, we estimate the feasible space of each model within a space of urban form indicators, in comparison of empirical values for worldwide urban areas. We find a complementarity of the different types of processes, advocating for a plurality of urban models.",
        "published": "2020-08-30T21:04:24Z",
        "link": "http://arxiv.org/abs/2008.13277v1",
        "categories": [
            "physics.soc-ph",
            "cs.MA"
        ]
    },
    {
        "title": "Biased Opinion Dynamics: When the Devil Is in the Details",
        "authors": [
            "Aris Anagnostopoulos",
            "Luca Becchetti",
            "Emilio Cruciani",
            "Francesco Pasquale",
            "Sara Rizzo"
        ],
        "summary": "We investigate opinion dynamics in multi-agent networks when a bias toward one of two possible opinions exists; for example, reflecting a status quo vs a superior alternative. Starting with all agents sharing an initial opinion representing the status quo, the system evolves in steps. In each step, one agent selected uniformly at random adopts the superior opinion with some probability $\\alpha$, and with probability $1 - \\alpha$ it follows an underlying update rule to revise its opinion on the basis of those held by its neighbors. We analyze convergence of the resulting process under two well-known update rules, namely majority and voter. The framework we propose exhibits a rich structure, with a non-obvious interplay between topology and underlying update rule. For example, for the voter rule we show that the speed of convergence bears no significant dependence on the underlying topology, whereas the picture changes completely under the majority rule, where network density negatively affects convergence. We believe that the model we propose is at the same time simple, rich, and modular, affording mathematical characterization of the interplay between bias, underlying opinion dynamics, and social structure in a unified setting.",
        "published": "2020-08-31T13:22:09Z",
        "link": "http://arxiv.org/abs/2008.13589v2",
        "categories": [
            "cs.MA",
            "cs.SI"
        ]
    },
    {
        "title": "High Accuracy Traffic Light Controller for Increasing the Given Green   Time Utilization",
        "authors": [
            "Maythem K. Abbas",
            "Mohd N. Karsiti",
            "Madzlan Napiah",
            "Brahim B. Samir",
            "Marwan Al-Jemeli"
        ],
        "summary": "Traffic congestion has become one of the major problems in the urban cities according to the increasing number of vehicles in those cities, obsolete technologies used on the roads of those cities, inappropriate road design, and many other reasons. So, that has urged the need for a more accurate traffic light controlling system; one that will help in maintaining high stability at all levels of demand. This paper introduces a dynamic traffic light phase plan protocol for Single-Isolated Intersections. The developed controlling method was compared with four other methods and showed a good performance in terms of reducing the average and maximum queue lengths, optimizing the given green time amount as needed, and increased the intersections throughput (increased the given green time utilization). In addition, it maintained a good traffic light stability at all levels of demand.",
        "published": "2020-08-31T16:59:46Z",
        "link": "http://arxiv.org/abs/2008.13738v1",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Optimal Solution Analysis and Decentralized Mechanisms for Peer-to-Peer   Energy Markets",
        "authors": [
            "Dinh Hoa Nguyen"
        ],
        "summary": "This paper studies the optimal clearing problem for prosumers in peer-to-peer (P2P) energy markets. It is proved that if no trade weights are enforced and the communication structure between successfully traded peers is connected, then the optimal clearing price and total traded powers in P2P market are the same with that in the pool-based market. However, if such communication structure is unconnected, then the P2P market is clustered into smaller P2P markets. If the trade weights are imposed, then the derived P2P market solutions can be significantly changed. Next, a novel decentralized optimization approach is proposed to derive a trading mechanism for P2P markets, based on the alternating direction method of multipliers (ADMM) which naturally fits into the bidirectional trading in P2P energy systems and converges reasonably fast. Analytical formulas of variable updates reveal insightful relations for each pair of prosumers on their individually traded prices and powers with their total traded powers. Further, based on those formulas, decentralized learning schemes for tuning parameters of prosumers cost functions are proposed to attain successful trading with total traded power amount as desired. Case studies on a synthetic system and the IEEE European Low Voltage Test Feeder are then carried out to verify the proposed approaches.",
        "published": "2020-09-01T01:00:49Z",
        "link": "http://arxiv.org/abs/2009.00161v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Needs-driven Heterogeneous Multi-Robot Cooperation in Rescue Missions",
        "authors": [
            "Qin Yang",
            "Ramviyas Parasuraman"
        ],
        "summary": "This paper focuses on the teaming aspects and the role of heterogeneity in a multi-robot system applied to robot-aided urban search and rescue (USAR) missions. We propose a needs-driven multi-robot cooperation mechanism represented through a Behavior Tree structure and evaluate the system's performance in terms of the group utility and energy cost to achieve the rescue mission in a limited time. From the theoretical analysis, we prove that the needs-driven cooperation in a heterogeneous robot system enables higher group utility than a homogeneous robot system. We also perform simulation experiments to verify the proposed needs-driven collaboration and show that the heterogeneous multi-robot cooperation can achieve better performance and increase system robustness by reducing uncertainty in task execution. Finally, we discuss the application to human-robot teaming.",
        "published": "2020-09-01T08:37:36Z",
        "link": "http://arxiv.org/abs/2009.00288v2",
        "categories": [
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Energy-Optimal Motion Planning for Agents: Barycentric Motion and   Collision Avoidance Constraints",
        "authors": [
            "Logan E. Beaver",
            "Michael Dorothy",
            "Christopher Kroninger",
            "Andreas A. Malikopoulos"
        ],
        "summary": "As robotic swarm systems emerge, it is increasingly important to provide strong guarantees on energy consumption and safety to maximize system performance. One approach to achieve these guarantees is through constraint-driven control, where agents seek to minimize energy consumption subject to a set of safety and task constraints. In this paper, we provide a sufficient and necessary condition for an energy-minimizing agent with integrator dynamics to have a continuous control input at the transition between unconstrained and constrained trajectories. In addition, we present and analyze barycentric motion and collision avoidance constraints to be used in constraint-driven control of swarms.",
        "published": "2020-09-01T17:23:56Z",
        "link": "http://arxiv.org/abs/2009.00588v1",
        "categories": [
            "math.OC",
            "cs.MA"
        ]
    },
    {
        "title": "A Temporal Logic-Based Hierarchical Network Connectivity Controller",
        "authors": [
            "Hans Riess",
            "Yiannis Kantaros",
            "George Pappas",
            "Robert Ghrist"
        ],
        "summary": "In this paper, we consider networks of static sensors with integrated sensing and communication capabilities. The goal of the sensors is to propagate their collected information to every other agent in the network and possibly a human operator. Such a task requires constant communication among all agents which may result in collisions and congestion in wireless communication. To mitigate this issue, we impose locally non-interfering connectivity constraints that must be respected by every agent. We show that these constraints along with the requirement of propagating information in the network can be captured by a Linear Temporal Logic (LTL) framework. Existing temporal logic control synthesis algorithms can be used to design correct-by-construction communication schedules that satisfy the considered LTL formula. Nevertheless, such approaches are centralized and scale poorly with the size of the network. We propose a hierarchical LTL-based algorithm that designs communication schedules that determine which agents should communicate while maximizing network usage. We show that the proposed algorithm is complete and demonstrate its efficiency and scalability through analysis and numerical experiments.",
        "published": "2020-09-01T19:19:48Z",
        "link": "http://arxiv.org/abs/2009.00669v3",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY",
            "math.LO",
            "03B44, 93B70, 68M18, 68W15, 68Q85"
        ]
    },
    {
        "title": "On Population-Based Algorithms for Distributed Constraint Optimization   Problems",
        "authors": [
            "Saaduddin Mahmud",
            "Md. Mosaddek Khan",
            "Nicholas R. Jennings"
        ],
        "summary": "Distributed Constraint Optimization Problems (DCOPs) are a widely studied class of optimization problems in which interaction between a set of cooperative agents are modeled as a set of constraints. DCOPs are NP-hard and significant effort has been devoted to developing methods for finding incomplete solutions. In this paper, we study an emerging class of such incomplete algorithms that are broadly termed as population-based algorithms. The main characteristic of these algorithms is that they maintain a population of candidate solutions of a given problem and use this population to cover a large area of the search space and to avoid local-optima. In recent years, this class of algorithms has gained significant attention due to their ability to produce high-quality incomplete solutions. With the primary goal of further improving the quality of solutions compared to the state-of-the-art incomplete DCOP algorithms, we present two new population-based algorithms in this paper. Our first approach, Anytime Evolutionary DCOP or AED, exploits evolutionary optimization meta-heuristics to solve DCOPs. We also present a novel anytime update mechanism that gives AED its anytime property. While in our second contribution, we show that population-based approaches can be combined with local search approaches. Specifically, we develop an algorithm called DPSA based on the Simulated Annealing meta-heuristic. We empirically evaluate these two algorithms to illustrate their respective effectiveness in different settings against the state-of-the-art incomplete DCOP algorithms including all existing population-based algorithms in a wide variety of benchmarks. Our evaluation shows AED and DPSA markedly outperform the state-of-the-art and produce up to 75% improved solutions.",
        "published": "2020-09-02T06:39:30Z",
        "link": "http://arxiv.org/abs/2009.01625v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Efficient Multi-Robot Exploration with Energy Constraint based on   Optimal Transport Theory",
        "authors": [
            "Rabiul Hasan Kabir",
            "Kooktae Lee"
        ],
        "summary": "This paper addresses an Optimal Transport (OT)-based efficient multi-robot exploration problem, considering the energy constraints of a multi-robot system. The efficiency in this problem implies how a team of robots (agents) covers a given domain, reflecting a priority of areas of interest represented by a density distribution, rather than simply following a preset of uniform patterns. To achieve an efficient multi-robot exploration, the optimal transport theory that quantifies a distance between two density distributions is employed as a tool, which also serves as a means of performance measure. The energy constraints for the multi-robot system is then incorporated into the OT-based multi-robot exploration scheme.   The proposed scheme is decoupled from robot dynamics, broadening the applicability of the multi-robot exploration plan to heterogeneous robot platforms. Not only the centralized but also decentralized algorithms are provided to cope with more realistic scenarios such as communication range limits between agents. To measure the exploration efficiency, the upper bound of the performance is developed for both the centralized and decentralized cases based on the optimal transport theory, which is computationally tractable as well as efficient. The proposed multi-robot exploration scheme is also applicable to a time-varying distribution, where the spatio-temporal evolution of the given reference distribution is desired. To validate the proposed method, multiple simulation results are provided.",
        "published": "2020-09-02T07:23:21Z",
        "link": "http://arxiv.org/abs/2009.00862v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.RO",
            "cs.SY"
        ]
    },
    {
        "title": "Quasi-synchronization of bounded confidence opinion dynamics with   stochastic asynchronous rule",
        "authors": [
            "Wei Su",
            "Xueqiao Wang",
            "Ge Chen",
            "Kai Shen"
        ],
        "summary": "Recently the theory of noise-induced synchronization of Hegselmann-Krause (HK) dynamics has been well developed. As a typical opinion dynamics of bounded confidence, the HK model obeys a synchronous updating rule, i.e., \\emph{all} agents check and update their opinions at each time point. However, whether asynchronous bounded confidence models, including the famous Deffuant-Weisbuch (DW) model, can be synchronized by noise have not been theoretically proved. In this paper, we propose a generalized bounded confidence model which possesses a stochastic asynchronous rule. The model takes the DW model and the HK model as special cases and can significantly generalize the bounded confidence models to practical application. We discover that the asynchronous model possesses a different noise-based synchronization behavior compared to the synchronous HK model. Generally, the HK dynamics can achieve quasi-synchronization \\emph{almost surely} under the drive of noise. For the asynchronous dynamics, we prove that the model can achieve quasi-synchronization \\emph{in mean}, which is a new type of quasi-synchronization weaker than the \"almost surely\" sense. The results unify the theory of noise-induced synchronization of bounded confidence opinion dynamics and hence proves the noise-induced synchronization of DW model theoretically for the first time. Moreover, the results provide a theoretical foundation for developing noise-based control strategy of more complex social opinion systems with stochastic asynchronous rules.",
        "published": "2020-09-03T05:21:55Z",
        "link": "http://arxiv.org/abs/2009.01455v1",
        "categories": [
            "cs.MA",
            "cs.SI",
            "math.OC",
            "nlin.AO"
        ]
    },
    {
        "title": "Fixed-Time Cooperative Tracking Control for Double-Integrator   Multi-Agent Systems: A Time-Based Generator Approach",
        "authors": [
            "Qiang Chen",
            "Yu Zhao",
            "Guanghui Wen",
            "Guoqing Shi",
            "Xinghuo Yu"
        ],
        "summary": "In this paper, both the fixed-time distributed consensus tracking and the fixed-time distributed average tracking problems for double-integrator-type multi-agent systems with bounded input disturbances are studied, respectively. Firstly, a new practical robust fixed-time sliding mode control method based on the time-based generator is proposed. Secondly, a fixed-time distributed consensus tracking observer for double-integrator-type multi-agent systems is designed to estimate the state disagreements between the leader and the followers under undirected and directed communication, respectively. Thirdly, a fixed-time distributed average tracking observer for double-integrator-type multi-agent systems is designed to measure the average value of reference signals under undirected communication. Note that both the observers for the distributed consensus tracking and the distributed average tracking are devised based on time-based generators and can be extended to that of high-order multi-agent systems trivially. Furthermore, by combing the fixed-time sliding mode control with the fixed-time observers, the fixed-time controllers are designed to solve the distributed consensus tracking and the distributed average tracking problems. Finally, a few numerical simulations are shown to verify the results.",
        "published": "2020-09-03T07:08:04Z",
        "link": "http://arxiv.org/abs/2009.01490v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "DRLE: Decentralized Reinforcement Learning at the Edge for Traffic Light   Control in the IoV",
        "authors": [
            "Pengyuan Zhou",
            "Xianfu Chen",
            "Zhi Liu",
            "Tristan Braud",
            "Pan Hui",
            "Jussi Kangasharju"
        ],
        "summary": "The Internet of Vehicles (IoV) enables real-time data exchange among vehicles and roadside units and thus provides a promising solution to alleviate traffic jams in the urban area. Meanwhile, better traffic management via efficient traffic light control can benefit the IoV as well by enabling a better communication environment and decreasing the network load. As such, IoV and efficient traffic light control can formulate a virtuous cycle. Edge computing, an emerging technology to provide low-latency computation capabilities at the edge of the network, can further improve the performance of this cycle. However, while the collected information is valuable, an efficient solution for better utilization and faster feedback has yet to be developed for edge-empowered IoV. To this end, we propose a Decentralized Reinforcement Learning at the Edge for traffic light control in the IoV (DRLE). DRLE exploits the ubiquity of the IoV to accelerate the collection of traffic data and its interpretation towards alleviating congestion and providing better traffic light control. DRLE operates within the coverage of the edge servers and uses aggregated data from neighboring edge servers to provide city-scale traffic light control. DRLE decomposes the highly complex problem of large area control. into a decentralized multi-agent problem. We prove its global optima with concrete mathematical reasoning. The proposed decentralized reinforcement learning algorithm running at each edge node adapts the traffic lights in real time. We conduct extensive evaluations and demonstrate the superiority of this approach over several state-of-the-art algorithms.",
        "published": "2020-09-03T08:09:04Z",
        "link": "http://arxiv.org/abs/2009.01502v2",
        "categories": [
            "cs.MA",
            "cs.DC",
            "cs.LG",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "A Visual Analytics Approach to Debugging Cooperative, Autonomous   Multi-Robot Systems' Worldviews",
        "authors": [
            "Suyun Bae",
            "Federico Rossi",
            "Joshua Vander Hook",
            "Scott Davidoff",
            "Kwan-Liu Ma"
        ],
        "summary": "Autonomous multi-robot systems, where a team of robots shares information to perform tasks that are beyond an individual robot's abilities, hold great promise for a number of applications, such as planetary exploration missions. Each robot in a multi-robot system that uses the shared-world coordination paradigm autonomously schedules which robot should perform a given task, and when, using its worldview--the robot's internal representation of its belief about both its own state, and other robots' states. A key problem for operators is that robots' worldviews can fall out of sync (often due to weak communication links), leading to desynchronization of the robots' scheduling decisions and inconsistent emergent behavior (e.g., tasks not performed, or performed by multiple robots). Operators face the time-consuming and difficult task of making sense of the robots' scheduling decisions, detecting de-synchronizations, and pinpointing the cause by comparing every robot's worldview. To address these challenges, we introduce MOSAIC Viewer, a visual analytics system that helps operators (i) make sense of the robots' schedules and (ii) detect and conduct a root cause analysis of the robots' desynchronized worldviews. Over a year-long partnership with roboticists at the NASA Jet Propulsion Laboratory, we conduct a formative study to identify the necessary system design requirements and a qualitative evaluation with 12 roboticists. We find that MOSAIC Viewer is faster- and easier-to-use than the users' current approaches, and it allows them to stitch low-level details to formulate a high-level understanding of the robots' schedules and detect and pinpoint the cause of the desynchronized worldviews.",
        "published": "2020-09-03T21:01:02Z",
        "link": "http://arxiv.org/abs/2009.01921v1",
        "categories": [
            "cs.HC",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Braess' paradox in the age of traffic information",
        "authors": [
            "Stefan Bittihn",
            "Andreas Schadschneider"
        ],
        "summary": "The Braess paradox describes the counterintuitive situation that the addition of new roads to road networks can lead to higher travel times for all network users. Recently we could show that user optima leading to the paradox exist in networks of microscopic transport models. We derived phase diagrams for two kinds of route choice strategies that were externally tuned and applied by all network users. Here we address the question whether these user optima are still realized if intelligent route choice decisions are made based upon two kinds of traffic information. We find that the paradox still can occur if the drivers 1) make informed decisions based on their own past experiences or 2) use traffic information similar to that provided by modern navigation apps. This indicates that modern traffic information systems are not able to resolve Braess' paradox.",
        "published": "2020-09-04T12:44:17Z",
        "link": "http://arxiv.org/abs/2009.02158v1",
        "categories": [
            "physics.soc-ph",
            "cs.MA",
            "nlin.CG"
        ]
    },
    {
        "title": "Collaboratively Optimizing Power Scheduling and Mitigating Congestion   using Local Pricing in a Receding Horizon Market",
        "authors": [
            "Cornelis Jan van Leeuwen",
            "Joost Stam",
            "Arun Subramanian",
            "Koen Kok"
        ],
        "summary": "A distributed, hierarchical, market based approach is introduced to solve the economic dispatch problem. The approach requires only a minimal amount of information to be shared between a central market operator and the end-users. Price signals from the market operator are sent down to end-user device agents, which in turn respond with power schedules. Intermediate congestion agents make sure that local power constraints are satisfied and any potential congestion is avoided by adding local pricing differences. Our results show that in 20% of the evaluated scenarios the solutions are identical to the global optimum when perfect knowledge is available. In the other 80% the results are not significantly worse, while providing a higher level of scalability and increasing the consumer's privacy.",
        "published": "2020-09-04T13:04:50Z",
        "link": "http://arxiv.org/abs/2009.02166v1",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Hybrid DCOP Solvers: Boosting Performance of Local Search Algorithms",
        "authors": [
            "Cornelis Jan van Leeuwen",
            "Przemyzław Pawełczak"
        ],
        "summary": "We propose a novel method for expediting both symmetric and asymmetric Distributed Constraint Optimization Problem (DCOP) solvers. The core idea is based on initializing DCOP solvers with greedy fast non-iterative DCOP solvers. This is contrary to existing methods where initialization is always achieved using a random value assignment. We empirically show that changing the starting conditions of existing DCOP solvers not only reduces the algorithm convergence time by up to 50\\%, but also reduces the communication overhead and leads to a better solution quality. We show that this effect is due to structural improvements in the variable assignment, which is caused by the spreading pattern of DCOP algorithm activation.) /Subject (Hybrid DCOPs)",
        "published": "2020-09-04T15:17:24Z",
        "link": "http://arxiv.org/abs/2009.02240v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.DC"
        ]
    },
    {
        "title": "Antenna Selection for Improving Energy Efficiency in XL-MIMO Systems",
        "authors": [
            "José Carlos Marinello",
            "Taufik Abrão",
            "Abolfazl Amiri",
            "Elisabeth de Carvalho",
            "Petar Popovski"
        ],
        "summary": "We consider the recently proposed extra-large scale massive multiple-input multiple-output (XL-MIMO) systems, with some hundreds of antennas serving a smaller number of users. Since the array length is of the same order as the distance to the users, the long-term fading coefficients of a given user vary with the different antennas at the base station (BS). Thus, the signal transmitted by some antennas might reach the user with much more power than that transmitted by some others. From a green perspective, it is not effective to simultaneously activate hundreds or even thousands of antennas, since the power-hungry radio frequency (RF) chains of the active antennas increase significantly the total energy consumption. Besides, a larger number of selected antennas increases the power required by linear processing, such as precoding matrix computation, and short-term channel estimation. In this paper, we propose four antenna selection (AS) approaches to be deployed in XL-MIMO systems aiming at maximizing the total energy efficiency (EE). Besides, employing some simplifying assumptions, we derive a closed-form analytical expression for the EE of the XL-MIMO system, and propose a straightforward iterative method to determine the optimal number of selected antennas able to maximize it. The proposed AS schemes are based solely on long-term fading parameters, thus, the selected antennas set remains valid for a relatively large time/frequency intervals. Comparing the results, we find that the genetic-algorithm based AS scheme usually achieves the best EE performance, although our proposed highest normalized received power AS scheme also achieves very promising EE performance in a simple and straightforward way.",
        "published": "2020-09-05T14:43:21Z",
        "link": "http://arxiv.org/abs/2009.02542v1",
        "categories": [
            "eess.SP",
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Participatory Budgeting with Cumulative Votes",
        "authors": [
            "Piotr Skowron",
            "Arkadii Slinko",
            "Stanisław Szufa",
            "Nimrod Talmon"
        ],
        "summary": "In participatory budgeting we are given a set of projects---each with a cost, an available budget, and a set of voters who in some form express their preferences over the projects. The goal is to select---based on voter preferences---a subset of projects whose total cost does not exceed the budget. We propose several aggregation methods based on the idea of cumulative votes, e.g., for the setting when each voter is given one coin and she specifies how this coin should be split among the projects. We compare our aggregation methods based on (1) axiomatic properties, and (2) computer simulations. We identify one method, Minimal Transfers over Costs, that demonstrates particularly desirable behavior. In particular, it significantly improves on existing methods, satisfies a strong notion of proportionality, and, thus, is promising to be used in practice.",
        "published": "2020-09-06T09:46:14Z",
        "link": "http://arxiv.org/abs/2009.02690v1",
        "categories": [
            "cs.MA",
            "cs.GT"
        ]
    },
    {
        "title": "New Results on Delay Robustness of Consensus Algorithms",
        "authors": [
            "Anton V. Proskurnikov",
            "Guiseppe Calafiore"
        ],
        "summary": "Consensus of autonomous agents is a benchmark problem in cooperative control. In this paper, we consider standard continuous-time averaging consensus policies (or Laplacian flows) over time-varying graphs and focus on robustness of consensus against communication delays. Such a robustness has been proved under the assumption of uniform quasi-strong connectivity of the graph. It is known, however, that the uniform connectivity is not necessary for consensus. For instance, in the case of undirected graph and undelayed communication consensus requires a much weaker condition of integral connectivity. In this paper, we show that the latter results remain valid in presence of unknown but bounded communication delays, furthermore, the condition of undirected graph can be substantially relaxed and replaced by the conditions of non-instantaneous type-symmetry. Furthermore, consensus can be proved for any feasible solution of the delay differential inequalities associated to the consensus algorithm. Such inequalities naturally arise in problems of containment control, distributed optimization and models of social dynamics.",
        "published": "2020-09-06T11:40:16Z",
        "link": "http://arxiv.org/abs/2009.02714v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY",
            "math.OC"
        ]
    },
    {
        "title": "Real-time and Large-scale Fleet Allocation of Autonomous Taxis: A Case   Study in New York Manhattan Island",
        "authors": [
            "Yue Yang",
            "Wencang Bao",
            "Mohsen Ramezani",
            "Zhe Xu"
        ],
        "summary": "Nowadays, autonomous taxis become a highly promising transportation mode, which helps relieve traffic congestion and avoid road accidents. However, it hinders the wide implementation of this service that traditional models fail to efficiently allocate the available fleet to deal with the imbalance of supply (autonomous taxis) and demand (trips), the poor cooperation of taxis, hardly satisfied resource constraints, and on-line platform's requirements. To figure out such urgent problems from a global and more farsighted view, we employ a Constrained Multi-agent Markov Decision Processes (CMMDP) to model fleet allocation decisions, which can be easily split into sub-problems formulated as a 'Dynamic assignment problem' combining both immediate rewards and future gains. We also leverage a Column Generation algorithm to guarantee the efficiency and optimality in a large scale. Through extensive experiments, the proposed approach not only achieves remarkable improvements over the state-of-the-art benchmarks in terms of the individual's efficiency (arriving at 12.40%, 6.54% rise of income and utilization, respectively) and the platform's profit (reaching 4.59% promotion) but also reveals a time-varying fleet adjustment policy to minimize the operation cost of the platform.",
        "published": "2020-09-06T16:00:15Z",
        "link": "http://arxiv.org/abs/2009.02762v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Modelling Gossip Interactions in Open Multi-Agent Systems",
        "authors": [
            "Charles Monnoyer de Galland",
            "Samuel Martin",
            "Julien M. Hendrickx"
        ],
        "summary": "We consider open multi-agent systems, which are systems subject to frequent arrivals and departures of agents while the studied process takes place. We study the behavior of all-to-all pairwise gossip interactions in such open systems. Arrivals and departures of agents imply that the composition and size of the system evolve with time, and in particular prevent convergence. We describe the expected behavior of the system by showing that the evolution of scale-independent quantities can be characterized exactly by a fixed-size linear dynamical system. We apply this approach to characterize the evolution of the two first moments (and thus also of the variance) for open systems of fixed and variable size. Our approach is based on the continuous-time modelling of random asynchronous events impacting the systems (gossip steps, arrivals, departures, and replacements), and can be extended to other types of events.",
        "published": "2020-09-07T09:30:56Z",
        "link": "http://arxiv.org/abs/2009.02970v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "An Analysis of Random Elections with Large Numbers of Voters",
        "authors": [
            "Matthew Harrison-Trainor"
        ],
        "summary": "In an election in which each voter ranks all of the candidates, we consider the head-to-head results between each pair of candidates and form a labeled directed graph, called the margin graph, which contains the margin of victory of each candidate over each of the other candidates. A central issue in developing voting methods is that there can be cycles in this graph, where candidate $\\mathsf{A}$ defeats candidate $\\mathsf{B}$, $\\mathsf{B}$ defeats $\\mathsf{C}$, and $\\mathsf{C}$ defeats $\\mathsf{A}$. In this paper we apply the central limit theorem, graph homology, and linear algebra to analyze how likely such situations are to occur for large numbers of voters. There is a large literature on analyzing the probability of having a majority winner; our analysis is more fine-grained. The result of our analysis is that in elections with the number of voters going to infinity, margin graphs that are more cyclic in a certain precise sense are less likely to occur.",
        "published": "2020-09-07T09:46:34Z",
        "link": "http://arxiv.org/abs/2009.02979v1",
        "categories": [
            "econ.TH",
            "cs.MA"
        ]
    },
    {
        "title": "Predicting Requests in Large-Scale Online P2P Ridesharing",
        "authors": [
            "Filippo Bistaffa",
            "Juan A. Rodríguez-Aguilar",
            "Jesús Cerquides"
        ],
        "summary": "Peer-to-peer ridesharing (P2P-RS) enables people to arrange one-time rides with their own private cars, without the involvement of professional drivers. It is a prominent collective intelligence application producing significant benefits both for individuals (reduced costs) and for the entire community (reduced pollution and traffic), as we showed in a recent publication where we proposed an online approximate solution algorithm for large-scale P2P-RS. In this paper we tackle the fundamental question of assessing the benefit of predicting ridesharing requests in the context of P2P-RS optimisation. Results on a public real-world show that, by employing a perfect predictor, the total reward can be improved by 5.27% with a forecast horizon of 1 minute. On the other hand, a vanilla long short-term memory neural network cannot improve upon a baseline predictor that simply replicates the previous day's requests, whilst achieving an almost-double accuracy.",
        "published": "2020-09-07T10:27:24Z",
        "link": "http://arxiv.org/abs/2009.02997v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Effect of lockdown interventions to control the COVID-19 epidemic in   India",
        "authors": [
            "Ankit Sharma",
            "Shreyash Arya",
            "Shashee Kumari",
            "Arnab Chatterjee"
        ],
        "summary": "The pandemic caused by the novel Coronavirus SARS-CoV2 has been responsible for life threatening health complications, and extreme pressure on healthcare systems. While preventive and definite curative medical interventions are yet to arrive, Non-Pharmaceutical Interventions (NPIs) like physical isolation, quarantine and drastic social measures imposed by governing agencies are effective in arresting the spread of infections in a population. In densely populated countries like India, lockdown interventions are partially effective due to social and administrative complexities. Using detailed demographic data, we present an agent based model to imitate the behavior of the population and its mobility features, even under intervention. We demonstrate the effectiveness of contact tracing policies and how our model efficiently relates to empirical findings on testing efficiency. We also present various lockdown intervention strategies for mitigation - using the bare number of infections, the effective reproduction rate, as well as using reinforcement learning. Our analysis can help assess the socio-economic consequences of such interventions, and provide useful ideas and insights to policy makers for better decision making.",
        "published": "2020-09-07T15:36:34Z",
        "link": "http://arxiv.org/abs/2009.03168v1",
        "categories": [
            "physics.soc-ph",
            "cs.MA",
            "q-bio.PE"
        ]
    },
    {
        "title": "Accelerated Multi-Agent Optimization Method over Stochastic Networks",
        "authors": [
            "Wicak Ananduta",
            "Carlos Ocampo-Martinez",
            "Angelia Nedić"
        ],
        "summary": "We propose a distributed method to solve a multi-agent optimization problem with strongly convex cost function and equality coupling constraints. The method is based on Nesterov's accelerated gradient approach and works over stochastically time-varying communication networks. We consider the standard assumptions of Nesterov's method and show that the sequence of the expected dual values converge toward the optimal value with the rate of $\\mathcal{O}(1/k^2)$. Furthermore, we provide a simulation study of solving an optimal power flow problem with a well-known benchmark case.",
        "published": "2020-09-08T14:07:38Z",
        "link": "http://arxiv.org/abs/2009.03775v2",
        "categories": [
            "math.OC",
            "cs.MA"
        ]
    },
    {
        "title": "Metis: Multi-Agent Based Crisis Simulation System",
        "authors": [
            "George Sidiropoulos",
            "Chairi Kiourt",
            "Lefteris Moussiades"
        ],
        "summary": "With the advent of the computational technologies (Graphics Processing Units - GPUs) and Machine Learning, the research domain of crowd simulation for crisis management has flourished. Along with the new techniques and methodologies that have been proposed all those years, aiming to increase the realism of crowd simulation, several crisis simulation systems/tools have been developed, but most of them focus on special cases without providing users the ability to adapt them based on their needs. Towards these directions, in this paper, we introduce a novel multi-agent-based crisis simulation system for indoor cases. The main advantage of the system is its ease of use feature, focusing on non-expert users (users with little to no programming skills) that can exploit its capabilities a, adapt the entire environment based on their needs (Case studies) and set up building evacuation planning experiments with some of the most popular Reinforcement Learning algorithms. Simply put, the system's features focus on dynamic environment design and crisis management, interconnection with popular Reinforcement Learning libraries, agents with different characteristics (behaviors), fire propagation parameterization, realistic physics based on popular game engine, GPU-accelerated agents training and simulation end conditions. A case study exploiting a popular reinforcement learning algorithm, for training of the agents, presents the dynamics and the capabilities of the proposed systems and the paper is concluded with the highlights of the system and some future directions.",
        "published": "2020-09-08T18:22:27Z",
        "link": "http://arxiv.org/abs/2009.03934v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "An Agent-Based Model of Delegation Relationships With Hidden-Action: On   the Effects of Heterogeneous Memory on Performance",
        "authors": [
            "Patrick Reinwald",
            "Stephan Leitner",
            "Friederike Wall"
        ],
        "summary": "We introduce an agent-based model of delegation relationships between a principal and an agent, which is based on the standard-hidden action model introduced by Holmstr\\\"om and, by doing so, provide a model which can be used to further explore theoretical topics in managerial economics, such as the efficiency of incentive mechanisms. We employ the concept of agentization, i.e., we systematically transform the standard hidden-action model into an agent-based model. Our modeling approach allows for a relaxation of some of the rather \"heroic\" assumptions included in the standard hidden-action model, whereby we particularly focus on assumptions related to the (i) availability of information about the environment and the (ii) principal's and agent's cognitive capabilities (with a particular focus on their learning capabilities and their memory). Our analysis focuses on how close and how fast the incentive scheme, which endogenously emerges from the agent-based model, converges to the solution proposed by the standard hidden-action model. Also, we investigate whether a stable solution can emerge from the agent-based model variant. The results show that in stable environments the emergent result can nearly reach the solution proposed by the standard hidden-action model. Surprisingly, the results indicate that turbulence in the environment leads to stability in earlier time periods.",
        "published": "2020-09-09T07:08:42Z",
        "link": "http://arxiv.org/abs/2009.07124v2",
        "categories": [
            "cs.MA",
            "econ.GN",
            "physics.soc-ph",
            "q-fin.EC"
        ]
    },
    {
        "title": "QR-MIX: Distributional Value Function Factorisation for Cooperative   Multi-Agent Reinforcement Learning",
        "authors": [
            "Jian Hu",
            "Seth Austin Harding",
            "Haibin Wu",
            "Siyue Hu",
            "Shih-wei Liao"
        ],
        "summary": "In Cooperative Multi-Agent Reinforcement Learning (MARL) and under the setting of Centralized Training with Decentralized Execution (CTDE), agents observe and interact with their environment locally and independently. With local observation and random sampling, the randomness in rewards and observations leads to randomness in long-term returns. Existing methods such as Value Decomposition Network (VDN) and QMIX estimate the value of long-term returns as a scalar that does not contain the information of randomness. Our proposed model QR-MIX introduces quantile regression, modeling joint state-action values as a distribution, combining QMIX with Implicit Quantile Network (IQN). However, the monotonicity in QMIX limits the expression of joint state-action value distribution and may lead to incorrect estimation results in non-monotonic cases. Therefore, we proposed a flexible loss function to approximate the monotonicity found in QMIX. Our model is not only more tolerant of the randomness of returns, but also more tolerant of the randomness of monotonic constraints. The experimental results demonstrate that QR-MIX outperforms the previous state-of-the-art method QMIX in the StarCraft Multi-Agent Challenge (SMAC) environment.",
        "published": "2020-09-09T10:28:44Z",
        "link": "http://arxiv.org/abs/2009.04197v5",
        "categories": [
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Towards a Modelling Framework for Self-Sovereign Identity Systems",
        "authors": [
            "Iain Barclay",
            "Maria Freytsis",
            "Sherri Bucher",
            "Swapna Radha",
            "Alun Preece",
            "Ian Taylor"
        ],
        "summary": "Self-sovereign Identity promises to give users control of their own data, and has the potential to foster advancements in terms of personal data privacy. Self-sovereign concepts can also be applied to other entities, such as datasets and devices. Systems adopting this paradigm will be decentralised, with messages passing between multiple actors, both human and representing other entities, in order to issue and request credentials necessary to meet individual and collective goals. Such systems are complex, and build upon social and technical interactions and behaviours. Modelling self-sovereign identity systems seeks to provide stakeholders and software architects with tools to enable them to communicate effectively, and lead to effective and well-regarded system designs and implementations. This paper draws upon research from Actor-based Modelling to guide a way forward in modelling self-sovereign systems, and reports early success in utilising the iStar 2.0 framework to provide a representation of a birth registration case study.",
        "published": "2020-09-09T14:32:28Z",
        "link": "http://arxiv.org/abs/2009.04327v2",
        "categories": [
            "cs.SE",
            "cs.MA"
        ]
    },
    {
        "title": "Resilient Task Allocation in Heterogeneous Multi-Robot Systems",
        "authors": [
            "Siddharth Mayya",
            "Diego S. D'antonio",
            "David Saldaña",
            "Vijay Kumar"
        ],
        "summary": "For a multi-robot system equipped with heterogeneous capabilities, this paper presents a mechanism to allocate robots to tasks in a resilient manner when anomalous environmental conditions such as weather events or adversarial attacks affect the performance of robots within the tasks. Our primary objective is to ensure that each task is assigned the requisite level of resources, measured as the aggregated capabilities of the robots allocated to the task. By keeping track of task performance deviations under external perturbations, our framework quantifies the extent to which robot capabilities (e.g., visual sensing or aerial mobility) are affected by environmental conditions. This enables an optimization-based framework to flexibly reallocate robots to tasks based on the most degraded capabilities within each task. In the face of resource limitations and adverse environmental conditions, our algorithm minimally relaxes the resource constraints corresponding to some tasks, thus exhibiting a graceful degradation of performance. Simulated experiments in a multi-robot coverage and target tracking scenario demonstrate the efficacy of the proposed approach.",
        "published": "2020-09-09T22:42:46Z",
        "link": "http://arxiv.org/abs/2009.04593v2",
        "categories": [
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "SkyTrakx: A Toolkit for Simulation and Verification of Unmanned   Air-Traffic Management Systems (Extended Version)",
        "authors": [
            "Chiao Hsieh",
            "Hussein Sibai",
            "Hebron Taylor",
            "Yifeng Ni",
            "Sayan Mitra"
        ],
        "summary": "The key concept for safe and efficient traffic management for Unmanned Aircraft Systems (UAS) is the notion of operation volume (OV). An OV is a 4-dimensional block of airspace and time, which can express an aircraft's intent, and can be used for planning, de-confliction, and traffic management. While there are several high-level simulators for UAS Traffic Management (UTM), we are lacking a framework for creating, manipulating, and reasoning about OVs for heterogeneous air vehicles. In this paper, we address this and present SkyTrakx -- a software toolkit for simulation and verification of UTM scenarios based on OVs. First, we illustrate a use case of SkyTrakx by presenting a specific air traffic coordination protocol. This protocol communicates OVs between participating aircraft and an airspace manager for traffic routing. We show how existing formal verification tools, Dafny and Dione, can assist in automatically checking key properties of the protocol. Second, we show how the OVs can be computed for heterogeneous air vehicles like quadcopters and fixed-wing aircraft using another verification technique, namely reachability analysis. Finally, we show that SkyTrakx can be used to simulate complex scenarios involving heterogeneous vehicles, for testing and performance evaluation in terms of workload and response delays analysis. Our experiments delineate the trade-off between performance and workload across different strategies for generating OVs.",
        "published": "2020-09-10T03:52:49Z",
        "link": "http://arxiv.org/abs/2009.04655v3",
        "categories": [
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Distributed Variable-Baseline Stereo SLAM from two UAVs",
        "authors": [
            "Marco Karrer",
            "Margarita Chli"
        ],
        "summary": "VIO has been widely used and researched to control and aid the automation of navigation of robots especially in the absence of absolute position measurements, such as GPS. However, when observable landmarks in the scene lie far away from the robot's sensor suite, as it is the case at high altitude flights, the fidelity of estimates and the observability of the metric scale degrades greatly for these methods. Aiming to tackle this issue, in this article, we employ two UAVs equipped with one monocular camera and one IMU each, to exploit their view overlap and relative distance measurements between them using UWB modules onboard to enable collaborative VIO. In particular, we propose a novel, distributed fusion scheme enabling the formation of a virtual stereo camera rig with adjustable baseline from the two UAVs. In order to control the \\gls{uav} agents autonomously, we propose a decentralized collaborative estimation scheme, where each agent hold its own local map, achieving an average pose estimation latency of 11ms, while ensuring consistency of the agents' estimates via consensus based optimization. Following a thorough evaluation on photorealistic simulations, we demonstrate the effectiveness of the approach at high altitude flights of up to 160m, going significantly beyond the capabilities of state-of-the-art VIO methods. Finally, we show the advantage of actively adjusting the baseline on-the-fly over a fixed, target baseline, reducing the error in our experiments by a factor of two.",
        "published": "2020-09-10T12:16:10Z",
        "link": "http://arxiv.org/abs/2009.04801v1",
        "categories": [
            "cs.RO",
            "cs.CV",
            "cs.MA"
        ]
    },
    {
        "title": "Nash equilibrium seeking under partial-decision information over   directed communication networks",
        "authors": [
            "Mattia Bianchi",
            "Sergio Grammatico"
        ],
        "summary": "We consider the Nash equilibrium problem in a partial-decision information scenario. Specifically, each agent can only receive information from some neighbors via a communication network, while its cost function depends on the strategies of possibly all agents. In particular, while the existing methods assume undirected or balanced communication, in this paper we allow for non-balanced, directed graphs. We propose a fully-distributed pseudo-gradient scheme, which is guaranteed to converge with linear rate to a Nash equilibrium, under strong monotonicity and Lipschitz continuity of the game mapping. Our algorithm requires global knowledge of the communication structure, namely of the Perron-Frobenius eigenvector of the adjacency matrix and of a certain constant related to the graph connectivity. Therefore, we adapt the procedure to setups where the network is not known in advance, by computing the eigenvector online and by means of vanishing step sizes.",
        "published": "2020-09-10T16:44:04Z",
        "link": "http://arxiv.org/abs/2009.04981v1",
        "categories": [
            "math.OC",
            "cs.DC",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Maximizing Convergence Time in Network Averaging Dynamics Subject to   Edge Removal",
        "authors": [
            "S. Rasoul Etesami"
        ],
        "summary": "We consider the consensus interdiction problem (CIP), in which the goal is to maximize the convergence time of consensus averaging dynamics subject to removing a limited number of network edges. We first show that CIP can be cast as an effective resistance interdiction problem (ERIP), in which the goal is to remove a limited number of network edges to maximize the effective resistance between a source node and a sink node. We show that ERIP is strongly NP-hard, even for bipartite graphs of diameter three with fixed source/sink edges, and establish the same hardness result for the CIP. We then show that both ERIP and CIP cannot be approximated up to a (nearly) polynomial factor assuming exponential time hypothesis. Subsequently, we devise a polynomial-time $mn$-approximation algorithm for the ERIP that only depends on the number of nodes $n$ and the number of edges $m$, but is independent of the size of edge resistances. Finally, using a quadratic program formulation for the CIP, we devise an iterative approximation algorithm to find a first-order stationary solution for the CIP and evaluate its good performance through numerical results.",
        "published": "2020-09-11T02:40:57Z",
        "link": "http://arxiv.org/abs/2009.05208v5",
        "categories": [
            "eess.SY",
            "cs.CC",
            "cs.MA",
            "cs.SY",
            "math.OC"
        ]
    },
    {
        "title": "Results of multi-agent system and ontology to manage ideas and represent   knowledge in a challenge of creativity",
        "authors": [
            "Pedro Barrios",
            "Davy Monticolo",
            "Sahbi Sidhom"
        ],
        "summary": "This article is about an intelligent system to support ideas management as a result of a multi-agent system used in a distributed system with heterogeneous information as ideas and knowledge, after the results about an ontology to describe the meaning of these ideas. The intelligent system assists participants of the creativity workshop to manage their ideas and consequently proposing an ontology dedicated to ideas. During the creative workshop many creative activities and collaborative creative methods are used by roles immersed in this creativity workshop event where they share knowledge. The collaboration of these roles is physically distant, their interactions might be synchrony or asynchrony, and the information of the ideas are heterogeneous, so we can say that the process is distributed. Those ideas are writing in natural language by participants which have a role and the ideas are heterogeneous since some of them are described by schema, text or scenario of use. This paper presents first, our MAS and second our Ontology design.",
        "published": "2020-09-11T08:31:30Z",
        "link": "http://arxiv.org/abs/2009.05282v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Stability of Decentralized Gradient Descent in Open Multi-Agent Systems",
        "authors": [
            "Julien M. Hendrickx",
            "Michael G. Rabbat"
        ],
        "summary": "The aim of decentralized gradient descent (DGD) is to minimize a sum of $n$ functions held by interconnected agents. We study the stability of DGD in open contexts where agents can join or leave the system, resulting each time in the addition or the removal of their function from the global objective. Assuming all functions are smooth, strongly convex, and their minimizers all lie in a given ball, we characterize the sensitivity of the global minimizer of the sum of these functions to the removal or addition of a new function and provide bounds in $ O\\left(\\min \\left(\\kappa^{0.5}, \\kappa/n^{0.5},\\kappa^{1.5}/n\\right)\\right)$ where $\\kappa$ is the condition number. We also show that the states of all agents can be eventually bounded independently of the sequence of arrivals and departures. The magnitude of the bound scales with the importance of the interconnection, which also determines the accuracy of the final solution in the absence of arrival and departure, exposing thus a potential trade-off between accuracy and sensitivity. Our analysis relies on the formulation of DGD as gradient descent on an auxiliary function. The tightness of our results is analyzed using the PESTO Toolbox.",
        "published": "2020-09-11T13:48:09Z",
        "link": "http://arxiv.org/abs/2009.05445v1",
        "categories": [
            "math.OC",
            "cs.MA"
        ]
    },
    {
        "title": "Modeling growth of urban firm networks",
        "authors": [
            "Juste Raimbault",
            "Natalia Zdanowska",
            "Elsa Arcaute"
        ],
        "summary": "The emergence of interconnected urban networks is a crucial feature of globalisation processes. Understanding the drivers behind the growth of such networks - in particular urban firm networks -, is essential for the economic resilience of urban systems. We introduce in this paper a generative network model for firm networks at the urban area level including several complementary processes: the economic size of urban areas at origin and destination, industrial sector proximity between firms, the strength of links from the past, as well as the geographical and socio-cultural distance. An empirical network analysis on European firm ownership data confirms the relevance of each of these factors. We then simulate network growth for synthetic systems of cities, unveiling stylized facts such as a transition from a local to a global regime or a maximal integration achieved at an intermediate interaction range. We calibrate the model on the European network, outperforming statistical models and showing a strong role of path-dependency. Potential applications of the model include the study of mitigation policies to deal with exogenous shocks such as economic crisis or potential lockdowns of countries, which we illustrate with an application on stylized scenarios.",
        "published": "2020-09-11T17:04:31Z",
        "link": "http://arxiv.org/abs/2009.05528v1",
        "categories": [
            "physics.soc-ph",
            "cs.MA"
        ]
    },
    {
        "title": "A general framework for decentralized optimization with first-order   methods",
        "authors": [
            "Ran Xin",
            "Shi Pu",
            "Angelia Nedić",
            "Usman A. Khan"
        ],
        "summary": "Decentralized optimization to minimize a finite sum of functions over a network of nodes has been a significant focus within control and signal processing research due to its natural relevance to optimal control and signal estimation problems. More recently, the emergence of sophisticated computing and large-scale data science needs have led to a resurgence of activity in this area. In this article, we discuss decentralized first-order gradient methods, which have found tremendous success in control, signal processing, and machine learning problems, where such methods, due to their simplicity, serve as the first method of choice for many complex inference and training tasks. In particular, we provide a general framework of decentralized first-order methods that is applicable to undirected and directed communication networks alike, and show that much of the existing work on optimization and consensus can be related explicitly to this framework. We further extend the discussion to decentralized stochastic first-order methods that rely on stochastic gradients at each node and describe how local variance reduction schemes, previously shown to have promise in the centralized settings, are able to improve the performance of decentralized methods when combined with what is known as gradient tracking. We motivate and demonstrate the effectiveness of the corresponding methods in the context of machine learning and signal processing problems that arise in decentralized environments.",
        "published": "2020-09-12T17:52:10Z",
        "link": "http://arxiv.org/abs/2009.05837v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "math.OC",
            "stat.ML"
        ]
    },
    {
        "title": "Monte Carlo Tree Search Based Tactical Maneuvering",
        "authors": [
            "Kunal Srivastava",
            "Amit Surana"
        ],
        "summary": "In this paper we explore the application of simultaneous move Monte Carlo Tree Search (MCTS) based online framework for tactical maneuvering between two unmanned aircrafts. Compared to other techniques, MCTS enables efficient search over long horizons and uses self-play to select best maneuver in the current state while accounting for the opponent aircraft tactics. We explore different algorithmic choices in MCTS and demonstrate the framework numerically in a simulated 2D tactical maneuvering application.",
        "published": "2020-09-13T02:03:25Z",
        "link": "http://arxiv.org/abs/2009.08807v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Pow-Wow: A Dataset and Study on Collaborative Communication in Pommerman",
        "authors": [
            "Takuma Yoneda",
            "Matthew R. Walter",
            "Jason Naradowsky"
        ],
        "summary": "In multi-agent learning, agents must coordinate with each other in order to succeed. For humans, this coordination is typically accomplished through the use of language. In this work we perform a controlled study of human language use in a competitive team-based game, and search for useful lessons for structuring communication protocol between autonomous agents. We construct Pow-Wow, a new dataset for studying situated goal-directed human communication. Using the Pommerman game environment, we enlisted teams of humans to play against teams of AI agents, recording their observations, actions, and communications. We analyze the types of communications which result in effective game strategies, annotate them accordingly, and present corpus-level statistical analysis of how trends in communications affect game outcomes. Based on this analysis, we design a communication policy for learning agents, and show that agents which utilize communication achieve higher win-rates against baseline systems than those which do not.",
        "published": "2020-09-13T07:11:37Z",
        "link": "http://arxiv.org/abs/2009.05940v1",
        "categories": [
            "cs.CL",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Rumor-robust Decentralized Gaussian Process Learning, Fusion, and   Planning for Modeling Multiple Moving Targets",
        "authors": [
            "Chang Liu",
            "Zhihao Liao",
            "Silvia Ferrari"
        ],
        "summary": "This paper presents a decentralized Gaussian Process (GP) learning, fusion, and planning (RESIN) formalism for mobile sensor networks to actively learn target motion models. RESIN is characterized by both computational and communication efficiency, and the robustness to rumor propagation in sensor networks. By using the weighted exponential product rule and the Chernoff information, a rumor-robust decentralized GP fusion approach is developed to generate a globally consistent target trajectory prediction from local GP models. A decentralized information-driven path planning approach is then proposed for mobile sensors to generate informative sensing paths. A novel, constant-sized information sharing strategy is developed for path coordination between sensors, and an analytical objective function is derived that significantly reduces the computational complexity of the path planning. The effectiveness of RESIN is demonstrated in various numerical simulations.",
        "published": "2020-09-13T15:21:55Z",
        "link": "http://arxiv.org/abs/2009.06021v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.RO",
            "cs.SY"
        ]
    },
    {
        "title": "The Platform Design Problem",
        "authors": [
            "Christos Papadimitriou",
            "Kiran Vodrahalli",
            "Mihalis Yannakakis"
        ],
        "summary": "On-line firms deploy suites of software platforms, where each platform is designed to interact with users during a certain activity, such as browsing, chatting, socializing, emailing, driving, etc. The economic and incentive structure of this exchange, as well as its algorithmic nature, have not been explored to our knowledge. We model this interaction as a Stackelberg game between a Designer and one or more Agents. We model an Agent as a Markov chain whose states are activities; we assume that the Agent's utility is a linear function of the steady-state distribution of this chain. The Designer may design a platform for each of these activities/states; if a platform is adopted by the Agent, the transition probabilities of the Markov chain are affected, and so is the objective of the Agent. The Designer's utility is a linear function of the steady state probabilities of the accessible states minus the development cost of the platforms. The underlying optimization problem of the Agent -- how to choose the states for which to adopt the platform -- is an MDP. If this MDP has a simple yet plausible structure (the transition probabilities from one state to another only depend on the target state and the recurrent probability of the current state) the Agent's problem can be solved by a greedy algorithm. The Designer's optimization problem (designing a custom suite for the Agent so as to optimize, through the Agent's optimum reaction, the Designer's revenue), is NP-hard to approximate within any finite ratio; however, the special case, while still NP-hard, has an FPTAS. These results generalize from a single Agent to a distribution of Agents with finite support, as well as to the setting where the Designer must find the best response to the existing strategies of other Designers. We discuss other implications of our results and directions of future research.",
        "published": "2020-09-13T23:53:19Z",
        "link": "http://arxiv.org/abs/2009.06117v2",
        "categories": [
            "cs.GT",
            "cs.CC",
            "cs.LG",
            "cs.MA",
            "econ.TH"
        ]
    },
    {
        "title": "Multi-Agent Reinforcement Learning in Cournot Games",
        "authors": [
            "Yuanyuan Shi",
            "Baosen Zhang"
        ],
        "summary": "In this work, we study the interaction of strategic agents in continuous action Cournot games with limited information feedback. Cournot game is the essential market model for many socio-economic systems where agents learn and compete without the full knowledge of the system or each other. We consider the dynamics of the policy gradient algorithm, which is a widely adopted continuous control reinforcement learning algorithm, in concave Cournot games. We prove the convergence of policy gradient dynamics to the Nash equilibrium when the price function is linear or the number of agents is two. This is the first result (to the best of our knowledge) on the convergence property of learning algorithms with continuous action spaces that do not fall in the no-regret class.",
        "published": "2020-09-14T06:53:21Z",
        "link": "http://arxiv.org/abs/2009.06224v1",
        "categories": [
            "math.OC",
            "cs.GT",
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Teaching to Learn: Sequential Teaching of Agents with Inner States",
        "authors": [
            "Mustafa Mert Celikok",
            "Pierre-Alexandre Murena",
            "Samuel Kaski"
        ],
        "summary": "In sequential machine teaching, a teacher's objective is to provide the optimal sequence of inputs to sequential learners in order to guide them towards the best model. In this paper we extend this setting from current static one-data-set analyses to learners which change their learning algorithm or latent state to improve during learning, and to generalize to new datasets. We introduce a multi-agent formulation in which learners' inner state may change with the teaching interaction, which affects the learning performance in future tasks. In order to teach such learners, we propose an optimal control approach that takes the future performance of the learner after teaching into account. This provides tools for modelling learners having inner states, and machine teaching of meta-learning algorithms. Furthermore, we distinguish manipulative teaching, which can be done by effectively hiding data and also used for indoctrination, from more general education which aims to help the learner become better at generalization and learning in new datasets in the absence of a teacher.",
        "published": "2020-09-14T07:03:15Z",
        "link": "http://arxiv.org/abs/2009.06227v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Persistent And Scalable JADE: A Cloud based InMemory Multi-agent   Framework",
        "authors": [
            "Nauman Khalid",
            "Ghalib Ahmed Tahir",
            "Peter Bloodsworth"
        ],
        "summary": "Multi-agent systems are often limited in terms of persistenceand scalability. This issue is more prevalent for applications inwhich agent states changes frequently. This makes the existingmethods less usable as they increase the agent's complexityand are less scalable. This research study has presented anovel in-memory agent persistence framework. Two prototypeshave been implemented, one using the proposed solution andthe other using an established agent persistency environment.Experimental results confirm that the proposed framework ismore scalable than existing approaches whilst providing asimilar level of persistency. These findings will help futurereal-time multiagent systems to become scalable and persistentin a dynamic cloud environment.",
        "published": "2020-09-14T13:22:37Z",
        "link": "http://arxiv.org/abs/2009.06425v2",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Competing AI: How does competition feedback affect machine learning?",
        "authors": [
            "Antonio Ginart",
            "Eva Zhang",
            "Yongchan Kwon",
            "James Zou"
        ],
        "summary": "This papers studies how competition affects machine learning (ML) predictors. As ML becomes more ubiquitous, it is often deployed by companies to compete over customers. For example, digital platforms like Yelp use ML to predict user preference and make recommendations. A service that is more often queried by users, perhaps because it more accurately anticipates user preferences, is also more likely to obtain additional user data (e.g. in the form of a Yelp review). Thus, competing predictors cause feedback loops whereby a predictor's performance impacts what training data it receives and biases its predictions over time. We introduce a flexible model of competing ML predictors that enables both rapid experimentation and theoretical tractability. We show with empirical and mathematical analysis that competition causes predictors to specialize for specific sub-populations at the cost of worse performance over the general population. We further analyze the impact of predictor specialization on the overall prediction quality experienced by users. We show that having too few or too many competing predictors in a market can hurt the overall prediction quality. Our theory is complemented by experiments on several real datasets using popular learning algorithms, such as neural networks and nearest neighbor methods.",
        "published": "2020-09-15T00:13:32Z",
        "link": "http://arxiv.org/abs/2009.06797v4",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Do economic effects of the anti-COVID-19 lockdowns in different regions   interact through supply chains?",
        "authors": [
            "Hiroyasu Inoue",
            "Yohsuke Murase",
            "Yasuyuki Todo"
        ],
        "summary": "To prevent the spread of COVID-19, many cities, states, and countries have `locked down', restricting economic activities in non-essential sectors. Such lockdowns have substantially shrunk production in most countries. This study examines how the economic effects of lockdowns in different regions interact through supply chains, a network of firms for production, simulating an agent-based model of production on supply-chain data for 1.6 million firms in Japan. We further investigate how the complex network structure affects the interactions of lockdowns, emphasising the role of upstreamness and loops by decomposing supply-chain flows into potential and circular flow components. We find that a region's upstreamness, intensity of loops, and supplier substitutability in supply chains with other regions largely determine the economic effect of the lockdown in the region. In particular, when a region lifts its lockdown, its economic recovery substantially varies depending on whether it lifts lockdown alone or together with another region closely linked through supply chains. These results propose the need for inter-region policy coordination to reduce the economic loss from lockdowns.",
        "published": "2020-09-15T07:14:48Z",
        "link": "http://arxiv.org/abs/2009.06894v2",
        "categories": [
            "cs.SI",
            "cs.MA",
            "econ.GN",
            "q-fin.EC"
        ]
    },
    {
        "title": "Managing network congestion with a tradable credit scheme: a trip-based   MFD approach",
        "authors": [
            "Renming Liu",
            "Siyu Chen",
            "Yu Jiang",
            "Ravi Seshadri",
            "Moshe E. Ben-Akiva",
            "Carlos Lima Azevedo"
        ],
        "summary": "This study investigates the efficiency and effectiveness of an area-based tradable credit scheme (TCS) using the trip-based Macroscopic Fundamental Diagram model for the morning commute problem. In the proposed TCS, the regulator distributes initial credits to all travelers and designs a time-varying and trip length specific credit tariff. Credits are traded between travelers and the regulator via a credit market, and the credit price is determined by the demand and supply of credits. The heterogeneity of travelers is considered in terms of desired arrival time, trip length and departure-time choice preferences. The TCS is incorporated into a day-to-day modelling framework to examine the travelers' learning process, the evolution of network, and the properties of the credit market. The existence of an equilibrium solution and the uniqueness of the credit price at the equilibrium state are established analytically. Furthermore, an open-source simulation framework is developed to validate the analytical properties of the proposed TCS and compare it with alternative control strategies in terms of mobility, network performance, and social welfare. Bayesian optimization is then adopted to optimize the credit toll scheme. The numerical results demonstrate that the proposed TCS outperforms the no-control case and matches the performance of the time-of-day pricing strategy, while maintaining revenue-neutral nature.",
        "published": "2020-09-15T10:15:23Z",
        "link": "http://arxiv.org/abs/2009.06965v2",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Value Alignment Equilibrium in Multiagent Systems",
        "authors": [
            "Nieves Montes",
            "Carles Sierra"
        ],
        "summary": "Value alignment has emerged in recent years as a basic principle to produce beneficial and mindful Artificial Intelligence systems. It mainly states that autonomous entities should behave in a way that is aligned with our human values. In this work, we summarize a previously developed model that considers values as preferences over states of the world and defines alignment between the governing norms and the values. We provide a use-case for this framework with the Iterated Prisoner's Dilemma model, which we use to exemplify the definitions we review. We take advantage of this use-case to introduce new concepts to be integrated with the established framework: alignment equilibrium and Pareto optimal alignment. These are inspired on the classical Nash equilibrium and Pareto optimality, but are designed to account for any value we wish to model in the system.",
        "published": "2020-09-16T11:58:04Z",
        "link": "http://arxiv.org/abs/2009.07619v3",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Energy-based Surprise Minimization for Multi-Agent Value Factorization",
        "authors": [
            "Karush Suri",
            "Xiao Qi Shi",
            "Konstantinos Plataniotis",
            "Yuri Lawryshyn"
        ],
        "summary": "Multi-Agent Reinforcement Learning (MARL) has demonstrated significant success in training decentralised policies in a centralised manner by making use of value factorization methods. However, addressing surprise across spurious states and approximation bias remain open problems for multi-agent settings. Towards this goal, we introduce the Energy-based MIXer (EMIX), an algorithm which minimizes surprise utilizing the energy across agents. Our contributions are threefold; (1) EMIX introduces a novel surprise minimization technique across multiple agents in the case of multi-agent partially-observable settings. (2) EMIX highlights a practical use of energy functions in MARL with theoretical guarantees and experiment validations of the energy operator. Lastly, (3) EMIX extends Maxmin Q-learning for addressing overestimation bias across agents in MARL. In a study of challenging StarCraft II micromanagement scenarios, EMIX demonstrates consistent stable performance for multiagent surprise minimization. Moreover, our ablation study highlights the necessity of the energy-based scheme and the need for elimination of overestimation bias in MARL. Our implementation of EMIX can be found at karush17.github.io/emix-web/.",
        "published": "2020-09-16T19:42:42Z",
        "link": "http://arxiv.org/abs/2009.09842v4",
        "categories": [
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Learnable Strategies for Bilateral Agent Negotiation over Multiple   Issues",
        "authors": [
            "Pallavi Bagga",
            "Nicola Paoletti",
            "Kostas Stathis"
        ],
        "summary": "We present a novel bilateral negotiation model that allows a self-interested agent to learn how to negotiate over multiple issues in the presence of user preference uncertainty. The model relies upon interpretable strategy templates representing the tactics the agent should employ during the negotiation and learns template parameters to maximize the average utility received over multiple negotiations, thus resulting in optimal bid acceptance and generation. Our model also uses deep reinforcement learning to evaluate threshold utility values, for those tactics that require them, thereby deriving optimal utilities for every environment state. To handle user preference uncertainty, the model relies on a stochastic search to find user model that best agrees with a given partial preference profile. Multi-objective optimization and multi-criteria decision-making methods are applied at negotiation time to generate Pareto-optimal outcomes thereby increasing the number of successful (win-win) negotiations. Rigorous experimental evaluations show that the agent employing our model outperforms the winning agents of the 10th Automated Negotiating Agents Competition (ANAC'19) in terms of individual as well as social-welfare utilities.",
        "published": "2020-09-17T13:52:18Z",
        "link": "http://arxiv.org/abs/2009.08302v2",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Decentralized Game-Theoretic Control for Dynamic Task Allocation   Problems for Multi-Agent Systems",
        "authors": [
            "Efstathios Bakolas",
            "Yoonjae Lee"
        ],
        "summary": "We propose a decentralized game-theoretic framework for dynamic task allocation problems for multi-agent systems. In our problem formulation, the agents' utilities depend on both the rewards and the costs associated with the successful completion of the tasks assigned to them. The rewards reflect how likely is for the agents to accomplish their assigned tasks whereas the costs reflect the effort needed to complete these tasks (this effort is determined by the solution of corresponding optimal control problems). The task allocation problem considered herein corresponds to a dynamic game whose solution depends on the states of the agents in contrast with classic static (or single-act) game formulations. We propose a greedy solution approach in which the agents negotiate with each other to find a mutually agreeable (or individually rational) task assignment profile based on evaluations of the task utilities that reflect their current states. We illustrate the main ideas of this work by means of extensive numerical simulations.",
        "published": "2020-09-18T05:03:00Z",
        "link": "http://arxiv.org/abs/2009.08628v2",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Approximately Socially-Optimal Decentralized Coalition Formation with   Application to P2P Energy Sharing",
        "authors": [
            "Sid Chi-Kin Chau",
            "Khaled Elbassioni",
            "Yue Zhou"
        ],
        "summary": "The paradigm of P2P (peer-to-peer) economy has emerged in diverse areas. \"P2P energy sharing\" is a new form of P2P economy in the energy sector, which allows users to establish longer-term sharing arrangements of their local energy resources (e.g., rooftop PVs, home batteries) with joint optimized energy management. In such a P2P setting, a coalition of users is formed for sharing resources in a decentralized manner by self-interested users based on their individual preferences. A likely outcome of decentralized coalition formation will be a stable coalition structure, where no group of users could cooperatively opt out to form another coalition that induces higher preferences to all its members. Remarkably, there exist a number of fair cost-sharing mechanisms (e.g., equal-split, proportional-split, egalitarian and Nash bargaining solutions of bargaining games) that model practical cost-sharing applications with desirable properties, such as the existence of a stable coalition structure with a small strong price-of-anarchy (SPoA) to approximate the social optimum. In this paper, we provide general results of decentralized coalition formation: (1) We establish a logarithmic lower bound on SPoA, and hence, show several previously known fair cost-sharing mechanisms are the best practical mechanisms with minimal SPoA. (2) We show that the SPoA of egalitarian and Nash bargaining cost-sharing mechanisms to match the lower bound. (3) We derive the SPoA of a mix of different cost-sharing mechanisms. (4) We present a decentralized algorithm to form a stable coalition structure. (5) Finally, we apply our general results to P2P energy sharing and present an empirical study of decentralized coalition formation in a real-world project. We study the empirical SPoA, which is observed within 95% of the social optimal cost with coalitions of 2 and 3 users, via fair cost-sharing mechanisms.",
        "published": "2020-09-18T05:22:11Z",
        "link": "http://arxiv.org/abs/2009.08632v3",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Multi-Robot Target Search using Probabilistic Consensus on Discrete   Markov Chains",
        "authors": [
            "Aniket Shirsat",
            "Karthik Elamvazhuthi",
            "Spring Berman"
        ],
        "summary": "In this paper, we propose a probabilistic consensus-based multi-robot search strategy that is robust to communication link failures, and thus is suitable for disaster affected areas. The robots, capable of only local communication, explore a bounded environment according to a random walk modeled by a discrete-time discrete-state (DTDS) Markov chain and exchange information with neighboring robots, resulting in a time-varying communication network topology. The proposed strategy is proved to achieve consensus, here defined as agreement on the presence of a static target, with no assumptions on the connectivity of the communication network. Using numerical simulations, we investigate the effect of the robot population size, domain size, and information uncertainty on the consensus time statistics under this scheme. We also validate our theoretical results with 3D physics-based simulations in Gazebo. The simulations demonstrate that all robots achieve consensus in finite time with the proposed search strategy over a range of robot densities in the environment.",
        "published": "2020-09-20T22:31:23Z",
        "link": "http://arxiv.org/abs/2009.09537v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Human Engagement Providing Evaluative and Informative Advice for   Interactive Reinforcement Learning",
        "authors": [
            "Adam Bignold",
            "Francisco Cruz",
            "Richard Dazeley",
            "Peter Vamplew",
            "Cameron Foale"
        ],
        "summary": "Interactive reinforcement learning proposes the use of externally-sourced information in order to speed up the learning process. When interacting with a learner agent, humans may provide either evaluative or informative advice. Prior research has focused on the effect of human-sourced advice by including real-time feedback on the interactive reinforcement learning process, specifically aiming to improve the learning speed of the agent, while minimising the time demands on the human. This work focuses on answering which of two approaches, evaluative or informative, is the preferred instructional approach for humans. Moreover, this work presents an experimental setup for a human-trial designed to compare the methods people use to deliver advice in terms of human engagement. The results obtained show that users giving informative advice to the learner agents provide more accurate advice, are willing to assist the learner agent for a longer time, and provide more advice per episode. Additionally, self-evaluation from participants using the informative approach has indicated that the agent's ability to follow the advice is higher, and therefore, they feel their own advice to be of higher accuracy when compared to people providing evaluative advice.",
        "published": "2020-09-21T02:14:02Z",
        "link": "http://arxiv.org/abs/2009.09575v2",
        "categories": [
            "cs.AI",
            "cs.HC",
            "cs.MA"
        ]
    },
    {
        "title": "Electing the Executive Branch",
        "authors": [
            "Rutvik Page",
            "Ehud Shapiro",
            "Nimrod Talmon"
        ],
        "summary": "The executive branch, or government, is typically not elected directly by the people, but rather formed by another elected body or person such as the parliament or the president. As a result, its members are not directly accountable to the people, individually or as a group. We consider a scenario in which the members of the government are elected directly by the people, and wish to achieve proportionality while doing so. We propose a formal model consisting of $k$ offices, each with its own disjoint set of candidates, and a set of voters who provide approval ballots for all offices. We wish to identify good aggregation rules that assign one candidate to each office. As using a simple majority vote for each office independently might result in disregarding minority preferences altogether, here we consider an adaptation of the greedy variant of Proportional Approval Voting (GreedyPAV) to our setting, and demonstrate -- through computer-based simulations -- how voting for all offices together using this rule overcomes this weakness. We note that the approach is applicable also to a party that employs direct democracy, where party members elect the party's representatives in a coalition government.",
        "published": "2020-09-21T10:07:56Z",
        "link": "http://arxiv.org/abs/2009.09734v4",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Collaborative Target Tracking in Elliptic Coordinates: a Binocular   Coordination Approach",
        "authors": [
            "Yuan Chang",
            "Zhiyong Sun",
            "Han Zhou",
            "Xiangke Wang",
            "Lincheng Shen",
            "Tianjiang Hu"
        ],
        "summary": "This paper concentrates on the collaborative target tracking control of a pair of tracking vehicles with formation constraints. The proposed controller requires only distance measurements between tracking vehicles and the target. Its novelty lies in two aspects: 1) the elliptic coordinates are used to represent an arbitrary tracking formation without singularity, which can be deduced from inter-agent distances, and 2) the regulation of the tracking vehicle system obeys a binocular coordination principle, which simplifies the design of the control law by leveraging rich physical meanings of elliptic coordinates. The tracking system with the proposed controller is proven to be exponentially convergent when the target is stationary. When the target drifts with a small velocity, the desired tracking formation is achieved within a small margin proportional to the magnitude of the target's drift velocity. Simulation examples are provided to demonstrate the tracking performance of the proposed controller.",
        "published": "2020-09-21T14:36:03Z",
        "link": "http://arxiv.org/abs/2009.09915v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "A multi-agent model for growing spiking neural networks",
        "authors": [
            "Javier Lopez Randulfe",
            "Leon Bonde Larsen"
        ],
        "summary": "Artificial Intelligence has looked into biological systems as a source of inspiration. Although there are many aspects of the brain yet to be discovered, neuroscience has found evidence that the connections between neurons continuously grow and reshape as a part of the learning process. This differs from the design of Artificial Neural Networks, that achieve learning by evolving the weights in the synapses between them and their topology stays unaltered through time.   This project has explored rules for growing the connections between the neurons in Spiking Neural Networks as a learning mechanism. These rules have been implemented on a multi-agent system for creating simple logic functions, that establish a base for building up more complex systems and architectures. Results in a simulation environment showed that for a given set of parameters it is possible to reach topologies that reproduce the tested functions.   This project also opens the door to the usage of techniques like genetic algorithms for obtaining the best suited values for the model parameters, and hence creating neural networks that can adapt to different functions.",
        "published": "2020-09-21T15:11:29Z",
        "link": "http://arxiv.org/abs/2010.15045v1",
        "categories": [
            "cs.NE",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Optimal Targeting in Super-Modular Games",
        "authors": [
            "Giacomo Como",
            "Stéphane Durand",
            "Fabio Fagnani"
        ],
        "summary": "We study an optimal targeting problem for super-modular games with binary actions and finitely many players. The considered problem consists in the selection of a subset of players of minimum size such that, when the actions of these players are forced to a controlled value while the others are left to repeatedly play a best response action, the system will converge to the greatest Nash equilibrium of the game. Our main contributions consist in showing that the problem is NP-complete and in proposing an efficient iterative algorithm with provable convergence properties for its solution. We discuss in detail the special case of network coordination games and its relation with the notion of cohesiveness. Finally, we show with simulations the strength of our approach with respect to naive heuristics based on classical network centrality measures.",
        "published": "2020-09-21T15:12:27Z",
        "link": "http://arxiv.org/abs/2009.09946v1",
        "categories": [
            "cs.GT",
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "math.OC"
        ]
    },
    {
        "title": "Solution Concepts in Hierarchical Games under Bounded Rationality with   Applications to Autonomous Driving",
        "authors": [
            "Atrisha Sarkar",
            "Krzysztof Czarnecki"
        ],
        "summary": "With autonomous vehicles (AV) set to integrate further into regular human traffic, there is an increasing consensus on treating AV motion planning as a multi-agent problem. However, the traditional game-theoretic assumption of complete rationality is too strong for human driving, and there is a need for understanding human driving as a \\emph{bounded rational} activity through a behavioural game-theoretic lens. To that end, we adapt four metamodels of bounded rational behaviour: three based on Quantal level-k and one based on Nash equilibrium with quantal errors. We formalize the different solution concepts that can be applied in the context of hierarchical games, a framework used in multi-agent motion planning, for the purpose of creating game theoretic models of driving behaviour. Furthermore, based on a contributed dataset of human driving at a busy urban intersection with a total of approximately 4k agents and 44k decision points, we evaluate the behaviour models on the basis of model fit to naturalistic data, as well as their predictive capacity. Our results suggest that among the behaviour models evaluated, at the level of maneuvers, modeling driving behaviour as an adaptation of the Quantal level-k model with level-0 behaviour modelled as pure rule-following provides the best fit to naturalistic driving behaviour. At the level of trajectories, bounds sampling of actions and a maxmax non-strategic models is the most accurate within the set of models in comparison. We also find a significant impact of situational factors on the performance of behaviour models.",
        "published": "2020-09-21T17:13:50Z",
        "link": "http://arxiv.org/abs/2009.10033v5",
        "categories": [
            "cs.AI",
            "cs.GT",
            "cs.MA",
            "cs.RO",
            "I.2.0; I.2.9"
        ]
    },
    {
        "title": "Faster Algorithms for Optimal Ex-Ante Coordinated Collusive Strategies   in Extensive-Form Zero-Sum Games",
        "authors": [
            "Gabriele Farina",
            "Andrea Celli",
            "Nicola Gatti",
            "Tuomas Sandholm"
        ],
        "summary": "We focus on the problem of finding an optimal strategy for a team of two players that faces an opponent in an imperfect-information zero-sum extensive-form game. Team members are not allowed to communicate during play but can coordinate before the game. In that setting, it is known that the best the team can do is sample a profile of potentially randomized strategies (one per player) from a joint (a.k.a. correlated) probability distribution at the beginning of the game. In this paper, we first provide new modeling results about computing such an optimal distribution by drawing a connection to a different literature on extensive-form correlation. Second, we provide an algorithm that computes such an optimal distribution by only using profiles where only one of the team members gets to randomize in each profile. We can also cap the number of such profiles we allow in the solution. This begets an anytime algorithm by increasing the cap. We find that often a handful of well-chosen such profiles suffices to reach optimal utility for the team. This enables team members to reach coordination through a relatively simple and understandable plan. Finally, inspired by this observation and leveraging theoretical concepts that we introduce, we develop an efficient column-generation algorithm for finding an optimal distribution for the team. We evaluate it on a suite of common benchmark games. It is three orders of magnitude faster than the prior state of the art on games that the latter can solve and it can also solve several games that were previously unsolvable.",
        "published": "2020-09-21T17:51:57Z",
        "link": "http://arxiv.org/abs/2009.10061v1",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Dynamic Multi-Agent Path Finding based on Conflict Resolution using   Answer Set Programming",
        "authors": [
            "Basem Atiq",
            "Volkan Patoglu",
            "Esra Erdem"
        ],
        "summary": "We study a dynamic version of multi-agent path finding problem (called D-MAPF) where existing agents may leave and new agents may join the team at different times. We introduce a new method to solve D-MAPF based on conflict-resolution. The idea is, when a set of new agents joins the team and there are conflicts, instead of replanning for the whole team, to replan only for a minimal subset of agents whose plans conflict with each other. We utilize answer set programming as part of our method for planning, replanning and identifying minimal set of conflicts.",
        "published": "2020-09-22T00:50:35Z",
        "link": "http://arxiv.org/abs/2009.10249v1",
        "categories": [
            "cs.AI",
            "cs.LO",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Simulation of Wheelchair Movements in Crowd Using Fine Grid Cellular   Automata",
        "authors": [
            "Siamak Sarmady",
            "Fazilah Haron",
            "Abdullah Zawawi Talib"
        ],
        "summary": "Crowd simulation models are used to assess the performance and safety of crowd systems. In some systems, wheelchairs and other moving objects are present in the crowd. The different size and speed of the wheelchairs could significantly change the behavior and dynamics of the crowd. In order to minimize the risks of overcrowding and other types of accidents, it is important to properly model the wheelchairs and their interactions with pedestrians and the environment. Cellular automata are extensively utilized in crowd modeling because of their simple and fast algorithms. Fine grid cellular automata model uses small cells in which moving entities (pedestrians, wheelchairs, cars and etc.) occupy several cells. The entities could have different sizes, shapes, and speeds. In this article, fine grid cellular automata model has been modified to allow building crowd simulation models with different ratios of wheelchairs that could be of different sizes and speed profiles. A scenario of a walkway has been used to evaluate the model. The slow down effect of the slower wheelchairs has been properly reproduced in the results which also match empirical data. Density-speed graphs are also compared to crowds comprising of only pedestrians.",
        "published": "2020-09-22T11:39:05Z",
        "link": "http://arxiv.org/abs/2010.00082v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Sense-Deliberate-Act Cognitive Agents for Sense-Compute-Control   Applications in the Internet of Things & Services",
        "authors": [
            "Armin Moin"
        ],
        "summary": "In this paper, we advocate Agent-Oriented Software Engi-neering (AOSE) through employing Belief-Desire-Intention (BDI) intel-ligent agents for developing Sense-Compute-Control (SCC) applications in the Internet of Things and Services (IoTS). We argue that not only the agent paradigm, in general, but also cognitive BDI agents with sense-deliberate-act cycle, in particular, fit very well to the nature of SCC applications in the IoTS. However, considering the highly constrained heterogeneous devices that are prevalent in the IoTS, existing BDI agent frameworks, even those especially created for Wireless Sensor Networks (WSNs), do not work. We elaborate on the challenges and propose pos-sible approaches to address them.",
        "published": "2020-09-22T15:52:21Z",
        "link": "http://arxiv.org/abs/2009.10638v1",
        "categories": [
            "cs.MA",
            "cs.SE"
        ]
    },
    {
        "title": "Simulation model of spacetime with the Minkowski metric",
        "authors": [
            "Vasyliy I. Gurianov"
        ],
        "summary": "In this paper, we propose a simulation model of spacetime as a discrete model of physical space. The model is based on the ideas of Stephen Wolfram and uses non-numerical modelling. The simulation model is described as an ontology. We use object-oriented simulation (OOS), but the model is also suitable for agent-based simulation (ABS). We use UML2 SP (UML Scientific Profile), an object-oriented simulation language used in scientific fields. This paper describes several experiments that demonstrate time dilation and dynamic relativistic effects. The reproducibility of experimental results can be verified. We provide a link to the repository in this paper. The model is implemented in Python.",
        "published": "2020-09-22T17:03:38Z",
        "link": "http://arxiv.org/abs/2009.10689v1",
        "categories": [
            "cs.CE",
            "cs.MA"
        ]
    },
    {
        "title": "Demand Responsive Dynamic Pricing Framework for Prosumer Dominated   Microgrids using Multiagent Reinforcement Learning",
        "authors": [
            "Amin Shojaeighadikolaei",
            "Arman Ghasemi",
            "Kailani R. Jones",
            "Alexandru G. Bardas",
            "Morteza Hashemi",
            "Reza Ahmadi"
        ],
        "summary": "Demand Response (DR) has a widely recognized potential for improving grid stability and reliability while reducing customers energy bills. However, the conventional DR techniques come with several shortcomings, such as inability to handle operational uncertainties and incurring customer disutility, impeding their wide spread adoption in real-world applications. This paper proposes a new multiagent Reinforcement Learning (RL) based decision-making environment for implementing a Real-Time Pricing (RTP) DR technique in a prosumer dominated microgrid. The proposed technique addresses several shortcomings common to traditional DR methods and provides significant economic benefits to the grid operator and prosumers. To show its better efficacy, the proposed DR method is compared to a baseline traditional operation scenario in a small-scale microgrid system. Finally, investigations on the use of prosumers energy storage capacity in this microgrid highlight the advantages of the proposed method in establishing a balanced market setup.",
        "published": "2020-09-23T01:44:57Z",
        "link": "http://arxiv.org/abs/2009.10890v1",
        "categories": [
            "eess.SY",
            "cs.LG",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "A Multi-Agent Deep Reinforcement Learning Approach for a Distributed   Energy Marketplace in Smart Grids",
        "authors": [
            "Arman Ghasemi",
            "Amin Shojaeighadikolaei",
            "Kailani Jones",
            "Morteza Hashemi",
            "Alexandru G. Bardas",
            "Reza Ahmadi"
        ],
        "summary": "This paper presents a Reinforcement Learning (RL) based energy market for a prosumer dominated microgrid. The proposed market model facilitates a real-time and demanddependent dynamic pricing environment, which reduces grid costs and improves the economic benefits for prosumers. Furthermore, this market model enables the grid operator to leverage prosumers storage capacity as a dispatchable asset for grid support applications. Simulation results based on the Deep QNetwork (DQN) framework demonstrate significant improvements of the 24-hour accumulative profit for both prosumers and the grid operator, as well as major reductions in grid reserve power utilization.",
        "published": "2020-09-23T02:17:51Z",
        "link": "http://arxiv.org/abs/2009.10905v1",
        "categories": [
            "eess.SY",
            "cs.LG",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Agent-based Simulation Model and Deep Learning Techniques to Evaluate   and Predict Transportation Trends around COVID-19",
        "authors": [
            "Ding Wang",
            "Fan Zuo",
            "Jingqin Gao",
            "Yueshuai He",
            "Zilin Bian",
            "Suzana Duran Bernardes",
            "Chaekuk Na",
            "Jingxing Wang",
            "John Petinos",
            "Kaan Ozbay",
            "Joseph Y. J. Chow",
            "Shri Iyer",
            "Hani Nassif",
            "Xuegang Jeff Ban"
        ],
        "summary": "The COVID-19 pandemic has affected travel behaviors and transportation system operations, and cities are grappling with what policies can be effective for a phased reopening shaped by social distancing. This edition of the white paper updates travel trends and highlights an agent-based simulation model's results to predict the impact of proposed phased reopening strategies. It also introduces a real-time video processing method to measure social distancing through cameras on city streets.",
        "published": "2020-09-23T05:37:15Z",
        "link": "http://arxiv.org/abs/2010.09648v1",
        "categories": [
            "cs.MA",
            "cs.CV",
            "eess.IV",
            "physics.soc-ph"
        ]
    },
    {
        "title": "Randomized fast no-loss expert system to play tic tac toe like a human",
        "authors": [
            "Aditya Jyoti Paul"
        ],
        "summary": "This paper introduces a blazingly fast, no-loss expert system for Tic Tac Toe using Decision Trees called T3DT, that tries to emulate human gameplay as closely as possible. It does not make use of any brute force, minimax or evolutionary techniques, but is still always unbeatable. In order to make the gameplay more human-like, randomization is prioritized and T3DT randomly chooses one of the multiple optimal moves at each step. Since it does not need to analyse the complete game tree at any point, T3DT is exceptionally faster than any brute force or minimax algorithm, this has been shown theoretically as well as empirically from clock-time analyses in this paper. T3DT also doesn't need the data sets or the time to train an evolutionary model, making it a practical no-loss approach to play Tic Tac Toe.",
        "published": "2020-09-23T15:41:10Z",
        "link": "http://arxiv.org/abs/2009.11225v2",
        "categories": [
            "cs.AI",
            "cs.GT",
            "cs.HC",
            "cs.MA",
            "68T37, 68T35, 68T27, 68T30, 68T20",
            "I.2.1; I.2.3; I.2.4; I.2.8; I.6.3; I.6.4"
        ]
    },
    {
        "title": "Emergence of complex data from simple local rules in a network game",
        "authors": [
            "Felipe S. Abrahão",
            "Klaus Wehmuth",
            "Artur Ziviani"
        ],
        "summary": "As one of the main subjects of investigation in data science, network science has been demonstrated a wide range of applications to real-world networks analysis and modeling. For example, the pervasive presence of structural or topological characteristics, such as the small-world phenomenon, small-diameter, scale-free properties, or fat-tailed degree distribution were one of the underlying pillars fostering the study of complex networks. Relating these phenomena with other emergent properties in complex systems became a subject of central importance. By introducing new implications on the interface between data science and complex systems science with the purpose of tackling some of these issues, in this article we present a model for a network game played by complex networks in which nodes are computable systems. In particular, we present and discuss how some network topological properties and simple local communication rules are able to generate a phase transition with respect to the emergence of incompressible data.",
        "published": "2020-09-23T19:43:27Z",
        "link": "http://arxiv.org/abs/2009.12210v1",
        "categories": [
            "cs.LO",
            "cs.GT",
            "cs.MA",
            "cs.SI",
            "cs.SY",
            "eess.SY",
            "physics.soc-ph"
        ]
    },
    {
        "title": "Safe Coverage of Moving Domains for Vehicles with Second Order Dynamics",
        "authors": [
            "Juan Chacon",
            "Mo Chen",
            "Razvan Fetecau"
        ],
        "summary": "Autonomous coverage of a specified area by robots operating in close proximity with each other has many potential applications such as real-time monitoring of rapidly changing environments, and search and rescue; however, coordination and safety are two fundamental challenges. For coordination, we propose a distributed controller for covering moving, compact domains for two types of vehicles with second order dynamics (double integrator and fixed-wing aircraft) with bounded input forces. This control policy is based on artificial potentials and alignment forces designed to promote desired vehicle-domain and inter-vehicle separations and relative velocities. We prove that certain coverage configurations are locally asymptotically stable. For safety, we establish energy conditions for collision free motion and utilize Hamilton-Jacobi (HJ) reachability theory for last-resort pairwise collision avoidance. We derive an analytical solution to the associated HJ partial differential equation corresponding to the collision avoidance problem between two double integrator vehicles. We demonstrate our approach in several numerical simulations involving the two types of vehicles covering convex and non-convex moving domains.",
        "published": "2020-09-24T05:46:25Z",
        "link": "http://arxiv.org/abs/2009.12211v1",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Evolution of Coordination in Pairwise and Multi-player Interactions via   Prior Commitments",
        "authors": [
            "Ogbo Ndidi Bianca",
            "Aiman Elgarig",
            "The Anh Han"
        ],
        "summary": "Upon starting a collective endeavour, it is important to understand your partners' preferences and how strongly they commit to a common goal. Establishing a prior commitment or agreement in terms of posterior benefits and consequences from those engaging in it provides an important mechanism for securing cooperation. Resorting to methods from Evolutionary Game Theory (EGT), here we analyse how prior commitments can also be adopted as a tool for enhancing coordination when its outcomes exhibit an asymmetric payoff structure, in both pairwise and multiparty interactions. Arguably, coordination is more complex to achieve than cooperation since there might be several desirable collective outcomes in a coordination problem (compared to mutual cooperation, the only desirable collective outcome in cooperation dilemmas). Our analysis, both analytically and via numerical simulations, shows that whether prior commitment would be a viable evolutionary mechanism for enhancing coordination and the overall population social welfare strongly depends on the collective benefit and severity of competition, and more importantly, how asymmetric benefits are resolved in a commitment deal. Moreover, in multiparty interactions, prior commitments prove to be crucial when a high level of group diversity is required for optimal coordination. The results are robust for different selection intensities. Overall, our analysis provides new insights into the complexity and beauty of behavioral evolution driven by humans' capacity for commitment, as well as for the design of self-organised and distributed multi-agent systems for ensuring coordination among autonomous agents.",
        "published": "2020-09-24T14:36:49Z",
        "link": "http://arxiv.org/abs/2009.11727v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.GT",
            "math-ph",
            "math.MP",
            "nlin.AO"
        ]
    },
    {
        "title": "Sensor Fault Detection and Isolation via Networked Estimation: Full-Rank   Dynamical Systems",
        "authors": [
            "Mohammadreza Doostmohammadian",
            "Nader Meskin"
        ],
        "summary": "This paper considers the problem of simultaneous sensor fault detection, isolation, and networked estimation of linear full-rank dynamical systems. The proposed networked estimation is a variant of single time-scale protocol and is based on (i) consensus on \\textit{a-priori} estimates and (ii) measurement innovation. The necessary connectivity condition on the sensor network and stabilizing block-diagonal gain matrix is derived based on our previous works. Considering additive faults in the presence of system and measurement noise, the estimation error at sensors is derived and proper residuals are defined for fault detection. Unlike many works in the literature, no simplifying upper-bound condition on the noise is considered and we assume Gaussian system/measurement noise. A probabilistic threshold is then defined for fault detection based on the estimation error covariance norm. Finally, a graph-theoretic sensor replacement scenario is proposed to recover possible loss of networked observability due to removing the faulty sensor. We examine the proposed fault detection and isolation scheme on an illustrative academic example to verify the results and make a comparison study with related literature.",
        "published": "2020-09-25T08:37:24Z",
        "link": "http://arxiv.org/abs/2009.12084v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "With Whom to Communicate: Learning Efficient Communication for   Multi-Robot Collision Avoidance",
        "authors": [
            "Álvaro Serra-Gómez",
            "Bruno Brito",
            "Hai Zhu",
            "Jen Jen Chung",
            "Javier Alonso-Mora"
        ],
        "summary": "Decentralized multi-robot systems typically perform coordinated motion planning by constantly broadcasting their intentions as a means to cope with the lack of a central system coordinating the efforts of all robots. Especially in complex dynamic environments, the coordination boost allowed by communication is critical to avoid collisions between cooperating robots. However, the risk of collision between a pair of robots fluctuates through their motion and communication is not always needed. Additionally, constant communication makes much of the still valuable information shared in previous time steps redundant. This paper presents an efficient communication method that solves the problem of \"when\" and with \"whom\" to communicate in multi-robot collision avoidance scenarios. In this approach, every robot learns to reason about other robots' states and considers the risk of future collisions before asking for the trajectory plans of other robots. We evaluate and verify the proposed communication strategy in simulation with four quadrotors and compare it with three baseline strategies: non-communicating, broadcasting and a distance-based method broadcasting information with quadrotors within a predefined distance.",
        "published": "2020-09-25T09:49:22Z",
        "link": "http://arxiv.org/abs/2009.12106v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Towards a Systematic Computational Framework for Modeling Multi-Agent   Decision-Making at Micro Level for Smart Vehicles in a Smart World",
        "authors": [
            "Qi Dai",
            "Xunnong Xu",
            "Wen Guo",
            "Suzhou Huang",
            "Dimitar Filev"
        ],
        "summary": "We propose a multi-agent based computational framework for modeling decision-making and strategic interaction at micro level for smart vehicles in a smart world. The concepts of Markov game and best response dynamics are heavily leveraged. Our aim is to make the framework conceptually sound and computationally practical for a range of realistic applications, including micro path planning for autonomous vehicles. To this end, we first convert the would-be stochastic game problem into a closely related deterministic one by introducing risk premium in the utility function for each individual agent. We show how the sub-game perfect Nash equilibrium of the simplified deterministic game can be solved by an algorithm based on best response dynamics. In order to better model human driving behaviors with bounded rationality, we seek to further simplify the solution concept by replacing the Nash equilibrium condition with a heuristic and adaptive optimization with finite look-ahead anticipation. In addition, the algorithm corresponding to the new solution concept drastically improves the computational efficiency. To demonstrate how our approach can be applied to realistic traffic settings, we conduct a simulation experiment: to derive merging and yielding behaviors on a double-lane highway with an unexpected barrier. Despite assumption differences involved in the two solution concepts, the derived numerical solutions show that the endogenized driving behaviors are very similar. We also briefly comment on how the proposed framework can be further extended in a number of directions in our forthcoming work, such as behavioral calibration using real traffic video data, computational mechanism design for traffic policy optimization, and so on.",
        "published": "2020-09-25T13:05:28Z",
        "link": "http://arxiv.org/abs/2009.12213v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.GT"
        ]
    },
    {
        "title": "Lineage Evolution Reinforcement Learning",
        "authors": [
            "Zeyu Zhang",
            "Guisheng Yin"
        ],
        "summary": "We propose a general agent population learning system, and on this basis, we propose lineage evolution reinforcement learning algorithm. Lineage evolution reinforcement learning is a kind of derivative algorithm which accords with the general agent population learning system. We take the agents in DQN and its related variants as the basic agents in the population, and add the selection, mutation and crossover modules in the genetic algorithm to the reinforcement learning algorithm. In the process of agent evolution, we refer to the characteristics of natural genetic behavior, add lineage factor to ensure the retention of potential performance of agent, and comprehensively consider the current performance and lineage value when evaluating the performance of agent. Without changing the parameters of the original reinforcement learning algorithm, lineage evolution reinforcement learning can optimize different reinforcement learning algorithms. Our experiments show that the idea of evolution with lineage improves the performance of original reinforcement learning algorithm in some games in Atari 2600.",
        "published": "2020-09-26T11:58:16Z",
        "link": "http://arxiv.org/abs/2010.14616v1",
        "categories": [
            "cs.NE",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Resilient Networking in Formation Flying UAVs",
        "authors": [
            "Lebsework Negash",
            "Han-Lim Choi"
        ],
        "summary": "The threats on cyber-physical system have changed much into a level of sophistication that elude the traditional security and protection methods. This work addresses a proactive approaches to the cyber security of a formation flying UAVs. A resilient formation control of UAVs in the presence of non-cooperative (defective or malicious) UAVs is presented. Based on local information a resilient consensus in the presence of misbehaving nodes is dealt with fault-tolerant consensus algorithm. In the proposed framework, a graph-theoretic property of network robustness conveying the notion of a direct information exchange between two sets of UAVs in the network is introduced to analyze the behavior and convergence of the distributed consensus algorithm. A distributed control policy is developed to maintain the network connectivity threshold to satisfy the topological requirement put forward for the resiliency of the consensus algorithm. Numerical examples are presented to show the applicability of the proactive approach used in dealing with the cyber attack treat on a formation flying UAVs",
        "published": "2020-09-27T03:47:18Z",
        "link": "http://arxiv.org/abs/2009.12738v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Defining and Quantifying Conversation Quality in Spontaneous   Interactions",
        "authors": [
            "Navin Raj Prabhu",
            "Chirag Raman",
            "Hayley Hung"
        ],
        "summary": "Social interactions in general are multifaceted and there exists a wide set of factors and events that influence them. In this paper, we quantify social interactions with a holistic viewpoint on individual experiences, particularly focusing on non-task-directed spontaneous interactions. To achieve this, we design a novel perceived measure, the perceived Conversation Quality, which intends to quantify spontaneous interactions by accounting for several socio-dimensional aspects of individual experiences.   To further quantitatively study spontaneous interactions, we devise a questionnaire which measures the perceived Conversation Quality, at both the individual- and at the group- level. Using the questionnaire, we collected perceived annotations for conversation quality in a publicly available dataset using naive annotators. The results of the analysis performed on the distribution and the inter-annotator agreeability shows that naive annotators tend to agree less in cases of low conversation quality samples, especially while annotating for group-level conversation quality.",
        "published": "2020-09-27T13:41:27Z",
        "link": "http://arxiv.org/abs/2009.12842v1",
        "categories": [
            "cs.MA",
            "cs.HC"
        ]
    },
    {
        "title": "Scalable Deep Reinforcement Learning for Ride-Hailing",
        "authors": [
            "Jiekun Feng",
            "Mark Gluzman",
            "J. G. Dai"
        ],
        "summary": "Ride-hailing services, such as Didi Chuxing, Lyft, and Uber, arrange thousands of cars to meet ride requests throughout the day. We consider a Markov decision process (MDP) model of a ride-hailing service system, framing it as a reinforcement learning (RL) problem. The simultaneous control of many agents (cars) presents a challenge for the MDP optimization because the action space grows exponentially with the number of cars. We propose a special decomposition for the MDP actions by sequentially assigning tasks to the drivers. The new actions structure resolves the scalability problem and enables the use of deep RL algorithms for control policy optimization. We demonstrate the benefit of our proposed decomposition with a numerical experiment based on real data from Didi Chuxing.",
        "published": "2020-09-27T20:07:12Z",
        "link": "http://arxiv.org/abs/2009.14679v1",
        "categories": [
            "math.OC",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Distributed Maximization of Submodular and Approximately Submodular   Functions",
        "authors": [
            "Lintao Ye",
            "Shreyas Sundaram"
        ],
        "summary": "We study the problem of maximizing a submodular function, subject to a cardinality constraint, with a set of agents communicating over a connected graph. We propose a distributed greedy algorithm that allows all the agents to converge to a near-optimal solution to the global maximization problem using only local information and communication with neighbors in the graph. The near-optimal solution approaches the (1-1/e) approximation of the optimal solution to the global maximization problem with an additive factor that depends on the number of communication steps in the algorithm. We then analyze convergence guarantees of the proposed algorithm. This analysis reveals a tradeoff between the number of communication steps and the performance of the algorithm. Finally, we extend our analysis to nonsubmodular settings, using the notion of approximate submodularity.",
        "published": "2020-09-28T00:33:58Z",
        "link": "http://arxiv.org/abs/2009.12992v1",
        "categories": [
            "math.OC",
            "cs.MA"
        ]
    },
    {
        "title": "Agent Environment Cycle Games",
        "authors": [
            "J K Terry",
            "Nathaniel Grammel",
            "Benjamin Black",
            "Ananth Hari",
            "Caroline Horsch",
            "Luis Santos"
        ],
        "summary": "Partially Observable Stochastic Games (POSGs) are the most general and common model of games used in Multi-Agent Reinforcement Learning (MARL). We argue that the POSG model is conceptually ill suited to software MARL environments, and offer case studies from the literature where this mismatch has led to severely unexpected behavior. In response to this, we introduce the Agent Environment Cycle Games (AEC Games) model, which is more representative of software implementation. We then prove it's as an equivalent model to POSGs. The AEC games model is also uniquely useful in that it can elegantly represent both all forms of MARL environments, whereas for example POSGs cannot elegantly represent strictly turn based games like chess.",
        "published": "2020-09-28T04:02:08Z",
        "link": "http://arxiv.org/abs/2009.13051v3",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.GT",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Compositionality of Linearly Solvable Optimal Control in Networked   Multi-Agent Systems",
        "authors": [
            "Lin Song",
            "Neng Wan",
            "Aditya Gahlawat",
            "Naira Hovakimyan",
            "Evangelos A. Theodorou"
        ],
        "summary": "In this paper, we discuss the methodology of generalizing the optimal control law from learned component tasks to unlearned composite tasks on Multi-Agent Systems (MASs), by using the linearity composition principle of linearly solvable optimal control (LSOC) problems. The proposed approach achieves both the compositionality and optimality of control actions simultaneously within the cooperative MAS framework in both discrete- and continuous-time in a sample-efficient manner, which reduces the burden of re-computation of the optimal control solutions for the new task on the MASs. We investigate the application of the proposed approach on the MAS with coordination between agents. The experiments show feasible results in investigated scenarios, including both discrete and continuous dynamical systems for task generalization without resampling.",
        "published": "2020-09-28T20:21:48Z",
        "link": "http://arxiv.org/abs/2009.13609v2",
        "categories": [
            "eess.SY",
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "math.OC"
        ]
    },
    {
        "title": "Learning to Play against Any Mixture of Opponents",
        "authors": [
            "Max Olan Smith",
            "Thomas Anthony",
            "Yongzhao Wang",
            "Michael P. Wellman"
        ],
        "summary": "Intuitively, experience playing against one mixture of opponents in a given domain should be relevant for a different mixture in the same domain. We propose a transfer learning method, Q-Mixing, that starts by learning Q-values against each pure-strategy opponent. Then a Q-value for any distribution of opponent strategies is approximated by appropriately averaging the separately learned Q-values. From these components, we construct policies against all opponent mixtures without any further training. We empirically validate Q-Mixing in two environments: a simple grid-world soccer environment, and a complicated cyber-security game. We find that Q-Mixing is able to successfully transfer knowledge across any mixture of opponents. We next consider the use of observations during play to update the believed distribution of opponents. We introduce an opponent classifier -- trained in parallel to Q-learning, using the same data -- and use the classifier results to refine the mixing of Q-values. We find that Q-Mixing augmented with the opponent classifier function performs comparably, and with lower variance, than training directly against a mixed-strategy opponent.",
        "published": "2020-09-29T17:48:10Z",
        "link": "http://arxiv.org/abs/2009.14180v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "An Overview on Optimal Flocking",
        "authors": [
            "Logan E. Beaver",
            "Andreas A. Malikopoulos"
        ],
        "summary": "The study of robotic flocking has received considerable attention in the past twenty years. As we begin to deploy flocking control algorithms on physical multi-agent and swarm systems, there is an increasing necessity for rigorous promises on safety and performance. In this paper, we present an overview the literature focusing on optimization approaches to achieve flocking behavior that provide strong safety guarantees. We separate the literature into cluster and line flocking, and categorize cluster flocking with respect to the system-level objective, which may be realized by a reactive or planning control algorithm. We also categorize the line flocking literature by the energy-saving mechanism that is exploited by the agents. We present several approaches aimed at minimizing the communication and computational requirements in real systems via neighbor filtering and event-driven planning, and conclude with our perspective on the outlook and future research direction of optimal flocking as a field.",
        "published": "2020-09-29T19:44:49Z",
        "link": "http://arxiv.org/abs/2009.14279v2",
        "categories": [
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "Centrality-Based Traffic Restriction in Delayed Epidemic Networks",
        "authors": [
            "Atefe Darabi",
            "Milad Siami"
        ],
        "summary": "During an epidemic, infectious individuals might not be detectable until some time after becoming infected. The studies show that carriers with mild or no symptoms are the main contributors to the transmission of a virus within the population. The average time it takes to develop the symptoms causes a delay in the spread dynamics of the disease. When considering the influence of delay on the disease propagation in epidemic networks, depending on the value of the time-delay and the network topology, the peak of epidemic could be considerably different in time, duration, and intensity. Motivated by the recent worldwide outbreak of the COVID-19 virus and the topological extent in which this virus has spread over the course of a few months, this study aims to highlight the effect of time-delay in the progress of such infectious diseases in the meta-population networks rather than individuals or a single population. In this regard, the notions of epidemic network centrality in terms of the underlying interaction graph of the network, structure of the uncertainties, and symptom development duration are investigated to establish a centrality-based analysis of the disease evolution. A convex traffic volume optimization method is then developed to control the outbreak. The control process is done by identifying the sub-populations with the highest centrality and then isolating them while maintaining the same overall traffic volume (motivated by economic considerations) in the meta-population level. The numerical results, along with the theoretical expectations, highlight the impact of time-delay as well as the importance of considering the worst-case scenarios in investigating the most effective methods of epidemic containment.",
        "published": "2020-09-29T22:43:36Z",
        "link": "http://arxiv.org/abs/2010.00398v2",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SI",
            "cs.SY"
        ]
    },
    {
        "title": "Co-design of Control and Planning for Multi-rotor UAVs with Signal   Temporal Logic Specifications",
        "authors": [
            "Yash Vardhan Pant",
            "He Yin",
            "Murat Arcak",
            "Sanjit A. Seshia"
        ],
        "summary": "Urban Air Mobility (UAM), or the scenario where multiple manned and Unmanned Aerial Vehicles (UAVs) carry out various tasks over urban airspaces, is a transportation concept of the future that is gaining prominence. UAM missions with complex spatial, temporal and reactive requirements can be succinctly represented using Signal Temporal Logic (STL), a behavioral specification language. However, planning and control of systems with STL specifications is computationally intensive, usually resulting in planning approaches that do not guarantee dynamical feasibility, or control approaches that cannot handle complex STL specifications. Here, we present an approach to co-design the planner and control such that a given STL specification (possibly over multiple UAVs) is satisfied with trajectories that are dynamically feasible and our controller can track them with a bounded tracking-error that the planner accounts for. The tracking controller is formulated for the non-linear dynamics of the individual UAVs, and the tracking error bound is computed for this controller when the trajectories satisfy some kinematic constraints. We also augment an existing multi-UAV STL-based trajectory generator in order to generate trajectories that satisfy such constraints. We show that this co-design allows for trajectories that satisfy a given STL specification, and are also dynamically feasible in the sense that they can be tracked with bounded error. The applicability of this approach is demonstrated through simulations of multi-UAV missions.",
        "published": "2020-09-30T01:00:47Z",
        "link": "http://arxiv.org/abs/2009.14363v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.RO",
            "cs.SY"
        ]
    },
    {
        "title": "Bridging the gap between Markowitz planning and deep reinforcement   learning",
        "authors": [
            "Eric Benhamou",
            "David Saltiel",
            "Sandrine Ungari",
            "Abhishek Mukhopadhyay"
        ],
        "summary": "While researchers in the asset management industry have mostly focused on techniques based on financial and risk planning techniques like Markowitz efficient frontier, minimum variance, maximum diversification or equal risk parity, in parallel, another community in machine learning has started working on reinforcement learning and more particularly deep reinforcement learning to solve other decision making problems for challenging task like autonomous driving, robot learning, and on a more conceptual side games solving like Go. This paper aims to bridge the gap between these two approaches by showing Deep Reinforcement Learning (DRL) techniques can shed new lights on portfolio allocation thanks to a more general optimization setting that casts portfolio allocation as an optimal control problem that is not just a one-step optimization, but rather a continuous control optimization with a delayed reward. The advantages are numerous: (i) DRL maps directly market conditions to actions by design and hence should adapt to changing environment, (ii) DRL does not rely on any traditional financial risk assumptions like that risk is represented by variance, (iii) DRL can incorporate additional data and be a multi inputs method as opposed to more traditional optimization methods. We present on an experiment some encouraging results using convolution networks.",
        "published": "2020-09-30T04:03:27Z",
        "link": "http://arxiv.org/abs/2010.09108v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "q-fin.PM"
        ]
    },
    {
        "title": "PettingZoo: Gym for Multi-Agent Reinforcement Learning",
        "authors": [
            "J. K. Terry",
            "Benjamin Black",
            "Nathaniel Grammel",
            "Mario Jayakumar",
            "Ananth Hari",
            "Ryan Sullivan",
            "Luis Santos",
            "Rodrigo Perez",
            "Caroline Horsch",
            "Clemens Dieffendahl",
            "Niall L. Williams",
            "Yashas Lokesh",
            "Praveen Ravi"
        ],
        "summary": "This paper introduces the PettingZoo library and the accompanying Agent Environment Cycle (\"AEC\") games model. PettingZoo is a library of diverse sets of multi-agent environments with a universal, elegant Python API. PettingZoo was developed with the goal of accelerating research in Multi-Agent Reinforcement Learning (\"MARL\"), by making work more interchangeable, accessible and reproducible akin to what OpenAI's Gym library did for single-agent reinforcement learning. PettingZoo's API, while inheriting many features of Gym, is unique amongst MARL APIs in that it's based around the novel AEC games model. We argue, in part through case studies on major problems in popular MARL environments, that the popular game models are poor conceptual models of games commonly used in MARL and accordingly can promote confusing bugs that are hard to detect, and that the AEC games model addresses these problems.",
        "published": "2020-09-30T06:42:09Z",
        "link": "http://arxiv.org/abs/2009.14471v7",
        "categories": [
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "CrowdEst: A Method for Estimating (and not Simulating) Crowd Evacuation   Parameters in Generic Environments",
        "authors": [
            "Estevso Testa",
            "Rodrigo C. Barros",
            "Soraia Raupp Musse"
        ],
        "summary": "Evacuation plans have been historically used as a safety measure for the construction of buildings. The existing crowd simulators require fully-modeled 3D environments and enough time to prepare and simulate scenarios, where the distribution and behavior of the crowd needs to be controlled. In addition, its population, routes or even doors and passages may change, so the 3D model and configurations have to be updated accordingly. This is a time-consuming task that commonly has to be addressed within the crowd simulators. With that in mind, we present a novel approach to estimate the resulting data of a given evacuation scenario without actually simulating it. For such, we divide the environment into smaller modular rooms with different configurations, in a divide-and-conquer fashion. Next, we train an artificial neural network to estimate all required data regarding the evacuation of a single room. After collecting the estimated data from each room, we develop a heuristic capable of aggregating per-room information so the full environment can be properly evaluated. Our method presents an average error of 5% when compared to evacuation time in a real-life environment. Our crowd estimator approach has several advantages, such as not requiring to model the 3D environment, nor learning how to use and configure a crowd simulator, which means any user can easily use it. Furthermore, the computational time to estimate evacuation data (inference time) is virtually zero, which is much better even when compared to the best-case scenario in a real-time crowd simulator.",
        "published": "2020-09-30T14:42:45Z",
        "link": "http://arxiv.org/abs/2010.00004v1",
        "categories": [
            "cs.MA",
            "cs.GR"
        ]
    },
    {
        "title": "Byzantine Fault-Tolerance in Decentralized Optimization under Minimal   Redundancy",
        "authors": [
            "Nirupam Gupta",
            "Thinh T. Doan",
            "Nitin H. Vaidya"
        ],
        "summary": "This paper considers the problem of Byzantine fault-tolerance in multi-agent decentralized optimization. In this problem, each agent has a local cost function. The goal of a decentralized optimization algorithm is to allow the agents to cooperatively compute a common minimum point of their aggregate cost function. We consider the case when a certain number of agents may be Byzantine faulty. Such faulty agents may not follow a prescribed algorithm, and they may share arbitrary or incorrect information with other non-faulty agents. Presence of such Byzantine agents renders a typical decentralized optimization algorithm ineffective. We propose a decentralized optimization algorithm with provable exact fault-tolerance against a bounded number of Byzantine agents, provided the non-faulty agents have a minimal redundancy.",
        "published": "2020-09-30T16:02:15Z",
        "link": "http://arxiv.org/abs/2009.14763v1",
        "categories": [
            "cs.DC",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Cooperative Path Integral Control for Stochastic Multi-Agent Systems",
        "authors": [
            "Neng Wan",
            "Aditya Gahlawat",
            "Naira Hovakimyan",
            "Evangelos A. Theodorou",
            "Petros G. Voulgaris"
        ],
        "summary": "A distributed stochastic optimal control solution is presented for cooperative multi-agent systems. The network of agents is partitioned into multiple factorial subsystems, each of which consists of a central agent and neighboring agents. Local control actions that rely only on agents' local observations are designed to optimize the joint cost functions of subsystems. When solving for the local control actions, the joint optimality equation for each subsystem is cast as a linear partial differential equation and solved using the Feynman-Kac formula. The solution and the optimal control action are then formulated as path integrals and approximated by a Monte-Carlo method. Numerical verification is provided through a simulation example consisting of a team of cooperative UAVs.",
        "published": "2020-09-30T16:24:14Z",
        "link": "http://arxiv.org/abs/2009.14775v2",
        "categories": [
            "eess.SY",
            "cs.LG",
            "cs.MA",
            "cs.RO",
            "cs.SY",
            "math.OC"
        ]
    },
    {
        "title": "Approximating Nash Social Welfare under Rado Valuations",
        "authors": [
            "Jugal Garg",
            "Edin Husic",
            "Laszlo A. Vegh"
        ],
        "summary": "We consider the problem of approximating maximum Nash social welfare (NSW) while allocating a set of indivisible items to $n$ agents. The NSW is a popular objective that provides a balanced tradeoff between the often conflicting requirements of fairness and efficiency, defined as the weighted geometric mean of agents' valuations. For the symmetric additive case of the problem, where agents have the same weight with additive valuations, the first constant-factor approximation algorithm was obtained in 2015. This led to a flurry of work obtaining constant-factor approximation algorithms for the symmetric case under mild generalizations of additive, and $O(n)$-approximation algorithms for more general valuations and for the asymmetric case.   In this paper, we make significant progress towards both symmetric and asymmetric NSW problems. We present the first constant-factor approximation algorithm for the symmetric case under Rado valuations. Rado valuations form a general class of valuation functions that arise from maximum cost independent matching problems, including as special cases assignment (OXS) valuations and weighted matroid rank functions. Furthermore, our approach also gives the first constant-factor approximation algorithm for the asymmetric case under Rado valuations, provided that the maximum ratio between the weights is bounded by a constant.",
        "published": "2020-09-30T17:07:51Z",
        "link": "http://arxiv.org/abs/2009.14793v1",
        "categories": [
            "cs.GT",
            "cs.DM",
            "cs.DS",
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "Unknown Delay for Adversarial Bandit Setting with Multiple Play",
        "authors": [
            "Olusola T. Odeyomi"
        ],
        "summary": "This paper addresses the problem of unknown delays in adversarial multi-armed bandit (MAB) with multiple play. Existing work on similar game setting focused on only the case where the learner selects an arm in each round. However, there are lots of applications in robotics where a learner needs to select more than one arm per round. It is therefore worthwhile to investigate the effect of delay when multiple arms are chosen. The multiple arms chosen per round in this setting are such that they experience the same amount of delay. There can be an aggregation of feedback losses from different combinations of arms selected at different rounds, and the learner is faced with the challenge of associating the feedback losses to the arms producing them. To address this problem, this paper proposes a delayed exponential, exploitation and exploration for multiple play (DEXP3.M) algorithm. The regret bound is only slightly worse than the regret of DEXP3 already proposed for the single play setting with unknown delay.",
        "published": "2020-10-01T01:07:19Z",
        "link": "http://arxiv.org/abs/2010.00161v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Herding stochastic autonomous agents via local control rules and online   global target selection strategies",
        "authors": [
            "Fabrizia Auletta",
            "Davide Fiore",
            "Michael J. Richardson",
            "Mario di Bernardo"
        ],
        "summary": "In this Paper we propose a simple yet effective set of local control rules to make a group of \"herder agents\" collect and contain in a desired region an ensemble of non-cooperative stochastic \"target agents\" in the plane. We investigate the robustness of the proposed strategies to variations of the number of target agents and the strength of the repulsive force they feel when in proximity of the herders. Extensive numerical simulations confirm the effectiveness of the approach and are complemented by a more realistic validation on commercially available robotic agents via ROS.",
        "published": "2020-10-01T13:26:27Z",
        "link": "http://arxiv.org/abs/2010.00386v3",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Mediating Artificial Intelligence Developments through Negative and   Positive Incentives",
        "authors": [
            "The Anh Han",
            "Luis Moniz Pereira",
            "Tom Lenaerts",
            "Francisco C. Santos"
        ],
        "summary": "The field of Artificial Intelligence (AI) is going through a period of great expectations, introducing a certain level of anxiety in research, business and also policy. This anxiety is further energised by an AI race narrative that makes people believe they might be missing out. Whether real or not, a belief in this narrative may be detrimental as some stake-holders will feel obliged to cut corners on safety precautions, or ignore societal consequences just to \"win\". Starting from a baseline model that describes a broad class of technology races where winners draw a significant benefit compared to others (such as AI advances, patent race, pharmaceutical technologies), we investigate here how positive (rewards) and negative (punishments) incentives may beneficially influence the outcomes. We uncover conditions in which punishment is either capable of reducing the development speed of unsafe participants or has the capacity to reduce innovation through over-regulation. Alternatively, we show that, in several scenarios, rewarding those that follow safety measures may increase the development speed while ensuring safe choices. Moreover, in {the latter} regimes, rewards do not suffer from the issue of over-regulation as is the case for punishment. Overall, our findings provide valuable insights into the nature and kinds of regulatory actions most suitable to improve safety compliance in the contexts of both smooth and sudden technological shifts.",
        "published": "2020-10-01T13:43:32Z",
        "link": "http://arxiv.org/abs/2010.00403v1",
        "categories": [
            "cs.AI",
            "cs.MA",
            "math.DS",
            "nlin.AO",
            "q-bio.PE"
        ]
    },
    {
        "title": "D3C: Reducing the Price of Anarchy in Multi-Agent Learning",
        "authors": [
            "Ian Gemp",
            "Kevin R. McKee",
            "Richard Everett",
            "Edgar A. Duéñez-Guzmán",
            "Yoram Bachrach",
            "David Balduzzi",
            "Andrea Tacchetti"
        ],
        "summary": "In multiagent systems, the complex interaction of fixed incentives can lead agents to outcomes that are poor (inefficient) not only for the group, but also for each individual. Price of anarchy is a technical, game-theoretic definition that quantifies the inefficiency arising in these scenarios -- it compares the welfare that can be achieved through perfect coordination against that achieved by self-interested agents at a Nash equilibrium. We derive a differentiable, upper bound on a price of anarchy that agents can cheaply estimate during learning. Equipped with this estimator, agents can adjust their incentives in a way that improves the efficiency incurred at a Nash equilibrium. Agents do so by learning to mix their reward (equiv. negative loss) with that of other agents by following the gradient of our derived upper bound. We refer to this approach as D3C. In the case where agent incentives are differentiable, D3C resembles the celebrated Win-Stay, Lose-Shift strategy from behavioral game theory, thereby establishing a connection between the global goal of maximum welfare and an established agent-centric learning rule. In the non-differentiable setting, as is common in multiagent reinforcement learning, we show the upper bound can be reduced via evolutionary strategies, until a compromise is reached in a distributed fashion. We demonstrate that D3C improves outcomes for each agent and the group as a whole on several social dilemmas including a traffic network exhibiting Braess's paradox, a prisoner's dilemma, and several multiagent domains.",
        "published": "2020-10-01T17:50:43Z",
        "link": "http://arxiv.org/abs/2010.00575v5",
        "categories": [
            "cs.MA",
            "cs.GT"
        ]
    },
    {
        "title": "Emergent Social Learning via Multi-agent Reinforcement Learning",
        "authors": [
            "Kamal Ndousse",
            "Douglas Eck",
            "Sergey Levine",
            "Natasha Jaques"
        ],
        "summary": "Social learning is a key component of human and animal intelligence. By taking cues from the behavior of experts in their environment, social learners can acquire sophisticated behavior and rapidly adapt to new circumstances. This paper investigates whether independent reinforcement learning (RL) agents in a multi-agent environment can learn to use social learning to improve their performance. We find that in most circumstances, vanilla model-free RL agents do not use social learning. We analyze the reasons for this deficiency, and show that by imposing constraints on the training environment and introducing a model-based auxiliary loss we are able to obtain generalized social learning policies which enable agents to: i) discover complex skills that are not learned from single-agent training, and ii) adapt online to novel environments by taking cues from experts present in the new environment. In contrast, agents trained with model-free RL or imitation learning generalize poorly and do not succeed in the transfer tasks. By mixing multi-agent and solo training, we can obtain agents that use social learning to gain skills that they can deploy when alone, even out-performing agents trained alone from the start.",
        "published": "2020-10-01T17:54:14Z",
        "link": "http://arxiv.org/abs/2010.00581v3",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Opinion Diffusion and Campaigning on Society Graphs",
        "authors": [
            "Piotr Faliszewski",
            "Rica Gonen",
            "Martin Koutecký",
            "Nimrod Talmon"
        ],
        "summary": "We study the effects of campaigning, where the society is partitioned into voter clusters and a diffusion process propagates opinions in a network connecting the clusters. Our model is very powerful and can incorporate many campaigning actions, various partitions of the society into clusters, and very general diffusion processes. Perhaps surprisingly, we show that computing the cheapest campaign for rigging a given election can usually be done efficiently, even with arbitrarily-many voters. Moreover, we report on certain computational simulations.",
        "published": "2020-10-01T19:25:55Z",
        "link": "http://arxiv.org/abs/2010.00651v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "PrognoseNet: A Generative Probabilistic Framework for Multimodal   Position Prediction given Context Information",
        "authors": [
            "Thomas Kurbiel",
            "Akash Sachdeva",
            "Kun Zhao",
            "Markus Buehren"
        ],
        "summary": "The ability to predict multiple possible future positions of the ego-vehicle given the surrounding context while also estimating their probabilities is key to safe autonomous driving. Most of the current state-of-the-art Deep Learning approaches are trained on trajectory data to achieve this task. However trajectory data captured by sensor systems is highly imbalanced, since by far most of the trajectories follow straight lines with an approximately constant velocity. This poses a huge challenge for the task of predicting future positions, which is inherently a regression problem. Current state-of-the-art approaches alleviate this problem only by major preprocessing of the training data, e.g. resampling, clustering into anchors etc. In this paper we propose an approach which reformulates the prediction problem as a classification task, allowing for powerful tools, e.g. focal loss, to combat the imbalance. To this end we design a generative probabilistic model consisting of a deep neural network with a Mixture of Gaussian head. A smart choice of the latent variable allows for the reformulation of the log-likelihood function as a combination of a classification problem and a much simplified regression problem. The output of our model is an estimate of the probability density function of future positions, hence allowing for prediction of multiple possible positions while also estimating their probabilities. The proposed approach can easily incorporate context information and does not require any preprocessing of the data.",
        "published": "2020-10-02T06:13:41Z",
        "link": "http://arxiv.org/abs/2010.00802v1",
        "categories": [
            "cs.CV",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Public Announcement Logic in HOL",
        "authors": [
            "Sebastian Reiche",
            "Christoph Benzmüller"
        ],
        "summary": "A shallow semantical embedding for public announcement logic with relativized common knowledge is presented. This embedding enables the first-time automation of this logic with off-the-shelf theorem provers for classical higher-order logic. It is demonstrated (i) how meta-theoretical studies can be automated this way, and (ii) how non-trivial reasoning in the target logic (public announcement logic), required e.g. to obtain a convincing encoding and automation of the wise men puzzle, can be realized. Key to the presented semantical embedding -- in contrast, e.g., to related work on the semantical embedding of normal modal logics -- is that evaluation domains are modeled explicitly and treated as additional parameter in the encodings of the constituents of the embedded target logic, while they were previously implicitly shared between meta logic and target logic.",
        "published": "2020-10-02T06:46:02Z",
        "link": "http://arxiv.org/abs/2010.00810v1",
        "categories": [
            "cs.AI",
            "cs.LO",
            "cs.MA",
            "math.LO",
            "03B60, 03B15, 68T27, 68T30, 68T15",
            "I.2.3; I.2.4; I.2.0; F.4"
        ]
    },
    {
        "title": "MADRaS : Multi Agent Driving Simulator",
        "authors": [
            "Anirban Santara",
            "Sohan Rudra",
            "Sree Aditya Buridi",
            "Meha Kaushik",
            "Abhishek Naik",
            "Bharat Kaul",
            "Balaraman Ravindran"
        ],
        "summary": "In this work, we present MADRaS, an open-source multi-agent driving simulator for use in the design and evaluation of motion planning algorithms for autonomous driving. MADRaS provides a platform for constructing a wide variety of highway and track driving scenarios where multiple driving agents can train for motion planning tasks using reinforcement learning and other machine learning algorithms. MADRaS is built on TORCS, an open-source car-racing simulator. TORCS offers a variety of cars with different dynamic properties and driving tracks with different geometries and surface properties. MADRaS inherits these functionalities from TORCS and introduces support for multi-agent training, inter-vehicular communication, noisy observations, stochastic actions, and custom traffic cars whose behaviours can be programmed to simulate challenging traffic conditions encountered in the real world. MADRaS can be used to create driving tasks whose complexities can be tuned along eight axes in well-defined steps. This makes it particularly suited for curriculum and continual learning. MADRaS is lightweight and it provides a convenient OpenAI Gym interface for independent control of each car. Apart from the primitive steering-acceleration-brake control mode of TORCS, MADRaS offers a hierarchical track-position -- speed control that can potentially be used to achieve better generalization. MADRaS uses multiprocessing to run each agent as a parallel process for efficiency and integrates well with popular reinforcement learning libraries like RLLib.",
        "published": "2020-10-02T13:38:49Z",
        "link": "http://arxiv.org/abs/2010.00993v1",
        "categories": [
            "cs.RO",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Correcting Experience Replay for Multi-Agent Communication",
        "authors": [
            "Sanjeevan Ahilan",
            "Peter Dayan"
        ],
        "summary": "We consider the problem of learning to communicate using multi-agent reinforcement learning (MARL). A common approach is to learn off-policy, using data sampled from a replay buffer. However, messages received in the past may not accurately reflect the current communication policy of each agent, and this complicates learning. We therefore introduce a 'communication correction' which accounts for the non-stationarity of observed communication induced by multi-agent learning. It works by relabelling the received message to make it likely under the communicator's current policy, and thus be a better reflection of the receiver's current environment. To account for cases in which agents are both senders and receivers, we introduce an ordered relabelling scheme. Our correction is computationally efficient and can be integrated with a range of off-policy algorithms. We find in our experiments that it substantially improves the ability of communicating MARL systems to learn across a variety of cooperative and competitive tasks.",
        "published": "2020-10-02T20:49:24Z",
        "link": "http://arxiv.org/abs/2010.01192v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Dynamics and Allocation of Transaction Cost in Multiagent Industrial   Symbiosis",
        "authors": [
            "Vahid Yazdanpanah",
            "Devrim Murat Yazan",
            "W. Henk M. Zijm"
        ],
        "summary": "This paper discusses the dynamics of Transaction Cost (TC) in Industrial Symbiosis Institutions (ISI) and provides a fair and stable mechanism for TC allocation among the involved firms in a given ISI. In principle, industrial symbiosis, as an implementation of the circular economy paradigm in the context of industrial relation, is a practice aiming at reducing the material/energy footprint of the firm. The well-engineered form of this practice is proved to decrease the transaction costs at a collective level. This can be achieved using information systems for: identifying potential synergies, evaluating mutually beneficial ones, implementing the contracts, and governing the behavior of the established relations. Then the question is \"how to distribute the costs for maintaining such an information system in a fair and stable manner?\" We see such a cost as a collective transaction cost and employ an integrated method rooted in cooperative game theory and multiagent systems research to develop a fair and stable allocation mechanism for it. The novelty is twofold: in developing analytical multiagent methods for capturing the dynamics of transaction costs in industrial symbiosis and in presenting a novel game-theoretic mechanism for its allocation in industrial symbiosis institutions. While the former contributes to the theories of industrial symbiosis (methodological contribution), the latter supports decision makers aiming to specify fair and stable industrial symbiosis contracts (practical contribution).",
        "published": "2020-10-03T13:56:59Z",
        "link": "http://arxiv.org/abs/2010.01361v1",
        "categories": [
            "cs.MA",
            "cs.GT"
        ]
    },
    {
        "title": "EECBS: A Bounded-Suboptimal Search for Multi-Agent Path Finding",
        "authors": [
            "Jiaoyang Li",
            "Wheeler Ruml",
            "Sven Koenig"
        ],
        "summary": "Multi-Agent Path Finding (MAPF), i.e., finding collision-free paths for multiple robots, is important for many applications where small runtimes are necessary, including the kind of automated warehouses operated by Amazon. CBS is a leading two-level search algorithm for solving MAPF optimally. ECBS is a bounded-suboptimal variant of CBS that uses focal search to speed up CBS by sacrificing optimality and instead guaranteeing that the costs of its solutions are within a given factor of optimal. In this paper, we study how to decrease its runtime even further using inadmissible heuristics. Motivated by Explicit Estimation Search (EES), we propose Explicit Estimation CBS (EECBS), a new bounded-suboptimal variant of CBS, that uses online learning to obtain inadmissible estimates of the cost of the solution of each high-level node and uses EES to choose which high-level node to expand next. We also investigate recent improvements of CBS and adapt them to EECBS. We find that EECBS with the improvements runs significantly faster than the state-of-the-art bounded-suboptimal MAPF algorithms ECBS, BCP-7, and eMDD-SAT on a variety of MAPF instances. We hope that the scalability of EECBS enables additional applications for bounded-suboptimal MAPF algorithms.",
        "published": "2020-10-03T14:19:00Z",
        "link": "http://arxiv.org/abs/2010.01367v2",
        "categories": [
            "cs.AI",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "A Generative Machine Learning Approach to Policy Optimization in   Pursuit-Evasion Games",
        "authors": [
            "Shiva Navabi",
            "Osonde A. Osoba"
        ],
        "summary": "We consider a pursuit-evasion game [11] played between two agents, 'Blue' (the pursuer) and 'Red' (the evader), over $T$ time steps. Red aims to attack Blue's territory. Blue's objective is to intercept Red by time $T$ and thereby limit the success of Red's attack. Blue must plan its pursuit trajectory by choosing parameters that determine its course of movement (speed and angle in our setup) such that it intercepts Red by time $T$. We show that Blue's path-planning problem in pursuing Red, can be posed as a sequential decision making problem under uncertainty. Blue's unawareness of Red's action policy renders the analytic dynamic programming approach intractable for finding the optimal action policy for Blue. In this work, we are interested in exploring data-driven approaches to the policy optimization problem that Blue faces. We apply generative machine learning (ML) approaches to learn optimal action policies for Blue. This highlights the ability of generative ML model to learn the relevant implicit representations for the dynamics of simulated pursuit-evasion games. We demonstrate the effectiveness of our modeling approach via extensive statistical assessments. This work can be viewed as a preliminary step towards further adoption of generative modeling approaches for addressing policy optimization problems that arise in the context of multi-agent learning and planning [1].",
        "published": "2020-10-04T22:43:44Z",
        "link": "http://arxiv.org/abs/2010.01711v2",
        "categories": [
            "cs.LG",
            "cs.GT",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "A Distributed Model-Free Ride-Sharing Approach for Joint Matching,   Pricing, and Dispatching using Deep Reinforcement Learning",
        "authors": [
            "Marina Haliem",
            "Ganapathy Mani",
            "Vaneet Aggarwal",
            "Bharat Bhargava"
        ],
        "summary": "Significant development of ride-sharing services presents a plethora of opportunities to transform urban mobility by providing personalized and convenient transportation while ensuring efficiency of large-scale ride pooling. However, a core problem for such services is route planning for each driver to fulfill the dynamically arriving requests while satisfying given constraints. Current models are mostly limited to static routes with only two rides per vehicle (optimally) or three (with heuristics). In this paper, we present a dynamic, demand aware, and pricing-based vehicle-passenger matching and route planning framework that (1) dynamically generates optimal routes for each vehicle based on online demand, pricing associated with each ride, vehicle capacities and locations. This matching algorithm starts greedily and optimizes over time using an insertion operation, (2) involves drivers in the decision-making process by allowing them to propose a different price based on the expected reward for a particular ride as well as the destination locations for future rides, which is influenced by supply-and demand computed by the Deep Q-network, (3) allows customers to accept or reject rides based on their set of preferences with respect to pricing and delay windows, vehicle type and carpooling preferences, and (4) based on demand prediction, our approach re-balances idle vehicles by dispatching them to the areas of anticipated high demand using deep Reinforcement Learning (RL). Our framework is validated using the New York City Taxi public dataset; however, we consider different vehicle types and designed customer utility functions to validate the setup and study different settings. Experimental results show the effectiveness of our approach in real-time and large scale settings.",
        "published": "2020-10-05T03:13:47Z",
        "link": "http://arxiv.org/abs/2010.01755v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Can we Generalize and Distribute Private Representation Learning?",
        "authors": [
            "Sheikh Shams Azam",
            "Taejin Kim",
            "Seyyedali Hosseinalipour",
            "Carlee Joe-Wong",
            "Saurabh Bagchi",
            "Christopher Brinton"
        ],
        "summary": "We study the problem of learning representations that are private yet informative, i.e., provide information about intended \"ally\" targets while hiding sensitive \"adversary\" attributes. We propose Exclusion-Inclusion Generative Adversarial Network (EIGAN), a generalized private representation learning (PRL) architecture that accounts for multiple ally and adversary attributes unlike existing PRL solutions. While centrally-aggregated dataset is a prerequisite for most PRL techniques, data in real-world is often siloed across multiple distributed nodes unwilling to share the raw data because of privacy concerns. We address this practical constraint by developing D-EIGAN, the first distributed PRL method that learns representations at each node without transmitting the source data. We theoretically analyze the behavior of adversaries under the optimal EIGAN and D-EIGAN encoders and the impact of dependencies among ally and adversary tasks on the optimization objective. Our experiments on various datasets demonstrate the advantages of EIGAN in terms of performance, robustness, and scalability. In particular, EIGAN outperforms the previous state-of-the-art by a significant accuracy margin (47% improvement), and D-EIGAN's performance is consistently on par with EIGAN under different network settings.",
        "published": "2020-10-05T05:43:47Z",
        "link": "http://arxiv.org/abs/2010.01792v5",
        "categories": [
            "cs.LG",
            "cs.CV",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "\"LazImpa\": Lazy and Impatient neural agents learn to communicate   efficiently",
        "authors": [
            "Mathieu Rita",
            "Rahma Chaabouni",
            "Emmanuel Dupoux"
        ],
        "summary": "Previous work has shown that artificial neural agents naturally develop surprisingly non-efficient codes. This is illustrated by the fact that in a referential game involving a speaker and a listener neural networks optimizing accurate transmission over a discrete channel, the emergent messages fail to achieve an optimal length. Furthermore, frequent messages tend to be longer than infrequent ones, a pattern contrary to the Zipf Law of Abbreviation (ZLA) observed in all natural languages. Here, we show that near-optimal and ZLA-compatible messages can emerge, but only if both the speaker and the listener are modified. We hence introduce a new communication system, \"LazImpa\", where the speaker is made increasingly lazy, i.e. avoids long messages, and the listener impatient, i.e.,~seeks to guess the intended content as soon as possible.",
        "published": "2020-10-05T09:25:53Z",
        "link": "http://arxiv.org/abs/2010.01878v1",
        "categories": [
            "cs.CL",
            "cs.AI",
            "cs.MA",
            "I.2",
            "I.2"
        ]
    },
    {
        "title": "Heterogeneous Multi-Agent Reinforcement Learning for Unknown Environment   Mapping",
        "authors": [
            "Ceyer Wakilpoor",
            "Patrick J. Martin",
            "Carrie Rebhuhn",
            "Amanda Vu"
        ],
        "summary": "Reinforcement learning in heterogeneous multi-agent scenarios is important for real-world applications but presents challenges beyond those seen in homogeneous settings and simple benchmarks. In this work, we present an actor-critic algorithm that allows a team of heterogeneous agents to learn decentralized control policies for covering an unknown environment. This task is of interest to national security and emergency response organizations that would like to enhance situational awareness in hazardous areas by deploying teams of unmanned aerial vehicles. To solve this multi-agent coverage path planning problem in unknown environments, we augment a multi-agent actor-critic architecture with a new state encoding structure and triplet learning loss to support heterogeneous agent learning. We developed a simulation environment that includes real-world environmental factors such as turbulence, delayed communication, and agent loss, to train teams of agents as well as probe their robustness and flexibility to such disturbances.",
        "published": "2020-10-06T12:23:05Z",
        "link": "http://arxiv.org/abs/2010.02663v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Reinforcement Learning in Deep Structured Teams: Initial Results with   Finite and Infinite Valued Features",
        "authors": [
            "Jalal Arabneydi",
            "Masoud Roudneshin",
            "Amir G. Aghdam"
        ],
        "summary": "In this paper, we consider Markov chain and linear quadratic models for deep structured teams with discounted and time-average cost functions under two non-classical information structures, namely, deep state sharing and no sharing. In deep structured teams, agents are coupled in dynamics and cost functions through deep state, where deep state refers to a set of orthogonal linear regressions of the states. In this article, we consider a homogeneous linear regression for Markov chain models (i.e., empirical distribution of states) and a few orthonormal linear regressions for linear quadratic models (i.e., weighted average of states). Some planning algorithms are developed for the case when the model is known, and some reinforcement learning algorithms are proposed for the case when the model is not known completely. The convergence of two model-free (reinforcement learning) algorithms, one for Markov chain models and one for linear quadratic models, is established. The results are then applied to a smart grid.",
        "published": "2020-10-06T16:45:49Z",
        "link": "http://arxiv.org/abs/2010.02868v4",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Dif-MAML: Decentralized Multi-Agent Meta-Learning",
        "authors": [
            "Mert Kayaalp",
            "Stefan Vlaski",
            "Ali H. Sayed"
        ],
        "summary": "The objective of meta-learning is to exploit the knowledge obtained from observed tasks to improve adaptation to unseen tasks. As such, meta-learners are able to generalize better when they are trained with a larger number of observed tasks and with a larger amount of data per task. Given the amount of resources that are needed, it is generally difficult to expect the tasks, their respective data, and the necessary computational capacity to be available at a single central location. It is more natural to encounter situations where these resources are spread across several agents connected by some graph topology. The formalism of meta-learning is actually well-suited to this decentralized setting, where the learner would be able to benefit from information and computational power spread across the agents. Motivated by this observation, in this work, we propose a cooperative fully-decentralized multi-agent meta-learning algorithm, referred to as Diffusion-based MAML or Dif-MAML. Decentralized optimization algorithms are superior to centralized implementations in terms of scalability, avoidance of communication bottlenecks, and privacy guarantees. The work provides a detailed theoretical analysis to show that the proposed strategy allows a collection of agents to attain agreement at a linear rate and to converge to a stationary point of the aggregate MAML objective even in non-convex environments. Simulation results illustrate the theoretical findings and the superior performance relative to the traditional non-cooperative setting.",
        "published": "2020-10-06T16:51:09Z",
        "link": "http://arxiv.org/abs/2010.02870v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "UneVEn: Universal Value Exploration for Multi-Agent Reinforcement   Learning",
        "authors": [
            "Tarun Gupta",
            "Anuj Mahajan",
            "Bei Peng",
            "Wendelin Böhmer",
            "Shimon Whiteson"
        ],
        "summary": "VDN and QMIX are two popular value-based algorithms for cooperative MARL that learn a centralized action value function as a monotonic mixing of per-agent utilities. While this enables easy decentralization of the learned policy, the restricted joint action value function can prevent them from solving tasks that require significant coordination between agents at a given timestep. We show that this problem can be overcome by improving the joint exploration of all agents during training. Specifically, we propose a novel MARL approach called Universal Value Exploration (UneVEn) that learns a set of related tasks simultaneously with a linear decomposition of universal successor features. With the policies of already solved related tasks, the joint exploration process of all agents can be improved to help them achieve better coordination. Empirical results on a set of exploration games, challenging cooperative predator-prey tasks requiring significant coordination among agents, and StarCraft II micromanagement benchmarks show that UneVEn can solve tasks where other state-of-the-art MARL methods fail.",
        "published": "2020-10-06T19:08:47Z",
        "link": "http://arxiv.org/abs/2010.02974v3",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Mapping of Real World Problems to Nature Inspired Algorithm using Goal   based Classification and TRIZ",
        "authors": [
            "Palak Sukharamwala",
            "Manojkumar Parmar"
        ],
        "summary": "The technologies and algorithms are growing at an exponential rate. The technologies are capable enough to solve technically challenging and complex problems which seemed impossible task. However, the trending methods and approaches are facing multiple challenges on various fronts of data, algorithms, software, computational complexities, and energy efficiencies. Nature also faces similar challenges. Nature has solved those challenges and formulation of those are available as Nature Inspired Algorithms (NIA), which are derived based on the study of nature. A novel method based on TRIZ to map the real-world problems to nature problems is explained here.TRIZ is a Theory of inventive problem solving. Using the proposed framework, best NIA can be identified to solve the real-world problems. For this framework to work, a novel classification of NIA based on the end goal that nature is trying to achieve is devised. The application of the this framework along with examples is also discussed.",
        "published": "2020-10-08T06:55:31Z",
        "link": "http://arxiv.org/abs/2010.03795v1",
        "categories": [
            "cs.NE",
            "cs.LG",
            "cs.MA",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "iPaaS in Agriculture 4.0: An Industrial Case",
        "authors": [
            "Rafael Cestari",
            "Sebastien Ducos",
            "Ernesto Exposito"
        ],
        "summary": "Current automation approaches in the Industry 4.0 have generated increased interest in the utilization of Integration Platforms as a Service (iPaaS) cloud architectures in order to unify and synchronize several systems, applications, and services in order to build smart solutions for automated and adaptive industrial process management. Existing iPaaS solutions present several out-of-the-box connectors and automation engines for easier integration of customers' projects, but show issues regarding overall adaptation outside their scope, brand locking, and occasionally high prices. Moreover, existing platforms fail to respond adequately to the needs of deploying multiple decision models capable of offering automated or semi-automated management of processes, thanks to the integration of the large diversity of data and event sources as well as the different physical or logical action entities. With the popularization of open-source software and applications such as BPM Engines, Machine Learning libraries, and Integration suites and libraries, it is possible to develop a fully customizable and adaptable, open-source iPaaS that can be used both in and outside industrial applications. In this paper, we propose a generic iPaaS architecture implemented on the basis of several open source solutions boasting integration, interoperability, and automated decision-making capabilities in the domain of Agriculture 4.0. A proof-of-concept based on these solutions is presented, as well as a case study on MA{\\\"I}SADOUR's grain storage process with a comparison with the currently human-operated tasks.",
        "published": "2020-10-08T07:52:37Z",
        "link": "http://arxiv.org/abs/2010.07015v1",
        "categories": [
            "cs.CY",
            "cs.MA",
            "cs.SE"
        ]
    },
    {
        "title": "Catch Me if I Can: Detecting Strategic Behaviour in Peer Assessment",
        "authors": [
            "Ivan Stelmakh",
            "Nihar B. Shah",
            "Aarti Singh"
        ],
        "summary": "We consider the issue of strategic behaviour in various peer-assessment tasks, including peer grading of exams or homeworks and peer review in hiring or promotions. When a peer-assessment task is competitive (e.g., when students are graded on a curve), agents may be incentivized to misreport evaluations in order to improve their own final standing. Our focus is on designing methods for detection of such manipulations. Specifically, we consider a setting in which agents evaluate a subset of their peers and output rankings that are later aggregated to form a final ordering. In this paper, we investigate a statistical framework for this problem and design a principled test for detecting strategic behaviour. We prove that our test has strong false alarm guarantees and evaluate its detection ability in practical settings. For this, we design and execute an experiment that elicits strategic behaviour from subjects and release a dataset of patterns of strategic behaviour that may be of independent interest. We then use the collected data to conduct a series of real and semi-synthetic evaluations that demonstrate a strong detection power of our test.",
        "published": "2020-10-08T15:08:40Z",
        "link": "http://arxiv.org/abs/2010.04041v1",
        "categories": [
            "cs.MA",
            "cs.GT",
            "cs.LG"
        ]
    },
    {
        "title": "Converging to a Desired Orientation in a Flock of Agents",
        "authors": [
            "Saar Cohen",
            "Noa Agmon"
        ],
        "summary": "This work concentrates on different aspects of the \\textit{consensus problem}, when applying it to a swarm of flocking agents. We examine the possible influence an external agent, referred to as {\\em influencing agent} has on the flock. We prove that even a single influencing agent with a \\textit{Face Desired Orientation behaviour} that is injected into the flock is sufficient for guaranteeing desired consensus of the flock of agents which follow a Vicsek-inspired Model. We further show that in some cases this can be guaranteed also in dynamic environments.",
        "published": "2020-10-09T17:15:01Z",
        "link": "http://arxiv.org/abs/2010.04686v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Graph Convolutional Value Decomposition in Multi-Agent Reinforcement   Learning",
        "authors": [
            "Navid Naderializadeh",
            "Fan H. Hung",
            "Sean Soleyman",
            "Deepak Khosla"
        ],
        "summary": "We propose a novel framework for value function factorization in multi-agent deep reinforcement learning (MARL) using graph neural networks (GNNs). In particular, we consider the team of agents as the set of nodes of a complete directed graph, whose edge weights are governed by an attention mechanism. Building upon this underlying graph, we introduce a mixing GNN module, which is responsible for i) factorizing the team state-action value function into individual per-agent observation-action value functions, and ii) explicit credit assignment to each agent in terms of fractions of the global team reward. Our approach, which we call GraphMIX, follows the centralized training and decentralized execution paradigm, enabling the agents to make their decisions independently once training is completed. We show the superiority of GraphMIX as compared to the state-of-the-art on several scenarios in the StarCraft II multi-agent challenge (SMAC) benchmark. We further demonstrate how GraphMIX can be used in conjunction with a recent hierarchical MARL architecture to both improve the agents' performance and enable fine-tuning them on mismatched test scenarios with higher numbers of agents and/or actions.",
        "published": "2020-10-09T18:01:01Z",
        "link": "http://arxiv.org/abs/2010.04740v2",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "A Decentralized Multi-Objective Optimization Algorithm",
        "authors": [
            "M. J. Blondin",
            "M. T. Hale"
        ],
        "summary": "During the past two decades, multi-agent optimization problems have drawn increased attention from the research community. When multiple objective functions are present among agents, many works optimize the sum of these objective functions. However, this formulation implies a decision regarding the relative importance of each objective function. In fact, optimizing the sum is a special case of a multi-objective problem in which all objectives are prioritized equally. In this paper, a distributed optimization algorithm that explores Pareto optimal solutions for non-homogeneously weighted sums of objective functions is proposed. This exploration is performed through a new rule based on agents' priorities that generates edge weights in agents' communication graph. These weights determine how agents update their decision variables with information received from other agents in the network. Agents initially disagree on the priorities of the objective functions though they are driven to agree upon them as they optimize. As a result, agents still reach a common solution. The network-level weight matrix is (non-doubly) stochastic, which contrasts with many works on the subject in which it is doubly-stochastic. New theoretical analyses are therefore developed to ensure convergence of the proposed algorithm. This paper provides a gradient-based optimization algorithm, proof of convergence to solutions, and convergence rates of the proposed algorithm. It is shown that agents' initial priorities influence the convergence rate of the proposed algorithm and that these initial choices affect its long-run behavior. Numerical results performed with different numbers of agents illustrate the performance and efficiency of the proposed algorithm.",
        "published": "2020-10-09T19:55:23Z",
        "link": "http://arxiv.org/abs/2010.04781v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "HAMLET: A Hierarchical Agent-based Machine Learning Platform",
        "authors": [
            "Ahmad Esmaeili",
            "John C. Gallagher",
            "John A. Springer",
            "Eric T. Matson"
        ],
        "summary": "Hierarchical Multi-Agent Systems provide convenient and relevant ways to analyze, model, and simulate complex systems composed of a large number of entities that interact at different levels of abstraction. In this paper, we introduce HAMLET (Hierarchical Agent-based Machine LEarning plaTform), a hybrid machine learning platform based on hierarchical multi-agent systems, to facilitate the research and democratization of geographically and/or locally distributed machine learning entities. The proposed system models a machine learning solutions as a hypergraph and autonomously sets up a multi-level structure of heterogeneous agents based on their innate capabilities and learned skills. HAMLET aids the design and management of machine learning systems and provides analytical capabilities for research communities to assess the existing and/or new algorithms/datasets through flexible and customizable queries. The proposed hybrid machine learning platform does not assume restrictions on the type of learning algorithms/datasets and is theoretically proven to be sound and complete with polynomial computational requirements. Additionally, it is examined empirically on 120 training and four generalized batch testing tasks performed on 24 machine learning algorithms and 9 standard datasets. The provided experimental results not only establish confidence in the platform's consistency and correctness but also demonstrate its testing and analytical capacity.",
        "published": "2020-10-10T03:46:59Z",
        "link": "http://arxiv.org/abs/2010.04894v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Event-Triggered Multi-agent Reinforcement Learning with Communication   under Limited-bandwidth Constraint",
        "authors": [
            "Guangzheng Hu",
            "Yuanheng Zhu",
            "Dongbin Zhao",
            "Mengchen Zhao",
            "Jianye Hao"
        ],
        "summary": "Communicating with each other in a distributed manner and behaving as a group are essential in multi-agent reinforcement learning. However, real-world multi-agent systems suffer from restrictions on limited-bandwidth communication. If the bandwidth is fully occupied, some agents are not able to send messages promptly to others, causing decision delay and impairing cooperative effects. Recent related work has started to address the problem but still fails in maximally reducing the consumption of communication resources. In this paper, we propose Event-Triggered Communication Network (ETCNet) to enhance the communication efficiency in multi-agent systems by sending messages only when necessary. According to the information theory, the limited bandwidth is translated to the penalty threshold of an event-triggered strategy, which determines whether an agent at each step sends a message or not. Then the design of the event-triggered strategy is formulated as a constrained Markov decision problem, and reinforcement learning finds the best communication protocol that satisfies the limited bandwidth constraint. Experiments on typical multi-agent tasks demonstrate that ETCNet outperforms other methods in terms of the reduction of bandwidth occupancy and still preserves the cooperative performance of multi-agent systems at the most.",
        "published": "2020-10-10T11:51:22Z",
        "link": "http://arxiv.org/abs/2010.04978v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "EB-DEVS: A Formal Framework for Modeling and Simulation of Emergent   Behavior in Dynamic Complex Systems",
        "authors": [
            "Daniel J. Foguelman",
            "Philipp Henning",
            "Adelinde Uhrmacher",
            "Rodrigo Castro"
        ],
        "summary": "Emergent behavior is a key feature defining a system under study as a complex system. Simulation has been recognized as the only way to deal with the study of the emergency of properties (at a macroscopic level) among groups of system components (at a microscopic level), for the manifestations of emergent structures cannot be deduced from analysing components in isolation. A systems-oriented generalisation must consider the presence of feedback loops (micro components react to macro properties), interaction among components of different classes (modular composition) and layered interaction of subsystems operating at different spatio-temporal scales (hierarchical organisation). In this work we introduce Emergent Behavior-DEVS (EB-DEVS) a Modeling and Simulation (M&S) formalism that permits reasoning about complex systems where emergent behavior is placed at the forefront of the analysis activity. EB-DEVS builds on the DEVS formalism, adding upward/downward communication channels to well-established capabilities for modular and hierarchical M&S of heterogeneous multi-formalism systems. EB-DEVS takes a minimalist stance on expressiveness, introducing a small set of extensions on Classic DEVS that can cope with emergent behavior, and making both formalisms interoperable (the modeler decides which subsystems deserve to be expressed via micro-macro dynamics). We present three case studies: flocks of birds with learning, population epidemics with vaccination and sub-cellular dynamics with homeostasis, through which we showcase how EB-DEVS performs by placing emergent properties at the center of the M&S process.",
        "published": "2020-10-10T16:39:41Z",
        "link": "http://arxiv.org/abs/2010.05042v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "nlin.AO"
        ]
    },
    {
        "title": "Autonomous Vehicle Visual Signals for Pedestrians: Experiments and   Design Recommendations",
        "authors": [
            "Henry Chen",
            "Robin Cohen",
            "Kerstin Dautenhahn",
            "Edith Law",
            "Krzysztof Czarnecki"
        ],
        "summary": "Autonomous Vehicles (AV) will transform transportation, but also the interaction between vehicles and pedestrians. In the absence of a driver, it is not clear how an AV can communicate its intention to pedestrians. One option is to use visual signals. To advance their design, we conduct four human-participant experiments and evaluate six representative AV visual signals for visibility, intuitiveness, persuasiveness, and usability at pedestrian crossings. Based on the results, we distill twelve practical design recommendations for AV visual signals, with focus on signal pattern design and placement. Moreover, the paper advances the methodology for experimental evaluation of visual signals, including lab, closed-course, and public road tests using an autonomous vehicle. In addition, the paper also reports insights on pedestrian crosswalk behaviours and the impacts of pedestrian trust towards AVs on the behaviors. We hope that this work will constitute valuable input to the ongoing development of international standards for AV lamps, and thus help mature automated driving in general.",
        "published": "2020-10-10T22:56:46Z",
        "link": "http://arxiv.org/abs/2010.05115v1",
        "categories": [
            "cs.AI",
            "cs.HC",
            "cs.MA",
            "cs.RO",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Distributed Resource Allocation with Multi-Agent Deep Reinforcement   Learning for 5G-V2V Communication",
        "authors": [
            "Alperen Gündogan",
            "H. Murat Gürsu",
            "Volker Pauli",
            "Wolfgang Kellerer"
        ],
        "summary": "We consider the distributed resource selection problem in Vehicle-to-vehicle (V2V) communication in the absence of a base station. Each vehicle autonomously selects transmission resources from a pool of shared resources to disseminate Cooperative Awareness Messages (CAMs). This is a consensus problem where each vehicle has to select a unique resource. The problem becomes more challenging when---due to mobility---the number of vehicles in vicinity of each other is changing dynamically. In a congested scenario, allocation of unique resources for each vehicle becomes infeasible and a congested resource allocation strategy has to be developed. The standardized approach in 5G, namely semi-persistent scheduling (SPS) suffers from effects caused by spatial distribution of the vehicles. In our approach, we turn this into an advantage. We propose a novel DIstributed Resource Allocation mechanism using multi-agent reinforcement Learning (DIRAL) which builds on a unique state representation. One challenging issue is to cope with the non-stationarity introduced by concurrently learning agents which causes convergence problems in multi-agent learning systems. We aimed to tackle non-stationarity with unique state representation. Specifically, we deploy view-based positional distribution as a state representation to tackle non-stationarity and perform complex joint behavior in a distributed fashion. Our results showed that DIRAL improves PRR by 20% compared to SPS in challenging congested scenarios.",
        "published": "2020-10-11T17:33:10Z",
        "link": "http://arxiv.org/abs/2010.05290v1",
        "categories": [
            "cs.NI",
            "cs.GT",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Privacy-Preserving Distributed Projection LMS for Linear Multitask   Networks",
        "authors": [
            "Chengcheng Wang",
            "Wee Peng Tay",
            "Ye Wei",
            "Yuan Wang"
        ],
        "summary": "We develop a privacy-preserving distributed projection least mean squares (LMS) strategy over linear multitask networks, where agents' local parameters of interest or tasks are linearly related. Each agent is interested in not only improving its local inference performance via in-network cooperation with neighboring agents, but also protecting its own individual task against privacy leakage. In our proposed strategy, at each time instant, each agent sends a noisy estimate, which is its local intermediate estimate corrupted by a zero-mean additive noise, to its neighboring agents. We derive a sufficient condition to determine the amount of noise to add to each agent's intermediate estimate to achieve an optimal trade-off between the network mean-square-deviation and an inference privacy constraint. We propose a distributed and adaptive strategy to compute the additive noise powers, and study the mean and mean-square behaviors and privacy-preserving performance of the proposed strategy. Simulation results demonstrate that our strategy is able to balance the trade-off between estimation accuracy and privacy preservation.",
        "published": "2020-10-12T08:31:40Z",
        "link": "http://arxiv.org/abs/2010.05527v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Differentially Private Secure Multi-Party Computation for Federated   Learning in Financial Applications",
        "authors": [
            "David Byrd",
            "Antigoni Polychroniadou"
        ],
        "summary": "Federated Learning enables a population of clients, working with a trusted server, to collaboratively learn a shared machine learning model while keeping each client's data within its own local systems. This reduces the risk of exposing sensitive data, but it is still possible to reverse engineer information about a client's private data set from communicated model parameters. Most federated learning systems therefore use differential privacy to introduce noise to the parameters. This adds uncertainty to any attempt to reveal private client data, but also reduces the accuracy of the shared model, limiting the useful scale of privacy-preserving noise. A system can further reduce the coordinating server's ability to recover private client information, without additional accuracy loss, by also including secure multiparty computation. An approach combining both techniques is especially relevant to financial firms as it allows new possibilities for collaborative learning without exposing sensitive client data. This could produce more accurate models for important tasks like optimal trade execution, credit origination, or fraud detection. The key contributions of this paper are: We present a privacy-preserving federated learning protocol to a non-specialist audience, demonstrate it using logistic regression on a real-world credit card fraud data set, and evaluate it using an open-source simulation platform which we have adapted for the development of federated learning systems.",
        "published": "2020-10-12T17:16:27Z",
        "link": "http://arxiv.org/abs/2010.05867v1",
        "categories": [
            "cs.CR",
            "cs.AI",
            "cs.MA",
            "q-fin.GN"
        ]
    },
    {
        "title": "Swarming of Aerial Robots with Markov Random Field Optimization",
        "authors": [
            "Malintha Fernando",
            "Lantao Liu"
        ],
        "summary": "Swarms are highly robust systems that offer unique benefits compared to their alternatives. In this work, we propose a bio-inspired and artificial potential field-driven robot swarm control method, where the swarm formation dynamics are modeled on the basis of Markov Random Field (MRF) optimization. We integrate the internal agent-wise local interactions and external environmental influences into the MRF. The optimized formation configurations at different stages of the trajectory can be viewed as formation \"shapes\" which further allows us to integrate dynamics-constrained motion control of the robots. We show that this approach can be used to generate dynamically feasible trajectories to navigate teams of aerial robots in complex environments.",
        "published": "2020-10-13T10:33:55Z",
        "link": "http://arxiv.org/abs/2010.06274v2",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "A game-theoretic analysis of networked system control for common-pool   resource management using multi-agent reinforcement learning",
        "authors": [
            "Arnu Pretorius",
            "Scott Cameron",
            "Elan van Biljon",
            "Tom Makkink",
            "Shahil Mawjee",
            "Jeremy du Plessis",
            "Jonathan Shock",
            "Alexandre Laterre",
            "Karim Beguir"
        ],
        "summary": "Multi-agent reinforcement learning has recently shown great promise as an approach to networked system control. Arguably, one of the most difficult and important tasks for which large scale networked system control is applicable is common-pool resource management. Crucial common-pool resources include arable land, fresh water, wetlands, wildlife, fish stock, forests and the atmosphere, of which proper management is related to some of society's greatest challenges such as food security, inequality and climate change. Here we take inspiration from a recent research program investigating the game-theoretic incentives of humans in social dilemma situations such as the well-known tragedy of the commons. However, instead of focusing on biologically evolved human-like agents, our concern is rather to better understand the learning and operating behaviour of engineered networked systems comprising general-purpose reinforcement learning agents, subject only to nonbiological constraints such as memory, computation and communication bandwidth. Harnessing tools from empirical game-theoretic analysis, we analyse the differences in resulting solution concepts that stem from employing different information structures in the design of networked multi-agent systems. These information structures pertain to the type of information shared between agents as well as the employed communication protocol and network topology. Our analysis contributes new insights into the consequences associated with certain design choices and provides an additional dimension of comparison between systems beyond efficiency, robustness, scalability and mean control performance.",
        "published": "2020-10-15T14:12:26Z",
        "link": "http://arxiv.org/abs/2010.07777v1",
        "categories": [
            "cs.LG",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Multi-Agent Trust Region Policy Optimization",
        "authors": [
            "Hepeng Li",
            "Haibo He"
        ],
        "summary": "We extend trust region policy optimization (TRPO) to multi-agent reinforcement learning (MARL) problems. We show that the policy update of TRPO can be transformed into a distributed consensus optimization problem for multi-agent cases. By making a series of approximations to the consensus optimization model, we propose a decentralized MARL algorithm, which we call multi-agent TRPO (MATRPO). This algorithm can optimize distributed policies based on local observations and private rewards. The agents do not need to know observations, rewards, policies or value/action-value functions of other agents. The agents only share a likelihood ratio with their neighbors during the training process. The algorithm is fully decentralized and privacy-preserving. Our experiments on two cooperative games demonstrate its robust performance on complicated MARL tasks.",
        "published": "2020-10-15T17:49:47Z",
        "link": "http://arxiv.org/abs/2010.07916v3",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Decentralized Multi-Agent Pursuit using Deep Reinforcement Learning",
        "authors": [
            "Cristino de Souza Jr",
            "Rhys Newbury",
            "Akansel Cosgun",
            "Pedro Castillo",
            "Boris Vidolov",
            "Dana Kulic"
        ],
        "summary": "Pursuit-evasion is the problem of capturing mobile targets with one or more pursuers. We use deep reinforcement learning for pursuing an omni-directional target with multiple, homogeneous agents that are subject to unicycle kinematic constraints. We use shared experience to train a policy for a given number of pursuers that is executed independently by each agent at run-time. The training benefits from curriculum learning, a sweeping-angle ordering to locally represent neighboring agents and encouraging good formations with reward structure that combines individual and group rewards. Simulated experiments with a reactive evader and up to eight pursuers show that our learning-based approach, with non-holonomic agents, performs on par with classical algorithms with omni-directional agents, and outperforms their non-holonomic adaptations. The learned policy is successfully transferred to the real world in a proof-of-concept demonstration with three motion-constrained pursuer drones.",
        "published": "2020-10-16T06:58:18Z",
        "link": "http://arxiv.org/abs/2010.08193v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Multi-Agent Collaboration via Reward Attribution Decomposition",
        "authors": [
            "Tianjun Zhang",
            "Huazhe Xu",
            "Xiaolong Wang",
            "Yi Wu",
            "Kurt Keutzer",
            "Joseph E. Gonzalez",
            "Yuandong Tian"
        ],
        "summary": "Recent advances in multi-agent reinforcement learning (MARL) have achieved super-human performance in games like Quake 3 and Dota 2. Unfortunately, these techniques require orders-of-magnitude more training rounds than humans and don't generalize to new agent configurations even on the same game. In this work, we propose Collaborative Q-learning (CollaQ) that achieves state-of-the-art performance in the StarCraft multi-agent challenge and supports ad hoc team play. We first formulate multi-agent collaboration as a joint optimization on reward assignment and show that each agent has an approximately optimal policy that decomposes into two parts: one part that only relies on the agent's own state, and the other part that is related to states of nearby agents. Following this novel finding, CollaQ decomposes the Q-function of each agent into a self term and an interactive term, with a Multi-Agent Reward Attribution (MARA) loss that regularizes the training. CollaQ is evaluated on various StarCraft maps and shows that it outperforms existing state-of-the-art techniques (i.e., QMIX, QTRAN, and VDN) by improving the win rate by 40% with the same number of samples. In the more challenging ad hoc team play setting (i.e., reweight/add/remove units without re-training or finetuning), CollaQ outperforms previous SoTA by over 30%.",
        "published": "2020-10-16T17:42:11Z",
        "link": "http://arxiv.org/abs/2010.08531v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Flow-FL: Data-Driven Federated Learning for Spatio-Temporal Predictions   in Multi-Robot Systems",
        "authors": [
            "Nathalie Majcherczyk",
            "Nishan Srishankar",
            "Carlo Pinciroli"
        ],
        "summary": "In this paper, we show how the Federated Learning (FL) framework enables learning collectively from distributed data in connected robot teams. This framework typically works with clients collecting data locally, updating neural network weights of their model, and sending updates to a server for aggregation into a global model. We explore the design space of FL by comparing two variants of this concept. The first variant follows the traditional FL approach in which a server aggregates the local models. In the second variant, that we call Flow-FL, the aggregation process is serverless thanks to the use of a gossip-based shared data structure. In both variants, we use a data-driven mechanism to synchronize the learning process in which robots contribute model updates when they collect sufficient data. We validate our approach with an agent trajectory forecasting problem in a multi-agent setting. Using a centralized implementation as a baseline, we study the effects of staggered online data collection, and variations in data flow, number of participating robots, and time delays introduced by the decentralization of the framework in a multi-robot setting.",
        "published": "2020-10-16T19:09:57Z",
        "link": "http://arxiv.org/abs/2010.08595v1",
        "categories": [
            "cs.RO",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "A Game AI Competition to foster Collaborative AI research and   development",
        "authors": [
            "Ana Salta",
            "Rui Prada",
            "Francisco S. Melo"
        ],
        "summary": "Game AI competitions are important to foster research and development on Game AI and AI in general. These competitions supply different challenging problems that can be translated into other contexts, virtual or real. They provide frameworks and tools to facilitate the research on their core topics and provide means for comparing and sharing results. A competition is also a way to motivate new researchers to study these challenges. In this document, we present the Geometry Friends Game AI Competition. Geometry Friends is a two-player cooperative physics-based puzzle platformer computer game. The concept of the game is simple, though its solving has proven to be difficult. While the main and apparent focus of the game is cooperation, it also relies on other AI-related problems such as planning, plan execution, and motion control, all connected to situational awareness. All of these must be solved in real-time. In this paper, we discuss the competition and the challenges it brings, and present an overview of the current solutions.",
        "published": "2020-10-17T23:03:06Z",
        "link": "http://arxiv.org/abs/2010.08885v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Implementing Agent-Based Systems via Computability Logic CL2",
        "authors": [
            "Keehang Kwon"
        ],
        "summary": "Computability logic(CoL) is a powerful computational model. In this paper, we show that CoL naturally supports multi-agent programming models where resources (coffee for example) are involved. To be specific, we discuss an implementation of the Starbucks based on CoL (CL2 to be exact).",
        "published": "2020-10-18T06:07:32Z",
        "link": "http://arxiv.org/abs/2010.08925v3",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Analysis of the impact of maker-taker fees on the stock market using   agent-based simulation",
        "authors": [
            "Isao Yagi",
            "Mahiro Hoshino",
            "Takanobu Mizuta"
        ],
        "summary": "Recently, most stock exchanges in the U.S. employ maker-taker fees, in which an exchange pays rebates to traders placing orders in the order book and charges fees to traders taking orders from the order book. Maker-taker fees encourage traders to place many orders that provide market liquidity to the exchange. However, it is not clear how maker-taker fees affect the total cost of a taking order, including all the charged fees and the market impact. In this study, we investigated the effect of maker-taker fees on the total cost of a taking order with our artificial market model, which is an agent-based model for financial markets. We found that maker-taker fees encourage market efficiency but increase the total costs of taking orders.",
        "published": "2020-10-18T14:12:05Z",
        "link": "http://arxiv.org/abs/2010.08992v1",
        "categories": [
            "q-fin.TR",
            "cs.MA"
        ]
    },
    {
        "title": "Model-free conventions in multi-agent reinforcement learning with   heterogeneous preferences",
        "authors": [
            "Raphael Köster",
            "Kevin R. McKee",
            "Richard Everett",
            "Laura Weidinger",
            "William S. Isaac",
            "Edward Hughes",
            "Edgar A. Duéñez-Guzmán",
            "Thore Graepel",
            "Matthew Botvinick",
            "Joel Z. Leibo"
        ],
        "summary": "Game theoretic views of convention generally rest on notions of common knowledge and hyper-rational models of individual behavior. However, decades of work in behavioral economics have questioned the validity of both foundations. Meanwhile, computational neuroscience has contributed a modernized 'dual process' account of decision-making where model-free (MF) reinforcement learning trades off with model-based (MB) reinforcement learning. The former captures habitual and procedural learning while the latter captures choices taken via explicit planning and deduction. Some conventions (e.g. international treaties) are likely supported by cognition that resonates with the game theoretic and MB accounts. However, convention formation may also occur via MF mechanisms like habit learning; though this possibility has been understudied. Here, we demonstrate that complex, large-scale conventions can emerge from MF learning mechanisms. This suggests that some conventions may be supported by habit-like cognition rather than explicit reasoning. We apply MF multi-agent reinforcement learning to a temporo-spatially extended game with incomplete information. In this game, large parts of the state space are reachable only by collective action. However, heterogeneity of tastes makes such coordinated action difficult: multiple equilibria are desirable for all players, but subgroups prefer a particular equilibrium over all others. This creates a coordination problem that can be solved by establishing a convention. We investigate start-up and free rider subproblems as well as the effects of group size, intensity of intrinsic preference, and salience on the emergence dynamics of coordination conventions. Results of our simulations show agents establish and switch between conventions, even working against their own preferred outcome when doing so is necessary for effective coordination.",
        "published": "2020-10-18T18:18:37Z",
        "link": "http://arxiv.org/abs/2010.09054v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Blockchain Based Decentralized Replay Attack Detection for Large Scale   Power Systems",
        "authors": [
            "Paritosh Ramanan",
            "Dan Li",
            "Nagi Gebraeel"
        ],
        "summary": "Large scale power systems are comprised of regional utilities with assets that stream sensor readings in real time. In order to detect cyberattacks, the globally acquired, real time sensor data needs to be analyzed in a centralized fashion. However, owing to operational constraints, such a centralized sharing mechanism turns out to be a major obstacle. In this paper, we propose a blockchain based decentralized framework for detecting coordinated replay attacks with full privacy of sensor data. We develop a Bayesian inference mechanism employing locally reported attack probabilities that is tailor made for a blockchain framework. We compare our framework to a traditional decentralized algorithm based on the broadcast gossip framework both theoretically as well as empirically. With the help of experiments on a private Ethereum blockchain, we show that our approach achieves good detection quality and significantly outperforms gossip driven approaches in terms of accuracy, timeliness and scalability.",
        "published": "2020-10-18T19:51:09Z",
        "link": "http://arxiv.org/abs/2010.09086v2",
        "categories": [
            "cs.DC",
            "cs.MA"
        ]
    },
    {
        "title": "Wireless Control for Smart Manufacturing: Recent Approaches and Open   Challenges",
        "authors": [
            "Dominik Baumann",
            "Fabian Mager",
            "Ulf Wetzker",
            "Lothar Thiele",
            "Marco Zimmerling",
            "Sebastian Trimpe"
        ],
        "summary": "Smart manufacturing aims to overcome the limitations of today's rigid assembly lines by making the material flow and manufacturing process more flexible, versatile, and scalable. The main economic drivers are higher resource and cost efficiency as the manufacturers can more quickly adapt to changing market needs and also increase the lifespan of their production sites. The ability to close feedback loops fast and reliably over long distances among mobile robots, remote sensors, and human operators is a key enabler for smart manufacturing. Thus, this article provides a perspective on control and coordination over wireless networks. Based on an analysis of real-world use cases, we identify the main technical challenges that need to be solved to close the large gap between the current state of the art in industry and the vision of smart manufacturing. We discuss to what extent existing control-over-wireless solutions in the literature address those challenges, including our own approach toward a tight integration of control and wireless communication. In addition to a theoretical analysis of closed-loop stability, practical experiments on a cyber-physical testbed demonstrate that our approach supports relevant smart manufacturing scenarios. The article concludes with a discussion of open challenges and future research directions.",
        "published": "2020-10-18T19:55:12Z",
        "link": "http://arxiv.org/abs/2010.09087v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.NI",
            "cs.SY"
        ]
    },
    {
        "title": "SMARTS: Scalable Multi-Agent Reinforcement Learning Training School for   Autonomous Driving",
        "authors": [
            "Ming Zhou",
            "Jun Luo",
            "Julian Villella",
            "Yaodong Yang",
            "David Rusu",
            "Jiayu Miao",
            "Weinan Zhang",
            "Montgomery Alban",
            "Iman Fadakar",
            "Zheng Chen",
            "Aurora Chongxi Huang",
            "Ying Wen",
            "Kimia Hassanzadeh",
            "Daniel Graves",
            "Dong Chen",
            "Zhengbang Zhu",
            "Nhat Nguyen",
            "Mohamed Elsayed",
            "Kun Shao",
            "Sanjeevan Ahilan",
            "Baokuan Zhang",
            "Jiannan Wu",
            "Zhengang Fu",
            "Kasra Rezaee",
            "Peyman Yadmellat",
            "Mohsen Rohani",
            "Nicolas Perez Nieves",
            "Yihan Ni",
            "Seyedershad Banijamali",
            "Alexander Cowen Rivers",
            "Zheng Tian",
            "Daniel Palenicek",
            "Haitham bou Ammar",
            "Hongbo Zhang",
            "Wulong Liu",
            "Jianye Hao",
            "Jun Wang"
        ],
        "summary": "Multi-agent interaction is a fundamental aspect of autonomous driving in the real world. Despite more than a decade of research and development, the problem of how to competently interact with diverse road users in diverse scenarios remains largely unsolved. Learning methods have much to offer towards solving this problem. But they require a realistic multi-agent simulator that generates diverse and competent driving interactions. To meet this need, we develop a dedicated simulation platform called SMARTS (Scalable Multi-Agent RL Training School). SMARTS supports the training, accumulation, and use of diverse behavior models of road users. These are in turn used to create increasingly more realistic and diverse interactions that enable deeper and broader research on multi-agent interaction. In this paper, we describe the design goals of SMARTS, explain its basic architecture and its key features, and illustrate its use through concrete multi-agent experiments on interactive scenarios. We open-source the SMARTS platform and the associated benchmark tasks and evaluation metrics to encourage and empower research on multi-agent learning for autonomous driving. Our code is available at https://github.com/huawei-noah/SMARTS.",
        "published": "2020-10-19T18:26:10Z",
        "link": "http://arxiv.org/abs/2010.09776v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.GT",
            "cs.LG",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Watch-And-Help: A Challenge for Social Perception and Human-AI   Collaboration",
        "authors": [
            "Xavier Puig",
            "Tianmin Shu",
            "Shuang Li",
            "Zilin Wang",
            "Yuan-Hong Liao",
            "Joshua B. Tenenbaum",
            "Sanja Fidler",
            "Antonio Torralba"
        ],
        "summary": "In this paper, we introduce Watch-And-Help (WAH), a challenge for testing social intelligence in agents. In WAH, an AI agent needs to help a human-like agent perform a complex household task efficiently. To succeed, the AI agent needs to i) understand the underlying goal of the task by watching a single demonstration of the human-like agent performing the same task (social perception), and ii) coordinate with the human-like agent to solve the task in an unseen environment as fast as possible (human-AI collaboration). For this challenge, we build VirtualHome-Social, a multi-agent household environment, and provide a benchmark including both planning and learning based baselines. We evaluate the performance of AI agents with the human-like agent as well as with real humans using objective metrics and subjective user ratings. Experimental results demonstrate that the proposed challenge and virtual environment enable a systematic evaluation on the important aspects of machine social intelligence at scale.",
        "published": "2020-10-19T21:48:31Z",
        "link": "http://arxiv.org/abs/2010.09890v2",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Robust Asynchronous and Network-Independent Cooperative Learning",
        "authors": [
            "Eduardo Mojica-Nava",
            "David Yanguas-Rojas",
            "César A. Uribe"
        ],
        "summary": "We consider the model of cooperative learning via distributed non-Bayesian learning, where a network of agents tries to jointly agree on a hypothesis that best described a sequence of locally available observations. Building upon recently proposed weak communication network models, we propose a robust cooperative learning rule that allows asynchronous communications, message delays, unpredictable message losses, and directed communication among nodes. We show that our proposed learning dynamics guarantee that all agents in the network will have an asymptotic exponential decay of their beliefs on the wrong hypothesis, indicating that the beliefs of all agents will concentrate on the optimal hypotheses. Numerical experiments provide evidence on a number of network setups.",
        "published": "2020-10-20T03:54:20Z",
        "link": "http://arxiv.org/abs/2010.09993v1",
        "categories": [
            "math.OC",
            "cs.DC",
            "cs.MA",
            "cs.SI",
            "stat.ML"
        ]
    },
    {
        "title": "A Particle Swarm Inspired Approach for Continuous Distributed Constraint   Optimization Problems",
        "authors": [
            "Moumita Choudhury",
            "Amit Sarker",
            "Md. Mosaddek Khan",
            "William Yeoh"
        ],
        "summary": "Distributed Constraint Optimization Problems (DCOPs) are a widely studied framework for coordinating interactions in cooperative multi-agent systems. In classical DCOPs, variables owned by agents are assumed to be discrete. However, in many applications, such as target tracking or sleep scheduling in sensor networks, continuous-valued variables are more suitable than discrete ones. To better model such applications, researchers have proposed Continuous DCOPs (C-DCOPs), an extension of DCOPs, that can explicitly model problems with continuous variables. The state-of-the-art approaches for solving C-DCOPs experience either onerous memory or computation overhead and unsuitable for non-differentiable optimization problems. To address this issue, we propose a new C-DCOP algorithm, namely Particle Swarm Optimization Based C-DCOP (PCD), which is inspired by Particle Swarm Optimization (PSO), a well-known centralized population-based approach for solving continuous optimization problems. In recent years, population-based algorithms have gained significant attention in classical DCOPs due to their ability in producing high-quality solutions. Nonetheless, to the best of our knowledge, this class of algorithms has not been utilized to solve C-DCOPs and there has been no work evaluating the potential of PSO in solving classical DCOPs or C-DCOPs. In light of this observation, we adapted PSO, a centralized algorithm, to solve C-DCOPs in a decentralized manner. The resulting PCD algorithm not only produces good-quality solutions but also finds solutions without any requirement for derivative calculations. Moreover, we design a crossover operator that can be used by PCD to further improve the quality of solutions found. Finally, we theoretically prove that PCD is an anytime algorithm and empirically evaluate PCD against the state-of-the-art C-DCOP algorithms in a wide variety of benchmarks.",
        "published": "2020-10-20T11:04:47Z",
        "link": "http://arxiv.org/abs/2010.10192v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Negotiating Team Formation Using Deep Reinforcement Learning",
        "authors": [
            "Yoram Bachrach",
            "Richard Everett",
            "Edward Hughes",
            "Angeliki Lazaridou",
            "Joel Z. Leibo",
            "Marc Lanctot",
            "Michael Johanson",
            "Wojciech M. Czarnecki",
            "Thore Graepel"
        ],
        "summary": "When autonomous agents interact in the same environment, they must often cooperate to achieve their goals. One way for agents to cooperate effectively is to form a team, make a binding agreement on a joint plan, and execute it. However, when agents are self-interested, the gains from team formation must be allocated appropriately to incentivize agreement. Various approaches for multi-agent negotiation have been proposed, but typically only work for particular negotiation protocols. More general methods usually require human input or domain-specific data, and so do not scale. To address this, we propose a framework for training agents to negotiate and form teams using deep reinforcement learning. Importantly, our method makes no assumptions about the specific negotiation protocol, and is instead completely experience driven. We evaluate our approach on both non-spatial and spatially extended team-formation negotiation environments, demonstrating that our agents beat hand-crafted bots and reach negotiation outcomes consistent with fair solutions predicted by cooperative game theory. Additionally, we investigate how the physical location of agents influences negotiation outcomes.",
        "published": "2020-10-20T15:41:23Z",
        "link": "http://arxiv.org/abs/2010.10380v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "I.2.6"
        ]
    },
    {
        "title": "Algebraic Structures from Concurrent Constraint Programming Calculi for   Distributed Information in Multi-Agent Systems",
        "authors": [
            "Michell Guzmán",
            "Sophia Knight",
            "Santiago Quintero",
            "Sergio Ramírez",
            "Camilo Rueda",
            "Frank Valencia"
        ],
        "summary": "Spatial constraint systems (scs) are semantic structures for reasoning about spatial and epistemic information in concurrent systems. We develop the theory of scs to reason about the distributed information of potentially infinite groups. We characterize the notion of distributed information of a group of agents as the infimum of the set of join-preserving functions that represent the spaces of the agents in the group. We provide an alternative characterization of this notion as the greatest family of join-preserving functions that satisfy certain basic properties. For completely distributive lattices, we establish that distributed information of a group is the greatest information below all possible combinations of information in the spaces of the agents in the group that derive a given piece of information. We show compositionality results for these characterizations and conditions under which information that can be obtained by an infinite group can also be obtained by a finite group. Finally, we provide an application on mathematical morphology where dilations, one of its fundamental operations, define an scs on a powerset lattice. We show that distributed information represents a particular dilation in such scs.",
        "published": "2020-10-20T23:13:03Z",
        "link": "http://arxiv.org/abs/2010.10667v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Coordinated Online Learning for Multi-Agent Systems with Coupled   Constraints and Perturbed Utility Observations",
        "authors": [
            "Ezra Tampubolon",
            "Holger Boche"
        ],
        "summary": "Competitive non-cooperative online decision-making agents whose actions increase congestion of scarce resources constitute a model for widespread modern large-scale applications. To ensure sustainable resource behavior, we introduce a novel method to steer the agents toward a stable population state, fulfilling the given coupled resource constraints. The proposed method is a decentralized resource pricing method based on the resource loads resulting from the augmentation of the game's Lagrangian. Assuming that the online learning agents have only noisy first-order utility feedback, we show that for a polynomially decaying agents' step size/learning rate, the population's dynamic will almost surely converge to generalized Nash equilibrium. A particular consequence of the latter is the fulfillment of resource constraints in the asymptotic limit. Moreover, we investigate the finite-time quality of the proposed algorithm by giving a nonasymptotic time decaying bound for the expected amount of resource constraint violation.",
        "published": "2020-10-21T10:11:17Z",
        "link": "http://arxiv.org/abs/2010.10878v1",
        "categories": [
            "math.OC",
            "cs.GT",
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "On Information Asymmetry in Competitive Multi-Agent Reinforcement   Learning: Convergence and Optimality",
        "authors": [
            "Ezra Tampubolon",
            "Haris Ceribasic",
            "Holger Boche"
        ],
        "summary": "In this work, we study the system of interacting non-cooperative two Q-learning agents, where one agent has the privilege of observing the other's actions. We show that this information asymmetry can lead to a stable outcome of population learning, which generally does not occur in an environment of general independent learners. The resulting post-learning policies are almost optimal in the underlying game sense, i.e., they form a Nash equilibrium. Furthermore, we propose in this work a Q-learning algorithm, requiring predictive observation of two subsequent opponent's actions, yielding an optimal strategy given that the latter applies a stationary strategy, and discuss the existence of the Nash equilibrium in the underlying information asymmetrical game.",
        "published": "2020-10-21T11:19:53Z",
        "link": "http://arxiv.org/abs/2010.10901v2",
        "categories": [
            "cs.LG",
            "cs.GT",
            "cs.MA",
            "cs.SY",
            "econ.TH",
            "eess.SY"
        ]
    },
    {
        "title": "I-nteract 2.0: A Cyber-Physical System to Design 3D Models using Mixed   Reality Technologies and Deep Learning for Additive Manufacturing",
        "authors": [
            "Ammar Malik",
            "Hugo Lhachemi",
            "Robert Shorten"
        ],
        "summary": "I-nteract is a cyber-physical system that enables real-time interaction with both virtual and real artifacts to design 3D models for additive manufacturing by leveraging on mixed reality technologies. This paper presents novel advances in the development of the interaction platform I-nteract to generate 3D models using both constructive solid geometry and artificial intelligence. The system also enables the user to adjust the dimensions of the 3D models with respect to their physical workspace. The effectiveness of the system is demonstrated by generating 3D models of furniture (e.g., chairs and tables) and fitting them into the physical space in a mixed reality environment.",
        "published": "2020-10-21T14:13:21Z",
        "link": "http://arxiv.org/abs/2010.11025v1",
        "categories": [
            "cs.HC",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "MADER: Trajectory Planner in Multi-Agent and Dynamic Environments",
        "authors": [
            "Jesus Tordesillas",
            "Jonathan P. How"
        ],
        "summary": "This paper presents MADER, a 3D decentralized and asynchronous trajectory planner for UAVs that generates collision-free trajectories in environments with static obstacles, dynamic obstacles, and other planning agents. Real-time collision avoidance with other dynamic obstacles or agents is done by performing outer polyhedral representations of every interval of the trajectories and then including the plane that separates each pair of polyhedra as a decision variable in the optimization problem. MADER uses our recently developed MINVO basis to obtain outer polyhedral representations with volumes 2.36 and 254.9 times, respectively, smaller than the Bernstein or B-Spline bases used extensively in the planning literature. Our decentralized and asynchronous algorithm guarantees safety with respect to other agents by including their committed trajectories as constraints in the optimization and then executing a collision check-recheck scheme. Finally, extensive simulations in challenging cluttered environments show up to a 33.9% reduction in the flight time, and a 88.8% reduction in the number of stops compared to the Bernstein and B-Spline bases, shorter flight distances than centralized approaches, and shorter total times on average than synchronous decentralized approaches.",
        "published": "2020-10-21T15:10:12Z",
        "link": "http://arxiv.org/abs/2010.11061v2",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "A Decentralised Self-Healing Approach for Network Topology Maintenance",
        "authors": [
            "Arles Rodríguez",
            "Jonatan Gómez",
            "Ada Diaconescu"
        ],
        "summary": "In many distributed systems, from cloud to sensor networks, different configurations impact system performance, while strongly depending on the network topology. Hence, topological changes may entail costly reconfiguration and optimisation processes. This paper proposes a multi-agent solution for recovering networks from node failures. To preserve the network topology, the proposed approach relies on local information about the network's structure, which is collected and disseminated at runtime. The paper studies two strategies for distributing topological data: one based on Mobile Agents (our proposal) and the other based on Trickle (a reference gossiping protocol from the literature). These two strategies were adapted for our self-healing approach to collect topological information for recovering the network; and were evaluated in terms of resource overheads. Experimental results show that both variants can recover the network topology, up to a certain node failure rate, which depends on the network topology. At the same time, Mobile Agents collect less information, focusing on local dissemination, which suffices for network recovery. This entails less bandwidth overheads than when Trickle is used. Still, Mobile Agents utilise more memory and exchange more messages, during data-collection, than Trickle does. These results validate the viability of the proposed self-healing solution, offering two variant implementations with diverse performance characteristics, which may suit different application domains.",
        "published": "2020-10-21T17:02:38Z",
        "link": "http://arxiv.org/abs/2010.11146v1",
        "categories": [
            "cs.MA",
            "cs.DC",
            "I.2.11"
        ]
    },
    {
        "title": "Heterogeneous Vehicle Routing and Teaming with Gaussian Distributed   Energy Uncertainty",
        "authors": [
            "Bo Fu",
            "William Smith",
            "Denise Rizzo",
            "Matthew Castanier",
            "Kira Barton"
        ],
        "summary": "For robot swarms operating on complex missions in an uncertain environment, it is important that the decision-making algorithm considers both heterogeneity and uncertainty. This paper presents a stochastic programming framework for the vehicle routing problem with stochastic travel energy costs and heterogeneous vehicles and tasks. We represent the heterogeneity as linear constraints, estimate the uncertain energy cost through Gaussian process regression, formulate this stochasticity as chance constraints or stochastic recourse costs, and then solve the stochastic programs using branch and cut algorithms to minimize the expected energy cost. The performance and practicality are demonstrated through extensive computational experiments and a practical test case.",
        "published": "2020-10-22T01:52:57Z",
        "link": "http://arxiv.org/abs/2010.11376v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Differentially-Private Federated Linear Bandits",
        "authors": [
            "Abhimanyu Dubey",
            "Alex Pentland"
        ],
        "summary": "The rapid proliferation of decentralized learning systems mandates the need for differentially-private cooperative learning. In this paper, we study this in context of the contextual linear bandit: we consider a collection of agents cooperating to solve a common contextual bandit, while ensuring that their communication remains private. For this problem, we devise \\textsc{FedUCB}, a multiagent private algorithm for both centralized and decentralized (peer-to-peer) federated learning. We provide a rigorous technical analysis of its utility in terms of regret, improving several results in cooperative bandit learning, and provide rigorous privacy guarantees as well. Our algorithms provide competitive performance both in terms of pseudoregret bounds and empirical benchmark performance in various multi-agent settings.",
        "published": "2020-10-22T03:58:39Z",
        "link": "http://arxiv.org/abs/2010.11425v1",
        "categories": [
            "cs.LG",
            "cs.CR",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Research Needed in Computational Social Science for Power System   Reliability, Resilience, and Restoration",
        "authors": [
            "Jaber Valinejad",
            "Lamine Mili",
            "Natalie van der Wal"
        ],
        "summary": "In the literature, smart grids are modeled as cyber-physical power systems without considering the computational social aspects. However, end-users are playing a key role in their operation and response to disturbances via demand response and distributed energy resources. Therefore, due to the critical role of active and passive end-users and the intermittency of renewable energy, smart grids must be planned and operated by considering the computational social aspects in addition to the technical aspects. The level of cooperation, flexibility, and other social features of the various stakeholders, including consumers, prosumers, and microgrids, affect the system efficiency, reliability, and resilience. In this paper, we design an artificial society simulating the interaction between power systems and the social communities that they serve via agent-based modeling inspired by Barsade's theory on the emotional spread. The simulation results show a decline in the consumers' and prosumers' satisfaction levels induced by a shortage of electricity. It also shows the effects of social diffusion via the Internet and mass media on the satisfaction level. In view of the importance of computational social science for power system applications and the limited number of publications devoted to it, we provide a list of research topics that need to be achieved to enhance the reliability and resilience of power systems' operation and planning.",
        "published": "2020-10-22T04:39:15Z",
        "link": "http://arxiv.org/abs/2011.08064v1",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "A simulation-based evaluation of a Cargo-Hitching service for E-commerce   using mobility-on-demand vehicles",
        "authors": [
            "Andre Alho",
            "Takanori Sakai",
            "Simon Oh",
            "Cheng Cheng",
            "Ravi Seshadri",
            "Wen Han Chong",
            "Yusuke Hara",
            "Julia Caravias",
            "Lynette Cheah",
            "Moshe Ben-Akiva"
        ],
        "summary": "Time-sensitive parcel deliveries, shipments requested for delivery in a day or less, are an increasingly important research subject. It is challenging to deal with these deliveries from a carrier perspective since it entails additional planning constraints, preventing an efficient consolidation of deliveries which is possible when demand is well known in advance. Furthermore, such time-sensitive deliveries are requested to a wider spatial scope than retail centers, including homes and offices. Therefore, an increase in such deliveries is considered to exacerbate negative externalities such as congestion and emissions. One of the solutions is to leverage spare capacity in passenger transport modes. This concept is often denominated as cargo-hitching. While there are various possible system designs, it is crucial that such solution does not deteriorate the quality of service of passenger trips. This research aims to evaluate the use of Mobility-On-Demand services to perform same-day parcel deliveries. For this purpose, we use SimMobility, a high-resolution agent-based simulation platform of passenger and freight flows, applied in Singapore. E-commerce demand carrier data are used to characterize simulated parcel delivery demand. Operational scenarios that aim to minimize the adverse effect of fulfilling deliveries with Mobility-On-Demand vehicles on Mobility-On-Demand passenger flows (fulfillment, wait and travel times) are explored. Results indicate that the Mobility-On-Demand services have potential to fulfill a considerable amount of parcel deliveries and decrease freight vehicle traffic and total vehicle-kilometers-travelled without compromising the quality of Mobility On-Demand for passenger travel.",
        "published": "2020-10-22T10:35:31Z",
        "link": "http://arxiv.org/abs/2010.11585v1",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Multi-agent active perception with prediction rewards",
        "authors": [
            "Mikko Lauri",
            "Frans A. Oliehoek"
        ],
        "summary": "Multi-agent active perception is a task where a team of agents cooperatively gathers observations to compute a joint estimate of a hidden variable. The task is decentralized and the joint estimate can only be computed after the task ends by fusing observations of all agents. The objective is to maximize the accuracy of the estimate. The accuracy is quantified by a centralized prediction reward determined by a centralized decision-maker who perceives the observations gathered by all agents after the task ends. In this paper, we model multi-agent active perception as a decentralized partially observable Markov decision process (Dec-POMDP) with a convex centralized prediction reward. We prove that by introducing individual prediction actions for each agent, the problem is converted into a standard Dec-POMDP with a decentralized prediction reward. The loss due to decentralization is bounded, and we give a sufficient condition for when it is zero. Our results allow application of any Dec-POMDP solution algorithm to multi-agent active perception problems, and enable planning to reduce uncertainty without explicit computation of joint estimates. We demonstrate the empirical usefulness of our results by applying a standard Dec-POMDP algorithm to multi-agent active perception problems, showing increased scalability in the planning horizon.",
        "published": "2020-10-22T16:10:15Z",
        "link": "http://arxiv.org/abs/2010.11835v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Graph-Homomorphic Perturbations for Private Decentralized Learning",
        "authors": [
            "Stefan Vlaski",
            "Ali H. Sayed"
        ],
        "summary": "Decentralized algorithms for stochastic optimization and learning rely on the diffusion of information as a result of repeated local exchanges of intermediate estimates. Such structures are particularly appealing in situations where agents may be hesitant to share raw data due to privacy concerns. Nevertheless, in the absence of additional privacy-preserving mechanisms, the exchange of local estimates, which are generated based on private data can allow for the inference of the data itself. The most common mechanism for guaranteeing privacy is the addition of perturbations to local estimates before broadcasting. These perturbations are generally chosen independently at every agent, resulting in a significant performance loss. We propose an alternative scheme, which constructs perturbations according to a particular nullspace condition, allowing them to be invisible (to first order in the step-size) to the network centroid, while preserving privacy guarantees. The analysis allows for general nonconvex loss functions, and is hence applicable to a large number of machine learning and signal processing problems, including deep learning.",
        "published": "2020-10-23T10:35:35Z",
        "link": "http://arxiv.org/abs/2010.12288v1",
        "categories": [
            "cs.LG",
            "cs.DC",
            "cs.MA",
            "eess.SP",
            "math.OC"
        ]
    },
    {
        "title": "Network Classifiers Based on Social Learning",
        "authors": [
            "Virginia Bordignon",
            "Stefan Vlaski",
            "Vincenzo Matta",
            "Ali H. Sayed"
        ],
        "summary": "This work proposes a new way of combining independently trained classifiers over space and time. Combination over space means that the outputs of spatially distributed classifiers are aggregated. Combination over time means that the classifiers respond to streaming data during testing and continue to improve their performance even during this phase. By doing so, the proposed architecture is able to improve prediction performance over time with unlabeled data. Inspired by social learning algorithms, which require prior knowledge of the observations distribution, we propose a Social Machine Learning (SML) paradigm that is able to exploit the imperfect models generated during the learning phase. We show that this strategy results in consistent learning with high probability, and it yields a robust structure against poorly trained classifiers. Simulations with an ensemble of feedforward neural networks are provided to illustrate the theoretical results.",
        "published": "2020-10-23T11:18:20Z",
        "link": "http://arxiv.org/abs/2010.12306v2",
        "categories": [
            "eess.SP",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Towards human-agent knowledge fusion (HAKF) in support of distributed   coalition teams",
        "authors": [
            "Dave Braines",
            "Federico Cerutti",
            "Marc Roig Vilamala",
            "Mani Srivastava",
            "Lance Kaplan Alun Preece",
            "Gavin Pearson"
        ],
        "summary": "Future coalition operations can be substantially augmented through agile teaming between human and machine agents, but in a coalition context these agents may be unfamiliar to the human users and expected to operate in a broad set of scenarios rather than being narrowly defined for particular purposes. In such a setting it is essential that the human agents can rapidly build trust in the machine agents through appropriate transparency of their behaviour, e.g., through explanations. The human agents are also able to bring their local knowledge to the team, observing the situation unfolding and deciding which key information should be communicated to the machine agents to enable them to better account for the particular environment. In this paper we describe the initial steps towards this human-agent knowledge fusion (HAKF) environment through a recap of the key requirements, and an explanation of how these can be fulfilled for an example situation. We show how HAKF has the potential to bring value to both human and machine agents working as part of a distributed coalition team in a complex event processing setting with uncertain sources.",
        "published": "2020-10-23T12:10:40Z",
        "link": "http://arxiv.org/abs/2010.12327v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Multi-UAV Path Planning for Wireless Data Harvesting with Deep   Reinforcement Learning",
        "authors": [
            "Harald Bayerlein",
            "Mirco Theile",
            "Marco Caccamo",
            "David Gesbert"
        ],
        "summary": "Harvesting data from distributed Internet of Things (IoT) devices with multiple autonomous unmanned aerial vehicles (UAVs) is a challenging problem requiring flexible path planning methods. We propose a multi-agent reinforcement learning (MARL) approach that, in contrast to previous work, can adapt to profound changes in the scenario parameters defining the data harvesting mission, such as the number of deployed UAVs, number, position and data amount of IoT devices, or the maximum flying time, without the need to perform expensive recomputations or relearn control policies. We formulate the path planning problem for a cooperative, non-communicating, and homogeneous team of UAVs tasked with maximizing collected data from distributed IoT sensor nodes subject to flying time and collision avoidance constraints. The path planning problem is translated into a decentralized partially observable Markov decision process (Dec-POMDP), which we solve through a deep reinforcement learning (DRL) approach, approximating the optimal UAV control policy without prior knowledge of the challenging wireless channel characteristics in dense urban environments. By exploiting a combination of centered global and local map representations of the environment that are fed into convolutional layers of the agents, we show that our proposed network architecture enables the agents to cooperate effectively by carefully dividing the data collection task among themselves, adapt to large complex environments and state spaces, and make movement decisions that balance data collection goals, flight-time efficiency, and navigation constraints. Finally, learning a control policy that generalizes over the scenario parameter space enables us to analyze the influence of individual parameters on collection performance and provide some intuition about system-level benefits.",
        "published": "2020-10-23T14:59:30Z",
        "link": "http://arxiv.org/abs/2010.12461v3",
        "categories": [
            "cs.MA",
            "cs.IT",
            "cs.LG",
            "cs.RO",
            "cs.SY",
            "eess.SY",
            "math.IT"
        ]
    },
    {
        "title": "Predicting Infectiousness for Proactive Contact Tracing",
        "authors": [
            "Yoshua Bengio",
            "Prateek Gupta",
            "Tegan Maharaj",
            "Nasim Rahaman",
            "Martin Weiss",
            "Tristan Deleu",
            "Eilif Muller",
            "Meng Qu",
            "Victor Schmidt",
            "Pierre-Luc St-Charles",
            "Hannah Alsdurf",
            "Olexa Bilanuik",
            "David Buckeridge",
            "Gáetan Marceau Caron",
            "Pierre-Luc Carrier",
            "Joumana Ghosn",
            "Satya Ortiz-Gagne",
            "Chris Pal",
            "Irina Rish",
            "Bernhard Schölkopf",
            "Abhinav Sharma",
            "Jian Tang",
            "Andrew Williams"
        ],
        "summary": "The COVID-19 pandemic has spread rapidly worldwide, overwhelming manual contact tracing in many countries and resulting in widespread lockdowns for emergency containment. Large-scale digital contact tracing (DCT) has emerged as a potential solution to resume economic and social activity while minimizing spread of the virus. Various DCT methods have been proposed, each making trade-offs between privacy, mobility restrictions, and public health. The most common approach, binary contact tracing (BCT), models infection as a binary event, informed only by an individual's test results, with corresponding binary recommendations that either all or none of the individual's contacts quarantine. BCT ignores the inherent uncertainty in contacts and the infection process, which could be used to tailor messaging to high-risk individuals, and prompt proactive testing or earlier warnings. It also does not make use of observations such as symptoms or pre-existing medical conditions, which could be used to make more accurate infectiousness predictions. In this paper, we use a recently-proposed COVID-19 epidemiological simulator to develop and test methods that can be deployed to a smartphone to locally and proactively predict an individual's infectiousness (risk of infecting others) based on their contact history and other information, while respecting strong privacy constraints. Predictions are used to provide personalized recommendations to the individual via an app, as well as to send anonymized messages to the individual's contacts, who use this information to better predict their own infectiousness, an approach we call proactive contact tracing (PCT). We find a deep-learning based PCT method which improves over BCT for equivalent average mobility, suggesting PCT could help in safe re-opening and second-wave prevention.",
        "published": "2020-10-23T17:06:07Z",
        "link": "http://arxiv.org/abs/2010.12536v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "cs.SI"
        ]
    },
    {
        "title": "Mechanism Design for Stable Matching with Contracts in a Dynamic   Manufacturing-as-a-Service (MaaS) Marketplace",
        "authors": [
            "Deepak Pahwa",
            "Umut Dur",
            "Binil Starly"
        ],
        "summary": "Two-sided manufacturing-as-a-service (MaaS) marketplaces connect clients requesting manufacturing services to suppliers providing those services. Matching mechanisms i.e. allocation of clients' orders to suppliers is a key design parameter of the marketplace platform. The platform might perform an allocation to maximize its revenue or optimize for social welfare of all participants. However, individual participants might not get maximum value from their match and reject it to form matches (called blocking groups) themselves, thereby bypassing the platform. This paper considers the bipartite matching problem in MaaS marketplaces in a dynamic environment and proposes approximately stable matching solutions using mechanism design and mathematical programming approaches to limit the formation of blocking groups. Matching is based on non-strict, incomplete and interdependent preferences of participants over contracts enabling negotiations between both sides. Empirical simulations are used to test the mechanisms in a simulated 3D printing marketplace and to evaluate the impact of stability on its performance. It is found that stable matching results in small degradation in social welfare of the marketplace. However, it leads to a significantly better outcome in terms of stability of allocation. Unstable matchings introduce anarchy into marketplace with participants rejecting its allocation leading to performance poorer than stable matchings.",
        "published": "2020-10-24T03:35:11Z",
        "link": "http://arxiv.org/abs/2010.12761v1",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Federated Bandit: A Gossiping Approach",
        "authors": [
            "Zhaowei Zhu",
            "Jingxuan Zhu",
            "Ji Liu",
            "Yang Liu"
        ],
        "summary": "In this paper, we study \\emph{Federated Bandit}, a decentralized Multi-Armed Bandit problem with a set of $N$ agents, who can only communicate their local data with neighbors described by a connected graph $G$. Each agent makes a sequence of decisions on selecting an arm from $M$ candidates, yet they only have access to local and potentially biased feedback/evaluation of the true reward for each action taken. Learning only locally will lead agents to sub-optimal actions while converging to a no-regret strategy requires a collection of distributed data. Motivated by the proposal of federated learning, we aim for a solution with which agents will never share their local observations with a central entity, and will be allowed to only share a private copy of his/her own information with their neighbors. We first propose a decentralized bandit algorithm Gossip_UCB, which is a coupling of variants of both the classical gossiping algorithm and the celebrated Upper Confidence Bound (UCB) bandit algorithm. We show that Gossip_UCB successfully adapts local bandit learning into a global gossiping process for sharing information among connected agents, and achieves guaranteed regret at the order of $O(\\max\\{ \\texttt{poly}(N,M) \\log T, \\texttt{poly}(N,M)\\log_{\\lambda_2^{-1}} N\\})$ for all $N$ agents, where $\\lambda_2\\in(0,1)$ is the second largest eigenvalue of the expected gossip matrix, which is a function of $G$. We then propose Fed_UCB, a differentially private version of Gossip_UCB, in which the agents preserve $\\epsilon$-differential privacy of their local data while achieving $O(\\max \\{\\frac{\\texttt{poly}(N,M)}{\\epsilon}\\log^{2.5} T, \\texttt{poly}(N,M) (\\log_{\\lambda_2^{-1}} N + \\log T) \\})$ regret.",
        "published": "2020-10-24T03:44:25Z",
        "link": "http://arxiv.org/abs/2010.12763v2",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Collaborative Machine Learning with Incentive-Aware Model Rewards",
        "authors": [
            "Rachael Hwee Ling Sim",
            "Yehong Zhang",
            "Mun Choon Chan",
            "Bryan Kian Hsiang Low"
        ],
        "summary": "Collaborative machine learning (ML) is an appealing paradigm to build high-quality ML models by training on the aggregated data from many parties. However, these parties are only willing to share their data when given enough incentives, such as a guaranteed fair reward based on their contributions. This motivates the need for measuring a party's contribution and designing an incentive-aware reward scheme accordingly. This paper proposes to value a party's reward based on Shapley value and information gain on model parameters given its data. Subsequently, we give each party a model as a reward. To formally incentivize the collaboration, we define some desirable properties (e.g., fairness and stability) which are inspired by cooperative game theory but adapted for our model reward that is uniquely freely replicable. Then, we propose a novel model reward scheme to satisfy fairness and trade off between the desirable properties via an adjustable parameter. The value of each party's model reward determined by our scheme is attained by injecting Gaussian noise to the aggregated training data with an optimized noise variance. We empirically demonstrate interesting properties of our scheme and evaluate its performance using synthetic and real-world datasets.",
        "published": "2020-10-24T06:20:55Z",
        "link": "http://arxiv.org/abs/2010.12797v1",
        "categories": [
            "cs.LG",
            "cs.GT",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Optimizing Multi-UAV Deployment in 3D Space to Minimize Task Completion   Time in UAV-Enabled Mobile Edge Computing Systems",
        "authors": [
            "Sujunjie Sun",
            "Guopeng Zhang",
            "Haibo Mei",
            "Kezhi Wang",
            "Kun Yang"
        ],
        "summary": "In Unmanned Aerial Vehicle (UAV)-enabled mobile edge computing (MEC) systems, UAVs can carry edge servers to help ground user equipment (UEs) offloading their computing tasks to the UAVs for execution. This paper aims to minimize the total time required for the UAVs to complete the offloaded tasks, while optimizing the three-dimensional (3D) deployment of UAVs, including their flying height and horizontal positions. Although the formulated optimization is a mixed integer nonlinear programmming, we convert it to a convex problem and develop a successive convex approximation (SCA) based algorithm to effectively solve it. The simulation results show that the joint optimization of the horizontal and the vertical position of a group of UAVs can achieve better performance than the traditional algorithms.",
        "published": "2020-10-24T12:51:05Z",
        "link": "http://arxiv.org/abs/2010.12894v1",
        "categories": [
            "cs.MA",
            "eess.SP"
        ]
    },
    {
        "title": "Trading Strategies of a Leveraged ETF in a Continuous Double Auction   Market Using an Agent-Based Simulation",
        "authors": [
            "Isao Yagi",
            "Shunya Maruyama",
            "Takanobu Mizuta"
        ],
        "summary": "A leveraged ETF is a fund aimed at achieving a rate of return several times greater than that of the underlying asset such as Nikkei 225 futures. Recently, it has been suggested that rebalancing trades of a leveraged ETF may destabilize the financial markets. An empirical study using an agent-based simulation indicated that a rebalancing trade strategy could affect the price formation of an underlying asset market. However, no leveraged ETF trading method for suppressing the increase in volatility as much as possible has yet been proposed. In this paper, we compare different strategies of trading for a proposed trading model and report the results of our investigation regarding how best to suppress an increase in market volatility. As a result, it was found that as the minimum number of orders in a rebalancing trade increases, the impact on the market price formation decreases.",
        "published": "2020-10-25T05:04:20Z",
        "link": "http://arxiv.org/abs/2010.13036v1",
        "categories": [
            "q-fin.TR",
            "cs.MA"
        ]
    },
    {
        "title": "Analysis of the Impact of High-Frequency Trading on Artificial Market   Liquidity",
        "authors": [
            "Isao Yagi",
            "Yuji Masuda",
            "Takanobu Mizuta"
        ],
        "summary": "Many empirical studies have discussed market liquidity, which is regarded as a measure of a booming financial market. Further, various indicators for objectively evaluating market liquidity have also been proposed and their merits have been discussed. In recent years, the impact of high-frequency traders (HFTs) on financial markets has been a focal concern, but no studies have systematically discussed their relationship with major market liquidity indicators, including volume, tightness, resiliency, and depth. In this study, we used agent-based simulations to compare the major liquidity indicators in an artificial market where an HFT participated was compared to one where no HFT participated. The results showed that all liquidity indicators in the market where an HFT participated improved more than those in the market where no HFT participated. Furthermore, as a result of investigating the correlations between the major liquidity indicators in our simulations and the extant empirical literature, we found that market liquidity can be measured not only by the major liquidity indicators but also by execution rate. Therefore, it is suggested that it could be appropriate to employ execution rate as a novel liquidity indicator in future studies.",
        "published": "2020-10-25T05:11:13Z",
        "link": "http://arxiv.org/abs/2010.13038v1",
        "categories": [
            "q-fin.TR",
            "cs.MA"
        ]
    },
    {
        "title": "Gramian-Based Adaptive Combination Policies for Diffusion Learning over   Networks",
        "authors": [
            "Y. Efe Erginbas",
            "Stefan Vlaski",
            "Ali H. Sayed"
        ],
        "summary": "This paper presents an adaptive combination strategy for distributed learning over diffusion networks. Since learning relies on the collaborative processing of the stochastic information at the dispersed agents, the overall performance can be improved by designing combination policies that adjust the weights according to the quality of the data. Such policies are important because they would add a new degree of freedom and endow multi-agent systems with the ability to control the flow of information over their edges for enhanced performance. Most adaptive and static policies available in the literature optimize certain performance metrics related to steady-state behavior, to the detriment of transient behavior. In contrast, we develop an adaptive combination rule that aims at optimizing the transient learning performance, while maintaining the enhanced steady-state performance obtained using policies previously developed in the literature.",
        "published": "2020-10-25T12:26:26Z",
        "link": "http://arxiv.org/abs/2010.13104v1",
        "categories": [
            "cs.MA",
            "cs.DC",
            "eess.SP"
        ]
    },
    {
        "title": "Learning Multi-Agent Coordination for Enhancing Target Coverage in   Directional Sensor Networks",
        "authors": [
            "Jing Xu",
            "Fangwei Zhong",
            "Yizhou Wang"
        ],
        "summary": "Maximum target coverage by adjusting the orientation of distributed sensors is an important problem in directional sensor networks (DSNs). This problem is challenging as the targets usually move randomly but the coverage range of sensors is limited in angle and distance. Thus, it is required to coordinate sensors to get ideal target coverage with low power consumption, e.g. no missing targets or reducing redundant coverage. To realize this, we propose a Hierarchical Target-oriented Multi-Agent Coordination (HiT-MAC), which decomposes the target coverage problem into two-level tasks: targets assignment by a coordinator and tracking assigned targets by executors. Specifically, the coordinator periodically monitors the environment globally and allocates targets to each executor. In turn, the executor only needs to track its assigned targets. To effectively learn the HiT-MAC by reinforcement learning, we further introduce a bunch of practical methods, including a self-attention module, marginal contribution approximation for the coordinator, goal-conditional observation filter for the executor, etc. Empirical results demonstrate the advantage of HiT-MAC in coverage rate, learning efficiency,and scalability, comparing to baselines. We also conduct an ablative analysis on the effectiveness of the introduced components in the framework.",
        "published": "2020-10-25T13:07:03Z",
        "link": "http://arxiv.org/abs/2010.13110v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Pooling for First and Last Mile: Integrating Carpooling and Transit",
        "authors": [
            "Andrea Araldo",
            "André de Palma",
            "Souhila Arib",
            "Vincent Gauthier",
            "Romain Sere",
            "Youssef Chaabouni",
            "Oussama Kharouaa",
            "Ado Adamou Abba Ari"
        ],
        "summary": "While carpooling is widely adopted for long travels, it is by construction inefficient for daily commuting, where it is difficult to match drivers and riders, sharing similar origin, destination and time. To overcome this limitation, we present an Integrated system, which integrates carpooling into transit, in the line of the philosophy of Mobility as a Service. Carpooling acts as feeder to transit and transit stations act as consolidation points, where trips of riders and drivers meet, increasing potential matching. We present algorithms to construct multimodal rider trips (including transit and carpooling legs) and driver detours. Simulation shows that our Integrated system increases transit ridership and reduces auto-dependency, with respect to current practice, in which carpooling and transit are operated separately. Indeed, the Integrated system decreases the number of riders who are left with no feasible travel option and would thus be forced to use private cars. The simulation code is available as open source.",
        "published": "2020-10-26T09:18:21Z",
        "link": "http://arxiv.org/abs/2010.13438v2",
        "categories": [
            "cs.MA",
            "cs.CY",
            "cs.SY",
            "econ.GN",
            "eess.SY",
            "q-fin.EC",
            "90Bxx",
            "J.6"
        ]
    },
    {
        "title": "Distributed Multi-Target Tracking in Camera Networks",
        "authors": [
            "Sara Casao",
            "Abel Naya",
            "Ana C. Murillo",
            "Eduardo Montijano"
        ],
        "summary": "Most recent works on multi-target tracking with multiple cameras focus on centralized systems. In contrast, this paper presents a multi-target tracking approach implemented in a distributed camera network. The advantages of distributed systems lie in lighter communication management, greater robustness to failures and local decision making. On the other hand, data association and information fusion are more challenging than in a centralized setup, mostly due to the lack of global and complete information. The proposed algorithm boosts the benefits of the Distributed-Consensus Kalman Filter with the support of a re-identification network and a distributed tracker manager module to facilitate consistent information. These techniques complement each other and facilitate the cross-camera data association in a simple and effective manner. We evaluate the whole system with known public data sets under different conditions demonstrating the advantages of combining all the modules. In addition, we compare our algorithm to some existing centralized tracking methods, outperforming their behavior in terms of accuracy and bandwidth usage.",
        "published": "2020-10-26T16:34:53Z",
        "link": "http://arxiv.org/abs/2010.13701v3",
        "categories": [
            "cs.CV",
            "cs.MA"
        ]
    },
    {
        "title": "LEAD: Min-Max Optimization from a Physical Perspective",
        "authors": [
            "Reyhane Askari Hemmat",
            "Amartya Mitra",
            "Guillaume Lajoie",
            "Ioannis Mitliagkas"
        ],
        "summary": "Adversarial formulations such as generative adversarial networks (GANs) have rekindled interest in two-player min-max games. A central obstacle in the optimization of such games is the rotational dynamics that hinder their convergence. In this paper, we show that game optimization shares dynamic properties with particle systems subject to multiple forces, and one can leverage tools from physics to improve optimization dynamics. Inspired by the physical framework, we propose LEAD, an optimizer for min-max games. Next, using Lyapunov stability theory and spectral analysis, we study LEAD's convergence properties in continuous and discrete time settings for a class of quadratic min-max games to demonstrate linear convergence to the Nash equilibrium. Finally, we empirically evaluate our method on synthetic setups and CIFAR-10 image generation to demonstrate improvements in GAN training.",
        "published": "2020-10-26T19:01:49Z",
        "link": "http://arxiv.org/abs/2010.13846v4",
        "categories": [
            "cs.LG",
            "cs.GT",
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "Computing Nash Equilibria in Multiplayer DAG-Structured Stochastic Games   with Persistent Imperfect Information",
        "authors": [
            "Sam Ganzfried"
        ],
        "summary": "Many important real-world settings contain multiple players interacting over an unknown duration with probabilistic state transitions, and are naturally modeled as stochastic games. Prior research on algorithms for stochastic games has focused on two-player zero-sum games, games with perfect information, and games with imperfect-information that is local and does not extend between game states. We present an algorithm for approximating Nash equilibrium in multiplayer general-sum stochastic games with persistent imperfect information that extends throughout game play. We experiment on a 4-player imperfect-information naval strategic planning scenario. Using a new procedure, we are able to demonstrate that our algorithm computes a strategy that closely approximates Nash equilibrium in this game.",
        "published": "2020-10-26T19:27:26Z",
        "link": "http://arxiv.org/abs/2010.13860v2",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.CR",
            "cs.MA"
        ]
    },
    {
        "title": "Succinct and Robust Multi-Agent Communication With Temporal Message   Control",
        "authors": [
            "Sai Qian Zhang",
            "Jieyu Lin",
            "Qi Zhang"
        ],
        "summary": "Recent studies have shown that introducing communication between agents can significantly improve overall performance in cooperative Multi-agent reinforcement learning (MARL). However, existing communication schemes often require agents to exchange an excessive number of messages at run-time under a reliable communication channel, which hinders its practicality in many real-world situations. In this paper, we present \\textit{Temporal Message Control} (TMC), a simple yet effective approach for achieving succinct and robust communication in MARL. TMC applies a temporal smoothing technique to drastically reduce the amount of information exchanged between agents. Experiments show that TMC can significantly reduce inter-agent communication overhead without impacting accuracy. Furthermore, TMC demonstrates much better robustness against transmission loss than existing approaches in lossy networking environments.",
        "published": "2020-10-27T15:55:08Z",
        "link": "http://arxiv.org/abs/2010.14391v2",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Assured Autonomy: Path Toward Living With Autonomous Systems We Can   Trust",
        "authors": [
            "Ufuk Topcu",
            "Nadya Bliss",
            "Nancy Cooke",
            "Missy Cummings",
            "Ashley Llorens",
            "Howard Shrobe",
            "Lenore Zuck"
        ],
        "summary": "The challenge of establishing assurance in autonomy is rapidly attracting increasing interest in the industry, government, and academia. Autonomy is a broad and expansive capability that enables systems to behave without direct control by a human operator. To that end, it is expected to be present in a wide variety of systems and applications. A vast range of industrial sectors, including (but by no means limited to) defense, mobility, health care, manufacturing, and civilian infrastructure, are embracing the opportunities in autonomy yet face the similar barriers toward establishing the necessary level of assurance sooner or later. Numerous government agencies are poised to tackle the challenges in assured autonomy.   Given the already immense interest and investment in autonomy, a series of workshops on Assured Autonomy was convened to facilitate dialogs and increase awareness among the stakeholders in the academia, industry, and government. This series of three workshops aimed to help create a unified understanding of the goals for assured autonomy, the research trends and needs, and a strategy that will facilitate sustained progress in autonomy.   The first workshop, held in October 2019, focused on current and anticipated challenges and problems in assuring autonomous systems within and across applications and sectors. The second workshop held in February 2020, focused on existing capabilities, current research, and research trends that could address the challenges and problems identified in workshop. The third event was dedicated to a discussion of a draft of the major findings from the previous two workshops and the recommendations.",
        "published": "2020-10-27T17:00:01Z",
        "link": "http://arxiv.org/abs/2010.14443v1",
        "categories": [
            "cs.CY",
            "cs.AI",
            "cs.HC",
            "cs.MA"
        ]
    },
    {
        "title": "A Genetic Algorithm Based Approach for Satellite Autonomy",
        "authors": [
            "Sidhdharth Sikka",
            "Harshvardhan Sikka"
        ],
        "summary": "Autonomous spacecraft maneuver planning using an evolutionary algorithmic approach is investigated. Simulated spacecraft were placed into four different initial orbits. Each was allowed a string of thirty delta-v impulse maneuvers in six cartesian directions, the positive and negative x, y and z directions. The goal of the spacecraft maneuver string was to, starting from some non-polar starting orbit, place the spacecraft into a polar, low eccentricity orbit. A genetic algorithm was implemented, using a mating, fitness, mutation and crossover scheme for impulse strings. The genetic algorithm was successfully able to produce this result for all the starting orbits. Performance and future work is also discussed.",
        "published": "2020-10-27T20:41:30Z",
        "link": "http://arxiv.org/abs/2011.05281v2",
        "categories": [
            "cs.NE",
            "cs.AI",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Collective Awareness for Abnormality Detection in Connected Autonomous   Vehicles",
        "authors": [
            "Divya Thekke Kanapram",
            "Fabio Patrone",
            "Pablo Marin-Plaza",
            "Mario Marchese",
            "Eliane L. Bodanese",
            "Lucio Marcenaro",
            "David Martín Gómez",
            "Carlo Regazzoni"
        ],
        "summary": "The advancements in connected and autonomous vehicles in these times demand the availability of tools providing the agents with the capability to be aware and predict their own states and context dynamics. This article presents a novel approach to develop an initial level of collective awareness in a network of intelligent agents. A specific collective self awareness functionality is considered, namely, agent centered detection of abnormal situations present in the environment around any agent in the network. Moreover, the agent should be capable of analyzing how such abnormalities can influence the future actions of each agent. Data driven dynamic Bayesian network (DBN) models learned from time series of sensory data recorded during the realization of tasks (agent network experiences) are here used for abnormality detection and prediction. A set of DBNs, each related to an agent, is used to allow the agents in the network to each synchronously aware possible abnormalities occurring when available models are used on a new instance of the task for which DBNs have been learned. A growing neural gas (GNG) algorithm is used to learn the node variables and conditional probabilities linking nodes in the DBN models; a Markov jump particle filter (MJPF) is employed for state estimation and abnormality detection in each agent using learned DBNs as filter parameters. Performance metrics are discussed to asses the algorithms reliability and accuracy. The impact is also evaluated by the communication channel used by the network to share the data sensed in a distributed way by each agent of the network. The IEEE 802.11p protocol standard has been considered for communication among agents. Real data sets are also used acquired by autonomous vehicles performing different tasks in a controlled environment.",
        "published": "2020-10-28T12:11:36Z",
        "link": "http://arxiv.org/abs/2010.14908v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "eess.SP"
        ]
    },
    {
        "title": "Self-awareness in intelligent vehicles: Feature based dynamic Bayesian   models for abnormality detection",
        "authors": [
            "Divya Thekke Kanapram",
            "Pablo Marin-Plaza",
            "Lucio Marcenaro",
            "David Martin",
            "Arturo de la Escalera",
            "Carlo Regazzoni"
        ],
        "summary": "The evolution of Intelligent Transportation Systems in recent times necessitates the development of self-awareness in agents. Before the intensive use of Machine Learning, the detection of abnormalities was manually programmed by checking every variable and creating huge nested conditions that are very difficult to track. This paper aims to introduce a novel method to develop self-awareness in autonomous vehicles that mainly focuses on detecting abnormal situations around the considered agents. Multi-sensory time-series data from the vehicles are used to develop the data-driven Dynamic Bayesian Network (DBN) models used for future state prediction and the detection of dynamic abnormalities. Moreover, an initial level collective awareness model that can perform joint anomaly detection in co-operative tasks is proposed. The GNG algorithm learns the DBN models' discrete node variables; probabilistic transition links connect the node variables. A Markov Jump Particle Filter (MJPF) is applied to predict future states and detect when the vehicle is potentially misbehaving using learned DBNs as filter parameters. In this paper, datasets from real experiments of autonomous vehicles performing various tasks used to learn and test a set of switching DBN models.",
        "published": "2020-10-29T09:29:47Z",
        "link": "http://arxiv.org/abs/2010.15441v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "eess.SP"
        ]
    },
    {
        "title": "Exploring Zero-Shot Emergent Communication in Embodied Multi-Agent   Populations",
        "authors": [
            "Kalesha Bullard",
            "Franziska Meier",
            "Douwe Kiela",
            "Joelle Pineau",
            "Jakob Foerster"
        ],
        "summary": "Effective communication is an important skill for enabling information exchange and cooperation in multi-agent settings. Indeed, emergent communication is now a vibrant field of research, with common settings involving discrete cheap-talk channels. One limitation of this setting is that it does not allow for the emergent protocols to generalize beyond the training partners. Furthermore, so far emergent communication has primarily focused on the use of symbolic channels. In this work, we extend this line of work to a new modality, by studying agents that learn to communicate via actuating their joints in a 3D environment. We show that under realistic assumptions, a non-uniform distribution of intents and a common-knowledge energy cost, these agents can find protocols that generalize to novel partners. We also explore and analyze specific difficulties associated with finding these solutions in practice. Finally, we propose and evaluate initial training improvements to address these challenges, involving both specific training curricula and providing the latent feature that can be coordinated on during training.",
        "published": "2020-10-29T19:23:10Z",
        "link": "http://arxiv.org/abs/2010.15896v2",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "COVI-AgentSim: an Agent-based Model for Evaluating Methods of Digital   Contact Tracing",
        "authors": [
            "Prateek Gupta",
            "Tegan Maharaj",
            "Martin Weiss",
            "Nasim Rahaman",
            "Hannah Alsdurf",
            "Abhinav Sharma",
            "Nanor Minoyan",
            "Soren Harnois-Leblanc",
            "Victor Schmidt",
            "Pierre-Luc St. Charles",
            "Tristan Deleu",
            "Andrew Williams",
            "Akshay Patel",
            "Meng Qu",
            "Olexa Bilaniuk",
            "Gaétan Marceau Caron",
            "Pierre Luc Carrier",
            "Satya Ortiz-Gagné",
            "Marc-Andre Rousseau",
            "David Buckeridge",
            "Joumana Ghosn",
            "Yang Zhang",
            "Bernhard Schölkopf",
            "Jian Tang",
            "Irina Rish",
            "Christopher Pal",
            "Joanna Merckx",
            "Eilif B. Muller",
            "Yoshua Bengio"
        ],
        "summary": "The rapid global spread of COVID-19 has led to an unprecedented demand for effective methods to mitigate the spread of the disease, and various digital contact tracing (DCT) methods have emerged as a component of the solution. In order to make informed public health choices, there is a need for tools which allow evaluation and comparison of DCT methods. We introduce an agent-based compartmental simulator we call COVI-AgentSim, integrating detailed consideration of virology, disease progression, social contact networks, and mobility patterns, based on parameters derived from empirical research. We verify by comparing to real data that COVI-AgentSim is able to reproduce realistic COVID-19 spread dynamics, and perform a sensitivity analysis to verify that the relative performance of contact tracing methods are consistent across a range of settings. We use COVI-AgentSim to perform cost-benefit analyses comparing no DCT to: 1) standard binary contact tracing (BCT) that assigns binary recommendations based on binary test results; and 2) a rule-based method for feature-based contact tracing (FCT) that assigns a graded level of recommendation based on diverse individual features. We find all DCT methods consistently reduce the spread of the disease, and that the advantage of FCT over BCT is maintained over a wide range of adoption rates. Feature-based methods of contact tracing avert more disability-adjusted life years (DALYs) per socioeconomic cost (measured by productive hours lost). Our results suggest any DCT method can help save lives, support re-opening of economies, and prevent second-wave outbreaks, and that FCT methods are a promising direction for enriching BCT using self-reported symptoms, yielding earlier warning signals and a significantly reduced spread of the virus per socioeconomic cost.",
        "published": "2020-10-30T00:47:01Z",
        "link": "http://arxiv.org/abs/2010.16004v1",
        "categories": [
            "cs.CY",
            "cs.LG",
            "cs.MA",
            "cs.SI"
        ]
    },
    {
        "title": "MAPS-X: Explainable Multi-Robot Motion Planning via Segmentation",
        "authors": [
            "Justin Kottinger",
            "Shaull Almagor",
            "Morteza Lahijanian"
        ],
        "summary": "Traditional multi-robot motion planning (MMP) focuses on computing trajectories for multiple robots acting in an environment, such that the robots do not collide when the trajectories are taken simultaneously. In safety-critical applications, a human supervisor may want to verify that the plan is indeed collision-free. In this work, we propose a notion of explanation for a plan of MMP, based on visualization of the plan as a short sequence of images representing time segments, where in each time segment the trajectories of the agents are disjoint, clearly illustrating the safety of the plan. We show that standard notions of optimality (e.g., makespan) may create conflict with short explanations. Thus, we propose meta-algorithms, namely multi-agent plan segmenting-X (MAPS-X) and its lazy variant, that can be plugged on existing centralized sampling-based tree planners X to produce plans with good explanations using a desirable number of images. We demonstrate the efficacy of this explanation-planning scheme and extensively evaluate the performance of MAPS-X.",
        "published": "2020-10-30T07:28:36Z",
        "link": "http://arxiv.org/abs/2010.16106v3",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Exploring Dynamic Context for Multi-path Trajectory Prediction",
        "authors": [
            "Hao Cheng",
            "Wentong Liao",
            "Xuejiao Tang",
            "Michael Ying Yang",
            "Monika Sester",
            "Bodo Rosenhahn"
        ],
        "summary": "To accurately predict future positions of different agents in traffic scenarios is crucial for safely deploying intelligent autonomous systems in the real-world environment. However, it remains a challenge due to the behavior of a target agent being affected by other agents dynamically and there being more than one socially possible paths the agent could take. In this paper, we propose a novel framework, named Dynamic Context Encoder Network (DCENet). In our framework, first, the spatial context between agents is explored by using self-attention architectures. Then, the two-stream encoders are trained to learn temporal context between steps by taking the respective observed trajectories and the extracted dynamic spatial context as input. The spatial-temporal context is encoded into a latent space using a Conditional Variational Auto-Encoder (CVAE) module. Finally, a set of future trajectories for each agent is predicted conditioned on the learned spatial-temporal context by sampling from the latent space, repeatedly. DCENet is evaluated on one of the most popular challenging benchmarks for trajectory forecasting Trajnet and reports a new state-of-the-art performance. It also demonstrates superior performance evaluated on the benchmark inD for mixed traffic at intersections. A series of ablation studies is conducted to validate the effectiveness of each proposed module. Our code is available at https://github.com/wtliao/DCENet.",
        "published": "2020-10-30T13:39:20Z",
        "link": "http://arxiv.org/abs/2010.16267v3",
        "categories": [
            "cs.CV",
            "cs.MA"
        ]
    },
    {
        "title": "Optimizing Mixed Autonomy Traffic Flow With Decentralized Autonomous   Vehicles and Multi-Agent RL",
        "authors": [
            "Eugene Vinitsky",
            "Nathan Lichtle",
            "Kanaad Parvate",
            "Alexandre Bayen"
        ],
        "summary": "We study the ability of autonomous vehicles to improve the throughput of a bottleneck using a fully decentralized control scheme in a mixed autonomy setting. We consider the problem of improving the throughput of a scaled model of the San Francisco-Oakland Bay Bridge: a two-stage bottleneck where four lanes reduce to two and then reduce to one. Although there is extensive work examining variants of bottleneck control in a centralized setting, there is less study of the challenging multi-agent setting where the large number of interacting AVs leads to significant optimization difficulties for reinforcement learning methods. We apply multi-agent reinforcement algorithms to this problem and demonstrate that significant improvements in bottleneck throughput, from 20\\% at a 5\\% penetration rate to 33\\% at a 40\\% penetration rate, can be achieved. We compare our results to a hand-designed feedback controller and demonstrate that our results sharply outperform the feedback controller despite extensive tuning. Additionally, we demonstrate that the RL-based controllers adopt a robust strategy that works across penetration rates whereas the feedback controllers degrade immediately upon penetration rate variation. We investigate the feasibility of both action and observation decentralization and demonstrate that effective strategies are possible using purely local sensing. Finally, we open-source our code at https://github.com/eugenevinitsky/decentralized_bottlenecks.",
        "published": "2020-10-30T22:06:05Z",
        "link": "http://arxiv.org/abs/2011.00120v1",
        "categories": [
            "eess.SY",
            "cs.LG",
            "cs.MA",
            "cs.RO",
            "cs.SY"
        ]
    },
    {
        "title": "FireCommander: An Interactive, Probabilistic Multi-agent Environment for   Heterogeneous Robot Teams",
        "authors": [
            "Esmaeil Seraj",
            "Xiyang Wu",
            "Matthew Gombolay"
        ],
        "summary": "The purpose of this tutorial is to help individuals use the \\underline{FireCommander} game environment for research applications. The FireCommander is an interactive, probabilistic joint perception-action reconnaissance environment in which a composite team of agents (e.g., robots) cooperate to fight dynamic, propagating firespots (e.g., targets). In FireCommander game, a team of agents must be tasked to optimally deal with a wildfire situation in an environment with propagating fire areas and some facilities such as houses, hospitals, power stations, etc. The team of agents can accomplish their mission by first sensing (e.g., estimating fire states), communicating the sensed fire-information among each other and then taking action to put the firespots out based on the sensed information (e.g., dropping water on estimated fire locations). The FireCommander environment can be useful for research topics spanning a wide range of applications from Reinforcement Learning (RL) and Learning from Demonstration (LfD), to Coordination, Psychology, Human-Robot Interaction (HRI) and Teaming. There are four important facets of the FireCommander environment that overall, create a non-trivial game: (1) Complex Objectives: Multi-objective Stochastic Environment, (2)Probabilistic Environment: Agents' actions result in probabilistic performance, (3) Hidden Targets: Partially Observable Environment and, (4) Uni-task Robots: Perception-only and Action-only agents. The FireCommander environment is first-of-its-kind in terms of including Perception-only and Action-only agents for coordination. It is a general multi-purpose game that can be useful in a variety of combinatorial optimization problems and stochastic games, such as applications of Reinforcement Learning (RL), Learning from Demonstration (LfD) and Inverse RL (iRL).",
        "published": "2020-10-31T02:06:07Z",
        "link": "http://arxiv.org/abs/2011.00165v2",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.HC",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "A Policy Gradient Algorithm for Learning to Learn in Multiagent   Reinforcement Learning",
        "authors": [
            "Dong-Ki Kim",
            "Miao Liu",
            "Matthew Riemer",
            "Chuangchuang Sun",
            "Marwa Abdulhai",
            "Golnaz Habibi",
            "Sebastian Lopez-Cot",
            "Gerald Tesauro",
            "Jonathan P. How"
        ],
        "summary": "A fundamental challenge in multiagent reinforcement learning is to learn beneficial behaviors in a shared environment with other simultaneously learning agents. In particular, each agent perceives the environment as effectively non-stationary due to the changing policies of other agents. Moreover, each agent is itself constantly learning, leading to natural non-stationarity in the distribution of experiences encountered. In this paper, we propose a novel meta-multiagent policy gradient theorem that directly accounts for the non-stationary policy dynamics inherent to multiagent learning settings. This is achieved by modeling our gradient updates to consider both an agent's own non-stationary policy dynamics and the non-stationary policy dynamics of other agents in the environment. We show that our theoretically grounded approach provides a general solution to the multiagent learning problem, which inherently comprises all key aspects of previous state of the art approaches on this topic. We test our method on a diverse suite of multiagent benchmarks and demonstrate a more efficient ability to adapt to new agents as they learn than baseline methods across the full spectrum of mixed incentive, competitive, and cooperative domains.",
        "published": "2020-10-31T22:50:21Z",
        "link": "http://arxiv.org/abs/2011.00382v5",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Sample Efficient Training in Multi-Agent Adversarial Games with Limited   Teammate Communication",
        "authors": [
            "Hardik Meisheri",
            "Harshad Khadilkar"
        ],
        "summary": "We describe our solution approach for Pommerman TeamRadio, a competition environment associated with NeurIPS 2019. The defining feature of our algorithm is achieving sample efficiency within a restrictive computational budget while beating the previous years learning agents. The proposed algorithm (i) uses imitation learning to seed the policy, (ii) explicitly defines the communication protocol between the two teammates, (iii) shapes the reward to provide a richer feedback signal to each agent during training and (iv) uses masking for catastrophic bad actions. We describe extensive tests against baselines, including those from the 2019 competition leaderboard, and also a specific investigation of the learned policy and the effect of each modification on performance. We show that the proposed approach is able to achieve competitive performance within half a million games of training, significantly faster than other studies in the literature.",
        "published": "2020-11-01T04:50:02Z",
        "link": "http://arxiv.org/abs/2011.00424v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "CL-MAPF: Multi-Agent Path Finding for Car-Like Robots with Kinematic and   Spatiotemporal Constraints",
        "authors": [
            "Licheng Wen",
            "Zhen Zhang",
            "Zhe Chen",
            "Xiangrui Zhao",
            "Yong Liu"
        ],
        "summary": "Multi-Agent Path Finding has been widely studied in the past few years due to its broad application in the field of robotics and AI. However, previous solvers rely on several simplifying assumptions. They limit their applicability in numerous real-world domains that adopt nonholonomic car-like agents rather than holonomic ones. In this paper, we give a mathematical formalization of Multi-Agent Path Finding for Car-Like robots (CL-MAPF) problem. For the first time, we propose a novel hierarchical search-based solver called Car-like Conflict-Based Search to address this problem. It applies a body conflict tree to address collisions considering shapes of the agents. We introduce a new algorithm called Spatiotemporal Hybrid-State A* as the single-agent path planner to generate path satisfying both kinematic and spatiotemporal constraints. We also present a sequential planning version of our method for the sake of efficiency. We compare our method with two baseline algorithms on a dedicated benchmark containing 3000 instances and validate it in real-world scenarios. The experiment results give clear evidence that our algorithm scales well to a large number of agents and is able to produce solutions that can be directly applied to car-like robots in the real world. The benchmark and source code are released in https://github.com/APRIL-ZJU/CL-CBS.",
        "published": "2020-11-01T06:42:25Z",
        "link": "http://arxiv.org/abs/2011.00441v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Alternating Direction Method of Multipliers for Constrained Iterative   LQR in Autonomous Driving",
        "authors": [
            "Jun Ma",
            "Zilong Cheng",
            "Xiaoxue Zhang",
            "Masayoshi Tomizuka",
            "Tong Heng Lee"
        ],
        "summary": "In the context of autonomous driving, the iterative linear quadratic regulator (iLQR) is known to be an efficient approach to deal with the nonlinear vehicle model in motion planning problems. Particularly, the constrained iLQR algorithm has shown noteworthy advantageous outcomes of computation efficiency in achieving motion planning tasks under general constraints of different types. However, the constrained iLQR methodology requires a feasible trajectory at the first iteration as a prerequisite when the logarithmic barrier function is used. Also, the methodology leaves open the possibility for incorporation of fast, efficient, and effective optimization methods to further speed up the optimization process such that the requirements of real-time implementation can be successfully fulfilled. In this paper, a well-defined motion planning problem is formulated under nonlinear vehicle dynamics and various constraints, and an alternating direction method of multipliers (ADMM) is utilized to determine the optimal control actions leveraging the iLQR. The approach is able to circumvent the feasibility requirement of the trajectory at the first iteration. An illustrative example of motion planning for autonomous vehicles is then investigated. A noteworthy achievement of high computation efficiency is attained with the proposed development; comparing with the constrained iLQR algorithm based on the logarithmic barrier function, our proposed method reduces the average computation time by 31.93%, 38.52%, and 44.57% in the three driving scenarios; compared with the optimization solver IPOPT, our proposed method reduces the average computation time by 46.02%, 53.26%, and 88.43% in the three driving scenarios. As a result, real-time computation and implementation can be realized through our proposed framework, and thus it provides additional safety to the on-road driving tasks.",
        "published": "2020-11-01T10:11:28Z",
        "link": "http://arxiv.org/abs/2011.00462v2",
        "categories": [
            "cs.RO",
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "Improved Hierarchical ADMM for Nonconvex Cooperative Distributed Model   Predictive Control",
        "authors": [
            "Xiaoxue Zhang",
            "Jun Ma",
            "Zilong Cheng",
            "Sunan Huang",
            "Clarence W. de Silva",
            "Tong Heng Lee"
        ],
        "summary": "Distributed optimization is often widely attempted and innovated as an attractive and preferred methodology to solve large-scale problems effectively in a localized and coordinated manner. Thus, it is noteworthy that the methodology of distributed model predictive control (DMPC) has become a promising approach to achieve effective outcomes, e.g., in decision-making tasks for multi-agent systems. However, the typical deployment of such distributed MPC frameworks would lead to the involvement of nonlinear processes with a large number of nonconvex constraints. To address this important problem, the development and innovation of a hierarchical three-block alternating direction method of multipliers (ADMM) approach is presented in this work to solve this nonconvex cooperative DMPC problem in multi-agent systems. Here firstly, an additional slack variable is introduced to transform the original large-scale nonconvex optimization problem. Then, a hierarchical ADMM approach, which contains outer loop iteration by the augmented Lagrangian method (ALM) and inner loop iteration by three-block semi-proximal ADMM, is utilized to solve the resulting transformed nonconvex optimization problem. Additionally, it is analytically shown and established that the requisite desired stationary point exists for convergence in the algorithm. Finally, an approximate optimization stage with a barrier method is then applied to further significantly improve the computational efficiency, yielding the final improved hierarchical ADMM. The effectiveness of the proposed method in terms of attained performance and computational efficiency is demonstrated on a cooperative DMPC problem of decision-making process for multiple unmanned aerial vehicles (UAVs).",
        "published": "2020-11-01T10:19:22Z",
        "link": "http://arxiv.org/abs/2011.00463v3",
        "categories": [
            "math.OC",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Can a Robot Trust You? A DRL-Based Approach to Trust-Driven Human-Guided   Navigation",
        "authors": [
            "Vishnu Sashank Dorbala",
            "Arjun Srinivasan",
            "Aniket Bera"
        ],
        "summary": "Humans are known to construct cognitive maps of their everyday surroundings using a variety of perceptual inputs. As such, when a human is asked for directions to a particular location, their wayfinding capability in converting this cognitive map into directional instructions is challenged. Owing to spatial anxiety, the language used in the spoken instructions can be vague and often unclear. To account for this unreliability in navigational guidance, we propose a novel Deep Reinforcement Learning (DRL) based trust-driven robot navigation algorithm that learns humans' trustworthiness to perform a language guided navigation task. Our approach seeks to answer the question as to whether a robot can trust a human's navigational guidance or not. To this end, we look at training a policy that learns to navigate towards a goal location using only trustworthy human guidance, driven by its own robot trust metric. We look at quantifying various affective features from language-based instructions and incorporate them into our policy's observation space in the form of a human trust metric. We utilize both these trust metrics into an optimal cognitive reasoning scheme that decides when and when not to trust the given guidance. Our results show that the learned policy can navigate the environment in an optimal, time-efficient manner as opposed to an explorative approach that performs the same task. We showcase the efficacy of our results both in simulation and a real-world environment.",
        "published": "2020-11-01T16:43:10Z",
        "link": "http://arxiv.org/abs/2011.00554v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "An Overview of Multi-Agent Reinforcement Learning from Game Theoretical   Perspective",
        "authors": [
            "Yaodong Yang",
            "Jun Wang"
        ],
        "summary": "Following the remarkable success of the AlphaGO series, 2019 was a booming year that witnessed significant advances in multi-agent reinforcement learning (MARL) techniques. MARL corresponds to the learning problem in a multi-agent system in which multiple agents learn simultaneously. It is an interdisciplinary domain with a long history that includes game theory, machine learning, stochastic control, psychology, and optimisation. Although MARL has achieved considerable empirical success in solving real-world games, there is a lack of a self-contained overview in the literature that elaborates the game theoretical foundations of modern MARL methods and summarises the recent advances. In fact, the majority of existing surveys are outdated and do not fully cover the recent developments since 2010. In this work, we provide a monograph on MARL that covers both the fundamentals and the latest developments in the research frontier. The goal of our monograph is to provide a self-contained assessment of the current state-of-the-art MARL techniques from a game theoretical perspective. We expect this work to serve as a stepping stone for both new researchers who are about to enter this fast-growing domain and existing domain experts who want to obtain a panoramic view and identify new directions based on recent advances.",
        "published": "2020-11-01T18:24:40Z",
        "link": "http://arxiv.org/abs/2011.00583v3",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "The Persistence of False Memory: Brain in a Vat Despite Perfect Clocks",
        "authors": [
            "Thomas Schlögl",
            "Ulrich Schmid",
            "Roman Kuznets"
        ],
        "summary": "Recently, a detailed epistemic reasoning framework for multi-agent systems with byzantine faulty asynchronous agents and possibly unreliable communication was introduced. We have developed a modular extension framework implemented on top of it, which allows to encode and safely combine additional system assumptions commonly used in the modeling and analysis of fault-tolerant distributed systems, like reliable communication, time-bounded communication, multicasting, synchronous and lock-step synchronous agents and even agents with coordinated actions. We use this extension framework for analyzing basic properties of synchronous and lock-step synchronous agents, such as the agents' local and global fault detection abilities. Moreover, we show that even the perfectly synchronized clocks available in lock-step synchronous systems cannot be used to avoid \"brain-in-a-vat\" scenarios.",
        "published": "2020-11-02T15:40:13Z",
        "link": "http://arxiv.org/abs/2011.01057v1",
        "categories": [
            "cs.MA",
            "cs.DC",
            "I.2.11"
        ]
    },
    {
        "title": "Multi-IRS-assisted Multi-Cell Uplink MIMO Communications under Imperfect   CSI: A Deep Reinforcement Learning Approach",
        "authors": [
            "Junghoon Kim",
            "Seyyedali Hosseinalipour",
            "Taejoon Kim",
            "David J. Love",
            "Christopher G. Brinton"
        ],
        "summary": "Applications of intelligent reflecting surfaces (IRSs) in wireless networks have attracted significant attention recently. Most of the relevant literature is focused on the single cell setting where a single IRS is deployed and perfect channel state information (CSI) is assumed. In this work, we develop a novel methodology for multi-IRS-assisted multi-cell networks in the uplink. We consider the scenario in which (i) channels are dynamic and (ii) only partial CSI is available at each base station (BS); specifically, scalar effective channel powers from only a subset of user equipments (UE). We formulate the sum-rate maximization problem aiming to jointly optimize the IRS reflect beamformers, BS combiners, and UE transmit powers. In casting this as a sequential decision making problem, we propose a multi-agent deep reinforcement learning algorithm to solve it, where each BS acts as an independent agent in charge of tuning the local UE transmit powers, the local IRS reflect beamformer, and its combiners. We introduce an efficient information-sharing scheme that requires limited information exchange among neighboring BSs to cope with the non-stationarity caused by the coupling of actions taken by multiple BSs. Our numerical results show that our method obtains substantial improvement in average data rate compared to baseline approaches, e.g., fixed UE transmit power and maximum ratio combining.",
        "published": "2020-11-02T17:33:23Z",
        "link": "http://arxiv.org/abs/2011.01141v6",
        "categories": [
            "eess.SP",
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Levels of Coupling in Dyadic Interaction: An Analysis of Neural and   Behavioral Complexity",
        "authors": [
            "Georgina Montserrat Reséndiz-Benhumea",
            "Ekaterina Sangati",
            "Tom Froese"
        ],
        "summary": "From an enactive approach, some previous studies have demonstrated that social interaction plays a fundamental role in the dynamics of neural and behavioral complexity of embodied agents. In particular, it has been shown that agents with a limited internal structure (2-neuron brains) that evolve in interaction can overcome this limitation and exhibit chaotic neural activity, typically associated with more complex dynamical systems (at least 3-dimensional). In the present paper we make two contributions to this line of work. First, we propose a conceptual distinction in levels of coupling between agents that could have an effect on neural and behavioral complexity. Second, we test the generalizability of previous results by testing agents with richer internal structure and evolving them in a richer, yet non-social, environment. We demonstrate that such agents can achieve levels of complexity comparable to agents that evolve in interactive settings. We discuss the significance of this result for the study of interaction.",
        "published": "2020-11-03T14:21:57Z",
        "link": "http://arxiv.org/abs/2011.01727v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Iterative Best Response for Multi-Body Asset-Guarding Games",
        "authors": [
            "Emmanuel Sin",
            "Murat Arcak",
            "Douglas Philbrick",
            "Peter Seiler"
        ],
        "summary": "We present a numerical approach to finding optimal trajectories for players in a multi-body, asset-guarding game with nonlinear dynamics and non-convex constraints. Using the Iterative Best Response (IBR) scheme, we solve for each player's optimal strategy assuming the other players' trajectories are known and fixed. Leveraging recent advances in Sequential Convex Programming (SCP), we use SCP as a subroutine within the IBR algorithm to efficiently solve an approximation of each player's constrained trajectory optimization problem. We apply the approach to an asset-guarding game example involving multiple pursuers and a single evader (i.e., n-versus-1 engagements). Resulting evader trajectories are tested in simulation to verify successful evasion against pursuers using conventional intercept guidance laws.",
        "published": "2020-11-03T18:11:45Z",
        "link": "http://arxiv.org/abs/2011.01893v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Moving Forward in Formation: A Decentralized Hierarchical Learning   Approach to Multi-Agent Moving Together",
        "authors": [
            "Shanqi Liu",
            "Licheng Wen",
            "Jinhao Cui",
            "Xuemeng Yang",
            "Junjie Cao",
            "Yong Liu"
        ],
        "summary": "Multi-agent path finding in formation has many potential real-world applications like mobile warehouse robots. However, previous multi-agent path finding (MAPF) methods hardly take formation into consideration. Furthermore, they are usually centralized planners and require the whole state of the environment. Other decentralized partially observable approaches to MAPF are reinforcement learning (RL) methods. However, these RL methods encounter difficulties when learning path finding and formation problem at the same time. In this paper, we propose a novel decentralized partially observable RL algorithm that uses a hierarchical structure to decompose the multi objective task into unrelated ones. It also calculates a theoretical weight that makes every task reward has equal influence on the final RL value function. Additionally, we introduce a communication method that helps agents cooperate with each other. Experiments in simulation show that our method outperforms other end-to-end RL methods and our method can naturally scale to large world sizes where centralized planner struggles. We also deploy and validate our method in a real world scenario.",
        "published": "2020-11-04T16:05:07Z",
        "link": "http://arxiv.org/abs/2011.02373v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Asynchrony and Acceleration in Gossip Algorithms",
        "authors": [
            "Mathieu Even",
            "Hadrien Hendrikx",
            "Laurent Massoulié"
        ],
        "summary": "This paper considers the minimization of a sum of smooth and strongly convex functions dispatched over the nodes of a communication network. Previous works on the subject either focus on synchronous algorithms, which can be heavily slowed down by a few slow nodes (the straggler problem), or consider a model of asynchronous operation (Boyd et al., 2006) in which adjacent nodes communicate at the instants of Poisson point processes. We have two main contributions. 1) We propose CACDM (a Continuously Accelerated Coordinate Dual Method), and for the Poisson model of asynchronous operation, we prove CACDM to converge to optimality at an accelerated convergence rate in the sense of Nesterov et Stich, 2017. In contrast, previously proposed asynchronous algorithms have not been proven to achieve such accelerated rate. While CACDM is based on discrete updates, the proof of its convergence crucially depends on a continuous time analysis. 2) We introduce a new communication scheme based on Loss-Networks, that is programmable in a fully asynchronous and decentralized way, unlike the Poisson model of asynchronous operation that does not capture essential aspects of asynchrony such as non-instantaneous communications and computations. Under this Loss-Network model of asynchrony, we establish for CDM (a Coordinate Dual Method) a rate of convergence in terms of the eigengap of the Laplacian of the graph weighted by local effective delays. We believe this eigengap to be a fundamental bottleneck for convergence rates of asynchronous optimization. Finally, we verify empirically that CACDM enjoys an accelerated convergence rate in the Loss-Network model of asynchrony.",
        "published": "2020-11-04T16:15:32Z",
        "link": "http://arxiv.org/abs/2011.02379v2",
        "categories": [
            "cs.DC",
            "cs.MA",
            "math.OC",
            "68Q87, 60G55, 90-10"
        ]
    },
    {
        "title": "Social Choice with Changing Preferences: Representation Theorems and   Long-Run Policies",
        "authors": [
            "Kshitij Kulkarni",
            "Sven Neth"
        ],
        "summary": "We study group decision making with changing preferences as a Markov Decision Process. We are motivated by the increasing prevalence of automated decision-making systems when making choices for groups of people over time. Our main contribution is to show how classic representation theorems from social choice theory can be adapted to characterize optimal policies in this dynamic setting. We provide an axiomatic characterization of MDP reward functions that agree with the Utilitarianism social welfare functionals of social choice theory. We also provide discussion of cases when the implementation of social choice-theoretic axioms may fail to lead to long-run optimal outcomes.",
        "published": "2020-11-04T21:21:04Z",
        "link": "http://arxiv.org/abs/2011.02544v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "EEGS: A Transparent Model of Emotions",
        "authors": [
            "Suman Ojha",
            "Jonathan Vitale",
            "Mary-Anne Williams"
        ],
        "summary": "This paper presents the computational details of our emotion model, EEGS, and also provides an overview of a three-stage validation methodology used for the evaluation of our model, which can also be applicable for other computational models of emotion. A major gap in existing emotion modelling literature has been the lack of computational/technical details of the implemented models, which not only makes it difficult for early-stage researchers to understand the area but also prevents benchmarking of the developed models for expert researchers. We partly addressed these issues by presenting technical details for the computation of appraisal variables in our previous work. In this paper, we present mathematical formulas for the calculation of emotion intensities based on the theoretical premises of appraisal theory. Moreover, we will discuss how we enable our emotion model to reach to a regulated emotional state for social acceptability of autonomous agents. We hope this paper will allow a better transparency of knowledge, accurate benchmarking and further evolution of the field of emotion modelling.",
        "published": "2020-11-04T23:18:20Z",
        "link": "http://arxiv.org/abs/2011.02573v1",
        "categories": [
            "cs.AI",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Learning a Decentralized Multi-arm Motion Planner",
        "authors": [
            "Huy Ha",
            "Jingxi Xu",
            "Shuran Song"
        ],
        "summary": "We present a closed-loop multi-arm motion planner that is scalable and flexible with team size. Traditional multi-arm robot systems have relied on centralized motion planners, whose runtimes often scale exponentially with team size, and thus, fail to handle dynamic environments with open-loop control. In this paper, we tackle this problem with multi-agent reinforcement learning, where a decentralized policy is trained to control one robot arm in the multi-arm system to reach its target end-effector pose given observations of its workspace state and target end-effector pose. The policy is trained using Soft Actor-Critic with expert demonstrations from a sampling-based motion planning algorithm (i.e., BiRRT). By leveraging classical planning algorithms, we can improve the learning efficiency of the reinforcement learning algorithm while retaining the fast inference time of neural networks. The resulting policy scales sub-linearly and can be deployed on multi-arm systems with variable team sizes. Thanks to the closed-loop and decentralized formulation, our approach generalizes to 5-10 multi-arm systems and dynamic moving targets (>90% success rate for a 10-arm system), despite being trained on only 1-4 arm planning tasks with static targets. Code and data links can be found at https://multiarm.cs.columbia.edu.",
        "published": "2020-11-05T01:47:23Z",
        "link": "http://arxiv.org/abs/2011.02608v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.CV",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "In the Beginning there were n Agents: Founding and Amending a   Constitution",
        "authors": [
            "Ben Abramowitz",
            "Ehud Shapiro",
            "Nimrod Talmon"
        ],
        "summary": "Consider n agents forming an egalitarian, self-governed community. Their first task is to decide on a decision rule to make further decisions. We start from a rather general initial agreement on the decision-making process based upon a set of intuitive and self-evident axioms, as well as simplifying assumptions about the preferences of the agents. From these humble beginnings we derive a decision rule. Crucially, the decision rule also specifies how it can be changed, or amended, and thus acts as a de facto constitution. Our main contribution is in providing an example of an initial agreement that is simple and intuitive, and a constitution that logically follows from it. The naive agreement is on the basic process of decision making - that agents approve or disapprove proposals; that their vote determines either the acceptance or rejection of each proposal; and on the axioms, which are requirements regarding a constitution that engenders a self-updating decision making process.",
        "published": "2020-11-05T21:50:32Z",
        "link": "http://arxiv.org/abs/2011.03111v4",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "A Hysteretic Q-learning Coordination Framework for Emerging Mobility   Systems in Smart Cities",
        "authors": [
            "Behdad Chalaki",
            "Andreas A. Malikopoulos"
        ],
        "summary": "Connected and automated vehicles (CAVs) can alleviate traffic congestion, air pollution, and improve safety. In this paper, we provide a decentralized coordination framework for CAVs at a signal-free intersection to minimize travel time and improve fuel efficiency. We employ a simple yet powerful reinforcement learning approach, an off-policy temporal difference learning called Q-learning, enhanced with a coordination mechanism to address this problem. Then, we integrate a first-in-first-out queuing policy to improve the performance of our system. We demonstrate the efficacy of our proposed approach through simulation and comparison with the classical optimal control method based on Pontryagin's minimum principle.",
        "published": "2020-11-05T23:30:05Z",
        "link": "http://arxiv.org/abs/2011.03137v1",
        "categories": [
            "math.OC",
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Data-Driven Predictive Control Towards Multi-Agent Motion Planning With   Non-Parametric Closed-Loop Behavior Learning",
        "authors": [
            "Jun Ma",
            "Zilong Cheng",
            "Wenxin Wang",
            "Abdullah Al Mamun",
            "Clarence W. de Silva",
            "Tong Heng Lee"
        ],
        "summary": "In many specific scenarios, accurate and effective system identification is a commonly encountered challenge in the model predictive control (MPC) formulation. As a consequence, the overall system performance could be significantly weakened in outcome when the traditional MPC algorithm is adopted under those circumstances when such accuracy is lacking. This paper investigates a non-parametric closed-loop behavior learning method for multi-agent motion planning, which underpins a data-driven predictive control framework. Utilizing an innovative methodology with closed-loop input/output measurements of the unknown system, the behavior of the system is learned based on the collected dataset, and thus the constructed non-parametric predictive model can be used to determine the optimal control actions. This non-parametric predictive control framework alleviates the heavy computational burden commonly encountered in the optimization procedures typically in alternate methodologies requiring open-loop input/output measurement data collection and parametric system identification. The proposed data-driven approach is also shown to preserve good robustness properties. Finally, a multi-UAV system is used to demonstrate the highly effective outcome of this promising development.",
        "published": "2020-11-06T07:16:18Z",
        "link": "http://arxiv.org/abs/2011.03213v3",
        "categories": [
            "cs.MA",
            "cs.RO",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Fast Near-Optimal Heterogeneous Task Allocation via Flow Decomposition",
        "authors": [
            "Kiril Solovey",
            "Saptarshi Bandyopadhyay",
            "Federico Rossi",
            "Michael T. Wolf",
            "Marco Pavone"
        ],
        "summary": "Multi-robot systems are uniquely well-suited to performing complex tasks such as patrolling and tracking, information gathering, and pick-up and delivery problems, offering significantly higher performance than single-robot systems. A fundamental building block in most multi-robot systems is task allocation: assigning robots to tasks (e.g., patrolling an area, or servicing a transportation request) as they appear based on the robots' states to maximize reward. In many practical situations, the allocation must account for heterogeneous capabilities (e.g., availability of appropriate sensors or actuators) to ensure the feasibility of execution, and to promote a higher reward, over a long time horizon. To this end, we present the FlowDec algorithm for efficient heterogeneous task-allocation achieving an approximation factor of at least 1/2 of the optimal reward. Our approach decomposes the heterogeneous problem into several homogeneous subproblems that can be solved efficiently using min-cost flow. Through simulation experiments, we show that our algorithm is faster by several orders of magnitude than a MILP approach.",
        "published": "2020-11-06T21:29:55Z",
        "link": "http://arxiv.org/abs/2011.03603v2",
        "categories": [
            "cs.RO",
            "cs.DS",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Differential Advising in Multi-Agent Reinforcement Learning",
        "authors": [
            "Dayong Ye",
            "Tianqing Zhu",
            "Zishuo Cheng",
            "Wanlei Zhou",
            "Philip S. Yu"
        ],
        "summary": "Agent advising is one of the main approaches to improve agent learning performance by enabling agents to share advice. Existing advising methods have a common limitation that an adviser agent can offer advice to an advisee agent only if the advice is created in the same state as the advisee's concerned state. However, in complex environments, it is a very strong requirement that two states are the same, because a state may consist of multiple dimensions and two states being the same means that all these dimensions in the two states are correspondingly identical. Therefore, this requirement may limit the applicability of existing advising methods to complex environments. In this paper, inspired by the differential privacy scheme, we propose a differential advising method which relaxes this requirement by enabling agents to use advice in a state even if the advice is created in a slightly different state. Compared with existing methods, agents using the proposed method have more opportunity to take advice from others. This paper is the first to adopt the concept of differential privacy on advising to improve agent learning performance instead of addressing security issues. The experimental results demonstrate that the proposed method is more efficient in complex environments than existing methods.",
        "published": "2020-11-07T00:04:25Z",
        "link": "http://arxiv.org/abs/2011.03640v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Timely Information from Prediction Markets",
        "authors": [
            "Grant Schoenebeck",
            "Chenkai Yu",
            "Fang-Yi Yu"
        ],
        "summary": "Prediction markets are powerful tools to elicit and aggregate beliefs from strategic agents. However, in current prediction markets, agents may exhaust the social welfare by competing to be the first to update the market. We initiate the study of the trade-off between how quickly information is aggregated by the market, and how much this information costs. We design markets to aggregate timely information from strategic agents to maximize social welfare. To this end, the market must incentivize agents to invest the correct amount of effort to acquire information: quickly enough to be useful, but not faster (and more expensively) than necessary. The market also must ensure that agents report their information truthfully and on time. We consider two settings: in the first, information is only valuable before a deadline; in the second, the value of information decreases as time passes. We use both theorems and simulations to demonstrate the mechanisms.",
        "published": "2020-11-07T00:31:27Z",
        "link": "http://arxiv.org/abs/2011.03645v2",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Reasoning about Temporary Coalitions and LTL-definable Ordered   Objectives in Infinite Concurrent Multiplayer Games",
        "authors": [
            "Dimitar P. Guelev"
        ],
        "summary": "We propose enhancing the use of propositions for denoting decisions and strategies as established in temporal languages such as CTL*, if interpreted on concurrent game models. The enhancement enables specifying varying coalition structure. In quantified CTL* this technique also enables quantifying over coalition structure, and we use it to quantify over an extended form of strategy profiles which capture temporary coalitions. We also extend CTL* by a temporal form of a binary preference operator that can be traced back to the work of Von Wright. The resulting extension of quantified CTL* can be used to spell out conditions on the rationality of behaviour in concurrent multiplayer games such as what appear in solution concepts, with players having multiple individual objectives and preferences on them, and with the possibility to form temporary coalitions taken in account. We propose complete axiomatisations for the extension of CTL* by the temporal preference operator. The decidability of the logic is not affected by that extension.",
        "published": "2020-11-07T08:23:31Z",
        "link": "http://arxiv.org/abs/2011.03724v1",
        "categories": [
            "cs.LO",
            "cs.MA"
        ]
    },
    {
        "title": "Autonomous Intruder Detection Using a ROS-Based Multi-Robot System   Equipped with 2D-LiDAR Sensors",
        "authors": [
            "Mashnoon Islam",
            "Touhid Ahmed",
            "Abu Tammam Bin Nuruddin",
            "Mashuda Islam",
            "Shahnewaz Siddique"
        ],
        "summary": "The application of autonomous mobile robots in robotic security platforms is becoming a promising field of innovation due to their adaptive capability of responding to potential disturbances perceived through a wide range of sensors. Researchers have proposed systems that either focus on utilizing a single mobile robot or a system of cooperative multiple robots. However, very few of the proposed works, particularly in the field of multi-robot systems, are completely dependent on LiDAR sensors for achieving various tasks. This is essential when other sensors on a robot fail to provide peak performance in particular conditions, such as a camera operating in the absence of light. This paper proposes a multi-robot system that is developed using ROS (Robot Operating System) for intruder detection in a single-range-sensor-per-robot scenario with centralized processing of detections from all robots by our central bot MIDNet (Multiple Intruder Detection Network). This work is aimed at providing an autonomous multi-robot security solution for a warehouse in the absence of human personnel.",
        "published": "2020-11-07T19:49:07Z",
        "link": "http://arxiv.org/abs/2011.03838v1",
        "categories": [
            "cs.RO",
            "cs.CV",
            "cs.MA",
            "68T45, 65D19",
            "I.2.9; I.2.10; I.2.11"
        ]
    },
    {
        "title": "Multimodal Trajectory Prediction via Topological Invariance for   Navigation at Uncontrolled Intersections",
        "authors": [
            "Junha Roh",
            "Christoforos Mavrogiannis",
            "Rishabh Madan",
            "Dieter Fox",
            "Siddhartha S. Srinivasa"
        ],
        "summary": "We focus on decentralized navigation among multiple non-communicating rational agents at \\emph{uncontrolled} intersections, i.e., street intersections without traffic signs or signals. Avoiding collisions in such domains relies on the ability of agents to predict each others' intentions reliably, and react quickly. Multiagent trajectory prediction is NP-hard whereas the sample complexity of existing data-driven approaches limits their applicability. Our key insight is that the geometric structure of the intersection and the incentive of agents to move efficiently and avoid collisions (rationality) reduces the space of likely behaviors, effectively relaxing the problem of trajectory prediction. In this paper, we collapse the space of multiagent trajectories at an intersection into a set of modes representing different classes of multiagent behavior, formalized using a notion of topological invariance. Based on this formalism, we design Multiple Topologies Prediction (MTP), a data-driven trajectory-prediction mechanism that reconstructs trajectory representations of high-likelihood modes in multiagent intersection scenes. We show that MTP outperforms a state-of-the-art multimodal trajectory prediction baseline (MFP) in terms of prediction accuracy by 78.24% on a challenging simulated dataset. Finally, we show that MTP enables our optimization-based planner, MTPnav, to achieve collision-free and time-efficient navigation across a variety of challenging intersection scenarios on the CARLA simulator.",
        "published": "2020-11-08T02:56:42Z",
        "link": "http://arxiv.org/abs/2011.03894v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Cooperative and Stochastic Multi-Player Multi-Armed Bandit: Optimal   Regret With Neither Communication Nor Collisions",
        "authors": [
            "Sébastien Bubeck",
            "Thomas Budzinski",
            "Mark Sellke"
        ],
        "summary": "We consider the cooperative multi-player version of the stochastic multi-armed bandit problem. We study the regime where the players cannot communicate but have access to shared randomness. In prior work by the first two authors, a strategy for this regime was constructed for two players and three arms, with regret $\\tilde{O}(\\sqrt{T})$, and with no collisions at all between the players (with very high probability). In this paper we show that these properties (near-optimal regret and no collisions at all) are achievable for any number of players and arms. At a high level, the previous strategy heavily relied on a $2$-dimensional geometric intuition that was difficult to generalize in higher dimensions, while here we take a more combinatorial route to build the new strategy.",
        "published": "2020-11-08T03:14:19Z",
        "link": "http://arxiv.org/abs/2011.03896v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Topology Inference for Multi-agent Cooperation under Unmeasurable Latent   Input",
        "authors": [
            "Qing Jiao",
            "Yushan Li",
            "Jianping He",
            "Ling Shi"
        ],
        "summary": "Topology inference is a crucial problem for cooperative control in multi-agent systems. Different from most prior works, this paper is dedicated to inferring the directed network topology from the observations that consist of a single, noisy and finite time-series system trajectory, where the cooperation dynamics is stimulated with the initial network state and the unmeasurable latent input. The unmeasurable latent input refers to intrinsic system signal and extrinsic environment interference. Considering the time-invariant/varying nature of the input, we propose two-layer optimization-based and iterative estimation based topology inference algorithms (TO-TIA and IE-TIA), respectively. TO-TIA allows us to capture the separability of global agent state and eliminates the unknown influence of time-invariant input on system dynamics. IE-TIA further exploits the identifiability and estimability of more general time-varying input and provides an asymptotic solution with desired convergence properties, with higher computation cost compared with TO-TIA. Our novel algorithms relax the dependence of observation scale and leverage the empirical risk reformulation to improve the inference accuracy in terms of the topology structure and edge weight. Comprehensive theoretical analysis and simulations for various topologies are provided to illustrate the inference feasibility and the performance of the proposed algorithms.",
        "published": "2020-11-08T12:14:20Z",
        "link": "http://arxiv.org/abs/2011.03964v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Kimera-Multi: a System for Distributed Multi-Robot Metric-Semantic   Simultaneous Localization and Mapping",
        "authors": [
            "Yun Chang",
            "Yulun Tian",
            "Jonathan P. How",
            "Luca Carlone"
        ],
        "summary": "We present the first fully distributed multi-robot system for dense metric-semantic Simultaneous Localization and Mapping (SLAM). Our system, dubbed Kimera-Multi, is implemented by a team of robots equipped with visual-inertial sensors, and builds a 3D mesh model of the environment in real-time, where each face of the mesh is annotated with a semantic label (e.g., building, road, objects). In Kimera-Multi, each robot builds a local trajectory estimate and a local mesh using Kimera. Then, when two robots are within communication range, they initiate a distributed place recognition and robust pose graph optimization protocol with a novel incremental maximum clique outlier rejection; the protocol allows the robots to improve their local trajectory estimates by leveraging inter-robot loop closures. Finally, each robot uses its improved trajectory estimate to correct the local mesh using mesh deformation techniques. We demonstrate Kimera-Multi in photo-realistic simulations and real data. Kimera-Multi (i) is able to build accurate 3D metric-semantic meshes, (ii) is robust to incorrect loop closures while requiring less computation than state-of-the-art distributed SLAM back-ends, and (iii) is efficient, both in terms of computation at each robot as well as communication bandwidth.",
        "published": "2020-11-08T21:38:12Z",
        "link": "http://arxiv.org/abs/2011.04087v1",
        "categories": [
            "cs.RO",
            "cs.CV",
            "cs.MA"
        ]
    },
    {
        "title": "Network Optimization via Smooth Exact Penalty Functions Enabled by   Distributed Gradient Computation",
        "authors": [
            "Priyank Srivastava",
            "Jorge Cortes"
        ],
        "summary": "This paper proposes a distributed algorithm for a network of agents to solve an optimization problem with separable objective function and locally coupled constraints. Our strategy is based on reformulating the original constrained problem as the unconstrained optimization of a smooth (continuously differentiable) exact penalty function. Computing the gradient of this penalty function in a distributed way is challenging even under the separability assumptions on the original optimization problem. Our technical approach shows that the distributed computation problem for the gradient can be formulated as a system of linear algebraic equations defined by separable problem data. To solve it, we design an exponentially fast, input-to-state stable distributed algorithm that does not require the individual agent matrices to be invertible. We employ this strategy to compute the gradient of the penalty function at the current network state. Our distributed algorithmic solver for the original constrained optimization problem interconnects this estimation with the prescription of having the agents follow the resulting direction. Numerical simulations illustrate the convergence and robustness properties of the proposed algorithm.",
        "published": "2020-11-08T23:14:12Z",
        "link": "http://arxiv.org/abs/2011.04100v2",
        "categories": [
            "math.OC",
            "cs.MA"
        ]
    },
    {
        "title": "Multiagent Rollout and Policy Iteration for POMDP with Application to   Multi-Robot Repair Problems",
        "authors": [
            "Sushmita Bhattacharya",
            "Siva Kailas",
            "Sahil Badyal",
            "Stephanie Gil",
            "Dimitri Bertsekas"
        ],
        "summary": "In this paper we consider infinite horizon discounted dynamic programming problems with finite state and control spaces, partial state observations, and a multiagent structure. We discuss and compare algorithms that simultaneously or sequentially optimize the agents' controls by using multistep lookahead, truncated rollout with a known base policy, and a terminal cost function approximation. Our methods specifically address the computational challenges of partially observable multiagent problems. In particular: 1) We consider rollout algorithms that dramatically reduce required computation while preserving the key cost improvement property of the standard rollout method. The per-step computational requirements for our methods are on the order of $O(Cm)$ as compared with $O(C^m)$ for standard rollout, where $C$ is the maximum cardinality of the constraint set for the control component of each agent, and $m$ is the number of agents. 2) We show that our methods can be applied to challenging problems with a graph structure, including a class of robot repair problems whereby multiple robots collaboratively inspect and repair a system under partial information. 3) We provide a simulation study that compares our methods with existing methods, and demonstrate that our methods can handle larger and more complex partially observable multiagent problems (state space size $10^{37}$ and control space size $10^{7}$, respectively). Finally, we incorporate our multiagent rollout algorithms as building blocks in an approximate policy iteration scheme, where successive rollout policies are approximated by using neural network classifiers. While this scheme requires a strictly off-line implementation, it works well in our computational experiments and produces additional significant performance improvement over the single online rollout iteration method.",
        "published": "2020-11-09T06:51:50Z",
        "link": "http://arxiv.org/abs/2011.04222v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Network Impacts of Automated Mobility-on-Demand: A Macroscopic   Fundamental Diagram Perspective",
        "authors": [
            "Simon Oh",
            "Antonis F. Lentzakis",
            "Ravi Seshadri",
            "Moshe Ben-Akiva"
        ],
        "summary": "Technological advancements have brought increasing attention to Automated Mobility on Demand (AMOD) as a promising solution that may improve future urban mobility. During the last decade, extensive research has been conducted on the design and evaluation of AMOD systems using simulation models. This paper adds to this growing body of literature by investigating the network impacts of AMOD through high-fidelity activity- and agent-based traffic simulation, including detailed models of AMOD fleet operations. Through scenario simulations of the entire island of Singapore, we explore network traffic dynamics by employing the concept of the Macroscopic Fundamental Diagram (MFD). Taking into account the spatial variability of density, we are able to capture the hysteresis loops, which inevitably form in a network of this size. Model estimation results at both the vehicle and passenger flow level are documented. Environmental impacts including energy and emissions are also discussed. Findings from the case study of Singapore suggest that the introduction of AMOD may bring about significant impacts on network performance in terms of increased VKT, additional travel delay and energy consumption, while reducing vehicle emissions, with respect to the baseline. Despite the increase in network congestion, production of passenger flows remains relatively unchanged.",
        "published": "2020-11-10T13:39:35Z",
        "link": "http://arxiv.org/abs/2011.05092v1",
        "categories": [
            "cs.CY",
            "cs.MA"
        ]
    },
    {
        "title": "Emergent Reciprocity and Team Formation from Randomized Uncertain Social   Preferences",
        "authors": [
            "Bowen Baker"
        ],
        "summary": "Multi-agent reinforcement learning (MARL) has shown recent success in increasingly complex fixed-team zero-sum environments. However, the real world is not zero-sum nor does it have fixed teams; humans face numerous social dilemmas and must learn when to cooperate and when to compete. To successfully deploy agents into the human world, it may be important that they be able to understand and help in our conflicts. Unfortunately, selfish MARL agents typically fail when faced with social dilemmas. In this work, we show evidence of emergent direct reciprocity, indirect reciprocity and reputation, and team formation when training agents with randomized uncertain social preferences (RUSP), a novel environment augmentation that expands the distribution of environments agents play in. RUSP is generic and scalable; it can be applied to any multi-agent environment without changing the original underlying game dynamics or objectives. In particular, we show that with RUSP these behaviors can emerge and lead to higher social welfare equilibria in both classic abstract social dilemmas like Iterated Prisoner's Dilemma as well in more complex intertemporal environments.",
        "published": "2020-11-10T20:06:19Z",
        "link": "http://arxiv.org/abs/2011.05373v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Do You See What I See? Coordinating Multiple Aerial Cameras for Robot   Cinematography",
        "authors": [
            "Arthur Bucker",
            "Rogerio Bonatti",
            "Sebastian Scherer"
        ],
        "summary": "Aerial cinematography is significantly expanding the capabilities of film-makers. Recent progress in autonomous unmanned aerial vehicles (UAVs) has further increased the potential impact of aerial cameras, with systems that can safely track actors in unstructured cluttered environments. Professional productions, however, require the use of multiple cameras simultaneously to record different viewpoints of the same scene, which are edited into the final footage either in real time or in post-production. Such extreme motion coordination is particularly hard for unscripted action scenes, which are a common use case of aerial cameras. In this work we develop a real-time multi-UAV coordination system that is capable of recording dynamic targets while maximizing shot diversity and avoiding collisions and mutual visibility between cameras. We validate our approach in multiple cluttered environments of a photo-realistic simulator, and deploy the system using two UAVs in real-world experiments. We show that our coordination scheme has low computational cost and takes only 1.17 ms on average to plan for a team of 3 UAVs over a 10 s time horizon. Supplementary video: https://youtu.be/m2R3anv2ADE",
        "published": "2020-11-10T22:43:25Z",
        "link": "http://arxiv.org/abs/2011.05437v2",
        "categories": [
            "cs.RO",
            "cs.CV",
            "cs.MA"
        ]
    },
    {
        "title": "Decentralized Motion Planning for Multi-Robot Navigation using Deep   Reinforcement Learning",
        "authors": [
            "Sivanathan Kandhasamy",
            "Vinayagam Babu Kuppusamy",
            "Tanmay Vilas Samak",
            "Chinmay Vilas Samak"
        ],
        "summary": "This work presents a decentralized motion planning framework for addressing the task of multi-robot navigation using deep reinforcement learning. A custom simulator was developed in order to experimentally investigate the navigation problem of 4 cooperative non-holonomic robots sharing limited state information with each other in 3 different settings. The notion of decentralized motion planning with common and shared policy learning was adopted, which allowed robust training and testing of this approach in a stochastic environment since the agents were mutually independent and exhibited asynchronous motion behavior. The task was further aggravated by providing the agents with a sparse observation space and requiring them to generate continuous action commands so as to efficiently, yet safely navigate to their respective goal locations, while avoiding collisions with other dynamic peers and static obstacles at all times. The experimental results are reported in terms of quantitative measures and qualitative remarks for both training and deployment phases.",
        "published": "2020-11-11T07:35:21Z",
        "link": "http://arxiv.org/abs/2011.05605v2",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "cs.NE"
        ]
    },
    {
        "title": "Multi-Hypothesis Interactions in Game-Theoretic Motion Planning",
        "authors": [
            "Forrest Laine",
            "David Fridovich-Keil",
            "Chih-Yuan Chiu",
            "Claire Tomlin"
        ],
        "summary": "We present a novel method for handling uncertainty about the intentions of non-ego players in dynamic games, with application to motion planning for autonomous vehicles. Equilibria in these games explicitly account for interaction among other agents in the environment, such as drivers and pedestrians. Our method models the uncertainty about the intention of other agents by constructing multiple hypotheses about the objectives and constraints of other agents in the scene. For each candidate hypothesis, we associate a Bernoulli random variable representing the probability of that hypothesis, which may or may not be independent of the probability of other hypotheses. We leverage constraint asymmetries and feedback information patterns to incorporate the probabilities of hypotheses in a natural way. Specifically, increasing the probability associated with a given hypothesis from $0$ to $1$ shifts the responsibility of collision avoidance from the hypothesized agent to the ego agent. This method allows the generation of interactive trajectories for the ego agent, where the level of assertiveness or caution that the ego exhibits is directly related to the easy-to-model uncertainty it maintains about the scene.",
        "published": "2020-11-11T20:00:00Z",
        "link": "http://arxiv.org/abs/2011.06047v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "SEIR-Campus: Modeling Infectious Diseases on University Campuses",
        "authors": [
            "Matthew Zalesak",
            "Samitha Samaranayake"
        ],
        "summary": "We introduce a Python package for modeling and studying the spread of infectious diseases using an agent-based SEIR style epidemiological model with a focus on university campuses. This document explains the epidemiological model used in the package and gives examples highlighting the ways that the package can be used.",
        "published": "2020-11-11T23:50:32Z",
        "link": "http://arxiv.org/abs/2011.06124v1",
        "categories": [
            "q-bio.PE",
            "cs.MA",
            "cs.SI",
            "physics.soc-ph"
        ]
    },
    {
        "title": "Opponent Learning Awareness and Modelling in Multi-Objective Normal Form   Games",
        "authors": [
            "Roxana Rădulescu",
            "Timothy Verstraeten",
            "Yijie Zhang",
            "Patrick Mannion",
            "Diederik M. Roijers",
            "Ann Nowé"
        ],
        "summary": "Many real-world multi-agent interactions consider multiple distinct criteria, i.e. the payoffs are multi-objective in nature. However, the same multi-objective payoff vector may lead to different utilities for each participant. Therefore, it is essential for an agent to learn about the behaviour of other agents in the system. In this work, we present the first study of the effects of such opponent modelling on multi-objective multi-agent interactions with non-linear utilities. Specifically, we consider two-player multi-objective normal form games with non-linear utility functions under the scalarised expected returns optimisation criterion. We contribute novel actor-critic and policy gradient formulations to allow reinforcement learning of mixed strategies in this setting, along with extensions that incorporate opponent policy reconstruction and learning with opponent learning awareness (i.e., learning while considering the impact of one's policy when anticipating the opponent's learning step). Empirical results in five different MONFGs demonstrate that opponent learning awareness and modelling can drastically alter the learning dynamics in this setting. When equilibria are present, opponent modelling can confer significant benefits on agents that implement it. When there are no Nash equilibria, opponent learning awareness and modelling allows agents to still converge to meaningful solutions that approximate equilibria.",
        "published": "2020-11-14T12:35:32Z",
        "link": "http://arxiv.org/abs/2011.07290v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.GT",
            "cs.LG"
        ]
    },
    {
        "title": "Spatiotemporal Characteristics of Ride-sourcing Operation in Urban Area",
        "authors": [
            "Simon Oh",
            "Daniel Kondor",
            "Ravi Seshadri",
            "Meng Zhou",
            "Diem-Trinh Le",
            "Moshe Ben-Akiva"
        ],
        "summary": "The emergence of ride-sourcing platforms has brought an innovative alternative in transportation, radically changed travel behaviors, and suggested new directions for transportation planners and operators. This paper provides an exploratory analysis on the operations of a ride-sourcing service using large-scale data on service performance. Observations over multiple days in Singapore suggest reproducible demand patterns and provide empirical estimates of fleet operations over time and space. During peak periods, we observe significant increases in the service rate along with surge price multipliers. We perform an in-depth analysis of fleet utilization rates and are able to explain daily patterns based on drivers' behavior by involving the number of shifts, shift duration, and shift start and end time choices. We also evaluate metrics of user experience, namely waiting and travel time distribution, and explain our empirical findings with distance metrics from driver trajectory analysis and congestion patterns. Our results of empirical observations on actual service in Singapore can help to understand the spatiotemporal characteristics of ride-sourcing services and provide important insights for transportation planning and operations.",
        "published": "2020-11-16T01:28:35Z",
        "link": "http://arxiv.org/abs/2011.07673v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "A Survey of Requirements for COVID-19 Mitigation Strategies. Part I:   Newspaper Clips",
        "authors": [
            "Wojciech Jamroga",
            "David Mestel",
            "Peter B. Roenne",
            "Peter Y. A. Ryan",
            "Marjan Skrobot"
        ],
        "summary": "The COVID-19 pandemic has influenced virtually all aspects of our lives. Across the world, countries have applied various mitigation strategies for the epidemic, based on social, political, and technological instruments. We postulate that one should {identify the relevant requirements} before committing to a particular mitigation strategy. One way to achieve it is through an overview of what is considered relevant by the general public, and referred to in the media. To this end, we have collected a number of news clips that mention the possible goals and requirements for a mitigation strategy. The snippets are sorted thematically into several categories, such as health-related goals, social and political impact, civil rights, ethical requirements, and so on.   In a forthcoming companion paper, we will present a digest of the requirements, derived from the news clips, and a preliminary take on their formal specification.",
        "published": "2020-11-16T12:00:49Z",
        "link": "http://arxiv.org/abs/2011.07887v4",
        "categories": [
            "cs.CY",
            "cs.MA"
        ]
    },
    {
        "title": "A Distributed Differentially Private Algorithm for Resource Allocation   in Unboundedly Large Settings",
        "authors": [
            "Panayiotis Danassis",
            "Aleksei Triastcyn",
            "Boi Faltings"
        ],
        "summary": "We introduce a practical and scalable algorithm (PALMA) for solving one of the fundamental problems of multi-agent systems -- finding matches and allocations -- in unboundedly large settings (e.g., resource allocation in urban environments, mobility-on-demand systems, etc.), while providing strong worst-case privacy guarantees. PALMA is decentralized, runs on-device, requires no inter-agent communication, and converges in constant time under reasonable assumptions. We evaluate PALMA in a mobility-on-demand and a paper assignment scenario, using real data in both, and demonstrate that it provides a strong level of privacy ($\\varepsilon \\leq 1$ and median as low as $\\varepsilon = 0.5$ across agents) and high-quality matchings (up to $86\\%$ of the non-private optimal, outperforming even the privacy-preserving centralized maximum-weight matching baseline).",
        "published": "2020-11-16T13:33:04Z",
        "link": "http://arxiv.org/abs/2011.07934v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.CR"
        ]
    },
    {
        "title": "Scalable Reinforcement Learning Policies for Multi-Agent Control",
        "authors": [
            "Christopher D. Hsu",
            "Heejin Jeong",
            "George J. Pappas",
            "Pratik Chaudhari"
        ],
        "summary": "We develop a Multi-Agent Reinforcement Learning (MARL) method to learn scalable control policies for target tracking. Our method can handle an arbitrary number of pursuers and targets; we show results for tasks consisting up to 1000 pursuers tracking 1000 targets. We use a decentralized, partially-observable Markov Decision Process framework to model pursuers as agents receiving partial observations (range and bearing) about targets which move using fixed, unknown policies. An attention mechanism is used to parameterize the value function of the agents; this mechanism allows us to handle an arbitrary number of targets. Entropy-regularized off-policy RL methods are used to train a stochastic policy, and we discuss how it enables a hedging behavior between pursuers that leads to a weak form of cooperation in spite of completely decentralized control execution. We further develop a masking heuristic that allows training on smaller problems with few pursuers-targets and execution on much larger problems. Thorough simulation experiments, ablation studies, and comparisons to state of the art algorithms are performed to study the scalability of the approach and robustness of performance to varying numbers of agents and targets.",
        "published": "2020-11-16T16:11:12Z",
        "link": "http://arxiv.org/abs/2011.08055v4",
        "categories": [
            "cs.MA",
            "cs.LG"
        ]
    },
    {
        "title": "Curiosity Based Reinforcement Learning on Robot Manufacturing Cell",
        "authors": [
            "Mohammed Sharafath Abdul Hameed",
            "Md Muzahid Khan",
            "Andreas Schwung"
        ],
        "summary": "This paper introduces a novel combination of scheduling control on a flexible robot manufacturing cell with curiosity based reinforcement learning. Reinforcement learning has proved to be highly successful in solving tasks like robotics and scheduling. But this requires hand tuning of rewards in problem domains like robotics and scheduling even where the solution is not obvious. To this end, we apply a curiosity based reinforcement learning, using intrinsic motivation as a form of reward, on a flexible robot manufacturing cell to alleviate this problem. Further, the learning agents are embedded into the transportation robots to enable a generalized learning solution that can be applied to a variety of environments. In the first approach, the curiosity based reinforcement learning is applied to a simple structured robot manufacturing cell. And in the second approach, the same algorithm is applied to a graph structured robot manufacturing cell. Results from the experiments show that the agents are able to solve both the environments with the ability to transfer the curiosity module directly from one environment to another. We conclude that curiosity based learning on scheduling tasks provide a viable alternative to the reward shaped reinforcement learning traditionally used.",
        "published": "2020-11-17T16:19:47Z",
        "link": "http://arxiv.org/abs/2011.08743v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Near-Optimal Multi-Robot Motion Planning with Finite Sampling",
        "authors": [
            "Dror Dayan",
            "Kiril Solovey",
            "Marco Pavone",
            "Dan Halperin"
        ],
        "summary": "An underlying structure in several sampling-based methods for continuous multi-robot motion planning (MRMP) is the tensor roadmap (TR), which emerges from combining multiple PRM graphs constructed for the individual robots via a tensor product. We study the conditions under which the TR encodes a near-optimal solution for MRMP -- satisfying these conditions implies near optimality for a variety of popular planners, including dRRT*, and the discrete methods M* and CBS when applied to the continuous domain. We develop the first finite-sample analysis of this kind, which specifies the number of samples, their deterministic distribution, and magnitude of the connection radii that should be used by each individual PRM graph, to guarantee near-optimality using the TR. This significantly improves upon a previous asymptotic analysis, wherein the number of samples tends to infinity. Our new finite sample-size analysis supports guaranteed high-quality solutions in practice within finite time. To achieve our new result, we first develop a sampling scheme, which we call the staggered grid, for finite-sample motion planning for individual robots, which requires significantly fewer samples than previous work. We then extend it to the much more involved MRMP setting which requires to account for interactions among multiple robots. Finally, we report on a few experiments that serve as a verification of our theoretical findings and raise interesting questions for further investigation.",
        "published": "2020-11-17T21:03:47Z",
        "link": "http://arxiv.org/abs/2011.08944v5",
        "categories": [
            "cs.RO",
            "cs.DS",
            "cs.MA"
        ]
    },
    {
        "title": "Consensus of Multi-Agent Systems Using Back-Tracking and History   Following Algorithms",
        "authors": [
            "Yanumula V. Karteek",
            "Indrani Kar",
            "Somanath Majhi"
        ],
        "summary": "This paper proposes two algorithms, namely \"back-tracking\" and \"history following\", to reach consensus in case of communication loss for a network of distributed agents with switching topologies. To reach consensus in distributed control, considered communication topology forms a strongly connected graph. The graph is no more strongly connected whenever an agent loses communication.Whenever an agent loses communication, the topology is no more strongly connected. The proposed back-tracking algorithm makes sure that the agent backtracks its position unless the communication is reestablished, and path is changed to reach consensus. In history following, the agents use their memory and move towards previous consensus point until the communication is regained. Upon regaining communication, a new consensus point is calculated depending on the current positions of the agents and they change their trajectories accordingly. Simulation results, for a network of six agents, show that when the agents follow the previous history, the average consensus time is less than that of back-tracking. However, situation may arise in history following where a false notion of reaching consensus makes one of the agents stop at a point near to the actual consensus point. An obstacle avoidance algorithm is integrated with the proposed algorithms to avoid collisions. Hardware implementation for a three robots system shows the effectiveness of the algorithms.",
        "published": "2020-11-17T22:39:20Z",
        "link": "http://arxiv.org/abs/2011.08990v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Game Plan: What AI can do for Football, and What Football can do for AI",
        "authors": [
            "Karl Tuyls",
            "Shayegan Omidshafiei",
            "Paul Muller",
            "Zhe Wang",
            "Jerome Connor",
            "Daniel Hennes",
            "Ian Graham",
            "William Spearman",
            "Tim Waskett",
            "Dafydd Steele",
            "Pauline Luc",
            "Adria Recasens",
            "Alexandre Galashov",
            "Gregory Thornton",
            "Romuald Elie",
            "Pablo Sprechmann",
            "Pol Moreno",
            "Kris Cao",
            "Marta Garnelo",
            "Praneet Dutta",
            "Michal Valko",
            "Nicolas Heess",
            "Alex Bridgland",
            "Julien Perolat",
            "Bart De Vylder",
            "Ali Eslami",
            "Mark Rowland",
            "Andrew Jaegle",
            "Remi Munos",
            "Trevor Back",
            "Razia Ahamed",
            "Simon Bouton",
            "Nathalie Beauguerlange",
            "Jackson Broshear",
            "Thore Graepel",
            "Demis Hassabis"
        ],
        "summary": "The rapid progress in artificial intelligence (AI) and machine learning has opened unprecedented analytics possibilities in various team and individual sports, including baseball, basketball, and tennis. More recently, AI techniques have been applied to football, due to a huge increase in data collection by professional teams, increased computational power, and advances in machine learning, with the goal of better addressing new scientific challenges involved in the analysis of both individual players' and coordinated teams' behaviors. The research challenges associated with predictive and prescriptive football analytics require new developments and progress at the intersection of statistical learning, game theory, and computer vision. In this paper, we provide an overarching perspective highlighting how the combination of these fields, in particular, forms a unique microcosm for AI research, while offering mutual benefits for professional teams, spectators, and broadcasters in the years to come. We illustrate that this duality makes football analytics a game changer of tremendous value, in terms of not only changing the game of football itself, but also in terms of what this domain can mean for the field of AI. We review the state-of-the-art and exemplify the types of analysis enabled by combining the aforementioned fields, including illustrative examples of counterfactual analysis using predictive models, and the combination of game-theoretic analysis of penalty kicks with statistical learning of player attributes. We conclude by highlighting envisioned downstream impacts, including possibilities for extensions to other sports (real and virtual).",
        "published": "2020-11-18T10:26:02Z",
        "link": "http://arxiv.org/abs/2011.09192v1",
        "categories": [
            "cs.AI",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "The Effect of Modern Traffic Information on Braess' Paradox",
        "authors": [
            "Stefan Bittihn",
            "Andreas Schadschneider"
        ],
        "summary": "Braess' paradox has been shown to appear rather generically in many systems of transport on networks. It is especially relevant for vehicular traffic where it shows that in certain situations building a new road in an urban or highway network can lead to increased average travel times for all users. Here we address the question whether this changes if the drivers (agents) have access to traffic information as available for modern traffic networks, i.e. through navigation apps and or personal experiences in the past. We study the effect of traffic information in the classical Braess network, but using a microscopic model for the traffic dynamics, to find out if the paradox can really be observed in such a scenario or if it only exists in some theoretically available user optima that are never realized by drivers that base their route choice decisions intelligently upon realistic traffic information. We address this question for different splits of the two information types.",
        "published": "2020-11-18T18:32:16Z",
        "link": "http://arxiv.org/abs/2011.09456v1",
        "categories": [
            "physics.soc-ph",
            "cs.MA",
            "nlin.CG"
        ]
    },
    {
        "title": "Zeroth-Order Feedback Optimization for Cooperative Multi-Agent Systems",
        "authors": [
            "Yujie Tang",
            "Zhaolin Ren",
            "Na Li"
        ],
        "summary": "We study a class of cooperative multi-agent optimization problems, where each agent is associated with a local action vector and a local cost, and the goal is to cooperatively find the joint action profile that minimizes the average of the local costs. Such problems arise in many applications, such as distributed routing control, wind farm operation, etc. In many of these problems, gradient information may not be readily available, and the agents may only observe their local costs incurred by their actions as a feedback to determine their new actions. In this paper, we propose a zeroth-order feedback optimization scheme for the class of problems we consider, and provide explicit complexity bounds for both the convex and nonconvex settings with noiseless and noisy local cost observations. We also discuss briefly on the impacts of knowledge of local function dependence between agents. The algorithm's performance is justified by a numerical example of distributed routing control.",
        "published": "2020-11-19T09:08:26Z",
        "link": "http://arxiv.org/abs/2011.09728v2",
        "categories": [
            "math.OC",
            "cs.MA"
        ]
    },
    {
        "title": "Decentralized Task and Path Planning for Multi-Robot Systems",
        "authors": [
            "Yuxiao Chen",
            "Ugo Rosolia",
            "Aaron D. Ames"
        ],
        "summary": "We consider a multi-robot system with a team of collaborative robots and multiple tasks that emerges over time. We propose a fully decentralized task and path planning (DTPP) framework consisting of a task allocation module and a localized path planning module. Each task is modeled as a Markov Decision Process (MDP) or a Mixed Observed Markov Decision Process (MOMDP) depending on whether full states or partial states are observable. The task allocation module then aims at maximizing the expected pure reward (reward minus cost) of the robotic team. We fuse the Markov model into a factor graph formulation so that the task allocation can be decentrally solved using the max-sum algorithm. Each robot agent follows the optimal policy synthesized for the Markov model and we propose a localized forward dynamic programming scheme that resolves conflicts between agents and avoids collisions. The proposed framework is demonstrated with high fidelity ROS simulations and experiments with multiple ground robots.",
        "published": "2020-11-19T18:54:28Z",
        "link": "http://arxiv.org/abs/2011.10034v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Elementary Effects Analysis of factors controlling COVID-19 infections   in computational simulation reveals the importance of Social Distancing and   Mask Usage",
        "authors": [
            "Kelvin K. F. Li",
            "Stephen A. Jarvis",
            "Fayyaz Minhas"
        ],
        "summary": "COVID-19 was declared a pandemic by the World Health Organization (WHO) on March 11th, 2020. With half of the world's countries in lockdown as of April due to this pandemic, monitoring and understanding the spread of the virus and infection rates and how these factors relate to behavioural and societal parameters is crucial for effective policy making. This paper aims to investigate the effectiveness of masks, social distancing, lockdown and self-isolation for reducing the spread of SARS-CoV-2 infections. Our findings based on agent-based simulation modelling show that whilst requiring a lockdown is widely believed to be the most efficient method to quickly reduce infection numbers, the practice of social distancing and the usage of surgical masks can potentially be more effective than requiring a lockdown. Our multivariate analysis of simulation results using the Morris Elementary Effects Method suggests that if a sufficient proportion of the population wore surgical masks and followed social distancing regulations, then SARS-CoV-2 infections can be controlled without requiring a lockdown.",
        "published": "2020-11-20T04:36:26Z",
        "link": "http://arxiv.org/abs/2011.11381v3",
        "categories": [
            "cs.AI",
            "cs.MA",
            "physics.soc-ph"
        ]
    },
    {
        "title": "A General Framework for Distributed Inference with Uncertain Models",
        "authors": [
            "James Z. Hare",
            "Cesar A. Uribe",
            "Lance Kaplan",
            "Ali Jadbabaie"
        ],
        "summary": "This paper studies the problem of distributed classification with a network of heterogeneous agents. The agents seek to jointly identify the underlying target class that best describes a sequence of observations. The problem is first abstracted to a hypothesis-testing framework, where we assume that the agents seek to agree on the hypothesis (target class) that best matches the distribution of observations. Non-Bayesian social learning theory provides a framework that solves this problem in an efficient manner by allowing the agents to sequentially communicate and update their beliefs for each hypothesis over the network. Most existing approaches assume that agents have access to exact statistical models for each hypothesis. However, in many practical applications, agents learn the likelihood models based on limited data, which induces uncertainty in the likelihood function parameters. In this work, we build upon the concept of uncertain models to incorporate the agents' uncertainty in the likelihoods by identifying a broad set of parametric distribution that allows the agents' beliefs to converge to the same result as a centralized approach. Furthermore, we empirically explore extensions to non-parametric models to provide a generalized framework of uncertain models in non-Bayesian social learning.",
        "published": "2020-11-20T22:17:12Z",
        "link": "http://arxiv.org/abs/2011.10669v1",
        "categories": [
            "cs.AI",
            "cs.MA",
            "cs.SI"
        ]
    },
    {
        "title": "Continuous-Time Convergence Rates in Potential and Monotone Games",
        "authors": [
            "Bolin Gao",
            "Lacra Pavel"
        ],
        "summary": "In this paper, we provide exponential rates of convergence to the interior Nash equilibrium for continuous-time dual-space game dynamics such as mirror descent (MD) and actor-critic (AC). We perform our analysis in $N$-player continuous concave games that satisfy certain monotonicity assumptions while possibly also admitting potential functions. In the first part of this paper, we provide a novel relative characterization of monotone games and show that MD and its discounted version converge with $\\mathcal{O}(e^{-\\beta t})$ in relatively strongly and relatively hypo-monotone games, respectively. In the second part of this paper, we specialize our results to games that admit a relatively strongly concave potential and show AC converges with $\\mathcal{O}(e^{-\\beta t})$. These rates extend their known convergence conditions. Simulations are performed which empirically back up our results.",
        "published": "2020-11-21T00:00:55Z",
        "link": "http://arxiv.org/abs/2011.10682v3",
        "categories": [
            "math.OC",
            "cs.GT",
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "math.DS"
        ]
    },
    {
        "title": "Learning-based attacks in Cyber-Physical Systems: Exploration,   Detection, and Control Cost trade-offs",
        "authors": [
            "Anshuka Rangi",
            "Mohammad Javad Khojasteh",
            "Massimo Franceschetti"
        ],
        "summary": "We study the problem of learning-based attacks in linear systems, where the communication channel between the controller and the plant can be hijacked by a malicious attacker. We assume the attacker learns the dynamics of the system from observations, then overrides the controller's actuation signal, while mimicking legitimate operation by providing fictitious sensor readings to the controller. On the other hand, the controller is on a lookout to detect the presence of the attacker and tries to enhance the detection performance by carefully crafting its control signals. We study the trade-offs between the information acquired by the attacker from observations, the detection capabilities of the controller, and the control cost. Specifically, we provide tight upper and lower bounds on the expected $\\epsilon$-deception time, namely the time required by the controller to make a decision regarding the presence of an attacker with confidence at least $(1-\\epsilon\\log(1/\\epsilon))$. We then show a probabilistic lower bound on the time that must be spent by the attacker learning the system, in order for the controller to have a given expected $\\epsilon$-deception time. We show that this bound is also order optimal, in the sense that if the attacker satisfies it, then there exists a learning algorithm with the given order expected deception time. Finally, we show a lower bound on the expected energy expenditure required to guarantee detection with confidence at least $1-\\epsilon \\log(1/\\epsilon)$.",
        "published": "2020-11-21T04:08:16Z",
        "link": "http://arxiv.org/abs/2011.10718v2",
        "categories": [
            "eess.SY",
            "cs.CR",
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "stat.AP"
        ]
    },
    {
        "title": "Emergent Road Rules In Multi-Agent Driving Environments",
        "authors": [
            "Avik Pal",
            "Jonah Philion",
            "Yuan-Hong Liao",
            "Sanja Fidler"
        ],
        "summary": "For autonomous vehicles to safely share the road with human drivers, autonomous vehicles must abide by specific \"road rules\" that human drivers have agreed to follow. \"Road rules\" include rules that drivers are required to follow by law -- such as the requirement that vehicles stop at red lights -- as well as more subtle social rules -- such as the implicit designation of fast lanes on the highway. In this paper, we provide empirical evidence that suggests that -- instead of hard-coding road rules into self-driving algorithms -- a scalable alternative may be to design multi-agent environments in which road rules emerge as optimal solutions to the problem of maximizing traffic flow. We analyze what ingredients in driving environments cause the emergence of these road rules and find that two crucial factors are noisy perception and agents' spatial density. We provide qualitative and quantitative evidence of the emergence of seven social driving behaviors, ranging from obeying traffic signals to following lanes, all of which emerge from training agents to drive quickly to destinations without colliding. Our results add empirical support for the social road rules that countries worldwide have agreed on for safe, efficient driving.",
        "published": "2020-11-21T09:43:50Z",
        "link": "http://arxiv.org/abs/2011.10753v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Imperfect Oracles: The Effect of Strategic Information on Stock Markets",
        "authors": [
            "Miklos Borsi"
        ],
        "summary": "Modern financial market dynamics warrant detailed analysis due to their significant impact on the world. This, however, often proves intractable; massive numbers of agents, strategies and their change over time in reaction to each other leads to difficulties in both theoretical and simulational approaches. Notable work has been done on strategy dominance in stock markets with respect to the ratios of agents with certain strategies. Perfect knowledge of the strategies employed could then put an individual agent at a consistent trading advantage. This research reports the effects of imperfect oracles on the system - dispensing noisy information about strategies - information which would normally be hidden from market participants. The effect and achievable profits of a singular trader with access to an oracle were tested exhaustively with previously unexplored factors such as changing order schedules. Additionally, the effect of noise on strategic information was traced through its effect on trader efficiency.",
        "published": "2020-11-21T18:23:04Z",
        "link": "http://arxiv.org/abs/2011.10837v1",
        "categories": [
            "cs.CE",
            "cs.GT",
            "cs.MA",
            "I.6.0; J.4"
        ]
    },
    {
        "title": "Multi-Agent Reinforcement Learning for Markov Routing Games: A New   Modeling Paradigm For Dynamic Traffic Assignment",
        "authors": [
            "Zhenyu Shou",
            "Xu Chen",
            "Yongjie Fu",
            "Xuan Di"
        ],
        "summary": "This paper aims to develop a paradigm that models the learning behavior of intelligent agents (including but not limited to autonomous vehicles, connected and automated vehicles, or human-driven vehicles with intelligent navigation systems where human drivers follow the navigation instructions completely) with a utility-optimizing goal and the system's equilibrating processes in a routing game among atomic selfish agents. Such a paradigm can assist policymakers in devising optimal operational and planning countermeasures under both normal and abnormal circumstances. To this end, we develop a Markov routing game (MRG) in which each agent learns and updates her own en-route path choice policy while interacting with others in transportation networks. To efficiently solve MRG, we formulate it as multi-agent reinforcement learning (MARL) and devise a mean field multi-agent deep Q learning (MF-MA-DQL) approach that captures the competition among agents. The linkage between the classical DUE paradigm and our proposed Markov routing game (MRG) is discussed. We show that the routing behavior of intelligent agents is shown to converge to the classical notion of predictive dynamic user equilibrium (DUE) when traffic environments are simulated using dynamic loading models (DNL). In other words, the MRG depicts DUEs assuming perfect information and deterministic environments propagated by DNL models. Four examples are solved to illustrate the algorithm efficiency and consistency between DUE and the MRG equilibrium, on a simple network without and with spillback, the Ortuzar Willumsen (OW) Network, and a real-world network near Columbia University's campus in Manhattan of New York City.",
        "published": "2020-11-22T02:31:14Z",
        "link": "http://arxiv.org/abs/2011.10915v2",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Restricted Airspace Protection using Multi-UAV Spatio-TemporalMulti-Task   Allocation",
        "authors": [
            "Shridhar Velhal",
            "Suresh Sundaram"
        ],
        "summary": "This paper addresses the problem of restricted airspace protection from invaders using the cooperative multi-UAV system. The objective is to detect and capture the invaders cooperatively by a team of homogeneous UAVs (called evaders)before invaders enter the restricted airspace. The problem of restricted airspace protection problem is formulated as a Multi-UAV Spatio-Temporal Multi-Task Allocation problem and is referred as MUST-MTA. The MUST-MTA problem is solved using a modified consensus-based bundled auction method. Here, the spatial and time constraints are handled by combining both spatial and temporal loss component. The solution identifies the sequence of spatial locations to be reached by the evader at specific time instants to neutralize the invaders. The performance of MUST-MTA with the consensus approach is evaluated in a simulated environment. The Monte-Carlo simulation results clearly indicate the efficacy of the proposed approach in restricted airspace protection against intruders",
        "published": "2020-11-23T07:13:42Z",
        "link": "http://arxiv.org/abs/2011.11247v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Envy-Free Allocations Respecting Social Networks",
        "authors": [
            "Robert Bredereck",
            "Andrzej Kaczmarczyk",
            "Rolf Niedermeier"
        ],
        "summary": "Finding an envy-free allocation of indivisible resources to agents is a central task in many multiagent systems. Often, non-trivial envy-free allocations do not exist, and, when they do, finding them can be computationally hard. Classical envy-freeness requires that every agent likes the resources allocated to it at least as much as the resources allocated to any other agent. In many situations this assumption can be relaxed since agents often do not even know each other. We enrich the envy-freeness concept by taking into account (directed) social networks of the agents. Thus, we require that every agent likes its own allocation at least as much as those of all its (out)neighbors. This leads to a \"more local\" concept of envy-freeness. We also consider a \"strong\" variant where every agent must like its own allocation more than those of all its (out)neighbors.   We analyze the classical and the parameterized complexity of finding allocations that are complete and, at the same time, envy-free with respect to one of the variants of our new concept. To this end, we study different restrictions of the agents' preferences and of the social network structure. We identify cases that become easier (from $\\Sigma^\\textrm{p}_2$-hard or NP-hard to polynomial-time solvability) and cases that become harder (from polynomial-time solvability to NP-hard) when comparing classical envy-freeness with our graph envy-freeness. Furthermore, we spot cases where graph envy-freeness is easier to decide than strong graph envy-freeness, and vice versa. On the route to one of our fixed-parameter tractability results, we also establish a connection to a directed and colored variant of the classical SUBGRAPH ISOMORPHISM problem, thereby extending a known fixed-parameter tractability result for the latter.",
        "published": "2020-11-23T18:14:15Z",
        "link": "http://arxiv.org/abs/2011.11596v1",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Modeling skier behavior for planning and management. Dynaski, an   agent-based in congested ski-areas",
        "authors": [
            "Alexis Poulhes",
            "Paul Mirial"
        ],
        "summary": "In leisure spaces, particularly theme parks and museums, researchers and managers have long been using simulation tools to tackle the big issue associated with attractiveness, flow management. In this research, we present the management and planning perspective of a multi-agent simulation tool which models the behavior of skiers in a ski-area. This is the first tool able to simulate and compare management and planning scenarios as well as their impacts on the comfort of skiers, in particular ski-area waiting times. This paper aims to integrate multiple data sources to calibrate the simulation on a real case study. An original field survey of users during a week details the skier population. The first average skier speeds are calculated from GPS data on one ordinary day. The validation data are used to calibrate the parameters of the behavioral model. A demonstration of the simulation tool is conducted on the La Plagne ski-area, one of the largest in France. A test case, the construction of new housing in a station near the ski-area, is conducted. An addition of 1620 new skiers delays the skier average waiting time by 12 pourcents.",
        "published": "2020-11-24T09:12:34Z",
        "link": "http://arxiv.org/abs/2011.11976v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "PowerNet: Multi-agent Deep Reinforcement Learning for Scalable Powergrid   Control",
        "authors": [
            "Dong Chen",
            "Kaian Chen. Zhaojian Li",
            "Tianshu Chu",
            "Rui Yao",
            "Feng Qiu",
            "Kaixiang Lin"
        ],
        "summary": "This paper develops an efficient multi-agent deep reinforcement learning algorithm for cooperative controls in powergrids. Specifically, we consider the decentralized inverter-based secondary voltage control problem in distributed generators (DGs), which is first formulated as a cooperative multi-agent reinforcement learning (MARL) problem. We then propose a novel on-policy MARL algorithm, PowerNet, in which each agent (DG) learns a control policy based on (sub-)global reward but local states from its neighboring agents. Motivated by the fact that a local control from one agent has limited impact on agents distant from it, we exploit a novel spatial discount factor to reduce the effect from remote agents, to expedite the training process and improve scalability. Furthermore, a differentiable, learning-based communication protocol is employed to foster the collaborations among neighboring agents. In addition, to mitigate the effects of system uncertainty and random noise introduced during on-policy learning, we utilize an action smoothing factor to stabilize the policy execution. To facilitate training and evaluation, we develop PGSim, an efficient, high-fidelity powergrid simulation platform. Experimental results in two microgrid setups show that the developed PowerNet outperforms a conventional model-based control, as well as several state-of-the-art MARL algorithms. The decentralized learning scheme and high sample efficiency also make it viable to large-scale power grids.",
        "published": "2020-11-24T20:22:36Z",
        "link": "http://arxiv.org/abs/2011.12354v2",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Mixed-Integer Linear Programming Models for Multi-Robot Non-Adversarial   Search",
        "authors": [
            "Beatriz A. Asfora",
            "Jacopo Banfi",
            "Mark Campbell"
        ],
        "summary": "In this letter, we consider the Multi-Robot Efficient Search Path Planning (MESPP) problem, where a team of robots is deployed in a graph-represented environment to capture a moving target within a given deadline. We prove this problem to be NP-hard, and present the first set of Mixed-Integer Linear Programming (MILP) models to tackle the MESPP problem. Our models are the first to encompass multiple searchers, arbitrary capture ranges, and false negatives simultaneously. While state-of-the-art algorithms for MESPP are based on simple path enumeration, the adoption of MILP as a planning paradigm allows to leverage the powerful techniques of modern solvers, yielding better computational performance and, as a consequence, longer planning horizons. The models are designed for computing optimal solutions offline, but can be easily adapted for a distributed online approach. Our simulations show that it is possible to achieve 98% decrease in computational time relative to the previous state-of-the-art. We also show that the distributed approach performs nearly as well as the centralized, within 6% in the settings studied in this letter, with the advantage of requiring significant less time - an important consideration in practical search missions.",
        "published": "2020-11-25T02:03:57Z",
        "link": "http://arxiv.org/abs/2011.12480v2",
        "categories": [
            "cs.RO",
            "cs.CC",
            "cs.MA"
        ]
    },
    {
        "title": "Coalition Control Model: A Dynamic Resource Distribution Method Based on   Model Predicative Control",
        "authors": [
            "Weizhi Du",
            "Harvey Tian"
        ],
        "summary": "Optimization of resource distribution has been a challenging topic in current society. To explore this topic, we develop a Coalition Control Model(CCM) based on the Model Predictive Control(MPC) and test it using a fishing model with linear parameters. The fishing model focuses on the problem of distributing fishing fleets in certain regions to maximize fish caught using either exhaustive or heuristic search. Our method introduces a communication mechanism to allow fishing fleets to merge or split, after which new coalitions can be automatically formed. Having the coalition structure stabilized, the system reaches the equilibrium state through the Nash-Bargaining process. Our experiments on the hypothetical fishing model demonstrated that the CCM can dynamically distribute limited resources in complex scenarios.",
        "published": "2020-11-25T13:23:20Z",
        "link": "http://arxiv.org/abs/2011.12711v1",
        "categories": [
            "cs.MA",
            "I.6.3, I.6.5"
        ]
    },
    {
        "title": "Modelling virus spreading in ride-pooling networks",
        "authors": [
            "Rafał Kucharski",
            "Oded Cats",
            "Julian Sienkiewicz"
        ],
        "summary": "Urban mobility needs alternative sustainable travel modes to keep our pandemic cities in motion. Ride-pooling, where a single vehicle is shared by more than one traveller, is not only appealing for mobility platforms and their travellers, but also for promoting the sustainability of urban mobility systems. Yet, the potential of ride-pooling rides to serve as a safe and effective alternative given the personal and public health risks considerations associated with the COVID-19 pandemic is hitherto unknown. To answer this, we combine epidemiological and behavioural shareability models to examine spreading among ride-pooling travellers, with an application for Amsterdam. Findings are at first sight devastating, with only few initially infected travellers needed to spread the virus to hundreds of ride-pooling users. Without intervention, ride-pooling system may substantially contribute to virus spreading. Notwithstanding, we identify an effective control measure allowing to halt the spreading before the outbreaks (at 50 instead of 800 infections) without sacrificing the efficiency achieved by pooling. Fixed matches among co-travellers disconnect the otherwise dense contact network, encapsulating the virus in small communities and preventing the outbreaks.",
        "published": "2020-11-25T14:32:14Z",
        "link": "http://arxiv.org/abs/2011.12770v3",
        "categories": [
            "physics.soc-ph",
            "cs.MA"
        ]
    },
    {
        "title": "MaaSSim -- agent-based two-sided mobility platform simulator",
        "authors": [
            "Rafał Kucharski",
            "Oded Cats"
        ],
        "summary": "Two-sided mobility platforms, such as Uber and Lyft, widely emerged in the urban mobility landscape, bringing disruptive changes to transportation systems worldwide. This calls for a simulation framework where researchers from various and across disciplines may introduce models aimed at representing the dynamics of platform-driven urban mobility systems. In this work, we present MaaSSim, an agent-based simulator reproducing the transport system used by two kind of agents: (i) travellers, requesting to travel from their origin to destination at a given time, and (ii) drivers supplying their travel needs by offering them rides. An intermediate agent, the platform, allows demand to be matched with supply. Agents are decision makers, specifically, travellers may decide which mode they use or reject an incoming offer. Similarly, drivers may opt-out from the system or reject incoming requests. All of the above behaviours are modelled through user-defined modules, representing agents' taste variations (heterogeneity), their previous experiences (learning) and available information (system control). MaaSSim is an open-source library available at a public repository github.com/RafalKucharskiPK/MaaSSim, along with a set of tutorials and reproducible use-case scenarios.",
        "published": "2020-11-25T15:32:13Z",
        "link": "http://arxiv.org/abs/2011.12827v1",
        "categories": [
            "cs.MA",
            "physics.soc-ph"
        ]
    },
    {
        "title": "TLeague: A Framework for Competitive Self-Play based Distributed   Multi-Agent Reinforcement Learning",
        "authors": [
            "Peng Sun",
            "Jiechao Xiong",
            "Lei Han",
            "Xinghai Sun",
            "Shuxing Li",
            "Jiawei Xu",
            "Meng Fang",
            "Zhengyou Zhang"
        ],
        "summary": "Competitive Self-Play (CSP) based Multi-Agent Reinforcement Learning (MARL) has shown phenomenal breakthroughs recently. Strong AIs are achieved for several benchmarks, including Dota 2, Glory of Kings, Quake III, StarCraft II, to name a few. Despite the success, the MARL training is extremely data thirsty, requiring typically billions of (if not trillions of) frames be seen from the environment during training in order for learning a high performance agent. This poses non-trivial difficulties for researchers or engineers and prevents the application of MARL to a broader range of real-world problems. To address this issue, in this manuscript we describe a framework, referred to as TLeague, that aims at large-scale training and implements several main-stream CSP-MARL algorithms. The training can be deployed in either a single machine or a cluster of hybrid machines (CPUs and GPUs), where the standard Kubernetes is supported in a cloud native manner. TLeague achieves a high throughput and a reasonable scale-up when performing distributed training. Thanks to the modular design, it is also easy to extend for solving other multi-agent problems or implementing and verifying MARL algorithms. We present experiments over StarCraft II, ViZDoom and Pommerman to show the efficiency and effectiveness of TLeague. The code is open-sourced and available at https://github.com/tencent-ailab/tleague_projpage",
        "published": "2020-11-25T17:24:20Z",
        "link": "http://arxiv.org/abs/2011.12895v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Message-Aware Graph Attention Networks for Large-Scale Multi-Robot Path   Planning",
        "authors": [
            "Qingbiao Li",
            "Weizhe Lin",
            "Zhe Liu",
            "Amanda Prorok"
        ],
        "summary": "The domains of transport and logistics are increasingly relying on autonomous mobile robots for the handling and distribution of passengers or resources. At large system scales, finding decentralized path planning and coordination solutions is key to efficient system performance. Recently, Graph Neural Networks (GNNs) have become popular due to their ability to learn communication policies in decentralized multi-agent systems. Yet, vanilla GNNs rely on simplistic message aggregation mechanisms that prevent agents from prioritizing important information. To tackle this challenge, in this paper, we extend our previous work that utilizes GNNs in multi-agent path planning by incorporating a novel mechanism to allow for message-dependent attention. Our Message-Aware Graph Attention neTwork (MAGAT) is based on a key-query-like mechanism that determines the relative importance of features in the messages received from various neighboring robots. We show that MAGAT is able to achieve a performance close to that of a coupled centralized expert algorithm. Further, ablation studies and comparisons to several benchmark models show that our attention mechanism is very effective across different robot densities and performs stably in different constraints in communication bandwidth. Experiments demonstrate that our model is able to generalize well in previously unseen problem instances, and that it achieves a 47\\% improvement over the benchmark success rate, even in very large-scale instances that are $\\times$100 larger than the training instances.",
        "published": "2020-11-26T10:37:13Z",
        "link": "http://arxiv.org/abs/2011.13219v2",
        "categories": [
            "cs.RO",
            "cs.DC",
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Adaptable Automation with Modular Deep Reinforcement Learning and Policy   Transfer",
        "authors": [
            "Zohreh Raziei",
            "Mohsen Moghaddam"
        ],
        "summary": "Recent advances in deep Reinforcement Learning (RL) have created unprecedented opportunities for intelligent automation, where a machine can autonomously learn an optimal policy for performing a given task. However, current deep RL algorithms predominantly specialize in a narrow range of tasks, are sample inefficient, and lack sufficient stability, which in turn hinder their industrial adoption. This article tackles this limitation by developing and testing a Hyper-Actor Soft Actor-Critic (HASAC) RL framework based on the notions of task modularization and transfer learning. The goal of the proposed HASAC is to enhance the adaptability of an agent to new tasks by transferring the learned policies of former tasks to the new task via a \"hyper-actor\". The HASAC framework is tested on a new virtual robotic manipulation benchmark, Meta-World. Numerical experiments show superior performance by HASAC over state-of-the-art deep RL algorithms in terms of reward value, success rate, and task completion time.",
        "published": "2020-11-27T03:09:05Z",
        "link": "http://arxiv.org/abs/2012.01934v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.HC",
            "cs.MA",
            "68T01, 68T40, 93C85"
        ]
    },
    {
        "title": "A methodology for co-constructing an interdisciplinary model: from model   to survey, from survey to model",
        "authors": [
            "Elise Beck",
            "Julie Dugdale",
            "Carole Adam",
            "Christelle Gaïdatzis",
            "Julius Bañgate"
        ],
        "summary": "How should computer science and social science collaborate to build a common model? How should they proceed to gather data that is really useful to the modelling? How can they design a survey that is tailored to the target model? This paper aims to answer those crucial questions in the framework of a multidisciplinary research project. This research addresses the issue of co-constructing a model when several disciplines are involved, and is applied to modelling human behaviour immediately after an earthquake. The main contribution of the work is to propose a tool dedicated to multidisciplinary dialogue. It also proposes a reflexive analysis of the enriching intellectual process carried out by the different disciplines involved. Finally, from working with an anthropologist, a complementary view of the multidisciplinary process is given.",
        "published": "2020-11-27T08:41:47Z",
        "link": "http://arxiv.org/abs/2011.13604v1",
        "categories": [
            "cs.CY",
            "cs.AI",
            "cs.MA",
            "I.6.5"
        ]
    },
    {
        "title": "A Probabilistic Guidance Approach to Swarm-to-Swarm Engagement Problem",
        "authors": [
            "Samet Uzun",
            "Nazim Kemal Ure"
        ],
        "summary": "This paper introduces a probabilistic guidance approach for the swarm-to-swarm engagement problem. The idea is based on driving the controlled swarm towards an adversary swarm, where the adversary swarm aims to converge to a stationary distribution that corresponds to a defended base location. The probabilistic approach is based on designing a Markov chain for the distribution of the swarm to converge a stationary distribution. This approach is decentralized, so each agent can propagate its position independently of other agents. Our main contribution is the formulation of the swarm-to-swarm engagement as an optimization problem where the population of each swarm decays with each engagement and determining a desired distribution for the controlled swarm to converge time-varying distribution and eliminate agents of the adversary swarm until adversary swarm enters the defended base location. We demonstrate the validity of proposed approach on several swarm engagement scenarios.",
        "published": "2020-11-28T12:52:27Z",
        "link": "http://arxiv.org/abs/2012.01928v1",
        "categories": [
            "math.OC",
            "cs.MA",
            "math.DS",
            "math.PR"
        ]
    },
    {
        "title": "Rules of the Road: Safety and Liveness Guarantees for Autonomous   Vehicles",
        "authors": [
            "Karena X. Cai",
            "Tung Phan-Minh",
            "Soon-Jo Chung",
            "Richard M. Murray"
        ],
        "summary": "The ability to guarantee safety and progress for all vehicles is vital to the success of the autonomous vehicle industry. We present a framework for designing autonomous vehicle behavior in a way that is safe and guarantees progress for all agents. In this paper, we first introduce a new game paradigm which we term the quasi-simultaneous game. We then define an agent protocol that all agents must use to make decisions in this quasi-simultaneous game setting. According to the protocol, agents first select an intended action using a behavioral profile. Then, the protocol defines whether an agent has precedence to take its intended action or must take a sub-optimal action. The protocol ensures safety under all traffic conditions and liveness for all agents under `sparse' traffic conditions. We provide proofs of correctness of the protocol and validate our results in simulation.",
        "published": "2020-11-28T15:37:05Z",
        "link": "http://arxiv.org/abs/2011.14148v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "A Q-values Sharing Framework for Multiagent Reinforcement Learning under   Budget Constraint",
        "authors": [
            "Changxi Zhu",
            "Ho-fung Leung",
            "Shuyue Hu",
            "Yi Cai"
        ],
        "summary": "In teacher-student framework, a more experienced agent (teacher) helps accelerate the learning of another agent (student) by suggesting actions to take in certain states. In cooperative multiagent reinforcement learning (MARL), where agents need to cooperate with one another, a student may fail to cooperate well with others even by following the teachers' suggested actions, as the polices of all agents are ever changing before convergence. When the number of times that agents communicate with one another is limited (i.e., there is budget constraint), the advising strategy that uses actions as advices may not be good enough. We propose a partaker-sharer advising framework (PSAF) for cooperative MARL agents learning with budget constraint. In PSAF, each Q-learner can decide when to ask for Q-values and share its Q-values. We perform experiments in three typical multiagent learning problems. Evaluation results show that our approach PSAF outperforms existing advising methods under both unlimited and limited budget, and we give an analysis of the impact of advising actions and sharing Q-values on agents' learning.",
        "published": "2020-11-29T04:51:57Z",
        "link": "http://arxiv.org/abs/2011.14281v1",
        "categories": [
            "cs.MA",
            "93A16 (Primary) 68T05 (Secondary)"
        ]
    },
    {
        "title": "Reinforcement Learning in Linear Quadratic Deep Structured Teams: Global   Convergence of Policy Gradient Methods",
        "authors": [
            "Vida Fathi",
            "Jalal Arabneydi",
            "Amir G. Aghdam"
        ],
        "summary": "In this paper, we study the global convergence of model-based and model-free policy gradient descent and natural policy gradient descent algorithms for linear quadratic deep structured teams. In such systems, agents are partitioned into a few sub-populations wherein the agents in each sub-population are coupled in the dynamics and cost function through a set of linear regressions of the states and actions of all agents. Every agent observes its local state and the linear regressions of states, called deep states. For a sufficiently small risk factor and/or sufficiently large population, we prove that model-based policy gradient methods globally converge to the optimal solution. Given an arbitrary number of agents, we develop model-free policy gradient and natural policy gradient algorithms for the special case of risk-neutral cost function. The proposed algorithms are scalable with respect to the number of agents due to the fact that the dimension of their policy space is independent of the number of agents in each sub-population. Simulations are provided to verify the theoretical results.",
        "published": "2020-11-29T16:02:39Z",
        "link": "http://arxiv.org/abs/2011.14393v2",
        "categories": [
            "cs.MA",
            "cs.LG",
            "cs.SY",
            "eess.SY",
            "math.OC"
        ]
    },
    {
        "title": "Low-Bandwidth Communication Emerges Naturally in Multi-Agent Learning   Systems",
        "authors": [
            "Niko A. Grupen",
            "Daniel D. Lee",
            "Bart Selman"
        ],
        "summary": "In this work, we study emergent communication through the lens of cooperative multi-agent behavior in nature. Using insights from animal communication, we propose a spectrum from low-bandwidth (e.g. pheromone trails) to high-bandwidth (e.g. compositional language) communication that is based on the cognitive, perceptual, and behavioral capabilities of social agents. Through a series of experiments with pursuit-evasion games, we identify multi-agent reinforcement learning algorithms as a computational model for the low-bandwidth end of the communication spectrum.",
        "published": "2020-11-30T15:29:57Z",
        "link": "http://arxiv.org/abs/2011.14890v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Pabulib: A Participatory Budgeting Library",
        "authors": [
            "Dariusz Stolicki",
            "Stanisław Szufa",
            "Nimrod Talmon"
        ],
        "summary": "We describe the PArticipatory BUdgeting LIBrary website (in short, Pabulib), which can be accessed via http://pabulib.org/, and which is a library of participatory budgeting data. In particular, we describe the file format (.pb) that is used for instances of participatory budgeting.",
        "published": "2020-12-01T08:23:28Z",
        "link": "http://arxiv.org/abs/2012.06539v1",
        "categories": [
            "cs.DC",
            "cs.MA"
        ]
    },
    {
        "title": "Gaussian Process Based Message Filtering for Robust Multi-Agent   Cooperation in the Presence of Adversarial Communication",
        "authors": [
            "Rupert Mitchell",
            "Jan Blumenkamp",
            "Amanda Prorok"
        ],
        "summary": "In this paper, we consider the problem of providing robustness to adversarial communication in multi-agent systems. Specifically, we propose a solution towards robust cooperation, which enables the multi-agent system to maintain high performance in the presence of anonymous non-cooperative agents that communicate faulty, misleading or manipulative information. In pursuit of this goal, we propose a communication architecture based on Graph Neural Networks (GNNs), which is amenable to a novel Gaussian Process (GP)-based probabilistic model characterizing the mutual information between the simultaneous communications of different agents due to their physical proximity and relative position. This model allows agents to locally compute approximate posterior probabilities, or confidences, that any given one of their communication partners is being truthful. These confidences can be used as weights in a message filtering scheme, thereby suppressing the influence of suspicious communication on the receiving agent's decisions. In order to assess the efficacy of our method, we introduce a taxonomy of non-cooperative agents, which distinguishes them by the amount of information available to them. We demonstrate in two distinct experiments that our method performs well across this taxonomy, outperforming alternative methods. For all but the best informed adversaries, our filtering method is able to reduce the impact that non-cooperative agents cause, reducing it to the point of negligibility, and with negligible cost to performance in the absence of adversaries.",
        "published": "2020-12-01T14:21:58Z",
        "link": "http://arxiv.org/abs/2012.00508v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Multi-Objective Optimization of the Textile Manufacturing Process Using   Deep-Q-Network Based Multi-Agent Reinforcement Learning",
        "authors": [
            "Zhenglei He",
            "Kim Phuc Tran",
            "Sebastien Thomassey",
            "Xianyi Zeng",
            "Jie Xu",
            "Changhai Yi"
        ],
        "summary": "Multi-objective optimization of the textile manufacturing process is an increasing challenge because of the growing complexity involved in the development of the textile industry. The use of intelligent techniques has been often discussed in this domain, although a significant improvement from certain successful applications has been reported, the traditional methods failed to work with high-as well as human intervention. Upon which, this paper proposed a multi-agent reinforcement learning (MARL) framework to transform the optimization process into a stochastic game and introduced the deep Q-networks algorithm to train the multiple agents. A utilitarian selection mechanism was employed in the stochastic game, which (-greedy policy) in each state to avoid the interruption of multiple equilibria and achieve the correlated equilibrium optimal solutions of the optimizing process. The case study result reflects that the proposed MARL system is possible to achieve the optimal solutions for the textile ozonation process and it performs better than the traditional approaches.",
        "published": "2020-12-02T11:37:44Z",
        "link": "http://arxiv.org/abs/2012.01101v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Vision-based Drone Flocking in Outdoor Environments",
        "authors": [
            "Fabian Schilling",
            "Fabrizio Schiano",
            "Dario Floreano"
        ],
        "summary": "Decentralized deployment of drone swarms usually relies on inter-agent communication or visual markers that are mounted on the vehicles to simplify their mutual detection. This letter proposes a vision-based detection and tracking algorithm that enables groups of drones to navigate without communication or visual markers. We employ a convolutional neural network to detect and localize nearby agents onboard the quadcopters in real-time. Rather than manually labeling a dataset, we automatically annotate images to train the neural network using background subtraction by systematically flying a quadcopter in front of a static camera. We use a multi-agent state tracker to estimate the relative positions and velocities of nearby agents, which are subsequently fed to a flocking algorithm for high-level control. The drones are equipped with multiple cameras to provide omnidirectional visual inputs. The camera setup ensures the safety of the flock by avoiding blind spots regardless of the agent configuration. We evaluate the approach with a group of three real quadcopters that are controlled using the proposed vision-based flocking algorithm. The results show that the drones can safely navigate in an outdoor environment despite substantial background clutter and difficult lighting conditions. The source code, image dataset, and trained detection model are available at https://github.com/lis-epfl/vswarm.",
        "published": "2020-12-02T14:44:40Z",
        "link": "http://arxiv.org/abs/2012.01245v2",
        "categories": [
            "cs.RO",
            "cs.CV",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Improving Solution Quality of Bounded Max-Sum Algorithm to Solve DCOPs   involving Hard and Soft Constraints",
        "authors": [
            "Md. Musfiqur Rahman",
            "Mashrur Rashik",
            "Md. Mamun-or-Rashid",
            "Md. Mosaddek Khan"
        ],
        "summary": "Bounded Max-Sum (BMS) is a message-passing algorithm that provides approximation solution to a specific form of de-centralized coordination problems, namely Distributed Constrained Optimization Problems (DCOPs). In particular, BMS algorithm is able to solve problems of this type having large search space at the expense of low computational cost. Notably, the traditional DCOP formulation does not consider those constraints that must be satisfied(also known as hard constraints), rather it concentrates only on soft constraints. Hence, although the presence of both types of constraints are observed in a number of real-world applications, the BMS algorithm does not actively capitalize on the hard constraints. To address this issue, we tailor BMS in such a way that can deal with DCOPs having both type constraints. In so doing, our approach improves the solution quality of the algorithm. The empirical results exhibit a marked improvement in the quality of the solutions of large DCOPs.",
        "published": "2020-12-02T18:10:14Z",
        "link": "http://arxiv.org/abs/2012.01369v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Second-Order Guarantees in Federated Learning",
        "authors": [
            "Stefan Vlaski",
            "Elsa Rizk",
            "Ali H. Sayed"
        ],
        "summary": "Federated learning is a useful framework for centralized learning from distributed data under practical considerations of heterogeneity, asynchrony, and privacy. Federated architectures are frequently deployed in deep learning settings, which generally give rise to non-convex optimization problems. Nevertheless, most existing analysis are either limited to convex loss functions, or only establish first-order stationarity, despite the fact that saddle-points, which are first-order stationary, are known to pose bottlenecks in deep learning. We draw on recent results on the second-order optimality of stochastic gradient algorithms in centralized and decentralized settings, and establish second-order guarantees for a class of federated learning algorithms.",
        "published": "2020-12-02T19:30:08Z",
        "link": "http://arxiv.org/abs/2012.01474v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "eess.SP",
            "math.OC",
            "stat.ML"
        ]
    },
    {
        "title": "Modeling Adverse Conditions in the Framework of Graph Transformation   Systems",
        "authors": [
            "Okan Özkan"
        ],
        "summary": "The concept of adverse conditions addresses systems interacting with an adversary environment and finds use also in the development of new technologies. We present an approach for modeling adverse conditions by graph transformation systems. In contrast to other approaches for graph-transformational interacting systems, the presented main constructs are graph transformation systems. We introduce joint graph transformation systems which involve a system, an interfering environment, and an automaton modeling their interaction. For joint graph transformation systems, we introduce notions of (partial) correctness under adverse conditions, which contain the correctness of the system and a recovery condition. As main result, we show that two instances of correctness, namely k-step correctness (recovery in at most k steps after an environment intervention) and last-minute correctness (recovery until next environment intervention) are expressible in LTL (linear temporal logic), and that a weaker notion of k-step correctness is expressible in CTL (computation tree logic).",
        "published": "2020-12-03T02:27:39Z",
        "link": "http://arxiv.org/abs/2012.01657v1",
        "categories": [
            "cs.LO",
            "cs.MA"
        ]
    },
    {
        "title": "Emergent Complexity and Zero-shot Transfer via Unsupervised Environment   Design",
        "authors": [
            "Michael Dennis",
            "Natasha Jaques",
            "Eugene Vinitsky",
            "Alexandre Bayen",
            "Stuart Russell",
            "Andrew Critch",
            "Sergey Levine"
        ],
        "summary": "A wide range of reinforcement learning (RL) problems - including robustness, transfer learning, unsupervised RL, and emergent complexity - require specifying a distribution of tasks or environments in which a policy will be trained. However, creating a useful distribution of environments is error prone, and takes a significant amount of developer time and effort. We propose Unsupervised Environment Design (UED) as an alternative paradigm, where developers provide environments with unknown parameters, and these parameters are used to automatically produce a distribution over valid, solvable environments. Existing approaches to automatically generating environments suffer from common failure modes: domain randomization cannot generate structure or adapt the difficulty of the environment to the agent's learning progress, and minimax adversarial training leads to worst-case environments that are often unsolvable. To generate structured, solvable environments for our protagonist agent, we introduce a second, antagonist agent that is allied with the environment-generating adversary. The adversary is motivated to generate environments which maximize regret, defined as the difference between the protagonist and antagonist agent's return. We call our technique Protagonist Antagonist Induced Regret Environment Design (PAIRED). Our experiments demonstrate that PAIRED produces a natural curriculum of increasingly complex environments, and PAIRED agents achieve higher zero-shot transfer performance when tested in highly novel environments.",
        "published": "2020-12-03T17:37:01Z",
        "link": "http://arxiv.org/abs/2012.02096v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Steady-State Planning in Expected Reward Multichain MDPs",
        "authors": [
            "George K. Atia",
            "Andre Beckus",
            "Ismail Alkhouri",
            "Alvaro Velasquez"
        ],
        "summary": "The planning domain has experienced increased interest in the formal synthesis of decision-making policies. This formal synthesis typically entails finding a policy which satisfies formal specifications in the form of some well-defined logic. While many such logics have been proposed with varying degrees of expressiveness and complexity in their capacity to capture desirable agent behavior, their value is limited when deriving decision-making policies which satisfy certain types of asymptotic behavior in general system models. In particular, we are interested in specifying constraints on the steady-state behavior of an agent, which captures the proportion of time an agent spends in each state as it interacts for an indefinite period of time with its environment. This is sometimes called the average or expected behavior of the agent and the associated planning problem is faced with significant challenges unless strong restrictions are imposed on the underlying model in terms of the connectivity of its graph structure. In this paper, we explore this steady-state planning problem that consists of deriving a decision-making policy for an agent such that constraints on its steady-state behavior are satisfied. A linear programming solution for the general case of multichain Markov Decision Processes (MDPs) is proposed and we prove that optimal solutions to the proposed programs yield stationary policies with rigorous guarantees of behavior.",
        "published": "2020-12-03T18:54:24Z",
        "link": "http://arxiv.org/abs/2012.02178v2",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Decentralized Multi-target Tracking with Multiple Quadrotors using a PHD   Filter",
        "authors": [
            "Aniket Shirsat",
            "Spring Berman"
        ],
        "summary": "We consider a scenario in which a group of quadrotors is tasked at tracking multiple stationary targets in an unknown, bounded environment. The quadrotors search for targets along a spatial grid overlaid on the environment while performing a random walk on this grid modeled by a discrete-time discrete-state (DTDS) Markov chain. The quadrotors can transmit their estimates of the target locations to other quadrotors that occupy their current location on the grid; thus, their communication network is time-varying and not necessarily connected. We model the search procedure as a renewal-reward process on the underlying DTDS Markov chain. To accommodate changes in the set of targets observed by each quadrotor as it explores the environment, along with uncertainties in the quadrotors' measurements of the targets, we formulate the tracking problem in terms of Random Finite Sets (RFS). The quadrotors use RFS-based Probability Hypothesis Density (PHD) filters to estimate the number of targets and their locations. We present a theoretical estimation framework, based on the Gaussian Mixture formulation of the PHD filter, and preliminary simulation results toward extending existing approaches for RFS-based multi-target tracking to a decentralized multi-robot strategy for multi-target tracking. We validate this approach with simulations of multi-target tracking scenarios with different densities of robots and targets, and we evaluate the average time required for the robots in each scenario to reach agreement on a common set of targets.",
        "published": "2020-12-04T00:07:02Z",
        "link": "http://arxiv.org/abs/2012.02340v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Decentralized State-Dependent Markov Chain Synthesis with an Application   to Swarm Guidance",
        "authors": [
            "Samet Uzun",
            "Nazim Kemal Ure",
            "Behcet Acikmese"
        ],
        "summary": "This paper introduces a decentralized state-dependent Markov chain synthesis (DSMC) algorithm for finite-state Markov chains. We present a state-dependent consensus protocol that achieves exponential convergence under mild technical conditions, without relying on any connectivity assumptions regarding the dynamic network topology. Utilizing the proposed consensus protocol, we develop the DSMC algorithm, updating the Markov matrix based on the current state while ensuring the convergence conditions of the consensus protocol. This result establishes the desired steady-state distribution for the resulting Markov chain, ensuring exponential convergence from all initial distributions while adhering to transition constraints and minimizing state transitions. The DSMC's performance is demonstrated through a probabilistic swarm guidance example, which interprets the spatial distribution of a swarm comprising a large number of mobile agents as a probability distribution and utilizes the Markov chain to compute transition probabilities between states. Simulation results demonstrate faster convergence for the DSMC based algorithm when compared to the previous Markov chain based swarm guidance algorithms.",
        "published": "2020-12-04T14:10:54Z",
        "link": "http://arxiv.org/abs/2012.02303v2",
        "categories": [
            "math.OC",
            "cs.MA",
            "math.DS",
            "math.PR"
        ]
    },
    {
        "title": "Polarization and Belief Convergence of Agents in Strongly-Connected   Influence Graphs",
        "authors": [
            "Mário S. Alvim",
            "Bernardo Amorim",
            "Sophia Knight",
            "Santiago Quintero",
            "Frank Valencia"
        ],
        "summary": "We describe a model for polarization in multi-agent systems based on Esteban and Ray's classic measure of polarization from economics. Agents evolve by updating their beliefs (opinions) based on the beliefs of others and an underlying influence graph. We show that polarization eventually disappears (converges to zero) if the influence graph is strongly-connected. If the influence graph is a circulation we determine the unique belief value all agents converge to. For clique influence graphs we determine the time after which agents will reach a given difference of opinion. Our results imply that if polarization does not disappear then either there is a disconnected subgroup of agents or some agent influences others more than she is influenced. Finally, we show that polarization does not necessarily vanish in weakly-connected graphs, and illustrate the model with a series of case studies and simulations giving some insights about polarization.",
        "published": "2020-12-04T16:21:13Z",
        "link": "http://arxiv.org/abs/2012.02703v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "An Improved Simulation Model for Pedestrian Crowd Evacuation",
        "authors": [
            "Danial A. Muhammed",
            "Tarik A. Rashid",
            "Abeer Alsadoon",
            "Nebojsa Bacanin",
            "Polla Fattah",
            "Mokhtar Mohammadi",
            "Indradip Banerjee"
        ],
        "summary": "This paper works on one of the most recent pedestrian crowd evacuation models, i.e., \"a simulation model for pedestrian crowd evacuation based on various AI techniques\", developed in late 2019. This study adds a new feature to the developed model by proposing a new method and integrating it with the model. This method enables the developed model to find a more appropriate evacuation area design, among others regarding safety due to selecting the best exit door location among many suggested locations. This method is completely dependent on the selected model's output, i.e., the evacuation time for each individual within the evacuation process. The new method finds an average of the evacuees' evacuation times of each exit door location; then, based on the average evacuation time, it decides which exit door location would be the best exit door to be used for evacuation by the evacuees. To validate the method, various designs for the evacuation area with various written scenarios were used. The results showed that the model with this new method could predict a proper exit door location among many suggested locations. Lastly, from the results of this research using the integration of this newly proposed method, a new capability for the selected model in terms of safety allowed the right decision in selecting the finest design for the evacuation area among other designs.",
        "published": "2020-12-04T18:25:03Z",
        "link": "http://arxiv.org/abs/2012.09135v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Modeling Voters in Multi-Winner Approval Voting",
        "authors": [
            "Jaelle Scheuerman",
            "Jason Harman",
            "Nicholas Mattei",
            "K. Brent Venable"
        ],
        "summary": "In many real world situations, collective decisions are made using voting and, in scenarios such as committee or board elections, employing voting rules that return multiple winners. In multi-winner approval voting (AV), an agent submits a ballot consisting of approvals for as many candidates as they wish, and winners are chosen by tallying up the votes and choosing the top-$k$ candidates receiving the most approvals. In many scenarios, an agent may manipulate the ballot they submit in order to achieve a better outcome by voting in a way that does not reflect their true preferences. In complex and uncertain situations, agents may use heuristics instead of incurring the additional effort required to compute the manipulation which most favors them. In this paper, we examine voting behavior in single-winner and multi-winner approval voting scenarios with varying degrees of uncertainty using behavioral data obtained from Mechanical Turk. We find that people generally manipulate their vote to obtain a better outcome, but often do not identify the optimal manipulation. There are a number of predictive models of agent behavior in the COMSOC and psychology literature that are based on cognitively plausible heuristic strategies. We show that the existing approaches do not adequately model real-world data. We propose a novel model that takes into account the size of the winning set and human cognitive constraints, and demonstrate that this model is more effective at capturing real-world behaviors in multi-winner approval voting scenarios.",
        "published": "2020-12-04T19:24:28Z",
        "link": "http://arxiv.org/abs/2012.02811v1",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.MA",
            "91A80, 91B10, 91B12, 91B14",
            "J.4; I.2"
        ]
    },
    {
        "title": "Multi-agent navigation based on deep reinforcement learning and   traditional pathfinding algorithm",
        "authors": [
            "Hongda Qiu"
        ],
        "summary": "We develop a new framework for multi-agent collision avoidance problem. The framework combined traditional pathfinding algorithm and reinforcement learning. In our approach, the agents learn whether to be navigated or to take simple actions to avoid their partners via a deep neural network trained by reinforcement learning at each time step. This framework makes it possible for agents to arrive terminal points in abstract new scenarios. In our experiments, we use Unity3D and Tensorflow to build the model and environment for our scenarios. We analyze the results and modify the parameters to approach a well-behaved strategy for our agents. Our strategy could be attached in different environments under different cases, especially when the scale is large.",
        "published": "2020-12-05T08:56:58Z",
        "link": "http://arxiv.org/abs/2012.09134v1",
        "categories": [
            "cs.MA",
            "cs.LG",
            "cs.RO"
        ]
    },
    {
        "title": "Exploration-Exploitation in Multi-Agent Learning: Catastrophe Theory   Meets Game Theory",
        "authors": [
            "Stefanos Leonardos",
            "Georgios Piliouras"
        ],
        "summary": "Exploration-exploitation is a powerful and practical tool in multi-agent learning (MAL), however, its effects are far from understood. To make progress in this direction, we study a smooth analogue of Q-learning. We start by showing that our learning model has strong theoretical justification as an optimal model for studying exploration-exploitation. Specifically, we prove that smooth Q-learning has bounded regret in arbitrary games for a cost model that explicitly captures the balance between game and exploration costs and that it always converges to the set of quantal-response equilibria (QRE), the standard solution concept for games under bounded rationality, in weighted potential games with heterogeneous learning agents. In our main task, we then turn to measure the effect of exploration in collective system performance. We characterize the geometry of the QRE surface in low-dimensional MAL systems and link our findings with catastrophe (bifurcation) theory. In particular, as the exploration hyperparameter evolves over-time, the system undergoes phase transitions where the number and stability of equilibria can change radically given an infinitesimal change to the exploration parameter. Based on this, we provide a formal theoretical treatment of how tuning the exploration parameter can provably lead to equilibrium selection with both positive as well as negative (and potentially unbounded) effects to system performance.",
        "published": "2020-12-05T17:37:22Z",
        "link": "http://arxiv.org/abs/2012.03083v2",
        "categories": [
            "cs.GT",
            "cs.MA",
            "math.DS",
            "93A16, 91A26, 91A68, 58K35",
            "G.3; J.4; F.2.2"
        ]
    },
    {
        "title": "Distributed Multi-agent Meta Learning for Trajectory Design in Wireless   Drone Networks",
        "authors": [
            "Ye Hu",
            "Mingzhe Chen",
            "Walid Saad",
            "H. Vincent Poor",
            "Shuguang Cui"
        ],
        "summary": "In this paper, the problem of the trajectory design for a group of energy-constrained drones operating in dynamic wireless network environments is studied. In the considered model, a team of drone base stations (DBSs) is dispatched to cooperatively serve clusters of ground users that have dynamic and unpredictable uplink access demands. In this scenario, the DBSs must cooperatively navigate in the considered area to maximize coverage of the dynamic requests of the ground users. This trajectory design problem is posed as an optimization framework whose goal is to find optimal trajectories that maximize the fraction of users served by all DBSs. To find an optimal solution for this non-convex optimization problem under unpredictable environments, a value decomposition based reinforcement learning (VDRL) solution coupled with a meta-training mechanism is proposed. This algorithm allows the DBSs to dynamically learn their trajectories while generalizing their learning to unseen environments. Analytical results show that, the proposed VD-RL algorithm is guaranteed to converge to a local optimal solution of the non-convex optimization problem. Simulation results show that, even without meta-training, the proposed VD-RL algorithm can achieve a 53.2% improvement of the service coverage and a 30.6% improvement in terms of the convergence speed, compared to baseline multi-agent algorithms. Meanwhile, the use of meta-learning improves the convergence speed of the VD-RL algorithm by up to 53.8% when the DBSs must deal with a previously unseen task.",
        "published": "2020-12-06T01:30:12Z",
        "link": "http://arxiv.org/abs/2012.03158v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "V2I-Based Platooning Design with Delay Awareness",
        "authors": [
            "Lifeng Wang",
            "Yu Duan",
            "Yun Lai",
            "Shizhuo Mu",
            "Xiang Li"
        ],
        "summary": "This paper studies the vehicle platooning system based on vehicle-to-infrastructure (V2I) communication, where all the vehicles in the platoon upload their driving state information to the roadside unit (RSU), and RSU makes the platoon control decisions with the assistance of edge computing. By addressing the delay concern, a platoon control approach is proposed to achieve plant stability and string stability. The effects of the time headway, communication and edge computing delays on the stability are quantified. The velocity and size of the stable platoon are calculated, which show the impacts of the radio parameters such as massive MIMO antennas and frequency band on the platoon configuration. The handover performance between RSUs in the V2I-based platooning system is quantified by considering the effects of the RSU's coverage and platoon size, which demonstrates that the velocity of a stable platoon should be appropriately chosen, in order to meet the V2I's Quality-of-Service and handover constraints.",
        "published": "2020-12-06T11:44:42Z",
        "link": "http://arxiv.org/abs/2012.03243v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Budget-feasible Maximum Nash Social Welfare Allocation is Almost   Envy-free",
        "authors": [
            "Xiaowei Wu",
            "Bo Li",
            "Jiarui Gan"
        ],
        "summary": "The Nash social welfare (NSW) is a well-known social welfare measurement that balances individual utilities and the overall efficiency. In the context of fair allocation of indivisible goods, it has been shown by Caragiannis et al. (EC 2016 and TEAC 2019) that an allocation maximizing the NSW is envy-free up to one good (EF1). In this paper, we are interested in the fairness of the NSW in a budget-feasible allocation problem, in which each item has a cost that will be incurred to the agent it is allocated to, and each agent has a budget constraint on the total cost of items she receives. We show that a budget-feasible allocation that maximizes the NSW achieves a 1/4-approximation of EF1 and the approximation ratio is tight. The approximation ratio improves gracefully when the items have small costs compared with the agents' budgets; it converges to 1/2 when the budget-cost ratio approaches infinity.",
        "published": "2020-12-07T15:07:40Z",
        "link": "http://arxiv.org/abs/2012.03766v1",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Learning Compositional Negation in Populations of Roth-Erev and Neural   Agents",
        "authors": [
            "Graham Todd",
            "Shane Steinert-Threlkeld",
            "Christopher Potts"
        ],
        "summary": "Agent-based models and signalling games are useful tools with which to study the emergence of linguistic communication in a tractable setting. These techniques have been used to study the compositional property of natural languages, but have been limited in how closely they model real communicators. In this work, we present a novel variant of the classic signalling game that explores the learnability of simple compositional rules concerning negation. The approach builds on the work of Steinert-Threlkeld (2016) by allowing agents to determine the identity of the \"function word\" representing negation while simultaneously learning to assign meanings to atomic symbols. We extend the analysis with the introduction of a population of concurrently communicating agents, and explore how the complications brought about by a larger population size affect the type and stability of the signalling systems learned. We also relax assumptions of the parametric form of the learning agents and examine how neural network-based agents optimized through reinforcement learning behave under various task settings. We find that basic compositional properties are robustly learnable across a wide range of model relaxations and agent instantiations.",
        "published": "2020-12-07T23:20:15Z",
        "link": "http://arxiv.org/abs/2012.04107v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Improved Swarm Engineering: Aligning Intuition and Analysis",
        "authors": [
            "John Harwell",
            "Maria Gini"
        ],
        "summary": "We present a set of metrics intended to supplement designer intuitions when designing swarm-robotic systems, increase accuracy in extrapolating swarm behavior from algorithmic descriptions and small test experiments, and lead to faster and less costly design cycles. We build on previous works studying self-organizing behaviors in autonomous systems to derive a metric for swarm emergent self-organization. We utilize techniques from high performance computing, time series analysis, and queueing theory to derive metrics for swarm scalability, flexibility to changing external environments, and robustness to internal system stimuli such as sensor and actuator noise and robot failures. We demonstrate the utility of our metrics by analyzing four different control algorithms in two scenarios: an indoor warehouse object transport scenario with static objects and a spatially unconstrained outdoor search and rescue scenario with moving objects. In the spatially constrained warehouse scenario, efficient use of space is key to success so algorithms that use mechanisms for traffic regulation and congestion reduction are the most appropriate. In the search and rescue scenario, the same will happen with algorithms which can cope well with object motion through dynamic task allocation and randomized search trajectories. We show that our intuitions about comparative algorithm performance are well supported by the quantitative results obtained using our metrics, and that our metrics can be synergistically used together to predict collective behaviors based on previous results in some cases.",
        "published": "2020-12-08T01:08:08Z",
        "link": "http://arxiv.org/abs/2012.04144v2",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "A wireless signal-based sensing framework for robotics",
        "authors": [
            "Ninad Jadhav",
            "Weiying Wang",
            "Diana Zhang",
            "Oussama Khatib",
            "Swarun Kumar",
            "Stephanie Gil"
        ],
        "summary": "In this paper we develop the analytical framework for a novel Wireless signal-based Sensing capability for Robotics (WSR) by leveraging robots' mobility. It allows robots to primarily measure relative direction, or Angle-of-Arrival (AOA), to other robots, while operating in non-line-of-sight unmapped environments and without requiring external infrastructure. We do so by capturing all of the paths that a wireless signal traverses as it travels from a transmitting to a receiving robot in the team, which we term as an AOA profile. The key intuition behind our approach is to enable a robot to emulate antenna arrays as it moves freely in 2D and 3D space. The small differences in the phase of the wireless signals are thus processed with knowledge of robots' local displacement to obtain the profile, via a method akin to Synthetic Aperture Radar (SAR). The main contribution of this work is the development of i) a framework to accommodate arbitrary 2D and 3D motion, as well as continuous mobility of both signal transmitting and receiving robots, while computing AOA profiles between them and ii) a Cramer-Rao Bound analysis, based on antenna array theory, that provides a lower bound on the variance in AOA estimation as a function of the geometry of robot motion. We show that allowing robots to use their full mobility in 3D space while performing SAR, results in more accurate AOA profiles and thus better AOA estimation. All analytical developments are substantiated by extensive simulation and hardware experiments on air/ground robot platforms using 5 GHz WiFi. Our experimental results bolster our analytical findings, demonstrating that 3D motion provides enhanced and consistent accuracy, with total AOA error of less than 10 degree for 95% of trials. We also analytically characterize the impact of displacement estimation errors on the measured AOA.",
        "published": "2020-12-08T02:31:06Z",
        "link": "http://arxiv.org/abs/2012.04174v5",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Deterministic Privacy Preservation in Static Average Consensus Problem",
        "authors": [
            "Amir-Salar Esteki",
            "Solmaz S. Kia"
        ],
        "summary": "In this paper we consider the problem of privacy preservation in the static average consensus problem. This problem normally is solved by proposing privacy preservation augmentations for the popular first order Laplacian-based algorithm. These mechanisms however come with computational overhead, may need coordination among the agents to choose their parameters and also alter the transient response of the algorithm. In this paper we show that an alternative iterative algorithm that is proposed in the literature in the context of dynamic average consensus problem has intrinsic privacy preservation and can be used as a privacy preserving algorithm that yields the same performance behavior as the well-known Laplacian consensus algorithm but without the overheads that come with the existing privacy preservation methods.",
        "published": "2020-12-08T04:59:29Z",
        "link": "http://arxiv.org/abs/2012.04213v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Impact of Heterogeneity in Multi-Robot Systems on Collective Behaviors   Studied Using a Search and Rescue Problem",
        "authors": [
            "Sanjay Sarma O V",
            "Ramviyas Parasuraman",
            "Ramana Pidaparti"
        ],
        "summary": "Many species in nature demonstrate symbiotic relationships leading to emergent behaviors through cooperation, which are sometimes beyond the scope of the partnerships within the same species. These symbiotic relationships are classified as mutualism, commensalism, and parasitism based on the benefit levels involved. While these partnerships are ubiquitous in nature, it is imperative to understand the benefits of collective behaviors in designing heterogeneous multi-robot systems (HMRS). In this paper, we investigate the impact of heterogeneity on the performance of HMRS applied to a search and rescue problem. The groups consisting of searchers and rescuers, varied in the individual robot behaviors with multiple degrees of functionality overlap and group compositions, demonstrating various levels of heterogeneity. We propose a new technique to measure heterogeneity in the agents through the use of Behavior Trees and use it to obtain heterogeneity informatics from our Monte Carlo simulations. The results show a positive correlation between the group's heterogeneity measure and the rescue efficiency demonstrating benefits in most of the scenarios. However, we also see cases where heterogeneity may hamper the group's abilities pointing to the need for determining the optimal heterogeneity in group required to maximally benefit from HMRS in real-world applications.",
        "published": "2020-12-08T14:31:14Z",
        "link": "http://arxiv.org/abs/2012.14329v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Resolving Implicit Coordination in Multi-Agent Deep Reinforcement   Learning with Deep Q-Networks & Game Theory",
        "authors": [
            "Griffin Adams",
            "Sarguna Janani Padmanabhan",
            "Shivang Shekhar"
        ],
        "summary": "We address two major challenges of implicit coordination in multi-agent deep reinforcement learning: non-stationarity and exponential growth of state-action space, by combining Deep-Q Networks for policy learning with Nash equilibrium for action selection. Q-values proxy as payoffs in Nash settings, and mutual best responses define joint action selection. Coordination is implicit because multiple/no Nash equilibria are resolved deterministically. We demonstrate that knowledge of game type leads to an assumption of mirrored best responses and faster convergence than Nash-Q. Specifically, the Friend-or-Foe algorithm demonstrates signs of convergence to a Set Controller which jointly chooses actions for two agents. This encouraging given the highly unstable nature of decentralized coordination over joint actions. Inspired by the dueling network architecture, which decouples the Q-function into state and advantage streams, as well as residual networks, we learn both a single and joint agent representation, and merge them via element-wise addition. This simplifies coordination by recasting it is as learning a residual function. We also draw high level comparative insights on key MADRL and game theoretic variables: competitive vs. cooperative, asynchronous vs. parallel learning, greedy versus socially optimal Nash equilibria tie breaking, and strategies for the no Nash equilibrium case. We evaluate on 3 custom environments written in Python using OpenAI Gym: a Predator Prey environment, an alternating Warehouse environment, and a Synchronization environment. Each environment requires successively more coordination to achieve positive rewards.",
        "published": "2020-12-08T17:30:47Z",
        "link": "http://arxiv.org/abs/2012.09136v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Multi-agent control of airplane wing stability under the flexural   torsion flutter",
        "authors": [
            "Dmitry S. Shalymov",
            "Oleg N. Granichin",
            "Zeev Volkovich",
            "Gerhard-Wilhelm Weber"
        ],
        "summary": "This paper proposes a novel method for prevention of the increasing oscillation of an aircraft wing under the flexural torsion flutter. The paper introduces the novel multi-agent method for control of an aircraft wing, assuming that the wing surface consists of controlled 'feathers' (agents). Theoretical evaluation of the approach demonstrates its high ability to prevent flexural-torsional vibrations of an aircraft. Our model expands the possibilities for damping the wing oscillations, which potentially allows an increase in aircraft speed without misgiving of flutter. The study shows that the main limitation is the time, during which the system is able to damp vibrations to a safe level and keep them. The relevance of this indicator is important because of the rather fast process of increasing wing oscillations during flutter. In this paper, we suggest a new method for controlling an aircraft wing, with the use of which it becomes theoretically possible to increase the maximum flight speed of an aircraft without flutter occurrence. A mathematical model of the bending-torsional vibrations of an airplane wing with controlled feathers on its surface is presented. Based on the Speed-Gradient method a new control laws are synthesized.",
        "published": "2020-12-08T17:32:10Z",
        "link": "http://arxiv.org/abs/2012.04582v1",
        "categories": [
            "cs.IT",
            "cs.MA",
            "math.IT",
            "math.OC"
        ]
    },
    {
        "title": "Multi Agent Team Learning in Disaggregated Virtualized Open Radio Access   Networks (O-RAN)",
        "authors": [
            "Pedro Enrique Iturria Rivera",
            "Shahram Mollahasani",
            "Melike Erol-Kantarci"
        ],
        "summary": "Starting from the Cloud Radio Access Network (C-RAN), continuing with the virtual Radio Access Network (vRAN) and most recently with Open RAN (O-RAN) initiative, Radio Access Network (RAN) architectures have significantly evolved in the past decade. In the last few years, the wireless industry has witnessed a strong trend towards disaggregated, virtualized and open RANs, with numerous tests and deployments world wide. One unique aspect that motivates this paper is the availability of new opportunities that arise from using machine learning to optimize the RAN in closed-loop, i.e. without human intervention, where the complexity of disaggregation and virtualization makes well-known Self-Organized Networking (SON) solutions inadequate. In our view, Multi-Agent Systems (MASs) with team learning, can play an essential role in the control and coordination of controllers of O-RAN, i.e. near-real-time and non-real-time RAN Intelligent Controller (RIC). In this article, we first present the state-of-the-art research in multi-agent systems and team learning, then we provide an overview of the landscape in RAN disaggregation and virtualization, as well as O-RAN which emphasizes the open interfaces introduced by the O-RAN Alliance. We present a case study for agent placement and the AI feedback required in O-RAN, and finally, we identify challenges and open issues to provide a roadmap for researchers.",
        "published": "2020-12-09T04:47:07Z",
        "link": "http://arxiv.org/abs/2012.04861v2",
        "categories": [
            "cs.MA",
            "cs.NI"
        ]
    },
    {
        "title": "A Discrete Model of Collective Marching on Rings",
        "authors": [
            "Michael Amir",
            "Noa Agmon",
            "Alfred M. Bruckstein"
        ],
        "summary": "We study the collective motion of autonomous mobile agents on a ringlike environment. The agents' dynamics is inspired by known laboratory experiments on the dynamics of locust swarms. In these experiments, locusts placed at arbitrary locations and initial orientations on a ring-shaped arena are observed to eventually all march in the same direction. In this work we ask whether, and how fast, a similar phenomenon occurs in a stochastic swarm of simple agents whose goal is to maintain the same direction of motion for as long as possible. The agents are randomly initiated as marching either clockwise or counterclockwise on a wide ring-shaped region, which we model as $k$ \"narrow\" concentric tracks on a cylinder. Collisions cause agents to change their direction of motion. To avoid this, agents may decide to switch tracks so as to merge with platoons of agents marching in their direction.   We prove that such agents must eventually converge to a local consensus about their direction of motion, meaning that all agents on each narrow track must eventually march in the same direction. We give asymptotic bounds for the expected amount of time it takes for such convergence or \"stabilization\" to occur, which depends on the number of agents, the length of the tracks, and the number of tracks. We show that when agents also have a small probability of \"erratic\", random track-jumping behaviour, a global consensus on the direction of motion across all tracks will eventually be reached. Finally, we verify our theoretical findings in numerical simulations.",
        "published": "2020-12-09T11:16:36Z",
        "link": "http://arxiv.org/abs/2012.04980v5",
        "categories": [
            "cs.MA",
            "cs.DM",
            "math.DS"
        ]
    },
    {
        "title": "Com-DDPG: A Multiagent Reinforcement Learning-based Offloading Strategy   for Mobile Edge Computing",
        "authors": [
            "Honghao Gao",
            "Xuejie Wang",
            "Xiaojin Ma",
            "Wei Wei",
            "Shahid Mumtaz"
        ],
        "summary": "The development of mobile services has impacted a variety of computation-intensive and time-sensitive applications, such as recommendation systems and daily payment methods. However, computing task competition involving limited resources increases the task processing latency and energy consumption of mobile devices, as well as time constraints. Mobile edge computing (MEC) has been widely used to address these problems. However, there are limitations to existing methods used during computation offloading. On the one hand, they focus on independent tasks rather than dependent tasks. The challenges of task dependency in the real world, especially task segmentation and integration, remain to be addressed. On the other hand, the multiuser scenarios related to resource allocation and the mutex access problem must be considered. In this paper, we propose a novel offloading approach, Com-DDPG, for MEC using multiagent reinforcement learning to enhance the offloading performance. First, we discuss the task dependency model, task priority model, energy consumption model, and average latency from the perspective of server clusters and multidependence on mobile tasks. Our method based on these models is introduced to formalize communication behavior among multiple agents; then, reinforcement learning is executed as an offloading strategy to obtain the results. Because of the incomplete state information, long short-term memory (LSTM) is employed as a decision-making tool to assess the internal state. Moreover, to optimize and support effective action, we consider using a bidirectional recurrent neural network (BRNN) to learn and enhance features obtained from agents' communication. Finally, we simulate experiments on the Alibaba cluster dataset. The results show that our method is better than other baselines in terms of energy consumption, load status and latency.",
        "published": "2020-12-09T15:22:47Z",
        "link": "http://arxiv.org/abs/2012.05105v1",
        "categories": [
            "cs.DC",
            "cs.MA"
        ]
    },
    {
        "title": "Participatory Budgeting with Project Groups",
        "authors": [
            "Pallavi Jain",
            "Krzysztof Sornat",
            "Nimrod Talmon",
            "Meirav Zehavi"
        ],
        "summary": "We study a generalization of the standard approval-based model of participatory budgeting (PB), in which voters are providing approval ballots over a set of predefined projects and -- in addition to a global budget limit, there are several groupings of the projects, each group with its own budget limit. We study the computational complexity of identifying project bundles that maximize voter satisfaction while respecting all budget limits. We show that the problem is generally intractable and describe efficient exact algorithms for several special cases, including instances with only few groups and instances where the group structure is close to be hierarchical, as well as efficient approximation algorithms. Our results could allow, e.g., municipalities to hold richer PB processes that are thematically and geographically inclusive.",
        "published": "2020-12-09T18:23:04Z",
        "link": "http://arxiv.org/abs/2012.05213v1",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.DS",
            "cs.MA",
            "68Q17, 68Q25, 68W05 (Primary), 68W25, 68T42 (Secondary)",
            "F.2.2"
        ]
    },
    {
        "title": "Imitating Interactive Intelligence",
        "authors": [
            "Josh Abramson",
            "Arun Ahuja",
            "Iain Barr",
            "Arthur Brussee",
            "Federico Carnevale",
            "Mary Cassin",
            "Rachita Chhaparia",
            "Stephen Clark",
            "Bogdan Damoc",
            "Andrew Dudzik",
            "Petko Georgiev",
            "Aurelia Guy",
            "Tim Harley",
            "Felix Hill",
            "Alden Hung",
            "Zachary Kenton",
            "Jessica Landon",
            "Timothy Lillicrap",
            "Kory Mathewson",
            "Soňa Mokrá",
            "Alistair Muldal",
            "Adam Santoro",
            "Nikolay Savinov",
            "Vikrant Varma",
            "Greg Wayne",
            "Duncan Williams",
            "Nathaniel Wong",
            "Chen Yan",
            "Rui Zhu"
        ],
        "summary": "A common vision from science fiction is that robots will one day inhabit our physical spaces, sense the world as we do, assist our physical labours, and communicate with us through natural language. Here we study how to design artificial agents that can interact naturally with humans using the simplification of a virtual environment. This setting nevertheless integrates a number of the central challenges of artificial intelligence (AI) research: complex visual perception and goal-directed physical control, grounded language comprehension and production, and multi-agent social interaction. To build agents that can robustly interact with humans, we would ideally train them while they interact with humans. However, this is presently impractical. Therefore, we approximate the role of the human with another learned agent, and use ideas from inverse reinforcement learning to reduce the disparities between human-human and agent-agent interactive behaviour. Rigorously evaluating our agents poses a great challenge, so we develop a variety of behavioural tests, including evaluation by humans who watch videos of agents or interact directly with them. These evaluations convincingly demonstrate that interactive training and auxiliary losses improve agent behaviour beyond what is achieved by supervised learning of actions alone. Further, we demonstrate that agent capabilities generalise beyond literal experiences in the dataset. Finally, we train evaluation models whose ratings of agents agree well with human judgement, thus permitting the evaluation of new agent models without additional effort. Taken together, our results in this virtual environment provide evidence that large-scale human behavioural imitation is a promising tool to create intelligent, interactive agents, and the challenge of reliably evaluating such agents is possible to surmount.",
        "published": "2020-12-10T13:55:47Z",
        "link": "http://arxiv.org/abs/2012.05672v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "AutoSelect: Automatic and Dynamic Detection Selection for 3D   Multi-Object Tracking",
        "authors": [
            "Xinshuo Weng",
            "Kris Kitani"
        ],
        "summary": "3D multi-object tracking is an important component in robotic perception systems such as self-driving vehicles. Recent work follows a tracking-by-detection pipeline, which aims to match past tracklets with detections in the current frame. To avoid matching with false positive detections, prior work filters out detections with low confidence scores via a threshold. However, finding a proper threshold is non-trivial, which requires extensive manual search via ablation study. Also, this threshold is sensitive to many factors such as target object category so we need to re-search the threshold if these factors change. To ease this process, we propose to automatically select high-quality detections and remove the efforts needed for manual threshold search. Also, prior work often uses a single threshold per data sequence, which is sub-optimal in particular frames or for certain objects. Instead, we dynamically search threshold per frame or per object to further boost performance. Through experiments on KITTI and nuScenes, our method can filter out $45.7\\%$ false positives while maintaining the recall, achieving new S.O.T.A. performance and removing the need for manually threshold tuning.",
        "published": "2020-12-10T18:55:51Z",
        "link": "http://arxiv.org/abs/2012.05894v1",
        "categories": [
            "cs.CV",
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "A generic and density-sensitive method for multi-scale pedestrian   dynamics",
        "authors": [
            "Daniel H. Biedermann",
            "Jan Clever",
            "Andre Borrmann"
        ],
        "summary": "Microscopic approaches to the simulation of pedestrian dynamics rely on modelling the behaviour of individual agents and their mutual interactions. Regarding the spatial resolution, microscopic simulators are either based on continuous (SpaceCont) or discrete (SpaceDisc) approaches. To combine the advantages of both approaches, we propose to integrate SpaceCont and SpaceDisc into a hybrid simulation model. Such a hybrid approach allows simulating critical regions with a continuous spatial resolution and uncritical ones with discrete spatial resolution while enabling consistent information exchange between the two simulation models. We introduce a generic approach that provides consistent solutions for the challenges resulting from coupling diverging time steps and spatial resolutions. Furthermore, we present a dynamic and density-sensitive approach to detect dense areas during the simulation run. If a critical region is detected, the simulation model used in this area is dynamically switched to a space-continuous one. The correctness of the hybrid model is evaluated by comparison with a established simulator. Its superior computational efficiency is shown by runtime comparison with a standard microscopic simulation.on with the simulation results of other, well-established simulation models.",
        "published": "2020-12-11T11:37:08Z",
        "link": "http://arxiv.org/abs/2012.07623v1",
        "categories": [
            "cs.MA",
            "physics.soc-ph"
        ]
    },
    {
        "title": "Inferring urban social networks from publicly available data",
        "authors": [
            "Stefano Guarino",
            "Enrico Mastrostefano",
            "Massimo Bernaschi",
            "Alessandro Celestini",
            "Marco Cianfriglia",
            "Davide Torre",
            "Lena Zastrow"
        ],
        "summary": "The emergence of social networks and the definition of suitable generative models for synthetic yet realistic social graphs are widely studied problems in the literature. By not being tied to any real data, random graph models cannot capture all the subtleties of real networks and are inadequate for many practical contexts -- including areas of research, such as computational epidemiology, which are recently high on the agenda. At the same time, the so-called contact networks describe interactions, rather than relationships, and are strongly dependent on the application and on the size and quality of the sample data used to infer them. To fill the gap between these two approaches, we present a data-driven model for urban social networks, implemented and released as open source software. Given a territory of interest, and only based on widely available aggregated demographic and social-mixing data, we construct an age-stratified and geo-referenced synthetic population whose individuals are connected by \"strong ties\" of two types: intra-household (e.g., kinship) or friendship. While household links are entirely data-driven, we propose a parametric probabilistic model for friendship, based on the assumption that distances and age differences play a role, and that not all individuals are equally sociable. The demographic and geographic factors governing the structure of the obtained network, under different configurations, are thoroughly studied through extensive simulations focused on three Italian cities of different size.",
        "published": "2020-12-11T21:47:00Z",
        "link": "http://arxiv.org/abs/2012.06652v2",
        "categories": [
            "cs.SI",
            "cs.MA"
        ]
    },
    {
        "title": "Bandit Learning in Decentralized Matching Markets",
        "authors": [
            "Lydia T. Liu",
            "Feng Ruan",
            "Horia Mania",
            "Michael I. Jordan"
        ],
        "summary": "We study two-sided matching markets in which one side of the market (the players) does not have a priori knowledge about its preferences for the other side (the arms) and is required to learn its preferences from experience. Also, we assume the players have no direct means of communication. This model extends the standard stochastic multi-armed bandit framework to a decentralized multiple player setting with competition. We introduce a new algorithm for this setting that, over a time horizon $T$, attains $\\mathcal{O}(\\log(T))$ stable regret when preferences of the arms over players are shared, and $\\mathcal{O}(\\log(T)^2)$ regret when there are no assumptions on the preferences on either side. Moreover, in the setting where a single player may deviate, we show that the algorithm is incentive compatible whenever the arms' preferences are shared, but not necessarily so when preferences are fully general.",
        "published": "2020-12-14T08:58:07Z",
        "link": "http://arxiv.org/abs/2012.07348v4",
        "categories": [
            "cs.LG",
            "cs.GT",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Specializing Inter-Agent Communication in Heterogeneous Multi-Agent   Reinforcement Learning using Agent Class Information",
        "authors": [
            "Douglas De Rizzo Meneghetti",
            "Reinaldo Augusto da Costa Bianchi"
        ],
        "summary": "Inspired by recent advances in agent communication with graph neural networks, this work proposes the representation of multi-agent communication capabilities as a directed labeled heterogeneous agent graph, in which node labels denote agent classes and edge labels, the communication type between two classes of agents. We also introduce a neural network architecture that specializes communication in fully cooperative heterogeneous multi-agent tasks by learning individual transformations to the exchanged messages between each pair of agent classes. By also employing encoding and action selection modules with parameter sharing for environments with heterogeneous agents, we demonstrate comparable or superior performance in environments where a larger number of agent classes operates.",
        "published": "2020-12-14T15:09:57Z",
        "link": "http://arxiv.org/abs/2012.07617v2",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "SAT-MARL: Specification Aware Training in Multi-Agent Reinforcement   Learning",
        "authors": [
            "Fabian Ritz",
            "Thomy Phan",
            "Robert Müller",
            "Thomas Gabor",
            "Andreas Sedlmeier",
            "Marc Zeller",
            "Jan Wieghardt",
            "Reiner Schmid",
            "Horst Sauer",
            "Cornel Klein",
            "Claudia Linnhoff-Popien"
        ],
        "summary": "A characteristic of reinforcement learning is the ability to develop unforeseen strategies when solving problems. While such strategies sometimes yield superior performance, they may also result in undesired or even dangerous behavior. In industrial scenarios, a system's behavior also needs to be predictable and lie within defined ranges. To enable the agents to learn (how) to align with a given specification, this paper proposes to explicitly transfer functional and non-functional requirements into shaped rewards. Experiments are carried out on the smart factory, a multi-agent environment modeling an industrial lot-size-one production facility, with up to eight agents and different multi-agent reinforcement learning algorithms. Results indicate that compliance with functional and non-functional constraints can be achieved by the proposed approach.",
        "published": "2020-12-14T21:33:16Z",
        "link": "http://arxiv.org/abs/2012.07949v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Fast-Convergent Dynamics for Distributed Allocation of Resources Over   Switching Sparse Networks with Quantized Communication Links",
        "authors": [
            "Mohammadreza Doostmohammadian",
            "Alireza Aghasi",
            "Mohammad Pirani",
            "Ehsan Nekouei",
            "Usman A. Khan",
            "Themistoklis Charalambous"
        ],
        "summary": "This paper proposes networked dynamics to solve resource allocation problems over time-varying multi-agent networks. The state of each agent represents the amount of used resources (or produced utilities) while the total amount of resources is fixed. The idea is to optimally allocate the resources among the group of agents by minimizing the overall cost function subject to fixed sum of resources. Each agents' information is restricted to its own state and cost function and those of its immediate in-neighbors. This is motivated by distributed applications such as mobile edge-computing, economic dispatch over smart grids, and multi-agent coverage control. This work provides a fast convergent solution (in comparison with linear dynamics) while considering relaxed network connectivity with quantized communication links. The proposed dynamics reaches optimal solution over switching (possibly disconnected) undirected networks as far as their union over some bounded non-overlapping time-intervals has a spanning-tree. We prove feasibility of the solution, uniqueness of the optimal state, and convergence to the optimal value under the proposed dynamics, where the analysis is applicable to similar 1st-order allocation dynamics with strongly sign-preserving nonlinearities, such as actuator saturation.",
        "published": "2020-12-15T09:57:54Z",
        "link": "http://arxiv.org/abs/2012.08181v4",
        "categories": [
            "eess.SY",
            "cs.LG",
            "cs.MA",
            "cs.SI",
            "cs.SY"
        ]
    },
    {
        "title": "Robust Multi-Agent Reinforcement Learning with Social Empowerment for   Coordination and Communication",
        "authors": [
            "T. van der Heiden",
            "C. Salge",
            "E. Gavves",
            "H. van Hoof"
        ],
        "summary": "We consider the problem of robust multi-agent reinforcement learning (MARL) for cooperative communication and coordination tasks. MARL agents, mainly those trained in a centralized way, can be brittle because they can adopt policies that act under the expectation that other agents will act a certain way rather than react to their actions. Our objective is to bias the learning process towards finding strategies that remain reactive towards others' behavior. Social empowerment measures the potential influence between agents' actions. We propose it as an additional reward term, so agents better adapt to other agents' actions. We show that the proposed method results in obtaining higher rewards faster and a higher success rate in three cooperative communication and coordination tasks.",
        "published": "2020-12-15T12:43:17Z",
        "link": "http://arxiv.org/abs/2012.08255v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Evolutionary Game Theory Squared: Evolving Agents in Endogenously   Evolving Zero-Sum Games",
        "authors": [
            "Stratis Skoulakis",
            "Tanner Fiez",
            "Ryann Sim",
            "Georgios Piliouras",
            "Lillian Ratliff"
        ],
        "summary": "The predominant paradigm in evolutionary game theory and more generally online learning in games is based on a clear distinction between a population of dynamic agents that interact given a fixed, static game. In this paper, we move away from the artificial divide between dynamic agents and static games, to introduce and analyze a large class of competitive settings where both the agents and the games they play evolve strategically over time. We focus on arguably the most archetypal game-theoretic setting -- zero-sum games (as well as network generalizations) -- and the most studied evolutionary learning dynamic -- replicator, the continuous-time analogue of multiplicative weights. Populations of agents compete against each other in a zero-sum competition that itself evolves adversarially to the current population mixture. Remarkably, despite the chaotic coevolution of agents and games, we prove that the system exhibits a number of regularities. First, the system has conservation laws of an information-theoretic flavor that couple the behavior of all agents and games. Secondly, the system is Poincar\\'{e} recurrent, with effectively all possible initializations of agents and games lying on recurrent orbits that come arbitrarily close to their initial conditions infinitely often. Thirdly, the time-average agent behavior and utility converge to the Nash equilibrium values of the time-average game. Finally, we provide a polynomial time algorithm to efficiently predict this time-average behavior for any such coevolving network game.",
        "published": "2020-12-15T15:54:46Z",
        "link": "http://arxiv.org/abs/2012.08382v1",
        "categories": [
            "cs.GT",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Distributed Wasserstein Barycenters via Displacement Interpolation",
        "authors": [
            "Pedro Cisneros-Velarde",
            "Francesco Bullo"
        ],
        "summary": "Consider a multi-agent system whereby each agent has an initial probability measure. In this paper, we propose a distributed algorithm based upon stochastic, asynchronous and pairwise exchange of information and displacement interpolation in the Wasserstein space. We characterize the evolution of this algorithm and prove it computes the Wasserstein barycenter of the initial measures under various conditions. One version of the algorithm computes a standard Wasserstein barycenter, i.e., a barycenter based upon equal weights; and the other version computes a randomized Wasserstein barycenter, i.e., a barycenter based upon random weights for the initial measures. Finally, we specialize our algorithm to Gaussian distributions and draw a connection with the modeling of opinion dynamics in mathematical sociology.",
        "published": "2020-12-15T20:50:28Z",
        "link": "http://arxiv.org/abs/2012.08610v3",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY",
            "60J20 (Primary), 49N99, 46N10 (Secondary)"
        ]
    },
    {
        "title": "Open Problems in Cooperative AI",
        "authors": [
            "Allan Dafoe",
            "Edward Hughes",
            "Yoram Bachrach",
            "Tantum Collins",
            "Kevin R. McKee",
            "Joel Z. Leibo",
            "Kate Larson",
            "Thore Graepel"
        ],
        "summary": "Problems of cooperation--in which agents seek ways to jointly improve their welfare--are ubiquitous and important. They can be found at scales ranging from our daily routines--such as driving on highways, scheduling meetings, and working collaboratively--to our global challenges--such as peace, commerce, and pandemic preparedness. Arguably, the success of the human species is rooted in our ability to cooperate. Since machines powered by artificial intelligence are playing an ever greater role in our lives, it will be important to equip them with the capabilities necessary to cooperate and to foster cooperation.   We see an opportunity for the field of artificial intelligence to explicitly focus effort on this class of problems, which we term Cooperative AI. The objective of this research would be to study the many aspects of the problems of cooperation and to innovate in AI to contribute to solving these problems. Central goals include building machine agents with the capabilities needed for cooperation, building tools to foster cooperation in populations of (machine and/or human) agents, and otherwise conducting AI research for insight relevant to problems of cooperation. This research integrates ongoing work on multi-agent systems, game theory and social choice, human-machine interaction and alignment, natural-language processing, and the construction of social tools and platforms. However, Cooperative AI is not the union of these existing areas, but rather an independent bet about the productivity of specific kinds of conversations that involve these and other areas. We see opportunity to more explicitly focus on the problem of cooperation, to construct unified theory and vocabulary, and to build bridges with adjacent communities working on cooperation, including in the natural, social, and behavioural sciences.",
        "published": "2020-12-15T21:39:50Z",
        "link": "http://arxiv.org/abs/2012.08630v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Accelerating Distributed Online Meta-Learning via Multi-Agent   Collaboration under Limited Communication",
        "authors": [
            "Sen Lin",
            "Mehmet Dedeoglu",
            "Junshan Zhang"
        ],
        "summary": "Online meta-learning is emerging as an enabling technique for achieving edge intelligence in the IoT ecosystem. Nevertheless, to learn a good meta-model for within-task fast adaptation, a single agent alone has to learn over many tasks, and this is the so-called 'cold-start' problem. Observing that in a multi-agent network the learning tasks across different agents often share some model similarity, we ask the following fundamental question: \"Is it possible to accelerate the online meta-learning across agents via limited communication and if yes how much benefit can be achieved? \" To answer this question, we propose a multi-agent online meta-learning framework and cast it as an equivalent two-level nested online convex optimization (OCO) problem. By characterizing the upper bound of the agent-task-averaged regret, we show that the performance of multi-agent online meta-learning depends heavily on how much an agent can benefit from the distributed network-level OCO for meta-model updates via limited communication, which however is not well understood. To tackle this challenge, we devise a distributed online gradient descent algorithm with gradient tracking where each agent tracks the global gradient using only one communication step with its neighbors per iteration, and it results in an average regret $O(\\sqrt{T/N})$ per agent, indicating that a factor of $\\sqrt{1/N}$ speedup over the optimal single-agent regret $O(\\sqrt{T})$ after $T$ iterations, where $N$ is the number of agents. Building on this sharp performance speedup, we next develop a multi-agent online meta-learning algorithm and show that it can achieve the optimal task-average regret at a faster rate of $O(1/\\sqrt{NT})$ via limited communication, compared to single-agent online meta-learning. Extensive experiments corroborate the theoretic results.",
        "published": "2020-12-15T23:08:36Z",
        "link": "http://arxiv.org/abs/2012.08660v2",
        "categories": [
            "cs.LG",
            "cs.DC",
            "cs.MA"
        ]
    },
    {
        "title": "Lévy walks derived from a Bayesian decision-making model in   non-stationary environments",
        "authors": [
            "Shuji Shinohara",
            "Nobuhito Manome",
            "Yoshihiro Nakajima",
            "Yukio Pegio Gunji",
            "Toru Moriyama",
            "Hiroshi Okamoto",
            "Shunji Mitsuyoshi",
            "Ung-il Chung"
        ],
        "summary": "L\\'evy walks are found in the migratory behaviour patterns of various organisms, and the reason for this phenomenon has been much discussed. We use simulations to demonstrate that learning causes the changes in confidence level during decision-making in non-stationary environments, and results in L\\'evy-walk-like patterns. One inference algorithm involving confidence is Bayesian inference. We propose an algorithm that introduces the effects of learning and forgetting into Bayesian inference, and simulate an imitation game in which two decision-making agents incorporating the algorithm estimate each other's internal models from their opponent's observational data. For forgetting without learning, agent confidence levels remained low due to a lack of information on the counterpart and Brownian walks occurred for a wide range of forgetting rates. Conversely, when learning was introduced, high confidence levels occasionally occurred even at high forgetting rates, and Brownian walks universally became L\\'evy walks through a mixture of high- and low-confidence states.",
        "published": "2020-12-16T10:59:22Z",
        "link": "http://arxiv.org/abs/2012.08858v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "cs.NE"
        ]
    },
    {
        "title": "Scalable and Safe Multi-Agent Motion Planning with Nonlinear Dynamics   and Bounded Disturbances",
        "authors": [
            "Jingkai Chen",
            "Jiaoyang Li",
            "Chuchu Fan",
            "Brian Williams"
        ],
        "summary": "We present a scalable and effective multi-agent safe motion planner that enables a group of agents to move to their desired locations while avoiding collisions with obstacles and other agents, with the presence of rich obstacles, high-dimensional, nonlinear, nonholonomic dynamics, actuation limits, and disturbances. We address this problem by finding a piecewise linear path for each agent such that the actual trajectories following these paths are guaranteed to satisfy the reach-and-avoid requirement. We show that the spatial tracking error of the actual trajectories of the controlled agents can be pre-computed for any qualified path that considers the minimum duration of each path segment due to actuation limits. Using these bounds, we find a collision-free path for each agent by solving Mixed Integer-Linear Programs and coordinate agents by using the priority-based search. We demonstrate our method by benchmarking in 2D and 3D scenarios with ground vehicles and quadrotors, respectively, and show improvements over the solving time and the solution quality compared to two state-of-the-art multi-agent motion planners.",
        "published": "2020-12-16T16:18:02Z",
        "link": "http://arxiv.org/abs/2012.09052v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Incentivizing Truthfulness Through Audits in Strategic Classification",
        "authors": [
            "Andrew Estornell",
            "Sanmay Das",
            "Yevgeniy Vorobeychik"
        ],
        "summary": "In many societal resource allocation domains, machine learning methods are increasingly used to either score or rank agents in order to decide which ones should receive either resources (e.g., homeless services) or scrutiny (e.g., child welfare investigations) from social services agencies. An agency's scoring function typically operates on a feature vector that contains a combination of self-reported features and information available to the agency about individuals or households.This can create incentives for agents to misrepresent their self-reported features in order to receive resources or avoid scrutiny, but agencies may be able to selectively audit agents to verify the veracity of their reports.   We study the problem of optimal auditing of agents in such settings. When decisions are made using a threshold on an agent's score, the optimal audit policy has a surprisingly simple structure, uniformly auditing all agents who could benefit from lying. While this policy can, in general, be hard to compute because of the difficulty of identifying the set of agents who could benefit from lying given a complete set of reported types, we also present necessary and sufficient conditions under which it is tractable. We show that the scarce resource setting is more difficult, and exhibit an approximately optimal audit policy in this case. In addition, we show that in either setting verifying whether it is possible to incentivize exact truthfulness is hard even to approximate. However, we also exhibit sufficient conditions for solving this problem optimally, and for obtaining good approximations.",
        "published": "2020-12-16T18:35:00Z",
        "link": "http://arxiv.org/abs/2012.09147v1",
        "categories": [
            "cs.MA",
            "cs.GT"
        ]
    },
    {
        "title": "Team Assignment for Heterogeneous Multi-Robot Sensor Coverage through   Graph Representation Learning",
        "authors": [
            "Brian Reily",
            "Hao Zhang"
        ],
        "summary": "Sensor coverage is the critical multi-robot problem of maximizing the detection of events in an environment through the deployment of multiple robots. Large multi-robot systems are often composed of simple robots that are typically not equipped with a complete set of sensors, so teams with comprehensive sensing abilities are required to properly cover an area. Robots also exhibit multiple forms of relationships (e.g., communication connections or spatial distribution) that need to be considered when assigning robot teams for sensor coverage. To address this problem, in this paper we introduce a novel formulation of sensor coverage by multi-robot systems with heterogeneous relationships as a graph representation learning problem. We propose a principled approach based on the mathematical framework of regularized optimization to learn a unified representation of the multi-robot system from the graphs describing the heterogeneous relationships and to identify the learned representation's underlying structure in order to assign the robots to teams. To evaluate the proposed approach, we conduct extensive experiments on simulated multi-robot systems and a physical multi-robot system as a case study, demonstrating that our approach is able to effectively assign teams for heterogeneous multi-robot sensor coverage.",
        "published": "2020-12-17T00:12:58Z",
        "link": "http://arxiv.org/abs/2012.09331v2",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Adaptation to Team Composition Changes for Heterogeneous Multi-Robot   Sensor Coverage",
        "authors": [
            "Brian Reily",
            "Terran Mott",
            "Hao Zhang"
        ],
        "summary": "We consider the problem of multi-robot sensor coverage, which deals with deploying a multi-robot team in an environment and optimizing the sensing quality of the overall environment. As real-world environments involve a variety of sensory information, and individual robots are limited in their available number of sensors, successful multi-robot sensor coverage requires the deployment of robots in such a way that each individual team member's sensing quality is maximized. Additionally, because individual robots have varying complements of sensors and both robots and sensors can fail, robots must be able to adapt and adjust how they value each sensing capability in order to obtain the most complete view of the environment, even through changes in team composition. We introduce a novel formulation for sensor coverage by multi-robot teams with heterogeneous sensing capabilities that maximizes each robot's sensing quality, balancing the varying sensing capabilities of individual robots based on the overall team composition. We propose a solution based on regularized optimization that uses sparsity-inducing terms to ensure a robot team focuses on all possible event types, and which we show is proven to converge to the optimal solution. Through extensive simulation, we show that our approach is able to effectively deploy a multi-robot team to maximize the sensing quality of an environment, responding to failures in the multi-robot team more robustly than non-adaptive approaches.",
        "published": "2020-12-17T00:22:18Z",
        "link": "http://arxiv.org/abs/2012.09334v2",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Adaptive Multi-Agent E-Learning Recommender Systems",
        "authors": [
            "Nethra Viswanathan"
        ],
        "summary": "Educational recommender systems have become a necessity in the recent years due to overload of available educational resource which makes it difficult for an individual to manually hunt for the required resource on the internet. E-learning recommender systems simplify the tedious task of gathering the right web pages and web documents from the scattered world wide web repositories according to every users' requirements thus increasing the demand and hence the curiosity to study them. Retrieval of a handful of recommendations from a very huge collection of web pages using different recommendation techniques becomes a productive and time efficient process when the system functions with a set of cooperative agents. The system is also required to keep up with the changing user interests and web resources in the dynamic web environment, and hence adaptivity is an important factor in determining the efficiency of recommender systems. The paper provides an overview of such adaptive multi-agent e-learning recommender systems and the concepts employed to implement them. It precisely provides all the information required by a researcher who wants to study the state-of-the-art work on such systems thus enabling him to decide on the implementation concepts for his own system.",
        "published": "2020-12-17T01:02:14Z",
        "link": "http://arxiv.org/abs/2012.09342v1",
        "categories": [
            "cs.IR",
            "cs.MA",
            "93A16"
        ]
    },
    {
        "title": "Learning Fair Policies in Decentralized Cooperative Multi-Agent   Reinforcement Learning",
        "authors": [
            "Matthieu Zimmer",
            "Claire Glanois",
            "Umer Siddique",
            "Paul Weng"
        ],
        "summary": "We consider the problem of learning fair policies in (deep) cooperative multi-agent reinforcement learning (MARL). We formalize it in a principled way as the problem of optimizing a welfare function that explicitly encodes two important aspects of fairness: efficiency and equity. As a solution method, we propose a novel neural network architecture, which is composed of two sub-networks specifically designed for taking into account the two aspects of fairness. In experiments, we demonstrate the importance of the two sub-networks for fair optimization. Our overall approach is general as it can accommodate any (sub)differentiable welfare function. Therefore, it is compatible with various notions of fairness that have been proposed in the literature (e.g., lexicographic maximin, generalized Gini social welfare function, proportional fairness). Our solution method is generic and can be implemented in various MARL settings: centralized training and decentralized execution, or fully decentralized. Finally, we experimentally validate our approach in various domains and show that it can perform much better than previous methods.",
        "published": "2020-12-17T07:17:36Z",
        "link": "http://arxiv.org/abs/2012.09421v4",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Game-theoretic Models of Moral and Other-Regarding Agents",
        "authors": [
            "Gabriel Istrate"
        ],
        "summary": "We investigate Kantian equilibria in finite normal form games, a class of non-Nashian, morally motivated courses of action that was recently proposed in the economics literature. We highlight a number of problems with such equilibria, including computational intractability, a high price of miscoordination, and expensive/problematic extension to general normal form games. We point out that such a proper generalization will likely involve the concept of program equilibrium. Finally we propose some general, intuitive, computationally tractable, other-regarding equilibria related to Kantian equilibria, as well as a class of courses of action that interpolates between purely self-regarding and Kantian behavior.",
        "published": "2020-12-17T17:16:50Z",
        "link": "http://arxiv.org/abs/2012.09759v2",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.MA",
            "cs.SI"
        ]
    },
    {
        "title": "Achieving State Machine Replication without Honest Players",
        "authors": [
            "Conor McMenamin",
            "Vanesa Daza",
            "Matteo Pontecorvi"
        ],
        "summary": "Existing standards for player characterisation in tokenised state machine replication protocols depend on honest players who will always follow the protocol, regardless of possible token increases for deviating. Given the ever-increasing market capitalisation of these tokenised protocols, honesty is becoming more expensive and more unrealistic. As such, this out-dated player characterisation must be removed to provide true guarantees of safety and liveness in a major stride towards universal trust in state machine replication protocols and a new scale of adoption. As all current state machine replication protocols are built on these legacy standards, it is imperative that a new player model is identified and utilised to reflect the true nature of players in tokenised protocols, now and into the future.   To this effect, we propose the ByRa player model for state machine replication protocols. In the ByRa model, players either attempt to maximise their tokenised rewards, or behave adversarially. This merges the fields of game theory and distributed systems, an intersection in which tokenised state machine replication protocols exist, but on which little formalisation has been carried out. In the ByRa model, we identify the properties of strong incentive compatibility in expectation and fairness that all protocols must satisfy in order to achieve state machine replication. We then provide Tenderstake, a protocol which provably satisfies these properties, and by doing so, achieves state machine replication in the ByRa model.",
        "published": "2020-12-18T10:13:35Z",
        "link": "http://arxiv.org/abs/2012.10146v2",
        "categories": [
            "cs.GT",
            "cs.DC",
            "cs.MA"
        ]
    },
    {
        "title": "A Distributed Simplex Architecture for Multi-Agent Systems",
        "authors": [
            "Usama Mehmood",
            "Scott D. Stoller",
            "Radu Grosu",
            "Shouvik Roy",
            "Amol Damare",
            "Scott A. Smolka"
        ],
        "summary": "We present Distributed Simplex Architecture (DSA), a new runtime assurance technique that provides safety guarantees for multi-agent systems (MASs). DSA is inspired by the Simplex control architecture of Sha et al., but with some significant differences. The traditional Simplex approach is limited to single-agent systems or a MAS with a centralized control scheme. DSA addresses this limitation by extending the scope of Simplex to include MASs under distributed control. In DSA, each agent has a local instance of traditional Simplex such that the preservation of safety in the local instances implies safety for the entire MAS. We provide a proof of safety for DSA, and present experimental results for several case studies, including flocking with collision avoidance, safe navigation of ground rovers through way-points, and the safe operation of a microgrid.",
        "published": "2020-12-18T10:31:50Z",
        "link": "http://arxiv.org/abs/2012.10153v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Reinforcement Learning for Unified Allocation and Patrolling in   Signaling Games with Uncertainty",
        "authors": [
            "Aravind Venugopal",
            "Elizabeth Bondi",
            "Harshavardhan Kamarthi",
            "Keval Dholakia",
            "Balaraman Ravindran",
            "Milind Tambe"
        ],
        "summary": "Green Security Games (GSGs) have been successfully used in the protection of valuable resources such as fisheries, forests and wildlife. While real-world deployment involves both resource allocation and subsequent coordinated patrolling with communication and real-time, uncertain information, previous game models do not fully address both of these stages simultaneously. Furthermore, adopting existing solution strategies is difficult since they do not scale well for larger, more complex variants of the game models.   We therefore first propose a novel GSG model that combines defender allocation, patrolling, real-time drone notification to human patrollers, and drones sending warning signals to attackers. The model further incorporates uncertainty for real-time decision-making within a team of drones and human patrollers. Second, we present CombSGPO, a novel and scalable algorithm based on reinforcement learning, to compute a defender strategy for this game model. CombSGPO performs policy search over a multi-dimensional, discrete action space to compute an allocation strategy that is best suited to a best-response patrolling strategy for the defender, learnt by training a multi-agent Deep Q-Network. We show via experiments that CombSGPO converges to better strategies and is more scalable than comparable approaches. Third, we provide a detailed analysis of the coordination and signaling behavior learnt by CombSGPO, showing group formation between defender resources and patrolling formations based on signaling and notifications between resources. Importantly, we find that strategic signaling emerges in the final learnt strategy. Finally, we perform experiments to evaluate these strategies under different levels of uncertainty.",
        "published": "2020-12-18T17:53:39Z",
        "link": "http://arxiv.org/abs/2012.10389v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Distributed Map Classification using Local Observations",
        "authors": [
            "Guangyi Liu",
            "Arash Amini",
            "Martin Takáč",
            "Héctor Muñoz-Avila",
            "Nader Motee"
        ],
        "summary": "We consider the problem of classifying a map using a team of communicating robots. It is assumed that all robots have localized visual sensing capabilities and can exchange their information with neighboring robots. Using a graph decomposition technique, we proposed an offline learning structure that makes every robot capable of communicating with and fusing information from its neighbors to plan its next move towards the most informative parts of the environment for map classification purposes. The main idea is to decompose a given undirected graph into a union of directed star graphs and train robots w.r.t a bounded number of star graphs. This will significantly reduce the computational cost of offline training and makes learning scalable (independent of the number of robots). Our approach is particularly useful for fast map classification in large environments using a large number of communicating robots. We validate the usefulness of our proposed methodology through extensive simulations.",
        "published": "2020-12-18T19:35:10Z",
        "link": "http://arxiv.org/abs/2012.10480v2",
        "categories": [
            "cs.RO",
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Bayesian Optimization of Area-based Road Pricing",
        "authors": [
            "Renming Liu",
            "Yu Jiang",
            "Carlos Lima Azevedo"
        ],
        "summary": "This study presents a Bayesian Optimization framework for area- and distance-based time-of-day pricing (TODP) for urban networks. The road pricing optimization problem can reach high level of complexity depending on the pricing scheme considered, its associated detailed network properties and the affected heterogeneous demand features. We consider heterogeneous travellers with individual-specific trip attributes and departure-time choice parameters together with a Macroscopic Fundamental Diagram (MFD) model for the urban network. Its mathematical formulation is presented and an agent-based simulation framework is constructed as evaluation function for the TODP optimization problem. The latter becomes highly nonlinear and relying on an expensive-to-evaluate objective function. We then present and test a Bayesian Optimization approach to compute different time-of-day pricing schemes by maximizing social welfare. Our proposed method learns the relationship between the prices and welfare within a few iterations and is able to find good solutions even in scenarios with high dimensionality in the decision variables space, setting a path for complexity reduction in more realistic road pricing optimization problems. Furthermore and as expected, the simulation results show that TODP improves the social welfare against the no-pricing case.",
        "published": "2020-12-20T23:13:01Z",
        "link": "http://arxiv.org/abs/2012.11047v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Difference Rewards Policy Gradients",
        "authors": [
            "Jacopo Castellini",
            "Sam Devlin",
            "Frans A. Oliehoek",
            "Rahul Savani"
        ],
        "summary": "Policy gradient methods have become one of the most popular classes of algorithms for multi-agent reinforcement learning. A key challenge, however, that is not addressed by many of these methods is multi-agent credit assignment: assessing an agent's contribution to the overall performance, which is crucial for learning good policies. We propose a novel algorithm called Dr.Reinforce that explicitly tackles this by combining difference rewards with policy gradients to allow for learning decentralized policies when the reward function is known. By differencing the reward function directly, Dr.Reinforce avoids difficulties associated with learning the Q-function as done by Counterfactual Multiagent Policy Gradients (COMA), a state-of-the-art difference rewards method. For applications where the reward function is unknown, we show the effectiveness of a version of Dr.Reinforce that learns an additional reward network that is used to estimate the difference rewards.",
        "published": "2020-12-21T11:23:17Z",
        "link": "http://arxiv.org/abs/2012.11258v2",
        "categories": [
            "cs.MA",
            "cs.LG",
            "I.2.6; I.2.11"
        ]
    },
    {
        "title": "Rapidly adapting robot swarms with Swarm Map-based Bayesian Optimisation",
        "authors": [
            "David M. Bossens",
            "Danesh Tarapore"
        ],
        "summary": "Rapid performance recovery from unforeseen environmental perturbations remains a grand challenge in swarm robotics. To solve this challenge, we investigate a behaviour adaptation approach, where one searches an archive of controllers for potential recovery solutions. To apply behaviour adaptation in swarm robotic systems, we propose two algorithms: (i) Swarm Map-based Optimisation (SMBO), which selects and evaluates one controller at a time, for a homogeneous swarm, in a centralised fashion; and (ii) Swarm Map-based Optimisation Decentralised (SMBO-Dec), which performs an asynchronous batch-based Bayesian optimisation to simultaneously explore different controllers for groups of robots in the swarm. We set up foraging experiments with a variety of disturbances: injected faults to proximity sensors, ground sensors, and the actuators of individual robots, with 100 unique combinations for each type. We also investigate disturbances in the operating environment of the swarm, where the swarm has to adapt to drastic changes in the number of resources available in the environment, and to one of the robots behaving disruptively towards the rest of the swarm, with 30 unique conditions for each such perturbation. The viability of SMBO and SMBO-Dec is demonstrated, comparing favourably to variants of random search and gradient descent, and various ablations, and improving performance up to 80% compared to the performance at the time of fault injection within at most 30 evaluations.",
        "published": "2020-12-21T15:54:37Z",
        "link": "http://arxiv.org/abs/2012.11444v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA",
            "cs.NE"
        ]
    },
    {
        "title": "Can we learn where people come from? Retracing of origins in merging   situations",
        "authors": [
            "Marion Gödel",
            "Luca Spataro",
            "Gerta Köster"
        ],
        "summary": "One crucial information for a pedestrian crowd simulation is the number of agents moving from an origin to a certain target. While this setup has a large impact on the simulation, it is in most setups challenging to find the number of agents that should be spawned at a source in the simulation. Often, number are chosen based on surveys and experience of modelers and event organizers. These approaches are important and useful but reach their limits when we want to perform real-time predictions. In this case, a static information about the inflow is not sufficient. Instead, we need a dynamic information that can be retrieved each time the prediction is started. Nowadays, sensor data such as video footage or GPS tracks of a crowd are often available. If we can estimate the number of pedestrians who stem from a certain origin from this sensor data, we can dynamically initialize the simulation. In this study, we use density heatmaps that can be derived from sensor data as input for a random forest regressor to predict the origin distributions. We study three different datasets: A simulated dataset, experimental data, and a hybrid approach with both experimental and simulated data. In the hybrid setup, the model is trained with simulated data and then tested on experimental data. The results demonstrate that the random forest model is able to predict the origin distribution based on a single density heatmap for all three configurations. This is especially promising for applying the approach on real data since there is often only a limited amount of data available.",
        "published": "2020-12-21T17:42:14Z",
        "link": "http://arxiv.org/abs/2012.11527v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Multi-Agent Online Optimization with Delays: Asynchronicity, Adaptivity,   and Optimism",
        "authors": [
            "Yu-Guan Hsieh",
            "Franck Iutzeler",
            "Jérôme Malick",
            "Panayotis Mertikopoulos"
        ],
        "summary": "In this paper, we provide a general framework for studying multi-agent online learning problems in the presence of delays and asynchronicities. Specifically, we propose and analyze a class of adaptive dual averaging schemes in which agents only need to accumulate gradient feedback received from the whole system, without requiring any between-agent coordination. In the single-agent case, the adaptivity of the proposed method allows us to extend a range of existing results to problems with potentially unbounded delays between playing an action and receiving the corresponding feedback. In the multi-agent case, the situation is significantly more complicated because agents may not have access to a global clock to use as a reference point; to overcome this, we focus on the information that is available for producing each prediction rather than the actual delay associated with each feedback. This allows us to derive adaptive learning strategies with optimal regret bounds, even in a fully decentralized, asynchronous environment. Finally, we also analyze an \"optimistic\" variant of the proposed algorithm which is capable of exploiting the predictability of problems with a slower variation and leads to improved regret bounds.",
        "published": "2020-12-21T18:55:55Z",
        "link": "http://arxiv.org/abs/2012.11579v2",
        "categories": [
            "cs.LG",
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "Scalable Deep Reinforcement Learning for Routing and Spectrum Access in   Physical Layer",
        "authors": [
            "Wei Cui",
            "Wei Yu"
        ],
        "summary": "This paper proposes a novel scalable reinforcement learning approach for simultaneous routing and spectrum access in wireless ad-hoc networks. In most previous works on reinforcement learning for network optimization, the network topology is assumed to be fixed, and a different agent is trained for each transmission node -- this limits scalability and generalizability. Further, routing and spectrum access are typically treated as separate tasks. Moreover, the optimization objective is usually a cumulative metric along the route, e.g., number of hops or delay. In this paper, we account for the physical-layer signal-to-interference-plus-noise ratio (SINR) in a wireless network and further show that bottleneck objective such as the minimum SINR along the route can also be optimized effectively using reinforcement learning. Specifically, we propose a scalable approach in which a single agent is associated with each flow and makes routing and spectrum access decisions as it moves along the frontier nodes. The agent is trained according to the physical-layer characteristics of the environment using a novel rewarding scheme based on the Monte Carlo estimation of the future bottleneck SINR. It learns to avoid interference by intelligently making joint routing and spectrum allocation decisions based on the geographical location information of the neighbouring nodes.",
        "published": "2020-12-22T01:47:20Z",
        "link": "http://arxiv.org/abs/2012.11783v2",
        "categories": [
            "eess.SP",
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "cs.NI"
        ]
    },
    {
        "title": "Modelling Human Routines: Conceptualising Social Practice Theory for   Agent-Based Simulation",
        "authors": [
            "Rijk Mercuur",
            "Virginia Dignum",
            "Catholijn M. Jonker"
        ],
        "summary": "Our routines play an important role in a wide range of social challenges such as climate change, disease outbreaks and coordinating staff and patients in a hospital. To use agent-based simulations (ABS) to understand the role of routines in social challenges we need an agent framework that integrates routines. This paper provides the domain-independent Social Practice Agent (SoPrA) framework that satisfies requirements from the literature to simulate our routines. By choosing the appropriate concepts from the literature on agent theory, social psychology and social practice theory we ensure SoPrA correctly depicts current evidence on routines. By creating a consistent, modular and parsimonious framework suitable for multiple domains we enhance the usability of SoPrA. SoPrA provides ABS researchers with a conceptual, formal and computational framework to simulate routines and gain new insights into social systems.",
        "published": "2020-12-22T10:06:47Z",
        "link": "http://arxiv.org/abs/2012.11903v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "I.6; I.2"
        ]
    },
    {
        "title": "QVMix and QVMix-Max: Extending the Deep Quality-Value Family of   Algorithms to Cooperative Multi-Agent Reinforcement Learning",
        "authors": [
            "Pascal Leroy",
            "Damien Ernst",
            "Pierre Geurts",
            "Gilles Louppe",
            "Jonathan Pisane",
            "Matthia Sabatelli"
        ],
        "summary": "This paper introduces four new algorithms that can be used for tackling multi-agent reinforcement learning (MARL) problems occurring in cooperative settings. All algorithms are based on the Deep Quality-Value (DQV) family of algorithms, a set of techniques that have proven to be successful when dealing with single-agent reinforcement learning problems (SARL). The key idea of DQV algorithms is to jointly learn an approximation of the state-value function $V$, alongside an approximation of the state-action value function $Q$. We follow this principle and generalise these algorithms by introducing two fully decentralised MARL algorithms (IQV and IQV-Max) and two algorithms that are based on the centralised training with decentralised execution training paradigm (QVMix and QVMix-Max). We compare our algorithms with state-of-the-art MARL techniques on the popular StarCraft Multi-Agent Challenge (SMAC) environment. We show competitive results when QVMix and QVMix-Max are compared to well-known MARL techniques such as QMIX and MAVEN and show that QVMix can even outperform them on some of the tested environments, being the algorithm which performs best overall. We hypothesise that this is due to the fact that QVMix suffers less from the overestimation bias of the $Q$ function.",
        "published": "2020-12-22T14:53:42Z",
        "link": "http://arxiv.org/abs/2012.12062v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Distributed Q-Learning with State Tracking for Multi-agent Networked   Control",
        "authors": [
            "Hang Wang",
            "Sen Lin",
            "Hamid Jafarkhani",
            "Junshan Zhang"
        ],
        "summary": "This paper studies distributed Q-learning for Linear Quadratic Regulator (LQR) in a multi-agent network. The existing results often assume that agents can observe the global system state, which may be infeasible in large-scale systems due to privacy concerns or communication constraints. In this work, we consider a setting with unknown system models and no centralized coordinator. We devise a state tracking (ST) based Q-learning algorithm to design optimal controllers for agents. Specifically, we assume that agents maintain local estimates of the global state based on their local information and communications with neighbors. At each step, every agent updates its local global state estimation, based on which it solves an approximate Q-factor locally through policy iteration. Assuming decaying injected excitation noise during the policy evaluation, we prove that the local estimation converges to the true global state, and establish the convergence of the proposed distributed ST-based Q-learning algorithm. The experimental studies corroborate our theoretical results by showing that our proposed method achieves comparable performance with the centralized case.",
        "published": "2020-12-22T22:03:49Z",
        "link": "http://arxiv.org/abs/2012.12383v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Distributed Adaptive Control: An ideal Cognitive Architecture candidate   for managing a robotic recycling plant",
        "authors": [
            "Oscar Guerrero-Rosado",
            "Paul Verschure"
        ],
        "summary": "In the past decade, society has experienced notable growth in a variety of technological areas. However, the Fourth Industrial Revolution has not been embraced yet. Industry 4.0 imposes several challenges which include the necessity of new architectural models to tackle the uncertainty that open environments represent to cyber-physical systems (CPS). Waste Electrical and Electronic Equipment (WEEE) recycling plants stand for one of such open environments. Here, CPSs must work harmoniously in a changing environment, interacting with similar and not so similar CPSs, and adaptively collaborating with human workers. In this paper, we support the Distributed Adaptive Control (DAC) theory as a suitable Cognitive Architecture for managing a recycling plant. Specifically, a recursive implementation of DAC (between both single-agent and large-scale levels) is proposed to meet the expected demands of the European Project HR-Recycler. Additionally, with the aim of having a realistic benchmark for future implementations of the recursive DAC, a micro-recycling plant prototype is presented.",
        "published": "2020-12-23T10:33:22Z",
        "link": "http://arxiv.org/abs/2012.12586v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.NE",
            "cs.RO",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Cohorting to isolate asymptomatic spreaders: An agent-based simulation   study on the Mumbai Suburban Railway",
        "authors": [
            "Alok Talekar",
            "Sharad Shriram",
            "Nidhin Vaidhiyan",
            "Gaurav Aggarwal",
            "Jiangzhuo Chen",
            "Srini Venkatramanan",
            "Lijing Wang",
            "Aniruddha Adiga",
            "Adam Sadilek",
            "Ashish Tendulkar",
            "Madhav Marathe",
            "Rajesh Sundaresan",
            "Milind Tambe"
        ],
        "summary": "The Mumbai Suburban Railways, \\emph{locals}, are a key transit infrastructure of the city and is crucial for resuming normal economic activity. To reduce disease transmission, policymakers can enforce reduced crowding and mandate wearing of masks. \\emph{Cohorting} -- forming groups of travelers that always travel together, is an additional policy to reduce disease transmission on \\textit{locals} without severe restrictions. Cohorting allows us to: ($i$) form traveler bubbles, thereby decreasing the number of distinct interactions over time; ($ii$) potentially quarantine an entire cohort if a single case is detected, making contact tracing more efficient, and ($iii$) target cohorts for testing and early detection of symptomatic as well as asymptomatic cases. Studying impact of cohorts using compartmental models is challenging because of the ensuing representational complexity. Agent-based models provide a natural way to represent cohorts along with the representation of the cohort members with the larger social network. This paper describes a novel multi-scale agent-based model to study the impact of cohorting strategies on COVID-19 dynamics in Mumbai. We achieve this by modeling the Mumbai urban region using a detailed agent-based model comprising of 12.4 million agents. Individual cohorts and their inter-cohort interactions as they travel on locals are modeled using local mean field approximations. The resulting multi-scale model in conjunction with a detailed disease transmission and intervention simulator is used to assess various cohorting strategies. The results provide a quantitative trade-off between cohort size and its impact on disease dynamics and well being. The results show that cohorts can provide significant benefit in terms of reduced transmission without significantly impacting ridership and or economic \\& social activity.",
        "published": "2020-12-23T18:06:22Z",
        "link": "http://arxiv.org/abs/2012.12839v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Awareness Logic: A Kripke-based Rendition of the Heifetz-Meier-Schipper   Model",
        "authors": [
            "Gaia Belardinelli",
            "Rasmus K. Rendsvig"
        ],
        "summary": "Heifetz, Meier and Schipper (HMS) present a lattice model of awareness. The HMS model is syntax-free, which precludes the simple option to rely on formal language to induce lattices, and represents uncertainty and unawareness with one entangled construct, making it difficult to assess the properties of either. Here, we present a model based on a lattice of Kripke models, induced by atom subset inclusion, in which uncertainty and unawareness are separate. We show the models to be equivalent by defining transformations between them which preserve formula satisfaction, and obtain completeness through our and HMS' results.",
        "published": "2020-12-23T21:24:06Z",
        "link": "http://arxiv.org/abs/2012.12982v1",
        "categories": [
            "cs.AI",
            "cs.LO",
            "cs.MA",
            "econ.TH",
            "math.LO",
            "03B42, 68T27",
            "I.2.0; I.2.4; I.2.11"
        ]
    },
    {
        "title": "Distributed Multi-object Tracking under Limited Field of View Sensors",
        "authors": [
            "Hoa Van Nguyen",
            "Hamid Rezatofighi",
            "Ba-Ngu Vo",
            "Damith C. Ranasinghe"
        ],
        "summary": "We consider the challenging problem of tracking multiple objects using a distributed network of sensors. In the practical setting of nodes with limited field of views (FoVs), computing power and communication resources, we develop a novel distributed multi-object tracking algorithm. To accomplish this, we first formalise the concept of label consistency, determine a sufficient condition to achieve it and develop a novel \\textit{label consensus approach} that reduces label inconsistency caused by objects' movements from one node's limited FoV to another. Second, we develop a distributed multi-object fusion algorithm that fuses local multi-object state estimates instead of local multi-object densities. This algorithm: i) requires significantly less processing time than multi-object density fusion methods; ii) achieves better tracking accuracy by considering Optimal Sub-Pattern Assignment (OSPA) tracking errors over several scans rather than a single scan; iii) is agnostic to local multi-object tracking techniques, and only requires each node to provide a set of estimated tracks. Thus, it is not necessary to assume that the nodes maintain multi-object densities, and hence the fusion outcomes do not modify local multi-object densities. Numerical experiments demonstrate our proposed solution's real-time computational efficiency and accuracy compared to state-of-the-art solutions in challenging scenarios. We also release source code at https://github.com/AdelaideAuto-IDLab/Distributed-limitedFoV-MOT for our fusion method to foster developments in DMOT algorithms.",
        "published": "2020-12-23T21:34:28Z",
        "link": "http://arxiv.org/abs/2012.12990v2",
        "categories": [
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Doubly Stochastic Pairwise Interactions for Agreement and Alignment",
        "authors": [
            "Thomas Dagès",
            "Alfred M. Bruckstein"
        ],
        "summary": "Random pairwise encounters often occur in large populations, or groups of mobile agents, and various types of local interactions that happen at encounters account for emergent global phenomena. In particular, in the fields of swarm robotics, sociobiology, and social dynamics, several types of local pairwise interactions were proposed and analysed leading to spatial gathering or clustering and agreement in teams of robotic agents coordinated motion, in animal herds, or in human societies. We here propose a very simple stochastic interaction at encounters that leads to agreement or geometric alignment in swarms of simple agents, and analyse the process of converging to consensus. Consider a group of agents whose \"states\" evolve in time by pairwise interactions: the state of an agent is either a real value (a randomly initialised position within an interval) or a vector that is either unconstrained (e.g. the location of the agent in the plane) or constrained to have unit length (e.g. the direction of the agent's motion). The interactions are doubly stochastic, in the sense that, at discrete time steps, pairs of agents are randomly selected and their new states are independently and uniformly set at random in (local) domains or intervals defined by the states of the interacting pair. We show that such processes lead, in finite expected time (measured by the number of interactions that occurred) to agreement in case of unconstrained states and alignment when the states are unit vectors.",
        "published": "2020-12-26T12:45:18Z",
        "link": "http://arxiv.org/abs/2012.13727v2",
        "categories": [
            "cs.MA",
            "93A14, 93C05, 93C10, 93E15"
        ]
    },
    {
        "title": "Generation of Traffic Flows in Multi-Agent Traffic Simulation with Agent   Behavior Model based on Deep Reinforcement Learning",
        "authors": [
            "Junjie Zhong",
            "Hiromitsu Hattori"
        ],
        "summary": "In multi-agent based traffic simulation, agents are always supposed to move following existing instructions, and mechanically and unnaturally imitate human behavior. The human drivers perform acceleration or deceleration irregularly all the time, which seems unnecessary in some conditions. For letting agents in traffic simulation behave more like humans and recognize other agents' behavior in complex conditions, we propose a unified mechanism for agents learn to decide various accelerations by using deep reinforcement learning based on a combination of regenerated visual images revealing some notable features, and numerical vectors containing some important data such as instantaneous speed. By handling batches of sequential data, agents are enabled to recognize surrounding agents' behavior and decide their own acceleration. In addition, we can generate a traffic flow behaving diversely to simulate the real traffic flow by using an architecture of fully decentralized training and fully centralized execution without violating Markov assumptions.",
        "published": "2020-12-26T15:13:06Z",
        "link": "http://arxiv.org/abs/2101.03230v2",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Approximate and Strategyproof Maximin Share Allocation of Chores with   Ordinal Preferences",
        "authors": [
            "Haris Aziz",
            "Bo Li",
            "Xiaowei Wu"
        ],
        "summary": "We initiate the work on maximin share (MMS) fair allocation of m indivisible chores to n agents using only their ordinal preferences, from both algorithmic and mechanism design perspectives. The previous best-known approximation is 2-1/n by Aziz et al. [IJCAI 2017]. We improve this result by giving a simple deterministic 5/3-approximation algorithm that determines an allocation sequence of agents, according to which items are allocated one by one. By a tighter analysis, we show that for n=2,3, our algorithm achieves better approximation ratios, and is actually optimal. We also consider the setting with strategic agents, where agents may misreport their preferences to manipulate the outcome. We first provide a O(\\log (m/n))-approximation consecutive picking algorithm, and then improve the approximation ratio to O(\\sqrt{\\log n}) by a randomized algorithm. Our results uncover some interesting contrasts between the approximation ratios achieved for chores versus goods.",
        "published": "2020-12-27T07:30:16Z",
        "link": "http://arxiv.org/abs/2012.13884v1",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Federated Multi-Agent Actor-Critic Learning for Age Sensitive Mobile   Edge Computing",
        "authors": [
            "Zheqi Zhu",
            "Shuo Wan",
            "Pingyi Fan",
            "Khaled B. Letaief"
        ],
        "summary": "As an emerging technique, mobile edge computing (MEC) introduces a new processing scheme for various distributed communication-computing systems such as industrial Internet of Things (IoT), vehicular communication, smart city, etc. In this work, we mainly focus on the timeliness of the MEC systems where the freshness of the data and computation tasks is significant. Firstly, we formulate a kind of age-sensitive MEC models and define the average age of information (AoI) minimization problems of interests. Then, a novel policy based multi-agent deep reinforcement learning (RL) framework, called heterogeneous multi-agent actor critic (H-MAAC), is proposed as a paradigm for joint collaboration in the investigated MEC systems, where edge devices and center controller learn the interactive strategies through their own observations. To improves the system performance, we develop the corresponding online algorithm by introducing an edge federated learning mode into the multi-agent cooperation whose advantages on learning convergence can be guaranteed theoretically. To the best of our knowledge, it's the first joint MEC collaboration algorithm that combines the edge federated mode with the multi-agent actor-critic reinforcement learning. Furthermore, we evaluate the proposed approach and compare it with classical RL based methods. As a result, the proposed framework not only outperforms the baseline on average system age, but also promotes the stability of training process. Besides, the simulation results provide some innovative perspectives for the system design under the edge federated collaboration.",
        "published": "2020-12-28T08:19:26Z",
        "link": "http://arxiv.org/abs/2012.14137v3",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "The temporal logic of coalitional goal assignments in concurrent   multi-player games",
        "authors": [
            "Sebastian Enqvist",
            "Valentin Goranko"
        ],
        "summary": "We introduce and study a natural extension of the Alternating time temporal logic ATL, called Temporal Logic of Coalitional Goal Assignments (TLCGA). It features just one, but quite expressive, coalitional strategic operator, viz. the coalitional goal assignment operator, which is based on a mapping assigning to each set of players in the game its coalitional goal, formalised by a path formula of the language of TLCGA, i.e. a formula prefixed with a temporal operator X,U, or G, representing a temporalised objective for the respective coalition, describing the property of the plays on which that objective is satisfied. We establish fixpoint characterizations of the temporal goal assignments in a mu-calculus extension of TLCGA, discuss its expressiveness and illustrate it with some examples, prove bisimulation invariance and Hennessy-Milner property for it with respect to a suitably defined notion of bisimulation, construct a sound and complete axiomatic system for TLCGA, and obtain its decidability via finite model property.",
        "published": "2020-12-28T11:20:20Z",
        "link": "http://arxiv.org/abs/2012.14195v3",
        "categories": [
            "cs.LO",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Prosocial Norm Emergence in Multiagent Systems",
        "authors": [
            "Mehdi Mashayekhi",
            "Nirav Ajmeri",
            "George F. List",
            "Munindar P. Singh"
        ],
        "summary": "Multiagent systems provide a basis for developing systems of autonomous entities and thus find application in a variety of domains. We consider a setting where not only the member agents are adaptive but also the multiagent system viewed as an entity in its own right is adaptive. Specifically, the social structure of a multiagent system can be reflected in the social norms among its members. It is well recognized that the norms that arise in society are not always beneficial to its members. We focus on prosocial norms, which help achieve positive outcomes for society and often provide guidance to agents to act in a manner that takes into account the welfare of others.   Specifically, we propose Cha, a framework for the emergence of prosocial norms. Unlike previous norm emergence approaches, Cha supports continual change to a system (agents may enter and leave) and dynamism (norms may change when the environment changes). Importantly, Cha agents incorporate prosocial decision making based on inequity aversion theory, reflecting an intuition of guilt arising from being antisocial. In this manner, Cha brings together two important themes in prosociality: decision making by individuals and fairness of system-level outcomes. We demonstrate via simulation that Cha can improve aggregate societal gains and fairness of outcomes.",
        "published": "2020-12-29T02:59:55Z",
        "link": "http://arxiv.org/abs/2012.14581v2",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Present-Biased Optimization",
        "authors": [
            "Fedor V. Fomin",
            "Pierre Fraigniaud",
            "Petr A. Golovach"
        ],
        "summary": "This paper explores the behavior of present-biased agents, that is, agents who erroneously anticipate the costs of future actions compared to their real costs. Specifically, the paper extends the original framework proposed by Akerlof (1991) for studying various aspects of human behavior related to time-inconsistent planning, including procrastination, and abandonment, as well as the elegant graph-theoretic model encapsulating this framework recently proposed by Kleinberg and Oren (2014). The benefit of this extension is twofold. First, it enables to perform fine grained analysis of the behavior of present-biased agents depending on the optimisation task they have to perform. In particular, we study covering tasks vs. hitting tasks, and show that the ratio between the cost of the solutions computed by present-biased agents and the cost of the optimal solutions may differ significantly depending on the problem constraints. Second, our extension enables to study not only underestimation of future costs, coupled with minimization problems, but also all combinations of minimization/maximization, and underestimation/overestimation. We study the four scenarios, and we establish upper bounds on the cost ratio for three of them (the cost ratio for the original scenario was known to be unbounded), providing a complete global picture of the behavior of present-biased agents, as far as optimisation tasks are concerned.",
        "published": "2020-12-29T12:40:59Z",
        "link": "http://arxiv.org/abs/2012.14736v1",
        "categories": [
            "math.OC",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Knowledge-Based Strategies for Multi-Agent Teams Playing Against Nature",
        "authors": [
            "Dilian Gurov",
            "Valentin Goranko",
            "Edvin Lundberg"
        ],
        "summary": "We study teams of agents that play against Nature towards achieving a common objective. The agents are assumed to have imperfect information due to partial observability, and have no communication during the play of the game. We propose a natural notion of higher-order knowledge of agents. Based on this notion, we define a class of knowledge-based strategies, and consider the problem of synthesis of strategies of this class. We introduce a multi-agent extension, MKBSC, of the well-known Knowledge-Based Subset Construction applied to such games. Its iterative applications turn out to compute higher-order knowledge of the agents. We show how the MKBSC can be used for the design of knowledge-based strategy profiles and investigate the transfer of existence of such strategies between the original game and in the iterated applications of the MKBSC, under some natural assumptions. We also relate and compare the \"intensional\" view on knowledge-based strategies based on explicit knowledge representation and update, with the \"extensional\" view on finite memory strategies based on finite transducers and show that, in a certain sense, these are equivalent.",
        "published": "2020-12-29T16:59:12Z",
        "link": "http://arxiv.org/abs/2012.14851v3",
        "categories": [
            "cs.MA",
            "F.m; I.2.4"
        ]
    },
    {
        "title": "Leveraging User Access Patterns and Advanced Cyberinfrastructure to   Accelerate Data Delivery from Shared-use Scientific Observatories",
        "authors": [
            "Yubo Qin",
            "Ivan Rodero",
            "Anthony Simonet",
            "Charles Meertens",
            "Daniel Reiner",
            "James Riley",
            "Manish Parashar"
        ],
        "summary": "With the growing number and increasing availability of shared-use instruments and observatories, observational data is becoming an essential part of application workflows and contributor to scientific discoveries in a range of disciplines. However, the corresponding growth in the number of users accessing these facilities coupled with the expansion in the scale and variety of the data, is making it challenging for these facilities to ensure their data can be accessed, integrated, and analyzed in a timely manner, and is resulting significant demands on their cyberinfrastructure (CI).   In this paper, we present the design of a push-based data delivery framework that leverages emerging in-network capabilities, along with data pre-fetching techniques based on a hybrid data management model. Specifically, we analyze data access traces for two large-scale observatories, Ocean Observatories Initiative (OOI) and Geodetic Facility for the Advancement of Geoscience (GAGE), to identify typical user access patterns and to develop a model that can be used for data pre-fetching. Furthermore, we evaluate our data pre-fetching model and the proposed framework using a simulation of the Virtual Data Collaboratory (VDC) platform that provides in-network data staging and processing capabilities. The results demonstrate that the ability of the framework to significantly improve data delivery performance and reduce network traffic at the observatories' facilities.",
        "published": "2020-12-30T20:52:00Z",
        "link": "http://arxiv.org/abs/2012.15321v1",
        "categories": [
            "cs.DC",
            "cs.MA"
        ]
    },
    {
        "title": "Model Free Reinforcement Learning Algorithm for Stationary Mean field   Equilibrium for Multiple Types of Agents",
        "authors": [
            "Arnob Ghosh",
            "Vaneet Aggarwal"
        ],
        "summary": "We consider a multi-agent Markov strategic interaction over an infinite horizon where agents can be of multiple types. We model the strategic interaction as a mean-field game in the asymptotic limit when the number of agents of each type becomes infinite. Each agent has a private state; the state evolves depending on the distribution of the state of the agents of different types and the action of the agent. Each agent wants to maximize the discounted sum of rewards over the infinite horizon which depends on the state of the agent and the distribution of the state of the leaders and followers. We seek to characterize and compute a stationary multi-type Mean field equilibrium (MMFE) in the above game. We characterize the conditions under which a stationary MMFE exists. Finally, we propose Reinforcement learning (RL) based algorithm using policy gradient approach to find the stationary MMFE when the agents are unaware of the dynamics. We, numerically, evaluate how such kind of interaction can model the cyber attacks among defenders and adversaries, and show how RL based algorithm can converge to an equilibrium.",
        "published": "2020-12-31T00:12:46Z",
        "link": "http://arxiv.org/abs/2012.15377v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.GT",
            "cs.LG",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Vehicular Network Slicing for Reliable Access and Deadline-Constrained   Data Offloading: A Multi-Agent On-Device Learning Approach",
        "authors": [
            "Md Ferdous Pervej",
            "Shih-Chun Lin"
        ],
        "summary": "Efficient data offloading plays a pivotal role in computational-intensive platforms as data rate over wireless channels is fundamentally limited. On top of that, high mobility adds an extra burden in vehicular edge networks (VENs), bolstering the desire for efficient user-centric solutions. Therefore, unlike the legacy inflexible network-centric approach, this paper exploits a software-defined flexible, open, and programmable networking platform for an efficient user-centric, fast, reliable, and deadline-constrained offloading solution in VENs. In the proposed model, each active vehicle user (VU) is served from multiple low-powered access points (APs) by creating a noble virtual cell (VC). A joint node association, power allocation, and distributed resource allocation problem is formulated. As centralized learning is not practical in many real-world problems, following the distributed nature of autonomous VUs, each VU is considered an edge learning agent. To that end, considering practical location-aware node associations, a joint radio and power resource allocation non-cooperative stochastic game is formulated. Leveraging reinforcement learning's (RL) efficacy, a multi-agent RL (MARL) solution is proposed where the edge learners aim to learn the Nash equilibrium (NE) strategies to solve the game efficiently. Besides, real-world map data, with a practical microscopic mobility model, are used for the simulation. Results suggest that the proposed user-centric approach can deliver remarkable performances in VENs. Moreover, the proposed MARL solution delivers near-optimal performances with approximately 3% collision probabilities in case of distributed random access in the uplink.",
        "published": "2020-12-31T11:15:10Z",
        "link": "http://arxiv.org/abs/2012.15545v2",
        "categories": [
            "cs.NI",
            "cs.DC",
            "cs.MA",
            "cs.SY",
            "eess.SP",
            "eess.SY"
        ]
    },
    {
        "title": "Partially Observable Mean Field Reinforcement Learning",
        "authors": [
            "Sriram Ganapathi Subramanian",
            "Matthew E. Taylor",
            "Mark Crowley",
            "Pascal Poupart"
        ],
        "summary": "Traditional multi-agent reinforcement learning algorithms are not scalable to environments with more than a few agents, since these algorithms are exponential in the number of agents. Recent research has introduced successful methods to scale multi-agent reinforcement learning algorithms to many agent scenarios using mean field theory. Previous work in this field assumes that an agent has access to exact cumulative metrics regarding the mean field behaviour of the system, which it can then use to take its actions. In this paper, we relax this assumption and maintain a distribution to model the uncertainty regarding the mean field of the system. We consider two different settings for this problem. In the first setting, only agents in a fixed neighbourhood are visible, while in the second setting, the visibility of agents is determined at random based on distances. For each of these settings, we introduce a Q-learning based algorithm that can learn effectively. We prove that this Q-learning estimate stays very close to the Nash Q-value (under a common set of assumptions) for the first setting. We also empirically show our algorithms outperform multiple baselines in three different games in the MAgents framework, which supports large environments with many agents learning simultaneously to achieve possibly distinct goals.",
        "published": "2020-12-31T18:12:31Z",
        "link": "http://arxiv.org/abs/2012.15791v3",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Painting Many Pasts: Synthesizing Time Lapse Videos of Paintings",
        "authors": [
            "Amy Zhao",
            "Guha Balakrishnan",
            "Kathleen M. Lewis",
            "Frédo Durand",
            "John V. Guttag",
            "Adrian V. Dalca"
        ],
        "summary": "We introduce a new video synthesis task: synthesizing time lapse videos depicting how a given painting might have been created. Artists paint using unique combinations of brushes, strokes, and colors. There are often many possible ways to create a given painting. Our goal is to learn to capture this rich range of possibilities.   Creating distributions of long-term videos is a challenge for learning-based video synthesis methods. We present a probabilistic model that, given a single image of a completed painting, recurrently synthesizes steps of the painting process. We implement this model as a convolutional neural network, and introduce a novel training scheme to enable learning from a limited dataset of painting time lapses. We demonstrate that this model can be used to sample many time steps, enabling long-term stochastic video synthesis. We evaluate our method on digital and watercolor paintings collected from video websites, and show that human raters find our synthetic videos to be similar to time lapse videos produced by real artists. Our code is available at https://xamyzhao.github.io/timecraft.",
        "published": "2020-01-04T03:12:38Z",
        "link": "http://arxiv.org/abs/2001.01026v2",
        "categories": [
            "cs.GR",
            "cs.CV"
        ]
    },
    {
        "title": "TCM-ICP: Transformation Compatibility Measure for Registering Multiple   LIDAR Scans",
        "authors": [
            "Aby Thomas",
            "Adarsh Sunilkumar",
            "Shankar Shylesh",
            "Aby Abahai T.",
            "Subhasree Methirumangalath",
            "Dong Chen",
            "Jiju Peethambaran"
        ],
        "summary": "Rigid registration of multi-view and multi-platform LiDAR scans is a fundamental problem in 3D mapping, robotic navigation, and large-scale urban modeling applications. Data acquisition with LiDAR sensors involves scanning multiple areas from different points of view, thus generating partially overlapping point clouds of the real world scenes. Traditionally, ICP (Iterative Closest Point) algorithm is used to register the acquired point clouds together to form a unique point cloud that captures the scanned real world scene. Conventional ICP faces local minima issues and often needs a coarse initial alignment to converge to the optimum. In this work, we present an algorithm for registering multiple, overlapping LiDAR scans. We introduce a geometric metric called Transformation Compatibility Measure (TCM) which aids in choosing the most similar point clouds for registration in each iteration of the algorithm. The LiDAR scan most similar to the reference LiDAR scan is then transformed using simplex technique. An optimization of the transformation using gradient descent and simulated annealing techniques are then applied to improve the resulting registration. We evaluate the proposed algorithm on four different real world scenes and experimental results shows that the registration performance of the proposed method is comparable or superior to the traditionally used registration methods. Further, the algorithm achieves superior registration results even when dealing with outliers.",
        "published": "2020-01-04T21:05:27Z",
        "link": "http://arxiv.org/abs/2001.01129v2",
        "categories": [
            "cs.CV",
            "cs.GR",
            "68U05",
            "I.3.5; I.4.8; I.5.3"
        ]
    },
    {
        "title": "MW-GAN: Multi-Warping GAN for Caricature Generation with Multi-Style   Geometric Exaggeration",
        "authors": [
            "Haodi Hou",
            "Jing Huo",
            "Jing Wu",
            "Yu-Kun Lai",
            "Yang Gao"
        ],
        "summary": "Given an input face photo, the goal of caricature generation is to produce stylized, exaggerated caricatures that share the same identity as the photo. It requires simultaneous style transfer and shape exaggeration with rich diversity, and meanwhile preserving the identity of the input. To address this challenging problem, we propose a novel framework called Multi-Warping GAN (MW-GAN), including a style network and a geometric network that are designed to conduct style transfer and geometric exaggeration respectively. We bridge the gap between the style and landmarks of an image with corresponding latent code spaces by a dual way design, so as to generate caricatures with arbitrary styles and geometric exaggeration, which can be specified either through random sampling of latent code or from a given caricature sample. Besides, we apply identity preserving loss to both image space and landmark space, leading to a great improvement in quality of generated caricatures. Experiments show that caricatures generated by MW-GAN have better quality than existing methods.",
        "published": "2020-01-07T03:08:30Z",
        "link": "http://arxiv.org/abs/2001.01870v2",
        "categories": [
            "cs.CV",
            "cs.GR",
            "cs.LG",
            "eess.IV"
        ]
    },
    {
        "title": "Deep Learning for Free-Hand Sketch: A Survey",
        "authors": [
            "Peng Xu",
            "Timothy M. Hospedales",
            "Qiyue Yin",
            "Yi-Zhe Song",
            "Tao Xiang",
            "Liang Wang"
        ],
        "summary": "Free-hand sketches are highly illustrative, and have been widely used by humans to depict objects or stories from ancient times to the present. The recent prevalence of touchscreen devices has made sketch creation a much easier task than ever and consequently made sketch-oriented applications increasingly popular. The progress of deep learning has immensely benefited free-hand sketch research and applications. This paper presents a comprehensive survey of the deep learning techniques oriented at free-hand sketch data, and the applications that they enable. The main contents of this survey include: (i) A discussion of the intrinsic traits and unique challenges of free-hand sketch, to highlight the essential differences between sketch data and other data modalities, e.g., natural photos. (ii) A review of the developments of free-hand sketch research in the deep learning era, by surveying existing datasets, research topics, and the state-of-the-art methods through a detailed taxonomy and experimental evaluation. (iii) Promotion of future work via a discussion of bottlenecks, open problems, and potential research directions for the community.",
        "published": "2020-01-08T16:23:56Z",
        "link": "http://arxiv.org/abs/2001.02600v3",
        "categories": [
            "cs.CV",
            "cs.GR",
            "cs.LG"
        ]
    },
    {
        "title": "Digesting the Elephant -- Experiences with Interactive Production   Quality Path Tracing of the Moana Island Scene",
        "authors": [
            "Ingo Wald",
            "Bruce Cherniak",
            "Will Usher",
            "Carson Brownlee",
            "Attila Afra",
            "Johannes Guenther",
            "Jefferson Amstutz",
            "Tim Rowley",
            "Valerio Pascucci",
            "Chris R Johnson",
            "Jim Jeffers"
        ],
        "summary": "New algorithmic and hardware developments over the past two decades have enabled interactive ray tracing of small to modest sized scenes, and are finding growing popularity in scientific visualization and games. However, interactive ray tracing has not been as widely explored in the context of production film rendering, where challenges due to the complexity of the models and, from a practical standpoint, their unavailability to the wider research community, have posed significant challenges. The recent release of the Disney Moana Island Scene has made one such model available to the community for experimentation. In this paper, we detail the challenges posed by this scene to an interactive ray tracer, and the solutions we have employed and developed to enable interactive path tracing of the scene with full geometric and shading detail, with the goal of providing insight and guidance to other researchers.",
        "published": "2020-01-08T16:58:52Z",
        "link": "http://arxiv.org/abs/2001.02620v1",
        "categories": [
            "cs.GR"
        ]
    },
    {
        "title": "OO-VR: NUMA Friendly Object-Oriented VR Rendering Framework For Future   NUMA-Based Multi-GPU Systems",
        "authors": [
            "Chenhao Xie",
            "Xin Fu",
            "Mingsong Chen",
            "Shuaiwen Leon Song"
        ],
        "summary": "With the strong computation capability, NUMA-based multi-GPU system is a promising candidate to provide sustainable and scalable performance for Virtual Reality. However, the entire multi-GPU system is viewed as a single GPU which ignores the data locality in VR rendering during the workload distribution, leading to tremendous remote memory accesses among GPU models. By conducting comprehensive characterizations on different kinds of parallel rendering frameworks, we observe that distributing the rendering object along with its required data per GPM can reduce the inter-GPM memory accesses. However, this object-level rendering still faces two major challenges in NUMA-based multi-GPU system: (1) the large data locality between the left and right views of the same object and the data sharing among different objects and (2) the unbalanced workloads induced by the software-level distribution and composition mechanisms. To tackle these challenges, we propose object-oriented VR rendering framework (OO-VR) that conducts the software and hardware co-optimization to provide a NUMA friendly solution for VR multi-view rendering in NUMA-based multi-GPU systems. We first propose an object-oriented VR programming model to exploit the data sharing between two views of the same object and group objects into batches based on their texture sharing levels. Then, we design an object aware runtime batch distribution engine and distributed hardware composition unit to achieve the balanced workloads among GPMs. Finally, evaluations on our VR featured simulator show that OO-VR provides 1.58x overall performance improvement and 76% inter-GPM memory traffic reduction over the state-of-the-art multi-GPU systems. In addition, OO-VR provides NUMA friendly performance scalability for the future larger multi-GPU scenarios with ever increasing asymmetric bandwidth between local and remote memory.",
        "published": "2020-01-08T19:44:51Z",
        "link": "http://arxiv.org/abs/2001.03537v1",
        "categories": [
            "cs.DC",
            "cs.GR"
        ]
    },
    {
        "title": "Unsupervised multi-modal Styled Content Generation",
        "authors": [
            "Omry Sendik",
            "Dani Lischinski",
            "Daniel Cohen-Or"
        ],
        "summary": "The emergence of deep generative models has recently enabled the automatic generation of massive amounts of graphical content, both in 2D and in 3D. Generative Adversarial Networks (GANs) and style control mechanisms, such as Adaptive Instance Normalization (AdaIN), have proved particularly effective in this context, culminating in the state-of-the-art StyleGAN architecture. While such models are able to learn diverse distributions, provided a sufficiently large training set, they are not well-suited for scenarios where the distribution of the training data exhibits a multi-modal behavior. In such cases, reshaping a uniform or normal distribution over the latent space into a complex multi-modal distribution in the data domain is challenging, and the generator might fail to sample the target distribution well. Furthermore, existing unsupervised generative models are not able to control the mode of the generated samples independently of the other visual attributes, despite the fact that they are typically disentangled in the training data.   In this paper, we introduce UMMGAN, a novel architecture designed to better model multi-modal distributions, in an unsupervised fashion. Building upon the StyleGAN architecture, our network learns multiple modes, in a completely unsupervised manner, and combines them using a set of learned weights. We demonstrate that this approach is capable of effectively approximating a complex distribution as a superposition of multiple simple ones. We further show that UMMGAN effectively disentangles between modes and style, thereby providing an independent degree of control over the generated content.",
        "published": "2020-01-10T19:36:08Z",
        "link": "http://arxiv.org/abs/2001.03640v2",
        "categories": [
            "cs.GR",
            "cs.LG"
        ]
    },
    {
        "title": "On Demand Solid Texture Synthesis Using Deep 3D Networks",
        "authors": [
            "Jorge Gutierrez",
            "Julien Rabin",
            "Bruno Galerne",
            "Thomas Hurtut"
        ],
        "summary": "This paper describes a novel approach for on demand volumetric texture synthesis based on a deep learning framework that allows for the generation of high quality 3D data at interactive rates. Based on a few example images of textures, a generative network is trained to synthesize coherent portions of solid textures of arbitrary sizes that reproduce the visual characteristics of the examples along some directions. To cope with memory limitations and computation complexity that are inherent to both high resolution and 3D processing on the GPU, only 2D textures referred to as \"slices\" are generated during the training stage. These synthetic textures are compared to exemplar images via a perceptual loss function based on a pre-trained deep network. The proposed network is very light (less than 100k parameters), therefore it only requires sustainable training (i.e. few hours) and is capable of very fast generation (around a second for $256^3$ voxels) on a single GPU. Integrated with a spatially seeded PRNG the proposed generator network directly returns an RGB value given a set of 3D coordinates. The synthesized volumes have good visual results that are at least equivalent to the state-of-the-art patch based approaches. They are naturally seamlessly tileable and can be fully generated in parallel.",
        "published": "2020-01-13T20:59:14Z",
        "link": "http://arxiv.org/abs/2001.04528v1",
        "categories": [
            "cs.GR",
            "cs.LG",
            "eess.IV"
        ]
    },
    {
        "title": "Neural Human Video Rendering by Learning Dynamic Textures and   Rendering-to-Video Translation",
        "authors": [
            "Lingjie Liu",
            "Weipeng Xu",
            "Marc Habermann",
            "Michael Zollhoefer",
            "Florian Bernard",
            "Hyeongwoo Kim",
            "Wenping Wang",
            "Christian Theobalt"
        ],
        "summary": "Synthesizing realistic videos of humans using neural networks has been a popular alternative to the conventional graphics-based rendering pipeline due to its high efficiency. Existing works typically formulate this as an image-to-image translation problem in 2D screen space, which leads to artifacts such as over-smoothing, missing body parts, and temporal instability of fine-scale detail, such as pose-dependent wrinkles in the clothing. In this paper, we propose a novel human video synthesis method that approaches these limiting factors by explicitly disentangling the learning of time-coherent fine-scale details from the embedding of the human in 2D screen space. More specifically, our method relies on the combination of two convolutional neural networks (CNNs). Given the pose information, the first CNN predicts a dynamic texture map that contains time-coherent high-frequency details, and the second CNN conditions the generation of the final video on the temporally coherent output of the first CNN. We demonstrate several applications of our approach, such as human reenactment and novel view synthesis from monocular video, where we show significant improvement over the state of the art both qualitatively and quantitatively.",
        "published": "2020-01-14T18:06:27Z",
        "link": "http://arxiv.org/abs/2001.04947v3",
        "categories": [
            "cs.GR",
            "cs.CV"
        ]
    },
    {
        "title": "Everybody's Talkin': Let Me Talk as You Want",
        "authors": [
            "Linsen Song",
            "Wayne Wu",
            "Chen Qian",
            "Ran He",
            "Chen Change Loy"
        ],
        "summary": "We present a method to edit a target portrait footage by taking a sequence of audio as input to synthesize a photo-realistic video. This method is unique because it is highly dynamic. It does not assume a person-specific rendering network yet capable of translating arbitrary source audio into arbitrary video output. Instead of learning a highly heterogeneous and nonlinear mapping from audio to the video directly, we first factorize each target video frame into orthogonal parameter spaces, i.e., expression, geometry, and pose, via monocular 3D face reconstruction. Next, a recurrent network is introduced to translate source audio into expression parameters that are primarily related to the audio content. The audio-translated expression parameters are then used to synthesize a photo-realistic human subject in each video frame, with the movement of the mouth regions precisely mapped to the source audio. The geometry and pose parameters of the target human portrait are retained, therefore preserving the context of the original video footage. Finally, we introduce a novel video rendering network and a dynamic programming method to construct a temporally coherent and photo-realistic video. Extensive experiments demonstrate the superiority of our method over existing approaches. Our method is end-to-end learnable and robust to voice variations in the source audio.",
        "published": "2020-01-15T09:54:23Z",
        "link": "http://arxiv.org/abs/2001.05201v1",
        "categories": [
            "cs.CV",
            "cs.GR",
            "cs.MM"
        ]
    },
    {
        "title": "Interoperable GPU Kernels as Latency Improver for MEC",
        "authors": [
            "Juuso Haavisto",
            "Jukka Riekki"
        ],
        "summary": "Mixed reality (MR) applications are expected to become common when 5G goes mainstream. However, the latency requirements are challenging to meet due to the resources required by video-based remoting of graphics, that is, decoding video codecs. We propose an approach towards tackling this challenge: a client-server implementation for transacting intermediate representation (IR) between a mobile UE and a MEC server instead of video codecs and this way avoiding video decoding. We demonstrate the ability to address latency bottlenecks on edge computing workloads that transact graphics. We select SPIR-V compatible GPU kernels as the intermediate representation. Our approach requires know-how in GPU architecture and GPU domain-specific languages (DSLs), but compared to video-based edge graphics, it decreases UE device delay by sevenfold. Further, we find that due to low cold-start times on both UEs and MEC servers, application migration can happen in milliseconds. We imply that graphics-based location-aware applications, such as MR, can benefit from this kind of approach.",
        "published": "2020-01-25T19:07:58Z",
        "link": "http://arxiv.org/abs/2001.09352v1",
        "categories": [
            "cs.DC",
            "cs.GR"
        ]
    },
    {
        "title": "An Automated Approach for the Discovery of Interoperability",
        "authors": [
            "Duygu Sap",
            "Daniel P. Szabo"
        ],
        "summary": "In this article, we present an automated approach that would test for and discover the interoperability of CAD systems based on the approximately-invariant shape properties of their models. We further show that exchanging models in standard format does not guarantee the preservation of shape properties. Our analysis is based on utilizing queries in deriving the shape properties and constructing the proxy models of the given CAD models [1]. We generate template files to accommodate the information necessary for the property computations and proxy model constructions, and implement an interoperability discovery program called DTest to execute the interoperability testing. We posit that our method could be extended to interoperability testing on CAD-to-CAE and/or CAD-to-CAM interactions by modifying the set of property checks and providing the additional requirements that may emerge in CAE or CAM applications.",
        "published": "2020-01-26T06:07:43Z",
        "link": "http://arxiv.org/abs/2001.10585v1",
        "categories": [
            "cs.GR",
            "cs.AI"
        ]
    },
    {
        "title": "A Variational Staggered Particle Framework for Incompressible   Free-Surface Flows",
        "authors": [
            "Xiaowei He",
            "Huamin Wang",
            "Guoping Wang",
            "Hongan Wang",
            "Enhua Wu"
        ],
        "summary": "Smoothed particle hydrodynamics (SPH) has been extensively studied in computer graphics to animate fluids with versatile effects. However, SPH still suffers from two numerical difficulties: the particle deficiency problem, which will deteriorate the simulation accuracy, and the particle clumping problem, which usually leads to poor stability of particle simulations. We propose to solve these two problems by developing an approximate projection method for incompressible free-surface flows under a variational staggered particle framework. After particle discretization, we first categorize all fluid particles into four subsets. Then according to the classification, we propose to solve the particle deficiency problem by analytically imposing free surface boundary conditions on both the Laplacian operator and the source term. To address the particle clumping problem, we propose to extend the Taylor-series consistent pressure gradient model with kernel function correction and semi-analytical boundary conditions. Compared to previous approximate projection method [1], our incompressibility solver is stable under both compressive and tensile stress states, no pressure clumping or iterative density correction (e.g., a density constrained pressure approach) is necessary to stabilize the solver anymore. Motivated by the Helmholtz free energy functional, we additionally introduce an iterative particle shifting algorithm to improve the accuracy. It significantly reduces particle splashes near the free surface. Therefore, high-fidelity simulations of the formation and fragmentation of liquid jets and sheets are obtained for both the two-jets and milk-crown examples.",
        "published": "2020-01-26T08:37:11Z",
        "link": "http://arxiv.org/abs/2001.09421v1",
        "categories": [
            "cs.GR",
            "physics.flu-dyn"
        ]
    },
    {
        "title": "Running on Raygun",
        "authors": [
            "Alexander Hirsch",
            "Peter Thoman"
        ],
        "summary": "With the introduction of Nvidia RTX hardware, ray tracing is now viable as a general real time rendering technique for complex 3D scenes. Leveraging this new technology, we present Raygun, an open source rendering, simulation, and game engine focusing on simplicity, expandability, and the topic of ray tracing realized through Nvidia's Vulkan ray tracing extension.",
        "published": "2020-01-27T13:58:19Z",
        "link": "http://arxiv.org/abs/2001.09792v1",
        "categories": [
            "cs.GR"
        ]
    },
    {
        "title": "MGCN: Descriptor Learning using Multiscale GCNs",
        "authors": [
            "Yiqun Wang",
            "Jing Ren",
            "Dong-Ming Yan",
            "Jianwei Guo",
            "Xiaopeng Zhang",
            "Peter Wonka"
        ],
        "summary": "We propose a novel framework for computing descriptors for characterizing points on three-dimensional surfaces. First, we present a new non-learned feature that uses graph wavelets to decompose the Dirichlet energy on a surface. We call this new feature wavelet energy decomposition signature (WEDS). Second, we propose a new multiscale graph convolutional network (MGCN) to transform a non-learned feature to a more discriminative descriptor. Our results show that the new descriptor WEDS is more discriminative than the current state-of-the-art non-learned descriptors and that the combination of WEDS and MGCN is better than the state-of-the-art learned descriptors. An important design criterion for our descriptor is the robustness to different surface discretizations including triangulations with varying numbers of vertices. Our results demonstrate that previous graph convolutional networks significantly overfit to a particular resolution or even a particular triangulation, but MGCN generalizes well to different surface discretizations. In addition, MGCN is compatible with previous descriptors and it can also be used to improve the performance of other descriptors, such as the heat kernel signature, the wave kernel signature, or the local point signature.",
        "published": "2020-01-28T17:25:14Z",
        "link": "http://arxiv.org/abs/2001.10472v3",
        "categories": [
            "cs.GR",
            "cs.CV"
        ]
    },
    {
        "title": "Developing an Augmented Reality Tourism App through User-Centred Design   (Extended Version)",
        "authors": [
            "Meredydd Williams",
            "Kelvin K. K. Yao",
            "Jason R. C. Nurse"
        ],
        "summary": "Augmented Reality (AR) bridges the gap between the physical and virtual world. Through overlaying graphics on natural environments, users can immerse themselves in a tailored environment. This offers great benefits to mobile tourism, where points of interest (POIs) can be annotated on a smartphone screen. While a variety of apps currently exist, usability issues can discourage users from embracing AR. Interfaces can become cluttered with icons, with POI occlusion posing further challenges. In this paper, we use user-centred design (UCD) to develop an AR tourism app. We solicit requirements through a synthesis of domain analysis, tourist observation and semi-structured interviews. Whereas previous user-centred work has designed mock-ups, we iteratively develop a full Android app. This includes overhead maps and route navigation, in addition to a detailed AR browser. The final product is evaluated by 20 users, who participate in a tourism task in a UK city. Users regard the system as usable and intuitive, and suggest the addition of further customisation. We finish by critically analysing the challenges of a user-centred methodology.",
        "published": "2020-01-29T23:35:32Z",
        "link": "http://arxiv.org/abs/2001.11131v1",
        "categories": [
            "cs.HC",
            "cs.CY",
            "cs.GR",
            "cs.SE"
        ]
    },
    {
        "title": "Rigidity Properties of the Blum Medial Axis",
        "authors": [
            "James Damon"
        ],
        "summary": "We consider the Blum medial axis of a region in $\\mathbb R^n$ with piecewise smooth boundary and examine its \"rigidity properties\", by which we mean properties preserved under diffeomorphisms of the regions preserving the medial axis. There are several possible versions of rigidity depending on what features of the Blum medial axis we wish to retain. We use a form of the cross ratio from projective geometry to show that in the case of four smooth sheets of the medial axis meeting along a branching submanifold, the cross ratio defines a function on the branching sheet which must be preserved under any diffeomorphism of the medial axis with another. Second, we show in the generic case, along a Y-branching submanifold that there are three cross ratios involving the three limiting tangent planes of the three smooth sheets and each of the hyperplanes defined by one of the radial lines and the tangent space to the Y-branching submanifold at the point, which again must be preserved. Moreover, the triple of cross ratios then locally uniquely determines the angles between the smooth sheets. Third, we observe that for a diffeomorphism of the region preserving the Blum medial axis and the infinitesimal directions of the radial lines, the second derivative of the diffeomorphism at points of the medial axis must satisfy a condition relating the radial shape operators and hence the differential geometry of the boundaries at corresponding boundary points.",
        "published": "2020-02-01T17:11:00Z",
        "link": "http://arxiv.org/abs/2002.00241v1",
        "categories": [
            "math.DG",
            "cs.GR",
            "Primary: 11S90, 32S25, 55R80, Secondary: 57T15, 14M12, 20G05"
        ]
    },
    {
        "title": "Fast 3D Indoor Scene Synthesis with Discrete and Exact Layout Pattern   Extraction",
        "authors": [
            "Song-Hai Zhang",
            "Shao-Kui Zhang",
            "Wei-Yu Xie",
            "Cheng-Yang Luo",
            "Hong-Bo Fu"
        ],
        "summary": "We present a fast framework for indoor scene synthesis, given a room geometry and a list of objects with learnt priors. Unlike existing data-driven solutions, which often extract priors by co-occurrence analysis and statistical model fitting, our method measures the strengths of spatial relations by tests for complete spatial randomness (CSR), and extracts complex priors based on samples with the ability to accurately represent discrete layout patterns. With the extracted priors, our method achieves both acceleration and plausibility by partitioning input objects into disjoint groups, followed by layout optimization based on the Hausdorff metric. Extensive experiments show that our framework is capable of measuring more reasonable relations among objects and simultaneously generating varied arrangements in seconds.",
        "published": "2020-02-02T05:09:09Z",
        "link": "http://arxiv.org/abs/2002.00328v2",
        "categories": [
            "cs.GR"
        ]
    },
    {
        "title": "Non-Euclidean Virtual Reality IV: Sol",
        "authors": [
            "Rémi Coulon",
            "Elisabetta A. Matsumoto",
            "Henry Segerman",
            "Steve Trettel"
        ],
        "summary": "This article presents virtual reality software designed to explore the Sol geometry. The simulation is available on 3-dimensional.space/sol.html",
        "published": "2020-02-02T11:32:30Z",
        "link": "http://arxiv.org/abs/2002.00369v1",
        "categories": [
            "math.HO",
            "cs.GR",
            "math.GT",
            "math.MG",
            "00A09, 00A66, 53A35, 57K35, 51-04, 68U05, 37D40"
        ]
    },
    {
        "title": "FibAR: Embedding Optical Fibers in 3D Printed Objects for Active Markers   in Dynamic Projection Mapping",
        "authors": [
            "Daiki Tone",
            "Daisuke Iwai",
            "Shinsaku Hiura",
            "Kosuke Sato"
        ],
        "summary": "This paper presents a novel active marker for dynamic projection mapping (PM) that emits a temporal blinking pattern of infrared (IR) light representing its ID. We used a multi-material three dimensional (3D) printer to fabricate a projection object with optical fibers that can guide IR light from LEDs attached on the bottom of the object. The aperture of an optical fiber is typically very small; thus, it is unnoticeable to human observers under projection and can be placed on a strongly curved part of a projection surface. In addition, the working range of our system can be larger than previous marker-based methods as the blinking patterns can theoretically be recognized by a camera placed at a wide range of distances from markers. We propose an automatic marker placement algorithm to spread multiple active markers over the surface of a projection object such that its pose can be robustly estimated using captured images from arbitrary directions. We also propose an optimization framework for determining the routes of the optical fibers in such a way that collisions of the fibers can be avoided while minimizing the loss of light intensity in the fibers. Through experiments conducted using three fabricated objects containing strongly curved surfaces, we confirmed that the proposed method can achieve accurate dynamic PMs in a significantly wide working range.",
        "published": "2020-02-06T08:56:46Z",
        "link": "http://arxiv.org/abs/2002.02159v1",
        "categories": [
            "cs.GR",
            "cs.CV",
            "cs.HC",
            "H.5.1"
        ]
    },
    {
        "title": "IlluminatedFocus: Vision Augmentation using Spatial Defocusing via Focal   Sweep Eyeglasses and High-Speed Projector",
        "authors": [
            "Tatsuyuki Ueda",
            "Daisuke Iwai",
            "Takefumi Hiraki",
            "Kosuke Sato"
        ],
        "summary": "Aiming at realizing novel vision augmentation experiences, this paper proposes the IlluminatedFocus technique, which spatially defocuses real-world appearances regardless of the distance from the user's eyes to observed real objects. With the proposed technique, a part of a real object in an image appears blurred, while the fine details of the other part at the same distance remain visible. We apply Electrically Focus-Tunable Lenses (ETL) as eyeglasses and a synchronized high-speed projector as illumination for a real scene. We periodically modulate the focal lengths of the glasses (focal sweep) at more than 60 Hz so that a wearer cannot perceive the modulation. A part of the scene to appear focused is illuminated by the projector when it is in focus of the user's eyes, while another part to appear blurred is illuminated when it is out of the focus. As the basis of our spatial focus control, we build mathematical models to predict the range of distance from the ETL within which real objects become blurred on the retina of a user. Based on the blur range, we discuss a design guideline for effective illumination timing and focal sweep range. We also model the apparent size of a real scene altered by the focal length modulation. This leads to an undesirable visible seam between focused and blurred areas. We solve this unique problem by gradually blending the two areas. Finally, we demonstrate the feasibility of our proposal by implementing various vision augmentation applications.",
        "published": "2020-02-06T09:16:11Z",
        "link": "http://arxiv.org/abs/2002.02167v1",
        "categories": [
            "cs.HC",
            "cs.GR",
            "H.5.1"
        ]
    },
    {
        "title": "AnimePose: Multi-person 3D pose estimation and animation",
        "authors": [
            "Laxman Kumarapu",
            "Prerana Mukherjee"
        ],
        "summary": "3D animation of humans in action is quite challenging as it involves using a huge setup with several motion trackers all over the person's body to track the movements of every limb. This is time-consuming and may cause the person discomfort in wearing exoskeleton body suits with motion sensors. In this work, we present a trivial yet effective solution to generate 3D animation of multiple persons from a 2D video using deep learning. Although significant improvement has been achieved recently in 3D human pose estimation, most of the prior works work well in case of single person pose estimation and multi-person pose estimation is still a challenging problem. In this work, we firstly propose a supervised multi-person 3D pose estimation and animation framework namely AnimePose for a given input RGB video sequence. The pipeline of the proposed system consists of various modules: i) Person detection and segmentation, ii) Depth Map estimation, iii) Lifting 2D to 3D information for person localization iv) Person trajectory prediction and human pose tracking. Our proposed system produces comparable results on previous state-of-the-art 3D multi-person pose estimation methods on publicly available datasets MuCo-3DHP and MuPoTS-3D datasets and it also outperforms previous state-of-the-art human pose tracking methods by a significant margin of 11.7% performance gain on MOTA score on Posetrack 2018 dataset.",
        "published": "2020-02-06T11:11:56Z",
        "link": "http://arxiv.org/abs/2002.02792v1",
        "categories": [
            "cs.GR",
            "cs.CV"
        ]
    },
    {
        "title": "A comparison of mobile VR display running on an ordinary smartphone with   standard PC display for P300-BCI stimulus presentation",
        "authors": [
            "Grégoire Cattan",
            "Anton Andreev",
            "Cesar Mendoza",
            "Marco Congedo"
        ],
        "summary": "A brain-computer interface (BCI) based on electroencephalography (EEG) is a promising technology for enhancing virtual reality (VR) applications-in particular, for gaming. We focus on the so-called P300-BCI, a stable and accurate BCI paradigm relying on the recognition of a positive event-related potential (ERP) occurring in the EEG about 300 ms post-stimulation. We implemented a basic version of such a BCI displayed on an ordinary and affordable smartphone-based head-mounted VR device: that is, a mobile and passive VR system (with no electronic components beyond the smartphone). The mobile phone performed the stimuli presentation, EEG synchronization (tagging) and feedback display. We compared the ERPs and the accuracy of the BCI on the VR device with a traditional BCI running on a personal computer (PC). We also evaluated the impact of subjective factors on the accuracy. The study was within-subjects, with 21 participants and one session in each modality. No significant difference in BCI accuracy was found between the PC and VR systems, although the P200 ERP was significantly wider and larger in the VR system as compared to the PC system.",
        "published": "2020-02-06T17:04:17Z",
        "link": "http://arxiv.org/abs/2002.02358v1",
        "categories": [
            "cs.HC",
            "cs.GR"
        ]
    },
    {
        "title": "Audio-Visual-Olfactory Resource Allocation for Tri-modal Virtual   Environments",
        "authors": [
            "Efstratios Doukakis",
            "Kurt Debattista",
            "Thomas Bashford-Rogers",
            "Amar Dhokia",
            "Ali Asadipour",
            "Alan Chalmers",
            "Carlo Harvey"
        ],
        "summary": "Virtual Environments (VEs) provide the opportunity to simulate a wide range of applications, from training to entertainment, in a safe and controlled manner. For applications which require realistic representations of real world environments, the VEs need to provide multiple, physically accurate sensory stimuli. However, simulating all the senses that comprise the human sensory system (HSS) is a task that requires significant computational resources. Since it is intractable to deliver all senses at the highest quality, we propose a resource distribution scheme in order to achieve an optimal perceptual experience within the given computational budgets. This paper investigates resource balancing for multi-modal scenarios composed of aural, visual and olfactory stimuli. Three experimental studies were conducted. The first experiment identified perceptual boundaries for olfactory computation. In the second experiment, participants (N=25) were asked, across a fixed number of budgets (M=5), to identify what they perceived to be the best visual, acoustic and olfactory stimulus quality for a given computational budget. Results demonstrate that participants tend to prioritise visual quality compared to other sensory stimuli. However, as the budget size is increased, users prefer a balanced distribution of resources with an increased preference for having smell impulses in the VE. Based on the collected data, a quality prediction model is proposed and its accuracy is validated against previously unused budgets and an untested scenario in a third and final experiment.",
        "published": "2020-02-07T08:59:41Z",
        "link": "http://arxiv.org/abs/2002.02671v1",
        "categories": [
            "cs.GR",
            "cs.HC",
            "cs.NE",
            "I.3; I.4"
        ]
    },
    {
        "title": "Deep No-reference Tone Mapped Image Quality Assessment",
        "authors": [
            "Chandra Sekhar Ravuri",
            "Rajesh Sureddi",
            "Sathya Veera Reddy Dendi",
            "Shanmuganathan Raman",
            "Sumohana S. Channappayya"
        ],
        "summary": "The process of rendering high dynamic range (HDR) images to be viewed on conventional displays is called tone mapping. However, tone mapping introduces distortions in the final image which may lead to visual displeasure. To quantify these distortions, we introduce a novel no-reference quality assessment technique for these tone mapped images. This technique is composed of two stages. In the first stage, we employ a convolutional neural network (CNN) to generate quality aware maps (also known as distortion maps) from tone mapped images by training it with the ground truth distortion maps. In the second stage, we model the normalized image and distortion maps using an Asymmetric Generalized Gaussian Distribution (AGGD). The parameters of the AGGD model are then used to estimate the quality score using support vector regression (SVR). We show that the proposed technique delivers competitive performance relative to the state-of-the-art techniques. The novelty of this work is its ability to visualize various distortions as quality maps (distortion maps), especially in the no-reference setting, and to use these maps as features to estimate the quality score of tone mapped images.",
        "published": "2020-02-08T13:41:18Z",
        "link": "http://arxiv.org/abs/2002.03165v1",
        "categories": [
            "cs.GR",
            "cs.CV",
            "cs.LG",
            "eess.IV"
        ]
    },
    {
        "title": "Correction of Chromatic Aberration from a Single Image Using Keypoints",
        "authors": [
            "Benjamin T. Cecchetto"
        ],
        "summary": "In this paper, we propose a method to correct for chromatic aberration in a single photograph. Our method replicates what a user would do in a photo editing program to account for this defect. We find matching keypoints in each colour channel then align them as a user would.",
        "published": "2020-02-08T16:36:30Z",
        "link": "http://arxiv.org/abs/2002.03196v1",
        "categories": [
            "cs.GR",
            "cs.CV",
            "eess.IV"
        ]
    },
    {
        "title": "Bilinear Graph Neural Network with Neighbor Interactions",
        "authors": [
            "Hongmin Zhu",
            "Fuli Feng",
            "Xiangnan He",
            "Xiang Wang",
            "Yan Li",
            "Kai Zheng",
            "Yongdong Zhang"
        ],
        "summary": "Graph Neural Network (GNN) is a powerful model to learn representations and make predictions on graph data. Existing efforts on GNN have largely defined the graph convolution as a weighted sum of the features of the connected nodes to form the representation of the target node. Nevertheless, the operation of weighted sum assumes the neighbor nodes are independent of each other, and ignores the possible interactions between them. When such interactions exist, such as the co-occurrence of two neighbor nodes is a strong signal of the target node's characteristics, existing GNN models may fail to capture the signal. In this work, we argue the importance of modeling the interactions between neighbor nodes in GNN. We propose a new graph convolution operator, which augments the weighted sum with pairwise interactions of the representations of neighbor nodes. We term this framework as Bilinear Graph Neural Network (BGNN), which improves GNN representation ability with bilinear interactions between neighbor nodes. In particular, we specify two BGNN models named BGCN and BGAT, based on the well-known GCN and GAT, respectively. Empirical results on three public benchmarks of semi-supervised node classification verify the effectiveness of BGNN -- BGCN (BGAT) outperforms GCN (GAT) by 1.6% (1.5%) in classification accuracy.Codes are available at: https://github.com/zhuhm1996/bgnn.",
        "published": "2020-02-10T06:43:38Z",
        "link": "http://arxiv.org/abs/2002.03575v5",
        "categories": [
            "cs.LG",
            "cs.GR",
            "stat.ML",
            "ams.org"
        ]
    },
    {
        "title": "SplitStreams: A Visual Metaphor for Evolving Hierarchies",
        "authors": [
            "Fabian Bolte",
            "Mahsan Nourani",
            "Eric D. Ragan",
            "Stefan Bruckner"
        ],
        "summary": "The visualization of hierarchically structured data over time is an ongoing challenge and several approaches exist trying to solve it. Techniques such as animated or juxtaposed tree visualizations are not capable of providing a good overview of the time series and lack expressiveness in conveying changes over time. Nested streamgraphs provide a better understanding of the data evolution, but lack the clear outline of hierarchical structures at a given timestep. Furthermore, these approaches are often limited to static hierarchies or exclude complex hierarchical changes in the data, limiting their use cases. We propose a novel visual metaphor capable of providing a static overview of all hierarchical changes over time, as well as clearly outlining the hierarchical structure at each individual time step. Our method allows for smooth transitions between tree maps and nested streamgraphs, enabling the exploration of the trade-off between dynamic behavior and hierarchical structure. As our technique handles topological changes of all types, it is suitable for a wide range of applications. We demonstrate the utility of our method on several use cases, evaluate it with a user study, and provide its full source code.",
        "published": "2020-02-10T16:00:01Z",
        "link": "http://arxiv.org/abs/2002.03891v1",
        "categories": [
            "cs.GR"
        ]
    },
    {
        "title": "Folding-based compression of point cloud attributes",
        "authors": [
            "Maurice Quach",
            "Giuseppe Valenzise",
            "Frederic Dufaux"
        ],
        "summary": "Existing techniques to compress point cloud attributes leverage either geometric or video-based compression tools. We explore a radically different approach inspired by recent advances in point cloud representation learning. Point clouds can be interpreted as 2D manifolds in 3D space. Specifically, we fold a 2D grid onto a point cloud and we map attributes from the point cloud onto the folded 2D grid using a novel optimized mapping method. This mapping results in an image, which opens a way to apply existing image processing techniques on point cloud attributes. However, as this mapping process is lossy in nature, we propose several strategies to refine it so that attributes can be mapped to the 2D grid with minimal distortion. Moreover, this approach can be flexibly applied to point cloud patches in order to better adapt to local geometric complexity. In this work, we consider point cloud attribute compression; thus, we compress this image with a conventional 2D image codec. Our preliminary results show that the proposed folding-based coding scheme can already reach performance similar to the latest MPEG Geometry-based PCC (G-PCC) codec.",
        "published": "2020-02-11T14:55:58Z",
        "link": "http://arxiv.org/abs/2002.04439v3",
        "categories": [
            "eess.IV",
            "cs.CV",
            "cs.GR",
            "cs.LG",
            "eess.SP",
            "stat.ML"
        ]
    },
    {
        "title": "Course notes Geometric Algebra for Computer Graphics, SIGGRAPH 2019",
        "authors": [
            "Charles G. Gunn"
        ],
        "summary": "What is the best representation for doing euclidean geometry on computers? These notes from a SIGGRAPH 2019 short course entitled \"Geometric algebra for computer graphics\" introduce projective geometric algebra (PGA) as a modern framework for this task. PGA features: uniform representation of points, lines, and planes; robust, parallel-safe join and meet operations; compact, polymorphic syntax for euclidean formulas and constructions; a single intuitive sandwich form for isometries; native support for automatic differentiation; and tight integration of kinematics and rigid body mechanics. PGA includes vector, quaternion, dual quaternion, and exterior algebras as sub-algebras, simplifying the learning curve and transition path for experienced practitioners. On the practical side, it can be efficiently implemented, while its rich syntax enhances programming productivity. The basic ideas are introduced in the 2D context and developed selectively for 3D. Advantages to traditional approaches are collected in a table at the end. The article aims to be a self-contained introduction for practitioners of euclidean geometry and includes numerous examples, formulas, figures, and tables.",
        "published": "2020-02-11T16:11:16Z",
        "link": "http://arxiv.org/abs/2002.04509v2",
        "categories": [
            "cs.GR"
        ]
    },
    {
        "title": "Visualizing modular forms",
        "authors": [
            "David Lowry-Duda"
        ],
        "summary": "We examine several currently used techniques for visualizing complex-valued functions applied to modular forms. We plot several examples and study the benefits and limitations of each technique. We then introduce a method of visualization that can take advantage of colormaps in Python's matplotlib library, describe an implementation, and give more examples. Much of this discussion applies to general visualizations of complex-valued functions in the plane.",
        "published": "2020-02-12T21:01:00Z",
        "link": "http://arxiv.org/abs/2002.05234v2",
        "categories": [
            "cs.GR",
            "math.NT"
        ]
    },
    {
        "title": "A Bounded Measure for Estimating the Benefit of Visualization",
        "authors": [
            "Min Chen",
            "Mateu Sbert",
            "Alfie Abdul-Rahman",
            "Deborah Silver"
        ],
        "summary": "Information theory can be used to analyze the cost-benefit of visualization processes. However, the current measure of benefit contains an unbounded term that is neither easy to estimate nor intuitive to interpret. In this work, we propose to revise the existing cost-benefit measure by replacing the unbounded term with a bounded one. We examine a number of bounded measures that include the Jenson-Shannon divergence and a new divergence measure formulated as part of this work. We use visual analysis to support the multi-criteria comparison, narrowing the search down to those options with better mathematical properties. We apply those remaining options to two visualization case studies to instantiate their uses in practical scenarios, while the collected real world data further informs the selection of a bounded measure, which can be used to estimate the benefit of visualization.",
        "published": "2020-02-12T23:39:07Z",
        "link": "http://arxiv.org/abs/2002.05282v2",
        "categories": [
            "cs.AI",
            "cs.GR",
            "cs.HC",
            "cs.IT",
            "math.IT"
        ]
    },
    {
        "title": "A User-centered Approach for Optimizing Information Visualizations",
        "authors": [
            "David Baum",
            "Pascal Kovacs",
            "Ulrich Eisenecker",
            "Richard Müller"
        ],
        "summary": "The optimization of information visualizations is time consuming and expensive. To reduce this we propose an improvement of existing optimization approaches based on user-centered design, focusing on readability, comprehensibility, and user satisfaction as optimization goals. The changes comprise (1) a separate optimization of user interface and representation, (2) a fully automated evaluation of the representation, and (3) qualitative user studies for simultaneously creating and evaluating interface variants. On the basis of these results we are able to find a local optimum of an information visualization in an efficient way.",
        "published": "2020-02-13T09:50:34Z",
        "link": "http://arxiv.org/abs/2002.05409v1",
        "categories": [
            "cs.HC",
            "cs.GR"
        ]
    },
    {
        "title": "A New Exocentric Metaphor for Complex Path Following to Control a UAV   Using Mixed Reality",
        "authors": [
            "Baptiste Wojtkowski",
            "Pedro Castillo",
            "Indira Thouvenin"
        ],
        "summary": "Teleoperation of Unmanned Aerial Vehicles (UAVs) has recently become an noteworthly research topic in the field of human robot interaction. Each year, a variety of devices is being studied to design adapted interface for diverse purpose such as view taking, search and rescue operation or suveillance. New interfaces have to be precise, simple and intuitive even for complex path planning. Moreover, when teleoperation involves long distance control, user needs to get proper feedbacks and avoid motion sickness. In order to overcome all these challenges, a new interaction metaphor named DrEAM (Drone Exocentric Advanced Metaphor) was designed. User can see the UAV he is controlling in a virtual environment mapped to the real world. He can interact with it as a simple object in a classical virtual world. An experiment was lead in order to evaluate the perfomances of this metaphor, comparing performance of novice user using either a direct-view joystick control or using DrEAM.",
        "published": "2020-02-13T11:02:33Z",
        "link": "http://arxiv.org/abs/2002.05721v1",
        "categories": [
            "cs.HC",
            "cs.GR",
            "cs.RO"
        ]
    },
    {
        "title": "Replacing Mobile Camera ISP with a Single Deep Learning Model",
        "authors": [
            "Andrey Ignatov",
            "Luc Van Gool",
            "Radu Timofte"
        ],
        "summary": "As the popularity of mobile photography is growing constantly, lots of efforts are being invested now into building complex hand-crafted camera ISP solutions. In this work, we demonstrate that even the most sophisticated ISP pipelines can be replaced with a single end-to-end deep learning model trained without any prior knowledge about the sensor and optics used in a particular device. For this, we present PyNET, a novel pyramidal CNN architecture designed for fine-grained image restoration that implicitly learns to perform all ISP steps such as image demosaicing, denoising, white balancing, color and contrast correction, demoireing, etc. The model is trained to convert RAW Bayer data obtained directly from mobile camera sensor into photos captured with a professional high-end DSLR camera, making the solution independent of any particular mobile ISP implementation. To validate the proposed approach on the real data, we collected a large-scale dataset consisting of 10 thousand full-resolution RAW-RGB image pairs captured in the wild with the Huawei P20 cameraphone (12.3 MP Sony Exmor IMX380 sensor) and Canon 5D Mark IV DSLR. The experiments demonstrate that the proposed solution can easily get to the level of the embedded P20's ISP pipeline that, unlike our approach, is combining the data from two (RGB + B/W) camera sensors. The dataset, pre-trained models and codes used in this paper are available on the project website.",
        "published": "2020-02-13T14:22:39Z",
        "link": "http://arxiv.org/abs/2002.05509v1",
        "categories": [
            "cs.CV",
            "cs.GR",
            "eess.IV"
        ]
    },
    {
        "title": "Pointfilter: Point Cloud Filtering via Encoder-Decoder Modeling",
        "authors": [
            "Dongbo Zhang",
            "Xuequan Lu",
            "Hong Qin",
            "Ying He"
        ],
        "summary": "Point cloud filtering is a fundamental problem in geometry modeling and processing. Despite of significant advancement in recent years, the existing methods still suffer from two issues: 1) they are either designed without preserving sharp features or less robust in feature preservation; and 2) they usually have many parameters and require tedious parameter tuning. In this paper, we propose a novel deep learning approach that automatically and robustly filters point clouds by removing noise and preserving their sharp features. Our point-wise learning architecture consists of an encoder and a decoder. The encoder directly takes points (a point and its neighbors) as input, and learns a latent representation vector which goes through the decoder to relate the ground-truth position with a displacement vector. The trained neural network can automatically generate a set of clean points from a noisy input. Extensive experiments show that our approach outperforms the state-of-the-art deep learning techniques in terms of both visual quality and quantitative error metrics. The source code and dataset can be found at https://github.com/dongbo-BUAA-VR/Pointfilter.",
        "published": "2020-02-14T11:06:44Z",
        "link": "http://arxiv.org/abs/2002.05968v2",
        "categories": [
            "cs.GR"
        ]
    },
    {
        "title": "Why Do Line Drawings Work? A Realism Hypothesis",
        "authors": [
            "Aaron Hertzmann"
        ],
        "summary": "Why is it that we can recognize object identity and 3D shape from line drawings, even though they do not exist in the natural world? This paper hypothesizes that the human visual system perceives line drawings as if they were approximately realistic images. Moreover, the techniques of line drawing are chosen to accurately convey shape to a human observer. Several implications and variants of this hypothesis are explored.",
        "published": "2020-02-14T21:41:00Z",
        "link": "http://arxiv.org/abs/2002.06260v1",
        "categories": [
            "cs.CV",
            "cs.GR"
        ]
    },
    {
        "title": "Analytic Marching: An Analytic Meshing Solution from Deep Implicit   Surface Networks",
        "authors": [
            "Jiabao Lei",
            "Kui Jia"
        ],
        "summary": "This paper studies a problem of learning surface mesh via implicit functions in an emerging field of deep learning surface reconstruction, where implicit functions are popularly implemented as multi-layer perceptrons (MLPs) with rectified linear units (ReLU). To achieve meshing from learned implicit functions, existing methods adopt the de-facto standard algorithm of marching cubes; while promising, they suffer from loss of precision learned in the MLPs, due to the discretization nature of marching cubes. Motivated by the knowledge that a ReLU based MLP partitions its input space into a number of linear regions, we identify from these regions analytic cells and analytic faces that are associated with zero-level isosurface of the implicit function, and characterize the theoretical conditions under which the identified analytic faces are guaranteed to connect and form a closed, piecewise planar surface. Based on our theorem, we propose a naturally parallelizable algorithm of analytic marching, which marches among analytic cells to exactly recover the mesh captured by a learned MLP. Experiments on deep learning mesh reconstruction verify the advantages of our algorithm over existing ones.",
        "published": "2020-02-16T15:36:19Z",
        "link": "http://arxiv.org/abs/2002.06597v1",
        "categories": [
            "cs.CV",
            "cs.GR"
        ]
    },
    {
        "title": "A Large-Scale Evaluation of Shape-Aware Neighborhood Weights and   Neighborhood Sizes",
        "authors": [
            "Martin Skrodzki",
            "Eric Zimmermann"
        ],
        "summary": "In this paper, we define and evaluate a weighting scheme for neighborhoods in point sets. Our weighting takes the shape of the geometry, i.e., the normal information, into account. This causes the obtained neighborhoods to be more reliable in the sense that connectivity also depends on the orientation of the point set. We utilize a sigmoid to define the weights based on the normal variation. For an evaluation of the weighting scheme, we turn to a Shannon entropy model for feature classification that can be proven to be non-degenerate for our family of weights. Based on this model, we evaluate our weighting terms on a large scale of both clean and real-world models. This evaluation provides results regarding the choice of optimal parameters within our weighting scheme. Furthermore, the large-scale evaluation also reveals that neighborhood sizes should not be fixed globally when processing models. Finally, we highlight the applicability of our weighting scheme withing the application context of denoising.",
        "published": "2020-02-17T08:25:26Z",
        "link": "http://arxiv.org/abs/2002.06827v3",
        "categories": [
            "cs.GR",
            "cs.CG",
            "68U05, 68U07, 65D18, 65D17"
        ]
    },
    {
        "title": "Jittering Samples using a kd-Tree Stratification",
        "authors": [
            "Alexandros D. Keros",
            "Divakaran Divakaran",
            "Kartic Subr"
        ],
        "summary": "Monte Carlo sampling techniques are used to estimate high-dimensional integrals that model the physics of light transport in virtual scenes for computer graphics applications. These methods rely on the law of large numbers to estimate expectations via simulation, typically resulting in slow convergence. Their errors usually manifest as undesirable grain in the pictures generated by image synthesis algorithms. It is well known that these errors diminish when the samples are chosen appropriately. A well known technique for reducing error operates by subdividing the integration domain, estimating integrals in each \\emph{stratum} and aggregating these values into a stratified sampling estimate. Na\\\"{i}ve methods for stratification, based on a lattice (grid) are known to improve the convergence rate of Monte Carlo, but require samples that grow exponentially with the dimensionality of the domain.   We propose a simple stratification scheme for $d$ dimensional hypercubes using the kd-tree data structure. Our scheme enables the generation of an arbitrary number of equal volume partitions of the rectangular domain, and $n$ samples can be generated in $O(n)$ time. Since we do not always need to explicitly build a kd-tree, we provide a simple procedure that allows the sample set to be drawn fully in parallel without any precomputation or storage, speeding up sampling to $O(\\log n)$ time per sample when executed on $n$ cores. If the tree is implicitly precomputed ($O(n)$ storage) the parallelised run time reduces to $O(1)$ on $n$ cores. In addition to these benefits, we provide an upper bound on the worst case star-discrepancy for $n$ samples matching that of lattice-based sampling strategies, which occur as a special case of our proposed method. We use a number of quantitative and qualitative tests to compare our method against state of the art samplers for image synthesis.",
        "published": "2020-02-17T15:27:52Z",
        "link": "http://arxiv.org/abs/2002.07002v1",
        "categories": [
            "cs.GR",
            "stat.CO",
            "11K45, 65C05",
            "I.3.6; G.3"
        ]
    },
    {
        "title": "Quantitative Evaluation of Time-Dependent Multidimensional Projection   Techniques",
        "authors": [
            "E. F. Vernier",
            "R. Garcia",
            "I. P. da Silva",
            "J. L. D. Comba",
            "A. C. Telea"
        ],
        "summary": "Dimensionality reduction methods are an essential tool for multidimensional data analysis, and many interesting processes can be studied as time-dependent multivariate datasets. There are, however, few studies and proposals that leverage on the concise power of expression of projections in the context of dynamic/temporal data. In this paper, we aim at providing an approach to assess projection techniques for dynamic data and understand the relationship between visual quality and stability. Our approach relies on an experimental setup that consists of existing techniques designed for time-dependent data and new variations of static methods. To support the evaluation of these techniques, we provide a collection of datasets that has a wide variety of traits that encode dynamic patterns, as well as a set of spatial and temporal stability metrics that assess the quality of the layouts. We present an evaluation of 11 methods, 10 datasets, and 12 quality metrics, and elect the best-suited methods for projecting time-dependent multivariate data, exploring the design choices and characteristics of each method. All our results are documented and made available in a public repository to allow reproducibility of results.",
        "published": "2020-02-18T10:40:02Z",
        "link": "http://arxiv.org/abs/2002.07481v1",
        "categories": [
            "cs.GR"
        ]
    },
    {
        "title": "A Survey on Deep Geometry Learning: From a Representation Perspective",
        "authors": [
            "Yun-Peng Xiao",
            "Yu-Kun Lai",
            "Fang-Lue Zhang",
            "Chunpeng Li",
            "Lin Gao"
        ],
        "summary": "Researchers have now achieved great success on dealing with 2D images using deep learning. In recent years, 3D computer vision and Geometry Deep Learning gain more and more attention. Many advanced techniques for 3D shapes have been proposed for different applications. Unlike 2D images, which can be uniformly represented by regular grids of pixels, 3D shapes have various representations, such as depth and multi-view images, voxel-based representation, point-based representation, mesh-based representation, implicit surface representation, etc. However, the performance for different applications largely depends on the representation used, and there is no unique representation that works well for all applications. Therefore, in this survey, we review recent development in deep learning for 3D geometry from a representation perspective, summarizing the advantages and disadvantages of different representations in different applications. We also present existing datasets in these representations and further discuss future research directions.",
        "published": "2020-02-19T03:59:56Z",
        "link": "http://arxiv.org/abs/2002.07995v2",
        "categories": [
            "cs.GR"
        ]
    },
    {
        "title": "STW and SPIHT Wavelet compression using MATLAB wavelet Tool for Color   Image",
        "authors": [
            "Manish Tiwari"
        ],
        "summary": "Images can be represented by mathematical function using wavelets. Wavelet can be manipulated (shrink/expand) by applying some values to its function. It helps to localize the signals. Application of wavelet in images processing has larger scope as proved. Image compression is one of the dimension. There are various wavelet image compression techniques. This research paper focused on comparison of only two techniques i.e. STW and SPIHT for color JPEG images.",
        "published": "2020-02-19T05:35:54Z",
        "link": "http://arxiv.org/abs/2002.08897v1",
        "categories": [
            "eess.IV",
            "cs.GR"
        ]
    },
    {
        "title": "Computational Design with Crowds",
        "authors": [
            "Yuki Koyama",
            "Takeo Igarashi"
        ],
        "summary": "Computational design is aimed at supporting or automating design processes using computational techniques. However, some classes of design tasks involve criteria that are difficult to handle only with computers. For example, visual design tasks seeking to fulfill aesthetic goals are difficult to handle purely with computers. One promising approach is to leverage human computation; that is, to incorporate human input into the computation process. Crowdsourcing platforms provide a convenient way to integrate such human computation into a working system.   In this chapter, we discuss such computational design with crowds in the domain of parameter tweaking tasks in visual design. Parameter tweaking is often performed to maximize the aesthetic quality of designed objects. Computational design powered by crowds can solve this maximization problem by leveraging human computation. We discuss the opportunities and challenges of computational design with crowds with two illustrative examples: (1) estimating the objective function (specifically, preference learning from crowds' pairwise comparisons) to facilitate interactive design exploration by a designer and (2) directly searching for the optimal parameter setting that maximizes the objective function (specifically, crowds-in-the-loop Bayesian optimization).",
        "published": "2020-02-20T10:40:13Z",
        "link": "http://arxiv.org/abs/2002.08657v1",
        "categories": [
            "cs.GR",
            "cs.HC",
            "cs.LG"
        ]
    },
    {
        "title": "Real-Time Visualization in Non-Isotropic Geometries",
        "authors": [
            "Eryk Kopczyński",
            "Dorota Celińska-Kopczyńska"
        ],
        "summary": "Non-isotropic geometries are of interest to low-dimensional topologists, physicists and cosmologists. However, they are challenging to comprehend and visualize. We present novel methods of computing real-time native geodesic rendering of non-isotropic geometries. Our methods can be applied not only to visualization, but also are essential for potential applications in machine learning and video games.",
        "published": "2020-02-21T19:51:54Z",
        "link": "http://arxiv.org/abs/2002.09533v2",
        "categories": [
            "cs.GR",
            "math.DG",
            "53A35 Non-Euclidean differential geometry",
            "I.3.7"
        ]
    },
    {
        "title": "Image Stylization: From Predefined to Personalized",
        "authors": [
            "Ignacio Garcia-Dorado",
            "Pascal Getreuer",
            "Bartlomiej Wronski",
            "Peyman Milanfar"
        ],
        "summary": "We present a framework for interactive design of new image stylizations using a wide range of predefined filter blocks. Both novel and off-the-shelf image filtering and rendering techniques are extended and combined to allow the user to unleash their creativity to intuitively invent, modify, and tune new styles from a given set of filters. In parallel to this manual design, we propose a novel procedural approach that automatically assembles sequences of filters, leading to unique and novel styles. An important aim of our framework is to allow for interactive exploration and design, as well as to enable videos and camera streams to be stylized on the fly. In order to achieve this real-time performance, we use the \\textit{Best Linear Adaptive Enhancement} (BLADE) framework -- an interpretable shallow machine learning method that simulates complex filter blocks in real time. Our representative results include over a dozen styles designed using our interactive tool, a set of styles created procedurally, and new filters trained with our BLADE approach.",
        "published": "2020-02-22T06:48:28Z",
        "link": "http://arxiv.org/abs/2002.10945v1",
        "categories": [
            "cs.GR",
            "cs.CV"
        ]
    },
    {
        "title": "PolyGen: An Autoregressive Generative Model of 3D Meshes",
        "authors": [
            "Charlie Nash",
            "Yaroslav Ganin",
            "S. M. Ali Eslami",
            "Peter W. Battaglia"
        ],
        "summary": "Polygon meshes are an efficient representation of 3D geometry, and are of central importance in computer graphics, robotics and games development. Existing learning-based approaches have avoided the challenges of working with 3D meshes, instead using alternative object representations that are more compatible with neural architectures and training approaches. We present an approach which models the mesh directly, predicting mesh vertices and faces sequentially using a Transformer-based architecture. Our model can condition on a range of inputs, including object classes, voxels, and images, and because the model is probabilistic it can produce samples that capture uncertainty in ambiguous scenarios. We show that the model is capable of producing high-quality, usable meshes, and establish log-likelihood benchmarks for the mesh-modelling task. We also evaluate the conditional models on surface reconstruction metrics against alternative methods, and demonstrate competitive performance despite not training directly on this task.",
        "published": "2020-02-23T17:16:34Z",
        "link": "http://arxiv.org/abs/2002.10880v1",
        "categories": [
            "cs.GR",
            "cs.CV",
            "cs.LG",
            "stat.ML"
        ]
    },
    {
        "title": "Implicit Geometric Regularization for Learning Shapes",
        "authors": [
            "Amos Gropp",
            "Lior Yariv",
            "Niv Haim",
            "Matan Atzmon",
            "Yaron Lipman"
        ],
        "summary": "Representing shapes as level sets of neural networks has been recently proved to be useful for different shape analysis and reconstruction tasks. So far, such representations were computed using either: (i) pre-computed implicit shape representations; or (ii) loss functions explicitly defined over the neural level sets. In this paper we offer a new paradigm for computing high fidelity implicit neural representations directly from raw data (i.e., point clouds, with or without normal information). We observe that a rather simple loss function, encouraging the neural network to vanish on the input point cloud and to have a unit norm gradient, possesses an implicit geometric regularization property that favors smooth and natural zero level set surfaces, avoiding bad zero-loss solutions. We provide a theoretical analysis of this property for the linear case, and show that, in practice, our method leads to state of the art implicit neural representations with higher level-of-details and fidelity compared to previous methods.",
        "published": "2020-02-24T07:36:32Z",
        "link": "http://arxiv.org/abs/2002.10099v2",
        "categories": [
            "cs.LG",
            "cs.CV",
            "cs.GR",
            "stat.ML"
        ]
    },
    {
        "title": "Audio-driven Talking Face Video Generation with Learning-based   Personalized Head Pose",
        "authors": [
            "Ran Yi",
            "Zipeng Ye",
            "Juyong Zhang",
            "Hujun Bao",
            "Yong-Jin Liu"
        ],
        "summary": "Real-world talking faces often accompany with natural head movement. However, most existing talking face video generation methods only consider facial animation with fixed head pose. In this paper, we address this problem by proposing a deep neural network model that takes an audio signal A of a source person and a very short video V of a target person as input, and outputs a synthesized high-quality talking face video with personalized head pose (making use of the visual information in V), expression and lip synchronization (by considering both A and V). The most challenging issue in our work is that natural poses often cause in-plane and out-of-plane head rotations, which makes synthesized talking face video far from realistic. To address this challenge, we reconstruct 3D face animation and re-render it into synthesized frames. To fine tune these frames into realistic ones with smooth background transition, we propose a novel memory-augmented GAN module. By first training a general mapping based on a publicly available dataset and fine-tuning the mapping using the input short video of target person, we develop an effective strategy that only requires a small number of frames (about 300 frames) to learn personalized talking behavior including head pose. Extensive experiments and two user studies show that our method can generate high-quality (i.e., personalized head movements, expressions and good lip synchronization) talking face videos, which are naturally looking with more distinguishing head movement effects than the state-of-the-art methods.",
        "published": "2020-02-24T10:02:10Z",
        "link": "http://arxiv.org/abs/2002.10137v2",
        "categories": [
            "cs.CV",
            "cs.GR"
        ]
    },
    {
        "title": "$G^1$ hole filling with S-patches made easy",
        "authors": [
            "Péter Salvi"
        ],
        "summary": "S-patches have been around for 30 years, but they are seldom used, and are considered more of a mathematical curiosity than a practical surface representation. In this article a method is presented for automatically creating S-patches of any degree or any number of sides, suitable for inclusion in a curve network with tangential continuity to the adjacent surfaces. The presentation aims at making the implementation straightforward; a few examples conclude the paper.",
        "published": "2020-02-25T14:29:25Z",
        "link": "http://arxiv.org/abs/2002.11109v1",
        "categories": [
            "cs.GR",
            "cs.CG"
        ]
    },
    {
        "title": "On the CAD-compatible conversion of S-patches",
        "authors": [
            "Péter Salvi"
        ],
        "summary": "S-patches have many nice mathematical properties. It is known since their first appearance, that any regular S-patch can be exactly converted into a trimmed rational B\\'ezier surface. This is a big advantage compared to other multi-sided surface representations that have to be approximated for exporting them into CAD/CAM systems. The actual conversion process, however, remained at a theoretical level, with bits and pieces scattered in multiple publications. In this paper we review the entirety of the algorithm, and investigate it from a practical aspect.",
        "published": "2020-02-25T15:09:05Z",
        "link": "http://arxiv.org/abs/2002.11111v1",
        "categories": [
            "cs.GR",
            "cs.CG"
        ]
    },
    {
        "title": "Computationally efficient transfinite patches with fullness control",
        "authors": [
            "Péter Salvi",
            "István Kovács",
            "Tamás Várady"
        ],
        "summary": "Transfinite patches provide a simple and elegant solution to the problem of representing non-four-sided continuous surfaces, which are useful in a variety of applications, such as curve network based design. Real-time responsiveness is essential in this context, and thus reducing the computation cost is an important concern. The Midpoint Coons (MC) patch presented in this paper is a fusion of two previous transfinite schemes, combining the speed of one with the superior control mechanism of the other. This is achieved using a new constrained parameterization based on generalized barycentric coordinates and transfinite blending functions.",
        "published": "2020-02-25T22:55:41Z",
        "link": "http://arxiv.org/abs/2002.11212v1",
        "categories": [
            "cs.GR",
            "cs.CG"
        ]
    },
    {
        "title": "A multi-sided generalization of the $C^0$ Coons patch",
        "authors": [
            "Péter Salvi"
        ],
        "summary": "Most multi-sided transfinite surfaces require cross-derivatives at the boundaries. Here we show a general $n$-sided patch that interpolates all boundaries based on only positional information. The surface is a weighted sum of $n$ Coons patches, using a parameterization based on Wachspress coordinates.",
        "published": "2020-02-26T08:14:02Z",
        "link": "http://arxiv.org/abs/2002.11347v1",
        "categories": [
            "cs.GR",
            "cs.CG"
        ]
    },
    {
        "title": "Learning to Shadow Hand-drawn Sketches",
        "authors": [
            "Qingyuan Zheng",
            "Zhuoru Li",
            "Adam Bargteil"
        ],
        "summary": "We present a fully automatic method to generate detailed and accurate artistic shadows from pairs of line drawing sketches and lighting directions. We also contribute a new dataset of one thousand examples of pairs of line drawings and shadows that are tagged with lighting directions. Remarkably, the generated shadows quickly communicate the underlying 3D structure of the sketched scene. Consequently, the shadows generated by our approach can be used directly or as an excellent starting point for artists. We demonstrate that the deep learning network we propose takes a hand-drawn sketch, builds a 3D model in latent space, and renders the resulting shadows. The generated shadows respect the hand-drawn lines and underlying 3D space and contain sophisticated and accurate details, such as self-shadowing effects. Moreover, the generated shadows contain artistic effects, such as rim lighting or halos appearing from back lighting, that would be achievable with traditional 3D rendering methods.",
        "published": "2020-02-26T21:57:17Z",
        "link": "http://arxiv.org/abs/2002.11812v2",
        "categories": [
            "cs.CV",
            "cs.GR",
            "cs.MM"
        ]
    },
    {
        "title": "A Feature-aware SPH for Isotropic Unstructured Mesh Generation",
        "authors": [
            "Zhe Ji",
            "Lin Fu",
            "Xiangyu Hu",
            "Nikolaus Adams"
        ],
        "summary": "In this paper, we present a feature-aware SPH method for the concurrent and automated isotropic unstructured mesh generation. Two additional objectives are achieved with the proposed method compared to the original SPH-based mesh generator (Fu et al., 2019). First, a feature boundary correction term is introduced to address the issue of incomplete kernel support at the boundary vicinity. The mesh generation of feature curves, feature surfaces and volumes can be handled concurrently without explicitly following a dimensional sequence. Second, a two-phase model is proposed to characterize the mesh-generation procedure by a feature-size-adaptation phase and a mesh-quality-optimization phase. By proposing a new error measurement criterion and an adaptive control system with two sets of simulation parameters, the objectives of faster feature-size adaptation and local mesh-quality improvement are merged into a consistent framework. The proposed method is validated with a set of 2D and 3D numerical tests with different complexities and scales. The results demonstrate that high-quality meshes are generated with a significant speedup of convergence.",
        "published": "2020-02-27T13:35:07Z",
        "link": "http://arxiv.org/abs/2003.01061v1",
        "categories": [
            "cs.GR",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Deep Slow Motion Video Reconstruction with Hybrid Imaging System",
        "authors": [
            "Avinash Paliwal",
            "Nima Khademi Kalantari"
        ],
        "summary": "Slow motion videos are becoming increasingly popular, but capturing high-resolution videos at extremely high frame rates requires professional high-speed cameras. To mitigate this problem, current techniques increase the frame rate of standard videos through frame interpolation by assuming linear object motion which is not valid in challenging cases. In this paper, we address this problem using two video streams as input; an auxiliary video with high frame rate and low spatial resolution, providing temporal information, in addition to the standard main video with low frame rate and high spatial resolution. We propose a two-stage deep learning system consisting of alignment and appearance estimation that reconstructs high resolution slow motion video from the hybrid video input. For alignment, we propose to compute flows between the missing frame and two existing frames of the main video by utilizing the content of the auxiliary video frames. For appearance estimation, we propose to combine the warped and auxiliary frames using a context and occlusion aware network. We train our model on synthetically generated hybrid videos and show high-quality results on a variety of test scenes. To demonstrate practicality, we show the performance of our system on two real dual camera setups with small baseline.",
        "published": "2020-02-27T14:18:12Z",
        "link": "http://arxiv.org/abs/2002.12106v2",
        "categories": [
            "cs.CV",
            "cs.GR"
        ]
    },
    {
        "title": "Exploiting Colorimetry for Fidelity in Data Visualization",
        "authors": [
            "M. J. Waters",
            "J. M. Walker",
            "C. T. Nelson",
            "D. Joester",
            "J. M. Rondinelli"
        ],
        "summary": "Advances in multimodal characterization methods fuel a generation of increasing immense hyper-dimensional datasets. Color mapping is employed for conveying higher dimensional data in two-dimensional (2D) representations for human consumption without relying on multiple projections. How one constructs these color maps, however, critically affects how accurately one perceives data. For simple scalar fields, perceptually uniform color maps and color selection have been shown to improve data readability and interpretation across research fields. Here we review core concepts underlying the design of perceptually uniform color map and extend the concepts from scalar fields to two-dimensional vector fields and three-component composition fields frequently found in materials-chemistry research to enable high-fidelity visualization. We develop the software tools PAPUC and CMPUC to enable researchers to utilize these colorimetry principles and employ perceptually uniform color spaces for rigorously meaningful color mapping of higher dimensional data representations. Last, we demonstrate how these approaches deliver immediate improvements in data readability and interpretation in microscopies and spectroscopies routinely used in discerning materials structure, chemistry, and properties.",
        "published": "2020-02-27T16:17:23Z",
        "link": "http://arxiv.org/abs/2002.12228v1",
        "categories": [
            "cs.HC",
            "cond-mat.mtrl-sci",
            "cs.GR"
        ]
    },
    {
        "title": "Learning to See: You Are What You See",
        "authors": [
            "Memo Akten",
            "Rebecca Fiebrink",
            "Mick Grierson"
        ],
        "summary": "The authors present a visual instrument developed as part of the creation of the artwork Learning to See. The artwork explores bias in artificial neural networks and provides mechanisms for the manipulation of specifically trained for real-world representations. The exploration of these representations acts as a metaphor for the process of developing a visual understanding and/or visual vocabulary of the world. These representations can be explored and manipulated in real time, and have been produced in such a way so as to reflect specific creative perspectives that call into question the relationship between how both artificial neural networks and humans may construct meaning.",
        "published": "2020-02-28T07:12:52Z",
        "link": "http://arxiv.org/abs/2003.00902v1",
        "categories": [
            "cs.CV",
            "cs.GR",
            "cs.HC",
            "cs.LG"
        ]
    },
    {
        "title": "MINA: Convex Mixed-Integer Programming for Non-Rigid Shape Alignment",
        "authors": [
            "Florian Bernard",
            "Zeeshan Khan Suri",
            "Christian Theobalt"
        ],
        "summary": "We present a convex mixed-integer programming formulation for non-rigid shape matching. To this end, we propose a novel shape deformation model based on an efficient low-dimensional discrete model, so that finding a globally optimal solution is tractable in (most) practical cases. Our approach combines several favourable properties: it is independent of the initialisation, it is much more efficient to solve to global optimality compared to analogous quadratic assignment problem formulations, and it is highly flexible in terms of the variants of matching problems it can handle. Experimentally we demonstrate that our approach outperforms existing methods for sparse shape matching, that it can be used for initialising dense shape matching methods, and we showcase its flexibility on several examples.",
        "published": "2020-02-28T09:54:06Z",
        "link": "http://arxiv.org/abs/2002.12623v1",
        "categories": [
            "cs.CV",
            "cs.GR",
            "cs.LG",
            "math.OC"
        ]
    },
    {
        "title": "PF-Net: Point Fractal Network for 3D Point Cloud Completion",
        "authors": [
            "Zitian Huang",
            "Yikuan Yu",
            "Jiawen Xu",
            "Feng Ni",
            "Xinyi Le"
        ],
        "summary": "In this paper, we propose a Point Fractal Network (PF-Net), a novel learning-based approach for precise and high-fidelity point cloud completion. Unlike existing point cloud completion networks, which generate the overall shape of the point cloud from the incomplete point cloud and always change existing points and encounter noise and geometrical loss, PF-Net preserves the spatial arrangements of the incomplete point cloud and can figure out the detailed geometrical structure of the missing region(s) in the prediction. To succeed at this task, PF-Net estimates the missing point cloud hierarchically by utilizing a feature-points-based multi-scale generating network. Further, we add up multi-stage completion loss and adversarial loss to generate more realistic missing region(s). The adversarial loss can better tackle multiple modes in the prediction. Our experiments demonstrate the effectiveness of our method for several challenging point cloud completion tasks.",
        "published": "2020-03-01T05:40:21Z",
        "link": "http://arxiv.org/abs/2003.00410v1",
        "categories": [
            "cs.CV",
            "cs.GR"
        ]
    },
    {
        "title": "Characterisation of rational and NURBS developable surfaces in Computer   Aided Design",
        "authors": [
            "Leonardo Fernandez-Jambrina"
        ],
        "summary": "In this paper we provide a characterisation of rational developable surfaces in terms of the blossoms of the bounding curves and three rational functions $\\Lambda$, $M$, $\\nu$. Properties of developable surfaces are revised in this framework. In particular, a closed algebraic formula for the edge of regression of the surface is obtained in terms of the functions $\\Lambda$, $M$, $\\nu$, which are closely related to the ones that appear in the standard decomposition of the derivative of the parametrisation of one of the bounding curves in terms of the director vector of the rulings and its derivative. It is also shown that all rational developable surfaces can be described as the set of developable surfaces which can be constructed with a constant $\\Lambda$, $M$, $\\nu$ . The results are readily extended to rational spline developable surfaces.",
        "published": "2020-03-02T12:09:16Z",
        "link": "http://arxiv.org/abs/2003.00792v1",
        "categories": [
            "cs.GR",
            "cs.NA",
            "math.NA",
            "65D17, 68U07"
        ]
    },
    {
        "title": "Lagrangian-Eulerian Multi-Density Topology Optimization with the   Material Point Method",
        "authors": [
            "Yue Li",
            "Xuan Li",
            "Minchen Li",
            "Yixin Zhu",
            "Bo Zhu",
            "Chenfanfu Jiang"
        ],
        "summary": "In this paper, a hybrid Lagrangian-Eulerian topology optimization (LETO) method is proposed to solve the elastic force equilibrium with the Material Point Method (MPM). LETO transfers density information from freely movable Lagrangian carrier particles to a fixed set of Eulerian quadrature points. This transfer is based on a smooth radial kernel involved in the compliance objective to avoid the artificial checkerboard pattern. The quadrature points act as MPM particles embedded in a lower-resolution grid and enable a sub-cell multi-density resolution of intricate structures with a reduced computational cost. A quadrature-level connectivity graph-based method is adopted to avoid the artificial checkerboard issues commonly existing in multi-resolution topology optimization methods. Numerical experiments are provided to demonstrate the efficacy of the proposed approach.",
        "published": "2020-03-02T22:05:45Z",
        "link": "http://arxiv.org/abs/2003.01215v4",
        "categories": [
            "physics.comp-ph",
            "cs.CE",
            "cs.GR"
        ]
    },
    {
        "title": "Optimizing JPEG Quantization for Classification Networks",
        "authors": [
            "Zhijing Li",
            "Christopher De Sa",
            "Adrian Sampson"
        ],
        "summary": "Deep learning for computer vision depends on lossy image compression: it reduces the storage required for training and test data and lowers transfer costs in deployment. Mainstream datasets and imaging pipelines all rely on standard JPEG compression. In JPEG, the degree of quantization of frequency coefficients controls the lossiness: an 8 by 8 quantization table (Q-table) decides both the quality of the encoded image and the compression ratio. While a long history of work has sought better Q-tables, existing work either seeks to minimize image distortion or to optimize for models of the human visual system. This work asks whether JPEG Q-tables exist that are \"better\" for specific vision networks and can offer better quality--size trade-offs than ones designed for human perception or minimal distortion. We reconstruct an ImageNet test set with higher resolution to explore the effect of JPEG compression under novel Q-tables. We attempt several approaches to tune a Q-table for a vision task. We find that a simple sorted random sampling method can exceed the performance of the standard JPEG Q-table. We also use hyper-parameter tuning techniques including bounded random search, Bayesian optimization, and composite heuristic optimization methods. The new Q-tables we obtained can improve the compression rate by 10% to 200% when the accuracy is fixed, or improve accuracy up to $2\\%$ at the same compression rate.",
        "published": "2020-03-05T19:13:06Z",
        "link": "http://arxiv.org/abs/2003.02874v1",
        "categories": [
            "cs.CV",
            "cs.GR",
            "cs.PF",
            "eess.IV"
        ]
    },
    {
        "title": "DeProCams: Simultaneous Relighting, Compensation and Shape   Reconstruction for Projector-Camera Systems",
        "authors": [
            "Bingyao Huang",
            "Haibin Ling"
        ],
        "summary": "Image-based relighting, projector compensation and depth/normal reconstruction are three important tasks of projector-camera systems (ProCams) and spatial augmented reality (SAR). Although they share a similar pipeline of finding projector-camera image mappings, in tradition, they are addressed independently, sometimes with different prerequisites, devices and sampling images. In practice, this may be cumbersome for SAR applications to address them one-by-one. In this paper, we propose a novel end-to-end trainable model named DeProCams to explicitly learn the photometric and geometric mappings of ProCams, and once trained, DeProCams can be applied simultaneously to the three tasks. DeProCams explicitly decomposes the projector-camera image mappings into three subprocesses: shading attributes estimation, rough direct light estimation and photorealistic neural rendering. A particular challenge addressed by DeProCams is occlusion, for which we exploit epipolar constraint and propose a novel differentiable projector direct light mask. Thus, it can be learned end-to-end along with the other modules. Afterwards, to improve convergence, we apply photometric and geometric constraints such that the intermediate results are plausible. In our experiments, DeProCams shows clear advantages over previous arts with promising quality and meanwhile being fully differentiable. Moreover, by solving the three tasks in a unified model, DeProCams waives the need for additional optical devices, radiometric calibrations and structured light.",
        "published": "2020-03-06T05:49:16Z",
        "link": "http://arxiv.org/abs/2003.03040v2",
        "categories": [
            "cs.CV",
            "cs.GR"
        ]
    },
    {
        "title": "PoseNet3D: Learning Temporally Consistent 3D Human Pose via Knowledge   Distillation",
        "authors": [
            "Shashank Tripathi",
            "Siddhant Ranade",
            "Ambrish Tyagi",
            "Amit Agrawal"
        ],
        "summary": "Recovering 3D human pose from 2D joints is a highly unconstrained problem. We propose a novel neural network framework, PoseNet3D, that takes 2D joints as input and outputs 3D skeletons and SMPL body model parameters. By casting our learning approach in a student-teacher framework, we avoid using any 3D data such as paired/unpaired 3D data, motion capture sequences, depth images or multi-view images during training. We first train a teacher network that outputs 3D skeletons, using only 2D poses for training. The teacher network distills its knowledge to a student network that predicts 3D pose in SMPL representation. Finally, both the teacher and the student networks are jointly fine-tuned in an end-to-end manner using temporal, self-consistency and adversarial losses, improving the accuracy of each individual network. Results on Human3.6M dataset for 3D human pose estimation demonstrate that our approach reduces the 3D joint prediction error by 18% compared to previous unsupervised methods. Qualitative results on in-the-wild datasets show that the recovered 3D poses and meshes are natural, realistic, and flow smoothly over consecutive frames.",
        "published": "2020-03-07T00:10:59Z",
        "link": "http://arxiv.org/abs/2003.03473v2",
        "categories": [
            "cs.CV",
            "cs.GR"
        ]
    },
    {
        "title": "STD-Net: Structure-preserving and Topology-adaptive Deformation Network   for 3D Reconstruction from a Single Image",
        "authors": [
            "Aihua Mao",
            "Canglan Dai",
            "Lin Gao",
            "Ying He",
            "Yong-jin Liu"
        ],
        "summary": "3D reconstruction from a single view image is a long-standing prob-lem in computer vision. Various methods based on different shape representations(such as point cloud or volumetric representations) have been proposed. However,the 3D shape reconstruction with fine details and complex structures are still chal-lenging and have not yet be solved. Thanks to the recent advance of the deepshape representations, it becomes promising to learn the structure and detail rep-resentation using deep neural networks. In this paper, we propose a novel methodcalled STD-Net to reconstruct the 3D models utilizing the mesh representationthat is well suitable for characterizing complex structure and geometry details.To reconstruct complex 3D mesh models with fine details, our method consists of(1) an auto-encoder network for recovering the structure of an object with bound-ing box representation from a single image, (2) a topology-adaptive graph CNNfor updating vertex position for meshes of complex topology, and (3) an unifiedmesh deformation block that deforms the structural boxes into structure-awaremeshed models. Experimental results on the images from ShapeNet show that ourproposed STD-Net has better performance than other state-of-the-art methods onreconstructing 3D objects with complex structures and fine geometric details.",
        "published": "2020-03-07T11:02:47Z",
        "link": "http://arxiv.org/abs/2003.03551v1",
        "categories": [
            "cs.GR",
            "cs.CV"
        ]
    },
    {
        "title": "Style-compatible Object Recommendation for Multi-room Indoor Scene   Synthesis",
        "authors": [
            "Yu He",
            "Yun Cai",
            "Yuan-Chen Guo",
            "Zheng-Ning Liu",
            "Shao-Kui Zhang",
            "Song-Hai Zhang",
            "Hong-Bo Fu",
            "Sheng-Yong Chen"
        ],
        "summary": "Traditional indoor scene synthesis methods often take a two-step approach: object selection and object arrangement. Current state-of-the-art object selection approaches are based on convolutional neural networks (CNNs) and can produce realistic scenes for a single room. However, they cannot be directly extended to synthesize style-compatible scenes for multiple rooms with different functions. To address this issue, we treat the object selection problem as combinatorial optimization based on a Labeled LDA (L-LDA) model. We first calculate occurrence probability distribution of object categories according to a topic model, and then sample objects from each category considering their function diversity along with style compatibility, while regarding not only separate rooms, but also associations among rooms. User study shows that our method outperforms the baselines by incorporating multi-function and multi-room settings with style constraints, and sometimes even produces plausible scenes comparable to those produced by professional designers.",
        "published": "2020-03-09T15:04:25Z",
        "link": "http://arxiv.org/abs/2003.04187v2",
        "categories": [
            "cs.GR"
        ]
    },
    {
        "title": "TailorNet: Predicting Clothing in 3D as a Function of Human Pose, Shape   and Garment Style",
        "authors": [
            "Chaitanya Patel",
            "Zhouyingcheng Liao",
            "Gerard Pons-Moll"
        ],
        "summary": "In this paper, we present TailorNet, a neural model which predicts clothing deformation in 3D as a function of three factors: pose, shape and style (garment geometry), while retaining wrinkle detail. This goes beyond prior models, which are either specific to one style and shape, or generalize to different shapes producing smooth results, despite being style specific. Our hypothesis is that (even non-linear) combinations of examples smooth out high frequency components such as fine-wrinkles, which makes learning the three factors jointly hard. At the heart of our technique is a decomposition of deformation into a high frequency and a low frequency component. While the low-frequency component is predicted from pose, shape and style parameters with an MLP, the high-frequency component is predicted with a mixture of shape-style specific pose models. The weights of the mixture are computed with a narrow bandwidth kernel to guarantee that only predictions with similar high-frequency patterns are combined. The style variation is obtained by computing, in a canonical pose, a subspace of deformation, which satisfies physical constraints such as inter-penetration, and draping on the body. TailorNet delivers 3D garments which retain the wrinkles from the physics based simulations (PBS) it is learned from, while running more than 1000 times faster. In contrast to PBS, TailorNet is easy to use and fully differentiable, which is crucial for computer vision algorithms. Several experiments demonstrate TailorNet produces more realistic results than prior work, and even generates temporally coherent deformations on sequences of the AMASS dataset, despite being trained on static poses from a different dataset. To stimulate further research in this direction, we will make a dataset consisting of 55800 frames, as well as our model publicly available at https://virtualhumans.mpi-inf.mpg.de/tailornet.",
        "published": "2020-03-10T08:49:51Z",
        "link": "http://arxiv.org/abs/2003.04583v2",
        "categories": [
            "cs.CV",
            "cs.GR"
        ]
    },
    {
        "title": "A Compact Spectral Descriptor for Shape Deformations",
        "authors": [
            "Skylar Sible",
            "Rodrigo Iza-Teran",
            "Jochen Garcke",
            "Nikola Aulig",
            "Patricia Wollstadt"
        ],
        "summary": "Modern product design in the engineering domain is increasingly driven by computational analysis including finite-element based simulation, computational optimization, and modern data analysis techniques such as machine learning. To apply these methods, suitable data representations for components under development as well as for related design criteria have to be found. While a component's geometry is typically represented by a polygon surface mesh, it is often not clear how to parametrize critical design properties in order to enable efficient computational analysis. In the present work, we propose a novel methodology to obtain a parameterization of a component's plastic deformation behavior under stress, which is an important design criterion in many application domains, for example, when optimizing the crash behavior in the automotive context. Existing parameterizations limit computational analysis to relatively simple deformations and typically require extensive input by an expert, making the design process time intensive and costly. Hence, we propose a way to derive a compact descriptor of deformation behavior that is based on spectral mesh processing and enables a low-dimensional representation of also complex deformations.We demonstrate the descriptor's ability to represent relevant deformation behavior by applying it in a nearest-neighbor search to identify similar simulation results in a filtering task. The proposed descriptor provides a novel approach to the parametrization of geometric deformation behavior and enables the use of state-of-the-art data analysis techniques such as machine learning to engineering tasks concerned with plastic deformation behavior.",
        "published": "2020-03-10T10:34:30Z",
        "link": "http://arxiv.org/abs/2003.08758v1",
        "categories": [
            "cs.CV",
            "cs.GR",
            "cs.LG"
        ]
    },
    {
        "title": "Enabling Viewpoint Learning through Dynamic Label Generation",
        "authors": [
            "Michael Schelling",
            "Pedro Hermosilla",
            "Pere-Pau Vazquez",
            "Timo Ropinski"
        ],
        "summary": "Optimal viewpoint prediction is an essential task in many computer graphics applications. Unfortunately, common viewpoint qualities suffer from two major drawbacks: dependency on clean surface meshes, which are not always available, and the lack of closed-form expressions, which requires a costly search involving rendering. To overcome these limitations we propose to separate viewpoint selection from rendering through an end-to-end learning approach, whereby we reduce the influence of the mesh quality by predicting viewpoints from unstructured point clouds instead of polygonal meshes. While this makes our approach insensitive to the mesh discretization during evaluation, it only becomes possible when resolving label ambiguities that arise in this context. Therefore, we additionally propose to incorporate the label generation into the training procedure, making the label decision adaptive to the current network predictions. We show how our proposed approach allows for learning viewpoint predictions for models from different object categories and for different viewpoint qualities. Additionally, we show that prediction times are reduced from several minutes to a fraction of a second, as compared to state-of-the-art (SOTA) viewpoint quality evaluation. We will further release the code and training data, which will to our knowledge be the biggest viewpoint quality dataset available.",
        "published": "2020-03-10T11:49:27Z",
        "link": "http://arxiv.org/abs/2003.04651v2",
        "categories": [
            "cs.GR",
            "cs.CV"
        ]
    },
    {
        "title": "Deep Vectorization of Technical Drawings",
        "authors": [
            "Vage Egiazarian",
            "Oleg Voynov",
            "Alexey Artemov",
            "Denis Volkhonskiy",
            "Aleksandr Safin",
            "Maria Taktasheva",
            "Denis Zorin",
            "Evgeny Burnaev"
        ],
        "summary": "We present a new method for vectorization of technical line drawings, such as floor plans, architectural drawings, and 2D CAD images. Our method includes (1) a deep learning-based cleaning stage to eliminate the background and imperfections in the image and fill in missing parts, (2) a transformer-based network to estimate vector primitives, and (3) optimization procedure to obtain the final primitive configurations. We train the networks on synthetic data, renderings of vector line drawings, and manually vectorized scans of line drawings. Our method quantitatively and qualitatively outperforms a number of existing techniques on a collection of representative technical drawings.",
        "published": "2020-03-11T18:19:00Z",
        "link": "http://arxiv.org/abs/2003.05471v3",
        "categories": [
            "cs.CV",
            "cs.GR"
        ]
    },
    {
        "title": "Geodesic Distance Field-based Curved Layer Volume Decomposition for   Multi-Axis Support-free Printing",
        "authors": [
            "Yamin Li",
            "Dong He",
            "Xiangyu Wang",
            "Kai Tang"
        ],
        "summary": "This paper presents a new curved layer volume decomposition method for multi-axis support-free printing of freeform solid parts. Given a solid model to be printed that is represented as a tetrahedral mesh, we first establish a geodesic distance field embedded on the mesh, whose value at any vertex is the geodesic distance to the base of the model. Next, the model is naturally decomposed into curved layers by interpolating a number of iso-geodesic distance surfaces (IGDSs). These IGDSs morph from bottom-up in an intrinsic and smooth way owing to the nature of geodesics, which will be used as the curved printing layers that are friendly to multi-axis printing. In addition, to cater to the collision-free requirement and to improve the printing efficiency, we also propose a printing sequence optimization algorithm for determining the printing order of the IGDSs, which helps reduce the air-move path length. Ample experiments in both computer simulation and physical printing are performed, and the experimental results confirm the advantages of our method.",
        "published": "2020-03-12T05:46:41Z",
        "link": "http://arxiv.org/abs/2003.05938v1",
        "categories": [
            "cs.GR"
        ]
    },
    {
        "title": "Latent Space Subdivision: Stable and Controllable Time Predictions for   Fluid Flow",
        "authors": [
            "Steffen Wiewel",
            "Byungsoo Kim",
            "Vinicius C. Azevedo",
            "Barbara Solenthaler",
            "Nils Thuerey"
        ],
        "summary": "We propose an end-to-end trained neural networkarchitecture to robustly predict the complex dynamics of fluid flows with high temporal stability. We focus on single-phase smoke simulations in 2D and 3D based on the incompressible Navier-Stokes (NS) equations, which are relevant for a wide range of practical problems. To achieve stable predictions for long-term flow sequences, a convolutional neural network (CNN) is trained for spatial compression in combination with a temporal prediction network that consists of stacked Long Short-Term Memory (LSTM) layers. Our core contribution is a novel latent space subdivision (LSS) to separate the respective input quantities into individual parts of the encoded latent space domain. This allows to distinctively alter the encoded quantities without interfering with the remaining latent space values and hence maximizes external control. By selectively overwriting parts of the predicted latent space points, our proposed method is capable to robustly predict long-term sequences of complex physics problems. In addition, we highlight the benefits of a recurrent training on the latent space creation, which is performed by the spatial compression network.",
        "published": "2020-03-12T12:38:52Z",
        "link": "http://arxiv.org/abs/2003.08723v1",
        "categories": [
            "cs.GR",
            "cs.LG",
            "stat.ML"
        ]
    },
    {
        "title": "Towards Photo-Realistic Virtual Try-On by Adaptively   Generating$\\leftrightarrow$Preserving Image Content",
        "authors": [
            "Han Yang",
            "Ruimao Zhang",
            "Xiaobao Guo",
            "Wei Liu",
            "Wangmeng Zuo",
            "Ping Luo"
        ],
        "summary": "Image visual try-on aims at transferring a target clothing image onto a reference person, and has become a hot topic in recent years. Prior arts usually focus on preserving the character of a clothing image (e.g. texture, logo, embroidery) when warping it to arbitrary human pose. However, it remains a big challenge to generate photo-realistic try-on images when large occlusions and human poses are presented in the reference person. To address this issue, we propose a novel visual try-on network, namely Adaptive Content Generating and Preserving Network (ACGPN). In particular, ACGPN first predicts semantic layout of the reference image that will be changed after try-on (e.g. long sleeve shirt$\\rightarrow$arm, arm$\\rightarrow$jacket), and then determines whether its image content needs to be generated or preserved according to the predicted semantic layout, leading to photo-realistic try-on and rich clothing details. ACGPN generally involves three major modules. First, a semantic layout generation module utilizes semantic segmentation of the reference image to progressively predict the desired semantic layout after try-on. Second, a clothes warping module warps clothing images according to the generated semantic layout, where a second-order difference constraint is introduced to stabilize the warping process during training. Third, an inpainting module for content fusion integrates all information (e.g. reference image, semantic layout, warped clothes) to adaptively produce each semantic part of human body. In comparison to the state-of-the-art methods, ACGPN can generate photo-realistic images with much better perceptual quality and richer fine-details.",
        "published": "2020-03-12T15:55:39Z",
        "link": "http://arxiv.org/abs/2003.05863v1",
        "categories": [
            "cs.CV",
            "cs.GR",
            "eess.IV"
        ]
    },
    {
        "title": "Fusion-Aware Point Convolution for Online Semantic 3D Scene Segmentation",
        "authors": [
            "Jiazhao Zhang",
            "Chenyang Zhu",
            "Lintao Zheng",
            "Kai Xu"
        ],
        "summary": "Online semantic 3D segmentation in company with real-time RGB-D reconstruction poses special challenges such as how to perform 3D convolution directly over the progressively fused 3D geometric data, and how to smartly fuse information from frame to frame. We propose a novel fusion-aware 3D point convolution which operates directly on the geometric surface being reconstructed and exploits effectively the inter-frame correlation for high quality 3D feature learning. This is enabled by a dedicated dynamic data structure which organizes the online acquired point cloud with global-local trees. Globally, we compile the online reconstructed 3D points into an incrementally growing coordinate interval tree, enabling fast point insertion and neighborhood query. Locally, we maintain the neighborhood information for each point using an octree whose construction benefits from the fast query of the global tree.Both levels of trees update dynamically and help the 3D convolution effectively exploits the temporal coherence for effective information fusion across RGB-D frames.",
        "published": "2020-03-13T12:32:24Z",
        "link": "http://arxiv.org/abs/2003.06233v4",
        "categories": [
            "cs.GR",
            "cs.CV"
        ]
    },
    {
        "title": "Symmetry Detection of Occluded Point Cloud Using Deep Learning",
        "authors": [
            "Zhelun Wu",
            "Hongyan Jiang",
            "Siyun He"
        ],
        "summary": "Symmetry detection has been a classical problem in computer graphics, many of which using traditional geometric methods. In recent years, however, we have witnessed the arising deep learning changed the landscape of computer graphics. In this paper, we aim to solve the symmetry detection of the occluded point cloud in a deep-learning fashion. To the best of our knowledge, we are the first to utilize deep learning to tackle such a problem. In such a deep learning framework, double supervisions: points on the symmetry plane and normal vectors are employed to help us pinpoint the symmetry plane. We conducted experiments on the YCB- video dataset and demonstrate the efficacy of our method.",
        "published": "2020-03-14T00:23:58Z",
        "link": "http://arxiv.org/abs/2003.06520v1",
        "categories": [
            "cs.CV",
            "cs.GR"
        ]
    },
    {
        "title": "Interactive Neural Style Transfer with Artists",
        "authors": [
            "Thomas Kerdreux",
            "Louis Thiry",
            "Erwan Kerdreux"
        ],
        "summary": "We present interactive painting processes in which a painter and various neural style transfer algorithms interact on a real canvas. Understanding what these algorithms' outputs achieve is then paramount to describe the creative agency in our interactive experiments. We gather a set of paired painting-pictures images and present a new evaluation methodology based on the predictivity of neural style transfer algorithms. We point some algorithms' instabilities and show that they can be used to enlarge the diversity and pleasing oddity of the images synthesized by the numerous existing neural style transfer algorithms. This diversity of images was perceived as a source of inspiration for human painters, portraying the machine as a computational catalyst.",
        "published": "2020-03-14T15:27:44Z",
        "link": "http://arxiv.org/abs/2003.06659v1",
        "categories": [
            "cs.HC",
            "cs.CV",
            "cs.GR",
            "cs.LG"
        ]
    },
    {
        "title": "PFPN: Continuous Control of Physically Simulated Characters using   Particle Filtering Policy Network",
        "authors": [
            "Pei Xu",
            "Ioannis Karamouzas"
        ],
        "summary": "Data-driven methods for physics-based character control using reinforcement learning have been successfully applied to generate high-quality motions. However, existing approaches typically rely on Gaussian distributions to represent the action policy, which can prematurely commit to suboptimal actions when solving high-dimensional continuous control problems for highly-articulated characters. In this paper, to improve the learning performance of physics-based character controllers, we propose a framework that considers a particle-based action policy as a substitute for Gaussian policies. We exploit particle filtering to dynamically explore and discretize the action space, and track the posterior policy represented as a mixture distribution. The resulting policy can replace the unimodal Gaussian policy which has been the staple for character control problems, without changing the underlying model architecture of the reinforcement learning algorithm used to perform policy optimization. We demonstrate the applicability of our approach on various motion capture imitation tasks. Baselines using our particle-based policies achieve better imitation performance and speed of convergence as compared to corresponding implementations using Gaussians, and are more robust to external perturbations during character control. Related code is available at: https://motion-lab.github.io/PFPN.",
        "published": "2020-03-16T00:35:36Z",
        "link": "http://arxiv.org/abs/2003.06959v4",
        "categories": [
            "cs.LG",
            "cs.GR",
            "stat.ML"
        ]
    },
    {
        "title": "Complexity of Shapes Embedded in ${\\mathbb Z^n}$ with a Bias Towards   Squares",
        "authors": [
            "M. Ferhat Arslan",
            "Sibel Tari"
        ],
        "summary": "Shape complexity is a hard-to-quantify quality, mainly due to its relative nature. Biased by Euclidean thinking, circles are commonly considered as the simplest. However, their constructions as digital images are only approximations to the ideal form. Consequently, complexity orders computed in reference to circle are unstable. Unlike circles which lose their circleness in digital images, squares retain their qualities. Hence, we consider squares (hypercubes in $\\mathbb Z^n$) to be the simplest shapes relative to which complexity orders are constructed. Using the connection between $L^\\infty$ norm and squares we effectively encode squareness-adapted simplification through which we obtain multi-scale complexity measure, where scale determines the level of interest to the boundary. The emergent scale above which the effect of a boundary feature (appendage) disappears is related to the ratio of the contacting width of the appendage to that of the main body. We discuss what zero complexity implies in terms of information repetition and constructibility and what kind of shapes in addition to squares have zero complexity.",
        "published": "2020-03-16T17:24:22Z",
        "link": "http://arxiv.org/abs/2003.07341v1",
        "categories": [
            "cs.CV",
            "cs.CG",
            "cs.GR"
        ]
    },
    {
        "title": "Real-time Image Smoothing via Iterative Least Squares",
        "authors": [
            "Wei Liu",
            "Pingping Zhang",
            "Xiaolin Huang",
            "Jie Yang",
            "Chunhua Shen",
            "Ian Reid"
        ],
        "summary": "Edge-preserving image smoothing is a fundamental procedure for many computer vision and graphic applications. There is a tradeoff between the smoothing quality and the processing speed: the high smoothing quality usually requires a high computational cost which leads to the low processing speed. In this paper, we propose a new global optimization based method, named iterative least squares (ILS), for efficient edge-preserving image smoothing. Our approach can produce high-quality results but at a much lower computational cost. Comprehensive experiments demonstrate that the propose method can produce results with little visible artifacts. Moreover, the computation of ILS can be highly parallel, which can be easily accelerated through either multi-thread computing or the GPU hardware. With the acceleration of a GTX 1080 GPU, it is able to process images of 1080p resolution ($1920\\times1080$) at the rate of 20fps for color images and 47fps for gray images. In addition, the ILS is flexible and can be modified to handle more applications that require different smoothing properties. Experimental results of several applications show the effectiveness and efficiency of the proposed method. The code is available at \\url{https://github.com/wliusjtu/Real-time-Image-Smoothing-via-Iterative-Least-Squares}",
        "published": "2020-03-17T02:49:32Z",
        "link": "http://arxiv.org/abs/2003.07504v2",
        "categories": [
            "cs.GR"
        ]
    },
    {
        "title": "Learning to Accelerate Decomposition for Multi-Directional 3D Printing",
        "authors": [
            "Chenming Wu",
            "Yong-Jin Liu",
            "Charlie C. L. Wang"
        ],
        "summary": "Multi-directional 3D printing has the capability of decreasing or eliminating the need for support structures. Recent work proposed a beam-guided search algorithm to find an optimized sequence of plane-clipping, which gives volume decomposition of a given 3D model. Different printing directions are employed in different regions to fabricate a model with tremendously less support (or even no support in many cases).To obtain optimized decomposition, a large beam width needs to be used in the search algorithm, leading to a very time-consuming computation. In this paper, we propose a learning framework that can accelerate the beam-guided search by using a smaller number of the original beam width to obtain results with similar quality. Specifically, we use the results of beam-guided search with large beam width to train a scoring function for candidate clipping planes based on six newly proposed feature metrics. With the help of these feature metrics, both the current and the sequence-dependent information are captured by the neural network to score candidates of clipping. As a result, we can achieve around 3x computational speed. We test and demonstrate our accelerated decomposition on a large dataset of models for 3D printing.",
        "published": "2020-03-17T18:37:44Z",
        "link": "http://arxiv.org/abs/2004.03450v3",
        "categories": [
            "cs.GR",
            "cs.CV",
            "cs.RO"
        ]
    },
    {
        "title": "Inferring the Material Properties of Granular Media for Robotic Tasks",
        "authors": [
            "Carolyn Matl",
            "Yashraj Narang",
            "Ruzena Bajcsy",
            "Fabio Ramos",
            "Dieter Fox"
        ],
        "summary": "Granular media (e.g., cereal grains, plastic resin pellets, and pills) are ubiquitous in robotics-integrated industries, such as agriculture, manufacturing, and pharmaceutical development. This prevalence mandates the accurate and efficient simulation of these materials. This work presents a software and hardware framework that automatically calibrates a fast physics simulator to accurately simulate granular materials by inferring material properties from real-world depth images of granular formations (i.e., piles and rings). Specifically, coefficients of sliding friction, rolling friction, and restitution of grains are estimated from summary statistics of grain formations using likelihood-free Bayesian inference. The calibrated simulator accurately predicts unseen granular formations in both simulation and experiment; furthermore, simulator predictions are shown to generalize to more complex tasks, including using a robot to pour grains into a bowl, as well as to create a desired pattern of piles and rings. Visualizations of the framework and experiments can be viewed at https://youtu.be/OBvV5h2NMKA",
        "published": "2020-03-18T04:00:08Z",
        "link": "http://arxiv.org/abs/2003.08032v4",
        "categories": [
            "cs.RO",
            "cs.GR"
        ]
    },
    {
        "title": "Rotate-and-Render: Unsupervised Photorealistic Face Rotation from   Single-View Images",
        "authors": [
            "Hang Zhou",
            "Jihao Liu",
            "Ziwei Liu",
            "Yu Liu",
            "Xiaogang Wang"
        ],
        "summary": "Though face rotation has achieved rapid progress in recent years, the lack of high-quality paired training data remains a great hurdle for existing methods. The current generative models heavily rely on datasets with multi-view images of the same person. Thus, their generated results are restricted by the scale and domain of the data source. To overcome these challenges, we propose a novel unsupervised framework that can synthesize photo-realistic rotated faces using only single-view image collections in the wild. Our key insight is that rotating faces in the 3D space back and forth, and re-rendering them to the 2D plane can serve as a strong self-supervision. We leverage the recent advances in 3D face modeling and high-resolution GAN to constitute our building blocks. Since the 3D rotation-and-render on faces can be applied to arbitrary angles without losing details, our approach is extremely suitable for in-the-wild scenarios (i.e. no paired data are available), where existing methods fall short. Extensive experiments demonstrate that our approach has superior synthesis quality as well as identity preservation over the state-of-the-art methods, across a wide range of poses and domains. Furthermore, we validate that our rotate-and-render framework naturally can act as an effective data augmentation engine for boosting modern face recognition systems even on strong baseline models.",
        "published": "2020-03-18T09:54:46Z",
        "link": "http://arxiv.org/abs/2003.08124v1",
        "categories": [
            "cs.CV",
            "cs.GR",
            "cs.LG"
        ]
    },
    {
        "title": "Lighthouse: Predicting Lighting Volumes for Spatially-Coherent   Illumination",
        "authors": [
            "Pratul P. Srinivasan",
            "Ben Mildenhall",
            "Matthew Tancik",
            "Jonathan T. Barron",
            "Richard Tucker",
            "Noah Snavely"
        ],
        "summary": "We present a deep learning solution for estimating the incident illumination at any 3D location within a scene from an input narrow-baseline stereo image pair. Previous approaches for predicting global illumination from images either predict just a single illumination for the entire scene, or separately estimate the illumination at each 3D location without enforcing that the predictions are consistent with the same 3D scene. Instead, we propose a deep learning model that estimates a 3D volumetric RGBA model of a scene, including content outside the observed field of view, and then uses standard volume rendering to estimate the incident illumination at any 3D location within that volume. Our model is trained without any ground truth 3D data and only requires a held-out perspective view near the input stereo pair and a spherical panorama taken within each scene as supervision, as opposed to prior methods for spatially-varying lighting estimation, which require ground truth scene geometry for training. We demonstrate that our method can predict consistent spatially-varying lighting that is convincing enough to plausibly relight and insert highly specular virtual objects into real images.",
        "published": "2020-03-18T17:46:30Z",
        "link": "http://arxiv.org/abs/2003.08367v2",
        "categories": [
            "cs.CV",
            "cs.GR"
        ]
    },
    {
        "title": "PT2PC: Learning to Generate 3D Point Cloud Shapes from Part Tree   Conditions",
        "authors": [
            "Kaichun Mo",
            "He Wang",
            "Xinchen Yan",
            "Leonidas J. Guibas"
        ],
        "summary": "3D generative shape modeling is a fundamental research area in computer vision and interactive computer graphics, with many real-world applications. This paper investigates the novel problem of generating 3D shape point cloud geometry from a symbolic part tree representation. In order to learn such a conditional shape generation procedure in an end-to-end fashion, we propose a conditional GAN \"part tree\"-to-\"point cloud\" model (PT2PC) that disentangles the structural and geometric factors. The proposed model incorporates the part tree condition into the architecture design by passing messages top-down and bottom-up along the part tree hierarchy. Experimental results and user study demonstrate the strengths of our method in generating perceptually plausible and diverse 3D point clouds, given the part tree condition. We also propose a novel structural measure for evaluating if the generated shape point clouds satisfy the part tree conditions.",
        "published": "2020-03-19T08:27:25Z",
        "link": "http://arxiv.org/abs/2003.08624v2",
        "categories": [
            "cs.CV",
            "cs.CG",
            "cs.GR"
        ]
    },
    {
        "title": "NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis",
        "authors": [
            "Ben Mildenhall",
            "Pratul P. Srinivasan",
            "Matthew Tancik",
            "Jonathan T. Barron",
            "Ravi Ramamoorthi",
            "Ren Ng"
        ],
        "summary": "We present a method that achieves state-of-the-art results for synthesizing novel views of complex scenes by optimizing an underlying continuous volumetric scene function using a sparse set of input views. Our algorithm represents a scene using a fully-connected (non-convolutional) deep network, whose input is a single continuous 5D coordinate (spatial location $(x,y,z)$ and viewing direction $(\\theta, \\phi)$) and whose output is the volume density and view-dependent emitted radiance at that spatial location. We synthesize views by querying 5D coordinates along camera rays and use classic volume rendering techniques to project the output colors and densities into an image. Because volume rendering is naturally differentiable, the only input required to optimize our representation is a set of images with known camera poses. We describe how to effectively optimize neural radiance fields to render photorealistic novel views of scenes with complicated geometry and appearance, and demonstrate results that outperform prior work on neural rendering and view synthesis. View synthesis results are best viewed as videos, so we urge readers to view our supplementary video for convincing comparisons.",
        "published": "2020-03-19T17:57:23Z",
        "link": "http://arxiv.org/abs/2003.08934v2",
        "categories": [
            "cs.CV",
            "cs.GR"
        ]
    },
    {
        "title": "Cross-Shape Attention for Part Segmentation of 3D Point Clouds",
        "authors": [
            "Marios Loizou",
            "Siddhant Garg",
            "Dmitry Petrov",
            "Melinos Averkiou",
            "Evangelos Kalogerakis"
        ],
        "summary": "We present a deep learning method that propagates point-wise feature representations across shapes within a collection for the purpose of 3D shape segmentation. We propose a cross-shape attention mechanism to enable interactions between a shape's point-wise features and those of other shapes. The mechanism assesses both the degree of interaction between points and also mediates feature propagation across shapes, improving the accuracy and consistency of the resulting point-wise feature representations for shape segmentation. Our method also proposes a shape retrieval measure to select suitable shapes for cross-shape attention operations for each test shape. Our experiments demonstrate that our approach yields state-of-the-art results in the popular PartNet dataset.",
        "published": "2020-03-20T00:23:10Z",
        "link": "http://arxiv.org/abs/2003.09053v6",
        "categories": [
            "cs.CV",
            "cs.GR",
            "cs.LG",
            "eess.IV"
        ]
    },
    {
        "title": "Gaussian Curvature Filter on 3D Meshes",
        "authors": [
            "Wenming Tang",
            "Yuanhao Gong",
            "Kanglin Liu",
            "Jun Liu",
            "Wei Pan",
            "Bozhi Liu",
            "Guoping Qiu"
        ],
        "summary": "Minimizing the Gaussian curvature of meshes can play a fundamental role in 3D mesh processing. However, there is a lack of computationally efficient and robust Gaussian curvature optimization method. In this paper, we present a simple yet effective method that can efficiently reduce Gaussian curvature for 3D meshes. We first present the mathematical foundation of our method. Then, we introduce a simple and robust implicit Gaussian curvature optimization method named Gaussian Curvature Filter (GCF). GCF implicitly minimizes Gaussian curvature without the need to explicitly calculate the Gaussian curvature itself. GCF is highly efficient and this method can be used in a large range of applications that involve Gaussian curvature. We conduct extensive experiments to demonstrate that GCF significantly outperforms state-of-the-art methods in minimizing Gaussian curvature, and geometric feature preserving soothing on 3D meshes. GCF program is available at https://github.com/tangwenming/GCF-filter.",
        "published": "2020-03-20T10:28:24Z",
        "link": "http://arxiv.org/abs/2003.09178v2",
        "categories": [
            "cs.GR"
        ]
    },
    {
        "title": "Volumetric density-equalizing reference map with applications",
        "authors": [
            "Gary P. T. Choi",
            "Chris H. Rycroft"
        ],
        "summary": "The density-equalizing map, a technique developed for cartogram creation, has been widely applied to data visualization but only for 2D applications. In this work, we propose a novel method called the volumetric density-equalizing reference map (VDERM) for computing density-equalizing map for volumetric domains. Given a prescribed density distribution in a volumetric domain in $\\mathbb{R}^3$, the proposed method continuously deforms the domain, with different volume elements enlarged or shrunk according to the density distribution. With the aid of the proposed method, medical and sociological data can be visualized via deformations of 3D objects. The method can also be applied to adaptive remeshing and shape modeling. Furthermore, by exploiting the time-dependent nature of the proposed method, applications to shape morphing can be easily achieved. Experimental results are presented to demonstrate the effectiveness of the proposed method.",
        "published": "2020-03-21T18:58:51Z",
        "link": "http://arxiv.org/abs/2003.09725v1",
        "categories": [
            "math.NA",
            "cs.CG",
            "cs.GR",
            "cs.NA",
            "68U05, 65D18, 76R50"
        ]
    },
    {
        "title": "Rig-space Neural Rendering",
        "authors": [
            "Dominik Borer",
            "Lu Yuhang",
            "Laura Wuelfroth",
            "Jakob Buhmann",
            "Martin Guay"
        ],
        "summary": "Movie productions use high resolution 3d characters with complex proprietary rigs to create the highest quality images possible for large displays. Unfortunately, these 3d assets are typically not compatible with real-time graphics engines used for games, mixed reality and real-time pre-visualization. Consequently, the 3d characters need to be re-modeled and re-rigged for these new applications, requiring weeks of work and artistic approval. Our solution to this problem is to learn a compact image-based rendering of the original 3d character, conditioned directly on the rig parameters. Our idea is to render the character in many different poses and views, and to train a deep neural network to render high resolution images, from the rig parameters directly. Many neural rendering techniques have been proposed to render from 2d skeletons, or geometry and UV maps. However these require manual work, and to do not remain compatible with the animator workflow of manipulating rig widgets, as well as the real-time game engine pipeline of interpolating rig parameters. We extend our architecture to support dynamic re-lighting and composition with other 3d objects in the scene. We designed a network that efficiently generates multiple scene feature maps such as normals, depth, albedo and mask, which are composed with other scene objects to form the final image.",
        "published": "2020-03-22T06:28:22Z",
        "link": "http://arxiv.org/abs/2003.09820v1",
        "categories": [
            "cs.GR"
        ]
    },
    {
        "title": "Multiview Neural Surface Reconstruction by Disentangling Geometry and   Appearance",
        "authors": [
            "Lior Yariv",
            "Yoni Kasten",
            "Dror Moran",
            "Meirav Galun",
            "Matan Atzmon",
            "Ronen Basri",
            "Yaron Lipman"
        ],
        "summary": "In this work we address the challenging problem of multiview 3D surface reconstruction. We introduce a neural network architecture that simultaneously learns the unknown geometry, camera parameters, and a neural renderer that approximates the light reflected from the surface towards the camera. The geometry is represented as a zero level-set of a neural network, while the neural renderer, derived from the rendering equation, is capable of (implicitly) modeling a wide set of lighting conditions and materials. We trained our network on real world 2D images of objects with different material properties, lighting conditions, and noisy camera initializations from the DTU MVS dataset. We found our model to produce state of the art 3D surface reconstructions with high fidelity, resolution and detail.",
        "published": "2020-03-22T10:20:13Z",
        "link": "http://arxiv.org/abs/2003.09852v3",
        "categories": [
            "cs.CV",
            "cs.GR",
            "cs.LG"
        ]
    },
    {
        "title": "Pose to Seat: Automated Design of Body-Supporting Surfaces",
        "authors": [
            "Kurt Leimer",
            "Andreas Winkler",
            "Stefan Ohrhallinger",
            "Przemyslaw Musialski"
        ],
        "summary": "The design of functional seating furniture is a complicated process which often requires extensive manual design effort and empirical evaluation. We propose a computational design framework for pose-driven automated generation of body-supports which are optimized for comfort of sitting. Given a human body in a specified pose as input, our method computes an approximate pressure distribution that also takes frictional forces and body torques into consideration which serves as an objective measure of comfort. Utilizing this information to find out where the body needs to be supported in order to maintain comfort of sitting, our algorithm can create a supporting mesh suited for a person in that specific pose. This is done in an automated fitting process, using a template model capable of supporting a large variety of sitting poses. The results can be used directly or can be considered as a starting point for further interactive design.",
        "published": "2020-03-22T21:08:52Z",
        "link": "http://arxiv.org/abs/2003.10435v1",
        "categories": [
            "cs.GR"
        ]
    },
    {
        "title": "Neural Contours: Learning to Draw Lines from 3D Shapes",
        "authors": [
            "Difan Liu",
            "Mohamed Nabail",
            "Aaron Hertzmann",
            "Evangelos Kalogerakis"
        ],
        "summary": "This paper introduces a method for learning to generate line drawings from 3D models. Our architecture incorporates a differentiable module operating on geometric features of the 3D model, and an image-based module operating on view-based shape representations. At test time, geometric and view-based reasoning are combined with the help of a neural module to create a line drawing. The model is trained on a large number of crowdsourced comparisons of line drawings. Experiments demonstrate that our method achieves significant improvements in line drawing over the state-of-the-art when evaluated on standard benchmarks, resulting in drawings that are comparable to those produced by experienced human artists.",
        "published": "2020-03-23T15:37:49Z",
        "link": "http://arxiv.org/abs/2003.10333v3",
        "categories": [
            "cs.CV",
            "cs.GR"
        ]
    },
    {
        "title": "Perspective picture from Visual Sphere: a new approach to image   rasterization",
        "authors": [
            "Jakub Maksymilian Fober"
        ],
        "summary": "In this paper alternative method for real-time 3D model rasterization is given. Surfaces are drawn in perspective-map space which acts as a virtual camera lens. It can render single-pass 360{\\deg} angle of view (AOV) image of unlimited shape, view-directions count and unrestrained projection geometry (e.g. direct lens distortion, projection mapping, curvilinear perspective), natively aliasing-free. In conjunction to perspective vector map, visual-sphere perspective model is proposed. A model capable of combining pictures from sources previously incompatible, like fish-eye camera and wide-angle lens picture. More so, method is proposed for measurement and simulation of a real optical system variable no-parallax point (NPP). This study also explores philosophical and historical aspects of picture perception and presents a guide for perspective design.",
        "published": "2020-03-23T21:45:26Z",
        "link": "http://arxiv.org/abs/2003.10558v4",
        "categories": [
            "cs.GR",
            "68U05",
            "I.3.3; I.3.5; I.3.7; J.5"
        ]
    },
    {
        "title": "Automatic Modelling of Human Musculoskeletal Ligaments -- Framework   Overview and Model Quality Evaluation",
        "authors": [
            "Noura Hamze",
            "Lukas Nocker",
            "Nikolaus Rauch",
            "Markus Walzthöni",
            "Fabio Carrillo",
            "Philipp Fürnstahl",
            "Matthias Harders"
        ],
        "summary": "Accurate segmentation of connective soft tissues is still a challenging task, which hinders the generation of corresponding geometric models for biomechanical computations. Alternatively, one could predict ligament insertion sites and then approximate the shapes, based on anatomical knowledge and morphological studies. Here, we describe a corresponding integrated framework for the automatic modelling of human musculoskeletal ligaments. We combine statistical shape modelling with geometric algorithms to automatically identify insertion sites, based on which geometric surface and volume meshes are created. For demonstrating a clinical use case, the framework has been applied to generate models of the interosseous membrane in the forearm. For the adoption to the forearm anatomy, ligament insertion sites in the statistical model were defined according to anatomical predictions following an approach proposed in prior work. For evaluation we compared the generated sites, as well as the ligament shapes, to data obtained from a cadaveric study, involving five forearms with a total of 15 ligaments. Our framework permitted the creation of 3D models approximating ligaments' shapes with good fidelity. However, we found that the statistical model trained with the state-of-the-art prediction of the insertion sites was not always reliable. Using that model, average mean square errors as well as Hausdorff distances of the meshes increased by more than one order of magnitude, as compared to employing the known insertion locations of the cadaveric study. Using the latter an average mean square error of 0.59 mm and an average Hausdorff distance of less than 7 mm resulted, for the complete set of ligaments. In conclusion, the presented approach for generating ligament shapes from insertion points appears to be feasible but the detection of the insertion sites with a SSM is too inaccurate.",
        "published": "2020-03-24T10:19:29Z",
        "link": "http://arxiv.org/abs/2003.11025v1",
        "categories": [
            "cs.GR",
            "cs.CE"
        ]
    },
    {
        "title": "Deformable Style Transfer",
        "authors": [
            "Sunnie S. Y. Kim",
            "Nicholas Kolkin",
            "Jason Salavon",
            "Gregory Shakhnarovich"
        ],
        "summary": "Both geometry and texture are fundamental aspects of visual style. Existing style transfer methods, however, primarily focus on texture, almost entirely ignoring geometry. We propose deformable style transfer (DST), an optimization-based approach that jointly stylizes the texture and geometry of a content image to better match a style image. Unlike previous geometry-aware stylization methods, our approach is neither restricted to a particular domain (such as human faces), nor does it require training sets of matching style/content pairs. We demonstrate our method on a diverse set of content and style images including portraits, animals, objects, scenes, and paintings. Code has been made publicly available at https://github.com/sunniesuhyoung/DST.",
        "published": "2020-03-24T18:00:18Z",
        "link": "http://arxiv.org/abs/2003.11038v2",
        "categories": [
            "cs.CV",
            "cs.GR",
            "cs.LG"
        ]
    },
    {
        "title": "Global Illumination of non-Euclidean spaces",
        "authors": [
            "Tiago Novello",
            "Vinicius da Silva",
            "Luiz Velho"
        ],
        "summary": "This paper presents a path tracer algorithm to compute the global illumination of non-Euclidean manifolds. We use the 3D torus as an example.",
        "published": "2020-03-24T22:21:28Z",
        "link": "http://arxiv.org/abs/2003.11133v1",
        "categories": [
            "cs.GR"
        ]
    },
    {
        "title": "Virtual reality for 3D histology: multi-scale visualization of organs   with interactive feature exploration",
        "authors": [
            "Kaisa Liimatainen",
            "Leena Latonen",
            "Masi Valkonen",
            "Kimmo Kartasalo",
            "Pekka Ruusuvuori"
        ],
        "summary": "Virtual reality (VR) enables data visualization in an immersive and engaging manner, and it can be used for creating ways to explore scientific data. Here, we use VR for visualization of 3D histology data, creating a novel interface for digital pathology. Our contribution includes 3D modeling of a whole organ and embedded objects of interest, fusing the models with associated quantitative features and full resolution serial section patches, and implementing the virtual reality application. Our VR application is multi-scale in nature, covering two object levels representing different ranges of detail, namely organ level and sub-organ level. In addition, the application includes several data layers, including the measured histology image layer and multiple representations of quantitative features computed from the histology. In this interactive VR application, the user can set visualization properties, select different samples and features, and interact with various objects. In this work, we used whole mouse prostates (organ level) with prostate cancer tumors (sub-organ objects of interest) as example cases, and included quantitative histological features relevant for tumor biology in the VR model. Due to automated processing of the histology data, our application can be easily adopted to visualize other organs and pathologies from various origins. Our application enables a novel way for exploration of high-resolution, multidimensional data for biomedical research purposes, and can also be used in teaching and researcher training.",
        "published": "2020-03-24T23:23:41Z",
        "link": "http://arxiv.org/abs/2003.11148v1",
        "categories": [
            "cs.GR",
            "eess.IV"
        ]
    },
    {
        "title": "A Hybrid Lagrangian/Eulerian Collocated Advection and Projection Method   for Fluid Simulation",
        "authors": [
            "Steven W. Gagniere",
            "David A. B. Hyde",
            "Alan Marquez-Razon",
            "Chenfanfu Jiang",
            "Ziheng Ge",
            "Xuchen Han",
            "Qi Guo",
            "Joseph Teran"
        ],
        "summary": "We present a hybrid particle/grid approach for simulating incompressible fluids on collocated velocity grids. We interchangeably use particle and grid representations of transported quantities to balance efficiency and accuracy. A novel Backward Semi-Lagrangian method is derived to improve accuracy of grid based advection. Our approach utilizes the implicit formula associated with solutions of Burgers' equation. We solve this equation using Newton's method enabled by $C^1$ continuous grid interpolation. We enforce incompressibility over collocated, rather than staggered grids. Our projection technique is variational and designed for B-spline interpolation over regular grids where multiquadratic interpolation is used for velocity and multilinear interpolation for pressure. Despite our use of regular grids, we extend the variational technique to allow for cut-cell definition of irregular flow domains for both Dirichlet and free surface boundary conditions.",
        "published": "2020-03-27T04:09:29Z",
        "link": "http://arxiv.org/abs/2003.12227v1",
        "categories": [
            "cs.GR",
            "cs.CE",
            "physics.comp-ph"
        ]
    },
    {
        "title": "LIMP: Learning Latent Shape Representations with Metric Preservation   Priors",
        "authors": [
            "Luca Cosmo",
            "Antonio Norelli",
            "Oshri Halimi",
            "Ron Kimmel",
            "Emanuele Rodolà"
        ],
        "summary": "In this paper, we advocate the adoption of metric preservation as a powerful prior for learning latent representations of deformable 3D shapes. Key to our construction is the introduction of a geometric distortion criterion, defined directly on the decoded shapes, translating the preservation of the metric on the decoding to the formation of linear paths in the underlying latent space. Our rationale lies in the observation that training samples alone are often insufficient to endow generative models with high fidelity, motivating the need for large training datasets. In contrast, metric preservation provides a rigorous way to control the amount of geometric distortion incurring in the construction of the latent space, leading in turn to synthetic samples of higher quality. We further demonstrate, for the first time, the adoption of differentiable intrinsic distances in the backpropagation of a geodesic loss. Our geometric priors are particularly relevant in the presence of scarce training data, where learning any meaningful latent structure can be especially challenging. The effectiveness and potential of our generative model is showcased in applications of style transfer, content generation, and shape completion.",
        "published": "2020-03-27T08:53:34Z",
        "link": "http://arxiv.org/abs/2003.12283v2",
        "categories": [
            "cs.LG",
            "cs.CG",
            "cs.GR",
            "stat.ML"
        ]
    },
    {
        "title": "Deep 3D Capture: Geometry and Reflectance from Sparse Multi-View Images",
        "authors": [
            "Sai Bi",
            "Zexiang Xu",
            "Kalyan Sunkavalli",
            "David Kriegman",
            "Ravi Ramamoorthi"
        ],
        "summary": "We introduce a novel learning-based method to reconstruct the high-quality geometry and complex, spatially-varying BRDF of an arbitrary object from a sparse set of only six images captured by wide-baseline cameras under collocated point lighting. We first estimate per-view depth maps using a deep multi-view stereo network; these depth maps are used to coarsely align the different views. We propose a novel multi-view reflectance estimation network architecture that is trained to pool features from these coarsely aligned images and predict per-view spatially-varying diffuse albedo, surface normals, specular roughness and specular albedo. We do this by jointly optimizing the latent space of our multi-view reflectance network to minimize the photometric error between images rendered with our predictions and the input images. While previous state-of-the-art methods fail on such sparse acquisition setups, we demonstrate, via extensive experiments on synthetic and real data, that our method produces high-quality reconstructions that can be used to render photorealistic images.",
        "published": "2020-03-27T21:28:54Z",
        "link": "http://arxiv.org/abs/2003.12642v2",
        "categories": [
            "cs.CV",
            "cs.GR"
        ]
    },
    {
        "title": "PointGMM: a Neural GMM Network for Point Clouds",
        "authors": [
            "Amir Hertz",
            "Rana Hanocka",
            "Raja Giryes",
            "Daniel Cohen-Or"
        ],
        "summary": "Point clouds are a popular representation for 3D shapes. However, they encode a particular sampling without accounting for shape priors or non-local information. We advocate for the use of a hierarchical Gaussian mixture model (hGMM), which is a compact, adaptive and lightweight representation that probabilistically defines the underlying 3D surface. We present PointGMM, a neural network that learns to generate hGMMs which are characteristic of the shape class, and also coincide with the input point cloud. PointGMM is trained over a collection of shapes to learn a class-specific prior. The hierarchical representation has two main advantages: (i) coarse-to-fine learning, which avoids converging to poor local-minima; and (ii) (an unsupervised) consistent partitioning of the input shape. We show that as a generative model, PointGMM learns a meaningful latent space which enables generating consistent interpolations between existing shapes, as well as synthesizing novel shapes. We also present a novel framework for rigid registration using PointGMM, that learns to disentangle orientation from structure of an input shape.",
        "published": "2020-03-30T10:34:59Z",
        "link": "http://arxiv.org/abs/2003.13326v1",
        "categories": [
            "cs.LG",
            "cs.CV",
            "cs.GR",
            "stat.ML"
        ]
    },
    {
        "title": "Human Motion Transfer with 3D Constraints and Detail Enhancement",
        "authors": [
            "Yang-Tian Sun",
            "Qian-Cheng Fu",
            "Yue-Ren Jiang",
            "Zitao Liu",
            "Yu-Kun Lai",
            "Hongbo Fu",
            "Lin Gao"
        ],
        "summary": "We propose a new method for realistic human motion transfer using a generative adversarial network (GAN), which generates a motion video of a target character imitating actions of a source character, while maintaining high authenticity of the generated results. We tackle the problem by decoupling and recombining the posture information and appearance information of both the source and target characters. The innovation of our approach lies in the use of the projection of a reconstructed 3D human model as the condition of GAN to better maintain the structural integrity of transfer results in different poses. We further introduce a detail enhancement net to enhance the details of transfer results by exploiting the details in real source frames. Extensive experiments show that our approach yields better results both qualitatively and quantitatively than the state-of-the-art methods.",
        "published": "2020-03-30T14:33:30Z",
        "link": "http://arxiv.org/abs/2003.13510v4",
        "categories": [
            "cs.GR"
        ]
    },
    {
        "title": "Label-Efficient Learning on Point Clouds using Approximate Convex   Decompositions",
        "authors": [
            "Matheus Gadelha",
            "Aruni RoyChowdhury",
            "Gopal Sharma",
            "Evangelos Kalogerakis",
            "Liangliang Cao",
            "Erik Learned-Miller",
            "Rui Wang",
            "Subhransu Maji"
        ],
        "summary": "The problems of shape classification and part segmentation from 3D point clouds have garnered increasing attention in the last few years. Both of these problems, however, suffer from relatively small training sets, creating the need for statistically efficient methods to learn 3D shape representations. In this paper, we investigate the use of Approximate Convex Decompositions (ACD) as a self-supervisory signal for label-efficient learning of point cloud representations. We show that using ACD to approximate ground truth segmentation provides excellent self-supervision for learning 3D point cloud representations that are highly effective on downstream tasks. We report improvements over the state-of-the-art for unsupervised representation learning on the ModelNet40 shape classification dataset and significant gains in few-shot part segmentation on the ShapeNetPart dataset.Code available at https://github.com/matheusgadelha/PointCloudLearningACD",
        "published": "2020-03-30T21:44:43Z",
        "link": "http://arxiv.org/abs/2003.13834v2",
        "categories": [
            "cs.CV",
            "cs.GR",
            "cs.LG"
        ]
    },
    {
        "title": "AvatarMe: Realistically Renderable 3D Facial Reconstruction   \"in-the-wild\"",
        "authors": [
            "Alexandros Lattas",
            "Stylianos Moschoglou",
            "Baris Gecer",
            "Stylianos Ploumpis",
            "Vasileios Triantafyllou",
            "Abhijeet Ghosh",
            "Stefanos Zafeiriou"
        ],
        "summary": "Over the last years, with the advent of Generative Adversarial Networks (GANs), many face analysis tasks have accomplished astounding performance, with applications including, but not limited to, face generation and 3D face reconstruction from a single \"in-the-wild\" image. Nevertheless, to the best of our knowledge, there is no method which can produce high-resolution photorealistic 3D faces from \"in-the-wild\" images and this can be attributed to the: (a) scarcity of available data for training, and (b) lack of robust methodologies that can successfully be applied on very high-resolution data. In this paper, we introduce AvatarMe, the first method that is able to reconstruct photorealistic 3D faces from a single \"in-the-wild\" image with an increasing level of detail. To achieve this, we capture a large dataset of facial shape and reflectance and build on a state-of-the-art 3D texture and shape reconstruction method and successively refine its results, while generating the per-pixel diffuse and specular components that are required for realistic rendering. As we demonstrate in a series of qualitative and quantitative experiments, AvatarMe outperforms the existing arts by a significant margin and reconstructs authentic, 4K by 6K-resolution 3D faces from a single low-resolution image that, for the first time, bridges the uncanny valley.",
        "published": "2020-03-30T22:17:54Z",
        "link": "http://arxiv.org/abs/2003.13845v1",
        "categories": [
            "cs.CV",
            "cs.GR",
            "I.2.10; I.3.7; I.4.1"
        ]
    },
    {
        "title": "Y-net: Multi-scale feature aggregation network with wavelet structure   similarity loss function for single image dehazing",
        "authors": [
            "Hao-Hsiang Yang",
            "Chao-Han Huck Yang",
            "Yi-Chang James Tsai"
        ],
        "summary": "Single image dehazing is the ill-posed two-dimensional signal reconstruction problem. Recently, deep convolutional neural networks (CNN) have been successfully used in many computer vision problems. In this paper, we propose a Y-net that is named for its structure. This network reconstructs clear images by aggregating multi-scale features maps. Additionally, we propose a Wavelet Structure SIMilarity (W-SSIM) loss function in the training step. In the proposed loss function, discrete wavelet transforms are applied repeatedly to divide the image into differently sized patches with different frequencies and scales. The proposed loss function is the accumulation of SSIM loss of various patches with respective ratios. Extensive experimental results demonstrate that the proposed Y-net with the W-SSIM loss function restores high-quality clear images and outperforms state-of-the-art algorithms. Code and models are available at https://github.com/dectrfov/Y-net.",
        "published": "2020-03-31T02:07:33Z",
        "link": "http://arxiv.org/abs/2003.13912v1",
        "categories": [
            "cs.CV",
            "cs.GR",
            "cs.LG",
            "eess.IV"
        ]
    },
    {
        "title": "StyleRig: Rigging StyleGAN for 3D Control over Portrait Images",
        "authors": [
            "Ayush Tewari",
            "Mohamed Elgharib",
            "Gaurav Bharaj",
            "Florian Bernard",
            "Hans-Peter Seidel",
            "Patrick Pérez",
            "Michael Zollhöfer",
            "Christian Theobalt"
        ],
        "summary": "StyleGAN generates photorealistic portrait images of faces with eyes, teeth, hair and context (neck, shoulders, background), but lacks a rig-like control over semantic face parameters that are interpretable in 3D, such as face pose, expressions, and scene illumination. Three-dimensional morphable face models (3DMMs) on the other hand offer control over the semantic parameters, but lack photorealism when rendered and only model the face interior, not other parts of a portrait image (hair, mouth interior, background). We present the first method to provide a face rig-like control over a pretrained and fixed StyleGAN via a 3DMM. A new rigging network, RigNet is trained between the 3DMM's semantic parameters and StyleGAN's input. The network is trained in a self-supervised manner, without the need for manual annotations. At test time, our method generates portrait images with the photorealism of StyleGAN and provides explicit control over the 3D semantic parameters of the face.",
        "published": "2020-03-31T21:20:34Z",
        "link": "http://arxiv.org/abs/2004.00121v2",
        "categories": [
            "cs.CV",
            "cs.GR"
        ]
    },
    {
        "title": "BCNet: Learning Body and Cloth Shape from A Single Image",
        "authors": [
            "Boyi Jiang",
            "Juyong Zhang",
            "Yang Hong",
            "Jinhao Luo",
            "Ligang Liu",
            "Hujun Bao"
        ],
        "summary": "In this paper, we consider the problem to automatically reconstruct garment and body shapes from a single near-front view RGB image. To this end, we propose a layered garment representation on top of SMPL and novelly make the skinning weight of garment independent of the body mesh, which significantly improves the expression ability of our garment model. Compared with existing methods, our method can support more garment categories and recover more accurate geometry. To train our model, we construct two large scale datasets with ground truth body and garment geometries as well as paired color images. Compared with single mesh or non-parametric representation, our method can achieve more flexible control with separate meshes, makes applications like re-pose, garment transfer, and garment texture mapping possible. Code and some data is available at https://github.com/jby1993/BCNet.",
        "published": "2020-04-01T03:41:36Z",
        "link": "http://arxiv.org/abs/2004.00214v2",
        "categories": [
            "cs.CV",
            "cs.GR"
        ]
    },
    {
        "title": "SoftSMPL: Data-driven Modeling of Nonlinear Soft-tissue Dynamics for   Parametric Humans",
        "authors": [
            "Igor Santesteban",
            "Elena Garces",
            "Miguel A. Otaduy",
            "Dan Casas"
        ],
        "summary": "We present SoftSMPL, a learning-based method to model realistic soft-tissue dynamics as a function of body shape and motion. Datasets to learn such task are scarce and expensive to generate, which makes training models prone to overfitting. At the core of our method there are three key contributions that enable us to model highly realistic dynamics and better generalization capabilities than state-of-the-art methods, while training on the same data. First, a novel motion descriptor that disentangles the standard pose representation by removing subject-specific features; second, a neural-network-based recurrent regressor that generalizes to unseen shapes and motions; and third, a highly efficient nonlinear deformation subspace capable of representing soft-tissue deformations of arbitrary shapes. We demonstrate qualitative and quantitative improvements over existing methods and, additionally, we show the robustness of our method on a variety of motion capture databases.",
        "published": "2020-04-01T10:35:06Z",
        "link": "http://arxiv.org/abs/2004.00326v1",
        "categories": [
            "cs.CV",
            "cs.GR"
        ]
    },
    {
        "title": "Two-shot Spatially-varying BRDF and Shape Estimation",
        "authors": [
            "Mark Boss",
            "Varun Jampani",
            "Kihwan Kim",
            "Hendrik P. A. Lensch",
            "Jan Kautz"
        ],
        "summary": "Capturing the shape and spatially-varying appearance (SVBRDF) of an object from images is a challenging task that has applications in both computer vision and graphics. Traditional optimization-based approaches often need a large number of images taken from multiple views in a controlled environment. Newer deep learning-based approaches require only a few input images, but the reconstruction quality is not on par with optimization techniques. We propose a novel deep learning architecture with a stage-wise estimation of shape and SVBRDF. The previous predictions guide each estimation, and a joint refinement network later refines both SVBRDF and shape. We follow a practical mobile image capture setting and use unaligned two-shot flash and no-flash images as input. Both our two-shot image capture and network inference can run on mobile hardware. We also create a large-scale synthetic training dataset with domain-randomized geometry and realistic materials. Extensive experiments on both synthetic and real-world datasets show that our network trained on a synthetic dataset can generalize well to real-world images. Comparisons with recent approaches demonstrate the superior performance of the proposed approach.",
        "published": "2020-04-01T12:56:13Z",
        "link": "http://arxiv.org/abs/2004.00403v1",
        "categories": [
            "cs.CV",
            "cs.GR",
            "cs.LG"
        ]
    },
    {
        "title": "PIFuHD: Multi-Level Pixel-Aligned Implicit Function for High-Resolution   3D Human Digitization",
        "authors": [
            "Shunsuke Saito",
            "Tomas Simon",
            "Jason Saragih",
            "Hanbyul Joo"
        ],
        "summary": "Recent advances in image-based 3D human shape estimation have been driven by the significant improvement in representation power afforded by deep neural networks. Although current approaches have demonstrated the potential in real world settings, they still fail to produce reconstructions with the level of detail often present in the input images. We argue that this limitation stems primarily form two conflicting requirements; accurate predictions require large context, but precise predictions require high resolution. Due to memory limitations in current hardware, previous approaches tend to take low resolution images as input to cover large spatial context, and produce less precise (or low resolution) 3D estimates as a result. We address this limitation by formulating a multi-level architecture that is end-to-end trainable. A coarse level observes the whole image at lower resolution and focuses on holistic reasoning. This provides context to an fine level which estimates highly detailed geometry by observing higher-resolution images. We demonstrate that our approach significantly outperforms existing state-of-the-art techniques on single image human shape reconstruction by fully leveraging 1k-resolution input images.",
        "published": "2020-04-01T13:52:53Z",
        "link": "http://arxiv.org/abs/2004.00452v1",
        "categories": [
            "cs.CV",
            "cs.GR"
        ]
    },
    {
        "title": "Synchronizing Probability Measures on Rotations via Optimal Transport",
        "authors": [
            "Tolga Birdal",
            "Michael Arbel",
            "Umut Şimşekli",
            "Leonidas Guibas"
        ],
        "summary": "We introduce a new paradigm, $\\textit{measure synchronization}$, for synchronizing graphs with measure-valued edges. We formulate this problem as maximization of the cycle-consistency in the space of probability measures over relative rotations. In particular, we aim at estimating marginal distributions of absolute orientations by synchronizing the $\\textit{conditional}$ ones, which are defined on the Riemannian manifold of quaternions. Such graph optimization on distributions-on-manifolds enables a natural treatment of multimodal hypotheses, ambiguities and uncertainties arising in many computer vision applications such as SLAM, SfM, and object pose estimation. We first formally define the problem as a generalization of the classical rotation graph synchronization, where in our case the vertices denote probability measures over rotations. We then measure the quality of the synchronization by using Sinkhorn divergences, which reduces to other popular metrics such as Wasserstein distance or the maximum mean discrepancy as limit cases. We propose a nonparametric Riemannian particle optimization approach to solve the problem. Even though the problem is non-convex, by drawing a connection to the recently proposed sparse optimization methods, we show that the proposed algorithm converges to the global optimum in a special case of the problem under certain conditions. Our qualitative and quantitative experiments show the validity of our approach and we bring in new perspectives to the study of synchronization.",
        "published": "2020-04-01T18:44:18Z",
        "link": "http://arxiv.org/abs/2004.00663v1",
        "categories": [
            "cs.CV",
            "cs.GR",
            "cs.LG",
            "cs.RO",
            "stat.ML"
        ]
    },
    {
        "title": "Deformation-Aware 3D Model Embedding and Retrieval",
        "authors": [
            "Mikaela Angelina Uy",
            "Jingwei Huang",
            "Minhyuk Sung",
            "Tolga Birdal",
            "Leonidas Guibas"
        ],
        "summary": "We introduce a new problem of retrieving 3D models that are deformable to a given query shape and present a novel deep deformation-aware embedding to solve this retrieval task. 3D model retrieval is a fundamental operation for recovering a clean and complete 3D model from a noisy and partial 3D scan. However, given a finite collection of 3D shapes, even the closest model to a query may not be satisfactory. This motivates us to apply 3D model deformation techniques to adapt the retrieved model so as to better fit the query. Yet, certain restrictions are enforced in most 3D deformation techniques to preserve important features of the original model that prevent a perfect fitting of the deformed model to the query. This gap between the deformed model and the query induces asymmetric relationships among the models, which cannot be handled by typical metric learning techniques. Thus, to retrieve the best models for fitting, we propose a novel deep embedding approach that learns the asymmetric relationships by leveraging location-dependent egocentric distance fields. We also propose two strategies for training the embedding network. We demonstrate that both of these approaches outperform other baselines in our experiments with both synthetic and real data. Our project page can be found at https://deformscan2cad.github.io/.",
        "published": "2020-04-02T19:10:57Z",
        "link": "http://arxiv.org/abs/2004.01228v3",
        "categories": [
            "cs.CV",
            "cs.GR",
            "cs.LG",
            "eess.IV"
        ]
    },
    {
        "title": "Intrinsic Point Cloud Interpolation via Dual Latent Space Navigation",
        "authors": [
            "Marie-Julie Rakotosaona",
            "Maks Ovsjanikov"
        ],
        "summary": "We present a learning-based method for interpolating and manipulating 3D shapes represented as point clouds, that is explicitly designed to preserve intrinsic shape properties. Our approach is based on constructing a dual encoding space that enables shape synthesis and, at the same time, provides links to the intrinsic shape information, which is typically not available on point cloud data. Our method works in a single pass and avoids expensive optimization, employed by existing techniques. Furthermore, the strong regularization provided by our dual latent space approach also helps to improve shape recovery in challenging settings from noisy point clouds across different datasets. Extensive experiments show that our method results in more realistic and smoother interpolations compared to baselines.",
        "published": "2020-04-03T16:28:55Z",
        "link": "http://arxiv.org/abs/2004.01661v1",
        "categories": [
            "cs.CV",
            "cs.GR"
        ]
    },
    {
        "title": "Robust 3D Self-portraits in Seconds",
        "authors": [
            "Zhe Li",
            "Tao Yu",
            "Chuanyu Pan",
            "Zerong Zheng",
            "Yebin Liu"
        ],
        "summary": "In this paper, we propose an efficient method for robust 3D self-portraits using a single RGBD camera. Benefiting from the proposed PIFusion and lightweight bundle adjustment algorithm, our method can generate detailed 3D self-portraits in seconds and shows the ability to handle subjects wearing extremely loose clothes. To achieve highly efficient and robust reconstruction, we propose PIFusion, which combines learning-based 3D recovery with volumetric non-rigid fusion to generate accurate sparse partial scans of the subject. Moreover, a non-rigid volumetric deformation method is proposed to continuously refine the learned shape prior. Finally, a lightweight bundle adjustment algorithm is proposed to guarantee that all the partial scans can not only \"loop\" with each other but also remain consistent with the selected live key observations. The results and experiments show that the proposed method achieves more robust and efficient 3D self-portraits compared with state-of-the-art methods.",
        "published": "2020-04-06T08:02:51Z",
        "link": "http://arxiv.org/abs/2004.02460v1",
        "categories": [
            "cs.CV",
            "cs.GR"
        ]
    },
    {
        "title": "GANSpace: Discovering Interpretable GAN Controls",
        "authors": [
            "Erik Härkönen",
            "Aaron Hertzmann",
            "Jaakko Lehtinen",
            "Sylvain Paris"
        ],
        "summary": "This paper describes a simple technique to analyze Generative Adversarial Networks (GANs) and create interpretable controls for image synthesis, such as change of viewpoint, aging, lighting, and time of day. We identify important latent directions based on Principal Components Analysis (PCA) applied either in latent space or feature space. Then, we show that a large number of interpretable controls can be defined by layer-wise perturbation along the principal directions. Moreover, we show that BigGAN can be controlled with layer-wise inputs in a StyleGAN-like manner. We show results on different GANs trained on various datasets, and demonstrate good qualitative matches to edit directions found through earlier supervised approaches.",
        "published": "2020-04-06T10:41:44Z",
        "link": "http://arxiv.org/abs/2004.02546v3",
        "categories": [
            "cs.CV",
            "cs.GR"
        ]
    },
    {
        "title": "Multimodal Medical Volume Colorization from 2D Style",
        "authors": [
            "Aradhya Neeraj Mathur",
            "Apoorv Khattar",
            "Ojaswa Sharma"
        ],
        "summary": "Colorization involves the synthesis of colors on a target image while preserving structural content as well as the semantics of the target image. This is a well-explored problem in 2D with many state-of-the-art solutions. We propose a novel deep learning-based approach for the colorization of 3D medical volumes. Our system is capable of directly mapping the colors of a 2D photograph to a 3D MRI volume in real-time, producing a high-fidelity color volume suitable for photo-realistic visualization. Since this work is first of its kind, we discuss the full pipeline in detail and the challenges that it brings for 3D medical data. The colorization of medical MRI volume also entails modality conversion that highlights the robustness of our approach in handling multi-modal data.",
        "published": "2020-04-06T10:53:25Z",
        "link": "http://arxiv.org/abs/2004.11702v1",
        "categories": [
            "eess.IV",
            "cs.GR"
        ]
    },
    {
        "title": "A Morphable Face Albedo Model",
        "authors": [
            "William A. P. Smith",
            "Alassane Seck",
            "Hannah Dee",
            "Bernard Tiddeman",
            "Joshua Tenenbaum",
            "Bernhard Egger"
        ],
        "summary": "In this paper, we bring together two divergent strands of research: photometric face capture and statistical 3D face appearance modelling. We propose a novel lightstage capture and processing pipeline for acquiring ear-to-ear, truly intrinsic diffuse and specular albedo maps that fully factor out the effects of illumination, camera and geometry. Using this pipeline, we capture a dataset of 50 scans and combine them with the only existing publicly available albedo dataset (3DRFE) of 23 scans. This allows us to build the first morphable face albedo model. We believe this is the first statistical analysis of the variability of facial specular albedo maps. This model can be used as a plug in replacement for the texture model of the Basel Face Model (BFM) or FLAME and we make the model publicly available. We ensure careful spectral calibration such that our model is built in a linear sRGB space, suitable for inverse rendering of images taken by typical cameras. We demonstrate our model in a state of the art analysis-by-synthesis 3DMM fitting pipeline, are the first to integrate specular map estimation and outperform the BFM in albedo reconstruction.",
        "published": "2020-04-06T14:49:40Z",
        "link": "http://arxiv.org/abs/2004.02711v2",
        "categories": [
            "cs.CV",
            "cs.GR"
        ]
    },
    {
        "title": "Rethinking Spatially-Adaptive Normalization",
        "authors": [
            "Zhentao Tan",
            "Dongdong Chen",
            "Qi Chu",
            "Menglei Chai",
            "Jing Liao",
            "Mingming He",
            "Lu Yuan",
            "Nenghai Yu"
        ],
        "summary": "Spatially-adaptive normalization is remarkably successful recently in conditional semantic image synthesis, which modulates the normalized activation with spatially-varying transformations learned from semantic layouts, to preserve the semantic information from being washed away. Despite its impressive performance, a more thorough understanding of the true advantages inside the box is still highly demanded, to help reduce the significant computation and parameter overheads introduced by these new structures. In this paper, from a return-on-investment point of view, we present a deep analysis of the effectiveness of SPADE and observe that its advantages actually come mainly from its semantic-awareness rather than the spatial-adaptiveness. Inspired by this point, we propose class-adaptive normalization (CLADE), a lightweight variant that is not adaptive to spatial positions or layouts. Benefited from this design, CLADE greatly reduces the computation cost while still being able to preserve the semantic information during the generation. Extensive experiments on multiple challenging datasets demonstrate that while the resulting fidelity is on par with SPADE, its overhead is much cheaper than SPADE. Take the generator for ADE20k dataset as an example, the extra parameter and computation cost introduced by CLADE are only 4.57% and 0.07% while that of SPADE are 39.21% and 234.73% respectively.",
        "published": "2020-04-06T17:58:25Z",
        "link": "http://arxiv.org/abs/2004.02867v1",
        "categories": [
            "cs.CV",
            "cs.GR"
        ]
    },
    {
        "title": "NiLBS: Neural Inverse Linear Blend Skinning",
        "authors": [
            "Timothy Jeruzalski",
            "David I. W. Levin",
            "Alec Jacobson",
            "Paul Lalonde",
            "Mohammad Norouzi",
            "Andrea Tagliasacchi"
        ],
        "summary": "In this technical report, we investigate efficient representations of articulated objects (e.g. human bodies), which is an important problem in computer vision and graphics. To deform articulated geometry, existing approaches represent objects as meshes and deform them using \"skinning\" techniques. The skinning operation allows a wide range of deformations to be achieved with a small number of control parameters. This paper introduces a method to invert the deformations undergone via traditional skinning techniques via a neural network parameterized by pose. The ability to invert these deformations allows values (e.g., distance function, signed distance function, occupancy) to be pre-computed at rest pose, and then efficiently queried when the character is deformed. We leave empirical evaluation of our approach to future work.",
        "published": "2020-04-06T20:46:37Z",
        "link": "http://arxiv.org/abs/2004.05980v1",
        "categories": [
            "cs.GR",
            "cs.LG"
        ]
    },
    {
        "title": "Learning Generative Models of Shape Handles",
        "authors": [
            "Matheus Gadelha",
            "Giorgio Gori",
            "Duygu Ceylan",
            "Radomir Mech",
            "Nathan Carr",
            "Tamy Boubekeur",
            "Rui Wang",
            "Subhransu Maji"
        ],
        "summary": "We present a generative model to synthesize 3D shapes as sets of handles -- lightweight proxies that approximate the original 3D shape -- for applications in interactive editing, shape parsing, and building compact 3D representations. Our model can generate handle sets with varying cardinality and different types of handles (Figure 1). Key to our approach is a deep architecture that predicts both the parameters and existence of shape handles, and a novel similarity measure that can easily accommodate different types of handles, such as cuboids or sphere-meshes. We leverage the recent advances in semantic 3D annotation as well as automatic shape summarizing techniques to supervise our approach. We show that the resulting shape representations are intuitive and achieve superior quality than previous state-of-the-art. Finally, we demonstrate how our method can be used in applications such as interactive shape editing, completion, and interpolation, leveraging the latent space learned by our model to guide these tasks. Project page: http://mgadelha.me/shapehandles.",
        "published": "2020-04-06T22:35:55Z",
        "link": "http://arxiv.org/abs/2004.03028v1",
        "categories": [
            "cs.CV",
            "cs.GR",
            "cs.LG"
        ]
    },
    {
        "title": "Multimodal Image Synthesis with Conditional Implicit Maximum Likelihood   Estimation",
        "authors": [
            "Ke Li",
            "Shichong Peng",
            "Tianhao Zhang",
            "Jitendra Malik"
        ],
        "summary": "Many tasks in computer vision and graphics fall within the framework of conditional image synthesis. In recent years, generative adversarial nets (GANs) have delivered impressive advances in quality of synthesized images. However, it remains a challenge to generate both diverse and plausible images for the same input, due to the problem of mode collapse. In this paper, we develop a new generic multimodal conditional image synthesis method based on Implicit Maximum Likelihood Estimation (IMLE) and demonstrate improved multimodal image synthesis performance on two tasks, single image super-resolution and image synthesis from scene layouts. We make our implementation publicly available.",
        "published": "2020-04-07T03:06:55Z",
        "link": "http://arxiv.org/abs/2004.03590v1",
        "categories": [
            "cs.CV",
            "cs.GR",
            "cs.LG",
            "cs.NE",
            "eess.IV"
        ]
    },
    {
        "title": "Iconify: Converting Photographs into Icons",
        "authors": [
            "Takuro Karamatsu",
            "Gibran Benitez-Garcia",
            "Keiji Yanai",
            "Seiichi Uchida"
        ],
        "summary": "In this paper, we tackle a challenging domain conversion task between photo and icon images. Although icons often originate from real object images (i.e., photographs), severe abstractions and simplifications are applied to generate icon images by professional graphic designers. Moreover, there is no one-to-one correspondence between the two domains, for this reason we cannot use it as the ground-truth for learning a direct conversion function. Since generative adversarial networks (GAN) can undertake the problem of domain conversion without any correspondence, we test CycleGAN and UNIT to generate icons from objects segmented from photo images. Our experiments with several image datasets prove that CycleGAN learns sufficient abstraction and simplification ability to generate icon-like images.",
        "published": "2020-04-07T08:01:47Z",
        "link": "http://arxiv.org/abs/2004.03179v1",
        "categories": [
            "cs.GR",
            "cs.CV"
        ]
    },
    {
        "title": "State of the Art on Neural Rendering",
        "authors": [
            "Ayush Tewari",
            "Ohad Fried",
            "Justus Thies",
            "Vincent Sitzmann",
            "Stephen Lombardi",
            "Kalyan Sunkavalli",
            "Ricardo Martin-Brualla",
            "Tomas Simon",
            "Jason Saragih",
            "Matthias Nießner",
            "Rohit Pandey",
            "Sean Fanello",
            "Gordon Wetzstein",
            "Jun-Yan Zhu",
            "Christian Theobalt",
            "Maneesh Agrawala",
            "Eli Shechtman",
            "Dan B Goldman",
            "Michael Zollhöfer"
        ],
        "summary": "Efficient rendering of photo-realistic virtual worlds is a long standing effort of computer graphics. Modern graphics techniques have succeeded in synthesizing photo-realistic images from hand-crafted scene representations. However, the automatic generation of shape, materials, lighting, and other aspects of scenes remains a challenging problem that, if solved, would make photo-realistic computer graphics more widely accessible. Concurrently, progress in computer vision and machine learning have given rise to a new approach to image synthesis and editing, namely deep generative models. Neural rendering is a new and rapidly emerging field that combines generative machine learning techniques with physical knowledge from computer graphics, e.g., by the integration of differentiable rendering into network training. With a plethora of applications in computer graphics and vision, neural rendering is poised to become a new area in the graphics community, yet no survey of this emerging field exists. This state-of-the-art report summarizes the recent trends and applications of neural rendering. We focus on approaches that combine classic computer graphics techniques with deep generative models to obtain controllable and photo-realistic outputs. Starting with an overview of the underlying computer graphics and machine learning concepts, we discuss critical aspects of neural rendering approaches. This state-of-the-art report is focused on the many important use cases for the described algorithms such as novel view synthesis, semantic photo manipulation, facial and body reenactment, relighting, free-viewpoint video, and the creation of photo-realistic avatars for virtual and augmented reality telepresence. Finally, we conclude with a discussion of the social implications of such technology and investigate open research problems.",
        "published": "2020-04-08T04:36:31Z",
        "link": "http://arxiv.org/abs/2004.03805v1",
        "categories": [
            "cs.CV",
            "cs.GR"
        ]
    },
    {
        "title": "ARCH: Animatable Reconstruction of Clothed Humans",
        "authors": [
            "Zeng Huang",
            "Yuanlu Xu",
            "Christoph Lassner",
            "Hao Li",
            "Tony Tung"
        ],
        "summary": "In this paper, we propose ARCH (Animatable Reconstruction of Clothed Humans), a novel end-to-end framework for accurate reconstruction of animation-ready 3D clothed humans from a monocular image. Existing approaches to digitize 3D humans struggle to handle pose variations and recover details. Also, they do not produce models that are animation ready. In contrast, ARCH is a learned pose-aware model that produces detailed 3D rigged full-body human avatars from a single unconstrained RGB image. A Semantic Space and a Semantic Deformation Field are created using a parametric 3D body estimator. They allow the transformation of 2D/3D clothed humans into a canonical space, reducing ambiguities in geometry caused by pose variations and occlusions in training data. Detailed surface geometry and appearance are learned using an implicit function representation with spatial local features. Furthermore, we propose additional per-pixel supervision on the 3D reconstruction using opacity-aware differentiable rendering. Our experiments indicate that ARCH increases the fidelity of the reconstructed humans. We obtain more than 50% lower reconstruction errors for standard metrics compared to state-of-the-art methods on public datasets. We also show numerous qualitative examples of animated, high-quality reconstructed avatars unseen in the literature so far.",
        "published": "2020-04-08T14:23:08Z",
        "link": "http://arxiv.org/abs/2004.04572v2",
        "categories": [
            "cs.GR",
            "cs.CV",
            "cs.LG",
            "eess.IV"
        ]
    },
    {
        "title": "Deep Manifold Prior",
        "authors": [
            "Matheus Gadelha",
            "Rui Wang",
            "Subhransu Maji"
        ],
        "summary": "We present a prior for manifold structured data, such as surfaces of 3D shapes, where deep neural networks are adopted to reconstruct a target shape using gradient descent starting from a random initialization. We show that surfaces generated this way are smooth, with limiting behavior characterized by Gaussian processes, and we mathematically derive such properties for fully-connected as well as convolutional networks. We demonstrate our method in a variety of manifold reconstruction applications, such as point cloud denoising and interpolation, achieving considerably better results against competitive baselines while requiring no training data. We also show that when training data is available, our method allows developing alternate parametrizations of surfaces under the framework of AtlasNet, leading to a compact network architecture and better reconstruction results on standard image to shape reconstruction benchmarks.",
        "published": "2020-04-08T20:47:56Z",
        "link": "http://arxiv.org/abs/2004.04242v1",
        "categories": [
            "cs.CV",
            "cs.GR"
        ]
    },
    {
        "title": "Multi-feature super-resolution network for cloth wrinkle synthesis",
        "authors": [
            "Lan Chen",
            "Juntao Ye",
            "Xiaopeng Zhang"
        ],
        "summary": "Existing physical cloth simulators suffer from expensive computation and difficulties in tuning mechanical parameters to get desired wrinkling behaviors. Data-driven methods provide an alternative solution. It typically synthesizes cloth animation at a much lower computational cost, and also creates wrinkling effects that highly resemble the much controllable training data. In this paper we propose a deep learning based method for synthesizing cloth animation with high resolution meshes. To do this we first create a dataset for training: a pair of low and high resolution meshes are simulated and their motions are synchronized. As a result the two meshes exhibit similar large-scale deformation but different small wrinkles. Each simulated mesh pair are then converted into a pair of low and high resolution \"images\" (a 2D array of samples), with each sample can be interpreted as any of three features: the displacement, the normal and the velocity. With these image pairs, we design a multi-feature super-resolution (MFSR) network that jointly train an upsampling synthesizer for the three features. The MFSR architecture consists of two key components: a sharing module that takes multiple features as input to learn low-level representations from corresponding super-resolution tasks simultaneously; and task-specific modules focusing on various high-level semantics. Frame-to-frame consistency is well maintained thanks to the proposed kinematics-based loss function. Our method achieves realistic results at high frame rates: 12-14 times faster than traditional physical simulation. We demonstrate the performance of our method with various experimental scenes, including a dressed character with sophisticated collisions.",
        "published": "2020-04-09T03:37:57Z",
        "link": "http://arxiv.org/abs/2004.04351v2",
        "categories": [
            "cs.GR"
        ]
    },
    {
        "title": "SESAME: Semantic Editing of Scenes by Adding, Manipulating or Erasing   Objects",
        "authors": [
            "Evangelos Ntavelis",
            "Andrés Romero",
            "Iason Kastanis",
            "Luc Van Gool",
            "Radu Timofte"
        ],
        "summary": "Recent advances in image generation gave rise to powerful tools for semantic image editing. However, existing approaches can either operate on a single image or require an abundance of additional information. They are not capable of handling the complete set of editing operations, that is addition, manipulation or removal of semantic concepts. To address these limitations, we propose SESAME, a novel generator-discriminator pair for Semantic Editing of Scenes by Adding, Manipulating or Erasing objects. In our setup, the user provides the semantic labels of the areas to be edited and the generator synthesizes the corresponding pixels. In contrast to previous methods that employ a discriminator that trivially concatenates semantics and image as an input, the SESAME discriminator is composed of two input streams that independently process the image and its semantics, using the latter to manipulate the results of the former. We evaluate our model on a diverse set of datasets and report state-of-the-art performance on two tasks: (a) image manipulation and (b) image generation conditioned on semantic labels.",
        "published": "2020-04-10T10:19:19Z",
        "link": "http://arxiv.org/abs/2004.04977v2",
        "categories": [
            "cs.CV",
            "cs.GR",
            "cs.LG",
            "eess.IV"
        ]
    },
    {
        "title": "Cross-domain Correspondence Learning for Exemplar-based Image   Translation",
        "authors": [
            "Pan Zhang",
            "Bo Zhang",
            "Dong Chen",
            "Lu Yuan",
            "Fang Wen"
        ],
        "summary": "We present a general framework for exemplar-based image translation, which synthesizes a photo-realistic image from the input in a distinct domain (e.g., semantic segmentation mask, or edge map, or pose keypoints), given an exemplar image. The output has the style (e.g., color, texture) in consistency with the semantically corresponding objects in the exemplar. We propose to jointly learn the crossdomain correspondence and the image translation, where both tasks facilitate each other and thus can be learned with weak supervision. The images from distinct domains are first aligned to an intermediate domain where dense correspondence is established. Then, the network synthesizes images based on the appearance of semantically corresponding patches in the exemplar. We demonstrate the effectiveness of our approach in several image translation tasks. Our method is superior to state-of-the-art methods in terms of image quality significantly, with the image style faithful to the exemplar with semantic consistency. Moreover, we show the utility of our method for several applications",
        "published": "2020-04-12T09:10:57Z",
        "link": "http://arxiv.org/abs/2004.05571v1",
        "categories": [
            "cs.CV",
            "cs.GR",
            "eess.IV"
        ]
    },
    {
        "title": "MLCVNet: Multi-Level Context VoteNet for 3D Object Detection",
        "authors": [
            "Qian Xie",
            "Yu-Kun Lai",
            "Jing Wu",
            "Zhoutao Wang",
            "Yiming Zhang",
            "Kai Xu",
            "Jun Wang"
        ],
        "summary": "In this paper, we address the 3D object detection task by capturing multi-level contextual information with the self-attention mechanism and multi-scale feature fusion. Most existing 3D object detection methods recognize objects individually, without giving any consideration on contextual information between these objects. Comparatively, we propose Multi-Level Context VoteNet (MLCVNet) to recognize 3D objects correlatively, building on the state-of-the-art VoteNet. We introduce three context modules into the voting and classifying stages of VoteNet to encode contextual information at different levels. Specifically, a Patch-to-Patch Context (PPC) module is employed to capture contextual information between the point patches, before voting for their corresponding object centroid points. Subsequently, an Object-to-Object Context (OOC) module is incorporated before the proposal and classification stage, to capture the contextual information between object candidates. Finally, a Global Scene Context (GSC) module is designed to learn the global scene context. We demonstrate these by capturing contextual information at patch, object and scene levels. Our method is an effective way to promote detection accuracy, achieving new state-of-the-art detection performance on challenging 3D object detection datasets, i.e., SUN RGBD and ScanNet. We also release our code at https://github.com/NUAAXQ/MLCVNet.",
        "published": "2020-04-12T19:10:24Z",
        "link": "http://arxiv.org/abs/2004.05679v1",
        "categories": [
            "cs.CV",
            "cs.GR"
        ]
    },
    {
        "title": "Line Art Correlation Matching Feature Transfer Network for Automatic   Animation Colorization",
        "authors": [
            "Zhang Qian",
            "Wang Bo",
            "Wen Wei",
            "Li Hai",
            "Liu Jun Hui"
        ],
        "summary": "Automatic animation line art colorization is a challenging computer vision problem, since the information of the line art is highly sparse and abstracted and there exists a strict requirement for the color and style consistency between frames. Recently, a lot of Generative Adversarial Network (GAN) based image-to-image translation methods for single line art colorization have emerged. They can generate perceptually appealing results conditioned on line art images. However, these methods can not be adopted for the purpose of animation colorization because there is a lack of consideration of the in-between frame consistency. Existing methods simply input the previous colored frame as a reference to color the next line art, which will mislead the colorization due to the spatial misalignment of the previous colored frame and the next line art especially at positions where apparent changes happen. To address these challenges, we design a kind of correlation matching feature transfer model (called CMFT) to align the colored reference feature in a learnable way and integrate the model into an U-Net based generator in a coarse-to-fine manner. This enables the generator to transfer the layer-wise synchronized features from the deep semantic code to the content progressively. Extension evaluation shows that CMFT model can effectively improve the in-between consistency and the quality of colored frames especially when the motion is intense and diverse.",
        "published": "2020-04-14T06:50:08Z",
        "link": "http://arxiv.org/abs/2004.06718v3",
        "categories": [
            "cs.CV",
            "cs.GR",
            "eess.IV"
        ]
    },
    {
        "title": "Intuitive, Interactive Beard and Hair Synthesis with Generative Models",
        "authors": [
            "Kyle Olszewski",
            "Duygu Ceylan",
            "Jun Xing",
            "Jose Echevarria",
            "Zhili Chen",
            "Weikai Chen",
            "Hao Li"
        ],
        "summary": "We present an interactive approach to synthesizing realistic variations in facial hair in images, ranging from subtle edits to existing hair to the addition of complex and challenging hair in images of clean-shaven subjects. To circumvent the tedious and computationally expensive tasks of modeling, rendering and compositing the 3D geometry of the target hairstyle using the traditional graphics pipeline, we employ a neural network pipeline that synthesizes realistic and detailed images of facial hair directly in the target image in under one second. The synthesis is controlled by simple and sparse guide strokes from the user defining the general structural and color properties of the target hairstyle. We qualitatively and quantitatively evaluate our chosen method compared to several alternative approaches. We show compelling interactive editing results with a prototype user interface that allows novice users to progressively refine the generated image to match their desired hairstyle, and demonstrate that our approach also allows for flexible and high-fidelity scalp hair synthesis.",
        "published": "2020-04-15T01:20:10Z",
        "link": "http://arxiv.org/abs/2004.06848v1",
        "categories": [
            "cs.CV",
            "cs.GR",
            "cs.HC",
            "cs.LG"
        ]
    },
    {
        "title": "MeshingNet: A New Mesh Generation Method based on Deep Learning",
        "authors": [
            "Zheyan Zhang",
            "Yongxing Wang",
            "Peter K. Jimack",
            "He Wang"
        ],
        "summary": "We introduce a novel approach to automatic unstructured mesh generation using machine learning to predict an optimal finite element mesh for a previously unseen problem. The framework that we have developed is based around training an artificial neural network (ANN) to guide standard mesh generation software, based upon a prediction of the required local mesh density throughout the domain. We describe the training regime that is proposed, based upon the use of \\emph{a posteriori} error estimation, and discuss the topologies of the ANNs that we have considered. We then illustrate performance using two standard test problems, a single elliptic partial differential equation (PDE) and a system of PDEs associated with linear elasticity. We demonstrate the effective generation of high quality meshes for arbitrary polygonal geometries and a range of material parameters, using a variety of user-selected error norms.",
        "published": "2020-04-15T11:29:00Z",
        "link": "http://arxiv.org/abs/2004.07016v1",
        "categories": [
            "math.NA",
            "cs.GR",
            "cs.LG",
            "cs.NA"
        ]
    },
    {
        "title": "Combinatorial 3D Shape Generation via Sequential Assembly",
        "authors": [
            "Jungtaek Kim",
            "Hyunsoo Chung",
            "Jinhwi Lee",
            "Minsu Cho",
            "Jaesik Park"
        ],
        "summary": "Sequential assembly with geometric primitives has drawn attention in robotics and 3D vision since it yields a practical blueprint to construct a target shape. However, due to its combinatorial property, a greedy method falls short of generating a sequence of volumetric primitives. To alleviate this consequence induced by a huge number of feasible combinations, we propose a combinatorial 3D shape generation framework. The proposed framework reflects an important aspect of human generation processes in real life -- we often create a 3D shape by sequentially assembling unit primitives with geometric constraints. To find the desired combination regarding combination evaluations, we adopt Bayesian optimization, which is able to exploit and explore efficiently the feasible regions constrained by the current primitive placements. An evaluation function conveys global structure guidance for an assembly process and stability in terms of gravity and external forces simultaneously. Experimental results demonstrate that our method successfully generates combinatorial 3D shapes and simulates more realistic generation processes. We also introduce a new dataset for combinatorial 3D shape generation. All the codes are available at \\url{https://github.com/POSTECH-CVLab/Combinatorial-3D-Shape-Generation}.",
        "published": "2020-04-16T01:23:14Z",
        "link": "http://arxiv.org/abs/2004.07414v2",
        "categories": [
            "cs.CV",
            "cs.GR",
            "cs.LG",
            "stat.ML"
        ]
    },
    {
        "title": "Pulsar: Efficient Sphere-based Neural Rendering",
        "authors": [
            "Christoph Lassner",
            "Michael Zollhöfer"
        ],
        "summary": "We propose Pulsar, an efficient sphere-based differentiable renderer that is orders of magnitude faster than competing techniques, modular, and easy-to-use due to its tight integration with PyTorch. Differentiable rendering is the foundation for modern neural rendering approaches, since it enables end-to-end training of 3D scene representations from image observations. However, gradient-based optimization of neural mesh, voxel, or function representations suffers from multiple challenges, i.e., topological inconsistencies, high memory footprints, or slow rendering speeds. To alleviate these problems, Pulsar employs: 1) a sphere-based scene representation, 2) an efficient differentiable rendering engine, and 3) neural shading. Pulsar executes orders of magnitude faster than existing techniques and allows real-time rendering and optimization of representations with millions of spheres. Using spheres for the scene representation, unprecedented speed is obtained while avoiding topology problems. Pulsar is fully differentiable and thus enables a plethora of applications, ranging from 3D reconstruction to general neural rendering.",
        "published": "2020-04-16T06:57:26Z",
        "link": "http://arxiv.org/abs/2004.07484v3",
        "categories": [
            "cs.GR"
        ]
    },
    {
        "title": "A Simple, General, and GPU Friendly Method for Computing Dual Mesh and   Iso-Surfaces of Adaptive Mesh Refinement (AMR) Data",
        "authors": [
            "Ingo Wald"
        ],
        "summary": "We propose a novel approach to extracting crack-free iso-surfaces from Structured AMR data that is more general than previous techniques, is trivially simple to implement, requires no information other than the list of AMR cells, and works, in particular, for different AMR formats including octree AMR, block-structured AMR with arbitrary level differences at level boundaries, and AMR data that consist of individual cells without any existing grid structure. We describe both the technique itself and a CUDA-based GPU implementation of this technique, and evaluate it on several non-trivial AMR data sets.",
        "published": "2020-04-17T22:41:01Z",
        "link": "http://arxiv.org/abs/2004.08475v1",
        "categories": [
            "cs.GR"
        ]
    },
    {
        "title": "SpectralWeight: a spectral graph wavelet framework for weight prediction   of pork cuts",
        "authors": [
            "Majid Masoumi",
            "Marcel Marcoux",
            "Laurence Maignel",
            "Candido Pomar"
        ],
        "summary": "In this paper, we propose a novel approach for the quality assessment of pork carcasses using 3D shape analysis. First, we make a 3D model of a pork half-carcass using a 3D scanner and then we take advantage of spectral graph wavelet signature (SGWS) to build a local spectral descriptor. Next, we aggregate the extracted features using the bag-of-geometric-words paradigm to globally represent the half-carcass shape. We then employ partial least-squares regression to predict the weight of pork cuts for the quality assessment of carcasses. Our results demonstrate that SpectralWeight can predict the weight of different pork cuts and tissues with high accuracy. Although in this study we evaluate the performance of SGWS for the weight prediction of pork dissection, our framework is fairly general and enables new ways to estimate the quality and economical value of carcasses of different animals.",
        "published": "2020-04-20T00:57:21Z",
        "link": "http://arxiv.org/abs/2005.05406v1",
        "categories": [
            "cs.GR"
        ]
    },
    {
        "title": "Developable B-spline surface generation from control rulings",
        "authors": [
            "Zixuan Hu",
            "Pengbo Bo"
        ],
        "summary": "An intuitive design method is proposed for generating developable ruled B-spline surfaces from a sequence of straight line segments indicating the surface shape. The first and last line segments are enforced to be the head and tail ruling lines of the resulting surface while the interior lines are required to approximate rulings on the resulting surface as much as possible. This manner of developable surface design is conceptually similar to the popular way of the freeform curve and surface design in the CAD community, observing that a developable ruled surface is a single parameter family of straight lines. This new design mode of the developable surface also provides more flexibility than the widely employed way of developable surface design from two boundary curves of the surface. The problem is treated by numerical optimization methods with which a particular level of distance error is allowed. We thus provide an effective tool for creating surfaces with a high degree of developability when the input control rulings do not lie in exact developable surfaces. We consider this ability as the superiority over analytical methods in that it can deal with arbitrary design inputs and find practically useful results.",
        "published": "2020-04-20T03:22:23Z",
        "link": "http://arxiv.org/abs/2004.09038v2",
        "categories": [
            "cs.GR"
        ]
    },
    {
        "title": "Robust and efficient tool path generation for poor-quality triangular   mesh surface machining",
        "authors": [
            "Qiang Zou"
        ],
        "summary": "This paper presents a new method to generate iso-scallop tool paths for triangular mesh surfaces. With the popularity of 3D scanning techniques, scanning-derived mesh surfaces have seen a significant increase in their application to machining. Quite often, such mesh surfaces exhibit defects such as noises, which differentiate them from the good-quality mesh surfaces previous research work focuses on. To generate tool paths for such poor-quality mesh surfaces, the primary challenge lies in robustness against the defects. In this work, a robust tool path generation method is proposed for poor-quality mesh surfaces. In addition to robustness, the method is quite efficient, providing the benefit of faster iterations and improved integration between scanning and machining. The fundamental principle of the method is to convert the tool path generation problem to the heat diffusion problem that has robust and efficient algorithms available. The effectiveness of the method will be demonstrated by a series of case studies and comparisons.",
        "published": "2020-04-20T08:58:50Z",
        "link": "http://arxiv.org/abs/2004.09136v1",
        "categories": [
            "cs.GR",
            "cs.CG"
        ]
    },
    {
        "title": "Pose Manipulation with Identity Preservation",
        "authors": [
            "Andrei-Timotei Ardelean",
            "Lucian Mircea Sasu"
        ],
        "summary": "This paper describes a new model which generates images in novel poses e.g. by altering face expression and orientation, from just a few instances of a human subject. Unlike previous approaches which require large datasets of a specific person for training, our approach may start from a scarce set of images, even from a single image. To this end, we introduce Character Adaptive Identity Normalization GAN (CainGAN) which uses spatial characteristic features extracted by an embedder and combined across source images. The identity information is propagated throughout the network by applying conditional normalization. After extensive adversarial training, CainGAN receives figures of faces from a certain individual and produces new ones while preserving the person's identity. Experimental results show that the quality of generated images scales with the size of the input set used during inference. Furthermore, quantitative measurements indicate that CainGAN performs better compared to other methods when training data is limited.",
        "published": "2020-04-20T09:51:31Z",
        "link": "http://arxiv.org/abs/2004.09169v1",
        "categories": [
            "cs.CV",
            "cs.GR",
            "cs.LG"
        ]
    },
    {
        "title": "Landmark Detection and 3D Face Reconstruction for Caricature using a   Nonlinear Parametric Model",
        "authors": [
            "Hongrui Cai",
            "Yudong Guo",
            "Zhuang Peng",
            "Juyong Zhang"
        ],
        "summary": "Caricature is an artistic abstraction of the human face by distorting or exaggerating certain facial features, while still retains a likeness with the given face. Due to the large diversity of geometric and texture variations, automatic landmark detection and 3D face reconstruction for caricature is a challenging problem and has rarely been studied before. In this paper, we propose the first automatic method for this task by a novel 3D approach. To this end, we first build a dataset with various styles of 2D caricatures and their corresponding 3D shapes, and then build a parametric model on vertex based deformation space for 3D caricature face. Based on the constructed dataset and the nonlinear parametric model, we propose a neural network based method to regress the 3D face shape and orientation from the input 2D caricature image. Ablation studies and comparison with state-of-the-art methods demonstrate the effectiveness of our algorithm design. Extensive experimental results demonstrate that our method works well for various caricatures. Our constructed dataset, source code and trained model are available at https://github.com/Juyong/CaricatureFace.",
        "published": "2020-04-20T10:34:52Z",
        "link": "http://arxiv.org/abs/2004.09190v2",
        "categories": [
            "cs.CV",
            "cs.GR"
        ]
    },
    {
        "title": "Bringing Old Photos Back to Life",
        "authors": [
            "Ziyu Wan",
            "Bo Zhang",
            "Dongdong Chen",
            "Pan Zhang",
            "Dong Chen",
            "Jing Liao",
            "Fang Wen"
        ],
        "summary": "We propose to restore old photos that suffer from severe degradation through a deep learning approach. Unlike conventional restoration tasks that can be solved through supervised learning, the degradation in real photos is complex and the domain gap between synthetic images and real old photos makes the network fail to generalize. Therefore, we propose a novel triplet domain translation network by leveraging real photos along with massive synthetic image pairs. Specifically, we train two variational autoencoders (VAEs) to respectively transform old photos and clean photos into two latent spaces. And the translation between these two latent spaces is learned with synthetic paired data. This translation generalizes well to real photos because the domain gap is closed in the compact latent space. Besides, to address multiple degradations mixed in one old photo, we design a global branch with a partial nonlocal block targeting to the structured defects, such as scratches and dust spots, and a local branch targeting to the unstructured defects, such as noises and blurriness. Two branches are fused in the latent space, leading to improved capability to restore old photos from multiple defects. The proposed method outperforms state-of-the-art methods in terms of visual quality for old photos restoration.",
        "published": "2020-04-20T17:59:23Z",
        "link": "http://arxiv.org/abs/2004.09484v1",
        "categories": [
            "cs.CV",
            "cs.GR",
            "eess.IV"
        ]
    },
    {
        "title": "A scriptable, generative modelling system for dynamic 3D meshes",
        "authors": [
            "Jon McCormack",
            "Ben Porter",
            "James Wetter"
        ],
        "summary": "We describe a flexible, script-based system for the procedural generation and animation of 3D geometry. Dynamic triangular meshes are generated through the real-time execution of scripts written in the Lua programming language. Tight integration between the programming environment, runtime engine and graphics visualisation enables a workflow between coding and visual results that encourages experimentation and rapid prototyping. The system has been used successfully to generate a variety of complex, dynamic organic forms including complex branching structures, scalable symmetric manifolds and abstract organic forms. We use examples in each of these areas to detail the main features of the system, which include a set of flexible 3D mesh operations integrated with a Lua-based L-system interpreter that creates geometry using generalised cylinders.",
        "published": "2020-04-22T00:59:07Z",
        "link": "http://arxiv.org/abs/2004.10354v1",
        "categories": [
            "cs.GR",
            "cs.CG",
            "I.3.5; I.3.7; I.6.2"
        ]
    },
    {
        "title": "Spectrally Consistent UNet for High Fidelity Image Transformations",
        "authors": [
            "Demetris Marnerides",
            "Thomas Bashford-Rogers",
            "Kurt Debattista"
        ],
        "summary": "Convolutional Neural Networks (CNNs) are the current de-facto models used for many imaging tasks due to their high learning capacity as well as their architectural qualities. The ubiquitous UNet architecture provides an efficient and multi-scale solution that combines local and global information. Despite the success of UNet architectures, the use of upsampling layers can cause artefacts. In this work, a method for assessing the structural biases of UNets and the effects these have on the outputs is presented, characterising their impact in the Fourier domain. A new upsampling module is proposed, based on a novel use of the Guided Image Filter, that provides spectrally consistent outputs when used in a UNet architecture, forming the Guided UNet (GUNet). The GUNet architecture is applied and evaluated for example applications of inverse tone mapping/dynamic range expansion and colourisation from grey-scale images and is shown to provide higher fidelity outputs.",
        "published": "2020-04-22T17:04:02Z",
        "link": "http://arxiv.org/abs/2004.10696v2",
        "categories": [
            "eess.IV",
            "cs.GR",
            "cs.LG",
            "stat.ML"
        ]
    },
    {
        "title": "Knot Morphing Algorithm for Quantum `Fragile Topology'",
        "authors": [
            "Kirk E. Jordan",
            "Ji Li",
            "Thomas J. Peters"
        ],
        "summary": "A knot theoretic algorithm is proposed to model `fragile topology' of quantum physics.",
        "published": "2020-04-22T22:01:47Z",
        "link": "http://arxiv.org/abs/2005.08873v1",
        "categories": [
            "math.GT",
            "cs.CG",
            "cs.GR",
            "57M25"
        ]
    },
    {
        "title": "Through the Looking Glass: Neural 3D Reconstruction of Transparent   Shapes",
        "authors": [
            "Zhengqin Li",
            "Yu-Ying Yeh",
            "Manmohan Chandraker"
        ],
        "summary": "Recovering the 3D shape of transparent objects using a small number of unconstrained natural images is an ill-posed problem. Complex light paths induced by refraction and reflection have prevented both traditional and deep multiview stereo from solving this challenge. We propose a physically-based network to recover 3D shape of transparent objects using a few images acquired with a mobile phone camera, under a known but arbitrary environment map. Our novel contributions include a normal representation that enables the network to model complex light transport through local computation, a rendering layer that models refractions and reflections, a cost volume specifically designed for normal refinement of transparent shapes and a feature mapping based on predicted normals for 3D point cloud reconstruction. We render a synthetic dataset to encourage the model to learn refractive light transport across different views. Our experiments show successful recovery of high-quality 3D geometry for complex transparent shapes using as few as 5-12 natural images. Code and data are publicly released.",
        "published": "2020-04-22T23:51:30Z",
        "link": "http://arxiv.org/abs/2004.10904v2",
        "categories": [
            "cs.CV",
            "cs.GR"
        ]
    },
    {
        "title": "Single-View View Synthesis with Multiplane Images",
        "authors": [
            "Richard Tucker",
            "Noah Snavely"
        ],
        "summary": "A recent strand of work in view synthesis uses deep learning to generate multiplane images (a camera-centric, layered 3D representation) given two or more input images at known viewpoints. We apply this representation to single-view view synthesis, a problem which is more challenging but has potentially much wider application. Our method learns to predict a multiplane image directly from a single image input, and we introduce scale-invariant view synthesis for supervision, enabling us to train on online video. We show this approach is applicable to several different datasets, that it additionally generates reasonable depth maps, and that it learns to fill in content behind the edges of foreground objects in background layers.   Project page at https://single-view-mpi.github.io/.",
        "published": "2020-04-23T17:59:19Z",
        "link": "http://arxiv.org/abs/2004.11364v1",
        "categories": [
            "cs.CV",
            "cs.GR"
        ]
    },
    {
        "title": "Tales from the Trenches: Developing sciview, a new 3D viewer for the   ImageJ community",
        "authors": [
            "Ulrik Günther",
            "Kyle I. S. Harrington"
        ],
        "summary": "ImageJ/Fiji is a widely-used tool in the biomedical community for performing everyday image analysis tasks. However, its 3D viewer component (aptly named 3D Viewer) has become dated and is no longer actively maintained. We set out to create an alternative tool that not only brings modern concepts and APIs from computer graphics to ImageJ, but is designed to be robust to long-term, open-source development. To achieve this we divided the visualization logic into two parts: the rendering framework, scenery, and the user-facing application, sciview. In this paper we describe the development process and design decisions made, putting an emphasis on sustainable development, community building, and software engineering best practises. We highlight the motivation for the Java Virtual Machine (JVM) as a target platform for visualisation applications. We conclude by discussing the remaining milestones and strategy for long-term sustainability.",
        "published": "2020-04-23T18:49:55Z",
        "link": "http://arxiv.org/abs/2004.11897v1",
        "categories": [
            "cs.GR"
        ]
    },
    {
        "title": "Deep Feature-preserving Normal Estimation for Point Cloud Filtering",
        "authors": [
            "Dening Lu",
            "Xuequan Lu",
            "Yangxing Sun",
            "Jun Wang"
        ],
        "summary": "Point cloud filtering, the main bottleneck of which is removing noise (outliers) while preserving geometric features, is a fundamental problem in 3D field. The two-step schemes involving normal estimation and position update have been shown to produce promising results. Nevertheless, the current normal estimation methods including optimization ones and deep learning ones, often either have limited automation or cannot preserve sharp features. In this paper, we propose a novel feature-preserving normal estimation method for point cloud filtering with preserving geometric features. It is a learning method and thus achieves automatic prediction for normals. For training phase, we first generate patch based samples which are then fed to a classification network to classify feature and non-feature points. We finally train the samples of feature and non-feature points separately, to achieve decent results. Regarding testing, given a noisy point cloud, its normals can be automatically estimated. For further point cloud filtering, we iterate the above normal estimation and a current position update algorithm for a few times. Various experiments demonstrate that our method outperforms state-of-the-art normal estimation methods and point cloud filtering techniques, in terms of both quality and quantity.",
        "published": "2020-04-24T07:05:48Z",
        "link": "http://arxiv.org/abs/2004.11563v1",
        "categories": [
            "cs.GR",
            "cs.CV"
        ]
    },
    {
        "title": "Deep Photon Mapping",
        "authors": [
            "Shilin Zhu",
            "Zexiang Xu",
            "Henrik Wann Jensen",
            "Hao Su",
            "Ravi Ramamoorthi"
        ],
        "summary": "Recently, deep learning-based denoising approaches have led to dramatic improvements in low sample-count Monte Carlo rendering. These approaches are aimed at path tracing, which is not ideal for simulating challenging light transport effects like caustics, where photon mapping is the method of choice. However, photon mapping requires very large numbers of traced photons to achieve high-quality reconstructions. In this paper, we develop the first deep learning-based method for particle-based rendering, and specifically focus on photon density estimation, the core of all particle-based methods. We train a novel deep neural network to predict a kernel function to aggregate photon contributions at shading points. Our network encodes individual photons into per-photon features, aggregates them in the neighborhood of a shading point to construct a photon local context vector, and infers a kernel function from the per-photon and photon local context features. This network is easy to incorporate in many previous photon mapping methods (by simply swapping the kernel density estimator) and can produce high-quality reconstructions of complex global illumination effects like caustics with an order of magnitude fewer photons compared to previous photon mapping methods.",
        "published": "2020-04-25T06:59:10Z",
        "link": "http://arxiv.org/abs/2004.12069v1",
        "categories": [
            "cs.GR",
            "cs.LG"
        ]
    },
    {
        "title": "TRAKO: Efficient Transmission of Tractography Data for Visualization",
        "authors": [
            "Daniel Haehn",
            "Loraine Franke",
            "Fan Zhang",
            "Suheyla Cetin Karayumak",
            "Steve Pieper",
            "Lauren O'Donnell",
            "Yogesh Rathi"
        ],
        "summary": "Fiber tracking produces large tractography datasets that are tens of gigabytes in size consisting of millions of streamlines. Such vast amounts of data require formats that allow for efficient storage, transfer, and visualization. We present TRAKO, a new data format based on the Graphics Layer Transmission Format (glTF) that enables immediate graphical and hardware-accelerated processing. We integrate a state-of-the-art compression technique for vertices, streamlines, and attached scalar and property data. We then compare TRAKO to existing tractography storage methods and provide a detailed evaluation on eight datasets. TRAKO can achieve data reductions of over 28x without loss of statistical significance when used to replicate analysis from previously published studies.",
        "published": "2020-04-26T01:19:50Z",
        "link": "http://arxiv.org/abs/2004.13630v1",
        "categories": [
            "eess.IV",
            "cs.CV",
            "cs.GR",
            "q-bio.QM"
        ]
    },
    {
        "title": "MakeItTalk: Speaker-Aware Talking-Head Animation",
        "authors": [
            "Yang Zhou",
            "Xintong Han",
            "Eli Shechtman",
            "Jose Echevarria",
            "Evangelos Kalogerakis",
            "Dingzeyu Li"
        ],
        "summary": "We present a method that generates expressive talking heads from a single facial image with audio as the only input. In contrast to previous approaches that attempt to learn direct mappings from audio to raw pixels or points for creating talking faces, our method first disentangles the content and speaker information in the input audio signal. The audio content robustly controls the motion of lips and nearby facial regions, while the speaker information determines the specifics of facial expressions and the rest of the talking head dynamics. Another key component of our method is the prediction of facial landmarks reflecting speaker-aware dynamics. Based on this intermediate representation, our method is able to synthesize photorealistic videos of entire talking heads with full range of motion and also animate artistic paintings, sketches, 2D cartoon characters, Japanese mangas, stylized caricatures in a single unified framework. We present extensive quantitative and qualitative evaluation of our method, in addition to user studies, demonstrating generated talking heads of significantly higher quality compared to prior state-of-the-art.",
        "published": "2020-04-27T17:56:15Z",
        "link": "http://arxiv.org/abs/2004.12992v3",
        "categories": [
            "cs.CV",
            "cs.GR"
        ]
    },
    {
        "title": "Graph2Plan: Learning Floorplan Generation from Layout Graphs",
        "authors": [
            "Ruizhen Hu",
            "Zeyu Huang",
            "Yuhan Tang",
            "Oliver van Kaick",
            "Hao Zhang",
            "Hui Huang"
        ],
        "summary": "We introduce a learning framework for automated floorplan generation which combines generative modeling using deep neural networks and user-in-the-loop designs to enable human users to provide sparse design constraints. Such constraints are represented by a layout graph. The core component of our learning framework is a deep neural network, Graph2Plan, which converts a layout graph, along with a building boundary, into a floorplan that fulfills both the layout and boundary constraints. Given an input building boundary, we allow a user to specify room counts and other layout constraints, which are used to retrieve a set of floorplans, with their associated layout graphs, from a database. For each retrieved layout graph, along with the input boundary, Graph2Plan first generates a corresponding raster floorplan image, and then a refined set of boxes representing the rooms. Graph2Plan is trained on RPLAN, a large-scale dataset consisting of 80K annotated floorplans. The network is mainly based on convolutional processing over both the layout graph, via a graph neural network (GNN), and the input building boundary, as well as the raster floorplan images, via conventional image convolution.",
        "published": "2020-04-27T23:17:36Z",
        "link": "http://arxiv.org/abs/2004.13204v1",
        "categories": [
            "cs.CV",
            "cs.GR",
            "68T45, 68U05",
            "I.3.6; I.2.10"
        ]
    },
    {
        "title": "How the deprecation of Java applets affected online visualization   frameworks -- a case study",
        "authors": [
            "Martin Skrodzki"
        ],
        "summary": "The JavaView visualization framework was designed at the end of the 1990s as a software that provides - among other services - easy, interactive geometry visualizations on web pages. We discuss how this and other design goals were met and present several applications to highlight the contemporary use-cases of the framework. However, as JavaView's easy web exports was based on Java Applets, the deprecation of this technology disabled one main functionality of the software. The remainder of the article uses JavaView as an example to highlight the effects of changes in the underlying programming language on a visualization toolkit. We discuss possible reactions of software to such challenges, where the JavaView framework serves as an example to illustrate development decisions. These discussions are guided by the broader, underlying question as to how long it is sensible to maintain a software.",
        "published": "2020-04-28T02:51:55Z",
        "link": "http://arxiv.org/abs/2004.13254v2",
        "categories": [
            "cs.SE",
            "cs.GR"
        ]
    },
    {
        "title": "A framework for adaptive width control of dense contour-parallel   toolpaths in fused deposition modeling",
        "authors": [
            "Tim Kuipers",
            "Eugeni L. Doubrovski",
            "Jun Wu",
            "Charlie C. L. Wang"
        ],
        "summary": "3D printing techniques such as Fused Deposition Modeling (FDM) have enabled the fabrication of complex geometry quickly and cheaply. High stiffness parts are produced by filling the 2D polygons of consecutive layers with contour-parallel extrusion toolpaths. Uniform width toolpaths consisting of inward offsets from the outline polygons produce over- and underfill regions in the center of the shape, which are especially detrimental to the mechanical performance of thin parts. In order to fill shapes with arbitrary diameter densely the toolpaths require adaptive width. Existing approaches for generating toolpaths with adaptive width result in a large variation in widths, which for some hardware systems is difficult to realize accurately. In this paper we present a framework which supports multiple schemes to generate toolpaths with adaptive width, by employing a function to decide the number of beads and their widths. Furthermore, we propose a novel scheme which reduces extreme bead widths, while limiting the number of altered toolpaths. We statistically validate the effectiveness of our framework and this novel scheme on a data set of representative 3D models, and physically validate it by developing a technique, called back pressure compensation, for off-the-shelf FDM systems to effectively realize adaptive width.",
        "published": "2020-04-28T13:30:18Z",
        "link": "http://arxiv.org/abs/2004.13497v1",
        "categories": [
            "cs.GR",
            "cs.RO",
            "cs.SY",
            "eess.SY",
            "J.6"
        ]
    },
    {
        "title": "A First Principles Approach for Data-Efficient System Identification of   Spring-Rod Systems via Differentiable Physics Engines",
        "authors": [
            "Kun Wang",
            "Mridul Aanjaneya",
            "Kostas Bekris"
        ],
        "summary": "We propose a novel differentiable physics engine for system identification of complex spring-rod assemblies. Unlike black-box data-driven methods for learning the evolution of a dynamical system and its parameters, we modularize the design of our engine using a discrete form of the governing equations of motion, similar to a traditional physics engine. We further reduce the dimension from 3D to 1D for each module, which allows efficient learning of system parameters using linear regression. As a side benefit, the regression parameters correspond to physical quantities, such as spring stiffness or the mass of the rod, making the pipeline explainable. The approach significantly reduces the amount of training data required, and also avoids iterative identification of data sampling and model training. We compare the performance of the proposed engine with previous solutions, and demonstrate its efficacy on tensegrity systems, such as NASA's icosahedron.",
        "published": "2020-04-28T21:37:55Z",
        "link": "http://arxiv.org/abs/2004.13859v1",
        "categories": [
            "cs.RO",
            "cs.GR",
            "cs.LG"
        ]
    },
    {
        "title": "Visualization of Unsteady Flow Using Heat Kernel Signatures",
        "authors": [
            "Kairong Jiang",
            "Matthew Berger",
            "Joshua A. Levine"
        ],
        "summary": "We introduce a new technique to visualize complex flowing phenomena by using concepts from shape analysis. Our approach uses techniques that examine the intrinsic geometry of manifolds through their heat kernel, to obtain representations of such manifolds that are isometry-invariant and multi-scale. These representations permit us to compute heat kernel signatures of each point on that manifold, and we can use these signatures as features for classification and segmentation that identify points that have similar structural properties.   Our approach adapts heat kernel signatures to unsteady flows by formulating a notion of shape where pathlines are observations of a manifold living in a high-dimensional space.   We use this space to compute and visualize heat kernel signatures associated with each pathline.   Besides being able to capture the structural features of a pathline, heat kernel signatures allow the comparison of pathlines from different flow datasets through a shape matching pipeline. We demonstrate the analytic power of heat kernel signatures by comparing both (1) different timesteps from the same unsteady flow as well as (2) flow datasets taken from ensemble simulations with varying simulation parameters. Our analysis only requires the pathlines themselves, and thus it does not utilize the underlying vector field directly. We make minimal assumptions on the pathlines: while we assume they are sampled from a continuous, unsteady flow, our computations can tolerate pathlines that have varying density and potential unknown boundaries. We evaluate our approach through visualizations of a variety of two-dimensional unsteady flows.",
        "published": "2020-04-28T23:27:59Z",
        "link": "http://arxiv.org/abs/2004.14381v1",
        "categories": [
            "cs.GR"
        ]
    },
    {
        "title": "Organic Narrative Charts",
        "authors": [
            "Fabian Bolte",
            "Stefan Bruckner"
        ],
        "summary": "Storyline visualizations display the interactions of groups and entities and their development over time. Existing approaches have successfully adopted the general layout from hand-drawn illustrations to automatically create similar depictions. Ward Shelley is the author of several diagrammatic paintings that show the timeline of art-related subjects, such as Downtown Body, a history of art scenes. His drawings include many stylistic elements that are not covered by existing storyline visualizations, like links between entities, splits and merges of streams, and tags or labels to describe the individual elements. We present a visualization method that provides a visual mapping for the complex relationships in the data, creates a layout for their display, and adopts a similar styling of elements to imitate the artistic appeal of such illustrations. We compare our results to the original drawings and provide an open-source authoring tool prototype.",
        "published": "2020-04-29T00:08:13Z",
        "link": "http://arxiv.org/abs/2004.13896v1",
        "categories": [
            "cs.GR"
        ]
    },
    {
        "title": "Image Morphing with Perceptual Constraints and STN Alignment",
        "authors": [
            "Noa Fish",
            "Richard Zhang",
            "Lilach Perry",
            "Daniel Cohen-Or",
            "Eli Shechtman",
            "Connelly Barnes"
        ],
        "summary": "In image morphing, a sequence of plausible frames are synthesized and composited together to form a smooth transformation between given instances. Intermediates must remain faithful to the input, stand on their own as members of the set, and maintain a well-paced visual transition from one to the next. In this paper, we propose a conditional GAN morphing framework operating on a pair of input images. The network is trained to synthesize frames corresponding to temporal samples along the transformation, and learns a proper shape prior that enhances the plausibility of intermediate frames. While individual frame plausibility is boosted by the adversarial setup, a special training protocol producing sequences of frames, combined with a perceptual similarity loss, promote smooth transformation over time. Explicit stating of correspondences is replaced with a grid-based freeform deformation spatial transformer that predicts the geometric warp between the inputs, instituting the smooth geometric effect by bringing the shapes into an initial alignment. We provide comparisons to classic as well as latent space morphing techniques, and demonstrate that, given a set of images for self-supervision, our network learns to generate visually pleasing morphing effects featuring believable in-betweens, with robustness to changes in shape and texture, requiring no correspondence annotation.",
        "published": "2020-04-29T10:49:10Z",
        "link": "http://arxiv.org/abs/2004.14071v1",
        "categories": [
            "cs.GR",
            "cs.CV",
            "cs.LG",
            "I.3.3"
        ]
    },
    {
        "title": "Informative Scene Decomposition for Crowd Analysis, Comparison and   Simulation Guidance",
        "authors": [
            "Feixiang He",
            "Yuanhang Xiang",
            "Xi Zhao",
            "He Wang"
        ],
        "summary": "Crowd simulation is a central topic in several fields including graphics. To achieve high-fidelity simulations, data has been increasingly relied upon for analysis and simulation guidance. However, the information in real-world data is often noisy, mixed and unstructured, making it difficult for effective analysis, therefore has not been fully utilized. With the fast-growing volume of crowd data, such a bottleneck needs to be addressed. In this paper, we propose a new framework which comprehensively tackles this problem. It centers at an unsupervised method for analysis. The method takes as input raw and noisy data with highly mixed multi-dimensional (space, time and dynamics) information, and automatically structure it by learning the correlations among these dimensions. The dimensions together with their correlations fully describe the scene semantics which consists of recurring activity patterns in a scene, manifested as space flows with temporal and dynamics profiles. The effectiveness and robustness of the analysis have been tested on datasets with great variations in volume, duration, environment and crowd dynamics. Based on the analysis, new methods for data visualization, simulation evaluation and simulation guidance are also proposed. Together, our framework establishes a highly automated pipeline from raw data to crowd analysis, comparison and simulation guidance. Extensive experiments and evaluations have been conducted to show the flexibility, versatility and intuitiveness of our framework.",
        "published": "2020-04-29T12:03:32Z",
        "link": "http://arxiv.org/abs/2004.14107v1",
        "categories": [
            "cs.GR",
            "cs.CV",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Augmented Semantic Signatures of Airborne LiDAR Point Clouds for   Comparison",
        "authors": [
            "Jaya Sreevalsan-Nair",
            "Pragyan Mohapatra"
        ],
        "summary": "LiDAR point clouds provide rich geometric information, which is particularly useful for the analysis of complex scenes of urban regions. Finding structural and semantic differences between two different three-dimensional point clouds, say, of the same region but acquired at different time instances is an important problem. A comparison of point clouds involves computationally expensive registration and segmentation. We are interested in capturing the relative differences in the geometric uncertainty and semantic content of the point cloud without the registration process. Hence, we propose an orientation-invariant geometric signature of the point cloud, which integrates its probabilistic geometric and semantic classifications. We study different properties of the geometric signature, which are an image-based encoding of geometric uncertainty and semantic content. We explore different metrics to determine differences between these signatures, which in turn compare point clouds without performing point-to-point registration. Our results show that the differences in the signatures corroborate with the geometric and semantic differences of the point clouds.",
        "published": "2020-04-29T15:27:07Z",
        "link": "http://arxiv.org/abs/2005.02152v2",
        "categories": [
            "cs.CV",
            "cs.GR",
            "eess.IV",
            "68U05, 68U10, 68U20, 65C50",
            "G.1.3; I.4.10; I.4.8; J.2"
        ]
    },
    {
        "title": "Interactive Video Stylization Using Few-Shot Patch-Based Training",
        "authors": [
            "Ondřej Texler",
            "David Futschik",
            "Michal Kučera",
            "Ondřej Jamriška",
            "Šárka Sochorová",
            "Menglei Chai",
            "Sergey Tulyakov",
            "Daniel Sýkora"
        ],
        "summary": "In this paper, we present a learning-based method to the keyframe-based video stylization that allows an artist to propagate the style from a few selected keyframes to the rest of the sequence. Its key advantage is that the resulting stylization is semantically meaningful, i.e., specific parts of moving objects are stylized according to the artist's intention. In contrast to previous style transfer techniques, our approach does not require any lengthy pre-training process nor a large training dataset. We demonstrate how to train an appearance translation network from scratch using only a few stylized exemplars while implicitly preserving temporal consistency. This leads to a video stylization framework that supports real-time inference, parallel processing, and random access to an arbitrary output frame. It can also merge the content from multiple keyframes without the need to perform an explicit blending operation. We demonstrate its practical utility in various interactive scenarios, where the user paints over a selected keyframe and sees her style transferred to an existing recorded sequence or a live video stream.",
        "published": "2020-04-29T21:33:28Z",
        "link": "http://arxiv.org/abs/2004.14489v1",
        "categories": [
            "cs.GR",
            "cs.CV"
        ]
    },
    {
        "title": "Real-World Textured Things: a Repository of Textured Models Generated   with Modern Photo-Reconstruction Tools",
        "authors": [
            "Andrea Maggiordomo",
            "Federico Ponchio",
            "Paolo Cignoni",
            "Marco Tarini"
        ],
        "summary": "We are witnessing a proliferation of textured 3D models captured from the real world with automatic photo-reconstruction tools. Digital 3D models of this class come with a unique set of characteristics and defects -- especially concerning their parametrization -- setting them starkly apart from 3D models originating from other, more traditional, sources. We study this class of 3D models by collecting a significant number of representatives and quantitatively evaluating their quality according to several metrics. These include a new invariant metric we design to assess the fragmentation of the UV map, one of the main weaknesses hindering the usability of these models. Our results back the widely shared notion that such models are not fit for direct use in downstream applications (such as videogames), and require challenging processing steps. Regrettably, existing automatic geometry processing tools are not always up to the task: for example, we verify that available tools for UV optimization often fail due mesh inconsistencies, geometric and topological noise, excessive resolution, or other factors; moreover, even when an output is produced, it is rarely a significant improvement over the input (according to the aforementioned measures). Therefore, we argue that further advancements are required specifically targeted at this class of models. Towards this goal, we share the models we collected in the form of a new public repository, Real-World Textured Things (RWTT), a benchmark to systematic field-test and compare algorithms. RWTT consists of 568 carefully selected textured 3D models representative of all the main modern off-the-shelf photo-reconstruction tools. The repository is available at http://texturedmesh.isti.cnr.it/ and is browsable by metadata collected during experiments, and comes with a tool, TexMetro, providing the same set of measures for generic UV mapped datasets.",
        "published": "2020-04-30T13:20:14Z",
        "link": "http://arxiv.org/abs/2004.14753v1",
        "categories": [
            "cs.GR"
        ]
    },
    {
        "title": "Levitating Rigid Objects with Hidden Rods and Wires",
        "authors": [
            "Sarah Kushner",
            "Risa Ulinski",
            "Karan Singh",
            "David I. W. Levin",
            "Alec Jacobson"
        ],
        "summary": "We propose a novel algorithm to efficiently generate hidden structures to support arrangements of floating rigid objects. Our optimization finds a small set of rods and wires between objects and each other or a supporting surface (e.g., wall or ceiling) that hold all objects in force and torque equilibrium. Our objective function includes a sparsity inducing total volume term and a linear visibility term based on efficiently pre-computed Monte-Carlo integration, to encourage solutions that are as-hidden-as-possible. The resulting optimization is convex and the global optimum can be efficiently recovered via a linear program. Our representation allows for a user-controllable mixture of tension-, compression-, and shear-resistant rods or tension-only wires. We explore applications to theatre set design, museum exhibit curation, and other artistic endeavours.",
        "published": "2020-04-30T19:48:57Z",
        "link": "http://arxiv.org/abs/2005.00074v2",
        "categories": [
            "cs.GR"
        ]
    },
    {
        "title": "Interactive Geometry Modification of High Performance Finite Element   Simulations",
        "authors": [
            "Corey Wetterer-Nelson",
            "Kenneth E. Jansen",
            "John A. Evans"
        ],
        "summary": "In the context of high performance finite element analysis, the cost of iteratively modifying a computational domain via re-meshing and restarting the analysis becomes time prohibitive as the size of simulations increases. In this paper, we demonstrate a new interactive simulation pipeline targeting high performance finite element simulations where the computational domain is modifiable in situ, that is, while the simulation is ongoing. This pipeline is designed to be modular so that it may interface with any existing finite element simulation framework. A server-client architecture is employed to manage simulation mesh data existing on a high performance computing resource while user-prescribed freeform geometric modifications take place on a separate workstation. We employ existing in situ visualization techniques to rapidly inform the user of simulation progression, enabling computational steering. By expressing the simulation domain in a reduced fashion on the client application, this pipeline manages highly refined finite element simulation domains on the server while maintaining good performance on the client application.",
        "published": "2020-05-01T03:53:26Z",
        "link": "http://arxiv.org/abs/2005.00202v2",
        "categories": [
            "cs.CE",
            "cs.GR"
        ]
    },
    {
        "title": "Bionic Tracking: Using Eye Tracking to Track Biological Cells in Virtual   Reality",
        "authors": [
            "Ulrik Günther",
            "Kyle I. S. Harrington",
            "Raimund Dachselt",
            "Ivo F. Sbalzarini"
        ],
        "summary": "We present Bionic Tracking, a novel method for solving biological cell tracking problems with eye tracking in virtual reality using commodity hardware. Using gaze data, and especially smooth pursuit eye movements, we are able to track cells in time series of 3D volumetric datasets. The problem of tracking cells is ubiquitous in developmental biology, where large volumetric microscopy datasets are acquired on a daily basis, often comprising hundreds or thousands of time points that span hours or days. The image data, however, is only a means to an end, and scientists are often interested in the reconstruction of cell trajectories and cell lineage trees. Reliably tracking cells in crowded three-dimensional space over many timepoints remains an open problem, and many current approaches rely on tedious manual annotation and curation. In our Bionic Tracking approach, we substitute the usual 2D point-and-click annotation to track cells with eye tracking in a virtual reality headset, where users simply have to follow a cell with their eyes in 3D space in order to track it. We detail the interaction design of our approach and explain the graph-based algorithm used to connect different time points, also taking occlusion and user distraction into account. We demonstrate our cell tracking method using the example of two different biological datasets. Finally, we report on a user study with seven cell tracking experts, demonstrating the benefits of our approach over manual point-and-click tracking.",
        "published": "2020-05-01T14:08:40Z",
        "link": "http://arxiv.org/abs/2005.00387v2",
        "categories": [
            "cs.HC",
            "cs.GR"
        ]
    },
    {
        "title": "Code Replicability in Computer Graphics",
        "authors": [
            "Nicolas Bonneel",
            "David Coeurjolly",
            "Julie Digne",
            "Nicolas Mellado"
        ],
        "summary": "Being able to duplicate published research results is an important process of conducting research whether to build upon these findings or to compare with them. This process is called \"replicability\" when using the original authors' artifacts (e.g., code), or \"reproducibility\" otherwise (e.g., re-implementing algorithms). Reproducibility and replicability of research results have gained a lot of interest recently with assessment studies being led in various fields, and they are often seen as a trigger for better result diffusion and transparency. In this work, we assess replicability in Computer Graphics, by evaluating whether the code is available and whether it works properly. As a proxy for this field we compiled, ran and analyzed 151 codes out of 374 papers from 2014, 2016 and 2018 SIGGRAPH conferences. This analysis shows a clear increase in the number of papers with available and operational research codes with a dependency on the subfields, and indicates a correlation between code replicability and citation count. We further provide an interactive tool to explore our results and evaluation data.",
        "published": "2020-05-01T18:03:13Z",
        "link": "http://arxiv.org/abs/2005.00554v2",
        "categories": [
            "cs.DL",
            "cs.GR"
        ]
    },
    {
        "title": "RigNet: Neural Rigging for Articulated Characters",
        "authors": [
            "Zhan Xu",
            "Yang Zhou",
            "Evangelos Kalogerakis",
            "Chris Landreth",
            "Karan Singh"
        ],
        "summary": "We present RigNet, an end-to-end automated method for producing animation rigs from input character models. Given an input 3D model representing an articulated character, RigNet predicts a skeleton that matches the animator expectations in joint placement and topology. It also estimates surface skin weights based on the predicted skeleton. Our method is based on a deep architecture that directly operates on the mesh representation without making assumptions on shape class and structure. The architecture is trained on a large and diverse collection of rigged models, including their mesh, skeletons and corresponding skin weights. Our evaluation is three-fold: we show better results than prior art when quantitatively compared to animator rigs; qualitatively we show that our rigs can be expressively posed and animated at multiple levels of detail; and finally, we evaluate the impact of various algorithm choices on our output rigs.",
        "published": "2020-05-01T18:12:44Z",
        "link": "http://arxiv.org/abs/2005.00559v2",
        "categories": [
            "cs.GR",
            "cs.CV"
        ]
    },
    {
        "title": "AR-Therapist: Design and Simulation of an AR-Game Environment as a CBT   for Patients with ADHD",
        "authors": [
            "Saad Alqithami",
            "Musaad Alzahrani",
            "Abdulkareem Alzahrani",
            "Ahmed Mustafa"
        ],
        "summary": "Attention Deficit Hyperactivity Disorder is one of the most common neurodevelopmental disorders in which patients have difficulties related to inattention, hyperactivity, and impulsivity. Those patients are in need of a psychological therapy use Cognitive Behavioral Therapy (CBT) to enhance the way they think and behave. This type of therapy is mostly common in treating patients with anxiety and depression but also is useful in treating autism, obsessive compulsive disorder and post-traumatic stress disorder. A major limitation of traditional CBT is that therapists may face difficulty in optimizing patients' neuropsychological stimulus following a specified treatment plan. Other limitations include availability, accessibility and level-of-experience of the therapists. Hence, this paper aims to design and simulate a generic cognitive model that can be used as an appropriate alternative treatment to traditional CBT, we term as \"AR-Therapist.\" This model takes advantage of the current developments of augmented reality to engage patients in both real and virtual game-based environments.",
        "published": "2020-05-01T22:51:25Z",
        "link": "http://arxiv.org/abs/2005.02189v1",
        "categories": [
            "cs.HC",
            "cs.GR",
            "J.4; I.2.1; J.3"
        ]
    },
    {
        "title": "Lagrangian Neural Style Transfer for Fluids",
        "authors": [
            "Byungsoo Kim",
            "Vinicius C. Azevedo",
            "Markus Gross",
            "Barbara Solenthaler"
        ],
        "summary": "Artistically controlling the shape, motion and appearance of fluid simulations pose major challenges in visual effects production. In this paper, we present a neural style transfer approach from images to 3D fluids formulated in a Lagrangian viewpoint. Using particles for style transfer has unique benefits compared to grid-based techniques. Attributes are stored on the particles and hence are trivially transported by the particle motion. This intrinsically ensures temporal consistency of the optimized stylized structure and notably improves the resulting quality. Simultaneously, the expensive, recursive alignment of stylization velocity fields of grid approaches is unnecessary, reducing the computation time to less than an hour and rendering neural flow stylization practical in production settings. Moreover, the Lagrangian representation improves artistic control as it allows for multi-fluid stylization and consistent color transfer from images, and the generality of the method enables stylization of smoke and liquids likewise.",
        "published": "2020-05-02T11:53:05Z",
        "link": "http://arxiv.org/abs/2005.00803v1",
        "categories": [
            "cs.GR",
            "cs.LG"
        ]
    },
    {
        "title": "An Information-theoretic Visual Analysis Framework for Convolutional   Neural Networks",
        "authors": [
            "Jingyi Shen",
            "Han-Wei Shen"
        ],
        "summary": "Despite the great success of Convolutional Neural Networks (CNNs) in Computer Vision and Natural Language Processing, the working mechanism behind CNNs is still under extensive discussions and research. Driven by a strong demand for the theoretical explanation of neural networks, some researchers utilize information theory to provide insight into the black box model. However, to the best of our knowledge, employing information theory to quantitatively analyze and qualitatively visualize neural networks has not been extensively studied in the visualization community. In this paper, we combine information entropies and visualization techniques to shed light on how CNN works. Specifically, we first introduce a data model to organize the data that can be extracted from CNN models. Then we propose two ways to calculate entropy under different circumstances. To provide a fundamental understanding of the basic building blocks of CNNs (e.g., convolutional layers, pooling layers, normalization layers) from an information-theoretic perspective, we develop a visual analysis system, CNNSlicer. CNNSlicer allows users to interactively explore the amount of information changes inside the model. With case studies on the widely used benchmark datasets (MNIST and CIFAR-10), we demonstrate the effectiveness of our system in opening the blackbox of CNNs.",
        "published": "2020-05-02T21:36:50Z",
        "link": "http://arxiv.org/abs/2005.02186v1",
        "categories": [
            "cs.CV",
            "cs.GR"
        ]
    },
    {
        "title": "Variational Shape Approximation of Point Set Surfaces",
        "authors": [
            "Martin Skrodzki",
            "Eric Zimmermann",
            "Konrad Polthier"
        ],
        "summary": "In this work, we present a translation of the complete pipeline for variational shape approximation (VSA) to the setting of point sets. First, we describe an explicit example for the theoretically known non-convergence of the currently available VSA approaches. The example motivates us to introduce an alternate version of VSA based on a switch operation for which we prove convergence. Second, we discuss how two operations - split and merge - can be included in a fully automatic pipeline that is in turn independent of the placement and number of initial seeds. Third and finally, we present two approaches how to obtain a simplified mesh from the output of the VSA procedure. This simplification is either based on simple plane intersection or based on a variational optimization problem. Several qualitative and quantitative results prove the relevance of our approach.",
        "published": "2020-05-03T06:44:27Z",
        "link": "http://arxiv.org/abs/2005.01003v2",
        "categories": [
            "cs.GR",
            "cs.CG",
            "68U05, 68U07, 65D18"
        ]
    },
    {
        "title": "Neural Subdivision",
        "authors": [
            "Hsueh-Ti Derek Liu",
            "Vladimir G. Kim",
            "Siddhartha Chaudhuri",
            "Noam Aigerman",
            "Alec Jacobson"
        ],
        "summary": "This paper introduces Neural Subdivision, a novel framework for data-driven coarse-to-fine geometry modeling. During inference, our method takes a coarse triangle mesh as input and recursively subdivides it to a finer geometry by applying the fixed topological updates of Loop Subdivision, but predicting vertex positions using a neural network conditioned on the local geometry of a patch. This approach enables us to learn complex non-linear subdivision schemes, beyond simple linear averaging used in classical techniques. One of our key contributions is a novel self-supervised training setup that only requires a set of high-resolution meshes for learning network weights. For any training shape, we stochastically generate diverse low-resolution discretizations of coarse counterparts, while maintaining a bijective mapping that prescribes the exact target position of every new vertex during the subdivision process. This leads to a very efficient and accurate loss function for conditional mesh generation, and enables us to train a method that generalizes across discretizations and favors preserving the manifold structure of the output. During training we optimize for the same set of network weights across all local mesh patches, thus providing an architecture that is not constrained to a specific input mesh, fixed genus, or category. Our network encodes patch geometry in a local frame in a rotation- and translation-invariant manner. Jointly, these design choices enable our method to generalize well, and we demonstrate that even when trained on a single high-resolution mesh our method generates reasonable subdivisions for novel shapes.",
        "published": "2020-05-04T20:03:21Z",
        "link": "http://arxiv.org/abs/2005.01819v1",
        "categories": [
            "cs.GR",
            "cs.LG"
        ]
    },
    {
        "title": "Illumination-Invariant Image from 4-Channel Images: The Effect of   Near-Infrared Data in Shadow Removal",
        "authors": [
            "Sorour Mohajerani",
            "Mark S. Drew",
            "Parvaneh Saeedi"
        ],
        "summary": "Removing the effect of illumination variation in images has been proved to be beneficial in many computer vision applications such as object recognition and semantic segmentation. Although generating illumination-invariant images has been studied in the literature before, it has not been investigated on real 4-channel (4D) data. In this study, we examine the quality of illumination-invariant images generated from red, green, blue, and near-infrared (RGBN) data. Our experiments show that the near-infrared channel substantively contributes toward removing illumination. As shown in our numerical and visual results, the illumination-invariant image obtained by RGBN data is superior compared to that obtained by RGB alone.",
        "published": "2020-05-04T22:51:36Z",
        "link": "http://arxiv.org/abs/2005.01878v1",
        "categories": [
            "cs.CV",
            "cs.GR"
        ]
    },
    {
        "title": "Overview of Surgical Simulation",
        "authors": [
            "Mohamed A. ElHelw"
        ],
        "summary": "Motivated by the current demand of clinical governance, surgical simulation is now a well-established modality for basic skills training and assessment. The practical deployment of the technique is a multi-disciplinary venture encompassing areas in engineering, medicine and psychology. This paper provides an overview of the key topics involved in surgical simulation and associated technical challenges. The paper discusses the clinical motivation for surgical simulation, the use of virtual environments for surgical training, model acquisition and simplification, deformable models, collision detection, tissue property measurement, haptic rendering and image synthesis. Additional topics include surgical skill training and assessment metrics as well as challenges facing the incorporation of surgical simulation into medical education curricula.",
        "published": "2020-05-06T11:51:31Z",
        "link": "http://arxiv.org/abs/2005.03011v1",
        "categories": [
            "cs.HC",
            "cs.GR",
            "I.6.3; I.6.8"
        ]
    },
    {
        "title": "CARL: Controllable Agent with Reinforcement Learning for Quadruped   Locomotion",
        "authors": [
            "Ying-Sheng Luo",
            "Jonathan Hans Soeseno",
            "Trista Pei-Chun Chen",
            "Wei-Chao Chen"
        ],
        "summary": "Motion synthesis in a dynamic environment has been a long-standing problem for character animation. Methods using motion capture data tend to scale poorly in complex environments because of their larger capturing and labeling requirement. Physics-based controllers are effective in this regard, albeit less controllable. In this paper, we present CARL, a quadruped agent that can be controlled with high-level directives and react naturally to dynamic environments. Starting with an agent that can imitate individual animation clips, we use Generative Adversarial Networks to adapt high-level controls, such as speed and heading, to action distributions that correspond to the original animations. Further fine-tuning through the deep reinforcement learning enables the agent to recover from unseen external perturbations while producing smooth transitions. It then becomes straightforward to create autonomous agents in dynamic environments by adding navigation modules over the entire process. We evaluate our approach by measuring the agent's ability to follow user control and provide a visual analysis of the generated motion to show its effectiveness.",
        "published": "2020-05-07T07:18:57Z",
        "link": "http://arxiv.org/abs/2005.03288v3",
        "categories": [
            "cs.LG",
            "cs.GR",
            "stat.ML"
        ]
    },
    {
        "title": "Vid2Curve: Simultaneous Camera Motion Estimation and Thin Structure   Reconstruction from an RGB Video",
        "authors": [
            "Peng Wang",
            "Lingjie Liu",
            "Nenglun Chen",
            "Hung-Kuo Chu",
            "Christian Theobalt",
            "Wenping Wang"
        ],
        "summary": "Thin structures, such as wire-frame sculptures, fences, cables, power lines, and tree branches, are common in the real world. It is extremely challenging to acquire their 3D digital models using traditional image-based or depth-based reconstruction methods because thin structures often lack distinct point features and have severe self-occlusion. We propose the first approach that simultaneously estimates camera motion and reconstructs the geometry of complex 3D thin structures in high quality from a color video captured by a handheld camera. Specifically, we present a new curve-based approach to estimate accurate camera poses by establishing correspondences between featureless thin objects in the foreground in consecutive video frames, without requiring visual texture in the background scene to lock on. Enabled by this effective curve-based camera pose estimation strategy, we develop an iterative optimization method with tailored measures on geometry, topology as well as self-occlusion handling for reconstructing 3D thin structures. Extensive validations on a variety of thin structures show that our method achieves accurate camera pose estimation and faithful reconstruction of 3D thin structures with complex shape and topology at a level that has not been attained by other existing reconstruction methods.",
        "published": "2020-05-07T10:39:20Z",
        "link": "http://arxiv.org/abs/2005.03372v3",
        "categories": [
            "cs.GR",
            "cs.CV",
            "eess.IV"
        ]
    },
    {
        "title": "Fast Automatic Visibility Optimization for Thermal Synthetic Aperture   Visualization",
        "authors": [
            "Indrajit Kurmi",
            "David C. Schedl",
            "Oliver Bimber"
        ],
        "summary": "In this article, we describe and validate the first fully automatic parameter optimization for thermal synthetic aperture visualization. It replaces previous manual exploration of the parameter space, which is time consuming and error prone. We prove that the visibility of targets in thermal integral images is proportional to the variance of the targets' image. Since this is invariant to occlusion it represents a suitable objective function for optimization. Our findings have the potential to enable fully autonomous search and recuse operations with camera drones.",
        "published": "2020-05-08T14:28:03Z",
        "link": "http://arxiv.org/abs/2005.04065v1",
        "categories": [
            "cs.CV",
            "cs.GR"
        ]
    },
    {
        "title": "Sequential Gallery for Interactive Visual Design Optimization",
        "authors": [
            "Yuki Koyama",
            "Issei Sato",
            "Masataka Goto"
        ],
        "summary": "Visual design tasks often involve tuning many design parameters. For example, color grading of a photograph involves many parameters, some of which non-expert users might be unfamiliar with. We propose a novel user-in-the-loop optimization method that allows users to efficiently find an appropriate parameter set by exploring such a high-dimensional design space through much easier two-dimensional search subtasks. This method, called sequential plane search, is based on Bayesian optimization to keep necessary queries to users as few as possible. To help users respond to plane-search queries, we also propose using a gallery-based interface that provides options in the two-dimensional subspace arranged in an adaptive grid view. We call this interactive framework Sequential Gallery since users sequentially select the best option from the options provided by the interface. Our experiment with synthetic functions shows that our sequential plane search can find satisfactory solutions in fewer iterations than baselines. We also conducted a preliminary user study, results of which suggest that novices can effectively complete search tasks with Sequential Gallery in a photo-enhancement scenario.",
        "published": "2020-05-08T15:24:35Z",
        "link": "http://arxiv.org/abs/2005.04107v1",
        "categories": [
            "cs.GR",
            "cs.HC",
            "cs.LG"
        ]
    },
    {
        "title": "ALLSTEPS: Curriculum-driven Learning of Stepping Stone Skills",
        "authors": [
            "Zhaoming Xie",
            "Hung Yu Ling",
            "Nam Hee Kim",
            "Michiel van de Panne"
        ],
        "summary": "Humans are highly adept at walking in environments with foot placement constraints, including stepping-stone scenarios where the footstep locations are fully constrained. Finding good solutions to stepping-stone locomotion is a longstanding and fundamental challenge for animation and robotics. We present fully learned solutions to this difficult problem using reinforcement learning. We demonstrate the importance of a curriculum for efficient learning and evaluate four possible curriculum choices compared to a non-curriculum baseline. Results are presented for a simulated human character, a realistic bipedal robot simulation and a monster character, in each case producing robust, plausible motions for challenging stepping stone sequences and terrains.",
        "published": "2020-05-09T00:16:38Z",
        "link": "http://arxiv.org/abs/2005.04323v2",
        "categories": [
            "cs.GR",
            "cs.LG",
            "cs.RO"
        ]
    },
    {
        "title": "FAME: 3D Shape Generation via Functionality-Aware Model Evolution",
        "authors": [
            "Yanran Guan",
            "Han Liu",
            "Kun Liu",
            "Kangxue Yin",
            "Ruizhen Hu",
            "Oliver van Kaick",
            "Yan Zhang",
            "Ersin Yumer",
            "Nathan Carr",
            "Radomir Mech",
            "Hao Zhang"
        ],
        "summary": "We introduce a modeling tool which can evolve a set of 3D objects in a functionality-aware manner. Our goal is for the evolution to generate large and diverse sets of plausible 3D objects for data augmentation, constrained modeling, as well as open-ended exploration to possibly inspire new designs. Starting with an initial population of 3D objects belonging to one or more functional categories, we evolve the shapes through part recombination to produce generations of hybrids or crossbreeds between parents from the heterogeneous shape collection. Evolutionary selection of offsprings is guided both by a functional plausibility score derived from functionality analysis of shapes in the initial population and user preference, as in a design gallery. Since cross-category hybridization may result in offsprings not belonging to any of the known functional categories, we develop a means for functionality partial matching to evaluate functional plausibility on partial shapes. We show a variety of plausible hybrid shapes generated by our functionality-aware model evolution, which can complement existing datasets as training data and boost the performance of contemporary data-driven segmentation schemes, especially in challenging cases. Our tool supports constrained modeling, allowing users to restrict or steer the model evolution with functionality labels. At the same time, unexpected yet functional object prototypes can emerge during open-ended exploration owing to structure breaking when evolving a heterogeneous collection.",
        "published": "2020-05-09T15:30:28Z",
        "link": "http://arxiv.org/abs/2005.04464v3",
        "categories": [
            "cs.GR"
        ]
    },
    {
        "title": "Design and visualization of Riemannian metrics",
        "authors": [
            "Tiago Novello",
            "Vinícius da Silva",
            "Luiz Velho"
        ],
        "summary": "Local and global illumination were recently defined in Riemannian manifolds to visualize classical Non-Euclidean spaces. This work focuses on Riemannian metric construction in $\\mathbb{R}^3$ to explore special effects like warping, mirages, and deformations. We investigate the possibility of using graphs of functions and diffeomorphism to produce such effects. For these, their Riemannian metrics and geodesics derivations are provided, and ways of accumulating such metrics. We visualize, in \"real-time\", the resulting Riemannian manifolds using a ray tracing implemented on top of Nvidia RTX GPUs.",
        "published": "2020-05-11T19:07:55Z",
        "link": "http://arxiv.org/abs/2005.05386v1",
        "categories": [
            "cs.GR"
        ]
    },
    {
        "title": "A Survey on Patch-based Synthesis: GPU Implementation and Optimization",
        "authors": [
            "Hadi Abdi Khojasteh"
        ],
        "summary": "This thesis surveys the research in patch-based synthesis and algorithms for finding correspondences between small local regions of images. We additionally explore a large kind of applications of this new fast randomized matching technique. One of the algorithms we have studied in particular is PatchMatch, can find similar regions or \"patches\" of an image one to two orders of magnitude faster than previous techniques. The algorithmic program is driven by applying mathematical properties of nearest neighbors in natural images. It is observed that neighboring correspondences tend to be similar or \"coherent\" and use this observation in algorithm in order to quickly converge to an approximate solution. The algorithm is the most general form can find k-nearest neighbor matching, using patches that translate, rotate, or scale, using arbitrary descriptors, and between two or more images. Speed-ups are obtained over various techniques in an exceeding range of those areas. We have explored many applications of PatchMatch matching algorithm. In computer graphics, we have explored removing unwanted objects from images, seamlessly moving objects in images, changing image aspect ratios, and video summarization. In computer vision we have explored denoising images, object detection, detecting image forgeries, and detecting symmetries. We conclude by discussing the restrictions of our algorithmic program, GPU implementation and areas for future analysis.",
        "published": "2020-05-11T19:25:28Z",
        "link": "http://arxiv.org/abs/2005.06278v1",
        "categories": [
            "cs.GR",
            "cs.CV",
            "eess.IV",
            "A.1; I.3.2; I.3.3; I.3.4; I.3.8; I.2.6; I.2.8; I.2.10; H.5.1; I.5.1;\n  I.5.4; I.5.5; J.5"
        ]
    },
    {
        "title": "Skeleton-Aware Networks for Deep Motion Retargeting",
        "authors": [
            "Kfir Aberman",
            "Peizhuo Li",
            "Dani Lischinski",
            "Olga Sorkine-Hornung",
            "Daniel Cohen-Or",
            "Baoquan Chen"
        ],
        "summary": "We introduce a novel deep learning framework for data-driven motion retargeting between skeletons, which may have different structure, yet corresponding to homeomorphic graphs. Importantly, our approach learns how to retarget without requiring any explicit pairing between the motions in the training set. We leverage the fact that different homeomorphic skeletons may be reduced to a common primal skeleton by a sequence of edge merging operations, which we refer to as skeletal pooling. Thus, our main technical contribution is the introduction of novel differentiable convolution, pooling, and unpooling operators. These operators are skeleton-aware, meaning that they explicitly account for the skeleton's hierarchical structure and joint adjacency, and together they serve to transform the original motion into a collection of deep temporal features associated with the joints of the primal skeleton. In other words, our operators form the building blocks of a new deep motion processing framework that embeds the motion into a common latent space, shared by a collection of homeomorphic skeletons. Thus, retargeting can be achieved simply by encoding to, and decoding from this latent space. Our experiments show the effectiveness of our framework for motion retargeting, as well as motion processing in general, compared to existing approaches. Our approach is also quantitatively evaluated on a synthetic dataset that contains pairs of motions applied to different skeletons. To the best of our knowledge, our method is the first to perform retargeting between skeletons with differently sampled kinematic chains, without any paired examples.",
        "published": "2020-05-12T12:51:40Z",
        "link": "http://arxiv.org/abs/2005.05732v1",
        "categories": [
            "cs.CV",
            "cs.GR",
            "cs.LG"
        ]
    },
    {
        "title": "Unpaired Motion Style Transfer from Video to Animation",
        "authors": [
            "Kfir Aberman",
            "Yijia Weng",
            "Dani Lischinski",
            "Daniel Cohen-Or",
            "Baoquan Chen"
        ],
        "summary": "Transferring the motion style from one animation clip to another, while preserving the motion content of the latter, has been a long-standing problem in character animation. Most existing data-driven approaches are supervised and rely on paired data, where motions with the same content are performed in different styles. In addition, these approaches are limited to transfer of styles that were seen during training. In this paper, we present a novel data-driven framework for motion style transfer, which learns from an unpaired collection of motions with style labels, and enables transferring motion styles not observed during training. Furthermore, our framework is able to extract motion styles directly from videos, bypassing 3D reconstruction, and apply them to the 3D input motion. Our style transfer network encodes motions into two latent codes, for content and for style, each of which plays a different role in the decoding (synthesis) process. While the content code is decoded into the output motion by several temporal convolutional layers, the style code modifies deep features via temporally invariant adaptive instance normalization (AdaIN). Moreover, while the content code is encoded from 3D joint rotations, we learn a common embedding for style from either 3D or 2D joint positions, enabling style extraction from videos. Our results are comparable to the state-of-the-art, despite not requiring paired training data, and outperform other methods when transferring previously unseen styles. To our knowledge, we are the first to demonstrate style transfer directly from videos to 3D animations - an ability which enables one to extend the set of style examples far beyond motions captured by MoCap systems.",
        "published": "2020-05-12T13:21:27Z",
        "link": "http://arxiv.org/abs/2005.05751v1",
        "categories": [
            "cs.GR",
            "cs.CV",
            "cs.LG"
        ]
    },
    {
        "title": "Representing Whole Slide Cancer Image Features with Hilbert Curves",
        "authors": [
            "Erich Bremer",
            "Jonas Almeida",
            "Joel Saltz"
        ],
        "summary": "Regions of Interest (ROI) contain morphological features in pathology whole slide images (WSI) are delimited with polygons[1]. These polygons are often represented in either a textual notation (with the array of edges) or in a binary mask form. Textual notations have an advantage of human readability and portability, whereas, binary mask representations are more useful as the input and output of feature-extraction pipelines that employ deep learning methodologies. For any given whole slide image, more than a million cellular features can be segmented generating a corresponding number of polygons. The corpus of these segmentations for all processed whole slide images creates various challenges for filtering specific areas of data for use in interactive real-time and multi-scale displays and analysis. Simple range queries of image locations do not scale and, instead, spatial indexing schemes are required. In this paper we propose using Hilbert Curves simultaneously for spatial indexing and as a polygonal ROI representation. This is achieved by using a series of Hilbert Curves[2] creating an efficient and inherently spatially-indexed machine-usable form. The distinctive property of Hilbert curves that enables both mask and polygon delimitation of ROIs is that the elements of the vector extracted ro describe morphological features maintain their relative positions for different scales of the same image.",
        "published": "2020-05-13T16:38:24Z",
        "link": "http://arxiv.org/abs/2005.06469v1",
        "categories": [
            "cs.GR",
            "cs.DB",
            "cs.IR",
            "q-bio.QM"
        ]
    },
    {
        "title": "Optimally Fast Soft Shadows on Curved Terrain with Dynamic Programming   and Maximum Mipmaps",
        "authors": [
            "Dawoon Jung",
            "Fridger Schrempp",
            "Seunghee Son"
        ],
        "summary": "We present a simple, novel method of efficiently rendering ray cast soft shadows on curved terrain by using dynamic programming and maximum mipmaps to rapidly find a global minimum shadow cost in constant runtime complexity. Additionally, we apply a new method of reducing view ray computation times that pre-displaces the terrain mesh to bootstrap ray starting positions. Combining these two methods, our ray casting engine runs in real-time with more than 200% speed up over uniform ray stepping with comparable image quality and without hardware ray tracing acceleration. To add support for accurate planetary ephemerides and interactive features, we integrated the engine into celestia.Sci, a general space simulation software. We demonstrate the ability of our engine to accurately handle a large range of distance scales by using it to generate videos of lunar landing trajectories. The numerical error when compared with real lunar mission imagery is small, demonstrating the accuracy and efficiency of our approach.",
        "published": "2020-05-14T00:06:00Z",
        "link": "http://arxiv.org/abs/2005.06671v1",
        "categories": [
            "cs.GR",
            "astro-ph.IM",
            "I.3.7; I.2.8"
        ]
    },
    {
        "title": "Plane-Activated Mapped Microstructure",
        "authors": [
            "Jeremy Youngquist",
            "Jörg Peters",
            "Meera Sitharam"
        ],
        "summary": "Querying and interacting with models of massive material micro-structure requires localized on-demand generation of the micro-structure since the full-scale storing and retrieving is cost prohibitive. When the micro-structure is efficiently represented as the image of a canonical structure under a non-linear space deformation to allow it to conform to curved shape, the additional challenge is to relate the query of the mapped micro-structure back to its canonical structure. This paper presents an efficient algorithm to pull back a mapped micro-structure to a partition of the canonical domain structure into boxes and only activates boxes whose image is likely intersected by a plane. The active boxes are organized into a forest whose trees are traversed depth first to generate mapped micro-structure only of the active boxes. The traversal supports, for example, 3D print slice generation in additive manufacturing.",
        "published": "2020-05-14T14:20:42Z",
        "link": "http://arxiv.org/abs/2005.06998v1",
        "categories": [
            "cs.GR",
            "cs.CG"
        ]
    },
    {
        "title": "Single Image HDR Reconstruction Using a CNN with Masked Features and   Perceptual Loss",
        "authors": [
            "Marcel Santana Santos",
            "Tsang Ing Ren",
            "Nima Khademi Kalantari"
        ],
        "summary": "Digital cameras can only capture a limited range of real-world scenes' luminance, producing images with saturated pixels. Existing single image high dynamic range (HDR) reconstruction methods attempt to expand the range of luminance, but are not able to hallucinate plausible textures, producing results with artifacts in the saturated areas. In this paper, we present a novel learning-based approach to reconstruct an HDR image by recovering the saturated pixels of an input LDR image in a visually pleasing way. Previous deep learning-based methods apply the same convolutional filters on well-exposed and saturated pixels, creating ambiguity during training and leading to checkerboard and halo artifacts. To overcome this problem, we propose a feature masking mechanism that reduces the contribution of the features from the saturated areas. Moreover, we adapt the VGG-based perceptual loss function to our application to be able to synthesize visually pleasing textures. Since the number of HDR images for training is limited, we propose to train our system in two stages. Specifically, we first train our system on a large number of images for image inpainting task and then fine-tune it on HDR reconstruction. Since most of the HDR examples contain smooth regions that are simple to reconstruct, we propose a sampling strategy to select challenging training patches during the HDR fine-tuning stage. We demonstrate through experimental results that our approach can reconstruct visually pleasing HDR results, better than the current state of the art on a wide range of scenes.",
        "published": "2020-05-15T03:13:44Z",
        "link": "http://arxiv.org/abs/2005.07335v1",
        "categories": [
            "eess.IV",
            "cs.GR"
        ]
    },
    {
        "title": "Online path sampling control with progressive spatio-temporal filtering",
        "authors": [
            "Jacopo Pantaleoni"
        ],
        "summary": "This work introduces progressive spatio-temporal filtering, an efficient method to build all-frequency approximations to the light transport distribution into a scene by filtering individual samples produced by an underlying path sampler, using online, iterative algorithms and data-structures that exploit both the spatial and temporal coherence of the approximated light field. Unlike previous approaches, the proposed method is both more efficient, due to its use of an iterative temporal feedback loop that massively improves convergence to a noise-free approximant, and more flexible, due to its introduction of a spatio-directional hashing representation that allows to encode directional variations like those due to glossy reflections. We then introduce four different methods to employ the resulting approximations to control the underlying path sampler and/or modify its associated estimator, greatly reducing its variance and enhancing its robustness to complex lighting scenarios. The core algorithms are highly scalable and low-overhead, requiring only minor modifications to an existing path tracer.",
        "published": "2020-05-15T13:52:41Z",
        "link": "http://arxiv.org/abs/2005.07547v2",
        "categories": [
            "cs.GR"
        ]
    },
    {
        "title": "Semantic Photo Manipulation with a Generative Image Prior",
        "authors": [
            "David Bau",
            "Hendrik Strobelt",
            "William Peebles",
            "Jonas Wulff",
            "Bolei Zhou",
            "Jun-Yan Zhu",
            "Antonio Torralba"
        ],
        "summary": "Despite the recent success of GANs in synthesizing images conditioned on inputs such as a user sketch, text, or semantic labels, manipulating the high-level attributes of an existing natural photograph with GANs is challenging for two reasons. First, it is hard for GANs to precisely reproduce an input image. Second, after manipulation, the newly synthesized pixels often do not fit the original image. In this paper, we address these issues by adapting the image prior learned by GANs to image statistics of an individual image. Our method can accurately reconstruct the input image and synthesize new content, consistent with the appearance of the input image. We demonstrate our interactive system on several semantic image editing tasks, including synthesizing new objects consistent with background, removing unwanted objects, and changing the appearance of an object. Quantitative and qualitative comparisons against several existing methods demonstrate the effectiveness of our method.",
        "published": "2020-05-15T18:22:05Z",
        "link": "http://arxiv.org/abs/2005.07727v2",
        "categories": [
            "cs.CV",
            "cs.GR",
            "cs.LG",
            "I.2.10; I.4; I.3"
        ]
    },
    {
        "title": "Face Identity Disentanglement via Latent Space Mapping",
        "authors": [
            "Yotam Nitzan",
            "Amit Bermano",
            "Yangyan Li",
            "Daniel Cohen-Or"
        ],
        "summary": "Learning disentangled representations of data is a fundamental problem in artificial intelligence. Specifically, disentangled latent representations allow generative models to control and compose the disentangled factors in the synthesis process. Current methods, however, require extensive supervision and training, or instead, noticeably compromise quality. In this paper, we present a method that learns how to represent data in a disentangled way, with minimal supervision, manifested solely using available pre-trained networks. Our key insight is to decouple the processes of disentanglement and synthesis, by employing a leading pre-trained unconditional image generator, such as StyleGAN. By learning to map into its latent space, we leverage both its state-of-the-art quality, and its rich and expressive latent space, without the burden of training it. We demonstrate our approach on the complex and high dimensional domain of human heads. We evaluate our method qualitatively and quantitatively, and exhibit its success with de-identification operations and with temporal identity coherency in image sequences. Through extensive experimentation, we show that our method successfully disentangles identity from other facial attributes, surpassing existing methods, even though they require more training and supervision.",
        "published": "2020-05-15T18:24:49Z",
        "link": "http://arxiv.org/abs/2005.07728v3",
        "categories": [
            "cs.CV",
            "cs.GR",
            "cs.LG"
        ]
    },
    {
        "title": "Generative Adversarial Networks for photo to Hayao Miyazaki style   cartoons",
        "authors": [
            "Filip Andersson",
            "Simon Arvidsson"
        ],
        "summary": "This paper takes on the problem of transferring the style of cartoon images to real-life photographic images by implementing previous work done by CartoonGAN. We trained a Generative Adversial Network(GAN) on over 60 000 images from works by Hayao Miyazaki at Studio Ghibli. To evaluate our results, we conducted a qualitative survey comparing our results with two state-of-the-art methods. 117 survey results indicated that our model on average outranked state-of-the-art methods on cartoon-likeness.",
        "published": "2020-05-15T19:26:11Z",
        "link": "http://arxiv.org/abs/2005.07702v1",
        "categories": [
            "cs.GR",
            "cs.LG",
            "eess.IV"
        ]
    },
    {
        "title": "Saving the Sonorine: Photovisual Audio Recovery Using Image Processing   and Computer Vision Techniques",
        "authors": [
            "Kevin Feng"
        ],
        "summary": "This paper presents a novel technique to recover audio from sonorines, an early 20th century form of analogue sound storage. Our method uses high resolution photographs of sonorines under different lighting conditions to observe the change in reflection behavior of the physical surface features and create a three-dimensional height map of the surface. Sound can then be extracted using height information within the surface's grooves, mimicking a physical stylus on a phonograph. Unlike traditional playback methods, our method has the advantage of being contactless: the medium will not incur damage and wear from being played repeatedly. We compare the results of our technique to a previously successful contactless method using flatbed scans of the sonorines, and conclude with future research that can be applied to this photovisual approach to audio recovery.",
        "published": "2020-05-16T00:45:26Z",
        "link": "http://arxiv.org/abs/2005.08944v3",
        "categories": [
            "cs.SD",
            "cs.CV",
            "cs.GR",
            "eess.AS"
        ]
    },
    {
        "title": "Attribute2Font: Creating Fonts You Want From Attributes",
        "authors": [
            "Yizhi Wang",
            "Yue Gao",
            "Zhouhui Lian"
        ],
        "summary": "Font design is now still considered as an exclusive privilege of professional designers, whose creativity is not possessed by existing software systems. Nevertheless, we also notice that most commercial font products are in fact manually designed by following specific requirements on some attributes of glyphs, such as italic, serif, cursive, width, angularity, etc. Inspired by this fact, we propose a novel model, Attribute2Font, to automatically create fonts by synthesizing visually-pleasing glyph images according to user-specified attributes and their corresponding values. To the best of our knowledge, our model is the first one in the literature which is capable of generating glyph images in new font styles, instead of retrieving existing fonts, according to given values of specified font attributes. Specifically, Attribute2Font is trained to perform font style transfer between any two fonts conditioned on their attribute values. After training, our model can generate glyph images in accordance with an arbitrary set of font attribute values. Furthermore, a novel unit named Attribute Attention Module is designed to make those generated glyph images better embody the prominent font attributes. Considering that the annotations of font attribute values are extremely expensive to obtain, a semi-supervised learning scheme is also introduced to exploit a large number of unlabeled fonts. Experimental results demonstrate that our model achieves impressive performance on many tasks, such as creating glyph images in new font styles, editing existing fonts, interpolation among different fonts, etc.",
        "published": "2020-05-16T04:06:53Z",
        "link": "http://arxiv.org/abs/2005.07865v1",
        "categories": [
            "cs.CV",
            "cs.GR"
        ]
    },
    {
        "title": "Deep Lighting Environment Map Estimation from Spherical Panoramas",
        "authors": [
            "Vasileios Gkitsas",
            "Nikolaos Zioulis",
            "Federico Alvarez",
            "Dimitrios Zarpalas",
            "Petros Daras"
        ],
        "summary": "Estimating a scene's lighting is a very important task when compositing synthetic content within real environments, with applications in mixed reality and post-production. In this work we present a data-driven model that estimates an HDR lighting environment map from a single LDR monocular spherical panorama. In addition to being a challenging and ill-posed problem, the lighting estimation task also suffers from a lack of facile illumination ground truth data, a fact that hinders the applicability of data-driven methods. We approach this problem differently, exploiting the availability of surface geometry to employ image-based relighting as a data generator and supervision mechanism. This relies on a global Lambertian assumption that helps us overcome issues related to pre-baked lighting. We relight our training data and complement the model's supervision with a photometric loss, enabled by a differentiable image-based relighting technique. Finally, since we predict spherical spectral coefficients, we show that by imposing a distribution prior on the predicted coefficients, we can greatly boost performance. Code and models available at https://vcl3d.github.io/DeepPanoramaLighting.",
        "published": "2020-05-16T14:23:05Z",
        "link": "http://arxiv.org/abs/2005.08000v1",
        "categories": [
            "cs.CV",
            "cs.GR"
        ]
    },
    {
        "title": "An error reduced and uniform parameter approximation in fitting of   B-spline curves to data points",
        "authors": [
            "Debashis Mukherjee"
        ],
        "summary": "Approximating data points in three or higher dimension space based on cubic B-spline curve is presented. Representations for planar curves, are merged and extended to the higher dimension. The curve is fitted to the order of data points, or uniform parameter values are assumed for the points. Tangents are assumed at the data points, corresponding to the property used in cardinal splines, for shape preserving and visually pleasing fit. Control points of piecewise continuous cubic bezier curves, meeting the boundary conditions of cardinal spline segments, are used for b-spline curve in corresponding coordinate planes. Approximation using error computed in the least square sense, based on a fraction of data points, is also presented.",
        "published": "2020-05-18T06:00:47Z",
        "link": "http://arxiv.org/abs/2005.08468v1",
        "categories": [
            "cs.GR"
        ]
    },
    {
        "title": "RBF-FD analysis of 2D time-domain acoustic wave propagation in   heterogeneous media",
        "authors": [
            "Jure Močnik - Berljavac",
            "Pankaj K Mishra",
            "Jure Slak",
            "Gregor Kosec"
        ],
        "summary": "Radial Basis Function-generated Finite Differences (RBF-FD) is a popular variant of local strong-form meshless methods that do not require a predefined connection between the nodes, making it easier to adapt node-distribution to the problem under consideration. This paper investigates an RBF-FD solution of time-domain acoustic wave propagation in the context of seismic modeling in the Earth's subsurface. Through a number of numerical tests, ranging from homogeneous to highly-heterogeneous velocity models including non-smooth irregular topography, we demonstrate that the present approach can be further generalized to solve large-scale seismic modeling and full waveform inversion problems in arbitrarily complex models enabling more robust interpretations of geophysical observations",
        "published": "2020-01-02T18:11:38Z",
        "link": "http://arxiv.org/abs/2001.01597v2",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA",
            "physics.geo-ph"
        ]
    },
    {
        "title": "Numerical investigation into fracture resistance of bone following   adaptation",
        "authors": [
            "Karol Lewandowski",
            "Łukasz Kaczmarczyk",
            "Ignatios Athanasiadis",
            "John F. Marshall",
            "Chris J. Pearce"
        ],
        "summary": "Bone adapts in response to its mechanical environment. This evolution of bone density is one of the most important mechanisms for developing fracture resistance. A finite element framework for simulating bone adaptation, commonly called bone remodelling, is presented. This is followed by a novel method to both quantify fracture resistance and to simulate fracture propagation. The authors' previous work on the application of configurational mechanics for modelling fracture is extended to include the influence of heterogeneous bone density distribution. The main advantage of this approach is that configurational forces, and fracture energy release rate, are expressed exclusively in terms of nodal quantities. This approach avoids the need for post-processing and enables a fully implicit formulation for modelling the evolving crack front. In this paper density fields are generated from both (a) bone adaptation analysis and (b) subject-specific geometry and material properties obtained from CT scans. It is shown that, in order to correctly evaluate the configurational forces at the crack front, it is necessary to have a spatially smooth density field with higher regularity than if the field is directly approximated on the finite element mesh. Therefore, discrete density data is approximated as a smooth density field using a Moving Weighted Least Squares method. Performance of the framework is demonstrated using numerical simulations for bone adaptation and subsequent crack propagation, including consideration of an equine 3rd metacarpal bone. The degree of bone adaption is shown to influence both fracture resistance and the resulting crack path.",
        "published": "2020-01-02T22:09:35Z",
        "link": "http://arxiv.org/abs/2001.00647v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A phase field model for cohesive fracture in micropolar continua",
        "authors": [
            "Hyoung Suk Suh",
            "WaiChing Sun",
            "Devin O'Connor"
        ],
        "summary": "While crack nucleation and propagation in the brittle or quasi-brittle regime can be predicted via variational or material-force-based phase field fracture models, these models often assume that the underlying elastic response of the material is non-polar and yet a length scale parameter must be introduced to enable the sharp cracks represented by a regularized implicit function. However, many materials with internal microstructures that contain surface tension, micro-cracks, micro-fracture, inclusion, cavity or those of particulate nature often exhibit size-dependent behaviors in both the path-independent and path-dependent regimes. This paper is intended to introduce a unified treatment that captures the size effect of the materials in both elastic and damaged states. By introducing a cohesive micropolar phase field fracture theory, along with the computational model and validation exercises, we explore the interacting size-dependent elastic deformation and fracture mechanisms exhibits in materials of complex microstructures. To achieve this goal, we introduce the distinctive degradation functions of the force-stress-strain and couple-stress-micro-rotation energy-conjugated pairs for a given regularization profile such that the macroscopic size-dependent responses of the micropolar continua is insensitive to the length scale parameter of the regularized interface. Then, we apply the variational principle to derive governing equations from the micropolar stored energy and dissipative functionals. Numerical examples are introduced to demonstrate the proper way to identify material parameters and the capacity of the new formulation to simulate complex crack patterns in the quasi-static regime.",
        "published": "2020-01-04T02:17:44Z",
        "link": "http://arxiv.org/abs/2001.01022v2",
        "categories": [
            "cs.CE",
            "74",
            "G.1.8"
        ]
    },
    {
        "title": "The Radial Point Interpolation Mixed Collocation (RPIMC) Method for the   Solution of Transient Diffusion Problems",
        "authors": [
            "Konstantinos A. Mountris",
            "Esther Pueyo"
        ],
        "summary": "The Radial Point Interpolation Mixed Collocation (RPIMC) method is proposed in this paper for transient analysis of diffusion problems. RPIMC is an efficient purely meshless method where the solution of the field variable is obtained through collocation. The field function and its gradient are both interpolated (mixed collocation approach) leading to reduced $C$-continuity requirement compared to strong-form collocation schemes. The method's accuracy is evaluated in heat conduction benchmark problems. The RPIMC convergence is compared against the Meshless Local Petrov-Galerkin Mixed Collocation (MLPG-MC) method and the Finite Element Method (FEM). Due to the delta Kronecker property of RPIMC, improved accuracy can be achieved as compared to MLPG-MC. RPIMC is proven to be a promising meshless alternative to FEM for transient diffusion problems.",
        "published": "2020-01-04T03:30:37Z",
        "link": "http://arxiv.org/abs/2001.01027v2",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "A stable SPH with adaptive B-spline kernel",
        "authors": [
            "Saptarshi Kumar Lahiri",
            "Kanishka Bhattacharya",
            "Amit Shaw",
            "L S Ramachandra"
        ],
        "summary": "Tensile instability, often observed in smoothed particle hydrodynamics (SPH), is a numerical artifact that manifests itself by unphysical clustering or separation of particles. The instability originates in estimating the derivatives of the smoothing functions which, when interact with material constitution may result in negative stiffness in the discretized system. In the present study, a stable formulation of SPH is developed where the kernel function is continuously adapted at every material point depending on its state of stress. Bspline basis function with a variable intermediate knot is used as the kernel function. The shape of the kernel function is then modified by changing the intermediate knot position such that the condition associated with instability does not arise. While implementing the algorithm the simplicity and computational efficiency of SPH are not compromised. One-dimensional dispersion analysis is performed to understand the effect adaptive kernel on the stability. Finally, the efficacy of the algorithm is demonstrated through some benchmark elastic dynamics problems.",
        "published": "2020-01-04T09:27:32Z",
        "link": "http://arxiv.org/abs/2001.03416v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Development, Demonstration, and Validation of Data-driven Compact Diode   Models for Circuit Simulation and Analysis",
        "authors": [
            "K. Aadithya",
            "P. Kuberry",
            "B. Paskaleva",
            "P. Bochev",
            "K. Leeson",
            "A. Mar",
            "T. Mei",
            "E. Keiter"
        ],
        "summary": "Compact semiconductor device models are essential for efficiently designing and analyzing large circuits. However, traditional compact model development requires a large amount of manual effort and can span many years. Moreover, inclusion of new physics (eg, radiation effects) into an existing compact model is not trivial and may require redevelopment from scratch. Machine Learning (ML) techniques have the potential to automate and significantly speed up the development of compact models. In addition, ML provides a range of modeling options that can be used to develop hierarchies of compact models tailored to specific circuit design stages. In this paper, we explore three such options: (1) table-based interpolation, (2)Generalized Moving Least-Squares, and (3) feed-forward Deep Neural Networks, to develop compact models for a p-n junction diode. We evaluate the performance of these \"data-driven\" compact models by (1) comparing their voltage-current characteristics against laboratory data, and (2) building a bridge rectifier circuit using these devices, predicting the circuit's behavior using SPICE-like circuit simulations, and then comparing these predictions against laboratory measurements of the same circuit.",
        "published": "2020-01-06T18:25:32Z",
        "link": "http://arxiv.org/abs/2001.01699v1",
        "categories": [
            "cs.LG",
            "cs.CE",
            "stat.ML",
            "J.2, J.6, I.6",
            "J.2; J.6; I.6"
        ]
    },
    {
        "title": "Preliminary Studies on the Usefulness of Nonlinear Boundary Element   Method for Real-Time Simulation of Biological Organs",
        "authors": [
            "Kirana Kumara P"
        ],
        "summary": "There is some literature on the application of linear boundary element method (BEM) for real-time simulation of biological organs. However, literature is scant when it comes to the application of nonlinear BEM, although there is a possibility that the use of nonlinear BEM would result in better simulations. Hence the present paper explores the possibility of using nonlinear BEM for real-time simulation of biological organs. This paper begins with a general discussion about using the nonlinear BEM for real-time simulation of biological organs. Literature on nonlinear BEM is reviewed and the literature that deal with nonlinear formulations and coding are noted down next. In the later sections, some results obtained from nonlinear analyses are compared with the corresponding results from linear analyses. The last section concludes with remarks that indicate that it might be possible to obtain better simulations in the future by using nonlinear BEM.",
        "published": "2020-01-06T19:48:07Z",
        "link": "http://arxiv.org/abs/2001.01756v1",
        "categories": [
            "cs.CE",
            "physics.med-ph"
        ]
    },
    {
        "title": "An Efficient Gradient Projection Method for Structural Topology   Optimization",
        "authors": [
            "Zhi Zeng",
            "Fulei Ma"
        ],
        "summary": "This paper presents an efficient gradient projection-based method for structural topological optimization problems characterized by a nonlinear objective function which is minimized over a feasible region defined by bilateral bounds and a single linear equality constraint. The specialty of the constraints type, as well as heuristic engineering experiences are exploited to improve the scaling scheme, projection, and searching step. In detail, gradient clipping and a modified projection of searching direction under certain condition are utilized to facilitate the efficiency of the proposed method. Besides, an analytical solution is proposed to approximate this projection with negligible computation and memory costs. Furthermore, the calculation of searching steps is largely simplified. Benchmark problems, including the MBB, the force inverter mechanism, and the 3D cantilever beam are used to validate the effectiveness of the method. The proposed method is implemented in MATLAB which is open-sourced for educational usage.",
        "published": "2020-01-07T05:22:21Z",
        "link": "http://arxiv.org/abs/2001.01896v2",
        "categories": [
            "cs.CE",
            "math.OC",
            "74P05, 74P15",
            "J.6.1"
        ]
    },
    {
        "title": "A machine learning based plasticity model using proper orthogonal   decomposition",
        "authors": [
            "Dengpeng Huang",
            "Jan Niklas Fuhg",
            "Christian Weißenfels",
            "Peter Wriggers"
        ],
        "summary": "Data-driven material models have many advantages over classical numerical approaches, such as the direct utilization of experimental data and the possibility to improve performance of predictions when additional data is available. One approach to develop a data-driven material model is to use machine learning tools. These can be trained offline to fit an observed material behaviour and then be applied in online applications. However, learning and predicting history dependent material models, such as plasticity, is still challenging. In this work, a machine learning based material modelling framework is proposed for both elasticity and plasticity. The machine learning based hyperelasticity model is developed with the Feed forward Neural Network (FNN) directly whereas the machine learning based plasticity model is developed by using of a novel method called Proper Orthogonal Decomposition Feed forward Neural Network (PODFNN). In order to account for the loading history, the accumulated absolute strain is proposed to be the history variable of the plasticity model. Additionally, the strain-stress sequence data for plasticity is collected from different loading-unloading paths based on the concept of sequence for plasticity. By means of the POD, the multi-dimensional stress sequence is decoupled leading to independent one dimensional coefficient sequences. In this case, the neural network with multiple output is replaced by multiple independent neural networks each possessing a one-dimensional output, which leads to less training time and better training performance. To apply the machine learning based material model in finite element analysis, the tangent matrix is derived by the automatic symbolic differentiation tool AceGen. The effectiveness and generalization of the presented models are investigated by a series of numerical examples using both 2D and 3D finite element analysis.",
        "published": "2020-01-07T15:46:16Z",
        "link": "http://arxiv.org/abs/2001.03438v1",
        "categories": [
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "ILS-MPM: an implicit level-set-based material point method for   frictional particulate contact mechanics of deformable particles",
        "authors": [
            "Chuanqi Liu",
            "Waiching Sun"
        ],
        "summary": "Finite element simulations of frictional multi-body contact problems via conformal meshes can be challenging and computationally demanding. To render geometrical features, unstructured meshes must be used and this unavoidably increases the degrees of freedom and therefore makes the construction of slave/master pairs more demanding. In this work, we introduce an implicit material point method designed to bypass the meshing of bodies by employing level set functions to represent boundaries at structured grids. This implicit function representation provides an elegant mean to link an unbiased intermediate reference surface with the true boundaries by closest point projection as shown in leichner et al. (2019). We then enforce the contact constraints by a penalty method where the Coulomb friction law is implemented as an elastoplastic constitutive model such that a return mapping algorithm can be used to provide constitutive updates for both the stick and slip states. To evolve the geometry of the contacts properly, the Hamilton-Jacobi equation is solved incrementally such that the level set and material points are both updated accord to the deformation field. To improve the accuracy and regularity of the numerical integration of the material point method, a moving least square method is used to project numerical values of the material points back to the standard locations for Gaussian-Legendre quadrature. Several benchmarks are used to verify the proposed model. Comparisons with discrete element simulations are made to analyze the importance of stress fields on predicting the macroscopic responses of granular assemblies.",
        "published": "2020-01-08T08:29:26Z",
        "link": "http://arxiv.org/abs/2001.02412v3",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Linear-frictional contact model for 3D discrete element simulations of   granular systems",
        "authors": [
            "Matthew R. Kuhn",
            "Kiichi Suzuki",
            "Ali Daouadji"
        ],
        "summary": "The linear-frictional contact model is the most commonly used contact mechanism for discrete element (DEM) simulations of granular materials. Linear springs with a frictional slider are used for modeling interactions in directions normal and tangential to the contact surface. Although the model is simple in two dimensions, its implementation in 3D faces certain subtle challenges, and the particle interactions that occur within a single time-step require careful modeling with a robust algorithm. The paper details a 3D algorithm that accounts for the changing direction of the tangential force within a time-step, the transition from elastic to slip behavior within a time-step, possible contact sliding during only part of a time-step, and twirling and rotation of the tangential force during a time-step. Without three of these adjustments, errors are introduced in the incremental stiffness of an assembly. Without the fourth adjustment, the resulting stress tensor is not only incorrect, it is no longer a tensor. The algorithm also computes the work increments during a time-step, both elastic and dissipative.",
        "published": "2020-01-09T00:09:53Z",
        "link": "http://arxiv.org/abs/2002.10231v1",
        "categories": [
            "cs.CE",
            "cond-mat.soft"
        ]
    },
    {
        "title": "A Generalized Probabilistic Learning Approach for Multi-Fidelity   Uncertainty Propagation in Complex Physical Simulations",
        "authors": [
            "Jonas Nitzler",
            "Jonas Biehler",
            "Niklas Fehn",
            "Phaedon-Stelios Koutsourelakis",
            "Wolfgang A. Wall"
        ],
        "summary": "Two of the most significant challenges in uncertainty quantification pertain to the high computational cost for simulating complex physical models and the high dimension of the random inputs. In applications of practical interest, both of these problems are encountered, and standard methods either fail or are not feasible. To overcome the current limitations, we present a generalized formulation of a Bayesian multi-fidelity Monte-Carlo (BMFMC) framework that can exploit lower-fidelity model versions in a small data regime. The goal of our analysis is an efficient and accurate estimation of the complete probabilistic response for high-fidelity models. BMFMC circumvents the curse of dimensionality by learning the relationship between the outputs of a reference high-fidelity model and potentially several lower-fidelity models. While the continuous formulation is mathematically exact and independent of the low-fidelity model's accuracy, we address challenges associated with the small data regime (i.e., only a small number of 50 to 300 high-fidelity model runs can be performed). Specifically, we complement the formulation with a set of informative input features at no extra cost. Despite the inaccurate and noisy information that some low-fidelity models provide, we demonstrate that accurate and certifiable estimates for the quantities of interest can be obtained for uncertainty quantification problems in high stochastic dimensions, with significantly fewer high-fidelity model runs than state-of-the-art methods for uncertainty quantification. We illustrate our approach by applying it to challenging numerical examples such as Navier-Stokes flow simulations and fluid-structure interaction problems.",
        "published": "2020-01-09T09:09:04Z",
        "link": "http://arxiv.org/abs/2001.02892v3",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Massively parallel finite difference elasticity using block-structured   adaptive mesh refinement with a geometric multigrid solver",
        "authors": [
            "Brandon Runnels",
            "Vinamra Agrawal",
            "Weiqun Zhang",
            "Ann Almgren"
        ],
        "summary": "Computationally solving the equations of elasticity is a key component in many materials science and mechanics simulations. Phenomena such as deformation-induced microstructure evolution, microfracture, and microvoid nucleation are examples of applications for which accurate stress and strain fields are required. A characteristic feature of these simulations is that the problem domain is simple (typically a rectilinear representative volume element (RVE)), but the evolution of internal topological features is extremely complex. Traditionally, the finite element method (FEM) is used for elasticity calculations; FEM is nearly ubiquituous due to (1) its ability to handle meshes of complex geometry using isoparametric elements, and (2) the weak formulation which eschews the need for computation of second derivatives. However, variable topology problems (e.g. microstructure evolution) require either remeshing, or adaptive mesh refinement (AMR) - both of which can cause extensive overhead and limited scaling. Block-structured AMR (BSAMR) is a method for adaptive mesh refinement that exhibits good scaling and is well-suited for many problems in materials science. Here, it is shown that the equations of elasticity can be efficiently solved using BSAMR using the finite difference method. The boundary operator method is used to treat different types of boundary conditions, and the \"reflux-free\" method is introduced to efficiently and easily treat the coarse-fine boundaries that arise in BSAMR. Examples are presented that demonstrate the use of this method in a variety of cases relevant to materials science: Eshelby inclusions, fracture, and microstructure evolution. Reasonable scaling is demonstrated up to $\\sim$4000 processors with tens of millions of grid points, and good AMR efficiency is observed.",
        "published": "2020-01-10T22:01:36Z",
        "link": "http://arxiv.org/abs/2001.04789v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Continuum modelling of stress diffusion interactions in an elastoplastic   medium in the presence of geometric discontinuity",
        "authors": [
            "Rupesh Kumar Mahendran",
            "Hirshikesh",
            "Ratna Kumar Annabattula",
            "Sundararajan Natarajan"
        ],
        "summary": "Chemo-mechanical coupled systems have been a subject of interest for many decades now. Previous attempts to solve such models have mainly focused on elastic materials without taking into account the plastic deformation beyond yield, thus causing inaccuracies in failure calculations. This paper aims to study the effect of stress-diffusion interactions in an elastoplastic material using a coupled chemo-mechanical system. The induced stress is dependent on the local concentration in a one way coupled system, and vice versa in a two way coupled system. The time-dependent transient coupled system is solved using a finite element formulation in an open-source finite element solver FEniCS. This paper attempts to computationally study the interaction of deformation and diffusion and its effect on the localization of plastic strain. We investigate the role of geometric discontinuities in scenarios involving diffusing species, namely, a plate with a notch/hole/void and particle with a void/hole/core. We also study the effect of stress concentrations and plastic yielding on the diffusion-deformation. The developed code can be from https://github.com/mrupeshkumar/Elastoplastic-stress-diffusion-coupling",
        "published": "2020-01-11T16:01:33Z",
        "link": "http://arxiv.org/abs/2001.04818v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Variational system identification of the partial differential equations   governing microstructure evolution in materials: Inference over sparse and   spatially unrelated data",
        "authors": [
            "Z. Wang",
            "X. Huan",
            "K. Garikipati"
        ],
        "summary": "Pattern formation is a widely observed phenomenon in diverse fields including materials physics, developmental biology and ecology, among many others. The physics underlying the patterns is specific to the mechanisms, and is encoded by partial differential equations (PDEs). With the aim of discovering hidden physics, we have previously presented a variational approach to identifying such systems of PDEs in the face of noisy data at varying fidelities (Computer Methods in Applied Mechanics and Engineering, 353:201-216, 2019). Here, we extend our variational system identification methods to address the challenges presented by image data on microstructures in materials physics. PDEs are formally posed as initial and boundary value problems over combinations of time intervals and spatial domains whose evolution is either fixed or can be tracked. However, the vast majority of microscopy techniques for evolving microstructure in a given material system deliver micrographs of pattern evolution over domains that bear no relation with each other at different time instants. The temporal resolution can rarely capture the fastest time scales that dominate the early dynamics, and noise abounds. Furthermore, data for evolution of the same phenomenon in a material system may well be obtained from different physical specimens. Against this backdrop of spatially unrelated, sparse and multi-source data, we exploit the variational framework to make judicious choices of weighting functions and identify PDE operators from the dynamics. A consistency condition arises for parsimonious inference of a minimal set of the spatial operators at steady state. It is complemented by a confirmation test that provides a sharp condition for acceptance of the inferred operators. The entire framework is demonstrated on synthetic data that reflect the characteristics of the experimental material microscopy images.",
        "published": "2020-01-11T18:19:50Z",
        "link": "http://arxiv.org/abs/2001.04816v4",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA",
            "physics.data-an"
        ]
    },
    {
        "title": "Non-Intrusive Parametric Model Order Reduction With Error Correction   Modeling for Changing Well Locations Using a Machine Learning Framework",
        "authors": [
            "Hardikkumar Zalavadia",
            "Eduardo Gildin"
        ],
        "summary": "The objective of this paper is to develop a global non-intrusive Parametric Model Order Reduction (PMOR) methodology for the problem of changing well locations in an oil field, that can eventually be used for well placement optimization to gain significant computational savings. In this work, we propose a proper orthogonal decomposition (POD) based PMOR strategy that is non-intrusive to the simulator source code and hence extends its applicability to any commercial simulator. The non-intrusiveness of the proposed technique stems from formulating a novel Machine Learning (ML) based framework used with POD. The features of ML model are designed such that they take into consideration the temporal evolution of the state solutions and thereby avoiding simulator access for time dependency of the solutions. We represent well location changes as a parameter by introducing geometry-based features and flow diagnostics inspired physics-based features. An error correction model based on reduced model solutions is formulated later to correct for discrepancies in the state solutions at well gridblocks. It was observed that the global PMOR could predict the overall trend in pressure and saturation solutions at the well blocks but some bias was observed that resulted in discrepancies in prediction of quantities of interest (QoI). Thus, the error correction model that considers the physics based reduced model solutions as features, proved to reduce the error in QoI significantly. This workflow is applied to a heterogeneous channelized reservoir that showed good solution accuracies and speed-ups of 50x-100x were observed for different cases considered. The method is formulated such that all the simulation time steps are independent and hence can make use of parallel resources very efficiently and also avoid stability issues that can result from error accumulation over timesteps.",
        "published": "2020-01-12T02:10:27Z",
        "link": "http://arxiv.org/abs/2001.05061v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Modelling Orebody Structures: Block Merging Algorithms and Block Model   Spatial Restructuring Strategies Given Mesh Surfaces of Geological Boundaries",
        "authors": [
            "Raymond Leung"
        ],
        "summary": "This paper describes a framework for capturing geological structures in a 3D block model and improving its spatial fidelity given new mesh surfaces. Using surfaces that represent geological boundaries, the objectives are to identify areas where refinement is needed, increase spatial resolution to minimize surface approximation error, reduce redundancy to increase the compactness of the model and identify the geological domain on a block-by-block basis. These objectives are fulfilled by four system components which perform block-surface overlap detection, spatial structure decomposition, sub-blocks consolidation and block tagging, respectively. The main contributions are a coordinate-ascent merging algorithm and a flexible architecture for updating the spatial structure of a block model when given multiple surfaces, which emphasizes the ability to selectively retain or modify previously assigned block labels. The techniques employed include block-surface intersection analysis based on the separable axis theorem and ray-tracing for establishing the location of blocks relative to surfaces. To demonstrate the robustness and applicability of the proposed block merging strategy in a more narrow setting, it is used to reduce block fragmentation in an existing model where surfaces are not given and the minimum block size is fixed. To obtain further insight, a systematic comparison with octree subblocking subsequently illustrates the inherent constraints of dyadic hierarchical decomposition and the importance of inter-scale merging. The results show the proposed method produces merged blocks with less extreme aspect ratios and is highly amenable to parallel processing. The overall framework is applicable to orebody modelling given geological boundaries, and 3D segmentation more generally, where there is a need to delineate spatial regions using mesh surfaces within a block model.",
        "published": "2020-01-13T01:10:03Z",
        "link": "http://arxiv.org/abs/2001.04023v3",
        "categories": [
            "cs.CE",
            "J.2; I.3.5; I.3.8"
        ]
    },
    {
        "title": "Reliable and interoperable computational molecular engineering: 2.   Semantic interoperability based on the European Materials and Modelling   Ontology",
        "authors": [
            "Martin Thomas Horsch",
            "Silvia Chiacchiera",
            "Youness Bami",
            "Georg J. Schmitz",
            "Gabriele Mogni",
            "Gerhard Goldbeck",
            "Emanuele Ghedini"
        ],
        "summary": "The European Materials and Modelling Ontology (EMMO) is a top-level ontology designed by the European Materials Modelling Council to facilitate semantic interoperability between platforms, models, and tools in computational molecular engineering, integrated computational materials engineering, and related applications of materials modelling and characterization. Additionally, domain ontologies exist based on data technology developments from specific platforms. The present work discusses the ongoing work on establishing a European Virtual Marketplace Framework, into which diverse platforms can be integrated. It addresses common challenges that arise when marketplace-level domain ontologies are combined with a top-level ontology like the EMMO by ontology alignment.",
        "published": "2020-01-13T12:02:37Z",
        "link": "http://arxiv.org/abs/2001.04175v1",
        "categories": [
            "cs.CE",
            "cond-mat.mtrl-sci",
            "cs.DB",
            "cs.DC"
        ]
    },
    {
        "title": "Rapid multi-component phase-split calculations using volume functions   and reduction methods",
        "authors": [
            "Mohamad Fathi",
            "Stefan Hickel"
        ],
        "summary": "We present a new family of fast and robust methods for the calculation of the vapor-liquid equilibrium at isobaric-isothermal (PT-flash), isochoric-isothermal (VT-flash), isenthalpic-isobaric (HP-flash), and isoenergetic-isochoric (UV-flash) conditions. The framework is provided by formulating phase-equilibrium conditions for multi-component mixtures in an effectively reduced space based on the molar specific value of the recently introduced volume function derived from the Helmholtz free energy. The proposed algorithmic implementation can fully exploit the optimum quadratic convergence of a Newton method with the analytical Jacobian matrix. This paper provides all required exact analytic expressions for the general cubic equation of state. Computational results demonstrate the effectivity and efficiency of the new methods. Compared to conventional methods, the proposed reduced-space iteration leads to a considerable speed-up as well as to improved robustness and better convergence behavior near the spinodal and coexistence curves of multi-component mixtures, where the preconditioning by the reduction method is most effective.",
        "published": "2020-01-13T21:17:57Z",
        "link": "http://arxiv.org/abs/2001.06285v1",
        "categories": [
            "cs.CE",
            "physics.comp-ph",
            "physics.flu-dyn"
        ]
    },
    {
        "title": "Accurate iteration-free mixed-stabilised formulation for laminar   incompressible Navier-Stokes: Applications to fluid-structure interaction",
        "authors": [
            "Chennakesava Kadapa",
            "Wulf G Dettmer",
            "Djordje Peric"
        ],
        "summary": "Stabilised mixed velocity-pressure formulations are one of the widely-used finite element schemes for computing the numerical solutions of laminar incompressible Navier-Stokes. In these formulations, the Newton-Raphson scheme is employed to solve the nonlinearity in the convection term. One fundamental issue with this approach is the computational cost incurred in the Newton-Raphson iterations at every load/time step. In this paper, we present an iteration-free mixed finite element formulation for incompressible Navier-Stokes that preserves second-order temporal accuracy of the generalised-alpha and related schemes for both velocity and pressure fields. First, we demonstrate the second-order temporal accuracy using numerical convergence studies for an example with a manufactured solution. Later, we assess the accuracy and the computational benefits of the proposed scheme by studying the benchmark example of flow past a fixed circular cylinder. Towards showcasing the applicability of the proposed technique in a wider context, the inf-sup stable P2-P1 pair for the formulation without stabilisation is also considered. Finally, the resulting benefits of using the proposed scheme for fluid-structure interaction problems is illustrated using two benchmark examples in fluid-flexible structure interaction.",
        "published": "2020-01-14T17:36:01Z",
        "link": "http://arxiv.org/abs/2001.04925v2",
        "categories": [
            "cs.CE",
            "physics.flu-dyn"
        ]
    },
    {
        "title": "GPU acceleration of CaNS for massively-parallel direct numerical   simulations of canonical fluid flows",
        "authors": [
            "Pedro Costa",
            "Everett Phillips",
            "Luca Brandt",
            "Massimiliano Fatica"
        ],
        "summary": "This work presents the GPU acceleration of the open-source code CaNS for very fast massively-parallel simulations of canonical fluid flows. The distinct feature of the many-CPU Navier-Stokes solver in CaNS is its fast direct solver for the second-order finite-difference Poisson equation, based on the method of eigenfunction expansions. The solver implements all the boundary conditions valid for this type of problems in a unified framework. Here, we extend the solver for GPU-accelerated clusters using CUDA Fortran. The porting makes extensive use of CUF kernels and has been greatly simplified by the unified memory feature of CUDA Fortran, which handles the data migration between host (CPU) and device (GPU) without defining new arrays in the source code. The overall implementation has been validated against benchmark data for turbulent channel flow and its performance assessed on a NVIDIA DGX-2 system (16 Tesla V100 32Gb, connected with NVLink via NVSwitch). The wall-clock time per time step of the GPU-accelerated implementation is impressively small when compared to its CPU implementation on state-of-the-art many-CPU clusters, as long as the domain partitioning is sufficiently small that the data resides mostly on the GPUs. The implementation has been made freely available and open-source under the terms of an MIT license.",
        "published": "2020-01-15T11:06:25Z",
        "link": "http://arxiv.org/abs/2001.05234v3",
        "categories": [
            "physics.flu-dyn",
            "cs.CE",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Isogeometric continuity constraints for multi-patch shells governed by   fourth-order deformation and phase field models",
        "authors": [
            "Karsten Paul",
            "Christopher Zimmermann",
            "Thang X. Duong",
            "Roger A. Sauer"
        ],
        "summary": "This work presents numerical techniques to enforce continuity constraints on multi-patch surfaces for three distinct problem classes. The first involves structural analysis of thin shells that are described by general Kirchhoff-Love kinematics. Their governing equation is a vector-valued, fourth-order, nonlinear, partial differential equation (PDE) that requires at least $C^1$-continuity within a displacement-based finite element formulation. The second class are surface phase separations modeled by a phase field. Their governing equation is the Cahn-Hilliard equation - a scalar, fourth-order, nonlinear PDE - that can be coupled to the thin shell PDE. The third class are brittle fracture processes modeled by a phase field approach. In this work, these are described by a scalar, fourth-order, nonlinear PDE that is similar to the Cahn-Hilliard equation and is also coupled to the thin shell PDE. Using a direct finite element discretization, the two phase field equations also require at least a $C^1$-continuous formulation. Isogeometric surface discretizations - often composed of multiple patches - thus require constraints that enforce the $C^1$-continuity of displacement and phase field. For this, two numerical strategies are presented: For this, two numerical strategies are presented: A Lagrange multiplier formulation and a penalty method. The curvilinear shell model including the geometrical constraints is taken from Duong et al. (2017) and it is extended to model the coupled phase field problems on thin shells of Zimmermann et al. (2019) and Paul et al. (2020) on multi-patches. Their accuracy and convergence are illustrated by several numerical examples considering deforming shells, phase separations on evolving surfaces, and dynamic brittle fracture of thin shells.",
        "published": "2020-01-16T17:52:18Z",
        "link": "http://arxiv.org/abs/2001.05964v3",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Active Learning over DNN: Automated Engineering Design Optimization for   Fluid Dynamics Based on Self-Simulated Dataset",
        "authors": [
            "Yang Chen"
        ],
        "summary": "Optimizing fluid-dynamic performance is an important engineering task. Traditionally, experts design shapes based on empirical estimations and verify them through expensive experiments. This costly process, both in terms of time and space, may only explore a limited number of shapes and lead to sub-optimal designs. In this research, a test-proven deep learning architecture is applied to predict the performance under various restrictions and search for better shapes by optimizing the learned prediction function. The major challenge is the vast amount of data points Deep Neural Network (DNN) demands, which is improvident to simulate. To remedy this drawback, a Frequentist active learning is used to explore regions of the output space that DNN predicts promising. This operation reduces the number of data samples demanded from ~8000 to 625. The final stage, a user interface, made the model capable of optimizing with given user input of minimum area and viscosity. Flood fill is used to define a boundary area function so that the optimal shape does not bypass the minimum area. Stochastic Gradient Langevin Dynamics (SGLD) is employed to make sure the ultimate shape is optimized while circumventing the required area. Jointly, shapes with extremely low drags are found explored by a practical user interface with no human domain knowledge and modest computation overhead.",
        "published": "2020-01-18T07:35:00Z",
        "link": "http://arxiv.org/abs/2001.08075v2",
        "categories": [
            "cs.CE",
            "cs.LG",
            "stat.ML"
        ]
    },
    {
        "title": "Contact with coupled adhesion and friction: Computational framework,   applications, and new insights",
        "authors": [
            "Janine C. Mergel",
            "Julien Scheibert",
            "Roger A. Sauer"
        ],
        "summary": "Contact involving soft materials often combines dry adhesion, sliding friction, and large deformations. At the local level, these three aspects are rarely captured simultaneously, but included in the theoretical models by Mergel et al. (2019). We here develop a corresponding finite element framework that captures 3D finite-strain contact of two deformable bodies. This framework is suitable to investigate sliding friction even under tensile normal loads. First, we demonstrate the capabilities of our finite element model using both 2D and 3D test cases, which range from compliant tapes to structures with high stiffness, and include deformable-rigid and deformable-deformable contact. We then provide new results on the onset of sliding of smooth elastomer-glass interfaces, a setup that couples nonlinear material behavior, adhesion, and large frictional stresses. Our simulations not only agree well with both experimental and theoretical findings, they also provide new insights into the current debate on the shear-induced reduction of the contact area in elastomeric contact.",
        "published": "2020-01-19T14:15:35Z",
        "link": "http://arxiv.org/abs/2001.06833v3",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Mathematical modelling of nuclear medicine data",
        "authors": [
            "Michele Piana",
            "Giacomo Caviglia",
            "Sara Sommariva"
        ],
        "summary": "Positron Emission Tomography using 2-[18F]-2deoxy-D-glucose as radiotracer (FDG-PET) is currently one of the most frequently applied functional imaging methods in clinical applications. The interpretation of FDG-PET data requires sophisticated mathematical approaches able to exploit the dynamical information contained in this kind of data. Most of these approaches are formulated within the framework of compartmental analysis, which connects the experimental nuclear data with unknown tracer coefficients measuring the effectiveness of the tracer metabolism by means of Cauchy systems of ordinary differential equations. This paper provides a coincise overview of linear compartmental methods, focusing on the analytical solution of the forward compartmental problem and on the specific issues concerning the corresponding compartmental inverse problem.",
        "published": "2020-01-19T19:12:24Z",
        "link": "http://arxiv.org/abs/2001.06884v1",
        "categories": [
            "q-bio.TO",
            "cs.CE",
            "92C42, 92C55, 65R32"
        ]
    },
    {
        "title": "AI-driven Inverse Design System for Organic Molecules",
        "authors": [
            "Seiji Takeda",
            "Toshiyuki Hama",
            "Hsiang-Han Hsu",
            "Toshiyuki Yamane",
            "Koji Masuda",
            "Victoria A. Piunova",
            "Dmitry Zubarev",
            "Jed Pitera",
            "Daniel P. Sanders",
            "Daiju Nakano"
        ],
        "summary": "Designing novel materials that possess desired properties is a central need across many manufacturing industries. Driven by that industrial need, a variety of algorithms and tools have been developed that combine AI (machine learning and analytics) with domain knowledge in physics, chemistry, and materials science. AI-driven materials design can be divided to mainly two stages; the first one is the modeling stage, where the goal is to build an accurate regression or classification model to predict material properties (e.g. glass transition temperature) or attributes (e.g. toxic/non-toxic). The next stage is design, where the goal is to assemble or tune material structures so that they can achieve user-demanded target property values based on a prediction model that is trained in the modeling stage. For maximum benefit, these two stages should be architected to form a coherent workflow. Today there are several emerging services and tools for AI-driven material design, however, most of them provide only partial technical components (e.g. data analyzer, regression model, structure generator, etc.), that are useful for specific purposes, but for comprehensive material design, those components need to be orchestrated appropriately. Our material design system provides an end-to-end solution to this problem, with a workflow that consists of data input, feature encoding, prediction modeling, solution search, and structure generation. The system builds a regression model to predict properties, solves an inverse problem on the trained model, and generates novel chemical structure candidates that satisfy the target properties. In this paper we will introduce the methodology of our system, and demonstrate a simple example of inverse design generating new chemical structures that satisfy targeted physical property values.",
        "published": "2020-01-20T09:15:51Z",
        "link": "http://arxiv.org/abs/2001.09038v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A Neural Network based Shock Detection and Localization Approach for   Discontinuous Galerkin Methods",
        "authors": [
            "Andrea D. Beck",
            "Jonas Zeifang",
            "Anna Schwarz",
            "David G. Flad"
        ],
        "summary": "The stable and accurate approximation of discontinuities such as shocks on a finite computational mesh is a challenging task. Detection of shocks or strong discontinuities in the flow solution is typically achieved through a priori troubled cell indicators, which guide the subsequent action of an appropriate shock capturing mechanism. Arriving at a stable and accurate solution often requires empirically based parameter tuning and adjustments of the indicator settings to the discretization and solution at hand. In this work, we propose to separate the task of shock detection and shock capturing more strongly and aim to develop a shock indicator that is robust, accurate, requires minimal user input and is suitable for high order element-based methods like discontinuous Galerkin and flux reconstruction methods. The novel indicator is learned from analytical data through a supervised learning strategy; its input is given by the high order solution field, its output is an element-local map of the shock position. We use state of the art methods from edge detection in image analysis based on deep convolutional multiscale networks and deep supervision to train the indicators. The resulting networks are then used as black box indicators, showing their robustness and accuracy on well established canonical testcases. All simulations are run ab initio using the developed indicators, showing that they provide also stability during the strongly transient phases. In particular for high order schemes with large cells and considerable inner-cell resolution capabilities, we demonstrate how the additional accurate prediction of the position of the shock front can be exploited to guide inner-element shock capturing strategies.",
        "published": "2020-01-20T10:37:34Z",
        "link": "http://arxiv.org/abs/2001.08201v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "High-order mixed finite elements for an energy-based model of the   polarization process in ferroelectric materials",
        "authors": [
            "Astrid S. Pechstein",
            "Martin Meindlhumer",
            "Alexander Humer"
        ],
        "summary": "An energy-based model of the ferroelectric polarization process is presented in the current contribution. In an energy-based setting, dielectric displacement and strain (or displacement) are the primary independent unknowns. As an internal variable, the remanent polarization vector is chosen. The model is then governed by two constitutive functions: the free energy function and the dissipation function. Choices for both functions are given. As the dissipation function for rate-independent response is non-differentiable, it is proposed to regularize the problem. Then, a variational equation can be posed, which is subsequently discretized using conforming finite elements for each quantity. We point out which kind of continuity is needed for each field (displacement, dielectric displacement and remanent polarization) is necessary to obtain a conforming method, and provide corresponding finite elements. The elements are chosen such that Gauss' law of zero charges is satisfied exactly. The discretized variational equations are solved for all unknowns at once in a single Newton iteration. We present numerical examples gained in the open source software package Netgen/NGSolve.",
        "published": "2020-01-20T13:41:16Z",
        "link": "http://arxiv.org/abs/2001.07105v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "A 3D-1D coupled blood flow and oxygen transport model to generate   microvascular networks",
        "authors": [
            "Tobias Köppl",
            "Ettore Vidotto",
            "Barbara Wohlmuth"
        ],
        "summary": "In this work, we introduce an algorithmic approach to generate microvascular networks starting from larger vessels that can be reconstructed without noticeable segmentation errors. Contrary to larger vessels, the reconstruction of fine-scale components of microvascular networks shows significant segmentation errors, and an accurate mapping is time and cost intense. Thus there is a need for fast and reliable reconstruction algorithms yielding surrogate networks having similar stochastic properties as the original ones. The microvascular networks are constructed in a marching way by adding vessels to the outlets of the vascular tree from the previous step. To optimise the structure of the vascular trees, we use Murray's law to determine the radii of the vessels and bifurcation angles. In each step, we compute the local gradient of the partial pressure of oxygen and adapt the orientation of the new vessels to this gradient. At the same time, we use the partial pressure of oxygen to check whether the considered tissue block is supplied sufficiently with oxygen. Computing the partial pressure of oxygen, we use a 3D-1D coupled model for blood flow and oxygen transport. To decrease the complexity of a fully coupled 3D model, we reduce the blood vessel network to a 1D graph structure and use a bi-directional coupling with the tissue which is described by a 3D homogeneous porous medium. The resulting surrogate networks are analysed with respect to morphological and physiological aspects.",
        "published": "2020-01-20T17:53:59Z",
        "link": "http://arxiv.org/abs/2001.07186v4",
        "categories": [
            "cs.CE",
            "q-bio.TO"
        ]
    },
    {
        "title": "Vector Single-Source Surface Integral Equation for TE Scattering From   Cylindrical Multilayered Objects",
        "authors": [
            "Zekun Zhu",
            "Xiaochao Zhou",
            "Shunchuan Yang",
            "Zhizhang",
            "Chen"
        ],
        "summary": "A single-source surface integral equation (SS-SIE) for transverse electric (TE) scattering from cylindrical multilayered objects is proposed in this paper. By incorporating the differential surface admittance operator (DSAO) and recursively applying the surface equivalence theorem from innermost to outermost boundaries, an equivalent model with only electric current density on the outermost boundary can be obtained. In addition, an integration approach is proposed, where the small argument expansion of the Hankel function is used to evaluate the singular and nearly singular integrals. Compared with other SIEs, such as the Poggio-Miller-Chang-Harrington-Wu-Tsai (PMCHWT) formulation, the computational expenditure is reduced for multilayered structures because only a single source is needed on the outermost boundary. As shown in the numerical results, the proposed method generates only 19% of unknowns, uses 26% of memory, and requires 29% of the CPU time of the PMCHWT formulation.",
        "published": "2020-01-21T09:38:20Z",
        "link": "http://arxiv.org/abs/2001.07408v3",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A Multi-Vector Interface Quasi-Newton Method with Linear Complexity for   Partitioned Fluid-Structure Interaction",
        "authors": [
            "Thomas Spenke",
            "Norbert Hosters",
            "Marek Behr"
        ],
        "summary": "In recent years, interface quasi-Newton methods have gained growing attention in the fluid-structure interaction community by significantly improving partitioned solution schemes: They not only help to control the inherent added-mass instability, but also prove to substantially speed up the coupling's convergence. In this work, we present a novel variant: The key idea is to build on the multi-vector Jacobian update scheme first presented by Bogaers et al. (2014) and avoid any explicit representation of the (inverse) Jacobian approximation, since it slows down the solution for large systems. Instead, all terms involving a quadratic complexity have been systematically eliminated. The result is a new multi-vector interface quasi-Newton variant whose computational cost scales linearly with the problem size.",
        "published": "2020-01-22T10:31:27Z",
        "link": "http://arxiv.org/abs/2001.07947v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "The divergence-conforming immersed boundary method: Application to   vesicle and capsule dynamics",
        "authors": [
            "Hugo Casquero",
            "Carles Bona-Casas",
            "Deepesh Toshniwal",
            "Thomas J. R. Hughes",
            "Hector Gomez",
            "Yongjie Jessica Zhang"
        ],
        "summary": "We extend the recently introduced divergence-conforming immersed boundary (DCIB) method [1] to fluid-structure interaction (FSI) problems involving closed co-dimension one solids. We focus on capsules and vesicles, whose discretization is particularly challenging due to the higher-order derivatives that appear in their formulations. In two-dimensional settings, we employ cubic B-splines with periodic knot vectors to obtain discretizations of closed curves with C^2 inter-element continuity. In three-dimensional settings, we use analysis-suitable bi-cubic T-splines to obtain discretizations of closed surfaces with at least C^1 inter-element continuity. Large spurious changes of the fluid volume inside closed co-dimension one solids is a well-known issue for IB methods. The DCIB method results in volume changes orders of magnitude lower than conventional IB methods. This is a byproduct of discretizing the velocity-pressure pair with divergence-conforming B-splines, which lead to negligible incompressibility errors at the Eulerian level. The higher inter-element continuity of divergence-conforming B-splines is also crucial to avoid the quadrature/interpolation errors of IB methods becoming the dominant discretization error. Benchmark and application problems of vesicle and capsule dynamics are solved, including mesh-independence studies and comparisons with other numerical methods.",
        "published": "2020-01-22T19:38:22Z",
        "link": "http://arxiv.org/abs/2001.08244v1",
        "categories": [
            "physics.flu-dyn",
            "cs.CE"
        ]
    },
    {
        "title": "A New Meshless \"Fragile Points Method\" and A Local Variational Iteration   Method for General Transient Heat Conduction in Anisotropic Nonhomogeneous   Media",
        "authors": [
            "Yue Guan",
            "Rade Grujicic",
            "Xuechuan Wang",
            "Leiting Dong",
            "Satya N. Atluri"
        ],
        "summary": "A new and effective computational approach is presented for analyzing transient heat conduction problems. The approach consists of a meshless Fragile Points Method (FPM) being utilized for spatial discretization, and a Local Variational Iteration (LVI) scheme for time discretization. Anisotropy and nonhomogeneity do not give rise to any difficulties in the present implementation. The meshless FPM is based on a Galerkin weak-form formulation and thus leads to symmetric matrices. Local, very simple, polynomial and discontinuous trial and test functions are employed. In the meshless FPM, Interior Penalty Numerical Fluxes are introduced to ensure the consistency of the method. The LVIM in the time domain is generated as a combination of the Variational Iteration Method (VIM) applied over a large time interval and numerical algorithms. A set of collocation nodes are employed in each finitely large time interval. The FPM + LVIM approach is capable of solving transient heat transfer problems in complex geometries with mixed boundary conditions, including pre-existing cracks. Numerical examples are presented in 2D and 3D domains. Both functionally graded materials and composite materials are considered. It is shown that, with suitable computational parameters, the FPM + LVIM approach is not only accurate, but also efficient, and has reliable stability under relatively large time intervals. The present methodology represents a considerable improvement to the current state of science in computational transient heat conduction in anisotropic nonhomogeneous media.",
        "published": "2020-01-23T18:17:52Z",
        "link": "http://arxiv.org/abs/2001.09034v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "juSFEM: A Julia-based Open-source Package of Parallel Smoothed Finite   Element Method (S-FEM) for Elastic Problems",
        "authors": [
            "Zenan Huo",
            "Gang Mei",
            "Nengxiong Xu"
        ],
        "summary": "The Smoothed Finite Element Method (S-FEM) proposed by Liu G.R. can achieve more accurate results than the conventional FEM. Currently, much commercial software and many open-source packages have been developed to analyze various science and engineering problems using the FEM. However, there is little work focusing on designing and developing software or packages for the S-FEM. In this paper, we design and implement an open-source package of the parallel S-FEM for elastic problems by utilizing the Julia language on multi-core CPU. The Julia language is a fast, easy-to-use, and open-source programming language that was originally designed for high-performance computing. We term our package as juSFEM. To the best of the authors knowledge, juSFEM is the first package of parallel S-FEM developed with the Julia language. To verify the correctness and evaluate the efficiency of juSFEM, two groups of benchmark tests are conducted. The benchmark results show that (1) juSFEM can achieve accurate results when compared to commercial FEM software ABAQUS, and (2) juSFEM only requires 543 seconds to calculate the displacements of a 3D elastic cantilever beam model which is composed of approximately 2 million tetrahedral elements, while in contrast the commercial FEM software needs 930 seconds for the same calculation model; (3) the parallel juSFEM executed on the 24-core CPU is approximately 20x faster than the corresponding serial version. Moreover, the structure and function of juSFEM are easily modularized, and the code in juSFEM is clear and readable, which is convenient for further development.",
        "published": "2020-01-23T23:37:15Z",
        "link": "http://arxiv.org/abs/2001.08849v1",
        "categories": [
            "cs.MS",
            "cs.CE"
        ]
    },
    {
        "title": "Electric Field Propagation Through Singular Value Decomposition",
        "authors": [
            "David Yevick"
        ],
        "summary": "We demonstrate that the singular value decomposition algorithm in conjunction with the fast Fourier transform or finite difference procedures provides a straightforward and accurate method for rapidly propagating electric fields in the one-way Helmholtz formalism.",
        "published": "2020-01-24T09:29:12Z",
        "link": "http://arxiv.org/abs/2001.09842v1",
        "categories": [
            "cs.CE",
            "eess.IV"
        ]
    },
    {
        "title": "Clustering Methods Assessment for Investment in Zero Emission   Neighborhoods Energy System",
        "authors": [
            "Dimitri Pinel"
        ],
        "summary": "This paper investigates the use of clustering in the context of designing the energy system of Zero Emission Neighborhoods (ZEN). ZENs are neighborhoods who aim to have net zero emissions during their lifetime. While previous work has used and studied clustering for designing the energy system of neighborhoods, no article dealt with neighborhoods such as ZEN, which have high requirements for the solar irradiance time series, include a CO2 factor time series and have a zero emission balance limiting the possibilities. To this end several methods are used and their results compared. The results are on the one hand the performances of the clustering itself and on the other hand, the performances of each method in the optimization model where the data is used. Various aspects related to the clustering methods are tested. The different aspects studied are: the goal (clustering to obtain days or hours), the algorithm (k-means or k-medoids), the normalization method (based on the standard deviation or range of values) and the use of heuristic. The results highlight that k-means offers better results than k-medoids and that k-means was systematically underestimating the objective value while k-medoids was constantly overestimating it. When the choice between clustering days and hours is possible, it appears that clustering days offers the best precision and solving time. The choice depends on the formulation used for the optimization model and the need to model seasonal storage. The choice of the normalization method has the least impact, but the range of values method show some advantages in terms of solving time. When a good representation of the solar irradiance time series is needed, a higher number of days or using hours is necessary. The choice depends on what solving time is acceptable.",
        "published": "2020-01-24T10:22:53Z",
        "link": "http://arxiv.org/abs/2001.08936v1",
        "categories": [
            "math.OC",
            "cs.CE"
        ]
    },
    {
        "title": "Solving Maxwell's Eigenvalue Problem via Isogeometric Boundary Elements   and a Contour Integral Method",
        "authors": [
            "Stefan Kurz",
            "Sebastian Schöps",
            "Gerhard Unger",
            "Felix Wolf"
        ],
        "summary": "We solve Maxwell's eigenvalue problem via isogeometric boundary elements and a contour integral method. We discuss the analytic properties of the discretisation, outline the implementation, and showcase numerical examples.",
        "published": "2020-01-27T10:54:08Z",
        "link": "http://arxiv.org/abs/2001.09686v2",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA",
            "34L16, 35P30, 65N38, 65D07"
        ]
    },
    {
        "title": "Reservoir computing model of two-dimensional turbulent convection",
        "authors": [
            "Sandeep Pandey",
            "Jörg Schumacher"
        ],
        "summary": "Reservoir computing is applied to model the large-scale evolution and the resulting low-order turbulence statistics of a two-dimensional turbulent Rayleigh-B\\'{e}nard convection flow at a Rayleigh number ${\\rm Ra}=10^7$ and a Prandtl number ${\\rm Pr}=7$ in an extended domain with an aspect ratio of 6. Our data-driven approach which is based on a long-term direct numerical simulation of the convection flow comprises a two-step procedure. (1) Reduction of the original simulation data by a Proper Orthogonal Decomposition (POD) snapshot analysis and subsequent truncation to the first 150 POD modes which are associated with the largest total energy amplitudes. (2) Setup and optimization of a reservoir computing model to describe the dynamical evolution of these 150 degrees of freedom and thus the large-scale evolution of the convection flow. The quality of the prediction of the reservoir computing model is comprehensively tested. At the core of the model is the reservoir, a very large sparse random network charcterized by the spectral radius of the corresponding adjacency matrix and a few further hyperparameters which are varied to investigate the quality of the prediction. Our work demonstrates that the reservoir computing model is capable to model the large-scale structure and low-order statistics of turbulent convection which can open new avenues for modeling mesoscale convection processes in larger circulation models.",
        "published": "2020-01-28T11:49:25Z",
        "link": "http://arxiv.org/abs/2001.10280v2",
        "categories": [
            "physics.flu-dyn",
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "Automatic weak imposition of free slip boundary conditions via Nitsche's   method: application to nonlinear problems in geodynamics",
        "authors": [
            "Nathan Sime",
            "Cian R. Wilson"
        ],
        "summary": "Imposition of free slip boundary conditions in science and engineering simulations presents a challenge when the simulation domain is non-trivial. Inspired by recent progress in symbolic computation of discontinuous Galerkin finite element methods, we present a symmetric interior penalty form of Nitsche's method to weakly impose these slip boundary conditions and present examples of its use in the Stokes subsystem motivated by problems in geodynamics. We compare numerical results with well established benchmark problems. We also examine performance of the method with iterative solvers.",
        "published": "2020-01-28T23:38:22Z",
        "link": "http://arxiv.org/abs/2001.10639v1",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Investigation of Numerical Dispersion with Time Step of The FDTD   Methods: Avoiding Erroneous Conclusions",
        "authors": [
            "Yu Cheng",
            "Guangzhi Chen",
            "Xiang-Hua Wang",
            "Shunchuan Yang"
        ],
        "summary": "It is widely thought that small time steps lead to small numerical errors in the finite-difference time-domain (FDTD) simulations. In this paper, we investigated how time steps impact on numerical dispersion of two FDTD methods including the FDTD(2,2) method and the FDTD(2,4) method. Through rigorously analytical and numerical analysis, it is found that small time steps of the FDTD methods do not always have small numerical errors. Our findings reveal that these two FDTD methods present different behaviors with respect to time steps: (1) for the FDTD(2,2) method, smaller time steps limited by the Courant-Friedrichs-Lewy (CFL) condition increase numerical dispersion and lead to larger simulation errors; (2) for the FDTD(2,4) method, as time step increases, numerical dispersion errors first decrease and then increase. Our findings are also comprehensively validated from one- to three-dimensional cases through several numerical examples including wave propagation, resonant frequencies of cavities and a practical electromagnetic compatibility (EMC) problem.",
        "published": "2020-01-29T08:28:46Z",
        "link": "http://arxiv.org/abs/2001.10721v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Reduced-Space Interior Point Methods in Power Grid Problems",
        "authors": [
            "Juraj Kardos",
            "Drosos Kourounis",
            "Olaf Schenk"
        ],
        "summary": "Due to critical environmental issues, the power systems have to accommodate a significant level of penetration of renewable generation which requires smart approaches to the power grid control. Associated optimal control problems are large-scale nonlinear optimization problems with up to hundreds of millions of variables and constraints. The interior point methods become computationally intractable, mainly due to the solution of large linear systems.   This document addresses the computational bottlenecks of the interior point method during the solution of the security constrained optimal power flow problems by applying reduced space quasi-Newton IPM, which could utilize high-performance computers due to the inherent parallelism in the adjoint method. Reduced space IPM approach and the adjoint method is a novel approach when it comes to solving the (security constrained) optimal power flow problems. These were previously used in the PDE-constrained optimization. The presented methodology is suitable for high-performance architectures due to inherent parallelism in the adjoint method during the gradient evaluation, since the individual contingency scenarios are modeled by independent set of the constraints. Preliminary evaluation of the performance and convergence is performed to study the reduced space approach.",
        "published": "2020-01-29T13:26:32Z",
        "link": "http://arxiv.org/abs/2001.10815v1",
        "categories": [
            "math.OC",
            "cs.CE",
            "cs.DC"
        ]
    },
    {
        "title": "FEA-Net: A Physics-guided Data-driven Model for Efficient Mechanical   Response Prediction",
        "authors": [
            "Houpu Yao",
            "Yi Gao",
            "Yongming Liu"
        ],
        "summary": "An innovative physics-guided learning algorithm for predicting the mechanical response of materials and structures is proposed in this paper. The key concept of the proposed study is based on the fact that physics models are governed by Partial Differential Equation (PDE), and its loading/ response mapping can be solved using Finite Element Analysis (FEA). Based on this, a special type of deep convolutional neural network (DCNN) is proposed that takes advantage of our prior knowledge in physics to build data-driven models whose architectures are of physics meaning. This type of network is named as FEA-Net and is used to solve the mechanical response under external loading. Thus, the identification of a mechanical system parameters and the computation of its responses are treated as the learning and inference of FEA-Net, respectively. Case studies on multi-physics (e.g., coupled mechanical-thermal analysis) and multi-phase problems (e.g., composite materials with random micro-structures) are used to demonstrate and verify the theoretical and computational advantages of the proposed method.",
        "published": "2020-01-31T09:37:44Z",
        "link": "http://arxiv.org/abs/2002.01893v1",
        "categories": [
            "cs.CE",
            "cs.LG",
            "stat.ML"
        ]
    },
    {
        "title": "Topology optimization of 2D structures with nonlinearities using deep   learning",
        "authors": [
            "Diab W. Abueidda",
            "Seid Koric",
            "Nahil A. Sobh"
        ],
        "summary": "The field of optimal design of linear elastic structures has seen many exciting successes that resulted in new architected materials and structural designs. With the availability of cloud computing, including high-performance computing, machine learning, and simulation, searching for optimal nonlinear structures is now within reach. In this study, we develop convolutional neural network models to predict optimized designs for a given set of boundary conditions, loads, and optimization constraints. We have considered the case of materials with a linear elastic response with and without stress constraint. Also, we have considered the case of materials with a hyperelastic response, where material and geometric nonlinearities are involved. For the nonlinear elastic case, the neo-Hookean model is utilized. For this purpose, we generate datasets composed of the optimized designs paired with the corresponding boundary conditions, loads, and constraints, using a topology optimization framework to train and validate the neural network models. The developed models are capable of accurately predicting the optimized designs without requiring an iterative scheme and with negligible inference computational time. The suggested pipeline can be generalized to other nonlinear mechanics scenarios and design domains.",
        "published": "2020-01-31T12:36:17Z",
        "link": "http://arxiv.org/abs/2002.01896v4",
        "categories": [
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "lbmpy: Automatic code generation for efficient parallel lattice   Boltzmann methods",
        "authors": [
            "Martin Bauer",
            "Harald Köstler",
            "Ulrich Rüde"
        ],
        "summary": "Lattice Boltzmann methods are a popular mesoscopic alternative to macroscopic computational fluid dynamics solvers. Many variants have been developed that vary in complexity, accuracy, and computational cost. Extensions are available to simulate multi-phase, multi-component, turbulent, or non-Newtonian flows. In this work we present lbmpy, a code generation package that supports a wide variety of different methods and provides a generic development environment for new schemes as well. A high-level domain-specific language allows the user to formulate, extend and test various lattice Boltzmann schemes. The method specification is represented in a symbolic intermediate representation. Transformations that operate on this intermediate representation optimize and parallelize the method, yielding highly efficient lattice Boltzmann compute kernels not only for single- and two-relaxation-time schemes but also for multi-relaxation-time, cumulant, and entropically stabilized methods. An integration into the HPC framework waLBerla makes massively parallel, distributed simulations possible, which is demonstrated through scaling experiments on the SuperMUC-NG supercomputing system",
        "published": "2020-01-31T13:00:26Z",
        "link": "http://arxiv.org/abs/2001.11806v2",
        "categories": [
            "cs.MS",
            "cs.CE",
            "cs.DC"
        ]
    },
    {
        "title": "Algorithms for 2D Mesh Decomposition in Distributed Design Optimization",
        "authors": [
            "Shuvodeep De",
            "Rakesh K. Kapania"
        ],
        "summary": "Optimization of thin-walled structures like an aircraft wing, aircraft fuselage or submarine hull often involves dividing the shell surface into numerous localized panels, each characterized by its own set of design variables. The process of extracting information about a localized panel (nodal coordinates, mesh connectivity) from a finite element model, input file is usually a problem-specific task. In this work, a generalized process to extract localized panels from the two-dimensional (2D) mesh is discussed. The process employs set operations on elemental connectivity information and is independent of nodal coordinates. Thus, it is capable of extracting panel of any shape given the boundary and thus can be used during optimization of a wide range of structures. A method to create stiffeners on the resulting local panels is also presented, and the effect of stiffener element size on buckling is studied. The local panel extraction process is demonstrated by integrating it into a distributed MDO framework for optimization of an aircraft wing having curvilinear spars and ribs (SpaRibs). A range of examples is included wherein the process is used to create panels on the wing-skin, bounded by adjacent SpaRibs.",
        "published": "2020-02-03T01:21:40Z",
        "link": "http://arxiv.org/abs/2002.00525v4",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Diffusion bridges for stochastic Hamiltonian systems and shape   evolutions",
        "authors": [
            "Alexis Arnaudon",
            "Frank van der Meulen",
            "Moritz Schauer",
            "Stefan Sommer"
        ],
        "summary": "Stochastically evolving geometric systems are studied in shape analysis and computational anatomy for modelling random evolutions of human organ shapes. The notion of geodesic paths between shapes is central to shape analysis and has a natural generalisation as diffusion bridges in a stochastic setting. Simulation of such bridges is key to solve inference and registration problems in shape analysis. We demonstrate how to apply state-of-the-art diffusion bridge simulation methods to recently introduced stochastic shape deformation models thereby substantially expanding the applicability of such models. We exemplify these methods by estimating template shapes from observed shape configurations while simultaneously learning model parameters.",
        "published": "2020-02-03T16:57:02Z",
        "link": "http://arxiv.org/abs/2002.00885v4",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "physics.comp-ph"
        ]
    },
    {
        "title": "An efficient algorithm for numerical homogenization of fluid filled   porous solids: part-I",
        "authors": [
            "Saumik Dana",
            "Mary F Wheeler"
        ],
        "summary": "The concept of representative volume element or RVE is invoked to develop an algorithm for numerical homogenization of fluid filled porous solids. RVE based methods decouple analysis of a composite material into analyses at the local and global levels. The local level analysis models the microstructural details to determine effective properties by applying boundary conditions to the RVE and solving the resultant boundary value problem. The composite structure is then replaced by an equivalent homogeneous material having the calculated effective properties. We combine the features of two techniques: one is the definition of a displacement field for the fluid phase to allow for a definition of a continuous displacement field across the microstructure and the other is the $FE^2$ numerical homogenization that couples the macroscale with the RVE scale via gauss points.",
        "published": "2020-02-03T21:42:47Z",
        "link": "http://arxiv.org/abs/2002.03770v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Generation of smoothly-varying infill configurations from a continuous   menu of cell patterns and the asymptotic analysis of its mechanical behaviour",
        "authors": [
            "Dingchuan Xue",
            "Yichao Zhu",
            "Xu Guo"
        ],
        "summary": "We here introduce a novel scheme for generating smoothly-varying infill graded microstructural (IGM) configurations from a given menu of generating cells. The scheme was originally proposed for essentially improving the variety of describable configurations in a modified asymptotic homogenisation-based topology optimisation framework [1] for fast IGM design. But the proposed scheme, after modification, also demonstrates its unique values in two aspects of applications. First, it provides a fairly simple way of generating an IGM configuration continuously patching any given cell configurations. Second, it tenders a straightforward mean for decorating microstructures on a given manifold. We will further show that the form of topology description function given here effectively offers a platform for unifying most existing approaches for IGM generation. Fuelled by asymptotic analysis of the mechanical behaviour of the resulting IGM configurations, a topology optimisation scheme for compliance minimisation is introduced. We will finally show that, the use of the present scheme helps reduce the compliance value of an optimised structure by nearly a half, if compared with that from the original framework [1].",
        "published": "2020-02-04T03:07:00Z",
        "link": "http://arxiv.org/abs/2002.01894v2",
        "categories": [
            "cs.CE",
            "physics.app-ph"
        ]
    },
    {
        "title": "On the generation of periodic discrete structures with identical   two-point correlation",
        "authors": [
            "Mauricio Fernández",
            "Felix Fritzen"
        ],
        "summary": "Strategies for the generation of periodic discrete structures with identical two-point correlation are developed. Starting from a pair of root structures, which are not related by translation, phase inversion or axis reflections, child structures of arbitrary resolution (i.e., pixel or voxel numbers) and number of phases (i.e., material phases/species) can be generated by means of trivial embedding based phase extension, application of kernels and/or phase coalescence, such that the generated structures inherit the two-point-correlation equivalence. Proofs of the inheritance property are provided by means of the Discrete Fourier Transform theory. A Python 3 implementation of the results is offered by the authors through the Github repository https://github.com/DataAnalyticsEngineering/EQ2PC in order to make the provided results reproducible and useful for all interested readers. Examples for the generation of structures are demonstrated, together with applications in the homogenization theory of periodic media.",
        "published": "2020-02-04T11:35:29Z",
        "link": "http://arxiv.org/abs/2002.01234v1",
        "categories": [
            "cs.CE",
            "74A40 (Primary), 68U10 (Secondary), 62P30"
        ]
    },
    {
        "title": "Diffusion in arrays of obstacles: beyond homogenisation",
        "authors": [
            "Yahya Farah",
            "Daniel Loghin",
            "Alexandra Tzella",
            "Jacques Vanneste"
        ],
        "summary": "We revisit the classical problem of diffusion of a scalar (or heat) released in a two-dimensional medium with an embedded periodic array of impermeable obstacles such as perforations. Homogenisation theory provides a coarse-grained description of the scalar at large times and predicts that it diffuses with a certain effective diffusivity, so the concentration is approximately Gaussian. We improve on this by developing a large-deviation approximation which also captures the non-Gaussian tails of the concentration through a rate function obtained by solving a family of eigenvalue problems. We focus on cylindrical obstacles and on the dense limit, when the obstacles occupy a large area fraction and non-Gaussianity is most marked. We derive an asymptotic approximation for the rate function in this limit, valid uniformly over a wide range of distances. We use finite-element implementations to solve the eigenvalue problems yielding the rate function for arbitrary obstacle area fractions and an elliptic boundary-value problem arising in the asymptotics calculation. Comparison between numerical results and asymptotic predictions confirm the validity of the latter.",
        "published": "2020-02-04T18:18:08Z",
        "link": "http://arxiv.org/abs/2002.04526v2",
        "categories": [
            "cs.CE",
            "physics.class-ph",
            "physics.comp-ph",
            "physics.flu-dyn"
        ]
    },
    {
        "title": "Self-Directed Online Machine Learning for Topology Optimization",
        "authors": [
            "Changyu Deng",
            "Yizhou Wang",
            "Can Qin",
            "Yun Fu",
            "Wei Lu"
        ],
        "summary": "Topology optimization by optimally distributing materials in a given domain requires non-gradient optimizers to solve highly complicated problems. However, with hundreds of design variables or more involved, solving such problems would require millions of Finite Element Method (FEM) calculations whose computational cost is huge and impractical. Here we report Self-directed Online Learning Optimization (SOLO) which integrates Deep Neural Network (DNN) with FEM calculations. A DNN learns and substitutes the objective as a function of design variables. A small number of training data is generated dynamically based on the DNN's prediction of the optimum. The DNN adapts to the new training data and gives better prediction in the region of interest until convergence. The optimum predicted by the DNN is proved to converge to the true global optimum through iterations. Our algorithm was tested by four types of problems including compliance minimization, fluid-structure optimization, heat transfer enhancement and truss optimization. It reduced the computational time by 2 ~ 5 orders of magnitude compared with directly using heuristic methods, and outperformed all state-of-the-art algorithms tested in our experiments. This approach enables solving large multi-dimensional optimization problems.",
        "published": "2020-02-04T20:00:28Z",
        "link": "http://arxiv.org/abs/2002.01927v8",
        "categories": [
            "cs.CE",
            "cs.LG",
            "stat.ML"
        ]
    },
    {
        "title": "Fracture in random quasibrittle media: I. Discrete mesoscale simulations   of load capacity and fracture process zone",
        "authors": [
            "Jan Eliáš",
            "Miroslav Vořechovský"
        ],
        "summary": "Numerical simulations of concrete fracture performed with a probabilistic mesoscale discrete model are presented. The model represents a substantial part of material randomness by assigning random locations to the largest aggregates. The remaining part of randomness is introduced by causing material parameters to fluctuate randomly via a homogeneous random field. An extensive numerical study performed with the model considers prisms loaded in uniaxial tension with both fixed and rotating platens, and also beams with and without a notch loaded in three point bending. The results show the nontrivial effect of (i) autocorrelation length and (ii) variance of the random field on the fracture behavior of the model. Statistics of the peak load are presented as well as the size and shape of the fracture process zone at the moment when the maximum load is attained. Local averaging within the fracture process zone and weakest-link are identified as underlying mechanisms explaining the reported results. The companion paper, Part II [64], introduces an analytical model capable of predicting the distribution of the peak load obtained with the probabilistic discrete model via the simple estimation of extremes of a random field obtained as moving average of local strength.",
        "published": "2020-02-05T14:24:14Z",
        "link": "http://arxiv.org/abs/2002.01804v2",
        "categories": [
            "cs.CE",
            "cond-mat.mtrl-sci"
        ]
    },
    {
        "title": "Damage-sensitive and domain-invariant feature extraction for   vehicle-vibration-based bridge health monitoring",
        "authors": [
            "Jingxiao Liu",
            "Bingqing Chen",
            "Siheng Chen",
            "Mario Berges",
            "Jacobo Bielak",
            "HaeYoung Noh"
        ],
        "summary": "We introduce a physics-guided signal processing approach to extract a damage-sensitive and domain-invariant (DS & DI) feature from acceleration response data of a vehicle traveling over a bridge to assess bridge health. Motivated by indirect sensing methods' benefits, such as low-cost and low-maintenance, vehicle-vibration-based bridge health monitoring has been studied to efficiently monitor bridges in real-time. Yet applying this approach is challenging because 1) physics-based features extracted manually are generally not damage-sensitive, and 2) features from machine learning techniques are often not applicable to different bridges. Thus, we formulate a vehicle bridge interaction system model and find a physics-guided DS & DI feature, which can be extracted using the synchrosqueezed wavelet transform representing non-stationary signals as intrinsic-mode-type components. We validate the effectiveness of the proposed feature with simulated experiments. Compared to conventional time- and frequency-domain features, our feature provides the best damage quantification and localization results across different bridges in five of six experiments.",
        "published": "2020-02-06T05:45:39Z",
        "link": "http://arxiv.org/abs/2002.02105v1",
        "categories": [
            "cs.CE",
            "cs.LG",
            "eess.SP",
            "physics.app-ph",
            "68T10 (Primary), 37N20 (Secondary)",
            "I.5.4; J.2"
        ]
    },
    {
        "title": "An Object-Oriented Library for Heat Transfer Modelling and Simulation in   Open Cell Foams",
        "authors": [
            "Tobias M. Scheuermann",
            "Paul Kotyczka",
            "Christian Martens",
            "Haithem Louati",
            "Bernhard Maschke",
            "Marie-Line Zanota",
            "Isabelle Pitault"
        ],
        "summary": "Metallic open cell foams have multiple applications in industry, e. g. as catalyst supports in chemical processes. Their regular or heterogeneous microscopic structure determines the macroscopic thermodynamic and chemical properties. We present an object-oriented python library that generates state space models for simulation and control from the microscopic foam data, which can be imported from the image processing tool iMorph. The foam topology and the 3D geometric data are the basis for discrete modeling of the balance laws using the cell method. While the material structure imposes a primal chain complex to define discrete thermodynamic driving forces, the internal energy balance is evaluated on a second chain complex, which is constructed by topological duality. The heat exchange between the solid and the fluid phase is described based on the available surface data. We illustrate in detail the construction of the dual chain complexes, and we show how the structured discrete model directly maps to the software objects of the python code. As a test case, we present simulation results for a foam with a Kelvin cell structure, and compare them to a surrogate finite element model with homogeneous parameters.",
        "published": "2020-02-06T10:29:45Z",
        "link": "http://arxiv.org/abs/2002.03789v1",
        "categories": [
            "cs.CE",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Progress Report on Numerical Modeling of a Prototype Fuel Cell",
        "authors": [
            "O. Beruski",
            "I. Korkischko",
            "T. Lopes",
            "F. C. Fonseca"
        ],
        "summary": "Progress on the numerical modeling of a prototype fuel cell is reported. Some known limitations of the previously published Alpha model are addressed, and the numerical uncertainty due to discretization of the improved model, Beta, was estimated. In Part 1, the Beta model is compared to Alpha, where significant albeit small differences are seen. Shortcomings of the improved model are discussed, paving the way forward, while a discrepancy with previous results is addressed, further suggesting the use of the Darcy-Brinkman over Stokes-Darcy formulation for free and porous media flow. Furthermore, a parametric study is carried out, constraining plausible values of the reaction rate constants identifying additional opportunities for validation. In Part 2, a mesh convergence study is carried out to estimate the discretization error of Beta model. A reduced, proxy geometry and two extrapolation schemes are used to estimate the exact solution, which is then used to estimate the model's uncertainty through the Grid Convergence Index framework. Error estimates are on average $\\sim 10\\%$ for the flow rate range simulated, larger than experimental ones available. Results suggest a difficulty in achieving mesh convergence in fuel cell-like models, even in simpler cases. Caution is thus suggested during validation or when devising predictions from numerical models. Finally, given the uncertainties in the numerical data and the available experimental data, the results lack validation power, highlighting the need for additional experimental data and improved precision for the numerical data.",
        "published": "2020-02-07T19:29:52Z",
        "link": "http://arxiv.org/abs/2002.04519v3",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Magnetic Field Simulation with Data-Driven Material Modeling",
        "authors": [
            "Herbert De Gersem",
            "Armin Galetzka",
            "Ion Gabriel Ion",
            "Dimitrios Loukrezis",
            "Ulrich Römer"
        ],
        "summary": "This paper developes a data-driven magnetostatic finite-element (FE) solver which directly exploits measured material data instead of a material curve constructed from it. The distances between the field solution and the measurement points are minimized while enforcing Maxwell's equations. The minimization problem is solved by employing the Lagrange multiplier approach. The procedure wraps the FE method within an outer data-driven iteration. The method is capable of considering anisotropic materials and is adapted to deal with models featuring a combination of exact material knowledge and measured material data. Thereto, three approaches with an increasing level of intrusivity according to the FE formulation are proposed. The numerical results for a quadrupole-magnet model show that data-driven field simulation is feasible and affordable and overcomes the need of modeling the material law.",
        "published": "2020-02-10T13:19:11Z",
        "link": "http://arxiv.org/abs/2002.03715v2",
        "categories": [
            "physics.comp-ph",
            "cs.CE"
        ]
    },
    {
        "title": "Wave propagation modeling in periodic elasto-thermo-diffusive materials   via multifield asymptotic homogenization",
        "authors": [
            "Francesca Fantoni",
            "Andrea Bacigalupo"
        ],
        "summary": "A multifield asymptotic homogenization technique for periodic thermo-diffusive elastic materials is provided in the present study. Field equations for the first-order equivalent medium are derived and overall constitutive tensors are obtained in closed form. These lasts depend upon the micro constitutive properties of the different phases composing the composite material and upon periodic perturbation functions, which allow taking into account the effects of microstructural heterogeneities. Perturbation functions are determined as solutions of recursive non homogeneous cell problems emanated from the substitution of asymptotic expansions of the micro fields in powers of the microstructural characteristic size into local balance equations. Average field equations of infinite order are also provided, whose formal solution can be obtained through asymptotic expansions of the macrofields. With the aim of investigating dispersion properties of waves propagating inside the medium, proper integral transforms are applied to governing field equations of the homogenized medium. A quadratic generalized eigenvalue problem is thus obtained, whose solution characterizes the complex valued frequency band structure of the first-order equivalent material. The validity of the proposed technique has been confirmed by the very good matching obtained between dispersion curves of the homogenized medium and the lowest frequency ones relative to the heterogeneous material. These lasts are computed from the resolution of a quadratic generalized eigenvalue problem over the periodic cell subjected to Floquet-Bloch boundary conditions. An illustrative benchmark is conducted referring to a Solid Oxide Fuel Cell (SOFC)-like material, whose microstructure can be modeled through the spatial tessellation of the domain with a periodic cell subjected to thermo-diffusive phenomena.",
        "published": "2020-02-11T15:31:35Z",
        "link": "http://arxiv.org/abs/2002.11479v1",
        "categories": [
            "physics.flu-dyn",
            "cond-mat.mtrl-sci",
            "cs.CE"
        ]
    },
    {
        "title": "Parallel Direct Domain Decomposition Methods (D3M) for Finite Elements",
        "authors": [
            "Javad Moshfegh",
            "Dimitrios G. Makris",
            "Marinos N. Vouvakis"
        ],
        "summary": "A parallel direct solution approach based on domain decomposition method (DDM) and directed acyclic graph (DAG) scheduling is outlined. Computations are represented as a sequence of small tasks that operate on domains of DDM or dense matrix blocks of a reduced matrix. These tasks can be statically scheduled for parallel execution using their DAG dependencies and weights that depend on estimates of computation and communication costs. Performance comparison with MUMPS 5.1.2 on electrically large problems suggest up to 20% better parallel efficiency, 30% less memory and slightly faster in run-time, while maintaining the same accuracy.",
        "published": "2020-02-11T17:38:43Z",
        "link": "http://arxiv.org/abs/2002.05026v1",
        "categories": [
            "cs.DC",
            "cs.CE"
        ]
    },
    {
        "title": "Direct Solution of FEM Models: Are Sparse Direct Solvers the Best   Strategy?",
        "authors": [
            "Javad Moshfegh",
            "Marinos N. Vouvakis"
        ],
        "summary": "A brief summary of direct solution approaches for finite element methods (FEM) in computational electromagnetics (CEM) is given along with an alternative direct solution based on domain decomposition (DD). Unlike recent trends in approximate/low-rank solvers, this work focuses on `numerically exact' solution methods as they are more reliable for complex `real-life' models. Preliminary studies on general three dimensional geometries with unstructured FEM meshes suggest that the proposed direct DD methodology offers significant memory advantages over highly optimized, high-performance sparse direct solver libraries, while maintaining approximately comparable or slightly slower serial serial execution speed but with significantly better parallel and GPU processing prospects.",
        "published": "2020-02-11T17:55:28Z",
        "link": "http://arxiv.org/abs/2002.05019v1",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Direct Domain Decomposition Method (D3M) for Finite Element   Electromagnetic Computations",
        "authors": [
            "Javad Moshfegh",
            "Marinos N. Vouvakis"
        ],
        "summary": "An exact arithmetic, memory efficient direct solution method for finite element method (FEM) computations is outlined. Unlike conventional black-box or low-rank direct solvers that are opaque to the underlying physical problem, the proposed method leverages physical insights at every stage of the development through a new symmetric domain decomposition method (DDM) with one set of Lagrange multipliers. Comparisons with state-of-the-art exact direct solvers on electrically large problems suggest up to 10 times less memory and better run-time complexity while maintaining the same accuracy.",
        "published": "2020-02-11T18:01:56Z",
        "link": "http://arxiv.org/abs/2002.05018v1",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Protecting Consumers Against Personalized Pricing: A Stopping Time   Approach",
        "authors": [
            "Roy Dong",
            "Erik Miehling",
            "Cedric Langbort"
        ],
        "summary": "The widespread availability of behavioral data has led to the development of data-driven personalized pricing algorithms: sellers attempt to maximize their revenue by estimating the consumer's willingness-to-pay and pricing accordingly. Our objective is to develop algorithms that protect consumer interests against personalized pricing schemes. In this paper, we consider a consumer who learns more and more about a potential purchase across time, while simultaneously revealing more and more information about herself to a potential seller. We formalize a strategic consumer's purchasing decision when interacting with a seller who uses personalized pricing algorithms, and contextualize this problem among the existing literature in optimal stopping time theory and computational finance. We provide an algorithm that consumers can use to protect their own interests against personalized pricing algorithms. This algorithmic stopping method uses sample paths to train estimates of the optimal stopping time. To the best of our knowledge, this is one of the first works that provides computational methods for the consumer to maximize her utility when decision making under surveillance. We demonstrate the efficacy of the algorithmic stopping method using a numerical simulation, where the seller uses a Kalman filter to approximate the consumer's valuation and sets prices based on myopic expected revenue maximization. Compared to a myopic purchasing strategy, we demonstrate increased payoffs for the consumer in expectation.",
        "published": "2020-02-12T02:28:30Z",
        "link": "http://arxiv.org/abs/2002.05346v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Differentially Private Call Auctions and Market Impact",
        "authors": [
            "Emily Diana",
            "Hadi Elzayn",
            "Michael Kearns",
            "Aaron Roth",
            "Saeed Sharifi-Malvajerdi",
            "Juba Ziani"
        ],
        "summary": "We propose and analyze differentially private (DP) mechanisms for call auctions as an alternative to the complex and ad-hoc privacy efforts that are common in modern electronic markets. We prove that the number of shares cleared in the DP mechanisms compares favorably to the non-private optimal and provide a matching lower bound. We analyze the incentive properties of our mechanisms and their behavior under natural no-regret learning dynamics by market participants. We include simulation results and connections to the finance literature on market impact.",
        "published": "2020-02-13T18:40:17Z",
        "link": "http://arxiv.org/abs/2002.05699v1",
        "categories": [
            "cs.GT",
            "cs.CE"
        ]
    },
    {
        "title": "Model Reduction Framework with a New Take on Active Subspaces for   Optimization Problems with Linearized Fluid-Structure Interaction Constraints",
        "authors": [
            "Gabriele Boncoraglio",
            "Charbel Farhat",
            "Charbel Bou-Mosleh"
        ],
        "summary": "In this paper, a new take on the concept of an active subspace for reducing the dimension of the design parameter space in a multidisciplinary analysis and optimization (MDAO) problem is proposed. The new approach is intertwined with the concepts of adaptive parameter sampling, projection-based model order reduction, and a database of linear, projection-based reduced-order models equipped with interpolation on matrix manifolds, in order to construct an efficient computational framework for MDAO. The framework is fully developed for MDAO problems with linearized fluid-structure interaction constraints. It is applied to the aeroelastic tailoring, under flutter constraints, of two different flight systems: a flexible configuration of NASA's Common Research Model; and NASA's Aeroelastic Research Wing #2 (ARW-2). The obtained results illustrate the feasibility of the computational framework for realistic MDAO problems and highlight the benefits of the new approach for constructing an active subspace in both terms of solution optimality and wall-clock time reduction",
        "published": "2020-02-14T02:52:26Z",
        "link": "http://arxiv.org/abs/2002.07602v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "A deep learning framework for solution and discovery in solid mechanics",
        "authors": [
            "Ehsan Haghighat",
            "Maziar Raissi",
            "Adrian Moure",
            "Hector Gomez",
            "Ruben Juanes"
        ],
        "summary": "We present the application of a class of deep learning, known as Physics Informed Neural Networks (PINN), to learning and discovery in solid mechanics. We explain how to incorporate the momentum balance and constitutive relations into PINN, and explore in detail the application to linear elasticity, and illustrate its extension to nonlinear problems through an example that showcases von~Mises elastoplasticity. While common PINN algorithms are based on training one deep neural network (DNN), we propose a multi-network model that results in more accurate representation of the field variables. To validate the model, we test the framework on synthetic data generated from analytical and numerical reference solutions. We study convergence of the PINN model, and show that Isogeometric Analysis (IGA) results in superior accuracy and convergence characteristics compared with classic low-order Finite Element Method (FEM). We also show the applicability of the framework for transfer learning, and find vastly accelerated convergence during network re-training. Finally, we find that honoring the physics leads to improved robustness: when trained only on a few parameters, we find that the PINN model can accurately predict the solution for a wide range of parameters new to the network---thus pointing to an important application of this framework to sensitivity analysis and surrogate modeling.",
        "published": "2020-02-14T08:24:53Z",
        "link": "http://arxiv.org/abs/2003.02751v2",
        "categories": [
            "cs.LG",
            "cs.CE",
            "stat.ML",
            "74S30 (primary), 74S05, 74B05, 74L05, 74L10 (secondary)",
            "J.2"
        ]
    },
    {
        "title": "Three-dimensional convolutional neural network (3D-CNN) for   heterogeneous material homogenization",
        "authors": [
            "Chengping Rao",
            "Yang Liu"
        ],
        "summary": "Homogenization is a technique commonly used in multiscale computational science and engineering for predicting collective response of heterogeneous materials and extracting effective mechanical properties. In this paper, a three-dimensional deep convolutional neural network (3D-CNN) is proposed to predict the effective material properties for representative volume elements (RVEs) with random spherical inclusions. The high-fidelity dataset generated by a computational homogenization approach is used for training the 3D-CNN models. The inference results of the trained networks on unseen data indicate that the network is capable of capturing the microstructural features of RVEs and produces an accurate prediction of effective stiffness and Poisson's ratio. The benefits of the 3D-CNN over conventional finite-element-based homogenization with regard to computational efficiency, uncertainty quantification and model's transferability are discussed in sequence. We find the salient features of the 3D-CNN approach make it a potentially suitable alternative for facilitating material design with fast product design iteration and efficient uncertainty quantification.",
        "published": "2020-02-14T17:52:48Z",
        "link": "http://arxiv.org/abs/2002.07600v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Topology-free immersed boundary method for incompressible turbulence   flows: An aerodynamic simulation for 'dirty' CAD geometry",
        "authors": [
            "Keiji Onishi",
            "Makoto Tsubokura"
        ],
        "summary": "To design a method to solve the issues of handling 'dirty' and highly complex geometries, the topology-free method combined with the immersed boundary method is presented for viscous and incompressible flows at a high Reynolds number. The method simultaneously employs a ghost-cell technique and distributed forcing technique to impose the boundary conditions. An axis-projected interpolation scheme is used to avoid searching failures during fluid and solid identification. This method yields a topology-free immersed boundary, which particularly suits flow simulations of highly complex geometries. Difficulties generally arise when generating the calculation grid for these scenarios. This method allows dirty data to be handled without any preparatory treatment work to simplify or clean-up the geometry. This method is also applicable to the coherent structural turbulence model employed in this study. The verification cases, used in conjunction with the second-order central-difference scheme, resulted in first-order accuracy at finer resolution, although the coarser resolution retained second-order accuracy. This method is fully parallelized for distributed memory platforms. In this study, the accuracy and fidelity of this method were examined by simulating the flow around the bluff body, past a flat plate, and past dirty spheres. These simulations were compared with experimental data and other established results. Finally, results from the simulation of practical applications demonstrate the ability of the method to model highly complex, non-canonical three-dimensional flows. The countermeasure based on the accurate classification of geometric features has provided a robust and reasonable solution.",
        "published": "2020-02-15T08:30:35Z",
        "link": "http://arxiv.org/abs/2002.06206v1",
        "categories": [
            "cs.CE",
            "physics.comp-ph",
            "physics.flu-dyn"
        ]
    },
    {
        "title": "Market Power in Convex Hull Pricing",
        "authors": [
            "Jian Sun",
            "Chenye Wu"
        ],
        "summary": "The start up costs in many kinds of generators lead to complex cost structures, which in turn yield severe market loopholes in the locational marginal price (LMP) scheme. Convex hull pricing (a.k.a. extended LMP) is proposed to improve the market efficiency by providing the minimal uplift payment to the generators. In this letter, we consider a stylized model where all generators share the same generation capacity. We analyze the generators' possible strategic behaviors in such a setting, and then propose an index for market power quantification in the convex hull pricing schemes.",
        "published": "2020-02-15T09:10:06Z",
        "link": "http://arxiv.org/abs/2002.07595v1",
        "categories": [
            "math.OC",
            "cs.CE",
            "econ.GN",
            "q-fin.EC"
        ]
    },
    {
        "title": "Topology Optimization with Accessibility Constraint for Multi-Axis   Machining",
        "authors": [
            "Amir M. Mirzendehdel",
            "Morad Behandish",
            "Saigopal Nelaturi"
        ],
        "summary": "In this paper, we present a topology optimization (TO) framework to enable automated design of mechanical components while ensuring the result can be manufactured using multi-axis machining. Although TO improves the part's performance, the as-designed model is often geometrically too complex to be machined and the as-manufactured model can significantly vary due to machining constraints that are not accounted for during TO. In other words, many of the optimized design features cannot be accessed by a machine tool without colliding with the part (or fixtures). The subsequent post-processing to make the part machinable with the given setup requires trial-and-error without guarantees on preserving the optimized performance. Our proposed approach is based on the well-established accessibility analysis formulation using convolutions in configuration space that is extensively used in spatial planning and robotics. We define an 'inaccessibility measure field' (IMF) over the design domain to identify non-manufacturable features and quantify their contribution to non-manufacturability. The IMF is used to penalize the sensitivity field of performance objectives and constraints to prevent formation of inaccessible regions. Unlike existing discrete formulations, our IMF provides a continuous spatial field that is desirable for TO convergence. Our approach applies to arbitrary geometric complexity of the part, tools, and fixtures, and is highly parallelizable on multi-core architecture. We demonstrate the effectiveness of our framework on benchmark and realistic examples in 2D and 3D. We also show that it is possible to directly construct manufacturing plans for the optimized designs based on the accessibility information.",
        "published": "2020-02-16T18:54:45Z",
        "link": "http://arxiv.org/abs/2002.07627v1",
        "categories": [
            "cs.CE",
            "cs.CG"
        ]
    },
    {
        "title": "Topology optimization of surface flows",
        "authors": [
            "Yongbo Deng",
            "Weihong Zhang",
            "Jihong Zhu",
            "Junqiang Bai",
            "Zhenyu Liu",
            "Jan G. Korvink"
        ],
        "summary": "This paper presents a topology optimization approach for surface flows, which can represent the viscous and incompressible fluidic motions at the solid/liquid and liquid/vapor interfaces. The fluidic motions on such material interfaces can be described by the surface Navier-Stokes equations defined on 2-manifolds or two-dimensional manifolds, where the elementary tangential calculus is implemented in terms of exterior differential operators expressed in a Cartesian system. Based on the topology optimization model for fluidic flows with porous medium filling the design domain, an artificial Darcy friction is added to the area force term of the surface Navier-Stokes equations and the physical area forces are penalized to eliminate their existence in the fluidic regions and to avoid the invalidity of the porous medium model. Topology optimization for steady and unsteady surface flows can be implemented by iteratively evolving the impermeability of the porous medium on the 2-manifolds, where the impermeability is interpolated by the material density derived from a design variable. The related partial differential equations are solved by using the surface finite element method. Numerical examples have been provided to demonstrate this topology optimization approach for surface flows, including the boundary velocity driven flows, area force driven flows and convection-diffusion flows.",
        "published": "2020-02-17T08:56:33Z",
        "link": "http://arxiv.org/abs/2002.06842v8",
        "categories": [
            "physics.comp-ph",
            "cs.CE",
            "physics.flu-dyn"
        ]
    },
    {
        "title": "Physics-Informed Multi-LSTM Networks for Metamodeling of Nonlinear   Structures",
        "authors": [
            "Ruiyang Zhang",
            "Yang Liu",
            "Hao Sun"
        ],
        "summary": "This paper introduces an innovative physics-informed deep learning framework for metamodeling of nonlinear structural systems with scarce data. The basic concept is to incorporate physics knowledge (e.g., laws of physics, scientific principles) into deep long short-term memory (LSTM) networks, which boosts the learning within a feasible solution space. The physics constraints are embedded in the loss function to enforce the model training which can accurately capture latent system nonlinearity even with very limited available training datasets. Specifically for dynamic structures, physical laws of equation of motion, state dependency and hysteretic constitutive relationship are considered to construct the physics loss. In particular, two physics-informed multi-LSTM network architectures are proposed for structural metamodeling. The satisfactory performance of the proposed framework is successfully demonstrated through two illustrative examples (e.g., nonlinear structures subjected to ground motion excitation). It turns out that the embedded physics can alleviate overfitting issues, reduce the need of big training datasets, and improve the robustness of the trained model for more reliable prediction. As a result, the physics-informed deep learning paradigm outperforms classical non-physics-guided data-driven neural networks.",
        "published": "2020-02-18T10:35:02Z",
        "link": "http://arxiv.org/abs/2002.10253v1",
        "categories": [
            "cs.CE",
            "eess.SP"
        ]
    },
    {
        "title": "Default Ambiguity: Finding the Best Solution to the Clearing Problem",
        "authors": [
            "Pál András Papp",
            "Roger Wattenhofer"
        ],
        "summary": "We study financial networks with debt contracts and credit default swaps between specific pairs of banks. Given such a financial system, we want to decide which of the banks are in default, and how much of their liabilities can these defaulting banks pay. There can easily be multiple different solutions to this problem, leading to a situation of default ambiguity, and a range of possible solutions to implement for a financial authority.   In this paper, we study the properties of the solution space of such financial systems, and analyze a wide range of reasonable objective functions for selecting from the set of solutions. Examples of such objective functions include minimizing the number of defaulting banks, minimizing the amount of unpaid debt, maximizing the number of satisfied banks, and many others. We show that for all of these objectives, it is NP-hard to approximate the optimal solution to an $n^{1-\\epsilon}$ factor for any $\\epsilon>0$, with $n$ denoting the number of banks. Furthermore, we show that this situation is rather difficult to avoid from a financial regulator's perspective: the same hardness results also hold if we apply strong restrictions on the weights of the debts, the structure of the network, or the amount of funds that banks must possess. However, if we restrict both the network structure and the amount of funds simultaneously, then the solution becomes unique, and it can be found efficiently.",
        "published": "2020-02-18T17:17:15Z",
        "link": "http://arxiv.org/abs/2002.07741v2",
        "categories": [
            "cs.CE",
            "cs.CC",
            "q-fin.MF",
            "91G45, 68Q17",
            "J.4"
        ]
    },
    {
        "title": "Physics-informed Neural Networks for Solving Nonlinear Diffusivity and   Biot's equations",
        "authors": [
            "Teeratorn Kadeethum",
            "Thomas M Jorgensen",
            "Hamidreza M Nick"
        ],
        "summary": "This paper presents the potential of applying physics-informed neural networks for solving nonlinear multiphysics problems, which are essential to many fields such as biomedical engineering, earthquake prediction, and underground energy harvesting. Specifically, we investigate how to extend the methodology of physics-informed neural networks to solve both the forward and inverse problems in relation to the nonlinear diffusivity and Biot's equations. We explore the accuracy of the physics-informed neural networks with different training example sizes and choices of hyperparameters. The impacts of the stochastic variations between various training realizations are also investigated. In the inverse case, we also study the effects of noisy measurements. Furthermore, we address the challenge of selecting the hyperparameters of the inverse model and illustrate how this challenge is linked to the hyperparameters selection performed for the forward one.",
        "published": "2020-02-19T15:22:26Z",
        "link": "http://arxiv.org/abs/2002.08235v1",
        "categories": [
            "cs.CE",
            "cs.LG",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "A subtractive manufacturing constraint for level set topology   optimization",
        "authors": [
            "Nigel Morris",
            "Adrian Butscher",
            "Francesco Iorio"
        ],
        "summary": "We present a method for enforcing manufacturability constraints in generated parts such that they will be automatically ready for fabrication using a subtractive approach. We primarily target multi-axis CNC milling approaches but the method should generalize to other subtractive methods as well. To this end, we take as user input: the radius of curvature of the tool bit, a coarse model of the tool head and optionally a set of milling directions. This allows us to enforce the following manufacturability conditions: 1) surface smoothness such that the radius of curvature of the part does not exceed the milling bit radius, 2) orientation such that every part of the surface to be milled is visible from at least one milling direction, 3) accessibility such that every surface patch can be reached by the tool bit without interference with the tool or head mount. We will show how to efficiently enforce the constraint during level set-based topology optimization modifying the advection velocity such that at each iteration the topology optimization maintains a descent optimization direction and does not violate any of the manufacturability conditions. This approach models the actual subtractive process by carving away material accessible to the machine at each iteration until a local optimum is achieved.",
        "published": "2020-02-19T19:28:11Z",
        "link": "http://arxiv.org/abs/2002.10246v1",
        "categories": [
            "cs.CE",
            "math.OC"
        ]
    },
    {
        "title": "Fractional-Order Models for the Static and Dynamic Analysis of Nonlocal   Plates",
        "authors": [
            "Sansit Patnaik",
            "Sai Sidhardh",
            "Fabio Semperlotti"
        ],
        "summary": "This study presents the analytical formulation and the finite element solution of fractional order nonlocal plates under both Mindlin and Kirchoff formulations. By employing consistent definitions for fractional-order kinematic relations, the governing equations and the associated boundary conditions are derived based on variational principles. Remarkably, the fractional-order nonlocal model gives rise to a self-adjoint and positive-definite system that accepts a unique solution. Further, owing to the difficulty in obtaining analytical solutions to this fractional-order differ-integral problem, a 2D finite element model for the fractional-order governing equations is presented. Following a thorough validation with benchmark problems, the 2D fractional finite element model is used to study the static as well as the free dynamic response of fractional-order plates subject to various loading and boundary conditions. It is established that the fractional-order nonlocality leads to a reduction in the stiffness of the plate structure thereby increasing the displacements and reducing the natural frequency of vibration of the plates. Further, it is seen that the effect of nonlocality is stronger on the higher modes of vibration when compared to the fundamental mode. These effects of the fractional-order nonlocality are noted irrespective of the nature of the boundary conditions. More specifically, the fractional-order model of nonlocal plates is free from boundary effects that lead to paradoxical predictions such as hardening and absence of nonlocal effects in classical integral approaches to nonlocal elasticity. This consistency in the predictions is a result of the well-posed nature of the fractional-order governing equations that accept a unique solution.",
        "published": "2020-02-19T22:01:46Z",
        "link": "http://arxiv.org/abs/2002.10244v1",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.AP",
            "math.DS",
            "math.NA"
        ]
    },
    {
        "title": "GivEn -- Shape Optimization for Gas Turbines in Volatile Energy Networks",
        "authors": [
            "Jan Backhaus",
            "Matthias Bolten",
            "Onur Tanil Doganay",
            "Matthias Ehrhardt",
            "Benedikt Engel",
            "Christian Frey",
            "Hanno Gottschalk",
            "Michael Günther",
            "Camilla Hahn",
            "Jens Jäschke",
            "Peter Jaksch",
            "Kathrin Klamroth",
            "Alexander Liefke",
            "Daniel Luft",
            "Lucas Mäde",
            "Vincent Marciniak",
            "Marco Reese",
            "Johanna Schultes",
            "Volker Schulz",
            "Sebastian Schmitz",
            "Johannes Steiner",
            "Michael Stiglmayr"
        ],
        "summary": "This paper describes the project GivEn that develops a novel multicriteria optimization process for gas turbine blades and vanes using modern \"adjoint\" shape optimization algorithms. Given the many start and shut-down processes of gas power plants in volatile energy grids, besides optimizing gas turbine geometries for efficiency, the durability understood as minimization of the probability of failure is a design objective of increasing importance. We also describe the underlying coupling structure of the multiphysical simulations and use modern, gradient based multicriteria optimization procedures to enhance the exploration of Pareto-optimal solutions.",
        "published": "2020-02-20T11:03:01Z",
        "link": "http://arxiv.org/abs/2002.08672v1",
        "categories": [
            "math.OC",
            "cs.CE",
            "G.1.6; G.3; G.1.8"
        ]
    },
    {
        "title": "Ambiguous phase assignment of discretized 3D geometries in topology   optimization",
        "authors": [
            "Jorge L. Barrera",
            "Kurt Maute"
        ],
        "summary": "Level set-based immersed boundary techniques operate on nonconforming meshes while providing a crisp definition of interface and external boundaries. In such techniques, an isocontour of a level set field interpolated from nodal level set values defines a problem's geometry. If the interface is explicitly tracked, the intersected elements are typically divided into sub-elements to which a phase needs to be assigned. Due to loss of information in the discretization of the level set field, certain geometrical configurations allow for ambiguous phase assignment of sub-elements, and thus ambiguous definition of the interface. The study presented here focuses on analyzing these topological ambiguities in embedded geometries constructed from discretized level set fields on hexahedral meshes. The analysis is performed on three-dimensional problems where several intersection configurations can significantly affect the problem's topology. This is in contrast to two-dimensional problems where ambiguous topological features exist only in one intersection configuration and identifying and resolving them is straightforward. A set of rules that resolve these ambiguities for two-phase problems is proposed, and algorithms for their implementations are provided. The influence of these rules on the evolution of the geometry in the optimization process is investigated with linear elastic topology optimization problems. These problems are solved by an explicit level set topology optimization framework that uses the extended finite element method to predict physical responses. This study shows that the choice of a rule to resolve topological features can result in drastically different final geometries. However, for the problems studied in this paper, the performances of the optimized design do not differ.",
        "published": "2020-02-20T17:49:21Z",
        "link": "http://arxiv.org/abs/2002.10255v1",
        "categories": [
            "cs.CE",
            "math.OC",
            "49M37 (Primary), 90C90 (Secondary)"
        ]
    },
    {
        "title": "Energy Resolved Neutron Imaging for Strain Reconstruction using the   Finite Element Method",
        "authors": [
            "Riya Aggarwal",
            "Mike Meylan",
            "Bishnu Lamichhane",
            "Chris Wensrich"
        ],
        "summary": "A pulsed neutron imaging technique is used to reconstruct the residual strain within a polycrystalline material from Bragg edge strain images. This technique offers the possibility of a nondestructive analysis of strain fields with a high spatial resolution. A finite element approach is used to reconstruct the strain using the least square method constrained by the conditions of equilibrium. The procedure is developed and verified by validating for a cantilevered beam problem. It is subsequently demonstrated by reconstructing the strain from experimental data for a ring-and-plug sample, measured at the spallation neutron source RADEN at J-PARC in Japan. The reconstruction is validated by comparison with conventional constant wavelength strain measurements on the KOWARI diffractometer at ANSTO in Australia. It is also shown that the addition of a simple Tikhonov regularization can improve the reconstruction.",
        "published": "2020-02-21T07:01:08Z",
        "link": "http://arxiv.org/abs/2002.12142v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "BLAST: Bridging Length/time scales via Atomistic Simulation Toolkit",
        "authors": [
            "Henry Chan",
            "Badri Narayanan",
            "Mathew Cherukara",
            "Troy D. Loeffler",
            "Michael G. Sternberg",
            "Anthony Avarca",
            "Subramanian K. R. S. Sankaranarayanan"
        ],
        "summary": "The ever-increasing power of supercomputers coupled with highly scalable simulation codes have made molecular dynamics an indispensable tool in applications ranging from predictive modeling of materials to computational design and discovery of new materials for a broad range of applications. Multi-fidelity scale bridging between the various flavors of molecular dynamics i.e. ab-initio, classical and coarse-grained models has remained a long-standing challenge. Here, we introduce our framework BLAST (Bridging Length/time scales via Atomistic Simulation Toolkit) that leverages machine learning principles to address this challenge. BLAST is a multi-fidelity scale bridging framework that provide users with the capabilities to train and develop their own classical atomistic and coarse-grained interatomic potentials (force fields) for molecular simulations. BLAST is designed to address several long-standing problems in the molecular simulations community, such as unintended misuse of existing force fields due to knowledge gap between developers and users, bottlenecks in traditional force field development approaches, and other issues relating to the accuracy, efficiency, and transferability of force fields. Here, we discuss several important aspects in force field development and highlight features in BLAST that enable its functionalities and ease of use.",
        "published": "2020-02-21T12:47:57Z",
        "link": "http://arxiv.org/abs/2002.10401v1",
        "categories": [
            "cs.CE",
            "cond-mat.mes-hall",
            "cond-mat.mtrl-sci"
        ]
    },
    {
        "title": "Petrophysically and geologically guided multi-physics inversion using a   dynamic Gaussian mixture model",
        "authors": [
            "Thibaut Astic",
            "Lindsey J. Heagy",
            "Douglas W. Oldenburg"
        ],
        "summary": "In a previous paper, we introduced a framework for carrying out petrophysically and geologically guided geophysical inversions. In that framework, petrophysical and geological information is modelled with a Gaussian Mixture Model (GMM). In the inversion, the GMM serves as a prior for the geophysical model. The formulation was confined to problems in which a single physical property model was sought, with a single geophysical dataset. In this paper, we extend that framework to jointly invert multiple geophysical datasets that depend on multiple physical properties. The petrophysical and geological information is used to couple geophysical surveys that, otherwise, rely on independent physics. This requires advancements in two areas. First, an extension from a univariate to a multivariate analysis of the petrophysical data, and their inclusion within the inverse problem, is necessary. Second, we address the practical issues of simultaneously inverting data from multiple surveys and finding a solution that acceptably reproduces each one, along with the petrophysical and geological information. To illustrate the efficacy of our approach and the advantages of carrying out multi-physics inversions, we invert synthetic gravity and magnetic data associated with a kimberlite deposit. The kimberlite pipe contains two distinct facies embedded in a host rock. Inverting the datasets individually leads to a binary geological model: background or kimberlite. A multi-physics inversion, with petrophysical information, differentiates between the two main kimberlite facies of the pipe. Through this example, we also highlight the capabilities of our framework to work with interpretive geologic assumptions when minimal quantitative information is available. In those cases, the dynamic updates of the Gaussian Mixture Model allow us to perform multi-physics inversions by learning a petrophysical model.",
        "published": "2020-02-21T19:20:17Z",
        "link": "http://arxiv.org/abs/2002.09515v3",
        "categories": [
            "physics.geo-ph",
            "cs.CE",
            "stat.AP"
        ]
    },
    {
        "title": "Exact artificial boundary conditions of 1D semi-discretized peridynamics",
        "authors": [
            "Songsong Ji",
            "Gang Pang",
            "Jiwei Zhang",
            "Yibo Yang",
            "Paris Perdikaris"
        ],
        "summary": "The peridynamic theory reformulates the equations of continuum mechanics in terms of integro-differential equations instead of partial differential equations. It is not trivial to directly apply naive approach in artificial boundary conditions for continua to peridynamics modeling, because it usually involves semi-discretization scheme. In this paper, we present a new way to construct exact boundary conditions for semi-discretized peridynamics using kernel functions and recursive relations. Specially, kernel functions are used to characterize one single source are combined to construct the exact boundary conditions. The recursive relationships between the kernel functions are proposed, therefore the kernel functions can be computed through the ordinary differential system and integral system with high precision. The numerical results demonstrate that the boundary condition has high accuracy. The proposed method can be applied to modeling of wave propagation of other nonlocal theories and high dimensional cases.",
        "published": "2020-02-25T03:48:17Z",
        "link": "http://arxiv.org/abs/2002.12846v1",
        "categories": [
            "cs.CE",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Bayesian Poroelastic Aquifer Characterization from InSAR Surface   Deformation Data. Part I: Maximum A Posteriori Estimate",
        "authors": [
            "Amal Alghamdi",
            "Marc A. Hesse",
            "Jingyi Chen",
            "Omar Ghattas"
        ],
        "summary": "Characterizing the properties of groundwater aquifers is essential for predicting aquifer response and managing groundwater resources. In this work, we develop a high-dimensional scalable Bayesian inversion framework governed by a three-dimensional quasi-static linear poroelastic model to characterize lateral permeability variations in groundwater aquifers. We determine the maximum a posteriori (MAP) point of the posterior permeability distribution from centimeter-level surface deformation measurements obtained from Interferometric Synthetic Aperture Radar (InSAR). The scalability of our method to high parameter dimension is achieved through the use of adjoint-based derivatives, inexact Newton methods to determine the MAP point, and a Mat\\'ern class sparse prior precision operator. Together, these guarantee that the MAP point is found at a cost, measured in number of forward/adjoint poroelasticity solves, that is independent of the parameter dimension. We apply our methodology to a test case for a municipal well in Mesquite, Nevada, in which InSAR and GPS surface deformation data are available. We solve problems with up to 320,824 state variable degrees of freedom (DOFs) and 16,896 parameter DOFs. A consistent treatment of noise level is employed so that the aquifer characterization result does not depend on the pixel spacing of surface deformation data. Our results show that the use of InSAR data significantly improves characterization of lateral aquifer heterogeneity, and the InSAR-based aquifer characterization recovers complex lateral displacement trends observed by independent daily GPS measurements.",
        "published": "2020-02-25T07:30:18Z",
        "link": "http://arxiv.org/abs/2002.10706v1",
        "categories": [
            "physics.geo-ph",
            "cs.CE"
        ]
    },
    {
        "title": "Using Reinforcement Learning in the Algorithmic Trading Problem",
        "authors": [
            "Evgeny Ponomarev",
            "Ivan Oseledets",
            "Andrzej Cichocki"
        ],
        "summary": "The development of reinforced learning methods has extended application to many areas including algorithmic trading. In this paper trading on the stock exchange is interpreted into a game with a Markov property consisting of states, actions, and rewards. A system for trading the fixed volume of a financial instrument is proposed and experimentally tested; this is based on the asynchronous advantage actor-critic method with the use of several neural network architectures. The application of recurrent layers in this approach is investigated. The experiments were performed on real anonymized data. The best architecture demonstrated a trading strategy for the RTS Index futures (MOEX:RTSI) with a profitability of 66% per annum accounting for commission. The project source code is available via the following link: http://github.com/evgps/a3c_trading.",
        "published": "2020-02-26T14:30:18Z",
        "link": "http://arxiv.org/abs/2002.11523v1",
        "categories": [
            "q-fin.TR",
            "cs.CE",
            "cs.NE"
        ]
    },
    {
        "title": "Cell cycle and protein complex dynamics in discovering signaling   pathways",
        "authors": [
            "Daniel Inostroza",
            "Cecilia Hernández",
            "Diego Seco",
            "Gonzalo Navarro",
            "Alvaro Olivera-Nappa"
        ],
        "summary": "Signaling pathways are responsible for the regulation of cell processes, such as monitoring the external environment, transmitting information across membranes, and making cell fate decisions. Given the increasing amount of biological data available and the recent discoveries showing that many diseases are related to the disruption of cellular signal transduction cascades, in silico discovery of signaling pathways in cell biology has become an active research topic in past years. However, reconstruction of signaling pathways remains a challenge mainly because of the need for systematic approaches for predicting causal relationships, like edge direction and activation/inhibition among interacting proteins in the signal flow. We propose an approach for predicting signaling pathways that integrates protein interactions, gene expression, phenotypes, and protein complex information. Our method first finds candidate pathways using a directed-edge-based algorithm and then defines a graph model to include causal activation relationships among proteins, in candidate pathways using cell cycle gene expression and phenotypes to infer consistent pathways in yeast. Then, we incorporate protein complex coverage information for deciding on the final predicted signaling pathways. We show that our approach improves the predictive results of the state of the art using different ranking metrics.",
        "published": "2020-02-26T16:55:24Z",
        "link": "http://arxiv.org/abs/2002.11612v2",
        "categories": [
            "q-bio.MN",
            "cs.CE",
            "q-bio.QM"
        ]
    },
    {
        "title": "Inline Vector Compression for Computational Physics",
        "authors": [
            "Will Trojak",
            "Freddie Witherden"
        ],
        "summary": "A novel inline data compression method is presented for single-precision vectors in three dimensions. The primary application of the method is for accelerating computational physics calculations where the throughput is bound by memory bandwidth. The scheme employs spherical polar coordinates, angle quantisation, and a bespoke floating-point representation of the magnitude to achieve a fixed compression ratio of 1.5. The anisotropy of this method is considered, along with companding and fractional splitting techniques to improve the efficiency of the representation. We evaluate the scheme numerically within the context of high-order computational fluid dynamics. For both the isentropic convecting vortex and the Taylor--Green vortex test cases, the results are found to be comparable to those without compression. Performance is evaluated for a vector addition kernel on an NVIDIA Titan V GPU; it is demonstrated that a speedup of 1.5 can be achieved.",
        "published": "2020-02-27T18:39:48Z",
        "link": "http://arxiv.org/abs/2003.02633v2",
        "categories": [
            "cs.CE",
            "physics.comp-ph",
            "68U20, 68W40, 68P30, 65M60, 76F65"
        ]
    },
    {
        "title": "On the presence of a critical detachment angle in gecko spatula peeling   -- A numerical investigation using an adhesive friction model",
        "authors": [
            "Saipraneeth Gouravaraju",
            "Roger A. Sauer",
            "Sachin Singh Gautam"
        ],
        "summary": "A continuum-based computational contact model is employed to study coupled adhesion and friction in gecko spatulae. Nonlinear finite element analysis is carried out to simulate spatula peeling from a rigid substrate. It is shown that the \"frictional adhesion\" behavior, until now only observed from seta to toe levels, is also present at the spatula level. It is shown that for sufficiently small spatula pad thickness, the spatula detaches at a constant angle known as the critical detachment angle irrespective of the peeling and shaft angles. The spatula reaches the same energy states at the jump-off contact point, which directly relates to the invariance of the critical detachment angle. This study also reveals that there is an optimum pad thickness associated with the invariance of the critical detachment angle. It is further observed that the sliding of the spatula pad is essential for the invariance of the critical detachment angle.",
        "published": "2020-02-27T19:32:43Z",
        "link": "http://arxiv.org/abs/2002.12401v1",
        "categories": [
            "cond-mat.soft",
            "cs.CE"
        ]
    },
    {
        "title": "Imposing minimum and maximum member size, minimum cavity size, and   minimum separation distance between solid members in topology optimization",
        "authors": [
            "Eduardo Fernández",
            "Kai-ke Yang",
            "Stijn Koppen",
            "Pablo Alarcón",
            "Simon Bauduin",
            "Pierre Duysinx"
        ],
        "summary": "This paper focuses on density-based topology optimization and proposes a combined method to simultaneously impose Minimum length scale in the Solid phase (MinSolid), Minimum length scale in the Void phase (MinVoid) and Maximum length scale in the Solid phase (MaxSolid). MinSolid and MinVoid mean that the size of solid parts and cavities must be greater than the size of a prescribed circle or sphere. This is ensured through the robust design approach based on eroded, intermediate and dilated designs. MaxSolid seeks to restrict the formation of solid parts larger than a prescribed size, which is imposed through local volume restrictions. In the first part of this article, we show that by proportionally restricting the maximum size of the eroded, intermediate and dilated designs, it is possible to obtain optimized designs satisfying, simultaneously, MinSolid, MinVoid and MaxSolid. However, in spite of obtaining designs with crisp boundaries, some results can be difficult to manufacture due to the presence of multiple rounded cavities, which are introduced by the maximum size restriction with the sole purpose of avoiding thick solid members in the structure. To address this issue, in the second part of this article we propose a new geometric constraint that seeks to control the minimum separation distance between two solid members, also called the Minimum Gap (MinGap). Differently from MinVoid, MinGap introduces large void areas that do not necessarily have to be round. 2D and 3D test cases show that simultaneous control of MinSolid, MinVoid, MaxSolid and MinGap can be useful to improve the manufacturability of maximum size constrained designs.",
        "published": "2020-02-29T14:12:47Z",
        "link": "http://arxiv.org/abs/2003.00263v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Markov Chain Monte Carlo with Neural Network Surrogates: Application to   Contaminant Source Identification",
        "authors": [
            "Zitong Zhou",
            "Daniel M. Tartakovsky"
        ],
        "summary": "Subsurface remediation often involves reconstruction of contaminant release history from sparse observations of solute concentration. Markov Chain Monte Carlo (MCMC), the most accurate and general method for this task, is rarely used in practice because of its high computational cost associated with multiple solves of contaminant transport equations. We propose an adaptive MCMC method, in which a transport model is replaced with a fast and accurate surrogate model in the form of a deep convolutional neural network (CNN). The CNN-based surrogate is trained on a small number of the transport model runs based on the prior knowledge of the unknown release history. Thus reduced computational cost allows one to reduce the sampling error associated with construction of the approximate likelihood function. As all MCMC strategies for source identification, our method has an added advantage of quantifying predictive uncertainty and accounting for measurement errors. Our numerical experiments demonstrate the accuracy comparable to that of MCMC with the forward transport model, which is obtained at a fraction of the computational cost of the latter.",
        "published": "2020-03-01T02:00:35Z",
        "link": "http://arxiv.org/abs/2003.02322v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Inverse design of photonic crystals through automatic differentiation",
        "authors": [
            "Momchil Minkov",
            "Ian A. D. Williamson",
            "Lucio C. Andreani",
            "Dario Gerace",
            "Beicheng Lou",
            "Alex Y. Song",
            "Tyler W. Hughes",
            "Shanhui Fan"
        ],
        "summary": "Gradient-based inverse design in photonics has already achieved remarkable results in designing small-footprint, high-performance optical devices. The adjoint variable method, which allows for the efficient computation of gradients, has played a major role in this success. However, gradient-based optimization has not yet been applied to the mode-expansion methods that are the most common approach to studying periodic optical structures like photonic crystals. This is because, in such simulations, the adjoint variable method cannot be defined as explicitly as in standard finite-difference or finite-element time- or frequency-domain methods. Here, we overcome this through the use of automatic differentiation, which is a generalization of the adjoint variable method to arbitrary computational graphs. We implement the plane-wave expansion and the guided-mode expansion methods using an automatic differentiation library, and show that the gradient of any simulation output can be computed efficiently and in parallel with respect to all input parameters. We then use this implementation to optimize the dispersion of a photonic crystal waveguide, and the quality factor of an ultra-small cavity in a lithium niobate slab. This extends photonic inverse design to a whole new class of simulations, and more broadly highlights the importance that automatic differentiation could play in the future for tracking and optimizing complicated physical models.",
        "published": "2020-03-01T02:11:21Z",
        "link": "http://arxiv.org/abs/2003.00379v1",
        "categories": [
            "physics.optics",
            "cs.CE",
            "physics.app-ph",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Data Normalization for Bilinear Structures in High-Frequency Financial   Time-series",
        "authors": [
            "Dat Thanh Tran",
            "Juho Kanniainen",
            "Moncef Gabbouj",
            "Alexandros Iosifidis"
        ],
        "summary": "Financial time-series analysis and forecasting have been extensively studied over the past decades, yet still remain as a very challenging research topic. Since the financial market is inherently noisy and stochastic, a majority of financial time-series of interests are non-stationary, and often obtained from different modalities. This property presents great challenges and can significantly affect the performance of the subsequent analysis/forecasting steps. Recently, the Temporal Attention augmented Bilinear Layer (TABL) has shown great performances in tackling financial forecasting problems. In this paper, by taking into account the nature of bilinear projections in TABL networks, we propose Bilinear Normalization (BiN), a simple, yet efficient normalization layer to be incorporated into TABL networks to tackle potential problems posed by non-stationarity and multimodalities in the input series. Our experiments using a large scale Limit Order Book (LOB) consisting of more than 4 million order events show that BiN-TABL outperforms TABL networks using other state-of-the-arts normalization schemes by a large margin.",
        "published": "2020-03-01T21:57:03Z",
        "link": "http://arxiv.org/abs/2003.00598v2",
        "categories": [
            "cs.CE",
            "q-fin.ST"
        ]
    },
    {
        "title": "Modified Bee Colony optimization algorithm for computational parameter   identification for pore scale transport in periodic porous media",
        "authors": [
            "Vasiliy V. Grigoriev",
            "Oleg Iliev",
            "Petr N. Vabishchevich"
        ],
        "summary": "This paper discusses an optimization method called Modified Bee Colony algorithm (MBC) based on a particular intelligent behavior of honeybee swarms. The algorithm was checked in a few benchmarks like Shekel, Rozenbroke, Himmelblau and Rastrigin functions, then was applied to parameter identification for reactive flow problems in periodic porous media. The simulation results show that the performance and efficiency of MBC algorithm are comparable to the other parameter identification methods and strategies, at the same time it is able to better capture local minima for the considered class of problems. The proposed identification approach is applicable for different geometries (random and periodic) and for a range of process parameters. In this paper the potential of the approach is demonstrated in identifying parameters of Langmuir isotherm for low Peclet and high Damkoler numbers reactive flow in a 2D periodic porous media with circular inclusions. Finite element approximation in space and implicit time discretization are exploited.",
        "published": "2020-03-02T12:41:33Z",
        "link": "http://arxiv.org/abs/2003.02653v1",
        "categories": [
            "cs.CE",
            "76S05, 86A22, 76D05, 76R50, 65M32"
        ]
    },
    {
        "title": "Lagrangian-Eulerian Multi-Density Topology Optimization with the   Material Point Method",
        "authors": [
            "Yue Li",
            "Xuan Li",
            "Minchen Li",
            "Yixin Zhu",
            "Bo Zhu",
            "Chenfanfu Jiang"
        ],
        "summary": "In this paper, a hybrid Lagrangian-Eulerian topology optimization (LETO) method is proposed to solve the elastic force equilibrium with the Material Point Method (MPM). LETO transfers density information from freely movable Lagrangian carrier particles to a fixed set of Eulerian quadrature points. This transfer is based on a smooth radial kernel involved in the compliance objective to avoid the artificial checkerboard pattern. The quadrature points act as MPM particles embedded in a lower-resolution grid and enable a sub-cell multi-density resolution of intricate structures with a reduced computational cost. A quadrature-level connectivity graph-based method is adopted to avoid the artificial checkerboard issues commonly existing in multi-resolution topology optimization methods. Numerical experiments are provided to demonstrate the efficacy of the proposed approach.",
        "published": "2020-03-02T22:05:45Z",
        "link": "http://arxiv.org/abs/2003.01215v4",
        "categories": [
            "physics.comp-ph",
            "cs.CE",
            "cs.GR"
        ]
    },
    {
        "title": "Framework of Fracture Network Modeling using Conditioned Data with   Sequential Gaussian Simulation",
        "authors": [
            "Yerlan Amanbek",
            "Timur Merembayev",
            "Sanjay Srinivasan"
        ],
        "summary": "The fracture characterization using a geostatistical tool with conditioning data is a computationally efficient tool for subsurface flow and transport applications. The main objective of the paper is to propose a framework of geostatistical method to model the fracture network. In the method, we have chosen neighborhood area to apply the Gaussian Sequential Simulation in order to generate the fracture network in the unknown region. The angle was propagated from the seed where direction is guided by the neighborhood data in simulation regime. Initial seeds can be distributed by Poisson procedure. The method is applied for geological faults from the Central Kazakhstan and for field data from Scotland, UK. The simulation results are compatible with the original fracture network in the flow and transport modeling setting. From the research that has been carried out, it is possible to conclude that the numerical simulation of fracture network is a valuable tool in the subsurface flow and transport applications.",
        "published": "2020-03-03T04:36:45Z",
        "link": "http://arxiv.org/abs/2003.01327v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Adaptive phase field modelling of crack propagation in orthotropic   functionally graded materials",
        "authors": [
            "Hirshikesh",
            "Emilio Martínez-Pañeda",
            "Sundararajan Natarajan"
        ],
        "summary": "In this work, we extend the recently proposed adaptive phase field method to model fracture in orthotropic functionally graded materials (FGMs). A recovery type error indicator combined with quadtree decomposition is employed for adaptive mesh refinement. The proposed approach is capable of capturing the fracture process with a localized mesh refinement that provides notable gains in computational efficiency. The implementation is validated against experimental data and other numerical experiments on orthotropic materials with different material orientations. The results reveal an increase in the stiffness and the maximum force with increasing material orientation angle. The study is then extended to the analysis of orthotropic FGMs. It is observed that, if the gradation in fracture properties is neglected, the material gradient plays a secondary role, with the fracture behaviour being dominated by the orthotropy of the material. However, when the toughness increases along the crack propagation path, a substantial gain in fracture resistance is observed.",
        "published": "2020-03-04T10:03:54Z",
        "link": "http://arxiv.org/abs/2003.04689v1",
        "categories": [
            "cs.CE",
            "cond-mat.mtrl-sci",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Identification of non-local continua for lattice-like materials",
        "authors": [
            "Andrea Bacigalupo",
            "Luigi Gambarotta"
        ],
        "summary": "The paper is focused on the dynamic homogenization of lattice-like materials with lumped mass at the nodes to obtain energetically consistent models providing accurate descriptions of the acoustic behavior of the discrete system. The equation of motion of the lattice is transformed according to a unitary approach aimed to identify equivalent non-local continuum models of integral-differential and gradient type, the latter obtained through standard or enhanced continualization. The bilateral Z-transform of the difference equation of motion is matched to the governing integral-differential equation of the equivalent continuum in the transformed Fourier space, which has the same frequency band structure as the Lagrangian one. Firstly, it is shown that the approximation of the kernels via Taylor polynomials leads to the differential field equations of higher order continua endowed with non-local constitutive terms. The field equations derived from such approach corresponds to the ones obtained through the so called standard continualization. However, the differential problem turns out to be ill-posed because the non-positive definiteness of the potential energy density of the higher order continuum. Energetically consistent equivalent continua have been identified through a proper mapping correlating the transformed macro-displacements in the Fourier space with a new auxiliary regularizing continuum macro-displacement field in the same space. Specifically, the mapping here introduced has zeros at the edge of the first Brillouin zone. The integral-differential governing equation and the corresponding differential one has been reformulated through an enhanced continualization that is characterized by energetically consistent differential equations. The constitutive and inertial kernels of the integral-differential equation exhibit polar singularities at the edge of the first Brillouin zone.",
        "published": "2020-03-04T12:55:45Z",
        "link": "http://arxiv.org/abs/2004.03348v1",
        "categories": [
            "physics.app-ph",
            "cs.CE"
        ]
    },
    {
        "title": "Multichannel Analysis of Surface Waves Accelerated (MASWAccelerated):   Software for Efficient Surface Wave Inversion Using MPI and GPUs",
        "authors": [
            "Joseph Kump",
            "Eileen R. Martin"
        ],
        "summary": "Multichannel Analysis of Surface Waves (MASW) is a technique frequently used in geotechnical engineering and engineering geophysics to infer layered models of seismic shear wave velocities in the top tens to hundreds of meters of the subsurface. We aim to accelerate MASW calculations by capitalizing on modern computer hardware available in the workstations of most engineers: multiple cores and graphics processing units (GPUs). We propose new parallel and GPU accelerated algorithms for evaluating MASW data, and provide software implementations in C using Message Passing Interface (MPI) and CUDA. These algorithms take advantage of sparsity that arises in the problem, and the work balance between processes considers typical data trends. We compare our methods to an existing open source Matlab MASW tool. Our serial C implementation achieves a 2x speedup over the Matlab software, and we continue to see improvements by parallelizing the problem with MPI. We see nearly perfect strong and weak scaling for uniform data, and improve strong scaling for realistic data by repartitioning the problem to process mapping. By utilizing GPUs available on most modern workstations, we observe an additional 1.3x speedup over the serial C implementation on the first use of the method. We typically repeatedly evaluate theoretical dispersion curves as part of an optimization procedure, and on the GPU the kernel can be cached for faster reuse on later runs. We observe a 3.2x speedup on the cached GPU runs compared to the serial C runs. This work is the first open-source parallel or GPU-accelerated software tool for MASW imaging, and should enable geotechnical engineers to fully utilize all computer hardware at their disposal.",
        "published": "2020-03-04T18:54:14Z",
        "link": "http://arxiv.org/abs/2003.02256v1",
        "categories": [
            "cs.CE",
            "cs.DC",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Fast uncertainty quantification of tracer distribution in the brain   interstitial fluid with multilevel and quasi Monte Carlo",
        "authors": [
            "Matteo Croci",
            "Vegard Vinje",
            "Marie E. Rognes"
        ],
        "summary": "Efficient uncertainty quantification algorithms are key to understand the propagation of uncertainty -- from uncertain input parameters to uncertain output quantities -- in high resolution mathematical models of brain physiology. Advanced Monte Carlo methods such as quasi Monte Carlo (QMC) and multilevel Monte Carlo (MLMC) have the potential to dramatically improve upon standard Monte Carlo (MC) methods, but their applicability and performance in biomedical applications is underexplored. In this paper, we design and apply QMC and MLMC methods to quantify uncertainty in a convection-diffusion model of tracer transport within the brain. We show that QMC outperforms standard MC simulations when the number of random inputs is small. MLMC considerably outperforms both QMC and standard MC methods and should therefore be preferred for brain transport models.",
        "published": "2020-03-04T20:10:36Z",
        "link": "http://arxiv.org/abs/2003.02311v2",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA",
            "stat.CO"
        ]
    },
    {
        "title": "Deriving peridynamic influence functions for one-dimensional elastic   materials with periodic microstructure",
        "authors": [
            "Xiao Xu",
            "John T. Foster"
        ],
        "summary": "The influence function in peridynamic material models has a large effect on the dynamic behavior of elastic waves and in turn can greatly effect dynamic simulations of fracture propagation and material failure. Typically, the influence functions that are used in peridynamic models are selected for their numerical properties without regard to physical considerations. In this work, we present a method of deriving the peridynamic influence function for a one-dimensional initial/boundary value problem in a material with periodic microstructure. Starting with the linear local elastodynamic equation of motion in the microscale, we first use polynomial anzatzes to approximate microstructural displacements and then derive the homogenized nonlocal dynamic equation of motion for the macroscopic displacements; which, is easily reformulated as linear peridyamic equation with a discrete influence function. The shape and localization of the discrete influence function is completely determined by microstructural mechanical properties and length scales. By comparison with a highly resolved microstructural finite element model and the standard linear peridynamic model with a linearly decaying influence function, we demonstrate that the influence function derived from microstructural considerations is more accurate in predicting time dependent displacements and wave dynamics.",
        "published": "2020-03-04T22:53:49Z",
        "link": "http://arxiv.org/abs/2003.05520v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "TopologyGAN: Topology Optimization Using Generative Adversarial Networks   Based on Physical Fields Over the Initial Domain",
        "authors": [
            "Zhenguo Nie",
            "Tong Lin",
            "Haoliang Jiang",
            "Levent Burak Kara"
        ],
        "summary": "In topology optimization using deep learning, load and boundary conditions represented as vectors or sparse matrices often miss the opportunity to encode a rich view of the design problem, leading to less than ideal generalization results. We propose a new data-driven topology optimization model called TopologyGAN that takes advantage of various physical fields computed on the original, unoptimized material domain, as inputs to the generator of a conditional generative adversarial network (cGAN). Compared to a baseline cGAN, TopologyGAN achieves a nearly $3\\times$ reduction in the mean squared error and a $2.5\\times$ reduction in the mean absolute error on test problems involving previously unseen boundary conditions. Built on several existing network models, we also introduce a hybrid network called U-SE(Squeeze-and-Excitation)-ResNet for the generator that further increases the overall accuracy. We publicly share our full implementation and trained network.",
        "published": "2020-03-05T14:40:11Z",
        "link": "http://arxiv.org/abs/2003.04685v2",
        "categories": [
            "cs.CE",
            "cs.AI",
            "eess.IV"
        ]
    },
    {
        "title": "Effective Response of Heterogeneous Materials using the Recursive   Projection Method",
        "authors": [
            "Xiaoyao Peng",
            "Dhriti Nepal",
            "Kaushik Dayal"
        ],
        "summary": "This paper applies the Recursive Projection Method (RPM) to the problem of finding the effective mechanical response of a periodic heterogeneous solid. Previous works apply the Fast Fourier Transform (FFT) in combination with various fixed-point methods to solve the problem on the periodic unit cell. These have proven extremely powerful in a range of problems ranging from image-based modeling to dislocation plasticity. However, the fixed-point iterations can converge very slowly, or not at all, if the elastic properties have high contrast, such as in the case of voids. The paper examines the reasons for slow, or lack of convergence, in terms of a variational perspective. In particular, when the material contains regions with zero or very small stiffness, there is lack of uniqueness, and the energy landscape has flat or shallow directions. Therefore, in this work, the fixed-point iteration is replaced by the RPM iteration. The RPM uses the fixed-point iteration to adaptively identify the subspace on which fixed-point iterations are unstable, and performs Newton iterations only on the unstable subspace, while fixed-point iterations are performed on the complementary stable subspace. This combination of efficient fixed-point iterations where possible, and expensive but well-convergent Newton iterations where required, is shown to lead to robust and efficient convergence of the method. In particular, RPM-FFT converges well for a wide range of choices of the reference medium, while usual fixed-point iterations are usually sensitive to this choice.",
        "published": "2020-03-06T15:10:00Z",
        "link": "http://arxiv.org/abs/2003.07720v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Smart Train Operation Algorithms based on Expert Knowledge and   Reinforcement Learning",
        "authors": [
            "Kaichen Zhou",
            "Shiji Song",
            "Anke Xue",
            "Keyou You",
            "Hui Wu"
        ],
        "summary": "During recent decades, the automatic train operation (ATO) system has been gradually adopted in many subway systems for its low-cost and intelligence. This paper proposes two smart train operation algorithms by integrating the expert knowledge with reinforcement learning algorithms. Compared with previous works, the proposed algorithms can realize the control of continuous action for the subway system and optimize multiple critical objectives without using an offline speed profile. Firstly, through learning historical data of experienced subway drivers, we extract the expert knowledge rules and build inference methods to guarantee the riding comfort, the punctuality, and the safety of the subway system. Then we develop two algorithms for optimizing the energy efficiency of train operation. One is the smart train operation (STO) algorithm based on deep deterministic policy gradient named (STOD) and the other is the smart train operation algorithm based on normalized advantage function (STON). Finally, we verify the performance of proposed algorithms via some numerical simulations with the real field data from the Yizhuang Line of the Beijing Subway and illustrate that the developed smart train operation algorithm are better than expert manual driving and existing ATO algorithms in terms of energy efficiency. Moreover, STOD and STON can adapt to different trip times and different resistance conditions.",
        "published": "2020-03-06T17:56:43Z",
        "link": "http://arxiv.org/abs/2003.03327v3",
        "categories": [
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "Optimizing Revenue while showing Relevant Assortments at Scale",
        "authors": [
            "Theja Tulabandhula",
            "Deeksha Sinha",
            "Saketh Karra"
        ],
        "summary": "Scalable real-time assortment optimization has become essential in e-commerce operations due to the need for personalization and the availability of a large variety of items. While this can be done when there are simplistic assortment choices to be made, the optimization process becomes difficult when imposing constraints on the collection of relevant assortments based on insights by store-managers and historically well-performing assortments. We design fast and flexible algorithms based on variations of binary search that find the (approximately) optimal assortment in this difficult regime. In particular, we revisit the problem of large-scale assortment optimization under the multinomial logit choice model without any assumptions on the structure of the feasible assortments. We speed up the comparison steps using advances in similarity search in the field of information retrieval/machine learning. For an arbitrary collection of assortments, our algorithms can find a solution in time that is sub-linear in the number of assortments, and for the simpler case of cardinality constraints - linear in the number of items (existing methods are quadratic or worse). Empirical validations using a real world dataset (in addition to experiments using semi-synthetic data based on the Billion Prices dataset and several retail transaction datasets) show that our algorithms are competitive even when the number of items is $\\sim 10^5$ ($10\\times$ larger instances than previously studied).",
        "published": "2020-03-06T20:16:49Z",
        "link": "http://arxiv.org/abs/2003.04736v2",
        "categories": [
            "cs.AI",
            "cs.CE",
            "stat.AP"
        ]
    },
    {
        "title": "ASAP-SML: An Antibody Sequence Analysis Pipeline Using Statistical   Testing and Machine Learning",
        "authors": [
            "Xinmeng Li",
            "James A. Van Deventer",
            "Soha Hassoun"
        ],
        "summary": "Antibodies are capable of potently and specifically binding individual antigens and, in some cases, disrupting their functions. The key challenge in generating antibody-based inhibitors is the lack of fundamental information relating sequences of antibodies to their unique properties as inhibitors. We develop a pipeline, Antibody Sequence Analysis Pipeline using Statistical testing and Machine Learning (ASAP-SML), to identify features that distinguish one set of antibody sequences from antibody sequences in a reference set. The pipeline extracts feature fingerprints from sequences. The fingerprints represent germline, CDR canonical structure, isoelectric point and frequent positional motifs. Machine learning and statistical significance testing techniques are applied to antibody sequences and extracted feature fingerprints to identify distinguishing feature values and combinations thereof. To demonstrate how it works, we applied the pipeline on sets of antibody sequences known to bind or inhibit the activities of matrix metalloproteinases (MMPs), a family of zinc-dependent enzymes that promote cancer progression and undesired inflammation under pathological conditions, against reference datasets that do not bind or inhibit MMPs. ASAP-SML identifies features and combinations of feature values found in the MMP-targeting sets that are distinct from those in the reference sets.",
        "published": "2020-03-08T16:53:42Z",
        "link": "http://arxiv.org/abs/2003.03811v1",
        "categories": [
            "cs.CE",
            "q-bio.QM"
        ]
    },
    {
        "title": "Enhancing Industrial X-ray Tomography by Data-Centric Statistical   Methods",
        "authors": [
            "Jarkko Suuronen",
            "Muhammad Emzir",
            "Sari Lasanen",
            "Simo Särkkä",
            "Lassi Roininen"
        ],
        "summary": "X-ray tomography has applications in various industrial fields such as sawmill industry, oil and gas industry, chemical engineering, and geotechnical engineering. In this article, we study Bayesian methods for the X-ray tomography reconstruction. In Bayesian methods, the inverse problem of tomographic reconstruction is solved with help of a statistical prior distribution which encodes the possible internal structures by assigning probabilities for smoothness and edge distribution of the object. We compare Gaussian random field priors, that favour smoothness, to non-Gaussian total variation, Besov, and Cauchy priors which promote sharp edges and high-contrast and low-contrast areas in the object. We also present computational schemes for solving the resulting high-dimensional Bayesian inverse problem with 100,000-1,000,000 unknowns. In particular, we study the applicability of a no-U-turn variant of Hamiltonian Monte Carlo methods and of a more classical adaptive Metropolis-within-Gibbs algorithm for this purpose. These methods also enable full uncertainty quantification of the reconstructions. For faster computations, we use maximum a posteriori estimates with limited-memory BFGS optimisation algorithm. As the first industrial application, we consider sawmill industry X-ray log tomography. The logs have knots, rotten parts, and even possibly metallic pieces, making them good examples for non-Gaussian priors. Secondly, we study drill-core rock sample tomography, an example from oil and gas industry. We show that Cauchy priors produce smaller number of artefacts than other choices, especially with sparse high-noise measurements, and choosing Hamiltonian Monte Carlo enables systematic uncertainty quantification.",
        "published": "2020-03-08T17:22:58Z",
        "link": "http://arxiv.org/abs/2003.03814v1",
        "categories": [
            "cs.CE",
            "eess.IV",
            "stat.ME"
        ]
    },
    {
        "title": "An energy stable one-field monolithic arbitrary Lagrangian-Eulerian   formulation for fluid-structure interaction",
        "authors": [
            "Yongxing Wang",
            "Peter K. Jimack",
            "Mark A. Walkley",
            "Olivier Pironneau"
        ],
        "summary": "In this article we present a one-field monolithic finite element method in the Arbitrary Lagrangian-Eulerian (ALE) formulation for Fluid-Structure Interaction (FSI) problems. The method only solves for one velocity field in the whole FSI domain, and it solves in a monolithic manner so that the fluid solid interface conditions are satisfied automatically. We prove that the proposed scheme is unconditionally stable, through energy analysis, by utilising a conservative formulation and an exact quadrature rule. We implement the algorithm using both ${\\bf F}$-scheme and ${\\bf d}$-scheme, and demonstrate that the former has the same formulation in two and three dimensions. Finally several numerical examples are presented to validate this methodology, including combination with remesh techniques to handle the case of very large solid displacement.",
        "published": "2020-03-08T17:53:44Z",
        "link": "http://arxiv.org/abs/2003.03819v1",
        "categories": [
            "cs.CE",
            "math.AP"
        ]
    },
    {
        "title": "Improved VIV response prediction using adaptive parameters and data   clustering",
        "authors": [
            "Jie Wu",
            "Decao Yin",
            "Halvor Lie",
            "Signe Riemer-Sørensen",
            "Svein Sævik",
            "Michael Triantafyllou"
        ],
        "summary": "Slender marine structures such as deep-water riser systems are continuously exposed to currents leading to vortex-induced vibrations (VIV) of the structure. This may result in amplified drag loads and fast accumulation of fatigue damage. Consequently, accurate prediction of VIV responses is of great importance for the safe design and operation of marine risers. Model tests with elastic pipes have shown that VIV responses are influenced by many structural and hydrodynamic parameters, which have not been fully modelled in present frequency domain VIV prediction tools. Traditionally, predictions have been computed using a single set of hydrodynamic parameters, often leading to inconsistent prediction accuracy when compared with observed field measurements and experimental data. Hence, it is necessary to implement a high safety factor of 10 - 20 in the riser design, which increases development cost and adds extra constraints in the field operation. One way to compensate for the simplifications in the mathematical prediction model is to apply adaptive parameters to describe different riser responses. The objective of this work is to demonstrate a new method to improve the prediction consistency and accuracy by applying adaptive hydrodynamic parameters. In the present work, a four-step approach has been proposed: First, the measured VIV response will be analysed to identify key parameters to represent the response characteristics. These parameters will be grouped using data clustering algorithms. Secondly, optimal hydrodynamic parameters will be identified for each data group by optimisation against measured data. Thirdly, the VIV response using the obtained parameters will be calculated and the prediction accuracy evaluated. The correct hydrodynamic parameters to be used for new cases can be obtained from the clustering. This concept has been demonstrated with examples from experimental data.",
        "published": "2020-03-10T08:20:38Z",
        "link": "http://arxiv.org/abs/2003.05519v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Predicting the vulnerability of spacecraft components: modelling debris   impact effects through vulnerable-zones",
        "authors": [
            "Mirko Trisolini",
            "Hugh G. Lewis",
            "Camilla Colombo"
        ],
        "summary": "The space environment around the Earth is populated by more than 130 million objects of 1 mm in size and larger, and future predictions shows that this amount is destined to increase, even if mitigation measures are implemented at a far better rate than today. These objects can hit and damage a spacecraft or its components. It is thus necessary to assess the risk level for a satellite during its mission lifetime. Few software packages perform this analysis, and most of them employ time-consuming ray-tracing methodology, where particles are randomly sampled from relevant distributions. In addition, they tend not to consider the risk associated with the secondary debris clouds. The paper presents the development of a vulnerability assessment model, which relies on a fully statistical procedure: the debris fluxes are directly used combining them with the concept of the vulnerable zone, avoiding the random sampling the debris fluxes. A novel methodology is presented to predict damage to internal components. It models the interaction between the components and the secondary debris cloud through basic geometric operations, considering mutual shielding and shadowing between internal components. The methodologies are tested against state-of-the-art software for relevant test cases, comparing results on external structures and internal components.",
        "published": "2020-03-10T15:17:02Z",
        "link": "http://arxiv.org/abs/2003.05521v1",
        "categories": [
            "astro-ph.IM",
            "cs.CE",
            "physics.space-ph"
        ]
    },
    {
        "title": "Estimation of lateral track irregularity through Kalman filtering   techniques",
        "authors": [
            "S. Munoz",
            "J. Ros",
            "J. L. Escalona"
        ],
        "summary": "The aim of this work is to develop a model-based methodology for monitoring lateral track irregularities based on the use of inertial sensors mounted on an in-service train. To this end, a gyroscope is used to measure the wheelset yaw angular velocity and two accelerometers are used to measure lateral acceleration of the wheelset and the bogie frame. Using a highly simplified linear bogie model that is able to capture the most relevant dynamic behaviour allows for the set-up of a very efficient Kalman-based monitoring strategy. The behaviour of the designed filter is assessed through the use of a detailed multibody model of an in-service vehicle running on a straight track with realistic irregularities. The model output is used to generate virtual measurements that are subsequently used to run the filter and validate the proposed estimator. In addition, the equivalent parameters of the simplified model are identified based on these simulations. In order to prove the robustness of the proposed technique, a systematic parametric analysis has been performed. The results obtained with the proposed method are promising, showing high accuracy and robustness for monitoring lateral alignment on straight tracks, with a very low computational cost.",
        "published": "2020-03-11T11:20:36Z",
        "link": "http://arxiv.org/abs/2003.05222v1",
        "categories": [
            "cs.CE",
            "eess.SP",
            "G.1; G.3; J.6"
        ]
    },
    {
        "title": "COVID-19 Evolves in Human Hosts",
        "authors": [
            "Yanni Li",
            "Bing Liu",
            "Zhi Wang",
            "Jiangtao Cui",
            "Kaicheng Yao",
            "Pengfan Lv",
            "Yulong Shen",
            "Yueshen Xu",
            "Yuanfang Guan",
            "Xiaoke Ma"
        ],
        "summary": "Today, we are all threatened by an unprecedented pandemic: COVID-19. How different is it from other coronaviruses? Will it be attenuated or become more virulent? Which animals may be its original host? In this study, we collected and analyzed nearly thirty thousand publicly available complete genome sequences for COVID-19 virus from 79 different countries, the previously known flu-causing coronaviruses (HCov-229E, HCov-OC43, HCov-NL63 and HCov-HKU1) and the lethal, pathogenic viruses, SARS, MERS, Victoria, Lassa, Yamagata, Ebola, and Dengue. We found strong similarities between the current circulating COVID-19 and SARS and MERS, as well as COVID-19 in rhinolophines and pangolins. On the contrary, COVID-19 shares little similarity with the flu-causing coronaviruses and the other known viruses. Strikingly, we observed that the divergence of COVID-19 strains isolated from human hosts has steadily increased from December 2019 to May 2020, suggesting COVID-19 is actively evolving in human hosts. In this paper, we first propose a novel MLCS algorithm NP-MLCS1 for the big sequence analysis, which can calculate the common model for COVID-19 complete genome sequences to provide important information for vaccine and antibody development. Geographic and time-course analysis of the evolution trees of the human COVID-19 reveals possible evolutional paths among strains from 79 countries. This finding has important implications to the management of COVID-19 and the development of vaccines and medications.",
        "published": "2020-03-12T02:33:13Z",
        "link": "http://arxiv.org/abs/2003.05580v6",
        "categories": [
            "q-bio.PE",
            "cs.CE"
        ]
    },
    {
        "title": "Data-driven modelling of nonlinear spatio-temporal fluid flows using a   deep convolutional generative adversarial network",
        "authors": [
            "M. Cheng",
            "F. Fang",
            "C. C. Pain",
            "I. M. Navon"
        ],
        "summary": "Deep learning techniques for improving fluid flow modelling have gained significant attention in recent years. Advanced deep learning techniques achieve great progress in rapidly predicting fluid flows without prior knowledge of the underlying physical relationships. Advanced deep learning techniques achieve great progress in rapidly predicting fluid flows without prior knowledge of the underlying physical relationships. However, most of existing researches focused mainly on either sequence learning or spatial learning, rarely on both spatial and temporal dynamics of fluid flows (Reichstein et al., 2019). In this work, an Artificial Intelligence (AI) fluid model based on a general deep convolutional generative adversarial network (DCGAN) has been developed for predicting spatio-temporal flow distributions. In deep convolutional networks, the high-dimensional flows can be converted into the low-dimensional \"latent\" representations. The complex features of flow dynamics can be captured by the adversarial networks. The above DCGAN fluid model enables us to provide reasonable predictive accuracy of flow fields while maintaining a high computational efficiency. The performance of the DCGAN is illustrated for two test cases of Hokkaido tsunami with different incoming waves along the coastal line. It is demonstrated that the results from the DCGAN are comparable with those from the original high fidelity model (Fluidity). The spatio-temporal flow features have been represented as the flow evolves, especially, the wave phases and flow peaks can be captured accurately. In addition, the results illustrate that the online CPU cost is reduced by five orders of magnitude compared to the original high fidelity model simulations. The promising results show that the DCGAN can provide rapid and reliable spatio-temporal prediction for nonlinear fluid flows.",
        "published": "2020-03-13T00:53:57Z",
        "link": "http://arxiv.org/abs/2004.00707v1",
        "categories": [
            "physics.ao-ph",
            "cs.CE",
            "physics.flu-dyn"
        ]
    },
    {
        "title": "Data-driven surrogate modelling and benchmarking for process equipment",
        "authors": [
            "Gabriel F. N. Gonçalves",
            "Assen Batchvarov",
            "Yuyi Liu",
            "Yuxin Liu",
            "Lachlan Mason",
            "Indranil Pan",
            "Omar K. Matar"
        ],
        "summary": "In chemical process engineering, surrogate models of complex systems are often necessary for tasks of domain exploration, sensitivity analysis of the design parameters, and optimization. A suite of computational fluid dynamics (CFD) simulations geared toward chemical process equipment modeling has been developed and validated with experimental results from the literature. Various regression-based active learning strategies are explored with these CFD simulators in-the-loop under the constraints of a limited function evaluation budget. Specifically, five different sampling strategies and five regression techniques are compared, considering a set of four test cases of industrial significance and varying complexity. Gaussian process regression was observed to have a consistently good performance for these applications. The present quantitative study outlines the pros and cons of the different available techniques and highlights the best practices for their adoption. The test cases and tools are available with an open-source license to ensure reproducibility and engage the wider research community in contributing to both the CFD models and developing and benchmarking new improved algorithms tailored to this field.",
        "published": "2020-03-13T18:22:43Z",
        "link": "http://arxiv.org/abs/2003.07701v2",
        "categories": [
            "cs.CE",
            "cs.LG",
            "physics.flu-dyn",
            "stat.ML"
        ]
    },
    {
        "title": "Inference of Gas-liquid Flowrate using Neural Networks",
        "authors": [
            "Akshay J. Dave",
            "Annalisa Manera"
        ],
        "summary": "The metering of gas-liquid flows is difficult due to the non-linear relationship between flow regimes and fluid properties, flow orientation, channel geometry, etc. In fact, a majority of commercial multiphase flow meters have a low accuracy, limited range of operation or require a physical separation of the phases. We introduce the inference of gas-liquid flowrates using a neural network model that is trained by wire-mesh sensor (WMS) experimental data. The WMS is an experimental tool that records high-resolution high-frequency 3D void fraction distributions in gas-liquid flows. The experimental database utilized spans over two orders of superficial velocity magnitude and multiple flow regimes for a vertical small-diameter pipe. Our findings indicate that a single network can provide accurate and precise inference with below a 7.5% MAP error across all flow regimes. The best performing networks have a combination of a 3D-Convolution head, and an LSTM tail. The finding indicates that the spatiotemporal features observed in gas-liquid flows can be systematically decomposed and used for inferring phase-wise flowrate. Our method does not involve any complex pre-processing of the void fraction matrices, resulting in an evaluation time that is negligible when contrasted to the input time-span. The efficiency of the model manifests in a response time two orders of magnitude lower than the current state-of-the-art.",
        "published": "2020-03-15T11:21:40Z",
        "link": "http://arxiv.org/abs/2003.08182v3",
        "categories": [
            "physics.flu-dyn",
            "cs.CE"
        ]
    },
    {
        "title": "A local basis approximation approach for nonlinear parametric model   order reduction",
        "authors": [
            "Konstantinos Vlachas",
            "Konstantinos Tatsis",
            "Konstantinos Agathos",
            "Adam R. Brink",
            "Eleni Chatzi"
        ],
        "summary": "The efficient condition assessment of engineered systems requires the coupling of high fidelity models with data extracted from the state of the system `as-is'. In enabling this task, this paper implements a parametric Model Order Reduction (pMOR) scheme for nonlinear structural dynamics, and the particular case of material nonlinearity. A physics-based parametric representation is developed, incorporating dependencies on system properties and/or excitation characteristics. The pMOR formulation relies on use of a Proper Orthogonal Decomposition applied to a series of snapshots of the nonlinear dynamic response. A new approach to manifold interpolation is proposed, with interpolation taking place on the reduced coefficient matrix mapping local bases to a global one. We demonstrate the performance of this approach firstly on the simple example of a shear-frame structure, and secondly on the more complex 3D numerical case study of an earthquake-excited wind turbine tower. Parametric dependence pertains to structural properties, as well as the temporal and spectral characteristics of the applied excitation. The developed parametric Reduced Order Model (pROM) can be exploited for a number of tasks including monitoring and diagnostics, control of vibrating structures, and residual life estimation of critical components.",
        "published": "2020-03-16T10:14:25Z",
        "link": "http://arxiv.org/abs/2003.07716v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Predicting Elastic Properties of Materials from Electronic Charge   Density Using 3D Deep Convolutional Neural Networks",
        "authors": [
            "Yong Zhao",
            "Kunpeng Yuan",
            "Yinqiao Liu",
            "Steph-Yves Louis",
            "Ming Hu",
            "Jianjun Hu"
        ],
        "summary": "Materials representation plays a key role in machine learning based prediction of materials properties and new materials discovery. Currently both graph and 3D voxel representation methods are based on the heterogeneous elements of the crystal structures. Here, we propose to use electronic charge density (ECD) as a generic unified 3D descriptor for materials property prediction with the advantage of possessing close relation with the physical and chemical properties of materials. We developed an ECD based 3D convolutional neural networks (CNNs) for predicting elastic properties of materials, in which CNNs can learn effective hierarchical features with multiple convolving and pooling operations. Extensive benchmark experiments over 2,170 Fm-3m face-centered-cubic (FCC) materials show that our ECD based CNNs can achieve good performance for elasticity prediction. Especially, our CNN models based on the fusion of elemental Magpie features and ECD descriptors achieved the best 5-fold cross-validation performance. More importantly, we showed that our ECD based CNN models can achieve significantly better extrapolation performance when evaluated over non-redundant datasets where there are few neighbor training samples around test samples. As additional validation, we evaluated the predictive performance of our models on 329 materials of space group Fm-3m by comparing to DFT calculated values, which shows better prediction power of our model for bulk modulus than shear modulus. Due to the unified representation power of ECD, it is expected that our ECD based CNN approach can also be applied to predict other physical and chemical properties of crystalline materials.",
        "published": "2020-03-17T06:21:36Z",
        "link": "http://arxiv.org/abs/2003.13425v2",
        "categories": [
            "cond-mat.mtrl-sci",
            "cs.CE",
            "cs.LG",
            "cs.NE",
            "physics.comp-ph",
            "74B99",
            "I.2.1"
        ]
    },
    {
        "title": "A Hybrid Phase Field Model for Fracture Induced by Lithium Diffusion in   Electrode Particles of Li-ion Batteries",
        "authors": [
            "Masoud Ahmadi"
        ],
        "summary": "Lithium-ion batteries (LIBs) of high energy density and light-weight design, have found wide applications in electronic devices and systems. Degradation mechanisms that caused by lithiation is a main challenging problem for LIBs with high capacity electrodes like silicon (Si), which eventually can reduce the lifetime of batteries. In this paper, a hybrid phase field model (PFM) is proposed to study the fracture behavior of LIB electrodes. The model considers the coupling effects between lithium (Li) -ion diffusion process, stress evolution and crack propagation. Also, the dependency of Elastic properties on the concentration magnitude of Li-ion is considered. A numerical implementation based on a MATLAB finite element (FE) code is elaborated. Then, the proposed hybrid PF approach is applied to a Nanowire (NW) Si electrode particle. It is shown that the hybrid model shows less tendency to crack growth than the isotropic model.",
        "published": "2020-03-17T10:41:33Z",
        "link": "http://arxiv.org/abs/2003.08804v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Pressio: Enabling projection-based model reduction for large-scale   nonlinear dynamical systems",
        "authors": [
            "Francesco Rizzi",
            "Patrick J. Blonigan",
            "Eric J. Parish",
            "Kevin T. Carlberg"
        ],
        "summary": "This work introduces Pressio, an open-source project aimed at enabling leading-edge projection-based reduced order models (ROMs) for large-scale nonlinear dynamical systems in science and engineering. Pressio provides model-reduction methods that can reduce both the number of spatial and temporal degrees of freedom for any dynamical system expressible as a system of parameterized ordinary differential equations (ODEs). We leverage this simple, expressive mathematical framework as a pivotal design choice to enable a minimal application programming interface (API) that is natural to dynamical systems. The core component of Pressio is a C++11 header-only library that leverages generic programming to support applications with arbitrary data types and arbitrarily complex programming models. This is complemented with Python bindings to expose these C++ functionalities to Python users with negligible overhead and no user-required binding code. We discuss the distinguishing characteristics of Pressio relative to existing model-reduction libraries, outline its key design features, describe how the user interacts with it, and present two test cases -- including one with over 20 million degrees of freedom -- that highlight the performance results of Pressio and illustrate the breath of problems that can be addressed with it.",
        "published": "2020-03-17T16:25:10Z",
        "link": "http://arxiv.org/abs/2003.07798v3",
        "categories": [
            "cs.MS",
            "cs.CE",
            "physics.comp-ph",
            "physics.flu-dyn"
        ]
    },
    {
        "title": "On the scalability of CFD tool for supersonic jet flow configurations",
        "authors": [
            "Carlos Junqueira-Junior",
            "João Luiz F. Azevedo",
            "Jairo Panetta",
            "William R. Wolf",
            "Sami Yamouni"
        ],
        "summary": "New regulations are imposing noise emissions limitations for the aviation industry which are pushing researchers and engineers to invest efforts in studying the aeroacoustics phenomena. Following this trend, an in-house computational fluid dynamics tool is build to reproduce high fidelity results of supersonic jet flows for aeroacoustic analogy applications. The solver is written using the large eddy simulation formulation that is discretized using a finite difference approach and an explicit time integration. Numerical simulations of supersonic jet flows are very expensive and demand efficient high-performance computing. Therefore, non-blocking message passage interface protocols and parallel Input/Output features are implemented into the code in order to perform simulations which demand up to one billion grid points. The present work addresses the evaluation of code improvements along with the computational performance of the solver running on a computer with maximum theoretical peak of 2.727 PFlops. Different mesh configurations, whose size varies from a few hundred thousand to approximately one billion grid points, are evaluated in the present paper. Calculations are performed using different workloads in order to assess the strong and weak scalability of the parallel computational tool. Moreover, validation results of a realistic flow condition are also presented in the current work.",
        "published": "2020-03-18T17:49:52Z",
        "link": "http://arxiv.org/abs/2003.09926v1",
        "categories": [
            "cs.DC",
            "cs.CE"
        ]
    },
    {
        "title": "The influence of initial perturbation power spectra on the growth of a   turbulent mixing layer induced by Richtmyer-Meshkov instability",
        "authors": [
            "Michael Groom",
            "Ben Thornber"
        ],
        "summary": "This paper investigates the influence of different broadband perturbations on the evolution of a Richtmyer--Meshkov turbulent mixing layer initiated by a Mach 1.84 shock traversing a perturbed interface separating gases with a density ratio of 3:1. Both the bandwidth of modes in the interface perturbation, as well as their relative amplitudes, are varied in a series of carefully designed numerical simulations at grid resolutions up to $3.2\\times10^9$ cells. Three different perturbations are considered, characterised by a power spectrum of the form $P(k)\\propto k^m$ where $m=-1$, $-2$ and $-3$. The growth of the mixing layer is shown to strongly depend on the initial conditions, with the growth rate exponent $\\theta$ found to be $0.5$, $0.63$ and $0.75$ for each value of $m$ at the highest grid resolution. The asymptotic values of the molecular mixing fraction $\\Theta$ are also shown to vary significantly with $m$; at the latest time considered $\\Theta$ is $0.56$, $0.39$ and $0.20$ respectively. Turbulent kinetic energy (TKE) is also analysed in both the temporal and spectral domains. The temporal decay rate of TKE is found not to match the predicted value of $n=2-3\\theta$, which is shown to be due to a time-varying {normalised dissipation rate $C_\\epsilon$}. In spectral space, the data follow the theoretical scaling of $k^{(m+2)/2}$ at low wavenumbers and tend towards $k^{-3/2}$ and $k^{-5/3}$ scalings at high wavenumbers for the spectra of transverse and normal velocity components respectively. The results represent a significant extension of previous work on the Richtmyer--Meshkov instability evolving from broadband initial perturbations and provide useful benchmarks for future research.",
        "published": "2020-03-18T23:42:21Z",
        "link": "http://arxiv.org/abs/2003.10549v1",
        "categories": [
            "physics.flu-dyn",
            "cs.CE"
        ]
    },
    {
        "title": "Strong Scaling of Numerical Solver for Supersonic Jet Flow Configuration",
        "authors": [
            "Carlos Junqueira-Junior",
            "João Luiz F. Azevedo",
            "Jairo Panetta",
            "William R. Wolf",
            "Sami Yamouni"
        ],
        "summary": "Acoustics loads are rocket design constraints which push researches and engineers to invest efforts in the aeroacoustics phenomena which is present on launch vehicles. Therefore, an in-house computational fluid dynamics tool is developed in order to reproduce high-fidelity results of supersonic jet flows for aeroacoustic analogy applications. The solver is written using the large eddy simulation formulation that is discretized using a finite-difference approach and an explicit time integration. Numerical simulations of supersonic jet flows are very expensive and demand efficient high-performance computing. Therefore, non-blocking message passage interface protocols and parallel input/output features are implemented into the code in order to perform simulations which demand up to one billion degrees of freedom. The present work evaluates the parallel efficiency of the solver when running on a supercomputer with a maximum theoretical peak of 127.4 TFLOPS. Speedup curves are generated using nine different workloads. Moreover, the validation results of a realistic flow condition are also presented in the current work.",
        "published": "2020-03-19T14:09:20Z",
        "link": "http://arxiv.org/abs/2003.08746v1",
        "categories": [
            "cs.CE",
            "cs.DC",
            "68W10"
        ]
    },
    {
        "title": "BetheSF: Efficient computation of the exact tagged-particle propagator   in single-file systems via the Bethe eigenspectrum",
        "authors": [
            "Alessio Lapolla",
            "Aljaz Godec"
        ],
        "summary": "Single-file diffusion is a paradigm for strongly correlated classical stochastic many-body dynamics and has widespread applications in soft condensed matter and biophysics. However, exact results for {single-file} systems are sparse and limited to the simplest scenarios. We present an algorithm for computing the non-Markovian time-dependent conditional probability density function of a {tagged-particle} in a {single-file} of $N$ particles diffusing in a confining external potential. The algorithm implements an eigenexpansion of the full interacting many-body problem obtained by means of the coordinate Bethe ansatz. While formally exact, the Bethe eigenspectrum involves the generation and evaluation of permutations, {which becomes unfeasible   for single-files with an increasing number of particles $N$.} Here we exploit the underlying {exchange} symmetries between the particles to the left and to the right of the {tagged-particle} and show that it is possible to reduce the complexity of the algorithm from the worst case scenario $\\mathcal{O}(N!)$ down to $\\mathcal{O}(N)$. A C++ code to calculate the non-Markovian probability density function using this algorithm is provided. Solutions for simple model potentials are readily implemented incl. {single-file diffusion} in a flat and a 'tilted' box, as well as in a parabolic potential. Notably, the program allows for implementations of solutions in arbitrary external potentials under the condition that the user can supply solutions to the respective single-particle eigenspectra.",
        "published": "2020-03-20T13:41:31Z",
        "link": "http://arxiv.org/abs/2003.09275v2",
        "categories": [
            "physics.comp-ph",
            "cond-mat.stat-mech",
            "cs.CE"
        ]
    },
    {
        "title": "Intelligent multiscale simulation based on process-guided composite   database",
        "authors": [
            "Zeliang Liu",
            "Haoyan Wei",
            "Tianyu Huang",
            "C. T. Wu"
        ],
        "summary": "In the paper, we present an integrated data-driven modeling framework based on process modeling, material homogenization, mechanistic machine learning, and concurrent multiscale simulation. We are interested in the injection-molded short fiber reinforced composites, which have been identified as key material systems in automotive, aerospace, and electronics industries. The molding process induces spatially varying microstructures across various length scales, while the resulting strongly anisotropic and nonlinear material properties are still challenging to be captured by conventional modeling approaches. To prepare the linear elastic training data for our machine learning tasks, Representative Volume Elements (RVE) with different fiber orientations and volume fractions are generated through stochastic reconstruction. More importantly, we utilize the recently proposed Deep Material Network (DMN) to learn the hidden microscale morphologies from data. With essential physics embedded in its building blocks, this data-driven material model can be extrapolated to predict nonlinear material behaviors efficiently and accurately. Through the transfer learning of DMN, we create a unified process-guided material database that covers a full range of geometric descriptors for short fiber reinforced composites. Finally, this unified DMN database is implemented and coupled with macroscale finite element model to enable concurrent multiscale simulations. From our perspective, the proposed framework is also promising in many other emergent multiscale engineering systems, such as additive manufacturing and compressive molding.",
        "published": "2020-03-20T20:39:19Z",
        "link": "http://arxiv.org/abs/2003.09491v1",
        "categories": [
            "cs.CE",
            "cs.LG",
            "physics.comp-ph"
        ]
    },
    {
        "title": "A machine learning accelerated FE$^2$ homogenization algorithm for   elastic solids",
        "authors": [
            "Saumik Dana",
            "Mary F Wheeler"
        ],
        "summary": "The FE$^2$ homogenization algorithm for multiscale modeling iterates between the macroscale and the microscale (represented by a representative volume element) till convergence is achieved at every increment of macroscale loading. The information exchange between the two scales occurs at the gauss points of the macroscale finite element discretization. The microscale problem is also solved using finite elements on-the-fly thus rendering the algorithm computationally expensive for complex microstructures. We invoke machine learning to establish the input-output causality of the RVE boundary value problem using a neural network framework. This renders the RVE as a blackbox which gets the information from the macroscale as an input and gives information back to the macroscale as output, thereby eliminating the need for on-the-fly finite element solves at the RVE level. This framework has the potential to significantly accelerate the FE$^2$ algorithm.",
        "published": "2020-03-21T18:01:02Z",
        "link": "http://arxiv.org/abs/2003.11372v3",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "An Improved Physics Based Numerical Model of Tunnel FET Using 2D NEGF   Formalism",
        "authors": [
            "Md Shamim Hussain"
        ],
        "summary": "In this work, we have investigated a 2D model of band-to-band tunneling based on 2-band model and implemented it using 2D NEGF formalism. Being 2D in nature, this model better addresses the variation in the directionality of the tunneling process occurring in most practical TFET device structures. It also works as a compromise between semi-classical and multiband quantum simulation of TFETs. In this work, we have presented a sound step by step mathematical development of the numerical model. We have also discussed how this model can be implemented in simulators and pointed out a few optimizations that can be made to reduce complexity and to save time. Finally, we have performed elaborate simulations for a practical TFET design and compared the results with commercially available TCAD simulations, to point out the limitations of the simplistic models that are frequently used, and how our model overcomes these limitations.",
        "published": "2020-03-24T06:14:54Z",
        "link": "http://arxiv.org/abs/2003.12568v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Position based dynamic of a particle system: a configurable algorithm to   describe complex behaviour of continuum material starting from swarm robotics",
        "authors": [
            "Ramiro dell'Erba"
        ],
        "summary": "In a previous work we considered a two-dimensional lattice of particles and calculated its time evolution by using an interaction law based on the spatial position of the particles themselves. The model reproduced the behaviour of deformable bodies both according to the standard Cauchy model and second gradient theory; this success led us to use this method in more complex cases. This work is intended as the natural evolution of the previous one in which we shall consider both energy aspects, coherence with the principle of Saint Venant and we start to manage a more general tool that can be adapted to different physical phenomena, supporting complex effects like lateral contraction, anisotropy or elastoplasticity.",
        "published": "2020-03-24T07:07:17Z",
        "link": "http://arxiv.org/abs/2003.11908v1",
        "categories": [
            "cs.CE",
            "cs.RO"
        ]
    },
    {
        "title": "Automatic Modelling of Human Musculoskeletal Ligaments -- Framework   Overview and Model Quality Evaluation",
        "authors": [
            "Noura Hamze",
            "Lukas Nocker",
            "Nikolaus Rauch",
            "Markus Walzthöni",
            "Fabio Carrillo",
            "Philipp Fürnstahl",
            "Matthias Harders"
        ],
        "summary": "Accurate segmentation of connective soft tissues is still a challenging task, which hinders the generation of corresponding geometric models for biomechanical computations. Alternatively, one could predict ligament insertion sites and then approximate the shapes, based on anatomical knowledge and morphological studies. Here, we describe a corresponding integrated framework for the automatic modelling of human musculoskeletal ligaments. We combine statistical shape modelling with geometric algorithms to automatically identify insertion sites, based on which geometric surface and volume meshes are created. For demonstrating a clinical use case, the framework has been applied to generate models of the interosseous membrane in the forearm. For the adoption to the forearm anatomy, ligament insertion sites in the statistical model were defined according to anatomical predictions following an approach proposed in prior work. For evaluation we compared the generated sites, as well as the ligament shapes, to data obtained from a cadaveric study, involving five forearms with a total of 15 ligaments. Our framework permitted the creation of 3D models approximating ligaments' shapes with good fidelity. However, we found that the statistical model trained with the state-of-the-art prediction of the insertion sites was not always reliable. Using that model, average mean square errors as well as Hausdorff distances of the meshes increased by more than one order of magnitude, as compared to employing the known insertion locations of the cadaveric study. Using the latter an average mean square error of 0.59 mm and an average Hausdorff distance of less than 7 mm resulted, for the complete set of ligaments. In conclusion, the presented approach for generating ligament shapes from insertion points appears to be feasible but the detection of the insertion sites with a SSM is too inaccurate.",
        "published": "2020-03-24T10:19:29Z",
        "link": "http://arxiv.org/abs/2003.11025v1",
        "categories": [
            "cs.GR",
            "cs.CE"
        ]
    },
    {
        "title": "Data-Driven Failure Prediction in Brittle Materials: A Phase-Field Based   Machine Learning Framework",
        "authors": [
            "Eduardo A. Barros de Moraes",
            "Hadi Salehi",
            "Mohsen Zayernouri"
        ],
        "summary": "Failure in brittle materials led by the evolution of micro- to macro-cracks under repetitive or increasing loads is often catastrophic with no significant plasticity to advert the onset of fracture. Early failure detection with respective location are utterly important features in any practical application, both of which can be effectively addressed using artificial intelligence. In this paper, we develop a supervised machine learning (ML) framework to predict failure in an isothermal, linear elastic and isotropic phase-field model for damage and fatigue of brittle materials. Time-series data of the phase-field model is extracted from virtual sensing nodes at different locations of the geometry. A pattern recognition scheme is introduced to represent time-series data/sensor nodes responses as a pattern with a corresponding label, integrated with ML algorithms, used for damage classification with identified patterns. We perform an uncertainty analysis by superposing random noise to the time-series data to assess the robustness of the framework with noise-polluted data. Results indicate that the proposed framework is capable of predicting failure with acceptable accuracy even in the presence of high noise levels. The findings demonstrate satisfactory performance of the supervised ML framework, and the applicability of artificial intelligence and ML to a practical engineering problem, i.,e, data-driven failure prediction in brittle materials.",
        "published": "2020-03-24T17:13:08Z",
        "link": "http://arxiv.org/abs/2003.10975v1",
        "categories": [
            "cs.CE",
            "cs.LG",
            "stat.ML"
        ]
    },
    {
        "title": "An Accelerated Surface Integral Equation Method for the Electromagnetic   Modeling of Dielectric and Lossy Objects of Arbitrary Conductivity",
        "authors": [
            "Shashwat Sharma",
            "Piero Triverio"
        ],
        "summary": "Surface integral equation (SIE) methods are of great interest for the numerical solution of Maxwell's equations in the presence of homogeneous objects. However, existing SIE algorithms have limitations, either in terms of scalability, frequency range, or material properties. We present a scalable SIE algorithm based on the generalized impedance boundary condition which can efficiently handle, in a unified manner, both dielectrics and conductors over a wide range of conductivity, size and frequency. We devise an efficient strategy for the iterative solution of the resulting equations, with efficient preconditioners and an object-specific use of the adaptive integral method. With a rigorous error analysis, we demonstrate that the adaptive integral method can be applied over a wide range of frequencies and conductivities. Several numerical examples, drawn from different applications, demonstrate the accuracy and efficiency of the proposed algorithm.",
        "published": "2020-03-25T23:35:02Z",
        "link": "http://arxiv.org/abs/2003.11679v3",
        "categories": [
            "physics.comp-ph",
            "cs.CE"
        ]
    },
    {
        "title": "XBlock-EOS: Extracting and Exploring Blockchain Data From EOSIO",
        "authors": [
            "Weilin Zheng",
            "Zibin Zheng",
            "Hong-Ning Dai",
            "Xu Chen",
            "Peilin Zheng"
        ],
        "summary": "Blockchain-based cryptocurrencies and applications have flourished in blockchain research community. Massive data generated from diverse blockchain systems bring not only huge business values but also technological challenges in data analytics of heterogeneous blockchain data. Different from Bitcoin and Ethereum, EOSIO has richer diversity and a higher volume of blockchain data due to its unique architectural design in resource management, consensus scheme and high throughput. Despite its popularity (e.g., 89,800,000 blocks generated till November 14, 2019 since its launch on June 8, 2018), few studies have been made on data analysis of EOSIO. To fill this gap, we collect and process the up-to-date on-chain data from EOSIO. We name these well-processed EOSIO datasets as XBlock-EOS, which consists of 7 well-processed datasets: 1) Block, Transaction and Action, 2) Internal and External EOS Transfer Action, 3) Contract Information, 4) Contract Invocation, 5) Token Action, 6) Account Creation, 7) Resource Management. It is challenging to process and analyze a high volume of raw EOSIO data and establish the mapping from original raw data to the well-grained datasets since it requires substantial efforts in extracting various types of data as well as sophisticated knowledge on software engineering and data analytics. Meanwhile, we present statistics and exploration on these datasets. Moreover, we also outline the possible research opportunities based on XBlock-EOS.",
        "published": "2020-03-26T15:03:11Z",
        "link": "http://arxiv.org/abs/2003.11967v3",
        "categories": [
            "cs.CE",
            "cs.CR"
        ]
    },
    {
        "title": "A Two-Stage Reconstruction of Microstructures with Arbitrarily Shaped   Inclusions",
        "authors": [
            "R. Piasecki",
            "W. Olchawa",
            "D. Frączek",
            "A. Bartecka"
        ],
        "summary": "The main goal of our research is to develop an effective method with a wide range of applications for the statistical reconstruction of heterogeneous microstructures with compact inclusions of any shape, such as highly irregular grains. The devised approach uses multi-scale extended entropic descriptors (ED) that quantify the degree of spatial non-uniformity of configurations of finite-sized objects. This technique is an innovative development of previously elaborated entropy methods for statistical reconstruction. Here, we discuss the two-dimensional case, but this method can be generalized into three dimensions. At the first stage, the developed procedure creates a set of black synthetic clusters that serve as surrogate inclusions. The clusters have the same individual areas and interfaces as their target counterparts, but random shapes. Then, from a given number of easy-to-generate synthetic cluster configurations, we choose the one with the lowest value of the cost function defined by us using extended ED. At the second stage, we make a significant change in the standard technique of simulated annealing (SA). Instead of swapping pixels of different phases, we randomly move each of the selected synthetic clusters. To demonstrate the accuracy of the method, we reconstruct and analyze two-phase microstructures with irregular inclusions of silica in rubber matrix as well as stones in cement paste. The results show that the two-stage reconstruction (TSR) method provides convincing realizations for these complex microstructures. The advantages of TSR include the ease of obtaining synthetic microstructures, very low computational costs, and satisfactory mapping in the statistical context of inclusion shapes. Finally, its simplicity should greatly facilitate independent applications.",
        "published": "2020-03-26T19:16:27Z",
        "link": "http://arxiv.org/abs/2004.02587v3",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A Hybrid Lagrangian/Eulerian Collocated Advection and Projection Method   for Fluid Simulation",
        "authors": [
            "Steven W. Gagniere",
            "David A. B. Hyde",
            "Alan Marquez-Razon",
            "Chenfanfu Jiang",
            "Ziheng Ge",
            "Xuchen Han",
            "Qi Guo",
            "Joseph Teran"
        ],
        "summary": "We present a hybrid particle/grid approach for simulating incompressible fluids on collocated velocity grids. We interchangeably use particle and grid representations of transported quantities to balance efficiency and accuracy. A novel Backward Semi-Lagrangian method is derived to improve accuracy of grid based advection. Our approach utilizes the implicit formula associated with solutions of Burgers' equation. We solve this equation using Newton's method enabled by $C^1$ continuous grid interpolation. We enforce incompressibility over collocated, rather than staggered grids. Our projection technique is variational and designed for B-spline interpolation over regular grids where multiquadratic interpolation is used for velocity and multilinear interpolation for pressure. Despite our use of regular grids, we extend the variational technique to allow for cut-cell definition of irregular flow domains for both Dirichlet and free surface boundary conditions.",
        "published": "2020-03-27T04:09:29Z",
        "link": "http://arxiv.org/abs/2003.12227v1",
        "categories": [
            "cs.GR",
            "cs.CE",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Model order reduction of thermo-mechanical models with parametric   convective boundary conditions: focus on machine tool",
        "authors": [
            "Pablo Hernández-Becerro",
            "Daniel Spescha",
            "Konrad Wegener"
        ],
        "summary": "This paper presents a parametric Model Order Reduction (MOR) method for weakly coupled thermo-mechanical Finite Element (FE) models of machine tools and other similar mechatronic systems. This work proposes a reduction method, Krylov Modal Subspace (KMS), and a theoretical bound of the reduction error. The developed method addresses the parametric dependency of the convective boundary conditions using the concept of system bilinearization. Additionally, this paper investigates the coupling between the reduced-order thermal system and the mechanical response. A numerical example shows that the reduced-order model captures the response of the original system in the frequency range of interest.",
        "published": "2020-03-27T11:00:26Z",
        "link": "http://arxiv.org/abs/2004.02586v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Crystal Structure Prediction via Oblivious Local Search",
        "authors": [
            "Dmytro Antypov",
            "Argyrios Deligkas",
            "Vladimir Gusev",
            "Matthew J. Rosseinsky",
            "Paul G. Spirakis",
            "Michail Theofilatos"
        ],
        "summary": "We study Crystal Structure Prediction, one of the major problems in computational chemistry. This is essentially a continuous optimization problem, where many different, simple and sophisticated, methods have been proposed and applied. The simple searching techniques are easy to understand, usually easy to implement, but they can be slow in practice. On the other hand, the more sophisticated approaches perform well in general, however almost all of them have a large number of parameters that require fine tuning and, in the majority of the cases, chemical expertise is needed in order to properly set them up. In addition, due to the chemical expertise involved in the parameter-tuning, these approaches can be {\\em biased} towards previously-known crystal structures. Our contribution is twofold. Firstly, we formalize the Crystal Structure Prediction problem, alongside several other intermediate problems, from a theoretical computer science perspective. Secondly, we propose an oblivious algorithm for Crystal Structure Prediction that is based on local search. Oblivious means that our algorithm requires minimal knowledge about the composition we are trying to compute a crystal structure for. In addition, our algorithm can be used as an intermediate step by {\\em any} method. Our experiments show that our algorithms outperform the standard basin hopping, a well studied algorithm for the problem.",
        "published": "2020-03-27T14:47:54Z",
        "link": "http://arxiv.org/abs/2003.12442v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "An iterative splitting method for pricing European options under the   Heston model",
        "authors": [
            "Hongshan Li",
            "Zhongyi Huang"
        ],
        "summary": "In this paper, we propose an iterative splitting method to solve the partial differential equations in option pricing problems. We focus on the Heston stochastic volatility model and the derived two-dimensional partial differential equation (PDE). We take the European option as an example and conduct numerical experiments using different boundary conditions. The iterative splitting method transforms the two-dimensional equation into two quasi one-dimensional equations with the variable on the other dimension fixed, which helps to lower the computational cost. Numerical results show that the iterative splitting method together with an artificial boundary condition (ABC) based on the method by Li and Huang (2019) gives the most accurate option price and Greeks compared to the classic finite difference method with the commonly-used boundary conditions in Heston (1993).",
        "published": "2020-03-29T03:21:58Z",
        "link": "http://arxiv.org/abs/2003.12934v1",
        "categories": [
            "cs.CE",
            "q-fin.CP"
        ]
    },
    {
        "title": "A Blackbox Yield Estimation Workflow with Gaussian Process Regression   Applied to the Design of Electromagnetic Devices",
        "authors": [
            "Mona Fuhrländer",
            "Sebastian Schöps"
        ],
        "summary": "In this paper an efficient and reliable method for stochastic yield estimation is presented. Since one main challenge of uncertainty quantification is the computational feasibility, we propose a hybrid approach where most of the Monte Carlo sample points are evaluated with a surrogate model, and only a few sample points are reevaluated with the original high fidelity model. Gaussian Process Regression is a non-intrusive method which is used to build the surrogate model. Without many prerequisites, this gives us not only an approximation of the function value, but also an error indicator that we can use to decide whether a sample point should be reevaluated or not. For two benchmark problems, a dielectrical waveguide and a lowpass filter, the proposed methods outperform classic approaches.",
        "published": "2020-03-30T08:56:59Z",
        "link": "http://arxiv.org/abs/2003.13278v2",
        "categories": [
            "cs.CE",
            "60G15, 60H35, 78M31,",
            "G.1.8; G.3; I.6.3; J.2"
        ]
    },
    {
        "title": "Deep-learning enhancement of large scale numerical simulations",
        "authors": [
            "Caspar van Leeuwen",
            "Damian Podareanu",
            "Valeriu Codreanu",
            "Maxwell X. Cai",
            "Axel Berg",
            "Simon Portegies Zwart",
            "Robin Stoffer",
            "Menno Veerman",
            "Chiel van Heerwaarden",
            "Sydney Otten",
            "Sascha Caron",
            "Cunliang Geng",
            "Francesco Ambrosetti",
            "Alexandre M. J. J. Bonvin"
        ],
        "summary": "Traditional simulations on High-Performance Computing (HPC) systems typically involve modeling very large domains and/or very complex equations. HPC systems allow running large models, but limits in performance increase that have become more prominent in the last 5-10 years will likely be experienced. Therefore new approaches are needed to increase application performance. Deep learning appears to be a promising way to achieve this. Recently deep learning has been employed to enhance solving problems that traditionally are solved with large-scale numerical simulations using HPC. This type of application, deep learning for high-performance computing, is the theme of this whitepaper. Our goal is to provide concrete guidelines to scientists and others that would like to explore opportunities for applying deep learning approaches in their own large-scale numerical simulations. These guidelines have been extracted from a number of experiments that have been undertaken in various scientific domains over the last two years, and which are described in more detail in the Appendix. Additionally, we share the most important lessons that we have learned.",
        "published": "2020-03-30T13:12:02Z",
        "link": "http://arxiv.org/abs/2004.03454v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "An Interface-enriched Generalized Finite Element Method for   Levelset-based Topology Optimization",
        "authors": [
            "Sanne J. van den Boom",
            "Jian Zhang",
            "Fred van Keulen",
            "Alejandro M. Aragón"
        ],
        "summary": "During design optimization, a smooth description of the geometry is important, especially for problems that are sensitive to the way interfaces are resolved, e.g., wave propagation or fluid-structure interaction. A levelset description of the boundary, when combined with an enriched finite element formulation, offers a smoother description of the design than traditional density-based methods. However, existing enriched methods have drawbacks, including ill-conditioning and difficulties in prescribing essential boundary conditions. In this work we introduce a new enriched topology optimization methodology that overcomes the aforementioned drawbacks; boundaries are resolved accurately by means of the Interface-enriched Generalized Finite Element Method (IGFEM), coupled to a levelset function constructed by radial basis functions. The enriched method used in this new approach to topology optimization has the same level of accuracy in the analysis as standard the finite element method with matching meshes, but without the need for remeshing. We derive the analytical sensitivities and we discuss the behavior of the optimization process in detail. We establish that IGFEM-based levelset topology optimization generates correct topologies for well-known compliance minimization problems.",
        "published": "2020-03-30T19:01:14Z",
        "link": "http://arxiv.org/abs/2003.13751v1",
        "categories": [
            "cs.CE",
            "74P20"
        ]
    },
    {
        "title": "A stochastic reduced-order model for statistical microstructure   descriptors evolution",
        "authors": [
            "Anh Tran",
            "Jing Sun",
            "Dehao Liu",
            "Tim Wildey",
            "Yan Wang"
        ],
        "summary": "Integrated Computational Materials Engineering (ICME) models have been a crucial building block for modern materials development, relieving heavy reliance on experiments and significantly accelerating the materials design process. However, ICME models are also computationally expensive, particularly with respect to time integration for dynamics, which hinders the ability to study statistical ensembles and thermodynamic properties of large systems for long time scales. To alleviate the computational bottleneck, we propose to model the evolution of statistical microstructure descriptors as a continuous-time stochastic process using a non-linear Langevin equation, where the probability density function (PDF) of the statistical microstructure descriptors, which are also the quantities of interests (QoIs), are modeled by the Fokker-Planck equation. We discuss how to calibrate the drift and diffusion terms of the Fokker-Planck equation from the theoretical and computational perspectives. The calibrated Fokker-Planck equation can be used as a stochastic reduced-order model (ROM) to simulate the microstructure evolution of statistical microstructure descriptors PDF. Considering statistical microstructure descriptors in the microstructure evolution as QoIs, we demonstrate our proposed methodology in three integrated computational materials engineering (ICME) models: kinetic Monte Carlo, phase field, and molecular dynamics simulations.",
        "published": "2020-03-30T23:13:35Z",
        "link": "http://arxiv.org/abs/2004.06487v2",
        "categories": [
            "cs.CE",
            "physics.comp-ph"
        ]
    },
    {
        "title": "A Modified SIR Model for the COVID-19 Contagion in Italy",
        "authors": [
            "Giuseppe C. Calafiore",
            "Carlo Novara",
            "Corrado Possieri"
        ],
        "summary": "The purpose of this work is to give a contribution to the understanding of the COVID-19 contagion in Italy. To this end, we developed a modified Susceptible-Infected-Recovered (SIR) model for the contagion, and we used official data of the pandemic up to March 30th, 2020 for identifying the parameters of this model. The non standard part of our approach resides in the fact that we considered as model parameters also the initial number of susceptible individuals, as well as the proportionality factor relating the detected number of positives with the actual (and unknown) number of infected individuals. Identifying the contagion, recovery and death rates as well as the mentioned parameters amounts to a non-convex identification problem that we solved by means of a two-dimensional grid search in the outer loop, with a standard weighted least-squares optimization problem as the inner step.",
        "published": "2020-03-31T17:34:37Z",
        "link": "http://arxiv.org/abs/2003.14391v1",
        "categories": [
            "physics.soc-ph",
            "cs.CE",
            "cs.SI",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Quantifying the Economic Impact of Extreme Shocks on Businesses using   Human Mobility Data: a Bayesian Causal Inference Approach",
        "authors": [
            "Takahiro Yabe",
            "Yunchang Zhang",
            "Satish Ukkusuri"
        ],
        "summary": "In recent years, extreme shocks, such as natural disasters, are increasing in both frequency and intensity, causing significant economic loss to many cities around the world. Quantifying the economic cost of local businesses after extreme shocks is important for post-disaster assessment and pre-disaster planning. Conventionally, surveys have been the primary source of data used to quantify damages inflicted on businesses by disasters. However, surveys often suffer from high cost and long time for implementation, spatio-temporal sparsity in observations, and limitations in scalability. Recently, large scale human mobility data (e.g. mobile phone GPS) have been used to observe and analyze human mobility patterns in an unprecedented spatio-temporal granularity and scale. In this work, we use location data collected from mobile phones to estimate and analyze the causal impact of hurricanes on business performance. To quantify the causal impact of the disaster, we use a Bayesian structural time series model to predict the counterfactual performances of affected businesses (what if the disaster did not occur?), which may use performances of other businesses outside the disaster areas as covariates. The method is tested to quantify the resilience of 635 businesses across 9 categories in Puerto Rico after Hurricane Maria. Furthermore, hierarchical Bayesian models are used to reveal the effect of business characteristics such as location and category on the long-term resilience of businesses. The study presents a novel and more efficient method to quantify business resilience, which could assist policy makers in disaster preparation and relief processes.",
        "published": "2020-04-01T01:44:56Z",
        "link": "http://arxiv.org/abs/2004.11121v1",
        "categories": [
            "q-fin.GN",
            "cs.CE",
            "cs.SI"
        ]
    },
    {
        "title": "Swarm robotics and complex behaviour of continuum material",
        "authors": [
            "R. dell'Erba"
        ],
        "summary": "In swarm robotics, just as for an animal swarm in Nature, one of the aims is to reach and maintain a desired configuration. One of the possibilities for the team, to reach this aim, is to see what its neighbours are doing. This approach generates a rules system governing the movement of the single robot just by reference to neighbour's motion. The same approach is used in position based dynamics to simulate behaviour of complex continuum materials under deformation. Therefore, in some previous works, we have considered a two-dimensional lattice of particles and calculated its time evolution by using a rules system derived from our experience in swarm robotics. The new position of a particle, like the element of a swarm, is determined by the spatial position of the other particles. No dynamic is considered, but it can be thought as being hidden in the behaviour rules. This method has given good results in some simple situations reproducing the behaviour of deformable bodies under imposed strain. In this paper we try to stress our model to highlight its limits and how they can be improved. Some other, more complex, examples are computed and discussed. Shear test, different lattice, different fracture mechanism and ASTM shape sample behaviour have been investigated by the software tool we have developed.",
        "published": "2020-04-01T08:36:34Z",
        "link": "http://arxiv.org/abs/2004.02975v1",
        "categories": [
            "cs.CE",
            "cs.RO"
        ]
    },
    {
        "title": "VoxCap: FFT-Accelerated and Tucker-Enhanced Capacitance Extraction   Simulator for Voxelized Structures",
        "authors": [
            "Mingyu Wang",
            "Cheng Qian",
            "Jacob K. White",
            "Abdulkadir C. Yucel"
        ],
        "summary": "VoxCap, a fast Fourier transform (FFT)-accelerated and Tucker-enhanced integral equation simulator for capacitance extraction of voxelized structures, is proposed. The VoxCap solves the surface integral equations (SIEs) for conductor and dielectric surfaces with three key attributes that make the VoxCap highly CPU and memory efficient for the capacitance extraction of the voxelized structures: (i) VoxCap exploits the FFTs for accelerating the matrix-vector multiplications during the iterative solution of linear system of equations arising due to the discretization of SIEs. (ii) During the iterative solution, VoxCap uses a highly effective and memory-efficient preconditioner that reduces the number of iterations significantly. (iii) VoxCap employs Tucker decompositions to compress the block Toeplitz and circulant tensors, requiring the largest memory in the simulator. By doing so, it reduces the memory requirement of these tensors from hundreds of gigabytes to a few megabytes and the CPU time required to obtain Toeplitz tensors from tens of minutes (even hours) to a few seconds for very large scale problems. VoxCap is capable of accurately computing capacitance of arbitrarily shaped and large-scale voxelized structures on a desktop computer.",
        "published": "2020-04-02T05:57:34Z",
        "link": "http://arxiv.org/abs/2004.02609v2",
        "categories": [
            "cs.CE",
            "eess.SP"
        ]
    },
    {
        "title": "Towards a Parallel-in-Time Calculation of Time-Periodic Solutions with   Unknown Period",
        "authors": [
            "Iryna Kulchytska-Ruchka",
            "Sebastian Schöps"
        ],
        "summary": "This paper presents a novel parallel-in-time algorithm able to compute time-periodic solutions of problems where the period is not given. Exploiting the idea of the multiple shooting method, the proposed approach calculates the initial values at each subinterval as well as the corresponding period iteratively. As in the Parareal method, parallelization in the time domain is performed using discretization on a two-level grid. A special linearization of the time-periodic system on the coarse grid is introduced to speed up the computations. The iterative algorithm is verified via its application to the Colpitt oscillator model.",
        "published": "2020-04-03T15:00:28Z",
        "link": "http://arxiv.org/abs/2004.01612v2",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Scalable In Situ Lagrangian Flow Map Extraction: Demonstrating the   Viability of a Communication-Free Model",
        "authors": [
            "Sudhanshu Sane",
            "Abhishek Yenpure",
            "Roxana Bujack",
            "Matthew Larsen",
            "Kenneth Moreland",
            "Christoph Garth",
            "Hank Childs"
        ],
        "summary": "We introduce and evaluate a new algorithm for the in situ extraction of Lagrangian flow maps, which we call Boundary Termination Optimization (BTO). Our approach is a communication-free model, requiring no message passing or synchronization between processes, improving scalability, thereby reducing overall execution time and alleviating the encumbrance placed on simulation codes from in situ processing. We terminate particle integration at node boundaries and store only a subset of the flow map that would have been extracted by communicating particles across nodes, thus introducing an accuracy-performance tradeoff. We run experiments with as many as 2048 GPUs and with multiple simulation data sets. For the experiment configurations we consider, our findings demonstrate that our communication-free technique saves as much as 2x to 4x in execution time in situ, while staying nearly as accurate quantitatively and qualitatively as previous work. Most significantly, this study establishes the viability of approaching in situ Lagrangian flow map extraction using communication-free models in the future.",
        "published": "2020-04-04T19:21:28Z",
        "link": "http://arxiv.org/abs/2004.02003v1",
        "categories": [
            "cs.CE",
            "cs.DC",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Using Machine Learning Approach for Computational Substructure in   Real-Time Hybrid Simulation",
        "authors": [
            "Elif Ecem Bas",
            "Mohamed A. Moustafa",
            "David Feil-Seifer",
            "Janelle Blankenburg"
        ],
        "summary": "Hybrid simulation (HS) is a widely used structural testing method that combines a computational substructure with a numerical model for well-understood components and an experimental substructure for other parts of the structure that are physically tested. One challenge for fast HS or real-time HS (RTHS) is associated with the analytical substructures of relatively complex structures, which could have large number of degrees of freedoms (DOFs), for instance. These large DOFs computations could be hard to perform in real-time, even with the all current hardware capacities. In this study, a metamodeling technique is proposed to represent the structural dynamic behavior of the analytical substructure. A preliminary study is conducted where a one-bay one-story concentrically braced frame (CBF) is tested under earthquake loading by using a compact HS setup at the University of Nevada, Reno. The experimental setup allows for using a small-scale brace as the experimental substructure combined with a steel frame at the prototype full-scale for the analytical substructure. Two different machine learning algorithms are evaluated to provide a valid and useful metamodeling solution for analytical substructure. The metamodels are trained with the available data that is obtained from the pure analytical solution of the prototype steel frame. The two algorithms used for developing the metamodels are: (1) linear regression (LR) model, and (2) basic recurrent neural network (RNN). The metamodels are first validated against the pure analytical response of the structure. Next, RTHS experiments are conducted by using metamodels. RTHS test results using both LR and RNN models are evaluated, and the advantages and disadvantages of these models are discussed.",
        "published": "2020-04-04T22:22:40Z",
        "link": "http://arxiv.org/abs/2004.02037v1",
        "categories": [
            "cs.LG",
            "cs.CE",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Model-free Data-Driven Computational Mechanics Enhanced by Tensor Voting",
        "authors": [
            "Robert Eggersmann",
            "Laurent Stainier",
            "Michael Ortiz",
            "Stefanie Reese"
        ],
        "summary": "The data-driven computing paradigm initially introduced by Kirchdoerfer & Ortiz (2016) is extended by incorporating locally linear tangent spaces into the data set. These tangent spaces are constructed by means of the tensor voting method introduced by Mordohai & Medioni (2010) which improves the learning of the underlying structure of a data set. Tensor voting is an instance-based machine learning technique which accumulates votes from the nearest neighbors to build up second-order tensors encoding tangents and normals to the underlying data structure. The here proposed second-order data-driven paradigm is a plug-in method for distance-minimizing as well as entropy-maximizing data-driven schemes. Like its predecessor, the resulting method aims to minimize a suitably defined free energy over phase space subject to compatibility and equilibrium constraints. The method's implementation is straightforward and numerically efficient since the data structure analysis is performed in an offline step. Selected numerical examples are presented that establish the higher-order convergence properties of the data-driven solvers enhanced by tensor voting for ideal and noisy data sets.",
        "published": "2020-04-06T09:18:24Z",
        "link": "http://arxiv.org/abs/2004.02503v2",
        "categories": [
            "cs.CE",
            "J.2"
        ]
    },
    {
        "title": "Fail-safe optimization of viscous dampers for seismic retrofitting",
        "authors": [
            "Nicolò Pollini"
        ],
        "summary": "This paper presents a new optimization approach for designing minimum-cost fail-safe distributions of fluid viscous dampers for seismic retrofitting. Failure is modeled as either complete damage of the dampers or partial degradation of the dampers' properties. In general, this leads to optimization problems with large number of constraints. Thus, the use of a working-set optimization algorithm is proposed. The main idea is to solve a sequence of relaxed optimization sub-problems with a small sub-set of all constraints. The algorithm terminates once a solution of a sub-problem is found that satisfies all the constraints of the problem. The retrofitting cost is minimized with constraints on the inter-story drifts at the peripheries of frame structures. The structures considered are subjected to a realistic ensemble of ground motions, and their response is evaluated with time-history analyses. The transient optimization problem is efficiently solved with a gradient-based sequential linear programming algorithm. The gradients of the response functions are calculated with a consistent adjoint sensitivity analysis procedure. Promising results attained for 3-D irregular frames are presented and discussed. The numerical results highlight the fact that the optimized layout and size of the dampers can change significantly even for moderate levels of damage.",
        "published": "2020-04-07T14:46:04Z",
        "link": "http://arxiv.org/abs/2004.03442v1",
        "categories": [
            "cs.CE",
            "math.OC"
        ]
    },
    {
        "title": "A stochastic user-operator assignment game for microtransit service   evaluation: A case study of Kussbus in Luxembourg",
        "authors": [
            "Tai-Yu Ma",
            "Joseph Y. J. Chow",
            "Sylvain Klein",
            "Ziyi Ma"
        ],
        "summary": "This paper proposes a stochastic variant of the stable matching model from Rasulkhani and Chow [1] which allows microtransit operators to evaluate their operation policy and resource allocations. The proposed model takes into account the stochastic nature of users' travel utility perception, resulting in a probabilistic stable operation cost allocation outcome to design ticket price and ridership forecasting. We applied the model for the operation policy evaluation of a microtransit service in Luxembourg and its border area. The methodology for the model parameters estimation and calibration is developed. The results provide useful insights for the operator and the government to improve the ridership of the service.",
        "published": "2020-04-08T06:57:35Z",
        "link": "http://arxiv.org/abs/2005.03465v1",
        "categories": [
            "physics.soc-ph",
            "cs.CE",
            "stat.AP"
        ]
    },
    {
        "title": "The ICSCREAM methodology: Identification of penalizing configurations in   computer experiments using screening and metamodel -- Applications in   thermal-hydraulics",
        "authors": [
            "A. Marrel",
            "Bertrand Iooss",
            "V Chabridon"
        ],
        "summary": "In the framework of risk assessment in nuclear accident analysis, best-estimatecomputer codes, associated to a probabilistic modeling of the uncertain input variables,are used to estimate safety margins. A first step in such uncertainty quantificationstudies is often to identify the critical configurations (or penalizing, in thesense of a prescribed safety margin) of several input parameters (called ``scenarioinputs''), under the uncertainty on the other input parameters. However, the largeCPU-time cost of most of the computer codes used in nuclear engineering, as theones related to thermal-hydraulic accident scenario simulations, involve to develophighly efficient strategies. This work focuses on machine learning algorithms bythe way of the metamodel-based approach (i.e., a mathematical model which is fittedon a small-size sample of simulations). To achieve it with a very large numberof inputs, a specific and original methodology, called ICSCREAM (Identificationof penalizing Configurations using SCREening And Metamodel), is proposed. Thescreening of influential inputs is based on an advanced global sensitivity analysistool (HSIC importance measures). A Gaussian process metamodel is then sequentiallybuilt and used to estimate, within a Bayesian framework, the conditionalprobabilities of exceeding a high-level threshold, according to the scenario inputs.The efficiency of this methodology is illustrated on two high-dimensional (arounda hundred inputs) thermal-hydraulic industrial cases simulating an accident of primarycoolant loss in a pressurized water reactor. For both use cases, the studyfocuses on the peak cladding temperature (PCT) and critical configurations aredefined by exceeding the 90%-quantile of PCT. In both cases, the ICSCREAMmethodology allows to estimate, by using only around one thousand of code simulations,the impact of the scenario inputs and their critical areas of values.",
        "published": "2020-04-08T07:01:34Z",
        "link": "http://arxiv.org/abs/2004.04663v3",
        "categories": [
            "cs.CE",
            "math.ST",
            "stat.TH"
        ]
    },
    {
        "title": "A random observation-based management model of population dynamics and   its ecological application",
        "authors": [
            "Hidekazu Yoshioka",
            "Yuta Yaegashi",
            "Motoh Tsujimura"
        ],
        "summary": "A new stochastic control problem of population dynamics under partial observation is formulated and analyzed both mathematically and numerically, with an emphasis on environmental and ecological problems. The decision-maker can only randomly and time-discretely observe and impulsively intervene the population dynamics governed by a regime-switching stochastic differential equation. The hybrid nature of the problem leads to an optimality equation containing an integro-differential equation and a static optimization problem. It is therefore different from the conventional Hamilton-Jacobi-Bellman equations. Existence and solvability issues of this optimality equation are analyzed in a viscosity sense. Its exact solution to a reduced but still nontrivial model is derived as well. The model is finally applied to a realistic environmental management problem in a river using a finite difference scheme.",
        "published": "2020-04-09T23:05:28Z",
        "link": "http://arxiv.org/abs/2004.04844v1",
        "categories": [
            "math.OC",
            "cs.CE",
            "math.PR"
        ]
    },
    {
        "title": "Automated and Accurate Geometry Extraction and Shape Optimization of 3D   Topology Optimization Results",
        "authors": [
            "Marco K. Swierstra",
            "Deepak K. Gupta",
            "Matthijs Langelaar"
        ],
        "summary": "Designs generated by density-based topology optimization (TO) exhibit jagged and/or smeared boundaries, which forms an obstacle to their integration with existing CAD tools. Addressing this problem by smoothing or manual design adjustments is time-consuming and affects the optimality of TO designs. This paper proposes a fully automated procedure to obtain unambiguous, accurate and optimized geometries from arbitrary 3D TO results. It consists of a geometry extraction stage using a level-set-based design description involving radial basis functions, followed by a shape optimization stage involving local analysis refinements near the structural boundary using the Finite Cell Method. Well-defined bounds on basis function weights ensure that sufficient sensitivity information is available throughout the shape optimization process. Our approach results in highly smooth and accurate optimized geometries, and its effectiveness is illustrated by 2D and 3D examples.",
        "published": "2020-04-11T17:29:28Z",
        "link": "http://arxiv.org/abs/2004.05448v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Deep learning-based topological optimization for representing a   user-specified design area",
        "authors": [
            "Keigo Nakamura",
            "Yoshiro Suzuki"
        ],
        "summary": "Presently, topology optimization requires multiple iterations to create an optimized structure for given conditions. Among the conditions for topology optimization,the design area is one of the most important for structural design. In this study, we propose a new deep learning model to generate an optimized structure for a given design domain and other boundary conditions without iteration. For this purpose, we used open-source topology optimization MATLAB code to generate a pair of optimized structures under various design conditions. The resolution of the optimized structure is 32 * 32 pixels, and the design conditions are design area, volume fraction, distribution of external forces, and load value. Our deep learning model is primarily composed of a convolutional neural network (CNN)-based encoder and decoder, trained with datasets generated with MATLAB code. In the encoder, we use batch normalization (BN) to increase the stability of the CNN model. In the decoder, we use SPADE (spatially adaptive denormalization) to reinforce the design area information. Comparing the performance of our proposed model with a CNN model that does not use BN and SPADE, values for mean absolute error (MAE), mean compliance error, and volume error with the optimized topology structure generated in MAT-LAB code were smaller, and the proposed model was able to represent the design area more precisely. The proposed method generates near-optimal structures reflecting the design area in less computational time, compared with the open-source topology optimization MATLAB code.",
        "published": "2020-04-11T18:54:07Z",
        "link": "http://arxiv.org/abs/2004.05461v2",
        "categories": [
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "Probabilistic Evolution of Stochastic Dynamical Systems: A Meso-scale   Perspective",
        "authors": [
            "Chao Yin",
            "Xihaier Luo",
            "Ahsan Kareem"
        ],
        "summary": "Stochastic dynamical systems arise naturally across nearly all areas of science and engineering. Typically, a dynamical system model is based on some prior knowledge about the underlying dynamics of interest in which probabilistic features are used to quantify and propagate uncertainties associated with the initial conditions, external excitations, etc. From a probabilistic modeling standing point, two broad classes of methods exist, i.e. macro-scale methods and micro-scale methods. Classically, macro-scale methods such as statistical moments-based strategies are usually too coarse to capture the multi-mode shape or tails of a non-Gaussian distribution. Micro-scale methods such as random samples-based approaches, on the other hand, become computationally very challenging in dealing with high-dimensional stochastic systems. In view of these potential limitations, a meso-scale scheme is proposed here that utilizes a meso-scale statistical structure to describe the dynamical evolution from a probabilistic perspective. The significance of this statistical structure is two-fold. First, it can be tailored to any arbitrary random space. Second, it not only maintains the probability evolution around sample trajectories but also requires fewer meso-scale components than the micro-scale samples. To demonstrate the efficacy of the proposed meso-scale scheme, a set of examples of increasing complexity are provided. Connections to the benchmark stochastic models as conservative and Markov models along with practical implementation guidelines are presented.",
        "published": "2020-04-11T19:17:22Z",
        "link": "http://arxiv.org/abs/2004.06803v1",
        "categories": [
            "cs.CE",
            "physics.data-an"
        ]
    },
    {
        "title": "Embedded model discrepancy: A case study of Zika modeling",
        "authors": [
            "Rebecca E. Morrison",
            "Americo Cunha Jr"
        ],
        "summary": "Mathematical models of epidemiological systems enable investigation of and predictions about potential disease outbreaks. However, commonly used models are often highly simplified representations of incredibly complex systems. Because of these simplifications, the model output, of say new cases of a disease over time, or when an epidemic will occur, may be inconsistent with available data. In this case, we must improve the model, especially if we plan to make decisions based on it that could affect human health and safety, but direct improvements are often beyond our reach. In this work, we explore this problem through a case study of the Zika outbreak in Brazil in 2016. We propose an embedded discrepancy operator---a modification to the model equations that requires modest information about the system and is calibrated by all relevant data. We show that the new enriched model demonstrates greatly increased consistency with real data. Moreover, the method is general enough to easily apply to many other mathematical models in epidemiology.",
        "published": "2020-04-13T22:12:10Z",
        "link": "http://arxiv.org/abs/2004.06220v1",
        "categories": [
            "q-bio.PE",
            "cs.CE"
        ]
    },
    {
        "title": "Modular-topology optimization with Wang tilings: An application to truss   structures",
        "authors": [
            "Marek Tyburec",
            "Jan Zeman",
            "Martin Doškář",
            "Martin Kružík",
            "Matěj Lepš"
        ],
        "summary": "Modularity is appealing for solving many problems in optimization. It brings the benefits of manufacturability and reconfigurability to structural optimization, and enables a trade-off between the computational performance of a Periodic Unit Cell (PUC) and the efficacy of non-uniform designs in multi-scale material optimization. Here, we introduce a novel strategy for concurrent minimum-compliance design of truss modules topologies and their macroscopic assembly encoded using Wang tiling, a formalism providing independent control over the number of modules and their interfaces. We tackle the emerging bilevel optimization problem with a combination of meta-heuristics and mathematical programming. At the upper level, we employ a genetic algorithm to optimize module assemblies. For each assembly, we obtain optimal module topologies as a solution to a convex second-order conic program that exploits the underlying modularity, incorporating stress constraints, multiple load cases, and reuse of module(s) for various structures. Merits of the proposed strategy are illustrated with three representative examples, clearly demonstrating that the best designs obtained by our method exhibited decreased compliance: from 56% to 69% compared to the PUC designs.",
        "published": "2020-04-15T11:06:37Z",
        "link": "http://arxiv.org/abs/2004.07002v1",
        "categories": [
            "cs.CE",
            "math.OC"
        ]
    },
    {
        "title": "The magnetic field from a homogeneously magnetized cylindrical tile",
        "authors": [
            "K. K. Nielsen",
            "R. Bjørk"
        ],
        "summary": "The magnetic field of a homogeneously magnetized cylindrical tile geometry, i.e. an angular section of a finite hollow cylinder, is found. The field is expressed as the product between a tensor field describing the geometrical part of the problem and a column vector holding the magnetization of the tile. Outside the tile, the tensor is identical to the demagnetization tensor. We find that four components of the tensor, $N_{xy},N_{xz},N_{yz}$ and $N_{zy}$, can be expressed fully analytically, while the five remaining components, $N_{xx},N_{yx},N_{yy},N_{zx}$ and $N_{zz}$, contain integrals that have to be evaluated numerically. When evaluated numerically the tensor is symmetric. A comparison between the found solution, implemented in the open source magnetic framework MagTense, and a finite element calculation of the magnetic flux density of a cylindrical tile shows excellent agreement.",
        "published": "2020-04-15T17:31:10Z",
        "link": "http://arxiv.org/abs/2004.11701v1",
        "categories": [
            "cs.CE",
            "physics.ins-det"
        ]
    },
    {
        "title": "The stray- and demagnetizing field from a homogeneously magnetized   tetrahedron",
        "authors": [
            "Kaspar K. Nielsen",
            "Andrea R. Insinga",
            "Rasmus Bjørk"
        ],
        "summary": "The stray- and demagnetization tensor field for a homogeneously magnetized tetrahedron is found analytically. The tetrahedron is a special case of four triangular faces with constant magnetization-charge surface density, for which we also determine the tensor field. The tensor field is implemented in the open source micromagnetic and magnetostatic simulation framework MagTense and compared with the obtained magnetic field from an FEM solution, showing excellent agreement. This result is important for modeling magnetostatics in general and for micromagnetism in particular as the demagnetizing field of an arbitrary body discretized using conventional meshing techniques is significantly simplified with this approach.",
        "published": "2020-04-15T17:34:11Z",
        "link": "http://arxiv.org/abs/2004.11700v1",
        "categories": [
            "cs.CE",
            "physics.ins-det"
        ]
    },
    {
        "title": "Extended source imaging, a unifying framework for seismic & medical   imaging",
        "authors": [
            "Ziyi Yin",
            "Rafael Orozco",
            "Philipp Witte",
            "Mathias Louboutin",
            "Gabrio Rizzuti",
            "Felix J. Herrmann"
        ],
        "summary": "We present three imaging modalities that live on the crossroads of seismic and medical imaging. Through the lens of extended source imaging, we can draw deep connections among the fields of wave-equation based seismic and medical imaging, despite first appearances. From the seismic perspective, we underline the importance to work with the correct physics and spatially varying velocity fields. Medical imaging, on the other hand, opens the possibility for new imaging modalities where outside stimuli, such as laser or radar pulses, can not only be used to identify endogenous optical or thermal contrasts but that these sources can also be used to insonify the medium so that images of the whole specimen can in principle be created.",
        "published": "2020-04-15T23:16:29Z",
        "link": "http://arxiv.org/abs/2004.07389v1",
        "categories": [
            "physics.geo-ph",
            "cs.CE",
            "eess.IV"
        ]
    },
    {
        "title": "Fast exact computation of the $k$ most abundant isotope peaks with   layer-ordered heaps",
        "authors": [
            "Patrick Kreitzberg",
            "Jake Pennington",
            "Kyle Lucke",
            "Oliver Serang"
        ],
        "summary": "The theoretical computation of isotopic distribution of compounds is crucial in many important applications of mass spectrometry, especially as machine precision grows. A considerable amount of good tools have been created in the last decade for doing so. In this paper we present a novel algorithm for calculating the top $k$ peaks of a given compound. The algorithm takes advantage of layer-ordered heaps used in an optimal method of selection on $X+Y$ and is able to efficiently calculate the top $k$ peaks on very large molecules. Among its peers, this algorithm shows a significant speedup on molecules whose elements have many isotopes. The algorithm obtains a speedup of more than 31x when compared to $\\textsc{IsoSpec}$ on \\ch{Au2Ca10Ga10Pd76} when computing 47409787 peaks, which covers 0.999 of the total abundance.",
        "published": "2020-04-16T03:55:30Z",
        "link": "http://arxiv.org/abs/2004.07444v1",
        "categories": [
            "cs.CE",
            "cs.DS"
        ]
    },
    {
        "title": "Structural Model Updating Using Adaptive Multi-Response Gaussian Process   Meta-modeling",
        "authors": [
            "Kai Zhou",
            "Jiong Tang"
        ],
        "summary": "Finite element model updating utilizing frequency response functions as inputs is an important procedure in structural analysis, design and control. This paper presents a highly efficient framework that is built upon Gaussian process emulation to inversely identify model parameters through sampling. In particular, a multi-response Gaussian process (MRGP) meta-modeling approach is formulated that can accurately construct the error response surface, i.e., the discrepancies between the frequency response predictions and actual measurement. In order to reduce the computational cost of repeated finite element simulations, an adaptive sampling strategy is established, where the search of unknown parameters is guided by the response surface features. Meanwhile, the information of previously sampled model parameters and the corresponding errors is utilized as additional training data to refine the MRGP meta-model. Two stochastic optimization techniques, i.e., particle swarm and simulated annealing, are employed to train the MRGP meta-model for comparison. Systematic case studies are conducted to examine the accuracy and robustness of the new framework of model updating.",
        "published": "2020-04-16T13:26:33Z",
        "link": "http://arxiv.org/abs/2004.11698v1",
        "categories": [
            "cs.CE",
            "eess.SP",
            "stat.CO",
            "stat.ME"
        ]
    },
    {
        "title": "Identifying Weakly Connected Subsystems in Building Energy Model for   Effective Load Estimation in Presence of Parametric Uncertainty",
        "authors": [
            "Arpan Mukherjee",
            "Anna Kuechle Szweda",
            "Andrew Alegria",
            "Rahul Rai",
            "Tarunraj Singh"
        ],
        "summary": "It is necessary to estimate the expected energy usage of a building to determine how to reduce energy usage. The expected energy usage of a building can be reliably simulated using a Building Energy Model (BEM). Many of the numerous input parameters in a BEM are uncertain. To ensure that the building simulation is sufficiently accurate, and to better understand the impact of imprecisions in the input parameters and calculation methods, it is desirable to quantify uncertainty in the BEM throughout the modeling process. Uncertainty quantification (UQ) typically requires a large number of simulations to produce meaningful data, which, due to the vast number of input parameters and the dynamic nature of building simulation, is computationally expensive. Uncertainty Quantification (UQ) in BEM domain is thus intractable due to the size of the problem and parameters involved and hence it needs an advanced methodology for analysis. The current paper outlines a novel Weakly-Connected-Systems (WCSs) identification-based UQ framework developed to propagate the quantifiable uncertainty in the BEM. The overall approach is demonstrated on the physics-based thermal model of an actual building in Central New York.",
        "published": "2020-04-17T18:16:36Z",
        "link": "http://arxiv.org/abs/2004.08417v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Application of Progressive Hedging to Var Expansion Planning Under   Uncertainty",
        "authors": [
            "Igor Carvalho",
            "Tiago Andrade",
            "Joaquim Dias Garcia",
            "Maria de Lujan Latorre"
        ],
        "summary": "This paper describes the application of a Progressive Hedging (PH) algorithm to the least-cost var planning under uncertainty. The method PH is a scenario-based decomposition technique for solving stochastic programs, i.e., it decomposes a large scale stochastic problem into s deterministic subproblems and couples the decision from the s subproblems to form a solution for the original stochastic problem. The effectiveness and computational performance of the proposed methodology will be illustrated with var planning studies for the IEEE 24-bus system (5 operating scenarios), the 200-bus Bolivian system (1,152 operating scenarios) and the 1,600-bus Colombian system (180 scenarios).",
        "published": "2020-04-17T21:54:36Z",
        "link": "http://arxiv.org/abs/2004.08466v1",
        "categories": [
            "math.OC",
            "cs.CE",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Deep Learning for One-dimensional Consolidation",
        "authors": [
            "Yared W. Bekele"
        ],
        "summary": "Neural networks with physical governing equations as constraints have recently created a new trend in machine learning research. In line with such efforts, a deep learning model for one-dimensional consolidation where the governing equation is applied as a constraint in the neural network is presented here. A review of related research is first presented and discussed. The deep learning model relies on automatic differentiation for applying the governing equation as a constraint. The total loss is measured as a combination of the training loss (based on analytical and model predicted solutions) and the constraint loss (a requirement to satisfy the governing equation). Two classes of problems are considered: forward and inverse problems. The forward problems demonstrate the performance of a physically constrained neural network model in predicting solutions for one-dimensional consolidation problems. Inverse problems show prediction of the coefficient of consolidation. Terzaghi's problem with varying boundary conditions are used as example and the deep learning model shows a remarkable performance in both the forward and inverse problems. While the application demonstrated here is a simple one-dimensional consolidation problem, such a deep learning model integrated with a physical law has huge implications for use in, such as, faster real-time numerical prediction for digital twins, numerical model reproducibility and constitutive model parameter optimization.",
        "published": "2020-04-20T06:58:15Z",
        "link": "http://arxiv.org/abs/2004.11689v1",
        "categories": [
            "cs.CE",
            "eess.IV"
        ]
    },
    {
        "title": "Robust 3D reconstruction of dynamic scenes from single-photon lidar   using Beta-divergences",
        "authors": [
            "Quentin Legros",
            "Julian Tachella",
            "Rachael Tobin",
            "Aongus McCarthy",
            "Sylvain Meignen",
            "Gerald S. Buller",
            "Yoann Altmann",
            "Stephen McLaughlin",
            "Michael E. Davies"
        ],
        "summary": "In this paper, we present a new algorithm for fast, online 3D reconstruction of dynamic scenes using times of arrival of photons recorded by single-photon detector arrays. One of the main challenges in 3D imaging using single-photon lidar in practical applications is the presence of strong ambient illumination which corrupts the data and can jeopardize the detection of peaks/surface in the signals. This background noise not only complicates the observation model classically used for 3D reconstruction but also the estimation procedure which requires iterative methods. In this work, we consider a new similarity measure for robust depth estimation, which allows us to use a simple observation model and a non-iterative estimation procedure while being robust to mis-specification of the background illumination model. This choice leads to a computationally attractive depth estimation procedure without significant degradation of the reconstruction performance. This new depth estimation procedure is coupled with a spatio-temporal model to capture the natural correlation between neighboring pixels and successive frames for dynamic scene analysis. The resulting online inference process is scalable and well suited for parallel implementation. The benefits of the proposed method are demonstrated through a series of experiments conducted with simulated and real single-photon lidar videos, allowing the analysis of dynamic scenes at 325 m observed under extreme ambient illumination conditions.",
        "published": "2020-04-20T11:24:31Z",
        "link": "http://arxiv.org/abs/2004.09211v3",
        "categories": [
            "eess.IV",
            "cs.CE"
        ]
    },
    {
        "title": "PowerModelsDistribution.jl: An Open-Source Framework for Exploring   Distribution Power Flow Formulations",
        "authors": [
            "David M Fobes",
            "Sander Claeys",
            "Frederik Geth",
            "Carleton Coffrin"
        ],
        "summary": "In this work we introduce PowerModelsDistribution, a free, open-source toolkit for distribution power network optimization, whose primary focus is establishing a baseline implementation of steady-state multi-conductor unbalanced distribution network optimization problems, which includes implementations of Power Flow and Optimal Power Flow problem types. Currently implemented power flow formulations for these problem types include AC (polar and rectangular), a second-order conic relaxation of the Branch Flow Model (BFM) and Bus Injection Model (BIM), a semi-definite relaxation of BFM, and several linear approximations, such as the simplified unbalanced BFM. The results of AC power flow have been validated against OpenDSS, an open-source \"electric power distribution system simulator\", using IEEE distribution test feeders (13, 34, 123 bus and LVTestCase), all parsed using a built-in OpenDSS parser. This includes support for standard distribution system components as well as novel resource models such as generic energy storage (multi-period) and photovoltaic systems, with the intention to add support for additional components in the future.",
        "published": "2020-04-20T13:35:38Z",
        "link": "http://arxiv.org/abs/2004.10081v1",
        "categories": [
            "cs.CE",
            "cs.SY",
            "eess.SP",
            "eess.SY"
        ]
    },
    {
        "title": "Global Sensitivity Methods for Design of Experiments in Lithium-ion   Battery Context",
        "authors": [
            "Andrea Pozzi",
            "Xiangzhong Xie",
            "Davide M Raimondo",
            "René Schenkendorf"
        ],
        "summary": "Battery management systems may rely on mathematical models to provide higher performance than standard charging protocols. Electrochemical models allow us to capture the phenomena occurring inside a lithium-ion cell and therefore, could be the best model choice. However, to be of practical value, they require reliable model parameters. Uncertainty quantification and optimal experimental design concepts are essential tools for identifying systems and estimating parameters precisely. Approximation errors in uncertainty quantification result in sub-optimal experimental designs and consequently, less-informative data, and higher parameter unreliability. In this work, we propose a highly efficient design of experiment method based on global parameter sensitivities. This novel concept is applied to the single-particle model with electrolyte and thermal dynamics (SPMeT), a well-known electrochemical model for lithium-ion cells. The proposed method avoids the simplifying assumption of output-parameter linearization (i.e., local parameter sensitivities) used in conventional Fisher information matrix-based experimental design strategies. Thus, the optimized current input profile results in experimental data of higher information content and in turn, in more precise parameter estimates.",
        "published": "2020-04-20T23:05:43Z",
        "link": "http://arxiv.org/abs/2004.09668v2",
        "categories": [
            "cs.CE",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Structural clustering of volatility regimes for dynamic trading   strategies",
        "authors": [
            "Arjun Prakash",
            "Nick James",
            "Max Menzies",
            "Gilad Francis"
        ],
        "summary": "We develop a new method to find the number of volatility regimes in a nonstationary financial time series by applying unsupervised learning to its volatility structure. We use change point detection to partition a time series into locally stationary segments and then compute a distance matrix between segment distributions. The segments are clustered into a learned number of discrete volatility regimes via an optimization routine. Using this framework, we determine a volatility clustering structure for financial indices, large-cap equities, exchange-traded funds and currency pairs. Our method overcomes the rigid assumptions necessary to implement many parametric regime-switching models, while effectively distilling a time series into several characteristic behaviours. Our results provide significant simplification of these time series and a strong descriptive analysis of prior behaviours of volatility. Finally, we create and validate a dynamic trading strategy that learns the optimal match between the current distribution of a time series and its past regimes, thereby making online risk-avoidance decisions in the present.",
        "published": "2020-04-21T12:54:23Z",
        "link": "http://arxiv.org/abs/2004.09963v3",
        "categories": [
            "q-fin.ST",
            "cs.CE",
            "cs.LG",
            "q-fin.RM"
        ]
    },
    {
        "title": "Examining Lead-Lag Relationships In-Depth, With Focus On FX Market As   Covid-19 Crises Unfolds",
        "authors": [
            "Kartikay Gupta",
            "Niladri Chatterjee"
        ],
        "summary": "The lead-lag relationship plays a vital role in financial markets. It is the phenomenon where a certain price-series lags behind and partially replicates the movement of leading time-series. The present research proposes a new technique which helps better identify the lead-lag relationship empirically. Apart from better identifying the lead-lag path, the technique also gives a measure for adjudging closeness between financial time-series. Also, the proposed measure is closely related to correlation, and it uses Dynamic Programming technique for finding the optimal lead-lag path. Further, it retains most of the properties of a metric, so much so, it is termed as loose metric. Tests are performed on Synthetic Time Series (STS) with known lead-lag relationship and comparisons are done with other state-of-the-art models on the basis of significance and forecastability. The proposed technique gives the best results in both the tests. It finds paths which are all statistically significant, and its forecasts are closest to the target values. Then, we use the measure to study the topology evolution of the Foreign Exchange market, as the COVID-19 pandemic unfolds. Here, we study the FX currency prices of 29 prominent countries of the world. It is observed that as the crises unfold, all the currencies become strongly interlinked to each other. Also, USA Dollar starts playing even more central role in the FX market. Finally, we mention several other application areas of the proposed technique for designing intelligent systems.",
        "published": "2020-04-22T13:24:31Z",
        "link": "http://arxiv.org/abs/2004.10560v2",
        "categories": [
            "q-fin.ST",
            "cs.CE",
            "91G30, 68T10,",
            "G.3.3"
        ]
    },
    {
        "title": "The Second-Generation Shifted Boundary Method and Its Numerical Analysis",
        "authors": [
            "Nabil M. Atallah",
            "Claudio Canuto",
            "Guglielmo Scovazzi"
        ],
        "summary": "Recently, the Shifted Boundary Method (SBM) was proposed within the class of unfitted (or immersed, or embedded) finite element methods. By reformulating the original boundary value problem over a surrogate (approximate) computational domain, the SBM avoids integration over cut cells and the associated problematic issues regarding numerical stability and matrix conditioning. Accuracy is maintained by modifying the original boundary conditions using Taylor expansions. Hence the name of the method, that {\\it shifts} the location and values of the boundary conditions. In this article, we present enhanced variational SBM formulations for the Poisson and Stokes problems with improved flexibility and robustness. These simplified variational forms allow to relax some of the assumptions required by the mathematical proofs of stability and convergence of earlier implementations. First, we show that these new SBM implementations can be proved asymptotically stable and convergent even without the rather restrictive assumption that the inner product between the normals to the true and surrogate boundaries is positive. Second, we show that it is not necessary to introduce a stabilization term involving the tangential derivatives of the solution at Dirichlet boundaries, therefore avoiding the calibration of an additional stabilization parameter. Finally, we prove enhanced $L^{2}$-estimates without the cumbersome assumption - of earlier proofs - that the surrogate domain is convex. Instead we rely on a conventional assumption that the boundary of the true domain is smooth, which can also be replaced by requiring convexity of the true domain. The aforementioned improvements open the way to a more general and efficient implementation of the Shifted Boundary Method, particularly in complex three-dimensional geometries. We present numerical experiments in two and three dimensions.",
        "published": "2020-04-22T14:03:25Z",
        "link": "http://arxiv.org/abs/2004.10584v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "65N30, 65N12, 65N50"
        ]
    },
    {
        "title": "Modelling of flow through spatially varying porous media with   application to topology optimization",
        "authors": [
            "Rakotobe Michaël",
            "Ramalingom Delphine",
            "Cocquet Pierre-Henri",
            "Bastide Alain"
        ],
        "summary": "The objective of this study is to highlight the effect of porosity variation in a topology optimization process in the field of fluid dynamics. Usually a penalization term added to momentum equation provides to get material distribution. Every time material is added inside the computational domain, there is creation of new fluid-solid interfaces and apparition of gradient of porosity. However, at present, porosity variation is not taken account in topology optimization and the penalization term used to locate the solid is analogous to a Darcy term used for flows in porous media. With that in mind, in this paper, we first develop an original one-domain macroscopic model for the modelling of flow through spatially varying porous media that goes beyond the scope of Darcy regime. Next, we numerically solve a topology optimization problem and compare the results obtained with the standard model that does not include effect of porosity variation with those obtained with our model. Among our results, we show for instance that the designs obtained are different but percentages of reduction of objective functional remain quite close (below 4\\% of difference). In addition, we illustrate effects of porosity and particle diameter values on final optimized designs.",
        "published": "2020-04-22T17:16:32Z",
        "link": "http://arxiv.org/abs/2004.10712v1",
        "categories": [
            "physics.flu-dyn",
            "cs.CE",
            "math.OC"
        ]
    },
    {
        "title": "Bayesian Verification of Chemical Reaction Networks",
        "authors": [
            "Gareth W. Molyneux",
            "Viraj B. Wijesuriya",
            "Alessandro Abate"
        ],
        "summary": "We present a data-driven verification approach that determines whether or not a given chemical reaction network (CRN) satisfies a given property, expressed as a formula in a modal logic. Our approach consists of three phases, integrating formal verification over models with learning from data. First, we consider a parametric set of possible models based on a known stoichiometry and classify them against the property of interest. Secondly, we utilise Bayesian inference to update a probability distribution of the parameters within a parametric model with data gathered from the underlying CRN. In the third and final stage, we combine the results of both steps to compute the probability that the underlying CRN satisfies the given property. We apply the new approach to a case study and compare it to Bayesian statistical model checking.",
        "published": "2020-04-23T17:08:57Z",
        "link": "http://arxiv.org/abs/2004.11321v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "From Physics-Based Models to Predictive Digital Twins via Interpretable   Machine Learning",
        "authors": [
            "Michael G. Kapteyn",
            "Karen E. Willcox"
        ],
        "summary": "This work develops a methodology for creating a data-driven digital twin from a library of physics-based models representing various asset states. The digital twin is updated using interpretable machine learning. Specifically, we use optimal trees---a recently developed scalable machine learning method---to train an interpretable data-driven classifier. Training data for the classifier are generated offline using simulated scenarios solved by the library of physics-based models. These data can be further augmented using experimental or other historical data. In operation, the classifier uses observational data from the asset to infer which physics-based models in the model library are the best candidates for the updated digital twin. The approach is demonstrated through the development of a structural digital twin for a 12ft wingspan unmanned aerial vehicle. This digital twin is built from a library of reduced-order models of the vehicle in a range of structural states. The data-driven digital twin dynamically updates in response to structural damage or degradation and enables the aircraft to replan a safe mission accordingly. Within this context, we study the performance of the optimal tree classifiers and demonstrate how their interpretability enables explainable structural assessments from sparse sensor measurements, and also informs optimal sensor placement.",
        "published": "2020-04-23T17:55:04Z",
        "link": "http://arxiv.org/abs/2004.11356v3",
        "categories": [
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "Molecular Inverse-Design Platform for Material Industries",
        "authors": [
            "Seiji Takeda",
            "Toshiyuki Hama",
            "Hsiang-Han Hsu",
            "Victoria A. Piunova",
            "Dmitry Zubarev",
            "Daniel P. Sanders",
            "Jed W. Pitera",
            "Makoto Kogoh",
            "Takumi Hongo",
            "Yenwei Cheng",
            "Wolf Bocanett",
            "Hideaki Nakashika",
            "Akihiro Fujita",
            "Yuta Tsuchiya",
            "Katsuhiko Hino",
            "Kentaro Yano",
            "Shuichi Hirose",
            "Hiroki Toda",
            "Yasumitsu Orii",
            "Daiju Nakano"
        ],
        "summary": "The discovery of new materials has been the essential force which brings a discontinuous improvement to industrial products' performance. However, the extra-vast combinatorial design space of material structures exceeds human experts' capability to explore all, thereby hampering material development. In this paper, we present a material industry-oriented web platform of an AI-driven molecular inverse-design system, which automatically designs brand new molecular structures rapidly and diversely. Different from existing inverse-design solutions, in this system, the combination of substructure-based feature encoding and molecular graph generation algorithms allows a user to gain high-speed, interpretable, and customizable design process. Also, a hierarchical data structure and user-oriented UI provide a flexible and intuitive workflow. The system is deployed on IBM's and our client's cloud servers and has been used by 5 partner companies. To illustrate actual industrial use cases, we exhibit inverse-design of sugar and dye molecules, that were carried out by experimental chemists in those client companies. Compared to general human chemist's standard performance, the molecular design speed was accelerated more than 10 times, and greatly increased variety was observed in the inverse-designed molecules without loss of chemical realism.",
        "published": "2020-04-24T03:42:26Z",
        "link": "http://arxiv.org/abs/2004.11521v3",
        "categories": [
            "cs.CE",
            "physics.data-an"
        ]
    },
    {
        "title": "Bayesian Non-parametric Bragg-edge Fitting for Neutron Transmission   Strain Imaging",
        "authors": [
            "Johannes Hendriks",
            "Nicholas O'Dell",
            "Adrian Wills",
            "Anton Tremsin",
            "Christopher Wensrich",
            "Takenao Shinohara"
        ],
        "summary": "Energy resolved neutron transmission techniques can provide high-resolution images of strain within polycrystalline samples allowing the study of residual strain and stress in engineered components. Strain is estimated from such data by analysing features known as Bragg-edges for which several methods exist. It is important for these methods to provide both accurate estimates of strain and an accurate quantification the associated uncertainty. Our contribution is twofold. First, we present a numerical simulation analysis of these existing methods, which shows that the most accurate estimates of strain are provided by a method that provides inaccurate estimates of certainty. Second, a novel Bayesian non-parametric method for estimating strain from Bragg-edges is presented. The numerical simulation analysis indicates that this method provides both competitive estimates of strain and accurate quantification of certainty, two demonstrations on experimental data are then presented.",
        "published": "2020-04-24T04:18:11Z",
        "link": "http://arxiv.org/abs/2004.11526v2",
        "categories": [
            "cs.CE",
            "cond-mat.mtrl-sci",
            "eess.IV"
        ]
    },
    {
        "title": "86 PFLOPS Deep Potential Molecular Dynamics simulation of 100 million   atoms with ab initio accuracy",
        "authors": [
            "Denghui Lu",
            "Han Wang",
            "Mohan Chen",
            "Jiduan Liu",
            "Lin Lin",
            "Roberto Car",
            "Weinan E",
            "Weile Jia",
            "Linfeng Zhang"
        ],
        "summary": "We present the GPU version of DeePMD-kit, which, upon training a deep neural network model using ab initio data, can drive extremely large-scale molecular dynamics (MD) simulation with ab initio accuracy. Our tests show that the GPU version is 7 times faster than the CPU version with the same power consumption. The code can scale up to the entire Summit supercomputer. For a copper system of 113, 246, 208 atoms, the code can perform one nanosecond MD simulation per day, reaching a peak performance of 86 PFLOPS (43% of the peak). Such unprecedented ability to perform MD simulation with ab initio accuracy opens up the possibility of studying many important issues in materials and molecules, such as heterogeneous catalysis, electrochemical cells, irradiation damage, crack propagation, and biochemical reactions.",
        "published": "2020-04-24T11:16:39Z",
        "link": "http://arxiv.org/abs/2004.11658v3",
        "categories": [
            "physics.comp-ph",
            "cs.CE"
        ]
    },
    {
        "title": "Computing multiple solutions of topology optimization problems",
        "authors": [
            "Ioannis P. A. Papadopoulos",
            "Patrick E. Farrell",
            "Thomas M. Surowiec"
        ],
        "summary": "Topology optimization problems often support multiple local minima due to a lack of convexity. Typically, gradient-based techniques combined with continuation in model parameters are used to promote convergence to more optimal solutions; however, these methods can fail even in the simplest cases. In this paper, we present an algorithm to perform a systematic exploratory search for the solutions of the optimization problem via second-order methods without a good initial guess. The algorithm combines the techniques of deflation, barrier methods and primal-dual active set solvers in a novel way. We demonstrate this approach on several numerical examples, observe mesh-independence in certain cases and show that multiple distinct local minima can be recovered.",
        "published": "2020-04-24T15:28:34Z",
        "link": "http://arxiv.org/abs/2004.11797v2",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "An active learning high-throughput microstructure calibration framework   for solving inverse structure-process problems in materials informatics",
        "authors": [
            "Anh Tran",
            "John A. Mitchell",
            "Laura P. Swiler",
            "Tim Wildey"
        ],
        "summary": "Determining a process-structure-property relationship is the holy grail of materials science, where both computational prediction in the forward direction and materials design in the inverse direction are essential. Problems in materials design are often considered in the context of process-property linkage by bypassing the materials structure, or in the context of structure-property linkage as in microstructure-sensitive design problems. However, there is a lack of research effort in studying materials design problems in the context of process-structure linkage, which has a great implication in reverse engineering. In this work, given a target microstructure, we propose an active learning high-throughput microstructure calibration framework to derive a set of processing parameters, which can produce an optimal microstructure that is statistically equivalent to the target microstructure. The proposed framework is formulated as a noisy multi-objective optimization problem, where each objective function measures a deterministic or statistical difference of the same microstructure descriptor between a candidate microstructure and a target microstructure. Furthermore, to significantly reduce the physical waiting wall-time, we enable the high-throughput feature of the microstructure calibration framework by adopting an asynchronously parallel Bayesian optimization by exploiting high-performance computing resources. Case studies in additive manufacturing and grain growth are used to demonstrate the applicability of the proposed framework, where kinetic Monte Carlo (kMC) simulation is used as a forward predictive model, such that for a given target microstructure, the target processing parameters that produced this microstructure are successfully recovered.",
        "published": "2020-04-24T19:16:22Z",
        "link": "http://arxiv.org/abs/2004.11948v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "The computational framework for continuum-kinematics-inspired   peridynamics",
        "authors": [
            "A. Javili",
            "S. Firooz",
            "A. T. McBride",
            "P. Steinmann"
        ],
        "summary": "Peridynamics (PD) is a non-local continuum formulation. The original version of PD was restricted to bond-based interactions. Bond-based PD is geometrically exact and its kinematics are similar to classical continuum mechanics (CCM). However, it cannot capture the Poisson effect correctly. This shortcoming was addressed via state-based PD, but the kinematics are not accurately preserved. Continuum-kinematics-inspired peridynamics (CPD) provides a geometrically exact framework whose underlying kinematics coincide with that of CCM and captures the Poisson effect correctly. In CPD, one distinguishes between one-, two- and three-neighbour interactions. One-neighbour interactions are equivalent to the bond-based interactions of the original PD formalism. However, two- and three-neighbour interactions are fundamentally different from state-based interactions as the basic elements of continuum kinematics are preserved precisely. The objective of this contribution is to elaborate on computational aspects of CPD and present detailed derivations that are essential for its implementation. Key features of the resulting computational CPD are elucidated via a series of numerical examples. These include three-dimensional problems at large deformations. The proposed strategy is robust and the quadratic rate of convergence associated with the Newton--Raphson scheme is observed.",
        "published": "2020-04-25T18:46:10Z",
        "link": "http://arxiv.org/abs/2004.14223v1",
        "categories": [
            "cs.CE",
            "cond-mat.mtrl-sci"
        ]
    },
    {
        "title": "Forecasting in Non-stationary Environments with Fuzzy Time Series",
        "authors": [
            "Petrônio Cândido de Lima e Silva",
            "Carlos Alberto Severiano Junior",
            "Marcos Antonio Alves",
            "Rodrigo Silva",
            "Miri Weiss Cohen",
            "Frederico Gadelha Guimarães"
        ],
        "summary": "In this paper we introduce a Non-Stationary Fuzzy Time Series (NSFTS) method with time varying parameters adapted from the distribution of the data. In this approach, we employ Non-Stationary Fuzzy Sets, in which perturbation functions are used to adapt the membership function parameters in the knowledge base in response to statistical changes in the time series. The proposed method is capable of dynamically adapting its fuzzy sets to reflect the changes in the stochastic process based on the residual errors, without the need to retraining the model. This method can handle non-stationary and heteroskedastic data as well as scenarios with concept-drift. The proposed approach allows the model to be trained only once and remain useful long after while keeping reasonable accuracy. The flexibility of the method by means of computational experiments was tested with eight synthetic non-stationary time series data with several kinds of concept drifts, four real market indices (Dow Jones, NASDAQ, SP500 and TAIEX), three real FOREX pairs (EUR-USD, EUR-GBP, GBP-USD), and two real cryptocoins exchange rates (Bitcoin-USD and Ethereum-USD). As competitor models the Time Variant fuzzy time series and the Incremental Ensemble were used, these are two of the major approaches for handling non-stationary data sets. Non-parametric tests are employed to check the significance of the results. The proposed method shows resilience to concept drift, by adapting parameters of the model, while preserving the symbolic structure of the knowledge base.",
        "published": "2020-04-27T02:35:46Z",
        "link": "http://arxiv.org/abs/2004.12554v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.CE",
            "stat.ML"
        ]
    },
    {
        "title": "A linearised consistent mixed displacement-pressure formulation for   hyperelasticity",
        "authors": [
            "Chennakesava Kadapa",
            "Mokarram Hossain"
        ],
        "summary": "We propose a novel mixed displacement-pressure formulation based on an energy functional that takes into account the relation between the pressure and the volumetric energy function. We demonstrate that the proposed two-field mixed displacement-pressure formulation is not only applicable for nearly and truly incompressible cases but also is consistent in the compressible regime. Furthermore, we prove with analytical derivation and numerical results that the proposed two-field formulation is a simplified and efficient alternative for the three-field displacement-pressure-Jacobian formulation for hyperelastic materials whose strain energy density functions are decomposed into deviatoric and volumetric parts.",
        "published": "2020-04-27T22:44:33Z",
        "link": "http://arxiv.org/abs/2004.13201v1",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Various Ways to Quantify BDMPs",
        "authors": [
            "Marc Bouissou",
            "Shahid Khan",
            "Joost-Pieter Katoen",
            "Pavel Krcal"
        ],
        "summary": "A Boolean logic driven Markov process (BDMP) is a dependability analysis model that defines a continuous-time Markov chain (CTMC). This formalism has high expressive power, yet it remains readable because its graphical representation stays close to standard fault trees. The size of a BDMP is roughly speaking proportional to the size of the system it models, whereas the size of the CTMC specified by this BDMP suffers from exponential growth. Thus quantifying large BDMPs can be a challenging task. The most general method to quantify them is Monte Carlo simulation, but this may be intractable for highly reliable systems. On the other hand, some subcategories of BDMPs can be processed with much more efficient methods. For example, BDMPs without repairs can be translated into dynamic fault trees, a formalism accepted as an input of the STORM model checker, that performs numerical calculations on sparse matrices, or they can be processed with the tool FIGSEQ that explores paths going to a failure state and calculates their probabilities. BDMPs with repairs can be quantified by FIGSEQ (BDMPs capturing quickly and completely repairable behaviors are solved by a different algorithm), and by the I&AB (Initiator and All Barriers) method, recently published and implemented in a prototype version of RISKSPECTRUM PSA. This tool, based exclusively on Boolean representations looks for and quantifies minimal cut sets of the system, i.e., minimal combinations of component failures that induce the loss of the system. This allows a quick quantification of large models with repairable components, standby redundancies and some other types of dependencies between omponents. All these quantification methods have been tried on a benchmark whose definition was published at the MARS 2017 workshop: the model of emergency power supplies of a nuclear power plant. In this paper, after a recall of the theoretical principles of the various quantification methods, we compare their performances on that benchmark.",
        "published": "2020-04-28T04:21:21Z",
        "link": "http://arxiv.org/abs/2004.13283v1",
        "categories": [
            "cs.CE",
            "cs.MS"
        ]
    },
    {
        "title": "Design of multifunctional metamaterials using optimization",
        "authors": [
            "Ewan Fong",
            "Sadik L. Omairey",
            "Peter D. Dunning"
        ],
        "summary": "This paper explores the use of optimization to design multifunctional metamaterials, and proposes a methodology for constructing a design envelope of potential properties. A thermal-mechanical metamaterial, proposed by Ai and Gao (2017), is used as the subject of the study. The properties of the metamaterial are computed using finite element-based periodic homogenization, which is implemented in Abaqus utilizing an open-source plugin (EasyPBC). Several optimization problems are solved using a particle swarm-based optimization method from the pyOpt package. A series of constrained optimization problems are used to construct a design envelop of potential properties. The design envelope more fully captures the potential of the metamaterial, compared with the current practice of using parametric studies. This is because the optimizer can change all parameters simultaneously to find the optimal design. This demonstrates the potential of using an optimization-based approach for designing and exploring multifunctional metamaterial properties. This proposed approach is general and can be applied to any metamaterial design, assuming an accurate numerical model exists to evaluate its properties.",
        "published": "2020-04-28T14:55:15Z",
        "link": "http://arxiv.org/abs/2004.13571v1",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA",
            "math.OC"
        ]
    },
    {
        "title": "RotEqNet: Rotation-Equivariant Network for Fluid Systems with Symmetric   High-Order Tensors",
        "authors": [
            "Liyao Gao",
            "Yifan Du",
            "Hongshan Li",
            "Guang Lin"
        ],
        "summary": "In the recent application of scientific modeling, machine learning models are largely applied to facilitate computational simulations of fluid systems. Rotation symmetry is a general property for most symmetric fluid systems. However, in general, current machine learning methods have no theoretical way to guarantee rotational symmetry. By observing an important property of contraction and rotation operation on high-order symmetric tensors, we prove that the rotation operation is preserved via tensor contraction. Based on this theoretical justification, in this paper, we introduce Rotation-Equivariant Network (RotEqNet) to guarantee the property of rotation-equivariance for high-order tensors in fluid systems. We implement RotEqNet and evaluate our claims through four case studies on various fluid systems. The property of error reduction and rotation-equivariance is verified in these case studies. Results from the comparative study show that our method outperforms conventional methods, which rely on data augmentation.",
        "published": "2020-04-28T22:33:34Z",
        "link": "http://arxiv.org/abs/2005.04286v1",
        "categories": [
            "cs.CE",
            "cs.LG",
            "physics.comp-ph",
            "physics.flu-dyn",
            "stat.ML"
        ]
    },
    {
        "title": "Improving Vertical Positioning Accuracy with the Weighted Multinomial   Logistic Regression Classifier",
        "authors": [
            "Yiyan Yao",
            "Xin-long Luo"
        ],
        "summary": "In this paper, a method of improving vertical positioning accuracy with the Global Positioning System (GPS) information and barometric pressure values is proposed. Firstly, we clear null values for the raw data collected in various environments, and use the 3$\\sigma$-rule to identify outliers. Secondly, the Weighted Multinomial Logistic Regression (WMLR) classifier is trained to obtain the predicted altitude of outliers. Finally, in order to verify its effect, we compare the MLR method, the WMLR method, and the Support Vector Machine (SVM) method for the cleaned dataset which is regarded as the test baseline. The numerical results show that the vertical positioning accuracy is improved from 5.9 meters (the MLR method), 5.4 meters (the SVM method) to 5 meters (the WMLR method) for 67% test points.",
        "published": "2020-04-29T01:13:51Z",
        "link": "http://arxiv.org/abs/2004.13909v2",
        "categories": [
            "eess.SP",
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "Quantum circuit representation of Bayesian networks",
        "authors": [
            "Sima E. Borujeni",
            "Saideep Nannapaneni",
            "Nam H. Nguyen",
            "Elizabeth C. Behrman",
            "James E. Steck"
        ],
        "summary": "Probabilistic graphical models such as Bayesian networks are widely used to model stochastic systems to perform various types of analysis such as probabilistic prediction, risk analysis, and system health monitoring, which can become computationally expensive in large-scale systems. While demonstrations of true quantum supremacy remain rare, quantum computing applications managing to exploit the advantages of amplitude amplification have shown significant computational benefits when compared against their classical counterparts. We develop a systematic method for designing a quantum circuit to represent a generic discrete Bayesian network with nodes that may have two or more states, where nodes with more than two states are mapped to multiple qubits. The marginal probabilities associated with root nodes (nodes without any parent nodes) are represented using rotation gates, and the conditional probability tables associated with non-root nodes are represented using controlled rotation gates. The controlled rotation gates with more than one control qubit are represented using ancilla qubits. The proposed approach is demonstrated for three examples: a 4-node oil company stock prediction, a 10-node network for liquidity risk assessment, and a 9-node naive Bayes classifier for bankruptcy prediction. The circuits were designed and simulated using Qiskit, a quantum computing platform that enables simulations and also has the capability to run on real quantum hardware. The results were validated against those obtained from classical Bayesian network implementations.",
        "published": "2020-04-29T04:58:54Z",
        "link": "http://arxiv.org/abs/2004.14803v2",
        "categories": [
            "quant-ph",
            "cs.CE"
        ]
    },
    {
        "title": "A Flexible Storage Model for Power Network Optimization",
        "authors": [
            "Frederik Geth",
            "Carleton Coffrin",
            "David M Fobes"
        ],
        "summary": "This paper proposes a simple and flexible storage model for use in a variety of multi-period optimal power flow problems. The proposed model is designed for research use in a broad assortment of contexts enabled by the following key features: (i) the model can represent the dynamics of an energy buffer at a wide range of scales, from residential battery storage to grid-scale pumped hydro; (ii) it is compatible with both balanced and unbalanced formulations of the power flow equations; (iii) convex relaxations and linear approximations to allow seamless integration of the proposed model into applications where convexity or linearity is required are developed; (iv) a minimalist and standardized data model is presented, to facilitate easy of use by the research community. The proposed model is validated using a proof-of-concept twenty-four hour storage scheduling task that demonstrates the value of the model's key features. An open-source implementation of the model is provided as part of the PowerModels and PowerModelsDistribution optimization toolboxes.",
        "published": "2020-04-29T12:56:29Z",
        "link": "http://arxiv.org/abs/2004.14768v1",
        "categories": [
            "eess.SY",
            "cs.CE",
            "cs.SY",
            "eess.SP"
        ]
    },
    {
        "title": "A Higher-order Trace Finite Element Method for Shells",
        "authors": [
            "D. Schöllhammer",
            "T. P. Fries"
        ],
        "summary": "A higher-order fictitious domain method (FDM) for Reissner-Mindlin shells is proposed which uses a three-dimensional background mesh for the discretization. The midsurface of the shell is immersed into the higher-order background mesh and the geometry is implied by level-set functions. The mechanical model is based on the Tangential Differential Calculus (TDC) which extends the classical models based on curvilinear coordinates to implicit geometries. The shell model is described by PDEs on manifolds and the resulting FDM may typically be called Trace FEM. The three standard key aspects of FDMs have to be addressed in the Trace FEM as well to allow for a higher-order accurate method: (i) numerical integration in the cut background elements, (ii) stabilization of awkward cut situations and elimination of linear dependencies, and (iii) enforcement of boundary conditions using Nitsche's method. The numerical results confirm that higher-order accurate results are enabled by the proposed method provided that the solutions are sufficiently smooth.",
        "published": "2020-04-29T20:22:00Z",
        "link": "http://arxiv.org/abs/2004.14461v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A convolutional neural-network model of human cochlear mechanics and   filter tuning for real-time applications",
        "authors": [
            "Deepak Baby",
            "Arthur Van Den Broucke",
            "Sarah Verhulst"
        ],
        "summary": "Auditory models are commonly used as feature extractors for automatic speech-recognition systems or as front-ends for robotics, machine-hearing and hearing-aid applications. Although auditory models can capture the biophysical and nonlinear properties of human hearing in great detail, these biophysical models are computationally expensive and cannot be used in real-time applications. We present a hybrid approach where convolutional neural networks are combined with computational neuroscience to yield a real-time end-to-end model for human cochlear mechanics, including level-dependent filter tuning (CoNNear). The CoNNear model was trained on acoustic speech material and its performance and applicability were evaluated using (unseen) sound stimuli commonly employed in cochlear mechanics research. The CoNNear model accurately simulates human cochlear frequency selectivity and its dependence on sound intensity, an essential quality for robust speech intelligibility at negative speech-to-background-noise ratios. The CoNNear architecture is based on parallel and differentiable computations and has the power to achieve real-time human performance. These unique CoNNear features will enable the next generation of human-like machine-hearing applications.",
        "published": "2020-04-30T14:43:03Z",
        "link": "http://arxiv.org/abs/2004.14832v4",
        "categories": [
            "eess.AS",
            "cs.CE",
            "cs.LG",
            "cs.SD"
        ]
    },
    {
        "title": "Interactive Geometry Modification of High Performance Finite Element   Simulations",
        "authors": [
            "Corey Wetterer-Nelson",
            "Kenneth E. Jansen",
            "John A. Evans"
        ],
        "summary": "In the context of high performance finite element analysis, the cost of iteratively modifying a computational domain via re-meshing and restarting the analysis becomes time prohibitive as the size of simulations increases. In this paper, we demonstrate a new interactive simulation pipeline targeting high performance finite element simulations where the computational domain is modifiable in situ, that is, while the simulation is ongoing. This pipeline is designed to be modular so that it may interface with any existing finite element simulation framework. A server-client architecture is employed to manage simulation mesh data existing on a high performance computing resource while user-prescribed freeform geometric modifications take place on a separate workstation. We employ existing in situ visualization techniques to rapidly inform the user of simulation progression, enabling computational steering. By expressing the simulation domain in a reduced fashion on the client application, this pipeline manages highly refined finite element simulation domains on the server while maintaining good performance on the client application.",
        "published": "2020-05-01T03:53:26Z",
        "link": "http://arxiv.org/abs/2005.00202v2",
        "categories": [
            "cs.CE",
            "cs.GR"
        ]
    },
    {
        "title": "Application of accelerated fixed-point algorithms to hydrodynamic   well-fracture coupling",
        "authors": [
            "Vitalii Aksenov",
            "Maxim Chertov",
            "Konstantin Sinkov"
        ],
        "summary": "The coupled simulations of dynamic interactions between the well, hydraulic fractures and reservoir have significant importance in some areas of petroleum reservoir engineering. Several approaches to the problem of coupling between the numerical models of these parts of the full system have been developed in the industry in past years. One of the possible approaches allowing formulation of the problem as a fixed-point problem is studied in the present work. Accelerated Anderson's and Aitken's fixed-point algorithms are applied to the coupling problem. Accelerated algorithms are compared with traditional Picard iterations on the representative set of test cases including ones remarkably problematic for coupling. Relative performance is measured, and the robustness of the algorithms is tested. Accelerated algorithms enable a significant (up to two orders of magnitude) performance boost in some cases and convergent solutions in the cases where simple Picard iterations fail. Based on the analysis, we provide recommendations for the choice of the particular algorithm and tunable relaxation parameter depending on anticipated complexity of the problem.",
        "published": "2020-05-01T10:18:31Z",
        "link": "http://arxiv.org/abs/2005.01620v1",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Active Training of Physics-Informed Neural Networks to Aggregate and   Interpolate Parametric Solutions to the Navier-Stokes Equations",
        "authors": [
            "Christopher J Arthurs",
            "Andrew P King"
        ],
        "summary": "The goal of this work is to train a neural network which approximates solutions to the Navier-Stokes equations across a region of parameter space, in which the parameters define physical properties such as domain shape and boundary conditions. The contributions of this work are threefold:   1) To demonstrate that neural networks can be efficient aggregators of whole families of parameteric solutions to physical problems, trained using data created with traditional, trusted numerical methods such as finite elements. Advantages include extremely fast evaluation of pressure and velocity at any point in physical and parameter space (asymptotically, ~3 $\\mu s$ / query), and data compression (the network requires 99\\% less storage space compared to its own training data).   2) To demonstrate that the neural networks can accurately interpolate between finite element solutions in parameter space, allowing them to be instantly queried for pressure and velocity field solutions to problems for which traditional simulations have never been performed.   3) To introduce an active learning algorithm, so that during training, a finite element solver can automatically be queried to obtain additional training data in locations where the neural network's predictions are in most need of improvement, thus autonomously acquiring and efficiently distributing training data throughout parameter space.   In addition to the obvious utility of Item 2, above, we demonstrate an application of the network in rapid parameter sweeping, very precisely predicting the degree of narrowing in a tube which would result in a 50\\% increase in end-to-end pressure difference at a given flow rate. This capability could have applications in both medical diagnosis of arterial disease, and in computer-aided design.",
        "published": "2020-05-02T21:53:39Z",
        "link": "http://arxiv.org/abs/2005.05092v2",
        "categories": [
            "physics.comp-ph",
            "cs.CE",
            "cs.LG",
            "stat.ML"
        ]
    },
    {
        "title": "Plasticity without phenomenology: a first step",
        "authors": [
            "Sabyasachi Chatterjee",
            "Giacomo Po",
            "Xiaohan Zhang",
            "Amit Acharya",
            "Nasr Ghoniem"
        ],
        "summary": "A novel, concurrent multiscale approach to meso/macroscale plasticity is demonstrated. It utilizes a carefully designed coupling of a partial differential equation (pde) based theory of dislocation mediated crystal plasticity with time-averaged inputs from microscopic Dislocation Dynamics (DD), adapting a state-of-the-art mathematical coarse-graining scheme. The stress-strain response of mesoscopic samples at realistic, slow, loading rates up to appreciable values of strain is obtained, with significant speed-up in compute time compared to conventional DD. Effects of crystal orientation, loading rate, and the ratio of the initial mobile to sessile dislocation density on the macroscopic response, for both load and displacement controlled simulations are demonstrated. These results are obtained without using any phenomenological constitutive assumption, except for thermal activation which is not a part of microscopic DD. The results also demonstrate the effect of the internal stresses on the collective behavior of dislocations, manifesting, in a set of examples, as a Stage I to Stage II hardening transition.",
        "published": "2020-05-03T01:05:03Z",
        "link": "http://arxiv.org/abs/2005.02498v1",
        "categories": [
            "cs.CE",
            "cond-mat.mtrl-sci"
        ]
    },
    {
        "title": "Stochastic phase-field modeling of brittle fracture: computing multiple   crack patterns and their probabilities",
        "authors": [
            "Tymofiy Gerasimov",
            "Ulrich Römer",
            "Jaroslav Vondřejc",
            "Hermann G. Matthies",
            "Laura De Lorenzis"
        ],
        "summary": "In variational phase-field modeling of brittle fracture, the functional to be minimized is not convex, so that the necessary stationarity conditions of the functional may admit multiple solutions. The solution obtained in an actual computation is typically one out of several local minimizers. Evidence of multiple solutions induced by small perturbations of numerical or physical parameters was occasionally recorded but not explicitly investigated in the literature. In this work, we focus on this issue and advocate a paradigm shift, away from the search for one particular solution towards the simultaneous description of all possible solutions (local minimizers), along with the probabilities of their occurrence. Inspired by recent approaches advocating measure-valued solutions (Young measures as well as their generalization to statistical solutions) and their numerical approximations in fluid mechanics, we propose the stochastic relaxation of the variational brittle fracture problem through random perturbations of the functional. We introduce the concept of stochastic solution, with the main advantage that point-to-point correlations of the crack phase fields in the underlying domain can be captured. These stochastic solutions are represented by random fields or random variables with values in the classical deterministic solution spaces. In the numerical experiments, we use a simple Monte Carlo approach to compute approximations to such stochastic solutions. The final result of the computation is not a single crack pattern, but rather several possible crack patterns and their probabilities. The stochastic solution framework using evolving random fields allows additionally the interesting possibility of conditioning the probabilities of further crack paths on intermediate crack patterns.",
        "published": "2020-05-04T09:06:24Z",
        "link": "http://arxiv.org/abs/2005.01332v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A second-order face-centred finite volume method on general meshes with   automatic mesh adaptation",
        "authors": [
            "Matteo Giacomini",
            "Ruben Sevilla"
        ],
        "summary": "A second-order face-centred finite volume strategy on general meshes is proposed. The method uses a mixed formulation in which a constant approximation of the unknown is computed on the faces of the mesh. Such information is then used to solve a set of problems, independent cell-by-cell, to retrieve the local values of the solution and its gradient. The main novelty of this approach is the introduction of a new basis function, utilised for the linear approximation of the primal variable in each cell. Contrary to the commonly used nodal basis, the proposed basis is suitable for computations on general meshes, including meshes with different cell types. The resulting approach provides second-order accuracy for the solution and first-order for its gradient, without the need of reconstruction procedures, is robust in the incompressible limit and insensitive to cell distortion and stretching. The second-order accuracy of the solution is exploited to devise an automatic mesh adaptivity strategy. An efficient error indicator is obtained from the computation of one extra local problem, independent cell-by-cell, and is used to drive mesh adaptivity. Numerical examples illustrating the approximation properties of the method and of the mesh adaptivity procedure are presented. The potential of the proposed method with automatic mesh adaptation is demonstrated in the context of microfluidics.",
        "published": "2020-05-04T17:15:52Z",
        "link": "http://arxiv.org/abs/2005.01663v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "65N08, 65N30, 65N12"
        ]
    },
    {
        "title": "Topology design of two-fluid heat exchange",
        "authors": [
            "Hiroki Kobayashi",
            "Kentaro Yaji",
            "Shintaro Yamasaki",
            "Kikuo Fujita"
        ],
        "summary": "Heat exchangers are devices that typically transfer heat between two fluids. The performance of a heat exchanger such as heat transfer rate and pressure loss strongly depends on the flow regime in the heat transfer system. In this paper, we present a density-based topology optimization method for a two-fluid heat exchange system, which achieves a maximum heat transfer rate under fixed pressure loss. We propose a representation model accounting for three states, i.e., two fluids and a solid wall between the two fluids, by using a single design variable field. The key aspect of the proposed model is that mixing of the two fluids can be essentially prevented without any penalty scheme. This is because the solid constantly exists between the two fluids due to the use of the single design variable field. We demonstrate the effectiveness of the proposed approach through three-dimensional numerical examples in which an optimized design is compared with a simple reference design, and the effects of design conditions (i.e., Reynolds number, Prandtl number, design domain size, and flow arrangements) are investigated.",
        "published": "2020-05-05T04:53:14Z",
        "link": "http://arxiv.org/abs/2005.08870v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "An accurate methodology for surface tension modeling in OpenFOAM",
        "authors": [
            "Abd Essamade Saufi",
            "Olivier Desjardins",
            "Alberto Cuoci"
        ],
        "summary": "In this paper a numerical methodology for surface tension modeling is presented, with an emphasis on the implementation in the OpenFOAM framework. The methodology relies on a combination of (i) a well-balanced approach based on the Ghost Fluid Method (GFM), including the jump of density and pressure directly in the numerical discretization of the pressure equation, and (ii) Height Functions to evaluate the interface curvature, implemented, to the authors' knowledge, for the first time in OpenFOAM. The method is able to significantly reduce spurious currents (almost to machine accuracy) for a stationary droplet, showing second order convergence both for the curvature and the interface shape. Accurate results are also obtained for additional test cases such as translating droplets, capillary oscillations and rising bubbles, for which numerical results are comparable to what obtained by other numerical codes in the same conditions. Finally, the Height Functions method is extended to include the treatment of contact angles, both for sessile droplets and droplets suspended under the effect of gravity, showing a very good agreement with the theoretical prediction. The code works in parallel mode and details on the actual implementation in OpenFOAM are included to facilitate the reproducibility of the results.",
        "published": "2020-05-05T10:31:34Z",
        "link": "http://arxiv.org/abs/2005.02865v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Evolutionary-Based Sparse Regression for the Experimental Identification   of Duffing Oscillator",
        "authors": [
            "Saeideh Khatiry Goharoodi",
            "Kevin Dekemele",
            "Mia Loccufier",
            "Luc Dupre",
            "Guillaume Crevecoeur"
        ],
        "summary": "In this paper, an evolutionary-based sparse regression algorithm is proposed and applied onto experimental data collected from a Duffing oscillator setup and numerical simulation data. Our purpose is to identify the Coulomb friction terms as part of the ordinary differential equation of the system. Correct identification of this nonlinear system using sparse identification is hugely dependent on selecting the correct form of nonlinearity included in the function library. Consequently, in this work, the evolutionary-based sparse identification is replacing the need for user knowledge when constructing the library in sparse identification. Constructing the library based on the data-driven evolutionary approach is an effective way to extend the space of nonlinear functions, allowing for the sparse regression to be applied on an extensive space of functions. ,e results show that the method provides an effective algorithm for the purpose of unveiling the physical nature of the Duffing oscillator. In addition, the robustness of the identification algorithm is investigated for various levels of noise in simulation. ,e proposed method has possible applications to other nonlinear dynamic systems in mechatronics, robotics, and electronics.",
        "published": "2020-05-05T11:06:11Z",
        "link": "http://arxiv.org/abs/2005.08631v1",
        "categories": [
            "cs.CE",
            "eess.SP"
        ]
    },
    {
        "title": "Interface-resolved simulation of the evaporation and combustion of a   fuel droplet suspended in normal gravity",
        "authors": [
            "Abd Essamade Saufi",
            "Alessio Frassoldati",
            "Tiziano Faravelli",
            "Alberto Cuoci"
        ],
        "summary": "An interface-resolved simulation of the combustion of a fuel droplet suspended in normal gravity is presented in this work, followed by an extensive analysis on the physical aspects involved. The modeling is based on DropletSMOKE++, a multiphase solver developed for the modeling of droplet vaporization and combustion in convective conditions. A wide range of phenomena can be described by the model, including the interface advection, the phase-change, the combustion chemistry, non-ideal thermodynamics and multicomponent mixtures. To our knowledge, this is the most detailed simulation performed on this configuration, providing a useful theoretical and numerical support for the experimental activity on this field. A recent experimental work is used as a reference, in which a methanol droplet is suspended on a quartz fiber and ignited at different oxygen concentrations. The numerical analysis offers a detailed insight into the physics of the problem and a satisfactory agreement with the experiments in terms of diameter decay, radial temperature profiles and sensitivity to the oxygen concentration. The vaporization rate is affected by the thermal conduction from the fiber, due to the high temperatures involved. Moreover, the fiber perturbs the flame itself, providing quenching at its surface. The combustion physics is compared to the one predicted at zero-gravity, evidencing a lower standoff-ratio, a higher flame temperature and an intense internal circulation. The distribution of the species around the droplet shows (i) a local accumulation of intermediate oxidation products at the fiber surface and (ii) water absorption in the liquid phase, affecting the vaporization rate.",
        "published": "2020-05-05T13:43:10Z",
        "link": "http://arxiv.org/abs/2005.02866v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Long short-term memory networks and laglasso for bond yield forecasting:   Peeping inside the black box",
        "authors": [
            "Manuel Nunes",
            "Enrico Gerding",
            "Frank McGroarty",
            "Mahesan Niranjan"
        ],
        "summary": "Modern decision-making in fixed income asset management benefits from intelligent systems, which involve the use of state-of-the-art machine learning models and appropriate methodologies. We conduct the first study of bond yield forecasting using long short-term memory (LSTM) networks, validating its potential and identifying its memory advantage. Specifically, we model the 10-year bond yield using univariate LSTMs with three input sequences and five forecasting horizons. We compare those with multilayer perceptrons (MLP), univariate and with the most relevant features. To demystify the notion of black box associated with LSTMs, we conduct the first internal study of the model. To this end, we calculate the LSTM signals through time, at selected locations in the memory cell, using sequence-to-sequence architectures, uni and multivariate. We then proceed to explain the states' signals using exogenous information, for what we develop the LSTM-LagLasso methodology. The results show that the univariate LSTM model with additional memory is capable of achieving similar results as the multivariate MLP using macroeconomic and market information. Furthermore, shorter forecasting horizons require smaller input sequences and vice-versa. The most remarkable property found consistently in the LSTM signals, is the activation/deactivation of units through time, and the specialisation of units by yield range or feature. Those signals are complex but can be explained by exogenous variables. Additionally, some of the relevant features identified via LSTM-LagLasso are not commonly used in forecasting models. In conclusion, our work validates the potential of LSTMs and methodologies for bonds, providing additional tools for financial practitioners.",
        "published": "2020-05-05T14:23:00Z",
        "link": "http://arxiv.org/abs/2005.02217v1",
        "categories": [
            "q-fin.CP",
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "A new generation 99 line Matlab code for compliance Topology   Optimization and its extension to 3D",
        "authors": [
            "Federico Ferrari",
            "Ole Sigmund"
        ],
        "summary": "Compact and efficient Matlab implementations of compliance Topology Optimization (TO) for 2D and 3D continua are given, consisting of 99 and 125 lines respectively. On discretizations ranging from $3\\cdot 10^{4}$ to $4.8\\cdot10^{5}$ elements, the 2D version, named top99neo, shows speedups from 2.55 to 5.5 times compared to the well-known top88 code (Andreassen-etal 2011). The 3D version, named top3D125, is the most compact and efficient Matlab implementation for 3D TO to date, showing a speedup of 1.9 times compared to the code of Amir-etal 2014, on a discretization with $2.2\\cdot10^{5}$ elements. For both codes, improvements are due to much more efficient procedures for the assembly and implementation of filters and shortcuts in the design update step. The use of an acceleration strategy, yielding major cuts in the overall computational time, is also discussed, stressing its easy integration within the basic codes.",
        "published": "2020-05-05T14:32:52Z",
        "link": "http://arxiv.org/abs/2005.05436v2",
        "categories": [
            "cs.CE",
            "math.OC"
        ]
    },
    {
        "title": "DropletSMOKE++: a comprehensive multiphase CFD framework for the   evaporation of multidimensional fuel droplets",
        "authors": [
            "Abd Essamade Saufi",
            "Alessio Frassoldati",
            "Alberto Cuoci",
            "Tiziano Faravelli"
        ],
        "summary": "This paper aims at presenting the DropletSMOKE++ solver, a comprehensive multidimensional computational framework for the evaporation of fuel droplets, under the influence of a gravity field and an external fluid flow. The Volume Of Fluid (VOF) methodology is adopted to dynamically track the interface, coupled with the solution of energy and species equations. The evaporation rate is directly evaluated based on the vapor concentration gradient at the phase boundary, with no need of semi-empirical evaporation sub-models. The strong surface tension forces often prevent to model small droplets evaporation, because of the presence of parasitic currents. In this work we by-pass the problem, eliminating surface tension and introducing a centripetal force toward the center of the droplet. This expedient represents a major novelty of this work, which allows to numerically hang a droplet on a fiber in normal gravity conditions without modeling surface tension. Parasitic currents are completely suppressed, allowing to accurately model the evaporation process whatever the droplet size. DropletSMOKE++ shows an excellent agreement with the experimental data in a wide range of operating conditions, for various fuels and initial droplet diameters, both in natural and forced convection. The comparison with the same cases modeled in microgravity conditions highlights the impact of an external fluid flow on the evaporation mechanism, especially at high pressures. Non-ideal thermodynamics for phase-equilibrium is included to correctly capture evaporation rates at high pressures, otherwise not well predicted by an ideal gas assumption. Finally, the presence of flow circulation in the liquid phase is discussed, as well as its influence on the internal temperature field. DropletSMOKE++ will be released as an open-source code, open to contributions from the scientific community.",
        "published": "2020-05-05T14:32:58Z",
        "link": "http://arxiv.org/abs/2005.02867v1",
        "categories": [
            "cs.CE",
            "physics.comp-ph"
        ]
    },
    {
        "title": "High-order entropy stable discontinuous Galerkin methods for the shallow   water equations: curved triangular meshes and GPU acceleration",
        "authors": [
            "Xinhui Wu",
            "Jesse Chan",
            "Ethan Kubatko"
        ],
        "summary": "We present a high-order entropy stable discontinuous Galerkin (ESDG) method for the two dimensional shallow water equations (SWE) on curved triangular meshes. The presented scheme preserves a semi-discrete entropy inequality and remains well-balanced for continuous bathymetry profiles. We provide numerical experiments which confirm the high-order accuracy and theoretical properties of the scheme, and compare the presented scheme to an entropy stable scheme based on simplicial summation-by-parts (SBP) finite difference operators. Finally, we report the computational performance of an implementation on Graphics Processing Units (GPUs) and provide comparisons to existing GPU-accelerated implementations of high-order DG methods on quadrilateral meshes.",
        "published": "2020-05-05T21:56:21Z",
        "link": "http://arxiv.org/abs/2005.02516v2",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "A Smoothed Particle Hydrodynamics Mini-App for Exascale",
        "authors": [
            "Aurélien Cavelan",
            "Rubén M. Cabezón",
            "Michal Grabarczyk",
            "Florina M. Ciorba"
        ],
        "summary": "The Smoothed Particles Hydrodynamics (SPH) is a particle-based, meshfree, Lagrangian method used to simulate multidimensional fluids with arbitrary geometries, most commonly employed in astrophysics, cosmology, and computational fluid-dynamics (CFD). It is expected that these computationally-demanding numerical simulations will significantly benefit from the up-and-coming Exascale computing infrastructures, that will perform 10 18 FLOP/s. In this work, we review the status of a novel SPH-EXA mini-app, which is the result of an interdisciplinary co-design project between the fields of astrophysics, fluid dynamics and computer science, whose goal is to enable SPH simulations to run on Exascale systems. The SPH-EXA mini-app merges the main characteristics of three state-of-the-art parent SPH codes (namely ChaNGa, SPH-flow, SPHYNX) with state-of-the-art (parallel) programming, optimization, and parallelization methods. The proposed SPH-EXA mini-app is a C++14 lightweight and flexible header-only code with no external software dependencies. Parallelism is expressed via multiple programming models, which can be chosen at compilation time with or without accelerator support, for a hybrid process+thread+accelerator configuration. Strong and weak-scaling experiments on a production supercomputer show that the SPH-EXA mini-app can be efficiently executed with up 267 million particles and up to 65 billion particles in total on 2,048 hybrid CPU-GPU nodes.",
        "published": "2020-05-06T08:41:10Z",
        "link": "http://arxiv.org/abs/2005.02656v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Some improvements on the one-step inverse isogeometric analysis by   proposing a multi-step inverse isogeometric methodology in sheet metal   stamping processes",
        "authors": [
            "Amir Reza Isazadeh",
            "Mansoor Shamloofard",
            "Ahmad Assempour"
        ],
        "summary": "The isogeometric methodology has been successfully implemented in one-step inverse analysis of sheet metal stamping processes. However, these models are not capable of analyzing forming processes that require severe deformation and several forming stages. This paper presents a multi-step inverse isogeometric methodology to enhance the precision of one-step models in predictions of the initial blank, strain distributions, and drawability of the formed parts. This methodology deals with the minimization of potential energy, deformation theory of plasticity, and considering membrane elements. The presented methodology utilizes the NURBS basis functions to create the final, middle, and blank geometries and also to analyze sheet metal deformation. The characteristics of the applied formulations make it possible to simultaneously observe the effects of changing part parameters on its formability. One advantage of this approach is that the linear system of governing equations is solved without concerning about the convergence. Besides, the presented methodology can successfully generate the middle geometry and to restrict the movements of physical nodes along the middle surface, by presenting a new NURBS-based mapping and sliding constraint technique. The performance of the presented model is experimentally and numerically evaluated under two classical problems, including the forming of a rectangular box and a two-step drawing of a circular cup. Results comparisons indicate the credibility of the presented model in prediction of forming parameters at a low computation time.",
        "published": "2020-05-06T10:09:53Z",
        "link": "http://arxiv.org/abs/2005.02701v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "High-Contrast Reflection Tomography with Total-Variation Constraints",
        "authors": [
            "Ajinkya Kadu",
            "Hassan Mansour",
            "Petros T. Boufounos"
        ],
        "summary": "Inverse scattering is the process of estimating the spatial distribution of the scattering potential of an object by measuring the scattered wavefields around it. In this paper, we consider reflection tomography of high contrast objects that commonly occurs in ground-penetrating radar, exploration geophysics, terahertz imaging, ultrasound, and electron microscopy. Unlike conventional transmission tomography, the reflection regime is severely ill-posed since the measured wavefields contain far less spatial frequency information of the target object. We propose a constrained incremental frequency inversion framework that requires no side information from a background model of the object. Our framework solves a sequence of regularized least-squares subproblems that ensure consistency with the measured scattered wavefield while imposing total-variation and non-negativity constraints. We propose a proximal Quasi-Newton method to solve the resulting subproblem and devise an automatic parameter selection routine to determine the constraint of each subproblem. We validate the performance of our approach on synthetic low-resolution phantoms and with a mismatched forward model test on a high-resolution phantom.",
        "published": "2020-05-06T15:26:55Z",
        "link": "http://arxiv.org/abs/2005.02903v2",
        "categories": [
            "eess.SP",
            "cs.CE",
            "cs.CV",
            "eess.IV"
        ]
    },
    {
        "title": "Improved supervised prediction of aging-related genes via weighted   dynamic network analysis",
        "authors": [
            "Qi Li",
            "Khalique Newaz",
            "Tijana Milenković"
        ],
        "summary": "This study focuses on the task of supervised prediction of aging-related genes from -omics data. Unlike gene expression methods for this task that capture aging-specific information but ignore interactions between genes (i.e., their protein products), or protein-protein interaction (PPI) network methods for this task that account for PPIs but the PPIs are context-unspecific, we recently integrated the two data types into an aging-specific PPI subnetwork, which yielded more accurate aging-related gene predictions. However, a dynamic aging-specific subnetwork did not improve prediction performance compared to a static aging-specific subnetwork, despite the aging process being dynamic. This could be because the dynamic subnetwork was inferred using a naive Induced subgraph approach. Instead, we recently inferred a dynamic aging-specific subnetwork using a methodologically more advanced notion of network propagation (NP), which improved upon Induced dynamic aging-specific subnetwork in a different task, that of unsupervised analyses of the aging process. Here, we evaluate whether our existing NP-based dynamic subnetwork will improve upon the dynamic as well as static subnetwork constructed by the Induced approach in the considered task of supervised prediction of aging-related genes. The existing NP-based subnetwork is unweighted, i.e., it gives equal importance to each of the aging-specific PPIs. Because accounting for aging-specific edge weights might be important, we additionally propose a weighted NP-based dynamic aging-specific subnetwork. We demonstrate that a predictive machine learning model trained and tested on the weighted subnetwork yields higher accuracy when predicting aging-related genes than predictive models run on the existing unweighted dynamic or static subnetworks, regardless of whether the existing subnetworks were inferred using NP or the Induced approach.",
        "published": "2020-05-07T01:50:25Z",
        "link": "http://arxiv.org/abs/2005.03659v3",
        "categories": [
            "q-bio.MN",
            "cs.CE"
        ]
    },
    {
        "title": "Simultaneous topology and fastener layout optimization of assemblies   considering joint failure",
        "authors": [
            "Olaf Ambrozkiewicz",
            "Benedikt Kriegesmann"
        ],
        "summary": "This paper provides a method for the simultaneous topology optimization of parts and their corresponding joint locations in an assembly. Therein, the joint locations are not discrete and predefined, but continuously movable. The underlying coupling equations allow for connecting dissimilar meshes and avoid the need for remeshing when joint locations change. The presented method models the force transfer at a joint location not only by using single spring elements but accounts for the size and type of the joints. When considering riveted or bolted joints, the local part geometry at the joint location consists of holes that are surrounded by material. For spot welds, the joint locations are filled with material and may be smaller than for bolts. The presented method incorporates these material and clearance zones into the simultaneously running topology optimization of the parts. Furthermore, failure of joints may be taken into account at the optimization stage, yielding assemblies connected in a fail-safe manner.",
        "published": "2020-05-07T11:57:25Z",
        "link": "http://arxiv.org/abs/2005.03398v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Assessing the Precision and Recall of msTALI as Applied to an   Active-Site Study on Fold Families",
        "authors": [
            "Devaun McFarland",
            "Homayoun Valafar"
        ],
        "summary": "Proteins execute various activities required by biological cells. Further, they structurally support and pro-mote important biochemical reactions which functionally are sparked by active-sites. Active-sites are regions where reac-tions and binding events take place directly; they foster pro-tein purpose. Describing functional relationships depends on factors that incorporate sequence, structure, and the biochem-ical properties of amino acids that form proteins. Our ap-proach to active-site description is computational, and many other approaches utilizing available protein data fall short of ideal. Successful recognition of functional interactions is cru-cial to advancements in protein annotation and the bioinfor-matics field at large. This research outlines our Multiple Structure Torsion Angle Alignment (msTALI) as a suitable strategy for addressing active-site identification by comparing results to other existing methods. Specifically, we address the precision of msTALI across three protein families. Our target proteins are PDBIDs 1A2B, 1B4V, 1B8S, 1COY, 1CXZ, 3COX, 1D7E, 1DPF, 1F9I, 1FTN, 1IJH, 1KOU, 1NWZ, 2PHY, and 1SIC.",
        "published": "2020-05-07T22:03:57Z",
        "link": "http://arxiv.org/abs/2005.10739v1",
        "categories": [
            "q-bio.QM",
            "cs.CE"
        ]
    },
    {
        "title": "Construction of Minimum Spanning Trees from Financial Returns using Rank   Correlation",
        "authors": [
            "Tristan Millington",
            "Mahesan Niranjan"
        ],
        "summary": "The construction of minimum spanning trees (MSTs) from correlation matrices is an often used method to study relationships in the financial markets. However most of the work on this topic tends to use the Pearson correlation coefficient, which relies on the assumption of normality and can be brittle to the presence of outliers, neither of which is ideal for the study of financial returns. In this paper we study the inference of MSTs from daily US, UK and German financial returns using Pearson and two rank correlation methods, Spearman and Kendall's $\\tau$. MSTs constructed using these rank methods tend to be more stable and maintain more edges over the dataset than those constructed using Pearson correlation. The edge agreement between the Pearson and rank MSTs varies significantly depending on the state of the markets, but the rank MSTs generally show strong agreement at all times. Deviation from univariate normality can be related to changes in the correlation matrices but is more difficult to connect to changes in the MSTs. Irrelevant of coefficient, the trees tend to have similar topologies. Portfolios constructed from the MST correlation matrices have a smaller turnover than those from the full covariance matrix for the larger markets, but not for the smaller German market. Using a bootstrap method we find that the correlation matrices constructed using the rank correlations are more robust, but there is little difference between the robustness of the MSTs.",
        "published": "2020-05-08T11:27:15Z",
        "link": "http://arxiv.org/abs/2005.03963v2",
        "categories": [
            "cs.CE",
            "q-fin.ST"
        ]
    },
    {
        "title": "The Hetero-functional Graph Theory Toolbox",
        "authors": [
            "Dakota Thompson",
            "Prabhat Hegde",
            "Wester C. H. Schoonenberg",
            "Inas Khayal",
            "Amro M. Farid"
        ],
        "summary": "In the 20th century, newly invented technical artifacts were connected to form large-scale complex engineering systems. Furthermore, the interactions found within these networked systems has grown in both degree as well as heterogeneity. Consequently, these already complex engineering systems have converged in what is now called systems-of-systems. The analysis, design, planning, and operation of these engineering systems from a holistic perspective has necessitated ever-more sophisticated modeling techniques. Despite significant advancements in model-based systems engineering and network science, these seemingly disparate fields have experienced similar limitations in addressing the complexity of engineering systems. Hetero-Functional Graph Theory (HFGT) has emerged as a means to address some of these limitations. This paper serves as a user guide to a recently developed Hetero-functional Graph Theory Toolbox which facilitates the computation of HFGT mathematical models. It is written in the MATLAB language and has been tested with v9.6 (R2019a). It is openly available on GitHub together with a sample input file for straightforward re-use. The paper details the syntax and semantics of the input file, the principal data structure of the toolbox, and the functions used to construct and populate this data structure. The toolbox has been fully validated against several peer-review HFGT publications.",
        "published": "2020-05-08T15:10:59Z",
        "link": "http://arxiv.org/abs/2005.10006v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Parsimonious neural networks learn interpretable physical laws",
        "authors": [
            "Saaketh Desai",
            "Alejandro Strachan"
        ],
        "summary": "Machine learning is playing an increasing role in the physical sciences and significant progress has been made towards embedding domain knowledge into models. Less explored is its use to discover interpretable physical laws from data. We propose parsimonious neural networks (PNNs) that combine neural networks with evolutionary optimization to find models that balance accuracy with parsimony. The power and versatility of the approach is demonstrated by developing models for classical mechanics and to predict the melting temperature of materials from fundamental properties. In the first example, the resulting PNNs are easily interpretable as Newton's second law, expressed as a non-trivial time integrator that exhibits time-reversibility and conserves energy, where the parsimony is critical to extract underlying symmetries from the data. In the second case, the PNNs not only find the celebrated Lindemann melting law, but also new relationships that outperform it in the pareto sense of parsimony vs. accuracy.",
        "published": "2020-05-08T16:15:47Z",
        "link": "http://arxiv.org/abs/2005.11144v3",
        "categories": [
            "cs.LG",
            "cs.CE",
            "physics.comp-ph",
            "stat.ML"
        ]
    },
    {
        "title": "A finite-strain model for incomplete damage in elastoplastic materials",
        "authors": [
            "David Melching",
            "Michael Neunteufel",
            "Joachim Schöberl",
            "Ulisse Stefanelli"
        ],
        "summary": "We address a three-dimensional model capable of describing coupled damage and plastic effects in solids at finite strains. Formulated within the variational setting of {\\it generalized standard materials}, the constitutive model results from the balance of conservative and dissipative forces. Material response is rate-independent and associative and damage evolution is unidirectional. We assess the model features and performance on both uniaxial and non-proportional biaxial tests.   The constitutive model is then complemented with the quasistatic equilibrium system and initial and boundary conditions. We produce numerical simulations with the help of the powerful multiphysics finite element software NETGEN/NGSolve. We show the flexibility of the implementation and run simulations for various 2D and 3D settings under different choices of boundary conditions and possibly in presence of pre-damaged regions.",
        "published": "2020-05-11T09:52:23Z",
        "link": "http://arxiv.org/abs/2005.04965v1",
        "categories": [
            "math.AP",
            "cs.CE",
            "cs.NA",
            "math.NA",
            "74C15 (Primary) 74A45, 65N30, 35Q74, 49J40 (Secondary)"
        ]
    },
    {
        "title": "Conformally Mapped Polynomial Chaos Expansions for Maxwell's Source   Problem with Random Input Data",
        "authors": [
            "Niklas Georg",
            "Ulrich Römer"
        ],
        "summary": "Generalized Polynomial Chaos (gPC) expansions are well established for forward uncertainty propagation in many application areas. Although the associated computational effort may be reduced in comparison to Monte Carlo techniques, for instance, further convergence acceleration may be important to tackle problems with high parametric sensitivities. In this work, we propose the use of conformal maps to construct a transformed gPC basis, in order to enhance the convergence order. The proposed basis still features orthogonality properties and hence, facilitates the computation of many statistical properties such as sensitivities and moments. The corresponding surrogate models are computed by pseudo-spectral projection using mapped quadrature rules, which leads to an improved cost accuracy ratio. We apply the methodology to Maxwell's source problem with random input data. In particular, numerical results for a parametric finite element model of an optical grating coupler are given.",
        "published": "2020-05-11T14:43:58Z",
        "link": "http://arxiv.org/abs/2005.05152v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Simplified ResNet approach for data driven prediction of   microstructure-fatigue relationship",
        "authors": [
            "Christian Gebhardt",
            "Torsten Trimborn",
            "Felix Weber",
            "Alexander Bezold",
            "Christoph Broeckmann",
            "Michael Herty"
        ],
        "summary": "The heterogeneous microstructure in metallic components results in locally varying fatigue strength. Metal fatigue strongly depends on size and shape of non-metallic inclusions and pores, commonly referred to as \"defects\". Nodular cast iron (NCI) contains graphite inclusions (nodules) whose shape and frequency influence the fatigue strength. Fatigue strength can be simulated by micromechanical finite element models. The drawback of these models are the large computational costs. Therefore, we employ a data-driven machine learning methodology. More precisely, we utilize the simplified residual neural network (SimResNet) which was recently introduced (Herty et al., Kinetic Theory for Residual Neural Networks, 2020) to predict fatigue strength from metallographic data. For the training, we use fatigue data which is simulated with a micromechanical model and the shakedown theorem. The micromechanical models are derived directly from micrographs of nodular cast iron, respectively. The application of SimResNet shows a good performance to predict fatigue strength by local microstructures of nodular cast iron. We show several test cases. The simplified character of SimResNet enables fast predictions of fatigue by microstructures, even in comparision to classical residual neural networks.",
        "published": "2020-05-11T22:23:59Z",
        "link": "http://arxiv.org/abs/2005.06615v1",
        "categories": [
            "cs.CE",
            "cond-mat.mtrl-sci"
        ]
    },
    {
        "title": "Non-equilibrium transport of inhomogeneous shale gas under ultra-tight   confinement",
        "authors": [
            "Baochao Shan",
            "Runxi Wang",
            "Peng Wang",
            "Yonghao Zhang",
            "Liehui Zhang",
            "Zhaoli Guo"
        ],
        "summary": "The non-equilibrium transport of inhomogeneous and dense gases highly confined by surface is encountered in many engineering applications. For example, in the shale gas production process, methane is extracted from ultra-tight pores under high pressure so the gas is inhomogeneous and dense. Currently, the complex non-equilibrium transport of inhomogeneous and dense gases where gas surface interactions play a key role is commonly investigated by molecular dynamics or on a continuum-assumption basis. Here, a tractable kinetic model based on the generalized Enskog equation and the mean-field theory is employed to couple the effects of the volume exclusion and the long-range intermolecular attraction forces. The interactions between gas molecules and confined surface are modelled by a 10-4-3 Lennard-Jones potential, which can capture gas surface adsorption. The cross-sectional density profiles of methane under different confinements are in good agreement with the molecular dynamics results reported in the literature, and the transport behaviors are validated by the non-equilibrium molecular dynamics. The velocity of methane flow in shale matrix is plug-like due to its dense characteristics in nanopores. The influence of pressure, temperature, pore size and shale composition on density and velocity profiles is analyzed quantitatively. Our results show that the Klinkenberg correction is not applicable to model shale gas flow in the production process; the Navier-Stokes model using the second-order slip boundary condition cannot produce the proper velocity profiles, and consequently fails to predict the accurate flow rate in nanopores. This study sheds new light on understanding the physics of non-equilibrium dense gas flows in shale strata.",
        "published": "2020-05-12T08:57:58Z",
        "link": "http://arxiv.org/abs/2005.05622v1",
        "categories": [
            "physics.geo-ph",
            "cs.CE"
        ]
    },
    {
        "title": "On Idle Energy Consumption Minimization in Production: Industrial   Example and Mathematical Model",
        "authors": [
            "Ondřej Benedikt",
            "Přemysl Šůcha",
            "Zdeněk Hanzálek"
        ],
        "summary": "This paper, inspired by a real production process of steel hardening, investigates a scheduling problem to minimize the idle energy consumption of machines. The energy minimization is achieved by switching a machine to some power-saving mode when it is idle. For the steel hardening process, the mode of the machine (i.e., furnace) can be associated with its inner temperature. Contrary to the recent methods, which consider only a small number of machine modes, the temperature in the furnace can be changed continuously, and so an infinite number of the power-saving modes must be considered to achieve the highest possible savings. To model the machine modes efficiently, we use the concept of the energy function, which was originally introduced in the domain of embedded systems but has yet to take roots in the domain of production research. The energy function is illustrated with several application examples from the literature. Afterward, it is integrated into a mathematical model of a scheduling problem with parallel identical machines and jobs characterized by release times, deadlines, and processing times. Numerical experiments show that the proposed model outperforms a reference model adapted from the literature.",
        "published": "2020-05-12T11:44:44Z",
        "link": "http://arxiv.org/abs/2005.06270v1",
        "categories": [
            "cs.CE",
            "math.OC"
        ]
    },
    {
        "title": "Heterogeneous CPU/GPU co-execution of CFD simulations on the POWER9   architecture: Application to airplane aerodynamics",
        "authors": [
            "R. Borrell",
            "D. Dosimont",
            "M. Garcia-Gasulla",
            "G. Houzeaux",
            "O. Lehmkuhl",
            "V. Mehta",
            "H. Owen",
            "M. Vazquez",
            "G. Oyarzun"
        ],
        "summary": "High fidelity Computational Fluid Dynamics simulations are generally associated with large computing requirements, which are progressively acute with each new generation of supercomputers. However, significant research efforts are required to unlock the computing power of leading-edge systems, currently referred to as pre-Exascale systems, based on increasingly complex architectures. In this paper, we present the approach implemented in the computational mechanics code Alya. We describe in detail the parallelization strategy implemented to fully exploit the different levels of parallelism, together with a novel co-execution method for the efficient utilization of heterogeneous CPU/GPU architectures. The latter is based on a multi-code co-execution approach with a dynamic load balancing mechanism. The assessment of the performance of all the proposed strategies has been carried out for airplane simulations on the POWER9 architecture accelerated with NVIDIA Volta V100 GPUs.",
        "published": "2020-05-12T16:21:39Z",
        "link": "http://arxiv.org/abs/2005.05899v3",
        "categories": [
            "cs.DC",
            "cs.CE"
        ]
    },
    {
        "title": "Sliding Basis Optimization for Heterogeneous Material Design",
        "authors": [
            "Nurcan Gecer Ulu",
            "Svyatoslav Korneev",
            "Erva Ulu",
            "Saigopal Nelaturi"
        ],
        "summary": "We present the sliding basis computational framework to automatically synthesize heterogeneous (graded or discrete) material fields for parts designed using constrained optimization. Our framework uses the fact that any spatially varying material field over a given domain may be parameterized as a weighted sum of the Laplacian eigenfunctions enabling efficient design space exploration with the weights as a small set of design variables. We further improve computational efficiency by using the property that the Laplacian eigenfunctions form a spectrum and may be ordered from lower to higher frequencies. This approach allows greater localized control of the material distribution as the sliding window moves through higher frequencies. The approach also reduces the number of optimization variables per iteration, thus the design optimization process speeds up independent of the domain resolution without sacrificing analysis quality. Our method is most beneficial when the gradients may not be computed easily (i.e., optimization problems coupled with external black-box analysis) thereby enabling optimization of otherwise intractable design problems. The sliding basis framework is independent of any particular physics analysis, objective and constraints, providing a versatile and powerful design optimization tool for various applications. We demonstrate our approach on graded solid rocket fuel design and multi-material topology optimization applications and evaluate its performance.",
        "published": "2020-05-13T22:10:53Z",
        "link": "http://arxiv.org/abs/2005.08838v1",
        "categories": [
            "cs.CE",
            "cs.CG"
        ]
    },
    {
        "title": "A New Meshless \"Fragile Points Method (FPM)\" Based on A Galerkin   Weak-Form for 2D Flexoelectric Analysis",
        "authors": [
            "Yue Guan",
            "Leiting Dong",
            "Satya N. Atluri"
        ],
        "summary": "A meshless Fragile Points Method (FPM) is presented for analyzing 2D flexoelectric problems. Local, simple, polynomial and discontinuous trial and test functions are generated with the help of a local meshless differential quadrature approximation of the first three derivatives. Interior Penalty Numerical Fluxes are employed to ensure the consistency of the method. Based on a Galerkin weak-form formulation, the present FPM leads to symmetric and sparse matrices, and avoids the difficulties of numerical integration in the previous meshfree methods. Numerical examples including isotropic and anisotropic materials with flexoelectric and piezoelectric effects are provided as validations. The present method is much simpler than the Finite Element Method, or the Element-Free Galerkin (EFG) and Meshless Local Petrov-Galerkin (MLPG) methods, and the numerical integration of the weak form is trivially simple.",
        "published": "2020-05-14T14:13:19Z",
        "link": "http://arxiv.org/abs/2005.08839v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "An Artificial-intelligence/Statistics Solution to Quantify Material   Distortion for Thermal Compensation in Additive Manufacturing",
        "authors": [
            "Chao Wang",
            "Shaofan Li",
            "Danielle Zeng",
            "Xinhai Zhu"
        ],
        "summary": "In this paper, we introduce a probabilistic statistics solution or artificial intelligence (AI) approach to identify and quantify permanent (non-zero strain) continuum/material deformation only based on the scanned material data in the spatial configuration and the shape of the initial design configuration or the material configuration. The challenge of this problem is that we only know the scanned material data in the spatial configuration and the shape of the design configuration of three-dimensional (3D) printed products, whereas for a specific scanned material point we do not know its corresponding material coordinates in the initial or designed referential configuration, provided that we do not know the detailed information on actual physical deformation process. Different from physics-based modeling, the method developed here is a data-driven artificial intelligence method, which solves the problem with incomplete deformation data or with missing information of actual physical deformation process. We coined the method is an AI-based material deformation finding algorithm.   This method has practical significance and important applications in finding and designing thermal compensation configuration of a 3D printed product in additive manufacturing, which is at the heart of the cutting edge 3D printing technology. In this paper, we demonstrate that the proposed AI continuum/material deformation finding approach can accurately find permanent thermal deformation configuration for a complex 3D printed structure component, and hence to identify the thermal compensation design configuration in order to minimizing the impact of temperature fluctuations on 3D printed structure components that are sensitive to changes of temperature.",
        "published": "2020-05-14T20:02:47Z",
        "link": "http://arxiv.org/abs/2005.09084v1",
        "categories": [
            "cs.CE",
            "cs.CV"
        ]
    },
    {
        "title": "Simple and robust element-free Galerkin method with interpolating shape   functions for finite deformation elasticity",
        "authors": [
            "George Bourantas",
            "Benjamin F. Zwick",
            "Grand Joldes",
            "Adam Wittek",
            "Karol Miller"
        ],
        "summary": "In this paper, we present a meshless method belonging to the family of element-free Galerkin (EFG) methods. The distinguishing feature of the presented meshless method is that it allows accurate enforcement of essential boundary conditions. The method uses total Lagrangian formulation with explicit time integration to facilitate code simplicity and robust computations in applications that involve large deformations and non-linear materials. We use a regularized weight function, which closely approximates the Kronecker delta, to generate interpolating shape functions. The imposition of the prescribed displacements on the boundary becomes as straightforward as in the finite element (FE) method. The effectiveness and accuracy of the proposed method is demonstrated using 3D numerical examples that include cylinder indentation by 70% of its initial height, and indentation of the brain.",
        "published": "2020-05-15T00:58:57Z",
        "link": "http://arxiv.org/abs/2005.09075v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A Nonlocal Model for Dislocations with Embedded Discontinuity   Peridynamics",
        "authors": [
            "Teng Zhao",
            "Yongxing Shen"
        ],
        "summary": "We develop a novel nonlocal model of dislocations based on the framework of peridynamics. By embedding interior discontinuities into the nonlocal constitutive law, the displacement jump in the Volterra dislocation model is reproduced, intrinsic singularities in classical elasticity are regularized, and the surface effect in previous peridynamics models is avoided. The extended embedded discontinuity peridynamics overcomes unphysical dissipation in treating discontinuity and is still easy to be solved with the particle-based meshless method. The properties of the proposed dislocation model are compared with classical elasticity solutions under the case of an edge dislocation, double edge dislocations, a screw dislocation and a circular dislocation loop. Numerical results show a high consistency in displacement field while no singularity appears in the peridynamics model, the interaction force is in agreement with be the Peach-Koehler formula down to the core region and high accuracy can be reached in 3D with limited computation cost. The proposed model provides a feasible tool for multiscale modeling of dislocations. Though dislocation is modeled as pre-defined displacement jump, it is straightforward to extend the method to model various fracture conditions.",
        "published": "2020-05-15T12:29:14Z",
        "link": "http://arxiv.org/abs/2005.09076v1",
        "categories": [
            "cs.CE",
            "74A70"
        ]
    },
    {
        "title": "Kaemika app, Integrating protocols and chemical simulation",
        "authors": [
            "Luca Cardelli"
        ],
        "summary": "Kaemika is an app available on the four major app stores. It provides deterministic and stochastic simulation, supporting natural chemical notation enhanced with recursive and conditional generation of chemical reaction networks. It has a liquid-handling protocol sublanguage compiled to a virtual digital microfluidic device. Chemical and microfluidic simulations can be interleaved for full experimental-cycle modeling. A novel and unambiguous representation of directed multigraphs is used to lay out chemical reaction networks in graphical form.",
        "published": "2020-05-16T20:47:07Z",
        "link": "http://arxiv.org/abs/2005.08097v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "An Efficient Machine-Learning Approach for PDF Tabulation in Turbulent   Combustion Closure",
        "authors": [
            "Rishikesh Ranade",
            "Genong Li",
            "Shaoping Li",
            "Tarek Echekki"
        ],
        "summary": "Probability density function (PDF) based turbulent combustion modelling is limited by the need to store multi-dimensional PDF tables that can take up large amounts of memory. A significant saving in storage can be achieved by using various machine-learning techniques that represent the thermo-chemical quantities of a PDF table using mathematical functions. These functions can be computationally more expensive than the existing interpolation methods used for thermo-chemical quantities. More importantly, the training time can amount to a considerable portion of the simulation time. In this work, we address these issues by introducing an adaptive training algorithm that relies on multi-layer perception (MLP) neural networks for regression and self-organizing maps (SOMs) for clustering data to tabulate using different networks. The algorithm is designed to address both the multi-dimensionality of the PDF table as well as the computational efficiency of the proposed algorithm. SOM clustering divides the PDF table into several parts based on similarities in data. Each cluster of data is trained using an MLP algorithm on simple network architectures to generate local functions for thermo-chemical quantities. The algorithm is validated for the so-called DLR-A turbulent jet diffusion flame using both RANS and LES simulations and the results of the PDF tabulation are compared to the standard linear interpolation method. The comparison yields a very good agreement between the two tabulation techniques and establishes the MLP-SOM approach as a viable method for PDF tabulation.",
        "published": "2020-05-18T00:13:55Z",
        "link": "http://arxiv.org/abs/2005.09747v1",
        "categories": [
            "cs.CE",
            "cs.LG",
            "physics.flu-dyn"
        ]
    },
    {
        "title": "Modeling extra-deep electromagnetic logs using a deep neural network",
        "authors": [
            "Sergey Alyaev",
            "Mostafa Shahriari",
            "David Pardo",
            "Angel Javier Omella",
            "David Larsen",
            "Nazanin Jahani",
            "Erich Suter"
        ],
        "summary": "Modern geosteering is heavily dependent on real-time interpretation of deep electromagnetic (EM) measurements. We present a methodology to construct a deep neural network (DNN) model trained to reproduce a full set of extra-deep EM logs consisting of 22 measurements per logging position. The model is trained in a 1D layered environment consisting of up to seven layers with different resistivity values. A commercial simulator provided by a tool vendor is used to generate a training dataset. The dataset size is limited because the simulator provided by the vendor is optimized for sequential execution. Therefore, we design a training dataset that embraces the geological rules and geosteering specifics supported by the forward model. We use this dataset to produce an EM simulator based on a DNN without access to the proprietary information about the EM tool configuration or the original simulator source code. Despite employing a relatively small training set size, the resulting DNN forward model is quite accurate for the considered examples: a multi-layer synthetic case and a section of a published historical operation from the Goliat Field. The observed average evaluation time of 0.15 ms per logging position makes it also suitable for future use as part of evaluation-hungry statistical and/or Monte-Carlo inversion algorithms within geosteering workflows.",
        "published": "2020-05-18T17:45:46Z",
        "link": "http://arxiv.org/abs/2005.08919v3",
        "categories": [
            "eess.SP",
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "Topology optimization of nonlinear periodically microstructured   materials for tailored homogenized constitutive properties",
        "authors": [
            "Reza Behrou",
            "Maroun Abi Ghanem",
            "Brianna C. Macnider",
            "Vimarsh Verma",
            "Ryan Alvey",
            "Jinho Hong",
            "Ashley F. Emery",
            "Hyunsun Alicia Kim",
            "Nicholas Boechler"
        ],
        "summary": "A topology optimization method is presented for the design of periodic microstructured materials with prescribed homogenized nonlinear constitutive properties over finite strain ranges. The mechanical model assumes linear elastic isotropic materials, geometric nonlinearity at finite strain, and a quasi-static response. The optimization problem is solved by a nonlinear programming method and the sensitivities computed via the adjoint method. Two-dimensional structures identified using this optimization method are additively manufactured and their uniaxial tensile strain response compared with the numerically predicted behavior. The optimization approach herein enables the design and development of lattice-like materials with prescribed nonlinear effective properties, for use in myriad potential applications, ranging from stress wave and vibration mitigation to soft robotics.",
        "published": "2020-05-18T22:02:20Z",
        "link": "http://arxiv.org/abs/2005.09111v1",
        "categories": [
            "cs.CE",
            "math.OC"
        ]
    },
    {
        "title": "Towards a Generalized Approach to Nonlocal Elasticity via   Fractional-Order Mechanics",
        "authors": [
            "Sansit Patnaik",
            "Sai Sidhardh",
            "Fabio Semperlotti"
        ],
        "summary": "This study presents a fractional-order continuum mechanics approach that allows combining selected characteristics of nonlocal elasticity, typical of classical integral and gradient formulations, under a single frame-invariant framework. The resulting generalized theory is capable of capturing both stiffening and softening effects and it is not subject to the inconsistencies often observed under selected external loads and boundary conditions. The governing equations of a 1D continuum are derived by continualization of the Lagrangian of a 1D lattice subject to long-range interactions. This approach is particularly well suited to highlight the connection between the fractional-order operators and the microscopic properties of the medium. The approach is also extended to derive, by means of variational principles, the governing equations of a 3D continuum in strong form. The positive definite potential energy, characteristic of our fractional formulation, always ensures well-posed governing equations. This aspect, combined with the differ-integral nature of fractional-order operators, guarantees both stability and the ability to capture dispersion without requiring additional inertia gradient terms. The proposed formulation is applied to the static and free vibration analyses of either Timoshenko beams or Mindlin plates. Numerical results, obtained by a fractional-order finite element method, show that the fractional-order formulation is able to model both stiffening and softening response in these slender structures. The numerical results provide the foundation to critically analyze the physical significance of the different fractional model parameters as well as their effect on the response of the structural elements.",
        "published": "2020-05-19T03:59:47Z",
        "link": "http://arxiv.org/abs/2005.10079v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "math.DS"
        ]
    },
    {
        "title": "SEMDOT: Smooth-Edged Material Distribution for Optimizing Topology   Algorithm",
        "authors": [
            "Yun-Fei Fu",
            "Bernard Rolfe",
            "Ngai Sum Louis Chiu",
            "Yanan Wang",
            "Xiaodong Huang",
            "Kazem Ghabraie"
        ],
        "summary": "Element-based topology optimization algorithms capable of generating smooth boundaries have drawn serious attention given the significance of accurate boundary information in engineering applications. The basic framework of a new element-based continuum algorithm is proposed in this paper. This algorithm is based on a smooth-edged material distribution strategy that uses solid/void grid points assigned to each element. Named Smooth-Edged Material Distribution for Optimizing Topology (SEMDOT), the algorithm uses elemental volume fractions which depend on the densities of grid points in the Finite Element Analysis (FEA) model rather than elemental densities. Several numerical examples are studied to demonstrate the application and effectiveness of SEMDOT. In these examples, SEMDOT proved to be capable of obtaining optimized topologies with smooth and clear boundaries showing better or comparable performance compared to other topology optimization methods. Through these examples, first, the advantages of using the Heaviside smooth function are discussed in comparison to the Heaviside step function. Then, the benefits of introducing multiple filtering steps in this algorithm are shown. Finally, comparisons are conducted to exhibit the differences between SEMDOT and some well-established element-based algorithms. The validation of the sensitivity analysis method adopted in SEMDOT is conducted using a typical compliant mechanism design case. In addition, this paper provides the Matlab code of SEMDOT for educational and academic purposes.",
        "published": "2020-05-19T06:03:40Z",
        "link": "http://arxiv.org/abs/2005.09233v3",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "On the Bound of Cumulative Return in Trading Series and the Verification   Using Technical Trading Rules",
        "authors": [
            "Can Yang",
            "Junjie Zhai",
            "Helong Li"
        ],
        "summary": "Although there is a wide use of technical trading rules in stock markets, the profitability of them still remains controversial. This paper first presents and proves the upper bound of cumulative return, and then introduces many of conventional technical trading rules. Furthermore, with the help of bootstrap methodology, we investigate the profitability of technical trading rules on different international stock markets, including developed markets and emerging markets. At last, the results show that the technical trading rules are hard to beat the market, and even less profitable than the random trading strategy.",
        "published": "2020-05-19T09:40:32Z",
        "link": "http://arxiv.org/abs/2005.13974v1",
        "categories": [
            "q-fin.ST",
            "cs.CE",
            "stat.OT"
        ]
    },
    {
        "title": "SINDy-BVP: Sparse Identification of Nonlinear Dynamics for Boundary   Value Problems",
        "authors": [
            "Daniel E. Shea",
            "Steven L. Brunton",
            "J. Nathan Kutz"
        ],
        "summary": "We develop a data-driven model discovery and system identification technique for spatially-dependent boundary value problems (BVPs). Specifically, we leverage the sparse identification of nonlinear dynamics (SINDy) algorithm and group sparse regression techniques with a set of forcing functions and corresponding state variable measurements to yield a parsimonious model of the system. The approach models forced systems governed by linear or nonlinear operators of the form $L[u(x)] = f(x)$ on a prescribed domain $x \\in [a, b]$. We demonstrate the approach on a range of example systems, including Sturm-Liouville operators, beam theory (elasticity), and a class of nonlinear BVPs. The generated data-driven model is used to infer both the operator and/or spatially-dependent parameters that describe the heterogenous, physical quantities of the system. Our SINDy-BVP framework will enables the characterization of a broad range of systems, including for instance, the discovery of anisotropic materials with heterogeneous variability.",
        "published": "2020-05-19T19:23:43Z",
        "link": "http://arxiv.org/abs/2005.10756v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A simple extrapolated predictor for overcoming the starting and tracking   issues in the arc-length method for nonlinear structural mechanics",
        "authors": [
            "Chennakesava Kadapa"
        ],
        "summary": "This paper presents a simplified implementation of the arc-length method for computing the equilibrium paths of nonlinear structural mechanics problems using the finite element method. In the proposed technique, the predictor is computed by extrapolating the solutions from two previously converged load steps. The extrapolation is a linear combination of the previous solutions; therefore, it is simple and inexpensive. Additionally, the proposed extrapolated predictor also serves as a means for identifying the forward movement along the equilibrium path without the need for any sophisticated techniques commonly employed for explicit tracking. The ability of the proposed technique to successfully compute complex equilibrium paths in static structural mechanics problems is demonstrated using seven numerical examples involving truss, beam-column and shell models. The computed numerical results are in excellent agreement with the reference solutions. The present approach does not require prohibitively small increments for its success.",
        "published": "2020-05-20T16:57:46Z",
        "link": "http://arxiv.org/abs/2005.10192v2",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Inverse Estimation of Elastic Modulus Using Physics-Informed Generative   Adversarial Networks",
        "authors": [
            "James E. Warner",
            "Julian Cuevas",
            "Geoffrey F. Bomarito",
            "Patrick E. Leser",
            "William P. Leser"
        ],
        "summary": "While standard generative adversarial networks (GANs) rely solely on training data to learn unknown probability distributions, physics-informed GANs (PI-GANs) encode physical laws in the form of stochastic partial differential equations (PDEs) using auto differentiation. By relating observed data to unobserved quantities of interest through PDEs, PI-GANs allow for the estimation of underlying probability distributions without their direct measurement (i.e. inverse problems). The scalable nature of GANs allows high-dimensional, spatially-dependent probability distributions (i.e., random fields) to be inferred, while incorporating prior information through PDEs allows the training datasets to be relatively small.   In this work, PI-GANs are demonstrated for the application of elastic modulus estimation in mechanical testing. Given measured deformation data, the underlying probability distribution of spatially-varying elastic modulus (stiffness) is learned. Two feed-forward deep neural network generators are used to model the deformation and material stiffness across a two dimensional domain. Wasserstein GANs with gradient penalty are employed for enhanced stability. In the absence of explicit training data, it is demonstrated that the PI-GAN learns to generate realistic, physically-admissible realizations of material stiffness by incorporating the PDE that relates it to the measured deformation. It is shown that the statistics (mean, standard deviation, point-wise distributions, correlation length) of these generated stiffness samples have good agreement with the true distribution.",
        "published": "2020-05-20T20:14:10Z",
        "link": "http://arxiv.org/abs/2006.05791v1",
        "categories": [
            "eess.IV",
            "cs.CE",
            "cs.LG",
            "stat.AP",
            "stat.ML"
        ]
    },
    {
        "title": "Matrix moments of the diffusion tensor distribution",
        "authors": [
            "A. Reymbaut"
        ],
        "summary": "Purpose: To facilitate the implementation/validation of signal representations and models using parametric matrix-variate distributions to approximate the diffusion tensor distribution (DTD) $\\mathcal{P}(\\mathbf{D})$. Theory: We establish practical mathematical tools, the matrix moments of the DTD, enabling to compute the mean diffusion tensor and covariance tensor associated with any parametric matrix-variate DTD whose moment-generating function is known. As a proof of concept, we apply these tools to the non-central matrix-variate Gamma (nc-mv-Gamma) distribution, whose covariance tensor was so far unknown, and design a new signal representation capturing intra-voxel heterogeneity via a single nc-mv-Gamma distribution: the matrix-variate Gamma approximation. Methods: Furthering this proof of concept, we evaluate the matrix-variate Gamma approximation in silico and in vivo, in a human-brain 'tensor-valued' diffusion MRI dataset. Results: The matrix-variate Gamma approximation fails to capture the heterogeneity arising from orientation dispersion and from simultaneous variances in the trace (size) and anisotropy (shape) of the underlying diffusion tensors, which is explained by the structure of the covariance tensor associated with the nc-mv-Gamma distribution. Conclusion: The matrix moments promote a more widespread use of matrix-variate distributions as plausible approximations of the DTD by alleviating their intractability, thereby facilitating the design/validation of matrix-variate microstructural techniques.",
        "published": "2020-05-21T00:33:00Z",
        "link": "http://arxiv.org/abs/2005.11280v1",
        "categories": [
            "cs.CE",
            "physics.med-ph"
        ]
    },
    {
        "title": "Detecting and explaining changes in various assets' relationships in   financial markets",
        "authors": [
            "Makoto Naraoka",
            "Teruaki Hayashi",
            "Takaaki Yoshino",
            "Toshiaki Sugie",
            "Kota Takano",
            "Yukio Ohsawa"
        ],
        "summary": "We study the method for detecting relationship changes in financial markets and providing human-interpretable network visualization to support the decision-making of fund managers dealing with multi-assets. First, we construct co-occurrence networks with each asset as a node and a pair with a strong relationship in price change as an edge at each time step. Second, we calculate Graph-Based Entropy to represent the variety of price changes based on the network. Third, we apply the Differential Network to finance, which is traditionally used in the field of bioinformatics. By the method described above, we can visualize when and what kind of changes are occurring in the financial market, and which assets play a central role in changes in financial markets. Experiments with multi-asset time-series data showed results that were well fit with actual events while maintaining high interpretability. It is suggested that this approach is useful for fund managers to use as a new option for decision making.",
        "published": "2020-05-21T12:33:43Z",
        "link": "http://arxiv.org/abs/2005.10603v4",
        "categories": [
            "q-fin.GN",
            "cs.CE"
        ]
    },
    {
        "title": "Solving a steady-state PDE using spiking networks and neuromorphic   hardware",
        "authors": [
            "J. Darby Smith",
            "William Severa",
            "Aaron J. Hill",
            "Leah Reeder",
            "Brian Franke",
            "Richard B. Lehoucq",
            "Ojas D. Parekh",
            "James B. Aimone"
        ],
        "summary": "The widely parallel, spiking neural networks of neuromorphic processors can enable computationally powerful formulations. While recent interest has focused on primarily machine learning tasks, the space of appropriate applications is wide and continually expanding. Here, we leverage the parallel and event-driven structure to solve a steady state heat equation using a random walk method. The random walk can be executed fully within a spiking neural network using stochastic neuron behavior, and we provide results from both IBM TrueNorth and Intel Loihi implementations. Additionally, we position this algorithm as a potential scalable benchmark for neuromorphic systems.",
        "published": "2020-05-21T21:06:19Z",
        "link": "http://arxiv.org/abs/2005.10904v1",
        "categories": [
            "cs.NE",
            "cs.CE"
        ]
    },
    {
        "title": "HPC compact quasi-Newton algorithm for interface problems",
        "authors": [
            "A. Santiago",
            "M. Zavala-Aké",
            "R. Borell",
            "G. Houzeaux"
        ],
        "summary": "In this work we present a robust interface coupling algorithm called Compact Interface quasi-Newton (CIQN). It is designed for computationally intensive applications using an MPI multi-code partitioned scheme. The algorithm allows to reuse information from previous time steps, feature that has been previously proposed to accelerate convergence. Through algebraic manipulation, an efficient usage of the computational resources is achieved by: avoiding construction of dense matrices and reduce every multiplication to a matrix-vector product and reusing the computationally expensive loops. This leads to a compact version of the original quasi-Newton algorithm. Altogether with an efficient communication, in this paper we show an efficient scalability up to 4800 cores. Three examples with qualitatively different dynamics are shown to prove that the algorithm can efficiently deal with added mass instability and two-field coupled problems. We also show how reusing histories and filtering does not necessarily makes a more robust scheme and, finally, we prove the necessity of this HPC version of the algorithm. The novelty of this article lies in the HPC focused implementation of the algorithm, detailing how to fuse and combine the composing blocks to obtain an scalable MPI implementation. Such an implementation is mandatory in large scale cases, for which the contact surface cannot be stored in a single computational node, or the number of contact nodes is not negligible compared with the size of the domain. \\c{opyright} <2020> Elsevier. This manuscript version is made available under the CC-BY-NC-ND 4.0 license http://creativecommons.org/licenses/by-nc-nd/4.0/",
        "published": "2020-05-22T06:36:43Z",
        "link": "http://arxiv.org/abs/2005.13439v2",
        "categories": [
            "cs.CE",
            "68U20, 00A72, 68Q85, 65-04, 74F10"
        ]
    },
    {
        "title": "Peri-Net-Pro: The neural processes with quantified uncertainty for crack   patterns",
        "authors": [
            "Moonseop Kim",
            "Guang Lin"
        ],
        "summary": "This paper uses the peridynamic theory, which is well-suited to crack studies, to predict the crack patterns in a moving disk and classify them according to the modes and finally perform regression analysis. In that way, the crack patterns are obtained according to each mode by Molecular Dynamic (MD) simulation using the peridynamics. Image classification and regression studies are conducted through Convolutional Neural Networks (CNNs) and the neural processes. First, we increased the amount and quality of the data using peridynamics, which can theoretically compensate for the problems of the finite element method (FEM) in generating crack pattern images. Second, we did the case study for the PMB, LPS, and VES models that were obtained using the peridynamic theory. Case studies were performed to classify the images using CNNs and determine the PMB, LBS, and VES models' suitability. Finally, we performed the regression analysis for the images of the crack patterns with neural processes to predict the crack patterns. In the regression problem, by representing the results of the variance according to the epochs, it can be confirmed that the result of the variance is decreased by increasing the epoch numbers through the neural processes. The most critical point of this study is that the neural processes make an accurate prediction even if there are missing or insufficient training data.",
        "published": "2020-05-23T06:33:37Z",
        "link": "http://arxiv.org/abs/2005.13461v1",
        "categories": [
            "cs.CE",
            "stat.ML"
        ]
    },
    {
        "title": "3D CA model of tumor-induced angiogenesis",
        "authors": [
            "Monjoy Saha",
            "Amit Kumar Ray",
            "Swapan Kumar Basu"
        ],
        "summary": "Tumor-induced angiogenesis is the formation of new sprouts from preexisting nearby parent blood vessels. Computationally, tumor-induced angiogenesis can be modeled using cellular automata (CA), partial differential equations, etc. In this present study, a realistic physiological approach has been made to model the process of angiogenesis by using 3D CA model. CA technique uses various neighborhoods like Von-Neumann neighborhood, Moore neighborhood, and Margolus neighborhood. In our model Von-Neumann neighborhood has used for distribution of some significant chemical and non-chemical tumor angiogenic factors like vascular endothelial growth factor, endothelial cells, O2, extracellular matrix, fibronectin, etc., and Moore neighborhood is used for distribution of matrix metalloproteinase. In vivo tumor environment all the factors are not distributed equally in the extracellular matrix. Distributions of those chemical and nonchemical factors depend on their source, nature and function. To keep similarity with the biological tumor environment, we have formulated initial distributions of the chemical and non-chemical factors accordingly. We have started the simulation in MATLAB with this initial distribution. Number of sprouts randomly varies from one run to another. We observed that sprouts are not originating from the same locations in each simulation. A sprout has high sensitivity of VEGF and fibronectin concentrations. sVEGFR-1 always tries to regress the sprout. When two or more sprouts come closer, they merge with each other leading to anastomosis. Sufficient number of tip cells may cause sprout towards tumor.",
        "published": "2020-05-25T03:50:24Z",
        "link": "http://arxiv.org/abs/2005.12852v1",
        "categories": [
            "q-bio.OT",
            "cs.CE"
        ]
    },
    {
        "title": "Semi-Submersible Wind Turbine Hull Shape Design for a Favorable System   Response Behavior",
        "authors": [
            "Frank Lemmer",
            "Wei Yu",
            "Kolja Müller",
            "Po Wen Cheng"
        ],
        "summary": "Floating offshore wind turbines are a novel technology, which has reached, with the first wind farm in operation, an advanced state of development. The question of how floating wind systems can be optimized to operate smoothly in harsh wind and wave conditions is the subject of the present work. An integrated optimization was conducted, where the hull shape of a semi-submersible, as well as the wind turbine controller were varied with the goal of finding a cost-efficient design, which does not respond to wind and wave excitations, resulting in small structural fatigue and extreme loads. The optimum design was found to have a remarkably low tower-base fatigue load response and small rotor fore-aft amplitudes. Further investigations showed that the reason for the good dynamic behavior is a particularly favorable response to first-order wave loads: The floating wind turbine rotates in pitch-direction about a point close to the rotor hub and the rotor fore-aft motion is almost unaffected by the wave excitation. As a result, the power production and the blade loads are not influenced by the waves. A comparable effect was so far known for Tension Leg Platforms but not for semi-submersible wind turbines. The methodology builds on a low-order simulation model, coupled to a parametric panel code model, a detailed viscous drag model and an individually tuned blade pitch controller. The results are confirmed by the higher-fidelity model FAST. A new indicator to express the optimal behavior through a single design criterion has been developed.",
        "published": "2020-05-25T11:39:35Z",
        "link": "http://arxiv.org/abs/2005.13440v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Otimizacao e Processos Estocasticos Aplicados a Economia e Financas",
        "authors": [
            "Julio Michael Stern",
            "Carlos Alberto de Braganca Pereira",
            "Celma de Oliveira Ribeiro",
            "Cibele Dunder",
            "Fabio Nakano",
            "Marcelo Lauretto"
        ],
        "summary": "Optimization and Stochastic Processes Applied to Economy and Finance -- is the name of this book translated to English; It has been used at the IME-USP - The Institute of Mathematics and Statistics of the University of Sao Paulo, since 1993.   Contents: Ch.1: Linear Programming; Ch.2: Non-Linear Programming; Ch.3: Quadratic Programming; Ch.4: Markowitz Model; Ch.5: Dynamic Programming; Ch.6: LQG Estimation and Control; Ch.7: Decision Trees; Ch.8: Pension Funds; Ch.9: Mixed Portfolios Including Derivative Contracts; Appendices: App.A: Matlab; App.B: Critical-Point Software; App.C: Computational Linear Algebra; App.D: Probability; App.E: Computer Codes.   This book is written in Portuguese language.",
        "published": "2020-05-25T21:30:29Z",
        "link": "http://arxiv.org/abs/2005.13459v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "How the planned V0 railway line would increase the resilience of the   railway network of Hungary against attacks",
        "authors": [
            "B. G. Tóth",
            "I. Horváth"
        ],
        "summary": "The spatial distribution of the railway crossings on the river Danube in Hungary is very uneven. There is only one electrified and double-tracked bridge in the country, the Southern Railway Bridge in Budapest. The \\'Ujpest bridge in Budapest only provides connection through line 4 which is not electrified and the Baja bridge is not electrified, too, and both of them are single-tracked. The long-planned V0 railway line that is to be cross the Danube approximately halfway between Budapest and Baja would not only help to redistribute the total network flow which currently passes through almost exclusively the Southern bridge but would also provide redundancy for the existing bridges in the case of their disruption. Four of the five proposed V0 path alternatives are analyzed on the basis of these two network properties.",
        "published": "2020-05-26T15:36:44Z",
        "link": "http://arxiv.org/abs/2005.12802v1",
        "categories": [
            "cs.CE",
            "cs.DM",
            "math.OC"
        ]
    },
    {
        "title": "Waveform relaxation for low frequency coupled field/circuit   differential-algebraic models of index 2",
        "authors": [
            "Idoia Cortes Garcia",
            "Jonas Pade",
            "Sebastian Schöps",
            "Caren Tischendorf"
        ],
        "summary": "Motivated by the task to design quench protection systems for superconducting magnets in particle accelerators we address a coupled field/circuit simulation based on a magneto-quasistatic field modeling. We investigate how a waveform relaxation of Gau{\\ss}-Seidel type performs for a coupled simulation when circuit solving packages are used that describe the circuit by the modified nodal analysis. We present sufficient convergence criteria for the coupled simulation of FEM discretised field models and circuit models formed by a differential-algebraic equation (DAE) system of index 2. In particular, we demonstrate by a simple benchmark system the drastic influence of the circuit topology on the convergence behavior of the coupled simulation.",
        "published": "2020-05-27T10:41:09Z",
        "link": "http://arxiv.org/abs/2005.13272v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "35Q61, 65Z05, 65L05, 68W10"
        ]
    },
    {
        "title": "The Impacts of Convex Piecewise Linear Cost Formulations on AC Optimal   Power Flow",
        "authors": [
            "Carleton Coffrin",
            "Bernard Knueven",
            "Jesse Holzer",
            "Marc Vuffray"
        ],
        "summary": "Despite strong connections through shared application areas, research efforts on power market optimization (e.g., unit commitment) and power network optimization (e.g., optimal power flow) remain largely independent. A notable illustration of this is the treatment of power generation cost functions, where nonlinear network optimization has largely used polynomial representations and market optimization has adopted piecewise linear encodings. This work combines state-of-the-art results from both lines of research to understand the best mathematical formulations of the nonlinear AC optimal power flow problem with piecewise linear generation cost functions. An extensive numerical analysis of non-convex models, linear approximations, and convex relaxations across fifty-four realistic test cases illustrates that nonlinear optimization methods are surprisingly sensitive to the mathematical formulation of piecewise linear functions. The results indicate that a poor formulation choice can slow down algorithm performance by a factor of ten, increasing the runtime from seconds to minutes. These results provide valuable insights into the best formulations of nonlinear optimal power flow problems with piecewise linear cost functions, a important step towards building a new generation of energy markets that incorporate the nonlinear AC power flow model.",
        "published": "2020-05-28T15:29:24Z",
        "link": "http://arxiv.org/abs/2005.14087v2",
        "categories": [
            "math.OC",
            "cs.CE"
        ]
    },
    {
        "title": "Bayesian Surface Warping Approach For Rectifying Geological Boundaries   Using Displacement Likelihood And Evidence From Geochemical Assays",
        "authors": [
            "Raymond Leung",
            "Alexander Lowe",
            "Anna Chlingaryan",
            "Arman Melkumyan",
            "John Zigman"
        ],
        "summary": "This paper presents a Bayesian framework for manipulating mesh surfaces with the aim of improving the positional integrity of the geological boundaries that they seek to represent. The assumption is that these surfaces, created initially using sparse data, capture the global trend and provide a reasonable approximation of the stratigraphic, mineralisation and other types of boundaries for mining exploration, but they are locally inaccurate at scales typically required for grade estimation. The proposed methodology makes local spatial corrections automatically to maximise the agreement between the modelled surfaces and observed samples. Where possible, vertices on a mesh surface are moved to provide a clear delineation, for instance, between ore and waste material across the boundary based on spatial and compositional analysis; using assay measurements collected from densely spaced, geo-registered blast holes. The maximum a posteriori (MAP) solution ultimately considers the chemistry observation likelihood in a given domain. Furthermore, it is guided by an apriori spatial structure which embeds geological domain knowledge and determines the likelihood of a displacement estimate. The results demonstrate that increasing surface fidelity can significantly improve grade estimation performance based on large-scale model validation.",
        "published": "2020-05-29T07:28:24Z",
        "link": "http://arxiv.org/abs/2005.14427v2",
        "categories": [
            "cs.CE",
            "I.3.5; G.3; J.2"
        ]
    },
    {
        "title": "A hybridizable discontinuous Galerkin method for simulation of   electrostatic problems with floating potential conductors",
        "authors": [
            "Liang Chen",
            "Ming Dong",
            "Ping Li",
            "Hakan Bagci"
        ],
        "summary": "In an electrostatic simulation, an equipotential condition with an undefined/floating potential value has to be enforced on the surface of an isolated conductor. If this conductor is charged, a nonzero charge condition is also required. While implementation of these conditions using a traditional finite element method (FEM) is not straightforward, they can be easily discretized and incorporated within a discontinuous Galerkin (DG) method. However, DG discretization results in a larger number of unknowns as compared to FEM. In this work, a hybridizable DG (HDG) method is proposed to alleviate this problem. Floating potential boundary conditions, possibly with different charge values, are introduced on surfaces of each isolated conductor and are weakly enforced in the global problem of HDG. The unknowns of the global HDG problem are those only associated with the nodes on the mesh skeleton and their number is much smaller than the total number of unknowns required by DG. Numerical examples show that the proposed method is as accurate as DG while it improves the computational efficiency significantly.",
        "published": "2020-05-29T13:05:09Z",
        "link": "http://arxiv.org/abs/2006.02549v2",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Efficient Discontinuous Galerkin Scheme for Analyzing Nanostructured   Photoconductive Devices",
        "authors": [
            "Liang Chen",
            "Kostyantyn Sirenko",
            "Ping Li",
            "Hakan Bagci"
        ],
        "summary": "Incorporation of plasmonic nanostructures in the design of photoconductive devices (PCDs) has significantly improved their optical-to-terahertz conversion efficiency. However, this improvement comes at the cost of increased complexity for the design and simulation of these devices. Indeed, accurate and efficient modeling of multiphysics processes and intricate device geometries of nanostructured PCDs is challenging due to the high computational cost resulting from multiple characteristic scales in time and space. In this work, a discontinuous Galerkin (DG)-based unit-cell scheme for efficient simulation of PCDs with periodic nanostructures is proposed. The scheme considers two physical stages of the device and models them using two coupled systems: a system of Poisson and drift-diffusion equations describing the nonequilibrium steady state, and a system of Maxwell and drift-diffusion equations describing the transient stage. A \"potential-drop\" boundary condition is enforced on the opposing boundaries of the unit cell to mimic the effect of the bias voltage. Periodic boundary conditions are used for carrier densities and electromagnetic fields. The unit-cell model described by these coupled equations and boundary conditions is discretized using DG methods. Numerical results demonstrate that the proposed DG-based unit-cell scheme has the same accuracy in predicting the THz photocurrent as the DG framework that takes into account the whole device, while it significantly reduces the computational cost.",
        "published": "2020-05-29T20:36:23Z",
        "link": "http://arxiv.org/abs/2006.02141v4",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Homogenization of the wave equation with non-uniformly oscillating   coefficients",
        "authors": [
            "Danial P. Shahraki",
            "Bojan B. Guzina"
        ],
        "summary": "The focus of our work is dispersive, second-order effective model describing the low-frequency wave motion in heterogeneous (e.g.~functionally-graded) media endowed with periodic microstructure. For this class of quasi-periodic medium variations, we pursue homogenization of the scalar wave equation in $\\mathbb{R}^d$, $d\\geqslant 1$ within the framework of multiple scales expansion. When either $d=1$ or $d=2$, this model problem bears direct relevance to the description of (anti-plane) shear waves in elastic solids. By adopting the lengthscale of microscopic medium fluctuations as the perturbation parameter, we synthesize the germane low-frequency behavior via a fourth-order differential equation (with smoothly varying coefficients) governing the mean wave motion in the medium, where the effect of microscopic heterogeneities is upscaled by way of the so-called cell functions. In an effort to demonstrate the relevance of our analysis toward solving boundary value problems (deemed to be the ultimate goal of most homogenization studies), we also develop effective boundary conditions, up to the second order of asymptotic approximation, applicable to one-dimensional (1D) shear wave motion in a macroscopically heterogeneous solid with periodic microstructure. We illustrate the analysis numerically in 1D by considering (i) low-frequency wave dispersion, (ii) mean-field homogenized description of the shear waves propagating in a finite domain, and (iii) full-field homogenized description thereof. In contrast to (i) where the overall wave dispersion appears to be fairly well described by the leading-order model, the results in (ii) and (iii) demonstrate the critical role that higher-order corrections may have in approximating the actual waveforms in quasi-periodic media.",
        "published": "2020-05-29T23:38:13Z",
        "link": "http://arxiv.org/abs/2006.02550v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "math.CA"
        ]
    },
    {
        "title": "Multi-fidelity machine-learning with uncertainty quantification and   Bayesian optimization for materials design: Application to ternary random   alloys",
        "authors": [
            "Anh Tran",
            "Julien Tranchida",
            "Tim Wildey",
            "Aidan P. Thompson"
        ],
        "summary": "We present a scale-bridging approach based on a multi-fidelity (MF) machine-learning (ML) framework leveraging Gaussian processes (GP) to fuse atomistic computational model predictions across multiple levels of fidelity. Through the posterior variance of the MFGP, our framework naturally enables uncertainty quantification, providing estimates of confidence in the predictions. We used Density Functional Theory as high-fidelity prediction, while a ML interatomic potential is used as the low-fidelity prediction. Practical materials design efficiency is demonstrated by reproducing the ternary composition dependence of a quantity of interest (bulk modulus) across the full aluminum-niobium-titanium ternary random alloy composition space. The MFGP is then coupled to a Bayesian optimization procedure and the computational efficiency of this approach is demonstrated by performing an on-the-fly search for the global optimum of bulk modulus in the ternary composition space. The framework presented in this manuscript is the first application of MFGP to atomistic materials simulations fusing predictions between Density Functional Theory and classical interatomic potential calculations.",
        "published": "2020-05-30T00:42:45Z",
        "link": "http://arxiv.org/abs/2006.00139v3",
        "categories": [
            "physics.comp-ph",
            "cs.CE",
            "physics.atom-ph"
        ]
    },
    {
        "title": "Critical Point Calculations by Numerical Inversion of Functions",
        "authors": [
            "C. N. Parajara",
            "G. M. Platt",
            "F. D. Moura Neto",
            "M. Escobar",
            "G. B. Libotte"
        ],
        "summary": "In this work, we propose a new approach to the problem of critical point calculation, based on the formulation of Heidemann and Khalil (1980). This leads to a $2 \\times 2$ system of nonlinear algebraic equations in temperature and molar volume, which makes possible the prediction of critical points of the mixture through an adaptation of the technique of inversion of functions from the plane to the plane, proposed by Malta, Saldanha, and Tomei (1993). The results are compared to those obtained by three methodologies: ($i$) the classical method of Heidemann and Khalil (1980), which uses a double-loop structure, also in terms of temperature and molar volume; ($ii$) the algorithm of Dimitrakopoulos, Jia, and Li (2014), which employs a damped Newton algorithm and ($iii$) the methodology proposed by Nichita and Gomez (2010), based on a stochastic algorithm. The proposed methodology proves to be robust and accurate in the prediction of critical points, as well as provides a global view of the nonlinear problem.",
        "published": "2020-05-30T14:49:40Z",
        "link": "http://arxiv.org/abs/2006.09822v1",
        "categories": [
            "cs.CE",
            "math.OC"
        ]
    },
    {
        "title": "METASET: Exploring Shape and Property Spaces for Data-Driven   Metamaterials Design",
        "authors": [
            "Yu-Chin Chan",
            "Faez Ahmed",
            "Liwei Wang",
            "Wei Chen"
        ],
        "summary": "Data-driven design of mechanical metamaterials is an increasingly popular method to combat costly physical simulations and immense, often intractable, geometrical design spaces. Using a precomputed dataset of unit cells, a multiscale structure can be quickly filled via combinatorial search algorithms, and machine learning models can be trained to accelerate the process. However, the dependence on data induces a unique challenge: An imbalanced dataset containing more of certain shapes or physical properties can be detrimental to the efficacy of data-driven approaches. In answer, we posit that a smaller yet diverse set of unit cells leads to scalable search and unbiased learning. To select such subsets, we propose METASET, a methodology that 1) uses similarity metrics and positive semi-definite kernels to jointly measure the closeness of unit cells in both shape and property spaces, and 2) incorporates Determinantal Point Processes for efficient subset selection. Moreover, METASET allows the trade-off between shape and property diversity so that subsets can be tuned for various applications. Through the design of 2D metamaterials with target displacement profiles, we demonstrate that smaller, diverse subsets can indeed improve the search process as well as structural performance. By eliminating inherent overlaps in a dataset of 3D unit cells created with symmetry rules, we also illustrate that our flexible method can distill unique subsets regardless of the metric employed. Our diverse subsets are provided publicly for use by any designer.",
        "published": "2020-06-01T03:36:37Z",
        "link": "http://arxiv.org/abs/2006.02142v3",
        "categories": [
            "cs.CE",
            "cs.LG",
            "stat.ML"
        ]
    },
    {
        "title": "Multiple Sclerosis disease: a computational approach for investigating   its drug interactions",
        "authors": [
            "Simone Pernice",
            "Marco Beccuti",
            "Greta Romano",
            "Marzio Pennisi",
            "Alessandro Maglione",
            "Santina Cutrupi",
            "Francesco Pappalardo",
            "Lorenzo Capra",
            "Giuliana Franceschinis",
            "Massimiliano De Pierro",
            "Gianfranco Balbo",
            "Francesca Cordero",
            "Raffaele Calogero"
        ],
        "summary": "Multiple Sclerosis (MS) is a chronic and potentially highly disabling disease that can cause permanent damage and deterioration of the central nervous system. In Europe it is the leading cause of non-traumatic disabilities in young adults, since more than 700,000 EU people suffer from MS. Although recent studies on MS pathophysiology have been provided, MS remains a challenging disease. In this context, thanks to recent advances in software and hardware technologies, computational models and computer simulations are becoming appealing research tools to support scientists in the study of such disease. Thus, motivated by this consideration we propose in this paper a new model to study the evolution of MS in silico, and the effects of the administration of Daclizumab drug, taking into account also spatiality and temporality of the involved phenomena. Moreover, we show how the intrinsic symmetries of the system can be exploited to drastically reduce the complexity of its analysis.",
        "published": "2020-06-01T09:40:43Z",
        "link": "http://arxiv.org/abs/2006.00813v1",
        "categories": [
            "q-bio.QM",
            "cs.CE"
        ]
    },
    {
        "title": "Surrogate sea ice model enables efficient tuning",
        "authors": [
            "Kelly Kochanski",
            "Ivana Cvijanovic",
            "Donald Lucas"
        ],
        "summary": "Predicting changes in sea ice cover is critical for shipping, ecosystem monitoring, and climate modeling. Current sea ice models, however, predict more ice than is observed in the Arctic, and less in the Antarctic. Improving the fit of these physics-based models to observations is challenging because the models are expensive to run, and therefore expensive to optimize. Here, we construct a machine learning surrogate that emulates the effect of changing model physics on forecasts of sea ice area from the Los Alamos Sea Ice Model (CICE). We use the surrogate model to investigate the sensitivity of CICE to changes in the parameters governing: ice's ridging and albedo; snow's albedo, aging, and thermal conductivity; the effect of meltwater on albedo; and the effect of ponds on albedo. We find that CICE's sensitivity to these model parameters differs between hemispheres. We propose that future sea ice modelers separate the snow conductivity and snow grain size distributions on a seasonal and inter-hemispheric basis, and we recommend optimal values of these parameters. This will make it possible to make models that fit observations of both Arctic and Antarctic sea ice more closely. These results demonstrate that important aspects of the behavior of a leading sea ice model can be captured by a relatively simple support vector regression surrogate model, and that this surrogate dramatically increases the ease of tuning the full simulation.",
        "published": "2020-06-01T19:42:43Z",
        "link": "http://arxiv.org/abs/2006.12977v1",
        "categories": [
            "physics.ao-ph",
            "cs.CE"
        ]
    },
    {
        "title": "Wavelet Scattering Networks for Atomistic Systems with Extrapolation of   Material Properties",
        "authors": [
            "Paul Sinz",
            "Michael W. Swift",
            "Xavier Brumwell",
            "Jialin Liu",
            "Kwang Jin Kim",
            "Yue Qi",
            "Matthew Hirn"
        ],
        "summary": "The dream of machine learning in materials science is for a model to learn the underlying physics of an atomic system, allowing it to move beyond interpolation of the training set to the prediction of properties that were not present in the original training data. In addition to advances in machine learning architectures and training techniques, achieving this ambitious goal requires a method to convert a 3D atomic system into a feature representation that preserves rotational and translational symmetry, smoothness under small perturbations, and invariance under re-ordering. The atomic orbital wavelet scattering transform preserves these symmetries by construction, and has achieved great success as a featurization method for machine learning energy prediction. Both in small molecules and in the bulk amorphous $\\text{Li}_{\\alpha}\\text{Si}$ system, machine learning models using wavelet scattering coefficients as features have demonstrated a comparable accuracy to Density Functional Theory at a small fraction of the computational cost. In this work, we test the generalizability of our $\\text{Li}_{\\alpha}\\text{Si}$ energy predictor to properties that were not included in the training set, such as elastic constants and migration barriers. We demonstrate that statistical feature selection methods can reduce over-fitting and lead to remarkable accuracy in these extrapolation tasks.",
        "published": "2020-06-01T20:36:17Z",
        "link": "http://arxiv.org/abs/2006.01247v2",
        "categories": [
            "physics.comp-ph",
            "cs.CE",
            "cs.LG",
            "physics.chem-ph",
            "stat.ML"
        ]
    },
    {
        "title": "Data-driven fracture mechanics",
        "authors": [
            "Pietro Carrara",
            "Laura De Lorenzis",
            "Laurent Stainier",
            "Michael Ortiz"
        ],
        "summary": "We present a new data-driven paradigm for variational brittle fracture mechanics. The fracture-related material modeling assumptions are removed and the governing equations stemming from variational principles are combined with a set of discrete data points, leading to a model-free data-driven method of solution. The solution at a given load step is identified as the point within the data set that best satisfies either the Kuhn-Tucker conditions stemming from the variational fracture problem or global minimization of a suitable energy functional, leading to data-driven counterparts of both the local and the global minimization approaches of variational fracture mechanics. Both formulations are tested on different test configurations with and without noise and for Griffith and R-curve type fracture behavior.",
        "published": "2020-06-03T16:33:30Z",
        "link": "http://arxiv.org/abs/2006.03133v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A Memory-efficient Implementation of Perfectly Matched Layer with   Smoothly-varying Coefficients in Discontinuous Galerkin Time-Domain Method",
        "authors": [
            "Liang Chen",
            "Mehmet Burak Ozakin",
            "Shehab Ahmed",
            "Hakan Bagci"
        ],
        "summary": "Wrapping a computation domain with a perfectly matched layer (PML) is one of the most effective methods of imitating/approximating the radiation boundary condition in Maxwell and wave equation solvers. Many PML implementations often use a smoothly-increasing attenuation coefficient to increase the absorption for a given layer thickness, and, at the same time, to reduce the numerical reflection from the interface between the computation domain and the PML. In discontinuous Galerkin time-domain (DGTD) methods, using a PML coefficient that varies within a mesh element requires a different mass matrix to be stored for every element and therefore significantly increases the memory footprint. In this work, this bottleneck is addressed by applying a weight-adjusted approximation to these mass matrices. The resulting DGTD scheme has the same advantages as the scheme that stores individual mass matrices, namely higher accuracy (due to reduced numerical reflection) and increased meshing flexibility (since the PML does not have to be defined layer by layer) but it requires significantly less memory.",
        "published": "2020-06-04T14:01:33Z",
        "link": "http://arxiv.org/abs/2006.02551v2",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "physics.comp-ph"
        ]
    },
    {
        "title": "A combined XFEM phase-field computational model for crack growth without   remeshing",
        "authors": [
            "Alba Muixí",
            "Onofre Marco",
            "Antonio Rodríguez-Ferran",
            "Sonia Fernández-Méndez"
        ],
        "summary": "This paper presents an adaptive strategy for phase-field simulations with transition to fracture. The phase-field equations are solved only in small subdomains around crack tips to determine propagation, while an XFEM discretization is used in the rest of the domain to represent sharp cracks, enabling to use a coarser discretization and therefore reducing the computational cost. Crack-tip subdomains move as cracks propagate in a fully automatic process. The same computational mesh is used during all the simulation, with an $h$-refined approximation in the elements in the crack-tip subdomains. Continuity of the displacement between the refined subdomains and the XFEM region is imposed in weak form via Nitsche's method. The robustness of the strategy is shown for some numerical examples in 2D and 3D, including branching and coalescence tests.",
        "published": "2020-06-05T18:11:53Z",
        "link": "http://arxiv.org/abs/2006.03617v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Geometrically nonlinear modelling of pre-stressed viscoelastic   fibre-reinforced composites with application to arteries",
        "authors": [
            "I. I. Tagiltsev",
            "A. V. Shutov"
        ],
        "summary": "Modelling of mechanical behaviour of pre-stressed fibre-reinforced composites is considered in a geometrically exact setting. A general approach which includes two different reference configurations is employed: one configuration corresponds to the load-free state of the structure and another one to the stress-free state of each material particle. The applicability of the approach is demonstrated in terms of a viscoelastic material model; both the matrix and the fibre are modelled using a multiplicative split of the deformation gradient tensor; a transformation rule for initial conditions is elaborated and specified. Apart from its simplicity, an important advantage of the approach is that well-established numerical algorithms can be used for pre-stressed inelastic structures. The interrelation between the advocated approach and the widely used \"opening angle\" approach is clarified. A full-scale FEM simulation confirms the main predictions of the \"opening angle\" approach. A locking effect is discovered; the effect is that in some cases the opening angle of the composite is essentially smaller than the opening angles of its individual layers. Thus, the standard cutting test typically used to analyse pre-stresses does not carry enough information and more refined experimental techniques are needed.",
        "published": "2020-06-05T20:41:22Z",
        "link": "http://arxiv.org/abs/2006.08719v1",
        "categories": [
            "cs.CE",
            "74D10, 74S05"
        ]
    },
    {
        "title": "Subsurface Boundary Geometry Modeling: Applying Computational Physics,   Computer Vision and Signal Processing Techniques to Geoscience",
        "authors": [
            "Raymond Leung"
        ],
        "summary": "This paper describes an interdisciplinary approach to geometry modeling of geospatial boundaries. The objective is to extract surfaces from irregular spatial patterns using differential geometry and obtain coherent directional predictions along the boundary of extracted surfaces to enable more targeted sampling and exploration. Specific difficulties of the data include sparsity, incompleteness, causality and resolution disparity. Surface slopes are estimated using only sparse samples from cross-sections within a geological domain with no other information at intermediate depths. From boundary detection to subsurface reconstruction, processes are automated in between. The key problems to be solved are boundary extraction, region correspondence and propagation of the boundaries via contour morphing. Established techniques from computational physics, computer vision and signal processing are used with appropriate modifications to address challenges in each area. To facilitate boundary extraction, an edge map synthesis procedure is presented. This works with connected component analysis, anisotropic diffusion and active contours to convert unordered points into regularized boundaries. For region correspondence, component relationships are handled via graphical decomposition. FFT-based spatial alignment strategies are used in region merging and splitting scenarios. Shape changes between aligned regions are described by contour metamorphosis. Specifically, local spatial deformation is modeled by PDE and computed using level-set methods. Directional predictions are obtained using particle trajectories by following the evolving boundary. However, when a branching point is encountered, particles may lose track of the wavefront. To overcome this, a curvelet backtracking algorithm has been proposed to recover information for boundary segments without particle coverage to minimize shape distortion.",
        "published": "2020-06-06T01:39:20Z",
        "link": "http://arxiv.org/abs/2006.03752v1",
        "categories": [
            "cs.CE",
            "J.2; I.3.5"
        ]
    },
    {
        "title": "Constructing rigid-foldable generalized Miura-ori tessellations for   curved surfaces",
        "authors": [
            "Yucai Hu",
            "Yexin Zhou",
            "Haiyi Liang"
        ],
        "summary": "Origami has shown the potential to approximate three-dimensional curved surfaces by folding through designed crease patterns on flat materials. The Miura-ori tessellation is a widely used pattern in engineering and tiles the plane when partially folded. Based on constrained optimization, this paper presents the construction of generalized Miura-ori patterns that can approximate three-dimensional parametric surfaces of varying curvatures while preserving the inherent properties of the standard Miura-ori, including developability, flat-foldability and rigid-foldability. An initial configuration is constructed by tiling the target surface with triangulated Miura-like unit cells and used as the initial guess for the optimization. For approximation of a single target surface, a portion of the vertexes on the one side is attached to the target surface; for fitting of two target surfaces, a portion of vertexes on the other side is also attached to the second target surface. The parametric coordinates are adopted as the unknown variables for the vertexes on the target surfaces whilst the Cartesian coordinates are the unknowns for the other vertexes. The constructed generalized Miura-ori tessellations can be rigidly folded from the flat state to the target state with a single degree of freedom.",
        "published": "2020-06-07T07:40:44Z",
        "link": "http://arxiv.org/abs/2006.04070v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Generating Realistic Stock Market Order Streams",
        "authors": [
            "Junyi Li",
            "Xitong Wang",
            "Yaoyang Lin",
            "Arunesh Sinha",
            "Micheal P. Wellman"
        ],
        "summary": "We propose an approach to generate realistic and high-fidelity stock market data based on generative adversarial networks (GANs). Our Stock-GAN model employs a conditional Wasserstein GAN to capture history dependence of orders. The generator design includes specially crafted aspects including components that approximate the market's auction mechanism, augmenting the order history with order-book constructions to improve the generation task. We perform an ablation study to verify the usefulness of aspects of our network structure. We provide a mathematical characterization of distribution learned by the generator. We also propose statistics to measure the quality of generated orders. We test our approach with synthetic and actual market data, compare to many baseline generative models, and find the generated data to be close to real data.",
        "published": "2020-06-07T17:32:42Z",
        "link": "http://arxiv.org/abs/2006.04212v1",
        "categories": [
            "q-fin.ST",
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "On smooth or 0/1 designs of the fixed-mesh element-based topology   optimization",
        "authors": [
            "Xiaodong Huang"
        ],
        "summary": "The traditional element-based topology optimization based on material penalization typically aims at a 0/1 design. Our numerical experiments reveal that the compliance of a smooth design is overestimated when material properties of boundary intermediate elements under the fixed-mesh finite element analysis are interpolated with a material penalization model. This paper proposes a floating projection topology optimization (FPTO) method for seeking a smooth design using the ersatz material model or a 0/1 design using a material penalization model. The proposed floating projection constraint combining with the upper and lower bounds heuristically simulates 0/1 constraints of design variables in the original discrete optimization problem. Numerical examples demonstrate the capability of the proposed element-based topology optimization approach in obtaining 0/1 or smooth designs for 2D and 3D compliance minimization problems. The proposed topology optimization approach can be easily implemented under the framework of the fixed-mesh finite element analysis and provides an alternative way to form explicit topologies of structures, especially when the ersatz material model is adopted.",
        "published": "2020-06-08T01:17:54Z",
        "link": "http://arxiv.org/abs/2006.04306v1",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "AutoMat -- Automatic Differentiation for Generalized Standard Materials   on GPUs",
        "authors": [
            "Johannes Blühdorn",
            "Nicolas R. Gauger",
            "Matthias Kabel"
        ],
        "summary": "We propose a universal method for the evaluation of generalized standard materials that greatly simplifies the material law implementation process. By means of automatic differentiation and a numerical integration scheme, AutoMat reduces the implementation effort to two potential functions. By moving AutoMat to the GPU, we close the performance gap to conventional evaluation routines and demonstrate in detail that the expression level reverse mode of automatic differentiation as well as its extension to second order derivatives can be applied inside CUDA kernels. We underline the effectiveness and the applicability of AutoMat by integrating it into the FFT-based homogenization scheme of Moulinec and Suquet and discuss the benefits of using AutoMat with respect to runtime and solution accuracy for an elasto-viscoplastic example.",
        "published": "2020-06-08T07:38:28Z",
        "link": "http://arxiv.org/abs/2006.04391v2",
        "categories": [
            "cs.CE",
            "cs.MS",
            "G.1.4; G.1.7; G.4; J.2"
        ]
    },
    {
        "title": "Folding Simulation of Rigid Origami with Lagrange Multiplier Method",
        "authors": [
            "Yucai Hu",
            "Haiyi Liang"
        ],
        "summary": "Origami crease patterns are folding paths that transform flat sheets into spatial objects. Origami patterns with a single degree of freedom (DOF) have creases that fold simultaneously. More often, several substeps are required to sequentially fold origami of multiple DOFs, and at each substep some creases fold and the rest remain fixed. In this study, we combine the loop closure constraint with Lagrange multiplier method to account for the sequential folding of rigid origami of multiple DOFs, by controlling the rotation of different sets of creases during successive substeps. This strategy is also applicable to model origami-inspired devices, where creases may be equipped with rotational springs and the folding process involves elastic energy. Several examples are presented to verify the proposed algorithms in tracing the sequential folding process as well as searching the equilibrium configurations of origami with rotational springs.",
        "published": "2020-06-09T03:02:34Z",
        "link": "http://arxiv.org/abs/2006.05025v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "The Computational Patient has Diabetes and a COVID",
        "authors": [
            "Pietro Barbiero",
            "Pietro Lió"
        ],
        "summary": "Medicine is moving from a curative discipline to a preventative discipline relying on personalised and precise treatment plans. The complex and multi level pathophysiological patterns of most diseases require a systemic medicine approach and are challenging current medical therapies. On the other hand, computational medicine is a vibrant interdisciplinary field that could help move from an organ-centered approach to a process-oriented approach. The ideal computational patient would require an international interdisciplinary effort, of larger scientific and technological interdisciplinarity than the Human Genome Project. When deployed, such a patient would have a profound impact on how healthcare is delivered to patients. Here we present a computational patient model that integrates, refines and extends recent mechanistic or phenomenological models of cardiovascular, RAS and diabetic processes. Our aim is twofold: analyse the modularity and composability of the model-building blocks of the computational patient and to study the dynamical properties of well-being and disease states in a broader functional context. We present results from a number of experiments among which we characterise the dynamic impact of COVID-19 and type-2 diabetes (T2D) on cardiovascular and inflammation conditions. We tested these experiments under different exercise, meal and drug regimens. We report results showing the striking importance of transient dynamical responses to acute state conditions and we provide guidelines for system design principles for the inter-relationship between modules and components in systemic medicine. Finally this initial computational Patient can be used as a toolbox for further modifications and extensions.",
        "published": "2020-06-09T07:08:07Z",
        "link": "http://arxiv.org/abs/2006.06435v3",
        "categories": [
            "cs.CE",
            "q-bio.QM"
        ]
    },
    {
        "title": "A refined dynamic finite-strain shell theory for incompressible   hyperelastic materials: equations and two-dimensional shell virtual work   principle",
        "authors": [
            "Xiang Yu",
            "Yibin Fu",
            "Hui-Hui Dai"
        ],
        "summary": "Based on previous work for the static problem, in this paper we first derive one form of dynamic finite-strain shell equations for incompressible hyperelastic materials that involve three shell constitutive relations. In order to single out the bending effect as well as to reduce the number of shell constitutive relations, a further refinement is performed, which leads to a refined dynamic finite-strain shell theory with only two shell constitutive relations (deducible from the given three-dimensional (3D) strain energy function) and some new insights are also deduced. By using the weak formulation of the shell equations and the variation of the 3D Lagrange functional, boundary conditions and the two-dimensional (2D) shell virtual work principle are derived. As a benchmark problem, we consider the extension and inflation of an arterial segment. The good agreement between the asymptotic solution based on the shell equations and that from the 3D exact one gives verification of the former. The refined shell theory is also applied to study the plane-strain vibrations of a pressurized artery, and the effects of the axial pre-stretch, pressure and fibre angle on the vibration frequencies are investigated in detail.",
        "published": "2020-06-09T11:38:21Z",
        "link": "http://arxiv.org/abs/2006.04949v8",
        "categories": [
            "cs.CE",
            "physics.bio-ph"
        ]
    },
    {
        "title": "The aggregated unfitted finite element method on parallel tree-based   adaptive meshes",
        "authors": [
            "Santiago Badia",
            "Alberto F. Martín",
            "Eric Neiva",
            "Francesc Verdugo"
        ],
        "summary": "In this work, we present an adaptive unfitted finite element scheme that combines the aggregated finite element method with parallel adaptive mesh refinement. We introduce a novel scalable distributed-memory implementation of the resulting scheme on locally-adapted Cartesian forest-of-trees meshes. We propose a two-step algorithm to construct the finite element space at hand by means of a discrete extension operator that carefully mixes aggregation constraints of problematic degrees of freedom, which get rid of the small cut cell problem, and standard hanging degree of freedom constraints, which ensure trace continuity on non-conforming meshes. Following this approach, we derive a finite element space that can be expressed as the original one plus well-defined linear constraints. Moreover, it requires minimum parallelization effort, using standard functionality available in existing large-scale finite element codes. Numerical experiments demonstrate its optimal mesh adaptation capability, robustness to cut location and parallel efficiency, on classical Poisson $hp$-adaptivity benchmarks. Our work opens the path to functional and geometrical error-driven dynamic mesh adaptation with the aggregated finite element method in large-scale realistic scenarios. Likewise, it can offer guidance for bridging other scalable unfitted methods and parallel adaptive mesh refinement.",
        "published": "2020-06-09T16:08:13Z",
        "link": "http://arxiv.org/abs/2006.05373v2",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "Deep Adversarial Koopman Model for Reaction-Diffusion systems",
        "authors": [
            "Kaushik Balakrishnan",
            "Devesh Upadhyay"
        ],
        "summary": "Reaction-diffusion systems are ubiquitous in nature and in engineering applications, and are often modeled using a non-linear system of governing equations. While robust numerical methods exist to solve them, deep learning-based reduced ordermodels (ROMs) are gaining traction as they use linearized dynamical models to advance the solution in time. One such family of algorithms is based on Koopman theory, and this paper applies this numerical simulation strategy to reaction-diffusion systems. Adversarial and gradient losses are introduced, and are found to robustify the predictions. The proposed model is extended to handle missing training data as well as recasting the problem from a control perspective. The efficacy of these developments are demonstrated for two different reaction-diffusion problems: (1) the Kuramoto-Sivashinsky equation of chaos and (2) the Turing instability using the Gray-Scott model.",
        "published": "2020-06-09T23:12:12Z",
        "link": "http://arxiv.org/abs/2006.05547v1",
        "categories": [
            "cs.CE",
            "cs.LG",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Variational Optimization for the Submodular Maximum Coverage Problem",
        "authors": [
            "Jian Du",
            "Zhigang Hua",
            "Shuang Yang"
        ],
        "summary": "We examine the \\emph{submodular maximum coverage problem} (SMCP), which is related to a wide range of applications. We provide the first variational approximation for this problem based on the Nemhauser divergence, and show that it can be solved efficiently using variational optimization. The algorithm alternates between two steps: (1) an E step that estimates a variational parameter to maximize a parameterized \\emph{modular} lower bound; and (2) an M step that updates the solution by solving the local approximate problem. We provide theoretical analysis on the performance of the proposed approach and its curvature-dependent approximate factor, and empirically evaluate it on a number of public data sets and several application tasks.",
        "published": "2020-06-10T00:50:25Z",
        "link": "http://arxiv.org/abs/2006.05583v1",
        "categories": [
            "cs.LG",
            "cs.CE",
            "stat.ML"
        ]
    },
    {
        "title": "Computational Design and Evaluation Methods for Empowering Non-Experts   in Digital Fabrication",
        "authors": [
            "Nurcan Gecer Ulu"
        ],
        "summary": "Despite the increasing availability of personal fabrication hardware and services, the true potential of digital fabrication remains unrealized due to lack of computational techniques that can support 3D shape design by non-experts. This work develops computational methods that address two key aspects of content creation:(1) Function-driven design synthesis, (2) Design assessment.   For design synthesis, a generative shape modeling algorithm that facilitates automatic geometry synthesis and user-driven modification for non-experts is introduced. A critical observation that arises from this study is that the most geometrical specifications are dictated by functional requirements. To support design by high-level functional prescriptions, a physics based shape optimization method for compliant coupling behavior design has been developed. In line with this idea, producing complex 3D surfaces from flat 2D sheets by exploiting the concept of buckling beams has also been explored. Effective design assessment, the second key aspect, becomes critical for problems in which computational solutions do not exist. For these problems, this work proposes crowdsourcing as a way to empower non-experts in esoteric design domains that traditionally require expertise and specialized knowledge.",
        "published": "2020-06-10T16:15:16Z",
        "link": "http://arxiv.org/abs/2006.05921v1",
        "categories": [
            "cs.GR",
            "cs.CE"
        ]
    },
    {
        "title": "Physics informed deep learning for computational elastodynamics without   labeled data",
        "authors": [
            "Chengping Rao",
            "Hao Sun",
            "Yang Liu"
        ],
        "summary": "Numerical methods such as finite element have been flourishing in the past decades for modeling solid mechanics problems via solving governing partial differential equations (PDEs). A salient aspect that distinguishes these numerical methods is how they approximate the physical fields of interest. Physics-informed deep learning is a novel approach recently developed for modeling PDE solutions and shows promise to solve computational mechanics problems without using any labeled data. The philosophy behind it is to approximate the quantity of interest (e.g., PDE solution variables) by a deep neural network (DNN) and embed the physical law to regularize the network. To this end, training the network is equivalent to minimization of a well-designed loss function that contains the PDE residuals and initial/boundary conditions (I/BCs). In this paper, we present a physics-informed neural network (PINN) with mixed-variable output to model elastodynamics problems without resort to labeled data, in which the I/BCs are hardly imposed. In particular, both the displacement and stress components are taken as the DNN output, inspired by the hybrid finite element analysis, which largely improves the accuracy and trainability of the network. Since the conventional PINN framework augments all the residual loss components in a \"soft\" manner with Lagrange multipliers, the weakly imposed I/BCs cannot not be well satisfied especially when complex I/BCs are present. To overcome this issue, a composite scheme of DNNs is established based on multiple single DNNs such that the I/BCs can be satisfied forcibly in a \"hard\" manner. The propose PINN framework is demonstrated on several numerical elasticity examples with different I/BCs, including both static and dynamic problems as well as wave propagation in truncated domains. Results show the promise of PINN in the context of computational mechanics applications.",
        "published": "2020-06-10T19:05:08Z",
        "link": "http://arxiv.org/abs/2006.08472v1",
        "categories": [
            "math.NA",
            "cs.AI",
            "cs.CE",
            "cs.LG",
            "cs.NA"
        ]
    },
    {
        "title": "Calibration of the von Wolffersdorff model using Genetic Algorithms",
        "authors": [
            "Francisco J. Mendez",
            "Antonio Pasculli",
            "Miguel A. Mendez",
            "Nicola Sciarra"
        ],
        "summary": "This article proposes an optimization framework, based on Genetic Algorithms (GA), to calibrate the constitutive law of von Wolffersdorff. This constitutive law is known as Sand Hypoplasticity (SH), and allows for robust and accurate modeling of the soil behavior but requires a complex calibration involving eight parameters. The proposed optimization can automatically fit these parameters from the results of an oedometric and a triaxial drained compression test, by combining the GA with a numerical solver that integrates the SH in the test conditions. By repeating the same calibration several times, the stochastic nature of the optimizer enables the uncertainty quantification of the calibration parameters and allows studying their relative importance on the model prediction. After validating the numerical solver on the ExCaliber-Laboratory software from the SoilModels' website, the GA calibration is tested on a synthetic dataset to analyze the convergence and the statistics of the results. In particular, a correlation analysis reveals that two couples of the eight model parameters are strongly correlated. Finally, the calibration procedure is tested on the results from von Wolffersdorff, 1996, and Herle & Gudehus, 1999, on the Hochstetten sand. The model parameters identified by the Genetic Algorithm optimization improves the matching with the experimental data and hence lead to a better calibration.",
        "published": "2020-06-10T20:07:55Z",
        "link": "http://arxiv.org/abs/2006.08433v1",
        "categories": [
            "cs.CE",
            "cond-mat.mtrl-sci",
            "cs.NE"
        ]
    },
    {
        "title": "Uncovering the Underlying Physics of Degrading System Behavior Through a   Deep Neural Network Framework: The Case of Remaining Useful Life Prognosis",
        "authors": [
            "Sergio Cofre-Martel",
            "Enrique Lopez Droguett",
            "Mohammad Modarres"
        ],
        "summary": "Deep learning (DL) has become an essential tool in prognosis and health management (PHM), commonly used as a regression algorithm for the prognosis of a system's behavior. One particular metric of interest is the remaining useful life (RUL) estimated using monitoring sensor data. Most of these deep learning applications treat the algorithms as black-box functions, giving little to no control of the data interpretation. This becomes an issue if the models break the governing laws of physics or other natural sciences when no constraints are imposed. The latest research efforts have focused on applying complex DL models to achieve a low prediction error rather than studying how the models interpret the behavior of the data and the system itself. In this paper, we propose an open-box approach using a deep neural network framework to explore the physics of degradation through partial differential equations (PDEs). The framework has three stages, and it aims to discover a latent variable and corresponding PDE to represent the health state of the system. Models are trained as a supervised regression and designed to output the RUL as well as a latent variable map that can be used and interpreted as the system's health indicator.",
        "published": "2020-06-10T21:05:59Z",
        "link": "http://arxiv.org/abs/2006.09288v1",
        "categories": [
            "eess.SP",
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "On topology optimization of large deformation contact-aided shape   morphing compliant mechanisms",
        "authors": [
            "Prabhat Kumar",
            "Roger A. Sauer",
            "Anupam Saxena"
        ],
        "summary": "A topology optimization approach for designing large deformation contact-aided shape morphing compliant mechanisms is presented. Such mechanisms can be used in varying operating conditions. Design domains are described by regular hexagonal elements. Negative circular masks are employed to perform dual task, i.e., to decide material states of each element and also, to generate rigid contact surfaces. Each mask is characterized by five design variables, which are mutated by a zero-order based hill-climbing optimizer. Geometric and material nonlinearities are considered. Continuity in normals to boundaries of the candidate designs is ensured using a boundary resolution and smoothing scheme. Nonlinear mechanical equilibrium equations are solved using the Newton-Raphson method. An updated Lagrange approach in association with segment-to-segment contact method is employed for the contact formulation. Both mutual and self contact modes are permitted. Efficacy of the approach is demonstrated by designing four contact-aided shape morphing compliant mechanisms for different desired curves. Performance of the deformed profiles is verified using a commercial software. The effect of frictional contact surface on the actual profile is also studied",
        "published": "2020-06-10T21:57:19Z",
        "link": "http://arxiv.org/abs/2006.07207v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Bi-Level Graph Neural Networks for Drug-Drug Interaction Prediction",
        "authors": [
            "Yunsheng Bai",
            "Ken Gu",
            "Yizhou Sun",
            "Wei Wang"
        ],
        "summary": "We introduce Bi-GNN for modeling biological link prediction tasks such as drug-drug interaction (DDI) and protein-protein interaction (PPI). Taking drug-drug interaction as an example, existing methods using machine learning either only utilize the link structure between drugs without using the graph representation of each drug molecule, or only leverage the individual drug compound structures without using graph structure for the higher-level DDI graph. The key idea of our method is to fundamentally view the data as a bi-level graph, where the highest level graph represents the interaction between biological entities (interaction graph), and each biological entity itself is further expanded to its intrinsic graph representation (representation graphs), where the graph is either flat like a drug compound or hierarchical like a protein with amino acid level graph, secondary structure, tertiary structure, etc. Our model not only allows the usage of information from both the high-level interaction graph and the low-level representation graphs, but also offers a baseline for future research opportunities to address the bi-level nature of the data.",
        "published": "2020-06-11T04:49:26Z",
        "link": "http://arxiv.org/abs/2006.14002v1",
        "categories": [
            "cs.CE",
            "cs.LG",
            "stat.ML"
        ]
    },
    {
        "title": "Multi-scale modelling of concrete structures affected by alkali-silica   reaction: Coupling the mesoscopic damage evolution and the macroscopic   concrete deterioration",
        "authors": [
            "Emil R. Gallyamov",
            "Aurelia Isabel Cuba Ramos",
            "Mauro Corrado",
            "Roozbeh Rezakhani",
            "Jean-Francois Molinari"
        ],
        "summary": "A finite-element approach based on the first-order FE 2 homogenisation technique is formulated to analyse the alkali-silica reaction-induced damage in concrete structures, by linking the concrete degradation at the macro-scale to the reaction extent at the meso-scale. At the meso-scale level, concrete is considered as a heterogeneous material consisting of aggregates embedded in a mortar matrix. The mechanical effects of the Alkali-Silica Reaction (ASR) are modelled through the application of temperature-dependent eigenstrains in several localised spots inside the aggregates and the mechanical degradation of concrete is modelled using continuous damage model, which is capable of reproducing the complex ASR crack networks. Then, the effective stiffness tensor and the effective stress tensor for each macroscopic finite element are computed by homogenising the mechanical response of the corresponding representative volume element (RVE), thus avoiding the use of phenomenological constitutive laws at the macro-scale. Convergence between macro- and meso-scales is achieved via an iterative procedure. A 2D model of an ASR laboratory specimen is analysed as a proof of concept. The model is able to account for the loading applied at the macro-scale and the ASR-product expansion at the meso-scale. The results demonstrate that the macroscopic stress state influences the orientation of damage inside the underlying RVEs. The effective stiffness becomes anisotropic in cases where damage is aligned inside the RVE.",
        "published": "2020-06-11T09:50:42Z",
        "link": "http://arxiv.org/abs/2006.13859v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Frontiers in Mortar Methods for Isogeometric Analysis",
        "authors": [
            "Christian Hesch",
            "Ustim Khristenko",
            "Rolf Krause",
            "Alexander Popp",
            "Alexander Seitz",
            "Wolfgang Wall",
            "Barbara Wohlmuth"
        ],
        "summary": "Complex geometries as common in industrial applications consist of multiple patches, if spline based parametrizations are used. The requirements for the generation of analysis-suitable models are increasing dramatically since isogeometric analysis is directly based on the spline parametrization and nowadays used for the calculation of higher-order partial differential equations. The computational, or more general, the engineering analysis necessitates suitable coupling techniques between the different patches. Mortar methods have been successfully applied for coupling of patches and for contact mechanics in recent years to resolve the arising issues within the interface. We present here current achievements in the design of mortar technologies in isogeometric analysis within the Priority Program SPP 1748, Reliable Simulation Techniques in Solid Mechanics. Development of Non-standard Discretisation Methods, Mechanical and Mathematical Analysis.",
        "published": "2020-06-11T17:57:16Z",
        "link": "http://arxiv.org/abs/2006.06677v3",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "BioDynaMo: a general platform for scalable agent-based simulation",
        "authors": [
            "Lukas Breitwieser",
            "Ahmad Hesam",
            "Jean de Montigny",
            "Vasileios Vavourakis",
            "Alexandros Iosif",
            "Jack Jennings",
            "Marcus Kaiser",
            "Marco Manca",
            "Alberto Di Meglio",
            "Zaid Al-Ars",
            "Fons Rademakers",
            "Onur Mutlu",
            "Roman Bauer"
        ],
        "summary": "Motivation: Agent-based modeling is an indispensable tool for studying complex biological systems. However, existing simulators do not always take full advantage of modern hardware and often have a field-specific software design.   Results: We present a novel simulation platform called BioDynaMo that alleviates both of these problems. BioDynaMo features a general-purpose and high-performance simulation engine. We demonstrate that BioDynaMo can be used to simulate use cases in: neuroscience, oncology, and epidemiology. For each use case we validate our findings with experimental data or an analytical solution. Our performance results show that BioDynaMo performs up to three orders of magnitude faster than the state-of-the-art baseline. This improvement makes it feasible to simulate each use case with one billion agents on a single server, showcasing the potential BioDynaMo has for computational biology research.   Availability: BioDynaMo is an open-source project under the Apache 2.0 license and is available at www.biodynamo.org. Instructions to reproduce the results are available in supplementary information.   Contact: lukas.breitwieser@inf.ethz.ch, a.s.hesam@tudelft.nl, omutlu@ethz.ch, r.bauer@surrey.ac.uk   Supplementary information: Available at https://doi.org/10.5281/zenodo.4501515",
        "published": "2020-06-11T19:55:02Z",
        "link": "http://arxiv.org/abs/2006.06775v2",
        "categories": [
            "cs.CE",
            "cs.DC",
            "cs.MA"
        ]
    },
    {
        "title": "An efficient application of Bayesian optimization to an industrial MDO   framework for aircraft design",
        "authors": [
            "Remy Priem",
            "Hugo Gagnon",
            "Ian Chittick",
            "Stephane Dufresne",
            "Youssef Diouane",
            "Nathalie Bartoli"
        ],
        "summary": "The multi-level, multi-disciplinary and multi-fidelity optimization framework developed at Bombardier Aviation has shown great results to explore efficient and competitive aircraft configurations. This optimization framework has been developed within the Isight software, the latter offers a set of ready-to-use optimizers. Unfortunately, the computational effort required by the Isight optimizers can be prohibitive with respect to the requirements of an industrial context. In this paper, a constrained Bayesian optimization optimizer, namely the super efficient global optimization with mixture of experts, is used to reduce the optimization computational effort. The obtained results showed significant improvements compared to two of the popular Isight optimizers. The capabilities of the tested constrained Bayesian optimization solver are demonstrated on Bombardier research aircraft configuration study cases.",
        "published": "2020-06-12T07:44:25Z",
        "link": "http://arxiv.org/abs/2006.08434v1",
        "categories": [
            "cs.CE",
            "cs.AI",
            "cs.LG",
            "math.OC",
            "stat.ML"
        ]
    },
    {
        "title": "Improved estimations of stochastic chemical kinetics by finite state   expansion",
        "authors": [
            "Tabea Waizmann",
            "Luca Bortolussi",
            "Andrea Vandin",
            "Mirco Tribastone"
        ],
        "summary": "Stochastic reaction networks are a fundamental model to describe interactions between species where random fluctuations are relevant. The master equation provides the evolution of the probability distribution across the discrete state space consisting of vectors of population counts for each species. However, since its exact solution is often elusive, several analytical approximations have been proposed. The deterministic rate equation (DRE) gives a macroscopic approximation as a compact system of differential equations that estimate the average populations for each species, but it may be inaccurate in the case of nonlinear interaction dynamics. Here we propose finite state expansion (FSE), an analytical method mediating between the microscopic and the macroscopic interpretations of a stochastic reaction network by coupling the master equation dynamics of a chosen subset of the discrete state space with the mean population dynamics of the DRE. An algorithm translates a network into an expanded one where each discrete state is represented as a further distinct species. This translation exactly preserves the stochastic dynamics, but the DRE of the expanded network can be interpreted as a correction to the original one. The effectiveness of FSE is demonstrated in models that challenge state-of-the-art techniques due to intrinsic noise, multi-scale populations, and multi-stability.",
        "published": "2020-06-12T08:08:12Z",
        "link": "http://arxiv.org/abs/2006.06987v3",
        "categories": [
            "q-bio.MN",
            "cs.CE"
        ]
    },
    {
        "title": "Parametric solutions of turbulent incompressible flows in OpenFOAM via   the proper generalised decomposition",
        "authors": [
            "Vasileios Tsiolakis",
            "Matteo Giacomini",
            "Ruben Sevilla",
            "Carsten Othmer",
            "Antonio Huerta"
        ],
        "summary": "An a priori reduced order method based on the proper generalised decomposition (PGD) is proposed to compute parametric solutions involving turbulent incompressible flows of interest in an industrial context, using OpenFOAM. The PGD framework is applied for the first time to the incompressible Navier-Stokes equations in the turbulent regime, to compute a generalised solution for velocity, pressure and turbulent viscosity, explicitly depending on the design parameters of the problem. In order to simulate flows of industrial interest, a minimally intrusive implementation based on OpenFOAM SIMPLE algorithm applied to the Reynolds-averaged Navier-Stokes equations with the Spalart-Allmaras turbulence model is devised. The resulting PGD strategy is applied to parametric flow control problems and achieves both qualitative and quantitative agreement with the full order OpenFOAM solution for convection-dominated fully-developed turbulent incompressible flows, with Reynolds number up to one million.",
        "published": "2020-06-12T10:55:00Z",
        "link": "http://arxiv.org/abs/2006.07073v2",
        "categories": [
            "physics.comp-ph",
            "cs.CE",
            "cs.NA",
            "math.NA",
            "65N08, 76D05, 76D55, 62P30"
        ]
    },
    {
        "title": "Algorithms and Learning for Fair Portfolio Design",
        "authors": [
            "Emily Diana",
            "Travis Dick",
            "Hadi Elzayn",
            "Michael Kearns",
            "Aaron Roth",
            "Zachary Schutzman",
            "Saeed Sharifi-Malvajerdi",
            "Juba Ziani"
        ],
        "summary": "We consider a variation on the classical finance problem of optimal portfolio design. In our setting, a large population of consumers is drawn from some distribution over risk tolerances, and each consumer must be assigned to a portfolio of lower risk than her tolerance. The consumers may also belong to underlying groups (for instance, of demographic properties or wealth), and the goal is to design a small number of portfolios that are fair across groups in a particular and natural technical sense.   Our main results are algorithms for optimal and near-optimal portfolio design for both social welfare and fairness objectives, both with and without assumptions on the underlying group structure. We describe an efficient algorithm based on an internal two-player zero-sum game that learns near-optimal fair portfolios ex ante and show experimentally that it can be used to obtain a small set of fair portfolios ex post as well. For the special but natural case in which group structure coincides with risk tolerances (which models the reality that wealthy consumers generally tolerate greater risk), we give an efficient and optimal fair algorithm. We also provide generalization guarantees for the underlying risk distribution that has no dependence on the number of portfolios and illustrate the theory with simulation results.",
        "published": "2020-06-12T16:00:41Z",
        "link": "http://arxiv.org/abs/2006.07281v1",
        "categories": [
            "cs.LG",
            "cs.CE",
            "cs.GT",
            "stat.ML"
        ]
    },
    {
        "title": "Solving the Bethe-Salpeter equation on massively parallel architectures",
        "authors": [
            "Xiao Zhang",
            "Sebastian Achilles",
            "Jan Winkelmann",
            "Roland Haas",
            "André Schleife",
            "Edoardo Di Napoli"
        ],
        "summary": "The last ten years have witnessed fast spreading of massively parallel computing clusters, from leading supercomputing facilities down to the average university computing center. Many companies in the private sector have undergone a similar evolution. In this scenario, the seamless integration of software and middleware libraries is a key ingredient to ensure portability of scientific codes and guarantees them an extended lifetime. In this work, we describe the integration of the ChASE library, a modern parallel eigensolver, into an existing legacy code for the first-principles computation of optical properties of materials via solution of the Bethe-Salpeter equation for the optical polarization function. Our numerical tests show that, as a result of integrating ChASE and parallelizing the reading routine, the code experiences a remarkable speedup and greatly improved scaling behavior on both multi- and many-core architectures. We demonstrate that such a modernized BSE code will, by fully exploiting parallel computing architectures and file systems, enable domain scientists to accurately study complex material systems that were not accessible before.",
        "published": "2020-06-15T15:55:52Z",
        "link": "http://arxiv.org/abs/2006.08498v1",
        "categories": [
            "cs.CE",
            "cs.DC",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Morphological stability of three-dimensional cementite rods in   polycrystalline system: A phase-field analysis",
        "authors": [
            "Tobias Mittnacht",
            "Prince Gideon Kubendran Amos",
            "Daniel Schneider",
            "Britta Nestler"
        ],
        "summary": "Transformations accompanying shape-instability govern the morphological configuration and distribution of the phases in a microstructure. Owing to the influence of the microstructure on the properties of a material, the stability of three-dimensional rods in a representative polycrystalline system is extensively analysed. A multiphase-field model, which recovers the physical laws and sharp-interface relations, and includes grain boundary diffusion, is adopted to investigate the morphological evolution of the precipitate. Moreover, the efficiency of the numerical approach is ensured by establishing the volume-preserving chemical equilibrium through the incorporation TCFe8 (CALPHAD) data and solving phase-field evolution in the Allen-Cahn framework. The morphological evolution of the rod in the multiphase system exhibits a unique transformation mechanism which is significantly different from the evolution of an isolated finite-structure. It is realised that, in a polycrystalline arrangement, irrespective of the initial rod-size , the shape-change begins with the energy-minimising events at the triple junctions. This early transformation renders a characteristic morphology at the longitudinal ends of the structure, which introduces sufficient driving-force through the curvature-difference for the subsequent morphological changes. The continued mass transfer to the terminations, ultimately, breaks-off the rod into separate entities that are entangled in the grain boundary. With increasing aspect ratio of the rod, it is identified that the source of mass transfer, which turns into the ovulation site, shifts from the centre. This increases the number of fragmentation events and introduces satellite particle. A comprehensive understanding of the transformation kinetics and mechanism governing the morphological evolution of the rods in a polycrystalline system is rendered in this work.",
        "published": "2020-06-16T09:47:10Z",
        "link": "http://arxiv.org/abs/2006.09027v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Learning a functional control for high-frequency finance",
        "authors": [
            "Laura Leal",
            "Mathieu Laurière",
            "Charles-Albert Lehalle"
        ],
        "summary": "We use a deep neural network to generate controllers for optimal trading on high frequency data. For the first time, a neural network learns the mapping between the preferences of the trader, i.e. risk aversion parameters, and the optimal controls. An important challenge in learning this mapping is that in intraday trading, trader's actions influence price dynamics in closed loop via the market impact. The exploration--exploitation tradeoff generated by the efficient execution is addressed by tuning the trader's preferences to ensure long enough trajectories are produced during the learning phase. The issue of scarcity of financial data is solved by transfer learning: the neural network is first trained on trajectories generated thanks to a Monte-Carlo scheme, leading to a good initialization before training on historical trajectories. Moreover, to answer to genuine requests of financial regulators on the explainability of machine learning generated controls, we project the obtained \"blackbox controls\" on the space usually spanned by the closed-form solution of the stylized optimal trading problem, leading to a transparent structure. For more realistic loss functions that have no closed-form solution, we show that the average distance between the generated controls and their explainable version remains small. This opens the door to the acceptance of ML-generated controls by financial regulators.",
        "published": "2020-06-17T02:39:22Z",
        "link": "http://arxiv.org/abs/2006.09611v2",
        "categories": [
            "math.OC",
            "cs.CE",
            "cs.LG",
            "q-fin.CP",
            "q-fin.TR"
        ]
    },
    {
        "title": "Multiatlas Calibration of Biophysical Brain Tumor Growth Models with   Mass Effect",
        "authors": [
            "Shashank Subramanian",
            "Klaudius Scheufele",
            "Naveen Himthani",
            "George Biros"
        ],
        "summary": "We present a 3D fully-automatic method for the calibration of partial differential equation (PDE) models of glioblastoma (GBM) growth with mass effect, the deformation of brain tissue due to the tumor. We quantify the mass effect, tumor proliferation, tumor migration, and the localized tumor initial condition from a single multiparameteric Magnetic Resonance Imaging (mpMRI) patient scan. The PDE is a reaction-advection-diffusion partial differential equation coupled with linear elasticity equations to capture mass effect. The single-scan calibration model is notoriously difficult because the precancerous (healthy) brain anatomy is unknown. To solve this inherently ill-posed and ill-conditioned optimization problem, we introduce a novel inversion scheme that uses multiple brain atlases as proxies for the healthy precancer patient brain resulting in robust and reliable parameter estimation. We apply our method on both synthetic and clinical datasets representative of the heterogeneous spatial landscape typically observed in glioblastomas to demonstrate the validity and performance of our methods. In the synthetic data, we report calibration errors (due to the ill-posedness and our solution scheme) in the 10\\%-20\\% range. In the clinical data, we report good quantitative agreement with the observed tumor and qualitative agreement with the mass effect (for which we do not have a ground truth). Our method uses a minimal set of parameters and provides both global and local quantitative measures of tumor infiltration and mass effect.",
        "published": "2020-06-17T15:24:05Z",
        "link": "http://arxiv.org/abs/2006.09932v1",
        "categories": [
            "q-bio.QM",
            "cs.CE",
            "physics.med-ph"
        ]
    },
    {
        "title": "Topology synthesis of a 3-kink contact-aided compliant switch",
        "authors": [
            "B V S Nagendra Reddy",
            "Anupam Saxena"
        ],
        "summary": "A topology synthesis approach to design 2D Contact-aided Compliant Mechanisms (CCMs) to trace output paths with three or more kinks is presented. Synthesis process uses three different types of external, rigid contact surfaces: circular, elliptical and rectangular: which in combination, offer intricate local curvatures that CCMs can benefit from, to deliver desired, complex output characteristics. A network of line elements is employed to generate topologies. A set of circular subregions is laid over this network, and external contact surfaces are generated within each subregion. Both, discrete and continuous design variables are employed: the former set controls the CCM topology, appearance and type of external contact surfaces, whereas the latter set governs shapes and sizes of the CCM constituents, and sizes of contact surfaces. All contact types are permitted with contact modeling made significantly easier through identification of outer and inner loops. Line topologies are fleshed out via a user-defined number of quadrilateral elements along lateral and longitudinal directions. Candidate CCM designs are carefully preprocessed before analysis via a commercial software and evolution using a stochastic search. The process is exemplified via a contact-aided, 3-kink mechanical switch which is thoroughly analysed in presence of friction and wear.",
        "published": "2020-06-18T09:37:39Z",
        "link": "http://arxiv.org/abs/2006.10385v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Accelerating Training in Artificial Neural Networks with Dynamic Mode   Decomposition",
        "authors": [
            "Mauricio E. Tano",
            "Gavin D. Portwood",
            "Jean C. Ragusa"
        ],
        "summary": "Training of deep neural networks (DNNs) frequently involves optimizing several millions or even billions of parameters. Even with modern computing architectures, the computational expense of DNN training can inhibit, for instance, network architecture design optimization, hyper-parameter studies, and integration into scientific research cycles. The key factor limiting performance is that both the feed-forward evaluation and the back-propagation rule are needed for each weight during optimization in the update rule. In this work, we propose a method to decouple the evaluation of the update rule at each weight. At first, Proper Orthogonal Decomposition (POD) is used to identify a current estimate of the principal directions of evolution of weights per layer during training based on the evolution observed with a few backpropagation steps. Then, Dynamic Mode Decomposition (DMD) is used to learn the dynamics of the evolution of the weights in each layer according to these principal directions. The DMD model is used to evaluate an approximate converged state when training the ANN. Afterward, some number of backpropagation steps are performed, starting from the DMD estimates, leading to an update to the principal directions and DMD model. This iterative process is repeated until convergence. By fine-tuning the number of backpropagation steps used for each DMD model estimation, a significant reduction in the number of operations required to train the neural networks can be achieved. In this paper, the DMD acceleration method will be explained in detail, along with the theoretical justification for the acceleration provided by DMD. This method is illustrated using a regression problem of key interest for the scientific machine learning community: the prediction of a pollutant concentration field in a diffusion, advection, reaction problem.",
        "published": "2020-06-18T22:59:55Z",
        "link": "http://arxiv.org/abs/2006.14371v1",
        "categories": [
            "cs.LG",
            "cs.CE",
            "eess.SP",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Robust and scalable h-adaptive aggregated unfitted finite elements for   interface elliptic problems",
        "authors": [
            "Eric Neiva",
            "Santiago Badia"
        ],
        "summary": "This work introduces a novel, fully robust and highly-scalable, $h$-adaptive aggregated unfitted finite element method for large-scale interface elliptic problems. The new method is based on a recent distributed-memory implementation of the aggregated finite element method atop a highly-scalable Cartesian forest-of-trees mesh engine. It follows the classical approach of weakly coupling nonmatching discretisations at the interface to model internal discontinuities at the interface. We propose a natural extension of a single-domain parallel cell aggregation scheme to problems with a finite number of interfaces; it straightforwardly leads to aggregated finite element spaces that have the structure of a Cartesian product. We demonstrate, through standard numerical analysis and exhaustive numerical experimentation on several complex Poisson and linear elasticity benchmarks, that the new technique enjoys the following properties: well-posedness, robustness with respect to cut location and material contrast, optimal ($h$-adaptive) approximation properties, high scalability and easy implementation in large-scale finite element codes. As a result, the method offers great potential as a useful finite element solver for large-scale interface problems modelled by partial differential equations.",
        "published": "2020-06-19T09:50:02Z",
        "link": "http://arxiv.org/abs/2006.11042v2",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "Mesh deformation techniques in fluid-structure interaction: robustness,   accumulated distortion and computational efficiency",
        "authors": [
            "Alexander Shamanskiy",
            "Bernd Simeon"
        ],
        "summary": "An important ingredient of any moving-mesh method for fluid-structure interaction (FSI) problems is the mesh deformation technique (MDT) used to adapt the computational mesh in the moving fluid domain. An ideal technique is computationally inexpensive, can handle large mesh deformations without inverting mesh elements and can sustain an FSI simulation for extensive periods ot time without irreversibly distorting the mesh. Here we compare several commonly used techniques based on the solution of elliptic partial differential equations, including harmonic extension, bi-harmonic extension and techniques based on the equations of linear elasticity. Moreover, we propose a novel technique which utilizes ideas from continuation methods to efficiently solve the equations of nonlinear elasticity and proves to be robust even when the mesh is subject to extreme deformations. In addition to that, we study how each technique performs when combined with the Jacobian-based local stiffening. We evaluate each technique on a popular two-dimensional FSI benchmark reproduced by using an isogeometric partitioned solver with strong coupling.",
        "published": "2020-06-19T18:40:12Z",
        "link": "http://arxiv.org/abs/2006.14051v1",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Airfoil Design Parameterization and Optimization using Bézier   Generative Adversarial Networks",
        "authors": [
            "Wei Chen",
            "Kevin Chiu",
            "Mark Fuge"
        ],
        "summary": "Global optimization of aerodynamic shapes usually requires a large number of expensive computational fluid dynamics simulations because of the high dimensionality of the design space. One approach to combat this problem is to reduce the design space dimension by obtaining a new representation. This requires a parametric function that compactly and sufficiently describes useful variation in shapes. We propose a deep generative model, B\\'ezier-GAN, to parameterize aerodynamic designs by learning from shape variations in an existing database. The resulted new parameterization can accelerate design optimization convergence by improving the representation compactness while maintaining sufficient representation capacity. We use the airfoil design as an example to demonstrate the idea and analyze B\\'ezier-GAN's representation capacity and compactness. Results show that B\\'ezier-GAN both (1) learns smooth and realistic shape representations for a wide range of airfoils and (2) empirically accelerates optimization convergence by at least two times compared to state-of-the-art parameterization methods.",
        "published": "2020-06-21T05:28:08Z",
        "link": "http://arxiv.org/abs/2006.12496v2",
        "categories": [
            "cs.CE",
            "cs.LG",
            "stat.ML"
        ]
    },
    {
        "title": "Hybridisable discontinuous Galerkin solution of geometrically   parametrised Stokes flows",
        "authors": [
            "Ruben Sevilla",
            "Luca Borchini",
            "Matteo Giacomini",
            "Antonio Huerta"
        ],
        "summary": "This paper proposes a novel computational framework for the solution of geometrically parametrised flow problems governed by the Stokes equation. The proposed method uses a high-order hybridisable discontinuous Galerkin formulation and the proper generalised decomposition rationale to construct an off-line solution for a given set of geometric parameters. The generalised solution contains the information for all the geometric parameters in a user-defined range and it can be used to compute sensitivities. The proposed approach circumvents many of the weaknesses of other approaches based on the proper generalised decomposition for computing generalised solutions of geometrically parametrised problems. Four numerical examples show the optimal approximation properties of the proposed method and demonstrate its applicability in two and three dimensions.",
        "published": "2020-06-21T16:57:55Z",
        "link": "http://arxiv.org/abs/2006.11846v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "physics.comp-ph",
            "65M60, 76D07, 76M10"
        ]
    },
    {
        "title": "Large scale three-dimensional manufacturing tolerant stress-constrained   topology optimization",
        "authors": [
            "Gustavo Assis da Silva",
            "Niels Aage",
            "André Teófilo Beck",
            "Ole Sigmund"
        ],
        "summary": "In topology optimization, the treatment of stress constraints for very large scale problems has so far not been tractable due to the failure of robust agglomeration methods, i.e. their inability to accurately handle the locality of the stress constraints. This paper presents a three-dimensional design methodology that alleviates this shortcoming using both deterministic and robust problem formulations. The robust formulation, based on the three-field density projection approach, is extended to handle manufacturing uncertainty in three-dimensional stress-constrained problems. Several numerical examples are solved and further post-processed with body-fitted meshes using commercial software. The numerical investigations demonstrate that: (1) the employed solution approach based on the augmented Lagrangian method is able to handle large problems, with hundreds of millions of stress constraints; (2) if appropriate interpolation parameters are adopted, voxel-based (fixed grid) models can be used to compute von Mises stresses with excellent accuracy; and (3) in order to ensure manufacturing tolerance in three-dimensional stress-constrained topology optimization, a combination of double filtering and more than three realizations may be required.",
        "published": "2020-06-23T12:05:00Z",
        "link": "http://arxiv.org/abs/2006.12927v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Wavelet Augmented Regression Profiling (WARP): improved long-term   estimation of travel time series with recurrent congestion",
        "authors": [
            "Alvaro Cabrejas Egea",
            "Colm Connaughton"
        ],
        "summary": "Reliable estimates of typical travel times allow road users to forward plan journeys to minimise travel time, potentially increasing overall system efficiency. On busy highways, however, congestion events can cause large, short-term spikes in travel time. These spikes make direct forecasting of travel time using standard time series models difficult on the timescales of hours to days that are relevant to forward planning. The problem is that some such spikes are caused by unpredictable incidents and should be filtered out, whereas others are caused by recurrent peaks in demand and should be factored into estimates. Here we present the Wavelet Augmented Regression Profiling (WARP) method for long-term estimation of typical travel times. WARP linearly decomposes historical time series of travel times into two components: background and spikes. It then further separates the spikes into contributions from recurrent and residual congestion. This is achieved using a combination of wavelet transforms, spectral filtering and locally weighted regression. The background and recurrent congestion contributions are then used to estimate typical travel times with horizon of one week in an accurate and computationally inexpensive manner. We train and test WARP on the M6 and M11 motorways in the United Kingdom using 12 weeks of link level travel time data obtained from the UK's National Traffic Information Service (NTIS). In out-of-sample validation tests, WARP compares favourably to estimates produced by a simple segmentation method and to the estimates published by NTIS.",
        "published": "2020-06-23T14:50:28Z",
        "link": "http://arxiv.org/abs/2006.13072v1",
        "categories": [
            "cs.CE",
            "stat.AP"
        ]
    },
    {
        "title": "Level set based eXtended finite element modelling of the response of   fibrous networks under hygroscopic swelling",
        "authors": [
            "P. Samantray",
            "R. H. J. Peerlings",
            "E. Bosco",
            "M. G. D. Geers",
            "T. J. Massart",
            "O. Rokoš"
        ],
        "summary": "Materials like paper, consisting of a network of natural fibres, exposed to variations in moisture, undergo changes in geometrical and mechanical properties. This behaviour is particularly important for understanding the hygro-mechanical response of sheets of paper in applications like digital printing. A two-dimensional microstructural model of a fibrous network is therefore developed to upscale the hygro-expansion of individual fibres, through their interaction, to the resulting overall expansion of the network. The fibres are modelled with rectangular shapes and are assumed to be perfectly bonded where they overlap. For realistic networks the number of bonds is large and the network is geometrically so complex that discretizing it by conventional, geometry-conforming, finite elements is cumbersome. The combination of a level-set and XFEM formalism enables the use of regular, structured grids in order to model the complex microstructural geometry. In this approach, the fibres are described implicitly by a level-set function. In order to represent the fibre boundaries in the fibrous network, an XFEM discretization is used together with a Heaviside enrichment function. Numerical results demonstrate that the proposed approach successfully captures the hygro-expansive properties of the network with fewer degrees of freedom compared to classical FEM, preserving desired accuracy.",
        "published": "2020-06-23T14:59:39Z",
        "link": "http://arxiv.org/abs/2006.14049v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Fast Optimization of Temperature Focusing in Hyperthermia Treatment of   Sub-Superficial Tumors",
        "authors": [
            "Rossella Gaffoglio",
            "Marco Righero",
            "Giorgio Giordanengo",
            "Marcello Zucchi",
            "Giuseppe Vecchi"
        ],
        "summary": "Microwave hyperthermia aims at selectively heating cancer cells to a supra-physiological temperature. For non-superficial tumors, this can be achieved by means of an antenna array equipped with a proper cooling system (the water bolus) to avoid overheating of the skin. In patient-specific treatment planning, antenna feedings are optimized to maximize the specific absorption rate (SAR) inside the tumor, or to directly maximize the temperature there, involving a higher numerical cost. We present here a method to effect a low-complexity temperature-based planning. It arises from recognizing that SAR and temperature have shifted peaks due to thermal boundary conditions at the water bolus and for physiological effects like air flow in respiratory ducts. In our method, temperature focusing on the tumor is achieved via a SAR-based optimization of the antenna excitations, but optimizing its target to account for the cooling effects. The temperature optimization process is turned into finding a SAR peak position that maximizes the chosen temperature objective function. Application of this method to the 3D head and neck region provides a temperature coverage that is consistently better than that obtained with SAR-optimization alone, also considering uncertainties in thermal parameters. This improvement is obtained by solving the bioheat equation a reduced number of times, avoiding its inclusion in a global optimization process.",
        "published": "2020-06-23T18:33:24Z",
        "link": "http://arxiv.org/abs/2006.13261v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "The Power of Connection: Leveraging Network Analysis to Advance   Receivable Financing",
        "authors": [
            "Ilaria Bordino",
            "Francesco Gullo",
            "Giacomo Legnaro"
        ],
        "summary": "Receivable financing is the process whereby cash is advanced to firms against receivables their customers have yet to pay: a receivable can be sold to a funder, which immediately gives the firm cash in return for a small percentage of the receivable amount as a fee. Receivable financing has been traditionally handled in a centralized way, where every request is processed by the funder individually and independently of one another. In this work we propose a novel, network-based approach to receivable financing, which enables customers of the same funder to autonomously pay each other as much as possible, and gives benefits to both the funder (reduced cash anticipation and exposure risk) and its customers (smaller fees and lightweight service establishment). Our main contributions consist in providing a principled formulation of the network-based receivable-settlement strategy, and showing how to achieve all algorithmic challenges posed by the design of this strategy. We formulate network-based receivable financing as a novel combinatorial-optimization problem on a multigraph of receivables. We show that the problem is NP-hard, and devise an exact branch-and-bound algorithm, as well as algorithms to efficiently find effective approximate solutions. Our more efficient algorithms are based on cycle enumeration and selection, and exploit a theoretical characterization in terms of a knapsack problem, as well as a refining strategy that properly adds paths between cycles. We also investigate the real-world issue of avoiding temporary violations of the problem constraints, and design methods for handling it. An extensive experimental evaluation is performed on real receivable data. Results attest the good performance of our methods.",
        "published": "2020-06-24T13:52:14Z",
        "link": "http://arxiv.org/abs/2006.13738v1",
        "categories": [
            "cs.DS",
            "cs.CE",
            "cs.SI"
        ]
    },
    {
        "title": "Accelerating MRI Reconstruction on TPUs",
        "authors": [
            "Tianjian Lu",
            "Thibault Marin",
            "Yue Zhuo",
            "Yi-Fan Chen",
            "Chao Ma"
        ],
        "summary": "The advanced magnetic resonance (MR) image reconstructions such as the compressed sensing and subspace-based imaging are considered as large-scale, iterative, optimization problems. Given the large number of reconstructions required by the practical clinical usage, the computation time of these advanced reconstruction methods is often unacceptable. In this work, we propose using Google's Tensor Processing Units (TPUs) to accelerate the MR image reconstruction. TPU is an application-specific integrated circuit (ASIC) for machine learning applications, which has recently been used to solve large-scale scientific computing problems. As proof-of-concept, we implement the alternating direction method of multipliers (ADMM) in TensorFlow to reconstruct images on TPUs. The reconstruction is based on multi-channel, sparsely sampled, and radial-trajectory $k$-space data with sparsity constraints. The forward and inverse non-uniform Fourier transform operations are formulated in terms of matrix multiplications as in the discrete Fourier transform. The sparsifying transform and its adjoint operations are formulated as convolutions. The data decomposition is applied to the measured $k$-space data such that the aforementioned tensor operations are localized within individual TPU cores. The data decomposition and the inter-core communication strategy are designed in accordance with the TPU interconnect network topology in order to minimize the communication time. The accuracy and the high parallel efficiency of the proposed TPU-based image reconstruction method are demonstrated through numerical examples.",
        "published": "2020-06-24T22:18:39Z",
        "link": "http://arxiv.org/abs/2006.14080v1",
        "categories": [
            "cs.CE",
            "eess.IV"
        ]
    },
    {
        "title": "Extracting Non-Gaussian Governing Laws from Data on Mean Exit Time",
        "authors": [
            "Yanxia Zhang",
            "Jinqiao Duan",
            "Yanfei Jin",
            "Yang Li"
        ],
        "summary": "Motivated by the existing difficulties in establishing mathematical models and in observing the system state time series for some complex systems, especially for those driven by non-Gaussian Levy motion, we devise a method for extracting non-Gaussian governing laws with observations only on mean exit time. It is feasible to observe mean exit time for certain complex systems. With the observations, a sparse regression technique in the least squares sense is utilized to obtain the approximated function expression of mean exit time. Then, we learn the generator and further identify the stochastic differential equations through solving an inverse problem for a nonlocal partial differential equation and minimizing an error objective function. Finally, we verify the efficacy of the proposed method by three examples with the aid of the simulated data from the original systems. Results show that the method can apply to not only the stochastic dynamical systems driven by Gaussian Brownian motion but also those driven by non-Gaussian Levy motion, including those systems with complex rational drift.",
        "published": "2020-06-24T22:35:06Z",
        "link": "http://arxiv.org/abs/2006.14974v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Estimating Asset Class Health Indices in Power Systems",
        "authors": [
            "Ming Dong"
        ],
        "summary": "Power systems have widely adopted the concept of health index to describe asset health statuses and choose proper asset management actions. The existing application and research works have been focused on determining the current or near-future asset health index based on the current condition data. For preventative asset management, it is highly desirable to estimate asset health indices, especially for asset classes in which the assets share similar electrical and/or mechanical characteristics. This important problem has not been sufficiently addressed. This paper proposes a sequence learning based method to estimate health indices for power asset classes. A comprehensive data-driven method based on sequence learning is presented and solid tests are conducted based on real utility data. The proposed method revealed superior performance with comparison to other Estimation methods.",
        "published": "2020-06-25T06:15:43Z",
        "link": "http://arxiv.org/abs/2006.14193v3",
        "categories": [
            "cs.CE",
            "eess.SP"
        ]
    },
    {
        "title": "An unsupervised deep learning approach in solving partial   integro-differential equations",
        "authors": [
            "Ali Hirsa",
            "Weilong Fu"
        ],
        "summary": "We investigate solving partial integro-differential equations (PIDEs) using unsupervised deep learning in this paper. To price options, assuming underlying processes follow Levy processes, we require to solve PIDEs. In supervised deep learning, pre-calculated labels are used to train neural networks to fit the solution of the PIDE. In an unsupervised deep learning, neural networks are employed as the solution, and the derivatives and the integrals in the PIDE are calculated based on the neural network. By matching the PIDE and its boundary conditions, the neural network gives an accurate solution of the PIDE. Once trained, it would be fast for calculating options values as well as option Greeks.",
        "published": "2020-06-26T15:01:05Z",
        "link": "http://arxiv.org/abs/2006.15012v3",
        "categories": [
            "q-fin.CP",
            "cs.CE"
        ]
    },
    {
        "title": "A high-order well-balanced positivity-preserving moving mesh DG method   for the shallow water equations with non-flat bottom topography",
        "authors": [
            "Min Zhang",
            "Weizhang Huang",
            "Jianxian Qiu"
        ],
        "summary": "A rezoning-type adaptive moving mesh discontinuous Galerkin method is proposed for the numerical solution of the shallow water equations with non-flat bottom topography. The well-balance property is crucial to the simulation of perturbation waves over the lake-at-rest steady state such as waves on a lake or tsunami waves in the deep ocean. To ensure the well-balance and positivity-preserving properties, strategies are discussed in the use of slope limiting, positivity-preservation limiting, and data transferring between meshes. Particularly, it is suggested that a DG-interpolation scheme be used for the interpolation of both the flow variables and bottom topography from the old mesh to the new one and after each application of the positivity-preservation limiting on the water depth, a high-order correction be made to the approximation of the bottom topography according to the modifications in the water depth. Moreover, mesh adaptation based on the equilibrium variable and water depth is shown to give more desirable results than that based on the commonly used entropy function. Numerical examples in one and two spatial dimensions are presented to demonstrate the well-balance and positivity-preserving properties of the method and its ability to capture small perturbations of the lake-at-rest steady state.",
        "published": "2020-06-26T19:28:34Z",
        "link": "http://arxiv.org/abs/2006.15187v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "65M50, 65M60, 76B15, 35Q35"
        ]
    },
    {
        "title": "Spiral capacitor calculation using FEniCS",
        "authors": [
            "Slava Andrejev"
        ],
        "summary": "The paper shows how to optimize a water level sensor consisting of a cylinder with spiraling metal stripes on the side, using a powerful Python library FEniCS. It is shown how to reduce a 3D Laplace equation to a 2D, using a spiraling coordinate system; how to specify the correct boundary conditions for an open region; how to convert the partial differential equation to a variational form for FEniCS; and how to calculate the capacitance. Then the FEniCS code is shown that solves the Laplace equation and calculates the capacitance. The further numeric experiments show that there is an optimal combination of the spiral frequency and the width of the stripes that maximizes the sensitivity of the sensor. The Python code is given to calculate the optimum.",
        "published": "2020-06-26T22:13:17Z",
        "link": "http://arxiv.org/abs/2006.16919v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Data-Driven Topology Optimization with Multiclass Microstructures using   Latent Variable Gaussian Process",
        "authors": [
            "Liwei Wang",
            "Siyu Tao",
            "Ping Zhu",
            "Wei Chen"
        ],
        "summary": "The data-driven approach is emerging as a promising method for the topological design of multiscale structures with greater efficiency. However, existing data-driven methods mostly focus on a single class of microstructures without considering multiple classes to accommodate spatially varying desired properties. The key challenge is the lack of an inherent ordering or distance measure between different classes of microstructures in meeting a range of properties. To overcome this hurdle, we extend the newly developed latent-variable Gaussian process (LVGP) models to create multi-response LVGP (MR-LVGP) models for the microstructure libraries of metamaterials, taking both qualitative microstructure concepts and quantitative microstructure design variables as mixed-variable inputs. The MR-LVGP model embeds the mixed variables into a continuous design space based on their collective effects on the responses, providing substantial insights into the interplay between different geometrical classes and material parameters of microstructures. With this model, we can easily obtain a continuous and differentiable transition between different microstructure concepts that can render gradient information for multiscale topology optimization. We demonstrate its benefits through multiscale topology optimization with aperiodic microstructures. Design examples reveal that considering multiclass microstructures can lead to improved performance due to the consistent load-transfer paths for micro- and macro-structures.",
        "published": "2020-06-27T03:55:52Z",
        "link": "http://arxiv.org/abs/2006.15273v2",
        "categories": [
            "cs.CE",
            "cs.LG",
            "stat.ML"
        ]
    },
    {
        "title": "Deep Generative Modeling for Mechanistic-based Learning and Design of   Metamaterial Systems",
        "authors": [
            "Liwei Wang",
            "Yu-Chin Chan",
            "Faez Ahmed",
            "Zhao Liu",
            "Ping Zhu",
            "Wei Chen"
        ],
        "summary": "Metamaterials are emerging as a new paradigmatic material system to render unprecedented and tailorable properties for a wide variety of engineering applications. However, the inverse design of metamaterial and its multiscale system is challenging due to high-dimensional topological design space, multiple local optima, and high computational cost. To address these hurdles, we propose a novel data-driven metamaterial design framework based on deep generative modeling. A variational autoencoder (VAE) and a regressor for property prediction are simultaneously trained on a large metamaterial database to map complex microstructures into a low-dimensional, continuous, and organized latent space. We show in this study that the latent space of VAE provides a distance metric to measure shape similarity, enable interpolation between microstructures and encode meaningful patterns of variation in geometries and properties. Based on these insights, systematic data-driven methods are proposed for the design of microstructure, graded family, and multiscale system. For microstructure design, the tuning of mechanical properties and complex manipulations of microstructures are easily achieved by simple vector operations in the latent space. The vector operation is further extended to generate metamaterial families with a controlled gradation of mechanical properties by searching on a constructed graph model. For multiscale metamaterial systems design, a diverse set of microstructures can be rapidly generated using VAE for target properties at different locations and then assembled by an efficient graph-based optimization method to ensure compatibility between adjacent microstructures. We demonstrate our framework by designing both functionally graded and heterogeneous metamaterial systems that achieve desired distortion behaviors.",
        "published": "2020-06-27T03:56:55Z",
        "link": "http://arxiv.org/abs/2006.15274v2",
        "categories": [
            "cs.CE",
            "cs.LG",
            "stat.ML"
        ]
    },
    {
        "title": "Tusas: A fully implicit parallel approach for coupled phase-field   equations",
        "authors": [
            "Supriyo Ghosh",
            "Christopher K. Newman",
            "Marianne M. Francois"
        ],
        "summary": "We develop a fully-coupled, fully-implicit approach for phase-field modeling of solidification in metals and alloys. Predictive simulation of solidification in pure metals and metal alloys remains a significant challenge in the field of materials science, as microstructure formation during the solidification process plays a critical role in the properties and performance of the solid material. Our simulation approach consists of a finite element spatial discretization of the fully-coupled nonlinear system of partial differential equations at the microscale, which is treated implicitly in time with a preconditioned Jacobian-free Newton-Krylov method. The approach allows time steps larger than those restricted by the traditional explicit CFL limit and is algorithmically scalable as well as efficient due to an effective preconditioning strategy based on algebraic multigrid and block factorization. We implement this approach in the open-source Tusas framework, which is a general, flexible tool developed in C++ for solving coupled systems of nonlinear partial differential equations. The performance of our approach is analyzed in terms of algorithmic scalability and efficiency, while the computational performance of Tusas is presented in terms of parallel scalability and efficiency on emerging heterogeneous architectures. We demonstrate that modern algorithms, discretizations, and computational science, and heterogeneous hardware provide a robust route for predictive phase-field simulation of microstructure evolution during additive manufacturing.",
        "published": "2020-06-27T05:19:53Z",
        "link": "http://arxiv.org/abs/2006.16764v2",
        "categories": [
            "cs.CE",
            "cond-mat.mtrl-sci"
        ]
    },
    {
        "title": "A new level set-finite element formulation for anisotropic grain   boundary migration",
        "authors": [
            "J. Fausty",
            "B. Murgas",
            "S. Florez",
            "N. Bozzolo",
            "M. Bernacki"
        ],
        "summary": "Grain growth in polycrystals is one of the principal mechanisms that take place during heat treatment of metallic components. This work treats an aspect of the anisotropic grain growth problem. By applying the first principles of thermodynamics and mechanics, an expression for the velocity field of a migrating grain boundary with an inclination dependent energy density is expressed. This result is used to generate the first, to the authors' knowledge, analytical solution (for both the form and kinetics) to an anisotropic boundary configuration. This new benchmark is simulated in order to explore the convergence properties of the proposed level set finite element numerical model in an anisotropic setting. Convergence of the method being determined, another configuration, using a more general grain boundary energy density, is investigated in order to show the added value of the new formulation.",
        "published": "2020-06-28T07:51:07Z",
        "link": "http://arxiv.org/abs/2006.15531v1",
        "categories": [
            "cs.CE",
            "cond-mat.mtrl-sci",
            "math.DG"
        ]
    },
    {
        "title": "A spectral collocation method for the Landau equation in plasma physics",
        "authors": [
            "Francis Filbet"
        ],
        "summary": "In this paper we present a spectral collocation method for the fast evaluation of the Landau collision operator for plasma physics, which allows us to obtain spectrally accurate numerical solutions. The method is inspired by the seminal work [36], but it is specifically designed for Coulombian interactions, taking into account the particular structure of the operator. It allows us to reduce the number of discrete convolutions to provide an approximation of the Landau operator. Then, we show that the method preserves the total mass whereas momentum and energy are approximated with spectral accuracy. Numerical results for the Landau equation in three dimensions in velocity space are presented to illustrate the efficiency of the present approach.",
        "published": "2020-06-29T09:22:48Z",
        "link": "http://arxiv.org/abs/2006.15885v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Parametric Modeling of EEG by Mono-Component Non-Stationary Signal",
        "authors": [
            "Pradip Sircar",
            "Rakesh Kumar Sharma"
        ],
        "summary": "In this paper, we propose a novel approach for parametric modeling of electroencephalographic (EEG) signals. It is demonstrated that the EEG signal is a mono-component non-stationary signal whose amplitude and phase (frequency) can be expressed as functions of time. We present detailed strategy for estimation of the parameters of the proposed model with high accuracy. Simulation study illustrates the procedure of model fitting. Some interpretation of the characteristic features of the model is described.",
        "published": "2020-06-29T10:02:15Z",
        "link": "http://arxiv.org/abs/2006.15911v1",
        "categories": [
            "cs.CE",
            "eess.SP",
            "94-10",
            "H.1; H.4"
        ]
    },
    {
        "title": "A new Hodge operator in Discrete Exterior Calculus. Application to fluid   mechanics",
        "authors": [
            "Rama Ayoub",
            "Aziz Hamdouni",
            "Dina Razafindralandy"
        ],
        "summary": "This article introduces a new and general construction of discrete Hodge operator in the context of Discrete Exterior Calculus (DEC). This discrete Hodge operator enables to circumvent the well-centeredness limitation on the mesh with the popular diagonal Hodge. It allows a dual mesh based on any interior point, such as the incenter or the barycenter. It opens the way towards mesh-optimized discrete Hodge operators. In the particular case of a well-centered triangulation, it reduces to the diagonal Hodge if the dual mesh is circumcentric. Based on an analytical development, this discrete Hodge does not make use of Whitney forms, and is exact on piecewise constant forms, whichever interior point is chosen for the construction of the dual mesh. Numerical tests oriented to the resolution of fluid mechanics problems and thermal transfer are carried out. Convergence on various types of mesh is investigated.",
        "published": "2020-06-29T11:58:03Z",
        "link": "http://arxiv.org/abs/2006.16930v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Applying Dynamic Training-Subset Selection Methods Using Genetic   Programming for Forecasting Implied Volatility",
        "authors": [
            "Sana Ben Hamida",
            "Wafa Abdelmalek",
            "Fathi Abid"
        ],
        "summary": "Volatility is a key variable in option pricing, trading and hedging strategies. The purpose of this paper is to improve the accuracy of forecasting implied volatility using an extension of genetic programming (GP) by means of dynamic training-subset selection methods. These methods manipulate the training data in order to improve the out of sample patterns fitting. When applied with the static subset selection method using a single training data sample, GP could generate forecasting models which are not adapted to some out of sample fitness cases. In order to improve the predictive accuracy of generated GP patterns, dynamic subset selection methods are introduced to the GP algorithm allowing a regular change of the training sample during evolution. Four dynamic training-subset selection methods are proposed based on random, sequential or adaptive subset selection. The latest approach uses an adaptive subset weight measuring the sample difficulty according to the fitness cases errors. Using real data from SP500 index options, these techniques are compared to the static subset selection method. Based on MSE total and percentage of non fitted observations, results show that the dynamic approach improves the forecasting performance of the generated GP models, specially those obtained from the adaptive random training subset selection method applied to the whole set of training samples.",
        "published": "2020-06-29T21:28:30Z",
        "link": "http://arxiv.org/abs/2007.07207v1",
        "categories": [
            "q-fin.GN",
            "cs.CE",
            "cs.NE",
            "68Uxx"
        ]
    },
    {
        "title": "Dynamic Hedging using Generated Genetic Programming Implied Volatility   Models",
        "authors": [
            "Fathi Abid",
            "Wafa Abdelmalek",
            "Sana Ben Hamida"
        ],
        "summary": "The purpose of this paper is to improve the accuracy of dynamic hedging using implied volatilities generated by genetic programming. Using real data from S&P500 index options, the genetic programming's ability to forecast Black and Scholes implied volatility is compared between static and dynamic training-subset selection methods. The performance of the best generated GP implied volatilities is tested in dynamic hedging and compared with Black-Scholes model. Based on MSE total, the dynamic training of GP yields better results than those obtained from static training with fixed samples. According to hedging errors, the GP model is more accurate almost in all hedging strategies than the BS model, particularly for in-the-money call options and at-the-money put options.",
        "published": "2020-06-29T21:57:00Z",
        "link": "http://arxiv.org/abs/2006.16407v1",
        "categories": [
            "q-fin.CP",
            "cs.CE",
            "68"
        ]
    },
    {
        "title": "A Bayesian regularization-backpropagation neural network model for   peeling computations",
        "authors": [
            "Saipraneeth Gouravaraju",
            "Jyotindra Narayan",
            "Roger A. Sauer",
            "Sachin Singh Gautam"
        ],
        "summary": "Bayesian regularization-backpropagation neural network (BR-BPNN) model is employed to predict some aspects of the gecko spatula peeling viz. the variation of the maximum normal and tangential pull-off forces and the resultant force angle at detachment with the peeling angle. K-fold cross validation is used to improve the effectiveness of the model. The input data is taken from finite element (FE) peeling results. The neural network is trained with 75% of the FE dataset. The remaining 25% are utilized to predict the peeling behavior. The training performance is evaluated for every change in the number of hidden layer neurons to determine the optimal network structure. The relative error is calculated to draw a clear comparison between predicted and FE results. It is shown that the BR-BPNN model in conjunction with k-fold technique has significant potential to estimate the peeling behavior.",
        "published": "2020-06-29T21:58:43Z",
        "link": "http://arxiv.org/abs/2006.16409v3",
        "categories": [
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "On the Potential of Dynamic Substructuring Methods for Model Updating",
        "authors": [
            "Thomas Simpson",
            "Vasilis Dertimanis",
            "Costas Papadimitriou",
            "Eleni Chatzi"
        ],
        "summary": "While purely data-driven assessment is feasible for the first levels of the Structural Health Monitoring (SHM) process, namely damage detection and arguably damage localization, this does not hold true for more advanced processes. The tasks of damage quantification and eventually residual life prognosis are invariably linked to availability of a representation of the system, which bears physical connotation. In this context, it is often desirable to assimilate data and models, into what is often termed a digital twin of the monitored system.   One common take to such an end lies in exploitation of structural mechanics models, relying on use of Finite Element approximations. proper updating of these models, and their incorporation in an inverse problem setting may allow for damage quantification and localization, as well as more advanced tasks, including reliability analysis and fatigue assessment. However, this may only be achieved by means of repetitive analyses of the forward model, which implies considerable computational toll, when the model used is a detailed FE representation. In tackling this issue, reduced order models can be adopted, which retain the parameterisation and link to the parameters regulating the physical properties, albeit greatly reducing the computational burden.   In this work a detailed FE model of a wind turbine tower is considered, reduced forms of this model are found using both the Craig Bampton and Dual Craig Bampton methods. These reduced order models are then used and compared in a Transitional Markov Chain Monte Carlo procedure to localise and quantify damage which is introduced to the system.",
        "published": "2020-06-30T08:11:50Z",
        "link": "http://arxiv.org/abs/2006.16596v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "On Dynamic Substructuring of Systems with Localised Nonlinearities",
        "authors": [
            "Thomas Simpson",
            "Dimitrios Giagopoulos",
            "Vasilis Dertimanis",
            "Eleni Chatzi"
        ],
        "summary": "Dynamic substructuring (DS) methods encompass a range of techniques to decompose large structural systems into multiple coupled subsystems. This decomposition has the principle benefit of reducing computational time for dynamic simulation of the system. In this context, DS methods may form an essential component of hybrid simulation, wherein they can be used to couple physical and numerical substructures at reduced computational cost. Since most engineered systems are inherently nonlinear, particular potential lies in incorporating nonlinear methods in existing substructuring schemes which are largely linear methods.   The most widely used and studied DS methods are classical linear techniques such as the Craig-Bampton (CB) method. However, as linear methods they naturally break down in the presence of nonlinearities. Recent advancements in substructuring have involved the development of enrichments to linear methods, which allow for some degree of nonlinearity to be captured. The use of mode shape derivatives has been shown to be able to capture geometrically non-linear effects as an extension to the CBmethod. Other candidates include the method of Finite Element Tearing and Interconnecting.   In this work, a virtual hybrid simulation is presented in which a linear elastic vehicle frame supported on four nonlinear spring damper isolators is decomposed into separate domains. One domain consisting of the finite element model of the vehicle frame, which is reduced using the CB method. The second domain consists of the nonlinear isolators whose restoring forces are characterised by nonlinear spring and damper forces. Coupling between the models is carried out using a Lagrange multiplier method and time series simulations of the system are conducted and compared to the full global system with regards to simulation time and accuracy.",
        "published": "2020-06-30T09:06:42Z",
        "link": "http://arxiv.org/abs/2006.16612v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Dynamic Portfolio Optimization with Real Datasets Using Quantum   Processors and Quantum-Inspired Tensor Networks",
        "authors": [
            "Samuel Mugel",
            "Carlos Kuchkovsky",
            "Escolastico Sanchez",
            "Samuel Fernandez-Lorenzo",
            "Jorge Luis-Hita",
            "Enrique Lizaso",
            "Roman Orus"
        ],
        "summary": "In this paper we tackle the problem of dynamic portfolio optimization, i.e., determining the optimal trading trajectory for an investment portfolio of assets over a period of time, taking into account transaction costs and other possible constraints. This problem is central to quantitative finance. After a detailed introduction to the problem, we implement a number of quantum and quantum-inspired algorithms on different hardware platforms to solve its discrete formulation using real data from daily prices over 8 years of 52 assets, and do a detailed comparison of the obtained Sharpe ratios, profits and computing times. In particular, we implement classical solvers (Gekko, exhaustive), D-Wave Hybrid quantum annealing, two different approaches based on Variational Quantum Eigensolvers on IBM-Q (one of them brand-new and tailored to the problem), and for the first time in this context also a quantum-inspired optimizer based on Tensor Networks. In order to fit the data into each specific hardware platform, we also consider doing a preprocessing based on clustering of assets. From our comparison, we conclude that D-Wave Hybrid and Tensor Networks are able to handle the largest systems, where we do calculations up to 1272 fully-connected qubits for demonstrative purposes. Finally, we also discuss how to mathematically implement other possible real-life constraints, as well as several ideas to further improve the performance of the studied methods.",
        "published": "2020-06-30T18:00:03Z",
        "link": "http://arxiv.org/abs/2007.00017v2",
        "categories": [
            "quant-ph",
            "cs.CE",
            "q-fin.ST"
        ]
    },
    {
        "title": "A $C^1$-continuous Trace-Finite-Cell-Method for linear thin shell   analysis on implicitly defined surfaces",
        "authors": [
            "Michael Gfrerer"
        ],
        "summary": "A Trace-Finite-Cell-Method for the numerical analysis of thin shells is presented combining concepts of the TraceFEM and the Finite-Cell-Method. As an underlying shell model we use the Koiter model, which we re-derive in strong form based on first principles of continuum mechanics by recasting well-known relations formulated in local coordinates to a formulation independent of a parametrization. The field approximation is constructed by restricting shape functions defined on a structured background grid on the shell surface. As shape functions we use on a background grid the tensor product of cubic splines. This yields $C^1$-continuous approximation spaces, which are required by the governing equations of fourth order. The parametrization-free formulation allows a natural implementation of the proposed method and manufactured solutions on arbitrary geometries for code verification. Thus, the implementation is verified by a convergence analysis where the error is computed with an exact manufactured solution. Furthermore, benchmark tests are investigated.",
        "published": "2020-06-30T19:44:13Z",
        "link": "http://arxiv.org/abs/2007.00075v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Fast Computation of Electromagnetic Wave Propagation and Scattering for   Quasi-cylindrical Geometry",
        "authors": [
            "Shaolin Liao"
        ],
        "summary": "The cylindrical Taylor Interpolation through FFT (TI-FFT) algorithm for computation of the near-field and far-field in the quasi-cylindrical geometry has been introduced. The modal expansion coefficient of the vector potentials ${\\bf F}$ and ${\\bf A}$ within the context of the cylindrical harmonics (TE and TM modes) can be expressed in the closed-form expression through the cylindrical addition theorem. For the quasi-cylindrical geometry, the modal expansion coefficient can be evaluated through FFT with the help of the Taylor Interpolation (TI) technique. The near-field on any arbitrary cylindrical surface can be obtained through the Inverse Fourier Transform (IFT). The far-field can be obtained through the Near-Field Far-Field (NF-FF) transform. The cylindrical TI-FFT algorithm has the advantages of $\\mathcal{O} \\left( \\hbox{N} \\log_2 \\hbox{N} \\right)$ computational complexity for $\\hbox{N} = \\hbox{N}_\\phi \\times \\hbox{N}_z$ computational grid, small sampling rate (large sampling spacing) and no singularity problem.",
        "published": "2020-07-01T00:54:17Z",
        "link": "http://arxiv.org/abs/2007.01702v1",
        "categories": [
            "eess.SP",
            "cs.CE"
        ]
    },
    {
        "title": "Sparse Approximate Multifrontal Factorization with Butterfly Compression   for High Frequency Wave Equations",
        "authors": [
            "Yang Liu",
            "Pieter Ghysels",
            "Lisa Claus",
            "Xiaoye Sherry Li"
        ],
        "summary": "We present a fast and approximate multifrontal solver for large-scale sparse linear systems arising from finite-difference, finite-volume or finite-element discretization of high-frequency wave equations. The proposed solver leverages the butterfly algorithm and its hierarchical matrix extension for compressing and factorizing large frontal matrices via graph-distance guided entry evaluation or randomized matrix-vector multiplication-based schemes. Complexity analysis and numerical experiments demonstrate $\\mathcal{O}(N\\log^2 N)$ computation and $\\mathcal{O}(N)$ memory complexity when applied to an $N\\times N$ sparse system arising from 3D high-frequency Helmholtz and Maxwell problems.",
        "published": "2020-07-01T03:27:33Z",
        "link": "http://arxiv.org/abs/2007.00202v2",
        "categories": [
            "cs.MS",
            "cs.CE",
            "15A23, 65F50, 65R10, 65R20"
        ]
    },
    {
        "title": "A finite element model updating method based on global optimization",
        "authors": [
            "Maria Girardi",
            "Cristina Padovani",
            "Daniele Pellegrini",
            "Leonardo Robol"
        ],
        "summary": "Finite element model updating of a structure made of linear elastic materials is based on the solution of a minimization problem. The goal is to find some unknown parameters of the finite element model (elastic moduli, mass densities, constraints and boundary conditions) that minimize an objective function which evaluates the discrepancy between experimental and numerical dynamic properties. The objective function depends nonlinearly on the parameters and may have multiple local minimum points. This paper presents a numerical method able to find a global minimum point and assess its reliability. The numerical method has been tested on two simulated examples - a masonry tower and a domed temple - and validated via a generic genetic algorithm and a global sensitivity analysis tool. A real case study monitored under operational conditions has also been addressed, and the structure's experimental modal properties have been used in the model updating procedure to estimate the mechanical properties of its constituent materials.",
        "published": "2020-07-01T07:09:55Z",
        "link": "http://arxiv.org/abs/2007.00278v2",
        "categories": [
            "cs.CE",
            "D.2.0; G.1.6; G.1.10"
        ]
    },
    {
        "title": "A polynomial dimensional decomposition framework based on topology   derivatives for stochastic topology sensitivity analysis of high-dimensional   complex systems and a type of benchmark problems",
        "authors": [
            "Xuchun Ren"
        ],
        "summary": "In this paper, a new computational framework based on the topology derivative concept is presented for evaluating stochastic topological sensitivities of complex systems. The proposed framework, designed for dealing with high dimensional random inputs, dovetails a polynomial dimensional decomposition (PDD) of multivariate stochastic response functions and deterministic topology derivatives. On one hand, it provides analytical expressions to calculate topology sensitivities of the first three stochastic moments which are often required in robust topology optimization (RTO). On another hand, it offers embedded Monte Carlo Simulation (MCS) and finite difference formulations to estimate topology sensitivities of failure probability for reliability-based topology optimization (RBTO). For both cases, the quantification of uncertainties and their topology sensitivities are determined concurrently from a single stochastic analysis. Moreover, an original example of two random variables is developed for the first time to obtain analytical solutions for topology sensitivity of moments and failure probability. Another 53-dimension example is constructed for analytical solutions of topology sensitivity of moments and semi-analytical solutions of topology sensitivity of failure probabilities in order to verify the accuracy and efficiency of the proposed method for high-dimensional scenarios. Those examples are new and make it possible for researchers to benchmark stochastic topology sensitivities of existing or new algorithms. In addition, it is unveiled that under certain conditions the proposed method achieves better accuracies for stochastic topology sensitivities than for the stochastic quantities themselves.",
        "published": "2020-07-02T02:30:55Z",
        "link": "http://arxiv.org/abs/2007.06707v2",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA",
            "74pxx"
        ]
    },
    {
        "title": "Computational methods for cancer driver discovery: A survey",
        "authors": [
            "Vu Viet Hoang Pham",
            "Lin Liu",
            "Cameron Bracken",
            "Gregory Goodall",
            "Jiuyong Li",
            "Thuc Duy Le"
        ],
        "summary": "Motivation: Uncovering the genomic causes of cancer, known as cancer driver genes, is a fundamental task in biomedical research. Cancer driver genes drive the development and progression of cancer, thus identifying cancer driver genes and their regulatory mechanism is crucial to the design of cancer treatment and intervention. Many computational methods, which take the advantages of computer science and data science, have been developed to utilise multiple types of genomic data to reveal cancer drivers and their regulatory mechanism behind cancer development and progression. Due to the complexity of the mechanistic insight of cancer genes in driving cancer and the fast development of the field, it is necessary to have a comprehensive review about the current computational methods for discovering different types of cancer drivers. Results: We survey computational methods for identifying cancer drivers from genomic data. We categorise the methods into three groups, methods for single driver identification, methods for driver module identification, and methods for identifying personalised cancer drivers. We also conduct a case study to compare the performance of the current methods. We further analyse the advantages and limitations of the current methods, and discuss the challenges and future directions of the topic. In addition, we investigate the resources for discovering and validating cancer drivers in order to provide a one-stop reference of the tools to facilitate cancer driver discovery. The ultimate goal of the paper is to help those interested in the topic to establish a solid background to carry out further research in the field.",
        "published": "2020-07-02T05:18:08Z",
        "link": "http://arxiv.org/abs/2007.00887v1",
        "categories": [
            "q-bio.GN",
            "cs.CE"
        ]
    },
    {
        "title": "A differential neural network learns stochastic differential equations   and the Black-Scholes equation for pricing multi-asset options",
        "authors": [
            "Sang-Mun Chi"
        ],
        "summary": "Neural networks with sufficiently smooth activation functions can approximate values and derivatives of any smooth function, and they are differentiable themselves. We improve the approximation capability of neural networks by utilizing the differentiability of neural networks; the gradient and Hessian of neural networks are used to train the neural networks to satisfy the differential equations of the problems of interest. Several activation functions are also compared in term of effective differentiation of neural networks. We apply the differential neural networks to the pricing of financial options, where stochastic differential equations and the Black-Scholes partial differential equation represent the relation of price of option and underlying assets, and the first and second derivatives, Greeks, of option play important roles in financial engineering. The proposed neural network learns -- (a) the sample paths of option prices generated by stochastic differential equations and (b) the Black-Scholes equation at each time and asset price. Option pricing experiments were performed on multi-asset options such as exchange and basket options. Experimental results show that the proposed method gives accurate option values and Greeks; sufficiently smooth activation functions and the constraint of Black-Scholes equation contribute significantly for accurate option pricing.",
        "published": "2020-07-02T07:26:20Z",
        "link": "http://arxiv.org/abs/2007.00937v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "An Implementation of Partial Transmit Sequences to Design Energy   Efficient Underwater Acoustic OFDM Communication System",
        "authors": [
            "Waleed Raza",
            "Xuefei Ma",
            "Amir Ali",
            "Zubair Ali Shah",
            "Ghazanfar Mehdi"
        ],
        "summary": "In this article we research about underwater acoustics transceivers. As Underwater acoustic transceivers consume more power than Radio frequency transceivers. The techniques which are being utilized in radio frequency cannot be implemented directly in underwater acoustic system it needs to be re investigated to design new methods. To achieve reliable acoustic data transmission new techniques should be achieved or the traditional Orthogonal frequency divisional multiplexing techniques should be revised. The power consumption also relies upon underwater acoustic signal propagation and transmission distances. Several underwater acoustic applications require long-term monitoring of the sea. For the battery powered modems, it becomes very serious problem. By designing an Energy efficient OFDM Communication system we can solve this problem. We study about peak to average power ratio in an Orthogonal frequency divisional multiplexing system by reducing the major draw-back of OFDM system. The PAPR reduction utilized in this paper is Partial Transmit Sequences for underwater acoustic OFDM communication system which has lesser complexity. The results have provided better performance in underwater acoustic OFDM communication system.",
        "published": "2020-07-02T17:29:06Z",
        "link": "http://arxiv.org/abs/2007.01273v1",
        "categories": [
            "eess.SP",
            "cs.CE",
            "cs.IT",
            "math.IT"
        ]
    },
    {
        "title": "A variational formulation for motion design of adaptive compliant   structures",
        "authors": [
            "Renate Sachse",
            "Manfred Bischoff"
        ],
        "summary": "Adaptive structures are characterized by their ability to adjust their geometrical and other properties to changing loads or requirements during service. This contribution deals with a method for the design of quasi-static motions of structures between two prescribed geometrical configurations that are optimal with regard to a specified quality function while taking large deformations into account. It is based on a variational formulation and the solution by two finite element discretizations, the spatial discretization (the standard finite element mesh) and an additional discretization of the deformation path or trajectory. For the investigations, an exemplary objective function, the minimization of the internal energy, integrated along the deformation path, is used. The method for motion design presented herein uses the Newton-Raphson method as a second order optimization algorithm and allows for analytical sensitivity analysis. The proposed method is verified and its properties are investigated by benchmark examples including rigid body motions, instability phenomena and determination of inextensible deformations of shells.",
        "published": "2020-07-02T23:15:08Z",
        "link": "http://arxiv.org/abs/2007.01435v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Modes of Homogeneous Gradient Flows",
        "authors": [
            "Ido Cohen",
            "Omri Azencot",
            "Pavel Lifshitz",
            "Guy Gilboa"
        ],
        "summary": "Finding latent structures in data is drawing increasing attention in diverse fields such as image and signal processing, fluid dynamics, and machine learning. In this work we examine the problem of finding the main modes of gradient flows. Gradient descent is a fundamental process in optimization where its stochastic version is prominent in training of neural networks. Here our aim is to establish a consistent theory for gradient flows $\\psi_t = P(\\psi)$, where $P$ is a nonlinear homogeneous operator. Our proposed framework stems from analytic solutions of homogeneous flows, previously formalized by Cohen-Gilboa, where the initial condition $\\psi_0$ admits the nonlinear eigenvalue problem $P(\\psi_0)=\\lambda \\psi_0 $. We first present an analytic solution for \\ac{DMD} in such cases. We show an inherent flaw of \\ac{DMD}, which is unable to recover the essential dynamics of the flow. It is evident that \\ac{DMD} is best suited for homogeneous flows of degree one. We propose an adaptive time sampling scheme and show its dynamics are analogue to homogeneous flows of degree one with a fixed step size. Moreover, we adapt \\ac{DMD} to yield a real spectrum, using symmetric matrices. Our analytic solution of the proposed scheme recovers the dynamics perfectly and yields zero error. We then proceed to show that in the general case the orthogonal modes $\\{ \\phi_i \\}$ are approximately nonlinear eigenfunctions $P(\\phi_i) \\approx\\lambda_i \\phi_i $. We formulate Orthogonal Nonlinear Spectral decomposition (\\emph{OrthoNS}), which recovers the essential latent structures of the gradient descent process. Definitions for spectrum and filtering are given, and a Parseval-type identity is shown.",
        "published": "2020-07-03T07:51:34Z",
        "link": "http://arxiv.org/abs/2007.01534v3",
        "categories": [
            "math.DS",
            "cs.CE"
        ]
    },
    {
        "title": "Deep learning of thermodynamics-aware reduced-order models from data",
        "authors": [
            "Quercus Hernandez",
            "Alberto Badias",
            "David Gonzalez",
            "Francisco Chinesta",
            "Elias Cueto"
        ],
        "summary": "We present an algorithm to learn the relevant latent variables of a large-scale discretized physical system and predict its time evolution using thermodynamically-consistent deep neural networks. Our method relies on sparse autoencoders, which reduce the dimensionality of the full order model to a set of sparse latent variables with no prior knowledge of the coded space dimensionality. Then, a second neural network is trained to learn the metriplectic structure of those reduced physical variables and predict its time evolution with a so-called structure-preserving neural network. This data-based integrator is guaranteed to conserve the total energy of the system and the entropy inequality, and can be applied to both conservative and dissipative systems. The integrated paths can then be decoded to the original full-dimensional manifold and be compared to the ground truth solution. This method is tested with two examples applied to fluid and solid mechanics.",
        "published": "2020-07-03T08:49:01Z",
        "link": "http://arxiv.org/abs/2007.03758v2",
        "categories": [
            "cs.CE",
            "cs.LG",
            "stat.ML"
        ]
    },
    {
        "title": "Topology Optimization of Two Fluid Heat Exchangers",
        "authors": [
            "Lukas Christan Høghøj",
            "Daniel Ruberg Nørhave",
            "Joe Alexandersen",
            "Ole Sigmund",
            "Casper Schousboe Andreasen"
        ],
        "summary": "A method for density-based topology optimization of heat exchangers with two fluids is proposed. The goal of the optimization process is to maximize the heat transfer from one fluid to the other, under maximum pressure drop constraints for each of the fluid flows. A single design variable is used to describe the physical fields. The solid interface and the fluid domains are generated using an erosion-dilation based identification technique, which guarantees well-separated fluids, as well as a minimum wall thickness between them. Under the assumption of laminar steady flow, the two fluids are modelled separately, but in the entire computational domain using the Brinkman penalization technique for ensuring negligible velocities outside of the respective fluid subdomains. The heat transfer is modelled using the convection-diffusion equation, where the convection is driven by both fluid flows. A stabilized finite element discretization is used to solve the governing equations. Results are presented for two different problems: a two-dimensional example illustrating and verifying the methodology; and a three-dimensional example inspired by shell-and-tube heat exchangers. The optimized designs for both cases show an improved heat transfer compared to the baseline designs. For the shell-and-tube case, the full freedom topology optimization approach is shown to yield performance improvements of up to 113% under the same pressure drop.",
        "published": "2020-07-03T15:28:45Z",
        "link": "http://arxiv.org/abs/2007.01759v2",
        "categories": [
            "physics.flu-dyn",
            "cs.CE"
        ]
    },
    {
        "title": "Complexity matters: highly-accurate numerical models of coupled   radiative-conductive heat transfer in a laser flash experiment",
        "authors": [
            "Artem Lunev",
            "Vadim Zborovskii",
            "Teymur Aliev"
        ],
        "summary": "Thermal diffusivity measurements of samples transmitting thermal radiation require adjustments to the data treatment procedures in laser flash analysis. Conventionally, an unconstrained diathermic model is used. Current results show that the alternative coupled radiative-conductive models produce substantially different results -- for instance, at high temperatures in oxide ceramics. However, care must be taken to ensure accurate implementations of each constituent computational technique. The latter are presented in this work.",
        "published": "2020-07-03T18:22:23Z",
        "link": "http://arxiv.org/abs/2008.04079v1",
        "categories": [
            "cs.CE",
            "cond-mat.mtrl-sci",
            "physics.app-ph"
        ]
    },
    {
        "title": "Direct dissipation-based arc-length approach for the cracking elements   method",
        "authors": [
            "Yiming Zhang",
            "Junguang Huang",
            "Yong Yuan",
            "Herbert Mang"
        ],
        "summary": "Dissipated energy, representing a monotonically increasing state variable in nonlinear fracture mechanics, can be used as a restraint for tracing the dissipation instead of the elastic unloading path of the structure response. In this work, in contrast to other energy-based approaches that use internal energy and the work done by the external loads, a novel arc-length approach is proposed. It directly extracts the dissipated energy based on crack openings and tractions (displacement jumps and cohesive forces between two surfaces of one crack), taking advantage of the global/extended method of cracking elements. Its linearized form is developed, and the stiffness factor of the arc-length restraint is naturally obtained by means of the Sherman-Morrison formula. Once cohesive cracks appear, the proposed approach can be applied until most of the fracture energy is dissipated. Results from several numerical tests, in which arc-length control and self-propagating cracks are jointly used, are presented. They demonstrate the robustness of the proposed method, which captures both global and local peak loads and all snap-back parts of the force-displacement responses of loaded structures with multiple cracks.",
        "published": "2020-07-04T08:14:50Z",
        "link": "http://arxiv.org/abs/2007.12594v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Immersed boundary finite element method for blood flow simulation",
        "authors": [
            "G. C. Bourantas",
            "D. L. Lampropoulos",
            "B. F. Zwick",
            "V. C. Loukopoulos",
            "A. Wittek",
            "K. Miller"
        ],
        "summary": "We present an efficient and accurate immersed boundary (IB) finite element (FE) solver for numerically solving incompressible Navier--Stokes equations. Particular emphasis is given to internal flows with complex geometries (blood flow in the vasculature system). IB methods are computationally costly for internal flows, mainly due to the large percentage of grid points that lie outside the flow domain. In this study, we apply a local refinement strategy, along with a domain reduction approach in order to reduce the grid that covers the flow domain and increase the percentage of the grid nodes that fall inside the flow domain. The proposed method utilizes an efficient and accurate FE solver with the incremental pressure correction scheme (IPCS), along with the boundary condition enforced IB method to numerically solve the transient, incompressible Navier--Stokes flow equations. We verify the accuracy of the numerical method using the analytical solution for Poiseuille flow in a cylinder. We further examine the accuracy and applicability of the proposed method by considering flow within complex geometries, such as blood flow in aneurysmal vessels and the aorta, flow configurations which would otherwise be extremely difficult to solve by most IB methods. Our method offers high accuracy, as demonstrated by the verification examples, and high efficiency, as demonstrated through the solution of blood flow within complex geometry on an off-the-shelf laptop computer.",
        "published": "2020-07-04T12:24:57Z",
        "link": "http://arxiv.org/abs/2007.02082v1",
        "categories": [
            "cs.CE",
            "physics.flu-dyn"
        ]
    },
    {
        "title": "Scalable Bayesian Functional Connectivity Inference for Multi-Electrode   Array Recordings",
        "authors": [
            "Yun Zhao",
            "Richard Jiang",
            "Zhenni Xu",
            "Elmer Guzman",
            "Paul K. Hansma",
            "Linda Petzold"
        ],
        "summary": "Multi-electrode arrays (MEAs) can record extracellular action potentials (also known as 'spikes') from hundreds or thousands of neurons simultaneously. Inference of a functional network from a spike train is a fundamental and formidable computational task in neuroscience. With the advancement of MEA technology, it has become increasingly crucial to develop statistical tools for analyzing multiple neuronal activity as a network. In this paper, we propose a scalable Bayesian framework for inference of functional networks from MEA data. Our framework makes use of the hierarchical structure of networks of neurons. We split the large scale recordings into smaller local networks for network inference, which not only eases the computational burden from Bayesian sampling but also provides useful insights on regional connections in organoids and brains. We speed up the expensive Bayesian sampling process by using parallel computing. Experiments on both synthetic datasets and large-scale real-world MEA recordings show the effectiveness and efficiency of the scalable Bayesian framework. Inference of networks from controlled experiments exposing neural cultures to cadmium presents distinguishable results and further confirms the utility of our framework.",
        "published": "2020-07-04T22:24:46Z",
        "link": "http://arxiv.org/abs/2007.02198v1",
        "categories": [
            "cs.CE",
            "q-bio.NC"
        ]
    },
    {
        "title": "The vibrations of thin plates",
        "authors": [
            "Santiago R Simanca"
        ],
        "summary": "We describe the equations of motion of an incompressible elastic body $\\Omega$ in 3-space acted on by an external pressure force, and the Newton iteration scheme that proves the well-posedness of the resulting initial value problem for its equations of motion on $C^{k,\\alpha}$ spaces. We use the first iterate of this Newton scheme as an approximation to the actual vibration motion of the body, and given a (finite) triangulation $K$ of it, produce an algorithm that computes it, employing the direct sum of the space of PL vector fields associated to the oriented edges and faces of the first barycentric subdivision $K'$ of $K$ (the metric duals of the Whitney forms of $K'$ in degree one, and the metric duals of the local Hodge $*$ of the Whitney forms in degree two, respectively) as the discretizing space. These vector fields, which capture the algebraic topology properties of $\\Omega$, encode them into the solution of the weak version of the linearized equations of motion about a stationary point, the essential component in the finding of the first iterate in the alluded Newton scheme. This allows for the selection of appropriate choices of $K$, relative to the geometry of $\\Omega$, for which the algorithm produces solutions that accurately describe the vibration of thin plates in a computationally efficient manner. We use these to study the resonance modes of the vibration of these plates, and carry out several relevant simulations, the results of which are all consistent with known vibration patterns of thin plates derived experimentally.",
        "published": "2020-07-05T23:47:04Z",
        "link": "http://arxiv.org/abs/2007.03457v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "Primary: 35Q74, 57Q15, 65N22. Secondary: 74B20, 65N30"
        ]
    },
    {
        "title": "Meso-scale Finite Element Modeling of Alkali-Silica-Reaction",
        "authors": [
            "Roozbeh Rezakhani",
            "Emil Gallyamov",
            "Jean-François Molinari"
        ],
        "summary": "The alkali-silica reaction (ASR) in concrete is a chemical reaction, which produces an expansive product, generally called ''ASR gel'', and causes cracking and damage in concrete over time. Affecting numerous infrastructures all around the world, ASR has been the topic of much research over the past decades. In spite of that, many aspects of this reaction are still unknown. In this numerical-investigation paper, a three-dimensional concrete meso-structure model is simulated using the finite-element method. Coarse aggregates, cement paste, and ASR gel are explicitly represented. A temperature dependent eigen-strain is applied on the simulated ASR gel pockets to capture their expansive behavior. This applies pressure on the surrounding aggregates and the cement paste, leading to cracks initiation and propagation. Free expansion of concrete specimens due to ASR is modeled and validated using experimental data. Influence of different key factors on damage generation in aggregates and paste and macroscopic expansion are discussed.",
        "published": "2020-07-06T09:21:29Z",
        "link": "http://arxiv.org/abs/2007.02600v1",
        "categories": [
            "cs.CE",
            "physics.comp-ph"
        ]
    },
    {
        "title": "A micromechanics-informed phase field model for brittle fracture   accounting for the unilateral constraint",
        "authors": [
            "Yangyuanchen Liu",
            "Cheng Cheng",
            "Vahid Ziaei-Rad",
            "Yongxing Shen"
        ],
        "summary": "We propose a new direction-dependent model for the unilateral constraint involved in the phase field approach to fracture and also in the continuous damage mechanics models. The construction of this phase field model is informed by micromechanical modeling through the homogenization theory, where the representative volume element (RVE) has a planar crack in the center. The proposed model is made closely match the response of the RVE, including the frictionless self-contact condition. This homogenization approach allows to identify a direction-dependent phase field model with the tension-compression split obtained from cracked microstructures. One important feature of the proposed model is that unlike most other models, the material degradation is consistently determined without artificial assumptions or ad hoc parameters with no physical interpretation, thus, a more realistic modeling is resulted. With standard tests such as uniaxial loadings, three-point bending, simple shear, and through-crack tests, the proposed model predicts reasonable crack paths. Moreover, with the RVE response as a benchmark, the proposed model gives rise to an accurate stress-strain curve under shear loads, more accurate than most existing models.",
        "published": "2020-07-06T15:13:18Z",
        "link": "http://arxiv.org/abs/2007.03757v1",
        "categories": [
            "cs.CE",
            "65N30"
        ]
    },
    {
        "title": "Parallel Algorithms for Successive Convolution",
        "authors": [
            "Andrew J. Christlieb",
            "Pierson T. Guthrey",
            "William A. Sands",
            "Mathialakan Thavappiragasm"
        ],
        "summary": "In this work, we consider alternative discretizations for PDEs which use expansions involving integral operators to approximate spatial derivatives. These constructions use explicit information within the integral terms, but treat boundary data implicitly, which contributes to the overall speed of the method. This approach is provably unconditionally stable for linear problems and stability has been demonstrated experimentally for nonlinear problems. Additionally, it is matrix-free in the sense that it is not necessary to invert linear systems and iteration is not required for nonlinear terms. Moreover, the scheme employs a fast summation algorithm that yields a method with a computational complexity of $\\mathcal{O}(N)$, where $N$ is the number of mesh points along a direction. While much work has been done to explore the theory behind these methods, their practicality in large scale computing environments is a largely unexplored topic. In this work, we explore the performance of these methods by developing a domain decomposition algorithm suitable for distributed memory systems along with shared memory algorithms. As a first pass, we derive an artificial CFL condition that enforces a nearest-neighbor communication pattern and briefly discuss possible generalizations. We also analyze several approaches for implementing the parallel algorithms by optimizing predominant loop structures and maximizing data reuse. Using a hybrid design that employs MPI and Kokkos for the distributed and shared memory components of the algorithms, respectively, we show that our methods are efficient and can sustain an update rate $> 1\\times10^8$ DOF/node/s. We provide results that demonstrate the scalability and versatility of our algorithms using several different PDE test problems, including a nonlinear example, which employs an adaptive time-stepping rule.",
        "published": "2020-07-06T19:59:38Z",
        "link": "http://arxiv.org/abs/2007.03041v2",
        "categories": [
            "physics.comp-ph",
            "cs.CE",
            "cs.DC",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Generation expansion planning in the presence of wind power plants using   a genetic algorithm model",
        "authors": [
            "Ali Sahragard",
            "Hamid Falaghi",
            "Mahdi Farhadi",
            "Amir Mosavi",
            "Abouzar Estebsari"
        ],
        "summary": "One of the essential aspects of power system planning is generation expansion planning (GEP). The purpose of GEP is to enhance construction planning and reduce the costs of installing different types of power plants. This paper proposes a method based on Genetic Algorithm (GA) for GEP in the presence of wind power plants. Since it is desired to integrate the maximum possible wind power production in GEP, the constraints for incorporating different levels of wind energy in power generation are investigated comprehensively. This will allow obtaining the maximum reasonable amount of wind penetration in the network. Besides, due to the existence of different wind regimes, the penetration of strong and weak wind on GEP is assessed. The results show that the maximum utilization of wind power generation capacity could increase the exploitation of more robust wind regimes. Considering the growth of the wind farm industry and the cost reduction for building wind power plants, the sensitivity of GEP to the variations of this cost is investigated. The results further indicate that for a 10% reduction in the initial investment cost of wind power plants, the proposed model estimates that the overall cost will be minimized.",
        "published": "2020-07-07T07:20:15Z",
        "link": "http://arxiv.org/abs/2008.04703v1",
        "categories": [
            "cs.CE",
            "cs.NE",
            "eess.SP",
            "68T01"
        ]
    },
    {
        "title": "Non-local modeling with asymptotic expansion homogenization of random   materials",
        "authors": [
            "Sami Ben Elhaj Salah",
            "Azdine Nait-Ali",
            "Mikael Gueguen",
            "Carole Nadot-Martin"
        ],
        "summary": "The aim of this study is to build a non-local homogenized model for three-dimensional composites with inclusions randomly embedded within a matrix according to a stochastic point process w in a bounded open set associated with a suitable probability space). Both phases were linear elastic. Asymptotic expansion homogenization (AEH) was revisited by taking into account the stochastic parameter representing the inclusion centers distribution. The macroscopic behavior was then studied by combining the variational approach with the mean-ergodicity.",
        "published": "2020-07-08T06:42:21Z",
        "link": "http://arxiv.org/abs/2007.05066v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Comparison of nonlinear mappings for reduced-order modelling of   vibrating structures: normal form theory and quadratic manifold method with   modal derivatives",
        "authors": [
            "Alessandra Vizzaccaro",
            "Loïc Salles",
            "Cyril Touzé"
        ],
        "summary": "The objective of this contribution is to compare two methods proposed recently in order to build efficient reduced-order models for geometrically nonlinear structures. The first method relies on the normal form theory that allows one to obtain a nonlinear change of coordinates for expressing the reduced-order dynamics in an invariant-based span of the phase space. The second method is the modal derivative (MD) approach, and more specifically the quadratic manifold defined in order to derive a second-order nonlinear change of coordinates. Both methods share a common point of view, willing to introduce a nonlinear mapping to better define a reduced order model that could take more properly into account the nonlinear restoring forces. However the calculation methods are different and the quadratic manifold approach has not the invariance property embedded in its definition. Modal derivatives and static modal derivatives are investigated, and their distinctive features in the treatment of the quadratic nonlinearity is underlined. Assuming a slow/fast decomposition allows understanding how the three methods tend to share equivalent properties. While they give proper estimations for flat symmetric structures having a specific shape of nonlinearities and a clear slow/fast decomposition between flexural and in-plane modes, the treatment of the quadratic nonlinearity makes the predictions different in the case of curved structures such as arches and shells. In the more general case, normal form approach appears preferable since it allows correct predictions of a number of important nonlinear features, including for example the hardening/softening behaviour, whatever the relationships between slave and master coordinates are.",
        "published": "2020-07-08T16:35:01Z",
        "link": "http://arxiv.org/abs/2007.05067v2",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "On the role of solute drag in reconciling laboratory and natural   constraints on olivine grain growth kinetics",
        "authors": [
            "Jean Furstoss",
            "Carole Petit",
            "Andrea Tommasi",
            "Clément Ganino",
            "Daniel Pino Muñoz",
            "Marc Bernacki"
        ],
        "summary": "We investigate the effect of solute drag on grain growth (GG) kinetics in olivine-rich rocks through full field and mean field modelling. Considering a drag force exerted by impurities on grain boundary migration allows reconciling laboratory and natural constraints on olivine GG kinetics. Solute drag is implemented in a full field level-set framework and on a mean field model, which explicitly accounts for a grain size distribution. After calibration of the mean field model on full field results, both models are able to both reproduce laboratory GG kinetics and to predict grain sizes consistent with observations in peridotite xenoliths from different geological contexts.",
        "published": "2020-07-09T07:30:51Z",
        "link": "http://arxiv.org/abs/2007.04606v1",
        "categories": [
            "physics.geo-ph",
            "cond-mat.mtrl-sci",
            "cs.CE"
        ]
    },
    {
        "title": "Optimal control of cytotoxic and antiangiogenic therapies on prostate   cancer growth",
        "authors": [
            "Pierluigi Colli",
            "Hector Gomez",
            "Guillermo Lorenzo",
            "Gabriela Marinoschi",
            "Alessandro Reali",
            "Elisabetta Rocca"
        ],
        "summary": "Prostate cancer can be lethal in advanced stages, for which chemotherapy may become the only viable therapeutic option. While there is no clear clinical management strategy fitting all patients, cytotoxic chemotherapy with docetaxel is currently regarded as the gold standard. However, tumors may regain activity after treatment conclusion and become resistant to docetaxel. This situation calls for new delivery strategies and drug compounds enabling an improved therapeutic outcome. Combination of docetaxel with antiangiogenic therapy has been considered a promising strategy. Bevacizumab is the most common antiangiogenic drug, but clinical studies have not revealed a clear benefit from its combination with docetaxel. Here, we capitalize on our prior work on mathematical modeling of prostate cancer growth subjected to combined cytotoxic and antiangiogenic therapies, and propose an optimal control framework to robustly compute the drug-independent cytotoxic and antiangiogenic effects enabling an optimal therapeutic control of tumor dynamics. We describe the formulation of the optimal control problem, for which we prove the existence of at least a solution and determine the necessary first order optimality conditions. We then present numerical algorithms based on isogeometric analysis to run a preliminary simulation study over a single cycle of combined therapy. Our results suggest that only cytotoxic chemotherapy is required to optimize therapeutic performance and we show that our framework can produce superior solutions to combined therapy with docetaxel and bevacizumab. We also illustrate how the optimal drug-na\\\"{i}ve cytotoxic effects computed in these simulations may be successfully leveraged to guide drug production and delivery strategies by running a nonlinear least-square fit of protocols involving docetaxel and a new design drug.",
        "published": "2020-07-09T22:30:48Z",
        "link": "http://arxiv.org/abs/2007.05098v1",
        "categories": [
            "math.OC",
            "cs.CE",
            "q-bio.TO",
            "35Q92, 35Q93, 92C50, 65M60, 35K51, 35K58, 49J20, 49K20"
        ]
    },
    {
        "title": "Intelligent Credit Limit Management in Consumer Loans Based on Causal   Inference",
        "authors": [
            "Hang Miao",
            "Kui Zhao",
            "Zhun Wang",
            "Linbo Jiang",
            "Quanhui Jia",
            "Yanming Fang",
            "Quan Yu"
        ],
        "summary": "Nowadays consumer loan plays an important role in promoting the economic growth, and credit cards are the most popular consumer loan. One of the most essential parts in credit cards is the credit limit management. Traditionally, credit limits are adjusted based on limited heuristic strategies, which are developed by experienced professionals. In this paper, we present a data-driven approach to manage the credit limit intelligently. Firstly, a conditional independence testing is conducted to acquire the data for building models. Based on these testing data, a response model is then built to measure the heterogeneous treatment effect of increasing credit limits (i.e. treatments) for different customers, who are depicted by several control variables (i.e. features). In order to incorporate the diminishing marginal effect, a carefully selected log transformation is introduced to the treatment variable. Moreover, the model's capability can be further enhanced by applying a non-linear transformation on features via GBDT encoding. Finally, a well-designed metric is proposed to properly measure the performances of compared methods. The experimental results demonstrate the effectiveness of the proposed approach.",
        "published": "2020-07-10T06:22:44Z",
        "link": "http://arxiv.org/abs/2007.05188v1",
        "categories": [
            "cs.LG",
            "cs.CE",
            "econ.EM",
            "stat.ML"
        ]
    },
    {
        "title": "Numerical simulation, clustering and prediction of multi-component   polymer precipitation",
        "authors": [
            "Pavan Inguva",
            "Lachlan Mason",
            "Indranil Pan",
            "Miselle Hengardi",
            "Omar K. Matar"
        ],
        "summary": "Multi-component polymer systems are of interest in organic photovoltaic and drug delivery applications, among others where diverse morphologies influence performance. An improved understanding of morphology classification, driven by composition-informed prediction tools, will aid polymer engineering practice. We use a modified Cahn-Hilliard model to simulate polymer precipitation. Such physics-based models require high-performance computations that prevent rapid prototyping and iteration in engineering settings. To reduce the required computational costs, we apply machine learning techniques for clustering and consequent prediction of the simulated polymer blend images in conjunction with simulations. Integrating ML and simulations in such a manner reduces the number of simulations needed to map out the morphology of polymer blends as a function of input parameters and also generates a data set which can be used by others to this end. We explore dimensionality reduction, via principal component analysis and autoencoder techniques, and analyse the resulting morphology clusters. Supervised machine learning using Gaussian process classification was subsequently used to predict morphology clusters according to species molar fraction and interaction parameter inputs. Manual pattern clustering yielded the best results, but machine learning techniques were able to predict the morphology of polymer blends with $\\geq$ 90 $\\%$ accuracy.",
        "published": "2020-07-10T09:10:17Z",
        "link": "http://arxiv.org/abs/2007.07276v2",
        "categories": [
            "cs.CE",
            "cond-mat.soft",
            "cs.LG",
            "physics.flu-dyn",
            "stat.ML",
            "I.6.5; I.6.3; I.5.4"
        ]
    },
    {
        "title": "MAPS: Multi-agent Reinforcement Learning-based Portfolio Management   System",
        "authors": [
            "Jinho Lee",
            "Raehyun Kim",
            "Seok-Won Yi",
            "Jaewoo Kang"
        ],
        "summary": "Generating an investment strategy using advanced deep learning methods in stock markets has recently been a topic of interest. Most existing deep learning methods focus on proposing an optimal model or network architecture by maximizing return. However, these models often fail to consider and adapt to the continuously changing market conditions. In this paper, we propose the Multi-Agent reinforcement learning-based Portfolio management System (MAPS). MAPS is a cooperative system in which each agent is an independent \"investor\" creating its own portfolio. In the training procedure, each agent is guided to act as diversely as possible while maximizing its own return with a carefully designed loss function. As a result, MAPS as a system ends up with a diversified portfolio. Experiment results with 12 years of US market data show that MAPS outperforms most of the baselines in terms of Sharpe ratio. Furthermore, our results show that adding more agents to our system would allow us to get a higher Sharpe ratio by lowering risk with a more diversified portfolio.",
        "published": "2020-07-10T14:08:12Z",
        "link": "http://arxiv.org/abs/2007.05402v1",
        "categories": [
            "cs.AI",
            "cs.CE",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "On-the-fly construction of surrogate constitutive models for concurrent   multiscale mechanical analysis through probabilistic machine learning",
        "authors": [
            "I. B. C. M. Rocha",
            "P. Kerfriden",
            "F. P. van der Meer"
        ],
        "summary": "Concurrent multiscale finite element analysis (FE2) is a powerful approach for high-fidelity modeling of materials for which a suitable macroscopic constitutive model is not available. However, the extreme computational effort associated with computing a nested micromodel at every macroscopic integration point makes FE2 prohibitive for most practical applications. Constructing surrogate models able to efficiently compute the microscopic constitutive response is therefore a promising approach in enabling concurrent multiscale modeling. This work presents a reduction framework for adaptively constructing surrogate models based on statistical learning. The nested micromodels are replaced by a machine learning surrogate model based on Gaussian Processes (GP). The need for offline data collection is bypassed by training the GP models online based on data coming from a small set of fully-solved anchor micromodels that undergo the same strain history as their associated macro integration points. The Bayesian formalism inherent to GP models provides a natural tool for uncertainty estimation through which new observations or inclusion of new anchors are triggered. The surrogate constitutive manifold is constructed with as few micromechanical evaluations as possible by enhancing the GP models with gradient information and the solution scheme is made robust through a greedy data selection approach embedded within the conventional finite element solution loop for nonlinear analysis. The sensitivity to model parameters is studied with a tapered bar example with plasticity, while the applicability of the model to more complex cases is demonstrated with the elastoplastic analysis of a plate with multiple cutouts and a crack growth example for mixed-mode bending. Significant efficiency gains are obtained without resorting to offline training.",
        "published": "2020-07-11T10:29:45Z",
        "link": "http://arxiv.org/abs/2007.07749v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Distributed optimization for nonrigid nano-tomography",
        "authors": [
            "Viktor Nikitin",
            "Vincent De Andrade",
            "Azat Slyamov",
            "Benjamin J. Gould",
            "Yuepeng Zhang",
            "Vandana Sampathkumar",
            "Narayanan Kasthuri",
            "Doga Gursoy",
            "Francesco De Carlo"
        ],
        "summary": "Resolution level and reconstruction quality in nano-computed tomography (nano-CT) are in part limited by the stability of microscopes, because the magnitude of mechanical vibrations during scanning becomes comparable to the imaging resolution, and the ability of the samples to resist beam damage during data acquisition. In such cases, there is no incentive in recovering the sample state at different time steps like in time-resolved reconstruction methods, but instead the goal is to retrieve a single reconstruction at the highest possible spatial resolution and without any imaging artifacts. Here we propose a joint solver for imaging samples at the nanoscale with projection alignment, unwarping and regularization. Projection data consistency is regulated by dense optical flow estimated by Farneback's algorithm, leading to sharp sample reconstructions with less artifacts. Synthetic data tests show robustness of the method to Poisson and low-frequency background noise. Applicability of the method is demonstrated on two large-scale nano-imaging experimental data sets.",
        "published": "2020-07-11T19:22:43Z",
        "link": "http://arxiv.org/abs/2008.03375v2",
        "categories": [
            "cs.CE",
            "cs.CV",
            "eess.IV"
        ]
    },
    {
        "title": "A Computationally Tractable Framework for Nonlinear Dynamic Multiscale   Modeling of Membrane Fabric",
        "authors": [
            "Philip Avery",
            "Daniel Z. Huang",
            "Wanli He",
            "Johanna Ehlers",
            "Armen Derkevorkian",
            "Charbel Farhat"
        ],
        "summary": "A general-purpose computational homogenization framework is proposed for the nonlinear dynamic analysis of membranes exhibiting complex microscale and/or mesoscale heterogeneity characterized by in-plane periodicity that cannot be effectively treated by a conventional method, such as woven fabrics. The framework is a generalization of the \"finite element squared\" (or FE2) method in which a localized portion of the periodic subscale structure is modeled using finite elements. The numerical solution of displacement driven problems involving this model can be adapted to the context of membranes by a variant of the Klinkel-Govindjee method[1] originally proposed for using finite strain, three-dimensional material models in beam and shell elements. This approach relies on numerical enforcement of the plane stress constraint and is enabled by the principle of frame invariance. Computational tractability is achieved by introducing a regression-based surrogate model informed by a physics-inspired training regimen in which FE$^2$ is utilized to simulate a variety of numerical experiments including uniaxial, biaxial and shear straining of a material coupon. Several alternative surrogate models are evaluated including an artificial neural network. The framework is demonstrated and validated for a realistic Mars landing application involving supersonic inflation of a parachute canopy made of woven fabric.",
        "published": "2020-07-12T00:05:11Z",
        "link": "http://arxiv.org/abs/2007.05877v2",
        "categories": [
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "fenicsR13: A Tensorial Mixed Finite Element Solver for the Linear R13   Equations Using the FEniCS Computing Platform",
        "authors": [
            "Lambert Theisen",
            "Manuel Torrilhon"
        ],
        "summary": "We present a mixed finite element solver for the linearized R13 equations of non-equilibrium gas dynamics. The Python implementation builds upon the software tools provided by the FEniCS computing platform. We describe a new tensorial approach utilizing the extension capabilities of FEniCS's Unified Form Language (UFL) to define required differential operators for tensors above second degree. The presented solver serves as an example for implementing tensorial variational formulations in FEniCS, for which the documentation and literature seem to be very sparse. Using the software abstraction levels provided by the UFL allows an almost one-to-one correspondence between the underlying mathematics and the resulting source code. Test cases support the correctness of the proposed method using validation with exact solutions. To justify the usage of extended gas flow models, we discuss typical application cases involving rarefaction effects. We provide the documented and validated solver publicly.",
        "published": "2020-07-12T09:07:24Z",
        "link": "http://arxiv.org/abs/2007.05944v2",
        "categories": [
            "cs.CE",
            "cs.MS",
            "physics.flu-dyn",
            "65N30, 65-04, 76P05, 76-04, 35Q35, 35-04",
            "G.1.8; G.4; J.2"
        ]
    },
    {
        "title": "Sequence-guided protein structure determination using graph   convolutional and recurrent networks",
        "authors": [
            "Po-Nan Li",
            "Saulo H. P. de Oliveira",
            "Soichi Wakatsuki",
            "Henry van den Bedem"
        ],
        "summary": "Single particle, cryogenic electron microscopy (cryo-EM) experiments now routinely produce high-resolution data for large proteins and their complexes. Building an atomic model into a cryo-EM density map is challenging, particularly when no structure for the target protein is known a priori. Existing protocols for this type of task often rely on significant human intervention and can take hours to many days to produce an output. Here, we present a fully automated, template-free model building approach that is based entirely on neural networks. We use a graph convolutional network (GCN) to generate an embedding from a set of rotamer-based amino acid identities and candidate 3-dimensional C$\\alpha$ locations. Starting from this embedding, we use a bidirectional long short-term memory (LSTM) module to order and label the candidate identities and atomic locations consistent with the input protein sequence to obtain a structural model. Our approach paves the way for determining protein structures from cryo-EM densities at a fraction of the time of existing approaches and without the need for human intervention.",
        "published": "2020-07-14T06:24:07Z",
        "link": "http://arxiv.org/abs/2007.06847v3",
        "categories": [
            "q-bio.BM",
            "cs.CE",
            "cs.LG",
            "stat.ML"
        ]
    },
    {
        "title": "Generating Trading Signals by ML algorithms or time series ones?",
        "authors": [
            "Omid Safarzadeh"
        ],
        "summary": "This research investigates efficiency on-line learning Algorithms to generate trading signals.I employed technical indicators based on high frequency stock prices and generated trading signals through ensemble of Random Forests. Similarly, Kalman Filter was used for signaling trading positions. Comparing Time Series methods with Machine Learning methods, results spurious of Kalman Filter to Random Forests in case of on-line learning predictions of stock prices",
        "published": "2020-07-14T12:41:22Z",
        "link": "http://arxiv.org/abs/2007.11098v1",
        "categories": [
            "q-fin.ST",
            "cs.CE"
        ]
    },
    {
        "title": "A phase field model for elastic-gradient-plastic solids undergoing   hydrogen embrittlement",
        "authors": [
            "Philip K. Kristensen",
            "Christian F. Niordson",
            "Emilio Martínez-Pañeda"
        ],
        "summary": "We present a gradient-based theoretical framework for predicting hydrogen assisted fracture in elastic-plastic solids. The novelty of the model lies in the combination of: (i) stress-assisted diffusion of solute species, (ii) strain gradient plasticity, and (iii) a hydrogen-sensitive phase field fracture formulation, inspired by first principles calculations. The theoretical model is numerically implemented using a mixed finite element formulation and several boundary value problems are addressed to gain physical insight and showcase model predictions. The results reveal the critical role of plastic strain gradients in rationalising decohesion-based arguments and capturing the transition to brittle fracture observed in hydrogen-rich environments. Large crack tip stresses are predicted, which in turn raise the hydrogen concentration and reduce the fracture energy. The computation of the steady state fracture toughness as a function of the cohesive strength shows that cleavage fracture can be predicted in otherwise ductile metals using sensible values for the material parameters and the hydrogen concentration. In addition, we compute crack growth resistance curves in a wide variety of scenarios and demonstrate that the model can appropriately capture the sensitivity to: the plastic length scales, the fracture length scale, the loading rate and the hydrogen concentration. Model predictions are also compared with fracture experiments on a modern ultra-high strength steel, AerMet100. A promising agreement is observed with experimental measurements of threshold stress intensity factor $K_{th}$ over a wide range of applied potentials.",
        "published": "2020-07-14T15:14:56Z",
        "link": "http://arxiv.org/abs/2007.07093v1",
        "categories": [
            "cond-mat.mtrl-sci",
            "cs.CE",
            "cs.NA",
            "math.NA",
            "physics.app-ph"
        ]
    },
    {
        "title": "iESC: iterative Equivalent Surface Current Approximation",
        "authors": [
            "Shaolin Liao",
            "Lu Ou"
        ],
        "summary": "A novel iterative Equivalent Surface Current (iESC) algorithm has been developed to simulate the electromagnetic scattering of electrically large dielectric objects with relatively smooth surfaces. The iESC algorithm corrects the surface currents to compensate for the electromagnetic field deviation across the dielectric surface. Numerically validation has been performed with a dielectric sphere to show the performance of the iESC algorithm. The experimental result shows that it takes only a few iterations for the algorithm to increase the surface current accuracy by more than three orders of magnitude.",
        "published": "2020-07-14T17:12:01Z",
        "link": "http://arxiv.org/abs/2007.13881v1",
        "categories": [
            "cs.CE",
            "physics.app-ph"
        ]
    },
    {
        "title": "SLIM: A Well-Conditioned Single-Source Boundary Element Method for   Modeling Lossy Conductors in Layered Media",
        "authors": [
            "Shashwat Sharma",
            "Piero Triverio"
        ],
        "summary": "The boundary element method (BEM) enables the efficient electromagnetic modelling of lossy conductors with a surface-based discretization. Existing BEM techniques for conductor modelling require either expensive dual basis functions or the use of both single- and double-layer potential operators to obtain a well-conditioned system matrix. The associated computational cost is particularly significant when conductors are embedded in stratified media, and the expensive multilayer Green's function (MGF) must be invoked. In this work, a novel single-source BEM formulation is proposed, which leads to a well-conditioned system matrix without the need for dual basis functions. The proposed single-layer impedance matrix (SLIM) formulation does not require the double-layer potential to model the background medium, which reduces the cost associated with the MGF. The accuracy and efficiency of the proposed method is demonstrated through realistic examples drawn from different applications.",
        "published": "2020-07-14T22:10:08Z",
        "link": "http://arxiv.org/abs/2007.07378v2",
        "categories": [
            "physics.comp-ph",
            "cs.CE"
        ]
    },
    {
        "title": "3D CNN-PCA: A Deep-Learning-Based Parameterization for Complex Geomodels",
        "authors": [
            "Yimin Liu",
            "Louis J. Durlofsky"
        ],
        "summary": "Geological parameterization enables the representation of geomodels in terms of a relatively small set of variables. Parameterization is therefore very useful in the context of data assimilation and uncertainty quantification. In this study, a deep-learning-based geological parameterization algorithm, CNN-PCA, is developed for complex 3D geomodels. CNN-PCA entails the use of convolutional neural networks as a post-processor for the low-dimensional principal component analysis representation of a geomodel. The 3D treatments presented here differ somewhat from those used in the 2D CNN-PCA procedure. Specifically, we introduce a new supervised-learning-based reconstruction loss, which is used in combination with style loss and hard data loss. The style loss uses features extracted from a 3D CNN pretrained for video classification. The 3D CNN-PCA algorithm is applied for the generation of conditional 3D realizations, defined on $60\\times60\\times40$ grids, for three geological scenarios (binary and bimodal channelized systems, and a three-facies channel-levee-mud system). CNN-PCA realizations are shown to exhibit geological features that are visually consistent with reference models generated using object-based methods. Statistics of flow responses ($\\text{P}_{10}$, $\\text{P}_{50}$, $\\text{P}_{90}$ percentile results) for test sets of 3D CNN-PCA models are shown to be in consistent agreement with those from reference geomodels. Lastly, CNN-PCA is successfully applied for history matching with ESMDA for the bimodal channelized system.",
        "published": "2020-07-16T17:25:14Z",
        "link": "http://arxiv.org/abs/2007.08478v1",
        "categories": [
            "cs.CV",
            "cs.CE",
            "cs.LG",
            "physics.geo-ph"
        ]
    },
    {
        "title": "Flood zones detection using a runoff model built on Hexagonal shape   based cellular automata",
        "authors": [
            "Souhaib Douass",
            "M'hamed Ait Kbir"
        ],
        "summary": "This article presents a 3D geographic information systems (GIS) modeling and simulation of water flow in a landscape defined by a digital terrain model, provided by some available geolocation APIs. The proposed approach uses a cellular automata based algorithm to calculate water flow dynamic. The methodology was tested on a case study area of 27kmx19km located in Tangier, north of Morocco. In fact, we aim to detect flood zones in order to prevent problems related to space occupation in urban and rural regions. Some indices can be deduced from the stream shape using Cellular Automata (CA) based approach that can reduce the complexity related to space structures with multiple changes. A spatiotemporal simulation of the runoff process is provided using 3D visualization that we can pair with geographical information system tools (GIS). The 3D GIS modeling approach that was developed for the analyses of flood zones detection using a runoff model based on cellular automata was comprised of three main steps: Input (collection of data), calculation (CA tool) and visualization (3D simulation).",
        "published": "2020-07-16T23:42:31Z",
        "link": "http://arxiv.org/abs/2007.10079v1",
        "categories": [
            "cs.CE",
            "nlin.CG",
            "stat.CO"
        ]
    },
    {
        "title": "A comparison of interpolation techniques for non-conformal high-order   discontinuous Galerkin methods",
        "authors": [
            "Edward Laughton",
            "Gavin Tabor",
            "David Moxey"
        ],
        "summary": "The capability to incorporate moving geometric features within models for complex simulations is a common requirement in many fields. Fluid mechanics within aeronautical applications, for example, routinely feature rotating (e.g. turbines, wheels and fan blades) or sliding components (e.g. in compressor or turbine cascade simulations). With an increasing trend towards the high-fidelity modelling of these cases, in particular combined with the use of high-order discontinuous Galerkin methods, there is therefore a requirement to understand how different numerical treatments of the interfaces between the static mesh and the sliding/rotating part impact on overall solution quality. In this article, we compare two different approaches to handle this non-conformal interface. The first is the so-called mortar approach, where flux integrals along edges are split according to the positioning of the non-conformal grid. The second is a less-documented point-to-point interpolation method, where the interior and exterior quantities for flux evaluations are interpolated from elements lying on the opposing side of the interface. Although the mortar approach has significant advantages in terms of its numerical properties, in that it preserves the local conservation properties of DG methods, in the context of complex 3D meshes it poses notable implementation difficulties which the point-to-point method handles more readily. In this paper we examine the numerical properties of each method, focusing not only on observing convergence orders for smooth solutions, but also how each method performs in under-resolved simulations of linear and nonlinear hyperbolic problems, to inform the use of these methods in implicit large-eddy simulations.",
        "published": "2020-07-17T19:40:06Z",
        "link": "http://arxiv.org/abs/2007.15534v2",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Optimizing Off-Chain Payment Networks in Cryptocurrencies",
        "authors": [
            "Yotam Sali",
            "Aviv Zohar"
        ],
        "summary": "Off-chain transaction channels represent one of the leading techniques to scale the transaction throughput in cryptocurrencies such as Bitcoin. They allow multiple agents to route payments through one another. So far, the topology and construction of payment networks has not been explored much. Participants are expected to minimize costs that are due to the allocation of liquidity as well as blockchain record fees. In this paper we study the optimization of maintenance costs of such networks. We present for the first time, a closed model for symmetric off-chain channels, and provide efficient algorithms for constructing minimal cost spanning-tree networks under this model. We prove that for any network demands, a simple hub topology provides a 2-approximation to the minimal maintenance cost showing that spanning trees in general are efficient. We also show an unbounded price of anarchy in a greedy game between the transactors, when each player wishes to minimize his costs by changing the network's structure. Finally, we simulate and compare the costs of payment networks with scale free demand topologies.",
        "published": "2020-07-18T11:29:00Z",
        "link": "http://arxiv.org/abs/2007.09410v2",
        "categories": [
            "cs.GT",
            "cs.CE"
        ]
    },
    {
        "title": "A Manifold Learning Approach to Accelerate Phase Field Fracture   Simulations in the Representative Volume Element",
        "authors": [
            "Yangyuanchen Liu",
            "Kexin Weng",
            "Yongxing Shen"
        ],
        "summary": "The multiscale simulation of heterogeneous materials is a popular and important subject in solid mechanics and materials science due to the wide application of composite materials. However, the classical FE2 (finite element2) scheme can be costly, especially when the microproblem is nonlinear. In this paper, we consider the case when the microproblem is the phase field formulation for fracture. We adopt the locally linear embedding (LLE) manifold learning approach, a method for non-linear dimension reduction, to extract the manifold that contains a collection of phase-field-represented initial microcrack patterns in the representative volume element (RVE). Then the output data corresponding to any other microcrack pattern, e.g., the evolved phase field at a fixed load, can be accurately reconstructed using the learned manifold with minimum computation. The method has two features: a minimum number of parameters for the scheme, and an input-specific error bar. The latter feature enables an adaptive strategy for any new input on whether to use the proposed, less expensive reconstruction, or to use an accurate but costly high-fidelity computation instead.",
        "published": "2020-07-20T07:35:04Z",
        "link": "http://arxiv.org/abs/2007.09912v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Nonlinear Strain-limiting Elasticity for Fracture Propagation with   Phase-Field Approach",
        "authors": [
            "Sanghyun Lee",
            "Hyun Chul Yoon",
            "Mallikarjunaiah S. Muddamallappa"
        ],
        "summary": "The conventional model governing the spread of fractures in elastic material is formulated by coupling linear elasticity with deformation systems. The classical linear elastic fracture mechanics (LEFM) model is derived based on the assumption of small strain values. However, since the strain values in the model are linearly proportional to the stress values, the strain value can be large if the stress value increases. Thus this results in the contradiction of the assumption to LEFM and it is one of the major disadvantages of the model. In particular, this singular behavior of the strain values is often observed especially near the crack-tip, and it may not accurately predict realistic phenomena. Thus, we investigate the framework of a new class of theoretical model, which is known as the nonlinear strain-limiting model. The advantage of the nonlinear strain-limiting models over LEFM is that the strain value remains bounded even if the stress value tends to the infinity. This is achieved by assuming the nonlinear relation between the strain and stress in the derivation of the model. Moreover, we consider the quasi-static fracture propagation by coupling with the phase-field approach to present the effectiveness of the proposed strain-limiting model. Several numerical examples to evaluate and validate the performance of the new model and algorithms are presented. Detailed comparisons of the strain values, fracture energy, and fracture propagation speed between nonlinear strain-limiting model and LEFM for the quasi-static fracture propagation are discussed.",
        "published": "2020-07-20T16:18:25Z",
        "link": "http://arxiv.org/abs/2007.11101v1",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Anisotropic dual-continuum representations for multiscale poroelastic   materials: Development and numerical modelling",
        "authors": [
            "Mark Ashworth",
            "Florian Doster"
        ],
        "summary": "Dual-continuum (DC) models can be tractable alternatives to explicit approaches for the numerical modelling of multiscale materials with multiphysics behaviours. This work concerns the conceptual and numerical modelling of poroelastically coupled dual-scale materials such as naturally fractured rock. Apart from a few exceptions, previous poroelastic DC models have assumed isotropy of the constituents and the dual-material. Additionally, it is common to assume that only one continuum has intrinsic stiffness properties. Finally, little has been done into validating whether the DC paradigm can capture the global poroelastic behaviours of explicit numerical representations at the DC modelling scale. We address the aforementioned knowledge gaps in two steps. First, we utilise a homogenisation approach based on Levin's theorem to develop a previously derived anisotropic poroelastic constitutive model. Our development incorporates anisotropic intrinsic stiffness properties of both continua. This addition is in analogy to anisotropic fractured rock masses with stiff fractures. Second, we perform numerical modelling to test the dual-continuum model against fine-scale explicit equivalents. In doing, we present our hybrid numerical framework, as well as the conditions required for interpretation of the numerical results. The tests themselves progress from materials with isotropic to anisotropic mechanical and flow properties. The fine-scale simulations show anisotropy can have noticeable effects on deformation and flow behaviour. However, our numerical experiments show the DC approach can capture the global poroelastic behaviours of both isotropic and anisotropic fine-scale representations.",
        "published": "2020-07-20T17:18:10Z",
        "link": "http://arxiv.org/abs/2007.12264v1",
        "categories": [
            "physics.geo-ph",
            "cs.CE"
        ]
    },
    {
        "title": "Finite Cell Method for functionally graded materials based on V-models   and homogenized microstructures",
        "authors": [
            "Benjamin Wassermann",
            "Nina Korshunova",
            "Stefan Kollmannsberger",
            "Ernst Rank",
            "Gershon Elber"
        ],
        "summary": "This paper proposes an extension of the finite cell method (FCM) to V-rep models, a novel geometric framework for volumetric representations. This combination of an embedded domain approach (FCM) and a new modeling framework (V-rep) forms the basis for an efficient and accurate simulation of mechanical artifacts, which are not only characterized by complex shapes but also by their non-standard interior structure. These objects gain more and more interest in the context of the new design opportunities opened by additive manufacturing, mainly when graded or micro-structured material is applied. Two different types of functionally graded materials (FGM) are considered: The first one, multi-material FGM, is described using the V-rep models' inherent property to assign different properties throughout the interior of a domain. The second, single-material FGM -- which is heterogeneously micro-structured -- characterizes the effective material behavior of representative volume elements by homogenization and performs large-scale simulations using the embedded domain approach.",
        "published": "2020-07-20T19:46:56Z",
        "link": "http://arxiv.org/abs/2007.10433v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Quasi-Static Anti-Plane Shear Crack Propagation in a New Class of   Nonlinear Strain-Limiting Elastic Solids using Phase-Field Regularization",
        "authors": [
            "Hyun C. Yoon",
            "Sanghyun Lee",
            "S. M. Mallikarjunaiah"
        ],
        "summary": "We present a novel constitutive model using the framework of strain-limiting theories of elasticity for an evolution of quasi-static anti-plane fracture. The classical linear elastic fracture mechanics (LEFM), with conventional linear relationship between stress and strain, has a well documented inconsistency through which it predicts a singular cracktip strain. This clearly violates the basic tenant of the theory which is a first order approximation to finite elasticity. To overcome the issue, we investigate a new class of material models which predicts uniform and bounded strain throughout the body. The nonlinear model allows the strain value to remain small even if the stress value tends to infinity, which is achieved by an implicit relationship between stress and strain. A major objective of this paper is to couple a nonlinear bulk energy with diffusive crack employing the phase-field approach. Towards that end, an iterative L-scheme is employed and the numerical model is augmented with a penalization technique to accommodate irreversibility of crack. Several numerical experiments are presented to illustrate the capability and the performance of the proposed framework We observe the naturally bounded strain in the neighborhood of the crack-tip, leading to different bulk and crack energies for fracture propagation.",
        "published": "2020-07-21T07:40:40Z",
        "link": "http://arxiv.org/abs/2007.10327v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A strain-gradient formulation for fiber reinforced polymers: Hybrid   phase-field model for porous-ductile fracture",
        "authors": [
            "Maik Dittman",
            "Jonathan Schult",
            "Felix Schmidt",
            "Christian Hesch"
        ],
        "summary": "A novel numerical approach to analyze the mechanical behavior within composite materials including the inelastic regime up to final failure is presented. Therefore, a second-gradient theory is combined with phase-field methods to fracture. In particular, we assume that the polymeric matrix material undergoes ductile fracture, whereas continuously embedded fibers undergo brittle fracture as it is typical e.g. for roving glass reinforced thermoplastics. A hybrid phase-field approach is developed and applied along with a modified Gurson-Tvergaard-Needelman GTN-type plasticity model accounting for a temperature-dependent growth of voids on microscale. The mechanical response of the arising microstructure of the woven fabric gives rise to additional higher-order terms, representing homogenized bending contributions of the fibers. Eventually, a series of tests is conducted for this physically comprehensive multifield formulation to investigate different kinds and sequences of failure within long fiber reinforced polymers.",
        "published": "2020-07-21T14:55:50Z",
        "link": "http://arxiv.org/abs/2007.10871v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Dynamic Pooled Capacity Deployment for Urban Parcel Logistics",
        "authors": [
            "Louis Faugère",
            "Walid Klibi",
            "Chelsea White III",
            "Benoit Montreuil"
        ],
        "summary": "Last-mile logistics is regarded as an essential yet highly expensive component of parcel logistics. In dense urban environments, this is partially caused by inherent inefficiencies due to traffic congestion and the disparity and accessibility of customer locations. In parcel logistics, access hubs are facilities supporting relay-based last-mile activities by offering temporary storage locations enabling the decoupling of last-mile activities from the rest of the urban distribution chain. This paper focuses on a novel tactical problem: the geographically dynamic deployment of pooled relocatable storage capacity modules in an urban parcel network operating under space-time uncertainty. In particular, it proposes a two-stage stochastic optimization model for the access hub dynamic pooled capacity deployment problem with synchronization of underlying operations through travel time estimates, and a solution approach based on a rolling horizon algorithm with lookahead and a benders decomposition able to solve large scale instances of a real-sized megacity. Numerical results, inspired by the case of a large parcel express carrier, are provided to evaluate the computational performance of the proposed approach and suggest up to 28% last-mile cost savings and 26% capacity savings compared to a static capacity deployment strategy.",
        "published": "2020-07-22T08:43:05Z",
        "link": "http://arxiv.org/abs/2007.11270v1",
        "categories": [
            "math.OC",
            "cs.CE"
        ]
    },
    {
        "title": "Learning to predict metal deformations in hot-rolling processes",
        "authors": [
            "R. Omar Chavez-Garcia",
            "Emian Furger",
            "Samuele Kronauer",
            "Christian Brianza",
            "Marco Scarfò",
            "Luca Diviani",
            "Alessandro Giusti"
        ],
        "summary": "Hot-rolling is a metal forming process that produces a workpiece with a desired target cross-section from an input workpiece through a sequence of plastic deformations; each deformation is generated by a stand composed of opposing rolls with a specific geometry. In current practice, the rolling sequence (i.e., the sequence of stands and the geometry of their rolls) needed to achieve a given final cross-section is designed by experts based on previous experience, and iteratively refined in a costly trial-and-error process. Finite Element Method simulations are increasingly adopted to make this process more efficient and to test potential rolling sequences, achieving good accuracy at the cost of long simulation times, limiting the practical use of the approach. We propose a supervised learning approach to predict the deformation of a given workpiece by a set of rolls with a given geometry; the model is trained on a large dataset of procedurally-generated FEM simulations, which we publish as supplementary material. The resulting predictor is four orders of magnitude faster than simulations, and yields an average Jaccard Similarity Index of 0.972 (against ground truth from simulations) and 0.925 (against real-world measured deformations); we additionally report preliminary results on using the predictor for automatic planning of rolling sequences.",
        "published": "2020-07-22T13:33:44Z",
        "link": "http://arxiv.org/abs/2007.14471v1",
        "categories": [
            "cs.CE",
            "cs.CV",
            "cs.LG",
            "cs.RO"
        ]
    },
    {
        "title": "Towards a Better Modelling of the Cell Formation Problem: An Overview of   Decisions and a Critical analysis of Constraints and Objectives",
        "authors": [
            "Menouar Boulif",
            "Karim Atif"
        ],
        "summary": "Cell formation problem is among the first obstacles the designer of cellular production systems must overcome. This paper presents a critical analysis of the various criteria and constraints considered in the literature. The objective is to help any researcher who wants to model the problem by adopting a multi-criteria approach.",
        "published": "2020-07-22T17:44:11Z",
        "link": "http://arxiv.org/abs/2007.11566v1",
        "categories": [
            "cs.CE",
            "math.OC",
            "90C26",
            "F.2.2; J.6.2"
        ]
    },
    {
        "title": "A Preliminary Investigation in the Molecular Basis of Host Shutoff   Mechanism in SARS-CoV",
        "authors": [
            "Niharika Pandala",
            "Casey A. Cole",
            "Devaun McFarland",
            "Anita Nag",
            "Homayoun Valafar"
        ],
        "summary": "Recent events leading to the worldwide pandemic of COVID-19 have demonstrated the effective use of genomic sequencing technologies to establish the genetic sequence of this virus. In contrast, the COVID-19 pandemic has demonstrated the absence of computational approaches to understand the molecular basis of this infection rapidly. Here we present an integrated approach to the study of the nsp1 protein in SARS-CoV-1, which plays an essential role in maintaining the expression of viral proteins and further disabling the host protein expression, also known as the host shutoff mechanism. We present three independent methods of evaluating two potential binding sites speculated to participate in host shutoff by nsp1. We have combined results from computed models of nsp1, with deep mining of all existing protein structures (using PDBMine), and binding site recognition (using msTALI) to examine the two sites consisting of residues 55-59 and 73-80. Based on our preliminary results, we conclude that the residues 73-80 appear as the regions that facilitate the critical initial steps in the function of nsp1. Given the 90% sequence identity between nsp1 from SARS-CoV-1 and SARS-CoV-2, we conjecture the same critical initiation step in the function of COVID-19 nsp1.",
        "published": "2020-07-23T21:56:07Z",
        "link": "http://arxiv.org/abs/2007.13469v1",
        "categories": [
            "q-bio.BM",
            "cs.CE",
            "q-bio.QM"
        ]
    },
    {
        "title": "Electro-magneto-mechanically response of polycrystalline materials:   Computational Homogenization via the Virtual Element Method",
        "authors": [
            "Christoph Böhm",
            "Blaž Hudobivnik",
            "Michele Marino",
            "Peter Wriggers"
        ],
        "summary": "This work presents a study on the computational homogenization of electro-magneto-mechanically coupled problems through the Virtual Element Method (VEM). VE-approaches have great potential for the homogenization of the physical properties of heterogeneous polycrystalline microstructures with anisotropic grains. The flexibility in element shapes can be exploited for creating VE-mesh with a significant lower number of degrees of freedom if compared to finite element (FE) meshes, while maintaining a high accuracy. Evidence that VE-approaches outperform FEM are available in the literature, but only addressing purely-mechanic problems (i.e. elastic properties) and transversely anisotropic materials. The aim of this work is twofold. On one hand, the study compares VE-and FE-based numerical homogenization schemes for electro-mechanically coupled problems for different crystal lattice structures and degrees of elastic anisotropy. Within all considered materials, the VE-approach outperforms the FE-approach for the same number of nodes. On the other hand a hybrid microstructure made up by both electro-mechanical and magneto-mechanical grains is investigated resulting in a electro-magneto-mechanically coupled microstructure. Again, VEM provides a more accurate solution strategy.",
        "published": "2020-07-24T13:38:42Z",
        "link": "http://arxiv.org/abs/2008.01516v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Producing 3D Friction Loads by Tracking the Motion of the Contact Point   on Bodies in Mutual Contact",
        "authors": [
            "Luning Fang",
            "Dan Negrut"
        ],
        "summary": "We outline a phenomenological model to assess friction at the interface between two bodies in mutual contact. Although the approach is general, the application inspiring the approach is the Discrete Element Method. The kinematics of the friction process is expressed in terms of the relative 3D motion of the contact point on the two surfaces in mutual contact. The model produces expressions for three friction loads: slide force, roll torque, and spin torque. The cornerstone of the methodology is the process of tracking the evolution/path of the contact point on the surface of the two bodies in mutual contact. The salient attribute of the model lies with its ability to simultaneously compute, in a 3D setup, the slide, roll, and spin friction loads for smooth bodies of arbitrary geometry while accounting for both static and kinematic friction coefficients.",
        "published": "2020-07-24T18:00:44Z",
        "link": "http://arxiv.org/abs/2007.12713v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Data-driven optimization of building layouts for energy efficiency",
        "authors": [
            "Andrew Sonta",
            "Thomas R. Dougherty",
            "Rishee K. Jain"
        ],
        "summary": "One of the primary driving factors in building energy performance is occupant behavioral dynamics. As a result, the layout of building occupant workstations is likely to influence energy consumption. In this paper, we introduce methods for relating lighting zone energy to zone-level occupant dynamics, simulating energy consumption of a lighting system based on this relationship, and optimizing the layout of buildings through the use of both a clustering-based approach and a genetic algorithm in order to reduce energy consumption. We find in a case study that nonhomogeneous behavior (i.e., high diversity) among occupant schedules positively correlates with the energy consumption of a highly controllable lighting system. We additionally find through data-driven simulation that the na\\\"ive clustering-based optimization and the genetic algorithm (which makes use of the energy simulation engine) produce layouts that reduce energy consumption by roughly 5% compared to the existing layout of a real office space comprised of 165 occupants. Overall, this study demonstrates the merits of utilizing low-cost dynamic design of existing building layouts as a means to reduce energy usage. Our work provides an additional path to reach our sustainable energy goals in the built environment through new non-capital-intensive interventions.",
        "published": "2020-07-24T22:58:16Z",
        "link": "http://arxiv.org/abs/2007.12796v1",
        "categories": [
            "cs.CE",
            "cs.CY"
        ]
    },
    {
        "title": "Controlling the Outbreak of COVID-19: A Noncooperative Game Perspective",
        "authors": [
            "Anupam Kumar Bairagi",
            "Mehedi Masud",
            "Do Hyeon Kim",
            "Md. Shirajum Munir",
            "Abdullah Al Nahid",
            "Sarder Fakhrul Abedin",
            "Kazi Masudul Alam",
            "Sujit Biswas",
            "Sultan S Alshamrani",
            "Zhu Han",
            "Choong Seon Hong"
        ],
        "summary": "COVID-19 is a global epidemic. Till now, there is no remedy for this epidemic. However, isolation and social distancing are seemed to be effective preventive measures to control this pandemic. Therefore, in this paper, an optimization problem is formulated that accommodates both isolation and social distancing features of the individuals. To promote social distancing, we solve the formulated problem by applying a noncooperative game that can provide an incentive for maintaining social distancing to prevent the spread of COVID-19. Furthermore, the sustainability of the lockdown policy is interpreted with the help of our proposed game-theoretic incentive model for maintaining social distancing where there exists a Nash equilibrium. Finally, we perform an extensive numerical analysis that shows the effectiveness of the proposed approach in terms of achieving the desired social-distancing to prevent the outbreak of the COVID-19 in a noncooperative environment. Numerical results show that the individual incentive increases more than 85% with an increasing percentage of home isolation from 25% to 100% for all considered scenarios. The numerical results also demonstrate that in a particular percentage of home isolation, the individual incentive decreases with an increasing number of individuals.",
        "published": "2020-07-27T04:28:32Z",
        "link": "http://arxiv.org/abs/2007.13305v2",
        "categories": [
            "cs.CY",
            "cs.CE",
            "cs.GT"
        ]
    },
    {
        "title": "Intracranial hemodynamics simulations: An efficient and accurate   immersed boundary scheme",
        "authors": [
            "D. S. Lampropoulos",
            "G. C. Bourantas",
            "B. F. Zwick",
            "G. C. Kagadis",
            "A. Wittek",
            "K. Miller",
            "V. C. Loukopoulos"
        ],
        "summary": "Computational fluid dynamics (CFD) studies have been increasingly used for blood flow simulations in intracranial aneurysms (ICAs). However, despite the continuous progress of body-fitted CFD solvers, generating a high quality mesh is still the bottleneck of the CFD simulation, and strongly affects the accuracy of the numerical solution. To overcome this challenge, which will allow preforming CFD simulations efficiently for a large number of aneurysm cases we use an Immersed Boundary (IB) method. The proposed scheme relies on Cartesian grids to solve the incompressible Navier-Stokes (N-S) equations, using a finite element solver, and Lagrangian points to discretize the immersed object. All grid generations are conducted through automated algorithms which require no user input. Consequently, we verify the proposed method by comparing our numerical findings (velocity values) with published experimental results. Finally, we test the ability of the scheme to efficiently handle hemodynamic simulations on complex geometries on a sample of four patient-specific intracranial aneurysms.",
        "published": "2020-07-27T10:16:32Z",
        "link": "http://arxiv.org/abs/2007.13411v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Machine learning for metal additive manufacturing: Predicting   temperature and melt pool fluid dynamics using physics-informed neural   networks",
        "authors": [
            "Qiming Zhu",
            "Zeliang Liu",
            "Jinhui Yan"
        ],
        "summary": "The recent explosion of machine learning (ML) and artificial intelligence (AI) shows great potential in the breakthrough of metal additive manufacturing (AM) process modeling. However, the success of conventional machine learning tools in data science is primarily attributed to the unprecedented large amount of labeled data-sets (big data), which can be either obtained by experiments or first-principle simulations. Unfortunately, these labeled data-sets are expensive to obtain in AM due to the high expense of the AM experiments and prohibitive computational cost of high-fidelity simulations.   We propose a physics-informed neural network (PINN) framework that fuses both data and first physical principles, including conservation laws of momentum, mass, and energy, into the neural network to inform the learning processes. To the best knowledge of the authors, this is the first application of PINN to three dimensional AM processes modeling. Besides, we propose a hard-type approach for Dirichlet boundary conditions (BCs) based on a Heaviside function, which can not only enforce the BCs but also accelerate the learning process. The PINN framework is applied to two representative metal manufacturing problems, including the 2018 NIST AM-Benchmark test series. We carefully assess the performance of the PINN model by comparing the predictions with available experimental data and high-fidelity simulation results. The investigations show that the PINN, owed to the additional physical knowledge, can accurately predict the temperature and melt pool dynamics during metal AM processes with only a moderate amount of labeled data-sets. The foray of PINN to metal AM shows the great potential of physics-informed deep learning for broader applications to advanced manufacturing.",
        "published": "2020-07-28T20:34:38Z",
        "link": "http://arxiv.org/abs/2008.13547v2",
        "categories": [
            "cs.CE",
            "cs.LG",
            "physics.app-ph",
            "physics.flu-dyn"
        ]
    },
    {
        "title": "Correlation structure in the elasticity tensor for short   fiber-reinforced composites",
        "authors": [
            "Natalie Rauter",
            "Rolf Lammering"
        ],
        "summary": "The present work provides a profound analytical and numerical analysis of the material properties of SFRC on the mesoscale as well as the resulting correlation structure taking into account the probabilistic characteristics of the fiber geometry. This is done by calculating the engineering constants using the analytical framework given by Tandon and Weng as well as Halpin and Tsai. The input parameters like fiber length, diameter and orientation are chosen with respect to their probability density function. It is shown, that they are significantly influenced by the fiber length, the fiber orientation and the fiber volume fraction. The verification of the analytically obtained values is done on a numerical basis. Therefore, a two-dimensional microstructure is generated and transferred to a numerical model. The advantage of this procedure is, that there are several fibers with different geometrical properties placed in a preset area. The results of the numerical analysis meet the analytically obtained conclusions. Furthermore, the results of the numerical simulations are independent of the assumption of a plane strain and plane stress state, respectively. Finally, the correlation structure of the elasticity tensor is investigated. Not only the symmetry properties of the elasticity tensor characterize the correlation structure, but also the overall transversely-isotropic material behavior is confirmed. In contrast to the influencing parameters, the correlation functions vary for a plane strain and a plane stress state.",
        "published": "2020-07-29T11:36:00Z",
        "link": "http://arxiv.org/abs/2007.14751v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Metamodel Based Forward and Inverse Design for Passive Vibration   Suppression",
        "authors": [
            "Amir Behjat",
            "Manaswin Oddiraju",
            "Mohammad Ali Attarzadeh",
            "Mostafa Nouh",
            "Souma Chowdhury"
        ],
        "summary": "Aperiodic metamaterials represent a class of structural systems that are composed of different building blocks (cells), instead of a self-repeating chain of the same unit cells. Optimizing aperiodic cellular structural systems thus presents high-dimensional problems that are challenging to solve using purely high-fidelity structural optimization approaches. Specialized analytical modeling along with metamodel based optimization can provide a more tractable alternative solution approach. To this end, this paper presents a design automation framework applied to a 1D metamaterial system, namely a drill string, where vibration suppression is of utmost importance. The drill string comprises a set of nonuniform rings attached to the outer surface of a longitudinal rod. As such, the resultant system can now be perceived as an aperiodic 1D metamaterial with each ring/gap representing a cell. Despite being a 1D system, the simultaneous consideration of multiple DoF (i.e., torsional, axial, and lateral motions) poses significant computational challenges. Therefore, a transfer matrix method (TMM) is employed to analytically determine the frequency response of the drill string. A suite of neural networks (ANN) is trained on TMM samples (which present minute-scale computing costs per evaluation), to model the frequency response. ANN-based optimization is then performed to minimize mass subject to constraints on the gap between consecutive resonance peaks in one case, and minimizing this gap in the second case, leading to crucial improvements over baselines. Further novel contribution occurs through the development of an inverse modeling approach that can instantaneously produce the 1D metamaterial design with minimum mass for a given desired non-resonant frequency range. This is accomplished by using invertible neural networks, and results show promising alignment with forward solutions.",
        "published": "2020-07-29T18:11:11Z",
        "link": "http://arxiv.org/abs/2007.15038v1",
        "categories": [
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "Bayesian Inversion for Anisotropic Hydraulic Phase-Field Fracture",
        "authors": [
            "Nima Noii",
            "Amirreza Khodadadian",
            "Thomas Wick"
        ],
        "summary": "In this work, a Bayesian inversion framework for hydraulic phase-field transversely isotropic and orthotropy anisotropic fracture is proposed. Therein, three primary fields are pressure, displacements, and phase-field while direction-dependent responses are enforced (via penalty-like parameters). A new crack driving state function is introduced by avoiding the compressible part of anisotropic energy to be degraded. For the Bayesian inversion, we employ the delayed rejection adaptive Metropolis (DRAM) algorithm to identify the parameters. We adjust the algorithm to estimate parameters according to a hydraulic fracture observation, i.e., the maximum pressure. The focus is on uncertainties arising from different variables, including elasticity modulus, Biot's coefficient, Biot's modulus, dynamic fluid viscosity, and Griffith's energy release rate in the case of the isotropic hydraulic fracture while in the anisotropic setting, we identify additional penalty-like parameters. Several numerical examples are employed to substantiate our algorithmic developments.",
        "published": "2020-07-29T21:25:59Z",
        "link": "http://arxiv.org/abs/2007.16038v1",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Localized Nonlinear Solution Strategies for Efficient Simulation of   Unconventional Reservoirs",
        "authors": [
            "Jiamin Jiang"
        ],
        "summary": "Accurate and efficient numerical simulation of unconventional reservoirs is challenging. Long periods of transient flow and steep potential gradients occur due to the extreme conductivity contrast between matrix and fracture. Detailed near-well/near-fracture models are necessary to provide sufficient resolution, but they are computationally impractical for field cases with multiple fracture stages. Previous works in the literature of unconventional simulations mainly focus on gridding level that adapts to wells and fractures. Limited research has been conducted on nonlinear strategies that exploit locality across timesteps and nonlinear iterations. To perform localized computations, an a-priori strategy is essential to first determine the active subset of simulation cells for the subsequent iteration. The active set flags the cells that will be updated, and then the corresponding localized linear system is solved. This work develops localization methods that are readily applicable to complex fracture networks and flow physics in unconventional reservoirs. By utilizing the diffusive nature of pressure updates, an adaptive algorithm is proposed to make adequate estimates for the active domains. In addition, we develop a localized solver based on nonlinear domain decomposition (DD). Comparing to a standard DD method, domain partitions are dynamically constructed. The new solver provides effective partitioning that adapts to flow dynamics and Newton updates. We evaluate the developed methods using several complex problems with discrete fracture networks. The results show that large degrees of solution locality present across timesteps and iterations. Comparing to a standard Newton solver, the new solvers enable superior computational performance. Moreover, Newton convergence behavior is preserved, without any impact on solution accuracy.",
        "published": "2020-07-29T21:44:04Z",
        "link": "http://arxiv.org/abs/2008.01539v2",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Characterizing digital microstructures by the Minkowski-based quadratic   normal tensor",
        "authors": [
            "Felix Ernesti",
            "Matti Schneider",
            "Steffen Winter",
            "Daniel Hug",
            "Günter Last",
            "Thomas Böhlke"
        ],
        "summary": "For material modeling of microstructured media, an accurate characterization of the underlying microstructure is indispensable. Mathematically speaking, the overall goal of microstructure characterization is to find simple functionals which describe the geometric shape as well as the composition of the microstructures under consideration, and enable distinguishing microstructures with distinct effective material behavior. For this purpose, we propose using Minkowski tensors, in general, and the quadratic normal tensor, in particular, and introduce a computational algorithm applicable to voxel-based microstructure representations. Rooted in the mathematical field of integral geometry, Minkowski tensors associate a tensor to rather general geometric shapes, which make them suitable for a wide range of microstructured material classes. Furthermore, they satisfy additivity and continuity properties, which makes them suitable and robust for large-scale applications. We present a modular algorithm for computing the quadratic normal tensor of digital microstructures. We demonstrate multigrid convergence for selected numerical examples and apply our approach to a variety of microstructures. Strikingly, the presented algorithm remains unaffected by inaccurate computation of the interface area. The quadratic normal tensor may be used for engineering purposes, such as mean-field homogenization or as target value for generating synthetic microstructures.",
        "published": "2020-07-30T14:35:56Z",
        "link": "http://arxiv.org/abs/2007.15490v1",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Network connectivity optimization: An evaluation of heuristics applied   to complex networks and a transportation case study",
        "authors": [
            "Jeremy Auerbach",
            "Hyun Kim"
        ],
        "summary": "Network optimization has generally been focused on solving network flow problems, but recently there have been investigations into optimizing network characteristics. Optimizing network connectivity to maximize the number of nodes within a given distance to a focal node and then minimizing the number and length of additional connections has not been as thoroughly explored, yet is important in several domains including transportation planning, telecommunications networks, and geospatial analysis. We compare several heuristics to explore this network connectivity optimization problem with the use of random networks, including the introduction of two planar random networks that are useful for spatial network simulation research, and a real-world case study from urban planning and public health. We observe significant variation between nodal characteristics and optimal connections across network types. This result along with the computational costs of the search for optimal solutions highlights the difficulty of finding effective heuristics. A novel genetic algorithm is proposed and we find this optimization heuristic outperforms existing techniques and describe how it can be applied to other combinatorial and dynamic problems.",
        "published": "2020-07-31T16:07:04Z",
        "link": "http://arxiv.org/abs/2007.16150v1",
        "categories": [
            "physics.soc-ph",
            "cs.CE",
            "cs.SI"
        ]
    },
    {
        "title": "Process of Efficiently Parallelizing a Protein Structure Determination   Algorithm",
        "authors": [
            "Michael Bryson",
            "Xijiang Miao",
            "Homayoun Valafar"
        ],
        "summary": "Computational protein structure determination involves optimization in a problem space much too large to exhaustively search. Existing approaches include optimization algorithms such as gradient descent and simulated annealing, but these typically only find local minima. One novel approach implemented in REDcRAFT is to instead of folding a protein all at the same time, fold it residue by residue. This simulates a protein folding as each residue exits from the generating ribosome. While REDcRAFT exponentially reduces the problem space so it can be explored in polynomial time, it is still extremely computationally demanding. This algorithm does have the advantage that most of the execution time is spent in inherently parallelizable code. However, preliminary results from parallel execution indicate that approximately two-thirds of execution time is dedicated to system overhead. Additionally, by carefully analyzing and timing the structure of the program the major bottlenecks can be identified. After addressing these issues, REDcRAFT becomes a scalable parallel application with nearly two orders of magnitude improvement.",
        "published": "2020-07-31T18:04:39Z",
        "link": "http://arxiv.org/abs/2008.00018v1",
        "categories": [
            "cs.DC",
            "cs.CE",
            "cs.NA",
            "math.NA",
            "q-bio.BM"
        ]
    },
    {
        "title": "Signal metrics analysis of oscillatory patterns in bacterial multi-omic   networks",
        "authors": [
            "Francesco Bardozzo",
            "Pietro Liò",
            "Roberto Tagliaferri"
        ],
        "summary": "Motivation: One of the branches of Systems Biology is focused on a deep understanding of underlying regulatory networks through the analysis of the biomolecules oscillations and their interplay. Synthetic Biology exploits gene or/and protein regulatory networks towards the design of oscillatory networks for producing useful compounds. Therefore, at different levels of application and for different purposes, the study of biomolecular oscillations can lead to different clues about the mechanisms underlying living cells. It is known that network-level interactions involve more than one type of biomolecule as well as biological processes operating at multiple omic levels. Combining network/pathway-level information with genetic information it is possible to describe well-understood or unknown bacterial mechanisms and organism-specific dynamics. Results: Network multi-omic integration has led to the discovery of interesting oscillatory signals. Following the methodologies used in signal processing and communication engineering, a new methodology is introduced to identify and quantify the extent of the multi-omic oscillations of the signal. New signal metrics are designed to allow further biotechnological explanations and provide important clues about the oscillatory nature of the pathways and their regulatory circuits. Our algorithms designed for the analysis of multi-omic signals are tested and validated on 11 different bacteria for thousands of multi-omic signals perturbed at the network level by different experimental conditions. Information on the order of genes, codon usage, gene expression, and protein molecular weight is integrated at three different functional levels. Oscillations show interesting evidence that network-level multi-omic signals present a synchronized response to perturbations and evolutionary relations along with taxa.",
        "published": "2020-08-01T13:27:53Z",
        "link": "http://arxiv.org/abs/2008.00263v1",
        "categories": [
            "q-bio.MN",
            "cs.CE",
            "I.5.2"
        ]
    },
    {
        "title": "Uncertainty Quantification of Structural Systems with Subset of Data",
        "authors": [
            "Mohammad Amin Hariri-Ardebili",
            "Farhad Pourkamali-Anaraki",
            "Siamak Sattar"
        ],
        "summary": "Quantification of the impact of uncertainty in material properties as well as the input ground motion on structural responses is an important step in implementing a performance-based earthquake engineering (PBEE) framework. Among various sources of uncertainty, the variability in the input ground motions, a.k.a. record-to-record, greatly affects the assessment results. The objective of this paper is to quantify the uncertainty in structural response with hybrid uncertainty sources. In this paper, multiple matrix completion methods are proposed and applied on a case study structure. The matrix completion method is a means to estimate the analyses results for the entire set of input parameters by conducting analysis for only a small subset of analyses. The main algorithmic contributions of our proposed method are twofold. First, we develop a sampling technique for choosing a subset of representative simulations, which allows improving the accuracy of the estimated response. An unsupervised machine learning technique is used for this purpose. Next, the proposed matrix completion method for uncertainty quantification is further refined by incorporating a regression model that is trained on the available partial simulations. The regression model improves the initial sampling as it provides a rough estimation of the structural responses. Finally, the proposed algorithm is applied to a multi-degree-of-freedom system, and the structural responses (i.e., displacements and base shear) are estimated. Results show that the proposed algorithm can effectively estimate the response from a full set of nonlinear simulations by conducting analyses only on a small portion of the set.",
        "published": "2020-08-03T00:20:40Z",
        "link": "http://arxiv.org/abs/2008.04382v1",
        "categories": [
            "cs.CE",
            "stat.AP"
        ]
    },
    {
        "title": "Processing of Crowdsourced Observations of Aircraft in a High   Performance Computing Environment",
        "authors": [
            "Andrew Weinert",
            "Ngaire Underhill",
            "Bilal Gill",
            "Ashley Wicks"
        ],
        "summary": "As unmanned aircraft systems (UASs) continue to integrate into the U.S. National Airspace System (NAS), there is a need to quantify the risk of airborne collisions between unmanned and manned aircraft to support regulation and standards development. Both regulators and standards developing organizations have made extensive use of Monte Carlo collision risk analysis simulations using probabilistic models of aircraft flight. We've previously determined that the observations of manned aircraft by the OpenSky Network, a community network of ground-based sensors, are appropriate to develop models of the low altitude environment. This works overviews the high performance computing workflow designed and deployed on the Lincoln Laboratory Supercomputing Center to process 3.9 billion observations of aircraft. We then trained the aircraft models using more than 250,000 flight hours at 5,000 feet above ground level or below. A key feature of the workflow is that all the aircraft observations and supporting datasets are available as open source technologies or been released to the public domain.",
        "published": "2020-08-03T13:29:20Z",
        "link": "http://arxiv.org/abs/2008.00861v1",
        "categories": [
            "cs.DC",
            "cs.CE",
            "H.3; I.6.5; E.2"
        ]
    },
    {
        "title": "Multifidelity Data Fusion via Gradient-Enhanced Gaussian Process   Regression",
        "authors": [
            "Yixiang Deng",
            "Guang Lin",
            "Xiu Yang"
        ],
        "summary": "We propose a data fusion method based on multi-fidelity Gaussian process regression (GPR) framework. This method combines available data of the quantity of interest (QoI) and its gradients with different fidelity levels, namely, it is a Gradient-enhanced Cokriging method (GE-Cokriging). It provides the approximations of both the QoI and its gradients simultaneously with uncertainty estimates. We compare this method with the conventional multi-fidelity Cokriging method that does not use gradients information, and the result suggests that GE-Cokriging has a better performance in predicting both QoI and its gradients. Moreover, GE-Cokriging even shows better generalization result in some cases where Cokriging performs poorly due to the singularity of the covariance matrix. We demonstrate the application of GE-Cokriging in several practical cases including reconstructing the trajectories and velocity of an underdamped oscillator with respect to time simultaneously, and investigating the sensitivity of power factor of a load bus with respect to varying power inputs of a generator bus in a large scale power system. We also show that though GE-Cokriging method requires a little bit higher computational cost than Cokriging method, the result of accuracy comparison shows that this cost is usually worth it.",
        "published": "2020-08-03T17:57:12Z",
        "link": "http://arxiv.org/abs/2008.01066v1",
        "categories": [
            "cs.CE",
            "stat.ML"
        ]
    },
    {
        "title": "Frequency-Dependent Material Motion Benchmarks for Radiative Transfer",
        "authors": [
            "Ryan G. McClarren",
            "N. A. Gentile"
        ],
        "summary": "We present a general solution for the radiation intensity in front of a purely absorbing slab moving toward an observer at constant speed and with a constant temperature. The solution is obtained by integrating the lab-frame radiation transport equation through the slab to the observer. We present comparisons between our benchmark and results from the Kull simulation code for an aluminum slab moving toward the observer at 2% the speed-of-light. We demonstrate that ignoring certain material motion correction terms in the transport equation can lead to 20-80% errors with the error magnitude growing as the frequency resolution is improved. Our results also indicate that our benchmark can identify potential errors in the implementation of material motion corrections.",
        "published": "2020-08-03T18:27:34Z",
        "link": "http://arxiv.org/abs/2009.01905v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Least Squares Finite Element Method for Hepatic Sinusoidal Blood Flow",
        "authors": [
            "Fleurianne Bertrand",
            "Lena Lambers",
            "Tim Ricken"
        ],
        "summary": "The simulation of complex biological systems such as the description of blood flow in organs requires a lot of computational power as well as a detailed description of the organ physiology. We present a novel Least-Squares discretization method for the simulation of sinusoidal blood flow in liver lobules using a porous medium approach for the liver tissue. The scaling of the different Least-Squares terms leads to a robust algorithm and the inherent error estimator provides an efficient refinement strategy.",
        "published": "2020-08-04T13:26:10Z",
        "link": "http://arxiv.org/abs/2008.01512v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Data-driven reduced-order models via regularized operator inference for   a single-injector combustion process",
        "authors": [
            "Shane A. McQuarrie",
            "Cheng Huang",
            "Karen E. Willcox"
        ],
        "summary": "This paper derives predictive reduced-order models for rocket engine combustion dynamics via Operator Inference, a scientific machine learning approach that blends data-driven learning with physics-based modeling. The non-intrusive nature of the approach enables variable transformations that expose system structure. The specific contribution of this paper is to advance the formulation robustness and algorithmic scalability of the Operator Inference approach. Regularization is introduced to the formulation to avoid over-fitting. The task of determining an optimal regularization is posed as an optimization problem that balances training error and stability of long-time integration dynamics. A scalable algorithm and open-source implementation are presented, then demonstrated for a single-injector rocket combustion example. This example exhibits rich dynamics that are difficult to capture with state-of-the-art reduced models. With appropriate regularization and an informed selection of learning variables, the reduced-order models exhibit high accuracy in re-predicting the training regime and acceptable accuracy in predicting future dynamics, while achieving close to a million times speedup in computational cost. When compared to a state-of-the-art model reduction method, the Operator Inference models provide the same or better accuracy at approximately one thousandth of the computational cost.",
        "published": "2020-08-06T20:26:48Z",
        "link": "http://arxiv.org/abs/2008.02862v2",
        "categories": [
            "cs.CE",
            "J.2"
        ]
    },
    {
        "title": "An integrated numerical model for coupled poro-hydro-mechanics and   fracture propagation using embedded meshes",
        "authors": [
            "Guotong Ren",
            "Rami M. Younis"
        ],
        "summary": "Integrated models for fluid-driven fracture propagation and general multiphase flow in porous media are valuable to the study and engineering of several systems, including hydraulic fracturing, underground disposal of waste, and geohazard mitigation across such applications. This work extends the coupled model multiphase flow and poromechanical model of \\cite{ren2018embedded} to admit fracture propagation (FP). The coupled XFEM-EDFM scheme utilizes a separate fracture mesh that is embedded on a static background mesh. The onset and dynamics of fracture propagation (FP) are governed by the equivalent stress intensity factor (SIF) criterion. A domain-integral method (J integral) is applied to compute this information. An adaptive time-marching scheme is proposed to rapidly restrict and grow temporal resolution to match the underlying time-scales. The proposed model is verified with analytical solutions, and shows the capability to accurately and adaptively co-simulate fluid transport and deformation as well as the propagation of multiple fractures.",
        "published": "2020-08-07T13:47:52Z",
        "link": "http://arxiv.org/abs/2008.03186v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A new operational matrix technique to solve linear boundary value   problems",
        "authors": [
            "Udaya Pratap Singh"
        ],
        "summary": "A new technique is presented to solve a class of linear boundary value problems (BVP). Technique is primarily based on an operational matrix developed from a set of modified Bernoulli polynomials. The new set of polynomials is an orthonormal set obtained with Gram-Schmidt orthogonalization applied to classical Bernoulli polynomials. The presented method changes a given linear BVP into a system of algebraic equations which is solved to find an approximate solution of BVP in form of a polynomial of required degree. The technique is applied to four problems and obtained approximate solutions are graphically compared to available exact and other numerical solutions. The method is simpler than many existing methods and provides a high degree of accuracy.",
        "published": "2020-08-09T14:26:47Z",
        "link": "http://arxiv.org/abs/2008.05599v1",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA",
            "34B05, 65L10, 34A45, 34B60, 65L05"
        ]
    },
    {
        "title": "Modeling of non-equilibrium effects in intermittency region between two   phases",
        "authors": [
            "Tomasz Wacławczyk"
        ],
        "summary": "This paper concerns modeling of the evolution of intermittency region between two weakly miscible phases due to temporal and spatial variations of its characteristic length scale. First, the need of a more general description allowing for the evolution of intermittency region is rationalized. Afterwards, results of the previous work (Wac{\\l}awczyk T., 2017, On a relation between the volume of fluid, level-set and phase field interface models, Int. J. Multiphas. Flow, Vol. 97) are discussed in context of the sharp interface models known in the literature and insight into droplet coalescence mechanism recently recognized in the molecular dynamics studies (Perumanath S., Borg M.K., Chubynsky M.V., Sprittles J.E., Reese J.M., 2019, Droplet coalescence is initiated by thermal motion, Phys. Rev. Lett., Vol. 122). Finally, the physical and numerical models extending applicability of the equilibrium solution to the case when intermittency region could also be in the non-equilibrium state is introduced and verified in several test cases.",
        "published": "2020-08-10T13:12:20Z",
        "link": "http://arxiv.org/abs/2008.04098v2",
        "categories": [
            "physics.flu-dyn",
            "cond-mat.mes-hall",
            "cs.CE",
            "76T99"
        ]
    },
    {
        "title": "An Efficient Sliding Mesh Interface Method for High-Order Discontinuous   Galerkin Schemes",
        "authors": [
            "Jakob Dürrwächter",
            "Marius Kurz",
            "Patrick Kopper",
            "Daniel Kempf",
            "Claus-Dieter Munz",
            "Andrea Beck"
        ],
        "summary": "Sliding meshes are a powerful method to treat deformed domains in computational fluid dynamics, where different parts of the domain are in relative motion. In this paper, we present an efficient implementation of a sliding mesh method into a discontinuous Galerkin compressible Navier-Stokes solver and its application to a large eddy simulation of a 1-1/2 stage turbine. The method is based on the mortar method and is high-order accurate. It can handle three-dimensional sliding mesh interfaces with various interface shapes. For plane interfaces, which are the most common case, conservativity and free-stream preservation are ensured. We put an emphasis on efficient parallel implementation. Our implementation generates little computational and storage overhead. Inter-node communication via MPI in a dynamically changing mesh topology is reduced to a bare minimum by ensuring a priori information about communication partners and data sorting. We provide performance and scaling results showing the capability of the implementation strategy. Apart from analytical validation computations and convergence results, we present a wall-resolved implicit LES of the 1-1/2 stage Aachen turbine test case as a large scale practical application example.",
        "published": "2020-08-10T18:39:50Z",
        "link": "http://arxiv.org/abs/2008.04356v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Driver Assistance for Safe and Comfortable On-Ramp Merging Using   Environment Models Extended through V2X Communication and Role-Based Behavior   Predictions",
        "authors": [
            "Lucas Eiermann",
            "Florian Wirthmüller",
            "Kay Massow",
            "Gabi Breuel",
            "Ilja Radusch"
        ],
        "summary": "Modern driver assistance systems as well as autonomous vehicles take their decisions based on local maps of the environment. These maps include, for example, surrounding moving objects perceived by sensors as well as routes and navigation information. Current research in the field of environment mapping is concerned with two major challenges. The first one is the integration of information from different sources e.g. on-board sensors like radar, camera, ultrasound and lidar, offline map data or backend information. The second challenge comprises in finding an abstract representation of this aggregated information with suitable interfaces for different driving functions and traffic situations. To overcome these challenges, an extended environment model is a reasonable choice. In this paper, we show that role-based motion predictions in combination with v2x-extended environment models are able to contribute to increased traffic safety and driving comfort. Thus, we combine the mentioned research areas and show possible improvements, using the example of a threading process at a motorway access road. Furthermore, it is shown that already an average v2x equipment penetration of 80% can lead to a significant improvement of 0.33m/s^2 of the total acceleration and 12m more safety distance compared to non v2x-equipped vehicles during the threading process.",
        "published": "2020-08-11T14:00:20Z",
        "link": "http://arxiv.org/abs/2008.04707v3",
        "categories": [
            "eess.SP",
            "cs.CE",
            "cs.ET",
            "cs.RO",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "An immersed phase field fracture model for fluid-infiltrating porous   media with evolving Beavers-Joseph-Saffman condition",
        "authors": [
            "Hyoung Suk Suh",
            "WaiChing Sun"
        ],
        "summary": "This study presents a phase field model for brittle fracture in fluid-infiltrating vuggy porous media. While the state-of-the-art in hydraulic phase field fracture considers Darcian fracture flow with enhanced permeability along the crack, in this study, the phase field not only acts as a damage variable that provides diffuse representation of cracks or cavities, but also acts as an indicator function that separates the domain into two regions where fluid flows are governed by Stokes and Darcy equations, respectively. Since the phase field and its gradient can be respectively regarded as smooth approximations of the Heaviside function and Dirac delta function, our new approach is capable of imposing interfacial transmissibility conditions without explicit interface parametrizations. In addition, the interaction between solid and fluid constituents is modeled by adopting the concept of mixture theory, where the fluid velocities in Stokes and Darcy regions are considered as relative measures compared to the solid motion. This model is particularly attractive for coupled flow analysis in geological materials with complex microstructures undergoing brittle fracture often encountered in energy geotechnics problems, since it completely eliminates the needs to generate specific enrichment function, integration scheme, or meshing algorithm tailored for complex geological features.",
        "published": "2020-08-11T22:20:48Z",
        "link": "http://arxiv.org/abs/2008.11815v1",
        "categories": [
            "physics.flu-dyn",
            "cs.CE",
            "74",
            "G.1.8"
        ]
    },
    {
        "title": "Molecular dynamics simulation of crack growth in mono-crystal nickel   with voids and inclusions",
        "authors": [
            "Zhenxing Cheng",
            "Hu Wang",
            "Gui-Rong Liu",
            "Guangyao Li"
        ],
        "summary": "In this study, the crack propagation of the pre-cracked mono-crystal nickel with the voids and inclusions has been investigated by molecular dynamics simulations. Different sizes of voids, inclusions and materials of inclusions are used to fully study the effect of the voids and inclusions during the crack propagation process. The dislocations evolution, stress distribution and crack length are analyzed as the associated mechanical properties. The results indicate that the voids and inclusions can change the path of crack propagation of the pre-cracked mono-crystal nickel. Moreover, the results show that the voids and inclusions can lead a better resistance to plastic deformation of the mono-crystal and the inclusions can make the system more difficult to fracture.",
        "published": "2020-08-12T07:11:18Z",
        "link": "http://arxiv.org/abs/2008.05137v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Nonlinear static isogeometric analysis of arbitrarily curved   Kirchhoff-Love shells",
        "authors": [
            "G. Radenković",
            "A. Borković",
            "B. Marussig"
        ],
        "summary": "The geometrically rigorous nonlinear analysis of elastic shells is considered in the context of finite, but small, strain theory. The research is focused on the introduction of the full shell metric and examination of its influence on the nonlinear structural response. The exact relation between the reference and equidistant strains is employed and the complete analytic elastic constitutive relation between energetically conjugated forces and strains is derived via the reciprocal shift tensor. Utilizing these strict relations, the geometric stiffness matrix is derived explicitly by the variation of the unknown metric. Moreover, a compact form of this matrix is presented. Despite the linear displacement distribution due to the Kirchhoff-Love hypothesis, a nonlinear strain distribution arises along the shell thickness. This fact is sometimes disregarded for the nonlinear analysis of thin shells based on the initial geometry, thereby ignoring the strong curviness of a shell at some subsequent configuration. We show that the curviness of a shell at each configuration determines the appropriate shell formulation. For shells that become strongly curved at some configurations during deformation, the nonlinear distribution of strain throughout the thickness must be considered in order to obtain accurate results. We investigate four computational models: one based on the full analytical constitutive relation, and three simplified ones. Robustness, efficiency and accuracy of the presented formulation are examined via selected numerical experiments. Our main finding is that the employment of the full metric is often required when the complete response of the shells is sought, even for the initially thin shells. Finally, the simplified model that provided the best balance between efficiency and accuracy is suggested for the nonlinear analysis of strongly curved shells.",
        "published": "2020-08-12T12:02:10Z",
        "link": "http://arxiv.org/abs/2008.05254v2",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Topology optimization considering the distortion in additive   manufacturing",
        "authors": [
            "Takao Miki",
            "Takayuki Yamada"
        ],
        "summary": "Additive manufacturing is a free-form manufacturing technique in which parts are built in a layer-by-layer manner. Laser powder bed fusion is one of the popular techniques used to fabricate metal parts. However, it induces residual stress and distortion during fabrication that adversely affects the mechanical properties and dimensional accuracy of the manufactured parts. Therefore, predicting and avoiding the residual stress and distortion are critical issues. In this study, we propose a topology optimization method that accounts for the distortion. First, we propose a computationally inexpensive analytical model for additive manufacturing that uses laser powder bed fusion and formulated an optimization problem. Next, we approximate the topological derivative of the objective function using an adjoint variable method that is then utilized to update the level set function via a time evolutionary reaction-diffusion equation. Finally, the validity and effectiveness of the proposed optimization method was established using two-dimensional design examples.",
        "published": "2020-08-14T01:18:46Z",
        "link": "http://arxiv.org/abs/2008.06153v2",
        "categories": [
            "cs.CE",
            "math.OC"
        ]
    },
    {
        "title": "Formulation of Single-Source Surface Integral Equation for   Electromagnetic Analysis of Composite Penetrable Objects",
        "authors": [
            "Xiaochao Zhou",
            "Zekun Zhu",
            "Shunchuan Yang"
        ],
        "summary": "This paper presents a new single-source surface integral equation (SS-SIE) to model composite penetrable objects. In the proposed formulation, the surface electric and magnetic fields on all interior boundaries are first eliminated through combining integral solutions inside each object. Then, by enforcing the surface electric fields in the original and equivalent configurations are equal to each other, an equivalent model with only the electric current density on the outermost boundaries is derived. Compared with other SIEs, like the PMCHWT formulation, all unknowns are residing on the outermost boundaries in the proposed formulation and therefore, less count of unknowns can be obtained. Finally, two numerical examples are carried out to validate the effectiveness of the proposed SS-SIE.",
        "published": "2020-08-14T07:25:05Z",
        "link": "http://arxiv.org/abs/2008.06216v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Comparison and Application of non-Conforming Mesh Models for Flow in   Fractured Porous Media using dual {L}agrange multipliers",
        "authors": [
            "Patrick Zulian",
            "Philipp Schädle",
            "Liudmila Karagyaur",
            "Maria Nestola"
        ],
        "summary": "Geological settings with reservoir characteristics include fractures with different material and geometrical properties. Hence, numerical simulations in applied geophysics demands for computational frameworks which efficiently allow to integrate various fracture geometries in a porous medium matrix. This study presents a modeling approach for single-phase flow in fractured porous media and its application to different types of non-conforming mesh models. We propose a combination of the Lagrange multiplier method with variational transfer to allow for complex non-conforming geometries as well as hybrid- and equi-dimensional models and discretizations of flow through fractured porous media. The variational transfer is based on the $L^2$-projection and enables an accurate and highly efficient parallel projection of fields between non-conforming meshes (e.g.,\\ between fracture and porous matrix domain). We present the different techniques as a unified mathematical framework with a practical perspective. By means of numerical examples we discuss both, performance and applicability of the particular strategies. Comparisons of finite element simulation results to widely adopted 2D benchmark cases show good agreement and the dual Lagrange multiplier spaces show good performance. In an extension to 3D fracture networks, we first provide complementary results to a recently developed benchmark case, before we explore a complex scenario which leverages the different types of fracture meshes. Complex and highly conductive fracture networks are found more suitable in combination with embedded hybrid-dimensional fractures. However, thick and blocking fractures are better approximated by equi-dimensional embedded fractures and the equi-dimensional mortar method, respectively.",
        "published": "2020-08-14T13:27:08Z",
        "link": "http://arxiv.org/abs/2008.06360v1",
        "categories": [
            "physics.comp-ph",
            "cs.CE",
            "86-08, 6S05, 35-04"
        ]
    },
    {
        "title": "Fractional-Order Structural Stability: Formulation and Application to   the Critical Load of Slender Structures",
        "authors": [
            "Sai Sidhardh",
            "Sansit Patnaik",
            "Fabio Semperlotti"
        ],
        "summary": "This study presents the framework to perform a stability analysis of nonlocal solids whose response is formulated according to the fractional-order continuum theory. In this formulation, space fractional-order operators are used to capture the nonlocal response of the medium by introducing nonlocal kinematic relations. First, we use the geometrically nonlinear fractional-order kinematic relations within an energy-based approach to establish the Lagrange-Dirichlet stability criteria for fractional-order nonlocal structures. This energy-based approach to nonlocal structural stability is possible due to a positive-definite and thermodynamically consistent definition of deformation energy enabled by the fractional-order kinematic formulation. Then, the Rayleigh-Ritz coefficient for the critical load is derived for linear buckling conditions. The fractional-order formulation is finally used to determine critical buckling loads of slender nonlocal beams and plates using a dedicated fractional-order finite element solver. Results establish that, in contrast to existing studies, the effect of nonlocal interactions is observed on both the material and the geometric stiffness, when using the fractional-order kinematics approach. We support these observations quantitatively with the help of case studies focusing on the critical buckling response of fractional-order nonlocal slender structures, and qualitatively via direct comparison of the fractional-order approach with the classical nonlocal approaches.",
        "published": "2020-08-15T18:27:49Z",
        "link": "http://arxiv.org/abs/2008.11528v1",
        "categories": [
            "cs.CE",
            "cond-mat.mtrl-sci",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Wavelet Denoising and Attention-based RNN-ARIMA Model to Predict Forex   Price",
        "authors": [
            "Zhiwen Zeng",
            "Matloob Khushi"
        ],
        "summary": "Every change of trend in the forex market presents a great opportunity as well as a risk for investors. Accurate forecasting of forex prices is a crucial element in any effective hedging or speculation strategy. However, the complex nature of the forex market makes the predicting problem challenging, which has prompted extensive research from various academic disciplines. In this paper, a novel approach that integrates the wavelet denoising, Attention-based Recurrent Neural Network (ARNN), and Autoregressive Integrated Moving Average (ARIMA) are proposed. Wavelet transform removes the noise from the time series to stabilize the data structure. ARNN model captures the robust and non-linear relationships in the sequence and ARIMA can well fit the linear correlation of the sequential information. By hybridization of the three models, the methodology is capable of modelling dynamic systems such as the forex market. Our experiments on USD/JPY five-minute data outperforms the baseline methods. Root-Mean-Squared-Error (RMSE) of the hybrid approach was found to be 1.65 with a directional accuracy of ~76%.",
        "published": "2020-08-16T05:32:40Z",
        "link": "http://arxiv.org/abs/2008.06841v1",
        "categories": [
            "cs.CE",
            "cs.CV"
        ]
    },
    {
        "title": "GA-MSSR: Genetic Algorithm Maximizing Sharpe and Sterling Ratio Method   for RoboTrading",
        "authors": [
            "Zezheng Zhang",
            "Matloob Khushi"
        ],
        "summary": "Foreign exchange is the largest financial market in the world, and it is also one of the most volatile markets. Technical analysis plays an important role in the forex market and trading algorithms are designed utilizing machine learning techniques. Most literature used historical price information and technical indicators for training. However, the noisy nature of the market affects the consistency and profitability of the algorithms. To address this problem, we designed trading rule features that are derived from technical indicators and trading rules. The parameters of technical indicators are optimized to maximize trading performance. We also proposed a novel cost function that computes the risk-adjusted return, Sharpe and Sterling Ratio (SSR), in an effort to reduce the variance and the magnitude of drawdowns. An automatic robotic trading (RoboTrading) strategy is designed with the proposed Genetic Algorithm Maximizing Sharpe and Sterling Ratio model (GA-MSSR) model. The experiment was conducted on intraday data of 6 major currency pairs from 2018 to 2019. The results consistently showed significant positive returns and the performance of the trading system is superior using the optimized rule-based features. The highest return obtained was 320% annually using 5-minute AUDUSD currency pair. Besides, the proposed model achieves the best performance on risk factors, including maximum drawdowns and variance in return, comparing to benchmark models. The code can be accessed at https://github.com/zzzac/rule-based-forextrading-system",
        "published": "2020-08-16T05:33:35Z",
        "link": "http://arxiv.org/abs/2008.09471v1",
        "categories": [
            "q-fin.ST",
            "cs.CE",
            "cs.CV"
        ]
    },
    {
        "title": "Variable-Order Fracture Mechanics and its Application to Dynamic   Fracture",
        "authors": [
            "Sansit Patnaik",
            "Fabio Semperlotti"
        ],
        "summary": "This study presents the formulation, the numerical solution, and the validation of a theoretical framework based on the concept of variable-order mechanics and capable of modeling dynamic fracture in brittle and quasi-brittle solids. More specifically, the reformulation of the elastodynamic problem via variable and fractional order operators enables a unique and extremely powerful approach to model nucleation and propagation of cracks in solids under dynamic loading. The resulting dynamic fracture formulation is fully evolutionary hence enabling the analysis of complex crack patterns without requiring any a prior assumptions on the damage location and the growth path, as well as the use of any algorithm to track the evolving crack surface. The evolutionary nature of the variable-order formalism also prevents the need for additional partial differential equations to predict the damage field, hence suggesting a conspicuous reduction in the computational cost. Remarkably, the variable order formulation is naturally capable of capturing extremely detailed features characteristic of dynamic crack propagation such as crack surface roughening, single and multiple branching. The accuracy and robustness of the proposed variable-order formulation is validated by comparing the results of direct numerical simulations with experimental data of typical benchmark problems available in the literature.",
        "published": "2020-08-16T23:48:02Z",
        "link": "http://arxiv.org/abs/2008.10996v1",
        "categories": [
            "cond-mat.mtrl-sci",
            "cs.CE",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "An accurate hyper-singular boundary integral equation method for dynamic   poroelasticity in two dimensions",
        "authors": [
            "Lu Zhang",
            "Liwei Xu",
            "Tao Yin"
        ],
        "summary": "This paper is concerned with the boundary integral equation method for solving the exterior Neumann boundary value problem of dynamic poroelasticity in two dimensions. The main contribution of this work consists of two aspescts: the proposal of a novel regularized boundary integral equation, and the presentation of new regularized formulations of the strongly-singular and hyper-singular boundary integral operators. Firstly, turning to the spectral properties of the double-layer operator and the corresponding Calder\\'{o}n relation of the poroelasticity, we propose the novel low-GMRES-iteration integral equation whose eigenvalues are bounded away from zero and infinity. Secondly, with the help of the G\\\"{u}nter derivatives, we reformulate the strongly-singular and hyper-singular integral operators into combinations of the weakly-singular operators and the tangential derivatives. The accuracy and efficiency of the proposed methodology are demonstrated through several numerical examples.",
        "published": "2020-08-17T06:43:30Z",
        "link": "http://arxiv.org/abs/2008.07115v1",
        "categories": [
            "physics.comp-ph",
            "cs.CE"
        ]
    },
    {
        "title": "Accelerated reactive transport simulations in heterogeneous porous media   using Reaktoro and Firedrake",
        "authors": [
            "Svetlana Kyas",
            "Diego Volpatto",
            "Martin O. Saar",
            "Allan M. M. Leal"
        ],
        "summary": "This work investigates the performance of the on-demand machine learning (ODML) algorithm introduced in Leal et al. (2020) when applied to different reactive transport problems in heterogeneous porous media. ODML was devised to accelerate the computationally expensive geochemical reaction calculations in reactive transport simulations. We demonstrate that the ODML algorithm speeds up these calculations by one to three orders of magnitude. Such acceleration, in turn, significantly accelerates the entire reactive transport simulation. The numerical experiments are performed by implementing the coupling of two open-source software packages: Reaktoro (Leal, 2015) and Firedrake (Rathgeber et al., 2016).",
        "published": "2020-08-17T15:06:43Z",
        "link": "http://arxiv.org/abs/2009.01194v2",
        "categories": [
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "Embedded Fracture Model for Coupled Flow and Geomechanics",
        "authors": [
            "I. Shovkun",
            "T. Garipov",
            "H. A. Tchelepi"
        ],
        "summary": "Fluid injection and production cause changes in reservoir pressure, which result in deformations in the subsurface. This phenomenon is particularly important in reservoirs with abundant fractures and faults because the induced slip and opening of the fractures may significantly alter their hydraulic properties. Modeling strongly coupled poro-mechanical processes in naturally fractured reservoirs is a challenging problem. The Discrete Fracture Model (DFM) is a state-of-art method for modeling coupled flow and mechanics in fractured reservoirs. This method requires constructing computational grids that comform to fractures, which is very challenging in complex 3D settings. The objective of this study is to develop a numerical method that does not require gridding near fractures and can efficiently model hydromechanical interactions in fractured reservoirs. We utilize formulations based on the Strong Discontinuity Approach (SDA) for mechanics and Embedded Discrete Fracture Model (EDFM) for flow. We first present a mathematical formulation and emphasize the kinematic aspects of fracture slip and opening. We then introduce a series of mechanical tests that investigate the spatial convergence of the model and compare its accuracy with the Discrete Fracture Model (DFM). We finally consider a synthetic coupled case of a reservoir with several fractures and compare the performance of the SDA and DFM methods. Our results indicate super-linear spatial convergence of the proposed SDA algorithm. Numerical simulations confirm the applicability of the proposed method to modeling the coupling effects in subsurface applications.",
        "published": "2020-08-18T17:45:58Z",
        "link": "http://arxiv.org/abs/2008.08064v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "An adjoint optimization approach for the topological design of   large-scale district heating networks based on nonlinear models",
        "authors": [
            "Maarten Blommaert",
            "Yannick Wack",
            "Martine Baelmans"
        ],
        "summary": "This article deals with the problem of finding the best topology, pipe diameter choices, and operation parameters for realistic district heating networks. Present design tools that employ non-linear flow and heat transport models for topological design are limited to small heating networks with up to 20 potential consumers. We introduce an alternative adjoint-based numerical optimization strategy to enable large-scale nonlinear thermal network optimization. In order to avoid a strong computational cost scaling with the network size, we aggregate consumer constraints with a constraint aggregation strategy. Moreover, to align this continuous optimization strategy with the discrete nature of topology optimization and pipe size choices, we present a numerical continuation strategy that gradually forces the design variables towards discrete design choices. As such, optimal network topology and pipe sizes are determined simultaneously. Finally, we demonstrate the scalability of the algorithm by designing a fictitious district heating network with 160 consumers. As a proof-of-concept, the network is optimized for minimal investment cost and pumping power, while keeping the heat supplied to the consumers within a thermal comfort range of 5 %. Starting from a uniform distribution of 15 cm wide piping throughout the network, the novel algorithm finds a network lay-out that reduces piping investment by 23 % and pump-related costs by a factor of 14 in less than an hour on a standard laptop. Moreover, the importance of embedding the non-linear transport model is clear from a temperature-induced variation in the consumer flow rates of 72 %.",
        "published": "2020-08-19T08:37:00Z",
        "link": "http://arxiv.org/abs/2008.08328v2",
        "categories": [
            "cs.CE",
            "math.OC"
        ]
    },
    {
        "title": "Data-Driven Solvers for Strongly Nonlinear Material Response",
        "authors": [
            "Armin Galetzka",
            "Dimitrios Loukrezis",
            "Herbert De Gersem"
        ],
        "summary": "This work presents a data-driven magnetostatic finite-element solver that is specifically well-suited to cope with strongly nonlinear material responses. The data-driven computing framework is essentially a multiobjective optimization procedure matching the material operation points as closely as possible to given material data while obeying Maxwell's equations. Here, the framework is extended with heterogeneous (local) weighting factors - one per finite element - equilibrating the goal function locally according to the material behavior. This modification allows the data-driven solver to cope with unbalanced measurement data sets, i.e. data sets suffering from unbalanced space filling. This occurs particularly in the case of strongly nonlinear materials, which constitute problematic cases that hinder the efficiency and accuracy of standard data-driven solvers with a homogeneous (global) weighting factor. The local weighting factors are embedded in the distance-minimizing data-driven algorithm used for noiseless data, likewise for the maximum entropy data-driven algorithm used for noisy data. Numerical experiments based on a quadrupole magnet model with a soft magnetic material show that the proposed modification results in major improvements in terms of solution accuracy and solver efficiency. For the case of noiseless data, local weighting factors improve the convergence of the data-driven solver by orders of magnitude. When noisy data are considered, the convergence rate of the data-driven solver is doubled.",
        "published": "2020-08-19T14:42:27Z",
        "link": "http://arxiv.org/abs/2008.08482v3",
        "categories": [
            "physics.comp-ph",
            "cs.CE"
        ]
    },
    {
        "title": "Topology Optimization and 3D printing of Large Deformation Compliant   Mechanisms for Straining Biological Tissues",
        "authors": [
            "P. Kumar",
            "C. Schmidleithner",
            "N. B. Larsen",
            "O. Sigmund"
        ],
        "summary": "This paper presents a synthesis approach in a density-based topology optimization setting to design large deformation compliant mechanisms for inducing desired strains in biological tissues. The modelling is based on geometrical nonlinearity together with a suitably chosen hypereleastic material model, wherein the mechanical equilibrium equations are solved using the total Lagrangian finite element formulation. An objective based on least-square error with respect to target strains is formulated and minimized with the given set of constraints and the appropriate surroundings of the tissues. To circumvent numerical instabilities arising due to large deformation in low stiffness design regions during topology optimization, a strain-energy based interpolation scheme is employed. The approach uses an extended robust formulation i.e. the eroded, intermediate and dilated projections for the design description as well as variation in tissue stiffness. Efficacy of the synthesis approach is demonstrated by designing various compliant mechanisms for providing different target strains in biological tissue constructs. Optimized compliant mechanisms are 3D-printed and their performances are recorded in a simplified experiment and compared with simulation results obtained by a commercial software.",
        "published": "2020-08-20T11:42:48Z",
        "link": "http://arxiv.org/abs/2008.08902v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A stabilized finite element method for delamination analysis of   composites using cohesive elements",
        "authors": [
            "Gourab Ghosh",
            "Ravindra Duddu",
            "Chandrasekhar Annavarapu"
        ],
        "summary": "We demonstrate the ability of a stabilized finite element method, inspired by the weighted Nitsche approach, to alleviate spurious traction oscillations at interlaminar interfaces in multi-ply multi-directional composite laminates. In contrast with the standard (penalty-like) method, the stabilized method allows the use of arbitrarily large values of cohesive stiffness and obviates the need for engineering approaches to estimate minimum cohesive stiffness necessary for accurate delamination analysis. This is achieved by defining a weighted interface traction in the stabilized method, which allows a gradual transition from penalty-like method for soft elastic contact to Nitsche-like method for rigid contact. We conducted several simulation studies involving constant strain patch tests and benchmark delamination tests under mode-I, mode-II and mixed-mode loadings. Our results show clear evidence of traction oscillations with the standard method with structured and perturbed finite element meshes, and that the stabilized method alleviates these oscillations, thus illustrating its robustness.",
        "published": "2020-08-20T15:11:11Z",
        "link": "http://arxiv.org/abs/2008.09015v1",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "TRU-NET: A Deep Learning Approach to High Resolution Prediction of   Rainfall",
        "authors": [
            "Rilwan Adewoyin",
            "Peter Dueben",
            "Peter Watson",
            "Yulan He",
            "Ritabrata Dutta"
        ],
        "summary": "Climate models (CM) are used to evaluate the impact of climate change on the risk of floods and strong precipitation events. However, these numerical simulators have difficulties representing precipitation events accurately, mainly due to limited spatial resolution when simulating multi-scale dynamics in the atmosphere. To improve the prediction of high resolution precipitation we apply a Deep Learning (DL) approach using an input of CM simulations of the model fields (weather variables) that are more predictable than local precipitation. To this end, we present TRU-NET (Temporal Recurrent U-Net), an encoder-decoder model featuring a novel 2D cross attention mechanism between contiguous convolutional-recurrent layers to effectively model multi-scale spatio-temporal weather processes. We use a conditional-continuous loss function to capture the zero-skewed %extreme event patterns of rainfall. Experiments show that our model consistently attains lower RMSE and MAE scores than a DL model prevalent in short term precipitation prediction and improves upon the rainfall predictions of a state-of-the-art dynamical weather model. Moreover, by evaluating the performance of our model under various, training and testing, data formulation strategies, we show that there is enough data for our deep learning approach to output robust, high-quality results across seasons and varying regions.",
        "published": "2020-08-20T17:27:59Z",
        "link": "http://arxiv.org/abs/2008.09090v2",
        "categories": [
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "Development of a Novel Computational Model for Evaluating Fall Risk in   Patient Room Design",
        "authors": [
            "Roya Sabbagh Novin",
            "Ellen Taylor",
            "Tucker Hermans",
            "Andrew Merryweather"
        ],
        "summary": "Objectives: The aims of this study are to identify factors in physical environments that contribute to patient falls in hospitals and to propose a computational model to evaluate patient room designs.   Background: The existing fall risk assessment tools have an acceptable level of sensitivity and specificity, however, they only consider intrinsic factors and medications, making the prediction very limited in terms of how the physical environment contributes to fall risk.   Methods: We provide a computational model for risk of fall based on physical-environment and patient-motion factors. We use a trajectory optimization approach for patient motion prediction.   Results: We run the proposed model on four room designs as examples of various room design categories. Results show the capabilities of the proposed model in identifying risky locations within the room.   Conclusions: Our study shows the potential capabilities of the proposed model. Due to lack of enough evidence for the examined factors, it is not possible at this point to gain robust confidence in the final evaluations. More studies using quantitative, relational, or causal designs are recommended to inform the proposed model for patient falls.   Application: Developing a comprehensive fall risk model is a significant step in understanding and solving the problem of patient falls in hospitals. It can provide guidance for healthcare decision makers to optimize effective interventions to reduce risk of falls while promoting safe patient mobility in the hospital room environment. We can also use it in healthcare technologies such as assistive robots to provide informed assistance.",
        "published": "2020-08-20T19:13:37Z",
        "link": "http://arxiv.org/abs/2008.09169v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Evaluation of the cumulated impacts on the marine resource of a   socio-ecological coral system: approach by agent-based modeling",
        "authors": [
            "Olivier Rousselle"
        ],
        "summary": "In the context of climate change and significant changes in human activities around the world, coral reefs are subject to many disruptions. We develop here a tool to help decision-making in Moorea (French Polynesia), based on multi-agent modeling. We model the trophic interactions with a Lotka-Volterra model, and also the interactions between fishermen, trophic groups and tourist operators. The results are generated through global, temporal (time series), and spatial (GIS maps) outputs. The model produced here can be transposed to other ecological and economic situations, and other geographical areas, by modifying the parameters and changing the input map data.",
        "published": "2020-08-21T14:51:14Z",
        "link": "http://arxiv.org/abs/2008.09521v1",
        "categories": [
            "cs.MA",
            "cs.CE",
            "physics.ao-ph"
        ]
    },
    {
        "title": "ParaDRAM: A Cross-Language Toolbox for Parallel High-Performance   Delayed-Rejection Adaptive Metropolis Markov Chain Monte Carlo Simulations",
        "authors": [
            "Amir Shahmoradi",
            "Fatemeh Bagheri"
        ],
        "summary": "We present ParaDRAM, a high-performance Parallel Delayed-Rejection Adaptive Metropolis Markov Chain Monte Carlo software for optimization, sampling, and integration of mathematical objective functions encountered in scientific inference. ParaDRAM is currently accessible from several popular programming languages including C/C++, Fortran, MATLAB, Python and is part of the ParaMonte open-source project with the following principal design goals: 1. full automation of Monte Carlo simulations, 2. interoperability of the core library with as many programming languages as possible, thus, providing a unified Application Programming Interface and Monte Carlo simulation environment across all programming languages, 3. high-performance 4. parallelizability and scalability of simulations from personal laptops to supercomputers, 5. virtually zero-dependence on external libraries, 6. fully-deterministic reproducibility of simulations, 7. automatic comprehensive reporting and post-processing of the simulation results. We present and discuss several novel techniques implemented in ParaDRAM to automatically and dynamically ensure the good-mixing and the diminishing-adaptation of the resulting pseudo-Markov chains from ParaDRAM. We also discuss the implementation of an efficient data storage method used in ParaDRAM that reduces the average memory and storage requirements of the algorithm by, a factor of 4 for simple simulation problems, to an order of magnitude and more for sampling complex high-dimensional mathematical objective functions. Finally, we discuss how the design goals of ParaDRAM can help users readily and efficiently solve a variety of machine learning and scientific inference problems on a wide range of computing platforms.",
        "published": "2020-08-21T17:29:24Z",
        "link": "http://arxiv.org/abs/2008.09589v1",
        "categories": [
            "cs.CE",
            "astro-ph.IM",
            "physics.data-an",
            "stat.CO",
            "stat.ML"
        ]
    },
    {
        "title": "Urban Bike Lane Planning with Bike Trajectories: Models, Algorithms, and   a Real-World Case Study",
        "authors": [
            "Sheng Liu",
            "Zuo-Jun Max Shen",
            "Xiang Ji"
        ],
        "summary": "We study an urban bike lane planning problem based on the fine-grained bike trajectory data, which is made available by smart city infrastructure such as bike-sharing systems. The key decision is where to build bike lanes in the existing road network. As bike-sharing systems become widespread in the metropolitan areas over the world, bike lanes are being planned and constructed by many municipal governments to promote cycling and protect cyclists. Traditional bike lane planning approaches often rely on surveys and heuristics. We develop a general and novel optimization framework to guide the bike lane planning from bike trajectories. We formalize the bike lane planning problem in view of the cyclists' utility functions and derive an integer optimization model to maximize the utility. To capture cyclists' route choices, we develop a bilevel program based on the Multinomial Logit model. We derive structural properties about the base model and prove that the Lagrangian dual of the bike lane planning model is polynomial-time solvable. Furthermore, we reformulate the route choice based planning model as a mixed integer linear program using a linear approximation scheme. We develop tractable formulations and efficient algorithms to solve the large-scale optimization problem. Via a real-world case study with a city government, we demonstrate the efficiency of the proposed algorithms and quantify the trade-off between the coverage of bike trips and continuity of bike lanes. We show how the network topology evolves according to the utility functions and highlight the importance of understanding cyclists' route choices. The proposed framework drives the data-driven urban planning scheme in smart city operations management.",
        "published": "2020-08-21T18:46:51Z",
        "link": "http://arxiv.org/abs/2008.09645v1",
        "categories": [
            "cs.AI",
            "cs.CE",
            "math.OC",
            "90-10",
            "G.2.1; G.2.3; I.2.8"
        ]
    },
    {
        "title": "A Blockchain Transaction Graph based Machine Learning Method for Bitcoin   Price Prediction",
        "authors": [
            "Xiao Li",
            "Weili Wu"
        ],
        "summary": "Bitcoin, as one of the most popular cryptocurrency, is recently attracting much attention of investors. Bitcoin price prediction task is consequently a rising academic topic for providing valuable insights and suggestions. Existing bitcoin prediction works mostly base on trivial feature engineering, that manually designs features or factors from multiple areas, including Bticoin Blockchain information, finance and social media sentiments. The feature engineering not only requires much human effort, but the effectiveness of the intuitively designed features can not be guaranteed. In this paper, we aim to mining the abundant patterns encoded in bitcoin transactions, and propose k-order transaction graph to reveal patterns under different scope. We propose the transaction graph based feature to automatically encode the patterns. A novel prediction method is proposed to accept the features and make price prediction, which can take advantage from particular patterns from different history period. The results of comparison experiments demonstrate that the proposed method outperforms the most recent state-of-art methods.",
        "published": "2020-08-21T20:08:17Z",
        "link": "http://arxiv.org/abs/2008.09667v1",
        "categories": [
            "q-fin.ST",
            "cs.CE",
            "cs.LG",
            "cs.SI",
            "stat.ML"
        ]
    },
    {
        "title": "A Principled Approach to Design Using High Fidelity Fluid-Structure   Interaction Simulations",
        "authors": [
            "Wensi Wu",
            "Christophe Bonneville",
            "Christopher J. Earls"
        ],
        "summary": "A high fidelity fluid-structure interaction simulation may require many days to run, on hundreds of cores. This poses a serious burden, both in terms of time and economic considerations, when repetitions of such simulations may be required (e.g. for the purpose of design optimization). In this paper we present strategies based on (constrained) Bayesian optimization (BO) to alleviate this burden. BO is a numerical optimization technique based on Gaussian processes (GP) that is able to efficiently (with minimal calls to the expensive FSI models) converge towards some globally optimal design, as gauged using a black box objective function. In this study we present a principled design evolution that moves from FSI model verification, through a series of Bridge Simulations (bringing the verification case incrementally closer to the application), in order that we may identify material properties for an underwater, unmanned, autonomous vehicle (UUAV) sail plane. We are able to achieve fast convergence towards an optimal design, using a small number of FSI simulations (a dozen at most), even when selecting over several design parameters, and while respecting optimization constraints.",
        "published": "2020-08-21T21:37:12Z",
        "link": "http://arxiv.org/abs/2008.09687v1",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA",
            "physics.flu-dyn"
        ]
    },
    {
        "title": "On the treatment of boundary conditions for bond-based peridynamic   models",
        "authors": [
            "Serge Prudhomme",
            "Patrick Diehl"
        ],
        "summary": "In this paper, we propose two approaches to apply boundary conditions for bond-based peridynamic models. There has been in recent years a renewed interest in the class of so-called non-local models, which include peridynamic models, for the simulation of structural mechanics problems as an alternative approach to classical local continuum models. However, a major issue, which is often disregarded when dealing with this class of models, is concerned with the manner by which boundary conditions should be prescribed. Our point of view here is that classical boundary conditions, since applied on surfaces of solid bodies, are naturally associated with local models. The paper describes two methods to incorporate classical Dirichlet and Neumann boundary conditions into bond-based peridynamics. The first method consists in artificially extending the domain with a thin boundary layer over which the displacement field is required to behave as an odd function with respect to the boundary points. The second method resorts to the idea that peridynamic models and local models should be compatible in the limit that the so-called horizon vanishes. The approach consists then in decreasing the horizon from a constant value in the interior of the domain to zero at the boundary so that one can directly apply the classical boundary conditions. We present the continuous and discrete formulations of the two methods and assess their performance on several numerical experiments dealing with the simulation of a one-dimensional bar.",
        "published": "2020-08-22T00:48:06Z",
        "link": "http://arxiv.org/abs/2008.09725v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Variational Autoencoder for Anti-Cancer Drug Response Prediction",
        "authors": [
            "Hongyuan Dong",
            "Jiaqing Xie",
            "Zhi Jing",
            "Dexin Ren"
        ],
        "summary": "Cancer is a primary cause of human death, but discovering drugs and tailoring cancer therapies are expensive and time-consuming. We seek to facilitate the discovery of new drugs and treatment strategies for cancer using variational autoencoders (VAEs) and multi-layer perceptrons (MLPs) to predict anti-cancer drug responses. Our model takes as input gene expression data of cancer cell lines and anti-cancer drug molecular data and encodes these data with our {\\sc {GeneVae}} model, which is an ordinary VAE model, and a rectified junction tree variational autoencoder ({\\sc JTVae}) model, respectively. A multi-layer perceptron processes these encoded features to produce a final prediction. Our tests show our system attains a high average coefficient of determination ($R^{2} = 0.83$) in predicting drug responses for breast cancer cell lines and an average $R^{2} = 0.845$ for pan-cancer cell lines. Additionally, we show that our model can generates effective drug compounds not previously used for specific cancer cell lines.",
        "published": "2020-08-22T06:03:22Z",
        "link": "http://arxiv.org/abs/2008.09763v7",
        "categories": [
            "cs.LG",
            "cs.CE",
            "stat.ML"
        ]
    },
    {
        "title": "Compact 200 line MATLAB code for inverse design in photonics by topology   optimization: tutorial",
        "authors": [
            "Rasmus E. Christiansen",
            "Ole Sigmund"
        ],
        "summary": "We provide a compact 200 line MATLAB code demonstrating how topology optimization (TopOpt) as an inverse design tool may be used in photonics, targeting the design of two-dimensional dielectric metalenses and a metallic reflector as examples. The physics model is solved using the finite element method, and the code utilizes MATLAB's fmincon algorithm to solve the optimization problem. In addition to presenting the code itself, we briefly discuss a number of extensions and provide the code required to implement some of these. Finally, we demonstrate the superiority of using a gradient-based method compared to a genetic-algorithm-based method (using MATLAB's ga algorithm) for solving inverse design problems in photonics. The MATLAB software is freely available in the paper and may be downloaded from https://www.topopt.mek.dtu.dk.",
        "published": "2020-08-23T14:07:07Z",
        "link": "http://arxiv.org/abs/2009.14276v5",
        "categories": [
            "cs.MS",
            "cs.CE",
            "physics.optics"
        ]
    },
    {
        "title": "Towards Earnings Call and Stock Price Movement",
        "authors": [
            "Zhiqiang Ma",
            "Grace Bang",
            "Chong Wang",
            "Xiaomo Liu"
        ],
        "summary": "Earnings calls are hosted by management of public companies to discuss the company's financial performance with analysts and investors. Information disclosed during an earnings call is an essential source of data for analysts and investors to make investment decisions. Thus, we leverage earnings call transcripts to predict future stock price dynamics. We propose to model the language in transcripts using a deep learning framework, where an attention mechanism is applied to encode the text data into vectors for the discriminative network classifier to predict stock price movements. Our empirical experiments show that the proposed model is superior to the traditional machine learning baselines and earnings call information can boost the stock price prediction performance.",
        "published": "2020-08-23T20:38:14Z",
        "link": "http://arxiv.org/abs/2009.01317v1",
        "categories": [
            "q-fin.ST",
            "cs.CE",
            "cs.CL",
            "cs.LG"
        ]
    },
    {
        "title": "Highly scalable numerical simulation of coupled reaction-diffusion   systems with moving interfaces",
        "authors": [
            "Mojtaba Barzegari",
            "Liesbet Geris"
        ],
        "summary": "A combination of reaction-diffusion models with moving-boundary problems yields a system in which the diffusion (spreading and penetration) and reaction (transformation) evolve the system's state and geometry over time. These systems can be used in a wide range of engineering applications. In this study, as an example of such a system, the degradation of metallic materials is investigated. A mathematical model is constructed of the diffusion-reaction processes and the movement of corrosion front of a magnesium block floating in a chemical solution. The corresponding parallelized computational model is implemented using the finite element method, and the weak and strong scaling behaviors of the model are evaluated to analyze the performance and efficiency of the employed high-performance computing techniques.",
        "published": "2020-08-25T14:30:19Z",
        "link": "http://arxiv.org/abs/2008.11057v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A fractional stochastic theory for interfacial polarization of cell   aggregates",
        "authors": [
            "Pouria A. Mistani",
            "Samira Pakravan",
            "Frederic G. Gibou"
        ],
        "summary": "We present a theoretical framework to model the electric response of cell aggregates. We establish a coarse representation for each cell as a combination of membrane and cytoplasm dipole moments. Then we compute the effective conductivity of the resulting system, and thereafter derive a Fokker-Planck partial differential equation that captures the time-dependent evolution of the distribution of induced cellular polarizations in an ensemble of cells. Our model predicts that the polarization density parallel to an applied pulse follows a skewed t-distribution, while the transverse polarization density follows a symmetric t-distribution, which are in accordance with our direct numerical simulations. Furthermore, we report a reduced order model described by a coupled pair of ordinary differential equations that reproduces the average and the variance of induced dipole moments in the aggregate. We extend our proposed formulation by considering fractional order time derivatives that we find necessary to explain anomalous relaxation phenomena observed in experiments as well as our direct numerical simulations. Owing to its time-domain formulation, our framework can be easily used to consider nonlinear membrane effects or intercellular couplings that arise in several scientific, medical and technological applications.",
        "published": "2020-08-25T16:58:31Z",
        "link": "http://arxiv.org/abs/2008.11819v1",
        "categories": [
            "cs.CE",
            "physics.bio-ph",
            "physics.chem-ph",
            "physics.comp-ph"
        ]
    },
    {
        "title": "TAPsolver: A Python package for the simulation and analysis of TAP   reactor experiments",
        "authors": [
            "Adam Yonge",
            "M. Ross Kunz",
            "Rakesh Batchu",
            "Zongtang Fang",
            "Tobin Issac",
            "Rebecca Fushimi",
            "Andrew J. Medford"
        ],
        "summary": "An open-source, Python-based Temporal Analysis of Products (TAP) reactor simulation and processing program is introduced. TAPsolver utilizes algorithmic differentiation for the calculation of highly accurate derivatives, which are used to perform sensitivity analyses and PDE-constrained optimization. The tool supports constraints to ensure thermodynamic consistency, which can lead to more accurate parameters and assist in mechanism discrimination. The mathematical and structural details of TAPsolver are outlined, as well as validation of the forward and inverse problems against well-studied prototype problems. Benchmarks of the code are presented, and a case study for extracting thermodynamically-consistent kinetic parameters from experimental TAP measurements of CO oxidation on supported platinum particles is presented. TAPsolver will act as a foundation for future development and dissemination of TAP data processing techniques.",
        "published": "2020-08-26T17:07:10Z",
        "link": "http://arxiv.org/abs/2008.13584v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Industrial scale large eddy simulations (LES) with adaptive octree   meshes using immersogeometric analysis",
        "authors": [
            "Kumar Saurabh",
            "Boshun Gao",
            "Milinda Fernando",
            "Songzhe Xu",
            "Makrand A. Khanwale",
            "Biswajit Khara",
            "Ming-Chen Hsu",
            "Adarsh Krishnamurthy",
            "Hari Sundar",
            "Baskar Ganapathysubramanian"
        ],
        "summary": "We present a variant of the immersed boundary method integrated with octree meshes for highly efficient and accurate Large-Eddy Simulations (LES) of flows around complex geometries. We demonstrate the scalability of the proposed method up to $\\mathcal{O}(32K)$ processors. This is achieved by (a) rapid in-out tests; (b) adaptive quadrature for an accurate evaluation of forces; (c) tensorized evaluation during matrix assembly. We showcase this method on two non-trivial applications: accurately computing the drag coefficient of a sphere across Reynolds numbers $1-10^6$ encompassing the drag crisis regime; simulating flow features across a semi-truck for investigating the effect of platooning on efficiency.",
        "published": "2020-08-28T15:30:14Z",
        "link": "http://arxiv.org/abs/2009.00706v2",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "physics.flu-dyn"
        ]
    },
    {
        "title": "Momentum-based Accelerated Mirror Descent Stochastic Approximation for   Robust Topology Optimization under Stochastic Loads",
        "authors": [
            "Weichen Li",
            "Xiaojia Shelly Zhang"
        ],
        "summary": "Robust topology optimization (RTO) improves the robustness of designs with respect to random sources in real-world structures, yet an accurate sensitivity analysis requires the solution of many systems of equations at each optimization step, leading to a high computational cost. To open up the full potential of RTO under a variety of random sources, this paper presents a momentum-based accelerated mirror descent stochastic approximation (AC-MDSA) approach to efficiently solve RTO problems involving various types of load uncertainties. The proposed framework can perform high-quality design updates with highly noisy stochastic gradients. We reduce the sample size to two (minimum for unbiased variance estimation) and show only two samples are sufficient for evaluating stochastic gradients to obtain robust designs, thus drastically reducing the computational cost. We derive the AC-MDSA update formula based on $\\ell_1$-norm with entropy function, which is tailored to the geometry of the feasible domain. To accelerate and stabilize the algorithm, we integrate a momentum-based acceleration scheme, which also alleviates the step size sensitivity. Several 2D and 3D examples with various sizes are presented to demonstrate the effectiveness and efficiency of the proposed AC-MDSA framework to handle RTO involving various types of loading uncertainties.",
        "published": "2020-08-30T21:51:51Z",
        "link": "http://arxiv.org/abs/2008.13284v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A Newton Solver for Micromorphic Computational Homogenization Enabling   Multiscale Buckling Analysis of Pattern-Transforming Metamaterials",
        "authors": [
            "S. E. H. M. van Bree",
            "O. Rokoš",
            "R. H. J. Peerlings",
            "M. Doškář",
            "M. G. D. Geers"
        ],
        "summary": "Mechanical metamaterials feature engineered microstructures designed to exhibit exotic, and often counter-intuitive, effective behaviour. Such a behaviour is often achieved through instability-induced transformations of the underlying periodic microstructure into one or multiple patterning modes. Due to a strong kinematic coupling of individual repeating microstructural cells, non-local behaviour and size effects emerge, which cannot easily be captured by classical homogenization schemes. In addition, the individual patterning modes can mutually interact in space as well as in time, while at the engineering scale the entire structure can buckle globally. For efficient numerical macroscale predictions, a micromorphic computational homogenization scheme has recently been developed. Although this framework is in principle capable of accounting for spatial and temporal interactions between individual patterning modes, its implementation relied on a gradient-based quasi-Newton solution technique. This solver is suboptimal because (i) it has sub-quadratic convergence, and (ii) the absence of Hessians does not allow for proper bifurcation analyses. Given that mechanical metamaterials often rely on controlled instabilities, these limitations are serious. To address them, a full Newton method is provided in detail in this paper. The construction of the macroscopic tangent operator is not straightforward due to specific model assumptions on the decomposition of the underlying displacement field pertinent to the micromorphic framework, involving orthogonality constraints. Analytical expressions for the first and second variation of the total potential energy are given, and the complete algorithm is listed. The developed methodology is demonstrated with two examples in which a competition between local and global buckling exists and where multiple patterning modes emerge.",
        "published": "2020-08-31T11:06:02Z",
        "link": "http://arxiv.org/abs/2008.12850v2",
        "categories": [
            "cs.CE",
            "cond-mat.soft"
        ]
    },
    {
        "title": "An Expedient Approach to FDTD-based Modeling of Finite Periodic   Structures",
        "authors": [
            "Aaron J. Kogon",
            "Costas D. Sarris"
        ],
        "summary": "This paper proposes an efficient FDTD technique for determining electromagnetic fields interacting with a finite-sized 2D and 3D periodic structures. The technique combines periodic boundary conditions---modelling fields away from the edges of the structure---with independent simulations of fields near the edges of the structure. It is shown that this algorithm efficiently determines the size of a periodic structure necessary for fields to converge to the infinitely-periodic case. Numerical validations of the technique illustrate the savings concomitant with the algorithm.",
        "published": "2020-08-31T21:09:28Z",
        "link": "http://arxiv.org/abs/2009.01347v1",
        "categories": [
            "cs.CE",
            "physics.optics"
        ]
    },
    {
        "title": "AIMx: An Extended Adaptive Integral Method for the Fast Electromagnetic   Modeling of Complex Structures",
        "authors": [
            "Shashwat Sharma",
            "Piero Triverio"
        ],
        "summary": "Surface integral equation (SIE) methods are of great interest for the efficient electromagnetic modeling of various devices, from integrated circuits to antenna arrays. Existing acceleration algorithms for SIEs, such as the adaptive integral method (AIM), enable the fast approximation of interactions between well-separated mesh elements. Nearby interactions involve the singularity of the kernel, and must instead be computed accurately with direct integration at each frequency of interest, which can be computationally expensive. We propose a novel algorithm for reducing the cost-per-frequency of near-region computations for both homogeneous and layered background media. In the proposed extended AIM (AIMx), the SIE operators are decomposed into a frequency-independent term containing the singularity of the kernel, and a nonsingular frequency-dependent term. Direct integration is only required for the frequency-independent term, and can be reused at each frequency, leading to significantly faster frequency sweeps. The frequency-dependent term is captured with good accuracy via fast Fourier transform (FFT)-based acceleration even in the near region, as confirmed with an error analysis. The accuracy and efficiency of the proposed method are demonstrated through numerical examples drawn from several applications, and CPU times are significantly reduced by factors ranging from three to 16.",
        "published": "2020-09-01T17:26:36Z",
        "link": "http://arxiv.org/abs/2009.02281v2",
        "categories": [
            "cs.CE",
            "eess.SP"
        ]
    },
    {
        "title": "Accelerating engineering design by automatic selection of simulation   cases through Pool-Based Active Learning",
        "authors": [
            "J. H. Gaspar Elsas",
            "N. A. G. Casaprima",
            "I. F. M. Menezes"
        ],
        "summary": "A common workflow for many engineering design problems requires the evaluation of the design system to be investigated under a range of conditions. These conditions usually involve a combination of several parameters. To perform a complete evaluation of a single candidate configuration, it may be necessary to perform hundreds to thousands of simulations. This can be computationally very expensive, particularly if several configurations need to be evaluated, as in the case of the mathematical optimization of a design problem. Although the simulations are extremely complex, generally, there is a high degree of redundancy in them, as many of the cases vary only slightly from one another. This redundancy can be exploited by omitting some simulations that are uninformative, thereby reducing the number of simulations required to obtain a reasonable approximation of the complete system. The decision of which simulations are useful is made through the use of machine learning techniques, which allow us to estimate the results of \"yet-to-be-performed\" simulations from the ones that are already performed. In this study, we present the results of one such technique, namely active learning, to provide an approximate result of an entire offshore riser design simulation portfolio from a subset that is 80% smaller than the original one. These results are expected to facilitate a significant speed-up in the offshore riser design.",
        "published": "2020-09-03T02:31:59Z",
        "link": "http://arxiv.org/abs/2009.01420v2",
        "categories": [
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "Development and comparison of spectral algorithms for numerical modeling   of the quasi-static mechanical behavior of inhomogeneous materials",
        "authors": [
            "M. Khorrami",
            "J. R. Mianroodi",
            "P. Shanthraj",
            "B. Svendsen"
        ],
        "summary": "In the current work, a number of algorithms are developed and compared for the numerical solution of periodic (quasi-static) linear elastic mechanical boundary-value problems (BVPs) based on two different discretizations of Fourier series. The first is standard and based on the trapezoidal approximation of the Fourier mode integral, resulting in trapezoidal discretization (TD) of the truncated Fourier series. Less standard is the second discretization based on piecewise-constant approximation of the Fourier mode integrand, yielding a piecewise-constant discretization (PCD) of this series. Employing these, fixed-point algorithms are formulated via Green-function preconditioning (GFP) and finite-difference discretization (of differential operators; FDD). In particular, in the context of PCD, this includes an algorithm based on the so-called \"discrete Green operator\" (DGO) recently introduced by Eloh et al. (2019), which employs GFP, but not FDD. For computational comparisons, the (classic) benchmark case of a cubic inclusion embedded in a matrix (e.g., Suquet, 1997; Willot, 2015) is employed. Both discontinuous and smooth transitions in elastic stiffness at the matrix-inclusion (MI) interface are considered. In the context of both TD and PCD, a number of GFP- and FDD-based algorithms are developed. Among these, one based on so-called averaged-forward-backward-differencing (AFB) is shown to result in the greatest improvement in convergence rate. As it turns out, AFB is equivalent to the \"rotated scheme\" (R) of Willot (2015) in the context of TD. In the context of PCD, comparison of the performance and convergence behavior of AFB/R- and DGO-based algorithms shows that the former is more efficient than the latter for larger phase contrasts.",
        "published": "2020-09-04T10:22:35Z",
        "link": "http://arxiv.org/abs/2009.03762v1",
        "categories": [
            "cs.CE",
            "65N35, 74B05, 74Q99, 74S25",
            "J.2.7; J.2.9"
        ]
    },
    {
        "title": "An integrative smoothed particle hydrodynamics framework for modeling   cardiac function",
        "authors": [
            "Chi Zhang",
            "Jianhang Wang",
            "Massoud Rezavand",
            "Dong Wu",
            "Xiangyu Hu"
        ],
        "summary": "Mathematical modeling of cardiac function can provide augmented simulation-based diagnosis tool for complementing and extending human understanding of cardiac diseases which represent the most common cause of worldwide death. As the realistic starting-point for developing an unified meshless approach for total heart modeling, herein we propose an integrative smoothed particle hydrodynamics (SPH) framework for addressing the simulation of the principle aspects of cardiac function, including cardiac electrophysiology, passive mechanical response and electromechanical coupling. To that end, several algorithms, e.g., splitting reaction-by-reaction method combined with quasi-steady-state (QSS) solver , anisotropic SPH-diffusion discretization and total Lagrangian SPH formulation, are introduced and exploited for dealing with the fundamental challenges of developing integrative SPH framework for simulating cardiac function, namely, (i) the correct capturing of the stiff dynamics of the transmembrane potential and the gating variables , (ii) the stable predicting of the large deformations and the strongly anisotropic behavior of the myocardium, and (iii) the proper coupling of electrophysiology and tissue mechanics for electromechanical feedback. A set of numerical examples demonstrate the effectiveness and robustness of the present SPH framework, and render it a potential and powerful alternative that can augment current lines of total cardiac modeling and clinical applications.",
        "published": "2020-09-04T10:57:01Z",
        "link": "http://arxiv.org/abs/2009.03759v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A nested genetic algorithm strategy for the optimal plastic design of   frames",
        "authors": [
            "A. Greco",
            "F. Cannizzaro",
            "R. Bruno",
            "A. Pluchino"
        ],
        "summary": "An innovative strategy for the optimal design of planar frames able to resist to seismic excitations is here proposed. The procedure is based on genetic algorithms (GA) which are performed according to a nested structure suitable to be implemented in parallel computing on several devices. In particular, this solution foresees two nested genetic algorithms. The first one, named \"External GA\", seeks, among a predefined list of profiles, the size of the structural elements of the frame which correspond to the most performing solution associated to the highest value of an appropriate fitness function. The latter function takes into account, among other considerations, of the seismic safety factor and the failure mode which are calculated by means of the second algorithm, named \"Internal GA\". The details of the proposed procedure are provided and applications to the seismic design of two frames of different size are described.",
        "published": "2020-09-04T11:15:45Z",
        "link": "http://arxiv.org/abs/2009.02111v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Separated response surfaces for flows in parametrised domains:   comparison of a priori and a posteriori PGD algorithms",
        "authors": [
            "Matteo Giacomini",
            "Luca Borchini",
            "Ruben Sevilla",
            "Antonio Huerta"
        ],
        "summary": "Reduced order models (ROM) are commonly employed to solve parametric problems and to devise inexpensive response surfaces to evaluate quantities of interest in real-time. There are many families of ROMs in the literature and choosing among them is not always a trivial task. This work presents a comparison of the performance of a priori and a posteriori proper generalised decomposition (PGD) algorithms for an incompressible Stokes flow problem in a geometrically parametrised domain. This problem is particularly challenging as the geometric parameters affect both the solution manifold and the computational spatial domain. The difficulty is further increased because multiple geometric parameters are considered and extended ranges of values are analysed for the parameters and this leads to significant variations in the flow features. Using a set of numerical experiments involving geometrically parametrised microswimmers, the two PGD algorithms are extensively compared in terms of their accuracy and their computational cost, expressed as a function of the number of full-order solves required.",
        "published": "2020-09-04T13:22:58Z",
        "link": "http://arxiv.org/abs/2009.02176v2",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "65M60, 76D07, 76M10"
        ]
    },
    {
        "title": "Automatic feature-preserving size field for 3D mesh generation",
        "authors": [
            "Arthur Bawin",
            "François Henrotte",
            "Jean-François Remacle"
        ],
        "summary": "This paper presents a methodology aiming at easing considerably the generation of high-quality meshes for complex 3D domains. We show that the whole mesh generation process can be controlled with only five parameters to generate in one stroke quality meshes for arbitrary geometries. The main idea is to build a meshsize field $h(x)$ taking local features of the geometry, such as curvatures, into account. Meshsize information is then propagated from the surfaces into the volume, ensuring that the magnitude of $\\vert \\nabla h \\vert$ is always controlled so as to obtain a smoothly graded mesh. As the meshsize field is stored in an independent octree data structure, the function h can be computed separately, and then plugged in into any mesh generator able to respect a prescribed meshsize field. The whole procedure is automatic, in the sense that minimal interaction with the user is required. Applications examples based on models taken from the very large ABC dataset, are then presented, all treated with the same generic set of parameter values, to demonstrate the efficiency and the universality of the technique.",
        "published": "2020-09-04T16:08:39Z",
        "link": "http://arxiv.org/abs/2009.03984v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.CG",
            "cs.NA"
        ]
    },
    {
        "title": "Performance Analysis of FEM Solvers on Practical Electromagnetic   Problems",
        "authors": [
            "Gergely Máté Kiss",
            "Jan Kaska",
            "Roberto André Henrique de Oliveira",
            "Olena Rubanenko",
            "Balázs Tóth"
        ],
        "summary": "The paper presents a comparative analysis of different commercial and academic software. The comparison aims to examine how the integrated adaptive grid refinement methodologies can deal with challenging, electromagnetic-field related problems. For this comparison, two benchmark problems were examined in the paper. The first example is a solution of an L-shape domain like test problem, which has a singularity at a certain point in the geometry. The second problem is an induction heated aluminum rod, which accurate solution needs to solve a non-linear, coupled physical fields. The accurate solution of this problem requires applying adaptive mesh generation strategies or applying a very fine mesh in the electromagnetic domain, which can significantly increase the computational complexity. The results show that the fully-hp adaptive meshing strategies, which are integrated into Agros-suite, can significantly reduce the task's computational complexity compared to the automatic h-adaptivity, which is part of the examined, popular commercial solvers.",
        "published": "2020-09-04T21:24:36Z",
        "link": "http://arxiv.org/abs/2009.04399v1",
        "categories": [
            "cs.CE",
            "cs.MS",
            "G.1.10",
            "G.1.10"
        ]
    },
    {
        "title": "Improving Maritime Traffic Emission Estimations on Missing Data with   CRBMs",
        "authors": [
            "Alberto Gutierrez-Torre",
            "Josep Ll. Berral",
            "David Buchaca",
            "Marc Guevara",
            "Albert Soret",
            "David Carrera"
        ],
        "summary": "Maritime traffic emissions are a major concern to governments as they heavily impact the Air Quality in coastal cities. Ships use the Automatic Identification System (AIS) to continuously report position and speed among other features, and therefore this data is suitable to be used to estimate emissions, if it is combined with engine data. However, important ship features are often inaccurate or missing. State-of-the-art complex systems, like CALIOPE at the Barcelona Supercomputing Center, are used to model Air Quality. These systems can benefit from AIS based emission models as they are very precise in positioning the pollution. Unfortunately, these models are sensitive to missing or corrupted data, and therefore they need data curation techniques to significantly improve the estimation accuracy. In this work, we propose a methodology for treating ship data using Conditional Restricted Boltzmann Machines (CRBMs) plus machine learning methods to improve the quality of data passed to emission models. Results show that we can improve the default methods proposed to cover missing data. In our results, we observed that using our method the models boosted their accuracy to detect otherwise undetectable emissions. In particular, we used a real data-set of AIS data, provided by the Spanish Port Authority, to estimate that thanks to our method, the model was able to detect 45% of additional emissions, of additional emissions, representing 152 tonnes of pollutants per week in Barcelona and propose new features that may enhance emission modeling.",
        "published": "2020-09-07T10:32:43Z",
        "link": "http://arxiv.org/abs/2009.03001v2",
        "categories": [
            "cs.CY",
            "cs.CE",
            "cs.LG",
            "cs.NE",
            "J.2"
        ]
    },
    {
        "title": "TaBooN -- Boolean Network Synthesis Based on Tabu Search",
        "authors": [
            "Sara Sadat Aghamiri",
            "Franck Delaplace"
        ],
        "summary": "Recent developments in Omics-technologies revolutionized the investigation of biology by producing molecular data in multiple dimensions and scale. This breakthrough in biology raises the crucial issue of their interpretation based on modelling. In this undertaking, network provides a suitable framework for modelling the interactions between molecules. Basically a Biological network is composed of nodes referring to the components such as genes or proteins, and the edges/arcs formalizing interactions between them. The evolution of the interactions is then modelled by the definition of a dynamical system. Among the different categories of network, the Boolean network offers a reliable qualitative framework for the modelling. Automatically synthesizing a Boolean network from experimental data therefore remains a necessary but challenging issue. In this study, we present taboon, an original work-flow for synthesizing Boolean Networks from biological data. The methodology uses the data in the form of Boolean profiles for inferring all the potential local formula inference. They combine to form the model space from which the most truthful model with regards to biological knowledge and experiments must be found. In the taboon work-flow the selection of the fittest model is achieved by a Tabu-search algorithm. taboon is an automated method for Boolean Network inference from experimental data that can also assist to evaluate and optimize the dynamic behaviour of the biological networks providing a reliable platform for further modelling and predictions.",
        "published": "2020-09-08T08:56:14Z",
        "link": "http://arxiv.org/abs/2009.03587v1",
        "categories": [
            "cs.AI",
            "cs.CE",
            "q-bio.MN"
        ]
    },
    {
        "title": "A weakly compressible hybridizable discontinuous Galerkin formulation   for fluid-structure interaction problems",
        "authors": [
            "Andrea La Spina",
            "Martin Kronbichler",
            "Matteo Giacomini",
            "Wolfgang A. Wall",
            "Antonio Huerta"
        ],
        "summary": "A scheme for the solution of fluid-structure interaction (FSI) problems with weakly compressible flows is proposed in this work. A novel hybridizable discontinuous Galerkin (HDG) method is derived for the discretization of the fluid equations, while the standard continuous Galerkin (CG) approach is adopted for the structural problem. The chosen HDG solver combines robustness of discontinuous Galerkin (DG) approaches in advection-dominated flows with higher order accuracy and efficient implementations. Two coupling strategies are examined in this contribution, namely a partitioned Dirichlet-Neumann scheme in the context of hybrid HDG-CG discretizations and a monolithic approach based on Nitsche's method, exploiting the definition of the numerical flux and the trace of the solution to impose the coupling conditions. Numerical experiments show optimal convergence of the HDG and CG primal and mixed variables and superconvergence of the postprocessed fluid velocity. The robustness and the efficiency of the proposed weakly compressible formulation, in comparison to a fully incompressible one, are also highlighted on a selection of two and three dimensional FSI benchmark problems.",
        "published": "2020-09-09T09:09:56Z",
        "link": "http://arxiv.org/abs/2009.05106v1",
        "categories": [
            "physics.flu-dyn",
            "cs.CE",
            "cs.NA",
            "math.NA",
            "65M60, 76D07, 76M10"
        ]
    },
    {
        "title": "Using Spectral Submanifolds for Optimal Mode Selection in Model   Reduction",
        "authors": [
            "Gergely Buza",
            "Shobhit Jain",
            "George Haller"
        ],
        "summary": "Model reduction of large nonlinear systems often involves the projection of the governing equations onto linear subspaces spanned by carefully-selected modes. The criteria to select the modes relevant for reduction are usually problem-specific and heuristic. In this work, we propose a rigorous mode-selection criterion based on the recent theory of Spectral Submanifolds (SSM), which facilitates a reliable projection of the governing nonlinear equations onto modal subspaces. SSMs are exact invariant manifolds in the phase space that act as nonlinear continuations of linear normal modes. Our criterion identifies critical linear normal modes whose associated SSMs have locally the largest curvature. These modes should then be included in any projection-based model reduction as they are the most sensitive to nonlinearities. To make this mode selection automatic, we develop explicit formulas for the scalar curvature of an SSM and provide an open-source numerical implementation of our mode-selection procedure. We illustrate the power of this procedure by accurately reproducing the forced-response curves on three examples of varying complexity, including high-dimensional finite element models.",
        "published": "2020-09-09T11:52:18Z",
        "link": "http://arxiv.org/abs/2009.04232v1",
        "categories": [
            "math.DS",
            "cs.CE"
        ]
    },
    {
        "title": "Geometry-aware neural solver for fast Bayesian calibration of brain   tumor models",
        "authors": [
            "Ivan Ezhov",
            "Tudor Mot",
            "Suprosanna Shit",
            "Jana Lipkova",
            "Johannes C. Paetzold",
            "Florian Kofler",
            "Fernando Navarro",
            "Chantal Pellegrini",
            "Marcel Kollovieh",
            "Marie Metz",
            "Benedikt Wiestler",
            "Bjoern Menze"
        ],
        "summary": "Modeling of brain tumor dynamics has the potential to advance therapeutic planning. Current modeling approaches resort to numerical solvers that simulate the tumor progression according to a given differential equation. Using highly-efficient numerical solvers, a single forward simulation takes up to a few minutes of compute. At the same time, clinical applications of tumor modeling often imply solving an inverse problem, requiring up to tens of thousands forward model evaluations when used for a Bayesian model personalization via sampling. This results in a total inference time prohibitively expensive for clinical translation. While recent data-driven approaches become capable of emulating physics simulation, they tend to fail in generalizing over the variability of the boundary conditions imposed by the patient-specific anatomy. In this paper, we propose a learnable surrogate for simulating tumor growth which maps the biophysical model parameters directly to simulation outputs, i.e. the local tumor cell densities, whilst respecting patient geometry. We test the neural solver on Bayesian tumor model personalization for a cohort of glioma patients. Bayesian inference using the proposed surrogate yields estimates analogous to those obtained by solving the forward model with a regular numerical solver. The near-real-time computation cost renders the proposed method suitable for clinical settings. The code is available at https://github.com/IvanEz/tumor-surrogate.",
        "published": "2020-09-09T12:10:54Z",
        "link": "http://arxiv.org/abs/2009.04240v4",
        "categories": [
            "cs.CE",
            "eess.IV"
        ]
    },
    {
        "title": "A novel highly efficient Lagrangian model for massively multidomain   simulations: parallel context",
        "authors": [
            "Sebastian Florez",
            "Julien Fausty",
            "Karen Alvarado",
            "Brayan Murgas",
            "Marc Bernacki"
        ],
        "summary": "A new method for the simulation of evolving multi-domains problems has been introduced in a previous work (RealIMotion), Florez et al. (2020). In this article further developments of the model will be presented. The main focus here is a robust parallel implementation using a distributed-memory approach with the Message Passing Interface (MPI) library OpenMPI. The original 2D sequential methodology consists in a modified front-tracking approach where the main originality is that not only interfaces between domains are discretized but their interiors are also meshed. The interfaces are tracked based on the topological degree of each node on the mesh and the remeshing and topological changes of the domains are driven by selective local operations performed over an element patch. The accuracy and the performance of the sequential method has proven very promising in Florez et al. (2020). In this article a parallel implementation will be discussed and tested in context of motion by curvature flow for polycrystals, i.e. by considering Grain Growth (GG) mechanism. Results of the performance of the model are given and comparisons with other approaches in the literature are discussed.",
        "published": "2020-09-09T17:14:51Z",
        "link": "http://arxiv.org/abs/2009.04424v2",
        "categories": [
            "cs.CE",
            "cond-mat.mtrl-sci"
        ]
    },
    {
        "title": "Allocation of locally generated electricity in renewable energy   communities",
        "authors": [
            "Miguel Manuel de Villena",
            "Samy Aittahar",
            "Sebastien Mathieu",
            "Ioannis Boukas",
            "Eric Vermeulen",
            "Damien Ernst"
        ],
        "summary": "Local electricity markets represent a way of supplementing traditional retailing contracts for end consumers -- among these markets, the renewable energy community has gained momentum over the last few years. This paper proposes a practical and readily to be adopted modelling solution for these communities, one that allows their members to share the economic benefits derived from them. The proposed solution relies on an \\emph{ex-post} allocation of the electricity that is generated within energy communities (i.e., local electricity) based on the optimisation of \\emph{repartition keys}. Repartition keys are therefore optimally computed to represent the proportion of total local electricity to be allocated to each community member, and aim to minimise the sum of electricity bills of all community members. Since the optimisation takes place \\emph{ex-post} the repartition keys do not modify the actual electricity flows, but rather the financial flows of the community members. Then, the billing process of the community will take these keys into account to correctly send the electricity bills to each member. Building on this concept, we also introduce two additions to the basic algorithm to enhance the stability of the community, which a global bill minimisation may fail to ensure (e.g., very asymmetrical solutions between members may lead to some of them opting out).",
        "published": "2020-09-09T21:51:38Z",
        "link": "http://arxiv.org/abs/2009.05411v2",
        "categories": [
            "eess.SY",
            "cs.CE",
            "cs.SY"
        ]
    },
    {
        "title": "A block-coupled Finite Volume methodology for problems of large strain   and large displacement",
        "authors": [
            "L. R. Azevedo",
            "P. Cardiff",
            "F. J. Galindo-Rosales",
            "M. Schafer"
        ],
        "summary": "A nonlinear block-coupled Finite Volume methodology is developed for large displacement and large strain regime. The new methodology uses the same normal and tangential face derivative discretisations found in the original fully coupled cell-centred Finite Volume solution methodology for linear elasticity, meaning that existing block-coupled implementations may easily be extended to include finite strains. Details are given of the novel approach, including use of the Newton-Raphson procedure on a residual functional defined using the linear momentum equation. A number of 2-D benchmark cases have shown that, compared with a segregated procedure, the new approach exhibits errors with many orders of magnitude smaller and a much higher convergence rate.",
        "published": "2020-09-09T23:09:26Z",
        "link": "http://arxiv.org/abs/2009.06408v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Lattice Boltzmann Method for wave propagation in elastic solids with a   regular lattice: Theoretical analysis and validation",
        "authors": [
            "Maxime Escande",
            "Praveen Kumar Kolluru",
            "Louis Marie Cléon",
            "Pierre Sagaut"
        ],
        "summary": "The von Neumann stability analysis along with a Chapman-Enskog analysis is proposed for a single-relaxation-time lattice Boltzmann Method (LBM) for wave propagation in isotropic linear elastic solids, using a regular D2Q9 lattice. Different boundary conditions are considered: periodic, free surface, rigid interface. An original absorbing layer model is proposed to prevent spurious wave reflection at domain boundaries. The present method is assessed considering several test cases. First, a spatial Gaussian force modulated in time by a Ricker wavelet is used as a source. Comparisons are made with results obtained using a classical Fourier spectral method. Both P and S waves are shown to be very accurately predicted. The case of Rayleigh surface waves is then addressed to check the accuracy of the method.",
        "published": "2020-09-10T06:55:16Z",
        "link": "http://arxiv.org/abs/2009.06404v1",
        "categories": [
            "cs.CE",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Data-Driven Optimization Approach for Inverse Problems : Application to   Turbulent Mixed-Convection Flows",
        "authors": [
            "M. Oulghelou",
            "C. Beghein",
            "C. Allery"
        ],
        "summary": "Optimal control of turbulent mixed-convection flows has attracted considerable attention from researchers. Numerical algorithms such as Genetic Algorithms (GAs) are powerful tools that allow to perform global optimization. These algorithms are particularly of great interest in complex optimization problems where cost functionals may lack smoothness and regularity. In turbulent flow optimization, the hybridization of GA with high fidelity Computational Fluid Dynamics (CFD) is extremely demanding in terms of computational time and memory storage. Thus, alternative approaches aiming to alleviate these requirements are of great interest. Nowadays, data driven approaches gained attention due to their potential in predicting flow solutions based only on preexisting data. In the present paper, we propose a near-real time data-driven genetic algorithm (DDGA) for inverse parameter identification problems involving turbulent flows. In this optimization framework, the parametrized flow data are used in their reduced form obtained by the POD (Proper Orthogonal Decomposition) and solutions prediction is made by interpolating the temporal and the spatial POD subspaces through a recently developed Riemannian barycentric interpolation. The validation of the proposed optimization approach is carried out in the parameter identification problem of the turbulent mixed-convection flow in a cavity. The objective is to determine the inflow temperature and inflow velocity corresponding to a given temperature distribution in a restricted area of the spatial domain. The results show that the proposed genetic programming optimization framework is able to deliver good approximations of the optimal solutions within less than two minutes.",
        "published": "2020-09-10T18:08:18Z",
        "link": "http://arxiv.org/abs/2009.06724v2",
        "categories": [
            "cs.CE",
            "physics.flu-dyn"
        ]
    },
    {
        "title": "Hybridisable discontinuous Galerkin formulation of compressible flows",
        "authors": [
            "Jordi Vila-Pérez",
            "Matteo Giacomini",
            "Ruben Sevilla",
            "Antonio Huerta"
        ],
        "summary": "This work presents a review of high-order hybridisable discontinuous Galerkin (HDG) methods in the context of compressible flows. Moreover, an original unified framework for the derivation of Riemann solvers in hybridised formulations is proposed. This framework includes, for the first time in an HDG context, the HLL and HLLEM Riemann solvers as well as the traditional Lax-Friedrichs and Roe solvers. HLL-type Riemann solvers demonstrate their superiority with respect to Roe in supersonic cases due to their positivity preserving properties. In addition, HLLEM specifically outstands in the approximation of boundary layers because of its shear preservation, which confers it an increased accuracy with respect to HLL and Lax-Friedrichs. A comprehensive set of relevant numerical benchmarks of viscous and inviscid compressible flows is presented. The test cases are used to evaluate the competitiveness of the resulting high-order HDG scheme with the aforementioned Riemann solvers and equipped with a shock treatment technique based on artificial viscosity.",
        "published": "2020-09-10T20:23:59Z",
        "link": "http://arxiv.org/abs/2009.06396v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "physics.comp-ph",
            "physics.flu-dyn",
            "65M12, 65M22, 65M60, 76N15, 76N17"
        ]
    },
    {
        "title": "A scalable spectral Stokes solver for simulation of time-periodic flows   in complex geometries",
        "authors": [
            "Chenwei Meng",
            "Anirban Bhattacharjee",
            "Mahdi Esmaily"
        ],
        "summary": "Simulation of unsteady creeping flows in complex geometries has traditionally required the use of a time-stepping procedure, which is typically costly and unscalable. To reduce the cost and allow for computations at much larger scales, we propose an alternative approach that is formulated based on the unsteady Stokes equation expressed in the time-spectral domain. This transformation results in a boundary value problem with an imaginary source term proportional to the computed mode that is discretized and solved in a complex-valued finite element solver using Bubnov-Galerkin formulation. This transformed spatio-spectral formulation presents several advantages over the traditional spatio-temporal techniques. Firstly, for cases with boundary conditions varying smoothly in time, it provides a significant saving in computational cost as it can resolve time-variation of the solution using a few modes rather than thousands of time steps. Secondly, in contrast to the traditional time integration scheme with a finite order of accuracy, this method exhibits a super convergence behavior versus the number of computed modes. Thirdly, in contrast to the stabilized finite element methods for fluid, no stabilization term is employed in our formulation, producing a solution that is consistent and more accurate. Fourthly, the proposed approach is embarrassingly parallelizable owing to the independence of the solution modes, thus enabling scalable calculations at a much larger number of processors. The comparison of the proposed technique against a standard stabilized finite element solver is performed using two- and three-dimensional canonical and complex geometries. The results show that the proposed method can produce more accurate results at 1% to 11% of the cost of the standard technique for the studied cases.",
        "published": "2020-09-11T17:17:27Z",
        "link": "http://arxiv.org/abs/2009.06725v2",
        "categories": [
            "cs.CE",
            "physics.flu-dyn"
        ]
    },
    {
        "title": "On topology optimization of design-dependent pressure-loaded   three-dimensional structures and compliant mechanisms",
        "authors": [
            "Prabhat Kumar",
            "Matthijs Langelaar"
        ],
        "summary": "This paper presents a density-based topology optimization method for designing three-dimensional (3D) compliant mechanisms and loadbearing structures with design-dependent pressure loading. Instead of interface-tracking techniques, the Darcy law in conjunction with a drainage term is employed to obtain pressure field as a function of the design vector. To ensure continuous transition of pressure loads as the design evolves, the flow coefficient of a finite element is defined using a smooth Heaviside function. The obtained pressure field is converted into consistent nodal loads using a transformation matrix. The presented approach employs the standard finite element formulation and also, allows consistent and computationally inexpensive calculation of load sensitivities using the adjoint-variable method. For compliant mechanism design, a multi-criteria objective is minimized, whereas minimization of compliance is performed for designing loadbearing structures. Efficacy and robustness of the presented approach is demonstrated by designing various pressure-actuated 3D compliant mechanisms and structures.",
        "published": "2020-09-12T18:09:04Z",
        "link": "http://arxiv.org/abs/2009.05839v3",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Identifying Grey-box Thermal Models with Bayesian Neural Networks",
        "authors": [
            "Md Monir Hossain",
            "Tianyu Zhang",
            "Omid Ardakanian"
        ],
        "summary": "Smart thermostats are one of the most prevalent home automation products. They learn occupant preferences and schedules, and utilize an accurate thermal model to reduce the energy use of heating and cooling equipment while maintaining the temperature for maximum comfort. Despite the importance of having an accurate thermal model for the operation of smart thermostats, fast and reliable identification of this model is still an open problem. In this paper, we explore various techniques for establishing a suitable thermal model using time series data generated by smart thermostats. We show that Bayesian neural networks can be used to estimate parameters of a grey-box thermal model if sufficient training data is available, and this model outperforms several black-box models in terms of the temperature prediction accuracy. Leveraging real data from 8,884 homes equipped with smart thermostats, we discuss how the prior knowledge about the model parameters can be utilized to quickly build an accurate thermal model for another home with similar floor area and age in the same climate zone. Moreover, we investigate how to adapt the model originally built for the same home in another season using a small amount of data collected in this season. Our results confirm that maintaining only a small number of pre-trained thermal models will suffice to quickly build accurate thermal models for many other homes, and that 1~day smart thermostat data could significantly improve the accuracy of transferred models in another season.",
        "published": "2020-09-13T01:12:34Z",
        "link": "http://arxiv.org/abs/2009.05889v1",
        "categories": [
            "eess.SY",
            "cs.CE",
            "cs.SY"
        ]
    },
    {
        "title": "User Manual for the SU2 EQUiPS Module: Enabling Quantification of   Uncertainty in Physics Simulations",
        "authors": [
            "Jayant Mukhopadhaya"
        ],
        "summary": "This document serves as the manual for using the EQUiPS (Enabling Quantification of Uncertainty in Physics Simulations) module in SU2. The EQUiPS module uses the Eigenspace Perturbation methodology to provide interval bounds on Quantities of Interest (QoIs) that capture epistemic uncertainties arising from assumptions made in RANS turbulence models. This has been implemented and tested in SU2 for a variety of benchmark turbulence cases as well as flows of aerodynamic interest.",
        "published": "2020-09-13T17:33:33Z",
        "link": "http://arxiv.org/abs/2009.06627v1",
        "categories": [
            "cs.CE",
            "physics.flu-dyn"
        ]
    },
    {
        "title": "A novel combination of theoretical analysis and data-driven method for   reconstruction of structural defects",
        "authors": [
            "Qi Li",
            "Yihui Da",
            "Yinghong Zhang",
            "Bin Wang",
            "Dianzi Liu",
            "Zhenghua Qian"
        ],
        "summary": "Ultrasonic guided wave technology has played a significant role in the field of non-destructive testing as it employs acoustic waves that have advantages of high propagation efficiency and low energy consumption during the inspect process. However, theoretical solutions to guided wave scattering problems using assumptions such as Born approximation, have led to the poor quality of the reconstructed results. To address this issue, a novel approach to quantitative reconstruction of defects using the integration of data-driven method with the guided wave scattering analysis has been proposed in this paper. Based on the geometrical information of defects and initial results by the theoretical analysis of defect reconstructions, a deep learning neural network model is built to reveal the physical relationship between defects and the received signals. This data-driven model is then applied to quantitatively assess and characterize defect profiles in structures, reduce the inaccuracy of the theoretical modelling and eliminate the impact of noise pollution in the process of inspection. To demonstrate advantages of the developed approach to reconstructions of defects with complex profiles, numerical examples including basic defect profiles and a defect with the noisy fringe have been examined. Results show that this approach has greater accuracy for reconstruction of defects in structures as compared with the analytical method and provides a valuable insight into the development of artificial intelligence-assisted inspection systems with high accuracy and efficiency in the field of non-destructive testing.",
        "published": "2020-09-14T09:04:34Z",
        "link": "http://arxiv.org/abs/2009.06276v1",
        "categories": [
            "cs.CE",
            "J.2"
        ]
    },
    {
        "title": "Interfacing biology, category theory and mathematical statistics",
        "authors": [
            "Dominique Pastor",
            "Erwan Beurier",
            "Andrée Ehresmann",
            "Roger Waldeck"
        ],
        "summary": "Motivated by the concept of degeneracy in biology (Edelman, Gally 2001), we establish a first connection between the Multiplicity Principle (Ehresmann, Vanbremeersch 2007) and mathematical statistics. Specifically, we exhibit two families of statistical tests that satisfy this principle to achieve the detection of a signal in noise.",
        "published": "2020-09-15T02:15:18Z",
        "link": "http://arxiv.org/abs/2009.06832v1",
        "categories": [
            "math.CT",
            "cs.CE",
            "math.ST",
            "stat.TH"
        ]
    },
    {
        "title": "Which Trading Agent is Best? Using a Threaded Parallel Simulation of a   Financial Market Changes the Pecking-Order",
        "authors": [
            "Michael Rollins",
            "Dave Cliff"
        ],
        "summary": "This paper presents novel results generated from a new simulation model of a contemporary financial market, that cast serious doubt on the previously widely accepted view of the relative performance of various well-known public-domain automated-trading algorithms. Various public-domain trading algorithms have been proposed over the past 25 years in a kind of arms-race, where each new trading algorithm was compared to the previous best, thereby establishing a \"pecking order\", i.e. a partially-ordered dominance hierarchy from best to worst of the various trading algorithms. Many of these algorithms were developed and tested using simple minimal simulations of financial markets that only weakly approximated the fact that real markets involve many different trading systems operating asynchronously and in parallel. In this paper we use BSE, a public-domain market simulator, to run a set of experiments generating benchmark results from several well-known trading algorithms. BSE incorporates a very simple time-sliced approach to simulating parallelism, which has obvious known weaknesses. We then alter and extend BSE to make it threaded, so that different trader algorithms operate asynchronously and in parallel: we call this simulator Threaded-BSE (TBSE). We then re-run the trader experiments on TBSE and compare the TBSE results to our earlier benchmark results from BSE. Our comparison shows that the dominance hierarchy in our more realistic experiments is different from the one given by the original simple simulator. We conclude that simulated parallelism matters a lot, and that earlier results from simple simulations comparing different trader algorithms are no longer to be entirely trusted.",
        "published": "2020-09-15T07:44:30Z",
        "link": "http://arxiv.org/abs/2009.06905v1",
        "categories": [
            "q-fin.TR",
            "cs.CE"
        ]
    },
    {
        "title": "The impact of social influence in Australian real-estate: market   forecasting with a spatial agent-based model",
        "authors": [
            "Benjamin Patrick Evans",
            "Kirill Glavatskiy",
            "Michael S. Harré",
            "Mikhail Prokopenko"
        ],
        "summary": "Housing markets are inherently spatial, yet many existing models fail to capture this spatial dimension. Here we introduce a new graph-based approach for incorporating a spatial component in a large-scale urban housing agent-based model (ABM). The model explicitly captures several social and economic factors that influence the agents' decision-making behaviour (such as fear of missing out, their trend following aptitude, and the strength of their submarket outreach), and interprets these factors in spatial terms. The proposed model is calibrated and validated with the housing market data for the Greater Sydney region. The ABM simulation results not only include predictions for the overall market, but also produce area-specific forecasting at the level of local government areas within Sydney as arising from individual buy and sell decisions. In addition, the simulation results elucidate agent preferences in submarkets, highlighting differences in agent behaviour, for example, between first-time home buyers and investors, and between both local and overseas investors.",
        "published": "2020-09-15T08:21:11Z",
        "link": "http://arxiv.org/abs/2009.06914v2",
        "categories": [
            "q-fin.CP",
            "cs.CE",
            "nlin.AO",
            "physics.soc-ph"
        ]
    },
    {
        "title": "MO-PaDGAN: Reparameterizing Engineering Designs for Augmented   Multi-objective Optimization",
        "authors": [
            "Wei Chen",
            "Faez Ahmed"
        ],
        "summary": "Multi-objective optimization is key to solving many Engineering Design problems, where design parameters are optimized for several performance indicators. However, optimization results are highly dependent on how the designs are parameterized. Researchers have shown that deep generative models can learn compact design representations, providing a new way of parameterizing designs to achieve faster convergence and improved optimization performance. Despite their success in capturing complex distributions, existing generative models face three challenges when used for design problems: 1) generated designs have limited design space coverage, 2) the generator ignores design performance, and 3)~the new parameterization is unable to represent designs beyond training data. To address these challenges, we propose MO-PaDGAN, which adds a Determinantal Point Processes based loss function to the generative adversarial network to simultaneously model diversity and (multi-variate) performance. MO-PaDGAN can thus improve the performances and coverage of generated designs, and even generate designs with performances exceeding those from training data. When using MO-PaDGAN as a new parameterization in multi-objective optimization, we can discover much better Pareto fronts even though the training data do not cover those Pareto fronts. In a real-world multi-objective airfoil design example, we demonstrate that MO-PaDGAN achieves, on average, an over 180\\% improvement in the hypervolume indicator when compared to the vanilla GAN or other state-of-the-art parameterization methods.",
        "published": "2020-09-15T13:58:31Z",
        "link": "http://arxiv.org/abs/2009.07110v3",
        "categories": [
            "cs.LG",
            "cs.CE",
            "stat.ML"
        ]
    },
    {
        "title": "Accurate and efficient Simulation of very high-dimensional Neural Mass   Models with distributed-delay Connectome Tensors",
        "authors": [
            "A. González-Mitjans",
            "D. Paz-Linares",
            "A. Areces-Gonzalez",
            "M. Li",
            "Y. Wang",
            "ML. Bringas-Vega",
            "P. A Valdés-Sosa"
        ],
        "summary": "This paper introduces methods and a novel toolbox that efficiently integrates any high-dimensional Neural Mass Models (NMMs) specified by two essential components. The first is the set of nonlinear Random Differential Equations of the dynamics of each neural mass. The second is the highly sparse three-dimensional Connectome Tensor (CT) that encodes the strength of the connections and the delays of information transfer along the axons of each connection. Semi-analytical integration of the RDE is done with the Local Linearization scheme for each neural mass model, which is the only scheme guaranteeing dynamical fidelity to the original continuous-time nonlinear dynamic. It also seamlessly allows modeling distributed delays CT with any level of complexity or realism, as shown by the Moore-Penrose diagram of the algorithm. This ease of implementation includes models with distributed-delay CTs. We achieve high computational efficiency by using a tensor representation of the model that leverages semi-analytic expressions to integrate the Random Differential Equations (RDEs) underlying the NMM. We discretized the state equation with Local Linearization via an algebraic formulation. This approach increases numerical integration speed and efficiency, a crucial aspect of large-scale NMM simulations. To illustrate the usefulness of the toolbox, we simulate both a single Zetterberg-Jansen-Rit (ZJR) cortical column and an interconnected population of such columns. These examples illustrate the consequence of modifying the CT in these models, especially by introducing distributed delays. We provide an open-source Matlab live script for the toolbox.",
        "published": "2020-09-16T05:55:17Z",
        "link": "http://arxiv.org/abs/2009.07479v6",
        "categories": [
            "q-bio.NC",
            "cs.CE",
            "cs.NE"
        ]
    },
    {
        "title": "Variational phase-field continuum model uncovers adhesive wear   mechanisms in asperity junctions",
        "authors": [
            "Sylvain Collet",
            "Jean-François Molinari",
            "Stella Brach"
        ],
        "summary": "Wear is well known for causing material loss in a sliding interface. Available macroscopic approaches are bound to empirical fitting parameters, which range several orders of magnitude. Major advances in tribology have recently been achieved via Molecular Dynamics, although its use is strongly limited by computational cost. Here, we propose a study of the physical processes that lead to wear at the scale of the surface roughness, where adhesive junctions are formed between the asperities on the surface of the materials. Using a brittle formulation of the variational phase-field approach to fracture, we demonstrate that the failure mechanisms of an adhesive junction can be linked to its geometry. By imposing specific couplings between the damage and the elastic energy, we further investigate the triggering processes underlying each failure mechanism. We show that a large debris formation is mostly triggered by tensile stresses while shear stresses lead to small or no particle formation. We also study groups of junctions and discuss how microcontact interactions can be favored in some geometries to form macro-particles. This leads us to propose a classification in terms of macroscopic wear rate. Although based on a continuum approach, our phase-field calculations are able to effectively capture the failure of adhesive junctions, as observed through discrete Molecular Dynamics simulations.",
        "published": "2020-09-17T08:11:26Z",
        "link": "http://arxiv.org/abs/2009.08135v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A micropolar peridynamics model with non-unified horizon for damage of   solids with different non-local effects",
        "authors": [
            "Yiming Zhang",
            "Xueqing Yang",
            "Xiaoying Zhuang"
        ],
        "summary": "Most peridynamics models adopt regular point distribution and unified horizon, limiting their flexibility and engineering applications. In this work, a micropolar peridynamics approach with non-unified horizon (NHPD) is proposed. This approach is implemented in a conventional finite element framework, using element-based discretization. By modifying the dual horizon approach into the pre-processing part, point dependent horizon and non-unified beam-like bonds are built. By implementing a domain correction strategy, the equivalence of strain energy density is assured. Then, a novel energy density-based failure criterion is presented which directly bridges the critical stretch to the mechanical strength. The numerical results indicate the weak mesh dependency of NHPD and the effectiveness of the new failure criterion. Moreover, it is proven that damage of solid with different non-local effects can lead to similar results by only adjusting the mechanical strength.",
        "published": "2020-09-17T10:43:47Z",
        "link": "http://arxiv.org/abs/2009.08202v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Broadband Finite-Element Impedance Computation for Parasitic Extraction",
        "authors": [
            "Jonathan Stysch",
            "Andreas Klaedtke",
            "Herbert De Gersem"
        ],
        "summary": "Parasitic extraction is a powerful tool in the design process of electromechanical devices, specifically as part of workflows that check electromagnetic compatibility. A novel scheme to extract impedances from CAD device models, suitable for a finite element implementation, is derived from Maxwell's equations in differential form. It provides a foundation for parasitic extraction across a broad frequency range and is able to handle inhomogeneous permittivities and permeabilities, making it more flexible than existing integral equation approaches. The approach allows for the automatic treatment of multi-port models of arbitrary conductor geometry without requiring any significant manual user interaction. This is achieved by computing a connecting source current density that supplies current to the model's terminals, whatever their location in the model, subsequently using this current density to compute the electric field, and finally calculating the impedance via a scalar potential. A mandatory low-frequency stabilization scheme is outlined, ensuring a stable evaluation of the model at low frequencies as well. Two quasistatic approximations and the special case of perfect electric conductors are treated theoretically. The magnetoquasistatic approximation is validated against an analytical model in a numerical experiment. Moreover, the intrinsic capability of the method to treat inhomogeneous permittivities and permeabilities is demonstrated with a simple capacitor-coil model including dielectric insulation and magnetic core materials.",
        "published": "2020-09-17T12:30:54Z",
        "link": "http://arxiv.org/abs/2009.08232v3",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A numerical approach for hybrid reliability analysis of structures under   mixed uncertainties using the uncertainty theory",
        "authors": [
            "Lei Zhang"
        ],
        "summary": "This paper presents a novel numerical method for the hybrid reliability analysis by using the uncertainty theory. Aleatory uncertainty and epistemic uncertainty are considered simultaneously in this method. Epistemic uncertainty is characterized by the uncertainty theory, and the effect of epistemic uncertainty is quantified by the sub-additive uncertain measure. Then, under the framework of the chance theory which can be interpreted as the combination of the probability theory and the uncertainty theory, a general uncertainty quantification model is established to deal with the hybrid reliability analysis problem, then the corresponding reliability metric is defined. After that, to improve the feasibility of the proposed model, by utilizing the polar coordinate transformation based dimension reduction method, a numerical analysis method for the hybrid reliability model are provided. At last, several application cases are presented to prove the effectiveness of the proposed method for the reliability analysis under hybrid uncertainty. The comparisons between the results of the proposed method and the Monte Carlo simulation also illustrate the merit of this method.",
        "published": "2020-09-17T13:31:24Z",
        "link": "http://arxiv.org/abs/2009.08285v1",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA",
            "65F02",
            "F.2.1; G.1.10"
        ]
    },
    {
        "title": "A new front-tracking Lagrangian model for the modeling of dynamic and   post-dynamic recrystallization",
        "authors": [
            "Sebastian Florez",
            "Karen Alvarado",
            "Marc Bernacki"
        ],
        "summary": "A new method for the simulation of evolving multi-domains problems has been introduced in previous works (RealIMotion), Florez et al. (2020) and further developed in parallel in the context of isotropic Grain Growth (GG) with no consideration for the effects of the Stored Energy (SE) due to dislocations. The methodology consists in a new front-tracking approach where one of the originality is that not only interfaces between grains are discretized but their bulks are also meshed and topological changes of the domains are driven by selective local remeshing operations performed on the Finite Element (FE) mesh. In this article, further developments and studies of the model will be presented, mainly on the development of a model taking into account grain boundary migration by (GBM) SE. Further developments for the nucleation of new grains will be presented, allowing to model Dynamic Recrystallization (DRX) and Post-Dynamic Recrystallization (PDRX) phenomena. The accuracy and the performance of the numerical algorithms have been proven to be very promising in Florez et al. (2020). Here the results for multiple test cases will be given in order to validate the accuracy of the model taking into account GG and SE. The computational performance will be evaluated for the DRX and PDRX mechanisms and compared to a classical Finite Element (FE) framework using a Level-Set (LS) formulation.",
        "published": "2020-09-17T15:32:09Z",
        "link": "http://arxiv.org/abs/2009.08368v1",
        "categories": [
            "cs.CE",
            "cond-mat.mtrl-sci"
        ]
    },
    {
        "title": "Computational models in Electroencephalography",
        "authors": [
            "Katharina Glomb",
            "Joana Cabral",
            "Anna Cattani",
            "Alberto Mazzoni",
            "Ashish Raj",
            "Benedetta Franceschiello"
        ],
        "summary": "Computational models lie at the intersection of basic neuroscience and healthcare applications because they allow researchers to test hypotheses \\textit{in silico} and predict the outcome of experiments and interactions that are very hard to test in reality. Yet, what is meant by \"computational model\" is understood in many different ways by researchers in different fields of neuroscience and psychology, hindering communication and collaboration. In this review, we point out the state of the art of computational modeling in Electroencephalography (EEG) and outline how these models can be used to integrate findings from electrophysiology, network-level models, and behavior. On the one hand, computational models serve to investigate the mechanisms that generate brain activity, for example measured with EEG, such as the transient emergence of oscillations at different frequency bands and/or with different spatial topographies. On the other hand, computational models serve to design experiments and test hypotheses \\emph{in silico}. The final purpose of computational models of EEG is to obtain a comprehensive understanding of the mechanisms that underlie the EEG signal. This is crucial for an accurate interpretation of EEG measurements that may ultimately serve in the development of novel clinical applications.",
        "published": "2020-09-17T15:59:35Z",
        "link": "http://arxiv.org/abs/2009.08385v1",
        "categories": [
            "q-bio.NC",
            "cs.CE"
        ]
    },
    {
        "title": "Industry-Relevant Implicit Large-Eddy Simulation of a High-Performance   Road Car via Spectral/hp Element Methods",
        "authors": [
            "Gianmarco Mengaldo",
            "David Moxey",
            "Michael Turner",
            "Rodrigo C. Moura",
            "Ayad Jassim",
            "Mark Taylor",
            "Joaquim Peiro",
            "Spencer J. Sherwin"
        ],
        "summary": "We present a successful deployment of high-fidelity Large-Eddy Simulation (LES) technologies based on spectral/hp element methods to industrial flow problems, which are characterized by high Reynolds numbers and complex geometries. In particular, we describe the numerical methods, software development and steps that were required to perform the implicit LES of a real automotive car, namely the Elemental Rp1 model. To the best of the authors' knowledge, this simulation represents the first fifth-order accurate transient LES of an entire real car geometry. Moreover, this constitutes a key milestone towards considerably expanding the computational design envelope currently allowed in industry, where steady-state modelling remains the standard. To this end, a number of novel developments had to be made in order to overcome obstacles in mesh generation and solver technology to achieve this simulation, which we detail in this paper. The main objective is to present to the industrial and applied mathematics community, a viable pathway to translate academic developments into industrial tools, that can substantially advance the analysis and design capabilities of high-end engineering stakeholders. The novel developments and results were achieved using the academic-driven open-source framework Nektar++.",
        "published": "2020-09-18T09:46:21Z",
        "link": "http://arxiv.org/abs/2009.10178v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Non-intrusive reduced order modelling for the dynamics of geometrically   nonlinear flat structures using three-dimensional finite elements",
        "authors": [
            "Alessandra Vizzaccaro",
            "Arthur Givois",
            "Pierluigi Longobardi",
            "Yichang Shen",
            "Jean-François Deü",
            "Loïc Salles",
            "Cyril Touzé",
            "Olivier Thomas"
        ],
        "summary": "Non-intrusive methods have been used since two decades to derive reduced-order models for geometrically nonlinear structures, with a particular emphasis on the so-called STiffness Evaluation Procedure (STEP), relying on the static application of prescribed displacements in a finite-element context. We show that a particularly slow convergence of the modal expansion is observed when applying the method with 3D elements, because of nonlinear couplings occurring with very high frequency modes involving 3D thickness deformations. Focusing on the case of flat structures, we first show by computing all the modes of the structure that a converged solution can be exhibited by using either static condensation or normal form theory. We then show that static modal derivatives provide the same solution with fewer calculations. Finally, we propose a modified STEP, where the prescribed displacements are imposed solely on specific degrees of freedom of the structure, and show that this adjustment also provides efficiently a converged solution.",
        "published": "2020-09-18T14:42:01Z",
        "link": "http://arxiv.org/abs/2009.11377v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Analysis of tunnel failure characteristics under multiple explosion   loads based on persistent homology-based machine learning",
        "authors": [
            "Shengdong Zhang",
            "Shihui You",
            "Longfei Chen",
            "Xiaofei Liu"
        ],
        "summary": "The study of tunnel failure characteristics under the load of external explosion source is an important problem in tunnel design and protection, in particular, it is of great significance to construct an intelligent topological feature description of the tunnel failure process. The failure characteristics of tunnels under explosive loading are described by using discrete element method and persistent homology-based machine learning. Firstly, the discrete element model of shallow buried tunnel was established in the discrete element software, and the explosive load was equivalent to a series of uniformly distributed loads acting on the surface by Saint-Venant principle, and the dynamic response of the tunnel under multiple explosive loads was obtained through iterative calculation. The topological characteristics of surrounding rock is studied by persistent homology-based machine learning. The geometric, physical and interunit characteristics of the tunnel subjected to explosive loading are extracted, and the nonlinear mapping relationship between the topological quantity of persistent homology, and the failure characteristics of the surrounding rock is established, and the results of the intelligent description of the failure characteristics of the tunnel are obtained. The research shows that the length of the longest Betty 1 bar code is closely related to the stability of the tunnel, which can be used for effective early warning of the tunnel failure, and an intelligent description of the tunnel failure process can be established to provide a new idea for tunnel engineering protection.",
        "published": "2020-09-19T07:38:28Z",
        "link": "http://arxiv.org/abs/2009.10069v1",
        "categories": [
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "Topology Optimization through Differentiable Finite Element Solver",
        "authors": [
            "Liang Chen",
            "Herman M. H. Shen"
        ],
        "summary": "In this paper, a topology optimization framework utilizing automatic differentiation is presented as an efficient way for solving 2D density-based topology optimization problem by calculating gradients through the fully differentiable finite element solver. The optimization framework with the differentiable physics solver is proposed and tested on several classical topology optimization examples. The differentiable solver is implemented in Julia programming language and can be automatically differentiated in reverse mode to provide the pullback functions of every single operation. The entire end-to-end gradient information can be then backed up by utilizing chain rule. This framework incorporates a generator built from convolutional layers with a set of learnable parameters to propose new designs for every iteration. Since the whole process is differentiable, the parameters of the generator can be updated using any optimization algorithm given the gradient information from automatic differentiation. The proposed optimization framework is demonstrated on designing a half MBB beam and compared to the results with the ones from the efficient 88-line code. By only changing the objective function and the boundary conditions, it can run an optimization for designing a compliant mechanism, e.g. a force inverter where the output displacement is in the opposite direction of the input.",
        "published": "2020-09-20T19:35:46Z",
        "link": "http://arxiv.org/abs/2009.10072v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A Novel Method for Inference of Acyclic Chemical Compounds with Bounded   Branch-height Based on Artificial Neural Networks and Integer Programming",
        "authors": [
            "Naveed Ahmed Azam",
            "Jianshen Zhu",
            "Yanming Sun",
            "Yu Shi",
            "Aleksandar Shurbevski",
            "Liang Zhao",
            "Hiroshi Nagamochi",
            "Tatsuya Akutsu"
        ],
        "summary": "Analysis of chemical graphs is a major research topic in computational molecular biology due to its potential applications to drug design. One approach is inverse quantitative structure activity/property relationship (inverse QSAR/QSPR) analysis, which is to infer chemical structures from given chemical activities/properties. Recently, a framework has been proposed for inverse QSAR/QSPR using artificial neural networks (ANN) and mixed integer linear programming (MILP). This method consists of a prediction phase and an inverse prediction phase. In the first phase, a feature vector $f(G)$ of a chemical graph $G$ is introduced and a prediction function $\\psi$ on a chemical property $\\pi$ is constructed with an ANN. In the second phase, given a target value $y^*$ of property $\\pi$, a feature vector $x^*$ is inferred by solving an MILP formulated from the trained ANN so that $\\psi(x^*)$ is close to $y^*$ and then a set of chemical structures $G^*$ such that $f(G^*)= x^*$ is enumerated by a graph search algorithm. The framework has been applied to the case of chemical compounds with cycle index up to 2. The computational results conducted on instances with $n$ non-hydrogen atoms show that a feature vector $x^*$ can be inferred for up to around $n=40$ whereas graphs $G^*$ can be enumerated for up to $n=15$. When applied to the case of chemical acyclic graphs, the maximum computable diameter of $G^*$ was around up to around 8. We introduce a new characterization of graph structure, \"branch-height,\" based on which an MILP formulation and a graph search algorithm are designed for chemical acyclic graphs. The results of computational experiments using properties such as octanol/water partition coefficient, boiling point and heat of combustion suggest that the proposed method can infer chemical acyclic graphs $G^*$ with $n=50$ and diameter 30.",
        "published": "2020-09-21T07:11:59Z",
        "link": "http://arxiv.org/abs/2009.09646v1",
        "categories": [
            "cs.DS",
            "cs.CE",
            "05C92, 92E10, 05C30, 68T07, 90C11, 92-04"
        ]
    },
    {
        "title": "Towards real-time finite-strain anisotropic thermo-visco-elastodynamic   analysis of soft tissues for thermal ablative therapy",
        "authors": [
            "Jinao Zhang",
            "Remi Jacob Lay",
            "Stuart K. Roberts",
            "Sunita Chauhan"
        ],
        "summary": "Accurate and efficient prediction of soft tissue temperatures is essential to computer-assisted treatment systems for thermal ablation. It can be used to predict tissue temperatures and ablation volumes for personalised treatment planning and image-guided intervention. Numerically, it requires full nonlinear modelling of the coupled computational bioheat transfer and biomechanics, and efficient solution procedures; however, existing studies considered the bioheat analysis alone or the coupled linear analysis, without the fully coupled nonlinear analysis. We present a coupled thermo-visco-hyperelastic finite element algorithm, based on finite-strain thermoelasticity and total Lagrangian explicit dynamics. It considers the coupled nonlinear analysis of (i) bioheat transfer under soft tissue deformations and (ii) soft tissue deformations due to thermal expansion/shrinkage. The presented method accounts for anisotropic, finite-strain, temperature-dependent, thermal, and viscoelastic behaviours of soft tissues, and it is implemented using GPU acceleration for real-time computation. We also demonstrate the translational benefits of the presented method for clinical applications using a simulation of thermal ablation in the liver. The key advantage of the presented method is that it enables full nonlinear modelling of the anisotropic, finite-strain, temperature-dependent, thermal, and viscoelastic behaviours of soft tissues, instead of linear elastic, linear viscoelastic, and thermal-only modelling in the existing methods. It also provides high computational speeds for computer-assisted treatment systems towards enabling the operator to simulate thermal ablation accurately and visualise tissue temperatures and ablation zones immediately.",
        "published": "2020-09-22T09:04:29Z",
        "link": "http://arxiv.org/abs/2009.10400v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Simulation model of spacetime with the Minkowski metric",
        "authors": [
            "Vasyliy I. Gurianov"
        ],
        "summary": "In this paper, we propose a simulation model of spacetime as a discrete model of physical space. The model is based on the ideas of Stephen Wolfram and uses non-numerical modelling. The simulation model is described as an ontology. We use object-oriented simulation (OOS), but the model is also suitable for agent-based simulation (ABS). We use UML2 SP (UML Scientific Profile), an object-oriented simulation language used in scientific fields. This paper describes several experiments that demonstrate time dilation and dynamic relativistic effects. The reproducibility of experimental results can be verified. We provide a link to the repository in this paper. The model is implemented in Python.",
        "published": "2020-09-22T17:03:38Z",
        "link": "http://arxiv.org/abs/2009.10689v1",
        "categories": [
            "cs.CE",
            "cs.MA"
        ]
    },
    {
        "title": "Exactly Divergence-free Hybrid Discontinuous Galerkin Method for   Incompressible Turbulent Flows",
        "authors": [
            "Xaver Mooslechner"
        ],
        "summary": "This thesis deals with the investigation of a H(div)-conforming hybrid discontinuous Galerkin discretization for incompressible turbulent flows. The discretization method provides many physical and solving-oriented properties, which may be advantageous for resolving computationally intensive turbulent structures. A standard continuous Galerkin discretization for the Navier-Stokes equations with the well-known Taylor-Hood elements is also introduced in order to provide a comparison. The four different main principles of simulating turbulent flows are explained: the Reynolds-averaged Navier-Stokes simulation, large eddy simulation, variational multiscale method and the direct numerical simulation. The large eddy simulation and variational multiscale have shown good promise in the computation of traditionally difficult turbulent cases. This accuracy can be only surpassed by directly solving the Navier-Stokes equations, but comes with excessively high computational costs. The very common strategy is the Reynolds-average approach, since it is the most cost-effective. Those modelling principles have been applied to the two discretization techniques and validated through the basic plane channel flow test case. All numerical tests have been conducted with the finite element library Netgen/NGSolve.",
        "published": "2020-09-24T06:14:05Z",
        "link": "http://arxiv.org/abs/2009.11504v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Study of autonomous conservative oscillator using an improved   perturbation method",
        "authors": [
            "C. F. Sagar Zephania",
            "Tapas Sil"
        ],
        "summary": "In a recent article \\cite{manimegalai2019}, Aboodh transform based homotopy perturbation method ($AT$) has been found to produce approximate analytical solutions in a simple way but with better accuracy in comparison to those obtained from some of the established approximation methods \\cite{mehdipour2010application,nofal2013analytical} for some physically relevant anharmonic oscillators such as autonomous conservative oscillator (ACO). In the present article, expansion of frequency ($\\omega$) and an auxiliary parameter ($h$) are incorporated in the framework of the homotopy perturbation method (HPM) to improve the accuracy by retaining its simplicity. Laplace transform is used to make the calculation simpler. This improved HPM ($LH$) is simple but provides highly accurate results for ACO in comparison to those obtained from $AT$. The error in the values of frequency and displacement calculated using the $LH$ is found to be one or two order of magnitude less than those obtained from $AT$ for the considered parameter sets.",
        "published": "2020-09-24T08:26:55Z",
        "link": "http://arxiv.org/abs/2010.00944v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A compute-bound formulation of Galerkin model reduction for linear   time-invariant dynamical systems",
        "authors": [
            "Francesco Rizzi",
            "Eric J. Parish",
            "Patrick J. Blonigan",
            "John Tencer"
        ],
        "summary": "This work aims to advance computational methods for projection-based reduced order models (ROMs) of linear time-invariant (LTI) dynamical systems. For such systems, current practice relies on ROM formulations expressing the state as a rank-1 tensor (i.e., a vector), leading to computational kernels that are memory bandwidth bound and, therefore, ill-suited for scalable performance on modern many-core and hybrid computing nodes. This weakness can be particularly limiting when tackling many-query studies, where one needs to run a large number of simulations. This work introduces a reformulation, called rank-2 Galerkin, of the Galerkin ROM for LTI dynamical systems which converts the nature of the ROM problem from memory bandwidth to compute bound. We present the details of the formulation and its implementation, and demonstrate its utility through numerical experiments using, as a test case, the simulation of elastic seismic shear waves in an axisymmetric domain. We quantify and analyze performance and scaling results for varying numbers of threads and problem sizes. Finally, we present an end-to-end demonstration of using the rank-2 Galerkin ROM for a Monte Carlo sampling study. We show that the rank-2 Galerkin ROM is one order of magnitude more efficient than the rank-1 Galerkin ROM (the current practice) and about 970X more efficient than the full order model, while maintaining accuracy in both the mean and statistics of the field.",
        "published": "2020-09-24T15:06:00Z",
        "link": "http://arxiv.org/abs/2009.11742v3",
        "categories": [
            "physics.comp-ph",
            "cs.CE",
            "cs.DC",
            "cs.MS",
            "math.DS"
        ]
    },
    {
        "title": "AMReX: Block-Structured Adaptive Mesh Refinement for Multiphysics   Applications",
        "authors": [
            "Weiqun Zhang",
            "Andrew Myers",
            "Kevin Gott",
            "Ann Almgren",
            "John Bell"
        ],
        "summary": "Block-structured adaptive mesh refinement (AMR) provides the basis for the temporal and spatial discretization strategy for a number of ECP applications in the areas of accelerator design, additive manufacturing, astrophysics, combustion, cosmology, multiphase flow, and wind plant modelling. AMReX is a software framework that provides a unified infrastructure with the functionality needed for these and other AMR applications to be able to effectively and efficiently utilize machines from laptops to exascale architectures. AMR reduces the computational cost and memory footprint compared to a uniform mesh while preserving accurate descriptions of different physical processes in complex multi-physics algorithms. AMReX supports algorithms that solve systems of partial differential equations (PDEs) in simple or complex geometries, and those that use particles and/or particle-mesh operations to represent component physical processes. In this paper, we will discuss the core elements of the AMReX framework such as data containers and iterators as well as several specialized operations to meet the needs of the application projects. In addition we will highlight the strategy that the AMReX team is pursuing to achieve highly performant code across a range of accelerator-based architectures for a variety of different applications.",
        "published": "2020-09-25T02:59:30Z",
        "link": "http://arxiv.org/abs/2009.12009v1",
        "categories": [
            "cs.MS",
            "cs.CE",
            "cs.DC"
        ]
    },
    {
        "title": "A Column Generation based Heuristic for the Tail Assignment Problem",
        "authors": [
            "Akash Sambrekar",
            "El Mehdi Er Raqabi"
        ],
        "summary": "This article proposes an efficient heuristic in accelerating the column generation by parallel resolution of pricing problems for aircrafts in the tail assignment problem (TAP). The approach is able to achieve considerable improvement in resolution time for real life test instances from two major Indian air carriers. The different restrictions on individual aircraft for maintenance routing as per aviation regulatory bodies are considered in this paper. We also present a variable fixing heuristic to improve the integrality of the solution. The hybridization of constraint programming and column generation was substantial in accelerating the resolution process.",
        "published": "2020-09-25T03:41:00Z",
        "link": "http://arxiv.org/abs/2009.13301v1",
        "categories": [
            "cs.AI",
            "cs.CE"
        ]
    },
    {
        "title": "Direct computation of nonlinear mapping via normal form for   reduced-order models of finite element nonlinear structures",
        "authors": [
            "Alessandra Vizzaccaro",
            "Yichang Shen",
            "Loïc Salles",
            "Jiří Blahoš",
            "Cyril Touzé"
        ],
        "summary": "The direct computation of the third-order normal form for a geometrically nonlinear structure discretised with the finite element (FE) method, is detailed. The procedure allows to define a nonlinear mapping in order to derive accurate reduced-order models (ROM) relying on invariant manifold theory. The proposed reduction strategy is direct and simulation free, in the sense that it allows to pass from physical coordinates (FE nodes) to normal coordinates, describing the dynamics in an invariant-based span of the phase space. The number of master modes for the ROM is not a priori limited since a complete change of coordinate is proposed. The underlying theory ensures the quality of the predictions thanks to the invariance property of the reduced subspace, together with their curvatures in phase space that accounts for the nonresonant nonlinear couplings. The method is applied to a beam discretised with 3D elements and shows its ability in recovering internal resonance at high energy. Then a fan blade model is investigated and the correct prediction given by the ROMs are assessed and discussed. A method is proposed to approximate an aggregate value for the damping, that takes into account the damping coefficients of all the slave modes, and also using the Rayleigh damping model as input. Frequency-response curves for the beam and the blades are then exhibited, showing the accuracy of the proposed method.",
        "published": "2020-09-25T11:53:07Z",
        "link": "http://arxiv.org/abs/2009.12145v1",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Enhanced 3D Myocardial Strain Estimation from Multi-View 2D CMR Imaging",
        "authors": [
            "Mohamed Abdelkhalek",
            "Heba Aguib",
            "Mohamed Moustafa",
            "Khalil Elkhodary"
        ],
        "summary": "In this paper, we propose an enhanced 3D myocardial strain estimation procedure, which combines complementary displacement information from multiple orientations of a single imaging modality (untagged CMR SSFP images). To estimate myocardial strain across the left ventricle, we register the sets of short-axis, four-chamber and two-chamber views via a 2D non-rigid registration algorithm implemented in a commercial software (Segment, Medviso). We then create a series of interpolating functions for the three orthogonal directions of motion and use them to deform a tetrahedral mesh representation of a patient-specific left ventricle. Additionally, we correct for overestimation of displacement by introducing a weighting scheme that is based on displacement along the long axis. The procedure was evaluated on the STACOM 2011 dataset containing CMR SSFP images for 16 healthy volunteers. We show increased accuracy in estimating the three strain components (radial, circumferential, longitudinal) compared to reported results in the challenge, for the imaging modality of interest (SSFP). Our peak strain estimates are also significantly closer to reported measurements from studies of a larger cohort in the literature and our own ground truth measurements using Segment Strain Analysis Module. Our proposed procedure provides a relatively fast and simple method to improve 2D tracking results, with the added flexibility in either deforming a reconstructed mesh model from other image modalities or using the built-in CMR mesh reconstruction procedure. Our, proposed scheme presents a deforming patient-specific model of the left ventricle, using the commonest imaging modality , routinely administered in clinical settings, without requiring additional or specialized imaging protocols.",
        "published": "2020-09-25T22:47:50Z",
        "link": "http://arxiv.org/abs/2009.12466v2",
        "categories": [
            "eess.IV",
            "cs.CE",
            "cs.CV",
            "I.3; I.4; I.6; J.3"
        ]
    },
    {
        "title": "Additive manufacturing introduced substructure and computational   determination of metamaterials parameters by means of the asymptotic   homogenization",
        "authors": [
            "Bilen Emek Abali",
            "Emilio Barchiesi"
        ],
        "summary": "Metamaterials exhibit materials response deviation from conventional elasticity. This phenomenon is captured by the generalized elasticity as a result of extending the theory at the expense of introducing additional parameters. These parameters are linked to internal length scales. Describing on a macroscopic level a material possessing a substructure at a microscopic length scale calls for introducing additional constitutive parameters. Therefore, in principle, an asymptotic homogenization is feasible to determine these parameters given an accurate knowledge on the substructure. Especially in additive manufacturing, known under the infill ratio, topology optimization introduces a substructure leading to higher order terms in mechanical response. Hence, weight reduction creates a metamaterial with an accurately known substructure. Herein, we develop a computational scheme using both scales for numerically identifying metamaterials parameters. As a specific example we apply it on a honeycomb substructure and discuss the infill ratio. Such a computational approach is applicable to a wide class substructures and makes use of open-source codes; we make it publicly available for a transparent scientific exchange.",
        "published": "2020-09-26T13:29:27Z",
        "link": "http://arxiv.org/abs/2009.12589v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Aerostructural Wing Shape Optimization assisted by Algorithmic   Differentiation",
        "authors": [
            "Rocco Bombardieri",
            "Rauno Cavallaro",
            "Ruben Sanchez",
            "Nicolas R. Gauger"
        ],
        "summary": "With more efficient structures, last trends in aeronautics have witnessed an increased flexibility of wings, calling for adequate design and optimization approaches. To correctly model the coupled physics, aerostructural optimization has progressively become more important, being nowadays performed also considering higher-fidelity discipline methods, i.e., CFD for aerodynamics and FEM for structures. In this paper a methodology for high-fidelity gradient-based aerostructural optimization of wings, including aerodynamic and structural nonlinearities, is presented. The main key feature of the method is its modularity: each discipline solver, independently employing algorithmic differentiation for the evaluation of adjoint-based sensitivities, is interfaced at high-level by means of a wrapper to both solve the aerostructural primal problem and evaluate exact discrete gradients of the coupled problem. The implemented capability, ad-hoc created to demonstrate the methodology, and freely available within the open-source SU2 multiphysics suite, is applied to perform aerostructural optimization of aeroelastic test cases based on the ONERA M6 and NASA CRM wings. Single-point optimizations, employing Euler or RANS flow models, are carried out to find wing optimal outer mold line in terms of aerodynamic efficiency. Results remark the importance of taking into account the aerostructural coupling when performing wing shape optimization.",
        "published": "2020-09-26T19:17:29Z",
        "link": "http://arxiv.org/abs/2009.12669v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Fitting Cyclic Experimental Load-Deformation Data to The Pivot   Hysteresis Model Using Genetic Algorithm",
        "authors": [
            "Mirsalar Kamari",
            "Oguz Gunes"
        ],
        "summary": "Understanding the linear or nonlinear relationship between load and deformation in structural materials or structural frames is a key to a proper and a well-represented simulation. This research is dedicated to model a cyclic load-deformation hysteresis relationship, captured from experimental results, and utilize it to represent the cyclic hysteresis data. The Genetic Algorithm is used to find the best parameters to introduce the model and to minimize the deviation between the simulation and the experimental results. In other words, the parameters associated with the loading response of any displacement pattern, are found, while minimizing the deviation between simulation loading response and the loading data carried out from the experiment. First, to reduce the data size recorded with measuring devices or Linear Variable Differential Transformers (LVDTs in short), a data resampling technic is proposed. Second, the resampled data is used in Genetic Algorithm to seek for the best parameters to describe the model. This method could be used to train models to predict the capacity and performance of a materials and frames when they are exposed to any deformation patterns. Numerous examples are shown at the end of the paper.",
        "published": "2020-09-28T09:10:31Z",
        "link": "http://arxiv.org/abs/2009.13155v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Microstructure-informed reduced modes synthesized with Wang tiles and   the Generalized Finite Element Method",
        "authors": [
            "M. Doškář",
            "J. Zeman",
            "P. Krysl",
            "J. Novák"
        ],
        "summary": "A recently introduced representation by a set of Wang tiles -- a generalization of the traditional Periodic Unit Cell based approach -- serves as a reduced geometrical model for materials with stochastic heterogeneous microstructure, enabling an efficient synthesis of microstructural realizations. To facilitate macroscopic analyses with a fully resolved microstructure generated with Wang tiles, we develop a reduced order modelling scheme utilizing pre-computed characteristic features of the tiles. In the offline phase, inspired by the computational homogenization, we extract continuous fluctuation fields from the compressed microstructural representation as responses to generalized loading represented by the first- and second-order macroscopic gradients. In the online phase, using the ansatz of the Generalized Finite Element Method, we combine these fields with a coarse finite element discretization to create microstructure-informed reduced modes specific for a given macroscopic problem. Considering a two-dimensional scalar elliptic problem, we demonstrate that our scheme delivers less than a 3% error in both the relative $L_2$ and energy norms with only 0.01% of the unknowns when compared to the fully resolved problem. Accuracy can be further improved by locally refining the macroscopic discretization and/or employing more pre-computed fluctuation fields. Finally, unlike the standard snapshot-based reduced-order approaches, our scheme handles significant changes in the macroscopic geometry or loading without the need for recalculating the offline phase, because the fluctuation fields are extracted without any prior knowledge on the macroscopic problem.",
        "published": "2020-09-28T20:51:09Z",
        "link": "http://arxiv.org/abs/2010.02690v1",
        "categories": [
            "cond-mat.mtrl-sci",
            "cs.CE",
            "physics.comp-ph"
        ]
    },
    {
        "title": "A novel method for inference of chemical compounds with prescribed   topological substructures based on integer programming",
        "authors": [
            "Tatsuya Akutsu",
            "Hiroshi Nagamochi"
        ],
        "summary": "Analysis of chemical graphs is becoming a major research topic in computational molecular biology due to its potential applications to drug design. One of the major approaches in such a study is inverse quantitative structure activity/property relationships (inverse QSAR/QSPR) analysis, which is to infer chemical structures from given chemical activities/properties. Recently, a novel framework has been proposed for inverse QSAR/QSPR using both artificial neural networks (ANN) and mixed integer linear programming (MILP). This method consists of a prediction phase and an inverse prediction phase. In the first phase, a feature vector $f(G)$ of a chemical graph $G$ is introduced and a prediction function $\\psi_{\\mathcal{N}}$ on a chemical property $\\pi$ is constructed with an ANN $\\mathcal{N}$. In the second phase, given a target value $y^*$ of the chemical property $\\pi$, a feature vector $x^*$ is inferred by solving an MILP formulated from the trained ANN $\\mathcal{N}$ so that $\\psi_{\\mathcal{N}}(x^*)$ is equal to $y^*$ and then a set of chemical structures $G^*$ such that $f(G^*)= x^*$ is enumerated by a graph enumeration algorithm. The framework has been applied to chemical compounds with a rather abstract topological structure such as acyclic or monocyclic graphs and graphs with a specified polymer topology with cycle index up to 2.   In this paper, we propose a new flexible modeling method to the framework so that we can specify a topological substructure of graphs and a partial assignment of chemical elements and bond-multiplicity to a target graph.",
        "published": "2020-09-29T01:49:28Z",
        "link": "http://arxiv.org/abs/2010.09203v4",
        "categories": [
            "cs.CE",
            "math.CO"
        ]
    },
    {
        "title": "Topological feature study of slope failure process via persistent   homology-based machine learning",
        "authors": [
            "Shengdong Zhang",
            "Shihui You",
            "Longfei Chen",
            "Xiaofei Liu"
        ],
        "summary": "Using software UDEC to simulate the instability failure process of slope under seismic load, studing the dynamic response of slope failure, obtaining the deformation characteristics and displacement cloud map of slope, then analyzing the instability state of slope by using the theory of persistent homology, generates bar code map and extracts the topological characteristics of slope from bar code map. The topological characteristics corresponding to the critical state of slope instability are found, and the relationship between topological characteristics and instability evolution is established. Finally, it provides a topological research tool for slope failure prediction. The results show that the change of the longest Betti 1 bar code reflects the evolution process of the slope and the law of instability failure. Using discrete element method and persistent homology theory to study the failure characteristics of slope under external load can better understand the failure mechanism of slope, provide theoretical basis for engineering protection, and also provide a new mathematical method for slope safety design and disaster prediction research.",
        "published": "2020-09-29T11:39:24Z",
        "link": "http://arxiv.org/abs/2010.00391v1",
        "categories": [
            "physics.geo-ph",
            "cs.CE"
        ]
    },
    {
        "title": "Computational framework for real-time diagnostics and prognostics of   aircraft actuation systems",
        "authors": [
            "Pier Carlo Berri",
            "Matteo D. L. Dalla Vedova",
            "Laura Mainini"
        ],
        "summary": "Prognostics and Health Management (PHM) are emerging approaches to product life cycle that will maintain system safety and improve reliability, while reducing operating and maintenance costs. This is particularly relevant for aerospace systems, where high levels of integrity and high performances are required at the same time. We propose a novel strategy for the nearly real-time Fault Detection and Identification (FDI) of a dynamical assembly, and for the estimation of Remaining Useful Life (RUL) of the system. The availability of a timely estimate of the health status of the system will allow for an informed adaptive planning of maintenance and a dynamical reconfiguration of the mission profile, reducing operating costs and improving reliability. This work addresses the three phases of the prognostic flow - namely (1) signal acquisition, (2) Fault Detection and Identification, and (3) Remaining Useful Life estimation - and introduces a computationally efficient procedure suitable for real-time, on-board execution. To achieve this goal, we propose to combine information from physical models of different fidelity with machine learning techniques to obtain efficient representations (surrogate models) suitable for nearly real-time applications. Additionally, we propose an importance sampling strategy and a novel approach to model damage propagation for dynamical systems. The methodology is assessed for the FDI and RUL estimation of an aircraft electromechanical actuator (EMA) for secondary flight controls. The results show that the proposed method allows for a high precision in the evaluation of the system RUL, while outperforming common model-based techniques in terms of computational time.",
        "published": "2020-09-30T12:53:07Z",
        "link": "http://arxiv.org/abs/2009.14645v1",
        "categories": [
            "cs.CE",
            "cs.LG",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Finite element solution of nonlocal Cahn-Hilliard equations with   feedback control time step size adaptivity",
        "authors": [
            "Gabriel F. Barros",
            "Adriano M. A. Côrtes",
            "Alvaro L. G. A. Coutinho"
        ],
        "summary": "In this study, we evaluate the performance of feedback control-based time step adaptivity schemes for the nonlocal Cahn-Hilliard equation derived from the Ohta-Kawasaki free energy functional. The temporal adaptivity scheme is recast under the linear feedback control theory equipped with an error estimation that extrapolates the solution obtained from an energy-stable, fully implicit time marching scheme. We test three time step controllers with different properties: a simple Integral controller, a complete Proportional-Integral-Derivative controller, and the PC11 predictive controller. We assess the performance of the adaptive schemes for the nonlocal Cahn-Hilliard equation in terms of the number of time steps required for the complete simulation and the computational effort measured by the required number of nonlinear and linear solver iterations. We also present numerical evidence of mass conservation and free energy decay for simulations with the three different time step controllers. The PC11 predictive controller is the best in all three-dimensional test cases.",
        "published": "2020-09-30T15:24:58Z",
        "link": "http://arxiv.org/abs/2009.14739v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Emulating the First Principles of Matter: A Probabilistic Roadmap",
        "authors": [
            "Jianzhong Wu",
            "Mengyang Gu"
        ],
        "summary": "This chapter provides a tutorial overview of first principles methods to describe the properties of matter at the ground state or equilibrium. It begins with a brief introduction to quantum and statistical mechanics for predicting the electronic structure and diverse static properties of of many-particle systems useful for practical applications. Pedagogical examples are given to illustrate the basic concepts and simple applications of quantum Monte Carlo and density functional theory -- two representative methods commonly used in the literature of first principles modeling. In addition, this chapter highlights the practical needs for the integration of physics-based modeling and data-science approaches to reduce the computational cost and expand the scope of applicability. A special emphasis is placed on recent developments of statistical surrogate models to emulate first principles calculation from a probabilistic point of view. The probabilistic approach provides an internal assessment of the approximation accuracy of emulation that quantifies the uncertainty in predictions. Various recent advances toward this direction establish a new marriage between Gaussian processes and first principles calculation, with physical properties, such as translational, rotational, and permutation symmetry, naturally encoded in new kernel functions. Finally, it concludes with some prospects on future advances in the field toward faster yet more accurate computation leveraging a synergetic combination {of} novel theoretical concepts and efficient numerical algorithms.",
        "published": "2020-09-30T18:50:36Z",
        "link": "http://arxiv.org/abs/2010.05942v1",
        "categories": [
            "cs.CE",
            "physics.comp-ph",
            "stat.AP"
        ]
    },
    {
        "title": "A machine learning framework for LES closure terms",
        "authors": [
            "Marius Kurz",
            "Andrea Beck"
        ],
        "summary": "In the present work, we explore the capability of artificial neural networks (ANN) to predict the closure terms for large eddy simulations (LES) solely from coarse-scale data. To this end, we derive a consistent framework for LES closure models, with special emphasis laid upon the incorporation of implicit discretization-based filters and numerical approximation errors. We investigate implicit filter types, which are inspired by the solution representation of discontinuous Galerkin and finite volume schemes and mimic the behaviour of the discretization operator, and a global Fourier cutoff filter as a representative of a typical explicit LES filter. Within the perfect LES framework, we compute the exact closure terms for the different LES filter functions from direct numerical simulation results of decaying homogeneous isotropic turbulence. Multiple ANN with a multilayer perceptron (MLP) or a gated recurrent unit (GRU) architecture are trained to predict the computed closure terms solely from coarse-scale input data. For the given application, the GRU architecture clearly outperforms the MLP networks in terms of accuracy, whilst reaching up to 99.9% cross-correlation between the networks' predictions and the exact closure terms for all considered filter functions. The GRU networks are also shown to generalize well across different LES filters and resolutions. The present study can thus be seen as a starting point for the investigation of data-based modeling approaches for LES, which not only include the physical closure terms, but account for the discretization effects in implicitly filtered LES as well.",
        "published": "2020-10-01T08:42:37Z",
        "link": "http://arxiv.org/abs/2010.03030v1",
        "categories": [
            "physics.comp-ph",
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "Phase-field Fracture Modelling of Thin Monolithic and Laminated Glass   Plates under Quasi-static Bending",
        "authors": [
            "Jaroslav Schmidt",
            "Alena Zemanová",
            "Jan Zeman",
            "Michal Šejnoha"
        ],
        "summary": "A phase-field description of brittle fracture is employed in the reported four-point bending analyses of monolithic and laminated glass plates. Our aims are: (i) to compare different phase-field fracture formulations applied to thin glass plates, (ii) to assess the consequences of the dimensional reduction of the problem and mesh density and refinement, and (iii) to validate for quasi-static loading the time/temperature-dependent material properties we derived recently for two commonly used polymer foils made of Polyvinyl Butyral or Ethylene-Vinyl Acetate. As the nonlinear response prior to fracture, typical of the widely used Bourdin-Francfort-Marigo model, can lead to a significant overestimation of the response of thin plates under bending, the numerical study investigates two additional phase-field fracture models providing the linear elastic phase of the stress-strain diagram. The typical values of the critical fracture energy and tensile strength of glass lead to a phase-field length-scale parameter that is challenging to resolve in the numerical simulations. So, we show how to determine the fracture energy concerning the applied dimensional reduction and the value of the length-scale parameter relative to the thickness of the plate. The comparison shows that the phase-field models provide very good agreement with the measured stresses and resistance of laminated glass, despite the fact that only one/two cracks localised using the quasi-static analysis, whereas multiple cracks evolved during the experiment. It has also been observed that the stiffness and resistance of the partially fractured laminated glass can be well approximated using a 2D plane-stress model with initially predefined cracks, which provides a better estimation than the one-glass-layer limit.}",
        "published": "2020-10-01T13:16:32Z",
        "link": "http://arxiv.org/abs/2010.00375v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Modeling all alternative solutions for highly renewable energy systems",
        "authors": [
            "Tim T. Pedersen",
            "Marta Victoria",
            "Morten G. Rasmussen",
            "Gorm B. Andresen"
        ],
        "summary": "As the world is transitioning towards highly renewable energy systems, advanced tools are needed to analyze such complex networks. Energy system design is, however, challenged by real-world objective functions consisting of a blurry mix of technical and socioeconomic agendas, with limitations that cannot always be clearly stated. As a result, it is highly likely that solutions which are techno-economically suboptimal will be preferable. Here, we present a method capable of determining the continuum containing all techno-economically near-optimal solutions, moving the field of energy system modeling from discrete solutions to a new era where continuous solution ranges are available. The presented method is applied to study a range of technical and socioeconomic metrics on a model of the European electricity system. The near-optimal region is found to be relatively flat allowing for solutions that are slightly more expensive than the optimum but better in terms of equality, land use, and implementation time.",
        "published": "2020-10-02T07:58:41Z",
        "link": "http://arxiv.org/abs/2010.00836v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Physics-based Reconstruction Methods for Magnetic Resonance Imaging",
        "authors": [
            "Xiaoqing Wang",
            "Zhengguo Tan",
            "Nick Scholand",
            "Volkert Roeloffs",
            "Martin Uecker"
        ],
        "summary": "Conventional Magnetic Resonance Imaging (MRI) is hampered by long scan times and only qualitative image contrasts that prohibit a direct comparison between different systems. To address these limitations, model-based reconstructions explicitly model the physical laws that govern the MRI signal generation. By formulating image reconstruction as an inverse problem, quantitative maps of the underlying physical parameters can then be extracted directly from efficiently acquired k-space signals without intermediate image reconstruction -- addressing both shortcomings of conventional MRI at the same time. This review will discuss basic concepts of model-based reconstructions and report about our experience in developing several model-based methods over the last decade using selected examples that are provided complete with data and code.",
        "published": "2020-10-03T18:13:15Z",
        "link": "http://arxiv.org/abs/2010.01403v3",
        "categories": [
            "eess.IV",
            "cs.CE",
            "physics.comp-ph",
            "physics.med-ph"
        ]
    },
    {
        "title": "Learning the aerodynamic design of supercritical airfoils through deep   reinforcement learning",
        "authors": [
            "Runze Li",
            "Yufei Zhang",
            "Haixin Chen"
        ],
        "summary": "The aerodynamic design of modern civil aircraft requires a true sense of intelligence since it requires a good understanding of transonic aerodynamics and sufficient experience. Reinforcement learning is an artificial general intelligence that can learn sophisticated skills by trial-and-error, rather than simply extracting features or making predictions from data. The present paper utilizes a deep reinforcement learning algorithm to learn the policy for reducing the aerodynamic drag of supercritical airfoils. The policy is designed to take actions based on features of the wall Mach number distribution so that the learned policy can be more general. The initial policy for reinforcement learning is pretrained through imitation learning, and the result is compared with randomly generated initial policies. The policy is then trained in environments based on surrogate models, of which the mean drag reduction of 200 airfoils can be effectively improved by reinforcement learning. The policy is also tested by multiple airfoils in different flow conditions using computational fluid dynamics calculations. The results show that the policy is effective in both the training condition and other similar conditions, and the policy can be applied repeatedly to achieve greater drag reduction.",
        "published": "2020-10-05T14:10:14Z",
        "link": "http://arxiv.org/abs/2010.03651v2",
        "categories": [
            "cs.CE",
            "physics.data-an"
        ]
    },
    {
        "title": "Computational frameworks for homogenization and multiscale stability   analyses of nonlinear periodic metamaterials",
        "authors": [
            "Guodong Zhang",
            "Nan Feng",
            "Kapil Khandelwal"
        ],
        "summary": "This paper presents a consistent computational framework for multiscale 1st order finite strain homogenization and stability analyses of rate-independent solids with periodic microstructures. Based on the principle of multiscale virtual power, the homogenization formulation is built on a priori discretized microstructure, and algorithms for computing the matrix representations of the homogenized stresses and tangent moduli are consistently derived. The homogenization results lose their validity at the onset of 1st bifurcation, which can be computed from multiscale stability analysis. The multiscale instabilities include: a) microscale structural instability which is calculated by Bloch wave analysis; and b) macroscale material instability which is calculated by rank-1 convexity checks on the homogenized tangent moduli. Details on the implementation of the Bloch wave analysis are provided, including the selection of the wave vector space and the retrieval of the real-valued buckling mode from the complex-valued Bloch wave. Three methods are detailed for solving the resulted constrained eigenvalue problem - two condensation methods and a null-space based projection method. Both implementations of the homogenization and stability analyses are validated using numerical examples including hyperelastic and elastoplastic metamaterials. Various microscale buckling phenomena are also demonstrated by examining several representative metamaterial examples. Aligned with theoretical results, the numerical results show that the microscopic long wavelength buckling can be equivalently detected by the loss of rank-1 convexity of the homogenized tangent moduli.",
        "published": "2020-10-05T22:29:01Z",
        "link": "http://arxiv.org/abs/2010.02371v1",
        "categories": [
            "cs.CE",
            "nlin.PS"
        ]
    },
    {
        "title": "Learning Mesh-Based Simulation with Graph Networks",
        "authors": [
            "Tobias Pfaff",
            "Meire Fortunato",
            "Alvaro Sanchez-Gonzalez",
            "Peter W. Battaglia"
        ],
        "summary": "Mesh-based simulations are central to modeling complex physical systems in many disciplines across science and engineering. Mesh representations support powerful numerical integration methods and their resolution can be adapted to strike favorable trade-offs between accuracy and efficiency. However, high-dimensional scientific simulations are very expensive to run, and solvers and parameters must often be tuned individually to each system studied. Here we introduce MeshGraphNets, a framework for learning mesh-based simulations using graph neural networks. Our model can be trained to pass messages on a mesh graph and to adapt the mesh discretization during forward simulation. Our results show it can accurately predict the dynamics of a wide range of physical systems, including aerodynamics, structural mechanics, and cloth. The model's adaptivity supports learning resolution-independent dynamics and can scale to more complex state spaces at test time. Our method is also highly efficient, running 1-2 orders of magnitude faster than the simulation on which it is trained. Our approach broadens the range of problems on which neural network simulators can operate and promises to improve the efficiency of complex, scientific modeling tasks.",
        "published": "2020-10-07T13:34:49Z",
        "link": "http://arxiv.org/abs/2010.03409v4",
        "categories": [
            "cs.LG",
            "cs.CE"
        ]
    },
    {
        "title": "Combination of digital signal processing and assembled predictive models   facilitates the rational design of proteins",
        "authors": [
            "David Medina-Ortiz",
            "Sebastian Contreras",
            "Juan Amado-Hinojosa",
            "Jorge Torres-Almonacid",
            "Juan A. Asenjo",
            "Marcelo Navarrete",
            "Álvaro Olivera-Nappa"
        ],
        "summary": "Predicting the effect of mutations in proteins is one of the most critical challenges in protein engineering; by knowing the effect a substitution of one (or several) residues in the protein's sequence has on its overall properties, could design a variant with a desirable function. New strategies and methodologies to create predictive models are continually being developed. However, those that claim to be general often do not reach adequate performance, and those that aim to a particular task improve their predictive performance at the cost of the method's generality. Moreover, these approaches typically require a particular decision to encode the amino acidic sequence, without an explicit methodological agreement in such endeavor. To address these issues, in this work, we applied clustering, embedding, and dimensionality reduction techniques to the AAIndex database to select meaningful combinations of physicochemical properties for the encoding stage. We then used the chosen set of properties to obtain several encodings of the same sequence, to subsequently apply the Fast Fourier Transform (FFT) on them. We perform an exploratory stage of Machine-Learning models in the frequency space, using different algorithms and hyperparameters. Finally, we select the best performing predictive models in each set of properties and create an assembled model. We extensively tested the proposed methodology on different datasets and demonstrated that the generated assembled model achieved notably better performance metrics than those models based on a single encoding and, in most cases, better than those previously reported. The proposed method is available as a Python library for non-commercial use under the GNU General Public License (GPLv3) license.",
        "published": "2020-10-07T16:35:02Z",
        "link": "http://arxiv.org/abs/2010.03516v1",
        "categories": [
            "cs.CE",
            "cs.LG",
            "q-bio.BM"
        ]
    },
    {
        "title": "Solving stochastic inverse problems for property-structure linkages   using data-consistent inversion and machine learning",
        "authors": [
            "Anh Tran",
            "Tim Wildey"
        ],
        "summary": "Determining process-structure-property linkages is one of the key objectives in material science, and uncertainty quantification plays a critical role in understanding both process-structure and structure-property linkages. In this work, we seek to learn a distribution of microstructure parameters that are consistent in the sense that the forward propagation of this distribution through a crystal plasticity finite element model (CPFEM) matches a target distribution on materials properties. This stochastic inversion formulation infers a distribution of acceptable/consistent microstructures, as opposed to a deterministic solution, which expands the range of feasible designs in a probabilistic manner. To solve this stochastic inverse problem, we employ a recently developed uncertainty quantification (UQ) framework based on push-forward probability measures, which combines techniques from measure theory and Bayes rule to define a unique and numerically stable solution. This approach requires making an initial prediction using an initial guess for the distribution on model inputs and solving a stochastic forward problem. To reduce the computational burden in solving both stochastic forward and stochastic inverse problems, we combine this approach with a machine learning (ML) Bayesian regression model based on Gaussian processes and demonstrate the proposed methodology on two representative case studies in structure-property linkages.",
        "published": "2020-10-07T18:49:13Z",
        "link": "http://arxiv.org/abs/2010.03603v4",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Calibration of Elastoplastic Constitutive Model Parameters from   Full-field Data with Automatic Differentiation-based Sensitivities",
        "authors": [
            "Daniel Thomas Seidl",
            "Brian Neal Granzow"
        ],
        "summary": "We present a framework for calibration of parameters in elastoplastic constitutive models that is based on the use of automatic differentiation (AD). The model calibration problem is posed as a partial differential equation-constrained optimization problem where a finite element (FE) model of the coupled equilibrium equation and constitutive model evolution equations serves as the constraint. The objective function quantifies the mismatch between the displacement predicted by the FE model and full-field digital image correlation data, and the optimization problem is solved using gradient-based optimization algorithms. Forward and adjoint sensitivities are used to compute the gradient at considerably less cost than its calculation from finite difference approximations. Through the use of AD, we need only to write the constraints in terms of AD objects, where all of the derivatives required for the forward and inverse problems are obtained by appropriately seeding and evaluating these quantities. We present three numerical examples that verify the correctness of the gradient, demonstrate the AD approach's parallel computation capabilities via application to a large-scale FE model, and highlight the formulation's ease of extensibility to other classes of constitutive models.",
        "published": "2020-10-07T20:57:15Z",
        "link": "http://arxiv.org/abs/2010.03649v5",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A two-stage approach for beam hardening artifact reduction in low-dose   dental CBCT",
        "authors": [
            "T. Bayaraa",
            "C. M. Hyun",
            "T. J. Jang",
            "S. M. Lee",
            "J. K. Seo"
        ],
        "summary": "This paper presents a two-stage method for beam hardening artifact correction of dental cone beam computerized tomography (CBCT). The proposed artifact reduction method is designed to improve the quality of maxillofacial imaging, where soft tissue details are not required. Compared to standard CT, the additional difficulty of dental CBCT comes from the problems caused by offset detector, FOV truncation, and low signal-to-noise ratio due to low X-ray irradiation. To address these problems, the proposed method primarily performs a sinogram adjustment in the direction of enhancing data consistency, considering the situation according to the FOV truncation and offset detector. This sinogram correction algorithm significantly reduces beam hardening artifacts caused by high-density materials such as teeth, bones, and metal implants, while tending to amplify special types of noise. To suppress such noise, a deep convolutional neural network is complementarily used, where CT images adjusted by the sinogram correction are used as the input of the neural network. Numerous experiments validate that the proposed method successfully reduces beam hardening artifacts and, in particular, has the advantage of improving the image quality of teeth, associated with maxillofacial CBCT imaging.",
        "published": "2020-10-08T05:48:31Z",
        "link": "http://arxiv.org/abs/2010.03778v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Yield Optimization using Hybrid Gaussian Process Regression and a   Genetic Multi-Objective Approach",
        "authors": [
            "Mona Fuhrländer",
            "Sebastian Schöps"
        ],
        "summary": "Quantification and minimization of uncertainty is an important task in the design of electromagnetic devices, which comes with high computational effort. We propose a hybrid approach combining the reliability and accuracy of a Monte Carlo analysis with the efficiency of a surrogate model based on Gaussian Process Regression. We present two optimization approaches. An adaptive Newton-MC to reduce the impact of uncertainty and a genetic multi-objective approach to optimize performance and robustness at the same time. For a dielectrical waveguide, used as a benchmark problem, the proposed methods outperform classic approaches.",
        "published": "2020-10-08T14:44:37Z",
        "link": "http://arxiv.org/abs/2010.04028v1",
        "categories": [
            "cs.LG",
            "cs.CE",
            "60G15, 60H35, 78M31, 78M50",
            "G.1.8; G.3; I.6.3; J.2"
        ]
    },
    {
        "title": "MatDRAM: A pure-MATLAB Delayed-Rejection Adaptive Metropolis-Hastings   Markov Chain Monte Carlo Sampler",
        "authors": [
            "Shashank Kumbhare",
            "Amir Shahmoradi"
        ],
        "summary": "Markov Chain Monte Carlo (MCMC) algorithms are widely used for stochastic optimization, sampling, and integration of mathematical objective functions, in particular, in the context of Bayesian inverse problems and parameter estimation. For decades, the algorithm of choice in MCMC simulations has been the Metropolis-Hastings (MH) algorithm. An advancement over the traditional MH-MCMC sampler is the Delayed-Rejection Adaptive Metropolis (DRAM). In this paper, we present MatDRAM, a stochastic optimization, sampling, and Monte Carlo integration toolbox in MATLAB which implements a variant of the DRAM algorithm for exploring the mathematical objective functions of arbitrary-dimensions, in particular, the posterior distributions of Bayesian models in data science, Machine Learning, and scientific inference. The design goals of MatDRAM include nearly-full automation of MCMC simulations, user-friendliness, fully-deterministic reproducibility, and the restart functionality of simulations. We also discuss the implementation details of a technique to automatically monitor and ensure the diminishing adaptation of the proposal distribution of the DRAM algorithm and a method of efficiently storing the resulting simulated Markov chains. The MatDRAM library is open-source, MIT-licensed, and permanently located and maintained as part of the ParaMonte library at https://github.com/cdslaborg/paramonte.",
        "published": "2020-10-08T18:09:09Z",
        "link": "http://arxiv.org/abs/2010.04190v1",
        "categories": [
            "physics.data-an",
            "astro-ph.IM",
            "cs.CE",
            "q-bio.QM",
            "stat.AP"
        ]
    },
    {
        "title": "Accelerated computational micromechanics",
        "authors": [
            "Hao Zhou",
            "Kaushik Bhattacharya"
        ],
        "summary": "We present an approach to solving problems in micromechanics that is amenable to massively parallel calculations through the use of graphical processing units and other accelerators. The problems lead to nonlinear differential equations that are typically second order in space and first order in time. This combination of nonlinearity and nonlocality makes such problems difficult to solve in parallel. However, this combination is a result of collapsing nonlocal, but linear and universal physical laws (kinematic compatibility, balance laws), and nonlinear but local constitutive relations. We propose an operator-splitting scheme inspired by this structure. The governing equations are formulated as (incremental) variational problems, the differential constraints like compatibility are introduced using an augmented Lagrangian, and the resulting incremental variational principle is solved by the alternating direction method of multipliers. The resulting algorithm has a natural connection to physical principles, and also enables massively parallel implementation on structured grids. We present this method and use it to study two examples. The first concerns the long wavelength instability of finite elasticity, and allows us to verify the approach against previous numerical simulations. We also use this example to study convergence and parallel performance. The second example concerns microstructure evolution in liquid crystal elastomers and provides new insights into some counter-intuitive properties of these materials. We use this example to validate the model and the approach against experimental observations.",
        "published": "2020-10-09T05:16:07Z",
        "link": "http://arxiv.org/abs/2010.06697v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Phase field modelling of fracture and fatigue in Shape Memory Alloys",
        "authors": [
            "Marlini Simoes",
            "Emilio Martínez-Pañeda"
        ],
        "summary": "We present a new phase field framework for modelling fracture and fatigue in Shape Memory Alloys (SMAs). The constitutive model captures the superelastic behaviour of SMAs and damage is driven by the elastic and transformation strain energy densities. We consider both the assumption of a constant fracture energy and the case of a fracture energy dependent on the martensitic volume fraction. The framework is implemented in an implicit time integration scheme, with both monolithic and staggered solution strategies. The potential of this formulation is showcased by modelling a number of paradigmatic problems. First, a boundary layer model is used to examine crack tip fields and compute crack growth resistance curves (R-curves). We show that the model is able to capture the main fracture features associated with SMAs, including the toughening effect associated with stress-induced phase transformation. Insight is gained into the role of temperature, material strength, crack density function and fracture energy homogenisation. Secondly, several 2D and 3D boundary value problems are addressed, demonstrating the capabilities of the model in capturing complex cracking phenomena in SMAs, such as unstable crack growth, mixed-mode fracture or the interaction between several cracks. Finally, the model is extended to fatigue and used to capture crack nucleation and propagation in biomedical stents, a paradigmatic application of nitinol SMAs.",
        "published": "2020-10-09T06:51:48Z",
        "link": "http://arxiv.org/abs/2010.04390v1",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA",
            "physics.app-ph"
        ]
    },
    {
        "title": "Gaussian Process (GP)-based Learning Control of Selective Laser Melting   Process",
        "authors": [
            "Farshid Asadi",
            "Alaa A. Olleak",
            "Jingang Yi",
            "Yuebin Guo"
        ],
        "summary": "Selective laser melting (SLM) is one of emerging processes for effective metal additive manufacturing. Due to complex heat exchange and material phase changes, it is challenging to accurately model the SLM dynamics and design robust control of SLM process. In this paper, we first present a data-driven Gaussian process based dynamic model for SLM process and then design a model predictive control to regulate the melt pool size. Physical and process constraints are considered in the controller design. The learning model and control design are tested and validated with high-fidelity finite element simulation. The comparison results with other control design demonstrate the efficacy of the control design.",
        "published": "2020-10-09T17:55:42Z",
        "link": "http://arxiv.org/abs/2010.04712v2",
        "categories": [
            "math.OC",
            "cs.CE"
        ]
    },
    {
        "title": "Exponential time integrators for unsteady advection-diffusion problems   on refined meshes",
        "authors": [
            "M. A. Botchev"
        ],
        "summary": "Time integration of advection dominated advection-diffusion problems on refined meshes can be a challenging task, since local refinement can lead to a severe time step restriction, whereas standard implicit time stepping is usually hardly suitable for treating advection terms. We show that exponential time integrators can be an efficient, yet conceptually simple, option in this case. Our comparison includes three exponential integrators and one conventional scheme, the two-stage Rosenbrock method ROS2 which has been a popular alternative to splitting methods for solving advection-diffusion problems.",
        "published": "2020-10-09T18:28:20Z",
        "link": "http://arxiv.org/abs/2010.04756v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "physics.comp-ph",
            "65M20, 65F60, 65L06"
        ]
    },
    {
        "title": "A Locally Conservative Mixed Finite Element Framework for Coupled   Hydro-Mechanical-Chemical Processes in Heterogeneous Porous Media",
        "authors": [
            "T. Kadeethum",
            "S. Lee",
            "F. Ballarin",
            "J. Choo",
            "H. M. Nick"
        ],
        "summary": "This paper presents a mixed finite element framework for coupled hydro-mechanical-chemical processes in heterogeneous porous media. The framework combines two types of locally conservative discretization schemes: (1) an enriched Galerkin method for reactive flow, and (2) a three-field mixed finite element method for coupled fluid flow and solid deformation. This combination ensures local mass conservation, which is critical to flow and transport in heterogeneous porous media, with a relatively affordable computational cost. A particular class of the framework is constructed for calcite precipitation/dissolution reactions, incorporating their nonlinear effects on the fluid viscosity and solid deformation. Linearization schemes and algorithms for solving the nonlinear algebraic system are also presented. Through numerical examples of various complexity, we demonstrate that the proposed framework is a robust and efficient computational method for simulation of reactive flow and transport in deformable porous media, even when the material properties are strongly heterogeneous and anisotropic.",
        "published": "2020-10-10T13:27:49Z",
        "link": "http://arxiv.org/abs/2010.04994v1",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Total heat flux convergence in the calculation of 2d and 3d heat losses   through building elements",
        "authors": [
            "Sanjin Gumbarević",
            "Bojan Milovanović",
            "Mergim Gaši",
            "Marina Bagarić"
        ],
        "summary": "Heat losses through the building envelope is one of the key factors in the calculation of the building energy balance. If steady-state heat conduction is observed, which is commonly used to assess the heat losses in building, there is an analytical solution for one-dimensional problem. For two and three-dimensional problems, especially for the complex geometry cases, one must use numerical methods to solve the heat conduction equation. To standardise two and three-dimensional calculation of heat losses through building elements, ISO 10211 standard can be used. The standard has four benchmark examples with criteria that must be satisfied to declare a method as a high-precision calculation method. A problem occurs for Case 1 of benchmark test because the analysed problem has a singular point due to discretely assigned Dirichlet boundary conditions. The reliability of the results around the singular point could be improved by the refinement of the mesh in the area around the singular point, but as a point of interest is the total heat flux that is entering the building element, and it must converge between subdivisions, this method is not good since the reliable result cannot be reached. The problem for the convergence is in the marginal node because the temperature gradient in it increases as the temperature difference remains constant and the distance between the corresponding nodes decreases. For that reason, Case 1 from the benchmark is inadequate because even if there is a discontinuity in temperature field on the boundary, there is an interval in which this change is to happen, and the heat flux has a theoretical limit which is not infinity. From the results of this research, it is shown that one should neglect a certain number of singular points in order to achieve the tolerance given by the standard since the temperature further from the marginal node is stable for any subdivision.",
        "published": "2020-10-11T10:11:05Z",
        "link": "http://arxiv.org/abs/2010.05207v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Mandibular Teeth Movement Variations in Tipping Scenario: A Finite   Element Study on Several Patients",
        "authors": [
            "Torkan Gholamalizadeh",
            "Sune Darkner",
            "Paolo Maria Cattaneo",
            "Peter Søndergaard",
            "Kenny Erleben"
        ],
        "summary": "Previous studies on computational modeling of tooth movement in orthodontic treatments are limited to a single model and fail in generalizing the simulation results to other patients. To this end, we consider multiple patients and focus on tooth movement variations under the identical load and boundary conditions both for intra- and inter-patient analyses. We introduce a novel computational analysis tool based on finite element models (FEMs) addressing how to assess initial tooth displacement in the mandibular dentition across different patients for uncontrolled tipping scenarios with different load magnitudes applied to the mandibular dentition. This is done by modeling the movement of each patient's tooth as a nonlinear function of both load and tooth size. As the size of tooth can affect the resulting tooth displacement, a combination of two clinical biomarkers obtained from the tooth anatomy, i.e., crown height and root volume, is considered to make the proposed model generalizable to different patients and teeth.",
        "published": "2020-10-11T14:51:21Z",
        "link": "http://arxiv.org/abs/2010.05258v1",
        "categories": [
            "cs.CE",
            "stat.AP"
        ]
    },
    {
        "title": "Geomechanical simulation of energy storage in salt formations",
        "authors": [
            "Kishan Ramesh Kumar",
            "Artur A. Makhmutov",
            "Christopher J. Spiers",
            "Hadi Hajibeygi"
        ],
        "summary": "A promising option for storing large-scale quantities of green gases (e.g., hydrogen) is in subsurface rock salt caverns. The mechanical performance of salt caverns utilized for long-term subsurface energy storage plays a significant role in long-term stability and serviceability. However, rock salt undergoes non-linear creep deformation due to long-term loading caused by subsurface storage. Salt caverns have complex geometries and the geological domain surrounding salt caverns has a vast amount of material heterogeneity. To safely store gases in caverns, a thorough analysis of the geological domain becomes crucial. To date, few studies have attempted to analyze the influence of geometrical and material heterogeneity on the state of stress in salt caverns subjected to long-term loading. In this work, we present a rigorous and systematic modeling study to quantify the impact of heterogeneity on the deformation of salt caverns and quantify the state of stress around the caverns. A 2D finite element simulator was developed to consistently account for the non-linear creep deformation and also to model tertiary creep. The computational scheme was benchmarked with the already existing experimental study. The impact of cyclic loading on the cavern was studied considering maximum and minimum pressure that depends on lithostatic pressure. The influence of geometric heterogeneity such as irregularly-shaped caverns and material heterogeneity, which involves different elastic and creep properties of the different materials in the geological domain, is rigorously studied and quantified. Moreover, multi-cavern simulations are conducted to investigate the influence of a cavern on the adjacent caverns.",
        "published": "2020-10-12T18:37:49Z",
        "link": "http://arxiv.org/abs/2010.06581v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "An Auto-Generated Geometry-Based Discrete Finite Element Model for   Damage Evolution in Composite Laminates with Arbitrary Stacking Sequence",
        "authors": [
            "Jiakun Liu",
            "Stuart Leigh Phoenix"
        ],
        "summary": "Stiffness degradation and progressive failure of composite laminates are complex processes involving evolution and multi-mode interactions among fiber fractures, intra-ply matrix cracks and inter-ply delaminations. This paper presents a novel finite element model capable of explicitly treating such discrete failures in laminates of random layup. Matching of nodes is guaranteed at potential crack bifurcations to ensure correct displacement jumps near crack tips and explicit load transfer among cracks. The model is entirely geometry-based (no mesh prerequisite) with distinct segments assembled together using surface-based tie constraints, and thus requires no element partitioning or enrichment. Several numerical examples are included to demonstrate the model's ability to generate results that are in qualitative and quantitative agreement with experimental observations on both damage evolution and tensile strength of specimens. The present model is believed unique in realizing simultaneous and accurate coupling of all three types of failures in laminates having arbitrary ply angles and layup.",
        "published": "2020-10-12T20:27:59Z",
        "link": "http://arxiv.org/abs/2010.06009v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "A Physics-Guided Neural Network Framework for Elastic Plates: Comparison   of Governing Equations-Based and Energy-Based Approaches",
        "authors": [
            "Wei Li",
            "Martin Z. Bazant",
            "Juner Zhu"
        ],
        "summary": "One of the obstacles hindering the scaling-up of the initial successes of machine learning in practical engineering applications is the dependence of the accuracy on the size of the database that \"drives\" the algorithms. Incorporating the already-known physical laws into the training process can significantly reduce the size of the required database. In this study, we establish a neural network-based computational framework to characterize the finite deformation of elastic plates, which in classic theories is described by the F\\\"oppl--von K\\'arm\\'an (FvK) equations with a set of boundary conditions (BCs). A neural network is constructed by taking the spatial coordinates as the input and the displacement field as the output to approximate the exact solution of the FvK equations. The physical information (PDEs, BCs, and potential energies) is then incorporated into the loss function, and a pseudo dataset is sampled without knowing the exact solution to finally train the neural network. The prediction accuracy of the modeling framework is carefully examined by applying it to four different loading cases: in-plane tension with non-uniformly distributed stretching forces, in-plane central-hole tension, out-of-plane deflection, and buckling under compression. \\hl{Three ways of formulating the loss function are compared: 1) purely data-driven, 2) PDE-based, and 3) energy-based. Through the comparison with the finite element simulations, it is found that all the three approaches can characterize the elastic deformation of plates with a satisfactory accuracy if trained properly. Compared with incorporating the PDEs and BCs in the loss, using the total potential energy shows certain advantage in terms of the simplicity of hyperparameter tuning and the computational efficiency.",
        "published": "2020-10-12T21:51:35Z",
        "link": "http://arxiv.org/abs/2010.06050v3",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "IMPECCABLE: Integrated Modeling PipelinE for COVID Cure by Assessing   Better LEads",
        "authors": [
            "Aymen Al Saadi",
            "Dario Alfe",
            "Yadu Babuji",
            "Agastya Bhati",
            "Ben Blaiszik",
            "Thomas Brettin",
            "Kyle Chard",
            "Ryan Chard",
            "Peter Coveney",
            "Anda Trifan",
            "Alex Brace",
            "Austin Clyde",
            "Ian Foster",
            "Tom Gibbs",
            "Shantenu Jha",
            "Kristopher Keipert",
            "Thorsten Kurth",
            "Dieter Kranzlmüller",
            "Hyungro Lee",
            "Zhuozhao Li",
            "Heng Ma",
            "Andre Merzky",
            "Gerald Mathias",
            "Alexander Partin",
            "Junqi Yin",
            "Arvind Ramanathan",
            "Ashka Shah",
            "Abraham Stern",
            "Rick Stevens",
            "Li Tan",
            "Mikhail Titov",
            "Aristeidis Tsaris",
            "Matteo Turilli",
            "Huub Van Dam",
            "Shunzhou Wan",
            "David Wifling"
        ],
        "summary": "The drug discovery process currently employed in the pharmaceutical industry typically requires about 10 years and $2-3 billion to deliver one new drug. This is both too expensive and too slow, especially in emergencies like the COVID-19 pandemic. In silicomethodologies need to be improved to better select lead compounds that can proceed to later stages of the drug discovery protocol accelerating the entire process. No single methodological approach can achieve the necessary accuracy with required efficiency. Here we describe multiple algorithmic innovations to overcome this fundamental limitation, development and deployment of computational infrastructure at scale integrates multiple artificial intelligence and simulation-based approaches. Three measures of performance are:(i) throughput, the number of ligands per unit time; (ii) scientific performance, the number of effective ligands sampled per unit time and (iii) peak performance, in flop/s. The capabilities outlined here have been used in production for several months as the workhorse of the computational infrastructure to support the capabilities of the US-DOE National Virtual Biotechnology Laboratory in combination with resources from the EU Centre of Excellence in Computational Biomedicine.",
        "published": "2020-10-13T17:49:33Z",
        "link": "http://arxiv.org/abs/2010.06574v1",
        "categories": [
            "cs.DC",
            "cs.CE",
            "q-bio.QM"
        ]
    },
    {
        "title": "Enriched Galerkin Discretization for Modeling Poroelasticity and   Permeability Alteration in Heterogeneous Porous Media",
        "authors": [
            "T. Kadeethum",
            "H. M. Nick",
            "S. Lee",
            "F. Ballarin"
        ],
        "summary": "Accurate simulation of the coupled fluid flow and solid deformation in porous media is challenging, especially when the media permeability and storativity are heterogeneous. We apply the enriched Galerkin (EG) finite element method for the Biot's system. Block structure used to compose the enriched space and linearization and iterative schemes employed to solve the coupled media permeability alteration are illustrated. The open-source platform used to build the block structure is presented and illustrate that it helps the enriched Galerkin method easily adaptable to any existing discontinuous Galerkin codes. Subsequently, we compare the EG method with the classic continuous Galerkin (CG) and discontinuous Galerkin (DG) finite element methods. While these methods provide similar approximations for the pressure solution of Terzaghi's one-dimensional consolidation, the CG method produces spurious oscillations in fluid pressure and volumetric strain solutions at material interfaces that have permeability contrast and does not conserve mass locally. As a result, the flux approximation of the CG method is significantly different from the one of EG and DG methods, especially for the soft materials. The difference of flux approximation between EG and DG methods is insignificant; still, the EG method demands approximately two and three times fewer degrees of freedom than the DG method for two- and three-dimensional geometries, respectively. Lastly, we illustrate that the EG method produces accurate results even for much coarser meshes.",
        "published": "2020-10-13T19:41:04Z",
        "link": "http://arxiv.org/abs/2010.06653v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Fusing electrical and elasticity imaging",
        "authors": [
            "Andreas Hauptmann",
            "Danny Smyl"
        ],
        "summary": "Electrical and elasticity imaging are promising modalities for a suite of different applications including medical tomography, non-destructive testing, and structural health monitoring. These emerging modalities are capable of providing remote, non-invasive, and low cost opportunities. Unfortunately, both modalities are severely ill-posed nonlinear inverse problems, susceptive to noise and modelling errors. Nevertheless, the ability to incorporate complimentary data sets obtained simultaneously offers mutually-beneficial information. By fusing electrical and elastic modalities as a joint problem we are afforded the possibility to stabilise the inversion process via the utilisation of auxiliary information from both modalities as well as joint structural operators. In this study, we will discuss a possible approach to combine electrical and elasticity imaging in a joint reconstruction problem giving rise to novel multi-modality applications for use in both medical and structural engineering.",
        "published": "2020-10-14T07:19:10Z",
        "link": "http://arxiv.org/abs/2010.06847v2",
        "categories": [
            "physics.med-ph",
            "cs.CE",
            "cs.NA",
            "eess.SP",
            "math.NA",
            "math.OC"
        ]
    },
    {
        "title": "Effects of plasticity on the anisotropy of the effective fracture   toughness",
        "authors": [
            "Stella Brach"
        ],
        "summary": "This paper investigates the effects of plasticity on the effective fracture toughness. A layered material is considered as a modelling system.   An elastic-plastic phase-field model and a surfing boundary condition are used to study how the crack propagates throughout the material and the evolution of the effective toughness as a function of the layer angle. We first study three idealized situations, where only one property among fracture toughness, Young's modulus and yield strength is heterogeneous whereas the others are uniform. We observe that in the case of toughness and strength heterogeneity, the material exhibits anomalous isotropy: the effective toughness is equal to the largest of the point-wise values for any layer angle except when the layers are parallel to the macroscopic direction of propagation. As the layer angle decreases, the crack propagates along the brittle-to-tough interfaces, whereas it goes straight when the layers have different yield strength but uniform toughness. We find that smooth deflections in the crack path do not induce any overall toughening and that the effective toughness is not proportional to either the cumulated fracture energy or the cumulated plastic work. In the case of elastic heterogeneity, the material is anisotropic in the sense of the effective toughness, as the latter varies as a function of the layer angle. Four toughening mechanisms are active: stress fluctuations, crack renucleation, plastic dissipation and plastic blunting. Finally, we consider a layered medium comprised of compliant-tough-weak and stiff-brittle-strong phases, as it is the case for many structural composites. We observe a transition from an interface-dominated to a plasticity-dominated failure regime, as the phase constituents become more ductile. The material is anisotropic in the sense of the effective toughness.",
        "published": "2020-10-14T11:29:19Z",
        "link": "http://arxiv.org/abs/2010.06971v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Peridynamics-based discrete element method (PeriDEM) model of granular   systems involving breakage of arbitrarily shaped particles",
        "authors": [
            "Prashant K. Jha",
            "Prathamesh S. Desai",
            "Debdeep Bhattacharya",
            "Robert Lipton"
        ],
        "summary": "Usage, manipulation, transport, delivery, and mixing of granular or particulate media, comprised of spherical or polyhedral particles, is commonly encountered in industrial sectors of construction (cement and rock fragments), pharmaceutics (tablets), and transportation (ballast). Elucidating particulate media's behavior in concert with particle attrition (i.e., particle wear and subsequent particle fragmentation) is essential for predicting the performance and increasing the efficiency of engineering systems using such media. Discrete element method (DEM) based techniques can describe the interaction between particles but cannot model intra-particle deformation, especially intra-particle fracture. On the other hand, peridynamics provides the means to account for intra-particle deformation and fracture due to contact forces between particles. The present study proposes a hybrid model referred to as \\textit{PeriDEM} that combines the advantages of peridynamics and DEM. The model parameters can be tuned to achieve desired DEM contact forces, damping effects, and intra-particle stiffness. Two particle impacts and compressive behavior of multi-particle systems are thoroughly investigated. The model can account for any arbitrarily shaped particle in general. Spherical, hexagonal, and non-convex particle shapes are simulated in the present study. The effect of mesh resolution on intra-particle peridynamics is explicitly studied. The proposed hybrid model opens a new avenue to explore the complicated interactions encountered in discrete particle dynamics that involve the formation of force chains, particle interlocking, particle attrition, wear, and the eventual breakage.",
        "published": "2020-10-14T16:32:21Z",
        "link": "http://arxiv.org/abs/2010.07218v2",
        "categories": [
            "cs.CE",
            "7008, 7010, 7410"
        ]
    },
    {
        "title": "An Introduction to Electrocatalyst Design using Machine Learning for   Renewable Energy Storage",
        "authors": [
            "C. Lawrence Zitnick",
            "Lowik Chanussot",
            "Abhishek Das",
            "Siddharth Goyal",
            "Javier Heras-Domingo",
            "Caleb Ho",
            "Weihua Hu",
            "Thibaut Lavril",
            "Aini Palizhati",
            "Morgane Riviere",
            "Muhammed Shuaibi",
            "Anuroop Sriram",
            "Kevin Tran",
            "Brandon Wood",
            "Junwoong Yoon",
            "Devi Parikh",
            "Zachary Ulissi"
        ],
        "summary": "Scalable and cost-effective solutions to renewable energy storage are essential to addressing the world's rising energy needs while reducing climate change. As we increase our reliance on renewable energy sources such as wind and solar, which produce intermittent power, storage is needed to transfer power from times of peak generation to peak demand. This may require the storage of power for hours, days, or months. One solution that offers the potential of scaling to nation-sized grids is the conversion of renewable energy to other fuels, such as hydrogen or methane. To be widely adopted, this process requires cost-effective solutions to running electrochemical reactions. An open challenge is finding low-cost electrocatalysts to drive these reactions at high rates. Through the use of quantum mechanical simulations (density functional theory), new catalyst structures can be tested and evaluated. Unfortunately, the high computational cost of these simulations limits the number of structures that may be tested. The use of machine learning may provide a method to efficiently approximate these calculations, leading to new approaches in finding effective electrocatalysts. In this paper, we provide an introduction to the challenges in finding suitable electrocatalysts, how machine learning may be applied to the problem, and the use of the Open Catalyst Project OC20 dataset for model training.",
        "published": "2020-10-14T19:34:17Z",
        "link": "http://arxiv.org/abs/2010.09435v1",
        "categories": [
            "cond-mat.mtrl-sci",
            "cs.CE",
            "cs.LG",
            "I.2.6; J.2"
        ]
    },
    {
        "title": "An Artifact-based Workflow for Finite-Element Simulation Studies",
        "authors": [
            "Andreas Ruscheinski",
            "Pia Wilsdorf",
            "Julius Zimmermann",
            "Ursula van Rienen",
            "Adelinde M. Uhrmacher"
        ],
        "summary": "Workflow support typically focuses on single simulation experiments. This is also the case for simulation based on finite element methods. If entire simulation studies shall be supported, flexible means for intertwining revising the model, collecting data, executing and analyzing experiments are required. Artifact-based workflows present one means to support entire simulation studies, as has been shown for stochastic discrete-event simulation. To adapt the approach to finite element methods, the set of artifacts, i.e., conceptual model, requirement, simulation model, and simulation experiment, and the constraints that apply are extended by new artifacts, such as geometrical model, input data, and simulation data. Artifacts, their life cycles, and constraints are revisited revealing features both types of simulation studies share and those they vary in. Also, the potential benefits of exploiting an artifact-based workflow approach are shown based on a concrete simulation study. To those benefits belong guidance to systematically conduct simulation studies, reduction of effort by automatically executing specific steps, e.g., generating and executing convergence tests, and support for the automatic reporting of provenance.",
        "published": "2020-10-15T09:44:19Z",
        "link": "http://arxiv.org/abs/2010.07625v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A residual concept for Krylov subspace evaluation of the $\\varphi$   matrix function",
        "authors": [
            "Mike A. Botchev",
            "Leonid A. Knizhnerman",
            "Eugene E. Tyrtyshnikov"
        ],
        "summary": "An efficient Krylov subspace algorithm for computing actions of the $\\varphi$ matrix function for large matrices is proposed. This matrix function is widely used in exponential time integration, Markov chains and network analysis and many other applications. Our algorithm is based on a reliable residual based stopping criterion and a new efficient restarting procedure. For matrices with numerical range in the stable complex half plane, we analyze residual convergence and prove that the restarted method is guaranteed to converge for any Krylov subspace dimension. Numerical tests demonstrate efficiency of our approach for solving large scale evolution problems resulting from discretized in space time-dependent PDEs, in particular, diffusion and convection-diffusion problems.",
        "published": "2020-10-16T16:52:45Z",
        "link": "http://arxiv.org/abs/2010.08494v2",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "65F60, 65M20, 65L05"
        ]
    },
    {
        "title": "Modeling electrochemical systems with weakly imposed Dirichlet boundary   conditions",
        "authors": [
            "Sungu Kim",
            "Makrand A. Khanwale",
            "Robbyn K. Anand",
            "Baskar Ganapathysubramanian"
        ],
        "summary": "Finite element modeling of charged species transport has enabled analysis, design, and optimization of a diverse array of electrochemical and electrokinetic devices. These systems are represented by the Poisson-Nernst-Planck equations coupled with the Navier-Stokes equation, with a key quantity of interest being the current at the system boundaries. Accurately computing the current flux is challenging due to the small critical dimension of the boundary layers (small Debye layer) that require fine mesh resolution at the boundaries. We resolve this challenge by using the Dirichlet-to-Neumanntransformation to weakly impose the Dirichlet conditions for the Poisson-Nernst-Planck equations. The results obtained with weakly imposed Dirichlet boundary conditions showed excellent agreement with those obtained when conventional boundary conditions with highly resolved mesh we reemployed. Furthermore, the calculated current flux showed faster mesh convergence using weakly imposed conditions compared to the conventionally imposed Dirichlet boundary conditions. We illustrate the approach on canonical 3D problems that otherwise would have been computationally intractable to solve accurately. This approach substantially reduces the computational cost of model-ing electrochemical systems.",
        "published": "2020-10-17T12:30:42Z",
        "link": "http://arxiv.org/abs/2010.08778v3",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Model Optimization for A Dynamic Rail Transport System on an Asymmetric   Multi-Core System",
        "authors": [
            "Anas M. Al-Oraiqat",
            "Alexander Y. Ivanov",
            "Yuriy A. Ivanov"
        ],
        "summary": "The problem of optimization of the rolling dynamics model is considered. That providing safe movement at high frequency when interacting with the railway. Moreover, allowing to evaluate the dynamic parameters when designing new and modernizing existing locomotives. The object of this research is a rail transport dynamic system model. The article's purpose is to increase the efficiency of the digital hardware in the rolling stock loop model by optimizing the organization of the computing process. The mathematical model analysis of the object made it possible to attribute it to the class of hard real-time systems. The computation of the model phase variables with different frequencies is necessary to optimize the simulation time of the train movements and is performed by splitting the original algorithm into parallel threads. The developed planning algorithm and the cyclic schedule implementation for the model of a dynamic real-time object consider microarchitecture solutions of symmetric multiprocessor systems with shared memory and methods for optimizing software tools. The experiments confirmed the operability of the optimized model. Also, allow us to recommend it for practical use in studying objects and determine the dynamic force of trolley structural elements during operation. Analysis of the optimized model simulation results, using cyclic schedules shows the correspondence of the obtained simulation results to the standard. The main advantage of the model is the increase in productivity when performing data processing by reducing the processor time. The optimized cyclic schedule algorithm of the semi-natural modeling platform is used for the subsequent development of the control system in real and accelerated time scales.",
        "published": "2020-10-17T15:27:13Z",
        "link": "http://arxiv.org/abs/2010.08811v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A Bayesian Approach for Characterizing and Mitigating Gate and   Measurement Errors",
        "authors": [
            "Muqing Zheng",
            "Ang Li",
            "Tamás Terlaky",
            "Xiu Yang"
        ],
        "summary": "Various noise models have been developed in quantum computing study to describe the propagation and effect of the noise which is caused by imperfect implementation of hardware. Identifying parameters such as gate and readout error rates are critical to these models. We use a Bayesian inference approach to identity posterior distributions of these parameters, such that they can be characterized more elaborately. By characterizing the device errors in this way, we can further improve the accuracy of quantum error mitigation. Experiments conducted on IBM's quantum computing devices suggest that our approach provides better error mitigation performance than existing techniques used by the vendor. Also, our approach outperforms the standard Bayesian inference method in such experiments.",
        "published": "2020-10-19T03:27:28Z",
        "link": "http://arxiv.org/abs/2010.09188v6",
        "categories": [
            "quant-ph",
            "cs.CE",
            "stat.CO"
        ]
    },
    {
        "title": "A novel smoothed particle hydrodynamics and finite element coupling   scheme for fluid-structure interaction: the sliding boundary particle   approach",
        "authors": [
            "Sebastian L. Fuchs",
            "Christoph Meier",
            "Wolfgang A. Wall",
            "Christian J. Cyron"
        ],
        "summary": "A novel numerical formulation for solving fluid-structure interaction (FSI) problems is proposed where the fluid field is spatially discretized using smoothed particle hydrodynamics (SPH) and the structural field using the finite element method (FEM). As compared to fully mesh- or grid-based FSI frameworks, due to the Lagrangian nature of SPH this framework can be easily extended to account for more complex fluids consisting of multiple phases and dynamic phase transitions. Moreover, this approach facilitates the handling of large deformations of the fluid domain respectively the fluid-structure interface without additional methodological and computational efforts. In particular, to achieve an accurate representation of interaction forces between fluid particles and structural elements also for strongly curved interface geometries, the novel sliding boundary particle approach is proposed to ensure full support of SPH particles close to the interface. The coupling of the fluid and the structural field is based on a Dirichlet-Neumann partitioned approach, where the fluid field is the Dirichlet partition with prescribed interface displacements and the structural field is the Neumann partition subject to interface forces. To overcome instabilities inherent to weakly coupled schemes an iterative fixed-point coupling scheme is employed. Several numerical examples in form of well-known benchmark tests are considered to validate the accuracy, stability, and robustness of the proposed formulation. Finally, the filling process of a highly flexible thin-walled balloon-like container is studied, representing a model problem close to potential application scenarios of the proposed scheme in the field of biomechanics.",
        "published": "2020-10-19T13:57:41Z",
        "link": "http://arxiv.org/abs/2010.09526v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A General, Implicit, Large-Strain FE$^2$ Framework for the Simulation of   Dynamic Problems on Two Scales",
        "authors": [
            "Erik Tamsen",
            "Daniel Balzani"
        ],
        "summary": "In this paper we present a fully-coupled, two-scale homogenization method for dynamic loading in the spirit of FE$^2$ methods. The framework considers the balance of linear momentum including inertia at the microscale to capture possible dynamic effects arising from micro heterogeneities. A finite-strain formulation is adapted to account for geometrical nonlinearities enabling the study of e.g. plasticity or fiber pullout, which may be associated with large deformations. A consistent kinematic scale link is established as displacement constraint on the whole representative volume element. The consistent macroscopic material tangent moduli are derived including micro inertia in closed form. These can easily be calculated with a loop over all microscopic finite elements, only applying existing assembly and solving procedures. Thus, making it suitable for standard finite element program architectures. Numerical examples of a layered periodic material are presented and compared to direct numerical simulations to demonstrate the capability of the proposed framework.",
        "published": "2020-10-19T16:24:44Z",
        "link": "http://arxiv.org/abs/2010.09636v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Analysis of Markov Jump Processes under Terminal Constraints",
        "authors": [
            "Michael Backenköhler",
            "Luca Bortolussi",
            "Gerrit Großmann",
            "Verena Wolf"
        ],
        "summary": "Many probabilistic inference problems such as stochastic filtering or the computation of rare event probabilities require model analysis under initial and terminal constraints. We propose a solution to this bridging problem for the widely used class of population-structured Markov jump processes. The method is based on a state-space lumping scheme that aggregates states in a grid structure. The resulting approximate bridging distribution is used to iteratively refine relevant and truncate irrelevant parts of the state-space. This way the algorithm learns a well-justified finite-state projection yielding guaranteed lower bounds for the system behavior under endpoint constraints. We demonstrate the method's applicability to a wide range of problems such as Bayesian inference and the analysis of rare events.",
        "published": "2020-10-20T07:43:41Z",
        "link": "http://arxiv.org/abs/2010.10096v2",
        "categories": [
            "eess.SY",
            "cs.CE",
            "cs.SY",
            "q-bio.QM"
        ]
    },
    {
        "title": "Multi-objective free-form shape optimization of a synchronous reluctance   machine",
        "authors": [
            "Peter Gangl",
            "Stefan Köthe",
            "Christiane Mellak",
            "Alessio Cesarano",
            "Annette Mütze"
        ],
        "summary": "This paper deals with the design optimization of a synchronous reluctance machine to be used in an X-ray tube, where the goal is to maximize the torque, by means of gradient-based free-form shape optimization. The presented approach is based on the mathematical concept of shape derivatives and allows to obtain new motor designs without the need to introduce a geometric parametrization. We validate our results by comparing them to a parametric geometry optimization in JMAG by means of a stochastic optimization algorithm. While the obtained designs are of similar shape, the computational time used by the gradient-based algorithm is in the order of minutes, compared to several hours taken by the stochastic optimization algorithm. Finally, we show an extension of the free-form shape optimization algorithm to the case of multiple objective functions and illustrate a way to obtain an approximate Pareto front.",
        "published": "2020-10-20T08:16:54Z",
        "link": "http://arxiv.org/abs/2010.10117v1",
        "categories": [
            "cs.CE",
            "math.OC"
        ]
    },
    {
        "title": "Towards Accuracy and Scalability: Combining Isogeometric Analysis with   Deflation to Obtain Scalable Convergence for the Helmholtz Equation",
        "authors": [
            "Vandana Dwarka",
            "Roel Tielen",
            "Matthias Möller",
            "Kees Vuik"
        ],
        "summary": "Finding fast yet accurate numerical solutions to the Helmholtz equation remains a challenging task. The pollution error (i.e. the discrepancy between the numerical and analytical wave number k) requires the mesh resolution to be kept fine enough to obtain accurate solutions. A recent study showed that the use of Isogeometric Analysis (IgA) for the spatial discretization significantly reduces the pollution error.   However, solving the resulting linear systems by means of a direct solver remains computationally expensive when large wave numbers or multiple dimensions are considered. An alternative lies in the use of (preconditioned) Krylov subspace methods. Recently, the use of the exact Complex Shifted Laplacian Preconditioner (CSLP) with a small complex shift has shown to lead to wave number independent convergence while obtaining more accurate numerical solutions using IgA.   In this paper, we propose the use of deflation techniques combined with an approximated inverse of the CSLP using a geometric multigrid method. Numerical results obtained for both one- and two-dimensional model problems, including constant and non-constant wave numbers, show scalable convergence with respect to the wave number and approximation order p of the spatial discretization. Furthermore, when kh is kept constant, the proposed approach leads to a significant reduction of the computational time compared to the use of the exact inverse of the CSLP with a small shift.",
        "published": "2020-10-20T12:51:51Z",
        "link": "http://arxiv.org/abs/2010.10232v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Scalable HPC and AI Infrastructure for COVID-19 Therapeutics",
        "authors": [
            "Hyungro Lee",
            "Andre Merzky",
            "Li Tan",
            "Mikhail Titov",
            "Matteo Turilli",
            "Dario Alfe",
            "Agastya Bhati",
            "Alex Brace",
            "Austin Clyde",
            "Peter Coveney",
            "Heng Ma",
            "Arvind Ramanathan",
            "Rick Stevens",
            "Anda Trifan",
            "Hubertus Van Dam",
            "Shunzhou Wan",
            "Sean Wilkinson",
            "Shantenu Jha"
        ],
        "summary": "COVID-19 has claimed more 1 million lives and resulted in over 40 million infections. There is an urgent need to identify drugs that can inhibit SARS-CoV-2. In response, the DOE recently established the Medical Therapeutics project as part of the National Virtual Biotechnology Laboratory, and tasked it with creating the computational infrastructure and methods necessary to advance therapeutics development. We discuss innovations in computational infrastructure and methods that are accelerating and advancing drug design. Specifically, we describe several methods that integrate artificial intelligence and simulation-based approaches, and the design of computational infrastructure to support these methods at scale. We discuss their implementation and characterize their performance, and highlight science advances that these capabilities have enabled.",
        "published": "2020-10-20T14:13:52Z",
        "link": "http://arxiv.org/abs/2010.10517v1",
        "categories": [
            "cs.DC",
            "cs.CE"
        ]
    },
    {
        "title": "A statistical framework for model-based inverse problems in ultrasound   elastography",
        "authors": [
            "Narges Mohammadi",
            "Marvin M. Doyley",
            "Mujdat Cetin"
        ],
        "summary": "Model-based computational elasticity imaging of tissues can be posed as solving an inverse problem over finite elements spanning the displacement image. As most existing quasi-static elastography methods count on deterministic formulations of the forward model resulting in a constrained optimization problem, the impact of displacement observation errors has not been well addressed. To this end, we propose a new statistical technique that leads to a unified optimization problem for elasticity imaging. Our statistical model takes the imperfect nature of the displacement measurements into account, and leads to an observation model for the Young's modulus that involves signal dependent colored noise. To solve the resulting regularized optimization problem, we propose a fixed-point algorithm that leverages proximal splitting methods. Preliminary qualitative and quantitative results demonstrate the effectiveness and robustness of the proposed methodology.",
        "published": "2020-10-21T02:51:43Z",
        "link": "http://arxiv.org/abs/2010.10729v1",
        "categories": [
            "eess.IV",
            "cs.CE"
        ]
    },
    {
        "title": "Topology optimization of acoustic metasurfaces by using a two-scale   homogenization method",
        "authors": [
            "Yuki Noguchi",
            "Takayuki Yamada"
        ],
        "summary": "In this paper, we propose a level set-based topology optimization method for the unit-cell design of acoustic metasurfaces by using a two-scale homogenization method. Based on previous works, we first propose a homogenization method for acoustic metasurfaces that can be combined with topology optimization. In this method, a nonlocal transmission condition depending on the unit cell of the metasurface appears in a macroscale problem. Next, we formulate an optimization problem within the framework of a level set-based topology optimization method, wherein an objective functional is expressed as the macroscopic responses obtained through the homogenization, and material distributions in the unit cell are set as design variables. A sensitivity analysis is conducted based on the concept of the topological derivative. To confirm the validity of the proposed method, two-dimensional numerical examples are provided. First, we provide a numerical example that supports the validity of the homogenization method, and we then perform optimization calculations based on the waveguide settings of the acoustic metasurfaces. In addition, we discuss the mechanism of the obtained optimized structures.",
        "published": "2020-10-21T09:08:08Z",
        "link": "http://arxiv.org/abs/2010.10844v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "On the numerical solution to an inverse medium problem",
        "authors": [
            "Dinh-Liem Nguyen",
            "Trung Truong"
        ],
        "summary": "This paper is concerned with the inverse medium problem of determining the location and shape of penetrable scattering objects from measurements of the scattered field. We study a sampling indicator function for recovering the scattering object in a fast and robust way. A flexibility of this indicator function is that it is applicable to data measured in near-field regime or far-field regime. The implementation of the function is simple and does not involve solving any ill-posed problems. The resolution analysis and stability estimate of the indicator function are investigated using the factorization analysis of the far-field operator along with the Funk-Hecke formula. The performance of the method is verified on both simulated and experimental data.",
        "published": "2020-10-21T19:34:41Z",
        "link": "http://arxiv.org/abs/2010.11262v3",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Shape related constraints aware generation of Mechanical Designs through   Deep Convolutional GAN",
        "authors": [
            "Waad Almasri",
            "Dimitri Bettebghor",
            "Fakhreddine Ababsa",
            "Florence Danglade"
        ],
        "summary": "Mechanical product engineering often must comply with manufacturing or geometric constraints related to the shaping process. Mechanical design hence should rely on robust and fast tools to explore complex shapes, typically for design for additive manufacturing (DfAM). Topology optimization is such a powerful tool, yet integrating geometric constraints (shape-related) into it is hard. In this work, we leverage machine learning capability to handle complex geometric and spatial correlations to integrate into the mechanical design process geometry-related constraints at the conceptual level. More precisely, we explore the generative capabilities of recent Deep Learning architectures to enhance mechanical designs, typically for additive manufacturing. In this work, we build a generative Deep-Learning-based approach of topology optimization integrating mechanical conditions in addition to one typical manufacturing condition (the complexity of a design i.e. a geometrical condition). The approach is a dual-discriminator GAN: a generator that takes as input the mechanical and geometrical conditions and outputs a 2D structure and two discriminators, one to ensure that the generated structure follows the mechanical constraints and the other to assess the geometrical constraint. We also explore the generation of designs with a non-uniform material distribution and show promising results. Finally, We evaluate the generated designs with an objective evaluation of all wanted aspects: the mechanical as well as the geometrical constraints.",
        "published": "2020-10-22T16:09:19Z",
        "link": "http://arxiv.org/abs/2010.11833v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Accelerating computational modeling and design of high-entropy alloys",
        "authors": [
            "Rahul Singh",
            "Aayush Sharma",
            "Prashant Singh",
            "Ganesh Balasubramanian",
            "Duane D. Johnson"
        ],
        "summary": "With huge design spaces for unique chemical and mechanical properties, we remove a roadblock to computational design of {high-entropy alloys} using a metaheuristic hybrid Cuckoo Search (CS) for \"on-the-fly\" construction of Super-Cell Random APproximates (SCRAPs) having targeted atomic site and pair probabilities on arbitrary crystal lattices. Our hybrid-CS schema overcomes large, discrete combinatorial optimization by ultrafast global solutions that scale linearly in system size and strongly in parallel, e.g. a 4-element, 128-atom model [a $10^{73+}$ space] is found in seconds -- a reduction of 13,000+ over current strategies. With model-generation eliminated as a bottleneck, computational alloy design can be performed that is currently impossible or impractical. We showcase the method for real alloys with varying short-range order. Being problem-agnostic, our hybrid-CS schema offers numerous applications in diverse fields.",
        "published": "2020-10-22T23:19:28Z",
        "link": "http://arxiv.org/abs/2010.12107v1",
        "categories": [
            "cond-mat.mtrl-sci",
            "cs.CE"
        ]
    },
    {
        "title": "A Perspective on Machine Learning Methods in Turbulence Modelling",
        "authors": [
            "Andrea Beck",
            "Marius Kurz"
        ],
        "summary": "This work presents a review of the current state of research in data-driven turbulence closure modeling. It offers a perspective on the challenges and open issues, but also on the advantages and promises of machine learning methods applied to parameter estimation, model identification, closure term reconstruction and beyond, mostly from the perspective of Large Eddy Simulation and related techniques. We stress that consistency of the training data, the model, the underlying physics and the discretization is a key issue that needs to be considered for a successful ML-augmented modeling strategy. In order to make the discussion useful for non-experts in either field, we introduce both the modeling problem in turbulence as well as the prominent ML paradigms and methods in a concise and self-consistent manner. Following, we present a survey of the current data-driven model concepts and methods, highlight important developments and put them into the context of the discussed challenges.",
        "published": "2020-10-23T08:19:30Z",
        "link": "http://arxiv.org/abs/2010.12226v1",
        "categories": [
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "Beating the market with a bad predictive model",
        "authors": [
            "Ondřej Hubáček",
            "Gustav Šír"
        ],
        "summary": "It is a common misconception that in order to make consistent profits as a trader, one needs to posses some extra information leading to an asset value estimation more accurate than that reflected by the current market price. While the idea makes intuitive sense and is also well substantiated by the widely popular Kelly criterion, we prove that it is generally possible to make systematic profits with a completely inferior price-predicting model. The key idea is to alter the training objective of the predictive models to explicitly decorrelate them from the market, enabling to exploit inconspicuous biases in market maker's pricing, and profit on the inherent advantage of the market taker. We introduce the problem setting throughout the diverse domains of stock trading and sports betting to provide insights into the common underlying properties of profitable predictive models, their connections to standard portfolio optimization strategies, and the, commonly overlooked, advantage of the market taker. Consequently, we prove desirability of the decorrelation objective across common market distributions, translate the concept into a practical machine learning setting, and demonstrate its viability with real world market data.",
        "published": "2020-10-23T16:20:35Z",
        "link": "http://arxiv.org/abs/2010.12508v1",
        "categories": [
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "Nonseparable Symplectic Neural Networks",
        "authors": [
            "Shiying Xiong",
            "Yunjin Tong",
            "Xingzhe He",
            "Shuqi Yang",
            "Cheng Yang",
            "Bo Zhu"
        ],
        "summary": "Predicting the behaviors of Hamiltonian systems has been drawing increasing attention in scientific machine learning. However, the vast majority of the literature was focused on predicting separable Hamiltonian systems with their kinematic and potential energy terms being explicitly decoupled while building data-driven paradigms to predict nonseparable Hamiltonian systems that are ubiquitous in fluid dynamics and quantum mechanics were rarely explored. The main computational challenge lies in the effective embedding of symplectic priors to describe the inherently coupled evolution of position and momentum, which typically exhibits intricate dynamics. To solve the problem, we propose a novel neural network architecture, Nonseparable Symplectic Neural Networks (NSSNNs), to uncover and embed the symplectic structure of a nonseparable Hamiltonian system from limited observation data. The enabling mechanics of our approach is an augmented symplectic time integrator to decouple the position and momentum energy terms and facilitate their evolution. We demonstrated the efficacy and versatility of our method by predicting a wide range of Hamiltonian systems, both separable and nonseparable, including chaotic vortical flows. We showed the unique computational merits of our approach to yield long-term, accurate, and robust predictions for large-scale Hamiltonian systems by rigorously enforcing symplectomorphism.",
        "published": "2020-10-23T19:50:13Z",
        "link": "http://arxiv.org/abs/2010.12636v3",
        "categories": [
            "cs.LG",
            "cs.CE",
            "stat.ML"
        ]
    },
    {
        "title": "Pressure Mode Decomposition Analysis of the Flow past a Cross-flow   Oscillating Circular Cylinder",
        "authors": [
            "Muhammad Sufyan",
            "Hamayun Farooq",
            "Imran Akhtar",
            "Zafar Bangash"
        ],
        "summary": "Proper orthogonal decomposition (POD) is often employed in developing reduced-order models (ROM) in fluid flows for design, control, and optimization. Contrary to the usual practice where velocity field is the focus, we apply the POD analysis on the pressure field data obtained from numerical simulations of the flow past stationary and oscillating cylinders. Since pressure mainly contributes to the hydrodynamic forces acting on the structure, we compute the pressure POD modes on the cylinder surface oscillating in lock-in and lock-out regions. These modes are then dissected into sine and cosine magnitudes to estimate their contribution in the development of pressure lift and drag decomposition coefficients, respectively. The key finding of this study is that more POD modes are required to capture the flow physics in nonsynchronous regimes as compared to synchronization case. Engineering application of this study is the development of reduced-order models for effective control techniques.",
        "published": "2020-10-24T08:33:00Z",
        "link": "http://arxiv.org/abs/2010.12835v1",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA",
            "physics.flu-dyn"
        ]
    },
    {
        "title": "Towards Real-Time Magnetic Dosimetry Simulations for Inductive Charging   Systems",
        "authors": [
            "Norman Haussmann",
            "Martin Zang",
            "Robin Mease",
            "Markus Clemens",
            "Benedikt Schmuelling",
            "Matthias Bolten"
        ],
        "summary": "The exposure of a human by magneto-quasistatic fields from wireless charging systems is to be determined from magnetic field measurements in near real-time. This requires a fast linear equations solver for the discrete Poisson system of the Co-Simulation Scalar Potential Finite Difference (Co-Sim. SPFD) scheme. Here, the use of the AmgX library on NVIDIA GPUs is presented for this task. It enables solving the equation system resulting from an ICNIRP recommended human voxel model resolution of 2 mm in less than 0.5 seconds on a single NVIDIA Tesla V100 GPU.",
        "published": "2020-10-24T11:32:30Z",
        "link": "http://arxiv.org/abs/2010.12879v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Unsupervised discovery of interpretable hyperelastic constitutive laws",
        "authors": [
            "Moritz Flaschel",
            "Siddhant Kumar",
            "Laura De Lorenzis"
        ],
        "summary": "We propose a new approach for data-driven automated discovery of isotropic hyperelastic constitutive laws. The approach is unsupervised, i.e., it requires no stress data but only displacement and global force data, which are realistically available through mechanical testing and digital image correlation techniques; it delivers interpretable models, i.e., models that are embodied by parsimonious mathematical expressions discovered through sparse regression of a large catalogue of candidate functions; it is one-shot, i.e., discovery only needs one experiment - but can use more if available. The problem of unsupervised discovery is solved by enforcing equilibrium constraints in the bulk and at the loaded boundary of the domain. Sparsity of the solution is achieved by l_p regularization combined with thresholding, which calls for a non-linear optimization scheme. The ensuing fully automated algorithm leverages physics-based constraints for the automatic determination of the penalty parameter in the regularization term. Using numerically generated data including artificial noise, we demonstrate the ability of the approach to accurately discover five hyperelastic models of different complexity. We also show that, if a \"true\" feature is missing in the function library, the proposed approach is able to surrogate it in such a way that the actual response is still accurately predicted.",
        "published": "2020-10-26T11:38:51Z",
        "link": "http://arxiv.org/abs/2010.13496v3",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Manifold learning-based feature extraction for structural defect   reconstruction",
        "authors": [
            "Qi Li",
            "Dianzi Liu",
            "Zhenghua Qian"
        ],
        "summary": "Data-driven quantitative defect reconstructions using ultrasonic guided waves has recently demonstrated great potential in the area of non-destructive testing. In this paper, we develop an efficient deep learning-based defect reconstruction framework, called NetInv, which recasts the inverse guided wave scattering problem as a data-driven supervised learning progress that realizes a mapping between reflection coefficients in wavenumber domain and defect profiles in the spatial domain. The superiorities of the proposed NetInv over conventional reconstruction methods for defect reconstruction have been demonstrated by several examples. Results show that NetInv has the ability to achieve the higher quality of defect profiles with remarkable efficiency and provides valuable insight into the development of effective data driven structural health monitoring and defect reconstruction using machine learning.",
        "published": "2020-10-26T12:00:21Z",
        "link": "http://arxiv.org/abs/2010.15605v1",
        "categories": [
            "cs.CE",
            "cs.LG",
            "eess.IV",
            "J.2"
        ]
    },
    {
        "title": "Textbook efficiency: massively parallel matrix-free multigrid for the   Stokes system",
        "authors": [
            "Nils Kohl",
            "Ulrich Rüde"
        ],
        "summary": "We employ textbook multigrid efficiency (TME), as introduced by Achi Brandt, to construct an asymptotically optimal monolithic multigrid solver for the Stokes system. The geometric multigrid solver builds upon the concept of hierarchical hybrid grids (HHG), which is extended to higher-order finite-element discretizations, and a corresponding matrix-free implementation. The computational cost of the full multigrid (FMG) iteration is quantified, and the solver is applied to multiple benchmark problems. Through a parameter study, we suggest configurations that achieve TME for both, stabilized equal-order, and Taylor-Hood discretizations. The excellent node-level performance of the relevant compute kernels is presented via a roofline analysis. Finally, we demonstrate the weak and strong scalability to up to $147,456$ parallel processes and solve Stokes systems with more than $3.6 \\times 10^{12}$ (trillion) unknowns.",
        "published": "2020-10-26T12:11:55Z",
        "link": "http://arxiv.org/abs/2010.13513v1",
        "categories": [
            "cs.CE",
            "cs.MS",
            "cs.NA",
            "math.NA",
            "65F10, 65N30, 65N55"
        ]
    },
    {
        "title": "High-order maximum-entropy collocation methods",
        "authors": [
            "F. Greco",
            "M. Arroyo"
        ],
        "summary": "This paper considers the approximation of partial differential equations with a point collocation framework based on high-order local maximum-entropy schemes (HOLMES). In this approach, smooth basis functions are computed through an optimization procedure and the strong form of the problem is directly imposed at the collocation points, reducing significantly the computational times with respect to the Galerkin formulation. Furthermore, such a method is truly meshless, since no background integration grids are necessary. The validity of the proposed methodology is verified with supportive numerical examples, where the expected convergence rates are obtained. This includes the approximation of PDEs on domains bounded by implicit and explicit (NURBS) curves, illustrating a direct integration between the geometric modeling and the numerical analysis.",
        "published": "2020-10-26T14:33:02Z",
        "link": "http://arxiv.org/abs/2010.13615v2",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.AP",
            "math.NA"
        ]
    },
    {
        "title": "A higher-order finite element method with unstructured anisotropic mesh   adaption for two phase flows with surface tension",
        "authors": [
            "Modesar Shakoor",
            "Chung Hae Park"
        ],
        "summary": "A novel finite element framework is proposed for the numerical simulation of two phase flows with surface tension. The Level-Set (LS) method with piece-wise quadratic (P2) interpolation for the liquid-gas interface is used in order to reach higher-order convergence rates in regions with smooth interface. A balanced-force implementation of the continuum surface force model is used to take into account the surface tension and to solve static problems as accurately as possible. Given that this requires a balance between the discretization used for the LS function, and that used for the pressure field, an equal-order P2/P2/P2 scheme is proposed for the Navier-Stokes and LS advection equations, which are strongly coupled with each other. This fully implicit formulation is stabilized using the residual-based variational multiscale framework. In order to improve the accuracy and obtain optimal convergence rates with a minimum number of elements, an anisotropic mesh adaption method is proposed where the unstructured mesh is kept as fine as possible close to the zero iso-value of the P2 LS function. Elements are automatically stretched in regions with flat interface in order to keep the complexity fixed during the simulation. The accuracy and efficiency of this approach are demonstrated for two and three dimensional simulations of a rising bubble.",
        "published": "2020-10-26T16:58:34Z",
        "link": "http://arxiv.org/abs/2010.13716v1",
        "categories": [
            "cs.CE",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Scientific intuition inspired by machine learning generated hypotheses",
        "authors": [
            "Pascal Friederich",
            "Mario Krenn",
            "Isaac Tamblyn",
            "Alan Aspuru-Guzik"
        ],
        "summary": "Machine learning with application to questions in the physical sciences has become a widely used tool, successfully applied to classification, regression and optimization tasks in many areas. Research focus mostly lies in improving the accuracy of the machine learning models in numerical predictions, while scientific understanding is still almost exclusively generated by human researchers analysing numerical results and drawing conclusions. In this work, we shift the focus on the insights and the knowledge obtained by the machine learning models themselves. In particular, we study how it can be extracted and used to inspire human scientists to increase their intuitions and understanding of natural systems. We apply gradient boosting in decision trees to extract human interpretable insights from big data sets from chemistry and physics. In chemistry, we not only rediscover widely know rules of thumb but also find new interesting motifs that tell us how to control solubility and energy levels of organic molecules. At the same time, in quantum physics, we gain new understanding on experiments for quantum entanglement. The ability to go beyond numerics and to enter the realm of scientific insight and hypothesis generation opens the door to use machine learning to accelerate the discovery of conceptual understanding in some of the most challenging domains of science.",
        "published": "2020-10-27T12:12:12Z",
        "link": "http://arxiv.org/abs/2010.14236v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.CE",
            "physics.chem-ph",
            "quant-ph"
        ]
    },
    {
        "title": "Internal contact modeling for finite strain topology optimization",
        "authors": [
            "Gore Lukas Bluhm",
            "Ole Sigmund",
            "Konstantinos Poulios"
        ],
        "summary": "The present work proposes an extension of the third medium contact method for solving structural topology optimization problems that involve and exploit self-contact. A new regularization of the void region, which acts as the contact medium, makes the method suitable for cases with very large deformations. The proposed contact method is implemented in a second order topology optimization framework, which employs a coupled simultaneous solution of the mechanical, design update, and adjoint problems. All three problems are derived and presented in weak form, and discretized with finite elements of suitable order. The capabilities and accuracy of the developed method are demonstrated in a topology optimization problem for achieving a desired non-linear force-displacement path.",
        "published": "2020-10-27T13:22:48Z",
        "link": "http://arxiv.org/abs/2010.14277v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "An isogeometric finite element formulation for geometrically exact   Timoshenko beams with extensible directors",
        "authors": [
            "Myung-Jin Choi",
            "Roger A. Sauer",
            "Sven Klinkel"
        ],
        "summary": "An isogeometric finite element formulation for geometrically and materially nonlinear Timoshenko beams is presented, which incorporates in-plane deformation of the cross-section described by two extensible director vectors. Since those directors belong to the space ${\\Bbb R}^3$, a configuration can be additively updated. The developed formulation allows direct application of nonlinear three-dimensional constitutive equations without zero stress conditions. Especially, the significance of considering correct surface loads rather than applying an equivalent load directly on the central axis is investigated. Incompatible linear in-plane strain components for the cross-section have been added to alleviate Poisson locking by using an enhanced assumed strain (EAS) method. In various numerical examples exhibiting large deformations, the accuracy and efficiency of the presented beam formulation is assessed in comparison to brick elements. We particularly use hyperelastic materials of the St. Venant-Kirchhoff and compressible Neo-Hookean types.",
        "published": "2020-10-27T17:15:03Z",
        "link": "http://arxiv.org/abs/2010.14454v3",
        "categories": [
            "physics.app-ph",
            "cs.CE"
        ]
    },
    {
        "title": "Impossibility of phylogeny reconstruction from $k$-mer counts",
        "authors": [
            "Wai-Tong Louis Fan",
            "Brandon Legried",
            "Sebastien Roch"
        ],
        "summary": "We consider phylogeny estimation under a two-state model of sequence evolution by site substitution on a tree. In the asymptotic regime where the sequence lengths tend to infinity, we show that for any fixed $k$ no statistically consistent phylogeny estimation is possible from $k$-mer counts over the full leaf sequences alone. Formally, we establish that the joint distribution of $k$-mer counts over the entire leaf sequences on two distinct trees have total variation distance bounded away from $1$ as the sequence length tends to infinity. Our impossibility result implies that statistical consistency requires more sophisticated use of $k$-mer count information, such as block techniques developed in previous theoretical work.",
        "published": "2020-10-27T17:22:35Z",
        "link": "http://arxiv.org/abs/2010.14460v2",
        "categories": [
            "math.PR",
            "cs.CE",
            "math.ST",
            "q-bio.PE",
            "stat.TH"
        ]
    },
    {
        "title": "Object shape error modelling and simulation during early design stage by   morphing Gaussian Random Fields",
        "authors": [
            "Manoj Babu",
            "Pasquale Franciosa",
            "Prashanth Shekar",
            "Darek Ceglarek"
        ],
        "summary": "Geometric and dimensional variations in objects are caused by inevitable uncertainties in manufacturing processes and often lead to product quality issues. Failing to model the effect object shape errors, i.e., geometric and dimensional errors of parts, early during design phase inhibits the ability to predict such quality issues; consequently leading to expensive design changes after freezing of design. State-of-Art methodologies for modelling and simulating object shape error have limited defect fidelity, data versatility, and designer centricity that prevent their effective application during early design phase. Overcoming these limitations a novel Morphing Gaussian Random Field (MGRF) methodology for object shape error modelling and simulation is presented in this paper. The MGRF methodology has (i) high defect fidelity and is capable of simulating various part defects including local and global deformations, and technological patterns; (ii) high data versatility and can effectively simulate non-ideal parts under the constraint of limited data availability and can utilise historical non-ideal part data; (iii) designer centric capabilities such as performing `what if?' analysis of practically relevant defects; and (iv) capability to generate non-ideal parts conforming to statistical form tolerance specification. The aforementioned capabilities enable MGRF methodology to accurately model and simulate the effect of object shape variations on product quality during the early design phase. This is achieved by first, modelling the spatial correlation in the deviations of the part from its design nominal using Gaussian Random Field and then, utilising the modelled spatial correlations to generate non-ideal parts by conditional simulations. Practical applications of developed MGRF methodology and its advantages are demonstrated using sport-utility-vehicle door parts.",
        "published": "2020-10-28T11:17:24Z",
        "link": "http://arxiv.org/abs/2010.14889v2",
        "categories": [
            "cs.CE",
            "stat.AP"
        ]
    },
    {
        "title": "A fast and scalable computational framework for large-scale and   high-dimensional Bayesian optimal experimental design",
        "authors": [
            "Keyi Wu",
            "Peng Chen",
            "Omar Ghattas"
        ],
        "summary": "We develop a fast and scalable computational framework to solve large-scale and high-dimensional Bayesian optimal experimental design problems. In particular, we consider the problem of optimal observation sensor placement for Bayesian inference of high-dimensional parameters governed by partial differential equations (PDEs), which is formulated as an optimization problem that seeks to maximize an expected information gain (EIG). Such optimization problems are particularly challenging due to the curse of dimensionality for high-dimensional parameters and the expensive solution of large-scale PDEs. To address these challenges, we exploit two essential properties of such problems: the low-rank structure of the Jacobian of the parameter-to-observable map to extract the intrinsically low-dimensional data-informed subspace, and the high correlation of the approximate EIGs by a series of approximations to reduce the number of PDE solves. We propose an efficient offline-online decomposition for the optimization problem: an offline stage of computing all the quantities that require a limited number of PDE solves independent of parameter and data dimensions, and an online stage of optimizing sensor placement that does not require any PDE solve. For the online optimization, we propose a swapping greedy algorithm that first construct an initial set of sensors using leverage scores and then swap the chosen sensors with other candidates until certain convergence criteria are met. We demonstrate the efficiency and scalability of the proposed computational framework by a linear inverse problem of inferring the initial condition for an advection-diffusion equation, and a nonlinear inverse problem of inferring the diffusion coefficient of a log-normal diffusion equation, with both the parameter and data dimensions ranging from a few tens to a few thousands.",
        "published": "2020-10-28T19:30:51Z",
        "link": "http://arxiv.org/abs/2010.15196v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Essential Scattering Applications for Everyone. Overview",
        "authors": [
            "Denis Korolkov",
            "Stepan Rakhimov"
        ],
        "summary": "ESCAPE is a free python package and framework for creating applications for simulating and fitting of X-ray and neutron scattering data with current support for specular reflectivity, polarized neutron reflectometry, high resolution X-ray diffraction, small angle scattering with future support for off-specular scattering from structured samples with complicated morphology. Utilizing current features of Jupyter project, it allows to create highly customized applications in the format of notebooks. These notebooks, being shared with other users, can be used directly or started as web applications with graphical user interface. This paper is a brief overview of the core and scattering packages providing description of the major features with code examples. The following features make ESCAPE different from other projects: independent from scattering applications core, which provides access to models building blocks like parameters, variables, functors, data objects, models and optimizers; support of arithmetic operations and algebraic expressions on parameters and functors, offering models with complex dependencies of parameters; math module with standard mathematical functors and special functors which perform numerical integration over variable or parameter, supplying customization of intensity model; simultaneous fit of several models, also for models with different dimensions. Check our web site https://escape-app.net/ for further information.",
        "published": "2020-10-28T22:47:37Z",
        "link": "http://arxiv.org/abs/2011.01340v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A globally convergent modified Newton method for the direct minimization   of the Ohta-Kawasaki energy with application to the directed self-assembly of   diblock copolymers",
        "authors": [
            "Lianghao Cao",
            "Omar Ghattas",
            "J. Tinsley Oden"
        ],
        "summary": "We propose a fast and robust scheme for the direct minimization of the Ohta-Kawasaki energy that characterizes the microphase separation of diblock copolymer melts. The scheme employs a globally convergent modified Newton method with line search which is shown to be mass-conservative, energy-descending, asymptotically quadratically convergent, and three orders of magnitude more efficient than the commonly-used gradient flow approach. The regularity and the first-order condition of minimizers are analyzed. A numerical study of the chemical substrate guided directed self-assembly of diblock copolymer melts, based on a novel polymer-substrate interaction model and the proposed scheme, is provided.",
        "published": "2020-10-28T23:09:51Z",
        "link": "http://arxiv.org/abs/2010.15271v1",
        "categories": [
            "physics.comp-ph",
            "cs.CE",
            "cs.NA",
            "math.NA",
            "math.OC"
        ]
    },
    {
        "title": "Multiscale characteristics of the emerging global cryptocurrency market",
        "authors": [
            "Marcin Wątorek",
            "Stanisław Drożdż",
            "Jarosław Kwapień",
            "Ludovico Minati",
            "Paweł Oświęcimka",
            "Marek Stanuszek"
        ],
        "summary": "The review introduces the history of cryptocurrencies, offering a description of the blockchain technology behind them. Differences between cryptocurrencies and the exchanges on which they are traded have been shown. The central part surveys the analysis of cryptocurrency price changes on various platforms. The statistical properties of the fluctuations in the cryptocurrency market have been compared to the traditional markets. With the help of the latest statistical physics methods the non-linear correlations and multiscale characteristics of the cryptocurrency market are analyzed. In the last part the co-evolution of the correlation structure among the 100 cryptocurrencies having the largest capitalization is retraced. The detailed topology of cryptocurrency network on the Binance platform from bitcoin perspective is also considered. Finally, an interesting observation on the Covid-19 pandemic impact on the cryptocurrency market is presented and discussed: recently we have witnessed a \"phase transition\" of the cryptocurrencies from being a hedge opportunity for the investors fleeing the traditional markets to become a part of the global market that is substantially coupled to the traditional financial instruments like the currencies, stocks, and commodities.   The main contribution is an extensive demonstration that structural self-organization in the cryptocurrency markets has caused the same to attain complexity characteristics that are nearly indistinguishable from the Forex market at the level of individual time-series. However, the cross-correlations between the exchange rates on cryptocurrency platforms differ from it. The cryptocurrency market is less synchronized and the information flows more slowly, which results in more frequent arbitrage opportunities. The methodology used in the review allows the latter to be detected, and lead-lag relationships to be discovered.",
        "published": "2020-10-29T07:56:01Z",
        "link": "http://arxiv.org/abs/2010.15403v2",
        "categories": [
            "q-fin.ST",
            "cs.CE",
            "econ.EM",
            "stat.CO"
        ]
    },
    {
        "title": "Physics-informed deep learning for flow and deformation in poroelastic   media",
        "authors": [
            "Yared W. Bekele"
        ],
        "summary": "A physics-informed neural network is presented for poroelastic problems with coupled flow and deformation processes. The governing equilibrium and mass balance equations are discussed and specific derivations for two-dimensional cases are presented. A fully-connected deep neural network is used for training. Barry and Mercer's source problem with time-dependent fluid injection/extraction in an idealized poroelastic medium, which has an exact analytical solution, is used as a numerical example. A random sample from the analytical solution is used as training data and the performance of the model is tested by predicting the solution on the entire domain after training. The deep learning model predicts the horizontal and vertical deformations well while the error in the predicted pore pressure predictions is slightly higher because of the sparsity of the pore pressure values.",
        "published": "2020-10-29T09:04:11Z",
        "link": "http://arxiv.org/abs/2010.15426v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Space-time shape uncertainties in the forward and inverse problem of   electrocardiography",
        "authors": [
            "Lia Gander",
            "Rolf Krause",
            "Michael Multerer",
            "Simone Pezzuto"
        ],
        "summary": "In electrocardiography, the \"classic\" inverse problem is the reconstruction of electric potentials at a surface enclosing the heart from remote recordings at the body surface and an accurate description of the anatomy. The latter being affected by noise and obtained with limited resolution due to clinical constraints, a possibly large uncertainty may be perpetuated in the inverse reconstruction.   The purpose of this work is to study the effect of shape uncertainty on the forward and the inverse problem of electrocardiography. To this aim, the problem is first recast into a boundary integral formulation and then discretised with a collocation method to achieve high convergence rates and a fast time to solution. The shape uncertainty of the domain is represented by a random deformation field defined on a reference configuration. We propose a periodic-in-time covariance kernel for the random field and approximate the Karhunen-Lo\\`eve expansion using low-rank techniques for fast sampling. The space-time uncertainty in the expected potential and its variance is evaluated with an anisotropic sparse quadrature approach and validated by a quasi-Monte Carlo method.   We present several numerical experiments on a simplified but physiologically grounded 2-dimensional geometry to illustrate the validity of the approach. The tested parametric dimension ranged from 100 up to 600. For the forward problem the sparse quadrature is very effective. In the inverse problem, the sparse quadrature and the quasi-Monte Carlo method perform as expected, except for the total variation regularisation, where convergence is limited by lack of regularity. We finally investigate an $H^{1/2}$ regularisation, which naturally stems from the boundary integral formulation, and compare it to more classical approaches.",
        "published": "2020-10-30T07:14:23Z",
        "link": "http://arxiv.org/abs/2010.16104v2",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "A novel hydraulic fractures growth formulation",
        "authors": [
            "Francesca Fantoni",
            "Alberto Salvadori"
        ],
        "summary": "Propagation of a fluid-driven crack in an impermeable linear elastic medium under axis-symmetric conditions is investigated in the present work. The fluid exerting the pressure inside the crack is an incompressible Newtonian one and its front is allowed to lag behind the propagating fracture tip. The tip cavity is considered as filled by fluid vapors under constant pressure having a negligible value with respect to the far field confining stress. A novel algorithm is here presented, which is capable of tracking the evolution of both the fluid and the fracture fronts. Particularly, the fracture tracking is grounded on a recent viscous regularization of the quasi-static crack propagation problem as a standard dissipative system. It allows a simple and effective approximation of the fracture front velocity by imposing Griffith's criterion at every propagation step. Furthermore, for each new fracture configuration, a non linear system of integro-differential equations has to be solved. It arises from the non local elastic relationship existing between the crack opening and the fluid pressure, together with the non linear lubrication equation governing the flow of the fluid inside the fracture.",
        "published": "2020-10-30T15:06:35Z",
        "link": "http://arxiv.org/abs/2011.06417v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "physics.flu-dyn"
        ]
    },
    {
        "title": "A multiscale model of terrain dynamics for real-time earthmoving   simulation",
        "authors": [
            "Martin Servin",
            "Tomas Berglund",
            "Samuel Nystedt"
        ],
        "summary": "A multiscale model for real-time simulation of terrain dynamics is explored. To represent the dynamics on different scales the model combines the description of soil as a continuous solid, as distinct particles and as rigid multibodies. The models are dynamically coupled to each other and to the earthmoving equipment. Agitated soil is represented by a hybrid of contacting particles and continuum solid, with the moving equipment and resting soil as geometric boundaries. Each zone of active soil is aggregated into distinct bodies, with the proper mass, momentum and frictional-cohesive properties, which constrain the equipment's multibody dynamics. The particle model parameters are pre-calibrated to the bulk mechanical parameters for a wide range of different soils. The result is a computationally efficient model for earthmoving operations that resolve the motion of the soil, using a fast iterative solver, and provide realistic forces and dynamic for the equipment, using a direct solver for high numerical precision. Numerical simulations of excavation and bulldozing operations are performed to validate the model and measure the computational performance. Reference data is produced using coupled discrete element and multibody dynamics simulations at relatively high resolution. The digging resistance and soil displacements with the real-time multiscale model agree with the reference model up to 10-25%, and run more than three orders of magnitude faster.",
        "published": "2020-11-01T09:51:07Z",
        "link": "http://arxiv.org/abs/2011.00459v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Phase field predictions of microscopic fracture and R-curve behaviour of   fibre-reinforced composites",
        "authors": [
            "Wei Tan",
            "Emilio Martínez-Pañeda"
        ],
        "summary": "We present a computational framework to explore the effect of microstructure and constituent properties upon the fracture toughness of fibre-reinforced polymer composites. To capture microscopic matrix cracking and fibre-matrix debonding, the framework couples the phase field fracture method and a cohesive zone model in the context of the finite element method. Virtual single-notched three point bending tests are conducted. The actual microstructure of the composite is simulated by an embedded cell in the fracture process zone, while the remaining area is homogenised to be an anisotropic elastic solid. A detailed comparison of the predicted results with experimental observations reveals that it is possible to accurately capture the crack path, interface debonding and load versus displacement response. The sensitivity of the crack growth resistance curve (R-curve) to the matrix fracture toughness and the fibre-matrix interface properties is determined. The influence of porosity upon the R-curve of fibre-reinforced composites is also explored, revealing a stabler response with increasing void volume fraction. These results shed light into microscopic fracture mechanisms and set the basis for efficient design of high fracture toughness composites.",
        "published": "2020-11-02T07:10:31Z",
        "link": "http://arxiv.org/abs/2011.00779v1",
        "categories": [
            "physics.app-ph",
            "cond-mat.mtrl-sci",
            "cs.CE"
        ]
    },
    {
        "title": "Non-Equilibrium Skewness, Market Crises, and Option Pricing: Non-Linear   Langevin Model of Markets with Supersymmetry",
        "authors": [
            "Igor Halperin"
        ],
        "summary": "This paper presents a tractable model of non-linear dynamics of market returns using a Langevin approach. Due to non-linearity of an interaction potential, the model admits regimes of both small and large return fluctuations. Langevin dynamics are mapped onto an equivalent quantum mechanical (QM) system. Borrowing ideas from supersymmetric quantum mechanics (SUSY QM), a parameterized ground state wave function (WF) of this QM system is used as a direct input to the model, which also fixes a non-linear Langevin potential. Using a two-component Gaussian mixture as a ground state WF with an asymmetric double well potential produces a tractable low-parametric model with interpretable parameters, referred to as the NES (Non-Equilibrium Skew) model. Supersymmetry (SUSY) is then used to find time-dependent solutions of the model in an analytically tractable way. Additional approximations give rise to a final practical version of the NES model, where real-measure and risk-neutral return distributions are given by three component Gaussian mixtures. This produces a closed-form approximation for option pricing in the NES model by a mixture of three Black-Scholes prices, providing accurate calibration to option prices for either benign or distressed market environments, while using only a single volatility parameter. These results stand in stark contrast to the most of other option pricing models such as local, stochastic, or rough volatility models that need more complex specifications of noise to fit the market data.",
        "published": "2020-11-03T01:56:06Z",
        "link": "http://arxiv.org/abs/2011.01417v3",
        "categories": [
            "q-fin.CP",
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "A Data-Driven Machine Learning Approach for Consumer Modeling with Load   Disaggregation",
        "authors": [
            "A. Khaled Zarabie",
            "Sanjoy Das",
            "Hongyu Wu"
        ],
        "summary": "While non-parametric models, such as neural networks, are sufficient in the load forecasting, separate estimates of fixed and shiftable loads are beneficial to a wide range of applications such as distribution system operational planning, load scheduling, energy trading, and utility demand response programs. A semi-parametric estimation model is usually required, where cost sensitivities of demands must be known. Existing research work consistently uses somewhat arbitrary parameters that seem to work best. In this paper, we propose a generic class of data-driven semiparametric models derived from consumption data of residential consumers. A two-stage machine learning approach is developed. In the first stage, disaggregation of the load into fixed and shiftable components is accomplished by means of a hybrid algorithm consisting of non-negative matrix factorization (NMF) and Gaussian mixture models (GMM), with the latter trained by an expectation-maximization (EM) algorithm. The fixed and shiftable loads are subject to analytic treatment with economic considerations. In the second stage, the model parameters are estimated using an L2-norm, epsilon-insensitive regression approach. Actual energy usage data of two residential customers show the validity of the proposed method.",
        "published": "2020-11-04T13:36:11Z",
        "link": "http://arxiv.org/abs/2011.03519v1",
        "categories": [
            "eess.SP",
            "cs.CE",
            "cs.LG",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "A Multi-Stage Adaptive Sampling Scheme for Passivity Characterization of   Large-Scale Macromodels",
        "authors": [
            "Marco De Stefano",
            "Stefano Grivet-Talocia",
            "Torben Wendt",
            "Cheng Yang",
            "Christian Schuster"
        ],
        "summary": "This paper proposes a hierarchical adaptive sampling scheme for passivity characterization of large-scale linear lumped macromodels. Here, large-scale is intended both in terms of dynamic order and especially number of input/output ports. Standard passivity characterization approaches based on spectral properties of associated Hamiltonian matrices are either inefficient or non-applicable for large-scale models, due to an excessive computational cost. This paper builds on existing adaptive sampling methods and proposes a hybrid multi-stage algorithm that is able to detect the passivity violations with limited computing resources. Results from extensive testing demonstrate a major reduction in computational requirements with respect to competing approaches.",
        "published": "2020-11-05T12:48:25Z",
        "link": "http://arxiv.org/abs/2011.02789v1",
        "categories": [
            "cs.CE",
            "math.OC",
            "93C05, 93B15, 93C05, 37M99"
        ]
    },
    {
        "title": "Applying a Legendre collocation method based on domain decomposition to   calculate underwater sound propagation in a horizontally stratified   environment",
        "authors": [
            "Houwang Tu",
            "Yongxian Wang",
            "Qiang Lan",
            "Wei Liu",
            "Wenbin Xiao",
            "Shuqing Ma"
        ],
        "summary": "The propagation of sound waves in a horizontally stratified environment, a classic problem in ocean acoustics, has traditionally been calculated using normal modes. Most programs based on the normal mode model are discretized using the finite difference method (FDM). In this paper, a Legendre collocation method (LCM) based on domain decomposition is proposed to solve this problem. A set of collocation points cannot penetrate multiple layers of media, thus necessitating domain decomposition and the use of multiple sets of collocation points. The solution process of this method proceeds entirely in physical space, requiring that the original differential equation be strictly established at the collocation points; thus, a dense matrix eigenvalue system is formed, from which the solution for the horizontal wavenumbers and modes can be directly obtained. Numerical experiments are presented to demonstrate the validity and applicability of this method. A comparison with other methods shows that the LCM proposed in this article is more accurate than the FDM and offers roughly the same accuracy as but a faster calculation speed than other types of spectral methods.",
        "published": "2020-11-05T14:22:01Z",
        "link": "http://arxiv.org/abs/2011.02850v4",
        "categories": [
            "cs.CE",
            "math.SP",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Fast Solver for Quasi-Periodic 2D-Helmholtz Scattering in Layered Media",
        "authors": [
            "José Pinto",
            "Rubén Aylwin",
            "Carlos Jerez-Hanckes"
        ],
        "summary": "We present a fast spectral Galerkin scheme for the discretization of boundary integral equations arising from two-dimensional Helmholtz transmission problems in multi-layered periodic structures or gratings. Employing suitably parametrized Fourier basis and excluding Rayleigh-Wood anomalies, we rigorously establish the well-posedness of both continuous and discrete problems, and prove super-algebraic error convergence rates for the proposed scheme. Through several numerical examples, we confirm our findings and show performances competitive to those attained via Nystr\\\"om methods.",
        "published": "2020-11-05T15:29:57Z",
        "link": "http://arxiv.org/abs/2011.02905v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "65N35, 65N38, 45M15, 78A45"
        ]
    },
    {
        "title": "Accelerating frequency-domain numerical methods for weakly nonlinear   focused ultrasound using nested meshes",
        "authors": [
            "Samuel P. Groth",
            "Pierre Gélat",
            "Seyyed R. Haqshenas",
            "Nader Saffari",
            "Elwin van 't Wout",
            "Timo Betcke",
            "Garth N. Wells"
        ],
        "summary": "The numerical simulation of weakly nonlinear ultrasound is important in treatment planning for focused ultrasound (FUS) therapies. However, the large domain sizes and generation of higher harmonics at the focus make these problems extremely computationally demanding. Numerical methods typically employ a uniform mesh fine enough to resolve the highest harmonic present in the problem, leading to a very large number of degrees of freedom. This paper proposes a more efficient strategy in which each harmonic is approximated on a separate mesh, the size of which is proportional to the wavelength of the harmonic. The increase in resolution required to resolve a smaller wavelength is balanced by a reduction in the domain size. This nested meshing is feasible owing to the increasingly localised nature of higher harmonics near the focus.   Numerical experiments are performed for FUS transducers in homogeneous media in order to determine the size of the meshes required to accurately represent the harmonics. In particular, a fast \\emph{volume potential} approach is proposed and employed to perform convergence experiments as the computation domain size is modified. This approach allows each harmonic to be computed via the evaluation of an integral over the domain. Discretising this integral using the midpoint rule allows the computations to be performed rapidly with the FFT. It is shown that at least an order of magnitude reduction in memory consumption and computation time can be achieved with nested meshing. Finally, it is demonstrated how to generalise this approach to inhomogeneous propagation domains.",
        "published": "2020-11-05T18:06:57Z",
        "link": "http://arxiv.org/abs/2011.03009v3",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Magnetic Field Simulations Using Explicit Time Integration With Higher   Order Schemes",
        "authors": [
            "Bernhard Kähne",
            "Markus Clemens",
            "Sebastian Schöps"
        ],
        "summary": "A transient magneto-quasistatic vector potential formulation involving nonlinear material is spatially discretized using the finite element method of first and second polynomial order. By applying a generalized Schur complement the resulting system of differential algebraic equations is reformulated into a system of ordinary differential equations (ODE). The ODE system is integrated in time using the explicit Euler scheme, which is conditionally stable by a maximum time step size. To overcome this limit, an explicit multistage Runge-Kutta-Chebyshev time integration method of higher order is employed to enlarge the maximum stable time step size. Both time integration methods are compared regarding the overall computational effort.",
        "published": "2020-11-05T19:50:07Z",
        "link": "http://arxiv.org/abs/2011.03075v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Multiscale Reduced-Order Modeling of a Titanium Skin Panel Subjected to   Thermo-Mechanical Loading",
        "authors": [
            "Xiang Zhang",
            "Yang Liu",
            "Caglar Oskay"
        ],
        "summary": "This manuscript presents the formulation, implementation, calibration and application of a multiscale reduced-order model to simulate a titanium panel structure subjected to thermo-mechanical loading associated with high-speed flight. The formulation is based on the eigenstrain-based reduced-order homogenization model (EHM) and further considers thermal strain as well as temperature dependent material properties and evolution laws. The material microstructure (i.e., at the scale of a polycrystalline representative volume element (RVE)) and underlying microstructural mechanisms are directly incorporated and fully coupled with a structural analysis, allowing concurrently probing the response at the structural scale and the material microscale. The proposed approach was fully calibrated using a series of uniaxial tension tests of Ti-6242S at a wide range of temperatures and two different strain rates. The calibrated model is then adopted to study the response of a generic aircraft skin panel subjected to thermo-mechanical loading associated with high-speed flight. The analysis focuses on demonstrating the capability of the model to predict not only the structural scale response, but simultaneously the microscale response, and further studies the effects of temperature and texture on the response.",
        "published": "2020-11-08T06:03:15Z",
        "link": "http://arxiv.org/abs/2011.03907v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Exploring market power using deep reinforcement learning for intelligent   bidding strategies",
        "authors": [
            "Alexander J. M. Kell",
            "Matthew Forshaw",
            "A. Stephen McGough"
        ],
        "summary": "Decentralized electricity markets are often dominated by a small set of generator companies who control the majority of the capacity. In this paper, we explore the effect of the total controlled electricity capacity by a single, or group, of generator companies can have on the average electricity price. We demonstrate this through the use of ElecSim, a simulation of a country-wide energy market. We develop a strategic agent, representing a generation company, which uses a deep deterministic policy gradient reinforcement learning algorithm to bid in a uniform pricing electricity market. A uniform pricing market is one where all players are paid the highest accepted price. ElecSim is parameterized to the United Kingdom for the year 2018. This work can help inform policy on how to best regulate a market to ensure that the price of electricity remains competitive.   We find that capacity has an impact on the average electricity price in a single year. If any single generator company, or a collaborating group of generator companies, control more than ${\\sim}$11$\\%$ of generation capacity and bid strategically, prices begin to increase by ${\\sim}$25$\\%$. The value of ${\\sim}$25\\% and ${\\sim}$11\\% may vary between market structures and countries. For instance, different load profiles may favour a particular type of generator or a different distribution of generation capacity. Once the capacity controlled by a generator company, which bids strategically, is higher than ${\\sim}$35\\%, prices increase exponentially. We observe that the use of a market cap of approximately double the average market price has the effect of significantly decreasing this effect and maintaining a competitive market. A fair and competitive electricity market provides value to consumers and enables a more competitive economy through the utilisation of electricity by both industry and consumers.",
        "published": "2020-11-08T21:07:42Z",
        "link": "http://arxiv.org/abs/2011.04079v1",
        "categories": [
            "cs.CE",
            "cs.AI"
        ]
    },
    {
        "title": "An application of an Embedded Model Estimator to a synthetic   non-stationary reservoir model with multiple secondary variables",
        "authors": [
            "Colin Daly"
        ],
        "summary": "A method (Ember) for non-stationary spatial modelling with multiple secondary variables by combining Geostatistics with Random Forests is applied to a three-dimensional Reservoir Model. It extends the Random Forest method to an interpolation algorithm retaining similar consistency properties to both Geostatistical algorithms and Random Forests. It allows embedding of simpler interpolation algorithms into the process, combining them through the Random Forest training process. The algorithm estimates a conditional distribution at each target location. The family of such distributions is called the model envelope. An algorithm to produce stochastic simulations from the envelope is demonstrated. This algorithm allows the influence of the secondary variables as well as the variability of the result to vary by location in the simulation.",
        "published": "2020-11-09T00:15:06Z",
        "link": "http://arxiv.org/abs/2011.05561v1",
        "categories": [
            "cs.CE",
            "stat.AP"
        ]
    },
    {
        "title": "Inexact Methods for Sequential Fully Implicit (SFI) Reservoir Simulation",
        "authors": [
            "Jiamin Jiang",
            "Pavel Tomin",
            "Yifan Zhou"
        ],
        "summary": "The sequential fully implicit (SFI) scheme was introduced (Jenny et al. 2006) for solving coupled flow and transport problems. Each time step for SFI consists of an outer loop, in which there are inner Newton loops to implicitly and sequentially solve the pressure and transport sub-problems. In standard SFI, the sub-problems are usually solved with tight tolerances at every outer iteration. This can result in wasted computations that contribute little progress towards the coupled solution. The issue is known as `over-solving'. Our objective is to minimize the cost of inner solvers while maintaining the convergence rate of SFI. We first extended a nonlinear-acceleration (NA) framework (Jiang and Tchelepi 2019) to multi-component compositional models, for ensuring robust outer-loop convergence. We then developed inexact-type methods that alleviate `over-solving'. It is found that there is no need for one sub-problem to strive for perfection, while the coupled (outer) residual remains high due to the other sub-problem. The new SFI solver was tested using several complex cases. The problems involve multi-phase and EoS-based compositional fluid systems. We compared different strategies such as fixed relaxations on absolute and relative tolerances for the inner solvers, as well as an adaptive approach. The results show that the basic SFI method is quite inefficient. Away from a coupled solution, additional accuracy achieved in inner solvers is wasted, contributing to little or no reduction of the overall outer residual. By comparison, the adaptive inexact method provides relative tolerances adequate for the current convergence state of the sub-problems. We show across a wide range of flow conditions that the new solver can effectively resolve the over-solving issue, and thus greatly improve the overall efficiency.",
        "published": "2020-11-09T14:15:14Z",
        "link": "http://arxiv.org/abs/2011.06411v2",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "physics.comp-ph"
        ]
    },
    {
        "title": "A dual adaptive explicit time integration algorithm for efficiently   solving the cardiac monodomain equation",
        "authors": [
            "Konstantinos A Mountris",
            "Esther Pueyo"
        ],
        "summary": "The monodomain model is widely used in in-silico cardiology to describe excitation propagation in the myocardium. Frequently, operator splitting is used to decouple the stiff reaction term and the diffusion term in the monodomain model so that they can be solved separately. Commonly, the diffusion term is solved implicitly with a large time step while the reaction term is solved by using an explicit method with adaptive time stepping. In this work, we propose a fully explicit method for the solution of the decoupled monodomain model. In contrast to semi-implicit methods, fully explicit methods present lower memory footprint and higher scalability. However, such methods are only conditionally stable. We overcome the conditional stability limitation by proposing a dual adaptive explicit method in which adaptive time integration is applied for the solution of both the reaction and diffusion terms. In a set of numerical examples where cardiac propagation is simulated under physiological and pathophysiological conditions, results show that our proposed method presents preserved accuracy and improved computational efficiency as compared to standard operator splitting-based methods.",
        "published": "2020-11-09T20:43:09Z",
        "link": "http://arxiv.org/abs/2011.04747v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Interaction of void spacing and material size effect on inter-void flow   localisation",
        "authors": [
            "I. Holte",
            "A. Srivastava",
            "E. Martínez-Pañeda",
            "C. F. Niordson",
            "K. L. Nielsen"
        ],
        "summary": "The ductile fracture process in porous metals due to growth and coalescence of micron scale voids is not only affected by the imposed stress state but also by the distribution of the voids and the material size effect. The objective of this work is to understand the interaction of the inter-void spacing (or ligaments) and the resultant gradient induced material size effect on void coalescence for a range of imposed stress states. To this end, three dimensional finite element calculations of unit cell models with a discrete void embedded in a strain gradient enhanced material matrix are performed. The calculations are carried out for a range of initial inter-void ligament sizes and imposed stress states characterised by fixed values of the stress triaxiality and the Lode parameter. Our results show that in the absence of strain gradient effects on the material response, decreasing the inter-void ligament size results in an increase in the propensity for void coalescence. However, in a strain gradient enhanced material matrix, the strain gradients harden the material in the inter-void ligament and decrease the effect of inter-void ligament size on the propensity for void coalescence.",
        "published": "2020-11-10T06:38:19Z",
        "link": "http://arxiv.org/abs/2011.04937v1",
        "categories": [
            "physics.app-ph",
            "cond-mat.mtrl-sci",
            "cs.CE"
        ]
    },
    {
        "title": "Wavelet Adaptive Proper Orthogonal Decomposition for Large Scale Flow   Data",
        "authors": [
            "Philipp Krah",
            "Thomas Engels",
            "Kai Schneider",
            "Julius Reiss"
        ],
        "summary": "The proper orthogonal decomposition (POD) is a powerful classical tool in fluid mechanics used, for instance, for model reduction and extraction of coherent flow features. However, its applicability to high-resolution data, as produced by three-dimensional direct numerical simulations, is limited owing to its computational complexity. Here, we propose a wavelet-based adaptive version of the POD (the wPOD), in order to overcome this limitation. The amount of data to be analyzed is reduced by compressing them using biorthogonal wavelets, yielding a sparse representation while conveniently providing control of the compression error. Numerical analysis shows how the distinct error contributions of wavelet compression and POD truncation can be balanced under certain assumptions, allowing us to efficiently process high-resolution data from three-dimensional simulations of flow problems. Using a synthetic academic test case, we compare our algorithm with the randomized singular value decomposition. Furthermore, we demonstrate the ability of our method analyzing data of a 2D wake flow and a 3D flow generated by a flapping insect computed with direct numerical simulation.",
        "published": "2020-11-10T10:13:51Z",
        "link": "http://arxiv.org/abs/2011.05016v1",
        "categories": [
            "physics.flu-dyn",
            "cs.CE",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Nonlinear Iterative Projection Methods with Multigrid in Photon   Frequency for Thermal Radiative Transfer",
        "authors": [
            "Dmitriy Y. Anistratov"
        ],
        "summary": "This paper presents nonlinear iterative methods for the fundamental thermal radiative transfer (TRT) model defined by the time-dependent multifrequency radiative transfer (RT) equation and the material energy balance (MEB) equation. The iterative methods are based on the nonlinear projection approach and use multiple grids in photon frequency. They are formulated by the high-order RT equation on a given grid in photon frequency and low-order moment equations on a hierarchy of frequency grids. The material temperature is evaluated in the subspace of the lowest dimensionality from the MEB equation coupled to the effective grey low-order equations. The algorithms apply various multigrid cycles to visit frequency grids. Numerical results are presented to demonstrate convergence of the multigrid iterative algorithms in TRT problems with large number of photon frequency groups.",
        "published": "2020-11-10T22:18:36Z",
        "link": "http://arxiv.org/abs/2011.05427v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Lattice meets lattice: Application of lattice cubature to models in   lattice gauge theory",
        "authors": [
            "Tobias Hartung",
            "Karl Jansen",
            "Frances Y. Kuo",
            "Hernan Leövey",
            "Dirk Nuyens",
            "Ian H. Sloan"
        ],
        "summary": "High dimensional integrals are abundant in many fields of research including quantum physics. The aim of this paper is to develop efficient recursive strategies to tackle a class of high dimensional integrals having a special product structure with low order couplings, motivated by models in lattice gauge theory from quantum field theory. A novel element of this work is the potential benefit in using lattice cubature rules. The group structure within lattice rules combined with the special structure in the physics integrands may allow efficient computations based on Fast Fourier Transforms. Applications to the quantum mechanical rotor and compact $U(1)$ lattice gauge theory in two and three dimensions are considered.",
        "published": "2020-11-10T23:11:12Z",
        "link": "http://arxiv.org/abs/2011.05451v2",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "hep-lat",
            "65D30, 65D32, 65T50, 65Z05, 81T80"
        ]
    },
    {
        "title": "Effects of modal energy scattering and friction on the resonance   mitigation with an impact absorber",
        "authors": [
            "Timo Theurich",
            "Johann Gross",
            "Malte Krack"
        ],
        "summary": "A linear vibration absorber can be tuned to effectively suppress the resonance of a particular vibration mode. It relies on the targeted energy transfer into the absorber within a narrow and fixed frequency band. Nonlinear energy sinks (NES) have a similar working principle. They are effective in a much wider frequency band but generally only in a limited range of excitation levels. To design NES, their working principle must be thoroughly understood. We consider a particular type of NES, a small mass undergoing impacts and dry friction within a cavity of a base structure (vibro-impact NES or impact absorber). The nonlinear dynamic regimes under near-resonant forcing and resulting operating ranges are first revisited. We then investigate how off-resonant vibration modes and dissipation via impacts and dry friction contribute to the vibration suppression. Moreover, we assess the effectiveness of the impact absorber for suppressing multiple resonances in comparison to a linear tuned vibration absorber (LTVA) and a pure friction damper with the same mass.",
        "published": "2020-11-11T09:43:07Z",
        "link": "http://arxiv.org/abs/2012.07539v1",
        "categories": [
            "physics.app-ph",
            "cs.CE"
        ]
    },
    {
        "title": "BESS Optimal Sizing Methodology -Degree of Impact of Several Influencing   Factors",
        "authors": [
            "Benoît Richard",
            "Xavier Le Pivert",
            "Yves-Marie Bourien"
        ],
        "summary": "Battery Energy Storage Systems (BESS) are more and more competitive due to their increasing performances and decreasing costs. Although certain battery storage technologies may be mature and reliable from a technological perspective, with further cost reductions expected, the economic concern of battery systems is still a major barrier to be overcome before BESS can be fully utilized as a mainstream storage solution in the energy sector. Since the investment costs for deploying BESS are significant, one of the most crucial issues is to optimally size the battery system to balance the trade-off between using BESS to improve energy system performance and to achieve profitable investment. Determining the optimal BESS size for a specific application is a complex task because it relies on many factors, depending on the application itself, on the technical characteristics of the battery system and on the business model framework. This paper describes a generic simulation-based analytical method which has been developed to determine the BESS optimal size by taking into account both the application and the storage performance over its lifetime. Its implementation and the associated results are presented for two different BESS use cases: A smoothing and peak shaving application for PV injection and an off-grid hybrid microgrid case. In order to provide a better understanding of the most influencing drivers to consider during a BESS sizing procedure, several sensitivity analyses have been carried out on these two illustrative cases. The use of comparative scenarios led to quantify the degree of impact on optimal sizing results of several factors among the following topics: control strategy, forecast quality, degradation of battery performance due to ageing, precision of technical modelling.",
        "published": "2020-11-13T15:21:24Z",
        "link": "http://arxiv.org/abs/2011.06963v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A universal predictor-corrector type incremental algorithm for the   construction of weighted straight skeletons based on the notion of deforming   polygon",
        "authors": [
            "Baris Irhan"
        ],
        "summary": "A new predictor-corrector type incremental algorithm is proposed for the exact construction of weighted straight skeletons of 2D general planar polygons of arbitrary complexity based on the notion of deforming polygon. In the proposed algorithm, the raw input provided by the polygon itself is enough to resolve edge collapse and edge split events. Neither the construction of a kinetic triangulation nor the computation of a motorcycle graph is required. Due to its incremental nature, there is always a room in the algorithm for the interactive construction of the straight skeleton. The proposed algorithm is of predictor-corrector type. In the algorithm, the edge collapse and edge split events are tackled by a completely different novel original approach which is first of its kind. In the predictor step, the position of the vertices is advanced in time by direct integration assuming no event. Then predicted positions are corrected by using linear interpolation if there are edge collapse or edge split events within the same increment. In the algorithm edge collapse and edge split events are detected by, respectively, edge swap and edge penetration. The proposed algorithm has been used to construct roof topology starting from a floor plan of various complexity ranging from simple convex to highly nonconvex with holes. In order to construct, improve and test the building blocks of the underlying algorithm, a graphical user interface, Straight Skeleton Development Kit, has also been developed in parallel by the author using C++ programming language.",
        "published": "2020-11-13T19:54:09Z",
        "link": "http://arxiv.org/abs/2011.07107v1",
        "categories": [
            "cs.CG",
            "cs.CE"
        ]
    },
    {
        "title": "Identifying and tracking bubbles and drops in simulations: a toolbox for   obtaining sizes, lineages, and breakup and coalescence statistics",
        "authors": [
            "Wai Hong Ronald Chan",
            "Michael S. Dodd",
            "Perry L. Johnson",
            "Parviz Moin"
        ],
        "summary": "Knowledge of bubble and drop size distributions in two-phase flows is important for characterizing a wide range of phenomena, including combustor ignition, sonar communication, and cloud formation. The physical mechanisms driving the background flow also drive the time evolution of these distributions. Accurate and robust identification and tracking algorithms for the dispersed phase are necessary to reliably measure this evolution and thereby quantify the underlying mechanisms in interface-resolving flow simulations. The identification of individual bubbles and drops traditionally relies on an algorithm used to identify connected regions. This traditional algorithm can be sensitive to the presence of spurious structures. A cost-effective refinement is proposed to maximize volume accuracy while minimizing the identification of spurious bubbles and drops. An accurate identification scheme is crucial for distinguishing bubble and drop pairs with large size ratios. The identified bubbles and drops need to be tracked in time to obtain breakup and coalescence statistics that characterize the evolution of the size distribution, including breakup and coalescence frequencies, and the probability distributions of parent and child bubble and drop sizes. An algorithm based on mass conservation is proposed to construct bubble and drop lineages using simulation snapshots that are not necessarily from consecutive time-steps. These lineages are then used to detect breakup and coalescence events, and obtain the desired statistics. Accurate identification of large-size-ratio bubble and drop pairs enables accurate detection of breakup and coalescence events over a large size range. Together, these algorithms enable insights into the mechanisms behind bubble and drop formation and evolution in flows of practical importance.",
        "published": "2020-11-14T09:29:28Z",
        "link": "http://arxiv.org/abs/2011.07243v1",
        "categories": [
            "physics.flu-dyn",
            "cs.CE",
            "physics.ao-ph",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Applications of phase field fracture in modelling hydrogen assisted   failures",
        "authors": [
            "P. K. Kristensen",
            "C. F. Niordson",
            "E. Martínez-Pañeda"
        ],
        "summary": "The phase field fracture method has emerged as a promising computational tool for modelling a variety of problems including, since recently, hydrogen embrittlement and stress corrosion cracking. In this work, we demonstrate the potential of phase field-based multi-physics models in transforming the engineering assessment and design of structural components in hydrogen-containing environments. First, we present a theoretical and numerical framework coupling deformation, diffusion and fracture, which accounts for inertia effects.Several constitutive choices are considered for the crack density function, including choices with and without an elastic phase in the damage response. The material toughness is defined as a function of the hydrogen content using an atomistically-informed hydrogen degradation law. The model is numerically implemented in 2D and 3D using the finite element method. The resulting computational framework is used to address a number of case studies of particular engineering interest. These are intended to showcase the model capabilities in: (i) capturing complex fracture phenomena, such as dynamic crack branching or void-crack interactions, (ii) simulating standardised tests for critical components, such as bolts, and (iii) enabling simulation-based paradigms such as Virtual Testing or Digital Twins by coupling model predictions with inspection data of large-scale engineering components. The evolution of defects under in-service conditions can be predicted, up to the ultimate failure. By reproducing the precise geometry of the defects, as opposed to re-characterising them as sharp cracks, phase field modelling enables more realistic and effective structural integrity assessments.",
        "published": "2020-11-14T16:08:05Z",
        "link": "http://arxiv.org/abs/2011.07328v1",
        "categories": [
            "physics.app-ph",
            "cond-mat.mtrl-sci",
            "cs.CE"
        ]
    },
    {
        "title": "Discovery of the Hidden State in Ionic Models Using a Domain-Specific   Recurrent Neural Network",
        "authors": [
            "Shahriar Iravanian"
        ],
        "summary": "Ionic models, the set of ordinary differential equations (ODEs) describing the time evolution of the state of excitable cells, are the cornerstone of modeling in neuro- and cardiac electrophysiology. Modern ionic models can have tens of state variables and hundreds of tunable parameters. Fitting ionic models to experimental data, which usually covers only a limited subset of state variables, remains a challenging problem. In this paper, we describe a recurrent neural network architecture designed specifically to encode ionic models. The core of the model is a Gating Neural Network (GNN) layer, capturing the dynamics of classic (Hodgkin-Huxley) gating variables. The network is trained in two steps: first, it learns the theoretical model coded in a set of ODEs, and second, it is retrained on experimental data. The retrained network is interpretable, such that its results can be incorporated back into the model ODEs. We tested the GNN networks using simulated ventricular action potential signals and showed that it could deduce physiologically-feasible alterations of ionic currents. Such domain-specific neural networks can be employed in the exploratory phase of data assimilation before further fine-tuning using standard optimization techniques.",
        "published": "2020-11-14T21:13:41Z",
        "link": "http://arxiv.org/abs/2011.07388v1",
        "categories": [
            "cs.LG",
            "cs.CE",
            "q-bio.NC",
            "I.6; J.3"
        ]
    },
    {
        "title": "Robust and Efficient Multilevel-ILU Preconditioning of Hybrid   Newton-GMRES for Incompressible Navier-Stokes Equations",
        "authors": [
            "Qiao Chen",
            "Xiangmin Jiao",
            "Oliver Yang"
        ],
        "summary": "We introduce a robust and efficient preconditioner for a hybrid Newton-GMRES method for solving the nonlinear systems arising from incompressible Navier-Stokes equations. When the Reynolds number is relatively high, these systems often involve millions of degrees of freedom (DOFs), and the nonlinear systems are difficult to converge, partially due to the strong asymmetry of the system and the saddle-point structure. In this work, we propose to alleviate these issues by leveraging a multilevel ILU preconditioner called HILUCSI, which is particularly effective for saddle-point problems and can enable robust and rapid convergence of the inner iterations in Newton-GMRES. We further use Picard iterations with the Oseen systems to hot-start Newton-GMRES to achieve global convergence, also preconditioned using HILUCSI. To further improve efficiency and robustness, we use the Oseen operators as physics-based sparsifiers when building preconditioners for Newton iterations and introduce adaptive refactorization and iterative refinement in HILUCSI. We refer to the resulting preconditioned hybrid Newton-GMRES as HILUNG. We demonstrate the effectiveness of HILUNG by solving the standard 2D driven-cavity problem with Re 5000 and a 3D flow-over-cylinder problem with low viscosity. We compare HILUNG with some state-of-the-art customized preconditioners for INS, including two variants of augmented Lagrangian preconditioners and two physics-based preconditioners, as well as some general-purpose approximate-factorization techniques. Our comparison shows that HILUNG is much more robust for solving high-Re problems and it is also more efficient in both memory and runtime for moderate-Re problems.",
        "published": "2020-11-14T23:00:18Z",
        "link": "http://arxiv.org/abs/2011.07410v3",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Using simulation to incorporate dynamic criteria into multiple criteria   decision-making",
        "authors": [
            "Uwe Aickelin",
            "Jenna Marie Reps",
            "Peer-Olaf Siebers",
            "Peng Li"
        ],
        "summary": "In this paper, we present a case study demonstrating how dynamic and uncertain criteria can be incorporated into a multicriteria analysis with the help of discrete event simulation. The simulation guided multicriteria analysis can include both monetary and non-monetary criteria that are static or dynamic, whereas standard multi criteria analysis only deals with static criteria and cost benefit analysis only deals with static monetary criteria. The dynamic and uncertain criteria are incorporated by using simulation to explore how the decision options perform. The results of the simulation are then fed into the multicriteria analysis. By enabling the incorporation of dynamic and uncertain criteria, the dynamic multiple criteria analysis was able to take a unique perspective of the problem. The highest ranked option returned by the dynamic multicriteria analysis differed from the other decision aid techniques.",
        "published": "2020-11-16T05:11:45Z",
        "link": "http://arxiv.org/abs/2011.09891v1",
        "categories": [
            "cs.AI",
            "cs.CE"
        ]
    },
    {
        "title": "A General Numerical Method to Model Anisotropy in Discretized Bond-Based   Peridynamics",
        "authors": [
            "Naveen Prakash"
        ],
        "summary": "This work proposes a novel, general and robust method of determining bond micromoduli for anisotropic linear elastic bond-based peridynamics. The problem of finding a discrete distribution of bond micromoduli that reproduces an anisotropic peridynamic stiffness tensor is cast as a least-squares problem. The proposed numerical method is able to find a distribution of bond micromoduli that is able to exactly reproduce a desired anisotropic stiffness tensor provided conditions of Cauchy's relations are met. Examples of all eight possible elastic material symmetries, from triclinic to isotropic are given and discussed in depth. Parametric studies are conducted to demonstrate that the numerical method is robust enough to handle a variety of horizon sizes, neighborhood shapes, influence functions and lattice rotation effects. Finally, an example problem is presented to demonstrate that the proposed method is physically sound and that the solution agrees with the analytical solution from classical elasticity. The proposed method has great potential for modeling of deformation and fracture in anisotropic materials with bond-based peridynamics.",
        "published": "2020-11-16T14:57:21Z",
        "link": "http://arxiv.org/abs/2011.08013v2",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA",
            "math.OC"
        ]
    },
    {
        "title": "Falling balls in a viscous fluid with contact: Comparing numerical   simulations with experimental data",
        "authors": [
            "Henry von Wahl",
            "Thomas Richter",
            "Stefan Frei",
            "Thomas Hagemeier"
        ],
        "summary": "We evaluate a number of different finite element approaches for fluid-structure (contact) interaction problems against data from physical experiments. For this we take the data from experiments by Hagemeier [Mendeley Data, doi: 10.17632/mf27c92nc3.1]. This consists of trajectories of single particles falling through a highly viscous fluid and rebounding off the bottom fluid tank wall. The resulting flow is in the transitional regime between creeping and turbulent flows. This type of configuration is particularly challenging for numerical methods due to the large change of the fluid domain and the contact between the wall and particle. In the numerical simulations we consider both rigid body and linear elasticity models for the falling particles. In the first case, we compare results obtained with the well established Arbitrary Lagrangian Eulerian (ALE) approach and a moving domain CutFEM method together with a simple and common approach for contact avoidance. For the full fluid-structure interaction (FSI) problem with contact, we use a fully Eulerian approach in combination with a unified FSI-contact treatment using Nitsche's method. For higher computational efficiency we use the geometrical symmetry of the experimental set up to reformulate the FSI system into two spatial dimensions. Finally, we show full three dimensional ALE computations to study the effects of small perturbations in the initial state of the particle to investigate deviations from a perfectly vertical fall observed in the experiment. The methods are implemented in open-source finite element libraries and the results are made freely available to aide reproducibility.",
        "published": "2020-11-17T15:20:59Z",
        "link": "http://arxiv.org/abs/2011.08691v1",
        "categories": [
            "physics.flu-dyn",
            "cs.CE",
            "cs.NA",
            "math.NA",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Data Driven Modeling of Interfacial Traction Separation Relations using   a Thermodynamically Consistent Neural Network",
        "authors": [
            "Congjie Wei",
            "Jiaxin Zhang",
            "Kenneth M. Liechti",
            "Chenglin Wu"
        ],
        "summary": "For multilayer structures, interfacial failure is one of the most important elements related to device reliability. For cohesive zone modelling, traction-separation relations represent the adhesive interactions across interfaces. However, existing theoretical models do not currently capture traction-separation relations that have been extracted using direct methods, particularly under mixed-mode conditions. Given the complexity of the problem, models derived from the neural network approach are attractive. Although they can be trained to fit data along the loading paths taken in a particular set of mixed-mode fracture experiments, they may fail to obey physical laws for paths not covered by the training data sets. In this paper, a thermodynamically consistent neural network (TCNN) approach is established to model the constitutive behavior of interfaces when faced with sparse training data sets. Accordingly, three conditions are examined and implemented here: (i) thermodynamic consistency, (ii) maximum energy dissipation path control and (iii) J-integral conservation. These conditions are treated as constraints and are implemented as such in the loss function. The feasibility of this approach is demonstrated by comparing the modeling results with a range of physical constraints. Moreover, a Bayesian optimization algorithm is then adopted to optimize the weight factors associated with each of the constraints in order to overcome convergence issues that can arise when multiple constraints are present. The resultant numerical implementation of the ideas presented here produced well-behaved, mixed-mode traction separation surfaces that maintained the fidelity of the experimental data that was provided as input. The proposed approach heralds a new autonomous, point-to-point constitutive modeling concept for interface mechanics.",
        "published": "2020-11-17T22:15:02Z",
        "link": "http://arxiv.org/abs/2011.09946v4",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Continuous calibration of a digital twin: comparison of particle filter   and Bayesian calibration approaches",
        "authors": [
            "Rebecca Ward",
            "Ruchi Choudhary",
            "Alastair Gregory",
            "Melanie Jans-Singh",
            "Mark Girolami"
        ],
        "summary": "Assimilation of continuously streamed monitored data is an essential component of a digital twin; the assimilated data are used to ensure the digital twin is a true representation of the monitored system. One way this is achieved is by calibration of simulation models, whether data-derived or physics-based, or a combination of both. Traditional manual calibration is not possible in this context hence new methods are required for continuous calibration. In this paper, a particle filter methodology for continuous calibration of the physics-based model element of a digital twin is presented and applied to an example of an underground farm. The methodology is applied to a synthetic problem with known calibration parameter values prior to being used in conjunction with monitored data. The proposed methodology is compared against static and sequential Bayesian calibration approaches and compares favourably in terms of determination of the distribution of parameter values and analysis run-times, both essential requirements. The methodology is shown to be potentially useful as a means to ensure continuing model fidelity.",
        "published": "2020-11-19T13:31:40Z",
        "link": "http://arxiv.org/abs/2011.09810v3",
        "categories": [
            "cs.CE",
            "J.2"
        ]
    },
    {
        "title": "PIFE-PIC: Parallel Immersed-Finite-Element Particle-In-Cell For 3-D   Kinetic Simulations of Plasma-Material Interactions",
        "authors": [
            "Daoru Han",
            "Xiaoming He",
            "David Lund",
            "Xu Zhang"
        ],
        "summary": "This paper presents a recently developed particle simulation code package PIFE-PIC, which is a novel three-dimensional (3-D) Parallel Immersed-Finite-Element (IFE) Particle-in-Cell (PIC) simulation model for particle simulations of plasma-material interactions. This framework is based on the recently developed non-homogeneous electrostatic IFE-PIC algorithm, which is designed to handle complex plasma-material interface conditions associated with irregular geometries using a Cartesian-mesh-based PIC. Three-dimensional domain decomposition is utilized for both the electrostatic field solver with IFE and the particle operations in PIC to distribute the computation among multiple processors. A simulation of the orbital-motion-limited (OML) sheath of a dielectric sphere immersed in a stationary plasma is carried out to validate PIFE-PIC and profile the parallel performance of the code package. Furthermore, a large-scale simulation of plasma charging at a lunar crater containing 2 million PIC cells (10 million FE/IFE cells) and about 520 million particles, running for 20,000 PIC steps in about 109 wall-clock hours, is presented to demonstrate the high-performance computing capability of PIFE-PIC.",
        "published": "2020-11-20T04:53:16Z",
        "link": "http://arxiv.org/abs/2011.10214v1",
        "categories": [
            "cs.MS",
            "cs.CE"
        ]
    },
    {
        "title": "Sequential Defaulting in Financial Networks",
        "authors": [
            "Pál András Papp",
            "Roger Wattenhofer"
        ],
        "summary": "We consider financial networks, where banks are connected by contracts such as debts or credit default swaps. We study the clearing problem in these systems: we want to know which banks end up in a default, and what portion of their liabilities can these defaulting banks fulfill. We analyze these networks in a sequential model where banks announce their default one at a time, and the system evolves in a step-by-step manner.   We first consider the reversible model of these systems, where banks may return from a default. We show that the stabilization time in this model can heavily depend on the ordering of announcements. However, we also show that there are systems where for any choice of ordering, the process lasts for an exponential number of steps before an eventual stabilization. We also show that finding the ordering with the smallest (or largest) number of banks ending up in default is an NP-hard problem. Furthermore, we prove that defaulting early can be an advantageous strategy for banks in some cases, and in general, finding the best time for a default announcement is NP-hard. Finally, we discuss how changing some properties of this setting affects the stabilization time of the process, and then use these techniques to devise a monotone model of the systems, which ensures that every network stabilizes eventually.",
        "published": "2020-11-20T16:30:44Z",
        "link": "http://arxiv.org/abs/2011.10485v1",
        "categories": [
            "cs.CE",
            "q-fin.RM",
            "91B74, 68Q99",
            "J.4"
        ]
    },
    {
        "title": "A modified bond model for describing isotropic linear elastic material   behaviour with the particle method",
        "authors": [
            "Rahav Gowtham Venkateswaran",
            "Ursula Kowalsky",
            "Dieter Dinkler"
        ],
        "summary": "Particle based methods such as the Discrete Element Method and the Lattice Spring Method may be used for describing the behaviour of isotropic linear elastic materials. However, the common bond models employed to describe the interaction between particles restrict the range of Poisson's ratio that can be represented. In this paper, to overcome the restriction, a modified bond model that includes the coupling of shear strain energy of neighbouring bonds is proposed. The coupling is described by a multi-bond term that enables the model to distinguish between shear deformations and rigid-body rotations. The positive definiteness of the strain energy function of the modified bond model is verified. To validate the model, uniaxial tension, pure shear, pure bending and cantilever bending tests are performed. Comparison of the particle displacements with continuum mechanics solution demonstrates the ability of the model to describe the behaviour of isotropic linear elastic material for values of Poisson's ratio in the range $0 \\leq \\nu < 0.5$.",
        "published": "2020-11-20T17:19:15Z",
        "link": "http://arxiv.org/abs/2011.10515v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "An elastic framework for ensemble-based large-scale data assimilation",
        "authors": [
            "Sebastian Friedemann",
            "Bruno Raffin"
        ],
        "summary": "Prediction of chaotic systems relies on a floating fusion of sensor data (observations) with a numerical model to decide on a good system trajectory and to compensate nonlinear feedback effects. Ensemble-based data assimilation (DA) is a major method for this concern depending on propagating an ensemble of perturbed model realizations.In this paper we develop an elastic, online, fault-tolerant and modular framework called Melissa-DA for large-scale ensemble-based DA. Melissa-DA allows elastic addition or removal of compute resources for state propagation at runtime. Dynamic load balancing based on list scheduling ensuresefficient execution. Online processing of the data produced by ensemble members enables to avoid the I/O bottleneck of file-based approaches. Our implementation embeds the PDAF parallel DA engine, enabling the use of various DA methods. Melissa-DA can support extra ensemble-based DAmethods by implementing the transformation of member background states into analysis states. Experiments confirm the excellent scalability of Melissa-DA, running on up to 16,240 cores, to propagate 16,384 members for a regional hydrological critical zone assimilation relying on theParFlow model on a domain with about 4 M grid cells.",
        "published": "2020-11-21T11:23:43Z",
        "link": "http://arxiv.org/abs/2011.11635v2",
        "categories": [
            "cs.CE",
            "cs.DC",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Imperfect Oracles: The Effect of Strategic Information on Stock Markets",
        "authors": [
            "Miklos Borsi"
        ],
        "summary": "Modern financial market dynamics warrant detailed analysis due to their significant impact on the world. This, however, often proves intractable; massive numbers of agents, strategies and their change over time in reaction to each other leads to difficulties in both theoretical and simulational approaches. Notable work has been done on strategy dominance in stock markets with respect to the ratios of agents with certain strategies. Perfect knowledge of the strategies employed could then put an individual agent at a consistent trading advantage. This research reports the effects of imperfect oracles on the system - dispensing noisy information about strategies - information which would normally be hidden from market participants. The effect and achievable profits of a singular trader with access to an oracle were tested exhaustively with previously unexplored factors such as changing order schedules. Additionally, the effect of noise on strategic information was traced through its effect on trader efficiency.",
        "published": "2020-11-21T18:23:04Z",
        "link": "http://arxiv.org/abs/2011.10837v1",
        "categories": [
            "cs.CE",
            "cs.GT",
            "cs.MA",
            "I.6.0; J.4"
        ]
    },
    {
        "title": "Blade Envelopes Part I: Concept and Methodology",
        "authors": [
            "Chun Yui Wong",
            "Pranay Seshadri",
            "Ashley Scillitoe",
            "Andrew B. Duncan",
            "Geoffrey Parks"
        ],
        "summary": "Blades manufactured through flank and point milling will likely exhibit geometric variability. Gauging the aerodynamic repercussions of such variability, prior to manufacturing a component, is challenging enough, let alone trying to predict what the amplified impact of any in-service degradation will be. While rules of thumb that govern the tolerance band can be devised based on expected boundary layer characteristics at known regions and levels of degradation, it remains a challenge to translate these insights into quantitative bounds for manufacturing. In this work, we tackle this challenge by leveraging ideas from dimension reduction to construct low-dimensional representations of aerodynamic performance metrics. These low-dimensional models can identify a subspace which contains designs that are invariant in performance -- the inactive subspace. By sampling within this subspace, we design techniques for drafting manufacturing tolerances and for quantifying whether a scanned component should be used or scrapped. We introduce the blade envelope as a computational manufacturing guide for a blade that is also amenable to qualitative visualizations. In this paper, the first of two parts, we discuss its underlying concept and detail its computational methodology, assuming one is interested only in the single objective of ensuring that the loss of all manufactured blades remains constant. To demonstrate the utility of our ideas we devise a series of computational experiments with the Von Karman Institute's LS89 turbine blade.",
        "published": "2020-11-22T11:34:59Z",
        "link": "http://arxiv.org/abs/2011.11636v5",
        "categories": [
            "cs.CE",
            "stat.AP"
        ]
    },
    {
        "title": "On the implementation of large-scale integral operators with modern HPC   solutions -- Application to 3D Marchenko imaging by least-squares inversion",
        "authors": [
            "Matteo Ravasi",
            "Ivan Vasconcelos"
        ],
        "summary": "Numerical integral operators of convolution type form the basis of most wave-equation-based methods for processing and imaging of seismic data. As several of these methods require the solution of an inverse problem, multiple forward and adjoint passes of the modelling operator must be performed to converge to a satisfactory solution. This work highlights the challenges that arise when implementing such operators on 3D seismic datasets and it provides insights into their usage for solving large systems of integral equations. A Python framework is presented that leverages libraries for distributed storage and computing, and provides an high-level symbolic representation of linear operators. To validate its effectiveness, the forward and adjoint implementations of a multi-dimensional convolution operator are evaluated with respect to increasing size of the kernel and number of computational resources. Our computational framework is further shown to be suitable for both classic on-premise High-Performance Computing and cloud computing architectures. An example of target-oriented imaging of a 3D synthetic dataset which comprises of two subsequent steps of seismic redatuming is finally presented. In both cases, the redatumed fields are estimated by means of least-squares inversion using the full dataset as well as spatially decimated versions of the dataset as a way to investigate the robustness of both inverse problems to spatial aliasing in the input dataset. We observe that less strict sampling requirements apply in three dimensions for these algorithms compared to their two dimensions counterparts. Whilst aliasing introduces noise in the redatumed fields, they are however deprived of the well-known spurious artefacts arising from incorrect handling of the overburden propagation in cheaper, adjoint-based redatuming techniques.",
        "published": "2020-11-22T22:09:28Z",
        "link": "http://arxiv.org/abs/2011.11120v1",
        "categories": [
            "physics.geo-ph",
            "cs.CE"
        ]
    },
    {
        "title": "A Geometrically Exact Continuum Framework for Light-Matter Interaction   in Photo-Active Polymers I. Variational Setting",
        "authors": [
            "M Mehnert",
            "W Oates",
            "P Steinmann"
        ],
        "summary": "Molecular photo-switches as, e.g., azobenzene molecules allow, when embedded into a polymeric matrix, for photo-active polymer compounds responding mechanically when exposed to light of certain wavelength. Photo-mechanics, i.e. light-matter interaction in photo-active polymers holds great promise for, e.g., remote and contact-free activation of photo-driven actuators. In a series of earlier contributions, Oates et al. developed a successful continuum formulation for the coupled electric, electronic and mechanical problem capturing azobenzene polymer compounds, thereby mainly focussing on geometrically linearized kinematics. Building on that formulation, we here explore the variational setting of a geometrically exact continuum framework based on Dirichlet's and Hamilton's principle as well as, noteworthy, Hamilton's equations. Thereby, when treating the dissipative case, we resort to incremental versions of the various variational problems via suited incorporation of a dissipation potential. In particular, the Hamiltonian setting of geometrically exact photo-mechanics is up to now largely under-explored even for the energetic case, arguably since the corresponding Lagrangian is degenerate in Dirac's sense. Moreover, in general, the Hamiltonian setting of dissipative dynamical systems is a matter of ongoing debate per se. In this contribution, by advocating a novel incremental version of the Hamiltonian setting exemplified for the dissipative case of photo-mechanics, we aim to also unify the variational approach to dissipative dynamical systems. Taken together, the variational setting of a geometrically exact continuum framework of photo-mechanics paves the way for forthcoming theoretical and numerical analyses.",
        "published": "2020-11-23T04:30:17Z",
        "link": "http://arxiv.org/abs/2011.11205v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "An automatic-adaptivity stabilized finite element method via residual   minimization for heterogeneous, anisotropic advection-diffusion-reaction   problems",
        "authors": [
            "Roberto J. Cier",
            "Sergio Rojas",
            "Victor M. Calo"
        ],
        "summary": "In this paper, we describe a stable finite element formulation for advection-diffusion-reaction problems that allows for robust automatic adaptive strategies to be easily implemented. We consider locally vanishing, heterogeneous, and anisotropic diffusivities, as well as advection-dominated diffusion problems. The general stabilized finite element framework was described and analyzed in arXiv:1907.12605v3 for linear problems in general, and tested for pure advection problems. The method seeks for the discrete solution through a residual minimization process on a proper stable discontinuous Galerkin (dG) dual norm. This technique leads to a saddle-point problem that delivers a stable discrete solution and a robust error estimate that can drive mesh adaptivity. In this work, we demonstrate the efficiency of the method in extreme scenarios, delivering stable solutions. The quality and performance of the solutions are comparable to classical discontinuous Galerkin formulations in the respective discrete space norm on each mesh. Meanwhile, this technique allows us to solve on coarse meshes and adapt the solution to achieve a user-specified solution quality.",
        "published": "2020-11-23T08:09:16Z",
        "link": "http://arxiv.org/abs/2011.11264v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Simulating an Object-Oriented Financial System in a Functional Language",
        "authors": [
            "Lee Braine",
            "Keith Haviland",
            "Owen Smith-Jaynes",
            "Andy Vautier",
            "Chris Clack"
        ],
        "summary": "This paper summarises a successful application of functional programming within a commercial environment. We report on experience at Accenture's Financial Services Solution Centre in London with simulating an object-oriented financial system in order to assist analysis and design. The work was part of a large IT project for an international investment bank and provides a pragmatic case study.",
        "published": "2020-11-23T18:11:26Z",
        "link": "http://arxiv.org/abs/2011.11593v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A phase field formulation for dissolution-driven stress corrosion   cracking",
        "authors": [
            "Chuanjie Cui",
            "Rujin Ma",
            "Emilio Martínez-Pañeda"
        ],
        "summary": "We present a new theoretical and numerical framework for modelling mechanically-assisted corrosion in elastic-plastic solids. Both pitting and stress corrosion cracking (SCC) can be captured, as well as the pit-to-crack transition. Localised corrosion is assumed to be dissolution-driven and a formulation grounded upon the film rupture-dissolution-repassivation mechanism is presented to incorporate the influence of film passivation. The model incorporates, for the first time, the role of mechanical straining as the electrochemical driving force, accelerating corrosion kinetics. The computational complexities associated with tracking the evolving metal-electrolyte interface are resolved by making use of a phase field paradigm, enabling an accurate approximation of complex SCC morphologies. The coupled electro-chemo-mechanical formulation is numerically implemented using the finite element method and an implicit time integration scheme; displacements, phase field order parameter and concentration are the primary variables. Five case studies of particular interest are addressed to showcase the predictive capabilities of the model, revealing an excellent agreement with analytical solutions and experimental measurements. By modelling these paradigmatic 2D and 3D boundary value problems we show that our formulation can capture: (i) the transition from activation-controlled corrosion to diffusion-controlled corrosion, (ii) the sensitivity of interface kinetics to mechanical stresses and strains, (iii) the role of film passivation in reducing corrosion rates, and (iv) the dependence of the stability of the passive film to local strain rates. The influence of these factors in driving the shape change of SCC defects, including the pit-to-crack transition, is a natural outcome of the model, laying the foundations for a mechanistic assessment of engineering materials and structures.",
        "published": "2020-11-24T12:49:15Z",
        "link": "http://arxiv.org/abs/2011.12068v1",
        "categories": [
            "physics.app-ph",
            "cond-mat.mtrl-sci",
            "cs.CE"
        ]
    },
    {
        "title": "Model Order Reduction for Gas and Energy Networks",
        "authors": [
            "Christian Himpe",
            "Sara Grundel",
            "Peter Benner"
        ],
        "summary": "To counter the volatile nature of renewable energy sources, gas networks take a vital role. But, to ensure fulfillment of contracts under these circumstances, a vast number of possible scenarios, incorporating uncertain supply and demand, has to be simulated ahead of time. This many-query gas network simulation task can be accelerated by model reduction, yet, large-scale, nonlinear, parametric, hyperbolic partial differential(-algebraic) equation systems, modeling natural gas transport, are a challenging application for model order reduction algorithms.   For this industrial application, we bring together the scientific computing topics of: mathematical modeling of gas transport networks, numerical simulation of hyperbolic partial differential equation, and parametric model reduction for nonlinear systems. This research resulted in the \"morgen\" (Model Order Reduction for Gas and Energy Networks) software platform, which enables modular testing of various combinations of models, solvers, and model reduction methods. In this work we present the theoretical background on systemic modeling and structured, data-driven, system-theoretic model reduction for gas networks, as well as the implementation of \"morgen\" and associated numerical experiments testing model reduction adapted to gas network models.",
        "published": "2020-11-24T14:13:42Z",
        "link": "http://arxiv.org/abs/2011.12099v3",
        "categories": [
            "math.OC",
            "cs.CE",
            "cs.NA",
            "cs.SY",
            "eess.SY",
            "math.NA",
            "93-04, 76N15, 93B20"
        ]
    },
    {
        "title": "Space-time POD-Galerkin approach for parametric flow control",
        "authors": [
            "Francesco Ballarin",
            "Gianluigi Rozza",
            "Maria Strazzullo"
        ],
        "summary": "In this contribution we propose reduced order methods to fast and reliably solve parametrized optimal control problems governed by time dependent nonlinear partial differential equations. Our goal is to provide a tool to deal with the time evolution of several nonlinear optimality systems in many-query context, where a system must be analysed for various physical and geometrical features. Optimal control can be used in order to fill the gap between collected data and mathematical model and it is usually related to very time consuming activities: inverse problems, statistics, etc. Standard discretization techniques may lead to unbearable simulations for real applications. We aim at showing how reduced order modelling can solve this issue. We rely on a space-time POD-Galerkin reduction in order to solve the optimal control problem in a low dimensional reduced space in a fast way for several parametric instances. The proposed algorithm is validated with a numerical test based on environmental sciences: a reduced optimal control problem governed by viscous Shallow Waters Equations parametrized not only in the physics features, but also in the geometrical ones. We will show how the reduced model can be useful in order to recover desired velocity and height profiles more rapidly with respect to the standard simulation, not losing accuracy.",
        "published": "2020-11-24T14:15:33Z",
        "link": "http://arxiv.org/abs/2011.12101v2",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Inverse problems for semiconductors: models and methods",
        "authors": [
            "A. Leitao",
            "P. A. Markowich",
            "J. P. Zubelli"
        ],
        "summary": "We consider the problem of identifying discontinuous doping profiles in semiconductor devices from data obtained by different models connected to the voltage-current map. Stationary as well as transient settings are discussed and a framework for the corresponding inverse problems is established. Numerical implementations for the so-called stationary unipolar and stationary bipolar cases show the effectiveness of a level set approach to tackle the inverse problem.",
        "published": "2020-11-24T17:05:36Z",
        "link": "http://arxiv.org/abs/2011.12800v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "65J20, 47A52"
        ]
    },
    {
        "title": "Multiscale Modeling of Elasto-Plasticity in Heterogeneous Geomaterials   Based on Continuum Micromechanics",
        "authors": [
            "Mahdad Eghbalian",
            "Mehdi Pouragha",
            "Richard Wan"
        ],
        "summary": "In this paper, we investigate some micromechanical aspects of elasto-plasticity in heterogeneous geomaterials. The aim is to upscale the elasto-plastic behavior for a representative volume of the material which is indeed a very challenging task due to the irreversible deformations involved. Considering the plastic strains as eigen-strains allows us to employ the powerful tools offered by Continuum Micromechanics which are mainly developed for upscaling of eigen-stressed elastic media. The validity of such eigen-strain based formulation of multiscale elasto-plasticity is herein examined by comparing its predictions against Finite Element (FE) simulations.",
        "published": "2020-11-24T18:27:22Z",
        "link": "http://arxiv.org/abs/2011.12269v1",
        "categories": [
            "cs.CE",
            "74Q15 (primary), 74Q05 (secondary)",
            "J.2; I.6.5"
        ]
    },
    {
        "title": "Generation of In-group Asset Condition Data for Power System Reliability   Assessment",
        "authors": [
            "Ming Dong",
            "Alexandre B. Nassif",
            "Wenyuan Li"
        ],
        "summary": "In a power system, unlike some critical and standalone assets that are equipped with condition monitoring devices, the conditions of most regular in-group assets are acquired through periodic inspection work. Due to their large quantities, significant amount of manual inspection effort and sometimes data management issues, it is not uncommon to see the asset condition data in a target study area is unavailable or incomplete. Lack of asset condition data undermines the reliability assessment work. To solve this data problem and enhance data availability, this paper explores an unconventional method-generating numerical and non-numerical asset condition data based on condition degradation, condition correlation and categorical distribution models. Empirical knowledge from human experts can also be incorporated in the modeling process. Also, a probabilistic diversification step can be taken to make the generated numerical condition data probabilistic. This method can generate close-to-real asset condition data and has been validated systematically based on two public datasets. An area reliability assessment example based on cables is given to demonstrate the usefulness of this method and its generated data. This method can also be used to conveniently generate hypothetical asset condition data for research purposes.",
        "published": "2020-11-24T20:16:47Z",
        "link": "http://arxiv.org/abs/2011.12352v3",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Anomaly Detection Model for Imbalanced Datasets",
        "authors": [
            "Régis Houssou",
            "Stephan Robert-Nicoud"
        ],
        "summary": "This paper proposes a method to detect bank frauds using a mixed approach combining a stochastic intensity model with the probability of fraud observed on transactions. It is a dynamic unsupervised approach which is able to predict financial frauds. The fraud prediction probability on the financial transaction is derived as a function of the dynamic intensities. In this context, the Kalman filter method is proposed to estimate the dynamic intensities. The application of our methodology to financial datasets shows a better predictive power in higher imbalanced data compared to other intensity-based models.",
        "published": "2020-11-24T21:15:37Z",
        "link": "http://arxiv.org/abs/2011.12390v1",
        "categories": [
            "cs.CE",
            "math.PR"
        ]
    },
    {
        "title": "Concurrent consideration of cortical and cancellous bone within   continuum bone remodelling",
        "authors": [
            "Ina Schmidt",
            "Areti Papastavrou",
            "Paul Steinmann"
        ],
        "summary": "Continuum bone remodelling is an important tool for predicting the effects of mechanical stimuli on bone density evolution. While the modelling of only cancellous bone is considered in many studies based on continuum bone remodelling, this work presents an approach of modelling also cortical bone and the interaction of both bone types. The distinction between bone types is made by introducing an initial volume fraction. A simple point-wise example is used to study the behaviour of novel model options, as well as a proximal femur example, where the interaction of both bone types is demonstrated using initial density distributions. The results of the proposed model options indicate that the consideration of cortical bone remarkably changes the density evolution of cancellous bone, and should therefore not be neglected.",
        "published": "2020-11-25T06:13:31Z",
        "link": "http://arxiv.org/abs/2011.12537v1",
        "categories": [
            "q-bio.TO",
            "cs.CE"
        ]
    },
    {
        "title": "A non-oscillatory face-centred finite volume method for compressible   flows",
        "authors": [
            "Jordi Vila-Pérez",
            "Matteo Giacomini",
            "Ruben Sevilla",
            "Antonio Huerta"
        ],
        "summary": "This work presents the face-centred finite volume (FCFV) paradigm for the simulation of compressible flows. The FCFV method defines the unknowns at the face barycentre and uses a hybridisation procedure to eliminate all the degrees of freedom inside the cells. In addition, Riemann solvers are defined implicitly within the expressions of the numerical fluxes. The resulting methodology provides first-order accurate approximations of the conservative quantities, i.e. density, momentum and energy, as well as of the viscous stress tensor and of the heat flux, without the need of any gradient reconstruction procedure. Hence, the FCFV solver preserves the accuracy of the approximation in presence of distorted and highly stretched cells, providing a solver insensitive to mesh quality. In addition, FCFV is capable of constructing non-oscillatory approximations of sharp discontinuities without resorting to shock capturing or limiting techniques. For flows at low Mach number, the method is robust and is capable of computing accurate solutions in the incompressible limit without the need of introducing specific pressure correction strategies. A set of 2D and 3D benchmarks of external flows is presented to validate the methodology in different flow regimes, from inviscid to viscous laminar flows, from transonic to subsonic incompressible flows, demonstrating its potential to handle compressible flows in realistic scenarios.",
        "published": "2020-11-27T01:06:57Z",
        "link": "http://arxiv.org/abs/2011.13514v2",
        "categories": [
            "physics.flu-dyn",
            "cs.CE",
            "cs.NA",
            "math.NA",
            "physics.comp-ph",
            "76M12, 76Nxx, 65M08, 65M12, 76G25, 76H05"
        ]
    },
    {
        "title": "Numerical and experimental study of tonal noise sources at the outlet of   an isolated centrifugal fan",
        "authors": [
            "Martin Ottersten",
            "Hua-Dong Yao",
            "Lars Davidson"
        ],
        "summary": "In this study, tonal noise produced by an isolated centrifugal fan is investigated using unsteady Reynolds-averaged Navier-Stokes (URANS) equations. This type of fans is used in ventilation systems. As the fan propagates tonal noise in the system, it can severely affect the life quality of people that reside in the buildings. Our simulation shows that turbulence kinetic energy (TKE) is unevenly distributed around the rotation axis. Large TKE exists near the shroud at the pressure sides of the blades. It is caused by the recirculating flow. Moreover, the position of the largest TKE periodically varies among the blades. The period corresponds to approximately 4 times the fan rotation period, it was also found in acoustic measurements. The magnitude of the tonal noise at the blade passing frequencies agrees well with experimental data. By analyzing the wall-pressure fluctuations, it is found that the recirculating flow regions with large TKE are dominant sources of the tonal noise.",
        "published": "2020-11-27T10:38:19Z",
        "link": "http://arxiv.org/abs/2011.13645v1",
        "categories": [
            "cs.CE",
            "cs.SD",
            "eess.AS"
        ]
    },
    {
        "title": "A matrix-free isogeometric Galerkin method for Karhunen-Loève   approximation of random fields using tensor product splines, tensor   contraction and interpolation based quadrature",
        "authors": [
            "Michal Lukasz Mika",
            "Thomas Joseph Robert Hughes",
            "Dominik Schillinger",
            "Peter Wriggers",
            "René Rinke Hiemstra"
        ],
        "summary": "The Karhunen-Lo\\`eve series expansion (KLE) decomposes a stochastic process into an infinite series of pairwise uncorrelated random variables and pairwise $L^2$-orthogonal functions. For any given truncation order of the infinite series the basis is optimal in the sense that the total mean squared error is minimized. The orthogonal basis functions are determined as the solution of an eigenvalue problem corresponding to the homogeneous Fredholm integral equation of the second kind, which is computationally challenging for several reasons. Firstly, a Galerkin discretization requires numerical integration over a $2d$ dimensional domain, where $d$, in this work, denotes the spatial dimension. Secondly, the main system matrix of the discretized weak-form is dense. Consequently, the computational complexity of classical finite element formation and assembly procedures as well as the memory requirements of direct solution techniques become quickly computationally intractable with increasing polynomial degree, number of elements and degrees of freedom. The objective of this work is to significantly reduce several of the computational bottlenecks associated with numerical solution of the KLE. We present a matrix-free solution strategy, which is embarrassingly parallel and scales favorably with problem size and polynomial degree. Our approach is based on (1) an interpolation based quadrature that minimizes the required number of quadrature points; (2) an inexpensive reformulation of the generalized eigenvalue problem into a standard eigenvalue problem; and (3) a matrix-free and parallel matrix-vector product for iterative eigenvalue solvers. Two higher-order three-dimensional benchmarks illustrate exceptional computational performance combined with high accuracy and robustness.",
        "published": "2020-11-27T17:37:58Z",
        "link": "http://arxiv.org/abs/2011.13861v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Preserving general physical properties in model reduction of dynamical   systems via constrained-optimization projection",
        "authors": [
            "A. Schein",
            "K. T. Carlberg",
            "M. J. Zahr"
        ],
        "summary": "Model-reduction techniques aim to reduce the computational complexity of simulating dynamical systems by applying a (Petrov-)Galerkin projection process that enforces the dynamics to evolve in a low-dimensional subspace of the original state space. Frequently, the resulting reduced-order model (ROM) violates intrinsic physical properties of the original full-order model (FOM) (e.g., global conservation, Lagrangian structure, state-variable bounds) because the projection process does not generally ensure preservation of these properties. However, in many applications, ensuring the ROM preserves such intrinsic properties can enable the ROM to retain physical meaning and lead to improved accuracy and stability properties. In this work, we present a general constrained-optimization formulation for projection-based model reduction that can be used as a template to enforce the ROM to satisfy specific properties on the kinematics and dynamics. We introduce constrained-optimization formulations at both the time-continuous (i.e., ODE) level, which leads to a constrained Galerkin projection, and at the time-discrete level, which leads to a least-squares Petrov-Galerkin (LSPG) projection, in the context of linear multistep schemes. We demonstrate the ability of the proposed formulations to equip ROMs with desired properties such as global energy conservation and bounds on the total variation.",
        "published": "2020-11-27T21:38:20Z",
        "link": "http://arxiv.org/abs/2011.13998v3",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Thermodynamic Consistent Neural Networks for Learning Material   Interfacial Mechanics",
        "authors": [
            "Jiaxin Zhang",
            "Congjie Wei",
            "Chenglin Wu"
        ],
        "summary": "For multilayer materials in thin substrate systems, interfacial failure is one of the most challenges. The traction-separation relations (TSR) quantitatively describe the mechanical behavior of a material interface undergoing openings, which is critical to understand and predict interfacial failures under complex loadings. However, existing theoretical models have limitations on enough complexity and flexibility to well learn the real-world TSR from experimental observations. A neural network can fit well along with the loading paths but often fails to obey the laws of physics, due to a lack of experimental data and understanding of the hidden physical mechanism. In this paper, we propose a thermodynamic consistent neural network (TCNN) approach to build a data-driven model of the TSR with sparse experimental data. The TCNN leverages recent advances in physics-informed neural networks (PINN) that encode prior physical information into the loss function and efficiently train the neural networks using automatic differentiation. We investigate three thermodynamic consistent principles, i.e., positive energy dissipation, steepest energy dissipation gradient, and energy conservative loading path. All of them are mathematically formulated and embedded into a neural network model with a novel defined loss function. A real-world experiment demonstrates the superior performance of TCNN, and we find that TCNN provides an accurate prediction of the whole TSR surface and significantly reduces the violated prediction against the laws of physics.",
        "published": "2020-11-28T17:25:10Z",
        "link": "http://arxiv.org/abs/2011.14172v1",
        "categories": [
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "Scalable Deep-Learning-Accelerated Topology Optimization for Additively   Manufactured Materials",
        "authors": [
            "Sirui Bi",
            "Jiaxin Zhang",
            "Guannan Zhang"
        ],
        "summary": "Topology optimization (TO) is a popular and powerful computational approach for designing novel structures, materials, and devices. Two computational challenges have limited the applicability of TO to a variety of industrial applications. First, a TO problem often involves a large number of design variables to guarantee sufficient expressive power. Second, many TO problems require a large number of expensive physical model simulations, and those simulations cannot be parallelized. To address these issues, we propose a general scalable deep-learning (DL) based TO framework, referred to as SDL-TO, which utilizes parallel schemes in high performance computing (HPC) to accelerate the TO process for designing additively manufactured (AM) materials. Unlike the existing studies of DL for TO, our framework accelerates TO by learning the iterative history data and simultaneously training on the mapping between the given design and its gradient. The surrogate gradient is learned by utilizing parallel computing on multiple CPUs incorporated with a distributed DL training on multiple GPUs. The learned TO gradient enables a fast online update scheme instead of an expensive update based on the physical simulator or solver. Using a local sampling strategy, we achieve to reduce the intrinsic high dimensionality of the design space and improve the training accuracy and the scalability of the SDL-TO framework. The method is demonstrated by benchmark examples and AM materials design for heat conduction. The proposed SDL-TO framework shows competitive performance compared to the baseline methods but significantly reduces the computational cost by a speed up of around 8.6x over the standard TO implementation.",
        "published": "2020-11-28T17:38:31Z",
        "link": "http://arxiv.org/abs/2011.14177v1",
        "categories": [
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "Methods Matter: A Trading Agent with No Intelligence Routinely   Outperforms AI-Based Traders",
        "authors": [
            "Dave Cliff",
            "Michael Rollins"
        ],
        "summary": "There's a long tradition of research using computational intelligence (methods from artificial intelligence (AI) and machine learning (ML)), to automatically discover, implement, and fine-tune strategies for autonomous adaptive automated trading in financial markets, with a sequence of research papers on this topic published at AI conferences such as IJCAI and in journals such as Artificial Intelligence: we show here that this strand of research has taken a number of methodological mis-steps and that actually some of the reportedly best-performing public-domain AI/ML trading strategies can routinely be out-performed by extremely simple trading strategies that involve no AI or ML at all. The results that we highlight here could easily have been revealed at the time that the relevant key papers were published, more than a decade ago, but the accepted methodology at the time of those publications involved a somewhat minimal approach to experimental evaluation of trader-agents, making claims on the basis of a few thousand test-sessions of the trader-agent in a small number of market scenarios. In this paper we present results from exhaustive testing over wide ranges of parameter values, using parallel cloud-computing facilities, where we conduct millions of tests and thereby create much richer data from which firmer conclusions can be drawn. We show that the best public-domain AI/ML traders in the published literature can be routinely outperformed by a \"sub-zero-intelligence\" trading strategy that at face value appears to be so simple as to be financially ruinous, but which interacts with the market in such a way that in practice it is more profitable than the well-known AI/ML strategies from the research literature. That such a simple strategy can outperform established AI/ML-based strategies is a sign that perhaps the AI/ML trading strategies were good answers to the wrong question.",
        "published": "2020-11-29T11:55:59Z",
        "link": "http://arxiv.org/abs/2011.14346v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Bayesian Assessments of Aeroengine Performance with Transfer Learning",
        "authors": [
            "Pranay Seshadri",
            "Andrew Duncan",
            "George Thorne",
            "Geoffrey Parks",
            "Raul Vazquez Diaz",
            "Mark Girolami"
        ],
        "summary": "Aeroengine performance is determined by temperature and pressure profiles along various axial stations within an engine. Given limited sensor measurements both along and between axial stations, we require a statistically principled approach to inferring these profiles. In this paper we detail a Bayesian methodology for interpolating the spatial temperature or pressure profile at axial stations within an aeroengine. The profile at any given axial station is represented as a spatial Gaussian random field on an annulus, with circumferential variations modelled using a Fourier basis and radial variations modelled with a squared exponential kernel. This Gaussian random field is extended to ingest data from multiple axial measurement planes, with the aim of transferring information across the planes. To facilitate this type of transfer learning, a novel planar covariance kernel is proposed, with hyperparameters that characterise the correlation between any two measurement planes. In the scenario where precise frequencies comprising the temperature field are unknown, we utilise a sparsity-promoting prior on the frequencies to encourage sparse representations. This easily extends to cases with multiple engine planes whilst accommodating frequency variations between the planes. The main quantity of interest, the spatial area average is readily obtained in closed form. We term this the Bayesian area average and demonstrate how this metric offers far more precise averages than a sector area average -- a widely used area averaging approach. Furthermore, the Bayesian area average naturally decomposes the posterior uncertainty into terms characterising insufficient sampling and sensor measurement error respectively. This too provides a significant improvement over prior standard deviation based uncertainty breakdowns.",
        "published": "2020-11-30T11:25:05Z",
        "link": "http://arxiv.org/abs/2011.14698v2",
        "categories": [
            "cs.CE",
            "stat.CO"
        ]
    },
    {
        "title": "Decay: A Monte Carlo library for the decay of a particle with ROOT   compatibility",
        "authors": [
            "R. A. Kycia",
            "P. Lebiedowicz",
            "A. Szczurek"
        ],
        "summary": "Recently, there is a need for a general-purpose event generator of decays of an elementary particle or a hadron to a state of higher multiplicity ($N > 2$) that is simple to use and universal. We present the structure of such a library to produce generators that generate kinematics of decay processes and can be used to integrate any matrix element squared over phase space of this decay. Some test examples are presented, and results are compared with results known from the literature. As one of examples we consider the Standard Model Higgs boson decay into four leptons. The generators discussed here are compatible with the ROOT interface.",
        "published": "2020-11-30T13:05:33Z",
        "link": "http://arxiv.org/abs/2011.14750v1",
        "categories": [
            "hep-ph",
            "cs.CE",
            "hep-th",
            "nucl-th"
        ]
    },
    {
        "title": "Modeling of a multiple source heating plate",
        "authors": [
            "Stephan Scholz",
            "Lothar Berger"
        ],
        "summary": "Heating plates describe the transfer of heat from actuators to a target object. In other words, they separate the heat sources and heated object and can be further used to apply a specific heat distribution on this object. Therefore, an exact description of their thermal dynamics and an efficient coordination of their actuators is necessary to achieve a desired time-dependent temperature profile accurately. In this contribution, the thermal dynamics of a multiple source heating plate is modeled as a quasi-linear heat equation and the configuration of the spatially distributed actuators and sensors are discussed. Furthermore, the distributed parameter system is approximated using a Finite Volume scheme, and the influence of the actuators' spatial characterization on the plate's thermal dynamics is studied with the resulting high-dimensional system.",
        "published": "2020-11-30T16:06:46Z",
        "link": "http://arxiv.org/abs/2011.14939v1",
        "categories": [
            "cs.CE",
            "cs.SY",
            "eess.SY",
            "I.6.3; J.2"
        ]
    },
    {
        "title": "Derivative-Informed Projected Neural Networks for High-Dimensional   Parametric Maps Governed by PDEs",
        "authors": [
            "Thomas O'Leary-Roseberry",
            "Umberto Villa",
            "Peng Chen",
            "Omar Ghattas"
        ],
        "summary": "Many-query problems, arising from uncertainty quantification, Bayesian inversion, Bayesian optimal experimental design, and optimization under uncertainty-require numerous evaluations of a parameter-to-output map. These evaluations become prohibitive if this parametric map is high-dimensional and involves expensive solution of partial differential equations (PDEs). To tackle this challenge, we propose to construct surrogates for high-dimensional PDE-governed parametric maps in the form of projected neural networks that parsimoniously capture the geometry and intrinsic low-dimensionality of these maps. Specifically, we compute Jacobians of these PDE-based maps, and project the high-dimensional parameters onto a low-dimensional derivative-informed active subspace; we also project the possibly high-dimensional outputs onto their principal subspace. This exploits the fact that many high-dimensional PDE-governed parametric maps can be well-approximated in low-dimensional parameter and output subspace. We use the projection basis vectors in the active subspace as well as the principal output subspace to construct the weights for the first and last layers of the neural network, respectively. This frees us to train the weights in only the low-dimensional layers of the neural network. The architecture of the resulting neural network captures to first order, the low-dimensional structure and geometry of the parametric map. We demonstrate that the proposed projected neural network achieves greater generalization accuracy than a full neural network, especially in the limited training data regime afforded by expensive PDE-based parametric maps. Moreover, we show that the number of degrees of freedom of the inner layers of the projected network is independent of the parameter and output dimensions, and high accuracy can be achieved with weight dimension independent of the discretization dimension.",
        "published": "2020-11-30T18:46:40Z",
        "link": "http://arxiv.org/abs/2011.15110v2",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.LG",
            "cs.NA"
        ]
    },
    {
        "title": "Integral Equations & Model Reduction For Fast Computation of Nonlinear   Periodic Response",
        "authors": [
            "Gergely Buza",
            "George Haller",
            "Shobhit Jain"
        ],
        "summary": "We propose a reformulation for the integral equations approach of Jain, Breunung \\& Haller [Nonlinear Dyn. 97, 313--341 (2019)] to steady-state response computation for periodically forced nonlinear mechanical systems. This reformulation results in additional speed-up and better convergence. We show that the solutions of the reformulated equations are in one-to-one correspondence with those of the original integral equations and derive conditions under which a collocation type approximation converges to the exact solution in the reformulated setting. Furthermore, we observe that model reduction using a selected set of vibration modes of the linearized system substantially enhances the computational performance. Finally, we discuss an open-source implementation of this approach and demonstrate the gains in computational performance using three examples that also include nonlinear finite-element models.",
        "published": "2020-11-30T19:21:59Z",
        "link": "http://arxiv.org/abs/2012.00059v1",
        "categories": [
            "cs.CE",
            "math.DS"
        ]
    },
    {
        "title": "Efficient Data Structures for Model-free Data-Driven Computational   Mechanics",
        "authors": [
            "Robert Eggersmann",
            "Laurent Stainier",
            "Michael Ortiz",
            "Stefanie Reese"
        ],
        "summary": "The data-driven computing paradigm initially introduced by Kirchdoerfer and Ortiz (2016) enables finite element computations in solid mechanics to be performed directly from material data sets, without an explicit material model. From a computational effort point of view, the most challenging task is the projection of admissible states at material points onto their closest states in the material data set. In this study, we compare and develop several possible data structures for solving the nearest-neighbor problem. We show that approximate nearest-neighbor (ANN) algorithms can accelerate material data searches by several orders of magnitude relative to exact searching algorithms. The approximations are suggested by--and adapted to--the structure of the data-driven iterative solver and result in no significant loss of solution accuracy. We assess the performance of the ANN algorithm with respect to material data set size with the aid of a 3D elasticity test case. We show that computations on a single processor with up to one billion material data points are feasible within a few seconds execution time with a speedup of more than 106 with respect to exact k-d trees.",
        "published": "2020-12-01T09:32:39Z",
        "link": "http://arxiv.org/abs/2012.00357v1",
        "categories": [
            "cs.CE",
            "J.2"
        ]
    },
    {
        "title": "Quantitative supply security related significance measures for gas   reservoires",
        "authors": [
            "Dávid Csercsik"
        ],
        "summary": "Computational models corresponding to supply security in natural gas networks aim to describe flows and consumption values in the case of component failures or unforseen pipeline shutdowns. The role of natural gas reservoires in this process has only been marginally analyzed in such models, and typically only on the level of countries. In this paper we define a computational framework, which is capable of interpreting real flow and reservoir data to assign a quantitative supply security related measure to reservoires, depending on how much the given reservoir is critical in the process of restoring consumption outages in the network.",
        "published": "2020-12-02T11:29:47Z",
        "link": "http://arxiv.org/abs/2012.01095v2",
        "categories": [
            "cs.CE",
            "physics.soc-ph"
        ]
    },
    {
        "title": "3D architected isotropic materials with tunable stiffness and buckling   strength",
        "authors": [
            "Fengwen Wang",
            "Ole Sigmund"
        ],
        "summary": "This paper presents a class of 3D single-scale isotropic materials with tunable stiffness and buckling strength obtained via topology optimization and subsequent shape optimization. Compared to stiffness-optimal closed-cell plate material, the material class reduces the Young's modulus to a range from 79% to 58%, but improves the uniaxial buckling strength to a range from 180% to 767%. Based on small deformation theory, material stiffness is evaluated using the homogenization method. Buckling strength under a given macroscopic stress state is estimated using linear buckling analysis with Block-Floquet boundary conditions to capture both short and long wavelength buckling modes. The 3D isotropic single-scale materials with tunable properties are designed using topology optimization, and are then further simplified using shape optimization. Both topology and shape optimized results demonstrate that material buckling strength can be significantly enhanced by hybrids between truss and variable thickness plate structures.",
        "published": "2020-12-02T17:58:37Z",
        "link": "http://arxiv.org/abs/2012.01359v2",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "math.OC"
        ]
    },
    {
        "title": "Meshless physics-informed deep learning method for three-dimensional   solid mechanics",
        "authors": [
            "Diab W. Abueidda",
            "Qiyue Lu",
            "Seid Koric"
        ],
        "summary": "Deep learning and the collocation method are merged and used to solve partial differential equations describing structures' deformation. We have considered different types of materials: linear elasticity, hyperelasticity (neo-Hookean) with large deformation, and von Mises plasticity with isotropic and kinematic hardening. The performance of this deep collocation method (DCM) depends on the architecture of the neural network and the corresponding hyperparameters. The presented DCM is meshfree and avoids any spatial discretization, which is usually needed for the finite element method (FEM). We show that the DCM can capture the response qualitatively and quantitatively, without the need for any data generation using other numerical methods such as the FEM. Data generation usually is the main bottleneck in most data-driven models. The deep learning model is trained to learn the model's parameters yielding accurate approximate solutions. Once the model is properly trained, solutions can be obtained almost instantly at any point in the domain, given its spatial coordinates. Therefore, the deep collocation method is potentially a promising standalone technique to solve partial differential equations involved in the deformation of materials and structural systems as well as other physical phenomena.",
        "published": "2020-12-02T21:40:37Z",
        "link": "http://arxiv.org/abs/2012.01547v2",
        "categories": [
            "cs.LG",
            "cs.CE"
        ]
    },
    {
        "title": "Numerical computation of stress-permeability relationships of fracture   networks in a shale rock",
        "authors": [
            "Rafael March",
            "David Egya",
            "Christine Maier",
            "Andreas Busch",
            "Florian Doster"
        ],
        "summary": "We present stress-sensitive permeability relationships for two-dimensional fracture networks in the Opalinus Clay from the Mont Terri underground rock laboratory. These relationships may be used as a proxy for fracture network permeability in numerical models that resolve large spatial scales and are used in a variety of GeoEnergy applications involving flow in shaly rocks. To obtain these relationships we present a numerical procedure that uses experimentally determined stress-permeability relationships to numerically compute the effective permeability of the network. The material discontinuities stemming from the fractures are treated by a simple contact-interaction algorithm that accounts for normal interaction between fracture walls, allowing us to calculate the permeability of a fracture network under different stress conditions. We apply the procedure to four fracture networks digitized from two galleries of the Mont Terri rock laboratory. These fracture networks are mapped from the damage zone of the Main Fault that intersects the Opalinus Clay. The networks show a maximum variation of four orders of magnitude when stress ranges from 1MPa to 20 MPa. Our numerical procedure not only establishes representative stress-permeability relationships for a fractured rock mass under stress, but also provides a proxy for fracture network permeability for simulation in fractured formations.",
        "published": "2020-12-03T17:14:08Z",
        "link": "http://arxiv.org/abs/2012.02080v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "ChemNODE: A Neural Ordinary Differential Equations Approach for Chemical   Kinetics Solvers",
        "authors": [
            "Opeoluwa Owoyele",
            "Pinaki Pal"
        ],
        "summary": "Solving for detailed chemical kinetics remains one of the major bottlenecks for computational fluid dynamics simulations of reacting flows using a finite-rate-chemistry approach. This has motivated the use of fully connected artificial neural networks to predict stiff chemical source terms as functions of the thermochemical state of the combustion system. However, due to the nonlinearities and multi-scale nature of combustion, the predicted solution often diverges from the true solution when these deep learning models are coupled with a computational fluid dynamics solver. This is because these approaches minimize the error during training without guaranteeing successful integration with ordinary differential equation solvers. In the present work, a novel neural ordinary differential equations approach to modeling chemical kinetics, termed as ChemNODE, is developed. In this deep learning framework, the chemical source terms predicted by the neural networks are integrated during training, and by computing the required derivatives, the neural network weights are adjusted accordingly to minimize the difference between the predicted and ground-truth solution. A proof-of-concept study is performed with ChemNODE for homogeneous autoignition of hydrogen-air mixture over a range of composition and thermodynamic conditions. It is shown that ChemNODE accurately captures the correct physical behavior and reproduces the results obtained using the full chemical kinetic mechanism at a fraction of the computational cost.",
        "published": "2020-12-03T23:49:02Z",
        "link": "http://arxiv.org/abs/2101.04749v3",
        "categories": [
            "cs.CE",
            "physics.flu-dyn"
        ]
    },
    {
        "title": "Applying the Chebyshev-Tau spectral method to solve the parabolic   equation model of wide-angle rational approximation in ocean acoustics",
        "authors": [
            "Houwang Tu",
            "Yongxian Wang",
            "Xian Ma",
            "Xunjiang Zhu"
        ],
        "summary": "Solving an acoustic wave equation using a parabolic approximation is a popular approach for many existing ocean acoustic models. Commonly used parabolic equation (PE) model programs, such as the range-dependent acoustic model (RAM), are discretized by the finite difference method (FDM). Considering the idea and theory of the wide-angle rational approximation, a discrete PE model using the Chebyshev spectral method (CSM) is derived, and the code is developed. This method is currently suitable only for range-independent waveguides. Taking three ideal fluid waveguides as examples, the correctness of using the CSM discrete PE model in solving the underwater acoustic propagation problem is verified. The test results show that compared with the RAM, the method proposed in this paper can achieve higher accuracy in computational underwater acoustics and requires fewer discrete grid points. After optimization, this method is more advantageous than the FDM in terms of speed. Thus, the CSM provides high-precision reference standards for benchmark examples of the range-independent PE model.",
        "published": "2020-12-04T05:06:02Z",
        "link": "http://arxiv.org/abs/2012.02405v3",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA",
            "physics.flu-dyn"
        ]
    },
    {
        "title": "Revisiting element removal for density-based structural topology   optimization with reintroduction by Heaviside projection",
        "authors": [
            "Reza Behrou",
            "Reza Lotfi",
            "Josephine Voigt Carstensen",
            "Federico Ferrari",
            "James K. Guest"
        ],
        "summary": "We present a strategy grounded in the element removal idea of Bruns and Tortorelli [1] and aimed at reducing computational cost and circumventing potential numerical instabilities of density-based topology optimization. The design variables and the relative densities are both represented on a fixed, uniform finite element grid, and linked through filtering and Heaviside projection. The regions in the analysis domain where the relative density is below a specified threshold are removed from the forward analysis and replaced by fictitious nodal boundary conditions. This brings a progressive cut of the computational cost as the optimization proceeds and helps to mitigate numerical instabilities associated with low-density regions. Removed regions can be readily reintroduced since all the design variables remain active and are modeled in the formal sensitivity analysis. A key feature of the proposed approach is that the Heaviside functions promote material reintroduction along the structural boundaries by amplifying the magnitude of the sensitivities inside the filter reach. Several 2D and 3D structural topology optimization examples are presented, including linear and nonlinear compliance minimization, the design of a force inverter, and frequency and buckling load maximization. The approach is shown to be effective at producing optimized designs equivalent or nearly equivalent to those obtained without the element removal, while providing remarkable computational savings.",
        "published": "2020-12-04T21:22:46Z",
        "link": "http://arxiv.org/abs/2012.02860v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "math.OC"
        ]
    },
    {
        "title": "Finite element modelling of in-stent restenosis",
        "authors": [
            "Kiran Manjunatha",
            "Marek Behr",
            "Felix Vogt",
            "Stefanie Reese"
        ],
        "summary": "From the perspective of coronary heart disease, the development of stents has come significantly far in reducing the associated mortality rate, drug-eluting stents being the epitome of innovative and effective solutions. Within this work, the intricate process of in-stent restenosis is modelled considering one of the significant growth factors and its effect on constituents of the arterial wall. A multiphysical modelling approach is adopted in this regard. Experimental investigations from the literature have been used to hypothesize the governing equations and the corresponding parameters. A staggered solution strategy is utilised to capture the transport phenomena as well as the growth and remodeling that follows stent implantation. The model herein developed serves as a tool to predict in-stent restenosis depending on the endothelial injury sustained and the protuberance of stents into the lumen of the arteries. Keywords: in-stent restenosis, smooth mucsle cells, platelet-derived growth factor, extracellular matrix, growth",
        "published": "2020-12-05T06:37:23Z",
        "link": "http://arxiv.org/abs/2012.02959v2",
        "categories": [
            "cs.CE",
            "J.2; J.3"
        ]
    },
    {
        "title": "Constrained motion design with distinct actuators and motion   stabilization",
        "authors": [
            "Renate Sachse",
            "Florian Geiger",
            "Manfred Bischoff"
        ],
        "summary": "The design of adaptive structures is one method to improve sustainability of buildings. Adaptive structures are able to adapt to different loading and environmental conditions or to changing requirements by either small or large shape changes. In the latter case, also the mechanics and properties of the deformation process play a role for the structure's energy efficiency. The method of variational motion design, previously developed in the group of the authors, allows to identify deformation paths between two given geometrical configurations that are optimal with respect to a defined quality function. In a preliminary, academic setting this method assumes that every single degree of freedom is accessible to arbitrary external actuation forces that realize the optimized motion. These (nodal) forces can be recovered a posteriori. The present contribution deals with an extension of the method of motion design by the constraint that the motion is to be realized by a predefined set of actuation forces. These can be either external forces or prescribed length chances of discrete, internal actuator elements. As an additional constraint, static stability of each intermediate configuration during the motion is taken into account. It can be accomplished by enforcing a positive determinant of the stiffness matrix.",
        "published": "2020-12-05T13:12:50Z",
        "link": "http://arxiv.org/abs/2012.03026v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Forecasting fuel combustion-related CO$_2$ emissions by a novel   continuous fractional nonlinear grey Bernoulli model with Grey Wolf Optimizer",
        "authors": [
            "Wanli Xie",
            "Wen-Ze Wu",
            "Chong Liu",
            "Tao Zhang",
            "Zijie Dong"
        ],
        "summary": "Foresight of CO$_2$ emissions from fuel combustion is essential for policy-makers to identify ready targets for effective reduction plans and further to improve energy policies and plans. For the purpose of accurately forecasting the future development of China's CO$_2$ emissions from fuel combustion, a novel continuous fractional nonlinear grey Bernoulli model is developed in this paper. The fractional nonlinear grey Bernoulli model already in place is known that has a fixed first-order derivative that impairs the predictive performance to some extent. To address this problem, in the newly proposed model, a flexible variable is introduced into the order of derivative, freeing it from integer-order accumulation. In order to further improve the performance of the newly proposed model, a meta-heuristic algorithm, namely Grey Wolf Optimizer (GWO), is determined to the emerging coefficients. To demonstrate the effectiveness, two real examples and China's fuel combustion-related CO$_2$ emissions are used for model validation by comparing with other benchmark models, the results show the proposed model outperforms competitors. Thus, the future development trend of fuel combustion-related CO$_2$ emissions by 2023 are predicted, accounting for 10039.80 Million tons (Mt). In accordance with the forecasts, several suggestions are provided to curb carbon dioxide emissions.",
        "published": "2020-12-06T11:34:14Z",
        "link": "http://arxiv.org/abs/2012.03241v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "STSIR: Spatial Temporal Pandemic Model with Mobility Data",
        "authors": [
            "Wang Pan",
            "Qipu Deng",
            "Jiadong Li",
            "Zhi Wang",
            "Wenwu Zhu"
        ],
        "summary": "With the outbreak of COVID-19, how to mitigate and suppress its spread is a big issue to the government. Department of public health need powerful models to model and predict the trend and scale of such pandemic. And models that could evaluate the effect of the public policy are also essential to the fight with the COVID-19. A main limitation of existing models is that they can only evaluate the policy by calculating $R_0$ after infection happens instead of giving observable index. To tackle this, based on the transmission character of the COVID-19, we preposed a novel framework Spatial-Temporal-Susceptible-Infected-Removed (STSIR) model. In particular, we merged both intra-city and inter-city mobility index with the traditional SIR dynamics and make it a dynamic system. And we proved that the STSIR system is a closed system which makes the system self-consistent. And finally we proposed a Multi-Stage Simulated Annealing (MSSA) algorithm to find optimal parameter of the system. In our experiments, based on Baidu Mobility dataset, and China pandemic dataset provided by Dingxiangyuan, our model can effectively predict the total scale of the pandemic and also gives clear policy analysis with observable index.",
        "published": "2020-12-07T07:59:06Z",
        "link": "http://arxiv.org/abs/2012.03509v1",
        "categories": [
            "cs.CE",
            "physics.soc-ph"
        ]
    },
    {
        "title": "Adaptive Single- and Multilevel Stochastic Collocation Methods for   Uncertain Gas Transport in Large-Scale Networks",
        "authors": [
            "Jens Lang",
            "Pia Domschke",
            "Elisa Strauch"
        ],
        "summary": "In this paper, we are concerned with the quantification of uncertainties that arise from intra-day oscillations in the demand for natural gas transported through large-scale networks. The short-term transient dynamics of the gas flow is modelled by a hierarchy of hyperbolic systems of balance laws based on the isentropic Euler equations. We extend a novel adaptive strategy for solving elliptic PDEs with random data, recently proposed and analysed by Lang, Scheichl, and Silvester [J. Comput. Phys., 419:109692, 2020], to uncertain gas transport problems. Sample-dependent adaptive meshes and a model refinement in the physical space is combined with adaptive anisotropic sparse Smolyak grids in the stochastic space. A single-level approach which balances the discretization errors of the physical and stochastic approximations and a multilevel approach which additionally minimizes the computational costs are considered. Two examples taken from a public gas library demonstrate the reliability of the error control of expectations calculated from random quantities of interest, and the further use of stochastic interpolants to, e.g., approximate probability density functions of minimum and maximum pressure values at the exits of the network.",
        "published": "2020-12-07T10:15:39Z",
        "link": "http://arxiv.org/abs/2012.03565v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "physics.comp-ph",
            "65C20, 65C30, 65N35, 65M75"
        ]
    },
    {
        "title": "Modeling and computer simulation of the mixing and heat transfer in   heterogeneous turbulent two-phase jets of mutually immiscible liquids by the   method of Professor Alfred I. Nakorchevskii. Part 1",
        "authors": [
            "Ivan V Kazachkov"
        ],
        "summary": "The present paper is devoted to the mixing and heat transfer features of mutually immiscible liquids in the two-fluid turbulent heterogeneous jet flow. Many natural and technical processes deal with the turbulent jets of mutually immiscible liquids, which represent an important class of the modern multiphase system dynamics. Differential equations for the axially symmetrical two-dimensional stationary flow and the integral correlations in a cylindrical coordinate system were considered for the jet from a nozzle into a space filled with another fluid that is not miscible with the first one. Parameters of the turbulent mixing in the two-phase jet flow were modeled and analyzed. The results may be of interest for some research and industrial tasks, where the calculation of parameters of the multiphase turbulent mixing and heat transfer are important.",
        "published": "2020-12-07T10:38:25Z",
        "link": "http://arxiv.org/abs/2012.08304v1",
        "categories": [
            "physics.flu-dyn",
            "cs.CE"
        ]
    },
    {
        "title": "Freeform shape optimization of a compact DC photo-electron gun using   isogeometric analysis",
        "authors": [
            "Peter Förster",
            "Sebastian Schöps",
            "Joachim Enders",
            "Maximilian Herbert",
            "Abele Simona"
        ],
        "summary": "Compact DC high-voltage photo-electron guns are able to meet the sophisticated demands of high-current applications such as energy recovery linacs. A main design parameter for such sources is the electric field strength, which depends on the electrode geometry and is limited by the field emission threshold of the electrode material. In order to minimize the maximum field strength for optimal gun operation, isogeometric analysis (IGA) can be used to exploit the axisymmetric geometry and describe its cross section by non-uniform rational B-splines, the control points of which are the parameters to be optimized. This computationally efficient method is capable of describing CAD-generated geometries using open source software (GeoPDEs, NLopt, Octave) and it can simplify the step from design to simulation. We will present the mathematical formulation, the software workflow, and the results of an IGA-based shape optimization for a planned high-voltage upgrade of the DC photogun teststand Photo-CATCH at TU Darmstadt. The software builds on a general framework for isogeometric analysis and allows for easy adaptations to other geometries or quantities of interest. Simulations assuming a bias voltage of -300 kV yielded maximum field gradients of 9.06 MV/m on the surface of an inverted insulator electrode and below 3 MV/m on the surface of the photocathode.",
        "published": "2020-12-08T11:31:39Z",
        "link": "http://arxiv.org/abs/2012.04372v2",
        "categories": [
            "cs.CE",
            "physics.acc-ph",
            "35Q60, 65N30, 65D07 (Primary) 78A30, 78A35, 78M10 (Secondary)",
            "G.1.8; I.6; J.2; J.6"
        ]
    },
    {
        "title": "CoShaRP: A Convex Program for Single-shot Tomographic Shape Sensing",
        "authors": [
            "Ajinkya Kadu",
            "Tristan van Leeuwen",
            "K. Joost Batenburg"
        ],
        "summary": "We introduce single-shot X-ray tomography that aims to estimate the target image from a single cone-beam projection measurement. This linear inverse problem is extremely under-determined since the measurements are far fewer than the number of unknowns. Moreover, it is more challenging than conventional tomography where a sufficiently large number of projection angles forms the measurements, allowing for a simple inversion process. However, single-shot tomography becomes less severe if the target image is only composed of known shapes. Hence, the shape prior transforms a linear ill-posed image estimation problem to a non-linear problem of estimating the roto-translations of the shapes. In this paper, we circumvent the non-linearity by using a dictionary of possible roto-translations of the shapes. We propose a convex program CoShaRP to recover the dictionary-coefficients successfully. CoShaRP relies on simplex-type constraint and can be solved quickly using a primal-dual algorithm. The numerical experiments show that CoShaRP recovers shapes stably from moderately noisy measurements.",
        "published": "2020-12-08T16:44:34Z",
        "link": "http://arxiv.org/abs/2012.04551v2",
        "categories": [
            "cs.CV",
            "cs.CE",
            "cs.IR",
            "eess.IV",
            "math.OC"
        ]
    },
    {
        "title": "RLeave: an in silico cross-validation protocol for transcript   differential expression analysis",
        "authors": [
            "Matheus Costa e Silva",
            "Norma Lucena-Silva",
            "Juliana Doblas Massaro",
            "Eduardo Antônio Donadi"
        ],
        "summary": "Background and Objective: The massive parallel sequencing technology facilitates new discoveries in terms of transcript differential analysis; however, all the new findings must be validated, since the diversity of transcript expression may impair the identification of the most relevant ones.   Methods: The proposed RLeave algorithm (implemented in the R environment) utilizes a combination of conventional analysis (classic edgeR) together with other mathematical methods (Leave-one-out sample technique and Decision Trees validation) to identify more relevant candidates to be in vitro or in silico validated.   Results: The RLeave protocol was tested using miRNome expression analysis of two sample groups (diabetes mellitus and acute lymphoblastic leukemia), and both had their most important differentially expressed miRNA confirmed by RT-qPCR.   Conclusion: This protocol is applicable in RNA-SEQ research, highlighting the most relevant transcripts for in silico and/or in vitro validation.",
        "published": "2020-12-10T02:43:41Z",
        "link": "http://arxiv.org/abs/2012.05421v1",
        "categories": [
            "q-bio.GN",
            "cs.CE",
            "q-bio.QM"
        ]
    },
    {
        "title": "The natural frequencies of masonry beams",
        "authors": [
            "Maria Girardi"
        ],
        "summary": "The present paper aims at analytically evaluating the natural frequencies of cracked slender masonry elements. The problem is dealt with in the framework of linear perturbation, and the small oscillations of the structure are studied under loaded conditions, after the equilibrium for permanent loads has been achieved. A masonry beam element made of masonry-like material is considered, and some explicit expressions of the beam's fundamental frequency as a function of the external loads and the amplitude of imposed deformations are derived. The analytical results are validated via finite-element analysis.",
        "published": "2020-12-10T14:35:24Z",
        "link": "http://arxiv.org/abs/2012.05704v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A Probabilistic Graphical Model Foundation for Enabling Predictive   Digital Twins at Scale",
        "authors": [
            "Michael G. Kapteyn",
            "Jacob V. R. Pretorius",
            "Karen E. Willcox"
        ],
        "summary": "A unifying mathematical formulation is needed to move from one-off digital twins built through custom implementations to robust digital twin implementations at scale. This work proposes a probabilistic graphical model as a formal mathematical representation of a digital twin and its associated physical asset. We create an abstraction of the asset-twin system as a set of coupled dynamical systems, evolving over time through their respective state-spaces and interacting via observed data and control inputs. The formal definition of this coupled system as a probabilistic graphical model enables us to draw upon well-established theory and methods from Bayesian statistics, dynamical systems, and control theory. The declarative and general nature of the proposed digital twin model make it rigorous yet flexible, enabling its application at scale in a diverse range of application areas. We demonstrate how the model is instantiated to enable a structural digital twin of an unmanned aerial vehicle (UAV). The digital twin is calibrated using experimental data from a physical UAV asset. Its use in dynamic decision making is then illustrated in a synthetic example where the UAV undergoes an in-flight damage event and the digital twin is dynamically updated using sensor data. The graphical model foundation ensures that the digital twin calibration and updating process is principled, unified, and able to scale to an entire fleet of digital twins.",
        "published": "2020-12-10T17:33:59Z",
        "link": "http://arxiv.org/abs/2012.05841v3",
        "categories": [
            "cs.CE",
            "cs.AI",
            "cs.LG",
            "math.OC"
        ]
    },
    {
        "title": "Stochastic dynamics of storm surge with stable noise",
        "authors": [
            "Joshua Frankie Rayo",
            "Vena Pearl Boñgolan"
        ],
        "summary": "The Advanced Circulation (ADCIRC) and Simulating Nearshore Waves (SWAN) coupled model is modified to include a stochastic term in the shallow water equations that represents random external forces from debris carried by surge and short-term local scale atmospheric fluctuations. We added $\\alpha$-stable noise, uncorrelated in space and time, in the forcing terms of the coupled model. Inputs to the model are unstructured computational mesh derived from topography and bathymetry, land cover classification, tidal potential constituents and atmospheric forcing. The model simulated surge height of around five meters rushing at four meters per second near Tacloban City downtown. Underestimation of simulated surge height is expected with use of bare earth model and absence of fluid sources on the governing equations, while overestimation of simulated peak height also occurs due to presence of concrete barriers that reduced surge height and inundation extent. The stochastic model is sensitive to random external forces during low tide and relatively higher fluid speed. Low tide happens when the fluid speed is maximum and water elevation is lowest, while higher fluid speed is brought by external forces like storm surge. However, the difference of stochastic solutions from the deterministic solution averages to zero and there is no significant improvement of the storm surge model in general when it comes to additive noise. This is an expected result since the noise used has zero mean. As $\\alpha$ goes to zero larger jumps occur more frequently so $\\sigma$ needs to be as small as $10^{-8}$ for simulation stability.",
        "published": "2020-12-11T05:13:23Z",
        "link": "http://arxiv.org/abs/2012.06129v1",
        "categories": [
            "cs.CE",
            "physics.ao-ph"
        ]
    },
    {
        "title": "Interoperability and computational framework for simulating open channel   hydraulics: application to sensitivity analysis and calibration of Gironde   Estuary model",
        "authors": [
            "Cedric Goeury",
            "Yoann Audouin",
            "Fabrice Zaoui"
        ],
        "summary": "Water resource management is of crucial societal and economic importance, requiring a strong capacity for anticipating environmental change. Progress in physical process knowledge, numerical methods and computational power, allows us to address hydro-environmental problems of growing complexity. Modeling of river and marine flows is no exception. With the increase in IT resources, environmental modeling is evolving to meet the challenges of complex real-world problems. This paper presents a new distributed Application Programming Interface (API) of the open source TELEMAC-MASCARET system to run hydro-environmental simulations with the help of the interoperability concept. Use of the API encourages and facilitates the combination of worldwide reference environmental libraries with the hydro-informatic system. Consequently, the objective of the paper is to promote the interoperability concept for studies dealing with such issues as uncertainty propagation, global sensitivity analysis, optimization, multi-physics or multi-dimensional coupling. To illustrate the capability of the API, an operational problem for improving the navigation capacity of the Gironde Estuary is presented. The API potential is demonstrated in a re-calibration context. The API is used for a multivariate sensitivity analysis to quickly reveal the most influential parameters which can then be optimally calibrated with the help of a data assimilation technique.",
        "published": "2020-12-12T07:14:05Z",
        "link": "http://arxiv.org/abs/2012.09112v2",
        "categories": [
            "cs.CE",
            "physics.data-an",
            "stat.CO"
        ]
    },
    {
        "title": "Bayesian graph neural networks for strain-based crack localization",
        "authors": [
            "Charilaos Mylonas",
            "George Tsialiamanis",
            "Keith Worden",
            "Eleni N. Chatzi"
        ],
        "summary": "A common shortcoming of vibration-based damage localization techniques is that localized damages, i.e. small cracks, have a limited influence on the spectral characteristics of a structure. In contrast, even the smallest of defects, under particular loading conditions, cause localized strain concentrations with predictable spatial configuration. However, the effect of a small defect on strain decays quickly with distance from the defect, making strain-based localization rather challenging. In this work, an attempt is made to approximate, in a fully data-driven manner, the posterior distribution of a crack location, given arbitrary dynamic strain measurements at arbitrary discrete locations on a structure. The proposed technique leverages Graph Neural Networks (GNNs) and recent developments in scalable learning for Bayesian neural networks. The technique is demonstrated on the problem of inferring the position of an unknown crack via patterns of dynamic strain field measurements at discrete locations. The dataset consists of simulations of a hollow tube under random time-dependent excitations with randomly sampled crack geometry and orientation.",
        "published": "2020-12-12T11:42:52Z",
        "link": "http://arxiv.org/abs/2012.06791v3",
        "categories": [
            "cs.CE",
            "physics.data-an"
        ]
    },
    {
        "title": "Mixed interpolatory and inference non-intrusive reduced order modeling   with application to pollutants dispersion",
        "authors": [
            "Charles Poussot-Vassal",
            "Tiphaine Sabatier",
            "Claire Sarrat",
            "Pierre Vuillemin"
        ],
        "summary": "On the basis of input-output time-domain data collected from a complex simulator, this paper proposes a constructive methodology to infer a reduced-order linear, bilinear or quadratic time invariant dynamical model reproducing the underlying phenomena. The approach is essentially based on linear dynamical systems and approximation theory. More specifically, it sequentially involves the interpolatory Pencil and Loewner framework, known to be both very versatile and scalable to large-scale data sets, and a linear least square problem involving the raw data and reduced internal variables. With respect to intrusive methods, no prior knowledge on the operator is needed. In addition, compared to the traditional non-intrusive operator inference ones, the proposed approach alleviates the need of measuring the original full-order model internal variables. It is thus applicable to a wider application range than standard intrusive and non-intrusive methods. The rationale is successfully applied on a large eddy simulation of a pollutants dispersion case over an airport area involving multi-scale and multi-physics dynamical phenomena. Despite the simplicity of the resulting low complexity model, the proposed approach shows satisfactory results to predict the pollutants plume pattern while being significantly faster to simulate.",
        "published": "2020-12-13T19:04:14Z",
        "link": "http://arxiv.org/abs/2012.07126v1",
        "categories": [
            "math.DS",
            "cs.CE",
            "cs.SY",
            "eess.SY",
            "41A20, 68U07, 68U35, 76F20, 93A15, 93B15, 93B30, 93C23, 93C80, 93C95"
        ]
    },
    {
        "title": "Image-based numerical characterization and experimental validation of   tensile behavior of octet-truss lattice structures",
        "authors": [
            "Nina Korshunova",
            "Gianluca Alaimo",
            "Seyyed Bahram Hosseini",
            "Massimo Carraturo",
            "Alessandro Reali",
            "Jarkko Niiranen",
            "Ferdinando Auricchio",
            "Ernst Rank",
            "Stefan Kollmannsberger"
        ],
        "summary": "The production of lightweight metal lattice structures has received much attention due to the recent developments in additive manufacturing (AM). The design flexibility comes, however, with the complexity of the underlying physics. In fact, metal additive manufacturing introduces process-induced geometrical defects that mainly result in deviations of the effective geometry from the nominal one. This change in the final printed shape is the primary cause of the gap between the as-designed and as-manufactured mechanical behavior of AM products. Thus, the possibility to incorporate the precise manufactured geometries into the computational analysis is crucial for the quality and performance assessment of the final parts. Computed tomography (CT) is an accurate method for the acquisition of the manufactured shape. However, it is often not feasible to integrate the CT-based geometrical information into the traditional computational analysis due to the complexity of the meshing procedure for such high-resolution geometrical models and the prohibitive numerical costs. In this work, an embedded numerical framework is applied to efficiently simulate and compare the mechanical behavior of as-designed to as-manufactured octet-truss lattice structures. The parts are produced using laser powder bed fusion (LPBF). Employing an immersed boundary method, namely the Finite Cell Method (FCM), we perform direct numerical simulations (DNS) and first-order numerical homogenization analysis of a tensile test for a 3D printed octet-truss structure. Numerical results based on CT scan (as-manufactured geometry) show an excellent agreement with experimental measurements, whereas both DNS and first-order numerical homogenization performed directly on the 3D virtual model (as-designed geometry) of the structure show a significant deviation from experimental data.",
        "published": "2020-12-14T12:05:52Z",
        "link": "http://arxiv.org/abs/2012.07452v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "High--order discontinuous Galerkin approximation for a three--phase   incompressible Navier--Stokes/Cahn--Hilliard model",
        "authors": [
            "Juan Manzanero",
            "Carlos Redondo",
            "Miguel Chávez--Módena",
            "Gonzalo Rubio",
            "Eusebio Valero",
            "Susana Gómez--Álvarez",
            "Ángel Rivero--Jiménez"
        ],
        "summary": "In this work we introduce the development of a three--phase incompressible Navier--Stokes/Cahn--Hilliard numerical method to simulate three--phase flows, present in many industrial operations. The numerical method is then applied to successfully solve oil transport problems, such as those found in the oil and gas industry. The three--phase model adopted in this work is a Cahn--Hilliard diffuse interface model, which was derived by Boyer and Lapuerta et al. 2006. The Cahn--Hilliard model is coupled to the entropy--stable incompressible Navier--Stokes equations model derived by Manzanero et al. 2019. The spatial discretization uses a high--order discontinuous Galerkin spectral element method which yields highly accurate results in arbitrary geometries, while an implicit--explicit (IMEX) method is adopted as temporal discretization. The developed numerical tool is tested for two and three dimensional problems, including a convergence study, a two--dimensional jet, a three--dimensional annular flow, and realistic geometries like T--shaped pipe intersections.",
        "published": "2020-12-14T17:15:13Z",
        "link": "http://arxiv.org/abs/2012.07722v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "A 55-line code for large-scale parallel topology optimization in 2D and   3D",
        "authors": [
            "Abhinav Gupta",
            "Rajib Chowdhury",
            "Anupam Chakrabarti",
            "Timon Rabczuk"
        ],
        "summary": "This paper presents a 55-line code written in python for 2D and 3D topology optimization (TO) based on the open-source finite element computing software (FEniCS), equipped with various finite element tools and solvers. PETSc is used as the linear algebra back-end, which results in significantly less computational time than standard python libraries. The code is designed based on the popular solid isotropic material with penalization (SIMP) methodology. Extensions to multiple load cases, different boundary conditions, and incorporation of passive elements are also presented. Thus, this implementation is the most compact implementation of SIMP based topology optimization for 3D as well as 2D problems.   Utilizing the concept of Euclidean distance matrix to vectorize the computation of the weight matrix for the filter, we have achieved a substantial reduction in the computational time and have also made it possible for the code to work with complex ground structure configurations. We have also presented the code's extension to large-scale topology optimization problems with support for parallel computations on complex structural configuration, which could help students and researchers explore novel insights into the TO problem with dense meshes. Appendix-A contains the complete code, and the website: \\url{https://github.com/iitrabhi/topo-fenics} also contains the complete code.",
        "published": "2020-12-15T10:57:16Z",
        "link": "http://arxiv.org/abs/2012.08208v1",
        "categories": [
            "cs.MS",
            "cs.CE",
            "math.OC"
        ]
    },
    {
        "title": "A numerical method for computing the overall response of nonlinear   composites with complex microstructure",
        "authors": [
            "H. Moulinec",
            "Pierre Suquet"
        ],
        "summary": "The local and overall responses of nonlinear composites are classically investigated by the Finite Element Method. We propose an alternate method based on Fourier series which avoids meshing and which makes direct use of microstructure images. It is based on the exact expression of the Green function of a linear elastic and homogeneous comparison material. First, the case of elastic nonhomogeneous constituents is considered and an iterative procedure is proposed to solve the Lippman-Schwinger equation which naturally arises in the problem. Then, the method is extended to non-linear constituents by a step-by-step integration in time. The accuracy of the method is assessed by varying the spatial resolution of the microstructures. The flexibility of the method allows it to serve for a large variety of microstructures. (C) 1998 Elsevier Science S.A.",
        "published": "2020-12-15T13:58:07Z",
        "link": "http://arxiv.org/abs/2012.08962v1",
        "categories": [
            "cs.CE",
            "physics.class-ph"
        ]
    },
    {
        "title": "A novel smoothed particle hydrodynamics formulation for thermo-capillary   phase change problems with focus on metal additive manufacturing melt pool   modeling",
        "authors": [
            "Christoph Meier",
            "Sebastian L. Fuchs",
            "A. John Hart",
            "Wolfgang A. Wall"
        ],
        "summary": "Laser-based metal processing including welding and three dimensional printing, involves localized melting of solid or granular raw material, surface tension-driven melt flow and significant evaporation of melt due to the applied very high energy densities. The present work proposes a weakly compressible smoothed particle hydrodynamics formulation for thermo-capillary phase change problems involving solid, liquid and gaseous phases with special focus on selective laser melting, an emerging metal additive manufacturing technique. Evaporation-induced recoil pressure, temperature-dependent surface tension and wetting forces are considered as mechanical interface fluxes, while a Gaussian laser beam heat source and evaporation-induced heat losses are considered as thermal interface fluxes. A novel interface stabilization scheme is proposed, which is shown to allow for a stable and smooth liquid-gas interface by effectively damping spurious interface flows as typically occurring in continuum surface force approaches. Moreover, discretization strategies for the tangential projection of the temperature gradient, as required for the discrete Marangoni forces, are critically reviewed. The proposed formulation is deemed especially suitable for modeling of the melt pool dynamics in metal additive manufacturing because the full range of relevant interface forces is considered and the explicit resolution of the atmospheric gas phase enables a consistent description of pore formation by gas inclusion. The accuracy and robustness of the individual model and method building blocks is verified by means of several selected examples in the context of the selective laser melting process.",
        "published": "2020-12-16T08:15:24Z",
        "link": "http://arxiv.org/abs/2012.08788v3",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Exploring Narrative Economics: An Agent-Based-Modeling Platform that   Integrates Automated Traders with Opinion Dynamics",
        "authors": [
            "Kenneth Lomas",
            "Dave Cliff"
        ],
        "summary": "In seeking to explain aspects of real-world economies that defy easy understanding when analysed via conventional means, Nobel Laureate Robert Shiller has since 2017 introduced and developed the idea of Narrative Economics, where observable economic factors such as the dynamics of prices in asset markets are explained largely as a consequence of the narratives (i.e., the stories) heard, told, and believed by participants in those markets. Shiller argues that otherwise irrational and difficult-to-explain behaviors, such as investors participating in highly volatile cryptocurrency markets, are best explained and understood in narrative terms: people invest because they believe, because they have a heartfelt opinions, about the future prospects of the asset, and they tell to themselves and others stories (narratives) about those beliefs and opinions. In this paper we describe what is, to the best of our knowledge, the first ever agent-based modelling platform that allows for the study of issues in narrative economics. We have created this by integrating and synthesizing research in two previously separate fields: opinion dynamics (OD), and agent-based computational economics (ACE) in the form of minimally-intelligent trader-agents operating in accurately modelled financial markets. We show here for the first time how long-established models in OD and in ACE can be brought together to enable the experimental study of issues in narrative economics, and we present initial results from our system. The program-code for our simulation platform has been released as freely-available open-source software on GitHub, to enable other researchers to replicate and extend our work",
        "published": "2020-12-16T10:31:08Z",
        "link": "http://arxiv.org/abs/2012.08840v1",
        "categories": [
            "q-fin.TR",
            "cs.CE",
            "econ.GN",
            "physics.soc-ph",
            "q-fin.EC"
        ]
    },
    {
        "title": "An Extended Discontinuous Galerkin Method for High-Order Shock-Fitting",
        "authors": [
            "Markus Geisenhofer",
            "Florian Kummer",
            "Martin Oberlack"
        ],
        "summary": "We present a sub-cell accurate shock-fitting technique using a high-order extended discontinuous Galerkin (XDG) method, where a computational cell of the background grid is cut into two cut-cells at the shock position. Our technique makes use of a sharp interface description where the shock front is implicitly defined by means of the zero iso-contour of a level-set function. A novel implicit pseudo-time-stepping procedure is employed to correct the position of the shock front inside the cut background cell by using cell-local indicators, since the position and shape of shock waves are not known a priori for the general, multi-dimensional case. This iterative correction terminates if the shock front has converged to the exact position. The procedure is demonstrated for the test case of a one-dimensional stationary normal shock wave. Furthermore, the underlying sharp interface approach drastically reduces the complexity of the grid handling, since a simple Cartesian background grid can be employed.",
        "published": "2020-12-16T11:03:20Z",
        "link": "http://arxiv.org/abs/2012.08860v2",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "physics.flu-dyn"
        ]
    },
    {
        "title": "Kinetic-diffusion asymptotic-preserving Monte Carlo algorithm for   Boltzmann-BGK in the diffusive scaling",
        "authors": [
            "Bert Mortier",
            "Martine Baelmans",
            "Giovanni Samaey"
        ],
        "summary": "We develop a novel Monte Carlo strategy for the simulation of the Boltzmann-BGK model with both low-collisional and high-collisional regimes present. The presented solution to maintain accuracy in low-collisional regimes and remove exploding simulation costs in high-collisional regimes uses hybridized particles that exhibit both kinetic behaviour and diffusive behaviour depending on the local collisionality. In this work, we develop such a method that maintains the correct mean, variance, and correlation of the positional increments over multiple time steps of fixed step size for all values of the collisionality, under the condition of spatial homogeneity during the time step. In the low-collisional regime, the method reverts to the standard velocity-jump process. In the high-collisional regime, the method collapses to a standard random walk process. We analyze the error of the presented scheme in the low-collisional regime for which we obtain the order of convergence in the time step size. We furthermore provide an analysis in the high-collisional regime that demonstrates the asymptotic-preserving property.",
        "published": "2020-12-16T14:29:42Z",
        "link": "http://arxiv.org/abs/2012.08985v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Decentralized Finance, Centralized Ownership? An Iterative Mapping   Process to Measure Protocol Token Distribution",
        "authors": [
            "Matthias Nadler",
            "Fabian Schär"
        ],
        "summary": "In this paper, we analyze various Decentralized Finance (DeFi) protocols in terms of their token distributions. We propose an iterative mapping process that allows us to split aggregate token holdings from custodial and escrow contracts and assign them to their economic beneficiaries. This method accounts for liquidity-, lending-, and staking-pools, as well as token wrappers, and can be used to break down token holdings, even for high nesting levels. We compute individual address balances for several snapshots and analyze intertemporal distribution changes. In addition, we study reallocation and protocol usage data, and propose a proxy for measuring token dependencies and ecosystem integration. The paper offers new insights on DeFi interoperability as well as token ownership distribution and may serve as a foundation for further research.",
        "published": "2020-12-16T22:52:10Z",
        "link": "http://arxiv.org/abs/2012.09306v1",
        "categories": [
            "econ.GN",
            "cs.CE",
            "q-fin.EC"
        ]
    },
    {
        "title": "Time Aggregation Techniques Applied to a Capacity Expansion Model for   Real-Life Sector Coupled Energy Systems",
        "authors": [
            "Mette Gamst",
            "Stefanie Buchholz",
            "David Pisinger"
        ],
        "summary": "Simulating energy systems is vital for energy planning to understand the effects of fluctuating renewable energy sources and integration of multiple energy sectors. Capacity expansion is a powerful tool for energy analysts and consists of simulating energy systems with the option of investing in new energy sources. In this paper, we apply clustering based aggregation techniques from the literature to very different real-life sector coupled energy systems. We systematically compare the aggregation techniques with respect to solution quality and simulation time. Furthermore, we propose two new clustering approaches with promising results. We show that the aggregation techniques result in consistent solution time savings between 75% and 90%. Also, the quality of the aggregated solutions is generally very good. To the best of our knowledge, we are the first to analyze and conclude that a weighted representation of clusters is beneficial. Furthermore, to the best of our knowledge, we are the first to recommend a clustering technique with good performance across very different energy systems: the k-means with Euclidean distance measure, clustering days and with weighted selection, where the median, maximum and minimum elements from clusters are selected. A deeper analysis of the results reveal that the aggregation techniques excel when the investment decisions correlate well with the overall behavior of the energy system. We propose future research directions to remedy when this is not the case.",
        "published": "2020-12-17T12:16:36Z",
        "link": "http://arxiv.org/abs/2012.10244v1",
        "categories": [
            "eess.SY",
            "cs.CE",
            "cs.SY",
            "G.4; G.2.3"
        ]
    },
    {
        "title": "Crack propagation simulation without crack tracking algorithm: embedded   discontinuity formulation with incompatible modes",
        "authors": [
            "A. Stanic",
            "B. Brank",
            "A. Ibrahimbegovic",
            "H. G. Matthies"
        ],
        "summary": "We show that for the simulation of crack propagation in quasi-brittle, two-dimensional solids, very good results can be obtained with an embedded strong discontinuity quadrilateral finite element that has incompatible modes. Even more importantly, we demonstrate that these results can be obtained without using a crack tracking algorithm. Therefore, the simulation of crack patterns with several cracks, including branching, becomes possible. The avoidance of a tracking algorithm is mainly enabled by the application of a novel, local (Gauss-point based) criterion for crack nucleation, which determines the time of embedding the localisation line as well as its position and orientation. We treat the crack evolution in terms of a thermodynamical framework, with softening variables describing internal dissipative mechanisms of material degradation. As presented by numerical examples, many elements in the mesh may develop a crack, but only some of them actually open and/or slide, dissipate fracture energy, and eventually form the crack pattern. The novel approach has been implemented for statics and dynamics, and the results of computed difficult examples (including Kalthoff's test) illustrate its very satisfying performance. It effectively overcomes unfavourable restrictions of the standard embedded strong discontinuity formulations, namely the simulation of the propagation of a single crack only. Moreover, it is computationally fast and straightforward to implement. Our numerical solutions match the results of experimental tests and previously reported numerical results in terms of crack pattern, dissipated fracture energy, and load-displacement curve.",
        "published": "2020-12-17T13:46:29Z",
        "link": "http://arxiv.org/abs/2012.09581v3",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "A Bayesian multiscale CNN framework to predict local stress fields in   structures with microscale features",
        "authors": [
            "Vasilis Krokos",
            "Viet Bui Xuan",
            "Stéphane P. A. Bordas",
            "Philippe Young",
            "Pierre Kerfriden"
        ],
        "summary": "Multiscale computational modelling is challenging due to the high computational cost of direct numerical simulation by finite elements. To address this issue, concurrent multiscale methods use the solution of cheaper macroscale surrogates as boundary conditions to microscale sliding windows. The microscale problems remain a numerically challenging operation both in terms of implementation and cost. In this work we propose to replace the local microscale solution by an Encoder-Decoder Convolutional Neural Network that will generate fine-scale stress corrections to coarse predictions around unresolved microscale features, without prior parametrisation of local microscale problems. We deploy a Bayesian approach providing credible intervals to evaluate the uncertainty of the predictions, which is then used to investigate the merits of a selective learning framework. We will demonstrate the capability of the approach to predict equivalent stress fields in porous structures using linearised and finite strain elasticity theories.",
        "published": "2020-12-17T14:08:22Z",
        "link": "http://arxiv.org/abs/2012.11330v4",
        "categories": [
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "Explicit RKF-Compact Scheme for Pricing Regime Switching American   Options with Varying Time Step",
        "authors": [
            "Chinonso Nwankwo",
            "Weizhong Dai"
        ],
        "summary": "In this research work, an explicit Runge-Kutta-Fehlberg (RKF) time integration with a fourth-order compact finite difference scheme in space and a high order analytical approximation of the optimal exercise boundary is employed for solving the regime-switching pricing model. In detail, we recast the free boundary problem into a system of nonlinear partial differential equations with a multi-fixed domain. We then introduce a transformation based on the square root function with a Lipschitz character from which a high order analytical approximation is obtained to compute the derivative of the optimal exercise boundary in each regime. We further compute the boundary values, asset option, and the option Greeks for each regime using fourth-order spatial discretization and adaptive time integration. In particular, the coupled assets options and option Greeks are estimated using Hermite interpolation with Newton basis. Finally, a numerical experiment is carried out with two- and four-regimes examples and results are compared with the existing methods. The results obtained from the numerical experiment show that the present method provides better performance in terms of computational speed and more accurate solutions with a large step size.",
        "published": "2020-12-17T18:41:26Z",
        "link": "http://arxiv.org/abs/2012.09820v4",
        "categories": [
            "q-fin.CP",
            "cs.CE",
            "cs.NA",
            "math.NA",
            "q-fin.MF",
            "q-fin.PR",
            "65M50 65M22"
        ]
    },
    {
        "title": "Quantifying the unknown impact of segmentation uncertainty on   image-based simulations",
        "authors": [
            "Michael C. Krygier",
            "Tyler LaBonte",
            "Carianne Martinez",
            "Chance Norris",
            "Krish Sharma",
            "Lincoln N. Collins",
            "Partha P. Mukherjee",
            "Scott A. Roberts"
        ],
        "summary": "Image-based simulation, the use of 3D images to calculate physical quantities, fundamentally relies on image segmentation to create the computational geometry. However, this process introduces image segmentation uncertainty because there is a variety of different segmentation tools (both manual and machine-learning-based) that will each produce a unique and valid segmentation. First, we demonstrate that these variations propagate into the physics simulations, compromising the resulting physics quantities. Second, we propose a general framework for rapidly quantifying segmentation uncertainty. Through the creation and sampling of segmentation uncertainty probability maps, we systematically and objectively create uncertainty distributions of the physics quantities. We show that physics quantity uncertainty distributions can follow a Normal distribution, but, in more complicated physics simulations, the resulting uncertainty distribution can be both nonintuitive and surprisingly nontrivial. We also establish that simply bounding the uncertainty can fail in situations that are sensitive to image segmentation. While our work does not eliminate segmentation uncertainty, it makes visible the previously unrecognized range of uncertainty currently plaguing image-based simulation, enabling more credible simulations.",
        "published": "2020-12-17T20:17:42Z",
        "link": "http://arxiv.org/abs/2012.09913v3",
        "categories": [
            "cs.CE",
            "eess.IV"
        ]
    },
    {
        "title": "A multigrid/ensemble Kalman Filter strategy for assimilation of unsteady   flows",
        "authors": [
            "Gabriel Moldovan",
            "Guillame Lehnasch",
            "Laurent Cordier",
            "Marcello Meldi"
        ],
        "summary": "A sequential estimator based on the Ensemble Kalman Filter for Data Assimilation of fluid flows is presented in this research work. The main feature of this estimator is that the Kalman filter update, which relies on the determination of the Kalman gain, is performed exploiting the algorithmic features of the numerical solver employed as a model. More precisely, the multilevel resolution associated with the multigrid iterative approach for time advancement is used to generate several low-resolution numerical simulations. These results are used as ensemble members to determine the correction via Kalman filter, which is then projected on the high-resolution grid to correct a single simulation which corresponds to the numerical model. The assessment of the method is performed via the analysis of one-dimensional and two-dimensional test cases, using different dynamic equations. The results show an efficient trade-off in terms of accuracy and computational costs required. In addition, a physical regularization of the flow, which is not granted by classical KF approaches, is naturally obtained owing to the multigrid iterative calculations. The algorithm is also well suited for the analysis of unsteady phenomena and, in particular,for potential application to in-streaming Data Assimilation techniques.",
        "published": "2020-12-18T07:52:53Z",
        "link": "http://arxiv.org/abs/2012.10091v1",
        "categories": [
            "cs.CE",
            "physics.flu-dyn"
        ]
    },
    {
        "title": "yNet: a multi-input convolutional network for ultra-fast simulation of   field evolvement",
        "authors": [
            "Zhuo Wang",
            "Xiao Wang",
            "Wenhua Yang",
            "Yaohong Xiao",
            "Yucheng Liu",
            "Lei Chen"
        ],
        "summary": "The capability of multi-input field-to-field regression, i.e. mapping the initial field and applied conditions to the evolved field, is appealing, enabling ultra-fast physics-free simulation of various field evolvements across many disciplines. We hereby propose a y-shaped multi-input deep convolutional network, yNet, which can effectively account for combined effects of multiple mixed inputs on output field. The proposed yNet is applied to the simulation of porosity evolution in selective lasering sintering (SLS). Upon testing, yNet can simulate nearly identical porosity evolution and development to the physics-based model, with a 99.13% morphological similarity for various SLS conditions. We then effortlessly boost the porosity simulation capability to the realistic, full-component level. yNet is generally applicable to simulating various structural/morphological evolutions and other condition-concerned, continuous field evolvements even with spatially and/or temporally non-uniform evolving kinetics. Once trained, the light-weight yNet can be distributed easily and ran with limited computational resource while reducing computation time to a split second. It thus may have a transformative impact by democratizing the capability of ultra-fast and extreme-scale simulation of various field evolvements.",
        "published": "2020-12-19T02:09:57Z",
        "link": "http://arxiv.org/abs/2012.10575v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A Predictive Discrete-Continuum Multiscale Model of Plasticity With   Quantified Uncertainty",
        "authors": [
            "Jingye Tan",
            "Umberto Villa",
            "Nima Shamsaei",
            "Shuai Shao",
            "Hussein M. Zbib",
            "Danial Faghihi"
        ],
        "summary": "Multiscale models of materials, consisting of upscaling discrete simulations to continuum models, are unique in their capability to simulate complex materials behavior. The fundamental limitation in multiscale models is the presence of uncertainty in the computational predictions delivered by them. In this work, a sequential multiscale model has been developed, incorporating discrete dislocation dynamics (DDD) simulations and a strain gradient plasticity (SGP) model to predict the size effect in plastic deformations of metallic micro-pillars. The DDD simulations include uniaxial compression of micro-pillars with different sizes and over a wide range of initial dislocation densities and spatial distributions of dislocations. An SGP model is employed at the continuum level that accounts for the size-dependency of flow stress and hardening rate. Sequences of uncertainty analyses have been performed to assess the predictive capability of the multiscale model. The variance-based global sensitivity analysis determines the effect of parameter uncertainty on the SGP model prediction. The multiscale model is then constructed by calibrating the continuum model using the data furnished by the DDD simulations. A Bayesian calibration method is implemented to quantify the uncertainty due to microstructural randomness in discrete dislocation simulations (density and spatial distributions of dislocations) on the macroscopic continuum model prediction (size effect in plastic deformation). The outcomes of this study indicate that the discrete-continuum multiscale model can accurately simulate the plastic deformation of micro-pillars, despite the significant uncertainty in the DDD results. Additionally, depending on the macroscopic features represented by the DDD simulations, the SGP model can reliably predict the size effect in plasticity responses of the micropillars with below 10% of error",
        "published": "2020-12-20T01:29:38Z",
        "link": "http://arxiv.org/abs/2012.10823v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Universal Numbers Library: design and implementation of a   high-performance reproducible number systems library",
        "authors": [
            "E. Theodore L. Omtzigt",
            "Peter Gottschling",
            "Mark Seligman",
            "William Zorn"
        ],
        "summary": "With the proliferation of embedded systems requiring intelligent behavior, custom number systems to optimize performance per Watt of the entire system become essential components for successful commercial products. We present the Universal Number Library, a high-performance number systems library that includes arbitrary integer, decimal, fixed-point, floating-point, and introduces two tapered floating-point types, posit and valid, that support reproducible arithmetic computation in arbitrary concurrency environments. We discuss the design of the Universal library as a run-time for application development, and as a platform for application-driven hardware validation. The library implementation is described, and examples are provided to show educational examples to elucidate the number system properties, and how specialization is used to yield very high-performance emulation on existing x86, ARM, and POWER processors. We will highlight the integration of the library in larger application environments in computational science and engineering to enable multi-precision and adaptive precision algorithms to improve performance and efficiency of large scale and real-time applications. We will demonstrate the integration of the Universal library into a high-performance reproducible linear algebra run-time. We will conclude with the roadmap of additional functionality of the library as we are targeting new application domains, such as Software Defined Radio, instrumentation, sensor fusion, and model-predictive control.",
        "published": "2020-12-20T20:07:57Z",
        "link": "http://arxiv.org/abs/2012.11011v1",
        "categories": [
            "cs.CE",
            "cs.MS"
        ]
    },
    {
        "title": "A novel structure preserving semi-implicit finite volume method for   viscous and resistive magnetohydrodynamics",
        "authors": [
            "Francesco Fambri"
        ],
        "summary": "In this work we introduce a novel semi-implicit structure-preserving finite-volume/finite-difference scheme for the viscous and resistive equations of magnetohydrodynamics (MHD) based on an appropriate 3-split of the governing PDE system, which is decomposed into a first convective subsystem, a second subsystem involving the coupling of the velocity field with the magnetic field and a third subsystem involving the pressure-velocity coupling. The nonlinear convective terms are discretized explicitly, while the remaining two subsystems accounting for the Alfven waves and the magneto-acoustic waves are treated implicitly. The final algorithm is at least formally constrained only by a mild CFL stability condition depending on the velocity field of the pure hydrodynamic convection. To preserve the divergence-free constraint of the magnetic field exactly at the discrete level, a proper set of overlapping dual meshes is employed. The resulting linear algebraic systems are shown to be symmetric and therefore can be solved by means of an efficient standard matrix-free conjugate gradient algorithm. One of the peculiarities of the presented algorithm is that the magnetic field is defined on the edges of the main grid, while the electric field is on the faces. The final scheme can be regarded as a novel shock-capturing, conservative and structure preserving semi-implicit scheme for the nonlinear viscous and resistive MHD equations. Several numerical tests are presented to show the main features of our novel solver: linear-stability in the sense of Lyapunov is verified at a prescribed constant equilibrium solution; a 2nd-order of convergence is numerically estimated; shock-capturing capabilities are proven against a standard set of stringent MHD shock-problems; accuracy and robustness are verified against a nontrivial set of 2- and 3-dimensional MHD problems.",
        "published": "2020-12-21T10:01:34Z",
        "link": "http://arxiv.org/abs/2012.11218v2",
        "categories": [
            "math.NA",
            "astro-ph.IM",
            "cs.CE",
            "cs.NA",
            "physics.plasm-ph",
            "G.1; J.2"
        ]
    },
    {
        "title": "Quantifying the predictability of visual scanpaths using active   information storage",
        "authors": [
            "Patricia Wollstadt",
            "Martina Hasenjäger",
            "Christiane B. Wiebel-Herboth"
        ],
        "summary": "Entropy-based measures are an important tool for studying human gaze behavior under various conditions. In particular, gaze transition entropy (GTE) is a popular method to quantify the predictability of fixation transitions. However, GTE does not account for temporal dependencies beyond two consecutive fixations and may thus underestimate a scanpath's actual predictability. Instead, we propose to quantify scanpath predictability by estimating the active information storage (AIS), which can account for dependencies spanning multiple fixations. AIS is calculated as the mutual information between a processes' multivariate past state and its next value. It is thus able to measure how much information a sequence of past fixations provides about the next fixation, hence covering a longer temporal horizon. Applying the proposed approach, we were able to distinguish between induced observer states based on estimated AIS, providing first evidence that AIS may be used in the inference of user states to improve human-machine interaction.",
        "published": "2020-12-21T16:02:26Z",
        "link": "http://arxiv.org/abs/2012.11447v1",
        "categories": [
            "cs.CE",
            "cs.IT",
            "math.IT",
            "q-bio.QM"
        ]
    },
    {
        "title": "Structure-preserving, energy stable numerical schemes for a liquid thin   film coarsening model",
        "authors": [
            "Juan Zhang",
            "Cheng Wang",
            "Steven M. Wise",
            "Zhengru Zhang"
        ],
        "summary": "In this paper, two finite difference numerical schemes are proposed and analyzed for the droplet liquid film model, with a singular Leonard-Jones energy potential involved. Both first and second order accurate temporal algorithms are considered. In the first order scheme, the convex potential and the surface diffusion terms are implicitly, while the concave potential term is updated explicitly. Furthermore, we provide a theoretical justification that this numerical algorithm has a unique solution, such that the positivity is always preserved for the phase variable at a point-wise level, so that a singularity is avoided in the scheme. In fact, the singular nature of the Leonard-Jones potential term around the value of 0 prevents the numerical solution reaching such singular value, so that the positivity structure is always preserved. Moreover, an unconditional energy stability of the numerical scheme is derived, without any restriction for the time step size. In the second order numerical scheme, the BDF temporal stencil is applied, and an alternate convex-concave decomposition is derived, so that the concave part corresponds to a quadratic energy. In turn, the combined Leonard-Jones potential term is treated implicitly, and the concave part the is approximated by a second order Adams-Bashforth explicit extrapolation, and an artificial Douglas-Dupont regularization term is added to ensure the energy stability. The unique solvability and the positivity-preserving property for the second order scheme could be similarly established. In addition, optimal rate convergence analysis is provided for both the first and second order accurate schemes. A few numerical simulation results are also presented, which demonstrate the robustness of the numerical schemes.",
        "published": "2020-12-22T02:49:12Z",
        "link": "http://arxiv.org/abs/2012.11802v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "35A15 (Primary) 12-XX, 12-08 (Secondary)",
            "F.2.2; G.2"
        ]
    },
    {
        "title": "A Consistent Higher-Order Isogeometric Shell Formulation",
        "authors": [
            "Daniel Schöllhammer",
            "Benjamin Marussig",
            "Thomas-Peter Fries"
        ],
        "summary": "Shell analysis is a well-established field, but achieving optimal higher-order convergence rates for such simulations is a difficult challenge. We present an isogeometric Kirchhoff-Love shell framework that treats every numerical aspect in a consistent higher-order accurate way. In particular, a single trimmed B-spline surface provides a sufficiently smooth geometry, and the non-symmetric Nitsche method enforces the boundary conditions. A higher-order accurate reparametrization of cut knot spans in the parameter space provides a robust, higher-order accurate quadrature for (multiple) trimming curves, and the extended B-spline concept controls the conditioning of the resulting system of equations. Besides these components ensuring all requirements for higher-order accuracy, the presented shell formulation is based on tangential differential calculus, and level-set functions define the trimming curves. Numerical experiments confirm that the approach yields higher-order convergence rates, given that the solution is sufficiently smooth.",
        "published": "2020-12-22T12:53:16Z",
        "link": "http://arxiv.org/abs/2012.11975v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "An Entropy Stable Nodal Discontinuous Galerkin Method for the resistive   MHD Equations. Part II: Subcell Finite Volume Shock Capturing",
        "authors": [
            "Andrés M Rueda-Ramírez",
            "Sebastian Hennemann",
            "Florian J Hindenlang",
            "Andrew R Winters",
            "Gregor Gassner"
        ],
        "summary": "The second paper of this series presents two robust entropy stable shock-capturing methods for discontinuous Galerkin spectral element (DGSEM) discretizations of the compressible magneto-hydrodynamics (MHD) equations. Specifically, we use the resistive GLM-MHD equations, which include a divergence cleaning mechanism that is based on a generalized Lagrange multiplier (GLM). For the continuous entropy analysis to hold, and due to the divergence-free constraint on the magnetic field, the GLM-MHD system requires the use of non-conservative terms, which need special treatment.   Hennemann et al. [DOI:10.1016/j.jcp.2020.109935] recently presented an entropy stable shock-capturing strategy for DGSEM discretizations of the Euler equations that blends the DGSEM scheme with a subcell first-order finite volume (FV) method. Our first contribution is the extension of the method of Hennemann et al. to systems with non-conservative terms, such as the GLM-MHD equations. In our approach, the advective and non-conservative terms of the equations are discretized with a hybrid FV/DGSEM scheme, whereas the visco-resistive terms are discretized only with the high-order DGSEM method. We prove that the extended method is entropy stable on three-dimensional unstructured curvilinear meshes. Our second contribution is the derivation and analysis of a second entropy stable shock-capturing method that provides enhanced resolution by using a subcell reconstruction procedure that is carefully built to ensure entropy stability.   We provide a numerical verification of the properties of the hybrid FV/DGSEM schemes on curvilinear meshes and show their robustness and accuracy with common benchmark cases, such as the Orszag-Tang vortex and the GEM reconnection challenge. Finally, we simulate a space physics application: the interaction of Jupiter's magnetic field with the plasma torus generated by the moon Io.",
        "published": "2020-12-22T14:26:37Z",
        "link": "http://arxiv.org/abs/2012.12040v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Market Impact in Trader-Agents: Adding Multi-Level Order-Flow   Imbalance-Sensitivity to Automated Trading Systems",
        "authors": [
            "Zhen Zhang",
            "Dave Cliff"
        ],
        "summary": "Financial markets populated by human traders often exhibit \"market impact\", where the traders' quote-prices move in the direction of anticipated change, before any transaction has taken place, as an immediate reaction to the arrival of a large (i.e., \"block\") buy or sell order in the market: e.g., traders in the market know that a block buy order will push the price up, and so they immediately adjust their quote-prices upwards. Most major financial markets now involve many \"robot traders\", autonomous adaptive software agents, rather than humans. This paper explores how to give such trader-agents a reliable anticipatory sensitivity to block orders, such that markets populated entirely by robot traders also show market-impact effects. In a 2019 publication Church & Cliff presented initial results from a simple deterministic robot trader, ISHV, which exhibits this market impact effect via monitoring a metric of imbalance between supply and demand in the market. The novel contributions of our paper are: (a) we critique the methods used by Church & Cliff, revealing them to be weak, and argue that a more robust measure of imbalance is required; (b) we argue for the use of multi-level order-flow imbalance (MLOFI: Xu et al., 2019) as a better basis for imbalance-sensitive robot trader-agents; and (c) we demonstrate the use of the more robust MLOFI measure in extending ISHV, and also the well-known AA and ZIP trading-agent algorithms (which have both been previously shown to consistently outperform human traders). We demonstrate that the new imbalance-sensitive trader-agents introduced here do exhibit market impact effects, and hence are better-suited to operating in markets where impact is a factor of concern or interest, but do not suffer the weaknesses of the methods used by Church & Cliff. The source-code for our work reported here is freely available on GitHub.",
        "published": "2020-12-23T09:36:41Z",
        "link": "http://arxiv.org/abs/2012.12555v1",
        "categories": [
            "q-fin.TR",
            "cs.CE"
        ]
    },
    {
        "title": "Accurate evaluation of integrals in slender-body formulations for fibers   in viscous flow",
        "authors": [
            "Anna-Karin Tornberg"
        ],
        "summary": "A non-local slender body approximation for slender flexible fibers in Stokes flow can be derived, yielding an integral equation along the center lines of the fibers that involves a slenderness parameter. The formulation contains a so-called finite part singular integral, and can in the case of several fibers or evaluation of the flow field require the evaluation of nearly singular integrals.   We introduce a numerical technique to accurately and efficiently evaluate the finite part integral. This technique can be applied combined with any panel based quadrature rule and will add no additional cost except for a small precomputation of modified quadrature weights. We also show how a related technique that was recently introduced can be applied for the evaluation of the nearly singular integrals.",
        "published": "2020-12-23T10:31:48Z",
        "link": "http://arxiv.org/abs/2012.12585v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Optimal approximation spaces for discontinuous Petrov-Galerkin finite   element methods",
        "authors": [
            "Ankit Chakraborty",
            "Ajay Rangarajan",
            "Georg May"
        ],
        "summary": "Certain Petrov-Galerkin schemes are inherently stable formulations of variational problems on a given mesh. This stability is primarily obtained by computing an optimal test basis for a given approximation space. Furthermore, these Petrov-Galerkin schemes are equipped with a robust a posteriori error estimate which makes them an ideal candidate for mesh adaptation. One could extend these Petrov-Galerkin schemes not only to have optimal test spaces but also optimal approximation spaces with respect to current estimates of the solution. These extensions are the main focus of this article. In this article, we provide a methodology to drive mesh adaptation to produce optimal meshes for resolving solution features and output functionals which we demonstrate through numerical experiments.",
        "published": "2020-12-23T15:44:03Z",
        "link": "http://arxiv.org/abs/2012.12751v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A general theory for anisotropic Kirchhoff-Love shells with in-plane   bending of embedded fibers",
        "authors": [
            "Thang Xuan Duong",
            "Vu Ngoc Khiêm",
            "Mikhail Itskov",
            "Roger Andrew Sauer"
        ],
        "summary": "This work presents a generalized Kirchhoff-Love shell theory that can explicitly capture fiber-induced anisotropy not only in stretching and out-of-plane bending, but also in in-plane bending. This setup is particularly suitable for heterogeneous and fibrous materials such as textiles, biomaterials, composites and pantographic structures. The presented theory is a direct extension of classical Kirchhoff-Love shell theory to incorporate the in-plane bending resistance of fibers. It also extends existing second-gradient Kirchhoff-Love shell theory for initially straight fibers to initially curved fibers. To describe the additional kinematics of multiple fiber families, a so-called in-plane curvature tensor -- which is symmetric and of second order -- is proposed. The effective stress tensor and the in-plane and out-of-plane moment tensors are then identified from the mechanical power balance. These tensors are all second order and symmetric in general. Constitutive equations for hyperelastic materials are derived from different expressions of the mechanical power balance. The weak form is also presented as it is required for computational shell formulations based on rotation-free finite element discretizations.",
        "published": "2020-12-23T17:50:18Z",
        "link": "http://arxiv.org/abs/2101.03122v3",
        "categories": [
            "cond-mat.mtrl-sci",
            "cs.CE"
        ]
    },
    {
        "title": "Evaluating structural edge importance in temporal networks",
        "authors": [
            "Isobel Seabrook",
            "Paolo Barucca",
            "Fabio Caccioli"
        ],
        "summary": "To monitor risk in temporal financial networks, we need to understand how individual behaviours affect the global evolution of networks. Here we define a structural importance metric - which we denote as $l_e$ - for the edges of a network. The metric is based on perturbing the adjacency matrix and observing the resultant change in its largest eigenvalues. We then propose a model of network evolution where this metric controls the probabilities of subsequent edge changes. We show using synthetic data how the parameters of the model are related to the capability of predicting whether an edge will change from its value of $l_e$. We then estimate the model parameters associated with five real financial and social networks, and we study their predictability. These methods have application in financial regulation whereby it is important to understand how individual changes to financial networks will impact their global behaviour. It also provides fundamental insights into spectral predictability in networks, and it demonstrates how spectral perturbations can be a useful tool in understanding the interplay between micro and macro features of networks.",
        "published": "2020-12-23T18:50:39Z",
        "link": "http://arxiv.org/abs/2012.12883v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A second-order self-adjusting steepness based remapping method for   arbitrary quadrilateral meshes",
        "authors": [
            "Zhiwei He"
        ],
        "summary": "In this paper, based on the idea of self-adjusting steepness based schemes[5], a two-dimensional calculation method of steepness parameter is proposed, and thus a two-dimensional self-adjusting steepness based limiter is constructed. With the application of such limiter to the over-intersection based remapping framework, a low dissipation remapping method has been proposed that can be applied to the existing ALE method.",
        "published": "2020-12-26T12:44:37Z",
        "link": "http://arxiv.org/abs/2101.06298v1",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA",
            "physics.comp-ph"
        ]
    },
    {
        "title": "A coupled finite volume and material point method for two-phase   simulation of liquid-sediment and gas-sediment flows",
        "authors": [
            "Aaron S. Baumgarten",
            "Benjamin L. S. Couchman",
            "Ken Kamrin"
        ],
        "summary": "Mixtures of fluids and granular sediments play an important role in many industrial, geotechnical, and aerospace engineering problems, from waste management and transportation (liquid--sediment mixtures) to dust kick-up below helicopter rotors (gas--sediment mixtures). These mixed flows often involve bulk motion of hundreds of billions of individual sediment particles and can contain both highly turbulent regions and static, non-flowing regions. This breadth of phenomena necessitates the use of continuum simulation methods, such as the material point method (MPM), which can accurately capture these large deformations while also tracking the Lagrangian features of the flow (e.g.\\ the granular surface, elastic stress, etc.).   Recent works using two-phase MPM frameworks to simulate these mixtures have shown substantial promise; however, these approaches are hindered by the numerical limitations of MPM when simulating pure fluids. In addition to the well-known particle ringing instability and difficulty defining inflow/outflow boundary conditions, MPM has a tendency to accumulate quadrature errors as materials deform, increasing the rate of overall error growth as simulations progress. In this work, we present an improved, two-phase continuum simulation framework that uses the finite volume method (FVM) to solve the fluid phase equations of motion and MPM to solve the solid phase equations of motion, substantially reducing the effect of these errors and providing better accuracy and stability for long-duration simulations of these mixtures.",
        "published": "2020-12-27T04:55:49Z",
        "link": "http://arxiv.org/abs/2012.13862v2",
        "categories": [
            "cs.CE",
            "cond-mat.soft"
        ]
    },
    {
        "title": "Constrained optimisation of preliminary spacecraft configurations under   the design-for-demise paradigm",
        "authors": [
            "Mirko Trisolini",
            "Hugh G. Lewis",
            "Camilla Colombo"
        ],
        "summary": "In the past few years, the interest towards the implementation of design-for-demise measures has increased steadily. Most mid-sized satellites currently launched and already in orbit fail to comply with the casualty risk threshold of 0.0001. Therefore, satellites manufacturers and mission operators need to perform a disposal through a controlled re-entry, which has a higher cost and increased complexity. Through the design-for-demise paradigm, this additional cost and complexity can be removed as the spacecraft is directly compliant with the casualty risk regulations. However, building a spacecraft such that most of its parts will demise may lead to designs that are more vulnerable to space debris impacts, thus compromising the reliability of the mission. In fact, the requirements connected to the demisability and the survivability are in general competing. Given this competing nature, trade-off solutions can be found, which favour the implementation of design-for-demise measures while still maintaining the spacecraft resilient to space debris impacts. A multi-objective optimisation framework has been developed by the authors in previous works. The framework's objective is to find preliminary design solutions considering the competing nature of the demisability and the survivability of a spacecraft since the early stages of the mission design. In this way, a more integrated design can be achieved. The present work focuses on the improvement of the multi-objective optimisation framework by including constraints. The paper shows the application of the constrained optimisation to two relevant examples: the optimisation of a tank assembly and the optimisation of a typical satellite configuration.",
        "published": "2020-12-27T17:48:29Z",
        "link": "http://arxiv.org/abs/2101.01558v2",
        "categories": [
            "eess.SY",
            "cs.CE",
            "cs.NE",
            "cs.SY"
        ]
    },
    {
        "title": "Computational Analysis of Subscapularis Tears and Pectoralis Major   Transfers on Muscular Activity",
        "authors": [
            "Fabien Péan",
            "Philippe Favre",
            "Orcun Goksel"
        ],
        "summary": "Muscle transfers are commonly performed to restore joint function after muscle tears. However, there are not many biomechanical studies of muscle transfers, with the available ones often limited to passive movements in anatomical planes. Using data from three activities of daily living (ADL) and an available computational musculoskeletal model of the shoulder, we analyse the impact of a subscapularis tear and its treatment by a pectoralis major (PMA) transfer of the clavicular, sternal, or both segments. The shoulder model is validated against experimental data: the model kinematics with motion capture, muscle activity with EMG measurements, and model joint reaction force with in-vivo data from an instrumented prosthesis. Our results indicate that subscapularis tear requires a compensatory activation of the supraspinatus and is accompanied by a reduced co-contraction of the infraspinatus, both of which can be partially recovered after PMA transfer. Furthermore, although the PMA acts asynchronously to the subscapularis before the transfer, its patterns of activation change significantly after the transfer. Overall, this study demonstrates that muscle transfers have a significant impact on the neuromuscular system of the joint during active motion, beyond mere kinematics. Capability of a transferred muscle segment to activate similarly to intact subscapularis is found to be dependent on a considered motion. Differences in the activation patterns between intact subscapularis and segments of PMA may explain the difficulty of some patients in adapting their psycho-motor patterns during the rehabilitation period. Thereby, rehabilitation programs could benefit from targeted training on specific motion patterns and biofeedback programs. Finally, the condition of the anterior deltoid should be considered to avoid adding limitations to the joint function before a transfer of the clavicular part.",
        "published": "2020-12-28T16:32:41Z",
        "link": "http://arxiv.org/abs/2012.14340v1",
        "categories": [
            "physics.med-ph",
            "cs.CE",
            "q-bio.QM"
        ]
    },
    {
        "title": "Interactions of Linguistic and Domain Overhypotheses in Category   Learning",
        "authors": [
            "Luann C. Jung",
            "Haiyan Wang"
        ],
        "summary": "For humans learning to categorize and distinguish parts of the world, the set of assumptions (overhypotheses) they hold about potential category structures is directly related to their learning process. In this work we examine the effects of two overhypotheses for category learning: 1) the bias introduced by the presence of linguistic labels for objects; 2) the conceptual 'domain' biases inherent in the learner about which features are most indicative of category structure. These two biases work in tandem to impose priors on the learning process; and we model and detail their interaction and effects. This paper entails an adaptation and expansion of prior experimental work that addressed label bias effects but did not fully explore conceptual domain biases. Our results highlight the importance of both the domain and label biases in facilitating or hindering category learning.",
        "published": "2020-12-28T18:27:40Z",
        "link": "http://arxiv.org/abs/2012.14400v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A Stock Options Metaphor for Content Delivery Networks",
        "authors": [
            "Elias Vathias",
            "Stathes Hadjiefthymiades"
        ],
        "summary": "The concept of Stock Options is used to address the scarcity of resources, not adequately addressed by the previous tools of our Prediction Mechanism. Using a Predictive Reservation Scheme, network and disk resources are being monitored through well-established techniques (Kernel Regression Estimators) in a given time frame. Next, an Secondary Market mechanism significantly improves the efficiency and robustness of our Predictive Reservation Scheme by allowing the fast exchange of unused (remaining) resources between the Origin Servers (CDN Clients). This exchange can happen, either by implementing socially optimal practices or by allowing automatic electronic auctions at the end of the day or at shorter time intervals. Finally, we further enhance our Prediction Mechanism; Stock Options are obtained and exercised, depending on the lack of resources at the end of day. As a result, Origin Servers may acquire resources (if required) at a normal price. The effectiveness of our mechanism further improves.",
        "published": "2020-12-28T19:23:26Z",
        "link": "http://arxiv.org/abs/2012.14454v1",
        "categories": [
            "cs.NI",
            "cs.CE",
            "91-10 (Primary)",
            "C.2.4; I.6.6"
        ]
    },
    {
        "title": "Nonlinear modal analysis of nonconservative systems: Extension of the   periodic motion concept",
        "authors": [
            "Malte Krack"
        ],
        "summary": "As the motions of nonconservative autonomous systems are typically not periodic, the definition of nonlinear modes as periodic motions cannot be applied in the classical sense. In this paper, it is proposed 'make the motions periodic' by introducing an additional damping term of appropriate sign and magnitude. It is shown that this generalized definition is particularly suited to reflect the periodic vibration behavior induced by harmonic external forcing or negative linear damping. In a large range, the energy dependence of modal frequency, damping ratio and stability is reproduced well. The limitation to isolated or weakly-damped modes is discussed.",
        "published": "2020-12-28T19:26:38Z",
        "link": "http://arxiv.org/abs/2101.00949v1",
        "categories": [
            "nlin.CD",
            "cs.CE"
        ]
    },
    {
        "title": "An efficient method for approximating resonance curves of weakly-damped   nonlinear mechanical systems",
        "authors": [
            "Alwin Förster",
            "Malte Krack"
        ],
        "summary": "A method is presented for tracing the locus of a specific peak in the frequency response under variation of a parameter. It is applicable to periodic, steady-state vibrations of harmonically forced nonlinear mechanical systems. It operates in the frequency domain and its central idea is to assume a constant phase lag between forcing and response. The method is validated for a two-degree-of-freedom oscillator with cubic spring and a bladed disk with shroud contact. The method provides superior computational efficiency, but is limited to weakly-damped systems. Finally, the capability to reveal isolated solution branches is highlighted.",
        "published": "2020-12-28T19:33:12Z",
        "link": "http://arxiv.org/abs/2012.14458v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A High-Order Harmonic Balance Method for Systems With Distinct States",
        "authors": [
            "Malte Krack",
            "Lars Panning-von Scheidt",
            "Jörg Wallaschek"
        ],
        "summary": "A pure frequency domain method for the computation of periodic solutions of nonlinear ordinary differential equations (ODEs) is proposed in this study. The method is particularly suitable for the analysis of systems that feature distinct states, i.e. where the ODEs involve piecewise defined functions. An event-driven scheme is used which is based on the direct calculation of the state transition time instants between these states. An analytical formulation of the governing nonlinear algebraic system of equations is developed for the case of piecewise polynomial systems. Moreover, it is shown that derivatives of the solution of up to second order can be calculated analytically, making the method especially attractive for design studies. The methodology is applied to several structural dynamical systems with conservative and dissipative nonlinearities in externally excited and autonomous configurations. Great performance and robustness of the proposed procedure was ascertained.",
        "published": "2020-12-28T19:41:56Z",
        "link": "http://arxiv.org/abs/2101.01806v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "A method for nonlinear modal analysis and synthesis: Application to   harmonically forced and self-excited mechanical systems",
        "authors": [
            "Malte Krack",
            "Lars Panning-von Scheidt",
            "Jörg Wallaschek"
        ],
        "summary": "The recently developed generalized Fourier-Galerkin method is complemented by a numerical continuation with respect to the kinetic energy, which extends the framework to the investigation of modal interactions resulting in folds of the nonlinear modes. In order to enhance the practicability regarding the investigation of complex large-scale systems, it is proposed to provide analytical gradients and exploit sparsity of the nonlinear part of the governing algebraic equations. A novel reduced order model (ROM) is developed for those regimes where internal resonances are absent. The approach allows for an accurate approximation of the multi-harmonic content of the resonant mode and accounts for the contributions of the off-resonant modes in their linearized forms. The ROM facilitates the efficient analysis of self-excited limit cycle oscillations, frequency response functions and the direct tracing of forced resonances. The ROM is equipped with a large parameter space including parameters associated with linear damping and near-resonant harmonic forcing terms. An important objective of this paper is to demonstrate the broad applicability of the proposed overall methodology. This is achieved by selected numerical examples including finite element models of structures with strongly nonlinear, non-conservative contact constraints.",
        "published": "2020-12-28T19:51:16Z",
        "link": "http://arxiv.org/abs/2101.01804v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Reliability optimization of friction-damped systems using nonlinear   modes",
        "authors": [
            "Malte Krack",
            "Sebastian Tatzko",
            "Lars Panning-von Scheidt",
            "Jörg Wallaschek"
        ],
        "summary": "A novel probabilistic approach for the design of mechanical structures with friction interfaces is proposed. The objective function is defined as the probability that a specified performance measure of the forced vibration response is achieved subject to parameter uncertainties. The practicability of the approach regarding the extensive amount of required design evaluations is strictly related to the computational efficiency of the nonlinear dynamic analysis. Therefore, it is proposed to employ a recently developed parametric reduced order model (ROM) based on nonlinear modes of vibration, which can facilitate a decrease of the computational burden by several orders of magnitude. The approach was applied to a rotationally periodic assembly of a bladed disk with underplatform friction dampers. The robustness of the optimum damper design was significantly improved compared to the deterministic approach, taking into account uncertainties in the friction coefficient, the excitation level and the linear damping. Moreover, a scale invariance for piecewise linear contact constraints is proven, which can be very useful for the reduction of the numerical effort for the analysis of such systems.",
        "published": "2020-12-28T19:57:45Z",
        "link": "http://arxiv.org/abs/2012.14466v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "On the computation of the slow dynamics of nonlinear modes of mechanical   systems",
        "authors": [
            "Malte Krack",
            "Lars Panning-von Scheidt",
            "Jörg Wallaschek"
        ],
        "summary": "A novel method for the numerical prediction of the slowly varying dynamics of nonlinear mechanical systems has been developed. The method is restricted to the regime of an isolated nonlinear mode and consists of a two-step procedure: In the first step, a multiharmonic analysis of the autonomous system is performed to directly compute the amplitude-dependent characteristics of the considered nonlinear mode. In the second step, these modal properties are used to construct a two-dimensional reduced order model (ROM) that facilitates the efficient computation of steady-state and unsteady dynamics provided that nonlinear modal interactions are absent. The proposed methodology is applied to several nonlinear mechanical systems ranging form single degree-of-freedom to Finite Element models. Unsteady vibration phenomena such as approaching behavior towards an equilibrium point or limit cycles, and resonance passages are studied regarding the effect of various nonlinearities such as cubic springs, unilateral contact and friction. It is found that the proposed ROM facilitates very fast and accurate analysis of the slow dynamics of nonlinear systems. Moreover, the ROM concept offers a huge parameter space including additional linear damping, stiffness and near-resonant forcing.",
        "published": "2020-12-28T20:01:33Z",
        "link": "http://arxiv.org/abs/2012.14469v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A chemo-mechano-thermodynamical contact theory for adhesion, friction   and (de)bonding reactions",
        "authors": [
            "Roger A. Sauer",
            "Thang X. Duong",
            "Kranthi K. Mandadapu"
        ],
        "summary": "This work presents a self-contained continuum formulation for coupled chemical, mechanical and thermal contact interactions. The formulation is very general and hence admits arbitrary geometry, deformation and material behavior. All model equations are derived rigorously from the balance laws of mass, momentum, energy and entropy in the framework of irreversible thermodynamics, thus exposing all the coupling present in the field equations and constitutive relations. In the process, the conjugated kinematic and kinetic variables for mechanical, thermal and chemical contact are identified, and the analogies between mechanical, thermal and chemical contact are highlighted. Particular focus is placed on the thermodynamics of chemical bonding distinguishing between exothermic and endothermic contact reactions. Distinction is also made between long-range, non-touching surface interactions and short-range, touching contact. For all constitutive relations examples are proposed and discussed comprehensively with particular focus on their coupling. Finally, three analytical test cases are presented that illustrate the thermo-chemo-mechanical contact coupling and are useful for verifying computational models. While the main novelty is the extension of existing contact formulations to chemical contact, the presented formulation also sheds new light on thermo-mechanical contact, since it is consistently derived from basic principles using only few assumptions.",
        "published": "2020-12-29T16:19:45Z",
        "link": "http://arxiv.org/abs/2012.14832v2",
        "categories": [
            "physics.class-ph",
            "cs.CE"
        ]
    },
    {
        "title": "Heterogeneous recovery from large scale power failures",
        "authors": [
            "Amir Hossein Afsharinejad",
            "Chuanyi Ji",
            "Robert Wilcox"
        ],
        "summary": "Large-scale power failures are induced by nearly all natural disasters from hurricanes to wild fires. A fundamental problem is whether and how recovery guided by government policies is able to meet the challenge of a wide range of disruptions. Prior research on this problem is scant due to lack of sharing large-scale granular data at the operational energy grid, stigma of revealing limitations of services, and complex recovery coupled with policies and customers. As such, both quantification and firsthand information are lacking on capabilities and fundamental limitation of energy services in response to extreme events. Furthermore, government policies that guide recovery are often sidelined by prior study. This work studies the fundamental problem through the lens of recovery guided by two commonly adopted policies. We develop data analysis on unsupervised learning from non-stationary data. The data span failure events, from moderate to extreme, at the operational distribution grid during the past nine years in two service regions at the state of New York and Massachusetts. We show that under the prioritization policy favoring large failures, recovery exhibits a surprising scaling property which counteracts failure scaling on the infrastructure vulnerability. However, heterogeneous recovery widens with the severity of failure events: large failures that cannot be prioritized increase customer interruption time by 47 folds. And, prolonged small failures dominate the entire temporal evolution of recovery.",
        "published": "2020-12-31T03:12:46Z",
        "link": "http://arxiv.org/abs/2012.15420v1",
        "categories": [
            "cs.CE",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Blade Envelopes Part II: Multiple Objectives and Inverse Design",
        "authors": [
            "Chun Yui Wong",
            "Pranay Seshadri",
            "Ashley Scillitoe",
            "Bryn Noel Ubald",
            "Andrew B. Duncan",
            "Geoffrey Parks"
        ],
        "summary": "Blade envelopes offer a set of data-driven tolerance guidelines for manufactured components based on aerodynamic analysis. In Part I of this two-part paper, a workflow for the formulation of blade envelopes is described and demonstrated. In Part II, this workflow is extended to accommodate multiple objectives. This allows engineers to prescribe manufacturing guidelines that take into account multiple performance criteria. The quality of a manufactured blade can be correlated with features derived from the distribution of primal flow quantities over the surface. We show that these distributions can be accounted for in the blade envelope using vector-valued models derived from discrete surface flow measurements. Our methods result in a set of variables that allows flexible and independent control over multiple flow characteristics and performance metrics, similar in spirit to inverse design methods. The augmentations to the blade envelope workflow presented in this paper are demonstrated on the LS89 turbine blade, focusing on the control of loss, mass flow and the isentropic Mach number distribution. Finally, we demonstrate how blade envelopes can be used to visualize invariant designs by producing a 3D render of the envelope using 3D modelling software.",
        "published": "2020-12-31T12:27:15Z",
        "link": "http://arxiv.org/abs/2012.15579v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "How to Identify Investor's types in real financial markets by means of   agent based simulation",
        "authors": [
            "Filippo Neri"
        ],
        "summary": "The paper proposes a computational adaptation of the principles underlying principal component analysis with agent based simulation in order to produce a novel modeling methodology for financial time series and financial markets. Goal of the proposed methodology is to find a reduced set of investor s models (agents) which is able to approximate or explain a target financial time series. As computational testbed for the study, we choose the learning system L FABS which combines simulated annealing with agent based simulation for approximating financial time series. We will also comment on how L FABS s architecture could exploit parallel computation to scale when dealing with massive agent simulations. Two experimental case studies showing the efficacy of the proposed methodology are reported.",
        "published": "2020-12-31T16:22:30Z",
        "link": "http://arxiv.org/abs/2101.03127v1",
        "categories": [
            "q-fin.TR",
            "cs.CE",
            "cs.LG",
            "I.2.6"
        ]
    },
    {
        "title": "Data-driven topology optimization of spinodoid metamaterials with   seamlessly tunable anisotropy",
        "authors": [
            "Li Zheng",
            "Siddhant Kumar",
            "Dennis M. Kochmann"
        ],
        "summary": "We present a two-scale topology optimization framework for the design of macroscopic bodies with an optimized elastic response, which is achieved by means of a spatially-variant cellular architecture on the microscale. The chosen spinodoid topology for the cellular network on the microscale (which is inspired by natural microstructures forming during spinodal decomposition) admits a seamless spatial grading as well as tunable elastic anisotropy, and it is parametrized by a small set of design parameters associated with the underlying Gaussian random field. The macroscale boundary value problem is discretized by finite elements, which in addition to the displacement field continuously interpolate the microscale design parameters. By assuming a separation of scales, the local constitutive behavior on the macroscale is identified as the homogenized elastic response of the microstructure based on the local design parameters. As a departure from classical FE$^2$-type approaches, we replace the costly microscale homogenization by a data-driven surrogate model, using deep neural networks, which accurately and efficiently maps design parameters onto the effective elasticity tensor. The model is trained on homogenized stiffness data obtained from numerical homogenization by finite elements. As an added benefit, the machine learning setup admits automatic differentiation, so that sensitivities (required for the optimization problem) can be computed exactly and without the need for numerical derivatives - a strategy that holds promise far beyond the elastic stiffness. Therefore, this framework presents a new opportunity for multiscale topology optimization based on data-driven surrogate models.",
        "published": "2020-12-31T17:30:25Z",
        "link": "http://arxiv.org/abs/2012.15744v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A Hybrid MPI-CUDA Approach for Nonequispaced Discrete Fourier   Transformation",
        "authors": [
            "Sheng-Chun Yang",
            "Yong-Lei Wang"
        ],
        "summary": "Nonequispaced discrete Fourier transformation (NDFT) is widely applied in all aspects of computational science and engineering. The computational efficiency and accuracy of NDFT has always been a critical issue in hindering its comprehensive applications both in intensive and in extensive aspects of scientific computing. In our previous work (2018, S.-C. Yang et al., Appl. Comput. Harmon. Anal. 44, 273), a CUNFFT method was proposed and it shown outstanding performance in handling NDFT at intermediate scale based on CUDA (Compute Unified Device Architecture) technology. In the current work, we further improved the computational efficiency of the CUNTTF method using an efficient MPI-CUDA hybrid parallelization (HP) scheme of NFFT to achieve a cutting-edge treatment of NDFT at super extended scale. Within this HP-NFFT method, the spatial domain of NDFT is decomposed into several parts according to the accumulative feature of NDFT and the detailed number of CPU and GPU nodes. These decomposed NDFT subcells are independently calculated on different CPU nodes using a MPI process-level parallelization mode, and on different GPU nodes using a CUDA threadlevel parallelization mode and CUNFFT algorithm. A massive benchmarking of the HP-NFFT method indicates that this method exhibit a dramatic improvement in computational efficiency for handling NDFT at super extended scale without loss of computational precision. Furthermore, the HP-NFFT method is validated via the calculation of Madelung constant of fluorite crystal structure, and thereafter verified that this method is robust for the calculation of electrostatic interactions between charged ions in molecular dynamics simulation systems.",
        "published": "2020-01-01T07:01:00Z",
        "link": "http://arxiv.org/abs/2001.01583v1",
        "categories": [
            "cs.MS",
            "cond-mat.soft",
            "physics.chem-ph",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Issues with rounding in the GCC implementation of the ISO 18037:2008   standard fixed-point arithmetic",
        "authors": [
            "Mantas Mikaitis"
        ],
        "summary": "We describe various issues caused by the lack of round-to-nearest mode in the \\textit{gcc} compiler implementation of the fixed-point arithmetic data types and operations. We demonstrate that round-to-nearest is not performed in the conversion of constants, conversion from one numerical type to a less precise type and results of multiplications. Furthermore, we show that mixed-precision operations in fixed-point arithmetic lose precision on arguments, even before carrying out arithmetic operations. The ISO 18037:2008 standard was created to standardize C language extensions, including fixed-point arithmetic, for embedded systems. Embedded systems are usually based on ARM processors, of which approximately 100 billion have been manufactured by now. Therefore, the observations about numerical issues that we discuss in this paper can be rather dangerous and are important to address, given the wide ranging type of applications that these embedded systems are running.",
        "published": "2020-01-06T11:37:04Z",
        "link": "http://arxiv.org/abs/2001.01496v3",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "Comparing Python, Go, and C++ on the N-Queens Problem",
        "authors": [
            "Pascal Fua",
            "Krzysztof Lis"
        ],
        "summary": "Python currently is the dominant language in the field of Machine Learning but is often criticized for being slow to perform certain tasks. In this report, we use the well-known $N$-queens puzzle as a benchmark to show that once compiled using the Numba compiler it becomes competitive with C++ and Go in terms of execution speed while still allowing for very fast prototyping. This is true of both sequential and parallel programs. In most cases that arise in an academic environment, it therefore makes sense to develop in ordinary Python, identify computational bottlenecks, and use Numba to remove them.",
        "published": "2020-01-08T13:09:11Z",
        "link": "http://arxiv.org/abs/2001.02491v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "Automatic Generation of Efficient Sparse Tensor Format Conversion   Routines",
        "authors": [
            "Stephen Chou",
            "Fredrik Kjolstad",
            "Saman Amarasinghe"
        ],
        "summary": "This paper shows how to generate code that efficiently converts sparse tensors between disparate storage formats (data layouts) such as CSR, DIA, ELL, and many others. We decompose sparse tensor conversion into three logical phases: coordinate remapping, analysis, and assembly. We then develop a language that precisely describes how different formats group together and order a tensor's nonzeros in memory. This lets a compiler emit code that performs complex remappings of nonzeros when converting between formats. We also develop a query language that can extract statistics about sparse tensors, and we show how to emit efficient analysis code that computes such queries. Finally, we define an abstract interface that captures how data structures for storing a tensor can be efficiently assembled given specific statistics about the tensor. Disparate formats can implement this common interface, thus letting a compiler emit optimized sparse tensor conversion code for arbitrary combinations of many formats without hard-coding for any specific combination.   Our evaluation shows that the technique generates sparse tensor conversion routines with performance between 1.00 and 2.01$\\times$ that of hand-optimized versions in SPARSKIT and Intel MKL, two popular sparse linear algebra libraries. And by emitting code that avoids materializing temporaries, which both libraries need for many combinations of source and target formats, our technique outperforms those libraries by 1.78 to 4.01$\\times$ for CSC/COO to DIA/ELL conversion.",
        "published": "2020-01-08T16:43:35Z",
        "link": "http://arxiv.org/abs/2001.02609v3",
        "categories": [
            "cs.MS",
            "cs.PL"
        ]
    },
    {
        "title": "Awkward Arrays in Python, C++, and Numba",
        "authors": [
            "Jim Pivarski",
            "Peter Elmer",
            "David Lange"
        ],
        "summary": "The Awkward Array library has been an important tool for physics analysis in Python since September 2018. However, some interface and implementation issues have been raised in Awkward Array's first year that argue for a reimplementation in C++ and Numba. We describe those issues, the new architecture, and present some examples of how the new interface will look to users. Of particular importance is the separation of kernel functions from data structure management, which allows a C++ implementation and a Numba implementation to share kernel functions, and the algorithm that transforms record-oriented data into columnar Awkward Arrays.",
        "published": "2020-01-15T16:48:07Z",
        "link": "http://arxiv.org/abs/2001.06307v2",
        "categories": [
            "cs.MS",
            "hep-ex"
        ]
    },
    {
        "title": "MonteCarloMeasurements.jl: Nonlinear Propagation of Arbitrary   Multivariate Distributions by means of Method Overloading",
        "authors": [
            "Fredrik Bagge Carlson"
        ],
        "summary": "This manuscript outlines a software package that facilitates working with probability distributions by means of Monte-Carlo methods, in a way that allows for propagation of multivariate probability distributions through arbitrary functions. We provide a \\emph{type} that represents probability distributions by an internal vector of unweighted samples, \\texttt{Particles}, which is a subtype of a \\texttt{Real} number and behaves just like a regular real number in calculations by means of method overloading. This makes the software easy to work with and presents minimal friction for the user. We highlight how this design facilitates optimal usage of SIMD instructions and showcase the package for uncertainty propagation through an off-the-shelf ODE solver, as well as for robust probabilistic optimization with automatic differentiation.",
        "published": "2020-01-21T16:03:57Z",
        "link": "http://arxiv.org/abs/2001.07625v1",
        "categories": [
            "cs.MS",
            "stat.CO",
            "stat.OT"
        ]
    },
    {
        "title": "Automatically Harnessing Sparse Acceleration",
        "authors": [
            "Philip Ginsbach",
            "Bruce Collie",
            "Michael F. P. O'Boyle"
        ],
        "summary": "Sparse linear algebra is central to many scientific programs, yet compilers fail to optimize it well. High-performance libraries are available, but adoption costs are significant. Moreover, libraries tie programs into vendor-specific software and hardware ecosystems, creating non-portable code.   In this paper, we develop a new approach based on our specification Language for implementers of Linear Algebra Computations (LiLAC). Rather than requiring the application developer to (re)write every program for a given library, the burden is shifted to a one-off description by the library implementer. The LiLAC-enabled compiler uses this to insert appropriate library routines without source code changes.   LiLAC provides automatic data marshaling, maintaining state between calls and minimizing data transfers. Appropriate places for library insertion are detected in compiler intermediate representation, independent of source languages.   We evaluated on large-scale scientific applications written in FORTRAN; standard C/C++ and FORTRAN benchmarks; and C++ graph analytics kernels. Across heterogeneous platforms, applications and data sets we show speedups of 1.1$\\times$ to over 10$\\times$ without user intervention.",
        "published": "2020-01-22T10:04:36Z",
        "link": "http://arxiv.org/abs/2001.07938v1",
        "categories": [
            "cs.PF",
            "cs.MS"
        ]
    },
    {
        "title": "pymoo: Multi-objective Optimization in Python",
        "authors": [
            "Julian Blank",
            "Kalyanmoy Deb"
        ],
        "summary": "Python has become the programming language of choice for research and industry projects related to data science, machine learning, and deep learning. Since optimization is an inherent part of these research fields, more optimization related frameworks have arisen in the past few years. Only a few of them support optimization of multiple conflicting objectives at a time, but do not provide comprehensive tools for a complete multi-objective optimization task. To address this issue, we have developed pymoo, a multi-objective optimization framework in Python. We provide a guide to getting started with our framework by demonstrating the implementation of an exemplary constrained multi-objective optimization scenario. Moreover, we give a high-level overview of the architecture of pymoo to show its capabilities followed by an explanation of each module and its corresponding sub-modules. The implementations in our framework are customizable and algorithms can be modified/extended by supplying custom operators. Moreover, a variety of single, multi and many-objective test problems are provided and gradients can be retrieved by automatic differentiation out of the box. Also, pymoo addresses practical needs, such as the parallelization of function evaluations, methods to visualize low and high-dimensional spaces, and tools for multi-criteria decision making. For more information about pymoo, readers are encouraged to visit: https://pymoo.org",
        "published": "2020-01-22T16:04:24Z",
        "link": "http://arxiv.org/abs/2002.04504v1",
        "categories": [
            "cs.NE",
            "cs.LG",
            "cs.MS",
            "G.1.6; I.2.0; D.2.0"
        ]
    },
    {
        "title": "juSFEM: A Julia-based Open-source Package of Parallel Smoothed Finite   Element Method (S-FEM) for Elastic Problems",
        "authors": [
            "Zenan Huo",
            "Gang Mei",
            "Nengxiong Xu"
        ],
        "summary": "The Smoothed Finite Element Method (S-FEM) proposed by Liu G.R. can achieve more accurate results than the conventional FEM. Currently, much commercial software and many open-source packages have been developed to analyze various science and engineering problems using the FEM. However, there is little work focusing on designing and developing software or packages for the S-FEM. In this paper, we design and implement an open-source package of the parallel S-FEM for elastic problems by utilizing the Julia language on multi-core CPU. The Julia language is a fast, easy-to-use, and open-source programming language that was originally designed for high-performance computing. We term our package as juSFEM. To the best of the authors knowledge, juSFEM is the first package of parallel S-FEM developed with the Julia language. To verify the correctness and evaluate the efficiency of juSFEM, two groups of benchmark tests are conducted. The benchmark results show that (1) juSFEM can achieve accurate results when compared to commercial FEM software ABAQUS, and (2) juSFEM only requires 543 seconds to calculate the displacements of a 3D elastic cantilever beam model which is composed of approximately 2 million tetrahedral elements, while in contrast the commercial FEM software needs 930 seconds for the same calculation model; (3) the parallel juSFEM executed on the 24-core CPU is approximately 20x faster than the corresponding serial version. Moreover, the structure and function of juSFEM are easily modularized, and the code in juSFEM is clear and readable, which is convenient for further development.",
        "published": "2020-01-23T23:37:15Z",
        "link": "http://arxiv.org/abs/2001.08849v1",
        "categories": [
            "cs.MS",
            "cs.CE"
        ]
    },
    {
        "title": "Fast Cubic Spline Interpolation",
        "authors": [
            "Haysn Hornbeck"
        ],
        "summary": "The Numerical Recipes series of books are a useful resource, but all the algorithms they contain cannot be used within open-source projects. In this paper we develop drop-in alternatives to the two algorithms they present for cubic spline interpolation, showing as much of our work as possible to allow for replication or criticsm. The output of the new algorithms is compared to the old, and found to be no different within the limits imposed by floating-point precision. Benchmarks of all these algorithms, plus variations which may run faster in certain instances, are performed. In general, all these algorithms have approximately the same execution time when interpolating curves with few control points on feature-rich Intel processors; as the number of control points increases or processor features are removed, the new algorithms become consistently faster than the old. Exceptions to that generalization are explored to create implementation guidelines, such as when to expect division to be faster than multiplication.",
        "published": "2020-01-25T02:06:31Z",
        "link": "http://arxiv.org/abs/2001.09253v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "SLEEF: A Portable Vectorized Library of C Standard Mathematical   Functions",
        "authors": [
            "Naoki Shibata",
            "Francesco Petrogalli"
        ],
        "summary": "In this paper, we present techniques used to implement our portable vectorized library of C standard mathematical functions written entirely in C language. In order to make the library portable while maintaining good performance, intrinsic functions of vector extensions are abstracted by inline functions or preprocessor macros. We implemented the functions so that they can use sub-features of vector extensions such as fused multiply-add, mask registers and extraction of mantissa. In order to make computation with SIMD instructions efficient, the library only uses a small number of conditional branches, and all the computation paths are vectorized. We devised a variation of the Payne-Hanek argument reduction for trigonometric functions and a floating point remainder, both of which are suitable for vector computation. We compare the performance of our library to Intel SVML.",
        "published": "2020-01-25T03:05:52Z",
        "link": "http://arxiv.org/abs/2001.09258v1",
        "categories": [
            "cs.MS",
            "cs.DC",
            "cs.PL"
        ]
    },
    {
        "title": "A toolbox of Equation-Free functions in Matlab\\Octave for efficient   system level simulation",
        "authors": [
            "John Maclean",
            "J. E. Bunder",
            "A. J. Roberts"
        ],
        "summary": "The `equation-free toolbox' empowers the computer-assisted analysis of complex, multiscale systems. Its aim is to enable you to immediately use microscopic simulators to perform macro-scale system level tasks and analysis, because micro-scale simulations are often the best available description of a system. The methodology bypasses the derivation of macroscopic evolution equations by computing the micro-scale simulator only over short bursts in time on small patches in space, with bursts and patches well-separated in time and space respectively. We introduce the suite of coded equation-free functions in an accessible way, link to more detailed descriptions, discuss their mathematical support, and introduce a novel and efficient algorithm for Projective Integration. Some facets of toolbox development of equation-free functions are then detailed. Download the toolbox functions (https://github.com/uoa1184615/EquationFreeGit) and use to empower efficient and accurate simulation in a wide range of your science and engineering problems.",
        "published": "2020-01-31T11:20:04Z",
        "link": "http://arxiv.org/abs/2002.01895v2",
        "categories": [
            "cs.MS",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "lbmpy: Automatic code generation for efficient parallel lattice   Boltzmann methods",
        "authors": [
            "Martin Bauer",
            "Harald Köstler",
            "Ulrich Rüde"
        ],
        "summary": "Lattice Boltzmann methods are a popular mesoscopic alternative to macroscopic computational fluid dynamics solvers. Many variants have been developed that vary in complexity, accuracy, and computational cost. Extensions are available to simulate multi-phase, multi-component, turbulent, or non-Newtonian flows. In this work we present lbmpy, a code generation package that supports a wide variety of different methods and provides a generic development environment for new schemes as well. A high-level domain-specific language allows the user to formulate, extend and test various lattice Boltzmann schemes. The method specification is represented in a symbolic intermediate representation. Transformations that operate on this intermediate representation optimize and parallelize the method, yielding highly efficient lattice Boltzmann compute kernels not only for single- and two-relaxation-time schemes but also for multi-relaxation-time, cumulant, and entropically stabilized methods. An integration into the HPC framework waLBerla makes massively parallel, distributed simulations possible, which is demonstrated through scaling experiments on the SuperMUC-NG supercomputing system",
        "published": "2020-01-31T13:00:26Z",
        "link": "http://arxiv.org/abs/2001.11806v2",
        "categories": [
            "cs.MS",
            "cs.CE",
            "cs.DC"
        ]
    },
    {
        "title": "Large-Scale Discrete Fourier Transform on TPUs",
        "authors": [
            "Tianjian Lu",
            "Yi-Fan Chen",
            "Blake Hechtman",
            "Tao Wang",
            "John Anderson"
        ],
        "summary": "In this work, we present two parallel algorithms for the large-scale discrete Fourier transform (DFT) on Tensor Processing Unit (TPU) clusters. The two parallel algorithms are associated with two formulations of DFT: one is based on the Kronecker product, to be specific, dense matrix multiplications between the input data and the Vandermonde matrix, denoted as KDFT in this work; the other is based on the famous Cooley-Tukey algorithm and phase adjustment, denoted as FFT in this work. Both KDFT and FFT formulations take full advantage of TPU's strength in matrix multiplications. The KDFT formulation allows direct use of nonuniform inputs without additional step. In the two parallel algorithms, the same strategy of data decomposition is applied to the input data. Through the data decomposition, the dense matrix multiplications in KDFT and FFT are kept local within TPU cores, which can be performed completely in parallel. The communication among TPU cores is achieved through the one-shuffle scheme in both parallel algorithms, with which sending and receiving data takes place simultaneously between two neighboring cores and along the same direction on the interconnect network. The one-shuffle scheme is designed for the interconnect topology of TPU clusters, minimizing the time required by the communication among TPU cores. Both KDFT and FFT are implemented in TensorFlow. The three-dimensional complex DFT is performed on an example of dimension $8192 \\times 8192 \\times 8192$ with a full TPU Pod: the run time of KDFT is 12.66 seconds and that of FFT is 8.3 seconds. Scaling analysis is provided to demonstrate the high parallel efficiency of the two DFT implementations on TPUs.",
        "published": "2020-02-09T01:15:13Z",
        "link": "http://arxiv.org/abs/2002.03260v3",
        "categories": [
            "cs.MS",
            "cs.DC"
        ]
    },
    {
        "title": "Butterfly factorization via randomized matrix-vector multiplications",
        "authors": [
            "Yang Liu",
            "Xin Xing",
            "Han Guo",
            "Eric Michielssen",
            "Pieter Ghysels",
            "Xiaoye Sherry Li"
        ],
        "summary": "This paper presents an adaptive randomized algorithm for computing the butterfly factorization of a $m\\times n$ matrix with $m\\approx n$ provided that both the matrix and its transpose can be rapidly applied to arbitrary vectors. The resulting factorization is composed of $O(\\log n)$ sparse factors, each containing $O(n)$ nonzero entries. The factorization can be attained using $O(n^{3/2}\\log n)$ computation and $O(n\\log n)$ memory resources. The proposed algorithm applies to matrices with strong and weak admissibility conditions arising from surface integral equation solvers with a rigorous error bound, and is implemented in parallel.",
        "published": "2020-02-09T17:19:44Z",
        "link": "http://arxiv.org/abs/2002.03400v1",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "FEAST Eigenvalue Solver v4.0 User Guide",
        "authors": [
            "Eric Polizzi"
        ],
        "summary": "The FEAST library package represents an unified framework for solving various family of eigenvalue problems and achieving accuracy, robustness, high-performance and scalability on parallel architectures. Its originality lies with a new transformative numerical approach to the traditional eigenvalue algorithm design - the FEAST algorithm. The algorithm gathers key elements from complex analysis, numerical linear algebra and approximation theory, to construct an optimal subspace iteration technique using approximate spectral projectors. FEAST can be used for solving both standard and generalized forms of the Hermitian or non-Hermitian problems (linear or non-linear), and it belongs to the family of contour integration eigensolvers. FEAST's main computational task consists of a numerical quadrature computation that involves solving independent linear systems along a complex contour, each with multiple right hand sides. In v4.0, FEAST has been reimplemented using an inverse residual iteration algorithm which enables the linear systems to be solved with very low accuracy (in single precision) with no impact on the FEAST double precision convergence rate. As a result, v4.0 is on average 3-4 times faster than v2.1 and v3.0 using new default optimization parameters (v2.1 has been featured as Intel-MKL's principal HPC eigensolver since 2013). v4.0 also implements new important features such as IFEAST (using Inexact Iterative solver), Non-linear polynomial FEAST, and PFEAST with its 3-MPI levels of parallelism. FEAST is both a comprehensive library package, and an easy to use software. It includes flexible reverse communication interfaces and ready to use driver interfaces for dense, banded and sparse systems.",
        "published": "2020-02-12T05:26:04Z",
        "link": "http://arxiv.org/abs/2002.04807v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "The Space of Mathematical Software Systems -- A Survey of Paradigmatic   Systems",
        "authors": [
            "Katja Bercic",
            "Jacques Carette",
            "William M. Farmer",
            "Michael Kohlhase",
            "Dennis Müller",
            "Florian Rabe",
            "Yasmine Sharoda"
        ],
        "summary": "Mathematical software systems are becoming more and more important in pure and applied mathematics in order to deal with the complexity and scalability issues inherent in mathematics. In the last decades we have seen a cambric explosion of increasingly powerful but also diverging systems. To give researchers a guide to this space of systems, we devise a novel conceptualization of mathematical software that focuses on five aspects: inference covers formal logic and reasoning about mathematical statements via proofs and models, typically with strong emphasis on correctness; computation covers algorithms and software libraries for representing and manipulating mathematical objects, typically with strong emphasis on efficiency; concretization covers generating and maintaining collections of mathematical objects conforming to a certain pattern, typically with strong emphasis on complete enumeration; narration covers describing mathematical contexts and relations, typically with strong emphasis on human readability; finally, organization covers representing mathematical contexts and objects in machine-actionable formal languages, typically with strong emphasis on expressivity and system interoperability. Despite broad agreement that an ideal system would seamlessly integrate all these aspects, research has diversified into families of highly specialized systems focusing on a single aspect and possibly partially integrating others, each with their own communities, challenges, and successes. In this survey, we focus on the commonalities and differences of these systems from the perspective of a future multi-aspect system.",
        "published": "2020-02-12T12:46:17Z",
        "link": "http://arxiv.org/abs/2002.04955v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "Task-based, GPU-accelerated and Robust Library for Solving Dense   Nonsymmetric Eigenvalue Problems",
        "authors": [
            "Mirko Myllykoski",
            "Carl Christian Kjelgaard Mikkelsen"
        ],
        "summary": "In this paper, we present the StarNEig library for solving dense nonsymmetric standard and generalized eigenvalue problems. The library is built on top of the StarPU runtime system and targets both shared and distributed memory machines. Some components of the library have support for GPU acceleration. The library is currently in an early beta state and supports only real matrices. Support for complex matrices is planned for a future release. This paper is aimed at potential users of the library. We describe the design choices and capabilities of the library, and contrast them to existing software such as ScaLAPACK. StarNEig implements a ScaLAPACK compatibility layer which should assist new users in the transition to StarNEig. We demonstrate the performance of the library with a sample of computational experiments.",
        "published": "2020-02-12T14:28:55Z",
        "link": "http://arxiv.org/abs/2002.05024v1",
        "categories": [
            "cs.MS",
            "cs.DC"
        ]
    },
    {
        "title": "Computing rank-revealing factorizations of matrices stored out-of-core",
        "authors": [
            "Nathan Heavner",
            "Per-Gunnar Martinsson",
            "Gregorio Quintana-Ortí"
        ],
        "summary": "This paper describes efficient algorithms for computing rank-revealing factorizations of matrices that are too large to fit in RAM, and must instead be stored on slow external memory devices such as solid-state or spinning disk hard drives (out-of-core or out-of-memory). Traditional algorithms for computing rank revealing factorizations, such as the column pivoted QR factorization, or techniques for computing a full singular value decomposition of a matrix, are very communication intensive. They are naturally expressed as a sequence of matrix-vector operations, which become prohibitively expensive when data is not available in main memory. Randomization allows these methods to be reformulated so that large contiguous blocks of the matrix can be processed in bulk. The paper describes two distinct methods. The first is a blocked version of column pivoted Householder QR, organized as a \"left-looking\" method to minimize the number of write operations (which are more expensive than read operations on a spinning disk drive). The second method results in a so called UTV factorization which expresses a matrix $A$ as $A = U T V^*$ where $U$ and $V$ are unitary, and $T$ is triangular. This method is organized as an algorithm-by-blocks, in which floating point operations overlap read and write operations. The second method incorporates power iterations, and is exceptionally good at revealing the numerical rank; it can often be used as a substitute for a full singular value decomposition. Numerical experiments demonstrate that the new algorithms are almost as fast when processing data stored on a hard drive as traditional algorithms are for data stored in main memory. To be precise, the computational time for fully factorizing an $n\\times n$ matrix scales as $cn^{3}$, with a scaling constant $c$ that is only marginally larger when the matrix is stored out of core.",
        "published": "2020-02-17T13:58:08Z",
        "link": "http://arxiv.org/abs/2002.06960v2",
        "categories": [
            "cs.MS",
            "cs.CL",
            "cs.DC",
            "cs.DS",
            "cs.NA",
            "math.NA",
            "G.1.3; G.4; C.4; D.1.3; F.2.1"
        ]
    },
    {
        "title": "hyper.deal: An efficient, matrix-free finite-element library for   high-dimensional partial differential equations",
        "authors": [
            "Peter Munch",
            "Katharina Kormann",
            "Martin Kronbichler"
        ],
        "summary": "This work presents the efficient, matrix-free finite-element library hyper.deal for solving partial differential equations in two to six dimensions with high-order discontinuous Galerkin methods. It builds upon the low-dimensional finite-element library deal.II to create complex low-dimensional meshes and to operate on them individually. These meshes are combined via a tensor product on the fly and the library provides new special-purpose highly optimized matrix-free functions exploiting domain decomposition as well as shared memory via MPI-3.0 features. Both node-level performance analyses and strong/weak-scaling studies on up to 147,456 CPU cores confirm the efficiency of the implementation. Results of the library hyper.deal are reported for high-dimensional advection problems and for the solution of the Vlasov--Poisson equation in up to 6D phase space.",
        "published": "2020-02-19T11:25:35Z",
        "link": "http://arxiv.org/abs/2002.08110v1",
        "categories": [
            "cs.MS",
            "cs.NA",
            "math.NA",
            "G.4"
        ]
    },
    {
        "title": "NeuralSens: Sensitivity Analysis of Neural Networks",
        "authors": [
            "J. Pizarroso",
            "J. Portela",
            "A. Muñoz"
        ],
        "summary": "Neural networks are important tools for data-intensive analysis and are commonly applied to model non-linear relationships between dependent and independent variables. However, neural networks are usually seen as \"black boxes\" that offer minimal information about how the input variables are used to predict the response in a fitted model. This article describes the \\pkg{NeuralSens} package that can be used to perform sensitivity analysis of neural networks using the partial derivatives method. Functions in the package can be used to obtain the sensitivities of the output with respect to the input variables, evaluate variable importance based on sensitivity measures and characterize relationships between input and output variables. Methods to calculate sensitivities are provided for objects from common neural network packages in \\proglang{R}, including \\pkg{neuralnet}, \\pkg{nnet}, \\pkg{RSNNS}, \\pkg{h2o}, \\pkg{neural}, \\pkg{forecast} and \\pkg{caret}. The article presents an overview of the techniques for obtaining information from neural network models, a theoretical foundation of how are calculated the partial derivatives of the output with respect to the inputs of a multi-layer perceptron model, a description of the package structure and functions, and applied examples to compare \\pkg{NeuralSens} functions with analogous functions from other available \\proglang{R} packages.",
        "published": "2020-02-26T12:05:59Z",
        "link": "http://arxiv.org/abs/2002.11423v2",
        "categories": [
            "cs.LG",
            "cs.MS",
            "stat.ML"
        ]
    },
    {
        "title": "SplineLib: A Modern Multi-Purpose C++ Spline Library",
        "authors": [
            "Markus Frings",
            "Norbert Hosters",
            "Corinna Müller",
            "Max Spahn",
            "Christoph Susen",
            "Konstantin Key",
            "Stefanie Elgeti"
        ],
        "summary": "This paper provides the description of a novel, multi-purpose spline library. In accordance with the increasingly diverse modes of usage of splines, it is multi-purpose in the sense that it supports geometry representation, finite element analysis, and optimization. The library features reading and writing for various file formats and a wide range of spline manipulation algorithms. Further, a new efficient and objective-oriented algorithm for B-spline basis function evaluation is included. All features are available by a spline-type independent interface. The library is written in modern C++ with CMake as build system. This enables it for usage in typical scientific applications. It is provided as open-source library.",
        "published": "2020-02-27T18:43:07Z",
        "link": "http://arxiv.org/abs/2002.12323v1",
        "categories": [
            "cs.MS",
            "G.1.1; D.1.5; D.3.3; J.6"
        ]
    },
    {
        "title": "MORLAB -- The Model Order Reduction LABoratory",
        "authors": [
            "Peter Benner",
            "Steffen W. R. Werner"
        ],
        "summary": "For an easy use of model order reduction techniques in applications, software solutions are needed. In this paper, we describe the MORLAB, Model Order Reduction LABoratory, toolbox as an efficient implementation of model reduction techniques for dense, medium-scale linear time-invariant systems. Giving an introduction to the underlying programming principles of the toolbox, we show the basic idea of spectral splitting and present an overview about implemented model reduction techniques. Two numerical examples are used to illustrate different use cases of the MORLAB toolbox.",
        "published": "2020-02-28T12:42:26Z",
        "link": "http://arxiv.org/abs/2002.12682v1",
        "categories": [
            "cs.MS",
            "cs.NA",
            "cs.SY",
            "eess.SY",
            "math.NA",
            "math.OC"
        ]
    },
    {
        "title": "NLOptControl: A modeling language for solving optimal control problems",
        "authors": [
            "Huckleberry Febbo",
            "Paramsothy Jayakumar",
            "Jeffrey L. Stein",
            "Tulga Ersal"
        ],
        "summary": "Current direct-collocation-based optimal control software is either easy to use or fast, but not both. This is a major limitation for users that are trying to formulate complex optimal control problems (OCPs) for use in on-line applications. This paper introduces NLOptControl, an open-source modeling language that allows users to both easily formulate and quickly solve nonlinear OCPs using direct-collocation methods. To achieve these attributes, NLOptControl (1) is written in an efficient, dynamically-typed computing language called Julia, (2) extends an optimization modeling language called JuMP to provide a natural algebraic syntax for modeling nonlinear OCPs; and (3) uses reverse automatic differentiation with the acrylic-coloring method to exploit sparsity in the Hessian matrix. This work explores the novel design features of NLOptControl and compares its syntax and speed to those of PROPT. The syntax comparisons shows that NLOptControl models OCPs more concisely than PROPT. The speeds of various collocation methods within PROPT and NLOptControl are benchmarked over a range of collocation points using performance profiles; overall, NLOptControl's single, two, and four interval pseudospectral methods are roughly $14$, $26$, and $36$ times faster than PROPT's, respectively. NLOptControl is well-suited to improve existing off-line and on-line control systems and to engender new ones.",
        "published": "2020-02-29T00:55:28Z",
        "link": "http://arxiv.org/abs/2003.00142v2",
        "categories": [
            "cs.MS",
            "math.OC"
        ]
    },
    {
        "title": "Matrix Equations, Sparse Solvers: M-M.E.S.S.-2.0.1 -- Philosophy,   Features and Application for (Parametric) Model",
        "authors": [
            "Peter Benner",
            "Martin Köhler",
            "Jens Saak"
        ],
        "summary": "Matrix equations are omnipresent in (numerical) linear algebra and systems theory. Especially in model order reduction (MOR) they play a key role in many balancing based reduction methods for linear dynamical systems. When these systems arise from spatial discretizations of evolutionary partial differential equations, their coefficient matrices are typically large and sparse. Moreover, the numbers of inputs and outputs of these systems are typically far smaller than the number of spatial degrees of freedom. Then, in many situations the solutions of the corresponding large-scale matrix equations are observed to have low (numerical) rank. This feature is exploited by M-M.E.S.S. to find successively larger low-rank factorizations approximating the solutions. This contribution describes the basic philosophy behind the implementation and the features of the package, as well as its application in the model order reduction of large-scale linear time-invariant (LTI) systems and parametric LTI systems.",
        "published": "2020-03-04T14:02:21Z",
        "link": "http://arxiv.org/abs/2003.02088v2",
        "categories": [
            "cs.MS",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "COMPLEX-IT: A Case-Based Modeling and Scenario Simulation Platform for   Social Inquiry",
        "authors": [
            "Corey Schimpf",
            "Brian Castellani"
        ],
        "summary": "COMPLEX-IT is a case-based, mixed-methods platform for social inquiry into complex data/systems, designed to increase non-expert access to the tools of computational social science (i.e., cluster analysis, artificial intelligence, data visualization, data forecasting, and scenario simulation). In particular, COMPLEX-IT aids social inquiry though a heavy emphasis on learning about the complex data/system under study, which it does by (a) identifying and forecasting major and minor clusters/trends; (b) visualizing their complex causality; and (c) simulating scenarios for potential interventions. COMPLEX-IT is accessible through the web or can be run locally and is powered by R and the Shiny web framework.",
        "published": "2020-03-06T09:27:10Z",
        "link": "http://arxiv.org/abs/2003.03099v1",
        "categories": [
            "cs.MS",
            "cs.CY"
        ]
    },
    {
        "title": "Airline Crew Pairing Optimization Framework for Large Networks with   Multiple Crew Bases and Hub-and-Spoke Subnetworks",
        "authors": [
            "Divyam Aggarwal",
            "Dhish Kumar Saxena",
            "Thomas Bäck",
            "Michael Emmerich"
        ],
        "summary": "Crew Pairing Optimization aims at generating a set of flight sequences (crew pairings), covering all flights in an airline's flight schedule, at minimum cost, while satisfying several legality constraints. CPO is critically important for airlines' business viability, considering that the crew operating cost is their second-largest expense. It poses an NP-hard combinatorial optimization problem, to tackle which, the state-of-the-art relies on relaxing the underlying Integer Programming Problem (IPP) into a Linear Programming Problem (LPP), solving the latter through Column Generation (CG) technique, and integerization of the resulting LPP solution. However, with the growing scale and complexity of the flight networks (those with a large number of flights, multiple crew bases and/or multiple hub-and-spoke subnetworks), the utility of the conventional CG-practices has become questionable. This paper proposed an Airline Crew Pairing Optimization Framework, AirCROP, whose constitutive modules include the Legal Crew Pairing Generator, Initial Feasible Solution Generator, and an Optimization Engine built on heuristic-based CG-implementation. In this paper, besides the design of AirCROP's modules, insights into important questions related to how these modules interact, which the literature is otherwise silent on, have been shared. These relate to the sensitivity of AirCROP's performance towards: sources of variability over multiple runs for a given problem, initialization method, and termination parameters for LPP-solutioning and IPP-solutioning. The efficacy of the AirCROP has been demonstrated on real-world large-scale and complex flight networks (with over 4200 flights, 15 crew bases, and billion-plus pairings). It is hoped that with the emergence of such complex flight networks, this paper shall serve as an important milestone for affiliated research and applications.",
        "published": "2020-03-09T09:34:20Z",
        "link": "http://arxiv.org/abs/2003.03994v2",
        "categories": [
            "cs.MS",
            "math.OC"
        ]
    },
    {
        "title": "Flexible numerical optimization with ensmallen",
        "authors": [
            "Ryan R. Curtin",
            "Marcus Edel",
            "Rahul Ganesh Prabhu",
            "Suryoday Basak",
            "Zhihao Lou",
            "Conrad Sanderson"
        ],
        "summary": "This report provides an introduction to the ensmallen numerical optimization library, as well as a deep dive into the technical details of how it works. The library provides a fast and flexible C++ framework for mathematical optimization of arbitrary user-supplied functions. A large set of pre-built optimizers is provided, including many variants of Stochastic Gradient Descent and Quasi-Newton optimizers. Several types of objective functions are supported, including differentiable, separable, constrained, and categorical objective functions. Implementation of a new optimizer requires only one method, while a new objective function requires typically only one or two C++ methods. Through internal use of C++ template metaprogramming, ensmallen provides support for arbitrary user-supplied callbacks and automatic inference of unsupplied methods without any runtime overhead. Empirical comparisons show that ensmallen outperforms other optimization frameworks (such as Julia and SciPy), sometimes by large margins. The library is available at https://ensmallen.org and is distributed under the permissive BSD license.",
        "published": "2020-03-09T12:57:42Z",
        "link": "http://arxiv.org/abs/2003.04103v4",
        "categories": [
            "cs.MS",
            "cs.LG",
            "cs.SE",
            "math.OC"
        ]
    },
    {
        "title": "Parallel Robust Computation of Generalized Eigenvectors of Matrix   Pencils",
        "authors": [
            "Carl Christian Kjelgaard Mikkelsen",
            "Mirko Myllykoski"
        ],
        "summary": "In this paper we consider the problem of computing generalized eigenvectors of a matrix pencil in real Schur form. In exact arithmetic, this problem can be solved using substitution. In practice, substitution is vulnerable to floating-point overflow. The robust solvers xTGEVC in LAPACK prevent overflow by dynamically scaling the eigenvectors. These subroutines are sequential scalar codes which compute the eigenvectors one by one. In this paper we discuss how to derive robust blocked algorithms. The new StarNEig library contains a robust task-parallel solver Zazamoukh which runs on top of StarPU. Our numerical experiments show that Zazamoukh achieves a super-linear speedup compared with DTGEVC for sufficiently large matrices.",
        "published": "2020-03-10T14:37:39Z",
        "link": "http://arxiv.org/abs/2003.04776v1",
        "categories": [
            "cs.MS",
            "cs.DC",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Evaluating Abstract Asynchronous Schwarz solvers on GPUs",
        "authors": [
            "Pratik Nayak",
            "Terry Cojean",
            "Hartwig Anzt"
        ],
        "summary": "With the commencement of the exascale computing era, we realize that the majority of the leadership supercomputers are heterogeneous and massively parallel even on a single node with multiple co-processors such as GPUs and multiple cores on each node. For example, ORNLs Summit accumulates six NVIDIA Tesla V100s and 42 core IBM Power9s on each node. Synchronizing across all these compute resources in a single node or even across multiple nodes is prohibitively expensive. Hence it is necessary to develop and study asynchronous algorithms that circumvent this issue of bulk-synchronous computing for massive parallelism. In this study, we examine the asynchronous version of the abstract Restricted Additive Schwarz method as a solver where we do not explicitly synchronize, but allow for communication of the data between the sub-domains to be completely asynchronous thereby removing the bulk synchronous nature of the algorithm.   We accomplish this by using the onesided RMA functions of the MPI standard. We study the benefits of using such an asynchronous solver over its synchronous counterpart on both multi-core architectures and on multiple GPUs. We also study the communication patterns and local solvers and their effect on the global solver. Finally, we show that this concept can render attractive runtime benefits over the synchronous counterparts.",
        "published": "2020-03-11T15:28:53Z",
        "link": "http://arxiv.org/abs/2003.05361v2",
        "categories": [
            "cs.DC",
            "cs.MS"
        ]
    },
    {
        "title": "Optimization of Generalized Jacobian Chain Products without Memory   Constraints",
        "authors": [
            "Uwe Naumann"
        ],
        "summary": "The efficient computation of Jacobians represents a fundamental challenge in computational science and engineering. Large-scale modular numerical simulation programs can be regarded as sequences of evaluations of in our case differentiable modules with corresponding local Jacobians. The latter are typically not available. Tangent and adjoint versions of the individual modules are assumed to be given as results of algorithmic differentiation instead. The classical (Jacobian) matrix chain product formulation is extended with the optional evaluation of matrix-free Jacobian-matrix and matrix-Jacobian products as tangents and adjoints. We propose a dynamic programming algorithm for the minimization of the computational cost of such generalized Jacobian chain products without considering constraints on the available persistent system memory. In other words, the naive evaluation of an adjoint of the entire simulation program is assumed to be a feasible option. No checkpointing is required. Under the given assumptions we obtain optimal solutions which improve the best state of the art methods by factors of up to seven on a set of randomly generated problem instances of growing size.",
        "published": "2020-03-12T12:49:19Z",
        "link": "http://arxiv.org/abs/2003.05755v3",
        "categories": [
            "math.NA",
            "cs.DM",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "Parametric model order reduction using pyMOR",
        "authors": [
            "Petar Mlinarić",
            "Stephan Rave",
            "Jens Saak"
        ],
        "summary": "pyMOR is a free software library for model order reduction that includes both reduced basis and system-theoretic methods. All methods are implemented in terms of abstract vector and operator interfaces, which allows direct integration of pyMOR's algorithms with a wide array of external PDE solvers. In this contribution, we give a brief overview of the available methods and experimentally compare them for the parametric instationary thermal-block benchmark defined in arXiv:2003.00846.",
        "published": "2020-03-12T14:50:53Z",
        "link": "http://arxiv.org/abs/2003.05825v2",
        "categories": [
            "cs.MS",
            "cs.NA",
            "cs.SY",
            "eess.SY",
            "math.NA",
            "math.OC"
        ]
    },
    {
        "title": "FunGrim: a symbolic library for special functions",
        "authors": [
            "Fredrik Johansson"
        ],
        "summary": "We present the Mathematical Functions Grimoire (FunGrim), a website and database of formulas and theorems for special functions. We also discuss the symbolic computation library used as the backend and main development tool for FunGrim, and the Grim formula language used in these projects to represent mathematical content semantically.",
        "published": "2020-03-13T10:07:21Z",
        "link": "http://arxiv.org/abs/2003.06181v1",
        "categories": [
            "cs.MS",
            "cs.SC"
        ]
    },
    {
        "title": "An R Package for generating covariance matrices for maximum-entropy   sampling from precipitation chemistry data",
        "authors": [
            "Hessa Al-Thani",
            "Jon Lee"
        ],
        "summary": "We present an open-source R package (MESgenCov v 0.1.0) for temporally fitting multivariate precipitation chemistry data and extracting a covariance matrix for use in the MESP (maximum-entropy sampling problem). We provide multiple functionalities for modeling and model assessment. The package is tightly coupled with NADP/NTN (National Atmospheric Deposition Program / National Trends Network) data from their set of 379 monitoring sites, 1978--present. The user specifies the sites, chemicals, and time period desired, fits an appropriate user-specified univariate model for each site and chemical selected, and the package produces a covariance matrix for use by MESP algorithms.",
        "published": "2020-03-13T14:23:22Z",
        "link": "http://arxiv.org/abs/2003.06316v2",
        "categories": [
            "cs.MS",
            "90C27, 62M30, 62M10, 94A17"
        ]
    },
    {
        "title": "A Kogbetliantz-type algorithm for the hyperbolic SVD",
        "authors": [
            "Vedran Novaković",
            "Sanja Singer"
        ],
        "summary": "In this paper a two-sided, parallel Kogbetliantz-type algorithm for the hyperbolic singular value decomposition (HSVD) of real and complex square matrices is developed, with a single assumption that the input matrix, of order $n$, admits such a decomposition into the product of a unitary, a non-negative diagonal, and a $J$-unitary matrix, where $J$ is a given diagonal matrix of positive and negative signs. When $J=\\pm I$, the proposed algorithm computes the ordinary SVD. The paper's most important contribution -- a derivation of formulas for the HSVD of $2\\times 2$ matrices -- is presented first, followed by the details of their implementation in floating-point arithmetic. Next, the effects of the hyperbolic transformations on the columns of the iteration matrix are discussed. These effects then guide a redesign of the dynamic pivot ordering, being already a well-established pivot strategy for the ordinary Kogbetliantz algorithm, for the general, $n\\times n$ HSVD. A heuristic but sound convergence criterion is then proposed, which contributes to high accuracy demonstrated in the numerical testing results. Such a $J$-Kogbetliantz algorithm as presented here is intrinsically slow, but is nevertheless usable for matrices of small orders.",
        "published": "2020-03-14T20:54:39Z",
        "link": "http://arxiv.org/abs/2003.06701v4",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "65F15 (Primary) 65Y05, 15A18 (Secondary)"
        ]
    },
    {
        "title": "Pressio: Enabling projection-based model reduction for large-scale   nonlinear dynamical systems",
        "authors": [
            "Francesco Rizzi",
            "Patrick J. Blonigan",
            "Eric J. Parish",
            "Kevin T. Carlberg"
        ],
        "summary": "This work introduces Pressio, an open-source project aimed at enabling leading-edge projection-based reduced order models (ROMs) for large-scale nonlinear dynamical systems in science and engineering. Pressio provides model-reduction methods that can reduce both the number of spatial and temporal degrees of freedom for any dynamical system expressible as a system of parameterized ordinary differential equations (ODEs). We leverage this simple, expressive mathematical framework as a pivotal design choice to enable a minimal application programming interface (API) that is natural to dynamical systems. The core component of Pressio is a C++11 header-only library that leverages generic programming to support applications with arbitrary data types and arbitrarily complex programming models. This is complemented with Python bindings to expose these C++ functionalities to Python users with negligible overhead and no user-required binding code. We discuss the distinguishing characteristics of Pressio relative to existing model-reduction libraries, outline its key design features, describe how the user interacts with it, and present two test cases -- including one with over 20 million degrees of freedom -- that highlight the performance results of Pressio and illustrate the breath of problems that can be addressed with it.",
        "published": "2020-03-17T16:25:10Z",
        "link": "http://arxiv.org/abs/2003.07798v3",
        "categories": [
            "cs.MS",
            "cs.CE",
            "physics.comp-ph",
            "physics.flu-dyn"
        ]
    },
    {
        "title": "Scalable parallel algorithm for solving non-stationary systems of linear   inequalities",
        "authors": [
            "Leonid B. Sokolinsky",
            "Irina M. Sokolinskaya"
        ],
        "summary": "In this paper, a scalable iterative projection-type algorithm for solving non-stationary systems of linear inequalities is considered. A non-stationary system is understood as a large-scale system of inequalities in which coefficients and constant terms can change during the calculation process. The proposed parallel algorithm uses the concept of pseudo-projection which generalizes the notion of orthogonal projection. The parallel pseudo-projection algorithm is implemented using the parallel BSF-skeleton. An analytical estimation of the algorithm scalability boundary is obtained on the base of the BSF cost metric. The large-scale computational experiments were performed on a cluster computing system. The obtained results confirm the efficiency of the proposed approach.",
        "published": "2020-03-22T17:44:23Z",
        "link": "http://arxiv.org/abs/2003.09956v2",
        "categories": [
            "cs.MS",
            "cs.NA",
            "math.NA",
            "math.OC",
            "90-08",
            "G.4"
        ]
    },
    {
        "title": "Geometric Sparsification of Closeness Relations: Eigenvalue Clustering   for Computing Matrix Functions",
        "authors": [
            "Nir Goren",
            "Dan Halperin",
            "Sivan Toledo"
        ],
        "summary": "We show how to efficiently solve a clustering problem that arises in a method to evaluate functions of matrices. The problem requires finding the connected components of a graph whose vertices are eigenvalues of a real or complex matrix and whose edges are pairs of eigenvalues that are at most \\delta away from each other. Davies and Higham proposed solving this problem by enumerating the edges of the graph, which requires at least $\\Omega(n^{2})$ work. We show that the problem can be solved by computing the Delaunay triangulation of the eigenvalues, removing from it long edges, and computing the connected components of the remaining edges in the triangulation. This leads to an $O(n\\log n)$ algorithm. We have implemented both algorithms using CGAL, a mature and sophisticated computational-geometry software library, and we demonstrate that the new algorithm is much faster in practice than the naive algorithm. We also present a tight analysis of the naive algorithm, showing that it performs $\\Theta(n^{2})$ work, and correct a misrepresentation in the original statement of the problem. To the best of our knowledge, this is the first application of computational geometry to solve a real-world problem in numerical linear algebra.",
        "published": "2020-03-23T08:21:58Z",
        "link": "http://arxiv.org/abs/2003.11914v1",
        "categories": [
            "cs.CG",
            "cs.MS",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "FlexRiLoG -- A SageMath Package for Motions of Graphs",
        "authors": [
            "Georg Grasegger",
            "Jan Legerský"
        ],
        "summary": "In this paper we present the SageMath package FlexRiLoG (short for flexible and rigid labelings of graphs). Based on recent results the software generates motions of graphs using special edge colorings. The package computes and illustrates the colorings and the motions. We present the structure and usage of the package.",
        "published": "2020-03-26T16:50:43Z",
        "link": "http://arxiv.org/abs/2003.12029v1",
        "categories": [
            "cs.MS",
            "cs.RO",
            "math.CO",
            "52C25, 68R10"
        ]
    },
    {
        "title": "Vectorization and Minimization of Memory Footprint for Linear High-Order   Discontinuous Galerkin Schemes",
        "authors": [
            "Jean-Matthieu Gallard",
            "Leonhard Rannabauer",
            "Anne Reinarz",
            "Michael Bader"
        ],
        "summary": "We present a sequence of optimizations to the performance-critical compute kernels of the high-order discontinuous Galerkin solver of the hyperbolic PDE engine ExaHyPE -- successively tackling bottlenecks due to SIMD operations, cache hierarchies and restrictions in the software design.   Starting from a generic scalar implementation of the numerical scheme, our first optimized variant applies state-of-the-art optimization techniques by vectorizing loops, improving the data layout and using Loop-over-GEMM to perform tensor contractions via highly optimized matrix multiplication functions provided by the LIBXSMM library. We show that memory stalls due to a memory footprint exceeding our L2 cache size hindered the vectorization gains. We therefore introduce a new kernel that applies a sum factorization approach to reduce the kernel's memory footprint and improve its cache locality. With the L2 cache bottleneck removed, we were able to exploit additional vectorization opportunities, by introducing a hybrid Array-of-Structure-of-Array data layout that solves the data layout conflict between matrix multiplications kernels and the point-wise functions to implement PDE-specific terms.   With this last kernel, evaluated in a benchmark simulation at high polynomial order, only 2\\% of the floating point operations are still performed using scalar instructions and 22.5\\% of the available performance is achieved.",
        "published": "2020-03-28T13:27:09Z",
        "link": "http://arxiv.org/abs/2003.12787v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "Making RooFit Ready for Run 3",
        "authors": [
            "Stephan Hageboeck",
            "Lorenzo Moneta"
        ],
        "summary": "RooFit and RooStats, the toolkits for statistical modelling in ROOT, are used in most searches and measurements at the Large Hadron Collider. The data to be collected in Run 3 will enable measurements with higher precision and models with larger complexity, but also require faster data processing. In this work, first results on modernising RooFit's collections, restructuring data flow and vectorising likelihood fits in RooFit will be discussed. These improvements will enable the LHC experiments to process larger datasets without having to compromise with respect to model complexity, as fitting times would increase significantly with the large datasets to be expected in Run 3.",
        "published": "2020-03-28T18:22:20Z",
        "link": "http://arxiv.org/abs/2003.12861v1",
        "categories": [
            "cs.MS",
            "hep-ex",
            "physics.data-an"
        ]
    },
    {
        "title": "A Faster, More Intuitive RooFit",
        "authors": [
            "Stephan Hageboeck"
        ],
        "summary": "RooFit and RooStats, the toolkits for statistical modelling in ROOT, are used in most searches and measurements at the Large Hadron Collider as well as at $B$ factories. Larger datasets to be collected at e.g. the High-Luminosity LHC will enable measurements with higher precision, but will require faster data processing to keep fitting times stable. In this work, a simplification of RooFit's interfaces and a redesign of its internal dataflow is presented. Interfaces are being extended to look and feel more STL-like to be more accessible both from C++ and Python to improve interoperability and ease of use, while maintaining compatibility with old code. The redesign of the dataflow improves cache locality and data loading, and can be used to process batches of data with vectorised SIMD computations. This reduces the time for computing unbinned likelihoods by a factor four to 16. This will allow to fit larger datasets of the future in the same time or faster than today's fits.",
        "published": "2020-03-28T19:12:32Z",
        "link": "http://arxiv.org/abs/2003.12875v3",
        "categories": [
            "cs.MS",
            "hep-ex",
            "physics.data-an"
        ]
    },
    {
        "title": "Local congruence of chain complexes",
        "authors": [
            "Gianmaria DelMonte",
            "Elia Onofri",
            "Giorgio Scorzelli",
            "Alberto Paoluzzi"
        ],
        "summary": "The object of this paper is to transform a set of local chain complexes to a single global complex using an equivalence relation of congruence of cells, solving topologically the numerical inaccuracies of floating-point arithmetics. While computing the space arrangement generated by a collection of cellular complexes, one may start from independently and efficiently computing the intersection of each single input 2-cell with the others. The topology of these intersections is codified within a set of (0-2)-dimensional chain complexes. The target of this paper is to merge the local chains by using the equivalence relations of {\\epsilon}-congruence between 0-, 1-, and 2-cells (elementary chains). In particular, we reduce the block-diagonal coboundary matrices [\\Delta_0] and [\\Delta_1], used as matrix accumulators of the local coboundary chains, to the global matrices [\\delta_0] and [\\delta_1], representative of congruence topology, i.e., of congruence quotients between all 0-,1-,2-cells, via elementary algebraic operations on their columns. This algorithm is codified using the Julia porting of the SuiteSparse:GraphBLAS implementation of the GraphBLAS standard, conceived to efficiently compute algorithms on large graphs using linear algebra and sparse matrices [1, 2].",
        "published": "2020-03-31T18:15:32Z",
        "link": "http://arxiv.org/abs/2004.00046v1",
        "categories": [
            "cs.CG",
            "cs.MS"
        ]
    },
    {
        "title": "Interpolation of Dense and Sparse Rational Functions and other   Improvements in $\\texttt{FireFly}$",
        "authors": [
            "Jonas Klappert",
            "Sven Yannick Klein",
            "Fabian Lange"
        ],
        "summary": "We present the main improvements and new features in version $\\texttt{2.0}$ of the open-source $\\texttt{C++}$ library $\\texttt{FireFly}$ for the interpolation of rational functions. This includes algorithmic improvements, e.g. a hybrid algorithm for dense and sparse rational functions and an algorithm to identify and remove univariate factors. The new version is applied to a Feynman-integral reduction to showcase the runtime improvements achieved. Moreover, $\\texttt{FireFly}$ now supports parallelization with $\\texttt{MPI}$ and offers new tools like a parser for expressions or an executable for the insertion of replacement tables.",
        "published": "2020-04-03T10:40:08Z",
        "link": "http://arxiv.org/abs/2004.01463v2",
        "categories": [
            "cs.MS",
            "cs.SC",
            "hep-ph"
        ]
    },
    {
        "title": "Maintaining a Library of Formal Mathematics",
        "authors": [
            "Floris van Doorn",
            "Gabriel Ebner",
            "Robert Y. Lewis"
        ],
        "summary": "The Lean mathematical library mathlib is developed by a community of users with very different backgrounds and levels of experience. To lower the barrier of entry for contributors and to lessen the burden of reviewing contributions, we have developed a number of tools for the library which check proof developments for subtle mistakes in the code and generate documentation suited for our varied audience.",
        "published": "2020-04-07T19:52:20Z",
        "link": "http://arxiv.org/abs/2004.03673v2",
        "categories": [
            "cs.PL",
            "cs.MS",
            "math.HO"
        ]
    },
    {
        "title": "Geomstats: A Python Package for Riemannian Geometry in Machine Learning",
        "authors": [
            "Nina Miolane",
            "Alice Le Brigant",
            "Johan Mathe",
            "Benjamin Hou",
            "Nicolas Guigui",
            "Yann Thanwerdas",
            "Stefan Heyder",
            "Olivier Peltre",
            "Niklas Koep",
            "Hadi Zaatiti",
            "Hatem Hajri",
            "Yann Cabanes",
            "Thomas Gerald",
            "Paul Chauchat",
            "Christian Shewmake",
            "Bernhard Kainz",
            "Claire Donnat",
            "Susan Holmes",
            "Xavier Pennec"
        ],
        "summary": "We introduce Geomstats, an open-source Python toolbox for computations and statistics on nonlinear manifolds, such as hyperbolic spaces, spaces of symmetric positive definite matrices, Lie groups of transformations, and many more. We provide object-oriented and extensively unit-tested implementations. Among others, manifolds come equipped with families of Riemannian metrics, with associated exponential and logarithmic maps, geodesics and parallel transport. Statistics and learning algorithms provide methods for estimation, clustering and dimension reduction on manifolds. All associated operations are vectorized for batch computation and provide support for different execution backends, namely NumPy, PyTorch and TensorFlow, enabling GPU acceleration. This paper presents the package, compares it with related libraries and provides relevant code examples. We show that Geomstats provides reliable building blocks to foster research in differential geometry and statistics, and to democratize the use of Riemannian geometry in machine learning applications. The source code is freely available under the MIT license at \\url{geomstats.ai}.",
        "published": "2020-04-07T20:41:50Z",
        "link": "http://arxiv.org/abs/2004.04667v1",
        "categories": [
            "cs.LG",
            "cs.MS"
        ]
    },
    {
        "title": "Automatic Differentiation in ROOT",
        "authors": [
            "Vassil Vassilev",
            "Aleksandr Efremov",
            "Oksana Shadura"
        ],
        "summary": "In mathematics and computer algebra, automatic differentiation (AD) is a set of techniques to evaluate the derivative of a function specified by a computer program. AD exploits the fact that every computer program, no matter how complicated, executes a sequence of elementary arithmetic operations (addition, subtraction, multiplication, division, etc.), elementary functions (exp, log, sin, cos, etc.) and control flow statements. AD takes source code of a function as input and produces source code of the derived function. By applying the chain rule repeatedly to these operations, derivatives of arbitrary order can be computed automatically, accurately to working precision, and using at most a small constant factor more arithmetic operations than the original program.   This paper presents AD techniques available in ROOT, supported by Cling, to produce derivatives of arbitrary C/C++ functions through implementing source code transformation and employing the chain rule of differential calculus in both forward mode and reverse mode. We explain its current integration for gradient computation in TFormula. We demonstrate the correctness and performance improvements in ROOT's fitting algorithms.",
        "published": "2020-04-09T09:18:50Z",
        "link": "http://arxiv.org/abs/2004.04435v1",
        "categories": [
            "cs.MS",
            "cs.CL",
            "cs.SE"
        ]
    },
    {
        "title": "Fully Parallel Mesh I/O using PETSc DMPlex with an Application to   Waveform Modeling",
        "authors": [
            "Vaclav Hapla",
            "Matthew G. Knepley",
            "Michael Afanasiev",
            "Christian Boehm",
            "Martin van Driel",
            "Lion Krischer",
            "Andreas Fichtner"
        ],
        "summary": "Large-scale PDE simulations using high-order finite-element methods on unstructured meshes are an indispensable tool in science and engineering. The widely used open-source PETSc library offers an efficient representation of generic unstructured meshes within its DMPlex module. This paper details our recent implementation of parallel mesh reading and topological interpolation (computation of edges and faces from a cell-vertex mesh) into DMPlex. We apply these developments to seismic wave propagation scenarios on Mars as an example application. The principal motivation is to overcome single-node memory limits and reach mesh sizes which were impossible before. Moreover, we demonstrate that scalability of I/O and topological interpolation goes beyond 12'000 cores, and memory-imposed limits on mesh size vanish.",
        "published": "2020-04-18T23:26:04Z",
        "link": "http://arxiv.org/abs/2004.08729v2",
        "categories": [
            "cs.MS",
            "cs.NA",
            "math.NA",
            "65-04, 65Y05, 65M50, 05C90, 35L05"
        ]
    },
    {
        "title": "A practical approach to testing random number generators in computer   algebra systems",
        "authors": [
            "Migran N. Gevorkyan",
            "Dmitry S. Kulyabov",
            "Anastasia V. Demidova",
            "Anna V. Korolkova"
        ],
        "summary": "This paper has a practical aim. For a long time, implementations of pseudorandom number generators in standard libraries of programming languages had poor quality. The situation started to improve only recently. Up to now, a large number of libraries and weakly supported mathematical packages use outdated algorithms for random number generation. Four modern sets of statistical tests that can be used for verifying random number generators are described. It is proposed to use command line utilities, which makes it possible to avoid low-level programming in such languages as C or C++. Only free open source systems are considered.",
        "published": "2020-04-19T17:19:19Z",
        "link": "http://arxiv.org/abs/2004.08913v1",
        "categories": [
            "cs.MS",
            "cs.SC"
        ]
    },
    {
        "title": "GAPS: Generator for Automatic Polynomial Solvers",
        "authors": [
            "Bo Li",
            "Viktor Larsson"
        ],
        "summary": "Minimal problems in computer vision raise the demand of generating efficient automatic solvers for polynomial equation systems. Given a polynomial system repeated with different coefficient instances, the traditional Gr\\\"obner basis or normal form based solution is very inefficient. Fortunately the Gr\\\"obner basis of a same polynomial system with different coefficients is found to share consistent inner structure. By precomputing such structures offline, Gr\\\"obner basis as well as the polynomial system solutions can be solved automatically and efficiently online. In the past decade, several tools have been released to generate automatic solvers for a general minimal problems. The most recent tool autogen from Larsson et al. is a representative of these tools with state-of-the-art performance in solver efficiency. GAPS wraps and improves autogen with more user-friendly interface, more functionality and better stability. We demonstrate in this report the main approach and enhancement features of GAPS. A short tutorial of the software is also included.",
        "published": "2020-04-24T14:11:28Z",
        "link": "http://arxiv.org/abs/2004.11765v1",
        "categories": [
            "cs.CV",
            "cs.MS",
            "cs.RO",
            "cs.SC"
        ]
    },
    {
        "title": "Enhancements to the DIDO Optimal Control Toolbox",
        "authors": [
            "I. M. Ross"
        ],
        "summary": "In 2020, DIDO$^\\copyright$ turned 20! The software package emerged in 2001 as a basic, user-friendly MATLAB$^\\circledR$ teaching-tool to illustrate the various nuances of Pontryagin's Principle but quickly rose to prominence in 2007 after NASA announced it had executed a globally optimal maneuver using DIDO. Since then, the toolbox has grown in applications well beyond its aerospace roots: from solving problems in quantum control to ushering rapid, nonlinear sensitivity-analysis in designing high-performance automobiles. Most recently, it has been used to solve continuous-time traveling-salesman problems. Over the last two decades, DIDO's algorithms have evolved from their simple use of generic nonlinear programming solvers to a multifaceted engagement of fast spectral Hamiltonian programming techniques. A description of the internal enhancements to DIDO that define its mathematics and algorithms are described in this paper. A challenge example problem from robotics is included to showcase how the latest version of DIDO is capable of escaping the trappings of a ``local minimum'' that ensnare many other trajectory optimization methods.",
        "published": "2020-04-27T19:25:06Z",
        "link": "http://arxiv.org/abs/2004.13112v2",
        "categories": [
            "math.OC",
            "cs.MS",
            "cs.RO",
            "49-04, 49M25, 90C06",
            "D.1.5; F.2.1; G.4"
        ]
    },
    {
        "title": "Various Ways to Quantify BDMPs",
        "authors": [
            "Marc Bouissou",
            "Shahid Khan",
            "Joost-Pieter Katoen",
            "Pavel Krcal"
        ],
        "summary": "A Boolean logic driven Markov process (BDMP) is a dependability analysis model that defines a continuous-time Markov chain (CTMC). This formalism has high expressive power, yet it remains readable because its graphical representation stays close to standard fault trees. The size of a BDMP is roughly speaking proportional to the size of the system it models, whereas the size of the CTMC specified by this BDMP suffers from exponential growth. Thus quantifying large BDMPs can be a challenging task. The most general method to quantify them is Monte Carlo simulation, but this may be intractable for highly reliable systems. On the other hand, some subcategories of BDMPs can be processed with much more efficient methods. For example, BDMPs without repairs can be translated into dynamic fault trees, a formalism accepted as an input of the STORM model checker, that performs numerical calculations on sparse matrices, or they can be processed with the tool FIGSEQ that explores paths going to a failure state and calculates their probabilities. BDMPs with repairs can be quantified by FIGSEQ (BDMPs capturing quickly and completely repairable behaviors are solved by a different algorithm), and by the I&AB (Initiator and All Barriers) method, recently published and implemented in a prototype version of RISKSPECTRUM PSA. This tool, based exclusively on Boolean representations looks for and quantifies minimal cut sets of the system, i.e., minimal combinations of component failures that induce the loss of the system. This allows a quick quantification of large models with repairable components, standby redundancies and some other types of dependencies between omponents. All these quantification methods have been tried on a benchmark whose definition was published at the MARS 2017 workshop: the model of emergency power supplies of a nuclear power plant. In this paper, after a recall of the theoretical principles of the various quantification methods, we compare their performances on that benchmark.",
        "published": "2020-04-28T04:21:21Z",
        "link": "http://arxiv.org/abs/2004.13283v1",
        "categories": [
            "cs.CE",
            "cs.MS"
        ]
    },
    {
        "title": "Synergistic CPU-FPGA Acceleration of Sparse Linear Algebra",
        "authors": [
            "Mohammadreza Soltaniyeh",
            "Richard P. Martin",
            "Santosh Nagarakatte"
        ],
        "summary": "This paper describes REAP, a software-hardware approach that enables high performance sparse linear algebra computations on a cooperative CPU-FPGA platform. REAP carefully separates the task of organizing the matrix elements from the computation phase. It uses the CPU to provide a first-pass re-organization of the matrix elements, allowing the FPGA to focus on the computation. We introduce a new intermediate representation that allows the CPU to communicate the sparse data and the scheduling decisions to the FPGA. The computation is optimized on the FPGA for effective resource utilization with pipelining. REAP improves the performance of Sparse General Matrix Multiplication (SpGEMM) and Sparse Cholesky Factorization by 3.2X and 1.85X compared to widely used sparse libraries for them on the CPU, respectively.",
        "published": "2020-04-29T01:06:52Z",
        "link": "http://arxiv.org/abs/2004.13907v1",
        "categories": [
            "cs.DC",
            "cs.MS",
            "cs.PL"
        ]
    },
    {
        "title": "Custom-Precision Mathematical Library Explorations for Code Profiling   and Optimization",
        "authors": [
            "David Defour",
            "Pablo de Oliveira Castro",
            "Matei Istoan",
            "Eric Petit"
        ],
        "summary": "The typical processors used for scientific computing have fixed-width data-paths. This implies that mathematical libraries were specifically developed to target each of these fixed precisions (binary16, binary32, binary64). However, to address the increasing energy consumption and throughput requirements of scientific applications, library and hardware designers are moving beyond this one-size-fits-all approach. In this article we propose to study the effects and benefits of using user-defined floating-point formats and target accuracies in calculations involving mathematical functions. Our tool collects input-data profiles and iteratively explores lower precisions for each call-site of a mathematical function in user applications. This profiling data will be a valuable asset for specializing and fine-tuning mathematical function implementations for a given application. We demonstrate the tool's capabilities on SGP4, a satellite tracking application. The profile data shows the potential for specialization and provides insight into answering where it is useful to provide variable-precision designs for elementary function evaluation.",
        "published": "2020-05-06T11:06:11Z",
        "link": "http://arxiv.org/abs/2005.02732v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "CS-TSSOS: Correlative and term sparsity for large-scale polynomial   optimization",
        "authors": [
            "Jie Wang",
            "Victor Magron",
            "Jean B. Lasserre",
            "Ngoc Hoang Anh Mai"
        ],
        "summary": "This work proposes a new moment-SOS hierarchy, called CS-TSSOS, for solving large-scale sparse polynomial optimization problems. Its novelty is to exploit simultaneously correlative sparsity and term sparsity by combining advantages of two existing frameworks for sparse polynomial optimization. The former is due to Waki et al. while the latter was initially proposed by Wang et al. and later exploited in the TSSOS hierarchy. In doing so we obtain CS-TSSOS -- a two-level hierarchy of semidefinite programming relaxations with (i), the crucial property to involve blocks of SDP matrices and (ii), the guarantee of convergence to the global optimum under certain conditions. We demonstrate its efficiency and scalability on several large-scale instances of the celebrated Max-Cut problem and the important industrial optimal power flow problem, involving up to six thousand variables and tens of thousands of constraints.",
        "published": "2020-05-06T13:55:03Z",
        "link": "http://arxiv.org/abs/2005.02828v2",
        "categories": [
            "math.OC",
            "cs.MS"
        ]
    },
    {
        "title": "Delayed approximate matrix assembly in multigrid with dynamic precisions",
        "authors": [
            "Charles D. Murray",
            "Tobias Weinzierl"
        ],
        "summary": "The accurate assembly of the system matrix is an important step in any code that solves partial differential equations on a mesh. We either explicitly set up a matrix, or we work in a matrix-free environment where we have to be able to quickly return matrix entries upon demand. Either way, the construction can become costly due to non-trivial material parameters entering the equations, multigrid codes requiring cascades of matrices that depend upon each other, or dynamic adaptive mesh refinement that necessitates the recomputation of matrix entries or the whole equation system throughout the solve. We propose that these constructions can be performed concurrently with the multigrid cycles. Initial geometric matrices and low accuracy integrations kickstart the multigrid, while improved assembly data is fed to the solver as and when it becomes available. The time to solution is improved as we eliminate an expensive preparation phase traditionally delaying the actual computation. We eliminate algorithmic latency. Furthermore, we desynchronise the assembly from the solution process. This anarchic increase of the concurrency level improves the scalability. Assembly routines are notoriously memory- and bandwidth-demanding. As we work with iteratively improving operator accuracies, we finally propose the use of a hierarchical, lossy compression scheme such that the memory footprint is brought down aggressively where the system matrix entries carry little information or are not yet available with high accuracy.",
        "published": "2020-05-07T17:06:01Z",
        "link": "http://arxiv.org/abs/2005.03606v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "AutoHOOT: Automatic High-Order Optimization for Tensors",
        "authors": [
            "Linjian Ma",
            "Jiayu Ye",
            "Edgar Solomonik"
        ],
        "summary": "High-order optimization methods, including Newton's method and its variants as well as alternating minimization methods, dominate the optimization algorithms for tensor decompositions and tensor networks. These tensor methods are used for data analysis and simulation of quantum systems. In this work, we introduce AutoHOOT, the first automatic differentiation (AD) framework targeting at high-order optimization for tensor computations. AutoHOOT takes input tensor computation expressions and generates optimized derivative expressions. In particular, AutoHOOT contains a new explicit Jacobian / Hessian expression generation kernel whose outputs maintain the input tensors' granularity and are easy to optimize. The expressions are then optimized by both the traditional compiler optimization techniques and specific tensor algebra transformations. Experimental results show that AutoHOOT achieves competitive CPU and GPU performance for both tensor decomposition and tensor network applications compared to existing AD software and other tensor computation libraries with manually written kernels. The tensor methods generated by AutoHOOT are also well-parallelizable, and we demonstrate good scalability on a distributed memory supercomputer.",
        "published": "2020-05-10T01:15:37Z",
        "link": "http://arxiv.org/abs/2005.04540v2",
        "categories": [
            "cs.MS",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "A modular extension for a computer algebra system",
        "authors": [
            "Migran N. Gevorkyan",
            "Anna V. Korolkova",
            "Dmitry S. Kulyabov",
            "Leonid A. Sevastianov"
        ],
        "summary": "Computer algebra systems are complex software systems that cover a wide range of scientific and practical problems. However, the absolute coverage cannot be achieved. Often, it is required to create a user extension for an existing computer algebra system. In this case, the extensibility of the system should be taken into account. In this paper, we consider a technology for extending the SymPy computer algebra system with a low-level module that implements a random number generator.",
        "published": "2020-05-11T17:05:30Z",
        "link": "http://arxiv.org/abs/2005.05261v1",
        "categories": [
            "cs.MS",
            "cs.SC"
        ]
    },
    {
        "title": "SciANN: A Keras/Tensorflow wrapper for scientific computations and   physics-informed deep learning using artificial neural networks",
        "authors": [
            "Ehsan Haghighat",
            "Ruben Juanes"
        ],
        "summary": "In this paper, we introduce SciANN, a Python package for scientific computing and physics-informed deep learning using artificial neural networks. SciANN uses the widely used deep-learning packages Tensorflow and Keras to build deep neural networks and optimization models, thus inheriting many of Keras's functionalities, such as batch optimization and model reuse for transfer learning. SciANN is designed to abstract neural network construction for scientific computations and solution and discovery of partial differential equations (PDE) using the physics-informed neural networks (PINN) architecture, therefore providing the flexibility to set up complex functional forms. We illustrate, in a series of examples, how the framework can be used for curve fitting on discrete data, and for solution and discovery of PDEs in strong and weak forms. We summarize the features currently available in SciANN, and also outline ongoing and future developments.",
        "published": "2020-05-11T22:55:15Z",
        "link": "http://arxiv.org/abs/2005.08803v2",
        "categories": [
            "cs.OH",
            "cs.LG",
            "cs.MS",
            "74S30 (primary), 74S05, 74B05, 74L05, 74L10 (secondary)",
            "J.2"
        ]
    },
    {
        "title": "The JuliaConnectoR: a functionally oriented interface for integrating   Julia in R",
        "authors": [
            "Stefan Lenz",
            "Maren Hackenberg",
            "Harald Binder"
        ],
        "summary": "Like many groups considering the new programming language Julia, we faced the challenge of accessing the algorithms that we develop in Julia from R. Therefore, we developed the R package JuliaConnectoR, available from the CRAN repository and GitHub (https://github.com/stefan-m-lenz/JuliaConnectoR), in particular for making advanced deep learning tools available. For maintainability and stability, we decided to base communication between R and Julia on TCP, using an optimized binary format for exchanging data. Our package also specifically contains features that allow for a convenient interactive use in R. This makes it easy to develop R extensions with Julia or to simply call functionality from Julia packages in R. Interacting with Julia objects and calling Julia functions becomes user-friendly, as Julia functions and variables are made directly available as objects in the R workspace. We illustrate the further features of our package with code examples, and also discuss advantages over the two alternative packages JuliaCall and XRJulia. Finally, we demonstrate the usage of the package with a more extensive example for employing neural ordinary differential equations, a recent deep learning technique that has received much attention. This example also provides more general guidance for integrating deep learning techniques from Julia into R.",
        "published": "2020-05-13T14:18:34Z",
        "link": "http://arxiv.org/abs/2005.06334v2",
        "categories": [
            "cs.MS",
            "cs.LG",
            "cs.PL",
            "stat.CO",
            "stat.ML"
        ]
    },
    {
        "title": "Reproducibility of Parallel Preconditioned Conjugate Gradient in Hybrid   Programming Environments",
        "authors": [
            "Roman Iakymchuk",
            "Maria Barreda",
            "Stef Graillat",
            "Jose I. Aliaga",
            "Enrique S. Quintana-Orti"
        ],
        "summary": "The Preconditioned Conjugate Gradient method is often employed for the solution of linear systems of equations arising in numerical simulations of physical phenomena. While being widely used, the solver is also known for its lack of accuracy while computing the residual. In this article, we propose two algorithmic solutions that originate from the ExBLAS project to enhance the accuracy of the solver as well as to ensure its reproducibility in a hybrid MPI + OpenMP tasks programming environment. One is based on ExBLAS and preserves every bit of information until the final rounding, while the other relies upon floating-point expansions and, hence, expands the intermediate precision. Instead of converting the entire solver into its ExBLAS-related implementation, we identify those parts that violate reproducibility/non-associativity, secure them, and combine this with the sequential executions. These algorithmic strategies are reinforced with programmability suggestions to assure deterministic executions. Finally, we verify these approaches on two modern HPC systems: both versions deliver reproducible number of iterations, residuals, direct errors, and vector-solutions for the overhead of less than 37.7 % on 768 cores.",
        "published": "2020-05-14T22:10:15Z",
        "link": "http://arxiv.org/abs/2005.07282v1",
        "categories": [
            "cs.DC",
            "cs.MS"
        ]
    },
    {
        "title": "Batched computation of the singular value decompositions of order two by   the AVX-512 vectorization",
        "authors": [
            "Vedran Novaković"
        ],
        "summary": "In this paper a vectorized algorithm for simultaneously computing up to eight singular value decompositions (SVDs, each of the form $A=U\\Sigma V^{\\ast}$) of real or complex matrices of order two is proposed. The algorithm extends to a batch of matrices of an arbitrary length $n$, that arises, for example, in the annihilation part of the parallel Kogbetliantz algorithm for the SVD of a square matrix of order $2n$. The SVD algorithm for a single matrix of order two is derived first. It scales, in most instances error-free, the input matrix $A$ such that its singular values $\\Sigma_{ii}$ cannot overflow whenever its elements are finite, and then computes the URV factorization of the scaled matrix, followed by the SVD of a non-negative upper-triangular middle factor. A vector-friendly data layout for the batch is then introduced, where the same-indexed elements of each of the input and the output matrices form vectors, and the algorithm's steps over such vectors are described. The vectorized approach is then shown to be about three times faster than processing each matrix in isolation, while slightly improving accuracy over the straightforward method for the $2\\times 2$ SVD.",
        "published": "2020-05-15T08:16:11Z",
        "link": "http://arxiv.org/abs/2005.07403v1",
        "categories": [
            "cs.MS",
            "cs.NA",
            "math.NA",
            "65F15 (Primary) 65Y05, 65Y10 (Secondary)"
        ]
    },
    {
        "title": "Signal Processing for a Reverse-GPS Wildlife Tracking System: CPU and   GPU Implementation Experiences",
        "authors": [
            "Yaniv Rubinpur",
            "Sivan Toledo"
        ],
        "summary": "We present robust high-performance implementations of signal-processing tasks performed by a high-throughput wildlife tracking system called ATLAS. The system tracks radio transmitters attached to wild animals by estimating the time of arrival of radio packets to multiple receivers (base stations). Time-of-arrival estimation of wideband radio signals is computationally expensive, especially in acquisition mode (when the time of transmission is not known, not even approximately). These computations are a bottleneck that limits the throughput of the system. We developed a sequential high-performance CPU implementation of the computations a few years back, and more recencely a GPU implementation. Both strive to balance performance with simplicity, maintainability, and development effort, as most real-world codes do. The paper reports on the two implementations and carefully evaluates their performance. The evaluations indicates that the GPU implementation dramatically improves performance and power-performance relative to the sequential CPU implementation running on a desktop CPU typical of the computers in current base stations. Performance improves by more than 50X on a high-end GPU and more than 4X with a GPU platform that consumes almost 5 times less power than the CPU platform. Performance-per-Watt ratios also improve (by more than 16X), and so do the price-performance ratios.",
        "published": "2020-05-21T03:28:52Z",
        "link": "http://arxiv.org/abs/2005.10445v3",
        "categories": [
            "cs.DC",
            "cs.MS"
        ]
    },
    {
        "title": "SymJAX: symbolic CPU/GPU/TPU programming",
        "authors": [
            "Randall Balestriero"
        ],
        "summary": "SymJAX is a symbolic programming version of JAX simplifying graph input/output/updates and providing additional functionalities for general machine learning and deep learning applications. From an user perspective SymJAX provides a la Theano experience with fast graph optimization/compilation and broad hardware support, along with Lasagne-like deep learning functionalities.",
        "published": "2020-05-21T13:37:25Z",
        "link": "http://arxiv.org/abs/2005.10635v1",
        "categories": [
            "cs.MS",
            "cs.CV"
        ]
    },
    {
        "title": "Model Evidence with Fast Tree Based Quadrature",
        "authors": [
            "Thomas Foster",
            "Chon Lok Lei",
            "Martin Robinson",
            "David Gavaghan",
            "Ben Lambert"
        ],
        "summary": "High dimensional integration is essential to many areas of science, ranging from particle physics to Bayesian inference. Approximating these integrals is hard, due in part to the difficulty of locating and sampling from regions of the integration domain that make significant contributions to the overall integral. Here, we present a new algorithm called Tree Quadrature (TQ) that separates this sampling problem from the problem of using those samples to produce an approximation of the integral. TQ places no qualifications on how the samples provided to it are obtained, allowing it to use state-of-the-art sampling algorithms that are largely ignored by existing integration algorithms. Given a set of samples, TQ constructs a surrogate model of the integrand in the form of a regression tree, with a structure optimised to maximise integral precision. The tree divides the integration domain into smaller containers, which are individually integrated and aggregated to estimate the overall integral. Any method can be used to integrate each individual container, so existing integration methods, like Bayesian Monte Carlo, can be combined with TQ to boost their performance. On a set of benchmark problems, we show that TQ provides accurate approximations to integrals in up to 15 dimensions; and in dimensions 4 and above, it outperforms simple Monte Carlo and the popular Vegas method.",
        "published": "2020-05-22T17:48:06Z",
        "link": "http://arxiv.org/abs/2005.11300v1",
        "categories": [
            "stat.ML",
            "cs.LG",
            "cs.MS",
            "stat.CO"
        ]
    },
    {
        "title": "copent: Estimating Copula Entropy and Transfer Entropy in R",
        "authors": [
            "Jian Ma"
        ],
        "summary": "Statistical independence and conditional independence are two fundamental concepts in statistics and machine learning. Copula Entropy is a mathematical concept defined by Ma and Sun for multivariate statistical independence measuring and testing, and also proved to be closely related to conditional independence (or transfer entropy). As the unified framework for measuring both independence and causality, CE has been applied to solve several related statistical or machine learning problems, including association discovery, structure learning, variable selection, and causal discovery. The nonparametric methods for estimating copula entropy and transfer entropy were also proposed previously. This paper introduces copent, the R package which implements these proposed methods for estimating copula entropy and transfer entropy. The implementation detail of the package is introduced. Three examples with simulated data and real-world data on variable selection and causal discovery are also presented to demonstrate the usage of this package. The examples on variable selection and causal discovery show the strong ability of copent on testing (conditional) independence compared with the related packages. The copent package is available on the Comprehensive R Archive Network (CRAN) and also on GitHub at https://github.com/majianthu/copent.",
        "published": "2020-05-27T10:01:12Z",
        "link": "http://arxiv.org/abs/2005.14025v3",
        "categories": [
            "stat.CO",
            "cs.IT",
            "cs.LG",
            "cs.MS",
            "math.IT",
            "stat.ME"
        ]
    },
    {
        "title": "AutoMat -- Automatic Differentiation for Generalized Standard Materials   on GPUs",
        "authors": [
            "Johannes Blühdorn",
            "Nicolas R. Gauger",
            "Matthias Kabel"
        ],
        "summary": "We propose a universal method for the evaluation of generalized standard materials that greatly simplifies the material law implementation process. By means of automatic differentiation and a numerical integration scheme, AutoMat reduces the implementation effort to two potential functions. By moving AutoMat to the GPU, we close the performance gap to conventional evaluation routines and demonstrate in detail that the expression level reverse mode of automatic differentiation as well as its extension to second order derivatives can be applied inside CUDA kernels. We underline the effectiveness and the applicability of AutoMat by integrating it into the FFT-based homogenization scheme of Moulinec and Suquet and discuss the benefits of using AutoMat with respect to runtime and solution accuracy for an elasto-viscoplastic example.",
        "published": "2020-06-08T07:38:28Z",
        "link": "http://arxiv.org/abs/2006.04391v2",
        "categories": [
            "cs.CE",
            "cs.MS",
            "G.1.4; G.1.7; G.4; J.2"
        ]
    },
    {
        "title": "On Computing the Kronecker Structure of Polynomial and Rational Matrices   using Julia",
        "authors": [
            "Andreas Varga"
        ],
        "summary": "In this paper we discuss the mathematical background and the computational aspects which underly the implementation of a collection of Julia functions in the MatrixPencils package for the determination of structural properties of polynomial and rational matrices. We primarily focus on the computation of the finite and infinite spectral structures (e.g., eigenvalues, zeros, poles) as well as the left and right singular structures (e.g., Kronecker indices), which play a fundamental role in the structure of the solution of many problems involving polynomial and rational matrices. The basic analysis tool is the determination of the Kronecker structure of linear matrix pencils using numerically reliable algorithms, which is used in conjunction with several linearization techniques of polynomial and rational matrices. Examples of polynomial and rational matrices, which exhibit all relevant structural features, are considered to illustrate the main mathematical concepts and the capabilities of implemented tools.",
        "published": "2020-06-09T08:36:42Z",
        "link": "http://arxiv.org/abs/2006.06825v2",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "26C10, 30C10, 93B10, 93B60, 93C05"
        ]
    },
    {
        "title": "The aggregated unfitted finite element method on parallel tree-based   adaptive meshes",
        "authors": [
            "Santiago Badia",
            "Alberto F. Martín",
            "Eric Neiva",
            "Francesc Verdugo"
        ],
        "summary": "In this work, we present an adaptive unfitted finite element scheme that combines the aggregated finite element method with parallel adaptive mesh refinement. We introduce a novel scalable distributed-memory implementation of the resulting scheme on locally-adapted Cartesian forest-of-trees meshes. We propose a two-step algorithm to construct the finite element space at hand by means of a discrete extension operator that carefully mixes aggregation constraints of problematic degrees of freedom, which get rid of the small cut cell problem, and standard hanging degree of freedom constraints, which ensure trace continuity on non-conforming meshes. Following this approach, we derive a finite element space that can be expressed as the original one plus well-defined linear constraints. Moreover, it requires minimum parallelization effort, using standard functionality available in existing large-scale finite element codes. Numerical experiments demonstrate its optimal mesh adaptation capability, robustness to cut location and parallel efficiency, on classical Poisson $hp$-adaptivity benchmarks. Our work opens the path to functional and geometrical error-driven dynamic mesh adaptation with the aggregated finite element method in large-scale realistic scenarios. Likewise, it can offer guidance for bridging other scalable unfitted methods and parallel adaptive mesh refinement.",
        "published": "2020-06-09T16:08:13Z",
        "link": "http://arxiv.org/abs/2006.05373v2",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "Accelerating linear solvers for Stokes problems with C++ metaprogramming",
        "authors": [
            "Denis Demidov",
            "Lin Mu",
            "Bin Wang"
        ],
        "summary": "The efficient solution of large sparse saddle point systems is very important in computational fluid mechanics. The discontinuous Galerkin finite element methods have become increasingly popular for incompressible flow problems but their application is limited due to high computational cost. We describe the C++ programming techniques that may help to accelerate linear solvers for such problems. The approach is based on the policy-based design pattern and partial template specialization, and is implemented in the open source AMGCL library. The efficiency is demonstrated with the example of accelerating an iterative solver of a discontinuous Galerkin finite element method for the Stokes problem. The implementation allows selecting algorithmic components of the solver by adjusting template parameters without any changes to the codebase. It is possible to switch the system matrix to use small statically sized blocks to store the nonzero values, or use a mixed precision solution, which results in up to 4 times speedup, and reduces the memory footprint of the algorithm by about 40\\%. We evaluate both monolithic and composite preconditioning strategies for the 3 benchmark problems. The performance of the proposed solution is compared with a multithreaded direct Pardiso solver and a parallel iterative PETSc solver.",
        "published": "2020-06-10T20:20:05Z",
        "link": "http://arxiv.org/abs/2006.06052v3",
        "categories": [
            "cs.MS",
            "cs.DC",
            "cs.DS",
            "physics.flu-dyn",
            "35-04, 65-04, 65Y05, 65Y10, 65Y15, 97N80"
        ]
    },
    {
        "title": "Array Programming with NumPy",
        "authors": [
            "Charles R. Harris",
            "K. Jarrod Millman",
            "Stéfan J. van der Walt",
            "Ralf Gommers",
            "Pauli Virtanen",
            "David Cournapeau",
            "Eric Wieser",
            "Julian Taylor",
            "Sebastian Berg",
            "Nathaniel J. Smith",
            "Robert Kern",
            "Matti Picus",
            "Stephan Hoyer",
            "Marten H. van Kerkwijk",
            "Matthew Brett",
            "Allan Haldane",
            "Jaime Fernández del Río",
            "Mark Wiebe",
            "Pearu Peterson",
            "Pierre Gérard-Marchant",
            "Kevin Sheppard",
            "Tyler Reddy",
            "Warren Weckesser",
            "Hameer Abbasi",
            "Christoph Gohlke",
            "Travis E. Oliphant"
        ],
        "summary": "Array programming provides a powerful, compact, expressive syntax for accessing, manipulating, and operating on data in vectors, matrices, and higher-dimensional arrays. NumPy is the primary array programming library for the Python language. It plays an essential role in research analysis pipelines in fields as diverse as physics, chemistry, astronomy, geoscience, biology, psychology, material science, engineering, finance, and economics. For example, in astronomy, NumPy was an important part of the software stack used in the discovery of gravitational waves and the first imaging of a black hole. Here we show how a few fundamental array concepts lead to a simple and powerful programming paradigm for organizing, exploring, and analyzing scientific data. NumPy is the foundation upon which the entire scientific Python universe is constructed. It is so pervasive that several projects, targeting audiences with specialized needs, have developed their own NumPy-like interfaces and array objects. Because of its central position in the ecosystem, NumPy increasingly plays the role of an interoperability layer between these new array computation libraries.",
        "published": "2020-06-18T03:39:27Z",
        "link": "http://arxiv.org/abs/2006.10256v1",
        "categories": [
            "cs.MS",
            "stat.CO"
        ]
    },
    {
        "title": "Robust and scalable h-adaptive aggregated unfitted finite elements for   interface elliptic problems",
        "authors": [
            "Eric Neiva",
            "Santiago Badia"
        ],
        "summary": "This work introduces a novel, fully robust and highly-scalable, $h$-adaptive aggregated unfitted finite element method for large-scale interface elliptic problems. The new method is based on a recent distributed-memory implementation of the aggregated finite element method atop a highly-scalable Cartesian forest-of-trees mesh engine. It follows the classical approach of weakly coupling nonmatching discretisations at the interface to model internal discontinuities at the interface. We propose a natural extension of a single-domain parallel cell aggregation scheme to problems with a finite number of interfaces; it straightforwardly leads to aggregated finite element spaces that have the structure of a Cartesian product. We demonstrate, through standard numerical analysis and exhaustive numerical experimentation on several complex Poisson and linear elasticity benchmarks, that the new technique enjoys the following properties: well-posedness, robustness with respect to cut location and material contrast, optimal ($h$-adaptive) approximation properties, high scalability and easy implementation in large-scale finite element codes. As a result, the method offers great potential as a useful finite element solver for large-scale interface problems modelled by partial differential equations.",
        "published": "2020-06-19T09:50:02Z",
        "link": "http://arxiv.org/abs/2006.11042v2",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "Assign optimization for algorithmic differentiation reuse index   management strategies",
        "authors": [
            "Max Sagebaum",
            "Johannes Blühdorn",
            "Nicolas R. Gauger"
        ],
        "summary": "The identification of primal variables and adjoint variables is usually done via indices in operator overloading algorithmic differentiation tools. One approach is a linear management scheme, which is easy to implement and supports memory optimization for copy statements. An alternative approach performs a reuse of indices, which requires more implementation effort but results in much smaller adjoint vectors. Therefore, the vector mode of algorithmic differentiation scales better with the reuse management scheme. In this paper, we present a novel approach that reuses the indices and allows the copy optimization, thus combining the advantages of the two aforementioned schemes. The new approach is compared to the known approaches on a simple synthetic test case and a real-world example using the computational fluid dynamics solver SU2.",
        "published": "2020-06-23T13:40:46Z",
        "link": "http://arxiv.org/abs/2006.12992v3",
        "categories": [
            "cs.MS",
            "68N30",
            "G.1.4; G.4; D.2.2"
        ]
    },
    {
        "title": "Preparing Ginkgo for AMD GPUs -- A Testimonial on Porting CUDA Code to   HIP",
        "authors": [
            "Yuhsiang M. Tsai",
            "Terry Cojean",
            "Tobias Ribizel",
            "Hartwig Anzt"
        ],
        "summary": "With AMD reinforcing their ambition in the scientific high performance computing ecosystem, we extend the hardware scope of the Ginkgo linear algebra package to feature a HIP backend for AMD GPUs. In this paper, we report and discuss the porting effort from CUDA, the extension of the HIP framework to add missing features such as cooperative groups, the performance price of compiling HIP code for AMD architectures, and the design of a library providing native backends for NVIDIA and AMD GPUs while minimizing code duplication by using a shared code base.",
        "published": "2020-06-25T10:22:02Z",
        "link": "http://arxiv.org/abs/2006.14290v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "The flare Package for High Dimensional Linear Regression and Precision   Matrix Estimation in R",
        "authors": [
            "Xingguo Li",
            "Tuo Zhao",
            "Xiaoming Yuan",
            "Han Liu"
        ],
        "summary": "This paper describes an R package named flare, which implements a family of new high dimensional regression methods (LAD Lasso, SQRT Lasso, $\\ell_q$ Lasso, and Dantzig selector) and their extensions to sparse precision matrix estimation (TIGER and CLIME). These methods exploit different nonsmooth loss functions to gain modeling flexibility, estimation robustness, and tuning insensitiveness. The developed solver is based on the alternating direction method of multipliers (ADMM). The package flare is coded in double precision C, and called from R by a user-friendly interface. The memory usage is optimized by using the sparse matrix output. The experiments show that flare is efficient and can scale up to large problems.",
        "published": "2020-06-27T18:01:56Z",
        "link": "http://arxiv.org/abs/2006.15419v1",
        "categories": [
            "stat.ML",
            "cs.LG",
            "cs.MS"
        ]
    },
    {
        "title": "Hierarchical Jacobi Iteration for Structured Matrices on GPUs using   Shared Memory",
        "authors": [
            "Mohammad Shafaet Islam",
            "Qiqi Wang"
        ],
        "summary": "High fidelity scientific simulations modeling physical phenomena typically require solving large linear systems of equations which result from discretization of a partial differential equation (PDE) by some numerical method. This step often takes a vast amount of computational time to complete, and therefore presents a bottleneck in simulation work. Solving these linear systems efficiently requires the use of massively parallel hardware with high computational throughput, as well as the development of algorithms which respect the memory hierarchy of these hardware architectures to achieve high memory bandwidth.   In this paper, we present an algorithm to accelerate Jacobi iteration for solving structured problems on graphics processing units (GPUs) using a hierarchical approach in which multiple iterations are performed within on-chip shared memory every cycle. A domain decomposition style procedure is adopted in which the problem domain is partitioned into subdomains whose data is copied to the shared memory of each GPU block. Jacobi iterations are performed internally within each block's shared memory, avoiding the need to perform expensive global memory accesses every step. We test our algorithm on the linear systems arising from discretization of Poisson's equation in 1D and 2D, and observe speedup in convergence using our shared memory approach compared to a traditional Jacobi implementation which only uses global memory on the GPU. We observe a x8 speedup in convergence in the 1D problem and a nearly x6 speedup in the 2D case from the use of shared memory compared to a conventional GPU approach.",
        "published": "2020-06-30T01:36:58Z",
        "link": "http://arxiv.org/abs/2006.16465v1",
        "categories": [
            "cs.MS",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Adaptive SpMV/SpMSpV on GPUs for Input Vectors of Varied Sparsity",
        "authors": [
            "Min Li",
            "Yulong Ao",
            "Chao Yang"
        ],
        "summary": "Despite numerous efforts for optimizing the performance of Sparse Matrix and Vector Multiplication (SpMV) on modern hardware architectures, few works are done to its sparse counterpart, Sparse Matrix and Sparse Vector Multiplication (SpMSpV), not to mention dealing with input vectors of varied sparsity. The key challenge is that depending on the sparsity levels, distribution of data, and compute platform, the optimal choice of SpMV/SpMSpV kernel can vary, and a static choice does not suffice. In this paper, we propose an adaptive SpMV/SpMSpV framework, which can automatically select the appropriate SpMV/SpMSpV kernel on GPUs for any sparse matrix and vector at the runtime. Based on systematic analysis on key factors such as computing pattern, workload distribution and write-back strategy, eight candidate SpMV/SpMSpV kernels are encapsulated into the framework to achieve high performance in a seamless manner. A comprehensive study on machine learning based kernel selector is performed to choose the kernel and adapt with the varieties of both the input and hardware from both accuracy and overhead perspectives. Experiments demonstrate that the adaptive framework can substantially outperform the previous state-of-the-art in real-world applications on NVIDIA Tesla K40m, P100 and V100 GPUs.",
        "published": "2020-06-30T13:20:02Z",
        "link": "http://arxiv.org/abs/2006.16767v3",
        "categories": [
            "cs.DC",
            "cs.MS"
        ]
    },
    {
        "title": "Ginkgo: A Modern Linear Operator Algebra Framework for High Performance   Computing",
        "authors": [
            "Hartwig Anzt",
            "Terry Cojean",
            "Goran Flegar",
            "Fritz Göbel",
            "Thomas Grützmacher",
            "Pratik Nayak",
            "Tobias Ribizel",
            "Yuhsiang Mike Tsai",
            "Enrique S. Quintana-Ortí"
        ],
        "summary": "In this paper, we present Ginkgo, a modern C++ math library for scientific high performance computing. While classical linear algebra libraries act on matrix and vector objects, Ginkgo's design principle abstracts all functionality as \"linear operators\", motivating the notation of a \"linear operator algebra library\". Ginkgo's current focus is oriented towards providing sparse linear algebra functionality for high performance GPU architectures, but given the library design, this focus can be easily extended to accommodate other algorithms and hardware architectures. We introduce this sophisticated software architecture that separates core algorithms from architecture-specific back ends and provide details on extensibility and sustainability measures. We also demonstrate Ginkgo's usability by providing examples on how to use its functionality inside the MFEM and deal.ii finite element ecosystems. Finally, we offer a practical demonstration of Ginkgo's high performance on state-of-the-art GPU architectures.",
        "published": "2020-06-30T14:42:48Z",
        "link": "http://arxiv.org/abs/2006.16852v2",
        "categories": [
            "cs.MS",
            "D.2; G.1.3; G.4"
        ]
    },
    {
        "title": "SParSH-AMG: A library for hybrid CPU-GPU algebraic multigrid and   preconditioned iterative methods",
        "authors": [
            "Sashikumaar Ganesan",
            "Manan Shah"
        ],
        "summary": "Hybrid CPU-GPU algorithms for Algebraic Multigrid methods (AMG) to efficiently utilize both CPU and GPU resources are presented. In particular, hybrid AMG framework focusing on minimal utilization of GPU memory with performance on par with GPU-only implementations is developed. The hybrid AMG framework can be tuned to operate at a significantly lower GPU-memory, consequently, enables to solve large algebraic systems. Combining the hybrid AMG framework as a preconditioner with Krylov Subspace solvers like Conjugate Gradient, BiCG methods provides a solver stack to solve a large class of problems. The performance of the proposed hybrid AMG framework is analysed for an array of matrices with different properties and size. Further, the performance of CPU-GPU algorithms are compared with the GPU-only implementations to illustrate the significantly lower memory requirements.",
        "published": "2020-06-30T18:39:50Z",
        "link": "http://arxiv.org/abs/2007.00056v1",
        "categories": [
            "cs.MS",
            "65F10, 65F50, 65N55, 65Y05"
        ]
    },
    {
        "title": "Efficient parallel 3D computation of the compressible Euler equations   with an invariant-domain preserving second-order finite-element scheme",
        "authors": [
            "Matthias Maier",
            "Martin Kronbichler"
        ],
        "summary": "We discuss the efficient implementation of a high-performance second-order collocation-type finite-element scheme for solving the compressible Euler equations of gas dynamics on unstructured meshes. The solver is based on the convex limiting technique introduced by Guermond et al. (SIAM J. Sci. Comput. 40, A3211-A3239, 2018). As such it is invariant-domain preserving, i.e., the solver maintains important physical invariants and is guaranteed to be stable without the use of ad-hoc tuning parameters. This stability comes at the expense of a significantly more involved algorithmic structure that renders conventional high-performance discretizations challenging. We develop an algorithmic design that allows SIMD vectorization of the compute kernel, identify the main ingredients for a good node-level performance, and report excellent weak and strong scaling of a hybrid thread/MPI parallelization.",
        "published": "2020-06-30T20:19:45Z",
        "link": "http://arxiv.org/abs/2007.00094v2",
        "categories": [
            "cs.MS",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Sparse Approximate Multifrontal Factorization with Butterfly Compression   for High Frequency Wave Equations",
        "authors": [
            "Yang Liu",
            "Pieter Ghysels",
            "Lisa Claus",
            "Xiaoye Sherry Li"
        ],
        "summary": "We present a fast and approximate multifrontal solver for large-scale sparse linear systems arising from finite-difference, finite-volume or finite-element discretization of high-frequency wave equations. The proposed solver leverages the butterfly algorithm and its hierarchical matrix extension for compressing and factorizing large frontal matrices via graph-distance guided entry evaluation or randomized matrix-vector multiplication-based schemes. Complexity analysis and numerical experiments demonstrate $\\mathcal{O}(N\\log^2 N)$ computation and $\\mathcal{O}(N)$ memory complexity when applied to an $N\\times N$ sparse system arising from 3D high-frequency Helmholtz and Maxwell problems.",
        "published": "2020-07-01T03:27:33Z",
        "link": "http://arxiv.org/abs/2007.00202v2",
        "categories": [
            "cs.MS",
            "cs.CE",
            "15A23, 65F50, 65R10, 65R20"
        ]
    },
    {
        "title": "On Designing GPU Algorithms with Applications to Mesh Refinement",
        "authors": [
            "Zhenghai Chen",
            "Tiow-Seng Tan",
            "Hong-Yang Ong"
        ],
        "summary": "We present a set of rules to guide the design of GPU algorithms. These rules are grounded on the principle of reducing waste in GPU utility to achieve good speed up. In accordance to these rules, we propose GPU algorithms for 2D constrained, 3D constrained and 3D Restricted Delaunay refinement problems respectively. Our algorithms take a 2D planar straight line graph (PSLG) or 3D piecewise linear complex (PLC) $\\mathcal{G}$ as input, and generate quality meshes conforming or approximating to $\\mathcal{G}$. The implementation of our algorithms shows that they are the first to run an order of magnitude faster than current state-of-the-art counterparts in sequential and parallel manners while using similar numbers of Steiner points to produce triangulations of comparable qualities. It thus reduces the computing time of mesh refinement from possibly hours to a few seconds or minutes for possible use in interactive graphics applications.",
        "published": "2020-07-01T08:43:12Z",
        "link": "http://arxiv.org/abs/2007.00324v1",
        "categories": [
            "cs.GR",
            "cs.DC",
            "cs.MS"
        ]
    },
    {
        "title": "Volesti: Volume Approximation and Sampling for Convex Polytopes in R",
        "authors": [
            "Apostolos Chalkis",
            "Vissarion Fisikopoulos"
        ],
        "summary": "Sampling from high dimensional distributions and volume approximation of convex bodies are fundamental operations that appear in optimization, finance, engineering, artificial intelligence and machine learning. In this paper we present volesti, an R package that provides efficient, scalable algorithms for volume estimation, uniform and Gaussian sampling from convex polytopes. volesti scales to hundreds of dimensions, handles efficiently three different types of polyhedra and provides non existing sampling routines to R. We demonstrate the power of volesti by solving several challenging problems using the R language.",
        "published": "2020-07-03T09:47:14Z",
        "link": "http://arxiv.org/abs/2007.01578v3",
        "categories": [
            "stat.CO",
            "cs.CG",
            "cs.MS",
            "62, 68, 52",
            "G.3; G.4"
        ]
    },
    {
        "title": "Algorithm 1019: A Task-based Multi-shift QR/QZ Algorithm with Aggressive   Early Deflation",
        "authors": [
            "Mirko Myllykoski"
        ],
        "summary": "The QR algorithm is one of the three phases in the process of computing the eigenvalues and the eigenvectors of a dense nonsymmetric matrix. This paper describes a task-based QR algorithm for reducing an upper Hessenberg matrix to real Schur form. The task-based algorithm also supports generalized eigenvalue problems (QZ algorithm) but this paper concentrates on the standard case. The task-based algorithm adopts previous algorithmic improvements, such as tightly-coupled multi-shifts and Aggressive Early Deflation (AED), and also incorporates several new ideas that significantly improve the performance. This includes, but is not limited to, the elimination of several synchronization points, the dynamic merging of previously separate computational steps, the shortening and the prioritization of the critical path, and experimental GPU support. The task-based implementation is demonstrated to be multiple times faster than multi-threaded LAPACK and ScaLAPACK in both single-node and multi-node configurations on two different machines based on Intel and AMD CPUs. The implementation is built on top of the StarPU runtime system and is part of the open-source StarNEig library.",
        "published": "2020-07-07T15:53:50Z",
        "link": "http://arxiv.org/abs/2007.03576v3",
        "categories": [
            "cs.MS",
            "cs.DC",
            "cs.NA",
            "math.NA",
            "97N80, 15A18, 65F15, 65Y05, 68W10, 68W15",
            "F.1.2; F.2.1; G.1.3"
        ]
    },
    {
        "title": "A Novel Approach to Generate Correctly Rounded Math Libraries for New   Floating Point Representations",
        "authors": [
            "Jay P. Lim",
            "Mridul Aanjaneya",
            "John Gustafson",
            "Santosh Nagarakatte"
        ],
        "summary": "Given the importance of floating-point~(FP) performance in numerous domains, several new variants of FP and its alternatives have been proposed (e.g., Bfloat16, TensorFloat32, and Posits). These representations do not have correctly rounded math libraries. Further, the use of existing FP libraries for these new representations can produce incorrect results. This paper proposes a novel approach for generating polynomial approximations that can be used to implement correctly rounded math libraries. Existing methods generate polynomials that approximate the real value of an elementary function $f(x)$ and produce wrong results due to approximation errors and rounding errors in the implementation. In contrast, our approach generates polynomials that approximate the correctly rounded value of $f(x)$ (i.e., the value of $f(x)$ rounded to the target representation). It provides more margin to identify efficient polynomials that produce correctly rounded results for all inputs. We frame the problem of generating efficient polynomials that produce correctly rounded results as a linear programming problem. Our approach guarantees that we produce the correct result even with range reduction techniques. Using our approach, we have developed correctly rounded, yet faster, implementations of elementary functions for multiple target representations.",
        "published": "2020-07-09T17:45:15Z",
        "link": "http://arxiv.org/abs/2007.05344v3",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "Blends in Maple",
        "authors": [
            "Robert M. Corless",
            "Erik Postma"
        ],
        "summary": "A blend of two Taylor series for the same smooth real- or complex-valued function of a single variable can be useful for approximation. We use an explicit formula for a two-point Hermite interpolational polynomial to construct such blends. We show a robust Maple implementation that can stably and efficiently evaluate blends using linear-cost Horner form, evaluate their derivatives to arbitrary order at the same time, or integrate a blend exactly. The implementation is suited for use with evalhf. We provide a top-level user interface and efficient module exports for programmatic use. This work was presented at the Maple Conference 2020. See www.maplesoft.com/mapleconference",
        "published": "2020-07-09T19:27:10Z",
        "link": "http://arxiv.org/abs/2007.05041v2",
        "categories": [
            "cs.MS",
            "65D05, 65D32, 68W30",
            "I.1.1; G.1.2; G.1.7"
        ]
    },
    {
        "title": "ACORNS: An Easy-To-Use Code Generator for Gradients and Hessians",
        "authors": [
            "Deshana Desai",
            "Etai Shuchatowitz",
            "Zhongshi Jiang",
            "Teseo Schneider",
            "Daniele Panozzo"
        ],
        "summary": "The computation of first and second-order derivatives is a staple in many computing applications, ranging from machine learning to scientific computing. We propose an algorithm to automatically differentiate algorithms written in a subset of C99 code and its efficient implementation as a Python script. We demonstrate that our algorithm enables automatic, reliable, and efficient differentiation of common algorithms used in physical simulation and geometry processing.",
        "published": "2020-07-09T22:11:48Z",
        "link": "http://arxiv.org/abs/2007.05094v1",
        "categories": [
            "cs.MS",
            "cs.SC"
        ]
    },
    {
        "title": "Algorithmic differentiation of hyperbolic flow problems",
        "authors": [
            "Michael Herty",
            "Jonathan Hüser",
            "Uwe Naumann",
            "Thomas Schilden",
            "Wolfgang Schröder"
        ],
        "summary": "We are interested in the development of an algorithmic differentiation framework for computing approximations to tangent vectors to scalar and systems of hyperbolic partial differential equations. The main difficulty of such a numerical method is the presence of shock waves that are resolved by proposing a numerical discretization of the calculus introduced in Bressan and Marson [Rend. Sem. Mat. Univ. Padova, 94:79-94, 1995]. Numerical results are presented for the one-dimensional Burgers equation and the Euler equations. Using the essential routines of a state-of-the-art code for computational fluid dynamics (CFD) as a starting point, three modifications are required to apply the introduced calculus. First, the CFD code is modified to solve an additional equation for the shock location. Second, we customize the computation of the corresponding tangent to the shock location. Finally, the modified method is enhanced by algorithmic differentiation. Applying the introduced calculus to problems of the Burgers equation and the Euler equations, it is found that correct sensitivities can be computed, whereas the application of black-box algorithmic differentiation fails.",
        "published": "2020-07-10T12:20:20Z",
        "link": "http://arxiv.org/abs/2007.05330v1",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "physics.flu-dyn"
        ]
    },
    {
        "title": "fenicsR13: A Tensorial Mixed Finite Element Solver for the Linear R13   Equations Using the FEniCS Computing Platform",
        "authors": [
            "Lambert Theisen",
            "Manuel Torrilhon"
        ],
        "summary": "We present a mixed finite element solver for the linearized R13 equations of non-equilibrium gas dynamics. The Python implementation builds upon the software tools provided by the FEniCS computing platform. We describe a new tensorial approach utilizing the extension capabilities of FEniCS's Unified Form Language (UFL) to define required differential operators for tensors above second degree. The presented solver serves as an example for implementing tensorial variational formulations in FEniCS, for which the documentation and literature seem to be very sparse. Using the software abstraction levels provided by the UFL allows an almost one-to-one correspondence between the underlying mathematics and the resulting source code. Test cases support the correctness of the proposed method using validation with exact solutions. To justify the usage of extended gas flow models, we discuss typical application cases involving rarefaction effects. We provide the documented and validated solver publicly.",
        "published": "2020-07-12T09:07:24Z",
        "link": "http://arxiv.org/abs/2007.05944v2",
        "categories": [
            "cs.CE",
            "cs.MS",
            "physics.flu-dyn",
            "65N30, 65-04, 76P05, 76-04, 35Q35, 35-04",
            "G.1.8; G.4; J.2"
        ]
    },
    {
        "title": "Meta-analysis parameters computation: a Python approach to facilitate   the crossing of experimental conditions",
        "authors": [
            "Flavien Quijoux",
            "Charles Truong",
            "Aliénor Vienne-Jumeau",
            "Laurent Oudre",
            "François BERTIN-HUGAULT",
            "Philippe ZAWIEJA",
            "Marie LEFEVRE",
            "Pierre-Paul VIDAL",
            "Damien RICARD"
        ],
        "summary": "Meta-analysis is a data aggregation method that establishes an overall and objective level of evidence based on the results of several studies. It is necessary to maintain a high level of homogeneity in the aggregation of data collected from a systematic literature review. However, the current tools do not allow a cross-referencing of the experimental conditions that could explain the heterogeneity observed between studies. This article aims at proposing a Python programming code containing several functions allowing the analysis and rapid visualization of data from many studies, while allowing the possibility of cross-checking the results by experimental condition.",
        "published": "2020-07-13T09:42:28Z",
        "link": "http://arxiv.org/abs/2007.07799v1",
        "categories": [
            "stat.ME",
            "cs.MS",
            "stat.AP"
        ]
    },
    {
        "title": "A Survey of Numerical Methods Utilizing Mixed Precision Arithmetic",
        "authors": [
            "Ahmad Abdelfattah",
            "Hartwig Anzt",
            "Erik G. Boman",
            "Erin Carson",
            "Terry Cojean",
            "Jack Dongarra",
            "Mark Gates",
            "Thomas Grützmacher",
            "Nicholas J. Higham",
            "Sherry Li",
            "Neil Lindquist",
            "Yang Liu",
            "Jennifer Loe",
            "Piotr Luszczek",
            "Pratik Nayak",
            "Sri Pranesh",
            "Siva Rajamanickam",
            "Tobias Ribizel",
            "Barry Smith",
            "Kasia Swirydowicz",
            "Stephen Thomas",
            "Stanimire Tomov",
            "Yaohung M. Tsai",
            "Ichitaro Yamazaki",
            "Urike Meier Yang"
        ],
        "summary": "Within the past years, hardware vendors have started designing low precision special function units in response to the demand of the Machine Learning community and their demand for high compute power in low precision formats. Also the server-line products are increasingly featuring low-precision special function units, such as the NVIDIA tensor cores in ORNL's Summit supercomputer providing more than an order of magnitude higher performance than what is available in IEEE double precision. At the same time, the gap between the compute power on the one hand and the memory bandwidth on the other hand keeps increasing, making data access and communication prohibitively expensive compared to arithmetic operations. To start the multiprecision focus effort, we survey the numerical linear algebra community and summarize all existing multiprecision knowledge, expertise, and software capabilities in this landscape analysis report. We also include current efforts and preliminary results that may not yet be considered \"mature technology,\" but have the potential to grow into production quality within the multiprecision focus effort. As we expect the reader to be familiar with the basics of numerical linear algebra, we refrain from providing a detailed background on the algorithms themselves but focus on how mixed- and multiprecision technology can help improving the performance of these methods and present highlights of application significantly outperforming the traditional fixed precision methods.",
        "published": "2020-07-13T20:33:46Z",
        "link": "http://arxiv.org/abs/2007.06674v1",
        "categories": [
            "cs.MS",
            "cs.NA",
            "math.NA",
            "G.1.3; G.4"
        ]
    },
    {
        "title": "Accelerating Geometric Multigrid Preconditioning with Half-Precision   Arithmetic on GPUs",
        "authors": [
            "Kyaw L. Oo",
            "Andreas Vogel"
        ],
        "summary": "With the hardware support for half-precision arithmetic on NVIDIA V100 GPUs, high-performance computing applications can benefit from lower precision at appropriate spots to speed up the overall execution time. In this paper, we investigate a mixed-precision geometric multigrid method to solve large sparse systems of equations stemming from discretization of elliptic PDEs. While the final solution is always computed with high-precision accuracy, an iterative refinement approach with multigrid preconditioning in lower precision and residuum scaling is employed. We compare the FP64 baseline for Poisson's equation to purely FP16 multigrid preconditioning and to the employment of FP16-FP32-FP64 combinations within a mesh hierarchy. While the iteration count is almost not affected by using lower accuracy, the solver runtime is considerably decreased due to the reduced memory transfer and a speedup of up to 2.5x is gained for the overall solver. We investigate the performance of selected kernels with the hierarchical Roofline model.",
        "published": "2020-07-15T08:27:33Z",
        "link": "http://arxiv.org/abs/2007.07539v1",
        "categories": [
            "cs.MS",
            "cs.AR",
            "cs.PF"
        ]
    },
    {
        "title": "Languages for modeling the RED active queue management algorithms:   Modelica vs. Julia",
        "authors": [
            "Anna Maria Yu. Apreutesey",
            "Anna V. Korolkova",
            "Dmitry S. Kulyabov"
        ],
        "summary": "This work is devoted to the study of the capabilities of the Modelica and Julia programming languages for the implementation of a continuously discrete paradigm in modeling hybrid systems that contain both continuous and discrete aspects of behavior. A system consisting of an incoming stream that is processed according to the Transmission Control Protocol (TCP) and a router that processes traffic using the Random Early Detection (RED) algorithm acts as a simulated threshold system.",
        "published": "2020-07-18T17:49:33Z",
        "link": "http://arxiv.org/abs/2007.09488v1",
        "categories": [
            "cs.NI",
            "cs.MS"
        ]
    },
    {
        "title": "Approaches to the implementation of generalized complex numbers in the   Julia language",
        "authors": [
            "Migran N. Gevorkyan",
            "Anna V. Korolkova",
            "Dmitry S. Kulyabov"
        ],
        "summary": "In problems of mathematical physics, to study the structures of spaces using the Cayley-Klein models in theoretical calculations, the use of generalized complex numbers is required. In the case of computational experiments, such tasks require their high-quality implementation in a programming language. The proposed small implementation of generalized complex numbers in modern programming languages have several disadvantages. In this article, we propose using the Julia language as the language for implementing generalized complex numbers, not least because it supports the multiple dispatch mechanism. The paper demonstrates the approach to the implementation of one of the types of generalized complex numbers, namely dual numbers. We place particular emphasis on the description of the use of the multiple dispatch mechanism to implement a new numerical type. The resulting implementation of dual numbers can be considered as a prototype for a complete software module for supporting generalized complex numbers.",
        "published": "2020-07-19T18:24:08Z",
        "link": "http://arxiv.org/abs/2007.09737v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "Tegula -- exploring a galaxy of two-dimensional periodic tilings",
        "authors": [
            "Rüdiger Zeller",
            "Olaf Delgado Friedrichs",
            "Daniel H. Huson"
        ],
        "summary": "Periodic tilings play a role in the decorative arts, in construction and in crystal structures. Combinatorial tiling theory allows the systematic generation, visualization and exploration of such tilings of the plane, sphere and hyperbolic plane, using advanced algorithms and software.Here we present a \"galaxy\" of tilings that consists of the set of all 2.4 billion different types of periodic tilings that have Dress complexity up to 24. We make these available in a database and provide a new program called Tegula that can be used to search and visualize such tilings.   Availability: All tilings and software and are open source and available here: https://ab.inf.uni-tuebingen.de/software/tegula.",
        "published": "2020-07-21T07:04:42Z",
        "link": "http://arxiv.org/abs/2007.10625v1",
        "categories": [
            "math.CO",
            "cs.MS",
            "51-04",
            "G.4; E.0; K.3"
        ]
    },
    {
        "title": "An Adaptive Solver for Systems of Linear Equations",
        "authors": [
            "Conrad Sanderson",
            "Ryan Curtin"
        ],
        "summary": "Computational implementations for solving systems of linear equations often rely on a one-size-fits-all approach based on LU decomposition of dense matrices stored in column-major format. Such solvers are typically implemented with the aid of the xGESV set of functions available in the low-level LAPACK software, with the aim of reducing development time by taking advantage of well-tested routines. However, this straightforward approach does not take into account various matrix properties which can be exploited to reduce the computational effort and/or to increase numerical stability. Furthermore, direct use of LAPACK functions can be error-prone for non-expert users and results in source code that has little resemblance to originating mathematical expressions. We describe an adaptive solver that we have implemented inside recent versions of the high-level Armadillo C++ library for linear algebra. The solver automatically detects several common properties of a given system (banded, triangular, symmetric positive definite), followed by solving the system via mapping to a set of suitable LAPACK functions best matched to each property. The solver also detects poorly conditioned systems and automatically seeks a solution via singular value decomposition as a fallback. We show that the adaptive solver leads to notable speedups, while also freeing the user from using direct calls to cumbersome LAPACK functions.",
        "published": "2020-07-22T05:30:33Z",
        "link": "http://arxiv.org/abs/2007.11208v2",
        "categories": [
            "cs.MS",
            "65Y04, 65Y15, 65F45, 65H10, 15-04, 68N30",
            "G.4; G.1.3; H.3.4"
        ]
    },
    {
        "title": "Optimizing Block-Sparse Matrix Multiplications on CUDA with TVM",
        "authors": [
            "Zijing Gu"
        ],
        "summary": "We implemented and optimized matrix multiplications between dense and block-sparse matrices on CUDA. We leveraged TVM, a deep learning compiler, to explore the schedule space of the operation and generate efficient CUDA code. With the automatic parameter tuning in TVM, our cross-thread reduction based implementation achieved competitive or better performance compared with other state-of-the-art frameworks.",
        "published": "2020-07-26T04:50:51Z",
        "link": "http://arxiv.org/abs/2007.13055v1",
        "categories": [
            "cs.MS",
            "cs.DC",
            "cs.LG",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "multivar_horner: a python package for computing Horner factorisations of   multivariate polynomials",
        "authors": [
            "Jannik Michelfeit"
        ],
        "summary": "Many applications in the sciences require numerically stable and computationally efficient evaluation of multivariate polynomials. Finding beneficial representations of polynomials, such as Horner factorisations, is therefore crucial. multivar_horner, the python package presented here, is the first open source software for computing multivariate Horner factorisations. This work briefly outlines the functionality of the package and puts it into reference to previous work in the field. Benchmarks additionally prove the advantages of the implementation and Horner factorisations in general.",
        "published": "2020-07-26T15:43:10Z",
        "link": "http://arxiv.org/abs/2007.13152v2",
        "categories": [
            "cs.MS",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "HeAT -- a Distributed and GPU-accelerated Tensor Framework for Data   Analytics",
        "authors": [
            "Markus Götz",
            "Daniel Coquelin",
            "Charlotte Debus",
            "Kai Krajsek",
            "Claudia Comito",
            "Philipp Knechtges",
            "Björn Hagemeier",
            "Michael Tarnawa",
            "Simon Hanselmann",
            "Martin Siggel",
            "Achim Basermann",
            "Achim Streit"
        ],
        "summary": "To cope with the rapid growth in available data, the efficiency of data analysis and machine learning libraries has recently received increased attention. Although great advancements have been made in traditional array-based computations, most are limited by the resources available on a single computation node. Consequently, novel approaches must be made to exploit distributed resources, e.g. distributed memory architectures. To this end, we introduce HeAT, an array-based numerical programming framework for large-scale parallel processing with an easy-to-use NumPy-like API. HeAT utilizes PyTorch as a node-local eager execution engine and distributes the workload on arbitrarily large high-performance computing systems via MPI. It provides both low-level array computations, as well as assorted higher-level algorithms. With HeAT, it is possible for a NumPy user to take full advantage of their available resources, significantly lowering the barrier to distributed data analysis. When compared to similar frameworks, HeAT achieves speedups of up to two orders of magnitude.",
        "published": "2020-07-27T13:33:17Z",
        "link": "http://arxiv.org/abs/2007.13552v2",
        "categories": [
            "cs.DC",
            "cs.LG",
            "cs.MS",
            "C.1.2; C.2.4; D.1.3; G.1.3; G.4; I.2.0; I.2.5; I.5.5"
        ]
    },
    {
        "title": "The ITensor Software Library for Tensor Network Calculations",
        "authors": [
            "Matthew Fishman",
            "Steven R. White",
            "E. Miles Stoudenmire"
        ],
        "summary": "ITensor is a system for programming tensor network calculations with an interface modeled on tensor diagram notation, which allows users to focus on the connectivity of a tensor network without manually bookkeeping tensor indices. The ITensor interface rules out common programming errors and enables rapid prototyping of tensor network algorithms. After discussing the philosophy behind the ITensor approach, we show examples of each part of the interface including Index objects, the ITensor product operator, tensor factorizations, tensor storage types, algorithms for matrix product state (MPS) and matrix product operator (MPO) tensor networks, quantum number conserving block-sparse tensors, and the NDTensors library. We also review publications that have used ITensor for quantum many-body physics and for other areas where tensor networks are increasingly applied. To conclude we discuss promising features and optimizations to be added in the future.",
        "published": "2020-07-28T15:38:57Z",
        "link": "http://arxiv.org/abs/2007.14822v2",
        "categories": [
            "cs.MS",
            "cond-mat.str-el",
            "physics.comp-ph"
        ]
    },
    {
        "title": "A new framework for the computation of Hessians",
        "authors": [
            "Robert M. Gower",
            "Margarida P. Mello"
        ],
        "summary": "We investigate the computation of Hessian matrices via Automatic Differentiation, using a graph model and an algebraic model. The graph model reveals the inherent symmetries involved in calculating the Hessian. The algebraic model, based on Griewank and Walther's state transformations, synthesizes the calculation of the Hessian as a formula. These dual points of view, graphical and algebraic, lead to a new framework for Hessian computation. This is illustrated by developing edge_pushing, a new truly reverse Hessian computation algorithm that fully exploits the Hessian's symmetry. Computational experiments compare the performance of edge_pushing on sixteen functions from the CUTE collection against two algorithms available as drivers of the software ADOL-C, and the results are very promising.",
        "published": "2020-07-29T18:14:54Z",
        "link": "http://arxiv.org/abs/2007.15040v1",
        "categories": [
            "math.OC",
            "cs.MS",
            "65K10, 65D25, 65F50"
        ]
    },
    {
        "title": "Improved Time Warp Edit Distance -- A Parallel Dynamic Program in Linear   Memory",
        "authors": [
            "Garrett Wright"
        ],
        "summary": "Edit Distance is a classic family of dynamic programming problems, among which Time Warp Edit Distance refines the problem with the notion of a metric and temporal elasticity. A novel Improved Time Warp Edit Distance algorithm that is both massively parallelizable and requiring only linear storage is presented. This method uses the procession of a three diagonal band to cover the original dynamic program space. Every element of the diagonal update can be computed in parallel. The core method is a feature of the TWED Longest Common Subsequence data dependence and is applicable to dynamic programs that share similar band subproblem structure. The algorithm has been implemented as a CUDA C library with Python bindings. Speedups for challenging problems are phenomenal.",
        "published": "2020-07-31T15:31:05Z",
        "link": "http://arxiv.org/abs/2007.16135v1",
        "categories": [
            "cs.CG",
            "cs.DC",
            "cs.LG",
            "cs.MS",
            "math.MG"
        ]
    },
    {
        "title": "A parallel structured divide-and-conquer algorithm for symmetric   tridiagonal eigenvalue problems",
        "authors": [
            "Xia Liao",
            "Shengguo Li",
            "Yutong Lu",
            "Jose E. Roman"
        ],
        "summary": "In this paper, a parallel structured divide-and-conquer (PSDC) eigensolver is proposed for symmetric tridiagonal matrices based on ScaLAPACK and a parallel structured matrix multiplication algorithm, called PSMMA. Computing the eigenvectors via matrix-matrix multiplications is the most computationally expensive part of the divide-and-conquer algorithm, and one of the matrices involved in such multiplications is a rank-structured Cauchy-like matrix. By exploiting this particular property, PSMMA constructs the local matrices by using generators of Cauchy-like matrices without any communication, and further reduces the computation costs by using a structured low-rank approximation algorithm. Thus, both the communication and computation costs are reduced. Experimental results show that both PSMMA and PSDC are highly scalable and scale to 4096 processes at least. PSDC has better scalability than PHDC that was proposed in [J. Comput. Appl. Math. 344 (2018) 512--520] and only scaled to 300 processes for the same matrices. Comparing with \\texttt{PDSTEDC} in ScaLAPACK, PSDC is always faster and achieves $1.4$x--$1.6$x speedup for some matrices with few deflations. PSDC is also comparable with ELPA, with PSDC being faster than ELPA when using few processes and a little slower when using many processes.",
        "published": "2020-08-05T08:23:36Z",
        "link": "http://arxiv.org/abs/2008.01990v2",
        "categories": [
            "cs.MS",
            "cs.DC"
        ]
    },
    {
        "title": "EagerPy: Writing Code That Works Natively with PyTorch, TensorFlow, JAX,   and NumPy",
        "authors": [
            "Jonas Rauber",
            "Matthias Bethge",
            "Wieland Brendel"
        ],
        "summary": "EagerPy is a Python framework that lets you write code that automatically works natively with PyTorch, TensorFlow, JAX, and NumPy. Library developers no longer need to choose between supporting just one of these frameworks or reimplementing the library for each framework and dealing with code duplication. Users of such libraries can more easily switch frameworks without being locked in by a specific 3rd party library. Beyond multi-framework support, EagerPy also brings comprehensive type annotations and consistent support for method chaining to any framework. The latest documentation is available online at https://eagerpy.jonasrauber.de and the code can be found on GitHub at https://github.com/jonasrauber/eagerpy.",
        "published": "2020-08-10T14:57:41Z",
        "link": "http://arxiv.org/abs/2008.04175v1",
        "categories": [
            "cs.LG",
            "cs.MS",
            "stat.ML"
        ]
    },
    {
        "title": "Randomized Projection for Rank-Revealing Matrix Factorizations and   Low-Rank Approximations",
        "authors": [
            "Jed A. Duersch",
            "Ming Gu"
        ],
        "summary": "Rank-revealing matrix decompositions provide an essential tool in spectral analysis of matrices, including the Singular Value Decomposition (SVD) and related low-rank approximation techniques. QR with Column Pivoting (QRCP) is usually suitable for these purposes, but it can be much slower than the unpivoted QR algorithm. For large matrices, the difference in performance is due to increased communication between the processor and slow memory, which QRCP needs in order to choose pivots during decomposition. Our main algorithm, Randomized QR with Column Pivoting (RQRCP), uses randomized projection to make pivot decisions from a much smaller sample matrix, which we can construct to reside in a faster level of memory than the original matrix. This technique may be understood as trading vastly reduced communication for a controlled increase in uncertainty during the decision process. For rank-revealing purposes, the selection mechanism in RQRCP produces results that are the same quality as the standard algorithm, but with performance near that of unpivoted QR (often an order of magnitude faster for large matrices). We also propose two formulas that facilitate further performance improvements. The first efficiently updates sample matrices to avoid computing new randomized projections. The second avoids large trailing updates during the decomposition in truncated low-rank approximations. Our truncated version of RQRCP also provides a key initial step in our truncated SVD approximation, TUXV. These advances open up a new performance domain for large matrix factorizations that will support efficient problem-solving techniques for challenging applications in science, engineering, and data analysis.",
        "published": "2020-08-10T23:02:28Z",
        "link": "http://arxiv.org/abs/2008.04447v1",
        "categories": [
            "cs.MS",
            "math.SP",
            "68W20, 15A23, 15A18, 65F25"
        ]
    },
    {
        "title": "PyMGRIT: A Python Package for the parallel-in-time method MGRIT",
        "authors": [
            "Jens Hahne",
            "Stephanie Friedhoff",
            "Matthias Bolten"
        ],
        "summary": "In this paper, we introduce the Python framework PyMGRIT, which implements the multigrid-reduction-in-time (MGRIT) algorithm for solving the (non-)linear systems arising from the discretization of time-dependent problems. The MGRIT algorithm is a reduction-based iterative method that allows parallel-in-time simulations, i. e., calculating multiple time steps simultaneously in a simulation, by using a time-grid hierarchy. The PyMGRIT framework features many different variants of the MGRIT algorithm, ranging from different multigrid cycle types and relaxation schemes, as well as various coarsening strategies, including time-only and space-time coarsening, to using different time integrators on different levels in the multigrid hierachy. PyMGRIT allows serial runs for prototyping and testing of new approaches, as well as parallel runs using the Message Passing Interface (MPI). Here, we describe the implementation of the MGRIT algorithm in PyMGRIT and present the usage from both user and developer point of views. Three examples illustrate different aspects of the package, including pure time parallelism as well as space-time parallelism by coupling PyMGRIT with PETSc or Firedrake, which enable spatial parallelism through MPI.",
        "published": "2020-08-12T08:38:07Z",
        "link": "http://arxiv.org/abs/2008.05172v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "Elmer FEM-Dakota: A unified open-source computational framework for   electromagnetics and data analytics",
        "authors": [
            "Anjali Sandip"
        ],
        "summary": "Open-source electromagnetic design software, Elmer FEM, was interfaced with data analytics toolkit, Dakota. Furthermore, the coupled software was validated against a benchmark test. The interface developed provides a unified open-source computational framework for electromagnetics and data analytics. Its key features include uncertainty quantification, surrogate modelling and parameter studies. This framework enables a richer understanding of model predictions to better design electric machines in a time sensitive manner.",
        "published": "2020-08-16T20:37:28Z",
        "link": "http://arxiv.org/abs/2008.06992v2",
        "categories": [
            "physics.comp-ph",
            "cs.MS"
        ]
    },
    {
        "title": "Just another quantum assembly language (Jaqal)",
        "authors": [
            "Benjamin C. A. Morrison",
            "Andrew J. Landahl",
            "Daniel S. Lobser",
            "Kenneth M. Rudinger",
            "Antonio E. Russo",
            "Jay W. Van Der Wall",
            "Peter Maunz"
        ],
        "summary": "The Quantum Scientific Computing Open User Testbed (QSCOUT) is a trapped-ion quantum computer testbed realized at Sandia National Laboratories on behalf of the Department of Energy's Office of Science and its Advanced Scientific Computing (ASCR) program. Here we describe Jaqal, for Just another quantum assembly language, the programming language we invented to specify programs executed on QSCOUT. Jaqal is useful beyond QSCOUT---it can support mutliple hardware targets because it offloads gate names and their pulse-sequence definitions to external files. We describe the capabilities of the Jaqal language, our approach in designing it, and the reasons for its creation. To learn more about QSCOUT, Jaqal, or JaqalPaq, the metaprogramming Python package we developed for Jaqal, please visit https://qscout.sandia.gov, https://gitlab.com/jaqal, or send an e-mail to qscout@sandia.gov.",
        "published": "2020-08-18T17:10:00Z",
        "link": "http://arxiv.org/abs/2008.08042v1",
        "categories": [
            "quant-ph",
            "cs.MS"
        ]
    },
    {
        "title": "Evaluating the Performance of NVIDIA's A100 Ampere GPU for Sparse Linear   Algebra Computations",
        "authors": [
            "Yuhsiang Mike Tsai",
            "Terry Cojean",
            "Hartwig Anzt"
        ],
        "summary": "GPU accelerators have become an important backbone for scientific high performance computing, and the performance advances obtained from adopting new GPU hardware are significant. In this paper we take a first look at NVIDIA's newest server line GPU, the A100 architecture part of the Ampere generation. Specifically, we assess its performance for sparse linear algebra operations that form the backbone of many scientific applications and assess the performance improvements over its predecessor.",
        "published": "2020-08-19T14:38:07Z",
        "link": "http://arxiv.org/abs/2008.08478v1",
        "categories": [
            "cs.MS",
            "cs.PF"
        ]
    },
    {
        "title": "BSF-skeleton: A Template for Parallelization of Iterative Numerical   Algorithms on Cluster Computing Systems",
        "authors": [
            "Leonid B. Sokolinsky"
        ],
        "summary": "This article describes a method for creating applications for cluster computing systems using the parallel BSF skeleton based on the original BSF (Bulk Synchronous Farm) model of parallel computations developed by the author earlier. This model uses the master/slave paradigm. The main advantage of the BSF model is that it allows to estimate the scalability of a parallel algorithm before its implementation. Another important feature of the BSF model is the representation of problem data in the form of lists that greatly simplifies the logic of building applications. The BSF skeleton is designed for creating parallel programs in C++ using the MPI library. The scope of the BSF skeleton is iterative numerical algorithms of high computational complexity. The BSF skeleton has the following distinctive features. - The BSF-skeleton completely encapsulates all aspects that are associated with parallelizing a program. - The BSF skeleton allows error-free compilation at all stages of application development. - The BSF skeleton supports OpenMP programming model and workflows.",
        "published": "2020-08-22T15:58:24Z",
        "link": "http://arxiv.org/abs/2008.12256v3",
        "categories": [
            "cs.DC",
            "cs.MS",
            "68M14",
            "D.1.3"
        ]
    },
    {
        "title": "Compact 200 line MATLAB code for inverse design in photonics by topology   optimization: tutorial",
        "authors": [
            "Rasmus E. Christiansen",
            "Ole Sigmund"
        ],
        "summary": "We provide a compact 200 line MATLAB code demonstrating how topology optimization (TopOpt) as an inverse design tool may be used in photonics, targeting the design of two-dimensional dielectric metalenses and a metallic reflector as examples. The physics model is solved using the finite element method, and the code utilizes MATLAB's fmincon algorithm to solve the optimization problem. In addition to presenting the code itself, we briefly discuss a number of extensions and provide the code required to implement some of these. Finally, we demonstrate the superiority of using a gradient-based method compared to a genetic-algorithm-based method (using MATLAB's ga algorithm) for solving inverse design problems in photonics. The MATLAB software is freely available in the paper and may be downloaded from https://www.topopt.mek.dtu.dk.",
        "published": "2020-08-23T14:07:07Z",
        "link": "http://arxiv.org/abs/2009.14276v5",
        "categories": [
            "cs.MS",
            "cs.CE",
            "physics.optics"
        ]
    },
    {
        "title": "GPU-accelerating ImageJ Macro image processing workflows using CLIJ",
        "authors": [
            "Daniela Vorkel",
            "Robert Haase"
        ],
        "summary": "This chapter introduces GPU-accelerated image processing in ImageJ/FIJI. The reader is expected to have some pre-existing knowledge of ImageJ Macro programming. Core concepts such as variables, for-loops, and functions are essential. The chapter provides basic guidelines for improved performance in typical image processing workflows. We present in a step-by-step tutorial how to translate a pre-existing ImageJ macro into a GPU-accelerated macro.",
        "published": "2020-08-26T20:38:31Z",
        "link": "http://arxiv.org/abs/2008.11799v1",
        "categories": [
            "cs.MS",
            "cs.DC",
            "q-bio.QM"
        ]
    },
    {
        "title": "TriCG and TriMR: Two Iterative Methods for Symmetric Quasi-Definite   Systems",
        "authors": [
            "Alexis Montoison",
            "Dominique Orban"
        ],
        "summary": "We introduce iterative methods named TriCG and TriMR for solving symmetric quasi-definite systems based on the orthogonal tridiagonalization process proposed by Saunders, Simon and Yip in 1988. TriCG and TriMR are tantamount to preconditioned Block-CG and Block-MINRES with two right-hand sides in which the two approximate solutions are summed at each iteration, but require less storage and work per iteration. We evaluate the performance of TriCG and TriMR on linear systems generated from the SuiteSparse Matrix Collection and from discretized and stablized Stokes equations. We compare TriCG and TriMR with SYMMLQ and MINRES, the recommended Krylov methods for symmetric and indefinite systems. In all our experiments, TriCG and TriMR terminate earlier than SYMMLQ and MINRES on a residual-based stopping condition with an improvement of up to 50% in terms of number of iterations. They also terminate more reliably than Block-CG and Block-MINRES. Experiments in quadruple and octuple precision suggest that loss of orthogonality in the basis vectors is significantly less pronounced in TriCG and TriMR than in Block-CG and Block-MINRES.",
        "published": "2020-08-28T22:08:01Z",
        "link": "http://arxiv.org/abs/2008.12863v2",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "math.OC",
            "15A06, 65F10, 65F08, 65F22, 65F25, 65F35, 65F50, 90C06, 90C90"
        ]
    },
    {
        "title": "Introduction to Medical Image Registration with DeepReg, Between Old and   New",
        "authors": [
            "N. Montana Brown",
            "Y. Fu",
            "S. U. Saeed",
            "A. Casamitjana",
            "Z. M. C. Baum",
            "R. Delaunay",
            "Q. Yang",
            "A. Grimwood",
            "Z. Min",
            "E. Bonmati",
            "T. Vercauteren",
            "M. J. Clarkson",
            "Y. Hu"
        ],
        "summary": "This document outlines a tutorial to get started with medical image registration using the open-source package DeepReg. The basic concepts of medical image registration are discussed, linking classical methods to newer methods using deep learning. Two iterative, classical algorithms using optimisation and one learning-based algorithm using deep learning are coded step-by-step using DeepReg utilities, all with real, open-accessible, medical data.",
        "published": "2020-08-29T19:44:23Z",
        "link": "http://arxiv.org/abs/2009.01924v2",
        "categories": [
            "eess.IV",
            "cs.CV",
            "cs.LG",
            "cs.MS"
        ]
    },
    {
        "title": "A Survey of Singular Value Decomposition Methods for Distributed   Tall/Skinny Data",
        "authors": [
            "Drew Schmidt"
        ],
        "summary": "The Singular Value Decomposition (SVD) is one of the most important matrix factorizations, enjoying a wide variety of applications across numerous application domains. In statistics and data analysis, the common applications of SVD such as Principal Components Analysis (PCA) and linear regression. Usually these applications arise on data that has far more rows than columns, so-called \"tall/skinny\" matrices. In the big data analytics context, this may take the form of hundreds of millions to billions of rows with only a few hundred columns. There is a need, therefore, for fast, accurate, and scalable tall/skinny SVD implementations which can fully utilize modern computing resources. To that end, we present a survey of three different algorithms for computing the SVD for these kinds of tall/skinny data layouts using MPI for communication. We contextualize these with common big data analytics techniques, principally PCA. Finally, we present both CPU and GPU timing results from the Summit supercomputer, and discuss possible alternative approaches.",
        "published": "2020-09-02T00:34:54Z",
        "link": "http://arxiv.org/abs/2009.00761v1",
        "categories": [
            "cs.MS",
            "stat.CO"
        ]
    },
    {
        "title": "Performance Analysis of FEM Solvers on Practical Electromagnetic   Problems",
        "authors": [
            "Gergely Máté Kiss",
            "Jan Kaska",
            "Roberto André Henrique de Oliveira",
            "Olena Rubanenko",
            "Balázs Tóth"
        ],
        "summary": "The paper presents a comparative analysis of different commercial and academic software. The comparison aims to examine how the integrated adaptive grid refinement methodologies can deal with challenging, electromagnetic-field related problems. For this comparison, two benchmark problems were examined in the paper. The first example is a solution of an L-shape domain like test problem, which has a singularity at a certain point in the geometry. The second problem is an induction heated aluminum rod, which accurate solution needs to solve a non-linear, coupled physical fields. The accurate solution of this problem requires applying adaptive mesh generation strategies or applying a very fine mesh in the electromagnetic domain, which can significantly increase the computational complexity. The results show that the fully-hp adaptive meshing strategies, which are integrated into Agros-suite, can significantly reduce the task's computational complexity compared to the automatic h-adaptivity, which is part of the examined, popular commercial solvers.",
        "published": "2020-09-04T21:24:36Z",
        "link": "http://arxiv.org/abs/2009.04399v1",
        "categories": [
            "cs.CE",
            "cs.MS",
            "G.1.10",
            "G.1.10"
        ]
    },
    {
        "title": "distr6: R6 Object-Oriented Probability Distributions Interface in R",
        "authors": [
            "Raphael Sonabend",
            "Franz Kiraly"
        ],
        "summary": "distr6 is an object-oriented (OO) probability distributions interface leveraging the extensibility and scalability of R6, and the speed and efficiency of Rcpp. Over 50 probability distributions are currently implemented in the package with `core' methods including density, distribution, and generating functions, and more `exotic' ones including hazards and distribution function anti-derivatives. In addition to simple distributions, distr6 supports compositions such as truncation, mixtures, and product distributions. This paper presents the core functionality of the package and demonstrates examples for key use-cases. In addition this paper provides a critical review of the object-oriented programming paradigms in R and describes some novel implementations for design patterns and core object-oriented features introduced by the package for supporting distr6 components.",
        "published": "2020-09-07T10:20:00Z",
        "link": "http://arxiv.org/abs/2009.02993v3",
        "categories": [
            "cs.SE",
            "cs.MS",
            "stat.AP",
            "stat.CO"
        ]
    },
    {
        "title": "SeqROCTM: A Matlab toolbox for the analysis of Sequence of Random   Objects driven by Context Tree Models",
        "authors": [
            "Noslen Hernández",
            "Aline Duarte"
        ],
        "summary": "In several research problems we deal with probabilistic sequences of inputs (e.g., sequence of stimuli) from which an agent generates a corresponding sequence of responses and it is of interest to model the relation between them. A new class of stochastic processes, namely \\textit{sequences of random objects driven by context tree models}, has been introduced to model such relation in the context of auditory statistical learning. This paper introduces a freely available Matlab toolbox (SeqROCTM) that implements this new class of stochastic processes and three model selection procedures to make inference on it. Besides, due to the close relation of the new mathematical framework with context tree models, the toolbox also implements several existing model selection algorithms for context tree models.",
        "published": "2020-09-08T15:28:32Z",
        "link": "http://arxiv.org/abs/2009.06371v3",
        "categories": [
            "cs.AI",
            "cs.MS"
        ]
    },
    {
        "title": "Dune-CurvedGrid -- A Dune module for surface parametrization",
        "authors": [
            "Simon Praetorius",
            "Florian Stenger"
        ],
        "summary": "In this paper we introduce and describe an implementation of curved (surface) geometries within the Dune framework for grid-based discretizations. Therefore, we employ the abstraction of geometries as local-functions bound to a grid element, and the abstraction of a grid as connectivity of elements together with a grid-function that can be localized to the elements to provide element local parametrizations of the curved surface.",
        "published": "2020-09-10T15:32:42Z",
        "link": "http://arxiv.org/abs/2009.04938v3",
        "categories": [
            "cs.MS",
            "cs.CG",
            "53-04 (Primary) 53A05, 58J90, 65M50, 65-04 (Secondary)",
            "G.4; G.1.8"
        ]
    },
    {
        "title": "An Integer Arithmetic-Based Sparse Linear Solver Using a GMRES Method   and Iterative Refinement",
        "authors": [
            "Takeshi Iwashita",
            "Kengo Suzuki",
            "Takeshi Fukaya"
        ],
        "summary": "In this paper, we develop a (preconditioned) GMRES solver based on integer arithmetic, and introduce an iterative refinement framework for the solver. We describe the data format for the coefficient matrix and vectors for the solver that is based on integer or fixed-point numbers. To avoid overflow in calculations, we introduce initial scaling and logical shifts (adjustments) of operands in arithmetic operations. We present the approach for operand shifts, considering the characteristics of the GMRES algorithm. Numerical tests demonstrate that the integer arithmetic-based solver with iterative refinement has comparable solver performance in terms of convergence to the standard solver based on floating-point arithmetic. Moreover, we show that preconditioning is important, not only for improving convergence but also reducing the risk of overflow.",
        "published": "2020-09-16T06:38:18Z",
        "link": "http://arxiv.org/abs/2009.07495v2",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "m-arcsinh: An Efficient and Reliable Function for SVM and MLP in   scikit-learn",
        "authors": [
            "Luca Parisi"
        ],
        "summary": "This paper describes the 'm-arcsinh', a modified ('m-') version of the inverse hyperbolic sine function ('arcsinh'). Kernel and activation functions enable Machine Learning (ML)-based algorithms, such as Support Vector Machine (SVM) and Multi-Layer Perceptron (MLP), to learn from data in a supervised manner. m-arcsinh, implemented in the open source Python library 'scikit-learn', is hereby presented as an efficient and reliable kernel and activation function for SVM and MLP respectively. Improvements in reliability and speed to convergence in classification tasks on fifteen (N = 15) datasets available from scikit-learn and the University California Irvine (UCI) Machine Learning repository are discussed. Experimental results demonstrate the overall competitive classification performance of both SVM and MLP, achieved via the proposed function. This function is compared to gold standard kernel and activation functions, demonstrating its overall competitive reliability regardless of the complexity of the classification tasks involved.",
        "published": "2020-09-16T07:59:15Z",
        "link": "http://arxiv.org/abs/2009.07530v1",
        "categories": [
            "cs.LG",
            "cs.CV",
            "cs.MS",
            "stat.ML",
            "I.2.1; I.2.6"
        ]
    },
    {
        "title": "Accelerating Domain Propagation: an Efficient GPU-Parallel Algorithm   over Sparse Matrices",
        "authors": [
            "Boro Sofranac",
            "Ambros Gleixner",
            "Sebastian Pokutta"
        ],
        "summary": "Fast domain propagation of linear constraints has become a crucial component of today's best algorithms and solvers for mixed integer programming and pseudo-boolean optimization to achieve peak solving performance. Irregularities in the form of dynamic algorithmic behaviour, dependency structures, and sparsity patterns in the input data make efficient implementations of domain propagation on GPUs and, more generally, on parallel architectures challenging. This is one of the main reasons why domain propagation in state-of-the-art solvers is single thread only. In this paper, we present a new algorithm for domain propagation which (a) avoids these problems and allows for an efficient implementation on GPUs, and is (b) capable of running propagation rounds entirely on the GPU, without any need for synchronization or communication with the CPU. We present extensive computational results which demonstrate the effectiveness of our approach and show that ample speedups are possible on practically relevant problems: on state-of-the-art GPUs, our geometric mean speed-up for reasonably-large instances is around 10x to 20x and can be as high as 180x on favorably-large instances.",
        "published": "2020-09-16T16:25:29Z",
        "link": "http://arxiv.org/abs/2009.07785v5",
        "categories": [
            "cs.DC",
            "cs.DM",
            "cs.DS",
            "cs.MS",
            "math.OC"
        ]
    },
    {
        "title": "HDGlab: An open-source implementation of the hybridisable discontinuous   Galerkin method in MATLAB",
        "authors": [
            "Matteo Giacomini",
            "Ruben Sevilla",
            "Antonio Huerta"
        ],
        "summary": "This paper presents HDGlab, an open source MATLAB implementation of the hybridisable discontinuous Galerkin (HDG) method. The main goal is to provide a detailed description of both the HDG method for elliptic problems and its implementation available in HDGlab. Ultimately, this is expected to make this relatively new advanced discretisation method more accessible to the computational engineering community. HDGlab presents some features not available in other implementations of the HDG method that can be found in the free domain. First, it implements high-order polynomial shape functions up to degree nine, with both equally-spaced and Fekete nodal distributions. Second, it supports curved isoparametric simplicial elements in two and three dimensions. Third, it supports non-uniform degree polynomial approximations and it provides a flexible structure to devise degree adaptivity strategies. Finally, an interface with the open-source high-order mesh generator Gmsh is provided to facilitate its application to practical engineering problems.",
        "published": "2020-09-16T21:28:09Z",
        "link": "http://arxiv.org/abs/2009.08805v1",
        "categories": [
            "cs.MS",
            "cs.NA",
            "math.NA",
            "65-04, 35-04, 76-04, 65N30, 76M10"
        ]
    },
    {
        "title": "QR and LQ Decomposition Matrix Backpropagation Algorithms for Square,   Wide, and Deep -- Real or Complex -- Matrices and Their Software   Implementation",
        "authors": [
            "Denisa A. O. Roberts",
            "Lucas R. Roberts"
        ],
        "summary": "This article presents matrix backpropagation algorithms for the QR decomposition of matrices $A_{m, n}$, that are either square (m = n), wide (m < n), or deep (m > n), with rank $k = min(m, n)$. Furthermore, we derive novel matrix backpropagation results for the pivoted (full-rank) QR decomposition and for the LQ decomposition of deep input matrices. Differentiable QR decomposition offers a numerically stable, computationally efficient method to solve least squares problems frequently encountered in machine learning and computer vision. Other use cases such as graph learning and network compression are listed in the article. Software implementation across popular deep learning frameworks (PyTorch, TensorFlow, MXNet) incorporate the methods for general use within the deep learning community. Furthermore, this article aids the practitioner in understanding the matrix backpropagation methodology as part of larger computational graphs.",
        "published": "2020-09-19T21:03:37Z",
        "link": "http://arxiv.org/abs/2009.10071v4",
        "categories": [
            "math.NA",
            "cs.LG",
            "cs.MS",
            "cs.NA",
            "stat.ML"
        ]
    },
    {
        "title": "Portable high-order finite element kernels I: Streaming Operations",
        "authors": [
            "Noel Chalmers",
            "Tim Warburton"
        ],
        "summary": "This paper is devoted to the development of highly efficient kernels performing vector operations relevant in linear system solvers. In particular, we focus on the low arithmetic intensity operations (i.e., streaming operations) performed within the conjugate gradient iterative method, using the parameters specified in the CEED benchmark problems for high-order hexahedral finite elements. We propose a suite of new Benchmark Streaming tests to focus on the distinct streaming operations which must be performed. We implemented these new tests using the OCCA abstraction framework to demonstrate portability of these streaming operations on different GPU architectures, and propose a simple performance model for such kernels which can accurately capture data movement rates as well as kernel launch costs.",
        "published": "2020-09-23T03:11:10Z",
        "link": "http://arxiv.org/abs/2009.10917v1",
        "categories": [
            "cs.MS",
            "cs.DC",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "A compute-bound formulation of Galerkin model reduction for linear   time-invariant dynamical systems",
        "authors": [
            "Francesco Rizzi",
            "Eric J. Parish",
            "Patrick J. Blonigan",
            "John Tencer"
        ],
        "summary": "This work aims to advance computational methods for projection-based reduced order models (ROMs) of linear time-invariant (LTI) dynamical systems. For such systems, current practice relies on ROM formulations expressing the state as a rank-1 tensor (i.e., a vector), leading to computational kernels that are memory bandwidth bound and, therefore, ill-suited for scalable performance on modern many-core and hybrid computing nodes. This weakness can be particularly limiting when tackling many-query studies, where one needs to run a large number of simulations. This work introduces a reformulation, called rank-2 Galerkin, of the Galerkin ROM for LTI dynamical systems which converts the nature of the ROM problem from memory bandwidth to compute bound. We present the details of the formulation and its implementation, and demonstrate its utility through numerical experiments using, as a test case, the simulation of elastic seismic shear waves in an axisymmetric domain. We quantify and analyze performance and scaling results for varying numbers of threads and problem sizes. Finally, we present an end-to-end demonstration of using the rank-2 Galerkin ROM for a Monte Carlo sampling study. We show that the rank-2 Galerkin ROM is one order of magnitude more efficient than the rank-1 Galerkin ROM (the current practice) and about 970X more efficient than the full order model, while maintaining accuracy in both the mean and statistics of the field.",
        "published": "2020-09-24T15:06:00Z",
        "link": "http://arxiv.org/abs/2009.11742v3",
        "categories": [
            "physics.comp-ph",
            "cs.CE",
            "cs.DC",
            "cs.MS",
            "math.DS"
        ]
    },
    {
        "title": "AMReX: Block-Structured Adaptive Mesh Refinement for Multiphysics   Applications",
        "authors": [
            "Weiqun Zhang",
            "Andrew Myers",
            "Kevin Gott",
            "Ann Almgren",
            "John Bell"
        ],
        "summary": "Block-structured adaptive mesh refinement (AMR) provides the basis for the temporal and spatial discretization strategy for a number of ECP applications in the areas of accelerator design, additive manufacturing, astrophysics, combustion, cosmology, multiphase flow, and wind plant modelling. AMReX is a software framework that provides a unified infrastructure with the functionality needed for these and other AMR applications to be able to effectively and efficiently utilize machines from laptops to exascale architectures. AMR reduces the computational cost and memory footprint compared to a uniform mesh while preserving accurate descriptions of different physical processes in complex multi-physics algorithms. AMReX supports algorithms that solve systems of partial differential equations (PDEs) in simple or complex geometries, and those that use particles and/or particle-mesh operations to represent component physical processes. In this paper, we will discuss the core elements of the AMReX framework such as data containers and iterators as well as several specialized operations to meet the needs of the application projects. In addition we will highlight the strategy that the AMReX team is pursuing to achieve highly performant code across a range of accelerator-based architectures for a variety of different applications.",
        "published": "2020-09-25T02:59:30Z",
        "link": "http://arxiv.org/abs/2009.12009v1",
        "categories": [
            "cs.MS",
            "cs.CE",
            "cs.DC"
        ]
    },
    {
        "title": "Compressed Basis GMRES on High Performance GPUs",
        "authors": [
            "José I. Aliaga",
            "Hartwig Anzt",
            "Thomas Grützmacher",
            "Enrique S. Quintana-Ortí",
            "Andrés E. Tomás"
        ],
        "summary": "Krylov methods provide a fast and highly parallel numerical tool for the iterative solution of many large-scale sparse linear systems. To a large extent, the performance of practical realizations of these methods is constrained by the communication bandwidth in all current computer architectures, motivating the recent investigation of sophisticated techniques to avoid, reduce, and/or hide the message-passing costs (in distributed platforms) and the memory accesses (in all architectures).   This paper introduces a new communication-reduction strategy for the (Krylov) GMRES solver that advocates for decoupling the storage format (i.e., the data representation in memory) of the orthogonal basis from the arithmetic precision that is employed during the operations with that basis. Given that the execution time of the GMRES solver is largely determined by the memory access, the datatype transforms can be mostly hidden, resulting in the acceleration of the iterative step via a lower volume of bits being retrieved from memory. Together with the special properties of the orthonormal basis (whose elements are all bounded by 1), this paves the road toward the aggressive customization of the storage format, which includes some floating point as well as fixed point formats with little impact on the convergence of the iterative process.   We develop a high performance implementation of the \"compressed basis GMRES\" solver in the Ginkgo sparse linear algebra library and using a large set of test problems from the SuiteSparse matrix collection we demonstrate robustness and performance advantages on a modern NVIDIA V100 GPU of up to 50% over the standard GMRES solver that stores all data in IEEE double precision.",
        "published": "2020-09-25T09:37:38Z",
        "link": "http://arxiv.org/abs/2009.12101v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "Flexible Performant GEMM Kernels on GPUs",
        "authors": [
            "Thomas Faingnaert",
            "Tim Besard",
            "Bjorn De Sutter"
        ],
        "summary": "General Matrix Multiplication or GEMM kernels take centre place in high performance computing and machine learning. Recent NVIDIA GPUs include GEMM accelerators, such as NVIDIA's Tensor Cores. Their exploitation is hampered by the two-language problem: it requires either low-level programming which implies low programmer productivity or using libraries that only offer a limited set of components. Because rephrasing algorithms in terms of established components often introduces overhead, the libraries' lack of flexibility limits the freedom to explore new algorithms. Researchers using GEMMs can hence not enjoy programming productivity, high performance, and research flexibility at once.   In this paper we solve this problem. We present three sets of abstractions and interfaces to program GEMMs within the scientific Julia programming language. The interfaces and abstractions are co-designed for researchers' needs and Julia's features to achieve sufficient separation of concerns and flexibility to easily extend basic GEMMs in many different ways without paying a performance price. Comparing our GEMMs to state-of-the-art libraries cuBLAS and CUTLASS, we demonstrate that our performance is in the same ballpark of the libraries, and in some cases even exceeds it, without having to write a single line of code in CUDA C++ or assembly, and without facing flexibility limitations.",
        "published": "2020-09-25T14:29:08Z",
        "link": "http://arxiv.org/abs/2009.12263v4",
        "categories": [
            "cs.MS",
            "cs.DC",
            "cs.LG",
            "cs.PF"
        ]
    },
    {
        "title": "Extendible and Efficient Python Framework for Solving Evolution   Equations with Stabilized Discontinuous Galerkin Method",
        "authors": [
            "Andreas Dedner",
            "Robert Klöfkorn"
        ],
        "summary": "This paper discusses a Python interface for the recently published DUNE-FEM-DG module which provides highly efficient implementations of the Discontinuous Galerkin (DG) method for solving a wide range of non linear partial differential equations (PDE). Although the C++ interfaces of DUNE-FEM-DG are highly flexible and customizable, a solid knowledge of C++ is necessary to make use of this powerful tool. With this work easier user interfaces based on Python and the Unified Form Language are provided to open DUNE-FEM-DG for a broader audience. The Python interfaces are demonstrated for both parabolic and first order hyperbolic PDEs.",
        "published": "2020-09-25T16:23:57Z",
        "link": "http://arxiv.org/abs/2009.13416v2",
        "categories": [
            "cs.MS",
            "cs.DC",
            "cs.NA",
            "math.NA",
            "physics.comp-ph",
            "65M08, 65M60, 35Q31, 35Q90, 68N99"
        ]
    },
    {
        "title": "Regressor: A C program for Combinatorial Regressions",
        "authors": [
            "Eduardo M. Vasconcelos",
            "Adriano Gouveia de Souza"
        ],
        "summary": "In statistics, researchers use Regression models for data analysis and prediction in many productive sectors (industry, business, academy, etc.). Regression models are mathematical functions representing an approximation of dependent variable $Y$ from n independent variables $X_i \\in X$. The literature presents many regression methods divided into single and multiple regressions. There are several procedures to generate regression models and sets of commercial and academic tools that implement these procedures. This work presents one open-source program called Regressor that makes models from a specific variation of polynomial regression. These models relate the independent variables to generate an approximation of the original output dependent data. In many tests, Regressor was able to build models five times more accurate than commercial tools.",
        "published": "2020-09-25T18:10:14Z",
        "link": "http://arxiv.org/abs/2009.12386v1",
        "categories": [
            "stat.AP",
            "cs.MS"
        ]
    },
    {
        "title": "A highly scalable approach to solving linear systems using two-stage   multisplitting",
        "authors": [
            "Nick Brown",
            "J. Mark Bull",
            "Iain Bethune"
        ],
        "summary": "Iterative methods for solving large sparse systems of linear equations are widely used in many HPC applications. Extreme scaling of these methods can be difficult, however, since global communication to form dot products is typically required at every iteration.   To try to overcome this limitation we propose a hybrid approach, where the matrix is partitioned into blocks. Within each block, we use a highly optimised (parallel) conventional solver, but we then couple the blocks together using block Jacobi or some other multisplitting technique that can be implemented in either a synchronous or an asynchronous fashion. This allows us to limit the block size to the point where the conventional iterative methods no longer scale, and to avoid global communication (and possibly synchronisation) across all processes.   Our block framework has been built to use PETSc, a popular scientific suite for solving sparse linear systems, as the synchronous intra-block solver, and we demonstrate results on up to 32768 cores of a Cray XE6 system. At this scale, the conventional solvers are still more efficient, though trends suggest that the hybrid approach may be beneficial at higher core counts.",
        "published": "2020-09-26T16:44:34Z",
        "link": "http://arxiv.org/abs/2009.12638v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "BOML: A Modularized Bilevel Optimization Library in Python for Meta   Learning",
        "authors": [
            "Yaohua Liu",
            "Risheng Liu"
        ],
        "summary": "Meta-learning (a.k.a. learning to learn) has recently emerged as a promising paradigm for a variety of applications. There are now many meta-learning methods, each focusing on different modeling aspects of base and meta learners, but all can be (re)formulated as specific bilevel optimization problems. This work presents BOML, a modularized optimization library that unifies several meta-learning algorithms into a common bilevel optimization framework. It provides a hierarchical optimization pipeline together with a variety of iteration modules, which can be used to solve the mainstream categories of meta-learning methods, such as meta-feature-based and meta-initialization-based formulations. The library is written in Python and is available at https://github.com/dut-media-lab/BOML.",
        "published": "2020-09-28T14:21:55Z",
        "link": "http://arxiv.org/abs/2009.13357v1",
        "categories": [
            "cs.LG",
            "cs.MS",
            "stat.ML"
        ]
    },
    {
        "title": "Accelerating Sparse Matrix-Matrix Multiplication with GPU Tensor Cores",
        "authors": [
            "Orestis Zachariadis",
            "Nitin Satpute",
            "Juan Gómez-Luna",
            "Joaquín Olivares"
        ],
        "summary": "Sparse general matrix-matrix multiplication (spGEMM) is an essential component in many scientific and data analytics applications. However, the sparsity pattern of the input matrices and the interaction of their patterns make spGEMM challenging. Modern GPUs include Tensor Core Units (TCUs), which specialize in dense matrix multiplication. Our aim is to re-purpose TCUs for sparse matrices. The key idea of our spGEMM algorithm, tSparse, is to multiply sparse rectangular blocks using the mixed precision mode of TCUs. tSparse partitions the input matrices into tiles and operates only on tiles which contain one or more elements. It creates a task list of the tiles, and performs matrix multiplication of these tiles using TCUs. To the best of our knowledge, this is the first time that TCUs are used in the context of spGEMM. We show that spGEMM, with our tiling approach, benefits from TCUs. Our approach significantly improves the performance of spGEMM in comparison to cuSPARSE, CUSP, RMerge2, Nsparse, AC-SpGEMM and spECK.",
        "published": "2020-09-29T14:10:15Z",
        "link": "http://arxiv.org/abs/2009.14600v1",
        "categories": [
            "cs.MS",
            "cs.DC",
            "cs.PF"
        ]
    },
    {
        "title": "ParaMonte: A high-performance serial/parallel Monte Carlo simulation   library for C, C++, Fortran",
        "authors": [
            "Amir Shahmoradi",
            "Fatemeh Bagheri"
        ],
        "summary": "ParaMonte (standing for Parallel Monte Carlo) is a serial and MPI/Coarray-parallelized library of Monte Carlo routines for sampling mathematical objective functions of arbitrary-dimensions, in particular, the posterior distributions of Bayesian models in data science, Machine Learning, and scientific inference. The ParaMonte library has been developed with the design goal of unifying the **automation**, **accessibility**, **high-performance**, **scalability**, and **reproducibility** of Monte Carlo simulations. The current implementation of the library includes **ParaDRAM**, a **Para**llel **D**elyaed-**R**ejection **A**daptive **M**etropolis Markov Chain Monte Carlo sampler, accessible from a wide range of programming languages including C, C++, Fortran, with a unified Application Programming Interface and simulation environment across all supported programming languages. The ParaMonte library is MIT-licensed and is permanently located and maintained at [https://github.com/cdslaborg/paramonte](https://github.com/cdslaborg/paramonte).",
        "published": "2020-09-29T18:04:02Z",
        "link": "http://arxiv.org/abs/2009.14229v1",
        "categories": [
            "cs.MS",
            "astro-ph.IM",
            "physics.data-an",
            "q-bio.QM",
            "stat.ML"
        ]
    },
    {
        "title": "Scipp: Scientific data handling with labeled multi-dimensional arrays   for C++ and Python",
        "authors": [
            "Simon Heybrock",
            "Owen Arnold",
            "Igor Gudich",
            "Daniel Nixon",
            "Neil Vaytet"
        ],
        "summary": "Scipp is heavily inspired by the Python library xarray. It enriches raw NumPy-like multi-dimensional arrays of data by adding named dimensions and associated coordinates. Multiple arrays are combined into datasets. On top of this, scipp introduces (i) implicit handling of physical units, (ii) implicit propagation of uncertainties, (iii) support for histograms, i.e., bin-edge coordinate axes, which exceed the data's dimension extent by one, and (iv) support for event data. In conjunction these features enable a more natural and more concise user experience. The combination of named dimensions, coordinates, and units helps to drastically reduce the risk for programming errors. The core of scipp is written in C++ to open opportunities for performance improvements that a Python-based solution would not allow for. On top of the C++ core, scipp's Python components provide functionality for plotting and content representations, e.g., for use in Jupyter Notebooks. While none of scipp's concepts in isolation is novel per-se, we are not aware of any project combining all of these aspects in a single coherent software package.",
        "published": "2020-10-01T08:59:03Z",
        "link": "http://arxiv.org/abs/2010.00257v1",
        "categories": [
            "cs.MS",
            "physics.data-an",
            "physics.ins-det"
        ]
    },
    {
        "title": "Fast fully-reproducible serial/parallel Monte Carlo and MCMC simulations   and visualizations via ParaMonte::Python library",
        "authors": [
            "Amir Shahmoradi",
            "Fatemeh Bagheri",
            "Joshua Alexander Osborne"
        ],
        "summary": "ParaMonte::Python (standing for Parallel Monte Carlo in Python) is a serial and MPI-parallelized library of (Markov Chain) Monte Carlo (MCMC) routines for sampling mathematical objective functions, in particular, the posterior distributions of parameters in Bayesian modeling and analysis in data science, Machine Learning, and scientific inference in general. In addition to providing access to fast high-performance serial/parallel Monte Carlo and MCMC sampling routines, the ParaMonte::Python library provides extensive post-processing and visualization tools that aim to automate and streamline the process of model calibration and uncertainty quantification in Bayesian data analysis. Furthermore, the automatically-enabled restart functionality of ParaMonte::Python samplers ensure seamless fully-deterministic into-the-future restart of Monte Carlo simulations, should any interruptions happen. The ParaMonte::Python library is MIT-licensed and is permanently maintained on GitHub at https://github.com/cdslaborg/paramonte/tree/master/src/interface/Python.",
        "published": "2020-10-01T23:26:42Z",
        "link": "http://arxiv.org/abs/2010.00724v1",
        "categories": [
            "cs.MS",
            "astro-ph.IM",
            "q-bio.QM",
            "stat.ML"
        ]
    },
    {
        "title": "Simflowny 3: An upgraded platform for scientific modelling and   simulation",
        "authors": [
            "C. Palenzuela",
            "B. Miñano",
            "A. Arbona",
            "C. Bona-Casas",
            "C. Bona",
            "J. Massó"
        ],
        "summary": "Simflowny is an open platform which automatically generates efficient parallel code of scientific dynamical models for different simulation frameworks. Here we present major upgrades on this software to support simultaneously a quite generic family of partial differential equations. These equations can be discretized using: (i) standard finite-difference for systems with derivatives up to any order, (ii) High-Resolution-Shock-Capturing methods to deal with shocks and discontinuities of balance law equations, and (iii) particle-based methods. We have improved the adaptive-mesh-refinement algorithms to preserve the convergence order of the numerical methods, which is a requirement for improving scalability. Finally, we have also extended our graphical user interface (GUI) to accommodate these and future families of equations. This paper summarizes the formal representation and implementation of these new families, providing several validation results.",
        "published": "2020-10-02T10:04:30Z",
        "link": "http://arxiv.org/abs/2010.00902v1",
        "categories": [
            "physics.comp-ph",
            "cs.MS"
        ]
    },
    {
        "title": "Instead of Rewriting Foreign Code for Machine Learning, Automatically   Synthesize Fast Gradients",
        "authors": [
            "William S. Moses",
            "Valentin Churavy"
        ],
        "summary": "Applying differentiable programming techniques and machine learning algorithms to foreign programs requires developers to either rewrite their code in a machine learning framework, or otherwise provide derivatives of the foreign code. This paper presents Enzyme, a high-performance automatic differentiation (AD) compiler plugin for the LLVM compiler framework capable of synthesizing gradients of statically analyzable programs expressed in the LLVM intermediate representation (IR). Enzyme synthesizes gradients for programs written in any language whose compiler targets LLVM IR including C, C++, Fortran, Julia, Rust, Swift, MLIR, etc., thereby providing native AD capabilities in these languages. Unlike traditional source-to-source and operator-overloading tools, Enzyme performs AD on optimized IR. On a machine-learning focused benchmark suite including Microsoft's ADBench, AD on optimized IR achieves a geometric mean speedup of 4.5x over AD on IR before optimization allowing Enzyme to achieve state-of-the-art performance. Packaging Enzyme for PyTorch and TensorFlow provides convenient access to gradients of foreign code with state-of-the art performance, enabling foreign code to be directly incorporated into existing machine learning workflows.",
        "published": "2020-10-04T22:32:51Z",
        "link": "http://arxiv.org/abs/2010.01709v1",
        "categories": [
            "cs.MS",
            "cs.AI",
            "cs.LG",
            "cs.PF",
            "cs.PL"
        ]
    },
    {
        "title": "VECMAtk: A Scalable Verification, Validation and Uncertainty   Quantification Toolkit for Scientific Simulations",
        "authors": [
            "D. Groen",
            "H. Arabnejad",
            "V. Jancauskas",
            "W. N. Edeling",
            "F. Jansson",
            "R. A. Richardson",
            "J. Lakhlili",
            "L. Veen",
            "B. Bosak",
            "P. Kopta",
            "D. W. Wright",
            "N. Monnier",
            "P. Karlshoefer",
            "D. Suleimenova",
            "R. Sinclair",
            "M. Vassaux",
            "A. Nikishova",
            "M. Bieniek",
            "O. O. Luk",
            "M. Kulczewski",
            "E. Raffin",
            "D. Crommelin",
            "O. Hoenen",
            "D. P. Coster",
            "T. Piontek",
            "P. V. Coveney"
        ],
        "summary": "We present the VECMA toolkit (VECMAtk), a flexible software environment for single and multiscale simulations that introduces directly applicable and reusable procedures for verification, validation (V&V), sensitivity analysis (SA) and uncertainty quantification (UQ). It enables users to verify key aspects of their applications, systematically compare and validate the simulation outputs against observational or benchmark data, and run simulations conveniently on any platform from the desktop to current multi-petascale computers. In this sequel to our paper on VECMAtk which we presented last year, we focus on a range of functional and performance improvements that we have introduced, cover newly introduced components, and applications examples from seven different domains such as conflict modelling and environmental sciences. We also present several implemented patterns for UQ/SA and V&V, and guide the reader through one example concerning COVID-19 modelling in detail.",
        "published": "2020-10-08T12:08:33Z",
        "link": "http://arxiv.org/abs/2010.03923v2",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "Extending C++ for Heterogeneous Quantum-Classical Computing",
        "authors": [
            "Thien Nguyen",
            "Anthony Santana",
            "Tyler Kharazi",
            "Daniel Claudino",
            "Hal Finkel",
            "Alexander McCaskey"
        ],
        "summary": "We present qcor - a language extension to C++ and compiler implementation that enables heterogeneous quantum-classical programming, compilation, and execution in a single-source context. Our work provides a first-of-its-kind C++ compiler enabling high-level quantum kernel (function) expression in a quantum-language agnostic manner, as well as a hardware-agnostic, retargetable compiler workflow targeting a number of physical and virtual quantum computing backends. qcor leverages novel Clang plugin interfaces and builds upon the XACC system-level quantum programming framework to provide a state-of-the-art integration mechanism for quantum-classical compilation that leverages the best from the community at-large. qcor translates quantum kernels ultimately to the XACC intermediate representation, and provides user-extensible hooks for quantum compilation routines like circuit optimization, analysis, and placement. This work details the overall architecture and compiler workflow for qcor, and provides a number of illuminating programming examples demonstrating its utility for near-term variational tasks, quantum algorithm expression, and feed-forward error correction schemes.",
        "published": "2020-10-08T12:49:07Z",
        "link": "http://arxiv.org/abs/2010.03935v1",
        "categories": [
            "quant-ph",
            "cs.MS"
        ]
    },
    {
        "title": "Concurrent Alternating Least Squares for multiple simultaneous Canonical   Polyadic Decompositions",
        "authors": [
            "Christos Psarras",
            "Lars Karlsson",
            "Rasmus Bro",
            "Paolo Bientinesi"
        ],
        "summary": "Tensor decompositions, such as CANDECOMP/PARAFAC (CP), are widely used in a variety of applications, such as chemometrics, signal processing, and machine learning. A broadly used method for computing such decompositions relies on the Alternating Least Squares (ALS) algorithm. When the number of components is small, regardless of its implementation, ALS exhibits low arithmetic intensity, which severely hinders its performance and makes GPU offloading ineffective. We observe that, in practice, experts often have to compute multiple decompositions of the same tensor, each with a small number of components (typically fewer than 20), to ultimately find the best ones to use for the application at hand. In this paper, we illustrate how multiple decompositions of the same tensor can be fused together at the algorithmic level to increase the arithmetic intensity. Therefore, it becomes possible to make efficient use of GPUs for further speedups; at the same time the technique is compatible with many enhancements typically used in ALS, such as line search, extrapolation, and non-negativity constraints. We introduce the Concurrent ALS algorithm and library, which offers an interface to Matlab, and a mechanism to effectively deal with the issue that decompositions complete at different times. Experimental results on artificial and real datasets demonstrate a shorter time to completion due to increased arithmetic intensity.",
        "published": "2020-10-09T16:55:46Z",
        "link": "http://arxiv.org/abs/2010.04678v2",
        "categories": [
            "cs.MS",
            "cs.LG",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Temporal Vectorization for Stencils",
        "authors": [
            "Liang Yuan",
            "Hang Cao",
            "Yunquan Zhang",
            "Kun Li",
            "Pengqi Lu",
            "Yue Yue"
        ],
        "summary": "Stencil computations represent a very common class of nested loops in scientific and engineering applications. Exploiting vector units in modern CPUs is crucial to achieving peak performance. Previous vectorization approaches often consider the data space, in particular the innermost unit-strided loop. It leads to the well-known data alignment conflict problem that vector loads are overlapped due to the data sharing between continuous stencil computations. This paper proposes a novel temporal vectorization scheme for stencils. It vectorizes the stencil computation in the iteration space and assembles points with different time coordinates in one vector. The temporal vectorization leads to a small fixed number of vector reorganizations that is irrelevant to the vector length, stencil order, and dimension. Furthermore, it is also applicable to Gauss-Seidel stencils, whose vectorization is not well-studied. The effectiveness of the temporal vectorization is demonstrated by various Jacobi and Gauss-Seidel stencils.",
        "published": "2020-10-10T01:47:34Z",
        "link": "http://arxiv.org/abs/2010.04868v1",
        "categories": [
            "cs.MS",
            "cs.PF"
        ]
    },
    {
        "title": "Combining the Mersenne Twister and the Xorgens Designs",
        "authors": [
            "Marcel Van de Vel"
        ],
        "summary": "We combine the design of two \\emph{random number generators}, \\emph{Mersenne Twister} and \\emph{Xorgens}, to obtain a new class of generators with heavy-weight characteristic polynomials (exceeded only by the {\\sc well} generators) and high speed (comparable with the originals). Tables with parameter combinations are included for state sizes ranging from 521 to 44497 bits and each of the word lengths 32, 64, 128. These generators passed all tests of the \\emph{TestU01}-package for each 32-bit integer part and each 64-bit derived real part of the output. We determine \\emph{dimension gaps} for 32-bit words, neglecting the non-linear tempering, and compare with an alternative experimental linear tempering.",
        "published": "2020-10-10T17:50:47Z",
        "link": "http://arxiv.org/abs/2011.07963v1",
        "categories": [
            "cs.DS",
            "cs.MS",
            "math.CO",
            "11K45, 12E05, 12E20"
        ]
    },
    {
        "title": "CAPD::DynSys: a flexible C++ toolbox for rigorous numerical analysis of   dynamical systems",
        "authors": [
            "Tomasz Kapela",
            "Marian Mrozek",
            "Daniel Wilczak",
            "Piotr Zgliczyński"
        ],
        "summary": "We present the CAPD::DynSys library for rigorous numerical analysis of dynamical systems. The basic interface is described together with several interesting case studies illustrating how it can be used for computer-assisted proofs in dynamics of ODEs.",
        "published": "2020-10-14T13:53:54Z",
        "link": "http://arxiv.org/abs/2010.07097v1",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "math.DS"
        ]
    },
    {
        "title": "DSLib: An open source library for the dominant set clustering method",
        "authors": [
            "Sebastiano Vascon",
            "Samuel Rota Bulò",
            "Vittorio Murino",
            "Marcello Pelillo"
        ],
        "summary": "DSLib is an open-source implementation of the Dominant Set (DS) clustering algorithm written entirely in Matlab. The DS method is a graph-based clustering technique rooted in the evolutionary game theory that starts gaining lots of interest in the computer science community. Thanks to its duality with game theory and its strict relation to the notion of maximal clique, has been explored in several directions not only related to clustering problems. Applications in graph matching, segmentation, classification and medical imaging are common in literature. This package provides an implementation of the original DS clustering algorithm since no code has been officially released yet, together with a still growing collection of methods and variants related to it. Our library is integrable into a Matlab pipeline without dependencies, it is simple to use and easily extendable for upcoming works. The latest source code, the documentation and some examples can be downloaded from https://xwasco.github.io/DominantSetLibrary.",
        "published": "2020-10-15T17:36:48Z",
        "link": "http://arxiv.org/abs/2010.07906v1",
        "categories": [
            "cs.MS",
            "cs.LG"
        ]
    },
    {
        "title": "The Polylogarithm Function in Julia",
        "authors": [
            "Matthew Roughan"
        ],
        "summary": "The polylogarithm function is one of the constellation of important mathematical functions. It has a long history, and many connections to other special functions and series, and many applications, for instance in statistical physics. However, the practical aspects of its numerical evaluation have not received the type of comprehensive treatments lavished on its siblings. Only a handful of formal publications consider the evaluation of the function, and most focus on a specific domain and/or presume arbitrary precision arithmetic will be used. And very little of the literature contains any formal validation of numerical performance. In this paper we present an algorithm for calculating polylogarithms for both complex parameter and argument and evaluate it thoroughly in comparison to the arbitrary precision implementation in Mathematica. The implementation was created in a new scientific computing language Julia, which is ideal for the purpose, but also allows us to write the code in a simple, natural manner so as to make it easy to port the implementation to other such languages.",
        "published": "2020-10-16T06:35:17Z",
        "link": "http://arxiv.org/abs/2010.09860v1",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "33E20, 33F05, 65B10"
        ]
    },
    {
        "title": "Temporal blocking of finite-difference stencil operators with sparse   \"off-the-grid\" sources",
        "authors": [
            "George Bisbas",
            "Fabio Luporini",
            "Mathias Louboutin",
            "Rhodri Nelson",
            "Gerard Gorman",
            "Paul H. J. Kelly"
        ],
        "summary": "Stencil kernels dominate a range of scientific applications, including seismic and medical imaging, image processing, and neural networks. Temporal blocking is a performance optimization that aims to reduce the required memory bandwidth of stencil computations by re-using data from the cache for multiple time steps. It has already been shown to be beneficial for this class of algorithms. However, applying temporal blocking to practical applications' stencils remains challenging. These computations often consist of sparsely located operators not aligned with the computational grid (\"off-the-grid\"). Our work is motivated by modeling problems in which source injections result in wavefields that must then be measured at receivers by interpolation from the grided wavefield. The resulting data dependencies make the adoption of temporal blocking much more challenging. We propose a methodology to inspect these data dependencies and reorder the computation, leading to performance gains in stencil codes where temporal blocking has not been applicable. We implement this novel scheme in the Devito domain-specific compiler toolchain. Devito implements a domain-specific language embedded in Python to generate optimized partial differential equation solvers using the finite-difference method from high-level symbolic problem definitions. We evaluate our scheme using isotropic acoustic, anisotropic acoustic, and isotropic elastic wave propagators of industrial significance. After auto-tuning, performance evaluation shows that this enables substantial performance improvement through temporal blocking over highly-optimized vectorized spatially-blocked code of up to 1.6x.",
        "published": "2020-10-20T13:20:07Z",
        "link": "http://arxiv.org/abs/2010.10248v2",
        "categories": [
            "cs.DC",
            "cs.MS",
            "cs.PF"
        ]
    },
    {
        "title": "LightSeq: A High Performance Inference Library for Transformers",
        "authors": [
            "Xiaohui Wang",
            "Ying Xiong",
            "Yang Wei",
            "Mingxuan Wang",
            "Lei Li"
        ],
        "summary": "Transformer, BERT and their variants have achieved great success in natural language processing. Since Transformer models are huge in size, serving these models is a challenge for real industrial applications. In this paper, we propose LightSeq, a highly efficient inference library for models in the Transformer family. LightSeq includes a series of GPU optimization techniques to to streamline the computation of neural layers and to reduce memory footprint. LightSeq can easily import models trained using PyTorch and Tensorflow. Experimental results on machine translation benchmarks show that LightSeq achieves up to 14x speedup compared with TensorFlow and 1.4x compared with FasterTransformer, a concurrent CUDA implementation. The code is available at https://github.com/bytedance/lightseq.",
        "published": "2020-10-23T13:45:26Z",
        "link": "http://arxiv.org/abs/2010.13887v4",
        "categories": [
            "cs.MS",
            "cs.LG"
        ]
    },
    {
        "title": "Parallelizing multiple precision Taylor series method for integrating   the Lorenz system",
        "authors": [
            "I. Hristov",
            "R. Hristova",
            "S. Dimova",
            "P. Armyanov",
            "N. Shegunov",
            "I. Puzynin",
            "T. Puzynina",
            "Z. Sharipov",
            "Z. Tukhliev"
        ],
        "summary": "A hybrid MPI+OpenMP strategy for parallelizing multiple precision Taylor series method is proposed, realized and tested. To parallelize the algorithm we combine MPI and OpenMP parallel technologies together with GMP library (GNU miltiple precision libary) and the tiny MPIGMP library. The details of the parallelization are explained on the paradigmatic model of the Lorenz system. We succeed to obtain a correct reference solution in the rather long time interval - [0,7000]. The solution is verified by comparing the results for 2700-th order Taylor series method and precision of ~ 3374 decimal digits, and those with 2800-th order and precision of ~ 3510 decimal digits. With 192 CPU cores in Nestum cluster, Sofia, Bulgaria, the 2800-th order computation was ~ 145 hours with speedup ~ 105.",
        "published": "2020-10-26T09:28:08Z",
        "link": "http://arxiv.org/abs/2010.14993v3",
        "categories": [
            "cs.MS",
            "cs.DC",
            "cs.NA",
            "math.DS",
            "math.NA",
            "65L05, 65Y05",
            "G.1.7; G.1.0"
        ]
    },
    {
        "title": "Textbook efficiency: massively parallel matrix-free multigrid for the   Stokes system",
        "authors": [
            "Nils Kohl",
            "Ulrich Rüde"
        ],
        "summary": "We employ textbook multigrid efficiency (TME), as introduced by Achi Brandt, to construct an asymptotically optimal monolithic multigrid solver for the Stokes system. The geometric multigrid solver builds upon the concept of hierarchical hybrid grids (HHG), which is extended to higher-order finite-element discretizations, and a corresponding matrix-free implementation. The computational cost of the full multigrid (FMG) iteration is quantified, and the solver is applied to multiple benchmark problems. Through a parameter study, we suggest configurations that achieve TME for both, stabilized equal-order, and Taylor-Hood discretizations. The excellent node-level performance of the relevant compute kernels is presented via a roofline analysis. Finally, we demonstrate the weak and strong scalability to up to $147,456$ parallel processes and solve Stokes systems with more than $3.6 \\times 10^{12}$ (trillion) unknowns.",
        "published": "2020-10-26T12:11:55Z",
        "link": "http://arxiv.org/abs/2010.13513v1",
        "categories": [
            "cs.CE",
            "cs.MS",
            "cs.NA",
            "math.NA",
            "65F10, 65N30, 65N55"
        ]
    },
    {
        "title": "A comparison of techniques for solving the Poisson equation in CFD",
        "authors": [
            "Nick Brown"
        ],
        "summary": "CFD is a ubiquitous technique central to much of computational simulation such as that required by aircraft design. Solving of the Poisson equation occurs frequently in CFD and there are a number of possible approaches one may leverage. The dynamical core of the MONC atmospheric model is one example of CFD which requires the solving of the Poisson equation to determine pressure terms. Traditionally this aspect of the model has been very time consuming and-so it is important to consider how we might reduce the runtime cost.   In this paper we survey the different approaches implemented in MONC to perform the pressure solve. Designed to take advantage of large scale, modern, HPC machines, we are concerned with the computation and communication behaviour of the available techniques and in this text we focus on direct FFT and indirect iterative methods. In addition to describing the implementation of these techniques we illustrate on up to 32768 processor cores of a Cray XC30 both the performance and scalability of our approaches. Raw runtime is not the only measure so we also make some comments around the stability and accuracy of solution. The result of this work are a number of techniques, optimised for large scale HPC systems, and an understanding of which is most appropriate in different situations.",
        "published": "2020-10-27T08:43:53Z",
        "link": "http://arxiv.org/abs/2010.14132v1",
        "categories": [
            "cs.DC",
            "cs.MS"
        ]
    },
    {
        "title": "Generalized eigen, singular value, and partial least squares   decompositions: The GSVD package",
        "authors": [
            "Derek Beaton"
        ],
        "summary": "The generalized singular value decomposition (GSVD, a.k.a. \"SVD triplet\", \"duality diagram\" approach) provides a unified strategy and basis to perform nearly all of the most common multivariate analyses (e.g., principal components, correspondence analysis, multidimensional scaling, canonical correlation, partial least squares). Though the GSVD is ubiquitous, powerful, and flexible, it has very few implementations. Here I introduce the GSVD package for R. The general goal of GSVD is to provide a small set of accessible functions to perform the GSVD and two other related decompositions (generalized eigenvalue decomposition, generalized partial least squares-singular value decomposition). Furthermore, GSVD helps provide a more unified conceptual approach and nomenclature to many techniques. I first introduce the concept of the GSVD, followed by a formal definition of the generalized decompositions. Next I provide some key decisions made during development, and then a number of examples of how to use GSVD to implement various statistical techniques. These examples also illustrate one of the goals of GSVD: how others can (or should) build analysis packages that depend on GSVD. Finally, I discuss the possible future of GSVD.",
        "published": "2020-10-28T03:57:27Z",
        "link": "http://arxiv.org/abs/2010.14734v3",
        "categories": [
            "cs.MS",
            "cs.LG",
            "stat.CO",
            "stat.ME"
        ]
    },
    {
        "title": "DistStat.jl: Towards Unified Programming for High-Performance   Statistical Computing Environments in Julia",
        "authors": [
            "Seyoon Ko",
            "Hua Zhou",
            "Jin Zhou",
            "Joong-Ho Won"
        ],
        "summary": "The demand for high-performance computing (HPC) is ever-increasing for everyday statistical computing purposes. The downside is that we need to write specialized code for each HPC environment. CPU-level parallelization needs to be explicitly coded for effective use of multiple nodes in cluster supercomputing environments. Acceleration via graphics processing units (GPUs) requires to write kernel code. The Julia software package DistStat.jl implements a data structure for distributed arrays that work on both multi-node CPU clusters and multi-GPU environments transparently. This package paves a way to developing high-performance statistical software in various HPC environments simultaneously. As a demonstration of the transparency and scalability of the package, we provide applications to large-scale nonnegative matrix factorization, multidimensional scaling, and $\\ell_1$-regularized Cox proportional hazards model on an 8-GPU workstation and a 720-CPU-core virtual cluster in Amazon Web Services (AWS) cloud. As a case in point, we analyze the on-set of type-2 diabetes from the UK Biobank with 400,000 subjects and 500,000 single nucleotide polymorphisms using the $\\ell_1$-regularized Cox proportional hazards model. Fitting a half-million-variate regression model took less than 50 minutes on AWS.",
        "published": "2020-10-30T08:16:47Z",
        "link": "http://arxiv.org/abs/2010.16114v1",
        "categories": [
            "stat.CO",
            "cs.MS"
        ]
    },
    {
        "title": "Toward Performance-Portable PETSc for GPU-based Exascale Systems",
        "authors": [
            "Richard Tran Mills",
            "Mark F. Adams",
            "Satish Balay",
            "Jed Brown",
            "Alp Dener",
            "Matthew Knepley",
            "Scott E. Kruger",
            "Hannah Morgan",
            "Todd Munson",
            "Karl Rupp",
            "Barry F. Smith",
            "Stefano Zampini",
            "Hong Zhang",
            "Junchao Zhang"
        ],
        "summary": "The Portable Extensible Toolkit for Scientific computation (PETSc) library delivers scalable solvers for nonlinear time-dependent differential and algebraic equations and for numerical optimization.The PETSc design for performance portability addresses fundamental GPU accelerator challenges and stresses flexibility and extensibility by separating the programming model used by the application from that used by the library, and it enables application developers to use their preferred programming model, such as Kokkos, RAJA, SYCL, HIP, CUDA, or OpenCL, on upcoming exascale systems. A blueprint for using GPUs from PETSc-based codes is provided, and case studies emphasize the flexibility and high performance achieved on current GPU-based systems.",
        "published": "2020-11-02T04:05:29Z",
        "link": "http://arxiv.org/abs/2011.00715v2",
        "categories": [
            "cs.MS",
            "cs.DC",
            "65F10, 65F50, 68N99, 68W10",
            "G.4"
        ]
    },
    {
        "title": "Solving large number of non-stiff, low-dimensional ordinary differential   equation systems on GPUs and CPUs: performance comparisons of MPGOS, ODEINT   and DifferentialEquations.jl",
        "authors": [
            "Dániel Nagy",
            "Lambert Plavecz",
            "Ferenc Hegedűs"
        ],
        "summary": "In this paper, the performance characteristics of different solution techniques and program packages to solve a large number of independent ordinary differential equation systems is examined. The employed hardware are an Intel Core i7-4820K CPU with 30.4 GFLOPS peak double-precision performance per cores and an Nvidia GeForce Titan Black GPU that has a total of 1707 GFLOPS peak double-precision performance. The tested systems (Lorenz equation, Keller--Miksis equation and a pressure relief valve model) are non-stiff and have low dimension. Thus, the performance of the codes are not limited by memory bandwidth, and Runge--Kutta type solvers are efficient and suitable choices. The tested program packages are MPGOS written in C++ and specialised only for GPUs; ODEINT implemented in C++, which supports execution on both CPUs and GPUs; finally, DifferentialEquations.jl written in Julia that also supports execution on both CPUs and GPUs. Using GPUs, the program package MPGOS is superior. For CPU computations, the ODEINT program package has the best performance.",
        "published": "2020-11-02T09:40:24Z",
        "link": "http://arxiv.org/abs/2011.01740v1",
        "categories": [
            "cs.DC",
            "cs.MS",
            "cs.NA",
            "cs.PF",
            "math.NA"
        ]
    },
    {
        "title": "c-lasso -- a Python package for constrained sparse and robust regression   and classification",
        "authors": [
            "Léo Simpson",
            "Patrick L. Combettes",
            "Christian L. Müller"
        ],
        "summary": "We introduce c-lasso, a Python package that enables sparse and robust linear regression and classification with linear equality constraints. The underlying statistical forward model is assumed to be of the following form: \\[ y = X \\beta + \\sigma \\epsilon \\qquad \\textrm{subject to} \\qquad C\\beta=0 \\] Here, $X \\in \\mathbb{R}^{n\\times d}$is a given design matrix and the vector $y \\in \\mathbb{R}^{n}$ is a continuous or binary response vector. The matrix $C$ is a general constraint matrix. The vector $\\beta \\in \\mathbb{R}^{d}$ contains the unknown coefficients and $\\sigma$ an unknown scale. Prominent use cases are (sparse) log-contrast regression with compositional data $X$, requiring the constraint $1_d^T \\beta = 0$ (Aitchion and Bacon-Shone 1984) and the Generalized Lasso which is a special case of the described problem (see, e.g, (James, Paulson, and Rusmevichientong 2020), Example 3). The c-lasso package provides estimators for inferring unknown coefficients and scale (i.e., perspective M-estimators (Combettes and M\\\"uller 2020a)) of the form \\[ \\min_{\\beta \\in \\mathbb{R}^d, \\sigma \\in \\mathbb{R}_{0}} f\\left(X\\beta - y,{\\sigma} \\right) + \\lambda \\left\\lVert \\beta\\right\\rVert_1 \\qquad \\textrm{subject to} \\qquad C\\beta = 0 \\] for several convex loss functions $f(\\cdot,\\cdot)$. This includes the constrained Lasso, the constrained scaled Lasso, and sparse Huber M-estimators with linear equality constraints.",
        "published": "2020-11-02T11:16:27Z",
        "link": "http://arxiv.org/abs/2011.00898v1",
        "categories": [
            "stat.CO",
            "cs.MS",
            "math.OC",
            "stat.ML"
        ]
    },
    {
        "title": "Tinker-HP : Accelerating Molecular Dynamics Simulations of Large Complex   Systems with Advanced Point Dipole Polarizable Force Fields using GPUs and   Multi-GPUs systems",
        "authors": [
            "Olivier Adjoua",
            "Louis Lagardère",
            "Luc-Henri Jolly",
            "Arnaud Durocher",
            "Thibaut Very",
            "Isabelle Dupays",
            "Zhi Wang",
            "Théo Jaffrelot Inizan",
            "Frédéric Célerse",
            "Pengyu Ren",
            "Jay W. Ponder",
            "Jean-Philip Piquemal"
        ],
        "summary": "We present the extension of the Tinker-HP package (Lagard\\`ere et al., Chem. Sci., 2018,9, 956-972) to the use of Graphics Processing Unit (GPU) cards to accelerate molecular dynamics simulations using polarizable many-body force fields. The new high-performance module allows for an efficient use of single- and multi-GPU architectures ranging from research laboratories to modern supercomputer centers. After detailing an analysis of our general scalable strategy that relies on OpenACC and CUDA, we discuss the various capabilities of the package. Among them, the multi-precision possibilities of the code are discussed. If an efficient double precision implementation is provided to preserve the possibility of fast reference computations, we show that a lower precision arithmetic is preferred providing a similar accuracy for molecular dynamics while exhibiting superior performances. As Tinker-HP is mainly dedicated to accelerate simulations using new generation point dipole polarizable force field, we focus our study on the implementation of the AMOEBA model. Testing various NVIDIA platforms including 2080Ti, 3090, V100 and A100 cards, we provide illustrative benchmarks of the code for single- and multi-cards simulations on large biosystems encompassing up to millions of atoms. The new code strongly reduces time to solution and offers the best performances to date obtained using the AMOEBA polarizable force field. Perspectives toward the strong-scaling performance of our multi-node massive parallelization strategy, unsupervised adaptive sampling and large scale applicability of the Tinker-HP code in biophysics are discussed. The present software has been released in phase advance on GitHub in link with the High Performance Computing community COVID-19 research efforts and is free for Academics (see https://github.com/TinkerTools/tinker-hp).",
        "published": "2020-11-02T18:50:39Z",
        "link": "http://arxiv.org/abs/2011.01207v4",
        "categories": [
            "physics.comp-ph",
            "cs.DC",
            "cs.MS",
            "physics.chem-ph"
        ]
    },
    {
        "title": "Calcium: computing in exact real and complex fields",
        "authors": [
            "Fredrik Johansson"
        ],
        "summary": "Calcium is a C library for real and complex numbers in a form suitable for exact algebraic and symbolic computation. Numbers are represented as elements of fields $\\mathbb{Q}(a_1,\\ldots,a_n)$ where the extensions numbers $a_k$ may be algebraic or transcendental. The system combines efficient field operations with automatic discovery and certification of algebraic relations, resulting in a practical computational model of $\\mathbb{R}$ and $\\mathbb{C}$ in which equality is rigorously decidable for a large class of numbers.",
        "published": "2020-11-03T14:22:18Z",
        "link": "http://arxiv.org/abs/2011.01728v1",
        "categories": [
            "cs.MS",
            "cs.SC"
        ]
    },
    {
        "title": "Improving the Performance of the GMRES Method using Mixed-Precision   Techniques",
        "authors": [
            "Neil Lindquist",
            "Piotr Luszczek",
            "Jack Dongarra"
        ],
        "summary": "The GMRES method is used to solve sparse, non-symmetric systems of linear equations arising from many scientific applications. The solver performance within a single node is memory bound, due to the low arithmetic intensity of its computational kernels. To reduce the amount of data movement, and thus, to improve performance, we investigated the effect of using a mix of single and double precision while retaining double-precision accuracy. Previous efforts have explored reduced precision in the preconditioner, but the use of reduced precision in the solver itself has received limited attention. We found that GMRES only needs double precision in computing the residual and updating the approximate solution to achieve double-precision accuracy, although it must restart after each improvement of single-precision accuracy. This finding holds for the tested orthogonalization schemes: Modified Gram-Schmidt (MGS) and Classical Gram-Schmidt with Re-orthogonalization (CGSR). Furthermore, our mixed-precision GMRES, when restarted at least once, performed 19% and 24% faster on average than double-precision GMRES for MGS and CGSR, respectively. Our implementation uses generic programming techniques to ease the burden of coding implementations for different data types. Our use of the Kokkos library allowed us to exploit parallelism and optimize data management. Additionally, KokkosKernels was used when producing performance results. In conclusion, using a mix of single and double precision in GMRES can improve performance while retaining double-precision accuracy.",
        "published": "2020-11-03T17:12:35Z",
        "link": "http://arxiv.org/abs/2011.01850v1",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "Extending the statistical software package Engine for Likelihood-Free   Inference",
        "authors": [
            "Vasileios Gkolemis",
            "Michael Gutmann"
        ],
        "summary": "Bayesian inference is a principled framework for dealing with uncertainty. The practitioner can perform an initial assumption for the physical phenomenon they want to model (prior belief), collect some data and then adjust the initial assumption in the light of the new evidence (posterior belief). Approximate Bayesian Computation (ABC) methods, also known as likelihood-free inference techniques, are a class of models used for performing inference when the likelihood is intractable. The unique requirement of these models is a black-box sampling machine. Due to the modelling-freedom they provide these approaches are particularly captivating. Robust Optimisation Monte Carlo (ROMC) is one of the most recent techniques of the specific domain. It approximates the posterior distribution by solving independent optimisation problems. This dissertation focuses on the implementation of the ROMC method in the software package Engine for Likelihood-Free Inference (ELFI). In the first chapters, we provide the mathematical formulation and the algorithmic description of the ROMC approach. In the following chapters, we describe our implementation; (a) we present all the functionalities provided to the user and (b) we demonstrate how to perform inference on some real examples. Our implementation provides a robust and efficient solution to a practitioner who wants to perform inference on a simulator-based model. Furthermore, it exploits parallel processing for accelerating the inference wherever it is possible. Finally, it has been designed to serve extensibility; the user can easily replace specific subparts of the method without significant overhead on the development side. Therefore, it can be used by a researcher for further experimentation.",
        "published": "2020-11-08T13:22:37Z",
        "link": "http://arxiv.org/abs/2011.03977v1",
        "categories": [
            "cs.LG",
            "cs.MS"
        ]
    },
    {
        "title": "DoWhy: An End-to-End Library for Causal Inference",
        "authors": [
            "Amit Sharma",
            "Emre Kiciman"
        ],
        "summary": "In addition to efficient statistical estimators of a treatment's effect, successful application of causal inference requires specifying assumptions about the mechanisms underlying observed data and testing whether they are valid, and to what extent. However, most libraries for causal inference focus only on the task of providing powerful statistical estimators. We describe DoWhy, an open-source Python library that is built with causal assumptions as its first-class citizens, based on the formal framework of causal graphs to specify and test causal assumptions. DoWhy presents an API for the four steps common to any causal analysis---1) modeling the data using a causal graph and structural assumptions, 2) identifying whether the desired effect is estimable under the causal model, 3) estimating the effect using statistical estimators, and finally 4) refuting the obtained estimate through robustness checks and sensitivity analyses. In particular, DoWhy implements a number of robustness checks including placebo tests, bootstrap tests, and tests for unoberved confounding. DoWhy is an extensible library that supports interoperability with other implementations, such as EconML and CausalML for the the estimation step. The library is available at https://github.com/microsoft/dowhy",
        "published": "2020-11-09T06:22:11Z",
        "link": "http://arxiv.org/abs/2011.04216v1",
        "categories": [
            "stat.ME",
            "cs.AI",
            "cs.MS",
            "econ.EM"
        ]
    },
    {
        "title": "tvopt: A Python Framework for Time-Varying Optimization",
        "authors": [
            "Nicola Bastianello"
        ],
        "summary": "This paper introduces tvopt, a Python framework for prototyping and benchmarking time-varying (or online) optimization algorithms. The paper first describes the theoretical approach that informed the development of tvopt. Then it discusses the different components of the framework and their use for modeling and solving time-varying optimization problems. In particular, tvopt provides functionalities for defining both centralized and distributed online problems, and a collection of built-in algorithms to solve them, for example gradient-based methods, ADMM and other splitting methods. Moreover, the framework implements prediction strategies to improve the accuracy of the online solvers. The paper then proposes some numerical results on a benchmark problem and discusses their implementation using tvopt. The code for tvopt is available at https://github.com/nicola-bastianello/tvopt.",
        "published": "2020-11-12T16:14:09Z",
        "link": "http://arxiv.org/abs/2011.07119v2",
        "categories": [
            "cs.MS",
            "cs.LG",
            "math.OC"
        ]
    },
    {
        "title": "RCHOL: Randomized Cholesky Factorization for Solving SDD Linear Systems",
        "authors": [
            "Chao Chen",
            "Tianyu Liang",
            "George Biros"
        ],
        "summary": "We introduce a randomized algorithm, namely RCHOL, to construct an approximate Cholesky factorization for a given Laplacian matrix (a.k.a., graph Laplacian). From a graph perspective, the exact Cholesky factorization introduces a clique in the underlying graph after eliminating a row/column. By randomization, RCHOL only retains a sparse subset of the edges in the clique using a random sampling developed by Spielman and Kyng. We prove RCHOL is breakdown-free and apply it to solving large sparse linear systems with symmetric diagonally dominant matrices. In addition, we parallelize RCHOL based on the nested dissection ordering for shared-memory machines. We report numerical experiments that demonstrate the robustness and the scalability of RCHOL. For example, our parallel code scaled up to 64 threads on a single node for solving the 3D Poisson equation, discretized with the 7-point stencil on a $1024\\times 1024 \\times 1024$ grid, a problem that has one billion unknowns.",
        "published": "2020-11-16T08:08:05Z",
        "link": "http://arxiv.org/abs/2011.07769v4",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "A simple technique for unstructured mesh generation via adaptive finite   elements",
        "authors": [
            "Tom Gustafsson"
        ],
        "summary": "This work describes a concise algorithm for the generation of triangular meshes with the help of standard adaptive finite element methods. We demonstrate that a generic adaptive finite element solver can be repurposed into a triangular mesh generator if a robust mesh smoothing algorithm is applied between the mesh refinement steps. We present an implementation of the mesh generator and demonstrate the resulting meshes via examples.",
        "published": "2020-11-16T13:12:33Z",
        "link": "http://arxiv.org/abs/2011.07919v2",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "Threaded Gröbner Bases: a Macaulay2 package",
        "authors": [
            "Sonja Petrović",
            "Shahrzad Jamshidi Zelenberg"
        ],
        "summary": "The complexity of Gr\\\"{o}bner computations has inspired many improvements to Buchberger's algorithm over the years. Looking for further insights into the algorithm's performance, we offer a threaded implementation of classical Buchberger's algorithm in {\\it Macaulay2}. The output of the main function of the package includes information about {\\it lineages} of non-zero remainders that are added to the basis during the computation. This information can be used for further algorithm improvements and optimization.",
        "published": "2020-11-16T17:46:50Z",
        "link": "http://arxiv.org/abs/2011.08126v2",
        "categories": [
            "math.AC",
            "cs.MS",
            "13P10"
        ]
    },
    {
        "title": "Deep Learning Framework From Scratch Using Numpy",
        "authors": [
            "Andrei Nicolae"
        ],
        "summary": "This work is a rigorous development of a complete and general-purpose deep learning framework from the ground up. The fundamental components of deep learning - automatic differentiation and gradient methods of optimizing multivariable scalar functions - are developed from elementary calculus and implemented in a sensible object-oriented approach using only Python and the Numpy library. Demonstrations of solved problems using the framework, named ArrayFlow, include a computer vision classification task, solving for the shape of a catenary, and a 2nd order differential equation.",
        "published": "2020-11-17T06:28:05Z",
        "link": "http://arxiv.org/abs/2011.08461v1",
        "categories": [
            "cs.MS",
            "cs.LG"
        ]
    },
    {
        "title": "Ginkgo -- A Math Library designed for Platform Portability",
        "authors": [
            "Terry Cojean",
            "Yu-Hsiang \"Mike\" Tsai",
            "Hartwig Anzt"
        ],
        "summary": "The first associations to software sustainability might be the existence of a continuous integration (CI) framework; the existence of a testing framework composed of unit tests, integration tests, and end-to-end tests; and also the existence of software documentation. However, when asking what is a common deathblow for a scientific software product, it is often the lack of platform and performance portability. Against this background, we designed the Ginkgo library with the primary focus on platform portability and the ability to not only port to new hardware architectures, but also achieve good performance. In this paper we present the Ginkgo library design, radically separating algorithms from hardware-specific kernels forming the distinct hardware executors, and report our experience when adding execution backends for NVIDIA, AMD, and Intel GPUs. We also comment on the different levels of performance portability, and the performance we achieved on the distinct hardware backends.",
        "published": "2020-11-17T19:10:12Z",
        "link": "http://arxiv.org/abs/2011.08879v1",
        "categories": [
            "cs.DC",
            "cs.MS",
            "cs.PF",
            "cs.SE"
        ]
    },
    {
        "title": "Enabling New Flexibility in the SUNDIALS Suite of Nonlinear and   Differential/Algebraic Equation Solvers",
        "authors": [
            "David J. Gardner",
            "Daniel R. Reynolds",
            "Carol S. Woodward",
            "Cody J. Balos"
        ],
        "summary": "In recent years, the SUite of Nonlinear and DIfferential/ALgebraic equation Solvers (SUNDIALS) has been redesigned to better enable the use of application-specific and third-party algebraic solvers and data structures. Throughout this work, we have adhered to specific guiding principles that minimized the impact to current users while providing maximum flexibility for later evolution of solvers and data structures. The redesign was done through the addition of new linear and nonlinear solvers classes, enhancements to the vector class, and the creation of modern Fortran interfaces. The vast majority of this work has been performed \"behind-the-scenes,\" with minimal changes to the user interface and no reduction in solver capabilities or performance. These changes allow SUNDIALS users to more easily utilize external solver libraries and create highly customized solvers, enabling greater flexibility on extreme-scale, heterogeneous computational architectures.",
        "published": "2020-11-19T19:13:38Z",
        "link": "http://arxiv.org/abs/2011.10073v2",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "Scalable Local Timestepping on Octree Grids",
        "authors": [
            "Milinda Fernando",
            "Hari Sundar"
        ],
        "summary": "Numerical solutions of hyperbolic partial differential equations(PDEs) are ubiquitous in science and engineering. Method of lines is a popular approach to discretize PDEs defined in spacetime, where space and time are discretized independently. When using explicit timesteppers on adaptive grids, the use of a global timestep-size dictated by the finest grid-spacing leads to inefficiencies in the coarser regions. Even though adaptive space discretizations are widely used in computational sciences, temporal adaptivity is less common due to its sophisticated nature. In this paper, we present highly scalable algorithms to enable local timestepping (LTS) for explicit timestepping schemes on fully adaptive octrees. We demonstrate the accuracy of our methods as well as the scalability of our framework across 16K cores in TACC's Frontera. We also present a speed up estimation model for LTS, which predicts the speedup compared to global timestepping (GTS) with an average of 0.1 relative error.",
        "published": "2020-11-19T21:44:23Z",
        "link": "http://arxiv.org/abs/2011.10570v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "PIFE-PIC: Parallel Immersed-Finite-Element Particle-In-Cell For 3-D   Kinetic Simulations of Plasma-Material Interactions",
        "authors": [
            "Daoru Han",
            "Xiaoming He",
            "David Lund",
            "Xu Zhang"
        ],
        "summary": "This paper presents a recently developed particle simulation code package PIFE-PIC, which is a novel three-dimensional (3-D) Parallel Immersed-Finite-Element (IFE) Particle-in-Cell (PIC) simulation model for particle simulations of plasma-material interactions. This framework is based on the recently developed non-homogeneous electrostatic IFE-PIC algorithm, which is designed to handle complex plasma-material interface conditions associated with irregular geometries using a Cartesian-mesh-based PIC. Three-dimensional domain decomposition is utilized for both the electrostatic field solver with IFE and the particle operations in PIC to distribute the computation among multiple processors. A simulation of the orbital-motion-limited (OML) sheath of a dielectric sphere immersed in a stationary plasma is carried out to validate PIFE-PIC and profile the parallel performance of the code package. Furthermore, a large-scale simulation of plasma charging at a lunar crater containing 2 million PIC cells (10 million FE/IFE cells) and about 520 million particles, running for 20,000 PIC steps in about 109 wall-clock hours, is presented to demonstrate the high-performance computing capability of PIFE-PIC.",
        "published": "2020-11-20T04:53:16Z",
        "link": "http://arxiv.org/abs/2011.10214v1",
        "categories": [
            "cs.MS",
            "cs.CE"
        ]
    },
    {
        "title": "Efficient space-time reduced order model for linear dynamical systems in   Python using less than 120 lines of code",
        "authors": [
            "Youngkyu Kim",
            "Karen May Wang",
            "Youngsoo Choi"
        ],
        "summary": "A classical reduced order model (ROM) for dynamical problems typically involves only the spatial reduction of a given problem. Recently, a novel space-time ROM for linear dynamical problems has been developed, which further reduces the problem size by introducing a temporal reduction in addition to a spatial reduction without much loss in accuracy. The authors show an order of a thousand speed-up with a relative error of less than 0.00001 for a large-scale Boltzmann transport problem. In this work, we present for the first time the derivation of the space-time Petrov-Galerkin projection for linear dynamical systems and its corresponding block structures. Utilizing these block structures, we demonstrate the ease of construction of the space-time ROM method with two model problems: 2D diffusion and 2D convection diffusion, with and without a linear source term. For each problem, we demonstrate the entire process of generating the full order model (FOM) data, constructing the space-time ROM, and predicting the reduced-order solutions, all in less than 120 lines of Python code. We compare our Petrov-Galerkin method with the traditional Galerkin method and show that the space-time ROMs can achieve O(100) speed-ups with O(0.001) to O(0.0001) relative errors for these problems. Finally, we present an error analysis for the space-time Petrov-Galerkin projection and derive an error bound, which shows an improvement compared to traditional spatial Galerkin ROM methods.",
        "published": "2020-11-20T21:31:58Z",
        "link": "http://arxiv.org/abs/2011.10648v1",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "Automatic differentiation of Sylvester, Lyapunov, and algebraic Riccati   equations",
        "authors": [
            "Ta-Chu Kao",
            "Guillaume Hennequin"
        ],
        "summary": "Sylvester, Lyapunov, and algebraic Riccati equations are the bread and butter of control theorists. They are used to compute infinite-horizon Gramians, solve optimal control problems in continuous or discrete time, and design observers. While popular numerical computing frameworks (e.g., scipy) provide efficient solvers for these equations, these solvers are still largely missing from most automatic differentiation libraries. Here, we derive the forward and reverse-mode derivatives of the solutions to all three types of equations, and showcase their application on an inverse control problem.",
        "published": "2020-11-23T14:33:31Z",
        "link": "http://arxiv.org/abs/2011.11430v2",
        "categories": [
            "math.OC",
            "cs.LG",
            "cs.MS"
        ]
    },
    {
        "title": "The Chunks and Tasks Matrix Library 2.0",
        "authors": [
            "Emanuel H. Rubensson",
            "Elias Rudberg",
            "Anastasia Kruchinina",
            "Anton G. Artemov"
        ],
        "summary": "We present a C++ header-only parallel sparse matrix library, based on sparse quadtree representation of matrices using the Chunks and Tasks programming model. The library implements a number of sparse matrix algorithms for distributed memory parallelization that are able to dynamically exploit data locality to avoid movement of data. This is demonstrated for the example of block-sparse matrix-matrix multiplication applied to three sequences of matrices with different nonzero structure, using the CHT-MPI 2.0 runtime library implementation of the Chunks and Tasks model. The runtime library succeeds to dynamically load balance the calculation regardless of the sparsity structure.",
        "published": "2020-11-23T22:04:50Z",
        "link": "http://arxiv.org/abs/2011.11762v1",
        "categories": [
            "cs.DC",
            "cs.MS",
            "65F50",
            "D.1.3; G.1.3; G.4"
        ]
    },
    {
        "title": "Enabling GPU Accelerated Computing in the SUNDIALS Time Integration   Library",
        "authors": [
            "Cody J. Balos",
            "David J. Gardner",
            "Carol S. Woodward",
            "Daniel R. Reynolds"
        ],
        "summary": "As part of the Exascale Computing Project (ECP), a recent focus of development efforts for the SUite of Nonlinear and DIfferential/ALgebraic equation Solvers (SUNDIALS) has been to enable GPU-accelerated time integration in scientific applications at extreme scales. This effort has resulted in several new GPU-enabled implementations of core SUNDIALS data structures, support for programming paradigms which are aware of the heterogeneous architectures, and the introduction of utilities to provide new points of flexibility. In this paper, we discuss our considerations, both internal and external, when designing these new features and present the features themselves. We also present performance results for several of the features on the Summit supercomputer and early access hardware for the Frontier supercomputer, which demonstrate negligible performance overhead resulting from the additional infrastructure and significant speedups when using both NVIDIA and AMD GPUs.",
        "published": "2020-11-25T19:09:12Z",
        "link": "http://arxiv.org/abs/2011.12984v2",
        "categories": [
            "cs.DC",
            "cs.MS"
        ]
    },
    {
        "title": "Automatic Mathematical Information Retrieval to Perform Translations up   to Computer Algebra Systems",
        "authors": [
            "André Greiner-Petter"
        ],
        "summary": "In mathematics, LaTeX is the de facto standard to prepare documents, e.g., scientific publications. While some formulae are still developed using pen and paper, more complicated mathematical expressions used more and more often with computer algebra systems. Mathematical expressions are often manually transcribed to computer algebra systems. The goal of my doctoral thesis is to improve the efficiency of this workflow. My envisioned method will automatically semantically enrich mathematical expressions so that they can be imported to computer algebra systems and other systems that can take advantage of the semantics, such as search engines or automatic plagiarism detection systems. These imports should preserve the essential semantic features of the expression.",
        "published": "2020-11-30T08:36:58Z",
        "link": "http://arxiv.org/abs/2011.14616v1",
        "categories": [
            "cs.IR",
            "cs.MS"
        ]
    },
    {
        "title": "Combined Sieve Algorithm for Prime Gaps",
        "authors": [
            "Seth Troisi"
        ],
        "summary": "A new Combined Sieve algorithm is presented with cost proportional to the number of enumerated factors over a series of intervals. This algorithm achieves a significant speedup, over a traditional sieve, when handling many ([10^4, 10^7]) intervals concurrently. The speedup comes from a space-time tradeoff and a novel solution to a modular equation. In real world tests, this new algorithm regularly runs 10,000x faster. This faster sieve paired with higher sieving limits eliminates more composites and accelerates the search for large prime gaps by 30-70%. During the development and testing of this new algorithm, two top-10 record merit prime gaps were discovered.",
        "published": "2020-11-30T10:25:20Z",
        "link": "http://arxiv.org/abs/2012.03771v1",
        "categories": [
            "math.NT",
            "cs.MS",
            "11N05 (Primary) 11N35"
        ]
    },
    {
        "title": "A robust and scalable unfitted adaptive finite element framework for   nonlinear solid mechanics",
        "authors": [
            "Santiago Badia",
            "Manuel Caicedo",
            "Alberto F. Martín",
            "Javier Principe"
        ],
        "summary": "In this work, we bridge standard adaptive mesh refinement and coarsening on scalable octree background meshes and robust unfitted finite element formulations for the automatic and efficient solution of large-scale nonlinear solid mechanics problems posed on complex geometries, as an alternative to standard body-fitted formulations, unstructured mesh generation and graph partitioning strategies. We pay special attention to those aspects requiring a specialized treatment in the extension of the unfitted h-adaptive aggregated finite element method on parallel tree-based adaptive meshes, recently developed for linear scalar elliptic problems, to handle nonlinear problems in solid mechanics. In order to accurately and efficiently capture localized phenomena that frequently occur in nonlinear solid mechanics problems, we perform pseudo time-stepping in combination with h-adaptive dynamic mesh refinement and rebalancing driven by a-posteriori error estimators. The method is implemented considering both irreducible and mixed (u/p) formulations and thus it is able to robustly face problems involving incompressible materials. In the numerical experiments, both formulations are used to model the inelastic behavior of a wide range of compressible and incompressible materials. First, a selected set of benchmarks are reproduced as a verification step. Second, a set of experiments is presented with problems involving complex geometries. Among them, we model a cantilever beam problem with spherical hollows distributed in a Simple Cubic array. This test involves a discrete domain with up to 11.7M Degrees Of Freedom solved in less than two hours on 3072 cores of a parallel supercomputer.",
        "published": "2020-12-01T05:37:24Z",
        "link": "http://arxiv.org/abs/2012.00280v3",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "Automatically Building Diagrams for Olympiad Geometry Problems",
        "authors": [
            "Ryan Krueger",
            "Jesse Michael Han",
            "Daniel Selsam"
        ],
        "summary": "We present a method for automatically building diagrams for olympiad-level geometry problems and implement our approach in a new open-source software tool, the Geometry Model Builder (GMB). Central to our method is a new domain-specific language, the Geometry Model-Building Language (GMBL), for specifying geometry problems along with additional metadata useful for building diagrams. A GMBL program specifies (1) how to parameterize geometric objects (or sets of geometric objects) and initialize these parameterized quantities, (2) which quantities to compute directly from other quantities, and (3) additional constraints to accumulate into a (differentiable) loss function. A GMBL program induces a (usually) tractable numerical optimization problem whose solutions correspond to diagrams of the original problem statement, and that we can solve reliably using gradient descent. Of the 39 geometry problems since 2000 appearing in the International Mathematical Olympiad, 36 can be expressed in our logic and our system can produce diagrams for 94% of them on average. To the best of our knowledge, our method is the first in automated geometry diagram construction to generate models for such complex problems.",
        "published": "2020-12-01T05:56:25Z",
        "link": "http://arxiv.org/abs/2012.02590v2",
        "categories": [
            "cs.CG",
            "cs.MS"
        ]
    },
    {
        "title": "A Parallel Direct Eigensolver for Sequences of Hermitian Eigenvalue   Problems with No Tridiagonalization",
        "authors": [
            "Shengguo Li",
            "Xinzhe Wu",
            "Jose E. Roman",
            "Ziyang Yuan",
            "Ruibo Wang",
            "Lizhi Cheng"
        ],
        "summary": "In this paper, a Parallel Direct Eigensolver for Sequences of Hermitian Eigenvalue Problems with no tridiagonalization is proposed, denoted by \\texttt{PDESHEP}, and it combines direct methods with iterative methods. \\texttt{PDESHEP} first reduces a Hermitian matrix to its banded form, then applies a spectrum slicing algorithm to the banded matrix, and finally computes the eigenvectors of the original matrix via backtransform. Therefore, compared with conventional direct eigensolvers, \\texttt{PDESHEP} avoids tridiagonalization, which consists of many memory-bounded operations. In this work, the iterative method in \\texttt{PDESHEP} is based on the contour integral method implemented in FEAST. The combination of direct methods with iterative methods for banded matrices requires some efficient data redistribution algorithms both from 2D to 1D and from 1D to 2D data structures. Hence, some two-step data redistribution algorithms are proposed, which can be $10\\times$ faster than ScaLAPACK routine \\texttt{PXGEMR2D}. For the symmetric self-consistent field (SCF) eigenvalue problems, \\texttt{PDESHEP} can be on average $1.25\\times$ faster than the state-of-the-art direct solver in ELPA when using $4096$ processes. Numerical results are obtained for dense Hermitian matrices from real applications and large real sparse matrices from the SuiteSparse collection.",
        "published": "2020-12-01T14:21:18Z",
        "link": "http://arxiv.org/abs/2012.00506v3",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "Parameter Sensitivity Analysis of the SparTen High Performance Sparse   Tensor Decomposition Software: Extended Analysis",
        "authors": [
            "Jeremy M. Myers",
            "Daniel M. Dunlavy",
            "Keita Teranishi",
            "D. S. Hollman"
        ],
        "summary": "Tensor decomposition models play an increasingly important role in modern data science applications. One problem of particular interest is fitting a low-rank Canonical Polyadic (CP) tensor decomposition model when the tensor has sparse structure and the tensor elements are nonnegative count data. SparTen is a high-performance C++ library which computes a low-rank decomposition using different solvers: a first-order quasi-Newton or a second-order damped Newton method, along with the appropriate choice of runtime parameters. Since default parameters in SparTen are tuned to experimental results in prior published work on a single real-world dataset conducted using MATLAB implementations of these methods, it remains unclear if the parameter defaults in SparTen are appropriate for general tensor data. Furthermore, it is unknown how sensitive algorithm convergence is to changes in the input parameter values. This report addresses these unresolved issues with large-scale experimentation on three benchmark tensor data sets. Experiments were conducted on several different CPU architectures and replicated with many initial states to establish generalized profiles of algorithm convergence behavior.",
        "published": "2020-12-02T20:47:29Z",
        "link": "http://arxiv.org/abs/2012.01520v1",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "cs.PF",
            "stat.CO"
        ]
    },
    {
        "title": "What the new RooFit can do for your analysis",
        "authors": [
            "Stephan Hageboeck"
        ],
        "summary": "RooFit is a toolkit for statistical modelling and fitting, and together with RooStats it is used for measurements and statistical tests by most experiments in particle physics. Since one year, RooFit is being modernised. In this talk, improvements already released with ROOT will be discussed, such as faster data loading, vectorised computations and more standard-like interfaces. These allow for speeding up unbinned fits by several factors, and make RooFit easier to use from both C++ and Python.",
        "published": "2020-12-04T17:55:30Z",
        "link": "http://arxiv.org/abs/2012.02746v2",
        "categories": [
            "physics.data-an",
            "cs.MS",
            "hep-ex"
        ]
    },
    {
        "title": "MFST: A Python OpenFST Wrapper With Support for Custom Semirings and   Jupyter Notebooks",
        "authors": [
            "Matthew Francis-Landau"
        ],
        "summary": "This paper introduces mFST, a new Python library for working with Finite-State Machines based on OpenFST. mFST is a thin wrapper for OpenFST and exposes all of OpenFST's methods for manipulating FSTs. Additionally, mFST is the only Python wrapper for OpenFST that exposes OpenFST's ability to define a custom semirings. This makes mFST ideal for developing models that involve learning the weights on a FST or creating neuralized FSTs. mFST has been designed to be easy to get started with and has been previously used in homework assignments for a NLP class as well in projects for integrating FSTs and neural networks. In this paper, we exhibit mFST API and how to use mFST to build a simple neuralized FST with PyTorch.",
        "published": "2020-12-07T03:36:54Z",
        "link": "http://arxiv.org/abs/2012.03437v1",
        "categories": [
            "cs.LG",
            "cs.CL",
            "cs.MS"
        ]
    },
    {
        "title": "River: machine learning for streaming data in Python",
        "authors": [
            "Jacob Montiel",
            "Max Halford",
            "Saulo Martiello Mastelini",
            "Geoffrey Bolmier",
            "Raphael Sourty",
            "Robin Vaysse",
            "Adil Zouitine",
            "Heitor Murilo Gomes",
            "Jesse Read",
            "Talel Abdessalem",
            "Albert Bifet"
        ],
        "summary": "River is a machine learning library for dynamic data streams and continual learning. It provides multiple state-of-the-art learning methods, data generators/transformers, performance metrics and evaluators for different stream learning problems. It is the result from the merger of the two most popular packages for stream learning in Python: Creme and scikit-multiflow. River introduces a revamped architecture based on the lessons learnt from the seminal packages. River's ambition is to be the go-to library for doing machine learning on streaming data. Additionally, this open source package brings under the same umbrella a large community of practitioners and researchers. The source code is available at https://github.com/online-ml/river.",
        "published": "2020-12-08T21:04:44Z",
        "link": "http://arxiv.org/abs/2012.04740v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MS",
            "68-04",
            "I.2; I.2.5"
        ]
    },
    {
        "title": "Highly Efficient Lattice-Boltzmann Multiphase Simulations of Immiscible   Fluids at High-Density Ratios on CPUs and GPUs through Code Generation",
        "authors": [
            "Markus Holzer",
            "Martin Bauer",
            "Ulrich Rüde"
        ],
        "summary": "A high-performance implementation of a multiphase lattice Boltzmann method based on the conservative Allen-Cahn model supporting high-density ratios and high Reynolds numbers is presented. Metaprogramming techniques are used to generate optimized code for CPUs and GPUs automatically. The coupled model is specified in a high-level symbolic description and optimized through automatic transformations. The memory footprint of the resulting algorithm is reduced through the fusion of compute kernels. A roofline analysis demonstrates the excellent efficiency of the generated code on a single GPU. The resulting single GPU code has been integrated into the multiphysics framework waLBerla to run massively parallel simulations on large domains. Communication hiding and GPUDirect-enabled MPI yield near-perfect scaling behaviour. Scaling experiments are conducted on the Piz Daint supercomputer with up to 2048 GPUs, simulating several hundred fully resolved bubbles. Further, validation of the implementation is shown in a physically relevant scenario-a three-dimensional rising air bubble in water.",
        "published": "2020-12-11T06:07:58Z",
        "link": "http://arxiv.org/abs/2012.06144v1",
        "categories": [
            "physics.flu-dyn",
            "cs.MS",
            "cs.PF"
        ]
    },
    {
        "title": "Parallel Software to Offset the Cost of Higher Precision",
        "authors": [
            "Jan Verschelde"
        ],
        "summary": "Hardware double precision is often insufficient to solve large scientific problems accurately. Computing in higher precision defined by software causes significant computational overhead. The application of parallel algorithms compensates for this overhead. Newton's method to develop power series expansions of algebraic space curves is the use case for this application.",
        "published": "2020-12-11T19:23:55Z",
        "link": "http://arxiv.org/abs/2012.06607v1",
        "categories": [
            "cs.MS",
            "cs.DC",
            "cs.NA",
            "cs.SC",
            "math.AG",
            "math.NA"
        ]
    },
    {
        "title": "A 55-line code for large-scale parallel topology optimization in 2D and   3D",
        "authors": [
            "Abhinav Gupta",
            "Rajib Chowdhury",
            "Anupam Chakrabarti",
            "Timon Rabczuk"
        ],
        "summary": "This paper presents a 55-line code written in python for 2D and 3D topology optimization (TO) based on the open-source finite element computing software (FEniCS), equipped with various finite element tools and solvers. PETSc is used as the linear algebra back-end, which results in significantly less computational time than standard python libraries. The code is designed based on the popular solid isotropic material with penalization (SIMP) methodology. Extensions to multiple load cases, different boundary conditions, and incorporation of passive elements are also presented. Thus, this implementation is the most compact implementation of SIMP based topology optimization for 3D as well as 2D problems.   Utilizing the concept of Euclidean distance matrix to vectorize the computation of the weight matrix for the filter, we have achieved a substantial reduction in the computational time and have also made it possible for the code to work with complex ground structure configurations. We have also presented the code's extension to large-scale topology optimization problems with support for parallel computations on complex structural configuration, which could help students and researchers explore novel insights into the TO problem with dense meshes. Appendix-A contains the complete code, and the website: \\url{https://github.com/iitrabhi/topo-fenics} also contains the complete code.",
        "published": "2020-12-15T10:57:16Z",
        "link": "http://arxiv.org/abs/2012.08208v1",
        "categories": [
            "cs.MS",
            "cs.CE",
            "math.OC"
        ]
    },
    {
        "title": "Universal Numbers Library: design and implementation of a   high-performance reproducible number systems library",
        "authors": [
            "E. Theodore L. Omtzigt",
            "Peter Gottschling",
            "Mark Seligman",
            "William Zorn"
        ],
        "summary": "With the proliferation of embedded systems requiring intelligent behavior, custom number systems to optimize performance per Watt of the entire system become essential components for successful commercial products. We present the Universal Number Library, a high-performance number systems library that includes arbitrary integer, decimal, fixed-point, floating-point, and introduces two tapered floating-point types, posit and valid, that support reproducible arithmetic computation in arbitrary concurrency environments. We discuss the design of the Universal library as a run-time for application development, and as a platform for application-driven hardware validation. The library implementation is described, and examples are provided to show educational examples to elucidate the number system properties, and how specialization is used to yield very high-performance emulation on existing x86, ARM, and POWER processors. We will highlight the integration of the library in larger application environments in computational science and engineering to enable multi-precision and adaptive precision algorithms to improve performance and efficiency of large scale and real-time applications. We will demonstrate the integration of the Universal library into a high-performance reproducible linear algebra run-time. We will conclude with the roadmap of additional functionality of the library as we are targeting new application domains, such as Software Defined Radio, instrumentation, sensor fusion, and model-predictive control.",
        "published": "2020-12-20T20:07:57Z",
        "link": "http://arxiv.org/abs/2012.11011v1",
        "categories": [
            "cs.CE",
            "cs.MS"
        ]
    },
    {
        "title": "Digital Annealer for quadratic unconstrained binary optimization: a   comparative performance analysis",
        "authors": [
            "Oylum Şeker",
            "Neda Tanoumand",
            "Merve Bodur"
        ],
        "summary": "Digital Annealer (DA) is a computer architecture designed for tackling combinatorial optimization problems formulated as quadratic unconstrained binary optimization (QUBO) models. In this paper, we present the results of an extensive computational study to evaluate the performance of DA in a systematic way in comparison to multiple state-of-the-art solvers for different problem classes. We examine pure QUBO models, as well as QUBO reformulations of three constrained problems, namely quadratic assignment, quadratic cycle partition, and selective graph coloring, with the last two being new applications for DA. For the selective graph coloring problem, we also present a size reduction heuristic that significantly increases the number of eligible instances for DA. Our experimental results show that despite being in its development stage, DA can provide high-quality solutions quickly and in that regard rivals the state of the art, particularly for large instances. Moreover, as opposed to established solvers, within its limit on the number of decision variables, DA's solution times are not affected by the increase in instance size. These findings illustrate that DA has the potential to become a successful technology in tackling combinatorial optimization problems.",
        "published": "2020-12-22T09:12:27Z",
        "link": "http://arxiv.org/abs/2012.12264v1",
        "categories": [
            "math.OC",
            "cs.MS"
        ]
    },
    {
        "title": "NetworkDynamics.jl -- Composing and simulating complex networks in Julia",
        "authors": [
            "Michael Lindner",
            "Lucas Lincoln",
            "Fenja Drauschke",
            "Julia Monika Koulen",
            "Hans Würfel",
            "Anton Plietzsch",
            "Frank Hellmann"
        ],
        "summary": "NetworkDynamics.jl is an easy-to-use and computationally efficient package for working with heterogeneous dynamical systems on complex networks, written in Julia, a high-level, high-performance, dynamic programming language. By combining state of the art solver algorithms from DifferentialEquations.jl with efficient data structures, NetworkDynamics.jl achieves top performance while supporting advanced features like events, algebraic constraints, time-delays, noise terms and automatic differentiation.",
        "published": "2020-12-22T11:41:24Z",
        "link": "http://arxiv.org/abs/2012.12696v3",
        "categories": [
            "cs.MS",
            "physics.soc-ph",
            "G.4"
        ]
    },
    {
        "title": "Frequency extraction for BEM-matrices arising from the 3D scalar   Helmholtz equation",
        "authors": [
            "Simon Dirckx",
            "Daan Huybrechs",
            "Karl Meerbergen"
        ],
        "summary": "The discretisation of boundary integral equations for the scalar Helmholtz equation leads to large dense linear systems. Efficient boundary element methods (BEM), such as the fast multipole method (FMM) and $\\Hmat$ based methods, focus on structured low-rank approximations of subblocks in these systems. It is known that the ranks of these subblocks increase linearly with the wavenumber. We explore a data-sparse representation of BEM-matrices valid for a range of frequencies, based on extracting the known phase of the Green's function. Algebraically, this leads to a Hadamard product of a frequency matrix with an $\\Hmat$. We show that the frequency dependency of this $\\Hmat$ can be determined using a small number of frequency samples, even for geometrically complex three-dimensional scattering obstacles. We describe an efficient construction of the representation by combining adaptive cross approximation with adaptive rational approximation in the continuous frequency dimension. We show that our data-sparse representation allows to efficiently sample the full BEM-matrix at any given frequency, and as such it may be useful as part of an efficient sweeping routine.",
        "published": "2020-12-28T15:32:34Z",
        "link": "http://arxiv.org/abs/2012.14287v3",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "calculus: High Dimensional Numerical and Symbolic Calculus in R",
        "authors": [
            "Emanuele Guidotti"
        ],
        "summary": "The R package calculus implements C++ optimized functions for numerical and symbolic calculus, such as the Einstein summing convention, fast computation of the Levi-Civita symbol and generalized Kronecker delta, Taylor series expansion, multivariate Hermite polynomials, high-order derivatives, ordinary differential equations, differential operators and numerical integration in arbitrary orthogonal coordinate systems. The library applies numerical methods when working with R functions or symbolic programming when working with characters or expressions. The package handles multivariate numerical calculus in arbitrary dimensions and coordinates and implements the symbolic counterpart of the numerical methods whenever possible, without depending on external computer algebra systems. Except for Rcpp, the package has no strict dependencies in order to provide a stable self-contained toolbox that invites re-use.",
        "published": "2020-12-31T21:52:19Z",
        "link": "http://arxiv.org/abs/2101.00086v1",
        "categories": [
            "cs.MS",
            "cs.NA",
            "math.NA",
            "68-04",
            "G.4"
        ]
    },
    {
        "title": "Stieltjes moment sequences for pattern-avoiding permutations",
        "authors": [
            "Alin Bostan",
            "Andrew Elvey Price",
            "Anthony John Guttmann",
            "Jean-Marie Maillard"
        ],
        "summary": "A small set of combinatorial sequences have coefficients that can be represented as moments of a nonnegative measure on $[0, \\infty)$. Such sequences are known as Stieltjes moment sequences. This article focuses on some classical sequences in enumerative combinatorics, denoted $Av(\\mathcal{P})$, and counting permutations of $\\{1, 2, \\ldots, n \\}$ that avoid some given pattern $\\mathcal{P}$. For increasing patterns $\\mathcal{P}=(12\\ldots k)$, we recall that the corresponding sequences, $Av(123\\ldots k)$, are Stieltjes moment sequences, and we explicitly find the underlying density function, either exactly or numerically, by using the Stieltjes inversion formula as a fundamental tool. We show that the generating functions of the sequences $\\, Av(1234)$ and $\\, Av(12345)$ correspond, up to simple rational functions, to an order-one linear differential operator acting on a classical modular form given as a pullback of a Gaussian $\\, _2F_1$ hypergeometric function, respectively to an order-two linear differential operator acting on the square of a classical modular form given as a pullback of a $\\, _2F_1$ hypergeometric function. We demonstrate that the density function for the Stieltjes moment sequence $Av(123\\ldots k)$ is closely, but non-trivially, related to the density attached to the distance traveled by a walk in the plane with $k-1$ unit steps in random directions. Finally, we study the challenging case of the $Av(1324)$ sequence and give compelling numerical evidence that this too is a Stieltjes moment sequence. Accepting this, we show how rigorous lower bounds on the growth constant of this sequence can be constructed, which are stronger than existing bounds. A further unproven assumption leads to even better bounds, which can be extrapolated to give an estimate of the (unknown) growth constant.",
        "published": "2020-01-02T11:16:07Z",
        "link": "http://arxiv.org/abs/2001.00393v3",
        "categories": [
            "math.CO",
            "cs.SC",
            "Primary 44A60, 68W30, 33F10, 15B52, Secondary 05A15, 05A10, 11B65,\n  60B20, 11F03, 11F12, 33A30, 33C05, 34A05"
        ]
    },
    {
        "title": "A Condition for Multiplicity Structure of Univariate Polynomials",
        "authors": [
            "Hoon Hong",
            "Jing Yang"
        ],
        "summary": "We consider the problem of finding a condition for a univariate polynomial having a given multiplicity structure when the number of distinct roots is given. It is well known that such conditions can be written as conjunctions of several polynomial equations and one inequation in the coefficients, by using repeated parametric gcd's. In this paper, we give a novel condition which is not based on repeated gcd's. Furthermore, it is shown that the number of polynomials in the condition is optimal and the degree of polynomials is smaller than that in the previous condition based on repeated gcd's.",
        "published": "2020-01-08T05:50:55Z",
        "link": "http://arxiv.org/abs/2001.02388v2",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "On fast multiplication of a matrix by its transpose",
        "authors": [
            "Jean-Guillaume Dumas",
            "Clement Pernet",
            "Alexandre Sedoglavic"
        ],
        "summary": "We present a non-commutative algorithm for the multiplication of a 2x2-block-matrix by its transpose using 5 block products (3 recursive calls and 2 general products) over C or any finite field.We use geometric considerations on the space of bilinear forms describing 2x2 matrix products to obtain this algorithm and we show how to reduce the number of involved additions.The resulting algorithm for arbitrary dimensions is a reduction of multiplication of a matrix by its transpose to general matrix product, improving by a constant factor previously known reductions.Finally we propose schedules with low memory footprint that support a fast and memory efficient practical implementation over a finite field.To conclude, we show how to use our result in LDLT factorization.",
        "published": "2020-01-13T09:16:43Z",
        "link": "http://arxiv.org/abs/2001.04109v4",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Bisimilar Conversion of Multi-valued Networks to Boolean Networks",
        "authors": [
            "Franck Delaplace",
            "Sergiu Ivanov"
        ],
        "summary": "Discrete modelling frameworks of Biological networks can be divided in two distinct categories: Boolean and Multi-valued. Although Multi-valued networks are more expressive for qualifying the regulatory behaviours modelled by more than two values, the ability to automatically convert them to Boolean network with an equivalent behaviour breaks down the fundamental borders between the two approaches. Theoretically investigating the conversion process provides relevant insights into bridging the gap between them. Basically, the conversion aims at finding a Boolean network bisimulating a Multi-valued one. In this article, we investigate the bisimilar conversion where the Boolean integer coding is a parameter that can be freely modified. Based on this analysis, we define a computational method automatically inferring a bisimilar Boolean network from a given Multi-valued one.",
        "published": "2020-01-21T07:58:53Z",
        "link": "http://arxiv.org/abs/2001.07371v1",
        "categories": [
            "cs.DM",
            "cs.SC",
            "q-bio.QM"
        ]
    },
    {
        "title": "On mu-Symmetric Polynomials",
        "authors": [
            "Jing Yang",
            "Chee K. Yap"
        ],
        "summary": "In this paper, we study functions of the roots of a univariate polynomial in which the roots have a given multiplicity structure $\\mu$. Traditionally, root functions are studied via the theory of symmetric polynomials; we extend this theory to $\\mu$-symmetric polynomials. We were motivated by a conjecture from Becker et al.~(ISSAC 2016) about the $\\mu$-symmetry of a particular root function $D^+(\\mu)$, called D-plus. To investigate this conjecture, it was desirable to have fast algorithms for checking if a given root function is $\\mu$-symmetric. We designed three such algorithms: one based on Gr\\\"{o}bner bases, another based on preprocessing and reduction, and the third based on solving linear equations. We implemented them in Maple and experiments show that the latter two algorithms are significantly faster than the first.",
        "published": "2020-01-21T09:26:49Z",
        "link": "http://arxiv.org/abs/2001.07403v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Sparse Polynomial Interpolation Based on Derivative",
        "authors": [
            "Qiao-Long Huang"
        ],
        "summary": "In this paper, we propose two new interpolation algorithms for sparse multivariate polynomials represented by a straight-line program(SLP). Both of our algorithms work over any finite fields $F_q$ with large characteristic. The first one is a Monte Carlo randomized algorithm. Its arithmetic complexity is linear in the number $T$ of non-zero terms of $f$, in the number $n$ of variables. If $q$ is $O((nTD)^{(1)})$, where $D$ is the partial degree bound, then our algorithm has better complexity than other existing algorithms. The second one is a deterministic algorithm. It has better complexity than existing deterministic algorithms over a field with large characteristic. Its arithmetic complexity is quadratic in $n,T,\\log D$, i.e., quadratic in the size of the sparse representation. And we also show that the complexity of our deterministic algorithm is the same as the one of deterministic zero-testing of Bl\\\"{a}ser et al. for the polynomial given by an SLP over finite field (for large characteristic).",
        "published": "2020-01-21T16:34:15Z",
        "link": "http://arxiv.org/abs/2002.03708v1",
        "categories": [
            "cs.SC",
            "math.RA",
            "I.1.2"
        ]
    },
    {
        "title": "Sparse Polynomial Interpolation Based on Diversification",
        "authors": [
            "Qiao-Long Huang"
        ],
        "summary": "We consider the problem of interpolating a sparse multivariate polynomial over a finite field, represented with a black box. Building on the algorithm of Ben-Or and Tiwari for interpolating polynomials over rings with characteristic zero, we develop a new Monte Carlo algorithm over the finite field by doing additional probes. To interpolate a polynomial $f\\in F_q[x_1,\\dots,x_n]$ with a partial degree bound $D$ and a term bound $T$, our new algorithm costs $O^\\thicksim(nT\\log ^2q+nT\\sqrt{D}\\log q)$ bit operations and uses $2(n+1)T$ probes to the black box. If $q\\geq O(nT^2D)$, it has constant success rate to return the correct polynomial. Compared with previous algorithms over general finite field, our algorithm has better complexity in the parameters $n,T,D$ and is the first one to achieve the complexity of fractional power about $D$, while keeping linear in $n,T$. A key technique is a randomization which makes all coefficients of the unknown polynomial distinguishable, producing a diverse polynomial. This approach, called diversification, was proposed by Giesbrecht and Roche in 2011. Our algorithm interpolates each variable independently using $O(T)$ probes, and then uses the diversification to correlate terms in different images. At last, we get the exponents by solving the discrete logarithms and obtain coefficients by solving a linear system. We have implemented our algorithm in Maple. Experimental results shows that our algorithm can applied to sparse polynomials with large degree. We also analyze the success rate of the algorithm.",
        "published": "2020-01-21T16:39:11Z",
        "link": "http://arxiv.org/abs/2002.03706v1",
        "categories": [
            "cs.SC",
            "math.RA",
            "I.1.2"
        ]
    },
    {
        "title": "Sparse Interpolation in Terms of Multivariate Chebyshev Polynomials",
        "authors": [
            "Evelyne Hubert",
            "Michael F. Singer"
        ],
        "summary": "Sparse interpolation} refers to the exact recovery of a function as a short linear combination of basis functions from a limited number of evaluations. For multivariate functions, the case of the monomial basis is well studied, as is now the basis of exponential functions. Beyond the multivariate Chebyshev polynomial obtained as tensor products of univariate Chebyshev polynomials, the theory of root systems allows to define a variety of generalized multivariate Chebyshev polynomials that have connections to topics such as Fourier analysis and representations of Lie algebras. We present a deterministic algorithm to recover a function that is the linear combination of at most r such polynomials from the knowledge of r and an explicitly bounded number of evaluations of this function.",
        "published": "2020-01-24T18:52:21Z",
        "link": "http://arxiv.org/abs/2001.09144v1",
        "categories": [
            "cs.SC",
            "math.CA",
            "math.RA",
            "math.RT",
            "13A50, 17B10, 17B22, 30E05, 33C52, 33F10, 68W30"
        ]
    },
    {
        "title": "On the Uniqueness Problem for Quadrature Domains",
        "authors": [
            "Yacin Ameur",
            "Martin Helmer",
            "Felix Tellander"
        ],
        "summary": "We study questions of existence and uniqueness of quadrature domains using computational tools from real algebraic geometry. These problems are transformed into questions about the number of solutions to an associated real semi-algebraic system, which is analyzed using the method of real comprehensive triangular decomposition.",
        "published": "2020-01-26T10:23:39Z",
        "link": "http://arxiv.org/abs/2001.09431v3",
        "categories": [
            "math.CV",
            "cs.SC",
            "math.AG",
            "30C20, 31A25, 14P10, 68W30"
        ]
    },
    {
        "title": "Smart Induction for Isabelle/HOL (System Description)",
        "authors": [
            "Yutaka Nagashima"
        ],
        "summary": "Proof assistants offer tactics to facilitate inductive proofs. However, it still requires human ingenuity to decide what arguments to pass to those induction tactics. To automate this process, we present smart_induct for Isabelle/HOL. Given an inductive problem in any problem domain, smart_induct lists promising arguments for the induct tactic without relying on a search. Our evaluation demonstrated smart_induct produces valuable recommendations across problem domains.",
        "published": "2020-01-27T15:29:34Z",
        "link": "http://arxiv.org/abs/2001.10834v1",
        "categories": [
            "cs.AI",
            "cs.LO",
            "cs.PL",
            "cs.SC"
        ]
    },
    {
        "title": "Essentially Optimal Sparse Polynomial Multiplication",
        "authors": [
            "Pascal Giorgi",
            "Bruno Grenet",
            "Armelle Perret du Cray"
        ],
        "summary": "We present a probabilistic algorithm to compute the product of two univariate sparse polynomials over a field with a number of bit operations that is quasi-linear in the size of the input and the output. Our algorithm works for any field of characteristic zero or larger than the degree. We mainly rely on sparse interpolation and on a new algorithm for verifying a sparse product that has also a quasi-linear time complexity. Using Kronecker substitution techniques we extend our result to the multivariate case.",
        "published": "2020-01-31T17:23:45Z",
        "link": "http://arxiv.org/abs/2001.11959v2",
        "categories": [
            "cs.SC",
            "cs.CC",
            "cs.DS"
        ]
    },
    {
        "title": "Unsatisfiability Proofs for Weight 16 Codewords in Lam's Problem",
        "authors": [
            "Curtis Bright",
            "Kevin K. H. Cheung",
            "Brett Stevens",
            "Ilias Kotsireas",
            "Vijay Ganesh"
        ],
        "summary": "In the 1970s and 1980s, searches performed by L. Carter, C. Lam, L. Thiel, and S. Swiercz showed that projective planes of order ten with weight 16 codewords do not exist. These searches required highly specialized and optimized computer programs and required about 2,000 hours of computing time on mainframe and supermini computers. In 2011, these searches were verified by D. Roy using an optimized C program and 16,000 hours on a cluster of desktop machines. We performed a verification of these searches by reducing the problem to the Boolean satisfiability problem (SAT). Our verification uses the cube-and-conquer SAT solving paradigm, symmetry breaking techniques using the computer algebra system Maple, and a result of Carter that there are ten nonisomorphic cases to check. Our searches completed in about 30 hours on a desktop machine and produced nonexistence proofs of about 1 terabyte in the DRAT (deletion resolution asymmetric tautology) format.",
        "published": "2020-01-31T17:43:22Z",
        "link": "http://arxiv.org/abs/2001.11973v2",
        "categories": [
            "cs.DM",
            "cs.LO",
            "cs.SC",
            "math.CO"
        ]
    },
    {
        "title": "Nonexistence Certificates for Ovals in a Projective Plane of Order Ten",
        "authors": [
            "Curtis Bright",
            "Kevin K. H. Cheung",
            "Brett Stevens",
            "Ilias Kotsireas",
            "Vijay Ganesh"
        ],
        "summary": "In 1983, a computer search was performed for ovals in a projective plane of order ten. The search was exhaustive and negative, implying that such ovals do not exist. However, no nonexistence certificates were produced by this search, and to the best of our knowledge the search has never been independently verified. In this paper, we rerun the search for ovals in a projective plane of order ten and produce a collection of nonexistence certificates that, when taken together, imply that such ovals do not exist. Our search program uses the cube-and-conquer paradigm from the field of satisfiability (SAT) checking, coupled with a programmatic SAT solver and the nauty symbolic computation library for removing symmetries from the search.",
        "published": "2020-01-31T17:43:24Z",
        "link": "http://arxiv.org/abs/2001.11974v3",
        "categories": [
            "cs.DM",
            "cs.LO",
            "cs.SC",
            "math.CO"
        ]
    },
    {
        "title": "Efficient q-Integer Linear Decomposition of Multivariate Polynomials",
        "authors": [
            "Mark Giesbrecht",
            "Hui Huang",
            "George Labahn",
            "Eugene Zima"
        ],
        "summary": "We present two new algorithms for the computation of the q-integer linear decomposition of a multivariate polynomial. Such a decomposition is essential for the treatment of q-hypergeometric symbolic summation via creative telescoping and for describing the q-counterpart of Ore-Sato theory. Both of our algorithms require only basic integer and polynomial arithmetic and work for any unique factorization domain containing the ring of integers. Complete complexity analyses are conducted for both our algorithms and two previous algorithms in the case of multivariate integer polynomials, showing that our algorithms have better theoretical performances. A Maple implementation is also included which suggests that our algorithms are also much faster in practice than previous algorithms.",
        "published": "2020-02-01T02:05:19Z",
        "link": "http://arxiv.org/abs/2002.00124v2",
        "categories": [
            "cs.SC",
            "math.RA"
        ]
    },
    {
        "title": "Linearly Constrained Gaussian Processes with Boundary Conditions",
        "authors": [
            "Markus Lange-Hegermann"
        ],
        "summary": "One goal in Bayesian machine learning is to encode prior knowledge into prior distributions, to model data efficiently. We consider prior knowledge from systems of linear partial differential equations together with their boundary conditions. We construct multi-output Gaussian process priors with realizations in the solution set of such systems, in particular only such solutions can be represented by Gaussian process regression. The construction is fully algorithmic via Gr\\\"obner bases and it does not employ any approximation. It builds these priors combining two parametrizations via a pullback: the first parametrizes the solutions for the system of differential equations and the second parametrizes all functions adhering to the boundary conditions.",
        "published": "2020-02-03T15:19:03Z",
        "link": "http://arxiv.org/abs/2002.00818v3",
        "categories": [
            "cs.LG",
            "cs.SC",
            "math.AC",
            "stat.ML",
            "13P10, 13P20, 18-04, 47F05, 60G15, 60-08, 62G05, 68T01",
            "G.3; I.1.2; I.1.4; I.2.6; I.5.1"
        ]
    },
    {
        "title": "Separating Variables in Bivariate Polynomial Ideals",
        "authors": [
            "Manfred Buchacher",
            "Manuel Kauers",
            "Gleb Pogudin"
        ],
        "summary": "We present an algorithm which for any given ideal $I\\subseteq\\mathbb{K} [x,y]$ finds all elements of $I$ that have the form $f(x) - g(y)$, i.e., all elements in which no monomial is a multiple of $xy$.",
        "published": "2020-02-04T21:18:00Z",
        "link": "http://arxiv.org/abs/2002.01541v2",
        "categories": [
            "cs.SC",
            "math.AC"
        ]
    },
    {
        "title": "Convergence analysis of particle swarm optimization using stochastic   Lyapunov functions and quantifier elimination",
        "authors": [
            "Maximilian Gerwien",
            "Rick Voßwinkel",
            "Hendrik Richter"
        ],
        "summary": "This paper adds to the discussion about theoretical aspects of particle swarm stability by proposing to employ stochastic Lyapunov functions and to determine the convergence set by quantifier elimination. We present a computational procedure and show that this approach leads to reevaluation and extension of previously know stability regions for PSO using a Lyapunov approach under stagnation assumptions.",
        "published": "2020-02-05T07:47:07Z",
        "link": "http://arxiv.org/abs/2002.01673v1",
        "categories": [
            "cs.NE",
            "cs.SC",
            "math.DS"
        ]
    },
    {
        "title": "An Additive Decomposition in S-Primitive Towers",
        "authors": [
            "Hao Du",
            "Jing Guo",
            "Ziming Li",
            "Elaine Wong"
        ],
        "summary": "We consider the additive decomposition problem in primitive towers and present an algorithm to decompose a function in an S-primitive tower as a sum of a derivative in the tower and a remainder which is minimal in some sense. Special instances of S-primitive towers include differential fields generated by finitely many logarithmic functions and logarithmic integrals. A function in an S-primitive tower is integrable in the tower if and only if the remainder is equal to zero. The additive decomposition is achieved by viewing our towers not as a traditional chain of extension fields, but rather as a direct sum of certain subrings. Furthermore, we can determine whether or not a function in an S-primitive tower has an elementary integral without solving any differential equations. We also show that a kind of S-primitive towers, known as logarithmic towers, can be embedded into a particular extension where we can obtain a finer remainder.",
        "published": "2020-02-06T17:00:47Z",
        "link": "http://arxiv.org/abs/2002.02355v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Integral P-Recursive Sequences",
        "authors": [
            "Shaoshi Chen",
            "Lixin Du",
            "Manuel Kauers",
            "Thibaut Verron"
        ],
        "summary": "In an earlier paper, the notion of integrality known from algebraic number fields and fields of algebraic functions has been extended to D-finite functions. The aim of the present paper is to extend the notion to the case of P-recursive sequences. In order to do so, we formulate a general algorithm for finding all integral elements for valued vector spaces and then show that this algorithm includes not only the algebraic and the D-finite cases but also covers the case of P-recursive sequences.",
        "published": "2020-02-07T13:49:00Z",
        "link": "http://arxiv.org/abs/2002.02783v1",
        "categories": [
            "cs.SC",
            "math.NT"
        ]
    },
    {
        "title": "The Fundamental Theorem of Tropical Partial Differential Algebraic   Geometry",
        "authors": [
            "Sebastian Falkensteiner",
            "Cristhian Garay-López",
            "Mercedes Haiech",
            "Marc Paul Noordman",
            "Zeinab Toghani",
            "François Boulier"
        ],
        "summary": "Tropical Differential Algebraic Geometry considers difficult or even intractable problems in Differential Equations and tries to extract information on their solutions from a restricted structure of the input. The Fundamental Theorem of Tropical Differential Algebraic Geometry states that the support of solutions of systems of ordinary differential equations with formal power series coefficients over an uncountable algebraically closed field of characteristic zero can be obtained by solving a so-called tropicalized differential system. Tropicalized differential equations work on a completely different algebraic structure which may help in theoretical and computational questions. We show that the Fundamental Theorem can be extended to the case of systems of partial differential equations by introducing vertex sets of Newton polygons.",
        "published": "2020-02-07T23:08:18Z",
        "link": "http://arxiv.org/abs/2002.03041v1",
        "categories": [
            "math.AG",
            "cs.SC",
            "13P15, 13N99, 14T99, 52B20"
        ]
    },
    {
        "title": "First-Order Tests for Toricity",
        "authors": [
            "Hamid Rahkooy",
            "Thomas Sturm"
        ],
        "summary": "Motivated by problems arising with the symbolic analysis of steady state ideals in Chemical Reaction Network Theory, we consider the problem of testing whether the points in a complex or real variety with non-zero coordinates form a coset of a multiplicative group. That property corresponds to Shifted Toricity, a recent generalization of toricity of the corresponding polynomial ideal. The key idea is to take a geometric view on varieties rather than an algebraic view on ideals. Recently, corresponding coset tests have been proposed for complex and for real varieties. The former combine numerous techniques from commutative algorithmic algebra with Gr\\\"obner bases as the central algorithmic tool. The latter are based on interpreted first-order logic in real closed fields with real quantifier elimination techniques on the algorithmic side. Here we take a new logic approach to both theories, complex and real, and beyond. Besides alternative algorithms, our approach provides a unified view on theories of fields and helps to understand the relevance and interconnection of the rich existing literature in the area, which has been focusing on complex numbers, while from a scientific point of view the (positive) real numbers are clearly the relevant domain in chemical reaction network theory. We apply prototypical implementations of our new approach to a set of 129 models from the BioModels repository.",
        "published": "2020-02-10T07:56:07Z",
        "link": "http://arxiv.org/abs/2002.03586v1",
        "categories": [
            "cs.SC",
            "q-bio.MN"
        ]
    },
    {
        "title": "Compatible rewriting of noncommutative polynomials for proving operator   identities",
        "authors": [
            "Cyrille Chenavier",
            "Clemens Hofstadler",
            "Clemens G. Raab",
            "Georg Regensburger"
        ],
        "summary": "The goal of this paper is to prove operator identities using equalities between noncommutative polynomials. In general, a polynomial expression is not valid in terms of operators, since it may not be compatible with domains and codomains of the corresponding operators. Recently, some of the authors introduced a framework based on labelled quivers to rigorously translate polynomial identities to operator identities. In the present paper, we extend and adapt the framework to the context of rewriting and polynomial reduction. We give a sufficient condition on the polynomials used for rewriting to ensure that standard polynomial reduction automatically respects domains and codomains of operators. Finally, we adapt the noncommutative Buchberger procedure to compute additional compatible polynomials for rewriting. In the package OperatorGB, we also provide an implementation of the concepts developed.",
        "published": "2020-02-10T10:08:43Z",
        "link": "http://arxiv.org/abs/2002.03626v1",
        "categories": [
            "cs.SC",
            "math.RT"
        ]
    },
    {
        "title": "Signature-based algorithms for Gr{ö}bner bases over Tate algebras",
        "authors": [
            "Xavier Caruso",
            "Tristan Vaccon",
            "Thibaut Verron"
        ],
        "summary": "Introduced by Tate in [Ta71], Tate algebras play a major role in the context of analytic geometry over the-adics, where they act as a counterpart to the use of polynomial algebras in classical algebraic geometry. In [CVV19] the formalism of Gr{\\\"o}bner bases over Tate algebras has been introduced and effectively implemented. One of the bottleneck in the algorithms was the time spent on reduction , which are significantly costlier than over polynomials. In the present article, we introduce two signature-based Gr{\\\"o}bner bases algorithms for Tate algebras, in order to avoid many reductions. They have been implemented in SageMath. We discuss their superiority based on numerical evidences.",
        "published": "2020-02-11T15:47:40Z",
        "link": "http://arxiv.org/abs/2002.04491v2",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Smooth Points on Semi-algebraic Sets",
        "authors": [
            "Katherine Harris",
            "Jonathan D. Hauenstein",
            "Agnes Szanto"
        ],
        "summary": "Many algorithms for determining properties of real algebraic or semi-algebraic sets rely upon the ability to compute smooth points. Existing methods to compute smooth points on semi-algebraic sets use symbolic quantifier elimination tools. In this paper, we present a simple algorithm based on computing the critical points of some well-chosen function that guarantees the computation of smooth points in each connected compact component of a real (semi)-algebraic set. Our technique is intuitive in principal, performs well on previously difficult examples, and is straightforward to implement using existing numerical algebraic geometry software. The practical efficiency of our approach is demonstrated by solving a conjecture on the number of equilibria of the Kuramoto model for the $n=4$ case. We also apply our method to design an efficient algorithm to compute the real dimension of (semi)-algebraic sets, the original motivation for this research.",
        "published": "2020-02-11T21:52:41Z",
        "link": "http://arxiv.org/abs/2002.04707v3",
        "categories": [
            "cs.SC",
            "cs.NA",
            "math.AG",
            "math.NA"
        ]
    },
    {
        "title": "ENIGMA Anonymous: Symbol-Independent Inference Guiding Machine (system   description)",
        "authors": [
            "Jan Jakubův",
            "Karel Chvalovský",
            "Miroslav Olšák",
            "Bartosz Piotrowski",
            "Martin Suda",
            "Josef Urban"
        ],
        "summary": "We describe an implementation of gradient boosting and neural guidance of saturation-style automated theorem provers that does not depend on consistent symbol names across problems. For the gradient-boosting guidance, we manually create abstracted features by considering arity-based encodings of formulas. For the neural guidance, we use symbol-independent graph neural networks (GNNs) and their embedding of the terms and clauses. The two methods are efficiently implemented in the E prover and its ENIGMA learning-guided framework.   To provide competitive real-time performance of the GNNs, we have developed a new context-based approach to evaluation of generated clauses in E. Clauses are evaluated jointly in larger batches and with respect to a large number of already selected clauses (context) by the GNN that estimates their collectively most useful subset in several rounds of message passing. This means that approximative inference rounds done by the GNN are efficiently interleaved with precise symbolic inference rounds done inside E. The methods are evaluated on the MPTP large-theory benchmark and shown to achieve comparable real-time performance to state-of-the-art symbol-based methods. The methods also show high complementarity, solving a large number of hard Mizar problems.",
        "published": "2020-02-13T09:44:38Z",
        "link": "http://arxiv.org/abs/2002.05406v2",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.LO",
            "cs.NE",
            "cs.SC"
        ]
    },
    {
        "title": "A divide-and-conquer algorithm for computing Gröbner bases of syzygies   in finite dimension",
        "authors": [
            "Simone Naldi",
            "Vincent Neiger"
        ],
        "summary": "Let $f_1,\\ldots,f_m$ be elements in a quotient $R^n / N$ which has finite dimension as a $K$-vector space, where $R = K[X_1,\\ldots,X_r]$ and $N$ is an $R$-submodule of $R^n$. We address the problem of computing a Gr\\\"obner basis of the module of syzygies of $(f_1,\\ldots,f_m)$, that is, of vectors $(p_1,\\ldots,p_m) \\in R^m$ such that $p_1 f_1 + \\cdots + p_m f_m = 0$.   An iterative algorithm for this problem was given by Marinari, M\\\"oller, and Mora (1993) using a dual representation of $R^n / N$ as the kernel of a collection of linear functionals. Following this viewpoint, we design a divide-and-conquer algorithm, which can be interpreted as a generalization to several variables of Beckermann and Labahn's recursive approach for matrix Pad\\'e and rational interpolation problems. To highlight the interest of this method, we focus on the specific case of bivariate Pad\\'e approximation and show that it improves upon the best known complexity bounds.",
        "published": "2020-02-15T16:15:54Z",
        "link": "http://arxiv.org/abs/2002.06404v2",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "On the Uniqueness of Simultaneous Rational Function Reconstruction",
        "authors": [
            "Eleonora Guerrini",
            "Romain Lebreton",
            "Ilaria Zappatore"
        ],
        "summary": "This paper focuses on the problem of reconstructing a vector of rational functions given some evaluations, or more generally given their remainders modulo different polynomials. The special case of rational functions sharing the same denominator, a.k.a.Simultaneous Rational Function Reconstruction (SRFR), has many applications from linear system solving to coding theory, provided that SRFR has a unique solution. The number of unknowns in SRFR is smaller than for a general vector of rational function. This allows to reduce the number of evaluation points needed to guarantee the existence of a solution, but we may lose its uniqueness. In this work, we prove that uniqueness is guaranteed for a generic instance.",
        "published": "2020-02-20T14:22:31Z",
        "link": "http://arxiv.org/abs/2002.08748v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Robust Numerical Tracking of One Path of a Polynomial Homotopy on   Parallel Shared Memory Computers",
        "authors": [
            "Simon Telen",
            "Marc Van Barel",
            "Jan Verschelde"
        ],
        "summary": "We consider the problem of tracking one solution path defined by a polynomial homotopy on a parallel shared memory computer. Our robust path tracker applies Newton's method on power series to locate the closest singular parameter value. On top of that, it computes singular values of the Hessians of the polynomials in the homotopy to estimate the distance to the nearest different path. Together, these estimates are used to compute an appropriate adaptive stepsize. For n-dimensional problems, the cost overhead of our robust path tracker is O(n), compared to the commonly used predictor-corrector methods. This cost overhead can be reduced by a multithreaded program on a parallel shared memory computer.",
        "published": "2020-02-21T19:04:12Z",
        "link": "http://arxiv.org/abs/2002.09504v3",
        "categories": [
            "math.NA",
            "cs.DC",
            "cs.NA",
            "cs.SC"
        ]
    },
    {
        "title": "Fast In-place Algorithms for Polynomial Operations: Division,   Evaluation, Interpolation",
        "authors": [
            "Pascal Giorgi",
            "Bruno Grenet",
            "Daniel S. Roche"
        ],
        "summary": "We consider space-saving versions of several important operations on univariate polynomials, namely power series inversion and division, division with remainder, multi-point evaluation, and interpolation. Now-classical results show that such problems can be solved in (nearly) the same asymptotic time as fast polynomial multiplication. However, these reductions, even when applied to an in-place variant of fast polynomial multiplication, yield algorithms which require at least a linear amount of extra space for intermediate results. We demonstrate new in-place algorithms for the aforementioned polynomial computations which require only constant extra space and achieve the same asymptotic running time as their out-of-place counterparts. We also provide a precise complexity analysis so that all constants are made explicit, parameterized by the space usage of the underlying multiplication algorithms.",
        "published": "2020-02-24T15:27:58Z",
        "link": "http://arxiv.org/abs/2002.10304v3",
        "categories": [
            "cs.SC",
            "cs.CC"
        ]
    },
    {
        "title": "Space Efficient Representations of Finite Groups",
        "authors": [
            "Bireswar Das",
            "Shivdutt Sharma",
            "P. R. Vaidyanathan"
        ],
        "summary": "The Cayley table representation of a group uses $\\mathcal{O}(n^2)$ words for a group of order $n$ and answers multiplication queries in time $\\mathcal{O}(1)$. It is interesting to ask if there is a $o(n^2)$ space representation of groups that still has $\\mathcal{O}(1)$ query-time. We show that for any $\\delta$, $\\frac{1}{\\log n} \\le \\delta \\le 1$, there is an $\\mathcal{O}(\\frac{n^{1 +\\delta}}{\\delta})$ space representation for groups of order $n$ with $\\mathcal{O}(\\frac{1}{\\delta})$ query-time.   We also show that for Z-groups, simple groups and several group classes defined in terms of semidirect product, there are linear space representations with at most logarithmic query-time.   Farzan and Munro (ISSAC'06) defined a model for group representation and gave a succinct data structure for abelian groups with constant query-time. They asked if their result can be extended to categorically larger group classes. We construct data structures in their model for Hamiltonian groups and some other classes of groups with constant query-time.",
        "published": "2020-02-26T10:16:44Z",
        "link": "http://arxiv.org/abs/2002.11391v1",
        "categories": [
            "cs.DS",
            "cs.SC"
        ]
    },
    {
        "title": "Criteria for the numerical constant recognition",
        "authors": [
            "Andrzej Odrzywolek"
        ],
        "summary": "The need for recognition/approximation of functions in terms of elementary functions/operations emerges in many areas of experimental mathematics, numerical analysis, computer algebra systems, model building, machine learning, approximation and data compression. One of the most underestimated methods is the symbolic regression. In the article, reductionist approach is applied, reducing full problem to constant functions, i.e, pure numbers (decimal, floating-point). However, existing solutions are plagued by lack of solid criteria distinguishing between random formula, matching approximately or literally decimal expansion and probable ''exact'' (the best) expression match in the sense of Occam's razor. In particular, convincing STOP criteria for search were never developed. In the article, such a criteria, working in statistical sense, are provided. Recognition process can be viewed as (1) enumeration of all formulas in order of increasing Kolmogorov complexity K (2) random process with appropriate statistical distribution (3) compression of a decimal string. All three approaches are remarkably consistent, and provide essentially the same limit for practical depth of search. Tested unique formulas count must not exceed 1/sigma, where sigma is relative numerical error of the target constant. Beyond that, further search is pointless, because, in the view of approach (1), number of equivalent expressions within error bounds grows exponentially; in view of (2), probability of random match approaches 1; in view of (3) compression ratio much smaller than 1.",
        "published": "2020-02-28T13:01:21Z",
        "link": "http://arxiv.org/abs/2002.12690v2",
        "categories": [
            "cs.DM",
            "cs.SC",
            "stat.OT",
            "G.2.3; G.3; G.4; I.1.1; I.2.m; F.2.3; G.1.m; F.1.m"
        ]
    },
    {
        "title": "A Linear Algebra Approach for Detecting Binomiality of Steady State   Ideals of Reversible Chemical Reaction Networks",
        "authors": [
            "Hamid Rahkooy",
            "Ovidiu Radulescu",
            "Thomas Sturm"
        ],
        "summary": "Motivated by problems from Chemical Reaction Network Theory, we investigate whether steady state ideals of reversible reaction networks are generated by binomials. We take an algebraic approach considering, besides concentrations of species, also rate constants as indeterminates. This leads us to the concept of unconditional binomiality, meaning binomiality for all values of the rate constants. This concept is different from conditional binomiality that applies when rate constant values or relations among rate constants are given. We start by representing the generators of a steady state ideal as sums of binomials, which yields a corresponding coefficient matrix. On these grounds we propose an efficient algorithm for detecting unconditional binomiality. That algorithm uses exclusively elementary column and row operations on the coefficient matrix. We prove asymptotic worst case upper bounds on the time complexity of our algorithm. Furthermore, we experimentally compare its performance with other existing methods.",
        "published": "2020-02-28T13:07:53Z",
        "link": "http://arxiv.org/abs/2002.12693v2",
        "categories": [
            "cs.SC",
            "q-bio.MN"
        ]
    },
    {
        "title": "Effective Localization Using Double Ideal Quotient and Its   Implementation",
        "authors": [
            "Yuki Ishihara",
            "Kazuhiro Yokoyama"
        ],
        "summary": "In this paper, we propose a new method for localization of polynomial ideal, which we call \"Local Primary Algorithm\". For an ideal $I$ and a prime ideal $P$, our method computes a $P$-primary component of $I$ after checking if $P$ is associated with $I$ by using \"double ideal quotient\" $(I:(I:P))$ and its variants which give us a lot of information about localization of $I$.",
        "published": "2020-02-29T09:40:12Z",
        "link": "http://arxiv.org/abs/2003.00220v1",
        "categories": [
            "math.AC",
            "cs.SC"
        ]
    },
    {
        "title": "A complexity chasm for solving univariate sparse polynomial equations   over $p$-adic fields",
        "authors": [
            "J. Maurice Rojas",
            "Yuyu Zhu"
        ],
        "summary": "We reveal a complexity chasm, separating the trinomial and tetranomial cases, for solving univariate sparse polynomial equations over certain local fields. First, for any fixed field $K\\in\\{\\mathbb{Q}_2,\\mathbb{Q}_3,\\mathbb{Q}_5,\\ldots\\}$, we prove that any polynomial $f\\in\\mathbb{Z}[x]$ with exactly $3$ monomial terms, degree $d$, and all coefficients having absolute value at most $H$, can be solved over $K$ in deterministic time $O(\\log^{O(1)}(dH))$ in the classical Turing model. (The best previous algorithms were of complexity exponential in $\\log d$, even for just counting roots in $\\mathbb{Q}_p$.) In particular, our algorithm generates approximations in $\\mathbb{Q}$ with bit-length $O(\\log^{O(1)}(dH))$ to all the roots of $f$ in $K$, and these approximations converge quadratically under Newton iteration. On the other hand, we give a unified family of tetranomials requiring $\\Omega(d\\log H)$ digits to distinguish the base-$p$ expansions of their roots in $K$.",
        "published": "2020-02-29T17:30:26Z",
        "link": "http://arxiv.org/abs/2003.00314v4",
        "categories": [
            "math.NT",
            "cs.CC",
            "cs.SC"
        ]
    },
    {
        "title": "Solving Satisfiability of Polynomial Formulas By Sample-Cell Projection",
        "authors": [
            "Haokun Li",
            "Bican Xia"
        ],
        "summary": "A new algorithm for deciding the satisfiability of polynomial formulas over the reals is proposed. The key point of the algorithm is a new projection operator, called sample-cell projection operator, custom-made for Conflict-Driven Clause Learning (CDCL)-style search. Although the new operator is also a CAD (Cylindrical Algebraic Decomposition)-like projection operator which computes the cell (not necessarily cylindrical) containing a given sample such that each polynomial from the problem is sign-invariant on the cell, it is of singly exponential time complexity. The sample-cell projection operator can efficiently guide CDCL-style search away from conflicting states. Experiments show the effectiveness of the new algorithm.",
        "published": "2020-03-01T05:36:09Z",
        "link": "http://arxiv.org/abs/2003.00409v2",
        "categories": [
            "cs.LO",
            "cs.AI",
            "cs.SC"
        ]
    },
    {
        "title": "Maximum Absolute Determinants of Upper Hessenberg Bohemian Matrices",
        "authors": [
            "Jonathan P. Keating",
            "Ahmet Abdullah Keleş"
        ],
        "summary": "A matrix is called Bohemian if its entries are sampled from a finite set of integers. We determine the maximum absolute determinant of upper Hessenberg Bohemian Matrices for which the subdiagonal entries are fixed to be $1$ and upper triangular entries are sampled from $\\{0,1,\\cdots,n\\}$, extending previous results for $n=1$ and $n=2$ and proving a recent conjecture of Fasi & Negri Porzio [8]. Furthermore, we generalize the problem to non-integer-valued entries.",
        "published": "2020-03-01T10:03:17Z",
        "link": "http://arxiv.org/abs/2003.00454v2",
        "categories": [
            "cs.SC",
            "cs.NA",
            "math.CO",
            "math.NA"
        ]
    },
    {
        "title": "Modular Techniques for Effective Localization and Double Ideal Quotient",
        "authors": [
            "Yuki Ishihara"
        ],
        "summary": "By double ideal quotient, we mean $(I:(I:J))$ where ideals $I$ and $J$. In our previous work [11], double ideal quotient and its variants are shown to be very useful for checking prime divisor and generating primary component. Combining those properties, we can compute \"direct localization\" effectively, comparing with full primary decomposition. In this paper, we apply modular techniques effectively to computation of such double ideal quotient and its variants, where first we compute them modulo several prime numbers and then lift them up over rational numbers by Chinese Remainder Theorem and rational reconstruction. As a new modular technique for double ideal quotient and its variants, we devise criteria for output from modular computations. Also, we apply modular techniques to intermediate primary decomposition. We examine the effectiveness of our modular techniques for several examples by preliminary computational experiences on Singular.",
        "published": "2020-03-01T14:39:54Z",
        "link": "http://arxiv.org/abs/2003.00496v2",
        "categories": [
            "math.AC",
            "cs.SC"
        ]
    },
    {
        "title": "Enhancing simultaneous rational function recovery: adaptive error   correction capability and new bounds for applications",
        "authors": [
            "Eleonora Guerrini",
            "Romain Lebreton",
            "Ilaria Zappatore"
        ],
        "summary": "In this work we present some results that allow to improve the decoding radius in solving polynomial linear systems with errors in the scenario where errors are additive and randomly distributed over a finite field. The decoding radius depends on some bounds on the solution that we want to recover, so their overestimation could significantly decrease our error correction capability. For this reason, we introduce an algorithm that can bridge this gap, introducing some ad hoc parameters that reduce the discrepancy between the estimate decoding radius and the effective error correction capability.",
        "published": "2020-03-03T21:01:51Z",
        "link": "http://arxiv.org/abs/2003.01793v1",
        "categories": [
            "cs.IT",
            "cs.SC",
            "math.IT"
        ]
    },
    {
        "title": "The Absent-Minded Passengers Problem: A Motivating Challenge Solved by   Computer Algebra",
        "authors": [
            "Carsten Schneider"
        ],
        "summary": "In (S.B. Ekhad and D. Zeilberger, 2020) an exciting case study has been initiated in which experimental mathematics and symbolic computation are utilized to discover new properties concerning the so-called Absent-Minded Passengers Problem. Based on these results, Doron Zeilberger raised some challenging tasks to gain further probabilistic insight. In this note we report on this enterprise. In particular, we demonstrate how the computer algebra packages of RISC can be used to carry out the underlying heavy calculations.",
        "published": "2020-03-04T07:32:33Z",
        "link": "http://arxiv.org/abs/2003.01921v2",
        "categories": [
            "math.CO",
            "cs.SC"
        ]
    },
    {
        "title": "Algorithm to enumerate superspecial Howe curves of genus $4$",
        "authors": [
            "Momonari Kudo",
            "Shushi Harashita"
        ],
        "summary": "A Howe curve is a curve of genus $4$ obtained as the fiber product over $\\mathbf{P}^1$ of two elliptic curves. Any Howe curve is canonical. This paper provides an efficient algorithm to find superspecial Howe curves and that to enumerate their isomorphism classes. We discuss not only an algorithm to test the superspeciality but also an algorithm to test isomorphisms for Howe curves. Our algorithms are much more efficient than conventional ones proposed by the authors so far for general canonical curves. We show the existence of a superspecial Howe curve in characteristic $7<p\\le 331$ and enumerate the isomorphism classes of superspecial Howe curves in characteristic $p\\le 53$, by executing our algorithms over the computer algebra system Magma.",
        "published": "2020-03-09T13:53:14Z",
        "link": "http://arxiv.org/abs/2003.04153v1",
        "categories": [
            "math.NT",
            "cs.SC",
            "math.AG"
        ]
    },
    {
        "title": "Neuro-symbolic Architectures for Context Understanding",
        "authors": [
            "Alessandro Oltramari",
            "Jonathan Francis",
            "Cory Henson",
            "Kaixin Ma",
            "Ruwan Wickramarachchi"
        ],
        "summary": "Computational context understanding refers to an agent's ability to fuse disparate sources of information for decision-making and is, therefore, generally regarded as a prerequisite for sophisticated machine reasoning capabilities, such as in artificial intelligence (AI). Data-driven and knowledge-driven methods are two classical techniques in the pursuit of such machine sense-making capability. However, while data-driven methods seek to model the statistical regularities of events by making observations in the real-world, they remain difficult to interpret and they lack mechanisms for naturally incorporating external knowledge. Conversely, knowledge-driven methods, combine structured knowledge bases, perform symbolic reasoning based on axiomatic principles, and are more interpretable in their inferential processing; however, they often lack the ability to estimate the statistical salience of an inference. To combat these issues, we propose the use of hybrid AI methodology as a general framework for combining the strengths of both approaches. Specifically, we inherit the concept of neuro-symbolism as a way of using knowledge-bases to guide the learning progress of deep neural networks. We further ground our discussion in two applications of neuro-symbolism and, in both cases, show that our systems maintain interpretability while achieving comparable performance, relative to the state-of-the-art.",
        "published": "2020-03-09T15:04:07Z",
        "link": "http://arxiv.org/abs/2003.04707v1",
        "categories": [
            "cs.AI",
            "cs.CL",
            "cs.SC"
        ]
    },
    {
        "title": "Entropy of tropical holonomic sequences",
        "authors": [
            "Dima Grigoriev"
        ],
        "summary": "We introduce tropical holonomic sequences of a given order and calculate their entropy in case of the second order.",
        "published": "2020-03-11T18:08:11Z",
        "link": "http://arxiv.org/abs/2003.05466v2",
        "categories": [
            "math.AG",
            "cs.SC",
            "14T05"
        ]
    },
    {
        "title": "Deciding the Consistency of Non-Linear Real Arithmetic Constraints with   a Conflict Driven Search Using Cylindrical Algebraic Coverings",
        "authors": [
            "Erika Ábrahám",
            "James H. Davenport",
            "Matthew England",
            "Gereon Kremer"
        ],
        "summary": "We present a new algorithm for determining the satisfiability of conjunctions of non-linear polynomial constraints over the reals, which can be used as a theory solver for satisfiability modulo theory (SMT) solving for non-linear real arithmetic. The algorithm is a variant of Cylindrical Algebraic Decomposition (CAD) adapted for satisfiability, where solution candidates (sample points) are constructed incrementally, either until a satisfying sample is found or sufficient samples have been sampled to conclude unsatisfiability. The choice of samples is guided by the input constraints and previous conflicts.   The key idea behind our new approach is to start with a partial sample; demonstrate that it cannot be extended to a full sample; and from the reasons for that rule out a larger space around the partial sample, which build up incrementally into a cylindrical algebraic covering of the space. There are similarities with the incremental variant of CAD, the NLSAT method of Jovanovic and de Moura, and the NuCAD algorithm of Brown; but we present worked examples and experimental results on a preliminary implementation to demonstrate the differences to these, and the benefits of the new approach.",
        "published": "2020-03-12T06:02:48Z",
        "link": "http://arxiv.org/abs/2003.05633v2",
        "categories": [
            "cs.SC",
            "cs.LO"
        ]
    },
    {
        "title": "FunGrim: a symbolic library for special functions",
        "authors": [
            "Fredrik Johansson"
        ],
        "summary": "We present the Mathematical Functions Grimoire (FunGrim), a website and database of formulas and theorems for special functions. We also discuss the symbolic computation library used as the backend and main development tool for FunGrim, and the Grim formula language used in these projects to represent mathematical content semantically.",
        "published": "2020-03-13T10:07:21Z",
        "link": "http://arxiv.org/abs/2003.06181v1",
        "categories": [
            "cs.MS",
            "cs.SC"
        ]
    },
    {
        "title": "Experimental Evaluation of a Method to Simplify Expressions",
        "authors": [
            "Baudouin Le Charlier"
        ],
        "summary": "We present a method to simplify expressions in the context of an equational theory. The basic ideas and concepts of the method have been presented previously elsewhere but here we tackle the difficult task of making it efficient in practice, in spite of its great generality. We first recall the notion of a collection of structures, which allows us to manipulate very large (possibly infinite) sets of terms as a whole, i.e., without enumerating their elements. Then we use this tool to construct algorithms to simplify expressions. We give various reasons why it is difficult to make these algorithms precise and efficient. We then propose a number of approches to solve the raised issues. Finally, and importantly, we provide a detailed experimental evaluation of the method and a comparison of several variants of it. Although the method is completely generic, we use (arbitrary, not only two-level) boolean expressions as the application field for these experiments because impressive simplifications can be obtained in spite of the hardness of the problem.",
        "published": "2020-03-13T11:12:19Z",
        "link": "http://arxiv.org/abs/2003.06203v1",
        "categories": [
            "cs.LO",
            "cs.SC"
        ]
    },
    {
        "title": "Transforming ODEs and PDEs with radical coefficients into rational   coefficients",
        "authors": [
            "Jorge Caravantes",
            "J. Rafael Sendra",
            "David Sevilla",
            "Carlos Villarino"
        ],
        "summary": "We present an algorithm that transforms, if possible, a given ODE or PDE with radical function coefficients into one with rational coefficients by means of a rational change of variables. It also applies to systems of linear ODEs. It is based on previous work on reparametrization of radical algebraic varieties.",
        "published": "2020-03-13T13:53:51Z",
        "link": "http://arxiv.org/abs/2003.06301v1",
        "categories": [
            "math.CA",
            "cs.SC",
            "math.AG"
        ]
    },
    {
        "title": "An Algorithm for Computing a Minimal Comprehensive Gröbner\\, Basis of   a Parametric Polynomial System",
        "authors": [
            "Deepak Kapur",
            "Yiming Yang"
        ],
        "summary": "An algorithm to generate a minimal comprehensive Gr\\\"obner\\, basis of a parametric polynomial system from an arbitrary faithful comprehensive Gr\\\"obner\\, system is presented. A basis of a parametric polynomial ideal is a comprehensive Gr\\\"obner\\, basis if and only if for every specialization of parameters in a given field, the specialization of the basis is a Gr\\\"obner\\, basis of the associated specialized polynomial ideal. The key idea used in ensuring minimality is that of a polynomial being essential with respect to a comprehensive Gr\\\"obner\\, basis. The essentiality check is performed by determining whether a polynomial can be covered for various specializations by other polynomials in the associated branches in a comprehensive Gr\\\"obner\\, system. The algorithm has been implemented and successfully tried on many examples from the literature.",
        "published": "2020-03-17T21:43:18Z",
        "link": "http://arxiv.org/abs/2003.07957v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Moment State Dynamical Systems for Nonlinear Chance-Constrained Motion   Planning",
        "authors": [
            "Allen Wang",
            "Ashkan Jasour",
            "Brian Williams"
        ],
        "summary": "Chance-constrained motion planning requires uncertainty in dynamics to be propagated into uncertainty in state. When nonlinear models are used, Gaussian assumptions on the state distribution do not necessarily apply since almost all random variables propagated through nonlinear dynamics results in non-Gaussian state distributions. To address this, recent works have developed moment-based approaches for enforcing chance-constraints on non-Gaussian state distributions. However, there still lacks fast and accurate moment propagation methods to determine the necessary statistical moments of these state distributions. To address this gap, we present a framework that, given a stochastic dynamical system, can algorithmically search for a new dynamical system in terms of moment state that can be used to propagate moments of disturbance random variables into moments of the state distribution. The key algorithm, TreeRing, can be applied to a large class of nonlinear systems which we refer to as trigonometric polynomial systems. As an example application, we present a distributionally robust RRT (DR-RRT) algorithm that propagates uncertainty through the nonlinear Dubin's car model without linearization.",
        "published": "2020-03-23T16:48:55Z",
        "link": "http://arxiv.org/abs/2003.10379v2",
        "categories": [
            "eess.SY",
            "cs.RO",
            "cs.SC",
            "cs.SY"
        ]
    },
    {
        "title": "Generic bivariate multi-point evaluation, interpolation and modular   composition with precomputation",
        "authors": [
            "Vincent Neiger",
            "Johan Rosenkilde",
            "Grigory Solomatov"
        ],
        "summary": "Suppose $\\mathbb{K}$ is a large enough field and $\\mathcal{P} \\subset \\mathbb{K}^2$ is a fixed, generic set of points which is available for precomputation. We introduce a technique called \\emph{reshaping} which allows us to design quasi-linear algorithms for both: computing the evaluations of an input polynomial $f \\in \\mathbb{K}[x,y]$ at all points of $\\mathcal{P}$; and computing an interpolant $f \\in \\mathbb{K}[x,y]$ which takes prescribed values on $\\mathcal{P}$ and satisfies an input $y$-degree bound. Our genericity assumption is explicit and we prove that it holds for most point sets over a large enough field. If $\\mathcal{P}$ violates the assumption, our algorithms still work and the performance degrades smoothly according to a distance from being generic. To show that the reshaping technique may have an impact on other related problems, we apply it to modular composition: suppose generic polynomials $M \\in \\mathbb{K}[x]$ and $A \\in \\mathbb{K}[x]$ are available for precomputation, then given an input $f \\in \\mathbb{K}[x,y]$ we show how to compute $f(x, A(x)) \\operatorname{rem} M(x)$ in quasi-linear time.",
        "published": "2020-03-27T15:26:25Z",
        "link": "http://arxiv.org/abs/2003.12468v2",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Stream/block ciphers, difference equations and algebraic attacks",
        "authors": [
            "Roberto La Scala",
            "Sharwan K. Tiwari"
        ],
        "summary": "In this paper we model a class of stream and block ciphers as systems of (ordinary) explicit difference equations over a finite field. We call this class \"difference ciphers\" and we show that ciphers of application interest, as for example systems of LFSRs with a combiner, Trivium and Keeloq, belong to the class. By using Difference Algebra, that is, the formal theory of difference equations, we can properly define and study important properties of these ciphers, such as their invertibility and periodicity. We describe then general cryptanalytic methods for difference ciphers that follow from these properties and are useful to assess the security. We illustrate such algebraic attacks in practice by means of the ciphers Bivium and Keeloq.",
        "published": "2020-03-28T18:40:13Z",
        "link": "http://arxiv.org/abs/2003.14215v2",
        "categories": [
            "cs.CR",
            "cs.SC",
            "math.AC",
            "math.RA"
        ]
    },
    {
        "title": "Fast Encoding of AG Codes over $C_{ab}$ Curves",
        "authors": [
            "Peter Beelen",
            "Johan Rosenkilde",
            "Grigory Solomatov"
        ],
        "summary": "We investigate algorithms for encoding of one-point algebraic geometry (AG) codes over certain plane curves called $C_{ab}$ curves, as well as algorithms for inverting the encoding map, which we call \"unencoding\". Some $C_{ab}$ curves have many points or are even maximal, e.g. the Hermitian curve. Our encoding resp. unencoding algorithms have complexity $\\tilde{O}(n^{3/2})$ resp. $\\tilde{O}(qn)$ for AG codes over any $C_{ab}$ curve satisfying very mild assumptions, where $n$ is the code length and $q$ the base field size, and $\\tilde{O}$ ignores constants and logarithmic factors in the estimate. For codes over curves whose evaluation points lie on a grid-like structure, notably the Hermitian curve and norm-trace curves, we show that our algorithms have quasi-linear time complexity $\\tilde{O}(n)$ for both operations. For infinite families of curves whose number of points is a constant factor away from the Hasse--Weil bound, our encoding algorithm has complexity $\\tilde{O}(n^{5/4})$ while unencoding has $\\tilde{O}(n^{3/2})$.",
        "published": "2020-03-30T10:56:36Z",
        "link": "http://arxiv.org/abs/2003.13333v2",
        "categories": [
            "math.AG",
            "cs.IT",
            "cs.SC",
            "math.IT"
        ]
    },
    {
        "title": "Parallel Computation of tropical varieties, their positive part, and   tropical Grassmannians",
        "authors": [
            "Dominik Bendle",
            "Janko Boehm",
            "Yue Ren",
            "Benjamin Schröter"
        ],
        "summary": "In this article, we present a massively parallel framework for computing tropicalizations of algebraic varieties which can make use of finite symmetries. We compute the tropical Grassmannian TGr$_0(3,8)$, and show that it refines the $15$-dimensional skeleton of the Dressian Dr$(3,8)$ with the exception of $23$ special cones for which we construct explicit obstructions to the realizability of their tropical linear spaces. Moreover, we propose algorithms for identifying maximal-dimensional tropical cones which belong to the positive tropicalization. These algorithms exploit symmetries of the tropical variety even though the positive tropicalization need not be symmetric. We compute the maximal-dimensional cones of the positive Grassmannian TGr$^+(3,8)$ and compare them to the cluster complex of the classical Grassmannian Gr$(3,8)$.",
        "published": "2020-03-30T19:01:17Z",
        "link": "http://arxiv.org/abs/2003.13752v1",
        "categories": [
            "math.AG",
            "cs.SC",
            "math.CO",
            "14T15, 68W10, 68W30, 14Q15, 14M15, 52B15"
        ]
    },
    {
        "title": "Epistemic Phase Transitions in Mathematical Proofs",
        "authors": [
            "Scott Viteri",
            "Simon DeDeo"
        ],
        "summary": "Mathematical proofs are both paradigms of certainty and some of the most explicitly-justified arguments that we have in the cultural record. Their very explicitness, however, leads to a paradox, because the probability of error grows exponentially as the argument expands. When a mathematician encounters a proof, how does she come to believe it? Here we show that, under a cognitively-plausible belief formation mechanism combining deductive and abductive reasoning, belief in mathematical arguments can undergo what we call an epistemic phase transition: a dramatic and rapidly-propagating jump from uncertainty to near-complete confidence at reasonable levels of claim-to-claim error rates. To show this, we analyze an unusual dataset of forty-eight machine-aided proofs from the formalized reasoning system Coq, including major theorems ranging from ancient to 21st Century mathematics, along with five hand-constructed cases including Euclid, Apollonius, Hernstein's Topics in Algebra, and Andrew Wiles's proof of Fermat's Last Theorem. Our results bear both on recent work in the history and philosophy of mathematics on how we understand proofs, and on a question, basic to cognitive science, of how we justify complex beliefs.",
        "published": "2020-03-31T18:39:56Z",
        "link": "http://arxiv.org/abs/2004.00055v2",
        "categories": [
            "cs.SC",
            "cs.AI",
            "math.HO",
            "physics.soc-ph",
            "q-bio.NC"
        ]
    },
    {
        "title": "Interpolation of Dense and Sparse Rational Functions and other   Improvements in $\\texttt{FireFly}$",
        "authors": [
            "Jonas Klappert",
            "Sven Yannick Klein",
            "Fabian Lange"
        ],
        "summary": "We present the main improvements and new features in version $\\texttt{2.0}$ of the open-source $\\texttt{C++}$ library $\\texttt{FireFly}$ for the interpolation of rational functions. This includes algorithmic improvements, e.g. a hybrid algorithm for dense and sparse rational functions and an algorithm to identify and remove univariate factors. The new version is applied to a Feynman-integral reduction to showcase the runtime improvements achieved. Moreover, $\\texttt{FireFly}$ now supports parallelization with $\\texttt{MPI}$ and offers new tools like a parser for expressions or an executable for the insertion of replacement tables.",
        "published": "2020-04-03T10:40:08Z",
        "link": "http://arxiv.org/abs/2004.01463v2",
        "categories": [
            "cs.MS",
            "cs.SC",
            "hep-ph"
        ]
    },
    {
        "title": "Resultants over principal Artinian rings",
        "authors": [
            "Claus Fieker",
            "Tommy Hofmann",
            "Carlo Sircana"
        ],
        "summary": "The resultant of two univariate polynomials is an invariant of great importance in commutative algebra and vastly used in computer algebra systems. Here we present an algorithm to compute it over Artinian principal rings with a modified version of the Euclidean algorithm. Using the same strategy, we show how the reduced resultant and a pair of B\\'ezout coefficient can be computed. Particular attention is devoted to the special case of $\\mathbf{Z}/n\\mathbf{Z}$, where we perform a detailed analysis of the asymptotic cost of the algorithm. Finally, we illustrate how the algorithms can be exploited to improve ideal arithmetic in number fields and polynomial arithmetic over $p$-adic fields.",
        "published": "2020-04-07T13:17:38Z",
        "link": "http://arxiv.org/abs/2004.03341v1",
        "categories": [
            "cs.SC",
            "math.AC"
        ]
    },
    {
        "title": "Neural Analogical Matching",
        "authors": [
            "Maxwell Crouse",
            "Constantine Nakos",
            "Ibrahim Abdelaziz",
            "Kenneth Forbus"
        ],
        "summary": "Analogy is core to human cognition. It allows us to solve problems based on prior experience, it governs the way we conceptualize new information, and it even influences our visual perception. The importance of analogy to humans has made it an active area of research in the broader field of artificial intelligence, resulting in data-efficient models that learn and reason in human-like ways. While cognitive perspectives of analogy and deep learning have generally been studied independently of one another, the integration of the two lines of research is a promising step towards more robust and efficient learning techniques. As part of a growing body of research on such an integration, we introduce the Analogical Matching Network: a neural architecture that learns to produce analogies between structured, symbolic representations that are largely consistent with the principles of Structure-Mapping Theory.",
        "published": "2020-04-07T17:50:52Z",
        "link": "http://arxiv.org/abs/2004.03573v5",
        "categories": [
            "cs.AI",
            "cs.NE",
            "cs.SC"
        ]
    },
    {
        "title": "New Opportunities for the Formal Proof of Computational Real Geometry?",
        "authors": [
            "Erika {Á}brahám",
            "James Davenport",
            "Matthew England",
            "Gereon Kremer",
            "Zak Tonks"
        ],
        "summary": "The purpose of this paper is to explore the question \"to what extent could we produce formal, machine-verifiable, proofs in real algebraic geometry?\" The question has been asked before but as yet the leading algorithms for answering such questions have not been formalised. We present a thesis that a new algorithm for ascertaining satisfiability of formulae over the reals via Cylindrical Algebraic Coverings [\\'{A}brah\\'{a}m, Davenport, England, Kremer, \\emph{Deciding the Consistency of Non-Linear Real Arithmetic Constraints with a Conflict Driver Search Using Cylindrical Algebraic Coverings}, 2020] might provide trace and outputs that allow the results to be more susceptible to machine verification than those of competing algorithms.",
        "published": "2020-04-08T15:04:18Z",
        "link": "http://arxiv.org/abs/2004.04034v1",
        "categories": [
            "cs.SC",
            "cs.LO"
        ]
    },
    {
        "title": "A Simple Method for Computing Some Pseudo-Elliptic Integrals in Terms of   Elementary Functions",
        "authors": [
            "Sam Blake"
        ],
        "summary": "We introduce a method for computing some pseudo-elliptic integrals in terms of elementary functions. The method is simple and fast in comparison to the algebraic case of the Risch-Trager-Bronstein algorithm. This method can quickly solve many pseudo-elliptic integrals, which other well-known computer algebra systems either fail, return an answer in terms of special functions, or require more than 20 seconds of computing time. Randomised tests showed our method solved 73.4% of the integrals that could be solved with the best implementation of the Risch-Trager-Bronstein algorithm. Unlike the symbolic integration algorithms of Risch, Davenport, Trager, Bronstein and Miller; our method is not a decision process. The implementation of this method is less than 200 lines of Mathematica code and can be easily ported to other CAS that can solve systems of polynomial equations.",
        "published": "2020-04-10T05:04:15Z",
        "link": "http://arxiv.org/abs/2004.04910v3",
        "categories": [
            "cs.SC",
            "cs.IT",
            "math.IT"
        ]
    },
    {
        "title": "Computing all identifiable functions of parameters for ODE models",
        "authors": [
            "Alexey Ovchinnikov",
            "Anand Pillay",
            "Gleb Pogudin",
            "Thomas Scanlon"
        ],
        "summary": "Parameter identifiability is a structural property of an ODE model for recovering the values of parameters from the data (i.e., from the input and output variables). This property is a prerequisite for meaningful parameter identification in practice. In the presence of nonidentifiability, it is important to find all functions of the parameters that are identifiable. The existing algorithms check whether a given function of parameters is identifiable or, under the solvability condition, find all identifiable functions. However, this solvability condition is not always satisfied, which presents a challenge. Our first main result is an algorithm that computes all identifiable functions without any additional assumptions, which is the first such algorithm as far as we know. Our second main result concerns the identifiability from multiple experiments (with generically different inputs and initial conditions among the experiments). For this problem, we prove that the set of functions identifiable from multiple experiments is what would actually be computed by input-output equation-based algorithms (whether or not the solvability condition is fulfilled), which was not known before. We give an algorithm that not only finds these functions but also provides an upper bound for the number of experiments to be performed to identify these functions. We provide an implementation of the presented algorithms.",
        "published": "2020-04-16T17:07:33Z",
        "link": "http://arxiv.org/abs/2004.07774v3",
        "categories": [
            "eess.SY",
            "cs.SC",
            "cs.SY",
            "math.LO",
            "q-bio.QM",
            "34A55, 12H05, 03C60, 92B99, 93B07, 93B30"
        ]
    },
    {
        "title": "A case study for $ζ(4)$",
        "authors": [
            "Carsten Schneider",
            "Wadim Zudilin"
        ],
        "summary": "Using symbolic summation tools in the setting of difference rings, we prove a two-parametric identity that relates rational approximations to $\\zeta(4)$.",
        "published": "2020-04-17T10:29:49Z",
        "link": "http://arxiv.org/abs/2004.08158v2",
        "categories": [
            "math.NT",
            "cs.SC",
            "math.CO"
        ]
    },
    {
        "title": "A practical approach to testing random number generators in computer   algebra systems",
        "authors": [
            "Migran N. Gevorkyan",
            "Dmitry S. Kulyabov",
            "Anastasia V. Demidova",
            "Anna V. Korolkova"
        ],
        "summary": "This paper has a practical aim. For a long time, implementations of pseudorandom number generators in standard libraries of programming languages had poor quality. The situation started to improve only recently. Up to now, a large number of libraries and weakly supported mathematical packages use outdated algorithms for random number generation. Four modern sets of statistical tests that can be used for verifying random number generators are described. It is proposed to use command line utilities, which makes it possible to avoid low-level programming in such languages as C or C++. Only free open source systems are considered.",
        "published": "2020-04-19T17:19:19Z",
        "link": "http://arxiv.org/abs/2004.08913v1",
        "categories": [
            "cs.MS",
            "cs.SC"
        ]
    },
    {
        "title": "An Efficient Method for Computing Liouvillian First Integrals of Planar   Polynomial Vector Fields",
        "authors": [
            "L. G. S. Duarte",
            "L. A. C. P. da Mota"
        ],
        "summary": "Here we present an efficient method to compute Darboux polynomials for polynomial vector fields in the plane. This approach is restricetd to polynomial vector fields presenting a Liouvillian first integral (or, equivalently, to rational first order differential equations (rational 1ODEs) presenting a Liouvillian general solution). The key to obtaining this method was to separate the procedure of solving the (nonlinear) algebraic systems resulting from the equation that translates the condition of existence of a Darboux polynomial into feasible steos (procedures that requires less memory consumption). We also present a brief performance analysis of the algorithms developed.",
        "published": "2020-04-20T13:56:45Z",
        "link": "http://arxiv.org/abs/2004.09298v1",
        "categories": [
            "math-ph",
            "cs.SC",
            "math.MP"
        ]
    },
    {
        "title": "The Imandra Automated Reasoning System (system description)",
        "authors": [
            "Grant Olney Passmore",
            "Simon Cruanes",
            "Denis Ignatovich",
            "Dave Aitken",
            "Matt Bray",
            "Elijah Kagan",
            "Kostya Kanishev",
            "Ewen Maclean",
            "Nicola Mometto"
        ],
        "summary": "We describe Imandra, a modern computational logic theorem prover designed to bridge the gap between decision procedures such as SMT, semi-automatic inductive provers of the Boyer-Moore family like ACL2, and interactive proof assistants for typed higher-order logics. Imandra's logic is computational, based on a pure subset of OCaml in which all functions are terminating, with restrictions on types and higher-order functions that allow conjectures to be translated into multi-sorted first-order logic with theories, including arithmetic and datatypes. Imandra has novel features supporting large-scale industrial applications, including a seamless integration of bounded and unbounded verification, first-class computable counterexamples, efficiently executable models and a cloud-native architecture supporting live multiuser collaboration.   The core reasoning mechanisms of Imandra are (i) a semi-complete procedure for finding models of formulas in the logic mentioned above, centered around the lazy expansion of recursive functions, and (ii) an inductive waterfall and simplifier which \"lifts\" many Boyer-Moore ideas to our typed higher-order setting.   These mechanisms are tightly integrated and subject to many forms of user control. Imandra's user interfaces include an interactive toplevel, Jupyter notebooks and asynchronous document-based verification (in the spirit of Isabelle's Prover IDE) with VS Code.",
        "published": "2020-04-21T19:57:34Z",
        "link": "http://arxiv.org/abs/2004.10263v1",
        "categories": [
            "cs.LO",
            "cs.AI",
            "cs.PL",
            "cs.SC",
            "I.2.3; F.3.1; I.2.5; F.4.1"
        ]
    },
    {
        "title": "Algorithms yield upper bounds in differential algebra",
        "authors": [
            "Wei Li",
            "Alexey Ovchinnikov",
            "Gleb Pogudin",
            "Thomas Scanlon"
        ],
        "summary": "Consider an algorithm computing in a differential field with several commuting derivations such that the only operations it performs with the elements of the field are arithmetic operations, differentiation, and zero testing. We show that, if the algorithm is guaranteed to terminate on every input, then there is a computable upper bound for the size of the output of the algorithm in terms of the size of the input. We also generalize this to algorithms working with models of good enough theories (including for example, difference fields).   We then apply this to differential algebraic geometry to show that there exists a computable uniform upper bound for the number of components of any variety defined by a system of polynomial PDEs. We then use this bound to show the existence of a computable uniform upper bound for the elimination problem in systems of polynomial PDEs with delays.",
        "published": "2020-04-22T02:26:06Z",
        "link": "http://arxiv.org/abs/2005.01608v2",
        "categories": [
            "math.AC",
            "cs.SC",
            "math.AG",
            "math.LO",
            "12H05, 12H10, 03C10, 03C60, 03D15"
        ]
    },
    {
        "title": "High performance SIMD modular arithmetic for polynomial evaluation",
        "authors": [
            "Pierre Fortin",
            "Ambroise Fleury",
            "François Lemaire",
            "Michael Monagan"
        ],
        "summary": "Two essential problems in Computer Algebra, namely polynomial factorization and polynomial greatest common divisor computation, can be efficiently solved thanks to multiple polynomial evaluations in two variables using modular arithmetic. In this article, we focus on the efficient computation of such polynomial evaluations on one single CPU core. We first show how to leverage SIMD computing for modular arithmetic on AVX2 and AVX-512 units, using both intrinsics and OpenMP compiler directives. Then we manage to increase the operational intensity and to exploit instruction-level parallelism in order to increase the compute efficiency of these polynomial evaluations. All this results in the end to performance gains up to about 5x on AVX2 and 10x on AVX-512.",
        "published": "2020-04-24T07:28:45Z",
        "link": "http://arxiv.org/abs/2004.11571v1",
        "categories": [
            "cs.DC",
            "cs.SC"
        ]
    },
    {
        "title": "GAPS: Generator for Automatic Polynomial Solvers",
        "authors": [
            "Bo Li",
            "Viktor Larsson"
        ],
        "summary": "Minimal problems in computer vision raise the demand of generating efficient automatic solvers for polynomial equation systems. Given a polynomial system repeated with different coefficient instances, the traditional Gr\\\"obner basis or normal form based solution is very inefficient. Fortunately the Gr\\\"obner basis of a same polynomial system with different coefficients is found to share consistent inner structure. By precomputing such structures offline, Gr\\\"obner basis as well as the polynomial system solutions can be solved automatically and efficiently online. In the past decade, several tools have been released to generate automatic solvers for a general minimal problems. The most recent tool autogen from Larsson et al. is a representative of these tools with state-of-the-art performance in solver efficiency. GAPS wraps and improves autogen with more user-friendly interface, more functionality and better stability. We demonstrate in this report the main approach and enhancement features of GAPS. A short tutorial of the software is also included.",
        "published": "2020-04-24T14:11:28Z",
        "link": "http://arxiv.org/abs/2004.11765v1",
        "categories": [
            "cs.CV",
            "cs.MS",
            "cs.RO",
            "cs.SC"
        ]
    },
    {
        "title": "An Abstraction-guided Approach to Scalable and Rigorous Floating-Point   Error Analysis",
        "authors": [
            "Arnab Das",
            "Ian Briggs",
            "Ganesh Gopalakrishnan",
            "Pavel Panchekha",
            "Sriram Krishnamoorthy"
        ],
        "summary": "Automated techniques for rigorous floating-point round-off error analysis are important in areas including formal verification of correctness and precision tuning. Existing tools and techniques, while providing tight bounds, fail to analyze expressions with more than a few hundred operators, thus unable to cover important practical problems. In this work, we present Satire, a new tool that sheds light on how scalability and bound-tightness can be attained through a combination of incremental analysis, abstraction, and judicious use of concrete and symbolic evaluation. Satire has handled problems exceeding 200K operators. We present Satire's underlying error analysis approach, information-theoretic abstraction heuristics, and a wide range of case studies, with evaluation covering FFT, Lorenz system of equations, and various PDE stencil types. Our results demonstrate the tightness of Satire's bounds, its acceptable runtime, and valuable insights provided.",
        "published": "2020-04-24T19:42:33Z",
        "link": "http://arxiv.org/abs/2004.11960v3",
        "categories": [
            "cs.PL",
            "cs.NA",
            "cs.SC",
            "math.NA"
        ]
    },
    {
        "title": "CLUE: Exact maximal reduction of kinetic models by constrained lumping   of differential equations",
        "authors": [
            "Alexey Ovchinnikov",
            "Isabel Cristina Pérez Verona",
            "Gleb Pogudin",
            "Mirco Tribastone"
        ],
        "summary": "Motivation: Detailed mechanistic models of biological processes can pose significant challenges for analysis and parameter estimations due to the large number of equations used to track the dynamics of all distinct configurations in which each involved biochemical species can be found. Model reduction can help tame such complexity by providing a lower-dimensional model in which each macro-variable can be directly related to the original variables.   Results: We present CLUE, an algorithm for exact model reduction of systems of polynomial differential equations by constrained linear lumping. It computes the smallest dimensional reduction as a linear mapping of the state space such that the reduced model preserves the dynamics of user-specified linear combinations of the original variables. Even though CLUE works with nonlinear differential equations, it is based on linear algebra tools, which makes it applicable to high-dimensional models. Using case studies from the literature, we show how CLUE can substantially lower model dimensionality and help extract biologically intelligible insights from the reduction.   Availability: An implementation of the algorithm and relevant resources to replicate the experiments herein reported are freely available for download at https://github.com/pogudingleb/CLUE.   Supplementary information: enclosed.",
        "published": "2020-04-24T19:42:51Z",
        "link": "http://arxiv.org/abs/2004.11961v2",
        "categories": [
            "q-bio.MN",
            "cs.SC",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Iterative Variable Reordering: Taming Huge System Families",
        "authors": [
            "Clemens Dubslaff",
            "Andrey Morozov",
            "Christel Baier",
            "Klaus Janschek"
        ],
        "summary": "For the verification of systems using model-checking techniques, symbolic representations based on binary decision diagrams (BDDs) often help to tackle the well-known state-space explosion problem. Symbolic BDD-based representations have been also shown to be successful for the analysis of families of systems that arise, e.g., through configurable parameters or following the feature-oriented modeling approach. The state space of such system families face an additional exponential blowup in the number of parameters or features. It is well known that the order of variables in ordered BDDs is crucial for the size of the model representation. Especially for automatically generated models from real-world systems, family models might even be not constructible due to bad variable orders. In this paper we describe a technique, called iterative variable reordering, that can enable the construction of large-scale family models. We exemplify feasibility of our approach by means of an aircraft velocity control system with redundancy mechanisms modeled in the input language of the probabilistic model checker PRISM. We show that standard reordering and dynamic reordering techniques fail to construct the family model due to memory and time constraints, respectively, while the new iterative approach succeeds to generate a symbolic family model.",
        "published": "2020-04-28T04:23:14Z",
        "link": "http://arxiv.org/abs/2004.13287v1",
        "categories": [
            "cs.LO",
            "cs.PF",
            "cs.SC"
        ]
    },
    {
        "title": "It is Time for New Perspectives on How to Fight Bloat in GP",
        "authors": [
            "Francisco Fernández de Vega",
            "Gustavo Olague",
            "Francisco Chávez",
            "Daniel Lanza",
            "Wolfgang Banzhaf",
            "Erik Goodman"
        ],
        "summary": "The present and future of evolutionary algorithms depends on the proper use of modern parallel and distributed computing infrastructures. Although still sequential approaches dominate the landscape, available multi-core, many-core and distributed systems will make users and researchers to more frequently deploy parallel version of the algorithms. In such a scenario, new possibilities arise regarding the time saved when parallel evaluation of individuals are performed. And this time saving is particularly relevant in Genetic Programming. This paper studies how evaluation time influences not only time to solution in parallel/distributed systems, but may also affect size evolution of individuals in the population, and eventually will reduce the bloat phenomenon GP features. This paper considers time and space as two sides of a single coin when devising a more natural method for fighting bloat. This new perspective allows us to understand that new methods for bloat control can be derived, and the first of such a method is described and tested. Experimental data confirms the strength of the approach: using computing time as a measure of individuals' complexity allows to control the growth in size of genetic programming individuals.",
        "published": "2020-05-01T20:59:24Z",
        "link": "http://arxiv.org/abs/2005.00603v1",
        "categories": [
            "cs.NE",
            "cs.AI",
            "cs.SC"
        ]
    },
    {
        "title": "Rational Solutions of First Order Algebraic Ordinary Differential   Equations",
        "authors": [
            "Ruyong Feng",
            "Shuang Feng"
        ],
        "summary": "Let $f(t, y,y')=\\sum_{i=0}^d a_i(t, y)y'^i=0$ be a first order ordinary differential equation with polynomial coefficients. Eremenko in 1999 proved that there exists a constant $C$ such that every rational solution of $f(t, y,y')=0$ is of degree not greater than $C$. Examples show that this degree bound $C$ depends not only on the degrees of $f$ in $t,y,y'$ but also on the coefficients of $f$ viewed as polynomial in $t,y,y'$. In this paper, we show that if $$\\max_{i=0}^d \\{{\\rm deg}(a_i,y)-2(d-i)\\}>0 $$ then the degree bound $C$ only depends on the degrees of $f$, and furthermore we present an explicit expression for $C$ in terms of the degrees of $f$.",
        "published": "2020-05-04T06:55:59Z",
        "link": "http://arxiv.org/abs/2005.01289v1",
        "categories": [
            "cs.SC",
            "34A05, 68W30"
        ]
    },
    {
        "title": "Learning selection strategies in Buchberger's algorithm",
        "authors": [
            "Dylan Peifer",
            "Michael Stillman",
            "Daniel Halpern-Leistner"
        ],
        "summary": "Studying the set of exact solutions of a system of polynomial equations largely depends on a single iterative algorithm, known as Buchberger's algorithm. Optimized versions of this algorithm are crucial for many computer algebra systems (e.g., Mathematica, Maple, Sage). We introduce a new approach to Buchberger's algorithm that uses reinforcement learning agents to perform S-pair selection, a key step in the algorithm. We then study how the difficulty of the problem depends on the choices of domain and distribution of polynomials, about which little is known. Finally, we train a policy model using proximal policy optimization (PPO) to learn S-pair selection strategies for random systems of binomial equations. In certain domains, the trained model outperforms state-of-the-art selection heuristics in total number of polynomial additions performed, which provides a proof-of-concept that recent developments in machine learning have the potential to improve performance of algorithms in symbolic computation.",
        "published": "2020-05-05T02:27:00Z",
        "link": "http://arxiv.org/abs/2005.01917v3",
        "categories": [
            "cs.LG",
            "cs.SC",
            "math.AC",
            "math.AG",
            "stat.ML"
        ]
    },
    {
        "title": "Characterizing Triviality of the Exponent Lattice of A Polynomial   through Galois and Galois-Like Groups",
        "authors": [
            "Tao Zheng"
        ],
        "summary": "The problem of computing \\emph{the exponent lattice} which consists of all the multiplicative relations between the roots of a univariate polynomial has drawn much attention in the field of computer algebra. As is known, almost all irreducible polynomials with integer coefficients have only trivial exponent lattices. However, the algorithms in the literature have difficulty in proving such triviality for a generic polynomial. In this paper, the relations between the Galois group (respectively, \\emph{the Galois-like groups}) and the triviality of the exponent lattice of a polynomial are investigated. The $\\bbbq$\\emph{-trivial} pairs, which are at the heart of the relations between the Galois group and the triviality of the exponent lattice of a polynomial, are characterized. An effective algorithm is developed to recognize these pairs. Based on this, a new algorithm is designed to prove the triviality of the exponent lattice of a generic irreducible polynomial, which considerably improves a state-of-the-art algorithm of the same type when the polynomial degree becomes larger. In addition, the concept of the Galois-like groups of a polynomial is introduced. Some properties of the Galois-like groups are proved and, more importantly, a sufficient and necessary condition is given for a polynomial (which is not necessarily irreducible) to have trivial exponent lattice.",
        "published": "2020-05-05T06:20:01Z",
        "link": "http://arxiv.org/abs/2005.01963v1",
        "categories": [
            "cs.SC",
            "math.NT"
        ]
    },
    {
        "title": "Subquadratic-Time Algorithms for Normal Bases",
        "authors": [
            "Mark Giesbrecht",
            "Armin Jamshidpey",
            "Éric Schost"
        ],
        "summary": "For any finite Galois field extension $\\mathsf{K}/\\mathsf{F}$, with Galois group $G = \\mathrm{Gal}(\\mathsf{K}/\\mathsf{F})$, there exists an element $\\alpha \\in \\mathsf{K}$ whose orbit $G\\cdot\\alpha$ forms an $\\mathsf{F}$-basis of $\\mathsf{K}$. Such a $\\alpha$ is called a normal element and $G\\cdot\\alpha$ is a normal basis. We introduce a probabilistic algorithm for testing whether a given $\\alpha \\in \\mathsf{K}$ is normal, when $G$ is either a finite abelian or a metacyclic group. The algorithm is based on the fact that deciding whether $\\alpha$ is normal can be reduced to deciding whether $\\sum_{g \\in G} g(\\alpha)g \\in \\mathsf{K}[G]$ is invertible; it requires a slightly subquadratic number of operations. Once we know that $\\alpha$ is normal, we show how to perform conversions between the power basis of $\\mathsf{K}/\\mathsf{F}$ and the normal basis with the same asymptotic cost.",
        "published": "2020-05-05T19:54:39Z",
        "link": "http://arxiv.org/abs/2005.03497v2",
        "categories": [
            "cs.SC",
            "cs.CC",
            "12Y05, 12F10, 11y16, 68Q25"
        ]
    },
    {
        "title": "Probing the Natural Language Inference Task with Automated Reasoning   Tools",
        "authors": [
            "Zaid Marji",
            "Animesh Nighojkar",
            "John Licato"
        ],
        "summary": "The Natural Language Inference (NLI) task is an important task in modern NLP, as it asks a broad question to which many other tasks may be reducible: Given a pair of sentences, does the first entail the second? Although the state-of-the-art on current benchmark datasets for NLI are deep learning-based, it is worthwhile to use other techniques to examine the logical structure of the NLI task. We do so by testing how well a machine-oriented controlled natural language (Attempto Controlled English) can be used to parse NLI sentences, and how well automated theorem provers can reason over the resulting formulae. To improve performance, we develop a set of syntactic and semantic transformation rules. We report their performance, and discuss implications for NLI and logic-based NLP.",
        "published": "2020-05-06T03:18:11Z",
        "link": "http://arxiv.org/abs/2005.02573v1",
        "categories": [
            "cs.AI",
            "cs.CL",
            "cs.SC"
        ]
    },
    {
        "title": "Towards Concise, Machine-discovered Proofs of Gödel's Two   Incompleteness Theorems",
        "authors": [
            "Elijah Malaby",
            "Bradley Dragun",
            "John Licato"
        ],
        "summary": "There is an increasing interest in applying recent advances in AI to automated reasoning, as it may provide useful heuristics in reasoning over formalisms in first-order, second-order, or even meta-logics. To facilitate this research, we present MATR, a new framework for automated theorem proving explicitly designed to easily adapt to unusual logics or integrate new reasoning processes. MATR is formalism-agnostic, highly modular, and programmer-friendly. We explain the high-level design of MATR as well as some details of its implementation. To demonstrate MATR's utility, we then describe a formalized metalogic suitable for proofs of G\\\"odel's Incompleteness Theorems, and report on our progress using our metalogic in MATR to semi-autonomously generate proofs of both the First and Second Incompleteness Theorems.",
        "published": "2020-05-06T03:29:34Z",
        "link": "http://arxiv.org/abs/2005.02576v1",
        "categories": [
            "cs.LO",
            "cs.AI",
            "cs.SC"
        ]
    },
    {
        "title": "Algorithmic Averaging for Studying Periodic Orbits of Planar   Differential Systems",
        "authors": [
            "Bo Huang"
        ],
        "summary": "One of the main open problems in the qualitative theory of real planar differential systems is the study of limit cycles. In this article, we present an algorithmic approach for detecting how many limit cycles can bifurcate from the periodic orbits of a given polynomial differential center when it is perturbed inside a class of polynomial differential systems via the averaging method. We propose four symbolic algorithms to implement the averaging method. The first algorithm is based on the change of polar coordinates that allows one to transform a considered differential system to the normal form of averaging. The second algorithm is used to derive the solutions of certain differential systems associated to the unperturbed term of the normal of averaging. The third algorithm exploits the partial Bell polynomials and allows one to compute the integral formula of the averaged functions at any order. The last algorithm is based on the aforementioned algorithms and determines the exact expressions of the averaged functions for the considered differential systems. The implementation of our algorithms is discussed and evaluated using several examples. The experimental results have extended the existing relevant results for certain classes of differential systems.",
        "published": "2020-05-06T07:12:36Z",
        "link": "http://arxiv.org/abs/2005.03487v2",
        "categories": [
            "cs.SC",
            "math.DS"
        ]
    },
    {
        "title": "Efficient Exact Verification of Binarized Neural Networks",
        "authors": [
            "Kai Jia",
            "Martin Rinard"
        ],
        "summary": "Concerned with the reliability of neural networks, researchers have developed verification techniques to prove their robustness. Most verifiers work with real-valued networks. Unfortunately, the exact (complete and sound) verifiers face scalability challenges and provide no correctness guarantees due to floating point errors. We argue that Binarized Neural Networks (BNNs) provide comparable robustness and allow exact and significantly more efficient verification. We present a new system, EEV, for efficient and exact verification of BNNs. EEV consists of two parts: (i) a novel SAT solver that speeds up BNN verification by natively handling the reified cardinality constraints arising in BNN encodings; and (ii) strategies to train solver-friendly robust BNNs by inducing balanced layer-wise sparsity and low cardinality bounds, and adaptively cancelling the gradients. We demonstrate the effectiveness of EEV by presenting the first exact verification results for L-inf-bounded adversarial robustness of nontrivial convolutional BNNs on the MNIST and CIFAR10 datasets. Compared to exact verification of real-valued networks of the same architectures on the same tasks, EEV verifies BNNs hundreds to thousands of times faster, while delivering comparable verifiable accuracy in most cases.",
        "published": "2020-05-07T16:34:30Z",
        "link": "http://arxiv.org/abs/2005.03597v2",
        "categories": [
            "cs.AI",
            "cs.CV",
            "cs.LG",
            "cs.LO",
            "cs.SC"
        ]
    },
    {
        "title": "On the complexity of computing integral bases of function fields",
        "authors": [
            "Simon Abelard"
        ],
        "summary": "Let $\\mathcal{C}$ be a plane curve given by an equation $f(x,y)=0$ with $f\\in K[x][y]$ a monic squarefree polynomial. We study the problem of computing an integral basis of the algebraic function field $K(\\mathcal{C})$ and give new complexity bounds for three known algorithms dealing with this problem. For each algorithm, we study its subroutines and, when it is possible, we modify or replace them so as to take advantage of faster primitives. Then, we combine complexity results to derive an overall complexity estimate for each algorithm. In particular, we modify an algorithm due to B\\\"ohm et al. and achieve a quasi-optimal runtime.",
        "published": "2020-05-08T11:29:09Z",
        "link": "http://arxiv.org/abs/2005.03964v1",
        "categories": [
            "cs.SC",
            "math.AC",
            "math.AG"
        ]
    },
    {
        "title": "On Rational and Hypergeometric Solutions of Linear Ordinary Difference   Equations in $Π\\mathbfΣ^*$-field extensions",
        "authors": [
            "Sergei A. Abramov",
            "Manuel Bronstein",
            "Marko Petkovšek",
            "Carsten Schneider"
        ],
        "summary": "We present a complete algorithm that computes all hypergeometric solutions of homogeneous linear difference equations and rational solutions of parameterized linear difference equations in the setting of $\\Pi\\Sigma^*$-fields. More generally, we provide a flexible framework for a big class of difference fields that is built by a tower of $\\Pi\\Sigma^*$-field extensions over a difference field that satisfies certain algorithmic properties. As a consequence one can compute all solutions in terms of indefinite nested sums and products that arise within the components of a parameterized linear difference equation, and one can find all hypergeometric solutions that are defined over the arising sums and products of a homogeneous linear difference equation.",
        "published": "2020-05-11T09:15:31Z",
        "link": "http://arxiv.org/abs/2005.04944v2",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Towards Efficient Normalizers of Primitive Groups",
        "authors": [
            "Sergio Siccha"
        ],
        "summary": "We present the ideas behind an algorithm to compute normalizers of primitive groups with non-regular socle in polynomial time. We highlight a concept we developed called permutation morphisms and present timings for a partial implementation of our algorithm. This article is a collection of results from the author's PhD thesis.",
        "published": "2020-05-11T10:14:31Z",
        "link": "http://arxiv.org/abs/2005.04979v1",
        "categories": [
            "math.GR",
            "cs.SC",
            "20B15 (Primary) 20B40, 68W30 (Secondary)",
            "F.2.2; G.2.1"
        ]
    },
    {
        "title": "Positional Games and QBF: A Polished Encoding",
        "authors": [
            "Valentin Mayer-Eichberger",
            "Abdallah Saffidine"
        ],
        "summary": "Positional games are a mathematical class of two-player games comprising Tic-tac-toe and its generalizations. We propose a novel encoding of these games into Quantified Boolean Formulas (QBFs) such that a game instance admits a winning strategy for the first player if and only if the corresponding formula is true. Our approach improves over previous QBF encodings of games in multiple ways. First, it is generic and lets us encode other positional games, such as Hex. Second, the structural properties of positional games, together with careful treatment of illegal moves, let us generate more compact instances that can be solved faster by state-of-the-art QBF solvers. We establish the latter fact through extensive experiments. Finally, the compactness of our new encoding makes it feasible to translate realistic game problems. We identify a few such problems of historical significance and put them forward to the QBF community as milestones of increasing difficulty.",
        "published": "2020-05-11T13:32:03Z",
        "link": "http://arxiv.org/abs/2005.05098v2",
        "categories": [
            "cs.LO",
            "cs.AI",
            "cs.GT",
            "cs.SC"
        ]
    },
    {
        "title": "A modular extension for a computer algebra system",
        "authors": [
            "Migran N. Gevorkyan",
            "Anna V. Korolkova",
            "Dmitry S. Kulyabov",
            "Leonid A. Sevastianov"
        ],
        "summary": "Computer algebra systems are complex software systems that cover a wide range of scientific and practical problems. However, the absolute coverage cannot be achieved. Often, it is required to create a user extension for an existing computer algebra system. In this case, the extensibility of the system should be taken into account. In this paper, we consider a technology for extending the SymPy computer algebra system with a low-level module that implements a random number generator.",
        "published": "2020-05-11T17:05:30Z",
        "link": "http://arxiv.org/abs/2005.05261v1",
        "categories": [
            "cs.MS",
            "cs.SC"
        ]
    },
    {
        "title": "The Extended Theory of Trees and Algebraic (Co)datatypes",
        "authors": [
            "Fabian Zaiser",
            "C. -H. Luke Ong"
        ],
        "summary": "The first-order theory of finite and infinite trees has been studied since the eighties, especially by the logic programming community. Following Djelloul, Dao and Fr\\\"uhwirth, we consider an extension of this theory with an additional predicate for finiteness of trees, which is useful for expressing properties about (not just datatypes but also) codatatypes. Based on their work, we present a simplification procedure that determines whether any given (not necessarily closed) formula is satisfiable, returning a simplified formula which enables one to read off all possible models. Our extension makes the algorithm usable for algebraic (co)datatypes, which was impossible in their original work due to restrictive assumptions. We also provide a prototype implementation of our simplification procedure and evaluate it on instances from the SMT-LIB.",
        "published": "2020-05-13T23:12:42Z",
        "link": "http://arxiv.org/abs/2005.06659v2",
        "categories": [
            "cs.LO",
            "cs.SC"
        ]
    },
    {
        "title": "Generalizing The Davenport-Mahler-Mignotte Bound -- The Weighted Case",
        "authors": [
            "Vikram Sharma"
        ],
        "summary": "Root separation bounds play an important role as a complexity measure in understanding the behaviour of various algorithms in computational algebra, e.g., root isolation algorithms. A classic result in the univariate setting is the Davenport-Mahler-Mignotte (DMM) bound. One way to state the bound is to consider a directed acyclic graph $(V,E)$ on a subset of roots of a degree $d$ polynomial $f(z) \\in \\mathbb{C}[z]$, where the edges point from a root of smaller absolute value to one of larger absolute, and the in-degrees of all vertices is at most one. Then the DMM bound is an amortized lower bound on the following product: $\\prod_{(\\alpha,\\beta) \\in E}|\\alpha-\\beta|$. However, the lower bound involves the discriminant of the polynomial $f$, and becomes trivial if the polynomial is not square-free. This was resolved by Eigenwillig, (2008), by using a suitable subdiscriminant instead of the discriminant. Escorcielo-Perrucci, 2016, further dropped the in-degree constraint on the graph by using the theory of finite differences. Emiris et al., 2019, have generalized their result to handle the case where the exponent of the term $|\\alpha-\\beta|$ in the product is at most the multiplicity of either of the roots. In this paper, we generalize these results by allowing arbitrary positive integer weights on the edges of the graph, i.e., for a weight function $w: E \\rightarrow \\mathbb{Z}_{>0}$, we derive an amortized lower bound on $\\prod_{(\\alpha,\\beta) \\in E}|\\alpha-\\beta|^{w(\\alpha,\\beta)}$. Such a product occurs in the complexity estimates of some recent algorithms for root clustering (e.g., Becker et al., 2016), where the weights are usually some function of the multiplicity of the roots. Because of its amortized nature, our bound is arguably better than the bounds obtained by manipulating existing results to accommodate the weights.",
        "published": "2020-05-16T02:16:16Z",
        "link": "http://arxiv.org/abs/2005.07843v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Neural Collaborative Reasoning",
        "authors": [
            "Hanxiong Chen",
            "Shaoyun Shi",
            "Yunqi Li",
            "Yongfeng Zhang"
        ],
        "summary": "Existing Collaborative Filtering (CF) methods are mostly designed based on the idea of matching, i.e., by learning user and item embeddings from data using shallow or deep models, they try to capture the associative relevance patterns in data, so that a user embedding can be matched with relevant item embeddings using designed or learned similarity functions. However, as a cognition rather than a perception intelligent task, recommendation requires not only the ability of pattern recognition and matching from data, but also the ability of cognitive reasoning in data. In this paper, we propose to advance Collaborative Filtering (CF) to Collaborative Reasoning (CR), which means that each user knows part of the reasoning space, and they collaborate for reasoning in the space to estimate preferences for each other. Technically, we propose a Neural Collaborative Reasoning (NCR) framework to bridge learning and reasoning. Specifically, we integrate the power of representation learning and logical reasoning, where representations capture similarity patterns in data from perceptual perspectives, and logic facilitates cognitive reasoning for informed decision making. An important challenge, however, is to bridge differentiable neural networks and symbolic reasoning in a shared architecture for optimization and inference. To solve the problem, we propose a modularized reasoning architecture, which learns logical operations such as AND ($\\wedge$), OR ($\\vee$) and NOT ($\\neg$) as neural modules for implication reasoning ($\\rightarrow$). In this way, logical expressions can be equivalently organized as neural networks, so that logical reasoning and prediction can be conducted in a continuous space. Experiments on real-world datasets verified the advantages of our framework compared with both shallow, deep and reasoning models.",
        "published": "2020-05-16T23:29:31Z",
        "link": "http://arxiv.org/abs/2005.08129v5",
        "categories": [
            "cs.IR",
            "cs.AI",
            "cs.LG",
            "cs.SC"
        ]
    },
    {
        "title": "An Algebraic Model For Quorum Systems",
        "authors": [
            "Alex Pellegrini",
            "Luca Zanolini"
        ],
        "summary": "Quorum systems are a key mathematical abstraction in distributed fault-tolerant computing for capturing trust assumptions. A quorum system is a collection of subsets of all processes, called quorums, with the property that each pair of quorums have a non-empty intersection. They can be found at the core of many reliable distributed systems, such as cloud computing platforms, distributed storage systems and blockchains. In this paper we give a new interpretation of quorum systems, starting with classical majority-based quorum systems and extending this to Byzantine quorum systems. We propose an algebraic representation of the theory underlying quorum systems making use of multivariate polynomial ideals, incorporating properties of these systems, and studying their algebraic varieties. To achieve this goal we will exploit properties of Boolean Groebner bases. The nice nature of Boolean Groebner bases allows us to avoid part of the combinatorial computations required to check consistency and availability of quorum systems. Our results provide a novel approach to test quorum systems properties from both algebraic and algorithmic perspectives.",
        "published": "2020-05-18T08:48:41Z",
        "link": "http://arxiv.org/abs/2005.08536v2",
        "categories": [
            "cs.SC",
            "cs.DC"
        ]
    },
    {
        "title": "Applying Genetic Programming to Improve Interpretability in Machine   Learning Models",
        "authors": [
            "Leonardo Augusto Ferreira",
            "Frederico Gadelha Guimarães",
            "Rodrigo Silva"
        ],
        "summary": "Explainable Artificial Intelligence (or xAI) has become an important research topic in the fields of Machine Learning and Deep Learning. In this paper, we propose a Genetic Programming (GP) based approach, named Genetic Programming Explainer (GPX), to the problem of explaining decisions computed by AI systems. The method generates a noise set located in the neighborhood of the point of interest, whose prediction should be explained, and fits a local explanation model for the analyzed sample. The tree structure generated by GPX provides a comprehensible analytical, possibly non-linear, symbolic expression which reflects the local behavior of the complex model. We considered three machine learning techniques that can be recognized as complex black-box models: Random Forest, Deep Neural Network and Support Vector Machine in twenty data sets for regression and classifications problems. Our results indicate that the GPX is able to produce more accurate understanding of complex models than the state of the art. The results validate the proposed approach as a novel way to deploy GP to improve interpretability.",
        "published": "2020-05-18T16:09:49Z",
        "link": "http://arxiv.org/abs/2005.09512v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.NE",
            "cs.SC",
            "F.3.1; I.1.4; I.2.2; I.2.6"
        ]
    },
    {
        "title": "Pegasus: Sound Continuous Invariant Generation",
        "authors": [
            "Andrew Sogokon",
            "Stefan Mitsch",
            "Yong Kiam Tan",
            "Katherine Cordwell",
            "André Platzer"
        ],
        "summary": "Continuous invariants are an important component in deductive verification of hybrid and continuous systems. Just like discrete invariants are used to reason about correctness in discrete systems without having to unroll their loops, continuous invariants are used to reason about differential equations without having to solve them. Automatic generation of continuous invariants remains one of the biggest practical challenges to the automation of formal proofs of safety for hybrid systems. There are at present many disparate methods available for generating continuous invariants; however, this wealth of diverse techniques presents a number of challenges, with different methods having different strengths and weaknesses. To address some of these challenges, we develop Pegasus: an automatic continuous invariant generator which allows for combinations of various methods, and integrate it with the KeYmaera X theorem prover for hybrid systems. We describe some of the architectural aspects of this integration, comment on its methods and challenges, and present an experimental evaluation on a suite of benchmarks.",
        "published": "2020-05-19T10:19:14Z",
        "link": "http://arxiv.org/abs/2005.09348v2",
        "categories": [
            "cs.SC",
            "cs.LO",
            "F.3.1; F.4.1; G.4; I.1"
        ]
    },
    {
        "title": "Fast Decoding of Codes in the Rank, Subspace, and Sum-Rank Metric",
        "authors": [
            "Hannes Bartz",
            "Thomas Jerkovits",
            "Sven Puchinger",
            "Johan Rosenkilde"
        ],
        "summary": "We speed up existing decoding algorithms for three code classes in different metrics: interleaved Gabidulin codes in the rank metric, lifted interleaved Gabidulin codes in the subspace metric, and linearized Reed-Solomon codes in the sum-rank metric. The speed-ups are achieved by new algorithms that reduce the cores of the underlying computational problems of the decoders to one common tool: computing left and right approximant bases of matrices over skew polynomial rings. To accomplish this, we describe a skew-analogue of the existing PM-Basis algorithm for matrices over ordinary polynomials. This captures the bulk of the work in multiplication of skew polynomials, and the complexity benefit comes from existing algorithms performing this faster than in classical quadratic complexity. The new algorithms for the various decoding-related computational problems are interesting in their own and have further applications, in particular parts of decoders of several other codes and foundational problems related to the remainder-evaluation of skew polynomials.",
        "published": "2020-05-20T08:53:58Z",
        "link": "http://arxiv.org/abs/2005.09916v2",
        "categories": [
            "cs.IT",
            "cs.SC",
            "math.IT"
        ]
    },
    {
        "title": "A machine learning based software pipeline to pick the variable ordering   for algorithms with polynomial inputs",
        "authors": [
            "Dorian Florescu",
            "Matthew England"
        ],
        "summary": "We are interested in the application of Machine Learning (ML) technology to improve mathematical software. It may seem that the probabilistic nature of ML tools would invalidate the exact results prized by such software, however, the algorithms which underpin the software often come with a range of choices which are good candidates for ML application. We refer to choices which have no effect on the mathematical correctness of the software, but do impact its performance.   In the past we experimented with one such choice: the variable ordering to use when building a Cylindrical Algebraic Decomposition (CAD). We used the Python library Scikit-Learn (sklearn) to experiment with different ML models, and developed new techniques for feature generation and hyper-parameter selection.   These techniques could easily be adapted for making decisions other than our immediate application of CAD variable ordering. Hence in this paper we present a software pipeline to use sklearn to pick the variable ordering for an algorithm that acts on a polynomial system. The code described is freely available online.",
        "published": "2020-05-22T16:00:04Z",
        "link": "http://arxiv.org/abs/2005.11251v1",
        "categories": [
            "cs.SC",
            "cs.LG",
            "68W30, 68T05, 03C10",
            "I.2.6; I.1.0"
        ]
    },
    {
        "title": "miniKanren as a Tool for Symbolic Computation in Python",
        "authors": [
            "Brandon T. Willard"
        ],
        "summary": "In this article, we give a brief overview of the current state and future potential of symbolic computation within the Python statistical modeling and machine learning community. We detail the use of miniKanren as an underlying framework for term rewriting and symbolic mathematics, as well as its ability to orchestrate the use of existing Python libraries. We also discuss the relevance and potential of relational programming for implementing more robust, portable, domain-specific \"math-level\" optimizations--with a slight focus on Bayesian modeling. Finally, we describe the work going forward and raise some questions regarding potential cross-overs between statistical modeling and programming language theory.",
        "published": "2020-05-24T03:09:08Z",
        "link": "http://arxiv.org/abs/2005.11644v3",
        "categories": [
            "cs.PL",
            "cs.SC"
        ]
    },
    {
        "title": "First Neural Conjecturing Datasets and Experiments",
        "authors": [
            "Josef Urban",
            "Jan Jakubův"
        ],
        "summary": "We describe several datasets and first experiments with creating conjectures by neural methods. The datasets are based on the Mizar Mathematical Library processed in several forms and the problems extracted from it by the MPTP system and proved by the E prover using the ENIGMA guidance. The conjecturing experiments use the Transformer architecture and in particular its GPT-2 implementation.",
        "published": "2020-05-29T16:46:25Z",
        "link": "http://arxiv.org/abs/2005.14664v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.LO",
            "cs.NE",
            "cs.SC"
        ]
    },
    {
        "title": "Nonlinear observability algorithms with known and unknown inputs:   analysis and implementation",
        "authors": [
            "Nerea Martínez",
            "Alejandro F. Villaverde"
        ],
        "summary": "The observability of a dynamical system is affected by the presence of external inputs, either known (such as control actions) or unknown (disturbances). Inputs of unknown magnitude are especially detrimental for observability, and they also complicate its analysis. Hence the availability of computational tools capable of analysing the observability of nonlinear systems with unknown inputs has been limited until lately. Two symbolic algorithms based on differential geometry, ORC-DF and FISPO, have been recently proposed for this task, but their critical analysis and comparison is still lacking. Here we perform an analytical comparison of both algorithms and evaluate their performance on a set of problems, discussing their strengths and limitations. Additionally, we use these analyses to provide insights about certain aspects of the relationship between inputs and observability. We find that, while ORC-DF and FISPO follow a similar approach, they differ in key aspects that can have a substantial influence on their applicability and computational cost. The FISPO algorithm is more generally applicable, since it can analyse any nonlinear ODE model. The ORC-DF algorithm analyses models that are affine in the inputs, and if those models have known inputs it is sometimes more efficient. Thus, the optimal choice of a method depends on the characteristics of the problem under consideration. To facilitate the use of both algorithms we implement the ORC-DF algorithm in a new version of STRIKE-GOLDD, a MATLAB toolbox for structural identifiability and observability analysis. Since this software tool already had an implementation of the FISPO algorithm, the new release allows modellers and model users the convenience of choosing between different algorithms in a single tool, without changing the coding of their model.",
        "published": "2020-06-01T11:40:47Z",
        "link": "http://arxiv.org/abs/2006.00859v1",
        "categories": [
            "eess.SY",
            "cs.SC",
            "cs.SY",
            "math.DG"
        ]
    },
    {
        "title": "Good pivots for small sparse matrices",
        "authors": [
            "Manuel Kauers",
            "Jakob Moosbauer"
        ],
        "summary": "For sparse matrices up to size $8 \\times 8$, we determine optimal choices for pivot selection in Gaussian elimination. It turns out that they are slightly better than the pivots chosen by a popular pivot selection strategy, so there is some room for improvement. We then create a pivot selection strategy using machine learning and find that it indeed leads to a small improvement compared to the classical strategy.",
        "published": "2020-06-02T14:07:56Z",
        "link": "http://arxiv.org/abs/2006.01623v2",
        "categories": [
            "cs.SC",
            "cs.LG",
            "68W30"
        ]
    },
    {
        "title": "Characterizing an Analogical Concept Memory for Architectures   Implementing the Common Model of Cognition",
        "authors": [
            "Shiwali Mohan",
            "Matt Klenk",
            "Matthew Shreve",
            "Kent Evans",
            "Aaron Ang",
            "John Maxwell"
        ],
        "summary": "Architectures that implement the Common Model of Cognition - Soar, ACT-R, and Sigma - have a prominent place in research on cognitive modeling as well as on designing complex intelligent agents. In this paper, we explore how computational models of analogical processing can be brought into these architectures to enable concept acquisition from examples obtained interactively. We propose a new analogical concept memory for Soar that augments its current system of declarative long-term memories. We frame the problem of concept learning as embedded within the larger context of interactive task learning (ITL) and embodied language processing (ELP). We demonstrate that the analogical learning methods implemented in the proposed memory can quickly learn a diverse types of novel concepts that are useful not only in recognition of a concept in the environment but also in action selection. Our approach has been instantiated in an implemented cognitive system \\textsc{Aileen} and evaluated on a simulated robotic domain.",
        "published": "2020-06-02T21:54:03Z",
        "link": "http://arxiv.org/abs/2006.01962v3",
        "categories": [
            "cs.AI",
            "cs.HC",
            "cs.RO",
            "cs.SC"
        ]
    },
    {
        "title": "Analogical proportions",
        "authors": [
            "Christian Antić"
        ],
        "summary": "Analogy-making is at the core of human and artificial intelligence and creativity with applications to such diverse tasks as proving mathematical theorems and building mathematical theories, common sense reasoning, learning, language acquisition, and story telling. This paper introduces from first principles an abstract algebraic framework of analogical proportions of the form `$a$ is to $b$ what $c$ is to $d$' in the general setting of universal algebra. This enables us to compare mathematical objects possibly across different domains in a uniform way which is crucial for AI-systems. It turns out that our notion of analogical proportions has appealing mathematical properties. As we construct our model from first principles using only elementary concepts of universal algebra, and since our model questions some basic properties of analogical proportions presupposed in the literature, to convince the reader of the plausibility of our model we show that it can be naturally embedded into first-order logic via model-theoretic types and prove from that perspective that analogical proportions are compatible with structure-preserving mappings. This provides conceptual evidence for its applicability. In a broader sense, this paper is a first step towards a theory of analogical reasoning and learning systems with potential applications to fundamental AI-problems like common sense reasoning and computational learning and creativity.",
        "published": "2020-06-04T13:44:36Z",
        "link": "http://arxiv.org/abs/2006.02854v15",
        "categories": [
            "cs.LO",
            "cs.AI",
            "cs.LG",
            "cs.SC"
        ]
    },
    {
        "title": "Decomposable sparse polynomial systems",
        "authors": [
            "Taylor Brysiewicz",
            "Jose Israel Rodriguez",
            "Frank Sottile",
            "Thomas Yahl"
        ],
        "summary": "The Macaulay2 package DecomposableSparseSystems implements methods for studying and numerically solving decomposable sparse polynomial systems. We describe the structure of decomposable sparse systems and explain how the methods in this package may be used to exploit this structure, with examples.",
        "published": "2020-06-04T22:18:32Z",
        "link": "http://arxiv.org/abs/2006.03154v1",
        "categories": [
            "math.AG",
            "cs.NA",
            "cs.SC",
            "math.NA",
            "14M25, 65H10, 65H20"
        ]
    },
    {
        "title": "Walsh functions, scrambled $(0,m,s)$-nets, and negative covariance:   applying symbolic computation to quasi-Monte Carlo integration",
        "authors": [
            "Jaspar Wiart",
            "Elaine Wong"
        ],
        "summary": "We investigate base $b$ Walsh functions for which the variance of the integral estimator based on a scrambled $(0,m,s)$-net in base $b$ is less than or equal to that of the Monte-Carlo estimator based on the same number of points. First we compute the Walsh decomposition for the joint probability density function of two distinct points randomly chosen from a scrambled $(t,m,s)$-net in base $b$ in terms of certain counting numbers and simplify it in the special case $t$ is zero. Using this, we obtain an expression for the covariance of the integral estimator in terms of the Walsh coefficients of the function. Finally, we prove that the covariance of the integral estimator is negative when the Walsh coefficients of the function satisfy a certain decay condition. To do this, we use creative telescoping and recurrence solving algorithms from symbolic computation to find a sign equivalent closed form expression for the covariance term.",
        "published": "2020-06-11T06:51:17Z",
        "link": "http://arxiv.org/abs/2006.06225v1",
        "categories": [
            "math.NA",
            "cs.NA",
            "cs.SC"
        ]
    },
    {
        "title": "Pointer Data Structure Synthesis from Answer Set Programming   Specifications",
        "authors": [
            "Sarat Chandra Varanasi",
            "Neeraj Mittal",
            "Gopal Gupta"
        ],
        "summary": "We develop an inductive proof-technique to generate imperative programs for pointer data structures from behavioural specifications expressed in the Answer Set Programming (ASP) formalism. ASP is a non-monotonic logic based formalism that employs negation-as-failure which helps emulate the human thought process, allowing domain experts to model desired system behaviour succinctly. We argue in this paper that ASP's reliance on negation-as-failure makes it a better formalism than those based on first-order logic for writing formal specifications. We assume the a domain expert provides the representation of inductively defined data structures along with a specification of its operations. Our procedures combined with our novel proof-technique reason over the specifications and automatically generate an imperative program. Our proof-technique leverages the idea of partial deduction to simplify logical specifications. By algebraically simplifying logical specifications we arrive at a residual specification which can be interpreted as an appropriate imperative program. This work is in the realm of constructing programs that are correct according to a given specification.",
        "published": "2020-06-12T19:45:35Z",
        "link": "http://arxiv.org/abs/2006.07440v2",
        "categories": [
            "cs.LO",
            "cs.SC"
        ]
    },
    {
        "title": "Computing Igusa's local zeta function of univariates in deterministic   polynomial-time",
        "authors": [
            "Ashish Dwivedi",
            "Nitin Saxena"
        ],
        "summary": "Igusa's local zeta function $Z_{f,p}(s)$ is the generating function that counts the number of integral roots, $N_{k}(f)$, of $f(\\mathbf x) \\bmod p^k$, for all $k$. It is a famous result, in analytic number theory, that $Z_{f,p}$ is a rational function in $\\mathbb{Q}(p^s)$. We give an elementary proof of this fact for a univariate polynomial $f$. Our proof is constructive as it gives a closed-form expression for the number of roots $N_{k}(f)$.   Our proof, when combined with the recent root-counting algorithm of (Dwivedi, Mittal, Saxena, CCC, 2019), yields the first deterministic poly($|f|, \\log p$) time algorithm to compute $Z_{f,p}(s)$. Previously, an algorithm was known only in the case when $f$ completely splits over $\\mathbb{Q}_p$; it required the rational roots to use the concept of generating function of a tree (Z\\'u\\~niga-Galindo, J.Int.Seq., 2003).",
        "published": "2020-06-16T04:59:41Z",
        "link": "http://arxiv.org/abs/2006.08926v1",
        "categories": [
            "math.NT",
            "cs.CC",
            "cs.DS",
            "cs.SC",
            "11S40, 68Q01, 68W30 (Primary) 11Y16, 14G50 (Secondary)"
        ]
    },
    {
        "title": "On the Complexity of Solving Generic Over-determined Bilinear Systems",
        "authors": [
            "John B. Baena",
            "Daniel Cabarcas",
            "Javier Verbel"
        ],
        "summary": "In this paper, we study the complexity of solving generic over-determined bilinear systems over a finite field $\\mathbb{F}$. Given a generic bilinear sequence $B \\in \\mathbb{F}[\\mathbf{x},\\mathbf{y}]$, with respect to a partition of variables $\\mathbf{x}$, $\\mathbf{y}$, we show that, the solutions of the system $B= \\mathbf{0}$ can be efficiently found on the $\\mathbb{F}[\\mathbf{y}]$-module generated by $B$. Following this observation, we propose three variations of Gr\\\"obner basis algorithms, that only involve multiplication by monomials in they-variables, namely, $\\mathbf{y}$-XL, based on the XL algorithm, $\\mathbf{y}$-MLX, based on the mutant XL algorithm, and $\\mathbf{y}$-HXL, basedon a hybrid approach. We define notions of regularity for over-determined bilinear systems,that capture the idea of genericity, and we develop the necessary theoretical tools to estimate the complexity of the algorithms for such sequences. We also present extensive experimental results, testing our conjecture, verifying our results, and comparing the complexity of the various methods.",
        "published": "2020-06-16T18:39:09Z",
        "link": "http://arxiv.org/abs/2006.09442v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Logic, Probability and Action: A Situation Calculus Perspective",
        "authors": [
            "Vaishak Belle"
        ],
        "summary": "The unification of logic and probability is a long-standing concern in AI, and more generally, in the philosophy of science. In essence, logic provides an easy way to specify properties that must hold in every possible world, and probability allows us to further quantify the weight and ratio of the worlds that must satisfy a property. To that end, numerous developments have been undertaken, culminating in proposals such as probabilistic relational models. While this progress has been notable, a general-purpose first-order knowledge representation language to reason about probabilities and dynamics, including in continuous settings, is still to emerge. In this paper, we survey recent results pertaining to the integration of logic, probability and actions in the situation calculus, which is arguably one of the oldest and most well-known formalisms. We then explore reduction theorems and programming interfaces for the language. These results are motivated in the context of cognitive robotics (as envisioned by Reiter and his colleagues) for the sake of concreteness. Overall, the advantage of proving results for such a general language is that it becomes possible to adapt them to any special-purpose fragment, including but not limited to popular probabilistic relational models.",
        "published": "2020-06-17T13:49:53Z",
        "link": "http://arxiv.org/abs/2006.09868v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.LO",
            "cs.SC"
        ]
    },
    {
        "title": "Toric Eigenvalue Methods for Solving Sparse Polynomial Systems",
        "authors": [
            "Matías R. Bender",
            "Simon Telen"
        ],
        "summary": "We consider the problem of computing homogeneous coordinates of points in a zero-dimensional subscheme of a compact, complex toric variety $X$. Our starting point is a homogeneous ideal $I$ in the Cox ring of $X$, which in practice might arise from homogenizing a sparse polynomial system. We prove a new eigenvalue theorem in the toric compact setting, which leads to a novel, robust numerical approach for solving this problem. Our method works in particular for systems having isolated solutions with arbitrary multiplicities. It depends on the multigraded regularity properties of $I$. We study these properties and provide bounds on the size of the matrices appearing in our approach when $I$ is a complete intersection.",
        "published": "2020-06-18T16:24:36Z",
        "link": "http://arxiv.org/abs/2006.10654v3",
        "categories": [
            "math.AG",
            "cs.SC",
            "14M25 (Primary), 65H04 (Secondary), 65H10, 65H17"
        ]
    },
    {
        "title": "A unified framework for equivalences in social networks",
        "authors": [
            "Nina Otter",
            "Mason A. Porter"
        ],
        "summary": "A key concern in network analysis is the study of social positions and roles of actors in a network. The notion of \"position\" refers to an equivalence class of nodes that have similar ties to other nodes, whereas a \"role\" is an equivalence class of compound relations that connect the same pairs of nodes. An open question in network science is whether it is possible to simultaneously perform role and positional analysis. Motivated by the principle of functoriality in category theory we propose a new method that allows to tie role and positional analysis together. We illustrate our methods on two well-studied data sets in network science.",
        "published": "2020-06-18T17:57:38Z",
        "link": "http://arxiv.org/abs/2006.10733v1",
        "categories": [
            "cs.SI",
            "cs.DM",
            "cs.SC",
            "math.CT"
        ]
    },
    {
        "title": "Neuro-Symbolic Visual Reasoning: Disentangling \"Visual\" from \"Reasoning\"",
        "authors": [
            "Saeed Amizadeh",
            "Hamid Palangi",
            "Oleksandr Polozov",
            "Yichen Huang",
            "Kazuhito Koishida"
        ],
        "summary": "Visual reasoning tasks such as visual question answering (VQA) require an interplay of visual perception with reasoning about the question semantics grounded in perception. However, recent advances in this area are still primarily driven by perception improvements (e.g. scene graph generation) rather than reasoning. Neuro-symbolic models such as Neural Module Networks bring the benefits of compositional reasoning to VQA, but they are still entangled with visual representation learning, and thus neural reasoning is hard to improve and assess on its own. To address this, we propose (1) a framework to isolate and evaluate the reasoning aspect of VQA separately from its perception, and (2) a novel top-down calibration technique that allows the model to answer reasoning questions even with imperfect perception. To this end, we introduce a differentiable first-order logic formalism for VQA that explicitly decouples question answering from visual perception. On the challenging GQA dataset, this framework is used to perform in-depth, disentangled comparisons between well-known VQA models leading to informative insights regarding the participating models as well as the task.",
        "published": "2020-06-20T08:48:29Z",
        "link": "http://arxiv.org/abs/2006.11524v3",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.CV",
            "cs.NE",
            "cs.SC",
            "stat.ML"
        ]
    },
    {
        "title": "Computer Algebra in Physics: The hidden SO(4) symmetry of the hydrogen   atom",
        "authors": [
            "Pascal Szriftgiser",
            "Edgardo S. Cheb-Terrab"
        ],
        "summary": "Pauli first noticed the hidden SO(4) symmetry for the Hydrogen atom in the early stages of quantum mechanics [1]. Departing from that symmetry, one can recover the spectrum of a spinless hydrogen atom and the degeneracy of its states without explicitly solving Schr\\\"odinger's equation [2]. In this paper, we derive that SO(4) symmetry and spectrum using a computer algebra system (CAS). While this problem is well known [3, 4], its solution involves several steps of manipulating expressions with tensorial quantum operators, simplifying them by taking into account a combination of commutator rules and Einstein's sum rule for repeated indices. Therefore, it is an excellent model to test the current status of CAS concerning this kind of quantum-and-tensor-algebra computations. Generally speaking, when capable, CAS can significantly help with manipulations that, like non-commutative tensor calculus subject to algebra rules, are tedious, time-consuming and error-prone. The presentation also shows a pattern of computer algebra operations that can be useful for systematically tackling more complicated symbolic problems of this kind.",
        "published": "2020-06-22T14:37:42Z",
        "link": "http://arxiv.org/abs/2006.12498v2",
        "categories": [
            "cs.SC",
            "math-ph",
            "math.MP",
            "physics.comp-ph",
            "quant-ph",
            "81-08",
            "I.1.1; G.4; J.2"
        ]
    },
    {
        "title": "Noetherian operators and primary decomposition",
        "authors": [
            "Justin Chen",
            "Marc Härkönen",
            "Robert Krone",
            "Anton Leykin"
        ],
        "summary": "Noetherian operators are differential operators that encode primary components of a polynomial ideal. We develop a framework, as well as algorithms, for computing Noetherian operators with local dual spaces, both symbolically and numerically. For a primary ideal, such operators provide an alternative representation to one given by a set of generators. This description fits well with numerical algebraic geometry, taking a step toward the goal of numerical primary decomposition.",
        "published": "2020-06-24T17:06:07Z",
        "link": "http://arxiv.org/abs/2006.13881v1",
        "categories": [
            "math.AG",
            "cs.SC",
            "math.AC",
            "14Q15, 14-04, 13N05, 65L80, 65D05"
        ]
    },
    {
        "title": "Machine learning the real discriminant locus",
        "authors": [
            "Edgar A. Bernal",
            "Jonathan D. Hauenstein",
            "Dhagash Mehta",
            "Margaret H. Regan",
            "Tingting Tang"
        ],
        "summary": "Parameterized systems of polynomial equations arise in many applications in science and engineering with the real solutions describing, for example, equilibria of a dynamical system, linkages satisfying design constraints, and scene reconstruction in computer vision. Since different parameter values can have a different number of real solutions, the parameter space is decomposed into regions whose boundary forms the real discriminant locus. This article views locating the real discriminant locus as a supervised classification problem in machine learning where the goal is to determine classification boundaries over the parameter space, with the classes being the number of real solutions. For multidimensional parameter spaces, this article presents a novel sampling method which carefully samples the parameter space. At each sample point, homotopy continuation is used to obtain the number of real solutions to the corresponding polynomial system. Machine learning techniques including nearest neighbor and deep learning are used to efficiently approximate the real discriminant locus. One application of having learned the real discriminant locus is to develop a real homotopy method that only tracks the real solution paths unlike traditional methods which track all~complex~solution~paths. Examples show that the proposed approach can efficiently approximate complicated solution boundaries such as those arising from the equilibria of the Kuramoto model.",
        "published": "2020-06-24T22:18:08Z",
        "link": "http://arxiv.org/abs/2006.14078v2",
        "categories": [
            "stat.ML",
            "cs.LG",
            "cs.SC",
            "math.AG",
            "stat.AP"
        ]
    },
    {
        "title": "Error Correcting Codes, finding polynomials of bounded degree agreeing   on a dense fraction of a set of points",
        "authors": [
            "Priyank Deshpande"
        ],
        "summary": "Here we present some revised arguments to a randomized algorithm proposed by Sudan to find the polynomials of bounded degree agreeing on a dense fraction of a set of points in $\\mathbb{F}^{2}$ for some field $\\mathbb{F}$.",
        "published": "2020-06-29T21:40:11Z",
        "link": "http://arxiv.org/abs/2007.00445v1",
        "categories": [
            "cs.SC",
            "cs.DS"
        ]
    },
    {
        "title": "Ideal Membership Problem for Boolean Minority",
        "authors": [
            "Arpitha P. Bharathi",
            "Monaldo Mastrolilli"
        ],
        "summary": "The Ideal Membership Problem (IMP) tests if an input polynomial $f\\in \\mathbb{F}[x_1,\\dots,x_n]$ with coefficients from a field $\\mathbb{F}$ belongs to a given ideal $I \\subseteq \\mathbb{F}[x_1,\\dots,x_n]$. It is a well-known fundamental problem with many important applications, though notoriously intractable in the general case. In this paper we consider the IMP for polynomial ideals encoding combinatorial problems and where the input polynomial $f$ has degree at most $d=O(1)$ (we call this problem IMP$_d$). A dichotomy result between ``hard'' (NP-hard) and ``easy'' (polynomial time) IMPs was recently achieved for Constraint Satisfaction Problems over finite domains [Bulatov FOCS'17, Zhuk FOCS'17] (this is equivalent to IMP$_0$) and IMP$_d$ for the Boolean domain [Mastrolilli SODA'19], both based on the classification of the IMP through functions called polymorphisms. The complexity of the IMP$_d$ for five polymorphisms has been solved in [Mastrolilli SODA'19] whereas for the ternary minority polymorphism it was incorrectly declared to have been resolved by a previous result. As a matter of fact the complexity of the IMP$_d$ for the ternary minority polymorphism is open. In this paper we provide the missing link by proving that the IMP$_d$ for Boolean combinatorial ideals whose constraints are closed under the minority polymorphism can be solved in polynomial time. This result, along with the results in [Mastrolilli SODA'19], completes the identification of the precise borderline of tractability for the IMP$_d$ for constrained problems over the Boolean domain. This paper is motivated by the pursuit of understanding the issue of bit complexity of Sum-of-Squares proofs raised by O'Donnell [ITCS'17]. Raghavendra and Weitz [ICALP'17] show how the IMP$_d$ tractability for combinatorial ideals implies bounded coefficients in Sum-of-Squares proofs.",
        "published": "2020-06-29T22:41:11Z",
        "link": "http://arxiv.org/abs/2006.16422v1",
        "categories": [
            "cs.CC",
            "cs.SC",
            "math.CO"
        ]
    },
    {
        "title": "Learning an arbitrary mixture of two multinomial logits",
        "authors": [
            "Wenpin Tang"
        ],
        "summary": "In this paper, we consider mixtures of multinomial logistic models (MNL), which are known to $\\epsilon$-approximate any random utility model. Despite its long history and broad use, rigorous results are only available for learning a uniform mixture of two MNLs. Continuing this line of research, we study the problem of learning an arbitrary mixture of two MNLs. We show that the identifiability of the mixture models may only fail on an algebraic variety of a negligible measure. This is done by reducing the problem of learning a mixture of two MNLs to the problem of solving a system of univariate quartic equations. We also devise an algorithm to learn any mixture of two MNLs using a polynomial number of samples and a linear number of queries, provided that a mixture of two MNLs over some finite universe is identifiable. Several numerical experiments and conjectures are also presented.",
        "published": "2020-07-01T03:33:52Z",
        "link": "http://arxiv.org/abs/2007.00204v2",
        "categories": [
            "stat.ML",
            "cs.CC",
            "cs.LG",
            "cs.SC"
        ]
    },
    {
        "title": "Improvement on Extrapolation of Species Abundance Distribution Across   Scales from Moments Across Scales",
        "authors": [
            "Saeid Alirezazadeh",
            "Khadijeh Alibabaei"
        ],
        "summary": "Raw moments are used as a way to estimate species abundance distribution. The almost linear pattern of the log transformation of raw moments across scales allow us to extrapolate species abundance distribution for larger areas. However, results may produce errors. Some of these errors are due to computational complexity, fittings of patterns, binning methods, and so on. We provide some methods to reduce some of the errors. The main result is introducing new techniques for evaluating a more accurate species abundance distributions across scales through moments across scales.",
        "published": "2020-07-01T12:55:11Z",
        "link": "http://arxiv.org/abs/2007.00451v3",
        "categories": [
            "q-bio.PE",
            "cs.SC"
        ]
    },
    {
        "title": "A Family of Denominator Bounds for First Order Linear Recurrence Systems",
        "authors": [
            "Mark van Hoeij",
            "Moulay Barkatou",
            "Johannes Middeke"
        ],
        "summary": "For linear recurrence systems, the problem of finding rational solutions is reduced to the problem of computing polynomial solutions by computing a content bound or a denominator bound. There are several bounds in the literature. The sharpest bound leads to polynomial solutions of lower degrees, but this advantage need not compensate for the time spent on computing that bound.   To strike the best balance between sharpness of the bound versus CPU time spent obtaining it, we will give a family of bounds. The $J$'th member of this family is similar to (Abramov, Barkatou, 1998) when $J=1$, similar to (van Hoeij, 1998) when $J$ is large, and novel for intermediate values of $J$, which give the best balance between sharpness and CPU time.   The setting for our content bounds are systems $\\tau(Y) = MY$ where $\\tau$ is an automorphism of a UFD, and $M$ is an invertible matrix with entries in its field of fractions. This setting includes the shift case, the $q$-shift case, the multi-basic case and others. We give two versions, a global version, and a version that bounds each entry separately.",
        "published": "2020-07-06T17:56:05Z",
        "link": "http://arxiv.org/abs/2007.02926v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "ACORNS: An Easy-To-Use Code Generator for Gradients and Hessians",
        "authors": [
            "Deshana Desai",
            "Etai Shuchatowitz",
            "Zhongshi Jiang",
            "Teseo Schneider",
            "Daniele Panozzo"
        ],
        "summary": "The computation of first and second-order derivatives is a staple in many computing applications, ranging from machine learning to scientific computing. We propose an algorithm to automatically differentiate algorithms written in a subset of C99 code and its efficient implementation as a Python script. We demonstrate that our algorithm enables automatic, reliable, and efficient differentiation of common algorithms used in physical simulation and geometry processing.",
        "published": "2020-07-09T22:11:48Z",
        "link": "http://arxiv.org/abs/2007.05094v1",
        "categories": [
            "cs.MS",
            "cs.SC"
        ]
    },
    {
        "title": "Learning Reasoning Strategies in End-to-End Differentiable Proving",
        "authors": [
            "Pasquale Minervini",
            "Sebastian Riedel",
            "Pontus Stenetorp",
            "Edward Grefenstette",
            "Tim Rocktäschel"
        ],
        "summary": "Attempts to render deep learning models interpretable, data-efficient, and robust have seen some success through hybridisation with rule-based systems, for example, in Neural Theorem Provers (NTPs). These neuro-symbolic models can induce interpretable rules and learn representations from data via back-propagation, while providing logical explanations for their predictions. However, they are restricted by their computational complexity, as they need to consider all possible proof paths for explaining a goal, thus rendering them unfit for large-scale applications. We present Conditional Theorem Provers (CTPs), an extension to NTPs that learns an optimal rule selection strategy via gradient-based optimisation. We show that CTPs are scalable and yield state-of-the-art results on the CLUTRR dataset, which tests systematic generalisation of neural models by learning to reason over smaller graphs and evaluating on larger ones. Finally, CTPs show better link prediction results on standard benchmarks in comparison with other neural-symbolic models, while being explainable. All source code and datasets are available online, at https://github.com/uclnlp/ctp.",
        "published": "2020-07-13T16:22:14Z",
        "link": "http://arxiv.org/abs/2007.06477v3",
        "categories": [
            "cs.AI",
            "cs.CL",
            "cs.LG",
            "cs.NE",
            "cs.SC"
        ]
    },
    {
        "title": "Explicit isomorphisms of quaternion algebras over quadratic global   fields",
        "authors": [
            "Tímea Csahók",
            "Péter Kutas",
            "Mickaël Montessinos",
            "Gergely Zábrádi"
        ],
        "summary": "Let $L$ be a separable quadratic extension of either $\\mathbb{Q}$ or $\\mathbb{F}_q(t)$. We propose efficient algorithms for finding isomorphisms between quaternion algebras over $L$. Our techniques are based on computing maximal one-sided ideals of the corestriction of a central simple $L$-algebra.",
        "published": "2020-07-14T11:53:20Z",
        "link": "http://arxiv.org/abs/2007.06981v5",
        "categories": [
            "math.NT",
            "cs.SC",
            "math.RA"
        ]
    },
    {
        "title": "Computing stable resultant-based minimal solvers by hiding a variable",
        "authors": [
            "Snehal Bhayani",
            "Zuzana Kukelova",
            "Janne Heikkilä"
        ],
        "summary": "Many computer vision applications require robust and efficient estimation of camera geometry. The robust estimation is usually based on solving camera geometry problems from a minimal number of input data measurements, i.e., solving minimal problems, in a RANSAC-style framework. Minimal problems often result in complex systems of polynomial equations. The existing state-of-the-art methods for solving such systems are either based on Gr\\\"obner bases and the action matrix method, which have been extensively studied and optimized in the recent years or recently proposed approach based on a sparse resultant computation using an extra variable.   In this paper, we study an interesting alternative sparse resultant-based method for solving sparse systems of polynomial equations by hiding one variable. This approach results in a larger eigenvalue problem than the action matrix and extra variable sparse resultant-based methods; however, it does not need to compute an inverse or elimination of large matrices that may be numerically unstable. The proposed approach includes several improvements to the standard sparse resultant algorithms, which significantly improves the efficiency and stability of the hidden variable resultant-based solvers as we demonstrate on several interesting computer vision problems. We show that for the studied problems, our sparse resultant based approach leads to more stable solvers than the state-of-the-art Gr\\\"obner bases-based solvers as well as existing sparse resultant-based solvers, especially in close to critical configurations. Our new method can be fully automated and incorporated into existing tools for the automatic generation of efficient minimal solvers.",
        "published": "2020-07-17T07:40:10Z",
        "link": "http://arxiv.org/abs/2007.10100v1",
        "categories": [
            "cs.CV",
            "cs.SC",
            "I.4; I.1"
        ]
    },
    {
        "title": "On the Complexity of Quadratization for Polynomial Differential   Equations",
        "authors": [
            "Mathieu Hemery",
            "François Fages",
            "Sylvain Soliman"
        ],
        "summary": "Chemical reaction networks (CRNs) are a standard formalism used in chemistry and biology to reason about the dynamics of molecular interaction networks. In their interpretation by ordinary differential equations, CRNs provide a Turing-complete model of analog computattion, in the sense that any computable function over the reals can be computed by a finite number of molecular species with a continuous CRN which approximates the result of that function in one of its components in arbitrary precision. The proof of that result is based on a previous result of Bournez et al. on the Turing-completeness of polyno-mial ordinary differential equations with polynomial initial conditions (PIVP). It uses an encoding of real variables by two non-negative variables for concentrations, and a transformation to an equivalent quadratic PIVP (i.e. with degrees at most 2) for restricting ourselves to at most bimolecular reactions. In this paper, we study the theoretical and practical complexities of the quadratic transformation. We show that both problems of minimizing either the number of variables (i.e., molecular species) or the number of monomials (i.e. elementary reactions) in a quadratic transformation of a PIVP are NP-hard. We present an encoding of those problems in MAX-SAT and show the practical complexity of this algorithm on a benchmark of quadratization problems inspired from CRN design problems.",
        "published": "2020-07-17T11:39:09Z",
        "link": "http://arxiv.org/abs/2007.08910v2",
        "categories": [
            "q-bio.QM",
            "cs.SC"
        ]
    },
    {
        "title": "Graphical Conditions for Rate Independence in Chemical Reaction Networks",
        "authors": [
            "Elisabeth Degrand",
            "François Fages",
            "Sylvain Soliman"
        ],
        "summary": "Chemical Reaction Networks (CRNs) provide a useful abstraction of molecular interaction networks in which molecular structures as well as mass conservation principles are abstracted away to focus on the main dynamical properties of the network structure. In their interpretation by ordinary differential equations, we say that a CRN with distinguished input and output species computes a positive real function $f : R+ $\\rightarrow$ R+$, if for any initial concentration x of the input species, the concentration of the output molecular species stabilizes at concentration f (x). The Turing-completeness of that notion of chemical analog computation has been established by proving that any computable real function can be computed by a CRN over a finite set of molecular species. Rate-independent CRNs form a restricted class of CRNs of high practical value since they enjoy a form of absolute robustness in the sense that the result is completely independent of the reaction rates and depends solely on the input concentrations. The functions computed by rate-independent CRNs have been characterized mathematically as the set of piecewise linear functions from input species. However, this does not provide a mean to decide whether a given CRN is rate-independent. In this paper, we provide graphical conditions on the Petri Net structure of a CRN which entail the rate-independence property either for all species or for some output species. We show that in the curated part of the Biomodels repository, among the 590 reaction models tested, 2 reaction graphs were found to satisfy our rate-independence conditions for all species, 94 for some output species, among which 29 for some non-trivial output species. Our graphical conditions are based on a non-standard use of the Petri net notions of place-invariants and siphons which are computed by constraint programming techniques for efficiency reasons.",
        "published": "2020-07-17T11:41:05Z",
        "link": "http://arxiv.org/abs/2007.15642v1",
        "categories": [
            "q-bio.MN",
            "cs.SC",
            "q-bio.QM"
        ]
    },
    {
        "title": "Bit-Slicing the Hilbert Space: Scaling Up Accurate Quantum Circuit   Simulation to a New Level",
        "authors": [
            "Yuan-Hung Tsai",
            "Jie-Hong R. Jiang",
            "Chiao-Shan Jhang"
        ],
        "summary": "Quantum computing is greatly advanced in recent years and is expected to transform the computation paradigm in the near future. Quantum circuit simulation plays a key role in the toolchain for the development of quantum hardware and software systems. However, due to the enormous Hilbert space of quantum states, simulating quantum circuits with classical computers is extremely challenging despite notable efforts have been made. In this paper, we enhance quantum circuit simulation in two dimensions: accuracy and scalability. The former is achieved by using an algebraic representation of complex numbers; the latter is achieved by bit-slicing the number representation and replacing matrix-vector multiplication with symbolic Boolean function manipulation. Experimental results demonstrate that our method can be superior to the state-of-the-art for various quantum circuits and can simulate certain benchmark families with up to tens of thousands of qubits.",
        "published": "2020-07-18T01:26:40Z",
        "link": "http://arxiv.org/abs/2007.09304v1",
        "categories": [
            "cs.ET",
            "cs.SC",
            "quant-ph"
        ]
    },
    {
        "title": "On Algorithmic Estimation of Analytic Complexity for Polynomial   Solutions to Hypergeometric Systems",
        "authors": [
            "Vitaly A. Krasikov"
        ],
        "summary": "The paper deals with the analytic complexity of solutions to bivariate holonomic hypergeometric systems of the Horn type. We obtain estimates on the analytic complexity of Puiseux polynomial solutions to the hypergeometric systems defined by zonotopes. We also propose algorithms of the analytic complexity estimation for polynomials.",
        "published": "2020-07-18T11:16:28Z",
        "link": "http://arxiv.org/abs/2007.09407v1",
        "categories": [
            "cs.SC",
            "math.AP"
        ]
    },
    {
        "title": "Computing Regular Meromorphic Differential Forms via Saito's Logarithmic   Residues",
        "authors": [
            "Shinichi Tajima",
            "Katsusuke Nabeshima"
        ],
        "summary": "Logarithmic differential forms and logarithmic vector fields associated to a hypersurface with an isolated singularity are considered in the context of computational complex analysis. As applications, based on the concept of torsion differential forms due to A.G. Aleksandrov, regular meromorphic differential forms introduced by D. Barlet and M. Kersken, and Brieskorn formulae on Gauss-Manin connections are investigated. (i) A method is given to describe singular parts of regular meromorphic differential forms in terms of non-trivial logarithmic vector fields via Saito's logarithmic residues. The resulting algorithm is illustrated by using examples. (ii) A new link between Brieskorn formulae and logarithmic vector fields is discovered and an expression that rewrites Brieskorn formulae in terms of non-trivial logarithmic vector fields is presented. A new effective method is described to compute non trivial logarithmic vector fields which are suitable for the computation of Gauss-Manin connections. Some examples are given for illustration.",
        "published": "2020-07-20T08:57:00Z",
        "link": "http://arxiv.org/abs/2007.09950v4",
        "categories": [
            "math.AG",
            "cs.SC",
            "32S05, 32A27"
        ]
    },
    {
        "title": "Interpretable Control by Reinforcement Learning",
        "authors": [
            "Daniel Hein",
            "Steffen Limmer",
            "Thomas A. Runkler"
        ],
        "summary": "In this paper, three recently introduced reinforcement learning (RL) methods are used to generate human-interpretable policies for the cart-pole balancing benchmark. The novel RL methods learn human-interpretable policies in the form of compact fuzzy controllers and simple algebraic equations. The representations as well as the achieved control performances are compared with two classical controller design methods and three non-interpretable RL methods. All eight methods utilize the same previously generated data batch and produce their controller offline - without interaction with the real benchmark dynamics. The experiments show that the novel RL methods are able to automatically generate well-performing policies which are at the same time human-interpretable. Furthermore, one of the methods is applied to automatically learn an equation-based policy for a hardware cart-pole demonstrator by using only human-player-generated batch data. The solution generated in the first attempt already represents a successful balancing policy, which demonstrates the methods applicability to real-world problems.",
        "published": "2020-07-20T09:35:04Z",
        "link": "http://arxiv.org/abs/2007.09964v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.RO",
            "cs.SC",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Groebner basis structure of ideal interpolation",
        "authors": [
            "Yihe Gong",
            "Xue Jiang"
        ],
        "summary": "We study the relationship between certain Groebner bases for zero dimensional ideals, and the interpolation condition functionals of ideal interpolation. Ideal interpolation is defined by a linear idempotent projector whose kernel is a polynomial ideal. In this paper, we propose the notion of \"reverse\" complete reduced basis. Based on the notion, we present a fast algorithm to compute the reduced Groebner basis for the kernel of ideal projector under an arbitrary compatible ordering. As an application, we show that knowing the affine variety makes available information concerning the reduced Groebner basis.",
        "published": "2020-07-23T07:31:04Z",
        "link": "http://arxiv.org/abs/2007.11830v2",
        "categories": [
            "cs.SC",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Globally Optimal Solution to Inverse Kinematics of 7DOF Serial   Manipulator",
        "authors": [
            "Pavel Trutman",
            "Safey El Din Mohab",
            "Didier Henrion",
            "Tomas Pajdla"
        ],
        "summary": "The Inverse Kinematics (IK) problem is to nd robot control parameters to bring it into the desired position under the kinematics and collision constraints. We present a global solution to the optimal IK problem for a general serial 7DOF manipulator with revolute joints and a quadratic polynomial objective function. We show that the kinematic constraints due to rotations can all be generated by second-degree polynomials. This is important since it signicantly simplies further step where we nd the optimal solution by Lasserre relaxations of non-convex polynomial systems. We demonstrate that the second relaxation is sucient to solve the 7DOF IK problem. Our approach is certiably globally optimal. We demonstrate the method on the 7DOF KUKA LBR IIWA manipulator and show that we are able to compute the optimal IK or certify in-feasibility in 99 % tested poses.",
        "published": "2020-07-24T15:00:04Z",
        "link": "http://arxiv.org/abs/2007.12550v1",
        "categories": [
            "cs.RO",
            "cs.SC",
            "math.OC"
        ]
    },
    {
        "title": "Cyclotomic Identity Testing and Applications",
        "authors": [
            "Nikhil Balaji",
            "Sylvain Perifel",
            "Mahsa Shirmohammadi",
            "James Worrell"
        ],
        "summary": "We consider the cyclotomic identity testing (CIT) problem: given a polynomial $f(x_1,\\ldots,x_k)$, decide whether $f(\\zeta_n^{e_1},\\ldots,\\zeta_n^{e_k})$ is zero, where $\\zeta_n = e^{2\\pi i/n}$ is a primitive complex $n$-th root of unity and $e_1,\\ldots,e_k$ are integers, represented in binary. When $f$ is given by an algebraic circuit, we give a randomized polynomial-time algorithm for CIT assuming the generalised Riemann hypothesis (GRH), and show that the problem is in coNP unconditionally. When $f$ is given by a circuit of polynomially bounded degree, we give a randomized NC algorithm. In case $f$ is a linear form we show that the problem lies in NC. Towards understanding when CIT can be solved in deterministic polynomial-time, we consider so-called diagonal depth-3 circuits, i.e., polynomials $f=\\sum_{i=1}^m g_i^{d_i}$, where $g_i$ is a linear form and $d_i$ a positive integer given in unary. We observe that a polynomial-time algorithm for CIT on this class would yield a sub-exponential-time algorithm for polynomial identity testing. However, assuming GRH, we show that if the linear forms~$g_i$ are all identical then CIT can be solved in polynomial time. Finally, we use our results to give a new proof that equality of compressed strings, i.e., strings presented using context-free grammars, can be decided in randomized NC.",
        "published": "2020-07-26T17:02:30Z",
        "link": "http://arxiv.org/abs/2007.13179v2",
        "categories": [
            "cs.CC",
            "cs.SC"
        ]
    },
    {
        "title": "On Bergman's Diamond Lemma for Ring Theory",
        "authors": [
            "Takao Inoué"
        ],
        "summary": "This expository and review paper deals with the Diamond Lemma for ring theory, which is proved in the first section of G. M. Bergman, The Diamond Lemma for Ring Theory, Advances in Mathematics, 29 (1978), pp. 178-218. No originality of the present note is claimed on the part of the author, except for some suggestions and figures. Throughout this paper, I shall mostly use Bergman's expressions in his paper. In Remarks and Notes, the reader will find some useful information on this topic.",
        "published": "2020-07-27T20:21:25Z",
        "link": "http://arxiv.org/abs/2007.13845v2",
        "categories": [
            "math.RT",
            "cs.SC",
            "16S15, 16-02"
        ]
    },
    {
        "title": "Parameter identifiability and input-output equations",
        "authors": [
            "Alexey Ovchinnikov",
            "Gleb Pogudin",
            "Peter Thompson"
        ],
        "summary": "Structural parameter identifiability is a property of a differential model with parameters that allows for the parameters to be determined from the model equations in the absence of noise. One of the standard approaches to assessing this problem is via input-output equations and, in particular, characteristic sets of differential ideals. The precise relation between identifiability and input-output identifiability is subtle. The goal of this note is to clarify this relation. The main results are:   1) identifiability implies input-output identifiability;   2) these notions coincide if the model does not have rational first integrals;   3) the field of input-output identifiable functions is generated by the coefficients of a \"minimal\" characteristic set of the corresponding differential ideal.   We expect that some of these facts may be known to the experts in the area, but we are not aware of any articles in which these facts are stated precisely and rigorously proved.",
        "published": "2020-07-28T01:16:51Z",
        "link": "http://arxiv.org/abs/2007.14787v2",
        "categories": [
            "math.AG",
            "cs.SC",
            "cs.SY",
            "eess.SY",
            "math.DS"
        ]
    },
    {
        "title": "Formal Power Series on Algebraic Cryptanalysis",
        "authors": [
            "Shuhei Nakamura"
        ],
        "summary": "In the complexity estimation for an attack that reduces a cryptosystem to solving a system of polynomial equations, the degree of regularity and an upper bound of the first fall degree are often used in cryptanalysis. While the degree of regularity can be easily computed using a univariate formal power series under the semi-regularity assumption, determining an upper bound of the first fall degree requires investigating the concrete syzygies of an input system. In this paper, we investigate an upper bound of the first fall degree for a polynomial system over a sufficiently large field. In this case, we prove that the first fall degree of a non-semi-regular system is bounded above by the degree of regularity, and that the first fall degree of a multi-graded polynomial system is bounded above by a certain value determined from a multivariate formal power series. Moreover, we provide a theoretical assumption for computing the first fall degree of a polynomial system over a sufficiently large field.",
        "published": "2020-07-29T10:36:20Z",
        "link": "http://arxiv.org/abs/2007.14729v3",
        "categories": [
            "cs.SC",
            "cs.CR"
        ]
    },
    {
        "title": "Trace Logic for Inductive Loop Reasoning",
        "authors": [
            "Pamina Georgiou",
            "Bernhard Gleiss",
            "Laura Kovács"
        ],
        "summary": "We propose trace logic, an instance of many-sorted first-order logic, to automate the partial correctness verification of programs containing loops. Trace logic generalizes semantics of program locations and captures loop semantics by encoding properties at arbitrary timepoints and loop iterations. We guide and automate inductive loop reasoning in trace logic by using generic trace lemmas capturing inductive loop invariants. Our work is implemented in the RAPID framework, by extending and integrating superposition-based first-order reasoning within RAPID. We successfully used RAPID to prove correctness of many programs whose functional behavior are best summarized in the first-order theories of linear integer arithmetic, arrays and inductive data types.",
        "published": "2020-08-04T07:54:22Z",
        "link": "http://arxiv.org/abs/2008.01387v2",
        "categories": [
            "cs.LO",
            "cs.SC"
        ]
    },
    {
        "title": "Proceedings 8th International Workshop on Verification and Program   Transformation and 7th Workshop on Horn Clauses for Verification and   Synthesis",
        "authors": [
            "Laurent Fribourg",
            "Matthias Heizmann"
        ],
        "summary": "The proceedings consist of a keynote paper by Alberto followed by 6 invited papers written by Lorenzo Clemente (U. Warsaw), Alain Finkel (U. Paris-Saclay), John Gallagher (Roskilde U. and IMDEA Software Institute) et al., Neil Jones (U. Copenhagen) et al., Michael Leuschel (Heinrich-Heine U.) and Maurizio Proietti (IASI-CNR) et al.. These invited papers are followed by 4 regular papers accepted at VPT 2020 and the papers of HCVS 2020 which consist of three contributed papers and an invited paper on the third competition of solvers for Constrained Horn Clauses.   In addition, the abstracts (in HTML format) of 3 invited talks at VPT 2020 by Andrzej Skowron (U. Warsaw), Sophie Renault (EPO) and Moa Johansson (Chalmers U.), are included.",
        "published": "2020-08-06T07:11:26Z",
        "link": "http://arxiv.org/abs/2008.02483v1",
        "categories": [
            "cs.LO",
            "cs.PL",
            "cs.SC"
        ]
    },
    {
        "title": "From Big-Step to Small-Step Semantics and Back with Interpreter   Specialisation",
        "authors": [
            "John P. Gallagher",
            "Manuel Hermenegildo",
            "Bishoksan Kafle",
            "Maximiliano Klemen",
            "Pedro López García",
            "José Morales"
        ],
        "summary": "We investigate representations of imperative programs as constrained Horn clauses. Starting from operational semantics transition rules, we proceed by writing interpreters as constrained Horn clause programs directly encoding the rules. We then specialise an interpreter with respect to a given source program to achieve a compilation of the source language to Horn clauses (an instance of the first Futamura projection). The process is described in detail for an interpreter for a subset of C, directly encoding the rules of big-step operational semantics for C. A similar translation based on small-step semantics could be carried out, but we show an approach to obtaining a small-step representation using a linear interpreter for big-step Horn clauses. This interpreter is again specialised to achieve the translation from big-step to small-step style. The linear small-step program can be transformed back to a big-step non-linear program using a third interpreter. A regular path expression is computed for the linear program using Tarjan's algorithm, and this regular expression then guides an interpreter to compute a program path. The transformation is realised by specialisation of the path interpreter. In all of the transformation phases, we use an established partial evaluator and exploit standard logic program transformation to remove redundant data structures and arguments in predicates and rename predicates to make clear their link to statements in the original source program.",
        "published": "2020-08-07T01:23:04Z",
        "link": "http://arxiv.org/abs/2008.02931v1",
        "categories": [
            "cs.PL",
            "cs.LO",
            "cs.SC"
        ]
    },
    {
        "title": "An Experiment Combining Specialization with Abstract Interpretation",
        "authors": [
            "John P. Gallagher",
            "Robert Glück"
        ],
        "summary": "It was previously shown that control-flow refinement can be achieved by a program specializer incorporating property-based abstraction, to improve termination and complexity analysis tools. We now show that this purpose-built specializer can be reconstructed in a more modular way, and that the previous results can be achieved using an off-the-shelf partial evaluation tool, applied to an abstract interpreter. The key feature of the abstract interpreter is the abstract domain, which is the product of the property-based abstract domain with the concrete domain. This language-independent framework provides a practical approach to implementing a variety of powerful specializers, and contributes to a stream of research on using interpreters and specialization to achieve program transformations.",
        "published": "2020-08-07T01:24:31Z",
        "link": "http://arxiv.org/abs/2008.02937v1",
        "categories": [
            "cs.PL",
            "cs.LO",
            "cs.SC"
        ]
    },
    {
        "title": "Competition Report: CHC-COMP-20",
        "authors": [
            "Philipp Rümmer"
        ],
        "summary": "CHC-COMP-20 is the third competition of solvers for Constrained Horn Clauses. In this year, 9 solvers participated at the competition, and were evaluated in four separate tracks on problems in linear integer arithmetic, linear real arithmetic, and arrays. The competition was run in the first week of May 2020 using the StarExec computing cluster. This report gives an overview of the competition design, explains the organisation of the competition, and presents the competition results.",
        "published": "2020-08-07T01:24:57Z",
        "link": "http://arxiv.org/abs/2008.02939v1",
        "categories": [
            "cs.LO",
            "cs.SC",
            "F.3.1"
        ]
    },
    {
        "title": "A Simple and Fast Algorithm for Computing the $N$-th Term of a Linearly   Recurrent Sequence",
        "authors": [
            "Alin Bostan",
            "Ryuhei Mori"
        ],
        "summary": "We present a simple and fast algorithm for computing the $N$-th term of a given linearly recurrent sequence. Our new algorithm uses $O(\\mathsf{M}(d) \\log N)$ arithmetic operations, where $d$ is the order of the recurrence, and $\\mathsf{M}(d)$ denotes the number of arithmetic operations for computing the product of two polynomials of degree $d$. The state-of-the-art algorithm, due to Charles Fiduccia (1985), has the same arithmetic complexity up to a constant factor. Our algorithm is simpler, faster and obtained by a totally different method. We also discuss several algorithmic applications, notably to polynomial modular exponentiation, powering of matrices and high-order lifting.",
        "published": "2020-08-20T07:54:01Z",
        "link": "http://arxiv.org/abs/2008.08822v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Exact $p$-adic computation in Magma",
        "authors": [
            "Christopher Doris"
        ],
        "summary": "We describe a new arithmetic system for the Magma computer algebra system for working with $p$-adic numbers exactly, in the sense that numbers are represented lazily to infinite $p$-adic precision. This is the first highly featured such implementation. This has the benefits of increasing user-friendliness and speeding up some computations, as well as forcibly producing provable results. We give theoretical and practical justification for its design and describe some use cases. The intention is that this article will be of benefit to anyone wanting to implement similar functionality in other languages.",
        "published": "2020-08-24T11:01:01Z",
        "link": "http://arxiv.org/abs/2008.11063v1",
        "categories": [
            "math.NT",
            "cs.SC"
        ]
    },
    {
        "title": "Computing the Real Isolated Points of an Algebraic Hypersurface",
        "authors": [
            "Huu Phuoc Le",
            "Mohab Safey El Din",
            "Timo de Wolff"
        ],
        "summary": "Let $\\mathbb{R}$ be the field of real numbers. We consider the problem of computing the real isolated points of a real algebraic set in $\\mathbb{R}^n$ given as the vanishing set of a polynomial system. This problem plays an important role for studying rigidity properties of mechanism in material designs. In this paper, we design an algorithm which solves this problem. It is based on the computations of critical points as well as roadmaps for answering connectivity queries in real algebraic sets. This leads to a probabilistic algorithm of complexity $(nd)^{O(n\\log(n))}$ for computing the real isolated points of real algebraic hypersurfaces of degree $d$. It allows us to solve in practice instances which are out of reach of the state-of-the-art.",
        "published": "2020-08-24T11:44:56Z",
        "link": "http://arxiv.org/abs/2008.10331v1",
        "categories": [
            "cs.CG",
            "cs.SC"
        ]
    },
    {
        "title": "Computing singular elements modulo squares",
        "authors": [
            "Przemysław Koprowski"
        ],
        "summary": "The group of singular elements was first introduced by Helmut Hasse and later it has been studied by numerous authors including such well known mathematicians as: Cassels, Furtw\\\"{a}ngler, Hecke, Knebusch, Takagi and of course Hasse himself; to name just a few. The aim of the present paper is to present algorithms that explicitly construct groups of singular and $S$-singular elements (modulo squares) in a global function field.",
        "published": "2020-08-24T11:50:03Z",
        "link": "http://arxiv.org/abs/2008.10335v1",
        "categories": [
            "math.NT",
            "cs.SC",
            "68W30, 11Y40",
            "I.1.2"
        ]
    },
    {
        "title": "Towards a noncommutative Picard-Vessiot theory",
        "authors": [
            "G. Duchamp",
            "Viincel Hoang Ngoc Minh",
            "Vu Nguyen Dinh",
            "Pierre Simonnet"
        ],
        "summary": "A Chen generating series, along a path and with respect to $m$ differential forms,is a noncommutative series on $m$ letters and with coefficients which are holomorphic functionsover a simply connected manifold in other words a series with variable (holomorphic) coefficients.Such a series satisfies a first order noncommutative differential equation which is considered, bysome authors, as the universal differential equation, (i.e.) universality can beseen by replacing each letter by constant matrices (resp. analytic vector fields)and then solving a system of linear (resp. nonlinear) differential equations.Via rational series, on noncommutative indeterminates and with coefficients in rings, andtheir non-trivial combinatorial Hopf algebras, we give the first step of a noncommutativePicard-Vessiot theory and we illustrate it with the case of linear differential equationswith singular regular singularities thanks to the universal equation previously mentioned.",
        "published": "2020-08-25T08:06:48Z",
        "link": "http://arxiv.org/abs/2008.10872v5",
        "categories": [
            "math.AG",
            "cs.SC"
        ]
    },
    {
        "title": "Robots, computer algebra and eight connected components",
        "authors": [
            "Jose Capco",
            "Mohab Safey El Din",
            "Josef Schicho"
        ],
        "summary": "Answering connectivity queries in semi-algebraic sets is a long-standing and challenging computational issue with applications in robotics, in particular for the analysis of kinematic singularities. One task there is to compute the number of connected components of the complementary of the singularities of the kinematic map. Another task is to design a continuous path joining two given points lying in the same connected component of such a set. In this paper, we push forward the current capabilities of computer algebra to obtain computer-aided proofs of the analysis of the kinematic singularities of various robots used in industry. We first show how to combine mathematical reasoning with easy symbolic computations to study the kinematic singularities of an infinite family (depending on paramaters) modelled by the UR-series produced by the company ``Universal Robots''. Next, we compute roadmaps (which are curves used to answer connectivity queries) for this family of robots. We design an algorithm for ``solving'' positive dimensional polynomial system depending on parameters. The meaning of solving here means partitioning the parameter's space into semi-algebraic components over which the number of connected components of the semi-algebraic set defined by the input system is invariant. Practical experiments confirm our computer-aided proof and show that such an algorithm can already be used to analyze the kinematic singularities of the UR-series family. The number of connected components of the complementary of the kinematic singularities of generic robots in this family is $8$.",
        "published": "2020-08-31T06:57:26Z",
        "link": "http://arxiv.org/abs/2008.13392v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Homotopy techniques for solving sparse column support determinantal   polynomial systems",
        "authors": [
            "George Labahn",
            "Mohab Safey El Din",
            "Éric Schost",
            "Thi Xuan Vu"
        ],
        "summary": "Let $\\mathbf{K}$ be a field of characteristic zero with $\\overline{\\mathbf{K}}$ its algebraic closure. Given a sequence of polynomials $\\mathbf{g} = (g_1, \\ldots, g_s) \\in \\mathbf{K}[x_1, \\ldots , x_n]^s$ and a polynomial matrix $\\mathbf{F} = [f_{i,j}] \\in \\mathbf{K}[x_1, \\ldots, x_n]^{p \\times q}$, with $p \\leq q$, we are interested in determining the isolated points of $V_p(\\mathbf{F},\\mathbf{g})$, the algebraic set of points in $\\overline{\\mathbf{K}}$ at which all polynomials in $\\mathbf{g}$ and all $p$-minors of $\\mathbf{F}$ vanish, under the assumption $n = q - p + s + 1$. Such polynomial systems arise in a variety of applications including for example polynomial optimization and computational geometry. We design a randomized sparse homotopy algorithm for computing the isolated points in $V_p(\\mathbf{F},\\mathbf{g})$ which takes advantage of the determinantal structure of the system defining $V_p(\\mathbf{F}, \\mathbf{g})$. Its complexity is polynomial in the maximum number of isolated solutions to such systems sharing the same sparsity pattern and in some combinatorial quantities attached to the structure of such systems. It is the first algorithm which takes advantage both on the determinantal structure and sparsity of input polynomials. We also derive complexity bounds for the particular but important case where $\\mathbf{g}$ and the columns of $\\mathbf{F}$ satisfy weighted degree constraints. Such systems arise naturally in the computation of critical points of maps restricted to algebraic sets when both are invariant by the action of the symmetric group.",
        "published": "2020-09-02T06:50:46Z",
        "link": "http://arxiv.org/abs/2009.00844v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Computing critical points for invariant algebraic systems",
        "authors": [
            "Jean-Charles Faugère",
            "George Labahn",
            "Mohab Safey El Din",
            "Éric Schost",
            "Thi Xuan Vu"
        ],
        "summary": "Let $\\mathbf{K}$ be a field and $\\phi$, $\\mathbf{f} = (f_1, \\ldots, f_s)$ in $\\mathbf{K}[x_1, \\dots, x_n]$ be multivariate polynomials (with $s < n$) invariant under the action of $\\mathcal{S}_n$, the group of permutations of $\\{1, \\dots, n\\}$. We consider the problem of computing the points at which $\\mathbf{f}$ vanish and the Jacobian matrix associated to $\\mathbf{f}, \\phi$ is rank deficient provided that this set is finite. We exploit the invariance properties of the input to split the solution space according to the orbits of $\\mathcal{S}_n$. This allows us to design an algorithm which gives a triangular description of the solution space and which runs in time polynomial in $d^s$, ${{n+d}\\choose{d}}$ and $\\binom{n}{s+1}$ where $d$ is the maximum degree of the input polynomials. When $d,s$ are fixed, this is polynomial in $n$ while when $s$ is fixed and $d \\simeq n$ this yields an exponential speed-up with respect to the usual polynomial system solving algorithms.",
        "published": "2020-09-02T06:52:49Z",
        "link": "http://arxiv.org/abs/2009.00847v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "On a non-archimedean broyden method",
        "authors": [
            "Xavier Dahan",
            "Tristan Vaccon"
        ],
        "summary": "Newton's method is an ubiquitous tool to solve equations, both in the archimedean and non-archimedean settings -- for which it does not really differ. Broyden was the instigator of what is called \"quasi-Newton methods\". These methods use an iteration step where one does not need to compute a complete Jacobian matrix nor its inverse. We provide an adaptation of Broyden's method in a general non-archimedean setting, compatible with the lack of inner product, and study its Q and R convergence. We prove that our adapted method converges at least Q-linearly and R-superlinearly with R-order $2^{\\frac{1}{2m}}$ in dimension m. Numerical data are provided.",
        "published": "2020-09-03T08:28:04Z",
        "link": "http://arxiv.org/abs/2009.01511v1",
        "categories": [
            "cs.SC",
            "cs.NA",
            "math.NA",
            "math.NT"
        ]
    },
    {
        "title": "Strong Consistency and Thomas Decomposition of Finite Difference   Approximations to Systems of Partial Differential Equations",
        "authors": [
            "Vladimir P. Gerdt",
            "Daniel Robertz",
            "Yuri A. Blinkov"
        ],
        "summary": "For a wide class of polynomially nonlinear systems of partial differential equations we suggest an algorithmic approach that combines differential and difference algebra to analyze s(trong)-consistency of finite difference approximations. Our approach is applicable to regular solution grids. For the grids of this type we give a new definition of s-consistency for finite difference approximations which generalizes our definition given earlier for Cartesian grids. The algorithmic verification of s-consistency presented in the paper is based on the use of both differential and difference Thomas decomposition. First, we apply the differential decomposition to the input system, resulting in a partition of its solution space. Then, to the output subsystem that contains a solution of interest we apply a difference analogue of the differential Thomas decomposition which allows to check the s-consistency. For linear and some quasi-linear differential systems one can also apply difference \\Gr bases for the s-consistency analysis. We illustrate our methods and algorithms by a number of examples, which include Navier-Stokes equations for viscous incompressible flow.",
        "published": "2020-09-03T15:08:51Z",
        "link": "http://arxiv.org/abs/2009.01731v1",
        "categories": [
            "cs.SC",
            "cs.NA",
            "math.AP",
            "math.NA",
            "math.RA",
            "physics.flu-dyn",
            "12H05, 12H10",
            "F.2.1; I.1.4"
        ]
    },
    {
        "title": "On FGLM Algorithms with Tropical Gröbner bases",
        "authors": [
            "Yuki Ishihara",
            "Tristan Vaccon",
            "Kazuhiro Yokoyama"
        ],
        "summary": "Let K be a field equipped with a valuation. Tropical varieties over K can be defined with a theory of Gr{\\\"o}bner bases taking into account the valuation of K. Because of the use of the valuation, the theory of tropical Gr{\\\"o}bner bases has proved to provide settings for computations over polynomial rings over a p-adic field that are more stable than that of classical Gr{\\\"o}bner bases. In this article, we investigate how the FGLM change of ordering algorithm can be adapted to the tropical setting. As the valuations of the polynomial coefficients are taken into account, the classical FGLM algorithm's incremental way, monomo-mial by monomial, to compute the multiplication matrices and the change of basis matrix can not be transposed at all to the tropical setting. We mitigate this issue by developing new linear algebra algorithms and apply them to our new tropical FGLM algorithms. Motivations are twofold. Firstly, to compute tropical varieties, one usually goes through the computation of many tropical Gr{\\\"o}bner bases defined for varying weights (and then varying term orders). For an ideal of dimension 0, the tropical FGLM algorithm provides an efficient way to go from a tropical Gr{\\\"o}bner basis from one weight to one for another weight. Secondly, the FGLM strategy can be applied to go from a tropical Gr{\\\"o}bner basis to a classical Gr{\\\"o}bner basis. We provide tools to chain the stable computation of a tropical Gr{\\\"o}bner basis (for weight [0,. .. , 0]) with the p-adic stabilized variants of FGLM of [RV16] to compute a lexicographical or shape position basis. All our algorithms have been implemented into SageMath. We provide numerical examples to illustrate time-complexity. We then illustrate the superiority of our strategy regarding to the stability of p-adic numerical computations.",
        "published": "2020-09-04T08:38:34Z",
        "link": "http://arxiv.org/abs/2009.02067v1",
        "categories": [
            "cs.SC",
            "math.AC"
        ]
    },
    {
        "title": "PolyAdd: Polynomial Formal Verification of Adder Circuits",
        "authors": [
            "Rolf Drechsler"
        ],
        "summary": "Only by formal verification approaches functional correctness can be ensured. While for many circuits fast verification is possible, in other cases the approaches fail. In general no efficient algorithms can be given, since the underlying verification problem is NP-complete. In this paper we prove that for different types of adder circuits polynomial verification can be ensured based on BDDs. While it is known that the output functions for addition are polynomially bounded, we show in the following that the entire construction process can be carried out in polynomial time. This is shown for the simple Ripple Carry Adder, but also for fast adders like the Conditional Sum Adder and the Carry Look Ahead Adder. Properties about the adder function are proven and the core principle of polynomial verification is described that can also be extended to other classes of functions and circuit realizations.",
        "published": "2020-09-07T17:10:21Z",
        "link": "http://arxiv.org/abs/2009.03242v3",
        "categories": [
            "cs.AR",
            "cs.DS",
            "cs.SC",
            "68W30, 68M07, 68W35",
            "B.6.3; B.2.1; F.2.2"
        ]
    },
    {
        "title": "Characterizing Positively Invariant Sets: Inductive and Topological   Methods",
        "authors": [
            "Khalil Ghorbal",
            "Andrew Sogokon"
        ],
        "summary": "We present two characterizations of positive invariance of sets under the flow of systems of ordinary differential equations. The first characterization uses inward sets which intuitively collect those points from which the flow evolves within the set for a short period of time, whereas the second characterization uses the notion of exit sets, which intuitively collect those points from which the flow immediately leaves the set. Our proofs emphasize the use of the real induction principle as a generic and unifying proof technique that captures the essence of the formal reasoning justifying our results and provides cleaner alternative proofs of known results. The two characterizations presented in this article, while essentially equivalent, lead to two rather different decision procedures (termed respectively LZZ and ESE) for checking whether a given semi-algebraic set is positively invariant under the flow of a system of polynomial ordinary differential equations. The procedure LZZ improves upon the original work by Liu, Zhan and Zhao (EMSOFT 2011). The procedure ESE, introduced in this article, works by splitting the problem, in a principled way, into simpler sub-problems that are easier to check, and is shown to exhibit substantially better performance compared to LZZ on problems featuring semi-algebraic sets described by formulas with non-trivial Boolean structure.",
        "published": "2020-09-08T09:02:20Z",
        "link": "http://arxiv.org/abs/2009.09797v2",
        "categories": [
            "cs.CG",
            "cs.LO",
            "cs.SC",
            "F.2.2; I.1.2"
        ]
    },
    {
        "title": "Guessing Gr{ö}bner Bases of Structured Ideals of Relations of   Sequences",
        "authors": [
            "Jérémy Berthomieu",
            "Mohab Safey El Din"
        ],
        "summary": "Assuming sufficiently many terms of a n-dimensional table defined over a field are given, we aim at guessing the linear recurrence relations with either constant or polynomial coefficients they satisfy. In many applications, the table terms come along with a structure: for instance, they may be zero outside of a cone, they may be built from a Gr{\\\"o}bner basis of an ideal invariant under the action of a finite group. Thus, we show how to take advantage of this structure to both reduce the number of table queries and the number of operations in the base field to recover the ideal of relations of the table. In applications like in combinatorics, where all these zero terms make us guess many fake relations, this allows us to drastically reduce these wrong guesses. These algorithms have been implemented and, experimentally, they let us handle examples that we could not manage otherwise. Furthermore, we show which kind of cone and lattice structures are preserved by skew polynomial multiplication. This allows us to speed up the guessing of linear recurrence relations with polynomial coefficients by computing sparse Gr{\\\"o}bner bases or Gr{\\\"o}bner bases of an ideal invariant under the action of a finite group in a ring of skew polynomials.",
        "published": "2020-09-11T06:23:15Z",
        "link": "http://arxiv.org/abs/2009.05248v2",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Modeling Hierarchical System with Operads",
        "authors": [
            "Spencer Breiner",
            "Blake Pollard",
            "Eswaran Subrahmanian",
            "Olivier Marie-Rose"
        ],
        "summary": "This paper applies operads and functorial semantics to address the problem of failure diagnosis in complex systems. We start with a concrete example, developing a hierarchical interaction model for the Length Scale Interferometer, a high-precision measurement system operated by the US National Institute of Standards and Technology. The model is expressed in terms of combinatorial/diagrammatic structures called port-graphs, and we explain how to extract an operad LSI from a collection of these diagrams. Next we show how functors to the operad of probabilities organize and constrain the relative probabilities of component failure in the system. Finally, we show how to extend the analysis from general component failure to specific failure modes.",
        "published": "2020-09-15T02:14:02Z",
        "link": "http://arxiv.org/abs/2009.09848v1",
        "categories": [
            "cs.LO",
            "cs.SC"
        ]
    },
    {
        "title": "Deriving Theorems in Implicational Linear Logic, Declaratively",
        "authors": [
            "Paul Tarau",
            "Valeria de Paiva"
        ],
        "summary": "The problem we want to solve is how to generate all theorems of a given size in the implicational fragment of propositional intuitionistic linear logic. We start by filtering for linearity the proof terms associated by our Prolog-based theorem prover for Implicational Intuitionistic Logic. This works, but using for each formula a PSPACE-complete algorithm limits it to very small formulas. We take a few walks back and forth over the bridge between proof terms and theorems, provided by the Curry-Howard isomorphism, and derive step-by-step an efficient algorithm requiring a low polynomial effort per generated theorem. The resulting Prolog program runs in O(N) space for terms of size N and generates in a few hours 7,566,084,686 theorems in the implicational fragment of Linear Intuitionistic Logic together with their proof terms in normal form. As applications, we generate datasets for correctness and scalability testing of linear logic theorem provers and training data for neural networks working on theorem proving challenges. The results in the paper, organized as a literate Prolog program, are fully replicable.   Keywords: combinatorial generation of provable formulas of a given size, intuitionistic and linear logic theorem provers, theorems of the implicational fragment of propositional linear intuitionistic logic, Curry-Howard isomorphism, efficient generation of linear lambda terms in normal form, Prolog programs for lambda term generation and theorem proving.",
        "published": "2020-09-22T00:48:45Z",
        "link": "http://arxiv.org/abs/2009.10241v1",
        "categories": [
            "cs.LO",
            "cs.AI",
            "cs.PL",
            "cs.SC"
        ]
    },
    {
        "title": "Enhancing Linear Algebraic Computation of Logic Programs Using Sparse   Representation",
        "authors": [
            "Tuan Nguyen Quoc",
            "Katsumi Inoue",
            "Chiaki Sakama"
        ],
        "summary": "Algebraic characterization of logic programs has received increasing attention in recent years. Researchers attempt to exploit connections between linear algebraic computation and symbolic computation in order to perform logical inference in large scale knowledge bases. This paper proposes further improvement by using sparse matrices to embed logic programs in vector spaces. We show its great power of computation in reaching the fixpoint of the immediate consequence operator from the initial vector. In particular, performance for computing the least models of definite programs is dramatically improved in this way. We also apply the method to the computation of stable models of normal programs, in which the guesses are associated with initial matrices, and verify its effect when there are small numbers of negation. These results show good enhancement in terms of performance for computing consequences of programs and depict the potential power of tensorized logic programs.",
        "published": "2020-09-22T00:50:05Z",
        "link": "http://arxiv.org/abs/2009.10247v1",
        "categories": [
            "cs.LO",
            "cs.SC"
        ]
    },
    {
        "title": "A Low-Level Index for Distributed Logic Programming",
        "authors": [
            "Thomas Prokosch"
        ],
        "summary": "A distributed logic programming language with support for meta-programming and stream processing offers a variety of interesting research problems, such as: How can a versatile and stable data structure for the indexing of a large number of expressions be implemented with simple low-level data structures? Can low-level programming help to reduce the number of occur checks in Robinson's unification algorithm? This article gives the answers.",
        "published": "2020-09-22T00:52:15Z",
        "link": "http://arxiv.org/abs/2009.10255v1",
        "categories": [
            "cs.SC",
            "cs.DS",
            "cs.IR"
        ]
    },
    {
        "title": "KG-BART: Knowledge Graph-Augmented BART for Generative Commonsense   Reasoning",
        "authors": [
            "Ye Liu",
            "Yao Wan",
            "Lifang He",
            "Hao Peng",
            "Philip S. Yu"
        ],
        "summary": "Generative commonsense reasoning which aims to empower machines to generate sentences with the capacity of reasoning over a set of concepts is a critical bottleneck for text generation. Even the state-of-the-art pre-trained language generation models struggle at this task and often produce implausible and anomalous sentences. One reason is that they rarely consider incorporating the knowledge graph which can provide rich relational information among the commonsense concepts. To promote the ability of commonsense reasoning for text generation, we propose a novel knowledge graph augmented pre-trained language generation model KG-BART, which encompasses the complex relations of concepts through the knowledge graph and produces more logical and natural sentences as output. Moreover, KG-BART can leverage the graph attention to aggregate the rich concept semantics that enhances the model generalization on unseen concept sets. Experiments on benchmark CommonGen dataset verify the effectiveness of our proposed approach by comparing with several strong pre-trained language generation models, particularly KG-BART outperforms BART by 5.80, 4.60, in terms of BLEU-3, 4. Moreover, we also show that the generated context by our model can work as background scenarios to benefit downstream commonsense QA tasks.",
        "published": "2020-09-26T19:57:49Z",
        "link": "http://arxiv.org/abs/2009.12677v2",
        "categories": [
            "cs.CL",
            "cs.SC"
        ]
    },
    {
        "title": "Formal Verification of Arithmetic RTL: Translating Verilog to C++ to   ACL2",
        "authors": [
            "David M. Russinoff"
        ],
        "summary": "We present a methodology for formal verification of arithmetic RTL designs that combines sequential logic equivalence checking with interactive theorem proving. An intermediate model of a Verilog module is hand-coded in Restricted Algorithmic C (RAC), a primitive subset of C augmented by the integer and fixed-point register class templates of Algorithmic C. The model is designed to be as abstract and compact as possible, but sufficiently faithful to the RTL to allow efficient equivalence checking with a commercial tool. It is then automatically translated to the logic of ACL2, enabling a mechanically checked proof of correctness with respect to a formal architectural specification. In this paper, we describe the RAC language, the translation process, and some techniques that facilitate formal analysis of the resulting ACL2 code.",
        "published": "2020-09-29T04:09:53Z",
        "link": "http://arxiv.org/abs/2009.13761v1",
        "categories": [
            "cs.LO",
            "cs.SC"
        ]
    },
    {
        "title": "Iteration in ACL2",
        "authors": [
            "Matt Kaufmann",
            "J Strother Moore"
        ],
        "summary": "Iterative algorithms are traditionally expressed in ACL2 using recursion. On the other hand, Common Lisp provides a construct, loop, which -- like most programming languages -- provides direct support for iteration. We describe an ACL2 analogue loop$ of loop that supports efficient ACL2 programming and reasoning with iteration.",
        "published": "2020-09-29T04:10:05Z",
        "link": "http://arxiv.org/abs/2009.13762v1",
        "categories": [
            "cs.LO",
            "cs.SC"
        ]
    },
    {
        "title": "On Differentially Algebraic Generating Series for Walks in the Quarter   Plane",
        "authors": [
            "Charlotte Hardouin",
            "Michael F Singer"
        ],
        "summary": "We refine necessary and sufficient conditions for the generating series of a weighted model of a quarter plane walk to be differentially algebraic. In addition, we give algorithms based on the theory of Mordell-Weil lattices, that, for each weighted model, yield polynomial conditions on the weights determining this property of the associated generating series.",
        "published": "2020-10-02T12:51:24Z",
        "link": "http://arxiv.org/abs/2010.00963v1",
        "categories": [
            "math.CO",
            "cs.SC",
            "math.NT",
            "05A15, 11G05, 30D05, 39A06"
        ]
    },
    {
        "title": "A Deep Genetic Programming based Methodology for Art Media   Classification Robust to Adversarial Perturbations",
        "authors": [
            "Gustavo Olague",
            "Gerardo Ibarra-Vazquez",
            "Mariana Chan-Ley",
            "Cesar Puente",
            "Carlos Soubervielle-Montalvo",
            "Axel Martinez"
        ],
        "summary": "Art Media Classification problem is a current research area that has attracted attention due to the complex extraction and analysis of features of high-value art pieces. The perception of the attributes can not be subjective, as humans sometimes follow a biased interpretation of artworks while ensuring automated observation's trustworthiness. Machine Learning has outperformed many areas through its learning process of artificial feature extraction from images instead of designing handcrafted feature detectors. However, a major concern related to its reliability has brought attention because, with small perturbations made intentionally in the input image (adversarial attack), its prediction can be completely changed. In this manner, we foresee two ways of approaching the situation: (1) solve the problem of adversarial attacks in current neural networks methodologies, or (2) propose a different approach that can challenge deep learning without the effects of adversarial attacks. The first one has not been solved yet, and adversarial attacks have become even more complex to defend. Therefore, this work presents a Deep Genetic Programming method, called Brain Programming, that competes with deep learning and studies the transferability of adversarial attacks using two artworks databases made by art experts. The results show that the Brain Programming method preserves its performance in comparison with AlexNet, making it robust to these perturbations and competing to the performance of Deep Learning.",
        "published": "2020-10-03T00:36:34Z",
        "link": "http://arxiv.org/abs/2010.01238v1",
        "categories": [
            "cs.CV",
            "cs.SC"
        ]
    },
    {
        "title": "Factorization of Dual Quaternion Polynomials Without Study's Condition",
        "authors": [
            "Johannes Siegele",
            "Martin Pfurner",
            "Hans-Peter Schröcker"
        ],
        "summary": "In this paper we investigate factorizations of polynomials over the ring of dual quaternions into linear factors. While earlier results assume that the norm polynomial is real (\"motion polynomials\"), we only require the absence of real polynomial factors in the primal part and factorizability of the norm polynomial over the dual numbers into monic quadratic factors. This obviously necessary condition is also sufficient for existence of factorizations. We present an algorithm to compute factorizations of these polynomials and use it for new constructions of mechanisms which cannot be obtained by existing factorization algorithms for motion polynomials. While they produce mechanisms with rotational or translational joints, our approach yields mechanisms consisting of \"vertical Darboux joints\". They exhibit mechanical deficiencies so that we explore ways to replace them by cylindrical joints while keeping the overall mechanism sufficiently constrained.",
        "published": "2020-10-05T12:17:44Z",
        "link": "http://arxiv.org/abs/2010.01945v2",
        "categories": [
            "math.RA",
            "cs.SC",
            "16S36, 70B15"
        ]
    },
    {
        "title": "A Simple and Efficient Tensor Calculus for Machine Learning",
        "authors": [
            "Sören Laue",
            "Matthias Mitterreiter",
            "Joachim Giesen"
        ],
        "summary": "Computing derivatives of tensor expressions, also known as tensor calculus, is a fundamental task in machine learning. A key concern is the efficiency of evaluating the expressions and their derivatives that hinges on the representation of these expressions. Recently, an algorithm for computing higher order derivatives of tensor expressions like Jacobians or Hessians has been introduced that is a few orders of magnitude faster than previous state-of-the-art approaches. Unfortunately, the approach is based on Ricci notation and hence cannot be incorporated into automatic differentiation frameworks from deep learning like TensorFlow, PyTorch, autograd, or JAX that use the simpler Einstein notation. This leaves two options, to either change the underlying tensor representation in these frameworks or to develop a new, provably correct algorithm based on Einstein notation. Obviously, the first option is impractical. Hence, we pursue the second option. Here, we show that using Ricci notation is not necessary for an efficient tensor calculus and develop an equally efficient method for the simpler Einstein notation. It turns out that turning to Einstein notation enables further improvements that lead to even better efficiency.   The methods that are described in this paper have been implemented in the online tool www.MatrixCalculus.org for computing derivatives of matrix and tensor expressions.   An extended abstract of this paper appeared as \"A Simple and Efficient Tensor Calculus\", AAAI 2020.",
        "published": "2020-10-07T10:18:56Z",
        "link": "http://arxiv.org/abs/2010.03313v1",
        "categories": [
            "cs.LG",
            "cs.SC"
        ]
    },
    {
        "title": "SPPL: Probabilistic Programming with Fast Exact Symbolic Inference",
        "authors": [
            "Feras A. Saad",
            "Martin C. Rinard",
            "Vikash K. Mansinghka"
        ],
        "summary": "We present the Sum-Product Probabilistic Language (SPPL), a new probabilistic programming language that automatically delivers exact solutions to a broad range of probabilistic inference queries. SPPL translates probabilistic programs into sum-product expressions, a new symbolic representation and associated semantic domain that extends standard sum-product networks to support mixed-type distributions, numeric transformations, logical formulas, and pointwise and set-valued constraints. We formalize SPPL via a novel translation strategy from probabilistic programs to sum-product expressions and give sound exact algorithms for conditioning on and computing probabilities of events. SPPL imposes a collection of restrictions on probabilistic programs to ensure they can be translated into sum-product expressions, which allow the system to leverage new techniques for improving the scalability of translation and inference by automatically exploiting probabilistic structure. We implement a prototype of SPPL with a modular architecture and evaluate it on benchmarks the system targets, showing that it obtains up to 3500x speedups over state-of-the-art symbolic systems on tasks such as verifying the fairness of decision tree classifiers, smoothing hidden Markov models, conditioning transformed random variables, and computing rare event probabilities.",
        "published": "2020-10-07T15:42:37Z",
        "link": "http://arxiv.org/abs/2010.03485v3",
        "categories": [
            "cs.PL",
            "cs.LG",
            "cs.SC",
            "stat.CO",
            "stat.ML"
        ]
    },
    {
        "title": "Deterministic computation of the characteristic polynomial in the time   of matrix multiplication",
        "authors": [
            "Vincent Neiger",
            "Clément Pernet"
        ],
        "summary": "This paper describes an algorithm which computes the characteristic polynomial of a matrix over a field within the same asymptotic complexity, up to constant factors, as the multiplication of two square matrices. Previously, this was only achieved by resorting to genericity assumptions or randomization techniques, while the best known complexity bound with a general deterministic algorithm was obtained by Keller-Gehrig in 1985 and involves logarithmic factors. Our algorithm computes more generally the determinant of a univariate polynomial matrix in reduced form, and relies on new subroutines for transforming shifted reduced matrices into shifted weak Popov matrices, and shifted weak Popov matrices into shifted Popov matrices.",
        "published": "2020-10-09T16:08:12Z",
        "link": "http://arxiv.org/abs/2010.04662v2",
        "categories": [
            "cs.SC",
            "cs.CC"
        ]
    },
    {
        "title": "A Categorical Programming Language",
        "authors": [
            "Tatsuya Hagino"
        ],
        "summary": "A theory of data types based on category theory is presented. We organize data types under a new categorical notion of F,G-dialgebras which is an extension of the notion of adjunctions as well as that of T-algebras. T-algebras are also used in domain theory, but while domain theory needs some primitive data types, like products, to start with, we do not need any. Products, coproducts and exponentiations (i.e. function spaces) are defined exactly like in category theory using adjunctions. F,G-dialgebras also enable us to define the natural number object, the object for finite lists and other familiar data types in programming. Furthermore, their symmetry allows us to have the dual of the natural number object and the object for infinite lists (or lazy lists). We also introduce a programming language in a categorical style using F,G-dialgebras as its data type declaration mechanism. We define the meaning of the language operationally and prove that any program terminates using Tait's computability method.",
        "published": "2020-10-11T04:44:19Z",
        "link": "http://arxiv.org/abs/2010.05167v1",
        "categories": [
            "cs.PL",
            "cs.LO",
            "cs.SC"
        ]
    },
    {
        "title": "Exploiting Knowledge Graphs for Facilitating Product/Service Discovery",
        "authors": [
            "Sarika Jain"
        ],
        "summary": "Most of the existing techniques to product discovery rely on syntactic approaches, thus ignoring valuable and specific semantic information of the underlying standards during the process. The product data comes from different heterogeneous sources and formats giving rise to the problem of interoperability. Above all, due to the continuously increasing influx of data, the manual labeling is getting costlier. Integrating the descriptions of different products into a single representation requires organizing all the products across vendors in a single taxonomy. Practically relevant and quality product categorization standards are still limited in number; and that too in academic research projects where we can majorly see only prototypes as compared to industry. This work presents a cost-effective solution for e-commerce on the Data Web by employing an unsupervised approach for data classification and exploiting the knowledge graphs for matching. The proposed architecture describes available products in web ontology language OWL and stores them in a triple store. User input specifications for certain products are matched against the available product categories to generate a knowledge graph. This mullti-phased top-down approach to develop and improve existing, if any, tailored product recommendations will be able to connect users with the exact product/service of their choice.",
        "published": "2020-10-11T10:22:10Z",
        "link": "http://arxiv.org/abs/2010.05213v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.SC",
            "H.1.2; H.2.4; I.2; J.1; J.7"
        ]
    },
    {
        "title": "An Algorithm for the Factorization of Split Quaternion Polynomials",
        "authors": [
            "Daniel F. Scharler",
            "Hans-Peter Schröcker"
        ],
        "summary": "We present an algorithm to compute all factorizations into linear factors of univariate polynomials over the split quaternions, provided such a factorization exists. Failure of the algorithm is equivalent to non-factorizability for which we present also geometric interpretations in terms of rulings on the quadric of non-invertible split quaternions. However, suitable real polynomial multiples of split quaternion polynomials can still be factorized and we describe how to find these real polynomials. Split quaternion polynomials describe rational motions in the hyperbolic plane. Factorization with linear factors corresponds to the decomposition of the rational motion into hyperbolic rotations. Since multiplication with a real polynomial does not change the motion, this decomposition is always possible. Some of our ideas can be transferred to the factorization theory of motion polynomials. These are polynomials over the dual quaternions with real norm polynomial and they describe rational motions in Euclidean kinematics. We transfer techniques developed for split quaternions to compute new factorizations of certain dual quaternion polynomials.",
        "published": "2020-10-12T14:45:53Z",
        "link": "http://arxiv.org/abs/2010.05751v2",
        "categories": [
            "math.RA",
            "cs.SC",
            "math.MG",
            "12D05, 16S36, 51M09, 51M10, 70B10"
        ]
    },
    {
        "title": "On lattice point counting in $Δ$-modular polyhedra",
        "authors": [
            "D. V. Gribanov",
            "N. Yu. Zolotykh"
        ],
        "summary": "Let a polyhedron $P$ be defined by one of the following ways:   (i) $P = \\{x \\in R^n \\colon A x \\leq b\\}$, where $A \\in Z^{(n+k) \\times n}$, $b \\in Z^{(n+k)}$ and $rank\\, A = n$;   (ii) $P = \\{x \\in R_+^n \\colon A x = b\\}$, where $A \\in Z^{k \\times n}$, $b \\in Z^{k}$ and $rank\\, A = k$.   And let all rank order minors of $A$ be bounded by $\\Delta$ in absolute values. We show that the short rational generating function for the power series $$ \\sum\\limits_{m \\in P \\cap Z^n} x^m $$ can be computed with the arithmetic complexity $ O\\left(T_{SNF}(d) \\cdot d^{k} \\cdot d^{\\log_2 \\Delta}\\right), $ where $k$ and $\\Delta$ are fixed, $d = \\dim P$, and $T_{SNF}(m)$ is the complexity to compute the Smith Normal Form for $m \\times m$ integer matrix. In particular, $d = n$ for the case (i) and $d = n-k$ for the case (ii). The simplest examples of polyhedra that meet conditions (i) or (ii) are the simplicies, the subset sum polytope and the knapsack or multidimensional knapsack polytopes. We apply these results to parametric polytopes, and show that the step polynomial representation of the function $c_P(y) = |P_{y} \\cap Z^n|$, where $P_{y}$ is parametric polytope, can be computed by a polynomial time even in varying dimension if $P_{y}$ has a close structure to the cases (i) or (ii). As another consequence, we show that the coefficients $e_i(P,m)$ of the Ehrhart quasi-polynomial $$ \\left| mP \\cap Z^n\\right| = \\sum\\limits_{j = 0}^n e_i(P,m)m^j $$ can be computed by a polynomial time algorithm for fixed $k$ and $\\Delta$.",
        "published": "2020-10-12T15:05:06Z",
        "link": "http://arxiv.org/abs/2010.05768v4",
        "categories": [
            "cs.CC",
            "cs.DM",
            "cs.SC",
            "math.CO"
        ]
    },
    {
        "title": "A variational autoencoder for music generation controlled by tonal   tension",
        "authors": [
            "Rui Guo",
            "Ivor Simpson",
            "Thor Magnusson",
            "Chris Kiefer",
            "Dorien Herremans"
        ],
        "summary": "Many of the music generation systems based on neural networks are fully autonomous and do not offer control over the generation process. In this research, we present a controllable music generation system in terms of tonal tension. We incorporate two tonal tension measures based on the Spiral Array Tension theory into a variational autoencoder model. This allows us to control the direction of the tonal tension throughout the generated piece, as well as the overall level of tonal tension. Given a seed musical fragment, stemming from either the user input or from directly sampling from the latent space, the model can generate variations of this original seed fragment with altered tonal tension. This altered music still resembles the seed music rhythmically, but the pitch of the notes are changed to match the desired tonal tension as conditioned by the user.",
        "published": "2020-10-13T08:37:22Z",
        "link": "http://arxiv.org/abs/2010.06230v2",
        "categories": [
            "cs.SD",
            "cs.SC",
            "eess.AS"
        ]
    },
    {
        "title": "On Minor Left Prime Factorization Problem for Multivariate Polynomial   Matrices",
        "authors": [
            "Dong Lu",
            "Dingkang Wang",
            "Fanghui Xiao"
        ],
        "summary": "A new necessary and sufficient condition for the existence of minor left prime factorizations of multivariate polynomial matrices without full row rank is presented. The key idea is to establish a relationship between a matrix and its full row rank submatrix. Based on the new result, we propose an algorithm for factorizing matrices and have implemented it on the computer algebra system Maple. Two examples are given to illustrate the effectiveness of the algorithm, and experimental data shows that the algorithm is efficient.",
        "published": "2020-10-14T12:19:10Z",
        "link": "http://arxiv.org/abs/2010.06998v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "On Factor Left Prime Factorization Problems for Multivariate Polynomial   Matrices",
        "authors": [
            "Dong Lu",
            "Dingkang Wang",
            "Fanghui Xiao"
        ],
        "summary": "This paper is concerned with factor left prime factorization problems for multivariate polynomial matrices without full row rank. We propose a necessary and sufficient condition for the existence of factor left prime factorizations of a class of multivariate polynomial matrices, and then design an algorithm to compute all factor left prime factorizations if they exist. We implement the algorithm on the computer algebra system Maple, and two examples are given to illustrate the effectiveness of the algorithm. The results presented in this paper are also true for the existence of factor right prime factorizations of multivariate polynomial matrices without full column rank.",
        "published": "2020-10-14T12:31:09Z",
        "link": "http://arxiv.org/abs/2010.07007v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "New Remarks on the Factorization and Equivalence Problems for a Class of   Multivariate Polynomial Matrices",
        "authors": [
            "Dong Lu",
            "Dingkang Wang",
            "Fanghui Xiao"
        ],
        "summary": "This paper is concerned with the factorization and equivalence problems of multivariate polynomial matrices. We present some new criteria for the existence of matrix factorizations for a class of multivariate polynomial matrices, and obtain a necessary and sufficient condition for the equivalence of a square polynomial matrix and a diagonal matrix. Based on the constructive proof of the new criteria, we give a factorization algorithm and prove the uniqueness of the factorization. We implement the algorithm on Maple, and two illustrative examples are given to show the effectiveness of the algorithm.",
        "published": "2020-10-14T13:42:10Z",
        "link": "http://arxiv.org/abs/2010.07088v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Projective isomorphisms between rational surfaces",
        "authors": [
            "Bert Jüttler",
            "Niels Lubbes",
            "Josef Schicho"
        ],
        "summary": "We present a method for computing projective isomorphisms between rational surfaces that are given in terms of their parametrizations. The main idea is to reduce the computation of such projective isomorphisms to five base cases by modifying the parametric maps such that the components of the resulting maps have lower degree. Our method can be used to compute affine, Euclidean and M\\\"obius isomorphisms between surfaces.",
        "published": "2020-10-16T13:52:47Z",
        "link": "http://arxiv.org/abs/2010.08393v2",
        "categories": [
            "math.AG",
            "cs.SC",
            "14J50, 14J26"
        ]
    },
    {
        "title": "Creative Telescoping on Multiple Sums",
        "authors": [
            "Christoph Koutschan",
            "Elaine Wong"
        ],
        "summary": "We showcase a collection of practical strategies to deal with a problem arising from an analysis of integral estimators derived via quasi-Monte Carlo methods. The problem reduces to a triple binomial sum, thereby enabling us to open up the holonomic toolkit, which contains tools such as creative telescoping that can be used to deduce a recurrence satisfied by the sum. While applying these techniques, a host of issues arose that partly needed to be resolved by hand. In other words, no creative telescoping implementation currently exists that can resolve all these issues automatically. Thus, we felt the need to compile the different strategies we tried and the difficulties that we encountered along the way. In particular, we highlight the necessity of the certificate in these computations and how its complexity can greatly influence the computation time.",
        "published": "2020-10-18T00:00:02Z",
        "link": "http://arxiv.org/abs/2010.08889v2",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Optimal Descartes' Rule of Signs for Circuits",
        "authors": [
            "Frédéric Bihan",
            "Alicia Dickenstein",
            "Jens Forsgård"
        ],
        "summary": "We present an optimal version of Descartes' rule of signs to bound the number of positive real roots of a sparse system of polynomial equations in n variables with n+2 monomials. This sharp upper bound is given in terms of the sign variation of a sequence associated to the exponents and the coefficients of the system.",
        "published": "2020-10-19T01:28:15Z",
        "link": "http://arxiv.org/abs/2010.09165v2",
        "categories": [
            "math.AG",
            "cs.SC"
        ]
    },
    {
        "title": "Algorithmic Reduction of Biological Networks With Multiple Time Scales",
        "authors": [
            "Niclas Kruff",
            "Christoph Lüders",
            "Ovidiu Radulescu",
            "Thomas Sturm",
            "Sebastian Walcher"
        ],
        "summary": "We present a symbolic algorithmic approach that allows to compute invariant manifolds and corresponding reduced systems for differential equations modeling biological networks which comprise chemical reaction networks for cellular biochemistry, and compartmental models for pharmacology, epidemiology and ecology. Multiple time scales of a given network are obtained by scaling, based on tropical geometry. Our reduction is mathematically justified within a singular perturbation setting. The existence of invariant manifolds is subject to hyperbolicity conditions, for which we propose an algorithmic test based on Hurwitz criteria. We finally obtain a sequence of nested invariant manifolds and respective reduced systems on those manifolds. Our theoretical results are generally accompanied by rigorous algorithmic descriptions suitable for direct implementation based on existing off-the-shelf software systems, specifically symbolic computation libraries and Satisfiability Modulo Theories solvers. We present computational examples taken from the well-known BioModels database using our own prototypical implementations.",
        "published": "2020-10-20T08:48:09Z",
        "link": "http://arxiv.org/abs/2010.10129v2",
        "categories": [
            "q-bio.MN",
            "cs.LO",
            "cs.SC",
            "math.DS",
            "68W30 (Primary), 14P10, 34E15, 37D10, 92C45 (Secondary)"
        ]
    },
    {
        "title": "Evaluation of Logic Programs with Built-Ins and Aggregation: A Calculus   for Bag Relations",
        "authors": [
            "Matthew Francis-Landau",
            "Tim Vieira",
            "Jason Eisner"
        ],
        "summary": "We present a scheme for translating logic programs, which may use aggregation and arithmetic, into algebraic expressions that denote bag relations over ground terms of the Herbrand universe. To evaluate queries against these relations, we develop an operational semantics based on term rewriting of the algebraic expressions. This approach can exploit arithmetic identities and recovers a range of useful strategies, including lazy strategies that defer work until it becomes possible or necessary.",
        "published": "2020-10-20T17:55:36Z",
        "link": "http://arxiv.org/abs/2010.10503v1",
        "categories": [
            "cs.PL",
            "cs.SC"
        ]
    },
    {
        "title": "Logic Guided Genetic Algorithms",
        "authors": [
            "Dhananjay Ashok",
            "Joseph Scott",
            "Sebastian Wetzel",
            "Maysum Panju",
            "Vijay Ganesh"
        ],
        "summary": "We present a novel Auxiliary Truth enhanced Genetic Algorithm (GA) that uses logical or mathematical constraints as a means of data augmentation as well as to compute loss (in conjunction with the traditional MSE), with the aim of increasing both data efficiency and accuracy of symbolic regression (SR) algorithms. Our method, logic-guided genetic algorithm (LGGA), takes as input a set of labelled data points and auxiliary truths (ATs) (mathematical facts known a priori about the unknown function the regressor aims to learn) and outputs a specially generated and curated dataset that can be used with any SR method. Three key insights underpin our method: first, SR users often know simple ATs about the function they are trying to learn. Second, whenever an SR system produces a candidate equation inconsistent with these ATs, we can compute a counterexample to prove the inconsistency, and further, this counterexample may be used to augment the dataset and fed back to the SR system in a corrective feedback loop. Third, the value addition of these ATs is that their use in both the loss function and the data augmentation process leads to better rates of convergence, accuracy, and data efficiency. We evaluate LGGA against state-of-the-art SR tools, namely, Eureqa and TuringBot on 16 physics equations from \"The Feynman Lectures on Physics\" book. We find that using these SR tools in conjunction with LGGA results in them solving up to 30.0% more equations, needing only a fraction of the amount of data compared to the same tool without LGGA, i.e., resulting in up to a 61.9% improvement in data efficiency.",
        "published": "2020-10-21T21:57:12Z",
        "link": "http://arxiv.org/abs/2010.11328v1",
        "categories": [
            "cs.NE",
            "cs.AI",
            "cs.LG",
            "cs.SC"
        ]
    },
    {
        "title": "Optimized Multivariate Polynomial Determinant on GPU",
        "authors": [
            "Jianjun Wei",
            "Liangyu Chen"
        ],
        "summary": "We present an optimized algorithm calculating determinant for multivariate polynomial matrix on GPU. The novel algorithm provides precise determinant for input multivariate polynomial matrix in controllable time. Our approach is based on modular methods and split into Fast Fourier Transformation, Condensation method and Chinese Remainder Theorem where each algorithm is paralleled on GPU. The experiment results show that our parallel method owns substantial speedups compared to Maple, allowing memory overhead and time expedition in steady increment. We are also able to deal with complex matrix which is over the threshold on Maple and constrained on CPU. In addition, calculation during the process could be recovered without losing accuracy at any point regardless of disruptions. Furthermore, we propose a time prediction for calculation of polynomial determinant according to some basic matrix attributes and we solve an open problem relating to harmonic elimination equations on the basis of our GPU implementation.",
        "published": "2020-10-23T00:48:32Z",
        "link": "http://arxiv.org/abs/2010.12117v1",
        "categories": [
            "math.NA",
            "cs.DC",
            "cs.NA",
            "cs.SC"
        ]
    },
    {
        "title": "A Graph Theoretical Approach for Testing Binomiality of Reversible   Chemical Reaction Networks",
        "authors": [
            "Hamid Rahkooy",
            "Cristian Vargas Montero"
        ],
        "summary": "We study binomiality of the steady state ideals of chemical reaction networks. Considering rate constants as indeterminates, the concept of unconditional binomiality has been introduced and an algorithm based on linear algebra has been proposed in a recent work for reversible chemical reaction networks, which has a polynomial time complexity upper bound on the number of species and reactions. In this article, using a modified version of species--reaction graphs, we present an algorithm based on graph theory which performs by adding and deleting edges and changing the labels of the edges in order to test unconditional binomiality. We have implemented our graph theoretical algorithm as well as the linear algebra one in Maple and made experiments on biochemical models. Our experiments show that the performance of the graph theoretical approach is similar to or better than the linear algebra approach, while it is drastically faster than Groebner basis and quantifier elimination methods.",
        "published": "2020-10-23T19:02:55Z",
        "link": "http://arxiv.org/abs/2010.12615v2",
        "categories": [
            "cs.SC",
            "math.AC"
        ]
    },
    {
        "title": "On Linear Representation, Complexity and Inversion of maps over finite   fields",
        "authors": [
            "Ramachandran Anantharaman",
            "Virendra Sule"
        ],
        "summary": "This paper defines a linear representation for nonlinear maps $F:\\mathbb{F}^n\\rightarrow\\mathbb{F}^n$ where $\\mathbb{F}$ is a finite field, in terms of matrices over $\\mathbb{F}$. This linear representation of the map $F$ associates a unique number $N$ and a unique matrix $M$ in $\\mathbb{F}^{N\\times N}$, called the Linear Complexity and the Linear Representation of $F$ respectively, and shows that the compositional powers $F^{(k)}$ are represented by matrix powers $M^k$. It is shown that for a permutation map $F$ with representation $M$, the inverse map has the linear representation $M^{-1}$. This framework of representation is extended to a parameterized family of maps $F_{\\lambda}(x): \\mathbb{F} \\to \\mathbb{F}$, defined in terms of a parameter $\\lambda \\in \\mathbb{F}$, leading to the definition of an analogous linear complexity of the map $F_{\\lambda}(x)$, and a parameter-dependent matrix representation $M_\\lambda$ defined over the univariate polynomial ring $\\mathbb{F}[\\lambda]$. Such a representation leads to the construction of a parametric inverse of such maps where the condition for invertibility is expressed through the unimodularity of this matrix representation $M_\\lambda$. Apart from computing the compositional inverses of permutation polynomials, this linear representation is also used to compute the cycle structures of the permutation map. Lastly, this representation is extended to a representation of the cyclic group generated by a permutation map $F$, and to the group generated by a finite number of permutation maps over $\\mathbb{F}$.",
        "published": "2020-10-26T12:34:27Z",
        "link": "http://arxiv.org/abs/2010.14601v5",
        "categories": [
            "cs.SC",
            "cs.DM",
            "math.RT"
        ]
    },
    {
        "title": "Lexicographic Groebner bases of bivariate polynomials modulo a   univariate one",
        "authors": [
            "Xavier Dahan"
        ],
        "summary": "Let T(x) in k[x] be a monic non-constant polynomial and write R=k[x] / (T) the quotient ring. Consider two bivariate polynomials a(x, y), b(x, y) in R[y]. In a first part, T = p^e is assumed to be the power of an irreducible polynomial p. A new algorithm that computes a minimal lexicographic Groebner basis of the ideal ( a, b, p^e), is introduced. A second part extends this algorithm when T is general through the \"local/global\" principle realized by a generalization of \"dynamic evaluation\", restricted so far to a polynomial T that is squarefree. The algorithm produces splittings according to the case distinction \"invertible/nilpotent\", extending the usual \"invertible/zero\" in classic dynamic evaluation. This algorithm belongs to the Euclidean family, the core being a subresultant sequence of a and b modulo T. In particular no factorization or Groebner basis computations are necessary. The theoretical background relies on Lazard's structural theorem for lexicographic Groebner bases in two variables. An implementation is realized in Magma. Benchmarks show clearly the benefit, sometimes important, of this approach compared to the Groebner bases approach.",
        "published": "2020-10-28T05:37:20Z",
        "link": "http://arxiv.org/abs/2010.14775v3",
        "categories": [
            "math.AC",
            "cs.SC"
        ]
    },
    {
        "title": "Fast Minimal Presentations of Bi-graded Persistence Modules",
        "authors": [
            "Michael Kerber",
            "Alexander Rolle"
        ],
        "summary": "Multi-parameter persistent homology is a recent branch of topological data analysis. In this area, data sets are investigated through the lens of homology with respect to two or more scale parameters. The high computational cost of many algorithms calls for a preprocessing step to reduce the input size. In general, a minimal presentation is the smallest possible representation of a persistence module. Lesnick and Wright proposed recently an algorithm (the LW-algorithm) for computing minimal presentations based on matrix reduction. In this work, we propose, implement and benchmark several improvements over the LW-algorithm. Most notably, we propose the use of priority queues to avoid extensive scanning of the matrix columns, which constitutes the computational bottleneck in the LW-algorithm, and we combine their algorithm with ideas from the multi-parameter chunk algorithm by Fugacci and Kerber. Our extensive experiments show that our algorithm outperforms the LW-algorithm and computes the minimal presentation for data sets with millions of simplices within a few seconds. Our software is publicly available.",
        "published": "2020-10-29T14:11:01Z",
        "link": "http://arxiv.org/abs/2010.15623v1",
        "categories": [
            "math.AT",
            "cs.SC",
            "math.AC",
            "55N99, 13D02"
        ]
    },
    {
        "title": "The New Rewriting Engine of Dedukti",
        "authors": [
            "Gabriel Hondet",
            "Frédéric Blanqui"
        ],
        "summary": "Dedukti is a type-checker for the $\\lambda$$\\Pi$-calculus modulo rewriting, an extension of Edinburgh's logicalframework LF where functions and type symbols can be defined by rewrite rules. It thereforecontains an engine for rewriting LF terms and types according to the rewrite rules given by the user.A key component of this engine is the matching algorithm to find which rules can be fired. In thispaper, we describe the class of rewrite rules supported by Dedukti and the new implementation ofthe matching algorithm. Dedukti supports non-linear rewrite rules on terms with binders usinghigher-order pattern-matching as in Combinatory Reduction Systems (CRS). The new matchingalgorithm extends the technique of decision trees introduced by Luc Maranget in the OCamlcompiler to this more general context.",
        "published": "2020-10-30T08:19:19Z",
        "link": "http://arxiv.org/abs/2010.16115v2",
        "categories": [
            "cs.PL",
            "cs.SC"
        ]
    },
    {
        "title": "Rounding Error Analysis of Linear Recurrences Using Generating Series",
        "authors": [
            "Marc Mezzarobba"
        ],
        "summary": "We develop a toolbox for the error analysis of linear recurrences with constant or polynomial coefficients, based on generating series, Cauchy's method of majorants, and simple results from analytic combinatorics. We illustrate the power of the approach by several nontrivial application examples. Among these examples are a new worst-case analysis of an algorithm for computing Bernoulli numbers, and a new algorithm for evaluating differentially finite functions in interval arithmetic while avoiding interval blow-up.",
        "published": "2020-11-02T08:54:22Z",
        "link": "http://arxiv.org/abs/2011.00827v5",
        "categories": [
            "math.NA",
            "cs.NA",
            "cs.SC"
        ]
    },
    {
        "title": "Calcium: computing in exact real and complex fields",
        "authors": [
            "Fredrik Johansson"
        ],
        "summary": "Calcium is a C library for real and complex numbers in a form suitable for exact algebraic and symbolic computation. Numbers are represented as elements of fields $\\mathbb{Q}(a_1,\\ldots,a_n)$ where the extensions numbers $a_k$ may be algebraic or transcendental. The system combines efficient field operations with automatic discovery and certification of algebraic relations, resulting in a practical computational model of $\\mathbb{R}$ and $\\mathbb{C}$ in which equality is rigorously decidable for a large class of numbers.",
        "published": "2020-11-03T14:22:18Z",
        "link": "http://arxiv.org/abs/2011.01728v1",
        "categories": [
            "cs.MS",
            "cs.SC"
        ]
    },
    {
        "title": "Connectivity in Semi-Algebraic Sets I",
        "authors": [
            "Hoon Hong",
            "James Rohal",
            "Mohab Safey El Din",
            "Eric Schost"
        ],
        "summary": "A semi-algebraic set is a subset of the real space defined by polynomial equations and inequalities having real coefficients and is a union of finitely many maximally connected components. We consider the problem of deciding whether two given points in a semi-algebraic set are connected; that is, whether the two points lie in the same connected component. In particular, we consider the semi-algebraic set defined by f <> 0 where f is a given polynomial with integer coefficients. The motivation comes from the observation that many important or non-trivial problems in science and engineering can be often reduced to that of connectivity. Due to its importance, there has been intense research effort on the problem. We will describe a symbolic-numeric method based on gradient ascent. The method will be described in two papers. The first paper (the present one) will describe the symbolic part and the forthcoming second paper will describe the numeric part. In the present paper, we give proofs of correctness and termination for the symbolic part and illustrate the efficacy of the method using several non-trivial examples.",
        "published": "2020-11-04T07:24:31Z",
        "link": "http://arxiv.org/abs/2011.02162v2",
        "categories": [
            "math.AG",
            "cs.SC",
            "14Q30, 68W30, 14P10, 14P25, 37D15"
        ]
    },
    {
        "title": "A Neuro-Symbolic Method for Solving Differential and Functional   Equations",
        "authors": [
            "Maysum Panju",
            "Ali Ghodsi"
        ],
        "summary": "When neural networks are used to solve differential equations, they usually produce solutions in the form of black-box functions that are not directly mathematically interpretable. We introduce a method for generating symbolic expressions to solve differential equations while leveraging deep learning training methods. Unlike existing methods, our system does not require learning a language model over symbolic mathematics, making it scalable, compact, and easily adaptable for a variety of tasks and configurations. As part of the method, we propose a novel neural architecture for learning mathematical expressions to optimize a customizable objective. The system is designed to always return a valid symbolic formula, generating a useful approximation when an exact analytic solution to a differential equation is not or cannot be found. We demonstrate through examples how our method can be applied on a number of differential equations, often obtaining symbolic approximations that are useful or insightful. Furthermore, we show how the system can be effortlessly generalized to find symbolic solutions to other mathematical tasks, including integration and functional equations.",
        "published": "2020-11-04T17:13:25Z",
        "link": "http://arxiv.org/abs/2011.02415v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.SC"
        ]
    },
    {
        "title": "Quadratization of ODEs: Monomial vs. Non-Monomial",
        "authors": [
            "Foyez Alauddin"
        ],
        "summary": "Quadratization is a transform of a system of ODEs with polynomial right-hand side into a system of ODEs with at most quadratic right-hand side via the introduction of new variables. It has been recently used as a pre-processing step for new model order reduction methods, so it is important to keep the number of new variables small. Several algorithms have been designed to search for a quadratization with the new variables being monomials in the original variables. To understand the limitations and potential ways of improving such algorithms, we study the following question: can quadratizations with not necessarily monomial new variables produce a model of substantially smaller dimension than quadratization with only monomial new variables?   To do this, we restrict our attention to scalar polynomial ODEs. Our first result is that a scalar polynomial ODE $\\dot{x}=p(x)=a_nx^n+a_{n-1}x^{n-1}+\\ldots + a_0$ with $n\\geqslant 5$ and $a_n\\neq0$ can be quadratized using exactly one new variable if and only if $p(x-\\frac{a_{n-1}}{n\\cdot a_n})=a_nx^n+ax^2+bx$ for some $a, b \\in \\mathbb{C}$. In fact, the new variable can be taken $z:=(x-\\frac{a_{n-1}}{n\\cdot a_n})^{n-1}$. Our second result is that two non-monomial new variables are enough to quadratize all degree $6$ scalar polynomial ODEs. Based on these results, we observe that a quadratization with not necessarily monomial new variables can be much smaller than a monomial quadratization even for scalar ODEs.   The main results of the paper have been discovered using computational methods of applied nonlinear algebra (Gr\\\"obner bases), and we describe these computations.",
        "published": "2020-11-08T11:42:10Z",
        "link": "http://arxiv.org/abs/2011.03959v1",
        "categories": [
            "math.DS",
            "cs.SC",
            "math.AG"
        ]
    },
    {
        "title": "LDU factorization",
        "authors": [
            "Gennadi Malaschonok"
        ],
        "summary": "LU-factorization of matrices is one of the fundamental algorithms of linear algebra. The widespread use of supercomputers with distributed memory requires a review of traditional algorithms, which were based on the common memory of a computer. Matrix block recursive algorithms are a class of algorithms that provide coarse-grained parallelization. The block recursive LU factorization algorithm was obtained in 2010. This algorithm is called LEU-factorization. It, like the traditional LU-algorithm, is designed for matrices over number fields. However, it does not solve the problem of numerical instability. We propose a generalization of the LEU algorithm to the case of a commutative domain and its field of quotients. This LDU factorization algorithm decomposes the matrix over the commutative domain into a product of three matrices, in which the matrices L and U belong to the commutative domain, and the elements of the weighted truncated permutation matrix D are the elements inverse to the product of some pair of minors. All elements are calculated without errors, so the problem of instability does not arise.",
        "published": "2020-11-08T23:47:44Z",
        "link": "http://arxiv.org/abs/2011.04108v1",
        "categories": [
            "cs.SC",
            "15B33",
            "F.2.1"
        ]
    },
    {
        "title": "Invariants of Self-Intersected N-Periodics in the Elliptic Billiard",
        "authors": [
            "Ronaldo Garcia",
            "Dan Reznik"
        ],
        "summary": "We study self-intersected N-periodics in the elliptic billiard, describing new facts about their geometry (e.g., self-intersected 4-periodics have vertices concyclic with the foci). We also check if some invariants listed in \"Eighty New Invariants of N-Periodics in the Elliptic Billiard\" (2020), arXiv:2004.12497, remain invariant in the self-intersected case. Toward that end, we derive explicit expressions for many low-N simple and self-intersected cases. We identify two special cases (one simple, one self-intersected) where a quantity prescribed to be invariant is actually variable.",
        "published": "2020-11-12T20:28:53Z",
        "link": "http://arxiv.org/abs/2011.06640v3",
        "categories": [
            "math.MG",
            "cs.CG",
            "cs.RO",
            "cs.SC",
            "51M04 51N20 51N35 68T20"
        ]
    },
    {
        "title": "Symbolically Solving Partial Differential Equations using Deep Learning",
        "authors": [
            "Maysum Panju",
            "Kourosh Parand",
            "Ali Ghodsi"
        ],
        "summary": "We describe a neural-based method for generating exact or approximate solutions to differential equations in the form of mathematical expressions. Unlike other neural methods, our system returns symbolic expressions that can be interpreted directly. Our method uses a neural architecture for learning mathematical expressions to optimize a customizable objective, and is scalable, compact, and easily adaptable for a variety of tasks and configurations. The system has been shown to effectively find exact or approximate symbolic solutions to various differential equations with applications in natural sciences. In this work, we highlight how our method applies to partial differential equations over multiple variables and more complex boundary and initial value conditions.",
        "published": "2020-11-12T22:16:03Z",
        "link": "http://arxiv.org/abs/2011.06673v1",
        "categories": [
            "cs.LG",
            "cs.NE",
            "cs.SC"
        ]
    },
    {
        "title": "Sequence Positivity Through Numeric Analytic Continuation: Uniqueness of   the Canham Model for Biomembranes",
        "authors": [
            "Stephen Melczer",
            "Marc Mezzarobba"
        ],
        "summary": "We prove solution uniqueness for the genus one Canham variational problem arising in the shape prediction of biomembranes. The proof builds on a result of Yu and Chen that reduces the variational problem to proving non-negativity of a sequence defined by a linear recurrence relation with polynomial coefficients. We combine rigorous numeric analytic continuation of D-finite functions with classic bounds from singularity analysis to derive an effective index where the asymptotic behaviour of the sequence, which is positive, dominates the sequence behaviour. Positivity of the finite number of remaining terms is then checked computationally.",
        "published": "2020-11-16T18:26:34Z",
        "link": "http://arxiv.org/abs/2011.08155v1",
        "categories": [
            "math.CO",
            "cs.SC",
            "math.DG"
        ]
    },
    {
        "title": "Representation of hypergeometric products of higher nesting depths in   difference rings",
        "authors": [
            "Evans Doe Ocansey",
            "Carsten Schneider"
        ],
        "summary": "A non-trivial symbolic machinery is presented that can rephrase algorithmically a finite set of nested hypergeometric products in appropriately designed difference rings. As a consequence, one obtains an alternative representation in terms of one single product defined over a root of unity and nested hypergeometric products which are algebraically independent among each other. In particular, one can solve the zero-recognition problem: the input expression of nested hypergeometric products evaluates to zero if and only if the output expression is the zero expression. Combined with available symbolic summation algorithms in the setting of difference rings, one obtains a general machinery that can represent (and simplify) nested sums defined over nested products.",
        "published": "2020-11-17T17:01:56Z",
        "link": "http://arxiv.org/abs/2011.08775v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "An effective method for computing Grothendieck point residue mappings",
        "authors": [
            "Shinichi Tajima",
            "Katsusuke Nabeshima"
        ],
        "summary": "Grothendieck point residue is considered in the context of computational complex analysis. A new effective method is proposed for computing Grothendieck point residues mappings and residues. Basic ideas of our approach are the use of Grothendieck local duality and a transformation law for local cohomology classes. A new tool is devised for efficiency to solve the extended ideal membership problems in local rings. The resulting algorithms are described with an example to illustrate them. An extension of the proposed method to parametric cases is also discussed as an application.",
        "published": "2020-11-18T05:14:17Z",
        "link": "http://arxiv.org/abs/2011.09092v1",
        "categories": [
            "cs.SC",
            "math.AG",
            "32A27, 32C36, 13P10, 14B15"
        ]
    },
    {
        "title": "Multi-experiment parameter identifiability of ODEs and model theory",
        "authors": [
            "Alexey Ovchinnikov",
            "Anand Pillay",
            "Gleb Pogudin",
            "Thomas Scanlon"
        ],
        "summary": "Structural identifiability is a property of an ODE model with parameters that allows for the parameters to be determined from continuous noise-free data. This is a natural prerequisite for practical identifiability. Conducting multiple independent experiments could make more parameters or functions of parameters identifiable, which is a desirable property to have. How many experiments are sufficient? In the present paper, we provide an algorithm to determine the exact number of experiments for multi-experiment local identifiability and obtain an upper bound that is off at most by one for the number of experiments for multi-experiment global identifiability.   Interestingly, the main theoretical ingredient of the algorithm has been discovered and proved using model theory (in the sense of mathematical logic). We hope that this unexpected connection will stimulate interactions between applied algebra and model theory, and we provide a short introduction to model theory in the context of parameter identifiability. As another related application of model theory in this area, we construct a nonlinear ODE system with one output such that single-experiment and multiple-experiment identifiability are different for the system. This contrasts with recent results about single-output linear systems.   We also present a Monte Carlo randomized version of the algorithm with a polynomial arithmetic complexity. Implementation of the algorithm is provided and its performance is demonstrated on several examples. The source code is available at https://github.com/pogudingleb/ExperimentsBound.",
        "published": "2020-11-21T21:05:23Z",
        "link": "http://arxiv.org/abs/2011.10868v2",
        "categories": [
            "math.AG",
            "cs.SC",
            "cs.SY",
            "eess.SY",
            "math.LO"
        ]
    },
    {
        "title": "A new algorithm for computing $μ$-bases of the univariate polynomial   vector",
        "authors": [
            "Dingkang Wang",
            "Hesong Wang",
            "Fanghui Xiao"
        ],
        "summary": "In this paper, we characterized the relationship between Groebner bases and u-bases: any minimal Groebner basis of the syzygy module for n univariate polynomials with respect to the term-over-position monomial order is its u-basis. Moreover, based on the gcd computation, we construct a free basis of the syzygy module by the recursive way. According to this relationship and the constructed free basis, a new algorithm for computing u-bases of the syzygy module is presented. The theoretical complexity of the algorithm is O(n^3d^2) under a reasonable assumption, where d is the maximum degree of the input n polynomials. We have implemented this algorithm (MinGb) in Maple. Experimental data and performance comparison with the existing algorithms developed by Song and Goldman (2009) (SG algorithm) and Hong et al. (2017) (HHK algorithm) show that MinGb algorithm is more efficient than SG algorithm when n and d are sufficiently large, while MinGb algorithm and HHK algorithm both have their own advantages.",
        "published": "2020-11-22T03:39:46Z",
        "link": "http://arxiv.org/abs/2011.10924v2",
        "categories": [
            "cs.SC",
            "math.AG"
        ]
    },
    {
        "title": "Why Charles Can Pen-test: an Evolutionary Approach to Vulnerability   Testing",
        "authors": [
            "Gabriele Costa",
            "Andrea Valenza"
        ],
        "summary": "Discovering vulnerabilities in applications of real-world complexity is a daunting task: a vulnerability may affect a single line of code, and yet it compromises the security of the entire application. Even worse, vulnerabilities may manifest only in exceptional circumstances that do not occur in the normal operation of the application. It is widely recognized that state-of-the-art penetration testing tools play a crucial role, and are routinely used, to dig up vulnerabilities. Yet penetration testing is still primarily a human-driven activity, and its effectiveness still depends on the skills and ingenuity of the security analyst driving the tool. In this paper, we propose a technique for the automatic discovery of vulnerabilities in event-based systems, such as web and mobile applications. Our approach is based on a collaborative, co-evolutionary and contract-driven search strategy that iteratively (i) executes a pool of test cases, (ii) identifies the most promising ones, and (iii) generates new test cases from them. The approach makes a synergistic combination of evolutionary algorithms where several \"species\" contribute to solving the problem: one species, the test species, evolves to find the target test case, i.e., the set of instruction whose execution lead to the vulnerable statement, whereas the other species, called contract species, evolve to select the parameters for the procedure calls needed to trigger the vulnerability. To assess the effectiveness of our approach, we implemented a working prototype and ran it against both a case study and a benchmark web application. The experimental results confirm that our tool automatically discovers and executes a number of injection flaw attacks that are out of reach for state-of-the-art web scanners.",
        "published": "2020-11-26T10:15:53Z",
        "link": "http://arxiv.org/abs/2011.13213v2",
        "categories": [
            "cs.CR",
            "cs.SC"
        ]
    },
    {
        "title": "Solving parametric systems of polynomial equations over the reals   through Hermite matrices",
        "authors": [
            "Huu Phuoc Le",
            "Mohab Safey El Din"
        ],
        "summary": "We design a new algorithm for solving parametric systems having finitely many complex solutions for generic values of the parameters. More precisely, let $f = (f_1, \\ldots, f_m)\\subset \\mathbb{Q}[y][x]$ with $y = (y_1, \\ldots, y_t)$ and $x = (x_1, \\ldots, x_n)$, $V\\subset \\mathbb{C}^{t+n}$ be the algebraic set defined by $f$ and $\\pi$ be the projection $(y, x) \\to y$. Under the assumptions that $f$ admits finitely many complex roots for generic values of $y$ and that the ideal generated by $f$ is radical, we solve the following problem. On input $f$, we compute semi-algebraic formulas defining semi-algebraic subsets $S_1, \\ldots, S_l$ of the $y$-space such that $\\cup_{i=1}^l S_i$ is dense in $\\mathbb{R}^t$ and the number of real points in $V\\cap \\pi^{-1}(\\eta)$ is invariant when $\\eta$ varies over each $S_i$.   This algorithm exploits properties of some well chosen monomial bases in the algebra $\\mathbb{Q}(y)[x]/I$ where $I$ is the ideal generated by $f$ in $\\mathbb{Q}(y)[x]$ and the specialization property of the so-called Hermite matrices. This allows us to obtain compact representations of the sets $S_i$ by means of semi-algebraic formulas encoding the signature of a symmetric matrix. When $f$ satisfies extra genericity assumptions, we derive complexity bounds on the number of arithmetic operations in $\\mathbb{Q}$ and the degree of the output polynomials. Let $d$ be the maximal degree of the $f_i$'s and $D = n(d-1)d^n$, we prove that, on a generic $f=(f_1,\\ldots,f_n)$, one can compute those semi-algebraic formulas with $O^~( \\binom{t+D}{t}2^{3t}n^{2t+1} d^{3nt+2(n+t)+1})$ operations in $\\mathbb{Q}$ and that the polynomials involved have degree bounded by $D$.   We report on practical experiments which illustrate the efficiency of our algorithm on generic systems and systems from applications. It allows us to solve problems which are out of reach of the state-of-the-art.",
        "published": "2020-11-28T14:09:06Z",
        "link": "http://arxiv.org/abs/2011.14136v2",
        "categories": [
            "cs.SC",
            "cs.CG",
            "I.1.2"
        ]
    },
    {
        "title": "Proceedings of the Eleventh International Workshop on Graph Computation   Models",
        "authors": [
            "Berthold Hoffmann",
            "Mark Minas"
        ],
        "summary": "Graphs are common mathematical structures that are visual and intuitive. They constitute a natural and seamless way for system modelling in science, engineering and beyond, including computer science, biology, business process modelling, etc. Graph computation models constitute a class of very high-level models where graphs are first-class citizens. The aim of the International GCM Workshop series is to bring together researchers interested in all aspects of computation models based on graphs and graph transformation. It promotes the cross-fertilizing exchange of ideas and experiences among senior and young researchers from the different communities interested in the foundations, applications, and implementations of graph computation models and related areas.",
        "published": "2020-12-02T13:11:35Z",
        "link": "http://arxiv.org/abs/2012.01181v1",
        "categories": [
            "cs.FL",
            "cs.SC"
        ]
    },
    {
        "title": "An Algebraic Graph Transformation Approach for RDF and SPARQL",
        "authors": [
            "Dominique Duval",
            "Rachid Echahed",
            "Frédéric Prost"
        ],
        "summary": "We consider the recommendations of the World Wide Web Consortium (W3C) about RDF framework and its associated query language SPARQL. We propose a new formal framework based on category theory which provides clear and concise formal definitions of the main basic features of RDF and SPARQL. We define RDF graphs as well as SPARQL basic graph patterns as objects of some nested categories. This allows one to clarify, in particular, the role of blank nodes. Furthermore, we consider basic SPARQL CONSTRUCT and SELECT queries and formalize their operational semantics following a novel algebraic graph transformation approach called POIM.",
        "published": "2020-12-03T02:27:57Z",
        "link": "http://arxiv.org/abs/2012.01658v1",
        "categories": [
            "cs.DB",
            "cs.PL",
            "cs.SC",
            "H.2.3;D.3.2;F.4.2"
        ]
    },
    {
        "title": "A Generic and Executable Formalization of Signature-Based Gröbner   Basis Algorithms",
        "authors": [
            "Alexander Maletzky"
        ],
        "summary": "We present a generic and executable formalization of signature-based algorithms (such as Faug\\`ere's $F_5$) for computing Gr\\\"obner bases, as well as their mathematical background, in the Isabelle/HOL proof assistant. Said algorithms are currently the best known algorithms for computing Gr\\\"obner bases in terms of computational efficiency. The formal development attempts to be as generic as possible, generalizing most known variants of signature-based algorithms, but at the same time the implemented functions are effectively executable on concrete input for efficiently computing mechanically verified Gr\\\"obner bases. Besides correctness the formalization also proves that under certain conditions the algorithms a-priori detect and avoid all useless reductions to zero, and return minimal signature Gr\\\"obner bases.   To the best of our knowledge, the formalization presented here is the only formalization of signature-based Gr\\\"obner basis algorithms in existence so far.",
        "published": "2020-12-03T20:11:55Z",
        "link": "http://arxiv.org/abs/2012.02239v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "A SAT-based Resolution of Lam's Problem",
        "authors": [
            "Curtis Bright",
            "Kevin K. H. Cheung",
            "Brett Stevens",
            "Ilias Kotsireas",
            "Vijay Ganesh"
        ],
        "summary": "In 1989, computer searches by Lam, Thiel, and Swiercz experimentally resolved Lam's problem from projective geometry$\\unicode{x2014}$the long-standing problem of determining if a projective plane of order ten exists. Both the original search and an independent verification in 2011 discovered no such projective plane. However, these searches were each performed using highly specialized custom-written code and did not produce nonexistence certificates. In this paper, we resolve Lam's problem by translating the problem into Boolean logic and use satisfiability (SAT) solvers to produce nonexistence certificates that can be verified by a third party. Our work uncovered consistency issues in both previous searches$\\unicode{x2014}$highlighting the difficulty of relying on special-purpose search code for nonexistence results.",
        "published": "2020-12-08T20:06:25Z",
        "link": "http://arxiv.org/abs/2012.04715v1",
        "categories": [
            "cs.DM",
            "cs.AI",
            "cs.LO",
            "cs.SC",
            "math.CO"
        ]
    },
    {
        "title": "Counting Real Roots in Polynomial-Time for Systems Supported on Circuits",
        "authors": [
            "J. Maurice Rojas"
        ],
        "summary": "Suppose $A=\\{a_1,\\ldots,a_{n+2}\\}\\subset\\mathbb{Z}^n$ has cardinality $n+2$, with all the coordinates of the $a_j$ having absolute value at most $d$, and the $a_j$ do not all lie in the same affine hyperplane. Suppose $F=(f_1,\\ldots,f_n)$ is an $n\\times n$ polynomial system with generic integer coefficients at most $H$ in absolute value, and $A$ the union of the sets of exponent vectors of the $f_i$. We give the first algorithm that, for any fixed $n$, counts exactly the number of real roots of $F$ in in time polynomial in $\\log(dH)$.",
        "published": "2020-12-09T05:11:20Z",
        "link": "http://arxiv.org/abs/2012.04868v5",
        "categories": [
            "math.AG",
            "cs.CC",
            "cs.SC"
        ]
    },
    {
        "title": "Hexapods with a small linear span",
        "authors": [
            "Hans-Christian Graf von Bothmer",
            "Matteo Gallet",
            "Josef Schicho"
        ],
        "summary": "The understanding of mobile hexapods, i.e., parallel manipulators with six legs, is one of the driving questions in theoretical kinematics. We aim at contributing to this understanding by employing techniques from algebraic geometry. The set of configurations of a mobile hexapod with one degree of freedom has the structure of a projective curve, which hence has a degree and an embedding dimension. Our main result is a classification of configuration curves of hexapods that satisfy some restrictions on their embedding dimension.",
        "published": "2020-12-09T15:50:38Z",
        "link": "http://arxiv.org/abs/2012.05120v1",
        "categories": [
            "math.AG",
            "cs.RO",
            "cs.SC"
        ]
    },
    {
        "title": "Parallel Software to Offset the Cost of Higher Precision",
        "authors": [
            "Jan Verschelde"
        ],
        "summary": "Hardware double precision is often insufficient to solve large scientific problems accurately. Computing in higher precision defined by software causes significant computational overhead. The application of parallel algorithms compensates for this overhead. Newton's method to develop power series expansions of algebraic space curves is the use case for this application.",
        "published": "2020-12-11T19:23:55Z",
        "link": "http://arxiv.org/abs/2012.06607v1",
        "categories": [
            "cs.MS",
            "cs.DC",
            "cs.NA",
            "cs.SC",
            "math.AG",
            "math.NA"
        ]
    },
    {
        "title": "SONC Optimization and Exact Nonnegativity Certificates via Second-Order   Cone Programming",
        "authors": [
            "Victor Magron",
            "Jie Wang"
        ],
        "summary": "The second-order cone (SOC) is a class of simple convex cones and optimizing over them can be done more efficiently than with semidefinite programming. It is interesting both in theory and in practice to investigate which convex cones admit a representation using SOCs, given that they have a strong expressive ability. In this paper, we prove constructively that the cone of sums of nonnegative circuits (SONC) admits a SOC representation. Based on this, we give a new algorithm for unconstrained polynomial optimization via SOC programming. We also provide a hybrid numeric-symbolic scheme which combines the numerical procedure with a rounding-projection algorithm to obtain exact nonnegativity certificates. Numerical experiments demonstrate the efficiency of our algorithm for polynomials with fairly large degree and number of variables.",
        "published": "2020-12-14T19:32:45Z",
        "link": "http://arxiv.org/abs/2012.07903v3",
        "categories": [
            "math.OC",
            "cs.SC",
            "math.AG"
        ]
    },
    {
        "title": "Fast Computation of the $N$-th Term of a $q$-Holonomic Sequence and   Applications",
        "authors": [
            "Alin Bostan",
            "Sergey Yurkevich"
        ],
        "summary": "In 1977, Strassen invented a famous baby-step/giant-step algorithm that computes the factorial $N!$ in arithmetic complexity quasi-linear in $\\sqrt{N}$. In 1988, the Chudnovsky brothers generalized Strassen's algorithm to the computation of the $N$-th term of any holonomic sequence in essentially the same arithmetic complexity. We design $q$-analogues of these algorithms. We first extend Strassen's algorithm to the computation of the $q$-factorial of $N$, then Chudnovskys' algorithm to the computation of the $N$-th term of any $q$-holonomic sequence. Both algorithms work in arithmetic complexity quasi-linear in $\\sqrt{N}$; surprisingly, they are simpler than their analogues in the holonomic case. We provide a detailed cost analysis, in both arithmetic and bit complexity models. Moreover, we describe various algorithmic consequences, including the acceleration of polynomial and rational solving of linear $q$-differential equations, and the fast evaluation of large classes of polynomials, including a family recently considered by Nogneng and Schost.",
        "published": "2020-12-15T22:51:12Z",
        "link": "http://arxiv.org/abs/2012.08656v1",
        "categories": [
            "cs.SC",
            "68W30, 68Q25, 05A30, 33F10",
            "I.1.2"
        ]
    },
    {
        "title": "Investigating ADR mechanisms with knowledge graph mining and explainable   AI",
        "authors": [
            "Emmanuel Bresso",
            "Pierre Monnin",
            "Cédric Bousquet",
            "François-Elie Calvier",
            "Ndeye-Coumba Ndiaye",
            "Nadine Petitpain",
            "Malika Smaïl-Tabbone",
            "Adrien Coulet"
        ],
        "summary": "Adverse Drug Reactions (ADRs) are characterized within randomized clinical trials and postmarketing pharmacovigilance, but their molecular mechanism remains unknown in most cases. Aside from clinical trials, many elements of knowledge about drug ingredients are available in open-access knowledge graphs. In addition, drug classifications that label drugs as either causative or not for several ADRs, have been established. We propose to mine knowledge graphs for identifying biomolecular features that may enable reproducing automatically expert classifications that distinguish drug causative or not for a given type of ADR. In an explainable AI perspective, we explore simple classification techniques such as Decision Trees and Classification Rules because they provide human-readable models, which explain the classification itself, but may also provide elements of explanation for molecular mechanisms behind ADRs. In summary, we mine a knowledge graph for features; we train classifiers at distinguishing, drugs associated or not with ADRs; we isolate features that are both efficient in reproducing expert classifications and interpretable by experts (i.e., Gene Ontology terms, drug targets, or pathway names); and we manually evaluate how they may be explanatory. Extracted features reproduce with a good fidelity classifications of drugs causative or not for DILI and SCAR. Experts fully agreed that 73% and 38% of the most discriminative features are possibly explanatory for DILI and SCAR, respectively; and partially agreed (2/3) for 90% and 77% of them. Knowledge graphs provide diverse features to enable simple and explainable models to distinguish between drugs that are causative or not for ADRs. In addition to explaining classifications, most discriminative features appear to be good candidates for investigating ADR mechanisms further.",
        "published": "2020-12-16T16:59:25Z",
        "link": "http://arxiv.org/abs/2012.09077v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.SC"
        ]
    },
    {
        "title": "Repairing dynamic models: a method to obtain identifiable and observable   reparameterizations with mechanistic insights",
        "authors": [
            "Gemma Massonis",
            "Julio R. Banga",
            "Alejandro F. Villaverde"
        ],
        "summary": "Mechanistic dynamic models allow for a quantitative and systematic interpretation of data and the generation of testable hypotheses. However, these models are often over-parameterized, leading to non-identifiability and non-observability, i.e. the impossibility of inferring their parameters and state variables. The lack of structural identifiability and observability (SIO) compromises a model's ability to make predictions and provide insight. Here we present a methodology, AutoRepar, that corrects SIO deficiencies automatically, yielding reparameterized models that are structurally identifiable and observable. The reparameterization preserves the mechanistic meaning of selected variables, and has the exact same dynamics and input-output mapping as the original model. We implement AutoRepar as an extension of the STRIKE-GOLDD software toolbox for SIO analysis, applying it to several models from the literature to demonstrate its ability to repair their structural deficiencies. AutoRepar increases the applicability of mechanistic models, enabling them to provide reliable information about their parameters and dynamics.",
        "published": "2020-12-17T18:49:27Z",
        "link": "http://arxiv.org/abs/2012.09826v2",
        "categories": [
            "eess.SY",
            "cs.SC",
            "cs.SY"
        ]
    },
    {
        "title": "SymFields: An Open Source Symbolic Fields Analysis Tool for General   Curvilinear Coordinates in Python",
        "authors": [
            "Nan Chu"
        ],
        "summary": "An open source symbolic tool for vector fields analysis 'SymFields' is developed in Python. The SymFields module is constructed upon Python symbolic module sympy, which could only conduct scaler field analysis. With SymFields module, you can conduct vector analysis for general curvilinear coordinates regardless whether it is orthogonal or not. In SymFields, the differential operators based on metric tensor are normalized to real physical values, which means your can use real physical value of the vector fields as inputs. This could greatly free the physicists from the tedious calculation under complicated coordinates.",
        "published": "2020-12-19T16:08:15Z",
        "link": "http://arxiv.org/abs/2012.10723v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "A variant of van Hoeij's algorithm to compute hypergeometric term   solutions of holonomic recurrence equations",
        "authors": [
            "Bertrand Teguia Tabuguia"
        ],
        "summary": "Linear homogeneous recurrence equations with polynomial coefficients are said to be holonomic. Such equations have been introduced in the last century for proving and discovering combinatorial and hypergeometric identities. Given a field K of characteristic zero, a term a(n) is called hypergeometric with respect to K, if the ratio a(n+1)/a(n) is a rational function over K. The solutions space of holonomic recurrence equations gained more interest in the 1990s from the well known Zeilberger's algorithm. In particular, algorithms computing the subspace of hypergeometric term solutions which covers polynomial, rational, and some algebraic solutions of these equations were investigated by Marko Petkov\\v{s}ek (1993) and Mark van Hoeij (1999). The algorithm proposed by the latter is characterized by a much better efficiency than that of the other; it computes, in Gamma representations, a basis of the subspace of hypergeometric term solutions of any given holonomic recurrence equation, and is considered as the current state of the art in this area. Mark van Hoeij implemented his algorithm in the Computer Algebra System (CAS) Maple through the command $LREtools[hypergeomsols]$.   We propose a variant of van Hoeij's algorithm that performs the same efficiency and gives outputs in terms of factorials and shifted factorials, without considering certain recommendations of the original version. We have implementations of our algorithm for the CASs Maxima and Maple. Such an implementation is new for Maxima which is therefore used for general-purpose examples. Our Maxima code is currently available as a third-party package for Maxima. A comparison between van Hoeij's implementation and ours is presented for Maple 2020. It appears that both have the same efficiency, and moreover, for some particular cases, our code finds results where $LREtools[hypergeomsols]$ fails.",
        "published": "2020-12-21T17:28:05Z",
        "link": "http://arxiv.org/abs/2012.11513v1",
        "categories": [
            "cs.SC",
            "math.CO",
            "Primary: 33F10, 39A06, Secondary: 33C20, 68W30"
        ]
    },
    {
        "title": "Method for estimating hidden structures determined by unidentifiable   state-space models and time-series data based on the Groebner basis",
        "authors": [
            "Mizuka Komatsu",
            "Takaharu Yaguchi"
        ],
        "summary": "In this study, we propose a method for extracting the hidden algebraic structures of model parameters that are uniquely determined by observed time-series data and unidentifiable state-space models, explicitly and exhaustively. State-space models are often constructed based on the domain, for example, physical or biological. Such models include parameters that are assigned specific meanings in relation to the system under consideration, which is examined by estimating the parameters using the corresponding data. As the parameters of unidentifiable models cannot be uniquely determined from the given data, it is difficult to examine the systems described by such models. To overcome this difficulty, multiple possible sets of parameters are estimated and analysed in the exiting approaches; however, in general, all the possible parameters cannot be explored; therefore, considerations on the system using the estimated parameters become insufficient. In this study, focusing on certain structures determined by the observed data and models uniquely, even if they are unidentifiable, we introduce the concept of parameter variety. This is newly defined and proven to form algebraic varieties, in general. A computational algebraic method that relies on the Groebner basis for deriving the explicit representation of the varieties is presented along with the supporting theory. Furthermore, its application in the analysis of a model that describes virus dynamics is presented. With this, new insight on the dynamics overlooked by the conventional approach are discovered, confirming the applicability of our idea and the proposed method.",
        "published": "2020-12-22T10:09:42Z",
        "link": "http://arxiv.org/abs/2012.11906v1",
        "categories": [
            "eess.SY",
            "cs.SC",
            "cs.SY",
            "math.DS",
            "q-bio.QM",
            "93B25, 93B30"
        ]
    },
    {
        "title": "Augmenting Policy Learning with Routines Discovered from a Single   Demonstration",
        "authors": [
            "Zelin Zhao",
            "Chuang Gan",
            "Jiajun Wu",
            "Xiaoxiao Guo",
            "Joshua B. Tenenbaum"
        ],
        "summary": "Humans can abstract prior knowledge from very little data and use it to boost skill learning. In this paper, we propose routine-augmented policy learning (RAPL), which discovers routines composed of primitive actions from a single demonstration and uses discovered routines to augment policy learning. To discover routines from the demonstration, we first abstract routine candidates by identifying grammar over the demonstrated action trajectory. Then, the best routines measured by length and frequency are selected to form a routine library. We propose to learn policy simultaneously at primitive-level and routine-level with discovered routines, leveraging the temporal structure of routines. Our approach enables imitating expert behavior at multiple temporal scales for imitation learning and promotes reinforcement learning exploration. Extensive experiments on Atari games demonstrate that RAPL improves the state-of-the-art imitation learning method SQIL and reinforcement learning method A2C. Further, we show that discovered routines can generalize to unseen levels and difficulties on the CoinRun benchmark.",
        "published": "2020-12-23T03:15:21Z",
        "link": "http://arxiv.org/abs/2012.12469v4",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.SC"
        ]
    },
    {
        "title": "Exploring tropical differential equations",
        "authors": [
            "Ethan Cotterill",
            "Cristhian Garay",
            "Johana Luviano"
        ],
        "summary": "The purpose of this paper is fourfold. The first is to develop the theory of tropical differential algebraic geometry from scratch; the second is to present the tropical fundamental theorem for differential algebraic geometry, and show how it may be used to extract combinatorial information about the set of power series solutions to a given system of differential equations, both in the archimedean (complex analytic) and in the non-archimedean (e.g., $p$-adic) settings. A third and subsidiary aim is to show how tropical differential algebraic geometry is a natural application of semiring theory, and in so doing, contribute to the valuative study of differential algebraic geometry. We use this formalism to extend the fundamental theorem of partial differential algebraic geometry to the differential fraction field of the ring of formal power series in arbitrarily (finitely) many variables; in doing so we produce new examples of non-Krull valuations that merit further study in their own right.",
        "published": "2020-12-28T02:29:05Z",
        "link": "http://arxiv.org/abs/2012.14067v4",
        "categories": [
            "math.AG",
            "cs.SC",
            "13N99, 14T10 (Primary) 13P15, 52B20 (Secondary)"
        ]
    },
    {
        "title": "Notes on Computational Graph and Jacobian Accumulation",
        "authors": [
            "Yichong Zhou"
        ],
        "summary": "The optimal calculation order of a computational graph can be represented by a set of algebraic expressions. Computational graph and algebraic expression both have close relations and significant differences, this paper looks into these relations and differences, making plain their interconvertibility. By revealing different types of multiplication relations in algebraic expressions and their elimination dependencies in line-graph, we establish a theoretical limit on the efficiency of face elimination.",
        "published": "2020-12-30T04:28:37Z",
        "link": "http://arxiv.org/abs/2012.15034v1",
        "categories": [
            "cs.SC"
        ]
    }
]