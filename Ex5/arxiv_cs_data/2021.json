[
    {
        "title": "Design of heterogeneous multi-agent system for distributed computation",
        "authors": [
            "Jin Gyu Lee",
            "Hyungbo Shim"
        ],
        "summary": "A group behavior of a heterogeneous multi-agent system is studied which obeys an \"average of individual vector fields\" under strong couplings among the agents. Under stability of the averaged dynamics (not asking stability of individual agents), the behavior of heterogeneous multi-agent system can be estimated by the solution to the averaged dynamics. A following idea is to \"design\" individual agent's dynamics such that the averaged dynamics performs the desired task. A few applications are discussed including estimation of the number of agents in a network, distributed least-squares or median solver, distributed optimization, distributed state estimation, and robust synchronization of coupled oscillators. Since stability of the averaged dynamics makes the initial conditions forgotten as time goes on, these algorithms are initialization-free and suitable for plug-and-play operation. At last, nonlinear couplings are also considered, which potentially asserts that enforced synchronization gives rise to an emergent behavior of a heterogeneous multi-agent system.",
        "published": "2021-01-01T04:39:06Z",
        "link": "http://arxiv.org/abs/2101.00161v2",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Semi-Definite Relaxation Based ADMM for Cooperative Planning and Control   of Connected Autonomous Vehicles",
        "authors": [
            "Xiaoxue Zhang",
            "Zilong Cheng",
            "Jun Ma",
            "Sunan Huang",
            "Frank L. Lewis",
            "Tong Heng Lee"
        ],
        "summary": "This paper investigates the cooperative planning and control problem for multiple connected autonomous vehicles (CAVs) in different scenarios. In the existing literature, most of the methods suffer from significant problems in computational efficiency. Besides, as the optimization problem is nonlinear and nonconvex, it typically poses great difficultly in determining the optimal solution. To address this issue, this work proposes a novel and completely parallel computation framework by leveraging the alternating direction method of multipliers (ADMM). The nonlinear and nonconvex optimization problem in the autonomous driving problem can be divided into two manageable subproblems; and the resulting subproblems can be solved by using effective optimization methods in a parallel framework. Here, the differential dynamic programming (DDP) algorithm is capable of addressing the nonlinearity of the system dynamics rather effectively; and the nonconvex coupling constraints with small dimensions can be approximated by invoking the notion of semi-definite relaxation (SDR), which can also be solved in a very short time. Due to the parallel computation and efficient relaxation of nonconvex constraints, our proposed approach effectively realizes real-time implementation and thus also extra assurance of driving safety is provided. In addition, two transportation scenarios for multiple CAVs are used to illustrate the effectiveness and efficiency of the proposed method.",
        "published": "2021-01-01T09:08:01Z",
        "link": "http://arxiv.org/abs/2101.00201v1",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Sequential Convex Programming for Collaboration of Connected and   Automated Vehicles",
        "authors": [
            "Xiaoxue Zhang",
            "Jun Ma",
            "Zilong Cheng",
            "Frank L. Lewis",
            "Tong Heng Lee"
        ],
        "summary": "This paper investigates the collaboration of multiple connected and automated vehicles (CAVs) in different scenarios. In general, the collaboration of CAVs can be formulated as a nonlinear and nonconvex model predictive control (MPC) problem. Most of the existing approaches available for utilization to solve such an optimization problem suffer from the drawback of considerable computational burden, which hinders the practical implementation in real time. This paper proposes the use of sequential convex programming (SCP), which is a powerful approach to solving the nonlinear and nonconvex MPC problem in real time. To appropriately deploy the methodology, as a first stage, SCP requires linearization and discretization when addressing the nonlinear dynamics of the system model adequately. Based on the linearization and discretization, the original MPC problem can be transformed into a quadratically constrained quadratic programming (QCQP) problem. Besides, SCP also involves convexification to handle the associated nonconvex constraints. Thus, the nonconvex QCQP can be reduced to a quadratic programming (QP) problem that can be solved rather quickly. Therefore, the computational efficiency is suitably improved despite the existence of nonlinear and nonconvex characteristics, whereby the implementation is realized in real time. Furthermore, simulation results in three different scenarios of autonomous driving are presented to validate the effectiveness and efficiency of our proposed approach.",
        "published": "2021-01-01T09:19:04Z",
        "link": "http://arxiv.org/abs/2101.00202v2",
        "categories": [
            "math.OC",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Past, Present, and Future of Swarm Robotics",
        "authors": [
            "Ahmad Reza Cheraghi",
            "Sahdia Shahzad",
            "Kalman Graffi"
        ],
        "summary": "Swarm Robotics is an emerging field of adapting the phenomenon of natural swarms to robotics. It is a study of robots that are aimed to mimic natural swarms, like ants and birds, to form a system that is scalable, flexible, and robust. These robots show self-organization, autonomy, cooperation, and coordination amongst themselves. The cost and design complexity factor is aimed to keep low, hence trying to form systems that are very much similar to natural swarms. The robots operate without any central entity to control them, and the communication amongst the robots can either be direct (robot-to-robot) or indirect (robot-to-environment). Swarm robotics has a wide range of application fields, from simple household tasks to military missions. This paper reviews the swarm robotics approach from its history to its future. It discusses the basic idea of swarm robotics, its important features, simulators, projects, real life applications and some future ideas.",
        "published": "2021-01-03T17:27:36Z",
        "link": "http://arxiv.org/abs/2101.00671v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "MetaVIM: Meta Variationally Intrinsic Motivated Reinforcement Learning   for Decentralized Traffic Signal Control",
        "authors": [
            "Liwen Zhu",
            "Peixi Peng",
            "Zongqing Lu",
            "Xiangqian Wang",
            "Yonghong Tian"
        ],
        "summary": "Traffic signal control aims to coordinate traffic signals across intersections to improve the traffic efficiency of a district or a city. Deep reinforcement learning (RL) has been applied to traffic signal control recently and demonstrated promising performance where each traffic signal is regarded as an agent. However, there are still several challenges that may limit its large-scale application in the real world. To make the policy learned from a training scenario generalizable to new unseen scenarios, a novel Meta Variationally Intrinsic Motivated (MetaVIM) RL method is proposed to learn the decentralized policy for each intersection that considers neighbor information in a latent way. Specifically, we formulate the policy learning as a meta-learning problem over a set of related tasks, where each task corresponds to traffic signal control at an intersection whose neighbors are regarded as the unobserved part of the state. Then, a learned latent variable is introduced to represent the task's specific information and is further brought into the policy for learning. In addition, to make the policy learning stable, a novel intrinsic reward is designed to encourage each agent's received rewards and observation transition to be predictable only conditioned on its own history. Extensive experiments conducted on CityFlow demonstrate that the proposed method substantially outperforms existing approaches and shows superior generalizability.",
        "published": "2021-01-04T03:06:08Z",
        "link": "http://arxiv.org/abs/2101.00746v5",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "A Linearly Convergent Algorithm for Distributed Principal Component   Analysis",
        "authors": [
            "Arpita Gang",
            "Waheed U. Bajwa"
        ],
        "summary": "Principal Component Analysis (PCA) is the workhorse tool for dimensionality reduction in this era of big data. While often overlooked, the purpose of PCA is not only to reduce data dimensionality, but also to yield features that are uncorrelated. Furthermore, the ever-increasing volume of data in the modern world often requires storage of data samples across multiple machines, which precludes the use of centralized PCA algorithms. This paper focuses on the dual objective of PCA, namely, dimensionality reduction and decorrelation of features, but in a distributed setting. This requires estimating the eigenvectors of the data covariance matrix, as opposed to only estimating the subspace spanned by the eigenvectors, when data is distributed across a network of machines. Although a few distributed solutions to the PCA problem have been proposed recently, convergence guarantees and/or communications overhead of these solutions remain a concern. With an eye towards communications efficiency, this paper introduces a feedforward neural network-based one time-scale distributed PCA algorithm termed Distributed Sanger's Algorithm (DSA) that estimates the eigenvectors of the data covariance matrix when data is distributed across an undirected and arbitrarily connected network of machines. Furthermore, the proposed algorithm is shown to converge linearly to a neighborhood of the true solution. Numerical results are also provided to demonstrate the efficacy of the proposed solution.",
        "published": "2021-01-05T00:51:14Z",
        "link": "http://arxiv.org/abs/2101.01300v4",
        "categories": [
            "cs.LG",
            "cs.DC",
            "cs.MA",
            "eess.SP",
            "stat.ML"
        ]
    },
    {
        "title": "Neurosymbolic Transformers for Multi-Agent Communication",
        "authors": [
            "Jeevana Priya Inala",
            "Yichen Yang",
            "James Paulos",
            "Yewen Pu",
            "Osbert Bastani",
            "Vijay Kumar",
            "Martin Rinard",
            "Armando Solar-Lezama"
        ],
        "summary": "We study the problem of inferring communication structures that can solve cooperative multi-agent planning problems while minimizing the amount of communication. We quantify the amount of communication as the maximum degree of the communication graph; this metric captures settings where agents have limited bandwidth. Minimizing communication is challenging due to the combinatorial nature of both the decision space and the objective; for instance, we cannot solve this problem by training neural networks using gradient descent. We propose a novel algorithm that synthesizes a control policy that combines a programmatic communication policy used to generate the communication graph with a transformer policy network used to choose actions. Our algorithm first trains the transformer policy, which implicitly generates a \"soft\" communication graph; then, it synthesizes a programmatic communication policy that \"hardens\" this graph, forming a neurosymbolic transformer. Our experiments demonstrate how our approach can synthesize policies that generate low-degree communication graphs while maintaining near-optimal performance.",
        "published": "2021-01-05T04:13:57Z",
        "link": "http://arxiv.org/abs/2101.03238v1",
        "categories": [
            "cs.MA",
            "cs.LG",
            "cs.PL"
        ]
    },
    {
        "title": "Sequential Choice Bandits with Feedback for Personalizing users'   experience",
        "authors": [
            "Anshuka Rangi",
            "Massimo Franceschetti",
            "Long Tran-Thanh"
        ],
        "summary": "In this work, we study sequential choice bandits with feedback. We propose bandit algorithms for a platform that personalizes users' experience to maximize its rewards. For each action directed to a given user, the platform is given a positive reward, which is a non-decreasing function of the action, if this action is below the user's threshold. Users are equipped with a patience budget, and actions that are above the threshold decrease the user's patience. When all patience is lost, the user abandons the platform. The platform attempts to learn the thresholds of the users in order to maximize its rewards, based on two different feedback models describing the information pattern available to the platform at each action. We define a notion of regret by determining the best action to be taken when the platform knows that the user's threshold is in a given interval. We then propose bandit algorithms for the two feedback models and show that upper and lower bounds on the regret are of the order of $\\tilde{O}(N^{2/3})$ and $\\tilde\\Omega(N^{2/3})$, respectively, where $N$ is the total number of users. Finally, we show that the waiting time of any user before receiving a personalized experience is uniform in $N$.",
        "published": "2021-01-05T15:04:10Z",
        "link": "http://arxiv.org/abs/2101.01572v1",
        "categories": [
            "stat.ML",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "One-shot Policy Elicitation via Semantic Reward Manipulation",
        "authors": [
            "Aaquib Tabrez",
            "Ryan Leonard",
            "Bradley Hayes"
        ],
        "summary": "Synchronizing expectations and knowledge about the state of the world is an essential capability for effective collaboration. For robots to effectively collaborate with humans and other autonomous agents, it is critical that they be able to generate intelligible explanations to reconcile differences between their understanding of the world and that of their collaborators. In this work we present Single-shot Policy Explanation for Augmenting Rewards (SPEAR), a novel sequential optimization algorithm that uses semantic explanations derived from combinations of planning predicates to augment agents' reward functions, driving their policies to exhibit more optimal behavior. We provide an experimental validation of our algorithm's policy manipulation capabilities in two practically grounded applications and conclude with a performance analysis of SPEAR on domains of increasingly complex state space and predicate counts. We demonstrate that our method makes substantial improvements over the state-of-the-art in terms of runtime and addressable problem size, enabling an agent to leverage its own expertise to communicate actionable information to improve another's performance.",
        "published": "2021-01-06T04:11:22Z",
        "link": "http://arxiv.org/abs/2101.01860v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Dynamic Prioritization for Conflict-Free Path Planning of Multi-Robot   Systems",
        "authors": [
            "Aditya Rathi",
            "Rohith G",
            "Madhu Vadali"
        ],
        "summary": "Planning collision-free paths for multi-robot systems (MRS) is a challenging problem because of the safety and efficiency constraints required for real-world solutions. Even though coupled path planning approaches provide optimal collision-free paths for each agent of the MRS, they search the composite space of all the agents and therefore, suffer from exponential increase in computation with the number of robots. On the other hand, prioritized approaches provide a practical solution to applications with large number of robots, especially when path computation time and collision avoidance take precedence over guaranteed globally optimal solution. While most centrally-planned algorithms use static prioritization, a dynamic prioritization algorithm, PD*, is proposed that employs a novel metric, called freedom index, to decide the priority order of the robots at each time step. This allows the PD* algorithm to simultaneously plan the next step for all robots while ensuring collision-free operation in obstacle ridden environments. Extensive simulations were performed to test and compare the performance of the proposed PD* scheme with other state-of-the-art algorithms. It was found that PD* improves upon the computational time by 25% while providing solutions of similar path lengths. Increase in efficiency was particularly prominent in scenarios with large number of robots and/or higher obstacle densities, where the probability of collisions is higher, suggesting the suitability of PD* in solving such problems.",
        "published": "2021-01-06T11:31:44Z",
        "link": "http://arxiv.org/abs/2101.01978v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Latency Analysis of ROS2 Multi-Node Systems",
        "authors": [
            "Tobias Kronauer",
            "Joshwa Pohlmann",
            "Maximilian Matthe",
            "Till Smejkal",
            "Gerhard Fettweis"
        ],
        "summary": "The Robot Operating System 2 (ROS2) targets distributed real-time systems and is widely used in the robotics community. Especially in these systems, latency in data processing and communication can lead to instabilities. Though being highly configurable with respect to latency, ROS2 is often used with its default settings.   In this paper, we investigate the end-to-end latency of ROS2 for distributed systems with default settings and different Data Distribution Service (DDS) middlewares. In addition, we profile the ROS2 stack and point out latency bottlenecks. Our findings indicate that end-to-end latency strongly depends on the used DDS middleware. Moreover, we show that ROS2 can lead to 50% latency overhead compared to using low-level DDS communications. Our results imply guidelines for designing distributed ROS2 architectures and indicate possibilities for reducing the ROS2 overhead.",
        "published": "2021-01-06T14:50:09Z",
        "link": "http://arxiv.org/abs/2101.02074v3",
        "categories": [
            "cs.RO",
            "cs.DC",
            "cs.MA",
            "cs.PF",
            "cs.SE"
        ]
    },
    {
        "title": "Attention Actor-Critic algorithm for Multi-Agent Constrained   Co-operative Reinforcement Learning",
        "authors": [
            "P. Parnika",
            "Raghuram Bharadwaj Diddigi",
            "Sai Koti Reddy Danda",
            "Shalabh Bhatnagar"
        ],
        "summary": "In this work, we consider the problem of computing optimal actions for Reinforcement Learning (RL) agents in a co-operative setting, where the objective is to optimize a common goal. However, in many real-life applications, in addition to optimizing the goal, the agents are required to satisfy certain constraints specified on their actions. Under this setting, the objective of the agents is to not only learn the actions that optimize the common objective but also meet the specified constraints. In recent times, the Actor-Critic algorithm with an attention mechanism has been successfully applied to obtain optimal actions for RL agents in multi-agent environments. In this work, we extend this algorithm to the constrained multi-agent RL setting. The idea here is that optimizing the common goal and satisfying the constraints may require different modes of attention. By incorporating different attention modes, the agents can select useful information required for optimizing the objective and satisfying the constraints separately, thereby yielding better actions. Through experiments on benchmark multi-agent environments, we show the effectiveness of our proposed algorithm.",
        "published": "2021-01-07T03:21:15Z",
        "link": "http://arxiv.org/abs/2101.02349v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Rankings for Bipartite Tournaments via Chain Editing",
        "authors": [
            "Joseph Singleton",
            "Richard Booth"
        ],
        "summary": "Ranking the participants of a tournament has applications in voting, paired comparisons analysis, sports and other domains. In this paper we introduce bipartite tournaments, which model situations in which two different kinds of entity compete indirectly via matches against players of the opposite kind; examples include education (students/exam questions) and solo sports (golfers/courses). In particular, we look to find rankings via chain graphs, which correspond to bipartite tournaments in which the sets of adversaries defeated by the players on one side are nested with respect to set inclusion. Tournaments of this form have a natural and appealing ranking associated with them. We apply chain editing -- finding the minimum number of edge changes required to form a chain graph -- as a new mechanism for tournament ranking. The properties of these rankings are investigated in a probabilistic setting, where they arise as maximum likelihood estimators, and through the axiomatic method of social choice theory. Despite some nice properties, two problems remain: an important anonymity axiom is violated, and chain editing is NP-hard. We address both issues by relaxing the minimisation constraint in chain editing, and characterise the resulting ranking methods via a greedy approximation algorithm.",
        "published": "2021-01-07T10:49:57Z",
        "link": "http://arxiv.org/abs/2101.02476v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Active Screening for Recurrent Diseases: A Reinforcement Learning   Approach",
        "authors": [
            "Han-Ching Ou",
            "Haipeng Chen",
            "Shahin Jabbari",
            "Milind Tambe"
        ],
        "summary": "Active screening is a common approach in controlling the spread of recurring infectious diseases such as tuberculosis and influenza. In this approach, health workers periodically select a subset of population for screening. However, given the limited number of health workers, only a small subset of the population can be visited in any given time period. Given the recurrent nature of the disease and rapid spreading, the goal is to minimize the number of infections over a long time horizon. Active screening can be formalized as a sequential combinatorial optimization over the network of people and their connections. The main computational challenges in this formalization arise from i) the combinatorial nature of the problem, ii) the need of sequential planning and iii) the uncertainties in the infectiousness states of the population.   Previous works on active screening fail to scale to large time horizon while fully considering the future effect of current interventions. In this paper, we propose a novel reinforcement learning (RL) approach based on Deep Q-Networks (DQN), with several innovative adaptations that are designed to address the above challenges. First, we use graph convolutional networks (GCNs) to represent the Q-function that exploit the node correlations of the underlying contact network. Second, to avoid solving a combinatorial optimization problem in each time period, we decompose the node set selection as a sub-sequence of decisions, and further design a two-level RL framework that solves the problem in a hierarchical way. Finally, to speed-up the slow convergence of RL which arises from reward sparseness, we incorporate ideas from curriculum learning into our hierarchical RL approach. We evaluate our RL algorithm on several real-world networks.",
        "published": "2021-01-07T21:07:35Z",
        "link": "http://arxiv.org/abs/2101.02766v3",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Practical Control for Multicopters to Avoid Non-Cooperative Moving   Obstacles",
        "authors": [
            "Quan Quan",
            "Rao Fu",
            "Kai-Yuan Cai"
        ],
        "summary": "Unmanned Aerial Vehicles (UAVs) are now becoming increasingly accessible to amateur and commercial users alike. The main task for UAVs is to keep a prescribed separation with obstacles in the air. In this paper, a collision-avoidance control method for non-cooperative moving obstacles is proposed for a multicopter with the altitude hold mode by using a Lyapunov-like barrier function. Lyapunov-like functions are designed elaborately, based on which formal analysis and proofs of the proposed control are made to show that the collision-avoidance control problem can be solved if the moving obstacle is slower than the multicopter. The result can be extended to some cases of multiple obstacles. What is more, by the proposed control, a multicopter can keep away from obstacles as soon as possible, once obstacles enter into the safety area of the multicopter accidentally, and converge to the waypoint. Simulations and experiments are given to show the effectiveness of the proposed method by showing the distance between UAV and waypoint, obstacles respectively.",
        "published": "2021-01-08T07:47:11Z",
        "link": "http://arxiv.org/abs/2101.02889v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "The Computation of Approximate Generalized Feedback Nash Equilibria",
        "authors": [
            "Forrest Laine",
            "David Fridovich-Keil",
            "Chih-Yuan Chiu",
            "Claire Tomlin"
        ],
        "summary": "We present the concept of a Generalized Feedback Nash Equilibrium (GFNE) in dynamic games, extending the Feedback Nash Equilibrium concept to games in which players are subject to state and input constraints. We formalize necessary and sufficient conditions for (local) GFNE solutions at the trajectory level, which enable the development of efficient numerical methods for their computation. Specifically, we propose a Newton-style method for finding game trajectories which satisfy necessary conditions for an equilibrium, which can then be checked against sufficiency conditions. We show that the evaluation of the necessary conditions in general requires computing a series of nested, implicitly-defined derivatives, which quickly becomes intractable. To this end, we introduce an approximation to the necessary conditions which is amenable to efficient evaluation, and in turn, computation of solutions. We term the solutions to the approximate necessary conditions Generalized Feedback Quasi-Nash Equilibria (GFQNE), and we introduce numerical methods for their computation. In particular, we develop a Sequential Linear-Quadratic Game approach, in which a LQ local approximation of the game is solved at each iteration. The development of this method relies on the ability to compute a GFNE to inequality- and equality-constrained LQ games, and therefore specific methods for the solution of these special cases are developed in detail. We demonstrate the effectiveness of the proposed solution approach on a dynamic game arising in an autonomous driving application.",
        "published": "2021-01-08T08:17:36Z",
        "link": "http://arxiv.org/abs/2101.02900v3",
        "categories": [
            "math.OC",
            "cs.GT",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Robust and Scalable Routing with Multi-Agent Deep Reinforcement Learning   for MANETs",
        "authors": [
            "Saeed Kaviani",
            "Bo Ryu",
            "Ejaz Ahmed",
            "Kevin A. Larson",
            "Anh Le",
            "Alex Yahja",
            "Jae H. Kim"
        ],
        "summary": "Highly dynamic mobile ad-hoc networks (MANETs) are continuing to serve as one of the most challenging environments to develop and deploy robust, efficient, and scalable routing protocols. In this paper, we present DeepCQ+ routing which, in a novel manner, integrates emerging multi-agent deep reinforcement learning (MADRL) techniques into existing Q-learning-based routing protocols and their variants, and achieves persistently higher performance across a wide range of MANET configurations while training only on a limited range of network parameters and conditions. Quantitatively, DeepCQ+ shows consistently higher end-to-end throughput with lower overhead compared to its Q-learning-based counterparts with the overall gain of 10-15% in its efficiency. Qualitatively and more significantly, DeepCQ+ maintains remarkably similar performance gains under many scenarios that it was not trained for in terms of network sizes, mobility conditions, and traffic dynamics. To the best of our knowledge, this is the first successful demonstration of MADRL for the MANET routing problem that achieves and maintains a high degree of scalability and robustness even in the environments that are outside the trained range of scenarios. This implies that the proposed hybrid design approach of DeepCQ+ that combines MADRL and Q-learning significantly increases its practicality and explainability because the real-world MANET environment will likely vary outside the trained range of MANET scenarios.",
        "published": "2021-01-09T02:26:14Z",
        "link": "http://arxiv.org/abs/2101.03273v2",
        "categories": [
            "cs.NI",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "A negotiating protocol for group decision support systems",
        "authors": [
            "Safia Sadji"
        ],
        "summary": "Our contribution concerns interactive decision support systems for group decision support. Through this study, we apply to implement a decisional process aiming to represent the multiplicity of actors, their diversity, their behaviors and their interactions. In this context, we contribute to the design and development of a group decision support system. The system is modeled by a multi agents system while exploiting a negotiation protocol based on mediation and concession. This protocol allows decision-makers to express their preferences using multicriteria analysis methods, mainly the method by total aggregation AHP (Hierarchical Process Analysis) and the method by partial aggregation PROMETHEE II .",
        "published": "2021-01-10T16:52:51Z",
        "link": "http://arxiv.org/abs/2101.03580v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Deep Interactive Bayesian Reinforcement Learning via Meta-Learning",
        "authors": [
            "Luisa Zintgraf",
            "Sam Devlin",
            "Kamil Ciosek",
            "Shimon Whiteson",
            "Katja Hofmann"
        ],
        "summary": "Agents that interact with other agents often do not know a priori what the other agents' strategies are, but have to maximise their own online return while interacting with and learning about others. The optimal adaptive behaviour under uncertainty over the other agents' strategies w.r.t. some prior can in principle be computed using the Interactive Bayesian Reinforcement Learning framework. Unfortunately, doing so is intractable in most settings, and existing approximation methods are restricted to small tasks. To overcome this, we propose to meta-learn approximate belief inference and Bayes-optimal behaviour for a given prior. To model beliefs over other agents, we combine sequential and hierarchical Variational Auto-Encoders, and meta-train this inference model alongside the policy. We show empirically that our approach outperforms existing methods that use a model-free approach, sample from the approximate posterior, maintain memory-free models of others, or do not fully utilise the known structure of the environment.",
        "published": "2021-01-11T13:25:13Z",
        "link": "http://arxiv.org/abs/2101.03864v2",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "VIDA: A simulation model of domestic VIolence in times of social   DistAncing",
        "authors": [
            "Lígia Mori Madeira",
            "Bernardo Alves Furtado",
            "Alan Rafael Dill"
        ],
        "summary": "Violence against women occurs predominantly in the family and domestic context. The COVID-19 pandemic led Brazil to recommend and, at times, impose social distancing, with the partial closure of economic activities, schools, and restrictions on events and public services. Preliminary evidence shows that intense coexistence increases domestic violence, while social distancing measures may have prevented access to public services and networks, information, and help. We propose an agent-based model (ABM), called VIDA, to illustrate and examine multi-causal factors that influence events that generate violence. A central part of the model is the multi-causal stress indicator, created as a probability trigger of domestic violence occurring within the family environment. Two experimental design tests were performed: (a) absence or presence of the deterrence system of domestic violence against women and (b) measures to increase social distancing. VIDA presents comparative results for metropolitan regions and neighbourhoods considered in the experiments. Results suggest that social distancing measures, particularly those encouraging staying at home, may have increased domestic violence against women by about 10%. VIDA suggests further that more populated areas have comparatively fewer cases per hundred thousand women than less populous capitals or rural areas of urban concentrations. This paper contributes to the literature by formalising, to the best of our knowledge, the first model of domestic violence through agent-based modelling, using empirical detailed socioeconomic, demographic, educational, gender, and race data at the intraurban level (census sectors).",
        "published": "2021-01-11T17:42:49Z",
        "link": "http://arxiv.org/abs/2101.04057v1",
        "categories": [
            "cs.MA",
            "I.6.5; J.4"
        ]
    },
    {
        "title": "Survival of the strictest: Stable and unstable equilibria under   regularized learning with partial information",
        "authors": [
            "Angeliki Giannou",
            "Emmanouil-Vasileios Vlatakis-Gkaragkounis",
            "Panayotis Mertikopoulos"
        ],
        "summary": "In this paper, we examine the Nash equilibrium convergence properties of no-regret learning in general N-player games. For concreteness, we focus on the archetypal follow the regularized leader (FTRL) family of algorithms, and we consider the full spectrum of uncertainty that the players may encounter - from noisy, oracle-based feedback, to bandit, payoff-based information. In this general context, we establish a comprehensive equivalence between the stability of a Nash equilibrium and its support: a Nash equilibrium is stable and attracting with arbitrarily high probability if and only if it is strict (i.e., each equilibrium strategy has a unique best response). This equivalence extends existing continuous-time versions of the folk theorem of evolutionary game theory to a bona fide algorithmic learning setting, and it provides a clear refinement criterion for the prediction of the day-to-day behavior of no-regret learning in games",
        "published": "2021-01-12T18:55:11Z",
        "link": "http://arxiv.org/abs/2101.04667v2",
        "categories": [
            "cs.GT",
            "cs.LG",
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "Scalable Anytime Planning for Multi-Agent MDPs",
        "authors": [
            "Shushman Choudhury",
            "Jayesh K. Gupta",
            "Peter Morales",
            "Mykel J. Kochenderfer"
        ],
        "summary": "We present a scalable tree search planning algorithm for large multi-agent sequential decision problems that require dynamic collaboration. Teams of agents need to coordinate decisions in many domains, but naive approaches fail due to the exponential growth of the joint action space with the number of agents. We circumvent this complexity through an anytime approach that allows us to trade computation for approximation quality and also dynamically coordinate actions. Our algorithm comprises three elements: online planning with Monte Carlo Tree Search (MCTS), factored representations of local agent interactions with coordination graphs, and the iterative Max-Plus method for joint action selection. We evaluate our approach on the benchmark SysAdmin domain with static coordination graphs and achieve comparable performance with much lower computation cost than our MCTS baselines. We also introduce a multi-drone delivery domain with dynamic, i.e., state-dependent coordination graphs, and demonstrate how our approach scales to large problems on this domain that are intractable for other MCTS methods. We provide an open-source implementation of our algorithm at https://github.com/JuliaPOMDP/FactoredValueMCTS.jl.",
        "published": "2021-01-12T22:50:17Z",
        "link": "http://arxiv.org/abs/2101.04788v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "GPS Spoofing Mitigation and Timing Risk Analysis in Networked PMUs via   Stochastic Reachability",
        "authors": [
            "Sriramya Bhamidipati",
            "Grace Xingxin Gao"
        ],
        "summary": "To address PMU vulnerability against spoofing, we propose a set-valued state estimation technique known as Stochastic Reachability-based Distributed Kalman Filter (SR-DKF) that computes secure GPS timing across a network of receivers. Utilizing stochastic reachability, we estimate not only GPS time but also its stochastic reachable set, which is parameterized via probabilistic zonotope (p-Zonotope). While requiring known measurement error bounds in only non-spoofed conditions, we design a two-tier approach: We first perform measurement-level spoofing mitigation via deviation of measurement innovation from its expected p-Zonotope and second perform state-level timing risk analysis via intersection probability of estimated pZonotope with an unsafe set that violates IEEE C37.118.1a-2014 standards. We validate the proposed SR-DKF by subjecting a simulated receiver network to coordinated signal-level spoofing. We demonstrate improved GPS timing accuracy and successful spoofing mitigation via our SR-DKF. We validate the robustness of the estimated timing risk as the number of receivers is varied.",
        "published": "2021-01-13T02:15:17Z",
        "link": "http://arxiv.org/abs/2101.04835v1",
        "categories": [
            "cs.MA",
            "cs.RO",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Act to Reason: A Dynamic Game Theoretical Model of Driving",
        "authors": [
            "Cevahir Köprülü",
            "Yıldıray Yıldız"
        ],
        "summary": "The focus of this paper is to propose a driver model that incorporates human reasoning levels as actions during interactions with other drivers. Different from earlier work using game theoretical human reasoning levels, we propose a dynamic approach, where the actions are the levels themselves, instead of conventional driving actions such as accelerating or braking. This results in a dynamic behavior, where the agent adapts to its environment by exploiting different behavior models as available moves to choose from, depending on the requirements of the traffic situation. The bounded rationality assumption is preserved since the selectable strategies are designed by adhering to the fact that humans are cognitively limited in their understanding and decision making. Using a highway merging scenario, it is demonstrated that the proposed dynamic approach produces more realistic outcomes compared to the conventional method that employs fixed human reasoning levels.",
        "published": "2021-01-14T00:16:01Z",
        "link": "http://arxiv.org/abs/2101.05399v2",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Learning Safe Multi-Agent Control with Decentralized Neural Barrier   Certificates",
        "authors": [
            "Zengyi Qin",
            "Kaiqing Zhang",
            "Yuxiao Chen",
            "Jingkai Chen",
            "Chuchu Fan"
        ],
        "summary": "We study the multi-agent safe control problem where agents should avoid collisions to static obstacles and collisions with each other while reaching their goals. Our core idea is to learn the multi-agent control policy jointly with learning the control barrier functions as safety certificates. We propose a novel joint-learning framework that can be implemented in a decentralized fashion, with generalization guarantees for certain function classes. Such a decentralized framework can adapt to an arbitrarily large number of agents. Building upon this framework, we further improve the scalability by incorporating neural network architectures that are invariant to the quantity and permutation of neighboring agents. In addition, we propose a new spontaneous policy refinement method to further enforce the certificate condition during testing. We provide extensive experiments to demonstrate that our method significantly outperforms other leading multi-agent control approaches in terms of maintaining safety and completing original tasks. Our approach also shows exceptional generalization capability in that the control policy can be trained with 8 agents in one scenario, while being used on other scenarios with up to 1024 agents in complex multi-agent environments and dynamics.",
        "published": "2021-01-14T03:17:17Z",
        "link": "http://arxiv.org/abs/2101.05436v4",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Evaluating the Robustness of Collaborative Agents",
        "authors": [
            "Paul Knott",
            "Micah Carroll",
            "Sam Devlin",
            "Kamil Ciosek",
            "Katja Hofmann",
            "A. D. Dragan",
            "Rohin Shah"
        ],
        "summary": "In order for agents trained by deep reinforcement learning to work alongside humans in realistic settings, we will need to ensure that the agents are \\emph{robust}. Since the real world is very diverse, and human behavior often changes in response to agent deployment, the agent will likely encounter novel situations that have never been seen during training. This results in an evaluation challenge: if we cannot rely on the average training or validation reward as a metric, then how can we effectively evaluate robustness? We take inspiration from the practice of \\emph{unit testing} in software engineering. Specifically, we suggest that when designing AI agents that collaborate with humans, designers should search for potential edge cases in \\emph{possible partner behavior} and \\emph{possible states encountered}, and write tests which check that the behavior of the agent in these edge cases is reasonable. We apply this methodology to build a suite of unit tests for the Overcooked-AI environment, and use this test suite to evaluate three proposals for improving robustness. We find that the test suite provides significant insight into the effects of these proposals that were generally not revealed by looking solely at the average validation reward.",
        "published": "2021-01-14T09:02:45Z",
        "link": "http://arxiv.org/abs/2101.05507v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.HC",
            "cs.MA"
        ]
    },
    {
        "title": "Design of false data injection attack on distributed process estimation",
        "authors": [
            "Moulik Choraria",
            "Arpan Chattopadhyay",
            "Urbashi Mitra",
            "Erik Strom"
        ],
        "summary": "Herein, design of false data injection attack on a distributed cyber-physical system is considered. A stochastic process with linear dynamics and Gaussian noise is measured by multiple agent nodes, each equipped with multiple sensors. The agent nodes form a multi-hop network among themselves. Each agent node computes an estimate of the process by using its sensor observation and messages obtained from neighboring nodes, via Kalman-consensus filtering. An external attacker, capable of arbitrarily manipulating the sensor observations of some or all agent nodes, injects errors into those sensor observations. The goal of the attacker is to steer the estimates at the agent nodes as close as possible to a pre-specified value, while respecting a constraint on the attack detection probability. To this end, a constrained optimization problem is formulated to find the optimal parameter values of a certain class of linear attacks. The parameters of linear attack are learnt on-line via a combination of stochastic approximation based update of a Lagrange multiplier, and an optimization technique involving either the Karush-Kuhn-Tucker (KKT) conditions or online stochastic gradient descent. The problem turns out to be convex for some special cases. Desired convergence of the proposed algorithms are proved by exploiting the convexity and properties of stochastic approximation algorithms. Finally, numerical results demonstrate the efficacy of the attack.",
        "published": "2021-01-14T12:27:38Z",
        "link": "http://arxiv.org/abs/2101.05567v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Should the government reward cooperation? Insights from an agent-based   model of wealth redistribution",
        "authors": [
            "Frank Schweitzer",
            "Luca Verginer",
            "Giacomo Vaccario"
        ],
        "summary": "In our multi-agent model agents generate wealth from repeated interactions for which a prisoner's dilemma payoff matrix is assumed. Their gains are taxed by a government at a rate $\\alpha$. The resulting budget is spent to cover administrative costs and to pay a bonus to cooperative agents, which can be identified correctly only with a probability $p$. Agents decide at each time step to choose either cooperation or defection based on different information. In the local scenario, they compare their potential gains from both strategies. In the global scenario, they compare the gains of the cooperative and defective subpopulations. We derive analytical expressions for the critical bonus needed to make cooperation as attractive as defection. We show that for the local scenario the government can establish only a medium level of cooperation, because the critical bonus increases with the level of cooperation. In the global scenario instead full cooperation can be achieved once the cold-start problem is solved, because the critical bonus decreases with the level of cooperation. This allows to lower the tax rate, while maintaining high cooperation.",
        "published": "2021-01-14T13:19:02Z",
        "link": "http://arxiv.org/abs/2101.05580v1",
        "categories": [
            "physics.soc-ph",
            "cs.MA",
            "econ.GN",
            "nlin.AO",
            "q-fin.EC"
        ]
    },
    {
        "title": "Spillover Algorithm: A Decentralized Coordination Approach for   Multi-Robot Production Planning in Open Shared Factories",
        "authors": [
            "Marin Lujak",
            "Alberto Fernández",
            "Eva Onaindia"
        ],
        "summary": "Open and shared manufacturing factories typically dispose of a limited number of robots that should be properly allocated to tasks in time and space for an effective and efficient system performance. In particular, we deal with the dynamic capacitated production planning problem with sequence independent setup costs where quantities of products to manufacture and location of robots need to be determined at consecutive periods within a given time horizon and products can be anticipated or backordered related to the demand period. We consider a decentralized multi-agent variant of this problem in an open factory setting with multiple owners of robots as well as different owners of the items to be produced, both considered self-interested and individually rational. Existing solution approaches to the classic constrained lot-sizing problem are centralized exact methods that require sharing of global knowledge of all the participants' private and sensitive information and are not applicable in the described multi-agent context. Therefore, we propose a computationally efficient decentralized approach based on the spillover effect that solves this NP-hard problem by distributing decisions in an intrinsically decentralized multi-agent system environment while protecting private and sensitive information. To the best of our knowledge, this is the first decentralized algorithm for the solution of the studied problem in intrinsically decentralized environments where production resources and/or products are owned by multiple stakeholders with possibly conflicting objectives. To show its efficiency, the performance of the Spillover Algorithm is benchmarked against state-of-the-art commercial solver CPLEX 12.8.",
        "published": "2021-01-14T16:23:45Z",
        "link": "http://arxiv.org/abs/2101.05700v2",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.DM",
            "cs.MA"
        ]
    },
    {
        "title": "Energy-Optimal Goal Assignment of Multi-Agent System with Goal   Trajectories in Polynomials",
        "authors": [
            "Heeseung Bang",
            "Logan Beaver",
            "Andreas A. Malikopoulos"
        ],
        "summary": "In this paper, we propose an approach for solving an energy-optimal goal assignment problem to generate the desired formation in multi-agent systems. Each agent solves a decentralized optimization problem with only local information about its neighboring agents and the goals. The optimization problem consists of two sub-problems. The first problem seeks to minimize the energy for each agent to reach certain goals, while the second problem entreats an optimal combination of goal and agent pairs that minimizes the energy cost. By assuming the goal trajectories are given in a polynomial form, we prove the solution to the formulated problem exists globally. Finally, the effectiveness of the proposed approach is validated through the simulation.",
        "published": "2021-01-15T20:03:15Z",
        "link": "http://arxiv.org/abs/2101.06288v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Minimal Schedule with Minimal Number of Agents in Attack-Defence Trees",
        "authors": [
            "Jaime Arias",
            "Łukasz Maśko",
            "Wojciech Penczek",
            "Laure Petrucci",
            "Teofil Sidoruk"
        ],
        "summary": "Expressing attack-defence trees in a multi-agent setting allows for studying a new aspect of security scenarios, namely how the number of agents and their task assignment impact the performance, e.g. attack time, of strategies executed by opposing coalitions. Optimal scheduling of agents' actions, a non-trivial problem, is thus vital. We discuss associated caveats and propose an algorithm that synthesises such an assignment, targeting minimal attack time and using minimal number of agents for a given attack-defence tree.",
        "published": "2021-01-18T02:08:53Z",
        "link": "http://arxiv.org/abs/2101.06838v5",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Cooperative and Competitive Biases for Multi-Agent Reinforcement   Learning",
        "authors": [
            "Heechang Ryu",
            "Hayong Shin",
            "Jinkyoo Park"
        ],
        "summary": "Training a multi-agent reinforcement learning (MARL) algorithm is more challenging than training a single-agent reinforcement learning algorithm, because the result of a multi-agent task strongly depends on the complex interactions among agents and their interactions with a stochastic and dynamic environment. We propose an algorithm that boosts MARL training using the biased action information of other agents based on a friend-or-foe concept. For a cooperative and competitive environment, there are generally two groups of agents: cooperative-agents and competitive-agents. In the proposed algorithm, each agent updates its value function using its own action and the biased action information of other agents in the two groups. The biased joint action of cooperative agents is computed as the sum of their actual joint action and the imaginary cooperative joint action, by assuming all the cooperative agents jointly maximize the target agent's value function. The biased joint action of competitive agents can be computed similarly. Each agent then updates its own value function using the biased action information, resulting in a biased value function and corresponding biased policy. Subsequently, the biased policy of each agent is inevitably subjected to recommend an action to cooperate and compete with other agents, thereby introducing more active interactions among agents and enhancing the MARL policy learning. We empirically demonstrate that our algorithm outperforms existing algorithms in various mixed cooperative-competitive environments. Furthermore, the introduced biases gradually decrease as the training proceeds and the correction based on the imaginary assumption vanishes.",
        "published": "2021-01-18T05:52:22Z",
        "link": "http://arxiv.org/abs/2101.06890v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Social cohesion V.S. task cohesion: An evolutionary game theory study",
        "authors": [
            "Xinglong Qu",
            "Shun Kurokawa",
            "The Anh Han"
        ],
        "summary": "Using methods from evolutionary game theory, this paper investigates the difference between social cohesion and task cohesion in promoting the evolution of cooperation in group interactions. Players engage in public goods games and are allowed to leave their groups if too many defections occur. Both social cohesion and task cohesion may prevent players from leaving. While a higher level of social cohesion increases a player's tolerance towards defections, task cohesion is associated with her group performance in the past. With a higher level of task cohesion, it is more likely that a dissatisfied player will refer to the history and remains in her group if she was satisfied in the past. Our results reveal that social cohesion is detrimental to the evolution of cooperation while task cohesion facilitates it. This is because social cohesion hinders the conditional dissociation mechanism but task cohesion improves the robustness of cooperative groups which are usually vulnerable to mistakes. We also discuss other potential aspects of cohesion and how they can be investigated through our modelling. Overall, our analysis provides novel insights into the relationship between group cohesion and group performance through studying the group dynamics and suggests further application of evolutionary game theory in this area.",
        "published": "2021-01-18T09:52:16Z",
        "link": "http://arxiv.org/abs/2101.06961v1",
        "categories": [
            "physics.soc-ph",
            "cs.MA",
            "nlin.AO",
            "nlin.CD"
        ]
    },
    {
        "title": "Deep Reinforcement Learning for Active High Frequency Trading",
        "authors": [
            "Antonio Briola",
            "Jeremy Turiel",
            "Riccardo Marcaccioli",
            "Alvaro Cauderan",
            "Tomaso Aste"
        ],
        "summary": "We introduce the first end-to-end Deep Reinforcement Learning (DRL) based framework for active high frequency trading in the stock market. We train DRL agents to trade one unit of Intel Corporation stock by employing the Proximal Policy Optimization algorithm. The training is performed on three contiguous months of high frequency Limit Order Book data, of which the last month constitutes the validation data. In order to maximise the signal to noise ratio in the training data, we compose the latter by only selecting training samples with largest price changes. The test is then carried out on the following month of data. Hyperparameters are tuned using the Sequential Model Based Optimization technique. We consider three different state characterizations, which differ in their LOB-based meta-features. Analysing the agents' performances on test data, we argue that the agents are able to create a dynamic representation of the underlying environment. They identify occasional regularities present in the data and exploit them to create long-term profitable trading strategies. Indeed, agents learn trading strategies able to produce stable positive returns in spite of the highly stochastic and non-stationary environment.",
        "published": "2021-01-18T15:09:28Z",
        "link": "http://arxiv.org/abs/2101.07107v3",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "q-fin.TR"
        ]
    },
    {
        "title": "HAMMER: Multi-Level Coordination of Reinforcement Learning Agents via   Learned Messaging",
        "authors": [
            "Nikunj Gupta",
            "G Srinivasaraghavan",
            "Swarup Kumar Mohalik",
            "Nishant Kumar",
            "Matthew E. Taylor"
        ],
        "summary": "Cooperative multi-agent reinforcement learning (MARL) has achieved significant results, most notably by leveraging the representation-learning abilities of deep neural networks. However, large centralized approaches quickly become infeasible as the number of agents scale, and fully decentralized approaches can miss important opportunities for information sharing and coordination. Furthermore, not all agents are equal -- in some cases, individual agents may not even have the ability to send communication to other agents or explicitly model other agents. This paper considers the case where there is a single, powerful, \\emph{central agent} that can observe the entire observation space, and there are multiple, low-powered \\emph{local agents} that can only receive local observations and are not able to communicate with each other. The central agent's job is to learn what message needs to be sent to different local agents based on the global observations, not by centrally solving the entire problem and sending action commands, but by determining what additional information an individual agent should receive so that it can make a better decision. In this work we present our MARL algorithm \\algo, describe where it would be most applicable, and implement it in the cooperative navigation and multi-agent walker domains. Empirical results show that 1) learned communication does indeed improve system performance, 2) results generalize to heterogeneous local agents, and 3) results generalize to different reward structures.",
        "published": "2021-01-18T19:00:12Z",
        "link": "http://arxiv.org/abs/2102.00824v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Autonomous synthesis of metastable materials",
        "authors": [
            "Sebastian Ament",
            "Maximilian Amsler",
            "Duncan R. Sutherland",
            "Ming-Chiang Chang",
            "Dan Guevarra",
            "Aine B. Connolly",
            "John M. Gregoire",
            "Michael O. Thompson",
            "Carla P. Gomes",
            "R. Bruce van Dover"
        ],
        "summary": "Autonomous experimentation enabled by artificial intelligence (AI) offers a new paradigm for accelerating scientific discovery. Non-equilibrium materials synthesis is emblematic of complex, resource-intensive experimentation whose acceleration would be a watershed for materials discovery and development. The mapping of non-equilibrium synthesis phase diagrams has recently been accelerated via high throughput experimentation but still limits materials research because the parameter space is too vast to be exhaustively explored. We demonstrate accelerated synthesis and exploration of metastable materials through hierarchical autonomous experimentation governed by the Scientific Autonomous Reasoning Agent (SARA). SARA integrates robotic materials synthesis and characterization along with a hierarchy of AI methods that efficiently reveal the structure of processing phase diagrams. SARA designs lateral gradient laser spike annealing (lg-LSA) experiments for parallel materials synthesis and employs optical spectroscopy to rapidly identify phase transitions. Efficient exploration of the multi-dimensional parameter space is achieved with nested active learning (AL) cycles built upon advanced machine learning models that incorporate the underlying physics of the experiments as well as end-to-end uncertainty quantification. With this, and the coordination of AL at multiple scales, SARA embodies AI harnessing of complex scientific tasks. We demonstrate its performance by autonomously mapping synthesis phase boundaries for the Bi$_2$O$_3$ system, leading to orders-of-magnitude acceleration in establishment of a synthesis phase diagram that includes conditions for kinetically stabilizing $\\delta$-Bi$_2$O$_3$ at room temperature, a critical development for electrochemical technologies such as solid oxide fuel cells.",
        "published": "2021-01-19T00:29:26Z",
        "link": "http://arxiv.org/abs/2101.07385v2",
        "categories": [
            "cond-mat.mtrl-sci",
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Fairness Criteria for Allocating Indivisible Chores: Connections and   Efficiencies",
        "authors": [
            "Ankang Sun",
            "Bo Chen",
            "Xuan Vinh Doan"
        ],
        "summary": "We study several fairness notions in allocating indivisible chores (i.e., items with non-positive values) to agents who have additive and submodular cost functions. The fairness criteria we are concern with are envy-free up to any item (EFX), envy-free up to one item (EF1), maximin share (MMS), and pairwise maximin share (PMMS), which are proposed as relaxations of envy-freeness in the setting of additive cost functions. For allocations under each fairness criterion, we establish their approximation guarantee for other fairness criteria. Under the additive setting, our results show strong connections between these fairness criteria and, at the same time, reveal intrinsic differences between goods allocation and chores allocation. However, such strong relationships cannot be inherited by the submodular setting, under which PMMS and MMS are no longer relaxations of envy-freeness and, even worse, few non-trivial guarantees exist. We also investigate efficiency loss under these fairness constraints and establish their prices of fairness.",
        "published": "2021-01-19T03:08:43Z",
        "link": "http://arxiv.org/abs/2101.07435v3",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "A synthetic biology approach for the design of genetic algorithms with   bacterial agents",
        "authors": [
            "A. Gargantilla Becerra",
            "M. Gutiérrez",
            "R. Lahoz-Beltra"
        ],
        "summary": "Bacteria have been a source of inspiration for the design of evolutionary algorithms. At the beginning of the 20th century synthetic biology was born, a discipline whose goal is the design of biological systems that do not exist in nature, for example, programmable synthetic bacteria. In this paper, we introduce as a novelty the designing of evolutionary algorithms where all the steps are conducted by synthetic bacteria. To this end, we designed a genetic algorithm, which we have named BAGA, illustrating its utility solving simple instances of optimization problems such as function optimization, 0/1 knapsack problem, Hamiltonian path problem. The results obtained open the possibility of conceiving evolutionary algorithms inspired by principles, mechanisms and genetic circuits from synthetic biology. In summary, we can conclude that synthetic biology is a source of inspiration either for the design of evolutionary algorithms or for some of their steps, as shown by the results obtained in our simulation experiments.",
        "published": "2021-01-19T09:59:33Z",
        "link": "http://arxiv.org/abs/2101.07540v1",
        "categories": [
            "cs.NE",
            "cs.MA"
        ]
    },
    {
        "title": "Practical Distributed Control for VTOL UAVs to Pass a Virtual Tube",
        "authors": [
            "Quan Quan",
            "Rao Fu",
            "Mengxin Li",
            "Donghui Wei",
            "Yan Gao",
            "Kai-Yuan Cai"
        ],
        "summary": "Unmanned Aerial Vehicles (UAVs) are now becoming increasingly accessible to amateur and commercial users alike. An air traffic management (ATM) system is needed to help ensure that this newest entrant into the skies does not collide with others. In an ATM, airspace can be composed of airways, intersections and nodes. In this paper, for simplicity, distributed coordinating the motions of Vertical TakeOff and Landing (VTOL) UAVs to pass an airway is focused. This is formulated as a virtual tube passing problem, which includes passing a virtual tube, inter-agent collision avoidance and keeping within the virtual tube. Lyapunov-like functions are designed elaborately, and formal analysis based on invariant set theorem is made to show that all UAVs can pass the virtual tube without getting trapped, avoid collision and keep within the virtual tube. What is more, by the proposed distributed control, a VTOL UAV can keep away from another VTOL UAV or return back to the virtual tube as soon as possible, once it enters into the safety area of another or has a collision with the virtual tube during it is passing the virtual tube. Simulations and experiments are carried out to show the effectiveness of the proposed method and the comparison with other methods.",
        "published": "2021-01-19T11:52:30Z",
        "link": "http://arxiv.org/abs/2101.07578v2",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Flocking and Collision Avoidance for a Dynamic Squad of Fixed-Wing UAVs   Using Deep Reinforcement Learning",
        "authors": [
            "Chao Yan",
            "Xiaojia Xiang",
            "Chang Wang",
            "Zhen Lan"
        ],
        "summary": "Developing the flocking behavior for a dynamic squad of fixed-wing UAVs is still a challenge due to kinematic complexity and environmental uncertainty. In this paper, we deal with the decentralized flocking and collision avoidance problem through deep reinforcement learning (DRL). Specifically, we formulate a decentralized DRL-based decision making framework from the perspective of every follower, where a collision avoidance mechanism is integrated into the flocking controller. Then, we propose a novel reinforcement learning algorithm PS-CACER for training a shared control policy for all the followers. Besides, we design a plug-n-play embedding module based on convolutional neural networks and the attention mechanism. As a result, the variable-length system state can be encoded into a fixed-length embedding vector, which makes the learned DRL policy independent with the number and the order of followers. Finally, numerical simulation results demonstrate the effectiveness of the proposed method, and the learned policies can be directly transferred to semi-physical simulation without any parameter finetuning.",
        "published": "2021-01-20T11:23:35Z",
        "link": "http://arxiv.org/abs/2101.08074v2",
        "categories": [
            "eess.SY",
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "A generalized ride-matching approach for sustainable shared mobility",
        "authors": [
            "Seyed Mehdi Meshkani",
            "Bilal Farooq"
        ],
        "summary": "On-demand shared mobility is a promising and sustainable transportation approach that can mitigate vehicle externalities, such as traffic congestion and emission. On-demand shared mobility systems require matching of one (one-to-one) or multiple riders (many-to-one) to a vehicle based on real-time information. We propose a novel Graph-based Many-to-One ride-Matching (GMOMatch) algorithm for the dynamic many-to-one matching problem in the presence of traffic congestion. GMOMatch, which is an iterative two-step method, provides high service quality and is efficient in terms of computational complexity. It starts with a one-to-one matching in Step 1 and is followed by solving a maximum weight matching problem in Step 2 to combine the travel requests. To evaluate the performance, it is compared with a ride-matching algorithm developed by Simonetto et al. (2019). Both algorithms are implemented in a micro-traffic simulator to assess their performance and their impact on traffic congestion in Downtown, Toronto road network. In comparison to the Simonetto, GMOMatch improved the service rate, vehicle kilometer traveled and traffic travel time by 32%, 16.07%, and 4%, respectively. The sensitivity analysis indicated that utilizing vehicles with a capacity of 10 can achieve 25% service rate improvement compared to a capacity of 4.",
        "published": "2021-01-21T15:02:36Z",
        "link": "http://arxiv.org/abs/2101.08657v3",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Estimating $α$-Rank by Maximizing Information Gain",
        "authors": [
            "Tabish Rashid",
            "Cheng Zhang",
            "Kamil Ciosek"
        ],
        "summary": "Game theory has been increasingly applied in settings where the game is not known outright, but has to be estimated by sampling. For example, meta-games that arise in multi-agent evaluation can only be accessed by running a succession of expensive experiments that may involve simultaneous deployment of several agents. In this paper, we focus on $\\alpha$-rank, a popular game-theoretic solution concept designed to perform well in such scenarios. We aim to estimate the $\\alpha$-rank of the game using as few samples as possible. Our algorithm maximizes information gain between an epistemic belief over the $\\alpha$-ranks and the observed payoff. This approach has two main benefits. First, it allows us to focus our sampling on the entries that matter the most for identifying the $\\alpha$-rank. Second, the Bayesian formulation provides a facility to build in modeling assumptions by using a prior over game payoffs. We show the benefits of using information gain as compared to the confidence interval criterion of ResponseGraphUCB (Rowland et al. 2019), and provide theoretical results justifying our method.",
        "published": "2021-01-22T15:46:35Z",
        "link": "http://arxiv.org/abs/2101.09178v1",
        "categories": [
            "cs.MA",
            "cs.LG"
        ]
    },
    {
        "title": "A Survey of Requirements for COVID-19 Mitigation Strategies. Part II:   Elicitation of Requirements",
        "authors": [
            "Wojciech Jamroga"
        ],
        "summary": "The COVID-19 pandemic has influenced virtually all aspects of our lives. Across the world, countries have applied various mitigation strategies, based on social, political, and technological instruments. We postulate that multi-agent systems can provide a common platform to study (and balance) their essential properties. We also show how to obtain a comprehensive list of the properties by \"distilling\" them from media snippets. Finally, we present a preliminary take on their formal specification, using ideas from multi-agent logics.",
        "published": "2021-01-22T17:52:20Z",
        "link": "http://arxiv.org/abs/2101.09241v2",
        "categories": [
            "cs.CY",
            "cs.MA"
        ]
    },
    {
        "title": "Mean-field Approximations for Stochastic Population Processes with   Heterogeneous Interactions",
        "authors": [
            "Anirudh Sridhar",
            "Soummya Kar"
        ],
        "summary": "This paper studies a general class of stochastic population processes in which agents interact with one another over a network. Agents update their behaviors in a random and decentralized manner according to a policy that depends only on the agent's current state and an estimate of the macroscopic population state, given by a weighted average of the neighboring states. When the number of agents is large and the network is a complete graph (has all-to-all information access), the macroscopic behavior of the population can be well-approximated by a set of deterministic differential equations called a {\\it mean-field approximation}. For incomplete networks such characterizations remained previously unclear, i.e., in general whether a suitable mean-field approximation exists for the macroscopic behavior of the population. The paper addresses this gap by establishing a generic theory describing when various mean-field approximations are accurate for \\emph{arbitrary} interaction structures.   Our results are threefold. Letting $W$ be the matrix describing agent interactions, we first show that a simple mean-field approximation that incorrectly assumes a homogeneous interaction structure is accurate provided $W$ has a large spectral gap. Second, we show that a more complex mean-field approximation which takes into account agent interactions is accurate as long as the Frobenius norm of $W$ is small. Finally, we compare the predictions of the two mean-field approximations through simulations, highlighting cases where using mean-field approximations that assume a homogeneous interaction structure can lead to inaccurate qualitative and quantitative predictions.",
        "published": "2021-01-24T04:18:53Z",
        "link": "http://arxiv.org/abs/2101.09644v6",
        "categories": [
            "math.PR",
            "cs.MA",
            "cs.SI"
        ]
    },
    {
        "title": "Medical Information Retrieval and Interpretation: A Question-Answer   based Interaction Model",
        "authors": [
            "Nilanjan Sinhababu",
            "Rahul Saxena",
            "Monalisa Sarma",
            "Debasis Samanta"
        ],
        "summary": "The Internet has become a very powerful platform where diverse medical information are expressed daily. Recently, a huge growth is seen in searches like symptoms, diseases, medicines, and many other health related queries around the globe. The search engines typically populate the result by using the single query provided by the user and hence reaching to the final result may require a lot of manual filtering from the user's end. Current search engines and recommendation systems still lack real time interactions that may provide more precise result generation. This paper proposes an intelligent and interactive system tied up with the vast medical big data repository on the web and illustrates its potential in finding medical information.",
        "published": "2021-01-24T07:01:06Z",
        "link": "http://arxiv.org/abs/2101.09662v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.IR"
        ]
    },
    {
        "title": "Improving Continuous-time Conflict Based Search",
        "authors": [
            "Anton Andreychuk",
            "Konstantin Yakovlev",
            "Eli Boyarski",
            "Roni Stern"
        ],
        "summary": "Conflict-Based Search (CBS) is a powerful algorithmic framework for optimally solving classical multi-agent path finding (MAPF) problems, where time is discretized into the time steps. Continuous-time CBS (CCBS) is a recently proposed version of CBS that guarantees optimal solutions without the need to discretize time. However, the scalability of CCBS is limited because it does not include any known improvements of CBS. In this paper, we begin to close this gap and explore how to adapt successful CBS improvements, namely, prioritizing conflicts (PC), disjoint splitting (DS), and high-level heuristics, to the continuous time setting of CCBS. These adaptions are not trivial, and require careful handling of different types of constraints, applying a generalized version of the Safe interval path planning (SIPP) algorithm, and extending the notion of cardinal conflicts. We evaluate the effect of the suggested enhancements by running experiments both on general graphs and $2^k$-neighborhood grids. CCBS with these improvements significantly outperforms vanilla CCBS, solving problems with almost twice as many agents in some cases and pushing the limits of multiagent path finding in continuous-time domains.",
        "published": "2021-01-24T14:34:25Z",
        "link": "http://arxiv.org/abs/2101.09723v2",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Population and Inequality Dynamics in Simple Economies",
        "authors": [
            "John C. Stevenson"
        ],
        "summary": "While the use of spatial agent-based and individual-based models has flourished across many scientific disciplines, the complexities these models generate are often difficult to manage and quantify. This research reduces population-driven, spatial modeling of individuals to the simplest configurations and parameters: an equal resource opportunity landscape with equally capable individuals; and asks the question, \"Will valid complex population and inequality dynamics emerge from this simple economic model?\" Two foraging economies are modeled: subsistence and surplus. The resulting, emergent population dynamics are characterized by their sensitivities to agent and landscape parameters. The various steady and oscillating regimes of single-species population dynamics are generated by appropriate selection of model growth parameters. These emergent dynamics are shown to be consistent with the equation-based, continuum modeling of single-species populations in biology and ecology. The intrinsic growth rates, carry capacities, and delay parameters of these models are implied for these simple economies. Aggregate measures of individual distributions are used to understand the sensitivities to model parameters. New local measures are defined to describe complex behaviors driven by spatial effects, especially extinctions. This simple economic model is shown to generate significantly complex population and inequality dynamics. Model parameters generating the intrinsic growth rate have strong effects on these dynamics, including large variations in inequality. Significant inequality effects are shown to be caused by birth costs above and beyond their contribution to the intrinsic growth rate. The highest levels of inequality are found during the initial non-equilibrium period and are driven by factors different than those driving steady state inequality.",
        "published": "2021-01-24T22:45:25Z",
        "link": "http://arxiv.org/abs/2101.09817v2",
        "categories": [
            "physics.soc-ph",
            "cs.MA",
            "econ.GN",
            "q-fin.EC"
        ]
    },
    {
        "title": "Alternating Direction Method of Multipliers-Based Parallel Optimization   for Multi-Agent Collision-Free Model Predictive Control",
        "authors": [
            "Zilong Cheng",
            "Jun Ma",
            "Wenxin Wang",
            "Zicheng Zhu",
            "Clarence W. de Silva",
            "Tong Heng Lee"
        ],
        "summary": "This paper investigates the collision-free control problem for multi-agent systems. For such multi-agent systems, it is the typical situation where conventional methods using either the usual centralized model predictive control (MPC), or even the distributed counterpart, would suffer from substantial difficulty in balancing optimality and computational efficiency. Additionally, the non-convex characteristics that invariably arise in such collision-free control and optimization problems render it difficult to effectively derive a reliable solution (and also to thoroughly analyze the associated convergence properties). To overcome these challenging issues, this work establishes a suitably novel parallel computation framework through an innovative mathematical problem formulation; and then with this framework and formulation, a parallel algorithm based on alternating direction method of multipliers (ADMM) is presented to solve the sub-problems arising from the resulting parallel structure. Furthermore, an efficient and intuitive initialization procedure is developed to accelerate the optimization process, and the optimum is thus determined with significantly improved computational efficiency. As supported by rigorous proofs, the convergence of the proposed ADMM iterations for this non-convex optimization problem is analyzed and discussed in detail. Finally, a simulation with a group of unmanned aerial vehicles (UAVs) serves as an illustrative example here to demonstrate the effectiveness and efficiency of the proposed approach. Also, the simulation results verify significant improvements in accuracy and computational efficiency compared to other baselines, including primal quadratic mixed integer programming (PQ-MIP), non-convex quadratic mixed integer programming (NC-MIP), and non-convex quadratically constrained quadratic programming (NC-QCQP).",
        "published": "2021-01-25T04:54:01Z",
        "link": "http://arxiv.org/abs/2101.09894v2",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "math.OC"
        ]
    },
    {
        "title": "Agents.jl: A performant and feature-full agent based modelling software   of minimal code complexity",
        "authors": [
            "George Datseris",
            "Ali R. Vahdati",
            "Timothy C. DuBois"
        ],
        "summary": "Agent based modelling is a simulation method in which autonomous agents interact with their environment and one another, given a predefined set of rules. It is an integral method for modelling and simulating complex systems, such as socio-economic problems. Since agent based models are not described by simple and concise mathematical equations, code that generates them is typically complicated, large, and slow. Here we present Agents.jl, a Julia-based software that provides an ABM analysis platform with minimal code complexity. We compare our software with some of the most popular ABM software in other programming languages. We find that Agents.jl is not only the most performant, but also the least complicated software, providing the same (and sometimes more) features as the competitors with less input required from the user. Agents.jl also integrates excellently with the entire Julia ecosystem, including interactive applications, differential equations, parameter optimization, and more. This removes any ``extensions library'' requirement from Agents.jl, which is paramount in many other tools.",
        "published": "2021-01-25T13:36:28Z",
        "link": "http://arxiv.org/abs/2101.10072v3",
        "categories": [
            "cs.MA",
            "nlin.CG"
        ]
    },
    {
        "title": "Emergent Communication under Competition",
        "authors": [
            "Michael Noukhovitch",
            "Travis LaCroix",
            "Angeliki Lazaridou",
            "Aaron Courville"
        ],
        "summary": "The literature in modern machine learning has only negative results for learning to communicate between competitive agents using standard RL. We introduce a modified sender-receiver game to study the spectrum of partially-competitive scenarios and show communication can indeed emerge in a competitive setting. We empirically demonstrate three key takeaways for future research. First, we show that communication is proportional to cooperation, and it can occur for partially competitive scenarios using standard learning algorithms. Second, we highlight the difference between communication and manipulation and extend previous metrics of communication to the competitive case. Third, we investigate the negotiation game where previous work failed to learn communication between independent agents (Cao et al., 2018). We show that, in this setting, both agents must benefit from communication for it to emerge; and, with a slight modification to the game, we demonstrate successful communication between competitive agents. We hope this work overturns misconceptions and inspires more research in competitive emergent communication.",
        "published": "2021-01-25T17:58:22Z",
        "link": "http://arxiv.org/abs/2101.10276v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Accumulating Risk Capital Through Investing in Cooperation",
        "authors": [
            "Charlotte Roman",
            "Michael Dennis",
            "Andrew Critch",
            "Stuart Russell"
        ],
        "summary": "Recent work on promoting cooperation in multi-agent learning has resulted in many methods which successfully promote cooperation at the cost of becoming more vulnerable to exploitation by malicious actors. We show that this is an unavoidable trade-off and propose an objective which balances these concerns, promoting both safety and long-term cooperation. Moreover, the trade-off between safety and cooperation is not severe, and you can receive exponentially large returns through cooperation from a small amount of risk. We study both an exact solution method and propose a method for training policies that targets this objective, Accumulating Risk Capital Through Investing in Cooperation (ARCTIC), and evaluate them in iterated Prisoner's Dilemma and Stag Hunt.",
        "published": "2021-01-25T18:41:45Z",
        "link": "http://arxiv.org/abs/2101.10305v2",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Transparency in Multi-Human Multi-Robot Interaction",
        "authors": [
            "Jayam Patel",
            "Tyagaraja Ramaswamy",
            "Zhi Li",
            "Carlo Pinciroli"
        ],
        "summary": "Transparency is a key factor in improving the performance of human-robot interaction. A transparent interface allows humans to be aware of the state of a robot and to assess the progress of the tasks at hand. When multi-robot systems are involved, transparency is an even greater challenge, due to the larger number of variables affecting the behavior of the robots as a whole. Significant effort has been devoted to studying transparency when single operators interact with multiple robots. However, studies on transparency that focus on multiple human operators interacting with a multi-robot systems are limited. This paper aims to fill this gap by presenting a human-swarm interaction interface with graphical elements that can be enabled and disabled. Through this interface, we study which graphical elements are contribute to transparency by comparing four \"transparency modes\": (i) no transparency (no operator receives information from the robots), (ii) central transparency (the operators receive information only relevant to their personal task), (iii) peripheral transparency (the operators share information on each others' tasks), and (iv) mixed transparency (both central and peripheral). We report the results in terms of awareness, trust, and workload of a user study involving 18 participants engaged in a complex multi-robot task.",
        "published": "2021-01-26T00:13:58Z",
        "link": "http://arxiv.org/abs/2101.10495v2",
        "categories": [
            "cs.RO",
            "cs.HC",
            "cs.MA"
        ]
    },
    {
        "title": "No-harm principle, rationality, and Pareto optimality in games",
        "authors": [
            "Shaun Hargreaves Heap",
            "Mehmet S. Ismail"
        ],
        "summary": "Mill's classic argument for liberty requires that people's exercise of freedom should be governed by a no-harm principle (NHP). In this paper, we develop the concept of a no-harm equilibrium in $n$-person games where players maximize utility subject to the constraint of the NHP. Our main result is in the spirit of the fundamental theorems of welfare economics. We show that for every initial `reference point' in a game the associated no-harm equilibrium is Pareto efficient and, conversely, every Pareto efficient point can be supported as a no-harm equilibrium for some initial reference point.",
        "published": "2021-01-26T11:34:51Z",
        "link": "http://arxiv.org/abs/2101.10723v4",
        "categories": [
            "econ.TH",
            "cs.MA",
            "91A18, 91A10"
        ]
    },
    {
        "title": "Non-Monotone Energy-Aware Information Gathering for Heterogeneous Robot   Teams",
        "authors": [
            "Xiaoyi Cai",
            "Brent Schlotfeldt",
            "Kasra Khosoussi",
            "Nikolay Atanasov",
            "George J. Pappas",
            "Jonathan P. How"
        ],
        "summary": "This paper considers the problem of planning trajectories for a team of sensor-equipped robots to reduce uncertainty about a dynamical process. Optimizing the trade-off between information gain and energy cost (e.g., control effort, distance travelled) is desirable but leads to a non-monotone objective function in the set of robot trajectories. Therefore, common multi-robot planning algorithms based on techniques such as coordinate descent lose their performance guarantees. Methods based on local search provide performance guarantees for optimizing a non-monotone submodular function, but require access to all robots' trajectories, making it not suitable for distributed execution. This work proposes a distributed planning approach based on local search and shows how lazy/greedy methods can be adopted to reduce the computation and communication of the approach. We demonstrate the efficacy of the proposed method by coordinating robot teams composed of both ground and aerial vehicles with different sensing/control profiles and evaluate the algorithm's performance in two target tracking scenarios. Compared to the naive distributed execution of local search, our approach saves up to 60% communication and 80--92% computation on average when coordinating up to 10 robots, while outperforming the coordinate descent based algorithm in achieving a desirable trade-off between sensing and energy cost.",
        "published": "2021-01-26T21:38:55Z",
        "link": "http://arxiv.org/abs/2101.11093v2",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Exact and Approximate Heterogeneous Bayesian Decentralized Data Fusion",
        "authors": [
            "Ofer Dagan",
            "Nisar R. Ahmed"
        ],
        "summary": "In Bayesian peer-to-peer decentralized data fusion, the underlying distributions held locally by autonomous agents are frequently assumed to be over the same set of variables (homogeneous). This requires each agent to process and communicate the full global joint distribution, and thus leads to high computation and communication costs irrespective of relevancy to specific local objectives. This work formulates and studies heterogeneous decentralized fusion problems, defined as the set of problems in which either the communicated or the processed distributions describe different, but overlapping, random states of interest that are subsets of a larger full global joint state. We exploit the conditional independence structure of such problems and provide a rigorous derivation of novel exact and approximate conditionally factorized heterogeneous fusion rules. We further develop a new version of the homogeneous Channel Filter algorithm to enable conservative heterogeneous fusion for smoothing and filtering scenarios in dynamic problems. Numerical examples show more than $99.5\\%$ potential communication reduction for heterogeneous channel filter fusion, and a multi-target tracking simulation shows that these methods provide consistent estimates while remaining computationally scalable.",
        "published": "2021-01-26T22:26:05Z",
        "link": "http://arxiv.org/abs/2101.11116v4",
        "categories": [
            "cs.RO",
            "cs.MA",
            "cs.SY",
            "eess.SP",
            "eess.SY"
        ]
    },
    {
        "title": "Multi-agent simulation of voter's behaviour",
        "authors": [
            "Albin Soutif",
            "Carole Adam",
            "Sylvain Bouveret"
        ],
        "summary": "The goal of this paper is to simulate the voters behaviour given a voting method. Our approach uses a multi-agent simulation in order to model a voting process through many iterations, so that the voters can vote by taking into account the results of polls. Here we only tried basic rules and a single voting method, but further attempts could explore new features.",
        "published": "2021-01-27T16:48:03Z",
        "link": "http://arxiv.org/abs/2101.11538v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.CY"
        ]
    },
    {
        "title": "Modelling the Impact of Scandals: the case of the 2017 French   Presidential Election",
        "authors": [
            "Yassine Bouachrine",
            "Carole Adam"
        ],
        "summary": "This paper proposes an agent-based simulation of a presidential election, inspired by the French 2017 presidential election. The simulation is based on data extracted from polls, media coverage, and Twitter. The main contribution is to consider the impact of scandals and media bashing on the result of the election. In particular, it is shown that scandals can lead to higher abstention at the election, as voters have no relevant candidate left to vote for. The simulation is implemented in Unity 3D and is available to play online.",
        "published": "2021-01-27T17:08:38Z",
        "link": "http://arxiv.org/abs/2101.11548v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.CY"
        ]
    },
    {
        "title": "Agent Based Virus Model using NetLogo: Infection Propagation,   Precaution, Recovery, Multi-site Mobility and (Un)Lockdown",
        "authors": [
            "Dibakar Das"
        ],
        "summary": "This paper presents a novel virus propagation model using NetLogo. The model allows agents to move across multiple sites using different routes. Routes can be configured, enabled for mobility and (un)locked down independently. Similarly, locations can also be (un)locked down independently. Agents can get infected, propagate their infections to others, can take precautions against infection and also subsequently recover from infection. This model contains certain features that are not present in existing models. The model may be used for educational and research purposes, and the code is made available as open source. This model may also provide a broader framework for more detailed simulations. The results presented are only to demonstrate the model functionalities and do not serve any other purpose.",
        "published": "2021-01-28T10:20:13Z",
        "link": "http://arxiv.org/abs/2102.00844v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Exploring the Impact of Tunable Agents in Sequential Social Dilemmas",
        "authors": [
            "David O'Callaghan",
            "Patrick Mannion"
        ],
        "summary": "When developing reinforcement learning agents, the standard approach is to train an agent to converge to a fixed policy that is as close to optimal as possible for a single fixed reward function. If different agent behaviour is required in the future, an agent trained in this way must normally be either fully or partially retrained, wasting valuable time and resources. In this study, we leverage multi-objective reinforcement learning to create tunable agents, i.e. agents that can adopt a range of different behaviours according to the designer's preferences, without the need for retraining. We apply this technique to sequential social dilemmas, settings where there is inherent tension between individual and collective rationality. Learning a single fixed policy in such settings leaves one at a significant disadvantage if the opponents' strategies change after learning is complete. In our work, we demonstrate empirically that the tunable agents framework allows easy adaption between cooperative and competitive behaviours in sequential social dilemmas without the need for retraining, allowing a single trained agent model to be adjusted to cater for a wide range of behaviours and opponent strategies.",
        "published": "2021-01-28T12:44:31Z",
        "link": "http://arxiv.org/abs/2101.11967v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Federated Multi-Armed Bandits",
        "authors": [
            "Chengshuai Shi",
            "Cong Shen"
        ],
        "summary": "Federated multi-armed bandits (FMAB) is a new bandit paradigm that parallels the federated learning (FL) framework in supervised learning. It is inspired by practical applications in cognitive radio and recommender systems, and enjoys features that are analogous to FL. This paper proposes a general framework of FMAB and then studies two specific federated bandit models. We first study the approximate model where the heterogeneous local models are random realizations of the global model from an unknown distribution. This model introduces a new uncertainty of client sampling, as the global model may not be reliably learned even if the finite local models are perfectly known. Furthermore, this uncertainty cannot be quantified a priori without knowledge of the suboptimality gap. We solve the approximate model by proposing Federated Double UCB (Fed2-UCB), which constructs a novel \"double UCB\" principle accounting for uncertainties from both arm and client sampling. We show that gradually admitting new clients is critical in achieving an O(log(T)) regret while explicitly considering the communication cost. The exact model, where the global bandit model is the exact average of heterogeneous local models, is then studied as a special case. We show that, somewhat surprisingly, the order-optimal regret can be achieved independent of the number of clients with a careful choice of the update periodicity. Experiments using both synthetic and real-world datasets corroborate the theoretical analysis and demonstrate the effectiveness and efficiency of the proposed algorithms.",
        "published": "2021-01-28T18:59:19Z",
        "link": "http://arxiv.org/abs/2101.12204v2",
        "categories": [
            "cs.LG",
            "cs.IT",
            "cs.MA",
            "math.IT",
            "stat.ML"
        ]
    },
    {
        "title": "CoordiQ : Coordinated Q-learning for Electric Vehicle Charging   Recommendation",
        "authors": [
            "Carter Blum",
            "Hao Liu",
            "Hui Xiong"
        ],
        "summary": "Electric vehicles have been rapidly increasing in usage, but stations to charge them have not always kept up with demand, so efficient routing of vehicles to stations is critical to operating at maximum efficiency. Deciding which stations to recommend drivers to is a complex problem with a multitude of possible recommendations, volatile usage patterns and temporally extended consequences of recommendations. Reinforcement learning offers a powerful paradigm for solving sequential decision-making problems, but traditional methods may struggle with sample efficiency due to the high number of possible actions. By developing a model that allows complex representations of actions, we improve outcomes for users of our system by over 30% when compared to existing baselines in a simulation. If implemented widely, these better recommendations can globally save over 4 million person-hours of waiting and driving each year.",
        "published": "2021-01-28T21:25:33Z",
        "link": "http://arxiv.org/abs/2102.00847v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Strong coupling between scales in a multi-scalar model of urban dynamics",
        "authors": [
            "Juste Raimbault"
        ],
        "summary": "Urban evolution processes occur at different scales, with intricate interactions between levels and relatively distinct type of processes. To what extent actual urban dynamics include an actual strong coupling between scales, in the sense of both top-down and bottom-up feedbacks, remains an open issue with important practical implications for the sustainable management of territories. We introduce in this paper a multi-scalar simulation model of urban growth, coupling a system of cities interaction model at the macroscopic scale with morphogenesis models for the evolution of urban form at the scale of metropolitan areas. Strong coupling between scales is achieved through an update of model parameters at each scale depending on trajectories at the other scale. The model is applied and explored on synthetic systems of cities. Simulation results show a non-trivial effect of the strong coupling. As a consequence, an optimal action on policy parameters such as containing urban sprawl is shifted. We also run a multi-objective optimization algorithm on the model, showing showing that compromise between scales are captured. Our approach opens new research directions towards more operational urban dynamics models including a strong feedback between scales.",
        "published": "2021-01-29T18:37:44Z",
        "link": "http://arxiv.org/abs/2101.12725v1",
        "categories": [
            "physics.soc-ph",
            "cs.CY",
            "cs.MA"
        ]
    },
    {
        "title": "Poincaré-Bendixson Limit Sets in Multi-Agent Learning",
        "authors": [
            "Aleksander Czechowski",
            "Georgios Piliouras"
        ],
        "summary": "A key challenge of evolutionary game theory and multi-agent learning is to characterize the limit behavior of game dynamics. Whereas convergence is often a property of learning algorithms in games satisfying a particular reward structure (e.g., zero-sum games), even basic learning models, such as the replicator dynamics, are not guaranteed to converge for general payoffs. Worse yet, chaotic behavior is possible even in rather simple games, such as variants of the Rock-Paper-Scissors game. Although chaotic behavior in learning dynamics can be precluded by the celebrated Poincar\\'e-Bendixson theorem, it is only applicable to low-dimensional settings. Are there other characteristics of a game that can force regularity in the limit sets of learning? We show that behavior consistent with the Poincar\\'e-Bendixson theorem (limit cycles, but no chaotic attractor) can follow purely from the topological structure of the interaction graph, even for high-dimensional settings with an arbitrary number of players and arbitrary payoff matrices. We prove our result for a wide class of follow-the-regularized leader (FoReL) dynamics, which generalize replicator dynamics, for binary games characterized interaction graphs where the payoffs of each player are only affected by one other player (i.e., interaction graphs of indegree one). Since chaos occurs already in games with only two players and three strategies, this class of non-chaotic games may be considered maximal. Moreover, we provide simple conditions under which such behavior translates into efficiency guarantees, implying that FoReL learning achieves time-averaged sum of payoffs at least as good as that of a Nash equilibrium, thereby connecting the topology of the dynamics to social-welfare analysis.",
        "published": "2021-01-29T20:32:25Z",
        "link": "http://arxiv.org/abs/2102.00053v2",
        "categories": [
            "cs.GT",
            "cs.MA",
            "91A22, 91A26"
        ]
    },
    {
        "title": "SCAN: A Spatial Context Attentive Network for Joint Multi-Agent Intent   Prediction",
        "authors": [
            "Jasmine Sekhon",
            "Cody Fleming"
        ],
        "summary": "Safe navigation of autonomous agents in human centric environments requires the ability to understand and predict motion of neighboring pedestrians. However, predicting pedestrian intent is a complex problem. Pedestrian motion is governed by complex social navigation norms, is dependent on neighbors' trajectories, and is multimodal in nature. In this work, we propose SCAN, a Spatial Context Attentive Network that can jointly predict socially-acceptable multiple future trajectories for all pedestrians in a scene. SCAN encodes the influence of spatially close neighbors using a novel spatial attention mechanism in a manner that relies on fewer assumptions, is parameter efficient, and is more interpretable compared to state-of-the-art spatial attention approaches. Through experiments on several datasets we demonstrate that our approach can also quantitatively outperform state of the art trajectory prediction methods in terms of accuracy of predicted intent.",
        "published": "2021-01-29T23:35:00Z",
        "link": "http://arxiv.org/abs/2102.00109v2",
        "categories": [
            "cs.CV",
            "cs.MA"
        ]
    },
    {
        "title": "Multi-Agent Reinforcement Learning with Temporal Logic Specifications",
        "authors": [
            "Lewis Hammond",
            "Alessandro Abate",
            "Julian Gutierrez",
            "Michael Wooldridge"
        ],
        "summary": "In this paper, we study the problem of learning to satisfy temporal logic specifications with a group of agents in an unknown environment, which may exhibit probabilistic behaviour. From a learning perspective these specifications provide a rich formal language with which to capture tasks or objectives, while from a logic and automated verification perspective the introduction of learning capabilities allows for practical applications in large, stochastic, unknown environments. The existing work in this area is, however, limited. Of the frameworks that consider full linear temporal logic or have correctness guarantees, all methods thus far consider only the case of a single temporal logic specification and a single agent. In order to overcome this limitation, we develop the first multi-agent reinforcement learning technique for temporal logic specifications, which is also novel in its ability to handle multiple specifications. We provide correctness and convergence guarantees for our main algorithm - ALMANAC (Automaton/Logic Multi-Agent Natural Actor-Critic) - even when using function approximation. Alongside our theoretical results, we further demonstrate the applicability of our technique via a set of preliminary experiments.",
        "published": "2021-02-01T01:13:03Z",
        "link": "http://arxiv.org/abs/2102.00582v2",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.LO",
            "cs.MA"
        ]
    },
    {
        "title": "Hybrid Information-driven Multi-agent Reinforcement Learning",
        "authors": [
            "William A. Dawson",
            "Ruben Glatt",
            "Edward Rusu",
            "Braden C. Soper",
            "Ryan A. Goldhahn"
        ],
        "summary": "Information theoretic sensor management approaches are an ideal solution to state estimation problems when considering the optimal control of multi-agent systems, however they are too computationally intensive for large state spaces, especially when considering the limited computational resources typical of large-scale distributed multi-agent systems. Reinforcement learning (RL) is a promising alternative which can find approximate solutions to distributed optimal control problems that take into account the resource constraints inherent in many systems of distributed agents. However, the RL training can be prohibitively inefficient, especially in low-information environments where agents receive little to no feedback in large portions of the state space. We propose a hybrid information-driven multi-agent reinforcement learning (MARL) approach that utilizes information theoretic models as heuristics to help the agents navigate large sparse state spaces, coupled with information based rewards in an RL framework to learn higher-level policies. This paper presents our ongoing work towards this objective. Our preliminary findings show that such an approach can result in a system of agents that are approximately three orders of magnitude more efficient at exploring a sparse state space than naive baseline metrics. While the work is still in its early stages, it provides a promising direction for future research.",
        "published": "2021-02-01T17:28:39Z",
        "link": "http://arxiv.org/abs/2102.01004v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.IT",
            "math.IT"
        ]
    },
    {
        "title": "An Abstraction-based Method to Check Multi-Agent Deep   Reinforcement-Learning Behaviors",
        "authors": [
            "Pierre El Mqirmi",
            "Francesco Belardinelli",
            "Borja G. León"
        ],
        "summary": "Multi-agent reinforcement learning (RL) often struggles to ensure the safe behaviours of the learning agents, and therefore it is generally not adapted to safety-critical applications. To address this issue, we present a methodology that combines formal verification with (deep) RL algorithms to guarantee the satisfaction of formally-specified safety constraints both in training and testing. The approach we propose expresses the constraints to verify in Probabilistic Computation Tree Logic (PCTL) and builds an abstract representation of the system to reduce the complexity of the verification step. This abstract model allows for model checking techniques to identify a set of abstract policies that meet the safety constraints expressed in PCTL. Then, the agents' behaviours are restricted according to these safe abstract policies. We provide formal guarantees that by using this method, the actions of the agents always meet the safety constraints, and provide a procedure to generate an abstract model automatically. We empirically evaluate and show the effectiveness of our method in a multi-agent environment.",
        "published": "2021-02-02T11:12:30Z",
        "link": "http://arxiv.org/abs/2102.01434v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Approximately Solving Mean Field Games via Entropy-Regularized Deep   Reinforcement Learning",
        "authors": [
            "Kai Cui",
            "Heinz Koeppl"
        ],
        "summary": "The recent mean field game (MFG) formalism facilitates otherwise intractable computation of approximate Nash equilibria in many-agent settings. In this paper, we consider discrete-time finite MFGs subject to finite-horizon objectives. We show that all discrete-time finite MFGs with non-constant fixed point operators fail to be contractive as typically assumed in existing MFG literature, barring convergence via fixed point iteration. Instead, we incorporate entropy-regularization and Boltzmann policies into the fixed point iteration. As a result, we obtain provable convergence to approximate fixed points where existing methods fail, and reach the original goal of approximate Nash equilibria. All proposed methods are evaluated with respect to their exploitability, on both instructive examples with tractable exact solutions and high-dimensional problems where exact methods become intractable. In high-dimensional scenarios, we apply established deep reinforcement learning methods and empirically combine fictitious play with our approximations.",
        "published": "2021-02-02T16:22:07Z",
        "link": "http://arxiv.org/abs/2102.01585v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Convergence Voting: From Pairwise Comparisons to Consensus",
        "authors": [
            "Gergei Bana",
            "Wojciech Jamroga",
            "David Naccache",
            "Peter Y. A. Ryan"
        ],
        "summary": "An important aspect of AI design and ethics is to create systems that reflect aggregate preferences of the society. To this end, the techniques of social choice theory are often utilized. We propose a new social choice function motivated by the PageRank algorithm. The function ranks voting options based on the Condorcet graph of pairwise comparisons. To this end, we transform the Condorcet graph into a Markov chain whose stationary distribution provides the scores of the options. We show how the values in the stationary distribution can be interpreted as quantified aggregate support for the voting options, to which the community of voters converges through an imaginary sequence of negotiating steps. Because of that, we suggest the name \"convergence voting\" for the new voting scheme, and \"negotiated community support\" for the resulting stationary allocation of scores.   Our social choice function can be viewed as a consensus voting method, sitting somewhere between Copeland and Borda. On the one hand, it does not necessarily choose the Condorcet winner, as strong support from a part of the society can outweigh mediocre uniform support. On the other hand, the influence of unpopular candidates on the outcome is smaller than in the primary technique of consensus voting, i.e., the Borda count. We achieve that without having to introduce an ad hoc weighting that some other methods do.",
        "published": "2021-02-03T10:50:41Z",
        "link": "http://arxiv.org/abs/2102.01995v3",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Multi-UAV Mobile Edge Computing and Path Planning Platform based on   Reinforcement Learning",
        "authors": [
            "Huan Chang",
            "Yicheng Chen",
            "Baochang Zhang",
            "David Doermann"
        ],
        "summary": "Unmanned Aerial vehicles (UAVs) are widely used as network processors in mobile networks, but more recently, UAVs have been used in Mobile Edge Computing as mobile servers. However, there are significant challenges to use UAVs in complex environments with obstacles and cooperation between UAVs. We introduce a new multi-UAV Mobile Edge Computing platform, which aims to provide better Quality-of-Service and path planning based on reinforcement learning to address these issues. The contributions of our work include: 1) optimizing the quality of service for mobile edge computing and path planning in the same reinforcement learning framework; 2) using a sigmoid-like function to depict the terminal users' demand to ensure a higher quality of service; 3) applying synthetic considerations of the terminal users' demand, risk and geometric distance in reinforcement learning reward matrix to ensure the quality of service, risk avoidance, and the cost-savings. Simulations have shown the effectiveness and feasibility of our platform, which can help advance related researches.",
        "published": "2021-02-03T14:22:36Z",
        "link": "http://arxiv.org/abs/2102.02078v3",
        "categories": [
            "cs.MA",
            "cs.LG"
        ]
    },
    {
        "title": "Neural Recursive Belief States in Multi-Agent Reinforcement Learning",
        "authors": [
            "Pol Moreno",
            "Edward Hughes",
            "Kevin R. McKee",
            "Bernardo Avila Pires",
            "Théophane Weber"
        ],
        "summary": "In multi-agent reinforcement learning, the problem of learning to act is particularly difficult because the policies of co-players may be heavily conditioned on information only observed by them. On the other hand, humans readily form beliefs about the knowledge possessed by their peers and leverage beliefs to inform decision-making. Such abilities underlie individual success in a wide range of Markov games, from bluffing in Poker to conditional cooperation in the Prisoner's Dilemma, to convention-building in Bridge. Classical methods are usually not applicable to complex domains due to the intractable nature of hierarchical beliefs (i.e. beliefs of other agents' beliefs). We propose a scalable method to approximate these belief structures using recursive deep generative models, and to use the belief models to obtain representations useful to acting in complex tasks. Our agents trained with belief models outperform model-free baselines with equivalent representational capacity using common training paradigms. We also show that higher-order belief models outperform agents with lower-order models.",
        "published": "2021-02-03T20:10:23Z",
        "link": "http://arxiv.org/abs/2102.02274v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Improved Cooperation by Exploiting a Common Signal",
        "authors": [
            "Panayiotis Danassis",
            "Zeki Doruk Erden",
            "Boi Faltings"
        ],
        "summary": "Can artificial agents benefit from human conventions? Human societies manage to successfully self-organize and resolve the tragedy of the commons in common-pool resources, in spite of the bleak prediction of non-cooperative game theory. On top of that, real-world problems are inherently large-scale and of low observability. One key concept that facilitates human coordination in such settings is the use of conventions. Inspired by human behavior, we investigate the learning dynamics and emergence of temporal conventions, focusing on common-pool resources. Extra emphasis was given in designing a realistic evaluation setting: (a) environment dynamics are modeled on real-world fisheries, (b) we assume decentralized learning, where agents can observe only their own history, and (c) we run large-scale simulations (up to 64 agents).   Uncoupled policies and low observability make cooperation hard to achieve; as the number of agents grow, the probability of taking a correct gradient direction decreases exponentially. By introducing an arbitrary common signal (e.g., date, time, or any periodic set of numbers) as a means to couple the learning process, we show that temporal conventions can emerge and agents reach sustainable harvesting strategies. The introduction of the signal consistently improves the social welfare (by 258% on average, up to 3306%), the range of environmental parameters where sustainability can be achieved (by 46% on average, up to 300%), and the convergence speed in low abundance settings (by 13% on average, up to 53%).",
        "published": "2021-02-03T21:27:53Z",
        "link": "http://arxiv.org/abs/2102.02304v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "On Multi-Human Multi-Robot Remote Interaction: A Study of Transparency,   Inter-Human Communication, and Information Loss in Remote Interaction",
        "authors": [
            "Jayam Patel",
            "Prajankya Sonar",
            "Carlo Pinciroli"
        ],
        "summary": "In this paper, we investigate how to design an effective interface for remote multi-human multi-robot interaction. While significant research exists on interfaces for individual human operators, little research exists for the multi-human case. Yet, this is a critical problem to solve to make complex, large-scale missions achievable in which direct human involvement is impossible or undesirable, and robot swarms act as a semi-autonomous agents. This paper's contribution is twofold. The first contribution is an exploration of the design space of computer-based interfaces for multi-human multi-robot operations. In particular, we focus on information transparency and on the factors that affect inter-human communication in ideal conditions, i.e., without communication issues. Our second contribution concerns the same problem, but considering increasing degrees of information loss, defined as intermittent reception of data with noticeable gaps between individual receipts. We derived a set of design recommendations based on two user studies involving 48 participants.",
        "published": "2021-02-04T00:40:48Z",
        "link": "http://arxiv.org/abs/2102.02351v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Towards Decentralized Human-Swarm Interaction by Means of Sequential   Hand Gesture Recognition",
        "authors": [
            "Zahi Kakish",
            "Sritanay Vedartham",
            "Spring Berman"
        ],
        "summary": "In this work, we present preliminary work on a novel method for Human-Swarm Interaction (HSI) that can be used to change the macroscopic behavior of a swarm of robots with decentralized sensing and control. By integrating a small yet capable hand gesture recognition convolutional neural network (CNN) with the next-generation Robot Operating System \\emph{ros2}, which enables decentralized implementation of robot software for multi-robot applications, we demonstrate the feasibility of programming a swarm of robots to recognize and respond to a sequence of hand gestures that capable of correspond to different types of swarm behaviors. We test our approach using a sequence of gestures that modifies the target inter-robot distance in a group of three Turtlebot3 Burger robots in order to prevent robot collisions with obstacles. The approach is validated in three different Gazebo simulation environments and in a physical testbed that reproduces one of the simulated environments.",
        "published": "2021-02-04T06:43:14Z",
        "link": "http://arxiv.org/abs/2102.02439v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Persistent Rule-based Interactive Reinforcement Learning",
        "authors": [
            "Adam Bignold",
            "Francisco Cruz",
            "Richard Dazeley",
            "Peter Vamplew",
            "Cameron Foale"
        ],
        "summary": "Interactive reinforcement learning has allowed speeding up the learning process in autonomous agents by including a human trainer providing extra information to the agent in real-time. Current interactive reinforcement learning research has been limited to real-time interactions that offer relevant user advice to the current state only. Additionally, the information provided by each interaction is not retained and instead discarded by the agent after a single-use. In this work, we propose a persistent rule-based interactive reinforcement learning approach, i.e., a method for retaining and reusing provided knowledge, allowing trainers to give general advice relevant to more than just the current state. Our experimental results show persistent advice substantially improves the performance of the agent while reducing the number of interactions required for the trainer. Moreover, rule-based advice shows similar performance impact as state-based advice, but with a substantially reduced interaction count.",
        "published": "2021-02-04T06:48:57Z",
        "link": "http://arxiv.org/abs/2102.02441v2",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Aggregating Bipolar Opinions (With Appendix)",
        "authors": [
            "Stefan Lauren",
            "Francesco Belardinelli",
            "Francesca Toni"
        ],
        "summary": "We introduce a novel method to aggregate Bipolar Argumentation (BA) Frameworks expressing opinions by different parties in debates. We use Bipolar Assumption-based Argumentation (ABA) as an all-encompassing formalism for BA under different semantics. By leveraging on recent results on judgement aggregation in Social Choice Theory, we prove several preservation results, both positive and negative, for relevant properties of Bipolar ABA.",
        "published": "2021-02-04T20:43:30Z",
        "link": "http://arxiv.org/abs/2102.02881v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Optimizing Consensus-based Multi-target Tracking with Multiagent Rollout   Control Policies",
        "authors": [
            "Tianqi Li",
            "Lucas W. Krakow",
            "Swaminathan Gopalswamy"
        ],
        "summary": "This paper considers a multiagent, connected, robotic fleet where the primary functionality of the agents is sensing. A distributed multi-sensor control strategy maximizes the value of the collective sensing capability of the fleet, using an information-driven approach. Each agent individually performs sensor processing (Kalman Filtering and Joint Probabilistic Data Association) to identify trajectories (and associated distributions). Using communications with its neighbors the agents enhance the prediction of the trajectories using a Consensus of Information approach that iteratively calculates the Kullback-Leibler average of trajectory distributions, enabling the calculation of the value of the collective information for the fleet. The dynamics of the agents, the evolution of the identified trajectories for each agent, and the dynamics of individual observed objects are captured as a Partially Observable Markov Decision Process (POMDP). Using this POMDP and applying rollout with receding horizon control, an optimized non-myopic control policy that maximizes the collective fleet information value is synthesized. Simulations are performed for a scenario with three heterogeneous UAVs performing coordinated target tracking that illustrate the proposed methodology and compare the centralized approach with a contemporary sequential multiagent distributed decision technique.",
        "published": "2021-02-04T22:34:26Z",
        "link": "http://arxiv.org/abs/2102.02919v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Deceptive Reinforcement Learning for Privacy-Preserving Planning",
        "authors": [
            "Zhengshang Liu",
            "Yue Yang",
            "Tim Miller",
            "Peta Masters"
        ],
        "summary": "In this paper, we study the problem of deceptive reinforcement learning to preserve the privacy of a reward function. Reinforcement learning is the problem of finding a behaviour policy based on rewards received from exploratory behaviour. A key ingredient in reinforcement learning is a reward function, which determines how much reward (negative or positive) is given and when. However, in some situations, we may want to keep a reward function private; that is, to make it difficult for an observer to determine the reward function used. We define the problem of privacy-preserving reinforcement learning, and present two models for solving it. These models are based on dissimulation -- a form of deception that `hides the truth'. We evaluate our models both computationally and via human behavioural experiments. Results show that the resulting policies are indeed deceptive, and that participants can determine the true reward function less reliably than that of an honest agent.",
        "published": "2021-02-05T06:50:04Z",
        "link": "http://arxiv.org/abs/2102.03022v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "baller2vec: A Multi-Entity Transformer For Multi-Agent Spatiotemporal   Modeling",
        "authors": [
            "Michael A. Alcorn",
            "Anh Nguyen"
        ],
        "summary": "Multi-agent spatiotemporal modeling is a challenging task from both an algorithmic design and computational complexity perspective. Recent work has explored the efficacy of traditional deep sequential models in this domain, but these architectures are slow and cumbersome to train, particularly as model size increases. Further, prior attempts to model interactions between agents across time have limitations, such as imposing an order on the agents, or making assumptions about their relationships. In this paper, we introduce baller2vec, a multi-entity generalization of the standard Transformer that can, with minimal assumptions, simultaneously and efficiently integrate information across entities and time. We test the effectiveness of baller2vec for multi-agent spatiotemporal modeling by training it to perform two different basketball-related tasks: (1) simultaneously modeling the trajectories of all players on the court and (2) modeling the trajectory of the ball. Not only does baller2vec learn to perform these tasks well (outperforming a graph recurrent neural network with a similar number of parameters by a wide margin), it also appears to \"understand\" the game of basketball, encoding idiosyncratic qualities of players in its embeddings, and performing basketball-relevant functions with its attention heads.",
        "published": "2021-02-05T17:02:04Z",
        "link": "http://arxiv.org/abs/2102.03291v3",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Massive Self-Assembly in Grid Environments",
        "authors": [
            "Wenjie Chu",
            "Wei Zhang",
            "Haiyan Zhao",
            "Zhi Jin",
            "Hong Mei"
        ],
        "summary": "Self-assembly plays an essential role in many natural processes, involving the formation and evolution of living or non-living structures, and shows potential applications in many emerging domains. In existing research and practice, there still lacks an ideal self-assembly mechanism that manifests efficiency, scalability, and stability at the same time. Inspired by phototaxis observed in nature, we propose a computational approach for massive self-assembly of connected shapes in grid environments. The key component of this approach is an artificial light field superimposed on a grid environment, which is determined by the positions of all agents and at the same time drives all agents to change their positions, forming a dynamic mutual feedback process. This work advances the understanding and potential applications of self-assembly.",
        "published": "2021-02-05T17:37:29Z",
        "link": "http://arxiv.org/abs/2102.05037v2",
        "categories": [
            "cs.MA",
            "cs.DC",
            "cs.RO"
        ]
    },
    {
        "title": "SkillBot: Identifying Risky Content for Children in Alexa Skills",
        "authors": [
            "Tu Le",
            "Danny Yuxing Huang",
            "Noah Apthorpe",
            "Yuan Tian"
        ],
        "summary": "Many households include children who use voice personal assistants (VPA) such as Amazon Alexa. Children benefit from the rich functionalities of VPAs and third-party apps but are also exposed to new risks in the VPA ecosystem. In this paper, we first investigate \"risky\" child-directed voice apps that contain inappropriate content or ask for personal information through voice interactions. We build SkillBot - a natural language processing (NLP)-based system to automatically interact with VPA apps and analyze the resulting conversations. We find 28 risky child-directed apps and maintain a growing dataset of 31,966 non-overlapping app behaviors collected from 3,434 Alexa apps. Our findings suggest that although child-directed VPA apps are subject to stricter policy requirements and more intensive vetting, children remain vulnerable to inappropriate content and privacy violations. We then conduct a user study showing that parents are concerned about the identified risky apps. Many parents do not believe that these apps are available and designed for families/kids, although these apps are actually published in Amazon's \"Kids\" product category. We also find that parents often neglect basic precautions such as enabling parental controls on Alexa devices. Finally, we identify a novel risk in the VPA ecosystem: confounding utterances, or voice commands shared by multiple apps that may cause a user to interact with a different app than intended. We identify 4,487 confounding utterances, including 581 shared by child-directed and non-child-directed apps. We find that 27% of these confounding utterances prioritize invoking a non-child-directed app over a child-directed app. This indicates that children are at real risk of accidentally invoking non-child-directed apps due to confounding utterances.",
        "published": "2021-02-05T19:07:39Z",
        "link": "http://arxiv.org/abs/2102.03382v2",
        "categories": [
            "cs.MA",
            "cs.CL",
            "cs.CR",
            "cs.HC"
        ]
    },
    {
        "title": "Promoting Fair Proposers, Fair Responders or Both? Cost-Efficient   Interference in the Spatial Ultimatum Game",
        "authors": [
            "Theodor Cimpeanu",
            "Cedric Perret",
            "The Anh Han"
        ],
        "summary": "Institutions and investors face the constant challenge of making accurate decisions and predictions regarding how best they should distribute their endowments. The problem of achieving an optimal outcome at minimal cost has been extensively studied and resolved using several heuristics. However, these works usually fail to address how an external party can target different types of fair behaviour or do not take into account how limited information can shape this complex interplay. Here, we consider the well-known Ultimatum game in a spatial setting and propose a hierarchy of interference mechanisms based on the amount of information available to an external decision-maker and desired standards of fairness. Our analysis reveals that monitoring the population at a macroscopic level requires more strict information gathering in order to obtain an optimal outcome and that local observations can mediate this requirement. Moreover, we identify the conditions which must be met for an individual to be eligible for investment in order to avoid unnecessary spending. We further explore the effects of varying mutation or behavioural exploration rates on the choice of investment strategy and total accumulated costs to the investor. Overall, our analysis provides new insights about efficient heuristics for cost-efficient promotion of fairness in societies. Finally, we discuss the differences between our findings and previous work done on the PD and present our suggestions for promoting fairness as an external decision-maker.",
        "published": "2021-02-06T00:44:58Z",
        "link": "http://arxiv.org/abs/2102.03461v1",
        "categories": [
            "cs.MA",
            "cs.GT"
        ]
    },
    {
        "title": "Rethinking the Implementation Tricks and Monotonicity Constraint in   Cooperative Multi-Agent Reinforcement Learning",
        "authors": [
            "Jian Hu",
            "Siyang Jiang",
            "Seth Austin Harding",
            "Haibin Wu",
            "Shih-wei Liao"
        ],
        "summary": "Many complex multi-agent systems such as robot swarms control and autonomous vehicle coordination can be modeled as Multi-Agent Reinforcement Learning (MARL) tasks. QMIX, a widely popular MARL algorithm, has been used as a baseline for the benchmark environments, e.g., Starcraft Multi-Agent Challenge (SMAC), Difficulty-Enhanced Predator-Prey (DEPP). Recent variants of QMIX target relaxing the monotonicity constraint of QMIX, allowing for performance improvement in SMAC. In this paper, we investigate the code-level optimizations of these variants and the monotonicity constraint. (1) We find that such improvements of the variants are significantly affected by various code-level optimizations. (2) The experiment results show that QMIX with normalized optimizations outperforms other works in SMAC; (3) beyond the common wisdom from these works, the monotonicity constraint can improve sample efficiency in SMAC and DEPP. We also discuss why monotonicity constraints work well in purely cooperative tasks with a theoretical analysis. We open-source the code at \\url{https://github.com/hijkzzz/pymarl2}.",
        "published": "2021-02-06T02:28:09Z",
        "link": "http://arxiv.org/abs/2102.03479v19",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Multi-Agent Deep Reinforcement Learning for Request Dispatching in   Distributed-Controller Software-Defined Networking",
        "authors": [
            "Victoria Huang",
            "Gang Chen",
            "Qiang Fu"
        ],
        "summary": "Recently, distributed controller architectures have been quickly gaining popularity in Software-Defined Networking (SDN). However, the use of distributed controllers introduces a new and important Request Dispatching (RD) problem with the goal for every SDN switch to properly dispatch their requests among all controllers so as to optimize network performance. This goal can be fulfilled by designing an RD policy to guide distribution of requests at each switch. In this paper, we propose a Multi-Agent Deep Reinforcement Learning (MA-DRL) approach to automatically design RD policies with high adaptability and performance. This is achieved through a new problem formulation in the form of a Multi-Agent Markov Decision Process (MA-MDP), a new adaptive RD policy design and a new MA-DRL algorithm called MA-PPO. Extensive simulation studies show that our MA-DRL technique can effectively train RD policies to significantly outperform man-made policies, model-based policies, as well as RD policies learned via single-agent DRL algorithms.",
        "published": "2021-02-06T09:49:27Z",
        "link": "http://arxiv.org/abs/2103.03022v1",
        "categories": [
            "cs.NI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "An Autonomous Negotiating Agent Framework with Reinforcement Learning   Based Strategies and Adaptive Strategy Switching Mechanism",
        "authors": [
            "Ayan Sengupta",
            "Yasser Mohammad",
            "Shinji Nakadai"
        ],
        "summary": "Despite abundant negotiation strategies in literature, the complexity of automated negotiation forbids a single strategy from being dominant against all others in different negotiation scenarios. To overcome this, one approach is to use mixture of experts, but at the same time, one problem of this method is the selection of experts, as this approach is limited by the competency of the experts selected. Another problem with most negotiation strategies is their incapability of adapting to dynamic variation of the opponent's behaviour within a single negotiation session resulting in poor performance. This work focuses on both, solving the problem of expert selection and adapting to the opponent's behaviour with our Autonomous Negotiating Agent Framework. This framework allows real-time classification of opponent's behaviour and provides a mechanism to select, switch or combine strategies within a single negotiation session. Additionally, our framework has a reviewer component which enables self-enhancement capability by deciding to include new strategies or replace old ones with better strategies periodically. We demonstrate an instance of our framework by implementing maximum entropy reinforcement learning based strategies with a deep learning based opponent classifier. Finally, we evaluate the performance of our agent against state-of-the-art negotiators under varied negotiation scenarios.",
        "published": "2021-02-06T14:38:03Z",
        "link": "http://arxiv.org/abs/2102.03588v2",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Decentralized Ability-Aware Adaptive Control for Multi-robot   Collaborative Manipulation",
        "authors": [
            "Lei Yan",
            "Theodoros Stouraitis",
            "Sethu Vijayakumar"
        ],
        "summary": "Multi-robot teams can achieve more dexterous, complex and heavier payload tasks than a single robot, yet effective collaboration is required. Multi-robot collaboration is extremely challenging due to the different kinematic and dynamics capabilities of the robots, the limited communication between them, and the uncertainty of the system parameters. In this paper, a Decentralized Ability-Aware Adaptive Control is proposed to address these challenges based on two key features. Firstly, the common manipulation task is represented by the proposed nominal task ellipsoid, which is used to maximize each robot force capability online via optimizing its configuration. Secondly, a decentralized adaptive controller is designed to be Lyapunov stable in spite of heterogeneous actuation constraints of the robots and uncertain physical parameters of the object and environment. In the proposed framework, decentralized coordination and load distribution between the robots is achieved without communication, while only the control deficiency is broadcast if any of the robots reaches its force limits. In this case, the object reference trajectory is modified in a decentralized manner to guarantee stable interaction. Finally, we perform several numerical and physical simulations to analyse and verify the proposed method with heterogeneous multi-robot teams in collaborative manipulation tasks.",
        "published": "2021-02-07T00:04:39Z",
        "link": "http://arxiv.org/abs/2102.03689v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Asynchronous semi-anonymous dynamics over large-scale networks",
        "authors": [
            "Chiara Ravazzi",
            "Giacomo Como",
            "Michele Garetto",
            "Emilio Leonardi",
            "Alberto Tarable"
        ],
        "summary": "We analyze a class of stochastic processes, referred to as asynchronous and semi-anonymous dynamics (ASD), over directed labeled random networks. These processes are a natural tool to describe general best-response and noisy best-response dynamics in network games where each agent, at random times governed by independent Poisson clocks, can choose among a finite set of actions. The payoff is determined by the relative popularity of different actions among neighbors, while being independent of the specific identities of neighbors.   Using a mean-field approach, we prove that, under certain conditions on the network and initial node configuration, the evolution of ASD can be approximated, in the limit of large network sizes, by the solution of a system of non-linear ordinary differential equations. Our framework is very general and applies to a large class of graph ensembles for which the typical random graph locally behaves like a tree. In particular, we will focus on labeled configuration-model random graphs, a generalization of the traditional configuration model which allows different classes of nodes to be mixed together in the network, permitting us, for example, to incorporate a community structure in the system. Our analysis also applies to configuration-model graphs having a power-law degree distribution, an essential feature of many real systems. To demonstrate the power and flexibility of our framework, we consider several examples of dynamics belonging to our class of stochastic processes. Moreover, we illustrate by simulation the applicability of our analysis to realistic scenarios by running our example dynamics over a real social network graph.",
        "published": "2021-02-07T16:37:18Z",
        "link": "http://arxiv.org/abs/2102.03840v1",
        "categories": [
            "cs.SI",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "An Enhanced Corpus for Arabic Newspapers Comments",
        "authors": [
            "Hichem Rahab",
            "Abdelhafid Zitouni",
            "Mahieddine Djoudi"
        ],
        "summary": "In this paper, we propose our enhanced approach to create a dedicated corpus for Algerian Arabic newspapers comments. The developed approach has to enhance an existing approach by the enrichment of the available corpus and the inclusion of the annotation step by following the Model Annotate Train Test Evaluate Revise (MATTER) approach. A corpus is created by collecting comments from web sites of three well know Algerian newspapers. Three classifiers, support vector machines, na{\\\"i}ve Bayes, and k-nearest neighbors, were used for classification of comments into positive and negative classes. To identify the influence of the stemming in the obtained results, the classification was tested with and without stemming. Obtained results show that stemming does not enhance considerably the classification due to the nature of Algerian comments tied to Algerian Arabic Dialect. The promising results constitute a motivation for us to improve our approach especially in dealing with non Arabic sentences, especially Dialectal and French ones.",
        "published": "2021-02-08T10:15:44Z",
        "link": "http://arxiv.org/abs/2102.09965v1",
        "categories": [
            "cs.IR",
            "cs.CL",
            "cs.MA"
        ]
    },
    {
        "title": "Regular Model Checking Approach to Knowledge Reasoning over   Parameterized Systems (technical report)",
        "authors": [
            "Daniel Stan",
            "Anthony Widjaja Lin"
        ],
        "summary": "We present a general framework for modelling and verifying epistemic properties over parameterized multi-agent systems that communicate by truthful public announcements. In our framework, the number of agents or the amount of certain resources are parameterized (i.e. not known a priori), and the corresponding verification problem asks whether a given epistemic property is true regardless of the instantiation of the parameters. For example, in a muddy children puzzle, one could ask whether each child will eventually find out whether (s)he is muddy, regardless of the number of children.   Our framework is regular model checking (RMC)-based, wherein synchronous finite-state automata (equivalently, monadic second-order logic over words) are used to specify the systems. We propose an extension of public announcement logic as specification language. Of special interests is the addition of the so-called iterated public announcement operators, which are crucial for reasoning about knowledge in parameterized systems. Although the operators make the model checking problem undecidable, we show that this becomes decidable when an appropriate \"disappearance relation\" is given. Further, we show how Angluin's L*-algorithm for learning finite automata can be applied to find a disappearance relation, which is guaranteed to terminate if it is regular. We have implemented the algorithm and apply this to such examples as the Muddy Children Puzzle, the Russian Card Problem, and Large Number Challenge.",
        "published": "2021-02-08T17:10:24Z",
        "link": "http://arxiv.org/abs/2102.04361v3",
        "categories": [
            "cs.FL",
            "cs.LO",
            "cs.MA"
        ]
    },
    {
        "title": "Tractable mechanisms for computing near-optimal utility functions",
        "authors": [
            "Rahul Chandan",
            "Dario Paccagnan",
            "Jason R. Marden"
        ],
        "summary": "Large scale multiagent systems must rely on distributed decision making, as centralized coordination is either impractical or impossible. Recent works approach this problem under a game theoretic lens, whereby utility functions are assigned to each of the agents with the hope that their local optimization approximates the centralized optimal solution. Yet, formal guarantees on the resulting performance cannot be obtained for broad classes of problems without compromising on their accuracy. In this work, we address this concern relative to the well-studied problem of resource allocation with nondecreasing concave welfare functions. We show that optimally designed local utilities achieve an approximation ratio (price of anarchy) of 1-c/e, where c is the function's curvature and e is Euler's constant. The upshot of our contributions is the design of approximation algorithms that are distributed and efficient, and whose performance matches that of the best existing polynomial-time (and centralized) schemes.",
        "published": "2021-02-08T21:46:56Z",
        "link": "http://arxiv.org/abs/2102.04542v1",
        "categories": [
            "cs.GT",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Structured Diversification Emergence via Reinforced Organization Control   and Hierarchical Consensus Learning",
        "authors": [
            "Wenhao Li",
            "Xiangfeng Wang",
            "Bo Jin",
            "Junjie Sheng",
            "Yun Hua",
            "Hongyuan Zha"
        ],
        "summary": "When solving a complex task, humans will spontaneously form teams and to complete different parts of the whole task, respectively. Meanwhile, the cooperation between teammates will improve efficiency. However, for current cooperative MARL methods, the cooperation team is constructed through either heuristics or end-to-end blackbox optimization. In order to improve the efficiency of cooperation and exploration, we propose a structured diversification emergence MARL framework named {\\sc{Rochico}} based on reinforced organization control and hierarchical consensus learning. {\\sc{Rochico}} first learns an adaptive grouping policy through the organization control module, which is established by independent multi-agent reinforcement learning. Further, the hierarchical consensus module based on the hierarchical intentions with consensus constraint is introduced after team formation. Simultaneously, utilizing the hierarchical consensus module and a self-supervised intrinsic reward enhanced decision module, the proposed cooperative MARL algorithm {\\sc{Rochico}} can output the final diversified multi-agent cooperative policy. All three modules are organically combined to promote the structured diversification emergence. Comparative experiments on four large-scale cooperation tasks show that {\\sc{Rochico}} is significantly better than the current SOTA algorithms in terms of exploration efficiency and cooperation strength.",
        "published": "2021-02-09T11:46:12Z",
        "link": "http://arxiv.org/abs/2102.04775v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Hallmarks of Human-Machine Collaboration: A framework for assessment in   the DARPA Communicating with Computers Program",
        "authors": [
            "Robyn Kozierok",
            "John Aberdeen",
            "Cheryl Clark",
            "Christopher Garay",
            "Bradley Goodman",
            "Tonia Korves",
            "Lynette Hirschman",
            "Patricia L. McDermott",
            "Matthew W. Peterson"
        ],
        "summary": "There is a growing desire to create computer systems that can communicate effectively to collaborate with humans on complex, open-ended activities. Assessing these systems presents significant challenges. We describe a framework for evaluating systems engaged in open-ended complex scenarios where evaluators do not have the luxury of comparing performance to a single right answer. This framework has been used to evaluate human-machine creative collaborations across story and music generation, interactive block building, and exploration of molecular mechanisms in cancer. These activities are fundamentally different from the more constrained tasks performed by most contemporary personal assistants as they are generally open-ended, with no single correct solution, and often no obvious completion criteria.   We identified the Key Properties that must be exhibited by successful systems. From there we identified \"Hallmarks\" of success -- capabilities and features that evaluators can observe that would be indicative of progress toward achieving a Key Property. In addition to being a framework for assessment, the Key Properties and Hallmarks are intended to serve as goals in guiding research direction.",
        "published": "2021-02-09T17:13:53Z",
        "link": "http://arxiv.org/abs/2102.04958v1",
        "categories": [
            "cs.HC",
            "cs.AI",
            "cs.CL",
            "cs.MA",
            "cs.MM",
            "I.2.11; I.2.7; H.5.2"
        ]
    },
    {
        "title": "Equilibrium Refinements for Multi-Agent Influence Diagrams: Theory and   Practice",
        "authors": [
            "Lewis Hammond",
            "James Fox",
            "Tom Everitt",
            "Alessandro Abate",
            "Michael Wooldridge"
        ],
        "summary": "Multi-agent influence diagrams (MAIDs) are a popular form of graphical model that, for certain classes of games, have been shown to offer key complexity and explainability advantages over traditional extensive form game (EFG) representations. In this paper, we extend previous work on MAIDs by introducing the concept of a MAID subgame, as well as subgame perfect and trembling hand perfect equilibrium refinements. We then prove several equivalence results between MAIDs and EFGs. Finally, we describe an open source implementation for reasoning about MAIDs and computing their equilibria.",
        "published": "2021-02-09T18:20:50Z",
        "link": "http://arxiv.org/abs/2102.05008v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.GT"
        ]
    },
    {
        "title": "Multi-Agent Coordination in Adversarial Environments through Signal   Mediated Strategies",
        "authors": [
            "Federico Cacciamani",
            "Andrea Celli",
            "Marco Ciccone",
            "Nicola Gatti"
        ],
        "summary": "Many real-world scenarios involve teams of agents that have to coordinate their actions to reach a shared goal. We focus on the setting in which a team of agents faces an opponent in a zero-sum, imperfect-information game. Team members can coordinate their strategies before the beginning of the game, but are unable to communicate during the playing phase of the game. This is the case, for example, in Bridge, collusion in poker, and collusion in bidding. In this setting, model-free RL methods are oftentimes unable to capture coordination because agents' policies are executed in a decentralized fashion. Our first contribution is a game-theoretic centralized training regimen to effectively perform trajectory sampling so as to foster team coordination. When team members can observe each other actions, we show that this approach provably yields equilibrium strategies. Then, we introduce a signaling-based framework to represent team coordinated strategies given a buffer of past experiences. Each team member's policy is parametrized as a neural network whose output is conditioned on a suitable exogenous signal, drawn from a learned probability distribution. By combining these two elements, we empirically show convergence to coordinated equilibria in cases where previous state-of-the-art multi-agent RL algorithms did not.",
        "published": "2021-02-09T18:44:16Z",
        "link": "http://arxiv.org/abs/2102.05026v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.GT",
            "cs.LG"
        ]
    },
    {
        "title": "Multi-Agent Multi-Armed Bandits with Limited Communication",
        "authors": [
            "Mridul Agarwal",
            "Vaneet Aggarwal",
            "Kamyar Azizzadenesheli"
        ],
        "summary": "We consider the problem where $N$ agents collaboratively interact with an instance of a stochastic $K$ arm bandit problem for $K \\gg N$. The agents aim to simultaneously minimize the cumulative regret over all the agents for a total of $T$ time steps, the number of communication rounds, and the number of bits in each communication round. We present Limited Communication Collaboration - Upper Confidence Bound (LCC-UCB), a doubling-epoch based algorithm where each agent communicates only after the end of the epoch and shares the index of the best arm it knows. With our algorithm, LCC-UCB, each agent enjoys a regret of $\\tilde{O}\\left(\\sqrt{({K/N}+ N)T}\\right)$, communicates for $O(\\log T)$ steps and broadcasts $O(\\log K)$ bits in each communication step. We extend the work to sparse graphs with maximum degree $K_G$, and diameter $D$ and propose LCC-UCB-GRAPH which enjoys a regret bound of $\\tilde{O}\\left(D\\sqrt{(K/N+ K_G)DT}\\right)$. Finally, we empirically show that the LCC-UCB and the LCC-UCB-GRAPH algorithm perform well and outperform strategies that communicate through a central node",
        "published": "2021-02-10T06:28:37Z",
        "link": "http://arxiv.org/abs/2102.08462v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Automated and Distributed Statistical Analysis of Economic Agent-Based   Models",
        "authors": [
            "Andrea Vandin",
            "Daniele Giachini",
            "Francesco Lamperti",
            "Francesca Chiaromonte"
        ],
        "summary": "We propose a novel approach to the statistical analysis of stochastic simulation models and, especially, agent-based models (ABMs). Our main goal is to provide fully automated, model-independent and tool-supported techniques and algorithms to inspect simulations and perform counterfactual analysis. Our approach: (i) is easy-to-use by the modeller, (ii) improves reproducibility of results, (iii) optimizes running time given the modeller's machine, (iv) automatically chooses the number of required simulations and simulation steps to reach user-specified statistical confidence, and (v) automates a variety of statistical tests. In particular, our techniques are designed to distinguish the transient dynamics of the model from its steady-state behaviour (if any), estimate properties in both 'phases', and provide indications on the (non-)ergodic nature of the simulated processes - which, in turn, allows one to gauge the reliability of a steady-state analysis. Estimates are equipped with statistical guarantees, allowing for robust comparisons across computational experiments. To demonstrate the effectiveness of our approach, we apply it to two models from the literature: a large-scale macro-financial ABM and a small scale prediction market model. Compared to prior analyses of these models, we obtain new insights and we are able to identify and fix some erroneous conclusions.",
        "published": "2021-02-10T12:39:34Z",
        "link": "http://arxiv.org/abs/2102.05405v2",
        "categories": [
            "econ.GN",
            "cs.MA",
            "cs.PF",
            "q-fin.EC"
        ]
    },
    {
        "title": "Common Information Belief based Dynamic Programs for Stochastic Zero-sum   Games with Competing Teams",
        "authors": [
            "Dhruva Kartik",
            "Ashutosh Nayyar",
            "Urbashi Mitra"
        ],
        "summary": "Decentralized team problems where players have asymmetric information about the state of the underlying stochastic system have been actively studied, but \\emph{games} between such teams are less understood. We consider a general model of zero-sum stochastic games between two competing teams. This model subsumes many previously considered team and zero-sum game models. For this general model, we provide bounds on the upper (min-max) and lower (max-min) values of the game. Furthermore, if the upper and lower values of the game are identical (i.e., if the game has a \\emph{value}), our bounds coincide with the value of the game. Our bounds are obtained using two dynamic programs based on a sufficient statistic known as the common information belief (CIB). We also identify certain information structures in which only the minimizing team controls the evolution of the CIB. In these cases, we show that one of our CIB based dynamic programs can be used to find the min-max strategy (in addition to the min-max value). We propose an approximate dynamic programming approach for computing the values (and the strategy when applicable) and illustrate our results with the help of an example.",
        "published": "2021-02-11T04:07:17Z",
        "link": "http://arxiv.org/abs/2102.05838v2",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Regret, stability & fairness in matching markets with bandit learners",
        "authors": [
            "Sarah H. Cen",
            "Devavrat Shah"
        ],
        "summary": "Making an informed decision -- for example, when choosing a career or housing -- requires knowledge about the available options. Such knowledge is generally acquired through costly trial and error, but this learning process can be disrupted by competition. In this work, we study how competition affects the long-term outcomes of individuals as they learn. We build on a line of work that models this setting as a two-sided matching market with bandit learners. A recent result in this area states that it is impossible to simultaneously guarantee two natural desiderata: stability and low optimal regret for all agents. Resource-allocating platforms can point to this result as a justification for assigning good long-term outcomes to some agents and poor ones to others. We show that this impossibility need not hold true. In particular, by modeling two additional components of competition -- namely, costs and transfers -- we prove that it is possible to simultaneously guarantee four desiderata: stability, low optimal regret, fairness in the distribution of regret, and high social welfare.",
        "published": "2021-02-11T20:18:12Z",
        "link": "http://arxiv.org/abs/2102.06246v2",
        "categories": [
            "cs.LG",
            "cs.GT",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Fair Robust Assignment using Redundancy",
        "authors": [
            "Matthew Malencia",
            "Vijay Kumar",
            "George Pappas",
            "Amanda Prorok"
        ],
        "summary": "We study the consideration of fairness in redundant assignment for multi-agent task allocation. It has recently been shown that redundant assignment of agents to tasks provides robustness to uncertainty in task performance. However, the question of how to fairly assign these redundant resources across tasks remains unaddressed. In this paper, we present a novel problem formulation for fair redundant task allocation, which we cast as the optimization of worst-case task costs under a cardinality constraint. Solving this problem optimally is NP-hard. We exploit properties of supermodularity to propose a polynomial-time, near-optimal solution. In supermodular redundant assignment, the use of additional agents always improves task costs. Therefore, we provide a solution set that is $\\alpha$ times larger than the cardinality constraint. This constraint relaxation enables our approach to achieve a super-optimal cost by using a sub-optimal assignment size. We derive the sub-optimality bound on this cardinality relaxation, $\\alpha$. Additionally, we demonstrate that our algorithm performs near-optimally without the cardinality relaxation. We show simulations of redundant assignments of robots to goal nodes on transport networks with uncertain travel times. Empirically, our algorithm outperforms benchmarks, scales to large problems, and provides improvements in both fairness and average utility.",
        "published": "2021-02-11T20:48:16Z",
        "link": "http://arxiv.org/abs/2102.06265v2",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Interview Hoarding",
        "authors": [
            "Vikram Manjunath",
            "Thayer Morrill"
        ],
        "summary": "Many centralized matching markets are preceded by interviews between participants. We study the impact on the final match of an increase in the number of interviews for one side of the market. Our motivation is the match between residents and hospitals where, due to the COVID-19 pandemic, interviews for the 2020-21 season of the National Residency Matching Program were switched to a virtual format. This drastically reduced the cost to applicants of accepting interview invitations. However, the reduction in cost was not symmetric since applicants, not programs, previously bore most of the costs of in-person interviews. We show that if doctors can accept more interviews, but the hospitals do not increase the number of interviews they offer, then no previously matched doctor is better off and many are potentially harmed. This adverse consequence is the result of what we call interview hoarding. We prove this analytically and characterize optimal mitigation strategies for special cases. We use simulations to extend these insights to more general settings.",
        "published": "2021-02-12T11:06:18Z",
        "link": "http://arxiv.org/abs/2102.06440v4",
        "categories": [
            "econ.TH",
            "cs.MA"
        ]
    },
    {
        "title": "Intelligent Software Web Agents: A Gap Analysis",
        "authors": [
            "Sabrina Kirrane"
        ],
        "summary": "Semantic web technologies have shown their effectiveness, especially when it comes to knowledge representation, reasoning, and data integration. However, the original semantic web vision, whereby machine readable web data could be automatically actioned upon by intelligent software web agents, has yet to be realised. In order to better understand the existing technological opportunities and challenges, in this paper we examine the status quo in terms of intelligent software web agents, guided by research with respect to requirements and architectural components, coming from the agents community. We use the identified requirements to both further elaborate on the semantic web agent motivating use case scenario, and to summarise different perspectives on the requirements from the semantic web agent literature. We subsequently propose a hybrid semantic web agent architecture, and use the various components and subcomponents in order to provide a focused discussion in relation to existing semantic web standards and community activities. Finally, we highlight open research opportunities and challenges and take a broader perspective of the research by discussing the potential for intelligent software web agents as an enabling technology for emerging domains, such as digital assistants, cloud computing, and the internet of things.",
        "published": "2021-02-12T16:32:02Z",
        "link": "http://arxiv.org/abs/2102.06607v4",
        "categories": [
            "cs.AI",
            "cs.MA",
            "cs.NI"
        ]
    },
    {
        "title": "A Hybrid Variance-Reduced Method for Decentralized Stochastic Non-Convex   Optimization",
        "authors": [
            "Ran Xin",
            "Usman A. Khan",
            "Soummya Kar"
        ],
        "summary": "This paper considers decentralized stochastic optimization over a network of $n$ nodes, where each node possesses a smooth non-convex local cost function and the goal of the networked nodes is to find an $\\epsilon$-accurate first-order stationary point of the sum of the local costs. We focus on an online setting, where each node accesses its local cost only by means of a stochastic first-order oracle that returns a noisy version of the exact gradient. In this context, we propose a novel single-loop decentralized hybrid variance-reduced stochastic gradient method, called GT-HSGD, that outperforms the existing approaches in terms of both the oracle complexity and practical implementation. The GT-HSGD algorithm implements specialized local hybrid stochastic gradient estimators that are fused over the network to track the global gradient. Remarkably, GT-HSGD achieves a network topology-independent oracle complexity of $O(n^{-1}\\epsilon^{-3})$ when the required error tolerance $\\epsilon$ is small enough, leading to a linear speedup with respect to the centralized optimal online variance-reduced approaches that operate on a single node. Numerical experiments are provided to illustrate our main technical results.",
        "published": "2021-02-12T20:13:05Z",
        "link": "http://arxiv.org/abs/2102.06752v2",
        "categories": [
            "math.OC",
            "cs.DC",
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Modelling Cooperation in Network Games with Spatio-Temporal Complexity",
        "authors": [
            "Michiel A. Bakker",
            "Richard Everett",
            "Laura Weidinger",
            "Iason Gabriel",
            "William S. Isaac",
            "Joel Z. Leibo",
            "Edward Hughes"
        ],
        "summary": "The real world is awash with multi-agent problems that require collective action by self-interested agents, from the routing of packets across a computer network to the management of irrigation systems. Such systems have local incentives for individuals, whose behavior has an impact on the global outcome for the group. Given appropriate mechanisms describing agent interaction, groups may achieve socially beneficial outcomes, even in the face of short-term selfish incentives. In many cases, collective action problems possess an underlying graph structure, whose topology crucially determines the relationship between local decisions and emergent global effects. Such scenarios have received great attention through the lens of network games. However, this abstraction typically collapses important dimensions, such as geometry and time, relevant to the design of mechanisms promoting cooperation. In parallel work, multi-agent deep reinforcement learning has shown great promise in modelling the emergence of self-organized cooperation in complex gridworld domains. Here we apply this paradigm in graph-structured collective action problems. Using multi-agent deep reinforcement learning, we simulate an agent society for a variety of plausible mechanisms, finding clear transitions between different equilibria over time. We define analytic tools inspired by related literatures to measure the social outcomes, and use these to draw conclusions about the efficacy of different environmental interventions. Our methods have implications for mechanism design in both human and artificial agent systems.",
        "published": "2021-02-13T12:04:52Z",
        "link": "http://arxiv.org/abs/2102.06911v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "An Efficient QOS Based Multimedia Content Distribution Mechanism in P2P   Network",
        "authors": [
            "M Anandaraj",
            "P Ganeshkumar",
            "K. P. Vijayakumar"
        ],
        "summary": "Peer-to-peer network is one in which each node in the network can act as a client or server for the other nodes in the network. It allows shared access to various resources such as files, peripherals, and sensors without the need for a central server. Content distribution in the P2P network from server is done by multicasting. Multicasting is the process of sending the data to the multiple designations. This technology is highly efficient for the large scale multimedia content delivery in P2P network where the end peer have identical set of system components. But in reality, the peers have heterogeneous set of requirements for different service levels as well as different service components. The ability to provide differentiated services to each peer with widely varying requirements is becoming important. We need to provide differentiated Services above the existing shared network infrastructure. The solution proposed to solve the above said problem is to provide individualized service to each peer. It focuses on constructing and maintaining an efficient multiple overlay multicast tree structure in the P2P network. The tree maintenance process is governed by two mechanisms called as dynamic reconfiguration driven by peer and less frequent tree maintenance by network status change observation. In this paper new scalable architecture is constructed and analysed based on the above strategies.",
        "published": "2021-02-13T16:47:42Z",
        "link": "http://arxiv.org/abs/2102.06954v2",
        "categories": [
            "cs.MA",
            "cs.MM"
        ]
    },
    {
        "title": "Mitigating Negative Side Effects via Environment Shaping",
        "authors": [
            "Sandhya Saisubramanian",
            "Shlomo Zilberstein"
        ],
        "summary": "Agents operating in unstructured environments often produce negative side effects (NSE), which are difficult to identify at design time. While the agent can learn to mitigate the side effects from human feedback, such feedback is often expensive and the rate of learning is sensitive to the agent's state representation. We examine how humans can assist an agent, beyond providing feedback, and exploit their broader scope of knowledge to mitigate the impacts of NSE. We formulate this problem as a human-agent team with decoupled objectives. The agent optimizes its assigned task, during which its actions may produce NSE. The human shapes the environment through minor reconfiguration actions so as to mitigate the impacts of the agent's side effects, without affecting the agent's ability to complete its assigned task. We present an algorithm to solve this problem and analyze its theoretical properties. Through experiments with human subjects, we assess the willingness of users to perform minor environment modifications to mitigate the impacts of NSE. Empirical evaluation of our approach shows that the proposed framework can successfully mitigate NSE, without affecting the agent's ability to complete its assigned task.",
        "published": "2021-02-13T22:15:00Z",
        "link": "http://arxiv.org/abs/2102.07017v1",
        "categories": [
            "cs.AI",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Communication-efficient Distributed Cooperative Learning with Compressed   Beliefs",
        "authors": [
            "Mohammad Taha Toghani",
            "César A. Uribe"
        ],
        "summary": "We study the problem of distributed cooperative learning, where a group of agents seeks to agree on a set of hypotheses that best describes a sequence of private observations. In the scenario where the set of hypotheses is large, we propose a belief update rule where agents share compressed (either sparse or quantized) beliefs with an arbitrary positive compression rate. Our algorithm leverages a unified communication rule that enables agents to access wide-ranging compression operators as black-box modules. We prove the almost sure asymptotic exponential convergence of beliefs around the set of optimal hypotheses. Additionally, we show a non-asymptotic, explicit, and linear concentration rate in probability of the beliefs on the optimal hypothesis set. We provide numerical experiments to illustrate the communication benefits of our method. The simulation results show that the number of transmitted bits can be reduced to 5-10% of the non-compressed method in the studied scenarios.",
        "published": "2021-02-14T06:19:36Z",
        "link": "http://arxiv.org/abs/2102.07767v2",
        "categories": [
            "cs.LG",
            "cs.DC",
            "cs.MA",
            "math.OC",
            "stat.ML"
        ]
    },
    {
        "title": "On the Equilibrium Elicitation of Markov Games Through Information   Design",
        "authors": [
            "Tao Zhang",
            "Quanyan Zhu"
        ],
        "summary": "This work considers a novel information design problem and studies how the craft of payoff-relevant environmental signals solely can influence the behaviors of intelligent agents. The agents' strategic interactions are captured by an incomplete-information Markov game, in which each agent first selects one environmental signal from multiple signal sources as additional payoff-relevant information and then takes an action. There is a rational information designer (designer) who possesses one signal source and aims to control the equilibrium behaviors of the agents by designing the information structure of her signals sent to the agents. An obedient principle is established which states that it is without loss of generality to focus on the direct information design when the information design incentivizes each agent to select the signal sent by the designer, such that the design process avoids the predictions of the agents' strategic selection behaviors. We then introduce the design protocol given a goal of the designer referred to as obedient implementability (OIL) and characterize the OIL in a class of obedient perfect Bayesian Markov Nash equilibria (O-PBME). A new framework for information design is proposed based on an approach of maximizing the optimal slack variables. Finally, we formulate the designer's goal selection problem and characterize it in terms of information design by establishing a relationship between the O-PBME and the Bayesian Markov correlated equilibria, in which we build upon the revelation principle in classic information design in economics. The proposed approach can be applied to elicit desired behaviors of multi-agent systems in competing as well as cooperating settings and be extended to heterogeneous stochastic games in the complete- and the incomplete-information environments.",
        "published": "2021-02-14T13:30:06Z",
        "link": "http://arxiv.org/abs/2102.07152v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.GT"
        ]
    },
    {
        "title": "Task-oriented Communication Design in Cyber-Physical Systems: A Survey   on Theory and Applications",
        "authors": [
            "Arsham Mostaani",
            "Thang X. Vu",
            "Shree Krishna Sharma",
            "Van-Dinh Nguyen",
            "Qi Liao",
            "Symeon Chatzinotas"
        ],
        "summary": "Communications system design has been traditionally guided by task-agnostic principles, which aim at efficiently transmitting as many correct bits as possible through a given channel. However, in the era of cyber-physical systems, the effectiveness of communications is not dictated simply by the bit rate, but most importantly by the efficient completion of the task in hand, e.g., controlling remotely a robot, automating a production line or collaboratively sensing through a drone swarm. In parallel, it is projected that by 2023, half of the worldwide network connections will be among machines rather than humans. In this context, it is crucial to establish a new paradigm for designing communications strategies for multi-agent cyber-physical systems. This is a daunting task, since it requires a combination of principles from information, communication, control theories and computer science in order to formalize a general framework for task-oriented communication design. In this direction, this paper reviews and structures the relevant theoretical work across a wide range of scientific communities. Subsequently, it proposes a general conceptual framework for task-oriented communication design, along with its specializations according to the targeted use case. Furthermore, it provides a survey of relevant contributions in dominant applications, such as industrial internet of things, multi-UAV systems, tactile internet, autonomous vehicles, distributed learning systems, smart manufacturing plants and 5G and beyond self-organizing networks. Finally, it highlights the most important open research topics from both the theoretical framework and application points of view.",
        "published": "2021-02-14T14:51:38Z",
        "link": "http://arxiv.org/abs/2102.07166v4",
        "categories": [
            "cs.IT",
            "cs.MA",
            "math.IT"
        ]
    },
    {
        "title": "Partial Disclosure of Private Dependencies in Privacy Preserving   Planning",
        "authors": [
            "Rotem Lev Lehman",
            "Guy Shani",
            "Roni Stern"
        ],
        "summary": "In collaborative privacy preserving planning (CPPP), a group of agents jointly creates a plan to achieve a set of goals while preserving each others' privacy. During planning, agents often reveal the private dependencies between their public actions to other agents, that is, which public action facilitates the preconditions of another public action. Previous work in CPPP does not limit the disclosure of such dependencies. In this paper, we explicitly limit the amount of disclosed dependencies, allowing agents to publish only a part of their private dependencies. We investigate different strategies for deciding which dependencies to publish, and how they affect the ability to find solutions. We evaluate the ability of two solvers -- distribute forward search and centralized planning based on a single-agent projection -- to produce plans under this constraint. Experiments over standard CPPP domains show that the proposed dependency-sharing strategies enable generating plans while sharing only a small fraction of all private dependencies.",
        "published": "2021-02-14T16:10:08Z",
        "link": "http://arxiv.org/abs/2102.07185v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "I.2.8; I.2.11"
        ]
    },
    {
        "title": "Log-time Prediction Markets for Interval Securities",
        "authors": [
            "Miroslav Dudík",
            "Xintong Wang",
            "David M. Pennock",
            "David M. Rothschild"
        ],
        "summary": "We design a prediction market to recover a complete and fully general probability distribution over a random variable. Traders buy and sell interval securities that pay \\$1 if the outcome falls into an interval and \\$0 otherwise. Our market takes the form of a central automated market maker and allows traders to express interval endpoints of arbitrary precision. We present two designs in both of which market operations take time logarithmic in the number of intervals (that traders distinguish), providing the first computationally efficient market for a continuous variable. Our first design replicates the popular logarithmic market scoring rule (LMSR), but operates exponentially faster than a standard LMSR by exploiting its modularity properties to construct a balanced binary tree and decompose computations along the tree nodes. The second design consists of two or more parallel LMSR market makers that mediate submarkets of increasingly fine-grained outcome partitions. This design remains computationally efficient for all operations, including arbitrage removal across submarkets. It adds two additional benefits for the market designer: (1) the ability to express utility for information at various resolutions by assigning different liquidity values, and (2) the ability to guarantee a true constant bounded loss by appropriately decreasing the liquidity in each submarket.",
        "published": "2021-02-15T02:26:53Z",
        "link": "http://arxiv.org/abs/2102.07308v2",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "A Decentralized Multi-UAV Spatio-Temporal Multi-Task Allocation Approach   for Perimeter Defense",
        "authors": [
            "Shridhar Velhal",
            "Suresh Sundaram",
            "Narasimhan Sundararajan"
        ],
        "summary": "This paper provides a new solution approach to a multi-player perimeter defense game, in which the intruders' team tries to enter the territory, and a team of defenders protects the territory by capturing intruders on the perimeter of the territory. The objective of the defenders is to detect and capture the intruders before the intruders enter the territory. Each defender independently senses the intruder and computes his trajectory to capture the assigned intruders in a cooperative fashion. The intruder is estimated to reach a specific location on the perimeter at a specific time. Each intruder is viewed as a spatio-temporal task, and the defenders are assigned to execute these spatio-temporal tasks. At any given time, the perimeter defense problem is converted into a Decentralized Multi-UAV Spatio-Temporal Multi-Task Allocation (DMUST-MTA) problem. The cost of executing a task for a trajectory is defined by a composite cost function of both the spatial and temporal components. In this paper, a decentralized consensus-based bundle algorithm has been modified to solve the spatio-temporal multi-task allocation problem, and the performance evaluation of the proposed approach is carried out based on Monte-Carlo simulations. The simulation results show the effectiveness of the proposed approach to solve the perimeter defense game under different scenarios. Performance comparison with a state-of-the-art centralized approach with full observability, clearly indicates that DMUST-MTA achieves similar performance in a decentralized way with partial observability conditions with a lesser computational time and easy scaling up.",
        "published": "2021-02-15T07:45:56Z",
        "link": "http://arxiv.org/abs/2102.07381v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.RO",
            "cs.SY"
        ]
    },
    {
        "title": "Scaling Multi-Agent Reinforcement Learning with Selective Parameter   Sharing",
        "authors": [
            "Filippos Christianos",
            "Georgios Papoudakis",
            "Arrasy Rahman",
            "Stefano V. Albrecht"
        ],
        "summary": "Sharing parameters in multi-agent deep reinforcement learning has played an essential role in allowing algorithms to scale to a large number of agents. Parameter sharing between agents significantly decreases the number of trainable parameters, shortening training times to tractable levels, and has been linked to more efficient learning. However, having all agents share the same parameters can also have a detrimental effect on learning. We demonstrate the impact of parameter sharing methods on training speed and converged returns, establishing that when applied indiscriminately, their effectiveness is highly dependent on the environment. We propose a novel method to automatically identify agents which may benefit from sharing parameters by partitioning them based on their abilities and goals. Our approach combines the increased sample efficiency of parameter sharing with the representational capacity of multiple independent networks to reduce training time and increase final returns.",
        "published": "2021-02-15T11:33:52Z",
        "link": "http://arxiv.org/abs/2102.07475v2",
        "categories": [
            "cs.MA",
            "cs.LG"
        ]
    },
    {
        "title": "An Overview of Agent-based Traffic Simulators",
        "authors": [
            "Johannes Nguyen",
            "Simon T. Powers",
            "Neil Urquhart",
            "Thomas Farrenkopf",
            "Michael Guckert"
        ],
        "summary": "Individual traffic significantly contributes to climate change and environmental degradation. Therefore, innovation in sustainable mobility is gaining importance as it helps to reduce environmental pollution. However, effects of new ideas in mobility are difficult to estimate in advance and strongly depend on the individual traffic participants. The application of agent technology is particularly promising as it focuses on modelling heterogeneous individual preferences and behaviours. In this paper, we show how agent-based models are particularly suitable to address three pressing research topics in mobility: 1. Social dilemmas in resource utilisation; 2. Digital connectivity; and 3. New forms of mobility. We then explain how the features of several agent-based simulators are suitable for addressing these topics. We assess the capability of simulators to model individual travel behaviour, discussing implemented features and identifying gaps in functionality that we consider important.",
        "published": "2021-02-15T12:13:01Z",
        "link": "http://arxiv.org/abs/2102.07505v2",
        "categories": [
            "cs.MA",
            "cs.GT"
        ]
    },
    {
        "title": "Cooperation and Reputation Dynamics with Reinforcement Learning",
        "authors": [
            "Nicolas Anastassacos",
            "Julian García",
            "Stephen Hailes",
            "Mirco Musolesi"
        ],
        "summary": "Creating incentives for cooperation is a challenge in natural and artificial systems. One potential answer is reputation, whereby agents trade the immediate cost of cooperation for the future benefits of having a good reputation. Game theoretical models have shown that specific social norms can make cooperation stable, but how agents can independently learn to establish effective reputation mechanisms on their own is less understood. We use a simple model of reinforcement learning to show that reputation mechanisms generate two coordination problems: agents need to learn how to coordinate on the meaning of existing reputations and collectively agree on a social norm to assign reputations to others based on their behavior. These coordination problems exhibit multiple equilibria, some of which effectively establish cooperation. When we train agents with a standard Q-learning algorithm in an environment with the presence of reputation mechanisms, convergence to undesirable equilibria is widespread. We propose two mechanisms to alleviate this: (i) seeding a proportion of the system with fixed agents that steer others towards good equilibria; and (ii), intrinsic rewards based on the idea of introspection, i.e., augmenting agents' rewards by an amount proportionate to the performance of their own strategy against themselves. A combination of these simple mechanisms is successful in stabilizing cooperation, even in a fully decentralized version of the problem where agents learn to use and assign reputations simultaneously. We show how our results relate to the literature in Evolutionary Game Theory, and discuss implications for artificial, human and hybrid systems, where reputations can be used as a way to establish trust and cooperation.",
        "published": "2021-02-15T12:48:56Z",
        "link": "http://arxiv.org/abs/2102.07523v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Diverse Auto-Curriculum is Critical for Successful Real-World Multiagent   Learning Systems",
        "authors": [
            "Yaodong Yang",
            "Jun Luo",
            "Ying Wen",
            "Oliver Slumbers",
            "Daniel Graves",
            "Haitham Bou Ammar",
            "Jun Wang",
            "Matthew E. Taylor"
        ],
        "summary": "Multiagent reinforcement learning (MARL) has achieved a remarkable amount of success in solving various types of video games. A cornerstone of this success is the auto-curriculum framework, which shapes the learning process by continually creating new challenging tasks for agents to adapt to, thereby facilitating the acquisition of new skills. In order to extend MARL methods to real-world domains outside of video games, we envision in this blue sky paper that maintaining a diversity-aware auto-curriculum is critical for successful MARL applications. Specifically, we argue that \\emph{behavioural diversity} is a pivotal, yet under-explored, component for real-world multiagent learning systems, and that significant work remains in understanding how to design a diversity-aware auto-curriculum. We list four open challenges for auto-curriculum techniques, which we believe deserve more attention from this community. Towards validating our vision, we recommend modelling realistic interactive behaviours in autonomous driving as an important test bed, and recommend the SMARTS/ULTRA benchmark.",
        "published": "2021-02-15T16:40:02Z",
        "link": "http://arxiv.org/abs/2102.07659v2",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "DFAC Framework: Factorizing the Value Function via Quantile Mixture for   Multi-Agent Distributional Q-Learning",
        "authors": [
            "Wei-Fang Sun",
            "Cheng-Kuang Lee",
            "Chun-Yi Lee"
        ],
        "summary": "In fully cooperative multi-agent reinforcement learning (MARL) settings, the environments are highly stochastic due to the partial observability of each agent and the continuously changing policies of the other agents. To address the above issues, we integrate distributional RL and value function factorization methods by proposing a Distributional Value Function Factorization (DFAC) framework to generalize expected value function factorization methods to their DFAC variants. DFAC extends the individual utility functions from deterministic variables to random variables, and models the quantile function of the total return as a quantile mixture. To validate DFAC, we demonstrate DFAC's ability to factorize a simple two-step matrix game with stochastic rewards and perform experiments on all Super Hard tasks of StarCraft Multi-Agent Challenge, showing that DFAC is able to outperform expected value function factorization baselines.",
        "published": "2021-02-16T03:16:49Z",
        "link": "http://arxiv.org/abs/2102.07936v2",
        "categories": [
            "cs.MA",
            "cs.LG"
        ]
    },
    {
        "title": "RMIX: Learning Risk-Sensitive Policies for Cooperative Reinforcement   Learning Agents",
        "authors": [
            "Wei Qiu",
            "Xinrun Wang",
            "Runsheng Yu",
            "Xu He",
            "Rundong Wang",
            "Bo An",
            "Svetlana Obraztsova",
            "Zinovi Rabinovich"
        ],
        "summary": "Current value-based multi-agent reinforcement learning methods optimize individual Q values to guide individuals' behaviours via centralized training with decentralized execution (CTDE). However, such expected, i.e., risk-neutral, Q value is not sufficient even with CTDE due to the randomness of rewards and the uncertainty in environments, which causes the failure of these methods to train coordinating agents in complex environments. To address these issues, we propose RMIX, a novel cooperative MARL method with the Conditional Value at Risk (CVaR) measure over the learned distributions of individuals' Q values. Specifically, we first learn the return distributions of individuals to analytically calculate CVaR for decentralized execution. Then, to handle the temporal nature of the stochastic outcomes during executions, we propose a dynamic risk level predictor for risk level tuning. Finally, we optimize the CVaR policies with CVaR values used to estimate the target in TD error during centralized training and the CVaR values are used as auxiliary local rewards to update the local distribution via Quantile Regression loss. Empirically, we show that our method significantly outperforms state-of-the-art methods on challenging StarCraft II tasks, demonstrating enhanced coordination and improved sample efficiency.",
        "published": "2021-02-16T13:58:25Z",
        "link": "http://arxiv.org/abs/2102.08159v3",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Quantifying the effects of environment and population diversity in   multi-agent reinforcement learning",
        "authors": [
            "Kevin R. McKee",
            "Joel Z. Leibo",
            "Charlie Beattie",
            "Richard Everett"
        ],
        "summary": "Generalization is a major challenge for multi-agent reinforcement learning. How well does an agent perform when placed in novel environments and in interactions with new co-players? In this paper, we investigate and quantify the relationship between generalization and diversity in the multi-agent domain. Across the range of multi-agent environments considered here, procedurally generating training levels significantly improves agent performance on held-out levels. However, agent performance on the specific levels used in training sometimes declines as a result. To better understand the effects of co-player variation, our experiments introduce a new environment-agnostic measure of behavioral diversity. Results demonstrate that population size and intrinsic motivation are both effective methods of generating greater population diversity. In turn, training with a diverse set of co-players strengthens agent performance in some (but not all) cases.",
        "published": "2021-02-16T18:54:39Z",
        "link": "http://arxiv.org/abs/2102.08370v2",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Towards an AI Coach to Infer Team Mental Model Alignment in Healthcare",
        "authors": [
            "Sangwon Seo",
            "Lauren R. Kennedy-Metz",
            "Marco A. Zenati",
            "Julie A. Shah",
            "Roger D. Dias",
            "Vaibhav V. Unhelkar"
        ],
        "summary": "Shared mental models are critical to team success; however, in practice, team members may have misaligned models due to a variety of factors. In safety-critical domains (e.g., aviation, healthcare), lack of shared mental models can lead to preventable errors and harm. Towards the goal of mitigating such preventable errors, here, we present a Bayesian approach to infer misalignment in team members' mental models during complex healthcare task execution. As an exemplary application, we demonstrate our approach using two simulated team-based scenarios, derived from actual teamwork in cardiac surgery. In these simulated experiments, our approach inferred model misalignment with over 75% recall, thereby providing a building block for enabling computer-assisted interventions to augment human cognition in the operating room and improve teamwork.",
        "published": "2021-02-17T00:14:08Z",
        "link": "http://arxiv.org/abs/2102.08507v1",
        "categories": [
            "cs.AI",
            "cs.HC",
            "cs.LG",
            "cs.MA",
            "68T37, 62F15 (Primary) 90C40, 62M05, 62P10, 91C99 (Secondary)",
            "I.2.m; G.3; J.3"
        ]
    },
    {
        "title": "Distributed Fair Scheduling for Information Exchange in Multi-Agent   Systems",
        "authors": [
            "Majid Raeis",
            "S. Jamaloddin Golestani"
        ],
        "summary": "Information exchange is a crucial component of many real-world multi-agent systems. However, the communication between the agents involves two major challenges: the limited bandwidth, and the shared communication medium between the agents, which restricts the number of agents that can simultaneously exchange information. While both of these issues need to be addressed in practice, the impact of the latter problem on the performance of the multi-agent systems has often been neglected. This becomes even more important when the agents' information or observations have different importance, in which case the agents require different priorities for accessing the medium and sharing their information. Representing the agents' priorities by fairness weights and normalizing each agent's share by the assigned fairness weight, the goal can be expressed as equalizing the agents' normalized shares of the communication medium. To achieve this goal, we adopt a queueing theoretic approach and propose a distributed fair scheduling algorithm for providing weighted fairness in single-hop networks. Our proposed algorithm guarantees an upper-bound on the normalized share disparity among any pair of agents. This can particularly improve the short-term fairness, which is important in real-time applications. Moreover, our scheduling algorithm adjusts itself dynamically to achieve a high throughput at the same time. The simulation results validate our claims and comparisons with the existing methods show our algorithm's superiority in providing short-term fairness, while achieving a high throughput.",
        "published": "2021-02-17T15:20:26Z",
        "link": "http://arxiv.org/abs/2102.08814v1",
        "categories": [
            "cs.MA",
            "cs.NI",
            "cs.PF"
        ]
    },
    {
        "title": "Maximizing Social Welfare Subject to Network Externalities: A Unifying   Submodular Optimization Approach",
        "authors": [
            "S. Rasoul Etesami"
        ],
        "summary": "We consider the problem of allocating multiple indivisible items to a set of networked agents to maximize the social welfare subject to network externalities. Here, the social welfare is given by the sum of agents' utilities and externalities capture the effect that one user of an item has on the item's value to others. We first provide a general formulation that captures some of the existing models as a special case. We then show that the social welfare maximization problem benefits some nice diminishing or increasing marginal return properties. That allows us to devise polynomial-time approximation algorithms using the Lovasz extension and multilinear extension of the objective functions. Our principled approach recovers or improves some of the existing algorithms and provides a simple and unifying framework for maximizing social welfare subject to network externalities.",
        "published": "2021-02-17T18:12:32Z",
        "link": "http://arxiv.org/abs/2102.08915v4",
        "categories": [
            "cs.GT",
            "cs.DM",
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "math.OC"
        ]
    },
    {
        "title": "Distributed Algorithms for Linearly-Solvable Optimal Control in   Networked Multi-Agent Systems",
        "authors": [
            "Neng Wan",
            "Aditya Gahlawat",
            "Naira Hovakimyan",
            "Evangelos A. Theodorou",
            "Petros G. Voulgaris"
        ],
        "summary": "Distributed algorithms for both discrete-time and continuous-time linearly solvable optimal control (LSOC) problems of networked multi-agent systems (MASs) are investigated in this paper. A distributed framework is proposed to partition the optimal control problem of a networked MAS into several local optimal control problems in factorial subsystems, such that each (central) agent behaves optimally to minimize the joint cost function of a subsystem that comprises a central agent and its neighboring agents, and the local control actions (policies) only rely on the knowledge of local observations. Under this framework, we not only preserve the correlations between neighboring agents, but moderate the communication and computational complexities by decentralizing the sampling and computational processes over the network. For discrete-time systems modeled by Markov decision processes, the joint Bellman equation of each subsystem is transformed into a system of linear equations and solved using parallel programming. For continuous-time systems modeled by It\\^o diffusion processes, the joint optimality equation of each subsystem is converted into a linear partial differential equation, whose solution is approximated by a path integral formulation and a sample-efficient relative entropy policy search algorithm, respectively. The learned control policies are generalized to solve the unlearned tasks by resorting to the compositionality principle, and illustrative examples of cooperative UAV teams are provided to verify the effectiveness and advantages of these algorithms.",
        "published": "2021-02-18T01:31:17Z",
        "link": "http://arxiv.org/abs/2102.09104v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "cs.RO",
            "cs.SY",
            "eess.SY",
            "math.OC"
        ]
    },
    {
        "title": "Spatio-Temporal Graph Dual-Attention Network for Multi-Agent Prediction   and Tracking",
        "authors": [
            "Jiachen Li",
            "Hengbo Ma",
            "Zhihao Zhang",
            "Jinning Li",
            "Masayoshi Tomizuka"
        ],
        "summary": "An effective understanding of the environment and accurate trajectory prediction of surrounding dynamic obstacles are indispensable for intelligent mobile systems (e.g. autonomous vehicles and social robots) to achieve safe and high-quality planning when they navigate in highly interactive and crowded scenarios. Due to the existence of frequent interactions and uncertainty in the scene evolution, it is desired for the prediction system to enable relational reasoning on different entities and provide a distribution of future trajectories for each agent. In this paper, we propose a generic generative neural system (called STG-DAT) for multi-agent trajectory prediction involving heterogeneous agents. The system takes a step forward to explicit interaction modeling by incorporating relational inductive biases with a dynamic graph representation and leverages both trajectory and scene context information. We also employ an efficient kinematic constraint layer applied to vehicle trajectory prediction. The constraint not only ensures physical feasibility but also enhances model performance. Moreover, the proposed prediction model can be easily adopted by multi-target tracking frameworks. The tracking accuracy proves to be improved by empirical results. The proposed system is evaluated on three public benchmark datasets for trajectory prediction, where the agents cover pedestrians, cyclists and on-road vehicles. The experimental results demonstrate that our model achieves better performance than various baseline approaches in terms of prediction and tracking accuracy.",
        "published": "2021-02-18T02:25:35Z",
        "link": "http://arxiv.org/abs/2102.09117v1",
        "categories": [
            "cs.CV",
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "OSOUM Framework for Trading Data Research",
        "authors": [
            "Gregory Goren",
            "Roee Shraga",
            "Alexander Tuisov"
        ],
        "summary": "In the last decades, data have become a cornerstone component in many business decisions, and copious resources are being poured into production and acquisition of the high-quality data. This emerging market possesses unique features, and thus came under the spotlight for the stakeholders and researchers alike. In this work, we aspire to provide the community with a set of tools for making business decisions, as well as analysis of markets behaving according to certain rules. We supply, to the best of our knowledge, the first open source simulation platform, termed Open SOUrce Market Simulator (OSOUM) to analyze trading markets and specifically data markets. We also describe and implement a specific data market model, consisting of two types of agents: sellers who own various datasets available for acquisition, and buyers searching for relevant and beneficial datasets for purchase. The current simulation treats data as an infinite supply product. Yet, other market settings may be easily implemented using OSOUM. Although commercial frameworks, intended for handling data markets, already exist, we provide a free and extensive end-to-end research tool for simulating possible behavior for both buyers and sellers participating in (data) markets.",
        "published": "2021-02-18T09:20:26Z",
        "link": "http://arxiv.org/abs/2103.01778v1",
        "categories": [
            "cs.CY",
            "cs.MA"
        ]
    },
    {
        "title": "A two-layer model for coevolving opinion dynamics and collective   decision-making in complex social systems",
        "authors": [
            "Lorenzo Zino",
            "Mengbin Ye",
            "Ming Cao"
        ],
        "summary": "Motivated by the literature on opinion dynamics and evolutionary game theory, we propose a novel mathematical framework to model the intertwined coevolution of opinions and decision-making in a complex social system. In the proposed framework, the members of a social community update their opinions and revise their actions as they learn of others' opinions shared on a communication channel, and observe of others' actions through an influence channel; these interactions determine a two-layer network structure. We offer an application of the proposed framework by tailoring it to study the adoption of a novel social norm, demonstrating that the model is able to capture the emergence of several real-world collective phenomena such as paradigm shifts and unpopular norms. Through the establishment of analytical conditions and Monte Carlo numerical simulations, we shed light on the role of the coupling between opinion dynamics and decision-making, and of the network structure, in shaping the emergence of complex collective behavior in social systems.",
        "published": "2021-02-18T12:04:17Z",
        "link": "http://arxiv.org/abs/2102.09285v1",
        "categories": [
            "cs.SI",
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "math.DS",
            "physics.soc-ph"
        ]
    },
    {
        "title": "Highway Traffic Control via Smart e-Mobility -- Part I: Theory",
        "authors": [
            "Carlo Cenedese",
            "Michele Cucuzzella",
            "Jacquelien M. A. Scherpen",
            "Sergio Grammatico",
            "Ming Cao"
        ],
        "summary": "In this paper, we study how to alleviate highway traffic congestion by encouraging plug-in hybrid and electric vehicles to stop at a charging station around peak congestion times. Specifically, we design a pricing policy to make the charging price dynamic and dependent on the traffic congestion, predicted via the cell transmission model, and the availability of charging spots. Furthermore, we develop a novel framework to model how this policy affects the drivers' decisions by formulating a mixed-integer potential game. Technically, we introduce the concept of \"road-to-station\" (r2s) and \"station-to-road\" (s2r) flows, and show that the selfish actions of the drivers converge to charging schedules that are individually optimal in the sense of Nash. In the second part of this work, submitted as a separate paper (Part II: Case Study), we validate the proposed strategy on a simulated highway stretch between The Hague and Rotterdam, in The Netherlands.",
        "published": "2021-02-18T14:05:06Z",
        "link": "http://arxiv.org/abs/2102.09354v2",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY",
            "math.OC"
        ]
    },
    {
        "title": "Highway Traffic Control via Smart e-Mobility -- Part II: Dutch A13 Case   Study",
        "authors": [
            "Carlo Cenedese",
            "Michele Cucuzzella",
            "Jacquelien M. A. Scherpen",
            "Sergio Grammatico",
            "Ming Cao"
        ],
        "summary": "In this paper, we study how to alleviate highway traffic congestions by encouraging plug-in electric and hybrid vehicles to stop at charging stations around peak congestion times. Specifically, we focus on a case study and simulate the adoption of a dynamic charging price depending on the traffic congestion. We use real traffic data of the A13 highway stretch between The Hague and Rotterdam, in The Netherlands, to identify the Cell Transmission Model. Then, we apply the algorithm proposed in (Part I: Theory) to different scenarios, validating the theoretical results and showing the benefits of our strategy in terms of traffic congestion alleviation. Finally, we carry out a sensitivity analysis of the proposed algorithm and discuss how to optimize its performance.",
        "published": "2021-02-18T15:48:19Z",
        "link": "http://arxiv.org/abs/2102.09433v2",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY",
            "math.OC"
        ]
    },
    {
        "title": "B-ETS: A Trusted Blockchain-based Emissions Trading System for   Vehicle-to-Vehicle Networks",
        "authors": [
            "Lam Duc Nguyen",
            "Amari N. Lewis",
            "Israel Leyva-Mayorga",
            "Amelia Regan",
            "Petar Popovski"
        ],
        "summary": "Urban areas are negatively impacted by Carbon Dioxide (CO2 ) and Nitrogen Oxide (NOx) emissions. In order to achieve a cost-effective reduction of greenhouse gas emissions and to combat climate change, the European Union (EU) introduced an Emissions Trading System (ETS) where organizations can buy or receive emission allowances as needed. The current ETS is a centralized one, consisting of a set of complex rules. It is currently administered at the organizational level and is used for fixed-point sources of pollution such as factories, power plants, and refineries. However, the current ETS cannot efficiently cope with vehicle mobility, even though vehicles are one of the primary sources of CO2 and NOx emissions. In this study, we propose a new distributed Blockchain-based emissions allowance trading system called B-ETS. This system enables transparent and trustworthy data exchange as well as trading of allowances among vehicles, relying on vehicle-to-vehicle communication. In addition, we introduce an economic incentive-based mechanism that appeals to individual drivers and leads them to modify their driving behavior in order to reduce emissions. The efficiency of the proposed system is studied through extensive simulations, showing how increased vehicle connectivity can lead to a reduction of the emissions generated from those vehicles. We demonstrate that our method can be used for full life-cycle monitoring and fuel economy reporting. This leads us to conjecture that the proposed system could lead to important behavioral changes among the drivers",
        "published": "2021-02-18T21:52:56Z",
        "link": "http://arxiv.org/abs/2102.13477v2",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "The Effectiveness of Subsidies and Tolls in Congestion Games",
        "authors": [
            "Bryce L. Ferguson",
            "Philip N. Brown",
            "Jason R. Marden"
        ],
        "summary": "Are rewards or penalties more effective in influencing user behavior? This work compares the effectiveness of subsidies and tolls in incentivizing user behavior in congestion games. The predominantly studied method of influencing user behavior in network routing problems is to institute taxes which alter users' observed costs in a manner that causes their self-interested choices to more closely align with a system-level objective. Another conceivable method to accomplish the same goal is to subsidize the users' actions that are preferable from a system-level perspective. We show that, when users behave similarly and predictably, subsidies offer superior performance guarantees to tolls under similar budgetary constraints; however, in the presence of unknown player heterogeneity, subsidies fail to offer the same robustness as tolls.",
        "published": "2021-02-18T22:48:27Z",
        "link": "http://arxiv.org/abs/2102.09655v1",
        "categories": [
            "cs.GT",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Sim-Env: Decoupling OpenAI Gym Environments from Simulation Models",
        "authors": [
            "Andreas Schuderer",
            "Stefano Bromuri",
            "Marko van Eekelen"
        ],
        "summary": "Reinforcement learning (RL) is one of the most active fields of AI research. Despite the interest demonstrated by the research community in reinforcement learning, the development methodology still lags behind, with a severe lack of standard APIs to foster the development of RL applications. OpenAI Gym is probably the most used environment to develop RL applications and simulations, but most of the abstractions proposed in such a framework are still assuming a semi-structured methodology. This is particularly relevant for agent-based models whose purpose is to analyse adaptive behaviour displayed by self-learning agents in the simulation. In order to bridge this gap, we present a workflow and tools for the decoupled development and maintenance of multi-purpose agent-based models and derived single-purpose reinforcement learning environments, enabling the researcher to swap out environments with ones representing different perspectives or different reward models, all while keeping the underlying domain model intact and separate. The Sim-Env Python library generates OpenAI-Gym-compatible reinforcement learning environments that use existing or purposely created domain models as their simulation back-ends. Its design emphasizes ease-of-use, modularity and code separation.",
        "published": "2021-02-19T09:25:21Z",
        "link": "http://arxiv.org/abs/2102.09824v2",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Latent Variable Sequential Set Transformers For Joint Multi-Agent Motion   Prediction",
        "authors": [
            "Roger Girgis",
            "Florian Golemo",
            "Felipe Codevilla",
            "Martin Weiss",
            "Jim Aldon D'Souza",
            "Samira Ebrahimi Kahou",
            "Felix Heide",
            "Christopher Pal"
        ],
        "summary": "Robust multi-agent trajectory prediction is essential for the safe control of robotic systems. A major challenge is to efficiently learn a representation that approximates the true joint distribution of contextual, social, and temporal information to enable planning. We propose Latent Variable Sequential Set Transformers which are encoder-decoder architectures that generate scene-consistent multi-agent trajectories. We refer to these architectures as \"AutoBots\". The encoder is a stack of interleaved temporal and social multi-head self-attention (MHSA) modules which alternately perform equivariant processing across the temporal and social dimensions. The decoder employs learnable seed parameters in combination with temporal and social MHSA modules allowing it to perform inference over the entire future scene in a single forward pass efficiently. AutoBots can produce either the trajectory of one ego-agent or a distribution over the future trajectories for all agents in the scene. For the single-agent prediction case, our model achieves top results on the global nuScenes vehicle motion prediction leaderboard, and produces strong results on the Argoverse vehicle prediction challenge. In the multi-agent setting, we evaluate on the synthetic partition of TrajNet++ dataset to showcase the model's socially-consistent predictions. We also demonstrate our model on general sequences of sets and provide illustrative experiments modelling the sequential structure of the multiple strokes that make up symbols in the Omniglot data. A distinguishing feature of AutoBots is that all models are trainable on a single desktop GPU (1080 Ti) in under 48h.",
        "published": "2021-02-19T18:53:26Z",
        "link": "http://arxiv.org/abs/2104.00563v3",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.CV",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Factored Policy Gradients: Leveraging Structure for Efficient Learning   in MOMDPs",
        "authors": [
            "Thomas Spooner",
            "Nelson Vadori",
            "Sumitra Ganesh"
        ],
        "summary": "Policy gradient methods can solve complex tasks but often fail when the dimensionality of the action-space or objective multiplicity grow very large. This occurs, in part, because the variance on score-based gradient estimators scales quadratically. In this paper, we address this problem through a factor baseline which exploits independence structure encoded in a novel action-target influence network. Factored policy gradients (FPGs), which follow, provide a common framework for analysing key state-of-the-art algorithms, are shown to generalise traditional policy gradients, and yield a principled way of incorporating prior knowledge of a problem domain's generative processes. We provide an analysis of the proposed estimator and identify the conditions under which variance is reduced. The algorithmic aspects of FPGs are discussed, including optimal policy factorisation, as characterised by minimum biclique coverings, and the implications for the bias-variance trade-off of incorrectly specifying the network. Finally, we demonstrate the performance advantages of our algorithm on large-scale bandit and traffic intersection problems, providing a novel contribution to the latter in the form of a spatial approximation.",
        "published": "2021-02-20T14:51:12Z",
        "link": "http://arxiv.org/abs/2102.10362v3",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Mastering Terra Mystica: Applying Self-Play to Multi-agent Cooperative   Board Games",
        "authors": [
            "Luis Perez"
        ],
        "summary": "In this paper, we explore and compare multiple algorithms for solving the complex strategy game of Terra Mystica, hereafter abbreviated as TM. Previous work in the area of super-human game-play using AI has proven effective, with recent break-through for generic algorithms in games such as Go, Chess, and Shogi \\cite{AlphaZero}. We directly apply these breakthroughs to a novel state-representation of TM with the goal of creating an AI that will rival human players. Specifically, we present the initial results of applying AlphaZero to this state-representation and analyze the strategies developed. A brief analysis is presented. We call this modified algorithm with our novel state-representation AlphaTM. In the end, we discuss the success and shortcomings of this method by comparing against multiple baselines and typical human scores. All code used for this paper is available at on \\href{https://github.com/kandluis/terrazero}{GitHub}.",
        "published": "2021-02-21T07:53:34Z",
        "link": "http://arxiv.org/abs/2102.10540v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.GT"
        ]
    },
    {
        "title": "Exerting Control in Repeated Social Dilemmas with Thresholds",
        "authors": [
            "Kathinka Frieswijk",
            "Alain Govaert",
            "Ming Cao"
        ],
        "summary": "Situations in which immediate self-interest and long-term collective interest conflict often require some form of influence to prevent them from leading to undesirable or unsustainable outcomes. Next to sanctioning, social influence and social structure, it is possible that strategic solutions can exist for these social dilemmas. However, the existence of strategies that enable a player to exert control in the long-run outcomes can be difficult to show and different situations allow for different levels of strategic influence. Here, we investigate the effect of threshold nonlinearities on the possibilities of exerting unilateral control in finitely repeated n-player public goods games and snowdrift games. These models can describe situations in which a collective effort is necessary in order for a benefit to be created. We identify conditions in terms of a cooperator threshold for the existence of generous, extortionate and equalizing zero-determinant (ZD) strategies. Our results show that, for both games, the thresholds prevent equalizing ZD strategies from existing. In the snowdrift game, introducing a cooperator threshold has no effect on the region of feasible extortionate ZD strategies. For extortionate strategies in the public goods game, the threshold only restricts the region of enforceable strategies for small values of the public goods multiplier. Generous ZD strategies exist for both games, but introducing a cooperator threshold forces the slope more towards the value of a fair strategy, where the player has approximately the same payoff as the average payoff of his opponents.",
        "published": "2021-02-21T09:56:32Z",
        "link": "http://arxiv.org/abs/2104.10639v1",
        "categories": [
            "cs.MA",
            "cs.GT"
        ]
    },
    {
        "title": "Dealing with Non-Stationarity in MARL via Trust-Region Decomposition",
        "authors": [
            "Wenhao Li",
            "Xiangfeng Wang",
            "Bo Jin",
            "Junjie Sheng",
            "Hongyuan Zha"
        ],
        "summary": "Non-stationarity is one thorny issue in cooperative multi-agent reinforcement learning (MARL). One of the reasons is the policy changes of agents during the learning process. Some existing works have discussed various consequences caused by non-stationarity with several kinds of measurement indicators. This makes the objectives or goals of existing algorithms are inevitably inconsistent and disparate. In this paper, we introduce a novel notion, the $\\delta$-measurement, to explicitly measure the non-stationarity of a policy sequence, which can be further proved to be bounded by the KL-divergence of consecutive joint policies. A straightforward but highly non-trivial way is to control the joint policies' divergence, which is difficult to estimate accurately by imposing the trust-region constraint on the joint policy. Although it has lower computational complexity to decompose the joint policy and impose trust-region constraints on the factorized policies, simple policy factorization like mean-field approximation will lead to more considerable policy divergence, which can be considered as the trust-region decomposition dilemma. We model the joint policy as a pairwise Markov random field and propose a trust-region decomposition network (TRD-Net) based on message passing to estimate the joint policy divergence more accurately. The Multi-Agent Mirror descent policy algorithm with Trust region decomposition, called MAMT, is established by adjusting the trust-region of the local policies adaptively in an end-to-end manner. MAMT can approximately constrain the consecutive joint policies' divergence to satisfy $\\delta$-stationarity and alleviate the non-stationarity problem. Our method can bring noticeable and stable performance improvement compared with baselines in cooperative tasks of different complexity.",
        "published": "2021-02-21T14:46:50Z",
        "link": "http://arxiv.org/abs/2102.10616v2",
        "categories": [
            "cs.LG",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Multi-Agent Consensus Subject to Communication and Privacy Constraints",
        "authors": [
            "Dipankar Maity",
            "Panagiotis Tsiotras"
        ],
        "summary": "We consider a multi-agent consensus problem in the presence of adversarial agents. The adversaries are able to listen to the inter-agent communications and try to estimate the state of the agents. The agents have a limited bit-rate for communication and are required to quantize the transmitted signal in order to meet the bit-rate constraint of the communication channel. We propose a consensus protocol that is protected against the adversaries, i.e., the expected mean-square error of the adversary state estimate is lower bounded. In order to deal with the bit-rate constraint, we propose a dynamic quantization scheme that guarantees protected consensus.",
        "published": "2021-02-21T16:46:09Z",
        "link": "http://arxiv.org/abs/2102.10642v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "A Game-Theoretic Approach for Hierarchical Epidemic Control",
        "authors": [
            "Feiran Jia",
            "Aditya Mate",
            "Zun Li",
            "Shahin Jabbari",
            "Mithun Chakraborty",
            "Milind Tambe",
            "Michael Wellman",
            "Yevgeniy Vorobeychik"
        ],
        "summary": "We design and analyze a multi-level game-theoretic model of hierarchical policy interventions for epidemic control, such as those in response to the COVID-19 pandemic. Our model captures the potentially mismatched priorities among a hierarchy of policy-makers (e.g., federal, state, and local governments) with respect to two cost components that have opposite dependence on the policy strength -- post-intervention infection rates and the socio-economic cost of policy implementation. Additionally, our model includes a crucial third factor in decisions: a cost of non-compliance with the policy-maker immediately above in the hierarchy, such as non-compliance of counties with state-level policies. We propose two novel algorithms for approximating solutions to such games. The first is based on best response dynamics (BRD), and exploits the tree structure of the game. The second combines quadratic integer programming (QIP), which enables us to collapse the two lowest levels of the game, with best response dynamics. Through extensive experiments, we show that our QIP-based approach significantly outperforms the BRD algorithm both in running time and the quality of equilibrium solutions. Finally, we apply the QIP-based algorithm to experiments based on both synthetic and real-world data under various parameter configurations and analyze the resulting (approximate) equilibria to gain insight into the impact of decentralization on overall welfare (measured as the negative sum of costs) as well as emergent properties like free-riding and fairness in cost distribution among policy-makers.",
        "published": "2021-02-21T17:01:34Z",
        "link": "http://arxiv.org/abs/2102.10646v2",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Communication Efficient Parallel Reinforcement Learning",
        "authors": [
            "Mridul Agarwal",
            "Bhargav Ganguly",
            "Vaneet Aggarwal"
        ],
        "summary": "We consider the problem where $M$ agents interact with $M$ identical and independent environments with $S$ states and $A$ actions using reinforcement learning for $T$ rounds. The agents share their data with a central server to minimize their regret. We aim to find an algorithm that allows the agents to minimize the regret with infrequent communication rounds. We provide \\NAM\\ which runs at each agent and prove that the total cumulative regret of $M$ agents is upper bounded as $\\Tilde{O}(DS\\sqrt{MAT})$ for a Markov Decision Process with diameter $D$, number of states $S$, and number of actions $A$. The agents synchronize after their visitations to any state-action pair exceeds a certain threshold. Using this, we obtain a bound of $O\\left(MSA\\log(MT)\\right)$ on the total number of communications rounds. Finally, we evaluate the algorithm against multiple environments and demonstrate that the proposed algorithm performs at par with an always communication version of the UCRL2 algorithm, while with significantly lower communication.",
        "published": "2021-02-22T02:46:36Z",
        "link": "http://arxiv.org/abs/2102.10740v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "CoinTossX: An open-source low-latency high-throughput matching engine",
        "authors": [
            "Ivan Jericevich",
            "Dharmesh Sing",
            "Tim Gebbie"
        ],
        "summary": "We deploy and demonstrate the CoinTossX low-latency, high-throughput, open-source matching engine with orders sent using the Julia and Python languages. We show how this can be deployed for small-scale local desk-top testing and discuss a larger scale, but local hosting, with multiple traded instruments managed concurrently and managed by multiple clients. We then demonstrate a cloud based deployment using Microsoft Azure, with large-scale industrial and simulation research use cases in mind. The system is exposed and interacted with via sockets using UDP SBE message protocols and can be monitored using a simple web browser interface using HTTP. We give examples showing how orders can be be sent to the system and market data feeds monitored using the Julia and Python languages. The system is developed in Java with orders submitted as binary encodings (SBE) via UDP protocols using the Aeron Media Driver as the low-latency, high throughput message transport. The system separates the order-generation and simulation environments e.g. agent-based model simulation, from the matching of orders, data-feeds and various modularised components of the order-book system. This ensures a more natural and realistic asynchronicity between events generating orders, and the events associated with order-book dynamics and market data-feeds. We promote the use of Julia as the preferred order submission and simulation environment.",
        "published": "2021-02-22T11:50:34Z",
        "link": "http://arxiv.org/abs/2102.10925v1",
        "categories": [
            "cs.DC",
            "cs.MA",
            "q-fin.CP",
            "q-fin.TR"
        ]
    },
    {
        "title": "Models we Can Trust: Toward a Systematic Discipline of (Agent-Based)   Model Interpretation and Validation",
        "authors": [
            "Gabriel Istrate"
        ],
        "summary": "We advocate the development of a discipline of interacting with and extracting information from models, both mathematical (e.g. game-theoretic ones) and computational (e.g. agent-based models). We outline some directions for the development of a such a discipline:   - the development of logical frameworks for the systematic formal specification of stylized facts and social mechanisms in (mathematical and computational) social science. Such frameworks would bring to attention new issues, such as phase transitions, i.e. dramatical changes in the validity of the stylized facts beyond some critical values in parameter space. We argue that such statements are useful for those logical frameworks describing properties of ABM.   - the adaptation of tools from the theory of reactive systems (such as bisimulation) to obtain practically relevant notions of two systems \"having the same behavior\".   - the systematic development of an adversarial theory of model perturbations, that investigates the robustness of conclusions derived from models of social behavior to variations in several features of the social dynamics. These may include: activation order, the underlying social network, individual agent behavior.",
        "published": "2021-02-23T10:52:22Z",
        "link": "http://arxiv.org/abs/2102.11615v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Greedy-Step Off-Policy Reinforcement Learning",
        "authors": [
            "Yuhui Wang",
            "Qingyuan Wu",
            "Pengcheng He",
            "Xiaoyang Tan"
        ],
        "summary": "Most of the policy evaluation algorithms are based on the theories of Bellman Expectation and Optimality Equation, which derive two popular approaches - Policy Iteration (PI) and Value Iteration (VI). However, multi-step bootstrapping is often at cross-purposes with and off-policy learning in PI-based methods due to the large variance of multi-step off-policy correction. In contrast, VI-based methods are naturally off-policy but subject to one-step learning.In this paper, we deduce a novel multi-step Bellman Optimality Equation by utilizing a latent structure of multi-step bootstrapping with the optimal value function. Via this new equation, we derive a new multi-step value iteration method that converges to the optimal value function with exponential contraction rate $\\mathcal{O}(\\gamma^n)$ but only linear computational complexity. Moreover, it can naturally derive a suite of multi-step off-policy algorithms that can safely utilize data collected by arbitrary policies without correction.Experiments reveal that the proposed methods are reliable, easy to implement and achieve state-of-the-art performance on a series of standard benchmark datasets.",
        "published": "2021-02-23T14:32:20Z",
        "link": "http://arxiv.org/abs/2102.11717v4",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "School of hard knocks: Curriculum analysis for Pommerman with a fixed   computational budget",
        "authors": [
            "Omkar Shelke",
            "Hardik Meisheri",
            "Harshad Khadilkar"
        ],
        "summary": "Pommerman is a hybrid cooperative/adversarial multi-agent environment, with challenging characteristics in terms of partial observability, limited or no communication, sparse and delayed rewards, and restrictive computational time limits. This makes it a challenging environment for reinforcement learning (RL) approaches. In this paper, we focus on developing a curriculum for learning a robust and promising policy in a constrained computational budget of 100,000 games, starting from a fixed base policy (which is itself trained to imitate a noisy expert policy). All RL algorithms starting from the base policy use vanilla proximal-policy optimization (PPO) with the same reward function, and the only difference between their training is the mix and sequence of opponent policies. One expects that beginning training with simpler opponents and then gradually increasing the opponent difficulty will facilitate faster learning, leading to more robust policies compared against a baseline where all available opponent policies are introduced from the start. We test this hypothesis and show that within constrained computational budgets, it is in fact better to \"learn in the school of hard knocks\", i.e., against all available opponent policies nearly from the start. We also include ablation studies where we study the effect of modifying the base environment properties of ammo and bomb blast strength on the agent performance.",
        "published": "2021-02-23T15:43:09Z",
        "link": "http://arxiv.org/abs/2102.11762v2",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Dynamic Games among Teams with Delayed Intra-Team Information Sharing",
        "authors": [
            "Dengwang Tang",
            "Hamidreza Tavafoghi",
            "Vijay Subramanian",
            "Ashutosh Nayyar",
            "Demosthenis Teneketzis"
        ],
        "summary": "We analyze a class of stochastic dynamic games among teams with asymmetric information, where members of a team share their observations internally with a delay of $d$. Each team is associated with a controlled Markov Chain, whose dynamics are coupled through the players' actions. These games exhibit challenges in both theory and practice due to the presence of signaling and the increasing domain of information over time. We develop a general approach to characterize a subset of Nash Equilibria where the agents can use a compressed version of their information, instead of the full information, to choose their actions. We identify two subclasses of strategies: Sufficient Private Information Based (SPIB) strategies, which only compress private information, and Compressed Information Based (CIB) strategies, which compress both common and private information. We show that while SPIB-strategy-based equilibria always exist, the same is not true for CIB-strategy-based equilibria. We develop a backward inductive sequential procedure, whose solution (if it exists) provides a CIB strategy-based equilibrium. We identify some instances where we can guarantee the existence of a solution to the above procedure. Our results highlight the tension among compression of information, existence of (compression based) equilibria, and backward inductive sequential computation of such equilibria in stochastic dynamic games with asymmetric information.",
        "published": "2021-02-23T20:06:56Z",
        "link": "http://arxiv.org/abs/2102.11920v2",
        "categories": [
            "cs.MA",
            "cs.GT",
            "math.OC"
        ]
    },
    {
        "title": "PolicySpace2: modeling markets and endogenous public policies",
        "authors": [
            "Bernardo Alves Furtado"
        ],
        "summary": "Policymakers decide on alternative policies facing restricted budgets and uncertain, ever-changing future. Designing public policies is further difficult due to the need to decide on priorities and handle effects across policies. Housing policies, specifically, involve heterogeneous characteristics of properties themselves and the intricacy of housing markets and the spatial context of cities. We propose PolicySpace2 (PS2) as an adapted and extended version of the open source PolicySpace agent-based model. PS2 is a computer simulation that relies on empirically detailed spatial data to model real estate, along with labor, credit, and goods and services markets. Interaction among workers, firms, a bank, households and municipalities follow the literature benchmarks to integrate economic, spatial and transport scholarship. PS2 is applied to a comparison among three competing public policies aimed at reducing inequality and alleviating poverty: (a) house acquisition by the government and distribution to lower income households, (b) rental vouchers, and (c) monetary aid. Within the model context, the monetary aid, that is, smaller amounts of help for a larger number of households, makes the economy perform better in terms of production, consumption, reduction of inequality, and maintenance of financial duties. PS2 as such is also a framework that may be further adapted to a number of related research questions.",
        "published": "2021-02-23T20:29:59Z",
        "link": "http://arxiv.org/abs/2102.11929v4",
        "categories": [
            "cs.MA",
            "econ.GN",
            "physics.soc-ph",
            "q-fin.EC"
        ]
    },
    {
        "title": "Cellular Automata and Kan Extensions",
        "authors": [
            "Alexandre Fernandez",
            "Luidnel Maignan",
            "Antoine Spicher"
        ],
        "summary": "In this paper, we formalize precisely the sense in which the application of cellular automaton to partial configuration is a natural extension of its local transition function through the categorical notion of Kan extension. In fact, the two possible ways to do such an extension and the ingredients involved in their definition are related through Kan extensions in many ways. These relations provide additional links between computer science and category theory, and also give a new point of view on the famous Curtis-Hedlung theorem of cellular automata from the extended topological point of view provided by category theory. These relations provide additional links between computer science and category theory. No prior knowledge of category theory is assumed.",
        "published": "2021-02-24T09:24:40Z",
        "link": "http://arxiv.org/abs/2102.12156v2",
        "categories": [
            "cs.DC",
            "cs.MA",
            "math.CT",
            "math.DS",
            "nlin.CG"
        ]
    },
    {
        "title": "Credit Assignment with Meta-Policy Gradient for Multi-Agent   Reinforcement Learning",
        "authors": [
            "Jianzhun Shao",
            "Hongchang Zhang",
            "Yuhang Jiang",
            "Shuncheng He",
            "Xiangyang Ji"
        ],
        "summary": "Reward decomposition is a critical problem in centralized training with decentralized execution~(CTDE) paradigm for multi-agent reinforcement learning. To take full advantage of global information, which exploits the states from all agents and the related environment for decomposing Q values into individual credits, we propose a general meta-learning-based Mixing Network with Meta Policy Gradient~(MNMPG) framework to distill the global hierarchy for delicate reward decomposition. The excitation signal for learning global hierarchy is deduced from the episode reward difference between before and after \"exercise updates\" through the utility network. Our method is generally applicable to the CTDE method using a monotonic mixing network. Experiments on the StarCraft II micromanagement benchmark demonstrate that our method just with a simple utility network is able to outperform the current state-of-the-art MARL algorithms on 4 of 5 super hard scenarios. Better performance can be further achieved when combined with a role-based utility network.",
        "published": "2021-02-24T12:03:37Z",
        "link": "http://arxiv.org/abs/2102.12957v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Balancing Rational and Other-Regarding Preferences in   Cooperative-Competitive Environments",
        "authors": [
            "Dmitry Ivanov",
            "Vladimir Egorov",
            "Aleksei Shpilman"
        ],
        "summary": "Recent reinforcement learning studies extensively explore the interplay between cooperative and competitive behaviour in mixed environments. Unlike cooperative environments where agents strive towards a common goal, mixed environments are notorious for the conflicts of selfish and social interests. As a consequence, purely rational agents often struggle to achieve and maintain cooperation. A prevalent approach to induce cooperative behaviour is to assign additional rewards based on other agents' well-being. However, this approach suffers from the issue of multi-agent credit assignment, which can hinder performance. This issue is efficiently alleviated in cooperative setting with such state-of-the-art algorithms as QMIX and COMA. Still, when applied to mixed environments, these algorithms may result in unfair allocation of rewards. We propose BAROCCO, an extension of these algorithms capable to balance individual and social incentives. The mechanism behind BAROCCO is to train two distinct but interwoven components that jointly affect each agent's decisions. Our meta-algorithm is compatible with both Q-learning and Actor-Critic frameworks. We experimentally confirm the advantages over the existing methods and explore the behavioural aspects of BAROCCO in two mixed multi-agent setups.",
        "published": "2021-02-24T14:35:32Z",
        "link": "http://arxiv.org/abs/2102.12307v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Modelling SARS-CoV-2 coevolution with genetic algorithms",
        "authors": [
            "Aymeric Vie"
        ],
        "summary": "At the end of 2020, policy responses to the SARS-CoV-2 outbreak have been shaken by the emergence of virus variants, impacting public health and policy measures worldwide. The emergence of these strains suspected to be more contagious, more severe, or even resistant to antibodies and vaccines, seem to have taken by surprise health services and policymakers, struggling to adapt to the new variants constraints. Anticipating the emergence of these mutations to plan ahead adequate policies, and understanding how human behaviors may affect the evolution of viruses by coevolution, are key challenges. In this article, we propose coevolution with genetic algorithms (GAs) as a credible approach to model this relationship, highlighting its implications, potential and challenges. Because of their qualities of exploration of large spaces of possible solutions, capacity to generate novelty, and natural genetic focus, GAs are relevant for this issue. We present a dual GA model in which both viruses aiming for survival and policy measures aiming at minimising infection rates in the population, competitively evolve. This artificial coevolution system may offer us a laboratory to \"debug\" our current policy measures, identify the weaknesses of our current strategies, and anticipate the evolution of the virus to plan ahead relevant policies. It also constitutes a decisive opportunity to develop new genetic algorithms capable of simulating much more complex objects. We highlight some structural innovations for GAs for that virus evolution context that may carry promising developments in evolutionary computation, artificial life and AI.",
        "published": "2021-02-24T15:49:20Z",
        "link": "http://arxiv.org/abs/2102.12365v1",
        "categories": [
            "cs.NE",
            "cs.MA",
            "q-bio.PE"
        ]
    },
    {
        "title": "MAPFAST: A Deep Algorithm Selector for Multi Agent Path Finding using   Shortest Path Embeddings",
        "authors": [
            "Jingyao Ren",
            "Vikraman Sathiyanarayanan",
            "Eric Ewing",
            "Baskin Senbaslar",
            "Nora Ayanian"
        ],
        "summary": "Solving the Multi-Agent Path Finding (MAPF) problem optimally is known to be NP-Hard for both make-span and total arrival time minimization. While many algorithms have been developed to solve MAPF problems, there is no dominating optimal MAPF algorithm that works well in all types of problems and no standard guidelines for when to use which algorithm. In this work, we develop the deep convolutional network MAPFAST (Multi-Agent Path Finding Algorithm SelecTor), which takes a MAPF problem instance and attempts to select the fastest algorithm to use from a portfolio of algorithms. We improve the performance of our model by including single-agent shortest paths in the instance embedding given to our model and by utilizing supplemental loss functions in addition to a classification loss. We evaluate our model on a large and diverse dataset of MAPF instances, showing that it outperforms all individual algorithms in its portfolio as well as the state-of-the-art optimal MAPF algorithm selector. We also provide an analysis of algorithm behavior in our dataset to gain a deeper understanding of optimal MAPF algorithms' strengths and weaknesses to help other researchers leverage different heuristics in algorithm designs.",
        "published": "2021-02-24T18:41:37Z",
        "link": "http://arxiv.org/abs/2102.12461v2",
        "categories": [
            "cs.MA",
            "cs.LG"
        ]
    },
    {
        "title": "Learning Emergent Discrete Message Communication for Cooperative   Reinforcement Learning",
        "authors": [
            "Sheng Li",
            "Yutai Zhou",
            "Ross Allen",
            "Mykel J. Kochenderfer"
        ],
        "summary": "Communication is a important factor that enables agents work cooperatively in multi-agent reinforcement learning (MARL). Most previous work uses continuous message communication whose high representational capacity comes at the expense of interpretability. Allowing agents to learn their own discrete message communication protocol emerged from a variety of domains can increase the interpretability for human designers and other agents.This paper proposes a method to generate discrete messages analogous to human languages, and achieve communication by a broadcast-and-listen mechanism based on self-attention. We show that discrete message communication has performance comparable to continuous message communication but with much a much smaller vocabulary size.Furthermore, we propose an approach that allows humans to interactively send discrete messages to agents.",
        "published": "2021-02-24T20:44:14Z",
        "link": "http://arxiv.org/abs/2102.12550v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Active Modular Environment for Robot Navigation",
        "authors": [
            "Shota Kameyama",
            "Keisuke Okumura",
            "Yasumasa Tamura",
            "Xavier Défago"
        ],
        "summary": "This paper presents a novel robot-environment interaction in navigation tasks such that robots have neither a representation of their working space nor planning function, instead, an active environment takes charge of these aspects. This is realized by spatially deploying computing units, called cells, and making cells manage traffic in their respective physical region. Different from stigmegic approaches, cells interact with each other to manage environmental information and to construct instructions on how robots move.   As a proof-of-concept, we present an architecture called AFADA and its prototype, consisting of modular cells and robots moving on the cells. The instructions from cells are based on a distributed routing algorithm and a reservation protocol. We demonstrate that AFADA achieves efficient robot moves for single-robot navigation in a dynamic environment changing its topology with a stochastic model, comparing to self-navigation by a robot itself. This is followed by several demos, including multi-robot navigation, highlighting the power of offloading both representation and planning from robots to the environment. We expect that the concept of AFADA contributes to developing the infrastructure for multiple robots because it can engage online and lifelong planning and execution.",
        "published": "2021-02-25T09:23:17Z",
        "link": "http://arxiv.org/abs/2102.12748v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Maximizing Social Welfare and Agreement via Information Design in   Linear-Quadratic-Gaussian Games",
        "authors": [
            "Furkan Sezer",
            "Hossein Khazaei",
            "Ceyhun Eksin"
        ],
        "summary": "We consider linear-quadratic Gaussian (LQG) games in which players have quadratic payoffs that depend on the players' actions and an unknown payoff-relevant state, and signals on the state that follow a Gaussian distribution conditional on the state realization. An information designer decides the fidelity of information revealed to the players in order to maximize the social welfare of the players or reduce the disagreement among players' actions. Leveraging the semi-definiteness of the information design problem, we derive analytical solutions for these objectives under specific LQG games. We show that full information disclosure maximizes social welfare when there is a common payoff-relevant state, when there is strategic substitutability in the actions of players, or when the signals are public. Numerical results show that as strategic substitution increases, the value of the information disclosure increases. When the objective is to induce conformity among players' actions, hiding information is optimal. Lastly, we consider the information design objective that is a weighted combination of social welfare and cohesiveness of players' actions. We obtain an interval for the weights where full information disclosure is optimal under public signals for games with strategic substitutability. Numerical solutions show that the actual interval where full information disclosure is optimal gets close to the analytical interval obtained as substitution increases.",
        "published": "2021-02-25T17:56:39Z",
        "link": "http://arxiv.org/abs/2102.13047v2",
        "categories": [
            "math.OC",
            "cs.MA",
            "cs.SY",
            "econ.GN",
            "eess.SY",
            "q-fin.EC"
        ]
    },
    {
        "title": "V-RVO: Decentralized Multi-Agent Collision Avoidance using Voronoi   Diagrams and Reciprocal Velocity Obstacles",
        "authors": [
            "Senthil Hariharan Arul",
            "Dinesh Manocha"
        ],
        "summary": "We present a decentralized collision avoidance method for dense environments that is based on buffered Voronoi cells (BVC) and reciprocal velocity obstacles (RVO). Our approach is designed for scenarios with large number of close proximity agents and provides passive-friendly collision avoidance guarantees. The Voronoi cells are superimposed with RVO cones to compute a suitable direction for each agent and we use that direction for computing a local collision-free path. Our approach can satisfy double-integrator dynamics constraints and we use the properties of the BVC to formulate a simple, decentralized deadlock resolution strategy. We demonstrate the benefits of V-RVO in complex scenarios with tens of agents in close proximity. In practice, V-RVO's performance is comparable to prior velocity-obstacle methods and the collision avoidance behavior is significantly less conservative than ORCA.",
        "published": "2021-02-26T02:56:42Z",
        "link": "http://arxiv.org/abs/2102.13281v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Engineering Swarms of Cyber-Physical Systems with the CPSwarm Workbench",
        "authors": [
            "Micha Sende",
            "Melanie Schranz",
            "Gianluca Prato",
            "Etienne Brosse",
            "Omar Morando",
            "Martina Umlauft"
        ],
        "summary": "Engineering swarms of cyber-physical systems (CPSs) is a complex process. We present the CPSwarm workbench that creates an automated design workflow to ease this process. This formalized workflow guides the user from modeling, to code generation, to deployment, both in simulation and on CPS hardware platforms. The workbench combines existing and emerging tools to solve real-world CPS swarm problems. As a proof-of-concept, we use the workbench to design a swarm of unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs) for a search and rescue (SAR) use case. We evaluate the resulting swarm behaviors on three levels. First, abstract simulations for rapid prototyping. Second, detailed simulation to test the correctness of the results. Third, deployment on hardware to demonstrate the applicability. We measure the swarm performance in terms of area covered and victims rescued. The results show that the performance of the swarm is proportional to its size. Despite some manual steps, the proposed workbench shows to be well suited to ease the complicated task of deploying a swarm of CPSs.",
        "published": "2021-02-26T08:01:08Z",
        "link": "http://arxiv.org/abs/2102.13351v1",
        "categories": [
            "cs.MA",
            "68T40"
        ]
    },
    {
        "title": "Morning commute in congested urban rail transit system: A macroscopic   model for equilibrium distribution of passenger arrivals",
        "authors": [
            "Jiahua Zhang",
            "Kentaro Wada",
            "Takashi Oguchi"
        ],
        "summary": "This paper proposes a macroscopic model to describe the equilibrium distribution of passenger arrivals for the morning commute problem in a congested urban rail transit system. We use a macroscopic train operation sub-model developed by Seo et al (2017a,b) to express the interaction between the dynamics of passengers and trains in a simplified manner while maintaining their essential physical relations. The equilibrium conditions of the proposed model are derived and a solution method is provided. The characteristics of the equilibrium are then examined through analytical discussion and numerical examples. As an application of the proposed model, we analyze a simple time-dependent timetable optimization problem with equilibrium constraints and reveal that a \"capacity increasing paradox\" exists such that a higher dispatch frequency can increase the equilibrium cost. Furthermore, insights into the design of the timetable are obtained and the timetable influence on passengers' equilibrium travel costs are evaluated.",
        "published": "2021-02-26T13:18:12Z",
        "link": "http://arxiv.org/abs/2102.13454v2",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY",
            "physics.soc-ph"
        ]
    },
    {
        "title": "Collisionless and Decentralized Formation Control for Strings",
        "authors": [
            "Young-Pil Choi",
            "Dante Kalise",
            "Andrés A. Peters"
        ],
        "summary": "A decentralized feedback controller for multi-agent systems, inspired by vehicle platooning, is proposed. The closed-loop resulting from the decentralized control action has three distinctive features: the generation of collision-free trajectories, flocking of the system towards a consensus state in velocity, and asymptotic convergence to a prescribed pattern of distances between agents. For each feature, a rigorous dynamical analysis is provided, yielding a characterization of the set of parameters and initial configurations where collision avoidance, flocking, and pattern formation is guaranteed. Numerical tests assess the theoretical results presented.",
        "published": "2021-02-26T17:39:32Z",
        "link": "http://arxiv.org/abs/2102.13621v1",
        "categories": [
            "math.OC",
            "cs.MA",
            "math.DS",
            "nlin.AO"
        ]
    },
    {
        "title": "Cognitive Homeostatic Agents",
        "authors": [
            "Amol Kelkar"
        ],
        "summary": "Human brain has been used as an inspiration for building autonomous agents, but it is not obvious what level of computational description of the brain one should use. This has led to overly opinionated symbolic approaches and overly unstructured connectionist approaches. We propose that using homeostasis as the computational description provides a good compromise. Similar to how physiological homeostasis is the regulation of certain homeostatic variables, cognition can be interpreted as the regulation of certain 'cognitive homeostatic variables'. We present an outline of a Cognitive Homeostatic Agent, built as a hierarchy of physiological and cognitive homeostatic subsystems and describe structures and processes to guide future exploration. We expect this to be a fruitful line of investigation towards building sophisticated artificial agents that can act flexibly in complex environments, and produce behaviors indicating planning, thinking and feelings.",
        "published": "2021-02-27T07:29:43Z",
        "link": "http://arxiv.org/abs/2103.03359v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "cs.NE"
        ]
    },
    {
        "title": "Time Matters: Exploring the Effects of Urgency and Reaction Speed in   Automated Traders",
        "authors": [
            "Henry Hanifan",
            "Ben Watson",
            "John Cartlidge",
            "Dave Cliff"
        ],
        "summary": "We consider issues of time in automated trading strategies in simulated financial markets containing a single exchange with public limit order book and continuous double auction matching. In particular, we explore two effects: (i) reaction speed - the time taken for trading strategies to calculate a response to market events; and (ii) trading urgency - the sensitivity of trading strategies to approaching deadlines. Much of the literature on trading agents focuses on optimising pricing strategies only and ignores the effects of time, while real-world markets continue to experience a race to zero latency, as automated trading systems compete to quickly access information and act in the market ahead of others. We demonstrate that modelling reaction speed can significantly alter previously published results, with simple strategies such as SHVR outperforming more complex adaptive algorithms such as AA. We also show that adding a pace parameter to ZIP traders (ZIP-Pace, or ZIPP) can create a sense of urgency that significantly improves profitability.",
        "published": "2021-02-28T19:38:52Z",
        "link": "http://arxiv.org/abs/2103.00600v1",
        "categories": [
            "cs.MA",
            "cs.CE",
            "q-fin.CP",
            "q-fin.TR"
        ]
    },
    {
        "title": "A multi-layer network model to assess school opening policies during the   COVID-19 vaccination campaign",
        "authors": [
            "Christian Bongiorno",
            "Lorenzo Zino"
        ],
        "summary": "We propose a multi-layer network model for the spread of COVID-19 that accounts for interactions within the family, between schoolmates, and casual contacts in the population. We utilize the proposed model-calibrated on epidemiological and demographic data-to investigate current questions concerning the implementation of non-pharmaceutical interventions (NPIs) during the vaccination campaign. Specifically, we consider scenarios in which the most fragile population has already received the vaccine, and we focus our analysis on the role of schools as drivers of the contagions and on the implementation of targeted intervention policies oriented to children and their families. We perform our analysis by means of a campaign of Monte Carlo simulations. Our findings suggest that, in a phase with NPIs enacted but in-person education, children play a key role in the spreading of COVID-19. Interestingly, we show that children's testing might be an important tool to flatten the epidemic curve, in particular when combined with enacting temporary online education for classes in which infected students are detected. Finally, we test a vaccination strategy that prioritizes the members of large families and we demonstrate its good performance. We believe that our modeling framework and our findings could be of help for public health authorities for planning their current and future interventions, as well as to increase preparedness for future epidemic outbreaks.",
        "published": "2021-03-02T07:53:44Z",
        "link": "http://arxiv.org/abs/2103.12519v1",
        "categories": [
            "physics.soc-ph",
            "cs.MA"
        ]
    },
    {
        "title": "Sparse Training Theory for Scalable and Efficient Agents",
        "authors": [
            "Decebal Constantin Mocanu",
            "Elena Mocanu",
            "Tiago Pinto",
            "Selima Curci",
            "Phuong H. Nguyen",
            "Madeleine Gibescu",
            "Damien Ernst",
            "Zita A. Vale"
        ],
        "summary": "A fundamental task for artificial intelligence is learning. Deep Neural Networks have proven to cope perfectly with all learning paradigms, i.e. supervised, unsupervised, and reinforcement learning. Nevertheless, traditional deep learning approaches make use of cloud computing facilities and do not scale well to autonomous agents with low computational resources. Even in the cloud, they suffer from computational and memory limitations, and they cannot be used to model adequately large physical worlds for agents which assume networks with billions of neurons. These issues are addressed in the last few years by the emerging topic of sparse training, which trains sparse networks from scratch. This paper discusses sparse training state-of-the-art, its challenges and limitations while introducing a couple of new theoretical research directions which has the potential of alleviating sparse training limitations to push deep learning scalability well beyond its current boundaries. Nevertheless, the theoretical advancements impact in complex multi-agents settings is discussed from a real-world perspective, using the smart grid case study.",
        "published": "2021-03-02T10:48:29Z",
        "link": "http://arxiv.org/abs/2103.01636v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "cs.NE"
        ]
    },
    {
        "title": "The Surprising Effectiveness of PPO in Cooperative, Multi-Agent Games",
        "authors": [
            "Chao Yu",
            "Akash Velu",
            "Eugene Vinitsky",
            "Jiaxuan Gao",
            "Yu Wang",
            "Alexandre Bayen",
            "Yi Wu"
        ],
        "summary": "Proximal Policy Optimization (PPO) is a ubiquitous on-policy reinforcement learning algorithm but is significantly less utilized than off-policy learning algorithms in multi-agent settings. This is often due to the belief that PPO is significantly less sample efficient than off-policy methods in multi-agent systems. In this work, we carefully study the performance of PPO in cooperative multi-agent settings. We show that PPO-based multi-agent algorithms achieve surprisingly strong performance in four popular multi-agent testbeds: the particle-world environments, the StarCraft multi-agent challenge, Google Research Football, and the Hanabi challenge, with minimal hyperparameter tuning and without any domain-specific algorithmic modifications or architectures. Importantly, compared to competitive off-policy methods, PPO often achieves competitive or superior results in both final returns and sample efficiency. Finally, through ablation studies, we analyze implementation and hyperparameter factors that are critical to PPO's empirical performance, and give concrete practical suggestions regarding these factors. Our results show that when using these practices, simple PPO-based methods can be a strong baseline in cooperative multi-agent reinforcement learning. Source code is released at \\url{https://github.com/marlbenchmark/on-policy}.",
        "published": "2021-03-02T18:59:56Z",
        "link": "http://arxiv.org/abs/2103.01955v4",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Adversarial Environment Generation for Learning to Navigate the Web",
        "authors": [
            "Izzeddin Gur",
            "Natasha Jaques",
            "Kevin Malta",
            "Manoj Tiwari",
            "Honglak Lee",
            "Aleksandra Faust"
        ],
        "summary": "Learning to autonomously navigate the web is a difficult sequential decision making task. The state and action spaces are large and combinatorial in nature, and websites are dynamic environments consisting of several pages. One of the bottlenecks of training web navigation agents is providing a learnable curriculum of training environments that can cover the large variety of real-world websites. Therefore, we propose using Adversarial Environment Generation (AEG) to generate challenging web environments in which to train reinforcement learning (RL) agents. We provide a new benchmarking environment, gMiniWoB, which enables an RL adversary to use compositional primitives to learn to generate arbitrarily complex websites. To train the adversary, we propose a new technique for maximizing regret using the difference in the scores obtained by a pair of navigator agents. Our results show that our approach significantly outperforms prior methods for minimax regret AEG. The regret objective trains the adversary to design a curriculum of environments that are \"just-the-right-challenge\" for the navigator agents; our results show that over time, the adversary learns to generate increasingly complex web navigation tasks. The navigator agents trained with our technique learn to complete challenging, high-dimensional web navigation tasks, such as form filling, booking a flight etc. We show that the navigator agent trained with our proposed Flexible b-PAIRED technique significantly outperforms competitive automatic curriculum generation baselines -- including a state-of-the-art RL web navigation approach -- on a set of challenging unseen test environments, and achieves more than 80% success rate on some tasks.",
        "published": "2021-03-02T19:19:30Z",
        "link": "http://arxiv.org/abs/2103.01991v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "A Game-Theoretic Analysis of Cross-Ledger Swaps with Packetized Payments",
        "authors": [
            "Alevtina Dubovitskaya",
            "Damien Ackerer",
            "Jiahua Xu"
        ],
        "summary": "We propose a game-theoretic framework to study the outcomes of packetized payments, a cross-ledger transaction protocol, with strategic and possibly malicious agents. We derive the transaction failure rate and demonstrate that without disciplinary mechanisms, packetized payments are likely to be incomplete. Our analysis suggests that collateral deposits can prevent malicious agents from taking advantage of the protocol. We further infer that the deposit amount should depend on the underlying asset price volatility or that it should be dynamically adjusted as the price changes.",
        "published": "2021-03-02T22:12:20Z",
        "link": "http://arxiv.org/abs/2103.02056v3",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Inference-Based Deterministic Messaging For Multi-Agent Communication",
        "authors": [
            "Varun Bhatt",
            "Michael Buro"
        ],
        "summary": "Communication is essential for coordination among humans and animals. Therefore, with the introduction of intelligent agents into the world, agent-to-agent and agent-to-human communication becomes necessary. In this paper, we first study learning in matrix-based signaling games to empirically show that decentralized methods can converge to a suboptimal policy. We then propose a modification to the messaging policy, in which the sender deterministically chooses the best message that helps the receiver to infer the sender's observation. Using this modification, we see, empirically, that the agents converge to the optimal policy in nearly all the runs. We then apply this method to a partially observable gridworld environment which requires cooperation between two agents and show that, with appropriate approximation methods, the proposed sender modification can enhance existing decentralized training methods for more complex domains as well.",
        "published": "2021-03-03T03:09:22Z",
        "link": "http://arxiv.org/abs/2103.02150v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Cellular Formation Maintenance and Collision Avoidance Using   Centroid-Based Point Set Registration in a Swarm of Drones",
        "authors": [
            "Jawad N. Yasin",
            "Huma Mahboob",
            "Mohammad-Hashem Haghbayan",
            "Muhammad Mehboob Yasin",
            "Juha Plosila"
        ],
        "summary": "This work focuses on low-energy collision avoidance and formation maintenance in autonomous swarms of drones. Here, the two main problems are: 1) how to avoid collisions by temporarily breaking the formation, i.e., collision avoidance reformation, and 2) how do such reformation while minimizing the deviation resulting in minimization of the overall time and energy consumption of the drones. To address the first question, we use cellular automata based technique to find an efficient formation that avoids the obstacle while minimizing the time and energy. Concerning the second question, a near-optimal reformation of the swarm after successful collision avoidance is achieved by applying a temperature function reduction technique, originally used in the point set registration process. The goal of the reformation process is to remove the disturbance while minimizing the overall time it takes for the swarm to reach the destination and consequently reducing the energy consumption required by this operation. To measure the degree of formation disturbance due to collision avoidance, deviation of the centroid of the swarm formation is used, inspired by the concept of the center of mass in classical mechanics. Experimental results show the efficiency of the proposed technique, in terms of performance and energy.",
        "published": "2021-03-03T15:47:53Z",
        "link": "http://arxiv.org/abs/2103.02480v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Resilient Active Information Acquisition with Teams of Robots",
        "authors": [
            "Brent Schlotfeldt",
            "Vasileios Tzoumas",
            "George J. Pappas"
        ],
        "summary": "Emerging applications of collaborative autonomy, such as Multi-Target Tracking, Unknown Map Exploration, and Persistent Surveillance, require robots plan paths to navigate an environment while maximizing the information collected via on-board sensors. In this paper, we consider such information acquisition tasks but in adversarial environments, where attacks may temporarily disable the robots' sensors. We propose the first receding horizon algorithm, aiming for robust and adaptive multi-robot planning against any number of attacks, which we call Resilient Active Information acquisitioN (RAIN). RAIN calls, in an online fashion, a Robust Trajectory Planning (RTP) subroutine which plans attack-robust control inputs over a look-ahead planning horizon. We quantify RTP's performance by bounding its suboptimality. We base our theoretical analysis on notions of curvature introduced in combinatorial optimization. We evaluate RAIN in three information acquisition scenarios: Multi-Target Tracking, Occupancy Grid Mapping, and Persistent Surveillance. The scenarios are simulated in C++ and a Unity-based simulator. In all simulations, RAIN runs in real-time, and exhibits superior performance against a state-of-the-art baseline information acquisition algorithm, even in the presence of a high number of attacks. We also demonstrate RAIN's robustness and effectiveness against varying models of attacks (worst-case and random), as well as, varying replanning rates.",
        "published": "2021-03-03T22:48:25Z",
        "link": "http://arxiv.org/abs/2103.02733v2",
        "categories": [
            "cs.RO",
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "Time granularity impact on propagation of disruptions in a   system-of-systems simulation of infrastructure and business networks",
        "authors": [
            "Mateusz Iwo Dubaniowski",
            "Hans Rudolf Heinimann"
        ],
        "summary": "System-of-systems (SoS) approach is often used for simulating disruptions to business and infrastructure system networks allowing for integration of several models into one simulation. However, the integration is frequently challenging as each system is designed individually with different characteristics, such as time granularity. Understanding the impact of time granularity on propagation of disruptions between businesses and infrastructure systems and finding the appropriate granularity for the SoS simulation remain as major challenges. To tackle these, we explore how time granularity, recovery time, and disruption size affect the propagation of disruptions between constituent systems of an SoS simulation. To address this issue, we developed a High Level Architecture (HLA) simulation of 3 networks and performed a series of simulation experiments. Our results revealed that time granularity and especially recovery time have huge impact on propagation of disruptions. Consequently, we developed a model for selecting an appropriate time granularity for an SoS simulation based on expected recovery time. Our simulation experiments show that time granularity should be less than 1.13 of expected recovery time. We identified some areas for future research centered around extending the experimental factors space.",
        "published": "2021-03-04T10:39:37Z",
        "link": "http://arxiv.org/abs/2103.03247v1",
        "categories": [
            "cs.SI",
            "cs.DC",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "FAtiMA Toolkit -- Toward an effective and accessible tool for the   development of intelligent virtual agents and social robots",
        "authors": [
            "Samuel Mascarenhas",
            "Manuel Guimarães",
            "Pedro A. Santos",
            "João Dias",
            "Rui Prada",
            "Ana Paiva"
        ],
        "summary": "More than a decade has passed since the development of FearNot!, an application designed to help children deal with bullying through role-playing with virtual characters. It was also the application that led to the creation of FAtiMA, an affective agent architecture for creating autonomous characters that can evoke empathic responses. In this paper, we describe FAtiMA Toolkit, a collection of open-source tools that is designed to help researchers, game developers and roboticists incorporate a computational model of emotion and decision-making in their work. The toolkit was developed with the goal of making FAtiMA more accessible, easier to incorporate into different projects and more flexible in its capabilities for human-agent interaction, based upon the experience gathered over the years across different virtual environments and human-robot interaction scenarios. As a result, this work makes several different contributions to the field of Agent-Based Architectures. More precisely, FAtiMA Toolkit's library based design allows developers to easily integrate it with other frameworks, its meta-cognitive model affords different internal reasoners and affective components and its explicit dialogue structure gives control to the author even within highly complex scenarios. To demonstrate the use of FAtiMA Toolkit, several different use cases where the toolkit was successfully applied are described and discussed.",
        "published": "2021-03-04T13:30:59Z",
        "link": "http://arxiv.org/abs/2103.03020v1",
        "categories": [
            "cs.MA",
            "cs.HC",
            "cs.RO"
        ]
    },
    {
        "title": "Continuous Coordination As a Realistic Scenario for Lifelong Learning",
        "authors": [
            "Hadi Nekoei",
            "Akilesh Badrinaaraayanan",
            "Aaron Courville",
            "Sarath Chandar"
        ],
        "summary": "Current deep reinforcement learning (RL) algorithms are still highly task-specific and lack the ability to generalize to new environments. Lifelong learning (LLL), however, aims at solving multiple tasks sequentially by efficiently transferring and using knowledge between tasks. Despite a surge of interest in lifelong RL in recent years, the lack of a realistic testbed makes robust evaluation of LLL algorithms difficult. Multi-agent RL (MARL), on the other hand, can be seen as a natural scenario for lifelong RL due to its inherent non-stationarity, since the agents' policies change over time. In this work, we introduce a multi-agent lifelong learning testbed that supports both zero-shot and few-shot settings. Our setup is based on Hanabi -- a partially-observable, fully cooperative multi-agent game that has been shown to be challenging for zero-shot coordination. Its large strategy space makes it a desirable environment for lifelong RL tasks. We evaluate several recent MARL methods, and benchmark state-of-the-art LLL algorithms in limited memory and computation regimes to shed light on their strengths and weaknesses. This continual learning paradigm also provides us with a pragmatic way of going beyond centralized training which is the most commonly used training protocol in MARL. We empirically show that the agents trained in our setup are able to coordinate well with unseen agents, without any additional assumptions made by previous works. The code and all pre-trained models are available at https://github.com/chandar-lab/Lifelong-Hanabi.",
        "published": "2021-03-04T18:44:03Z",
        "link": "http://arxiv.org/abs/2103.03216v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "An Agent-Based Modelling Approach to Brain Drain",
        "authors": [
            "Furkan Gürsoy",
            "Bertan Badur"
        ],
        "summary": "The phenomenon of brain drain, that is the emigration of highly skilled people, has many undesirable effects, particularly for developing countries. In this study, an agent-based model is developed to understand the dynamics of such emigration. We hypothesise that skilled people's emigration decisions are based on several factors including the overall economic and social difference between the home and host countries, people's ability and capacity to obtain good jobs and start a life abroad, and the barriers of moving abroad. Furthermore, the social network of individuals also plays a significant role. The model is validated using qualitative and quantitative pattern matching with real-world observations. Sensitivity and uncertainty analyses are performed in addition to several scenario analyses. Linear and random forest response surface models are created to provide quick predictions on the number of emigrants as well as to understand the effect sizes of individual parameters. Overall, the study provides an abstract model where brain drain dynamics can be explored. Findings from the simulation outputs show that future socioeconomic state of the country is more important than the current state, lack of barriers results in a large number of emigrants, and network effects ensue compounding effects on emigration. Upon further development and customisation, future versions can assist in the decision-making of social policymakers regarding brain drain.",
        "published": "2021-03-04T18:55:40Z",
        "link": "http://arxiv.org/abs/2103.03234v2",
        "categories": [
            "physics.soc-ph",
            "cs.MA",
            "econ.GN",
            "q-fin.EC"
        ]
    },
    {
        "title": "Limits of Probabilistic Safety Guarantees when Considering Human   Uncertainty",
        "authors": [
            "Richard Cheng",
            "Richard M. Murray",
            "Joel W. Burdick"
        ],
        "summary": "When autonomous robots interact with humans, such as during autonomous driving, explicit safety guarantees are crucial in order to avoid potentially life-threatening accidents. Many data-driven methods have explored learning probabilistic bounds over human agents' trajectories (i.e. confidence tubes that contain trajectories with probability $\\delta$), which can then be used to guarantee safety with probability $1-\\delta$. However, almost all existing works consider $\\delta \\geq 0.001$. The purpose of this paper is to argue that (1) in safety-critical applications, it is necessary to provide safety guarantees with $\\delta < 10^{-8}$, and (2) current learning-based methods are ill-equipped to compute accurate confidence bounds at such low $\\delta$. Using human driving data (from the highD dataset), as well as synthetically generated data, we show that current uncertainty models use inaccurate distributional assumptions to describe human behavior and/or require infeasible amounts of data to accurately learn confidence bounds for $\\delta \\leq 10^{-8}$. These two issues result in unreliable confidence bounds, which can have dangerous implications if deployed on safety-critical systems.",
        "published": "2021-03-05T00:00:56Z",
        "link": "http://arxiv.org/abs/2103.03388v2",
        "categories": [
            "cs.RO",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "DeepFreight: Integrating Deep Reinforcement Learning and Mixed Integer   Programming for Multi-transfer Truck Freight Delivery",
        "authors": [
            "Jiayu Chen",
            "Abhishek K. Umrawal",
            "Tian Lan",
            "Vaneet Aggarwal"
        ],
        "summary": "With the freight delivery demands and shipping costs increasing rapidly, intelligent control of fleets to enable efficient and cost-conscious solutions becomes an important problem. In this paper, we propose DeepFreight, a model-free deep-reinforcement-learning-based algorithm for multi-transfer freight delivery, which includes two closely-collaborative components: truck-dispatch and package-matching. Specifically, a deep multi-agent reinforcement learning framework called QMIX is leveraged to learn a dispatch policy, with which we can obtain the multi-step joint vehicle dispatch decisions for the fleet with respect to the delivery requests. Then an efficient multi-transfer matching algorithm is executed to assign the delivery requests to the trucks. Also, DeepFreight is integrated with a Mixed-Integer Linear Programming optimizer for further optimization. The evaluation results show that the proposed system is highly scalable and ensures a 100\\% delivery success while maintaining low delivery-time and fuel consumption. The codes are available at https://github.com/LucasCJYSDL/DeepFreight.",
        "published": "2021-03-05T03:06:48Z",
        "link": "http://arxiv.org/abs/2103.03450v2",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Democratic Forking: Choosing Sides with Social Choice",
        "authors": [
            "Ben Abramowitz",
            "Edith Elkind",
            "Davide Grossi",
            "Ehud Shapiro",
            "Nimrod Talmon"
        ],
        "summary": "Any community in which membership is optional may eventually break apart, or fork. For example, forks may occur in political parties, business partnerships, social groups, cryptocurrencies, and federated governing bodies. Forking is typically the product of informal social processes or the organized action of an aggrieved minority, and it is not always amicable. Forks usually come at a cost, and can be seen as consequences of collective decisions that destabilize the community. Here, we provide a social choice setting in which agents can report preferences not only over a set of alternatives, but also over the possible forks that may occur in the face of disagreement. We study this social choice setting, concentrating on stability issues and concerns of strategic agent behavior.",
        "published": "2021-03-05T13:25:11Z",
        "link": "http://arxiv.org/abs/2103.03652v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "MAMBPO: Sample-efficient multi-robot reinforcement learning using   learned world models",
        "authors": [
            "Daniël Willemsen",
            "Mario Coppola",
            "Guido C. H. E. de Croon"
        ],
        "summary": "Multi-robot systems can benefit from reinforcement learning (RL) algorithms that learn behaviours in a small number of trials, a property known as sample efficiency. This research thus investigates the use of learned world models to improve sample efficiency. We present a novel multi-agent model-based RL algorithm: Multi-Agent Model-Based Policy Optimization (MAMBPO), utilizing the Centralized Learning for Decentralized Execution (CLDE) framework. CLDE algorithms allow a group of agents to act in a fully decentralized manner after training. This is a desirable property for many systems comprising of multiple robots. MAMBPO uses a learned world model to improve sample efficiency compared to model-free Multi-Agent Soft Actor-Critic (MASAC). We demonstrate this on two simulated multi-robot tasks, where MAMBPO achieves a similar performance to MASAC, but requires far fewer samples to do so. Through this, we take an important step towards making real-life learning for multi-robot systems possible.",
        "published": "2021-03-05T13:37:23Z",
        "link": "http://arxiv.org/abs/2103.03662v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA",
            "I.2.9; I.2.11"
        ]
    },
    {
        "title": "Distributed Dynamic Map Fusion via Federated Learning for Intelligent   Networked Vehicles",
        "authors": [
            "Zijian Zhang",
            "Shuai Wang",
            "Yuncong Hong",
            "Liangkai Zhou",
            "Qi Hao"
        ],
        "summary": "The technology of dynamic map fusion among networked vehicles has been developed to enlarge sensing ranges and improve sensing accuracies for individual vehicles. This paper proposes a federated learning (FL) based dynamic map fusion framework to achieve high map quality despite unknown numbers of objects in fields of view (FoVs), various sensing and model uncertainties, and missing data labels for online learning. The novelty of this work is threefold: (1) developing a three-stage fusion scheme to predict the number of objects effectively and to fuse multiple local maps with fidelity scores; (2) developing an FL algorithm which fine-tunes feature models (i.e., representation learning networks for feature extraction) distributively by aggregating model parameters; (3) developing a knowledge distillation method to generate FL training labels when data labels are unavailable. The proposed framework is implemented in the Car Learning to Act (CARLA) simulation platform. Extensive experimental results are provided to verify the superior performance and robustness of the developed map fusion and FL schemes.",
        "published": "2021-03-05T16:28:46Z",
        "link": "http://arxiv.org/abs/2103.03786v3",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Dynamic Resource Management for Providing QoS in Drone Delivery Systems",
        "authors": [
            "Behzad Khamidehi",
            "Majid Raeis",
            "Elvino S. Sousa"
        ],
        "summary": "Drones have been considered as an alternative means of package delivery to reduce the delivery cost and time. Due to the battery limitations, the drones are best suited for last-mile delivery, i.e., the delivery from the package distribution centers (PDCs) to the customers. Since a typical delivery system consists of multiple PDCs, each having random and time-varying demands, the dynamic drone-to-PDC allocation would be of great importance in meeting the demand in an efficient manner. In this paper, we study the dynamic UAV assignment problem for a drone delivery system with the goal of providing measurable Quality of Service (QoS) guarantees. We adopt a queueing theoretic approach to model the customer-service nature of the problem. Furthermore, we take a deep reinforcement learning approach to obtain a dynamic policy for the re-allocation of the UAVs. This policy guarantees a probabilistic upper-bound on the queue length of the packages waiting in each PDC, which is beneficial from both the service provider's and the customers' viewpoints. We evaluate the performance of our proposed algorithm by considering three broad arrival classes, including Bernoulli, Time-Varying Bernoulli, and Markov-Modulated Bernoulli arrivals. Our results show that the proposed method outperforms the baselines, particularly in scenarios with Time-Varying and Markov-Modulated Bernoulli arrivals, which are more representative of real-world demand patterns. Moreover, our algorithm satisfies the QoS constraints in all the studied scenarios while minimizing the average number of UAVs in use.",
        "published": "2021-03-06T03:11:07Z",
        "link": "http://arxiv.org/abs/2103.04015v1",
        "categories": [
            "cs.RO",
            "cs.LG",
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "Real-world Ride-hailing Vehicle Repositioning using Deep Reinforcement   Learning",
        "authors": [
            "Yan Jiao",
            "Xiaocheng Tang",
            "Zhiwei Qin",
            "Shuaiji Li",
            "Fan Zhang",
            "Hongtu Zhu",
            "Jieping Ye"
        ],
        "summary": "We present a new practical framework based on deep reinforcement learning and decision-time planning for real-world vehicle repositioning on ride-hailing (a type of mobility-on-demand, MoD) platforms. Our approach learns the spatiotemporal state-value function using a batch training algorithm with deep value networks. The optimal repositioning action is generated on-demand through value-based policy search, which combines planning and bootstrapping with the value networks. For the large-fleet problems, we develop several algorithmic features that we incorporate into our framework and that we demonstrate to induce coordination among the algorithmically-guided vehicles. We benchmark our algorithm with baselines in a ride-hailing simulation environment to demonstrate its superiority in improving income efficiency meausred by income-per-hour. We have also designed and run a real-world experiment program with regular drivers on a major ride-hailing platform. We have observed significantly positive results on key metrics comparing our method with experienced drivers who performed idle-time repositioning based on their own expertise.",
        "published": "2021-03-08T05:34:05Z",
        "link": "http://arxiv.org/abs/2103.04555v3",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Monte Carlo Tree Search: A Review of Recent Modifications and   Applications",
        "authors": [
            "Maciej Świechowski",
            "Konrad Godlewski",
            "Bartosz Sawicki",
            "Jacek Mańdziuk"
        ],
        "summary": "Monte Carlo Tree Search (MCTS) is a powerful approach to designing game-playing bots or solving sequential decision problems. The method relies on intelligent tree search that balances exploration and exploitation. MCTS performs random sampling in the form of simulations and stores statistics of actions to make more educated choices in each subsequent iteration. The method has become a state-of-the-art technique for combinatorial games, however, in more complex games (e.g. those with high branching factor or real-time ones), as well as in various practical domains (e.g. transportation, scheduling or security) an efficient MCTS application often requires its problem-dependent modification or integration with other techniques. Such domain-specific modifications and hybrid approaches are the main focus of this survey. The last major MCTS survey has been published in 2012. Contributions that appeared since its release are of particular interest for this review.",
        "published": "2021-03-08T17:44:15Z",
        "link": "http://arxiv.org/abs/2103.04931v4",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Provably Efficient Cooperative Multi-Agent Reinforcement Learning with   Function Approximation",
        "authors": [
            "Abhimanyu Dubey",
            "Alex Pentland"
        ],
        "summary": "Reinforcement learning in cooperative multi-agent settings has recently advanced significantly in its scope, with applications in cooperative estimation for advertising, dynamic treatment regimes, distributed control, and federated learning. In this paper, we discuss the problem of cooperative multi-agent RL with function approximation, where a group of agents communicates with each other to jointly solve an episodic MDP. We demonstrate that via careful message-passing and cooperative value iteration, it is possible to achieve near-optimal no-regret learning even with a fixed constant communication budget. Next, we demonstrate that even in heterogeneous cooperative settings, it is possible to achieve Pareto-optimal no-regret learning with limited communication. Our work generalizes several ideas from the multi-agent contextual and multi-armed bandit literature to MDPs and reinforcement learning.",
        "published": "2021-03-08T18:51:00Z",
        "link": "http://arxiv.org/abs/2103.04972v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "A multi-agent reinforcement learning model of reputation and cooperation   in human groups",
        "authors": [
            "Kevin R. McKee",
            "Edward Hughes",
            "Tina O. Zhu",
            "Martin J. Chadwick",
            "Raphael Koster",
            "Antonio Garcia Castaneda",
            "Charlie Beattie",
            "Thore Graepel",
            "Matt Botvinick",
            "Joel Z. Leibo"
        ],
        "summary": "Collective action demands that individuals efficiently coordinate how much, where, and when to cooperate. Laboratory experiments have extensively explored the first part of this process, demonstrating that a variety of social-cognitive mechanisms influence how much individuals choose to invest in group efforts. However, experimental research has been unable to shed light on how social cognitive mechanisms contribute to the where and when of collective action. We build and test a computational model of human behavior in Clean Up, a social dilemma task popular in multi-agent reinforcement learning research. We show that human groups effectively cooperate in Clean Up when they can identify group members and track reputations over time, but fail to organize under conditions of anonymity. A multi-agent reinforcement learning model of reputation demonstrates the same difference in cooperation under conditions of identifiability and anonymity. In addition, the model accurately predicts spatial and temporal patterns of group behavior: in this public goods dilemma, the intrinsic motivation for reputation catalyzes the development of a non-territorial, turn-taking strategy to coordinate collective action.",
        "published": "2021-03-08T18:58:40Z",
        "link": "http://arxiv.org/abs/2103.04982v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.GT"
        ]
    },
    {
        "title": "Learning Connectivity for Data Distribution in Robot Teams",
        "authors": [
            "Ekaterina Tolstaya",
            "Landon Butler",
            "Daniel Mox",
            "James Paulos",
            "Vijay Kumar",
            "Alejandro Ribeiro"
        ],
        "summary": "Many algorithms for control of multi-robot teams operate under the assumption that low-latency, global state information necessary to coordinate agent actions can readily be disseminated among the team. However, in harsh environments with no existing communication infrastructure, robots must form ad-hoc networks, forcing the team to operate in a distributed fashion. To overcome this challenge, we propose a task-agnostic, decentralized, low-latency method for data distribution in ad-hoc networks using Graph Neural Networks (GNN). Our approach enables multi-agent algorithms based on global state information to function by ensuring it is available at each robot. To do this, agents glean information about the topology of the network from packet transmissions and feed it to a GNN running locally which instructs the agent when and where to transmit the latest state information. We train the distributed GNN communication policies via reinforcement learning using the average Age of Information as the reward function and show that it improves training stability compared to task-specific reward functions. Our approach performs favorably compared to industry-standard methods for data distribution such as random flooding and round robin. We also show that the trained policies generalize to larger teams of both static and mobile agents.",
        "published": "2021-03-08T21:48:55Z",
        "link": "http://arxiv.org/abs/2103.05091v2",
        "categories": [
            "cs.RO",
            "cs.LG",
            "cs.MA",
            "cs.NI"
        ]
    },
    {
        "title": "Learning to Play Soccer From Scratch: Sample-Efficient Emergent   Coordination through Curriculum-Learning and Competition",
        "authors": [
            "Pavan Samtani",
            "Francisco Leiva",
            "Javier Ruiz-del-Solar"
        ],
        "summary": "This work proposes a scheme that allows learning complex multi-agent behaviors in a sample efficient manner, applied to 2v2 soccer. The problem is formulated as a Markov game, and solved using deep reinforcement learning. We propose a basic multi-agent extension of TD3 for learning the policy of each player, in a decentralized manner. To ease learning, the task of 2v2 soccer is divided in three stages: 1v0, 1v1 and 2v2. The process of learning in multi-agent stages (1v1 and 2v2) uses agents trained on a previous stage as fixed opponents. In addition, we propose using experience sharing, a method that shares experience from a fixed opponent, trained in a previous stage, for training the agent currently learning, and a form of frame-skipping, to raise performance significantly. Our results show that high quality soccer play can be obtained with our approach in just under 40M interactions. A summarized video of the resulting game play can be found in https://youtu.be/f25l1j1U9RM.",
        "published": "2021-03-09T01:57:16Z",
        "link": "http://arxiv.org/abs/2103.05174v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Decentralized Circle Formation Control for Fish-like Robots in the   Real-world via Reinforcement Learning",
        "authors": [
            "Tianhao Zhang",
            "Yueheng Li",
            "Shuai Li",
            "Qiwei Ye",
            "Chen Wang",
            "Guangming Xie"
        ],
        "summary": "In this paper, the circle formation control problem is addressed for a group of cooperative underactuated fish-like robots involving unknown nonlinear dynamics and disturbances. Based on the reinforcement learning and cognitive consistency theory, we propose a decentralized controller without the knowledge of the dynamics of the fish-like robots. The proposed controller can be transferred from simulation to reality. It is only trained in our established simulation environment, and the trained controller can be deployed to real robots without any manual tuning. Simulation results confirm that the proposed model-free robust formation control method is scalable with respect to the group size of the robots and outperforms other representative RL algorithms. Several experiments in the real world verify the effectiveness of our RL-based approach for circle formation control.",
        "published": "2021-03-09T08:38:28Z",
        "link": "http://arxiv.org/abs/2103.05293v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA",
            "68T40",
            "I.2.9"
        ]
    },
    {
        "title": "Distributed Frequency Restoration and SoC Balancing Control for AC   Microgrids",
        "authors": [
            "Chang Yu",
            "Xiaoqing Lu",
            "Jingang Lai",
            "Li Chai"
        ],
        "summary": "This paper develops an improved distributed finite-time control algorithm for multiagent-based ac microgrids with battery energy storage systems (BESSs) utilizing a low-width communication network. The proposed control algorithm can simultaneously coordinate BESSs to eliminate any deviation from the nominal frequency as well as solving the state of charge (SoC) balancing problem. The stability of the proposed control algorithm is established using the Lyapunov method and homogeneous approximation theory, which guarantees an accelerated convergence within a settling time that does not dependent on initial conditions. Based on this, to significantly reduce the communication burdens, an event-triggered communication mechanism is designed which can also avoid Zeno behavior. Then sufficient conditions on the event-triggered boundary are derived to guarantee the stability and reliability of the whole system. Practical local constraints are imposed to implement the control protocol, and the theoretical results are applied to a test system consisting of five DGs and five BESSs, which verifies the effectiveness of the proposed strategy.",
        "published": "2021-03-09T17:33:08Z",
        "link": "http://arxiv.org/abs/2103.05576v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "The AI Arena: A Framework for Distributed Multi-Agent Reinforcement   Learning",
        "authors": [
            "Edward W. Staley",
            "Corban G. Rivera",
            "Ashley J. Llorens"
        ],
        "summary": "Advances in reinforcement learning (RL) have resulted in recent breakthroughs in the application of artificial intelligence (AI) across many different domains. An emerging landscape of development environments is making powerful RL techniques more accessible for a growing community of researchers. However, most existing frameworks do not directly address the problem of learning in complex operating environments, such as dense urban settings or defense-related scenarios, that incorporate distributed, heterogeneous teams of agents. To help enable AI research for this important class of applications, we introduce the AI Arena: a scalable framework with flexible abstractions for distributed multi-agent reinforcement learning. The AI Arena extends the OpenAI Gym interface to allow greater flexibility in learning control policies across multiple agents with heterogeneous learning strategies and localized views of the environment. To illustrate the utility of our framework, we present experimental results that demonstrate performance gains due to a distributed multi-agent learning approach over commonly-used RL techniques in several different learning environments.",
        "published": "2021-03-09T22:16:19Z",
        "link": "http://arxiv.org/abs/2103.05737v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "GRIT: Fast, Interpretable, and Verifiable Goal Recognition with Learned   Decision Trees for Autonomous Driving",
        "authors": [
            "Cillian Brewitt",
            "Balint Gyevnar",
            "Samuel Garcin",
            "Stefano V. Albrecht"
        ],
        "summary": "It is important for autonomous vehicles to have the ability to infer the goals of other vehicles (goal recognition), in order to safely interact with other vehicles and predict their future trajectories. This is a difficult problem, especially in urban environments with interactions between many vehicles. Goal recognition methods must be fast to run in real time and make accurate inferences. As autonomous driving is safety-critical, it is important to have methods which are human interpretable and for which safety can be formally verified. Existing goal recognition methods for autonomous vehicles fail to satisfy all four objectives of being fast, accurate, interpretable and verifiable. We propose Goal Recognition with Interpretable Trees (GRIT), a goal recognition system which achieves these objectives. GRIT makes use of decision trees trained on vehicle trajectory data. We evaluate GRIT on two datasets, showing that GRIT achieved fast inference speed and comparable accuracy to two deep learning baselines, a planning-based goal recognition method, and an ablation of GRIT. We show that the learned trees are human interpretable and demonstrate how properties of GRIT can be formally verified using a satisfiability modulo theories (SMT) solver.",
        "published": "2021-03-10T15:06:11Z",
        "link": "http://arxiv.org/abs/2103.06113v3",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Hiding Leader's Identity in Leader-Follower Navigation through   Multi-Agent Reinforcement Learning",
        "authors": [
            "Ankur Deka",
            "Wenhao Luo",
            "Huao Li",
            "Michael Lewis",
            "Katia Sycara"
        ],
        "summary": "Leader-follower navigation is a popular class of multi-robot algorithms where a leader robot leads the follower robots in a team. The leader has specialized capabilities or mission-critical information (e.g. goal location) that the followers lack, and this makes the leader crucial for the mission's success. However, this also makes the leader a vulnerability - an external adversary who wishes to sabotage the robot team's mission can simply harm the leader and the whole robot team's mission would be compromised. Since robot motion generated by traditional leader-follower navigation algorithms can reveal the identity of the leader, we propose a defense mechanism of hiding the leader's identity by ensuring the leader moves in a way that behaviorally camouflages it with the followers, making it difficult for an adversary to identify the leader. To achieve this, we combine Multi-Agent Reinforcement Learning, Graph Neural Networks and adversarial training. Our approach enables the multi-robot team to optimize the primary task performance with leader motion similar to follower motion, behaviorally camouflaging it with the followers. Our algorithm outperforms existing work that tries to hide the leader's identity in a multi-robot team by tuning traditional leader-follower control parameters with Classical Genetic Algorithms. We also evaluated human performance in inferring the leader's identity and found that humans had lower accuracy when the robot team used our proposed navigation algorithm.",
        "published": "2021-03-10T22:07:07Z",
        "link": "http://arxiv.org/abs/2103.06359v2",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "XDO: A Double Oracle Algorithm for Extensive-Form Games",
        "authors": [
            "Stephen McAleer",
            "John Lanier",
            "Kevin Wang",
            "Pierre Baldi",
            "Roy Fox"
        ],
        "summary": "Policy Space Response Oracles (PSRO) is a reinforcement learning (RL) algorithm for two-player zero-sum games that has been empirically shown to find approximate Nash equilibria in large games. Although PSRO is guaranteed to converge to an approximate Nash equilibrium and can handle continuous actions, it may take an exponential number of iterations as the number of information states (infostates) grows. We propose Extensive-Form Double Oracle (XDO), an extensive-form double oracle algorithm for two-player zero-sum games that is guaranteed to converge to an approximate Nash equilibrium linearly in the number of infostates. Unlike PSRO, which mixes best responses at the root of the game, XDO mixes best responses at every infostate. We also introduce Neural XDO (NXDO), where the best response is learned through deep RL. In tabular experiments on Leduc poker, we find that XDO achieves an approximate Nash equilibrium in a number of iterations an order of magnitude smaller than PSRO. Experiments on a modified Leduc poker game and Oshi-Zumo show that tabular XDO achieves a lower exploitability than CFR with the same amount of computation. We also find that NXDO outperforms PSRO and NFSP on a sequential multidimensional continuous-action game. NXDO is the first deep RL method that can find an approximate Nash equilibrium in high-dimensional continuous-action sequential games. Experiment code is available at https://github.com/indylab/nxdo.",
        "published": "2021-03-11T03:05:44Z",
        "link": "http://arxiv.org/abs/2103.06426v2",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Preventing Extreme Polarization of Political Attitudes",
        "authors": [
            "Robert Axelrod",
            "Joshua J. Daymude",
            "Stephanie Forrest"
        ],
        "summary": "Extreme polarization can undermine democracy by making compromise impossible and transforming politics into a zero-sum game. Ideological polarization - the extent to which political views are widely dispersed - is already strong among elites, but less so among the general public (McCarty, 2019, p. 50-68). Strong mutual distrust and hostility between Democrats and Republicans in the U.S., combined with the elites' already strong ideological polarization, could lead to increasing ideological polarization among the public. The paper addresses two questions: (1) Is there a level of ideological polarization above which polarization feeds upon itself to become a runaway process? (2) If so, what policy interventions could prevent such dangerous positive feedback loops? To explore these questions, we present an agent-based model of ideological polarization that differentiates between the tendency for two actors to interact (exposure) and how they respond when interactions occur, positing that interaction between similar actors reduces their difference while interaction between dissimilar actors increases their difference. Our analysis explores the effects on polarization of different levels of tolerance to other views, responsiveness to other views, exposure to dissimilar actors, multiple ideological dimensions, economic self-interest, and external shocks. The results suggest strategies for preventing, or at least slowing, the development of extreme polarization.",
        "published": "2021-03-11T06:41:04Z",
        "link": "http://arxiv.org/abs/2103.06492v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Data Collection and Utilization Framework for Edge AI Applications",
        "authors": [
            "Hergys Rexha",
            "Sebastien Lafond"
        ],
        "summary": "As data being produced by IoT applications continues to explode, there is a growing need to bring computing power closer to the source of the data to meet the response time, power dissipation and cost goals of performance-critical applications in various domains like the Industrial Internet of Things (IIoT), Automated Driving, Medical Imaging or Surveillance among others. This paper proposes a data collection and utilization framework that allows runtime platform and application data to be sent to an edge and cloud system via data collection agents running close to the platform. Agents are connected to a cloud system able to train AI models to improve overall energy efficiency of an AI application executed on an edge platform. In the implementation part, we show the benefits of FPGA-based platform for the task of object detection. Furthermore, we show that it is feasible to collect relevant data from an FPGA platform, transmit the data to a cloud system for processing and receiving feedback actions to execute an edge AI application energy efficiently. As future work, we foresee the possibility to train, deploy and continuously improve a base model able to efficiently adapt the execution of edge applications.",
        "published": "2021-03-11T08:07:29Z",
        "link": "http://arxiv.org/abs/2103.06518v2",
        "categories": [
            "cs.LG",
            "cs.IR",
            "cs.MA"
        ]
    },
    {
        "title": "Utility of Traffic Information in Dynamic Routing: Is Sharing   Information Always Useful?",
        "authors": [
            "Mohammad Shaqfeh",
            "Salah Hessien",
            "Erchin Serpedin"
        ],
        "summary": "Real-time traffic information can be utilized to enhance the efficiency of transportation networks by dynamically updating routing plans to mitigate traffic jams. However, an interesting question is whether the network coordinator should broadcast real-time traffic information to all network users or communicate it selectively to some of them. Which option enhances the network efficiency more? In this work, we demonstrate using simulation experiments that sharing real-time traffic information with all network users is sub-optimal, and it is actually better to share the information with a majority subset of the total population in order to improve the overall network performance. This result is valid under the assumption that each network user decides its route to destination locally.",
        "published": "2021-03-11T10:02:41Z",
        "link": "http://arxiv.org/abs/2103.06574v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Test case generation for agent-based models: A systematic literature   review",
        "authors": [
            "Andrew G. Clark",
            "Neil Walkinshaw",
            "Robert M. Hierons"
        ],
        "summary": "Agent-based models play an important role in simulating complex emergent phenomena and supporting critical decisions. In this context, a software fault may result in poorly informed decisions that lead to disastrous consequences. The ability to rigorously test these models is therefore essential. In this systematic literature review, we answer five research questions related to the key aspects of test case generation in agent-based models: What are the information artifacts used to generate tests? How are these tests generated? How is a verdict assigned to a generated test? How is the adequacy of a generated test suite measured? What level of abstraction of an agent-based model is targeted by a generated test? Our results show that whilst the majority of techniques are effective for testing functional requirements at the agent and integration levels of abstraction, there are comparatively few techniques capable of testing society-level behaviour. Additionally, we identify a need for more thorough evaluation using realistic case studies that feature challenging properties associated with a typical agent-based model.",
        "published": "2021-03-12T16:07:12Z",
        "link": "http://arxiv.org/abs/2103.07370v2",
        "categories": [
            "cs.SE",
            "cs.MA"
        ]
    },
    {
        "title": "DeepGroup: Representation Learning for Group Recommendation with   Implicit Feedback",
        "authors": [
            "Sarina Sajadi Ghaemmaghami",
            "Amirali Salehi-Abari"
        ],
        "summary": "Group recommender systems facilitate group decision making for a set of individuals (e.g., a group of friends, a team, a corporation, etc.). Many of these systems, however, either assume that (i) user preferences can be elicited (or inferred) and then aggregated into group preferences or (ii) group preferences are partially observed/elicited. We focus on making recommendations for a new group of users whose preferences are unknown, but we are given the decisions/choices of other groups. By formulating this problem as group recommendation from group implicit feedback, we focus on two of its practical instances: group decision prediction and reverse social choice. Given a set of groups and their observed decisions, group decision prediction intends to predict the decision of a new group of users, whereas reverse social choice aims to infer the preferences of those users involved in observed group decisions. These two problems are of interest to not only group recommendation, but also to personal privacy when the users intend to conceal their personal preferences but have participated in group decisions. To tackle these two problems, we propose and study DeepGroup -- a deep learning approach for group recommendation with group implicit data. We empirically assess the predictive power of DeepGroup on various real-world datasets, group conditions (e.g., homophily or heterophily), and group decision (or voting) rules. Our extensive experiments not only demonstrate the efficacy of DeepGroup, but also shed light on the privacy-leakage concerns of some decision making processes.",
        "published": "2021-03-13T02:05:26Z",
        "link": "http://arxiv.org/abs/2103.07597v1",
        "categories": [
            "cs.AI",
            "cs.IR",
            "cs.MA"
        ]
    },
    {
        "title": "Electric Vehicle Charging Scheduling in Green Logistics: Challenges,   Approaches and Opportunities",
        "authors": [
            "Luyang Hou",
            "Chun Wang",
            "Jun Yan"
        ],
        "summary": "Replacing a fossil fuel-powered car with an electric model can halve greenhouse gas emissions over the course of the vehicle's lifetime and reduce the noise pollution in urban areas. In green logistics, a well-scheduled charging ensures an efficient operation of transportation and power systems and, at the same time, provides economical and satisfactory charging services for drivers. This paper presents a taxonomy of current electric vehicle charging scheduling problems in green logistics by analyzing its unique features with some typical use cases, such as space assignment, routing and energy management; discusses the challenges, i.e., the information availability and stakeholders' strategic behaviors that arise in stochastic and decentralized environments; and classifies the existing approaches, as centralized, distributed and decentralized ones, that apply to these challenges. Moreover, we discuss research opportunities in applying market-based mechanisms, which shall be coordinated with stochastic optimization and machine learning, to the decentralized, dynamic and data-driven charging scheduling problems for the management of the future green logistics.",
        "published": "2021-03-13T06:47:36Z",
        "link": "http://arxiv.org/abs/2103.07635v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Mean Field Behaviour of Collaborative Multi-Agent Foragers",
        "authors": [
            "Daniel Jarne Ornia",
            "Pedro J Zufiria",
            "Manuel Mazo Jr"
        ],
        "summary": "Collaborative multi-agent robotic systems where agents coordinate by modifying a shared environment often result in undesired dynamical couplings that complicate the analysis and experiments when solving a specific problem or task. Simultaneously, biologically-inspired robotics rely on simplifying agents and increasing their number to obtain more efficient solutions to such problems, drawing similarities with natural processes. In this work we focus on the problem of a biologically-inspired multi-agent system solving collaborative foraging. We show how mean field techniques can be used to re-formulate such a stochastic multi-agent problem into a deterministic autonomous system. This de-couples agent dynamics, enabling the computation of limit behaviours and the analysis of optimality guarantees. Furthermore, we analyse how having finite number of agents affects the performance when compared to the mean field limit and we discuss the implications of such limit approximations in this multi-agent system, which have impact on more general collaborative stochastic problems.",
        "published": "2021-03-13T13:12:56Z",
        "link": "http://arxiv.org/abs/2103.07714v2",
        "categories": [
            "cs.RO",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Modelling Behavioural Diversity for Learning in Open-Ended Games",
        "authors": [
            "Nicolas Perez Nieves",
            "Yaodong Yang",
            "Oliver Slumbers",
            "David Henry Mguni",
            "Ying Wen",
            "Jun Wang"
        ],
        "summary": "Promoting behavioural diversity is critical for solving games with non-transitive dynamics where strategic cycles exist, and there is no consistent winner (e.g., Rock-Paper-Scissors). Yet, there is a lack of rigorous treatment for defining diversity and constructing diversity-aware learning dynamics. In this work, we offer a geometric interpretation of behavioural diversity in games and introduce a novel diversity metric based on determinantal point processes (DPP). By incorporating the diversity metric into best-response dynamics, we develop diverse fictitious play and diverse policy-space response oracle for solving normal-form games and open-ended games. We prove the uniqueness of the diverse best response and the convergence of our algorithms on two-player games. Importantly, we show that maximising the DPP-based diversity metric guarantees to enlarge the gamescape -- convex polytopes spanned by agents' mixtures of strategies. To validate our diversity-aware solvers, we test on tens of games that show strong non-transitivity. Results suggest that our methods achieve at least the same, and in most games, lower exploitability than PSRO solvers by finding effective and diverse strategies.",
        "published": "2021-03-14T13:42:39Z",
        "link": "http://arxiv.org/abs/2103.07927v2",
        "categories": [
            "cs.AI",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Quasi-Equivalence Discovery for Zero-Shot Emergent Communication",
        "authors": [
            "Kalesha Bullard",
            "Douwe Kiela",
            "Franziska Meier",
            "Joelle Pineau",
            "Jakob Foerster"
        ],
        "summary": "Effective communication is an important skill for enabling information exchange in multi-agent settings and emergent communication is now a vibrant field of research, with common settings involving discrete cheap-talk channels. Since, by definition, these settings involve arbitrary encoding of information, typically they do not allow for the learned protocols to generalize beyond training partners. In contrast, in this work, we present a novel problem setting and the Quasi-Equivalence Discovery (QED) algorithm that allows for zero-shot coordination (ZSC), i.e., discovering protocols that can generalize to independently trained agents. Real world problem settings often contain costly communication channels, e.g., robots have to physically move their limbs, and a non-uniform distribution over intents. We show that these two factors lead to unique optimal ZSC policies in referential games, where agents use the energy cost of the messages to communicate intent. Other-Play was recently introduced for learning optimal ZSC policies, but requires prior access to the symmetries of the problem. Instead, QED can iteratively discovers the symmetries in this setting and converges to the optimal ZSC policy.",
        "published": "2021-03-14T23:42:37Z",
        "link": "http://arxiv.org/abs/2103.08067v2",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Learning in Markets: Greed Leads to Chaos but Following the Price is   Right",
        "authors": [
            "Yun Kuen Cheung",
            "Stefanos Leonardos",
            "Georgios Piliouras"
        ],
        "summary": "We study learning dynamics in distributed production economies such as blockchain mining, peer-to-peer file sharing and crowdsourcing. These economies can be modelled as multi-product Cournot competitions or all-pay auctions (Tullock contests) when individual firms have market power, or as Fisher markets with quasi-linear utilities when every firm has negligible influence on market outcomes. In the former case, we provide a formal proof that Gradient Ascent (GA) can be Li-Yorke chaotic for a step size as small as $\\Theta(1/n)$, where $n$ is the number of firms. In stark contrast, for the Fisher market case, we derive a Proportional Response (PR) protocol that converges to market equilibrium. The positive results on the convergence of the PR dynamics are obtained in full generality, in the sense that they hold for Fisher markets with \\emph{any} quasi-linear utility functions. Conversely, the chaos results for the GA dynamics are established even in the simplest possible setting of two firms and one good, and they hold for a wide range of price functions with different demand elasticities. Our findings suggest that by considering multi-agent interactions from a market rather than a game-theoretic perspective, we can formally derive natural learning protocols which are stable and converge to effective outcomes rather than being chaotic.",
        "published": "2021-03-15T16:48:30Z",
        "link": "http://arxiv.org/abs/2103.08529v2",
        "categories": [
            "cs.GT",
            "cs.MA",
            "econ.TH",
            "math.DS",
            "91A26, 91B55,"
        ]
    },
    {
        "title": "Graph-Based Multiobject Tracking with Embedded Particle Flow",
        "authors": [
            "Wenyu Zhang",
            "Florian Meyer"
        ],
        "summary": "Seamless situational awareness provided by modern radar systems relies on effective methods for multiobject tracking (MOT). This paper presents a graph-based Bayesian method for nonlinear and high-dimensional MOT problems that embeds particle flow. To perform operations on the graph effectively, particles are migrated towards regions of high likelihood based on the solution of a partial differential equation. This makes it possible to obtain good object detection and tracking performance with a relatively small number of particles even if object states are high dimensional and sensor measurements are very informative. Simulation results demonstrate reduced computational complexity and memory requirements as well as favorable detection and estimation accuracy in a challenging 3-D MOT scenario.",
        "published": "2021-03-16T10:46:30Z",
        "link": "http://arxiv.org/abs/2103.08968v1",
        "categories": [
            "eess.SP",
            "cs.MA",
            "cs.RO",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Formation Control for UAVs Using a Flux Guided Approach",
        "authors": [
            "John Hartley",
            "Hubert P. H. Shum",
            "Edmond S. L. Ho",
            "He Wang",
            "Subramanian Ramamoorthy"
        ],
        "summary": "Existing studies on formation control for unmanned aerial vehicles (UAV) have not considered encircling targets where an optimum coverage of the target is required at all times. Such coverage plays a critical role in many real-world applications such as tracking hostile UAVs. This paper proposes a new path planning approach called the Flux Guided (FG) method, which generates collision-free trajectories for multiple UAVs while maximising the coverage of target(s). Our method enables UAVs to track directly toward a target whilst maintaining maximum coverage. Furthermore, multiple scattered targets can be tracked by scaling the formation during flight. FG is highly scalable since it only requires communication between sub-set of UAVs on the open boundary of the formation's surface. Experimental results further validate that FG generates UAV trajectories $1.5 \\times$ shorter than previous work and that trajectory planning for 9 leader/follower UAVs to surround a target in two different scenarios only requires 0.52 seconds and 0.88 seconds, respectively. The resulting trajectories are suitable for robotic controls after time-optimal parameterisation; we demonstrate this using a 3d dynamic particle system that tracks the desired trajectories using a PID controller.",
        "published": "2021-03-16T16:30:56Z",
        "link": "http://arxiv.org/abs/2103.09184v2",
        "categories": [
            "cs.RO",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Learning in Nonzero-Sum Stochastic Games with Potentials",
        "authors": [
            "David Mguni",
            "Yutong Wu",
            "Yali Du",
            "Yaodong Yang",
            "Ziyi Wang",
            "Minne Li",
            "Ying Wen",
            "Joel Jennings",
            "Jun Wang"
        ],
        "summary": "Multi-agent reinforcement learning (MARL) has become effective in tackling discrete cooperative game scenarios. However, MARL has yet to penetrate settings beyond those modelled by team and zero-sum games, confining it to a small subset of multi-agent systems. In this paper, we introduce a new generation of MARL learners that can handle nonzero-sum payoff structures and continuous settings. In particular, we study the MARL problem in a class of games known as stochastic potential games (SPGs) with continuous state-action spaces. Unlike cooperative games, in which all agents share a common reward, SPGs are capable of modelling real-world scenarios where agents seek to fulfil their individual goals. We prove theoretically our learning method, SPot-AC, enables independent agents to learn Nash equilibrium strategies in polynomial time. We demonstrate our framework tackles previously unsolvable tasks such as Coordination Navigation and large selfish routing games and that it outperforms the state of the art MARL baselines such as MADDPG and COMIX in such scenarios.",
        "published": "2021-03-16T19:02:01Z",
        "link": "http://arxiv.org/abs/2103.09284v4",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Decentralized Reinforcement Learning for Multi-Target Search and   Detection by a Team of Drones",
        "authors": [
            "Roi Yehoshua",
            "Juan Heredia-Juesas",
            "Yushu Wu",
            "Christopher Amato",
            "Jose Martinez-Lorenzo"
        ],
        "summary": "Targets search and detection encompasses a variety of decision problems such as coverage, surveillance, search, observing and pursuit-evasion along with others. In this paper we develop a multi-agent deep reinforcement learning (MADRL) method to coordinate a group of aerial vehicles (drones) for the purpose of locating a set of static targets in an unknown area. To that end, we have designed a realistic drone simulator that replicates the dynamics and perturbations of a real experiment, including statistical inferences taken from experimental data for its modeling. Our reinforcement learning method, which utilized this simulator for training, was able to find near-optimal policies for the drones. In contrast to other state-of-the-art MADRL methods, our method is fully decentralized during both learning and execution, can handle high-dimensional and continuous observation spaces, and does not require tuning of additional hyperparameters.",
        "published": "2021-03-17T09:04:47Z",
        "link": "http://arxiv.org/abs/2103.09520v1",
        "categories": [
            "cs.RO",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Accretive Computation of Global Transformations",
        "authors": [
            "Alexandre Fernandez",
            "Luidnel Maignan",
            "Antoine Spicher"
        ],
        "summary": "Global transformations form a categorical framework adapting graph transformations to describe fully synchronous rule systems on a given data structure.In this work we focus on data structures that can be captured as presheaves and study the computational aspects of such synchronous rule systems.To obtain an online algorithm, a complete study of the sub-steps within each synchronous step is done at the semantic level.This leads to the definition of accretive rule systems and a local criterion to characterize these systems.Finally an online computation algorithm for theses systems is given.",
        "published": "2021-03-17T13:24:12Z",
        "link": "http://arxiv.org/abs/2103.09636v2",
        "categories": [
            "cs.DC",
            "cs.MA",
            "math.CT",
            "nlin.CG"
        ]
    },
    {
        "title": "Decentralized Fictitious Play in Near-Potential Games with Time-Varying   Communication Networks",
        "authors": [
            "Sarper Aydın",
            "Sina Arefizadeh",
            "Ceyhun Eksin"
        ],
        "summary": "We study the convergence properties of decentralized fictitious play (DFP) for the class of near-potential games where the incentives of agents are nearly aligned with a potential function. In DFP, agents share information only with their current neighbors in a sequence of time-varying networks, keep estimates of other agents' empirical frequencies, and take actions to maximize their expected utility functions computed with respect to the estimated empirical frequencies. We show that empirical frequencies of actions converge to a set of strategies with potential function values that are larger than the potential function values obtained by approximate Nash equilibria of the closest potential game. This result establishes that DFP has identical convergence guarantees in near-potential games as the standard fictitious play in which agents observe the past actions of all the other agents.",
        "published": "2021-03-17T18:12:42Z",
        "link": "http://arxiv.org/abs/2103.09845v1",
        "categories": [
            "math.OC",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "CrowdSim: A Hybrid Simulation Model for Failure Prediction in   Crowdsourced Software Development",
        "authors": [
            "Razieh Saremi",
            "Ye Yang",
            "Gregg Vesonder",
            "Guenther Ruhe",
            "He Zhang"
        ],
        "summary": "A typical crowdsourcing software development(CSD) marketplace consists of a list of software tasks as service demands and a pool of freelancer developers as service suppliers. Highly dynamic and competitive CSD market places may result in task failure due to unforeseen risks, such as increased competition over shared worker supply, or uncertainty associated with workers' experience and skills, and so on. To improve CSD effectiveness, it is essential to better understand and plan with respect to dynamic worker characteristics and risks associated with CSD processes. In this paper, we present a hybrid simulation model, CrowdSim, to forecast crowdsourcing task failure risk in competitive CSD platforms. CrowdSim is composed of three layered components: the macro-level reflects the overall crowdsourcing platform based on system dynamics,the meso-level represents the task life cycle based on discrete event simulation, and the micro-level models the crowd workers' decision-making processes based on agent-based simulation. CrowdSim is evaluated through three CSD decision scenarios to demonstrate its effectiveness, using a real-world historical dataset and the results demonstrate CrowdSim's potential in empowering crowdsourcing managers to explore crowdsourcing outcomes with respect to different task scheduling options.",
        "published": "2021-03-17T18:41:53Z",
        "link": "http://arxiv.org/abs/2103.09856v1",
        "categories": [
            "cs.SE",
            "cs.HC",
            "cs.MA"
        ]
    },
    {
        "title": "Computing Parameterized Invariants of Parameterized Petri Nets",
        "authors": [
            "Javier Esparza",
            "Mikhail Raskin",
            "Christoph Welzel"
        ],
        "summary": "A fundamental advantage of Petri net models is the possibility to automatically compute useful system invariants from the syntax of the net. Classical techniques used for this are place invariants, P-components, siphons or traps. Recently, Bozga et al. have presented a novel technique for the \\emph{parameterized} verification of safety properties of systems with a ring or array architecture. They show that the statement \\enquote{for every instance of the parameterized Petri net, all markings satisfying the linear invariants associated to all the P-components, siphons and traps of the instance are safe} can be encoded in \\acs{WS1S} and checked using tools like MONA. However, while the technique certifies that this infinite set of linear invariants extracted from P-components, siphons or traps are strong enough to prove safety, it does not return an explanation of this fact understandable by humans. We present a CEGAR loop that constructs a \\emph{finite} set of \\emph{parameterized} P-components, siphons or traps, whose infinitely many instances are strong enough to prove safety. For this we design parameterization procedures for different architectures.",
        "published": "2021-03-18T14:22:42Z",
        "link": "http://arxiv.org/abs/2103.10280v7",
        "categories": [
            "cs.DC",
            "cs.MA"
        ]
    },
    {
        "title": "A Quasi-centralized Collision-free Path Planning Approach for   Multi-Robot Systems",
        "authors": [
            "Rohith G",
            "Madhu Vadali"
        ],
        "summary": "This paper presents a novel quasi-centralized approach for collision-free path planning of multi-robot systems (MRS) in obstacle-ridden environments. A new formation potential fields (FPF) concept is proposed around a virtual agent, located at the center of the formation which ensures self-organization and maintenance of the formation. The path of the virtual agent is centrally planned and the robots at the minima of the FPF are forced to move along with the virtual agent. In the neighborhood of obstacles, individual robots selfishly avoid collisions, thus marginally deviating from the formation. The proposed quasi-centralized approach introduces formation flexibility into the MRS, which enables MRS to effectively navigate in an obstacle-ridden workspace. Methodical analysis of the proposed approach and guidelines for selecting the FPF are presented. Results using a candidate FPF are shown that ensure a pentagonal formation effectively squeezes through a narrow passage avoiding any collisions with the walls.",
        "published": "2021-03-18T15:19:50Z",
        "link": "http://arxiv.org/abs/2103.10316v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Forward and Backward Bellman equations improve the efficiency of EM   algorithm for DEC-POMDP",
        "authors": [
            "Takehiro Tottori",
            "Tetsuya J. Kobayashi"
        ],
        "summary": "Decentralized partially observable Markov decision process (DEC-POMDP) models sequential decision making problems by a team of agents. Since the planning of DEC-POMDP can be interpreted as the maximum likelihood estimation for the latent variable model, DEC-POMDP can be solved by the EM algorithm. However, in EM for DEC-POMDP, the forward--backward algorithm needs to be calculated up to the infinite horizon, which impairs the computational efficiency. In this paper, we propose the Bellman EM algorithm (BEM) and the modified Bellman EM algorithm (MBEM) by introducing the forward and backward Bellman equations into EM. BEM can be more efficient than EM because BEM calculates the forward and backward Bellman equations instead of the forward--backward algorithm up to the infinite horizon. However, BEM cannot always be more efficient than EM when the size of problems is large because BEM calculates an inverse matrix. We circumvent this shortcoming in MBEM by calculating the forward and backward Bellman equations without the inverse matrix. Our numerical experiments demonstrate that the convergence of MBEM is faster than that of EM.",
        "published": "2021-03-19T11:35:58Z",
        "link": "http://arxiv.org/abs/2103.10752v2",
        "categories": [
            "cs.LG",
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "Multi-Agent Algorithms for Collective Behavior: A structural and   application-focused atlas",
        "authors": [
            "Federico Rossi",
            "Saptarshi Bandyopadhyay",
            "Michael T. Wolf",
            "Marco Pavone"
        ],
        "summary": "The goal of this paper is to provide a survey and application-focused atlas of collective behavior coordination algorithms for multi-agent systems.   We survey the general family of collective behavior algorithms for multi-agent systems and classify them according to their underlying mathematical structure. In doing so, we aim to capture fundamental mathematical properties of algorithms (e.g., scalability with respect to the number of agents and bandwidth use) and to show how the same algorithm or family of algorithms can be used for multiple tasks and applications.   Collectively, this paper provides an application-focused atlas of algorithms for collective behavior of multi-agent systems, with three objectives:   1. to act as a tutorial guide to practitioners in the selection of coordination algorithms for a given application;   2. to highlight how mathematically similar algorithms can be used for a variety of tasks, ranging from low-level control to high-level coordination;   3. to explore the state-of-the-art in the field of control of multi-agent systems and identify areas for future research.",
        "published": "2021-03-20T00:37:06Z",
        "link": "http://arxiv.org/abs/2103.11067v1",
        "categories": [
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Efficient Global Optimization of Non-differentiable, Symmetric   Objectives for Multi Camera Placement",
        "authors": [
            "Maria L. Hänel",
            "Carola-B. Schönlieb"
        ],
        "summary": "We propose a novel iterative method for optimally placing and orienting multiple cameras in a 3D scene. Sample applications include improving the accuracy of 3D reconstruction, maximizing the covered area for surveillance, or improving the coverage in multi-viewpoint pedestrian tracking. Our algorithm is based on a block-coordinate ascent combined with a surrogate function and an exclusion area technique. This allows to flexibly handle difficult objective functions that are often expensive and quantized or non-differentiable. The solver is globally convergent and easily parallelizable. We show how to accelerate the optimization by exploiting special properties of the objective function, such as symmetry. Additionally, we discuss the trade-off between non-optimal stationary points and the cost reduction when optimizing the viewpoints consecutively.",
        "published": "2021-03-20T17:01:15Z",
        "link": "http://arxiv.org/abs/2103.11210v1",
        "categories": [
            "cs.CV",
            "cs.MA",
            "math.OC",
            "90-05, 90C26, 90C30, 90C56, 90C59",
            "I.4.8; I.6; I.2.10; I.2.11; I.2.8; G.1.6; G.1.1"
        ]
    },
    {
        "title": "Effects of Dynamic-Win-Stay-Lose-Learn model with voluntary   participation in social dilemma",
        "authors": [
            "Zhenyu Shi",
            "Wei Wei",
            "Xiangnan Feng",
            "Ruizhi Zhang",
            "Zhiming Zheng"
        ],
        "summary": "In recent years, Win-Stay-Lose-Learn rule has attracted wide attention as an effective strategy updating rule, and voluntary participation is proposed by introducing a third strategy in Prisoner's dilemma game. Some researches show that combining Win-Stay-Lose-Learn rule with voluntary participation could promote cooperation more significantly under moderate temptation values, however, cooperators' survival under high aspiration levels and high temptation values is still a challenging problem. In this paper, inspired by Achievement Motivation Theory, a Dynamic-Win-Stay-Lose-Learn rule with voluntary participation is investigated, where a dynamic aspiration process is introduced to describe the co-evolution of individuals' strategies and aspirations. It is found that cooperation is extremely promoted and defection is almost extinct in our model, even when the initial aspiration levels and temptation values are high. The combination of dynamic aspiration and voluntary participation plays an active role since loners could survive under high initial aspiration levels and they will expand stably because of their fixed payoffs. The robustness of our model is also discussed and some adverse structures are found which should be alerted in the evolutionary process. Our work provides a more realistic model and shows that cooperators may prevail defectors in an unfavorable initial environment.",
        "published": "2021-03-21T04:30:49Z",
        "link": "http://arxiv.org/abs/2103.11300v1",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Parameterised-Response Zero-Intelligence Traders",
        "authors": [
            "Dave Cliff"
        ],
        "summary": "I introduce PRZI (Parameterised-Response Zero Intelligence), a new form of zero-intelligence trader intended for use in simulation studies of the dynamics of continuous double auction markets. Like Gode & Sunder's classic ZIC trader, PRZI generates quote-prices from a random distribution over some specified domain of allowable quote-prices. Unlike ZIC, which uses a uniform distribution to generate prices, the probability distribution in a PRZI trader is parameterised in such a way that its probability mass function (PMF) is determined by a real-valued control variable s in the range [-1.0, +1.0] that determines the _strategy_ for that trader. When s=0, a PRZI trader is identical to ZIC, with a uniform PMF; but when |s|=~1 the PRZI trader's PMF becomes maximally skewed to one extreme or the other of the price-range, thereby making its quote-prices more or less urgent, biasing the quote-price distribution toward or away from the trader's limit-price. To explore the co-evolutionary dynamics of populations of PRZI traders that dynamically adapt their strategies, I show results from long-term market experiments in which each trader uses a simple stochastic hill-climber algorithm to repeatedly evaluate alternative s-values and choose the most profitable at any given time. In these experiments the profitability of any particular s-value may be non-stationary because the profitability of one trader's strategy at any one time can depend on the mix of strategies being played by the other traders at that time, which are each themselves continuously adapting. Results from these market experiments demonstrate that the population of traders' strategies can exhibit rich dynamics, with periods of stability lasting over hundreds of thousands of trader interactions interspersed by occasional periods of change. Python source-code for the work reported here has been made publicly available on GitHub.",
        "published": "2021-03-21T08:43:39Z",
        "link": "http://arxiv.org/abs/2103.11341v7",
        "categories": [
            "q-fin.TR",
            "cs.CE",
            "cs.GT",
            "cs.MA",
            "econ.TH"
        ]
    },
    {
        "title": "Dual Monte Carlo Tree Search",
        "authors": [
            "Prashank Kadam",
            "Ruiyang Xu",
            "Karl Lieberherr"
        ],
        "summary": "AlphaZero, using a combination of Deep Neural Networks and Monte Carlo Tree Search (MCTS), has successfully trained reinforcement learning agents in a tabula-rasa way. The neural MCTS algorithm has been successful in finding near-optimal strategies for games through self-play. However, the AlphaZero algorithm has a significant drawback; it takes a long time to converge and requires high computational power due to complex neural networks for solving games like Chess, Go, Shogi, etc. Owing to this, it is very difficult to pursue neural MCTS research without cutting-edge hardware, which is a roadblock for many aspiring neural MCTS researchers. In this paper, we propose a new neural MCTS algorithm, called Dual MCTS, which helps overcome these drawbacks. Dual MCTS uses two different search trees, a single deep neural network, and a new update technique for the search trees using a combination of the PUCB, a sliding-window, and the epsilon-greedy algorithm. This technique is applicable to any MCTS based algorithm to reduce the number of updates to the tree. We show that Dual MCTS performs better than one of the most widely used neural MCTS algorithms, AlphaZero, for various symmetric and asymmetric games.",
        "published": "2021-03-21T23:34:11Z",
        "link": "http://arxiv.org/abs/2103.11517v2",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Data-Driven Structured Policy Iteration for Homogeneous Distributed   Systems",
        "authors": [
            "Siavash Alemzadeh",
            "Shahriar Talebi",
            "Mehran Mesbahi"
        ],
        "summary": "Control of networked systems, comprised of interacting agents, is often achieved through modeling the underlying interactions. Constructing accurate models of such interactions--in the meantime--can become prohibitive in applications. Data-driven control methods avoid such complications by directly synthesizing a controller from the observed data. In this paper, we propose an algorithm referred to as Data-driven Structured Policy Iteration (D2SPI), for synthesizing an efficient feedback mechanism that respects the sparsity pattern induced by the underlying interaction network. In particular, our algorithm uses temporary \"auxiliary\" communication links in order to enable the required information exchange on a (smaller) sub-network during the \"learning phase\" -- links that will be removed subsequently for the final distributed feedback synthesis. We then proceed to show that the learned policy results in a stabilizing structured policy for the entire network. Our analysis is then followed by showing the stability and convergence of the proposed distributed policies throughout the learning phase, exploiting a construct referred to as the \"Patterned monoid.'' The performance of D2SPI is then demonstrated using representative simulation scenarios.",
        "published": "2021-03-22T03:47:47Z",
        "link": "http://arxiv.org/abs/2103.11572v2",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY",
            "math.OC"
        ]
    },
    {
        "title": "Multi-agent Aerial Monitoring of Moving Convoys using Elliptical Orbits",
        "authors": [
            "Aseem Vivek Borkar",
            "Girish Chowdhary"
        ],
        "summary": "We propose a novel scheme for surveillance of a dynamic ground convoy moving along a non-linear trajectory, by aerial agents that maintain a uniformly spaced formation on a time-varying elliptical orbit encompassing the convoy. Elliptical orbits are used as they are more economical than circular orbits for circumnavigating the group of targets in the moving convoy. The proposed scheme includes an algorithm for computing feasible elliptical orbits, a vector guidance law for agent motion along the desired orbit, and a cooperative strategy to control the speeds of the aerial agents in order to quickly achieve and maintain the desired formation. It achieves mission objectives while accounting for linear and angular speed constraints on the aerial agents. The scheme is validated through simulations and actual experiments with a convoy of ground robots and a team of quadrotors as the aerial agents, in a motion capture environment.",
        "published": "2021-03-22T04:00:07Z",
        "link": "http://arxiv.org/abs/2103.11574v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Regularized Softmax Deep Multi-Agent $Q$-Learning",
        "authors": [
            "Ling Pan",
            "Tabish Rashid",
            "Bei Peng",
            "Longbo Huang",
            "Shimon Whiteson"
        ],
        "summary": "Tackling overestimation in $Q$-learning is an important problem that has been extensively studied in single-agent reinforcement learning, but has received comparatively little attention in the multi-agent setting. In this work, we empirically demonstrate that QMIX, a popular $Q$-learning algorithm for cooperative multi-agent reinforcement learning (MARL), suffers from a more severe overestimation in practice than previously acknowledged, and is not mitigated by existing approaches. We rectify this with a novel regularization-based update scheme that penalizes large joint action-values that deviate from a baseline and demonstrate its effectiveness in stabilizing learning. Furthermore, we propose to employ a softmax operator, which we efficiently approximate in a novel way in the multi-agent setting, to further reduce the potential overestimation bias. Our approach, Regularized Softmax (RES) Deep Multi-Agent $Q$-Learning, is general and can be applied to any $Q$-learning based MARL algorithm. We demonstrate that, when applied to QMIX, RES avoids severe overestimation and significantly improves performance, yielding state-of-the-art results in a variety of cooperative multi-agent tasks, including the challenging StarCraft II micromanagement benchmarks.",
        "published": "2021-03-22T14:18:39Z",
        "link": "http://arxiv.org/abs/2103.11883v2",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Learning to Robustly Negotiate Bi-Directional Lane Usage in   High-Conflict Driving Scenarios",
        "authors": [
            "Christoph Killing",
            "Adam Villaflor",
            "John M. Dolan"
        ],
        "summary": "Recently, autonomous driving has made substantial progress in addressing the most common traffic scenarios like intersection navigation and lane changing. However, most of these successes have been limited to scenarios with well-defined traffic rules and require minimal negotiation with other vehicles. In this paper, we introduce a previously unconsidered, yet everyday, high-conflict driving scenario requiring negotiations between agents of equal rights and priorities. There exists no centralized control structure and we do not allow communications. Therefore, it is unknown if other drivers are willing to cooperate, and if so to what extent. We train policies to robustly negotiate with opposing vehicles of an unobservable degree of cooperativeness using multi-agent reinforcement learning (MARL). We propose Discrete Asymmetric Soft Actor-Critic (DASAC), a maximum-entropy off-policy MARL algorithm allowing for centralized training with decentralized execution. We show that using DASAC we are able to successfully negotiate and traverse the scenario considered over 99% of the time. Our agents are robust to an unknown timing of opponent decisions, an unobservable degree of cooperativeness of the opposing vehicle, and previously unencountered policies. Furthermore, they learn to exhibit human-like behaviors such as defensive driving, anticipating solution options and interpreting the behavior of other agents.",
        "published": "2021-03-22T14:46:43Z",
        "link": "http://arxiv.org/abs/2103.12070v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Gamified and Self-Adaptive Applications for the Common Good: Research   Challenges Ahead",
        "authors": [
            "Antonio Bucchiarone",
            "Antonio Cicchetti",
            "Nelly Bencomo",
            "Enrica Loria",
            "Annapaola Marconi"
        ],
        "summary": "Motivational digital systems offer capabilities to engage and motivate end-users to foster behavioral changes towards a common goal. In general these systems use gamification principles in non-games contexts. Over the years, gamification has gained consensus among researchers and practitioners as a tool to motivate people to perform activities with the ultimate goal of promoting behavioural change, or engaging the users to perform activities that can offer relevant benefits but which can be seen as unrewarding and even tedious.   There exists a plethora of heterogeneous application scenarios towards reaching the common good that can benefit from gamification. However, an open problem is how to effectively combine multiple motivational campaigns to maximise the degree of participation without exposing the system to counterproductive behaviours.   We conceive motivational digital systems as multi-agent systems: self-adaptation is a feature of the overall system, while individual agents may self-adapt in order to leverage other agents' resources, functionalities and capabilities to perform tasks more efficiently and effectively. Consequently, multiple campaigns can be run and adapted to reach common good. At the same time, agents are grouped into micro-communities in which agents contribute with their own social capital and leverage others' capabilities to balance their weaknesses.   In this paper we propose our vision on how the principles at the base of the autonomous and multi-agent systems can be exploited to design multi-challenge motivational systems to engage smart communities towards common goals. We present an initial version of a general framework based on the MAPE-K loop and a set of research challenges that characterise our research roadmap for the implementation of our vision.",
        "published": "2021-03-22T18:56:44Z",
        "link": "http://arxiv.org/abs/2103.15559v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "The dynamical regime and its importance for evolvability, task   performance and generalization",
        "authors": [
            "Jan Prosi",
            "Sina Khajehabdollahi",
            "Emmanouil Giannakakis",
            "Georg Martius",
            "Anna Levina"
        ],
        "summary": "It has long been hypothesized that operating close to the critical state is beneficial for natural and artificial systems. We test this hypothesis by evolving foraging agents controlled by neural networks that can change the system's dynamical regime throughout evolution. Surprisingly, we find that all populations, regardless of their initial regime, evolve to be subcritical in simple tasks and even strongly subcritical populations can reach comparable performance. We hypothesize that the moderately subcritical regime combines the benefits of generalizability and adaptability brought by closeness to criticality with the stability of the dynamics characteristic for subcritical systems. By a resilience analysis, we find that initially critical agents maintain their fitness level even under environmental changes and degrade slowly with increasing perturbation strength. On the other hand, subcritical agents originally evolved to the same fitness, were often rendered utterly inadequate and degraded faster. We conclude that although the subcritical regime is preferable for a simple task, the optimal deviation from criticality depends on the task difficulty: for harder tasks, agents evolve closer to criticality. Furthermore, subcritical populations cannot find the path to decrease their distance to criticality. In summary, our study suggests that initializing models near criticality is important to find an optimal and flexible solution.",
        "published": "2021-03-22T21:22:52Z",
        "link": "http://arxiv.org/abs/2103.12184v1",
        "categories": [
            "cs.NE",
            "cond-mat.dis-nn",
            "cs.MA",
            "nlin.AO",
            "q-bio.PE"
        ]
    },
    {
        "title": "Reward-Reinforced Reinforcement Learning for Multi-agent Systems",
        "authors": [
            "Changgang Zheng",
            "Shufan Yang",
            "Juan Parra-Ullauri",
            "Antonio Garcia-Dominguez",
            "Nelly Bencomo"
        ],
        "summary": "Reinforcement learning algorithms in multi-agent systems deliver highly resilient and adaptable solutions for common problems in telecommunications,aerospace, and industrial robotics. However, achieving an optimal global goal remains a persistent obstacle for collaborative multi-agent systems, where learning affects the behaviour of more than one agent. A number of nonlinear function approximation methods have been proposed for solving the Bellman equation, which describe a recursive format of an optimal policy. However, how to leverage the value distribution based on reinforcement learning, and how to improve the efficiency and efficacy of such systems remain a challenge. In this work, we developed a reward-reinforced generative adversarial network to represent the distribution of the value function, replacing the approximation of Bellman updates. We demonstrated our method is resilient and outperforms other conventional reinforcement learning methods. This method is also applied to a practical case study: maximising the number of user connections to autonomous airborne base stations in a mobile communication network. Our method maximises the data likelihood using a cost function under which agents have optimal learned behaviours. This reward-reinforced generative adversarial network can be used as ageneric framework for multi-agent learning at the system level",
        "published": "2021-03-22T21:50:09Z",
        "link": "http://arxiv.org/abs/2103.12192v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Differentiable Agent-Based Simulation for Gradient-Guided   Simulation-Based Optimization",
        "authors": [
            "Philipp Andelfinger"
        ],
        "summary": "Simulation-based optimization using agent-based models is typically carried out under the assumption that the gradient describing the sensitivity of the simulation output to the input cannot be evaluated directly. To still apply gradient-based optimization methods, which efficiently steer the optimization towards a local optimum, gradient estimation methods can be employed. However, many simulation runs are needed to obtain accurate estimates if the input dimension is large. Automatic differentiation (AD) is a family of techniques to compute gradients of general programs directly. Here, we explore the use of AD in the context of time-driven agent-based simulations. By substituting common discrete model elements such as conditional branching with smooth approximations, we obtain gradient information across discontinuities in the model logic. On the example of microscopic traffic models and an epidemics model, we study the fidelity and overhead of the differentiable models, as well as the convergence speed and solution quality achieved by gradient-based optimization compared to gradient-free methods. In traffic signal timing optimization problems with high input dimension, the gradient-based methods exhibit substantially superior performance. Finally, we demonstrate that the approach enables gradient-based training of neural network-controlled simulation entities embedded in the model logic.",
        "published": "2021-03-23T11:58:21Z",
        "link": "http://arxiv.org/abs/2103.12476v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "cs.NE",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Safe Multi-Agent Reinforcement Learning through Decentralized Multiple   Control Barrier Functions",
        "authors": [
            "Zhiyuan Cai",
            "Huanhui Cao",
            "Wenjie Lu",
            "Lin Zhang",
            "Hao Xiong"
        ],
        "summary": "Multi-Agent Reinforcement Learning (MARL) algorithms show amazing performance in simulation in recent years, but placing MARL in real-world applications may suffer safety problems. MARL with centralized shields was proposed and verified in safety games recently. However, centralized shielding approaches can be infeasible in several real-world multi-agent applications that involve non-cooperative agents or communication delay. Thus, we propose to combine MARL with decentralized Control Barrier Function (CBF) shields based on available local information. We establish a safe MARL framework with decentralized multiple CBFs and develop Multi-Agent Deep Deterministic Policy Gradient (MADDPG) to Multi-Agent Deep Deterministic Policy Gradient with decentralized multiple Control Barrier Functions (MADDPG-CBF). Based on a collision-avoidance problem that includes not only cooperative agents but obstacles, we demonstrate the construction of multiple CBFs with safety guarantees in theory. Experiments are conducted and experiment results verify that the proposed safe MARL framework can guarantee the safety of agents included in MARL.",
        "published": "2021-03-23T13:54:21Z",
        "link": "http://arxiv.org/abs/2103.12553v1",
        "categories": [
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Pursuing robust decisions in uncertain traffic equilibrium problems",
        "authors": [
            "Filippo Fabiani"
        ],
        "summary": "We evaluate the robustness of agents' traffic equilibria in randomized routing games characterized by an uncertain network demand with a possibly unknown probability distribution. Specifically, we extend the so-called hose model by considering a traffic equilibrium model where the uncertain network demand configuration belongs to a polyhedral set, whose shape is itself a-priori unknown. By exploiting available data, we apply the scenario approach theory to establish distribution-free feasibility guarantees for agents' traffic equilibria of the uncertain routing game without the need to know an explicit characterization of such set. A numerical example on a traffic network testbed corroborates the proposed theoretical results.",
        "published": "2021-03-23T14:38:33Z",
        "link": "http://arxiv.org/abs/2103.12585v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY",
            "math.OC"
        ]
    },
    {
        "title": "Spatial Intention Maps for Multi-Agent Mobile Manipulation",
        "authors": [
            "Jimmy Wu",
            "Xingyuan Sun",
            "Andy Zeng",
            "Shuran Song",
            "Szymon Rusinkiewicz",
            "Thomas Funkhouser"
        ],
        "summary": "The ability to communicate intention enables decentralized multi-agent robots to collaborate while performing physical tasks. In this work, we present spatial intention maps, a new intention representation for multi-agent vision-based deep reinforcement learning that improves coordination between decentralized mobile manipulators. In this representation, each agent's intention is provided to other agents, and rendered into an overhead 2D map aligned with visual observations. This synergizes with the recently proposed spatial action maps framework, in which state and action representations are spatially aligned, providing inductive biases that encourage emergent cooperative behaviors requiring spatial coordination, such as passing objects to each other or avoiding collisions. Experiments across a variety of multi-agent environments, including heterogeneous robot teams with different abilities (lifting, pushing, or throwing), show that incorporating spatial intention maps improves performance for different mobile manipulation tasks while significantly enhancing cooperative behaviors.",
        "published": "2021-03-23T17:31:14Z",
        "link": "http://arxiv.org/abs/2103.12710v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.CV",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "A Review & Framework for Modeling Complex Engineered System Development   Processes",
        "authors": [
            "John Meluso",
            "Jesse Austin-Breneman",
            "James P. Bagrow",
            "Laurent Hébert-Dufresne"
        ],
        "summary": "Developing complex engineered systems (CES) poses significant challenges for engineers, managers, designers, and businesspeople alike due to the inherent complexity of the systems and contexts involved. Furthermore, experts have expressed great interest in filling the gap in theory about how CES develop. This article begins to address that gap in two ways. First, it reviews the numerous definitions of CES along with existing theory and methods on CES development processes. Then, it proposes the ComplEx System Integrated Utilities Model (CESIUM), a novel framework for exploring how numerous system and development process characteristics may affect the performance of CES. CESIUM creates simulated representations of a system architecture, the corresponding engineering organization, and the new product development process through which the organization designs the system. It does so by representing the system as a network of interdependent artifacts designed by agents. Agents iteratively design their artifacts through optimization and share information with other agents, thereby advancing the CES toward a solution. This paper describes the model, conducts a sensitivity analysis, provides validation, and suggests directions for future study.",
        "published": "2021-03-23T20:12:51Z",
        "link": "http://arxiv.org/abs/2103.12820v2",
        "categories": [
            "cs.MA",
            "cs.SI",
            "nlin.AO"
        ]
    },
    {
        "title": "Online Learning in Budget-Constrained Dynamic Colonel Blotto Games",
        "authors": [
            "Vincent Leon",
            "S. Rasoul Etesami"
        ],
        "summary": "In this paper, we study the strategic allocation of limited resources using a Colonel Blotto game (CBG) under a dynamic setting and analyze the problem using an online learning approach. In this model, one of the players is a learner who has limited troops to allocate over a finite time horizon, and the other player is an adversary. In each round, the learner plays a one-shot Colonel Blotto game with the adversary and strategically determines the allocation of troops among battlefields based on past observations. The adversary chooses its allocation action randomly from some fixed distribution that is unknown to the learner. The learner's objective is to minimize its regret, which is the difference between the cumulative reward of the best mixed strategy and the realized cumulative reward by following a learning algorithm while not violating the budget constraint. The learning in dynamic CBG is analyzed under the framework of combinatorial bandits and bandits with knapsacks. We first convert the budget-constrained dynamic CBG to a path planning problem on a directed graph. We then devise an efficient algorithm that combines a special combinatorial bandit algorithm for path planning problem and a bandits with knapsack algorithm to cope with the budget constraint. The theoretical analysis shows that the learner's regret is bounded by a term sublinear in time horizon and polynomial in other parameters. Finally, we justify our theoretical results by carrying out simulations for various scenarios.",
        "published": "2021-03-23T20:52:56Z",
        "link": "http://arxiv.org/abs/2103.12833v4",
        "categories": [
            "cs.LG",
            "cs.GT",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Is radicalization reinforced by social media censorship?",
        "authors": [
            "Justin E. Lane",
            "Kevin McCaffree",
            "F. LeRon Shults"
        ],
        "summary": "Radicalized beliefs, such as those tied to QAnon, Russiagate, and other political conspiracy theories, can lead some individuals and groups to engage in violent behavior, as evidenced in recent months. Understanding the mechanisms by which such beliefs are accepted, spread, and intensified is critical for any attempt to mitigate radicalization and avoid increased political polarization. This article presents and agent-based model of a social media network that enables investigation of the effects of censorship on the amount of dissenting information to which agents become exposed and the certainty of their radicalized views. The model explores two forms of censorship: 1) decentralized censorship-in which individuals can choose to break an online social network tie (unfriend or unfollow) with another individual who transmits conflicting beliefs and 2) centralized censorship-in which a single authority can ban an individual from the social media network for spreading a certain type of belief. This model suggests that both forms of censorship increase certainty in radicalized views by decreasing the amount of dissent to which an agent is exposed, but centralized \"banning\" of individuals has the strongest effect on radicalization.",
        "published": "2021-03-23T21:07:34Z",
        "link": "http://arxiv.org/abs/2103.12842v1",
        "categories": [
            "cs.SI",
            "cs.CY",
            "cs.MA"
        ]
    },
    {
        "title": "Receding Horizon Motion Planning for Multi-Agent Systems: A Velocity   Obstacle Based Probabilistic Method",
        "authors": [
            "Xiaoxue Zhang",
            "Jun Ma",
            "Zilong Cheng",
            "Sunan Huang",
            "Tong Heng Lee"
        ],
        "summary": "In this paper, a novel and innovative methodology for feasible motion planning in the multi-agent system is developed. On the basis of velocity obstacles characteristics, the chance constraints are formulated in the receding horizon control (RHC) problem, and geometric information of collision cones is used to generate the feasible regions of velocities for the host agent. By this approach, the motion planning is conducted at the velocity level instead of the position level. Thus, it guarantees a safer collision-free trajectory for the multi-agent system, especially for the systems with high-speed moving agents. Moreover, a probability threshold of potential collisions can be satisfied during the motion planning process. In order to validate the effectiveness of the methodology, different scenarios for multiple agents are investigated, and the simulation results clearly show that the proposed approach can effectively avoid potential collisions with a collision probability less than a specific threshold.",
        "published": "2021-03-24T03:46:40Z",
        "link": "http://arxiv.org/abs/2103.12968v1",
        "categories": [
            "cs.RO",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "The Gradient Convergence Bound of Federated Multi-Agent Reinforcement   Learning with Efficient Communication",
        "authors": [
            "Xing Xu",
            "Rongpeng Li",
            "Zhifeng Zhao",
            "Honggang Zhang"
        ],
        "summary": "The paper considers independent reinforcement learning (IRL) for multi-agent collaborative decision-making in the paradigm of federated learning (FL). However, FL generates excessive communication overheads between agents and a remote central server, especially when it involves a large number of agents or iterations. Besides, due to the heterogeneity of independent learning environments, multiple agents may undergo asynchronous Markov decision processes (MDPs), which will affect the training samples and the model's convergence performance. On top of the variation-aware periodic averaging (VPA) method and the policy-based deep reinforcement learning (DRL) algorithm (i.e., proximal policy optimization (PPO)), this paper proposes two advanced optimization schemes orienting to stochastic gradient descent (SGD): 1) A decay-based scheme gradually decays the weights of a model's local gradients with the progress of successive local updates, and 2) By representing the agents as a graph, a consensus-based scheme studies the impact of exchanging a model's local gradients among nearby agents from an algebraic connectivity perspective. This paper also provides novel convergence guarantees for both developed schemes, and demonstrates their superior effectiveness and efficiency in improving the system's utility value through theoretical analyses and simulation results.",
        "published": "2021-03-24T07:21:43Z",
        "link": "http://arxiv.org/abs/2103.13026v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Pyfectious: An individual-level simulator to discover optimal   containment polices for epidemic diseases",
        "authors": [
            "Arash Mehrjou",
            "Ashkan Soleymani",
            "Amin Abyaneh",
            "Samir Bhatt",
            "Bernhard Schölkopf",
            "Stefan Bauer"
        ],
        "summary": "Simulating the spread of infectious diseases in human communities is critical for predicting the trajectory of an epidemic and verifying various policies to control the devastating impacts of the outbreak. Many existing simulators are based on compartment models that divide people into a few subsets and simulate the dynamics among those subsets using hypothesized differential equations. However, these models lack the requisite granularity to study the effect of intelligent policies that influence every individual in a particular way. In this work, we introduce a simulator software capable of modeling a population structure and controlling the disease's propagation at an individualistic level. In order to estimate the confidence of the conclusions drawn from the simulator, we employ a comprehensive probabilistic approach where the entire population is constructed as a hierarchical random variable. This approach makes the inferred conclusions more robust against sampling artifacts and gives confidence bounds for decisions based on the simulation results. To showcase potential applications, the simulator parameters are set based on the formal statistics of the COVID-19 pandemic, and the outcome of a wide range of control measures is investigated. Furthermore, the simulator is used as the environment of a reinforcement learning problem to find the optimal policies to control the pandemic. The obtained experimental results indicate the simulator's adaptability and capacity in making sound predictions and a successful policy derivation example based on real-world data. As an exemplary application, our results show that the proposed policy discovery method can lead to control measures that produce significantly fewer infected individuals in the population and protect the health system against saturation.",
        "published": "2021-03-24T10:54:46Z",
        "link": "http://arxiv.org/abs/2103.15561v2",
        "categories": [
            "q-bio.PE",
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Multi-Agent Off-Policy TD Learning: Finite-Time Analysis with   Near-Optimal Sample Complexity and Communication Complexity",
        "authors": [
            "Ziyi Chen",
            "Yi Zhou",
            "Rongrong Chen"
        ],
        "summary": "The finite-time convergence of off-policy TD learning has been comprehensively studied recently. However, such a type of convergence has not been well established for off-policy TD learning in the multi-agent setting, which covers broader applications and is fundamentally more challenging. This work develops two decentralized TD with correction (TDC) algorithms for multi-agent off-policy TD learning under Markovian sampling. In particular, our algorithms preserve full privacy of the actions, policies and rewards of the agents, and adopt mini-batch sampling to reduce the sampling variance and communication frequency. Under Markovian sampling and linear function approximation, we proved that the finite-time sample complexity of both algorithms for achieving an $\\epsilon$-accurate solution is in the order of $\\mathcal{O}(\\epsilon^{-1}\\ln \\epsilon^{-1})$, matching the near-optimal sample complexity of centralized TD(0) and TDC. Importantly, the communication complexity of our algorithms is in the order of $\\mathcal{O}(\\ln \\epsilon^{-1})$, which is significantly lower than the communication complexity $\\mathcal{O}(\\epsilon^{-1}\\ln \\epsilon^{-1})$ of the existing decentralized TD(0). Experiments corroborate our theoretical findings.",
        "published": "2021-03-24T12:48:08Z",
        "link": "http://arxiv.org/abs/2103.13147v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "Are energy savings the only reason for the emergence of bird echelon   formation?",
        "authors": [
            "Mingming Shi",
            "Julien M. Hendrickx"
        ],
        "summary": "We analyze the conditions under which the emergence of frequently observed echelon formation can be explained solely by the maximization of energy savings. We consider a two-dimensional multi-agent echelon formation, where each agent receives a benefit that depends on its position relative to the others, and adjusts its position to increase this benefit. We analyze the selfish case where each agent maximizes its own benefit, leading to a Nash-equilibrium problem, and the collaborative case in which agents maximize the global benefit of the group. We provide conditions on the benefit function under which the frequently observed echelon formations cannot be Nash equilbriums or group optimums.   We then show that these conditions are satisfied by the conventionally used fixed-wing wake benefit model. This implies that energy saving alone is not sufficient to explain the emergence of the migratory formations observed, based on the fixed-wing model. Hence, either non-aerodynamic aspects or a more accurate model of bird dynamics should be considered to construct such formations.",
        "published": "2021-03-24T17:54:28Z",
        "link": "http://arxiv.org/abs/2103.13381v1",
        "categories": [
            "eess.SY",
            "cs.GT",
            "cs.MA",
            "cs.SY",
            "math.OC"
        ]
    },
    {
        "title": "ModGNN: Expert Policy Approximation in Multi-Agent Systems with a   Modular Graph Neural Network Architecture",
        "authors": [
            "Ryan Kortvelesy",
            "Amanda Prorok"
        ],
        "summary": "Recent work in the multi-agent domain has shown the promise of Graph Neural Networks (GNNs) to learn complex coordination strategies. However, most current approaches use minor variants of a Graph Convolutional Network (GCN), which applies a convolution to the communication graph formed by the multi-agent system. In this paper, we investigate whether the performance and generalization of GCNs can be improved upon. We introduce ModGNN, a decentralized framework which serves as a generalization of GCNs, providing more flexibility. To test our hypothesis, we evaluate an implementation of ModGNN against several baselines in the multi-agent flocking problem. We perform an ablation analysis to show that the most important component of our framework is one that does not exist in a GCN. By varying the number of agents, we also demonstrate that an application-agnostic implementation of ModGNN possesses an improved ability to generalize to new environments.",
        "published": "2021-03-24T18:48:12Z",
        "link": "http://arxiv.org/abs/2103.13446v3",
        "categories": [
            "cs.LG",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Robust Stochastic Stability in Dynamic and Reactive Environments",
        "authors": [
            "Brandon C. Collins",
            "Lisa Hines",
            "Gia Barboza",
            "Philip N. Brown"
        ],
        "summary": "The theory of learning in games has extensively studied situations where agents respond dynamically to each other by optimizing a fixed utility function. However, in many settings of interest, agent utility functions themselves vary as a result of past agent choices. The ongoing COVID-19 pandemic provides an example: a highly prevalent virus may incentivize individuals to wear masks, but extensive adoption of mask-wearing reduces virus prevalence which in turn reduces individual incentives for mask-wearing. This paper develops a general framework using probabilistic coupling methods that can be used to derive the stochastically stable states of log-linear learning in certain games which feature such game-environment feedback. As a case study, we apply this framework to a simple dynamic game-theoretic model of social precautions in an epidemic and give conditions under which maximally cautious social behavior in this model is stochastically stable.",
        "published": "2021-03-24T20:36:36Z",
        "link": "http://arxiv.org/abs/2103.13475v2",
        "categories": [
            "cs.MA",
            "cs.GT"
        ]
    },
    {
        "title": "Compressed Gradient Tracking Methods for Decentralized Optimization with   Linear Convergence",
        "authors": [
            "Yiwei Liao",
            "Zhuorui Li",
            "Kun Huang",
            "Shi Pu"
        ],
        "summary": "Communication compression techniques are of growing interests for solving the decentralized optimization problem under limited communication, where the global objective is to minimize the average of local cost functions over a multi-agent network using only local computation and peer-to-peer communication. In this paper, we first propose a novel compressed gradient tracking algorithm (C-GT) that combines gradient tracking technique with communication compression. In particular, C-GT is compatible with a general class of compression operators that unifies both unbiased and biased compressors. We show that C-GT inherits the advantages of gradient tracking-based algorithms and achieves linear convergence rate for strongly convex and smooth objective functions. In the second part of this paper, we propose an error feedback based compressed gradient tracking algorithm (EF-C-GT) to further improve the algorithm efficiency for biased compression operators. Numerical examples complement the theoretical findings and demonstrate the efficiency and flexibility of the proposed algorithms.",
        "published": "2021-03-25T11:00:49Z",
        "link": "http://arxiv.org/abs/2103.13748v3",
        "categories": [
            "math.OC",
            "cs.DC",
            "cs.MA",
            "cs.SI"
        ]
    },
    {
        "title": "AgentFormer: Agent-Aware Transformers for Socio-Temporal Multi-Agent   Forecasting",
        "authors": [
            "Ye Yuan",
            "Xinshuo Weng",
            "Yanglan Ou",
            "Kris Kitani"
        ],
        "summary": "Predicting accurate future trajectories of multiple agents is essential for autonomous systems, but is challenging due to the complex agent interaction and the uncertainty in each agent's future behavior. Forecasting multi-agent trajectories requires modeling two key dimensions: (1) time dimension, where we model the influence of past agent states over future states; (2) social dimension, where we model how the state of each agent affects others. Most prior methods model these two dimensions separately, e.g., first using a temporal model to summarize features over time for each agent independently and then modeling the interaction of the summarized features with a social model. This approach is suboptimal since independent feature encoding over either the time or social dimension can result in a loss of information. Instead, we would prefer a method that allows an agent's state at one time to directly affect another agent's state at a future time. To this end, we propose a new Transformer, AgentFormer, that jointly models the time and social dimensions. The model leverages a sequence representation of multi-agent trajectories by flattening trajectory features across time and agents. Since standard attention operations disregard the agent identity of each element in the sequence, AgentFormer uses a novel agent-aware attention mechanism that preserves agent identities by attending to elements of the same agent differently than elements of other agents. Based on AgentFormer, we propose a stochastic multi-agent trajectory prediction model that can attend to features of any agent at any previous timestep when inferring an agent's future position. The latent intent of all agents is also jointly modeled, allowing the stochasticity in one agent's behavior to affect other agents. Our method substantially improves the state of the art on well-established pedestrian and autonomous driving datasets.",
        "published": "2021-03-25T17:59:01Z",
        "link": "http://arxiv.org/abs/2103.14023v3",
        "categories": [
            "cs.AI",
            "cs.CV",
            "cs.LG",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Hastily Formed Knowledge Networks and Distributed Situation Awareness   for Collaborative Robotics",
        "authors": [
            "Cyrille Berger",
            "Patrick Doherty",
            "Piotr Rudol",
            "Mariusz Wzorek"
        ],
        "summary": "In the context of collaborative robotics, distributed situation awareness is essential for supporting collective intelligence in teams of robots and human agents where it can be used for both individual and collective decision support. This is particularly important in applications pertaining to emergency rescue and crisis management. During operational missions, data and knowledge is gathered incrementally and in different ways by heterogeneous robots and humans. We describe this as the creation of \\emph{Hastily Formed Knowledge Networks} (HFKNs). The focus of this paper is the specification and prototyping of a general distributed system architecture that supports the creation of HFKNs by teams of robots and humans. The information collected ranges from low-level sensor data to high-level semantic knowledge, the latter represented in part as RDF Graphs. The framework includes a synchronization protocol and associated algorithms that allow for the automatic distribution and sharing of data and knowledge between agents. This is done through the distributed synchronization of RDF Graphs shared between agents. High-level semantic queries specified in SPARQL can be used by robots and humans alike to acquire both knowledge and data content from team members. The system is empirically validated and complexity results of the proposed algorithms are provided. Additionally, a field robotics case study is described, where a 3D mapping mission has been executed using several UAVs in a collaborative emergency rescue scenario while using the full HFKN Framework.",
        "published": "2021-03-25T18:53:18Z",
        "link": "http://arxiv.org/abs/2103.14078v1",
        "categories": [
            "cs.MA",
            "cs.RO",
            "I.2.4; I.2.9; I.2.11"
        ]
    },
    {
        "title": "Preliminary Experimental Results of Context-Aware Teams of Multiple   Autonomous Agents Operating under Constrained Communications",
        "authors": [
            "Jose Martinez-Lorenzo",
            "Jeff Hudack",
            "Yutao Jing",
            "Michael Shaham",
            "Zixuan Liang",
            "Abdullah Al Bashit",
            "Yushu Wu",
            "Weite Zhang",
            "Matthew Skopin",
            "Juan Heredia-Juesas",
            "Yuntao Ma",
            "Tristan Sweeney",
            "Nicolas Ares",
            "Ari Fox"
        ],
        "summary": "This work presents and experimentally test the framework used by our context-aware, distributed team of small Unmanned Aerial Systems (SUAS) capable of operating in real-time, in an autonomous fashion, and under constrained communications. Our framework relies on three layered approach: (1) Operational layer, where fast temporal and narrow spatial decisions are made; (2) Tactical Layer, where temporal and spatial decisions are made for a team of agents; and (3) Strategical Layer, where slow temporal and wide spatial decisions are made for the team of agents. These three layers are coordinated by an ad-hoc, software-defined communications network, which ensures sparse, but timely delivery of messages amongst groups and teams of agents at each layer even under constrained communications. Experimental results are presented for a team of 10 small unmanned aerial systems tasked with searching and monitoring a person in an open area. At the operational layer, our use case presents an agent autonomously performing searching, detection, localization, classification, identification, tracking, and following of the person, while avoiding malicious collisions. At the tactical layer, our experimental use case presents the cooperative interaction of a group of multiple agents that enable the monitoring of the targeted person over a wider spatial and temporal regions. At the strategic layer, our use case involves the detection of complex behaviors-i.e. the person being followed enters a car and runs away, or the person being followed exits the car and runs away-that requires strategic responses to successfully accomplish the mission.",
        "published": "2021-03-25T20:29:58Z",
        "link": "http://arxiv.org/abs/2103.14123v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Automated Worst-Case Performance Analysis of Decentralized Gradient   Descent",
        "authors": [
            "Sebastien Colla",
            "Julien M. Hendrickx"
        ],
        "summary": "We develop a methodology to automatically compute worst-case performance bounds for a class of decentralized algorithms that optimize the average of local functions distributed across a network. We extend the recently proposed PEP approach to decentralized optimization. This approach allows computing the exact worst-case performance and worst-case instance of centralized algorithms by solving an SDP. We obtain an exact formulation when the network matrix is given, and a relaxation when considering entire classes of network matrices characterized by their spectral range. We apply our methodology to the decentralized (sub)gradient method, obtain a nearly tight worst-case performance bound that significantly improves over the literature, and gain insights into the worst communication networks for a given spectral range.",
        "published": "2021-03-26T10:57:07Z",
        "link": "http://arxiv.org/abs/2103.14396v3",
        "categories": [
            "math.OC",
            "cs.MA"
        ]
    },
    {
        "title": "Scalable Coverage Path Planning of Multi-Robot Teams for Monitoring   Non-Convex Areas",
        "authors": [
            "Leighton Collins",
            "Payam Ghassemi",
            "Ehsan T. Esfahani",
            "David Doermann",
            "Karthik Dantu",
            "Souma Chowdhury"
        ],
        "summary": "This paper presents a novel multi-robot coverage path planning (CPP) algorithm - aka SCoPP - that provides a time-efficient solution, with workload balanced plans for each robot in a multi-robot system, based on their initial states. This algorithm accounts for discontinuities (e.g., no-fly zones) in a specified area of interest, and provides an optimized ordered list of way-points per robot using a discrete, computationally efficient, nearest neighbor path planning algorithm. This algorithm involves five main stages, which include the transformation of the user's input as a set of vertices in geographical coordinates, discretization, load-balanced partitioning, auctioning of conflict cells in a discretized space, and a path planning procedure. To evaluate the effectiveness of the primary algorithm, a multi-unmanned aerial vehicle (UAV) post-flood assessment application is considered, and the performance of the algorithm is tested on three test maps of varying sizes. Additionally, our method is compared with a state-of-the-art method created by Guasella et al. Further analyses on scalability and computational time of SCoPP are conducted. The results show that SCoPP is superior in terms of mission completion time; its computing time is found to be under 2 mins for a large map covered by a 150-robot team, thereby demonstrating its computationally scalability.",
        "published": "2021-03-26T19:45:45Z",
        "link": "http://arxiv.org/abs/2103.14709v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Control of Agreement and Disagreement Cascades with Distributed Inputs",
        "authors": [
            "Anastasia Bizyaeva",
            "Timothy Sorochkin",
            "Alessio Franci",
            "Naomi Ehrich Leonard"
        ],
        "summary": "For a group of autonomous communicating agents, the ability to distinguish a meaningful input from disturbance, and come to collective agreement or disagreement in response to that input, is paramount for carrying out coordinated objectives. In this work we study how a cascade of opinion formation spreads through a group of networked decision-makers in response to a distributed input signal. Using a nonlinear opinion dynamics model with dynamic feedback modulation of an attention parameter, we show how the triggering of an opinion cascade and the collective decision itself depend on both the distributed input and the node agreement and disagreement centrality, determined by the spectral properties of the network graph. We further show how the attention dynamics introduce an implicit threshold that distinguishes between distributed inputs that trigger cascades and ones that are rejected as disturbance.",
        "published": "2021-03-26T23:19:01Z",
        "link": "http://arxiv.org/abs/2103.14764v1",
        "categories": [
            "math.OC",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Multi-Robot Distributed Semantic Mapping in Unfamiliar Environments   through Online Matching of Learned Representations",
        "authors": [
            "Stewart Jamieson",
            "Kaveh Fathian",
            "Kasra Khosoussi",
            "Jonathan P. How",
            "Yogesh Girdhar"
        ],
        "summary": "We present a solution to multi-robot distributed semantic mapping of novel and unfamiliar environments. Most state-of-the-art semantic mapping systems are based on supervised learning algorithms that cannot classify novel observations online. While unsupervised learning algorithms can invent labels for novel observations, approaches to detect when multiple robots have independently developed their own labels for the same new class are prone to erroneous or inconsistent matches. These issues worsen as the number of robots in the system increases and prevent fusing the local maps produced by each robot into a consistent global map, which is crucial for cooperative planning and joint mission summarization. Our proposed solution overcomes these obstacles by having each robot learn an unsupervised semantic scene model online and use a multiway matching algorithm to identify consistent sets of matches between learned semantic labels belonging to different robots. Compared to the state of the art, the proposed solution produces 20-60% higher quality global maps that do not degrade even as many more local maps are fused.",
        "published": "2021-03-27T04:22:14Z",
        "link": "http://arxiv.org/abs/2103.14805v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Approval-Based Committee Voting under Incomplete Information",
        "authors": [
            "Aviram Imber",
            "Jonas Israel",
            "Markus Brill",
            "Benny Kimelfeld"
        ],
        "summary": "We investigate approval-based committee voting with incomplete information about the approval preferences of voters. We consider several models of incompleteness where each voter partitions the set of candidates into approved, disapproved, and unknown candidates, possibly with ordinal preference constraints among candidates in the latter category. This captures scenarios where voters have not evaluated all candidates and/or it is unknown where voters draw the threshold between approved and disapproved candidates. We study the complexity of some fundamental computational problems for a number of classic approval-based committee voting rules including Proportional Approval Voting and Chamberlin-Courant. These problems include determining whether a given set of candidates is a possible or necessary winning committee and whether a given candidate is possibly or necessarily a member of the winning committee. We also consider proportional representation axioms and the problem of deciding whether a given committee is possibly or necessarily representative.",
        "published": "2021-03-27T09:11:06Z",
        "link": "http://arxiv.org/abs/2103.14847v3",
        "categories": [
            "cs.GT",
            "cs.CC",
            "cs.MA"
        ]
    },
    {
        "title": "KnowRU: Knowledge Reusing via Knowledge Distillation in Multi-agent   Reinforcement Learning",
        "authors": [
            "Zijian Gao",
            "Kele Xu",
            "Bo Ding",
            "Huaimin Wang",
            "Yiying Li",
            "Hongda Jia"
        ],
        "summary": "Recently, deep Reinforcement Learning (RL) algorithms have achieved dramatically progress in the multi-agent area. However, training the increasingly complex tasks would be time-consuming and resources-exhausting. To alleviate this problem, efficient leveraging the historical experience is essential, which is under-explored in previous studies as most of the exiting methods may fail to achieve this goal in a continuously variational system due to their complicated design and environmental dynamics. In this paper, we propose a method, named \"KnowRU\" for knowledge reusing which can be easily deployed in the majority of the multi-agent reinforcement learning algorithms without complicated hand-coded design. We employ the knowledge distillation paradigm to transfer the knowledge among agents with the goal to accelerate the training phase for new tasks, while improving the asymptotic performance of agents. To empirically demonstrate the robustness and effectiveness of KnowRU, we perform extensive experiments on state-of-the-art multi-agent reinforcement learning (MARL) algorithms on collaborative and competitive scenarios. The results show that KnowRU can outperform the recently reported methods, which emphasizes the importance of the proposed knowledge reusing for MARL.",
        "published": "2021-03-27T12:38:01Z",
        "link": "http://arxiv.org/abs/2103.14891v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Dynamic Information Sharing and Punishment Strategies",
        "authors": [
            "Konstantinos Ntemos",
            "George Pikramenos",
            "Nicholas Kalouptsidis"
        ],
        "summary": "In this paper we study the problem of information sharing among rational self-interested agents as a dynamic game of asymmetric information. We assume that the agents imperfectly observe a Markov chain and they are called to decide whether they will share their noisy observations or not at each time instant. We utilize the notion of conditional mutual information to evaluate the information being shared among the agents. The challenges that arise due to the inter-dependence of agents' information structure and decision-making are exhibited. For the finite horizon game we prove that agents do not have incentive to share information. In contrast, we show that cooperation can be sustained in the infinite horizon case by devising appropriate punishment strategies which are defined over the agents' beliefs on the system state. We show that these strategies are closed under the best-response mapping and that cooperation can be the optimal choice in some subsets of the state belief simplex. We characterize these equilibrium regions, prove uniqueness of a maximal equilibrium region and devise an algorithm for its approximate computation.",
        "published": "2021-03-27T20:09:40Z",
        "link": "http://arxiv.org/abs/2103.14979v1",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Playing Against the Board: Rolling Horizon Evolutionary Algorithms   Against Pandemic",
        "authors": [
            "Konstantinos Sfikas",
            "Antonios Liapis"
        ],
        "summary": "Competitive board games have provided a rich and diverse testbed for artificial intelligence. This paper contends that collaborative board games pose a different challenge to artificial intelligence as it must balance short-term risk mitigation with long-term winning strategies. Collaborative board games task all players to coordinate their different powers or pool their resources to overcome an escalating challenge posed by the board and a stochastic ruleset. This paper focuses on the exemplary collaborative board game Pandemic and presents a rolling horizon evolutionary algorithm designed specifically for this game. The complex way in which the Pandemic game state changes in a stochastic but predictable way required a number of specially designed forward models, macro-action representations for decision-making, and repair functions for the genetic operations of the evolutionary algorithm. Variants of the algorithm which explore optimistic versus pessimistic game state evaluations, different mutation rates and event horizons are compared against a baseline hierarchical policy agent. Results show that an evolutionary approach via short-horizon rollouts can better account for the future dangers that the board may introduce, and guard against them. Results highlight the types of challenges that collaborative board games pose to artificial intelligence, especially for handling multi-player collaboration interactions.",
        "published": "2021-03-28T09:22:10Z",
        "link": "http://arxiv.org/abs/2103.15090v1",
        "categories": [
            "cs.AI",
            "cs.MA",
            "cs.NE"
        ]
    },
    {
        "title": "Synchronization and Control for Multi-Weighted and Directed Complex   Networks",
        "authors": [
            "Xiwei Liu"
        ],
        "summary": "The study of complex networks with multi-weights has been a hot topic recently. For a network with a single weight, previous studies have shown that they can promote synchronization. But for complex networks with multi-weights, there are no rigorous analysis to show that synchronization can be reached faster. In this paper, the complex network is allowed to be directed, which will make the synchronization analysis difficult for multiple couplings. In virtue of the normalized left eigenvectors (NLEVec) corresponding to the zero eigenvalue of coupling matrices, we prove that if the Chebyshev distance between NLEVec is less than some value, which is defined as the allowable deviation bound, then the synchronization and control will be realized with sufficiently large coupling strengths, i.e., all coupling matrices do accelerate synchronization. Moreover, adaptive rules are also designed for the coupling strength.",
        "published": "2021-03-28T21:50:22Z",
        "link": "http://arxiv.org/abs/2103.15230v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "FisherMob : a bioeconomic model of fishers' migrations",
        "authors": [
            "Timothée Brochier",
            "Alassane Bah"
        ],
        "summary": "Sea fishing is a highly mobile activity, favoured by the vastness of the oceans, the absence of physical boundaries and the abstraction of legislative boundaries. Understanding and anticipating this mobility is a major challenge for fisheries management issues, both at the national and international levels. ''FisherMob'' is a free Gama tool designed to study the effect of economic and biological factors on the dynamics of connected fisheries. It incorporate the most important processes involved in fisheries dynamics: fish abundance variability, price of the fishing effort and ex-vessel fish market price that which depends on the ratio between offer and demand. The tool uses as input a scheme of a coastal area with delimited fishing sites, fish biological parameters and fisheries parameters. It runs with a userfriendly graphic interface and generates output files that can be post-processed easily using graphic and statistical software.",
        "published": "2021-03-29T14:34:16Z",
        "link": "http://arxiv.org/abs/2103.16496v1",
        "categories": [
            "q-bio.PE",
            "cs.MA"
        ]
    },
    {
        "title": "Competing Adaptive Networks",
        "authors": [
            "Stefan Vlaski",
            "Ali H. Sayed"
        ],
        "summary": "Adaptive networks have the capability to pursue solutions of global stochastic optimization problems by relying only on local interactions within neighborhoods. The diffusion of information through repeated interactions allows for globally optimal behavior, without the need for central coordination. Most existing strategies are developed for cooperative learning settings, where the objective of the network is common to all agents. We consider in this work a team setting, where a subset of the agents form a team with a common goal while competing with the remainder of the network. We develop an algorithm for decentralized competition among teams of adaptive agents, analyze its dynamics and present an application in the decentralized training of generative adversarial neural networks.",
        "published": "2021-03-29T14:42:15Z",
        "link": "http://arxiv.org/abs/2103.15664v1",
        "categories": [
            "cs.MA",
            "cs.LG",
            "eess.SP",
            "stat.ML"
        ]
    },
    {
        "title": "Scalable Planning in Multi-Agent MDPs",
        "authors": [
            "Dinuka Sahabandu",
            "Luyao Niu",
            "Andrew Clark",
            "Radha Poovendran"
        ],
        "summary": "Multi-agent Markov Decision Processes (MMDPs) arise in a variety of applications including target tracking, control of multi-robot swarms, and multiplayer games. A key challenge in MMDPs occurs when the state and action spaces grow exponentially in the number of agents, making computation of an optimal policy computationally intractable for medium- to large-scale problems. One property that has been exploited to mitigate this complexity is transition independence, in which each agent's transition probabilities are independent of the states and actions of other agents. Transition independence enables factorization of the MMDP and computation of local agent policies but does not hold for arbitrary MMDPs. In this paper, we propose an approximate transition dependence property, called $\\delta$-transition dependence and develop a metric for quantifying how far an MMDP deviates from transition independence. Our definition of $\\delta$-transition dependence recovers transition independence as a special case when $\\delta$ is zero. We develop a polynomial time algorithm in the number of agents that achieves a provable bound on the global optimum when the reward functions are monotone increasing and submodular in the agent actions. We evaluate our approach on two case studies, namely, multi-robot control and multi-agent patrolling example.",
        "published": "2021-03-29T19:04:39Z",
        "link": "http://arxiv.org/abs/2103.15894v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Distributed learning in congested environments with partial information",
        "authors": [
            "Tomer Boyarski",
            "Amir Leshem",
            "Vikram Krishnamurthy"
        ],
        "summary": "How can non-communicating agents learn to share congested resources efficiently? This is a challenging task when the agents can access the same resource simultaneously (in contrast to multi-agent multi-armed bandit problems) and the resource valuations differ among agents. We present a fully distributed algorithm for learning to share in congested environments and prove that the agents' regret with respect to the optimal allocation is poly-logarithmic in the time horizon. Performance in the non-asymptotic regime is illustrated in numerical simulations. The distributed algorithm has applications in cloud computing and spectrum sharing. Keywords: Distributed learning, congestion games, poly-logarithmic regret.",
        "published": "2021-03-29T19:22:32Z",
        "link": "http://arxiv.org/abs/2103.15901v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "FaiR-IoT: Fairness-aware Human-in-the-Loop Reinforcement Learning for   Harnessing Human Variability in Personalized IoT",
        "authors": [
            "Salma Elmalaki"
        ],
        "summary": "Thanks to the rapid growth in wearable technologies, monitoring complex human context becomes feasible, paving the way to develop human-in-the-loop IoT systems that naturally evolve to adapt to the human and environment state autonomously. Nevertheless, a central challenge in designing such personalized IoT applications arises from human variability. Such variability stems from the fact that different humans exhibit different behaviors when interacting with IoT applications (intra-human variability), the same human may change the behavior over time when interacting with the same IoT application (inter-human variability), and human behavior may be affected by the behaviors of other people in the same environment (multi-human variability). To that end, we propose FaiR-IoT, a general reinforcement learning-based framework for adaptive and fairness-aware human-in-the-loop IoT applications. In FaiR-IoT, three levels of reinforcement learning agents interact to continuously learn human preferences and maximize the system's performance and fairness while taking into account the intra-, inter-, and multi-human variability. We validate the proposed framework on two applications, namely (i) Human-in-the-Loop Automotive Advanced Driver Assistance Systems and (ii) Human-in-the-Loop Smart House. Results obtained on these two applications validate the generality of FaiR-IoT and its ability to provide a personalized experience while enhancing the system's performance by 40%-60% compared to non-personalized systems and enhancing the fairness of the multi-human systems by 1.5 orders of magnitude.",
        "published": "2021-03-30T02:30:25Z",
        "link": "http://arxiv.org/abs/2103.16033v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Stability and Control of Chaplygin Beanies Coupled to a Platform through   Nonholonomic Constraints",
        "authors": [
            "Blake Buchanan",
            "Matthew Travers",
            "Howie Choset",
            "Scott Kelly"
        ],
        "summary": "Many multi-agent systems in nature are comprised of agents that interact with, and respond to, the dynamics of their environment. In this paper, we approach the study of such agent-environment interactions through the study of passively compliant vehicles coupled to their environment via simple nonholonomic constraints. We first consider a single passively compliant Chaplygin beanie atop a platform having translational compliance, introduce the reduced equations for the system using the notion of nonholonomic momentum, and provide proof for its stability under arbitrary deformations of the elastic element modeling its compliance. We then direct our focus to results concerning the frequency response and control of passive Chaplygin beanies under actuation of the platform, discuss rich dynamical features arising from periodic actuation, and develop rules by which control can be exerted to collect and disperse multiple passive vehicles. We then discuss how the latter of these results clarifies the extent to which stable behavior can be excited in the system through exogenous control.",
        "published": "2021-03-30T14:17:37Z",
        "link": "http://arxiv.org/abs/2103.16376v2",
        "categories": [
            "nlin.CD",
            "cs.MA"
        ]
    },
    {
        "title": "The Division of Assets in Multiagent Systems: A Case Study in Team   Blotto Games",
        "authors": [
            "Keith Paarporn",
            "Rahul Chandan",
            "Mahnoosh Alizadeh",
            "Jason R. Marden"
        ],
        "summary": "Multi-agent systems are designed to concurrently accomplish a diverse set of tasks at unprecedented scale. Here, the central problems faced by a system operator are to decide (i) how to divide available resources amongst the agents assigned to tasks and (ii) how to coordinate the behavior of the agents to optimize the efficiency of the resulting collective behavior. The focus of this paper is on problem (i), where we seek to characterize the impact of the division of resources on the best-case efficiency of the resulting collective behavior. Specifically, we focus on a team Colonel Blotto game where there are two sub-colonels competing against a common adversary in a two battlefield environment. Here, each sub-colonel is assigned a given resource budget and is required to allocate these resources independent of the other sub-colonel. However, their success is dependent on the allocation strategy of both sub-colonels. The central focus of this manuscript is on how to divide a common pool of resources among the two sub-colonels to optimize the resulting best-case efficiency guarantees. Intuitively, one would imagine that the more balanced the division of resources, the worse the performance, as such divisions restrict the sub-colonels' ability to employ joint randomized strategies that tend to be necessary for optimizing performance guarantees. However, the main result of this paper demonstrates that this intuition is actually incorrect. A more balanced division of resources can offer better performance guarantees than a more centralized division. Hence, this paper demonstrates that the resource division problem is highly non-trivial in such enmeshed environments and worthy of significant future research efforts.",
        "published": "2021-03-30T21:20:18Z",
        "link": "http://arxiv.org/abs/2103.16688v1",
        "categories": [
            "eess.SY",
            "cs.GT",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Cooperator driven oscillation in a time-delayed feedback-evolving game",
        "authors": [
            "Fang Yan",
            "Xiaojie Chen",
            "Zhipeng Qiu",
            "Attila Szolnoki"
        ],
        "summary": "Considering feedback of collective actions of cooperation on common resources has vital importance to reach sustainability. But such efforts may have not immediate consequence on the state of environment and it is unclear how they influence the strategic and environmental dynamics with feedbacks. To address this issue, we construct a feedback-evolving game model in which we consider the growth capacity of resources and the punishment efficiency on defectors who do not provide returns to the environment. Importantly, we further assume a delay in adopting the contribution of cooperative individuals to environmental change in our model. We find that when this contribution amount from cooperators' endowment is fixed, the time delay has no particular consequence on the coevolutionary dynamics. However, when the return is proportional to their endowment, then the time delay can induce periodic oscillatory dynamics of cooperation level and environment. Our work reveals the potential effects of time delay of cooperative actions on the coevolutionary dynamics in strategic interactions with environmental feedback.",
        "published": "2021-03-31T05:11:20Z",
        "link": "http://arxiv.org/abs/2103.16813v1",
        "categories": [
            "physics.soc-ph",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Solving Heterogeneous General Equilibrium Economic Models with Deep   Reinforcement Learning",
        "authors": [
            "Edward Hill",
            "Marco Bardoscia",
            "Arthur Turrell"
        ],
        "summary": "General equilibrium macroeconomic models are a core tool used by policymakers to understand a nation's economy. They represent the economy as a collection of forward-looking actors whose behaviours combine, possibly with stochastic effects, to determine global variables (such as prices) in a dynamic equilibrium. However, standard semi-analytical techniques for solving these models make it difficult to include the important effects of heterogeneous economic actors. The COVID-19 pandemic has further highlighted the importance of heterogeneity, for example in age and sector of employment, in macroeconomic outcomes and the need for models that can more easily incorporate it. We use techniques from reinforcement learning to solve such models incorporating heterogeneous agents in a way that is simple, extensible, and computationally efficient. We demonstrate the method's accuracy and stability on a toy problem for which there is a known analytical solution, its versatility by solving a general equilibrium problem that includes global stochasticity, and its flexibility by solving a combined macroeconomic and epidemiological model to explore the economic and health implications of a pandemic. The latter successfully captures plausible economic behaviours induced by differential health risks by age.",
        "published": "2021-03-31T10:55:10Z",
        "link": "http://arxiv.org/abs/2103.16977v1",
        "categories": [
            "econ.GN",
            "cs.LG",
            "cs.MA",
            "q-fin.EC",
            "stat.ML",
            "91B69",
            "I.2.8; I.6.5; J.4"
        ]
    },
    {
        "title": "Energy Efficient Edge Computing: When Lyapunov Meets Distributed   Reinforcement Learning",
        "authors": [
            "Mohamed Sana",
            "Mattia Merluzzi",
            "Nicola di Pietro",
            "Emilio Calvanese Strinati"
        ],
        "summary": "In this work, we study the problem of energy-efficient computation offloading enabled by edge computing. In the considered scenario, multiple users simultaneously compete for limited radio and edge computing resources to get offloaded tasks processed under a delay constraint, with the possibility of exploiting low power sleep modes at all network nodes. The radio resource allocation takes into account inter- and intra-cell interference, and the duty cycles of the radio and computing equipment have to be jointly optimized to minimize the overall energy consumption. To address this issue, we formulate the underlying problem as a dynamic long-term optimization. Then, based on Lyapunov stochastic optimization tools, we decouple the formulated problem into a CPU scheduling problem and a radio resource allocation problem to be solved in a per-slot basis. Whereas the first one can be optimally and efficiently solved using a fast iterative algorithm, the second one is solved using distributed multi-agent reinforcement learning due to its non-convexity and NP-hardness. The resulting framework achieves up to 96.5% performance of the optimal strategy based on exhaustive search, while drastically reducing complexity. The proposed solution also allows to increase the network's energy efficiency compared to a benchmark heuristic approach.",
        "published": "2021-03-31T11:02:29Z",
        "link": "http://arxiv.org/abs/2103.16985v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "cs.NI"
        ]
    },
    {
        "title": "A multiscale model of urban morphogenesis",
        "authors": [
            "Juste Raimbault"
        ],
        "summary": "The dynamics and processes of urban morphogenesis are a central issue regarding a long-term sustainability of urban systems. They however imply stakeholders and parameters at multiple temporal and spatial scales simultaneously, leading to intricate interactions between dimensions and scales. We introduce in this paper from a theoretical viewpoint a simple agent-based model of urban morphogenesis at the scale of an urban area, with the feature of integrating the microscopic and the mesoscopic scales. At the local level, developer agents drive urban development conditioned by local properties but also an infrastructure network at a smaller scale. The network evolves more slowly following global properties. Indicators of sustainability including modal shares and urban density suggest an application of the model to multi-objective optimisation. We finally discuss possible implementation, extensions and applications of the model.",
        "published": "2021-03-31T17:39:33Z",
        "link": "http://arxiv.org/abs/2103.17241v1",
        "categories": [
            "physics.soc-ph",
            "cs.MA"
        ]
    },
    {
        "title": "AdaPool: A Diurnal-Adaptive Fleet Management Framework using Model-Free   Deep Reinforcement Learning and Change Point Detection",
        "authors": [
            "Marina Haliem",
            "Vaneet Aggarwal",
            "Bharat Bhargava"
        ],
        "summary": "This paper introduces an adaptive model-free deep reinforcement approach that can recognize and adapt to the diurnal patterns in the ride-sharing environment with car-pooling. Deep Reinforcement Learning (RL) suffers from catastrophic forgetting due to being agnostic to the timescale of changes in the distribution of experiences. Although RL algorithms are guaranteed to converge to optimal policies in Markov decision processes (MDPs), this only holds in the presence of static environments. However, this assumption is very restrictive. In many real-world problems like ride-sharing, traffic control, etc., we are dealing with highly dynamic environments, where RL methods yield only sub-optimal decisions. To mitigate this problem in highly dynamic environments, we (1) adopt an online Dirichlet change point detection (ODCP) algorithm to detect the changes in the distribution of experiences, (2) develop a Deep Q Network (DQN) agent that is capable of recognizing diurnal patterns and making informed dispatching decisions according to the changes in the underlying environment. Rather than fixing patterns by time of week, the proposed approach automatically detects that the MDP has changed, and uses the results of the new model. In addition to the adaptation logic in dispatching, this paper also proposes a dynamic, demand-aware vehicle-passenger matching and route planning framework that dynamically generates optimal routes for each vehicle based on online demand, vehicle capacities, and locations. Evaluation on New York City Taxi public dataset shows the effectiveness of our approach in improving the fleet utilization, where less than 50% of the fleet are utilized to serve the demand of up to 90% of the requests, while maximizing profits and minimizing idle times.",
        "published": "2021-04-01T02:14:01Z",
        "link": "http://arxiv.org/abs/2104.00203v2",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Bounding the Inefficiency of Route Control in Intelligent Transport   Systems",
        "authors": [
            "Charlotte Roman",
            "Paolo Turrini"
        ],
        "summary": "Route controlled autonomous vehicles could have a significant impact in reducing congestion in the future. Before applying multi-agent reinforcement learning algorithms to route control, we can model the system using a congestion game to predict and mitigate potential issues. We consider the problem of distributed operating systems in a transportation network that control the routing choices of their assigned vehicles. We formulate an associated network control game, consisting of multiple actors seeking to optimise the social welfare of their assigned subpopulations in an underlying nonatomic congestion game. Then we find the inefficiency of the routing equilibria by calculating the Price of Anarchy for polynomial cost functions. Finally, we extend the analysis to allow vehicles to choose their operating system.",
        "published": "2021-04-01T09:23:54Z",
        "link": "http://arxiv.org/abs/2104.00357v1",
        "categories": [
            "cs.MA",
            "cs.GT"
        ]
    },
    {
        "title": "Consensus-Based Distributed Estimation in the Presence of Heterogeneous,   Time-Invariant Delays",
        "authors": [
            "Mohammadreza Doostmohammadian",
            "Usman A. Khan",
            "Mohammad Pirani",
            "Themistoklis Charalambous"
        ],
        "summary": "Classical distributed estimation scenarios typically assume timely and reliable exchanges of information over the sensor network. This paper, in contrast, considers single time-scale distributed estimation via a sensor network subject to transmission time-delays. The proposed discrete-time networked estimator consists of two steps: (i) consensus on (delayed) a-priori estimates, and (ii) measurement update. The sensors only share their a-priori estimates with their out-neighbors over (possibly) time-delayed transmission links. The delays are assumed to be fixed over time, heterogeneous, and known. We assume distributed observability instead of local observability, which significantly reduces the communication/sensing loads on sensors. Using the notions of augmented matrices and Kronecker product, the convergence of the proposed estimator over strongly-connected networks is proved for a specific upper-bound on the time-delay.",
        "published": "2021-04-01T10:55:20Z",
        "link": "http://arxiv.org/abs/2104.00394v2",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SI",
            "cs.SY",
            "eess.SP",
            "math.DS"
        ]
    },
    {
        "title": "Edge Differential Privacy for Algebraic Connectivity of Graphs",
        "authors": [
            "Bo Chen",
            "Calvin Hawkins",
            "Kasra Yazdani",
            "Matthew Hale"
        ],
        "summary": "Graphs are the dominant formalism for modeling multi-agent systems. The algebraic connectivity of a graph is particularly important because it provides the convergence rates of consensus algorithms that underlie many multi-agent control and optimization techniques. However, sharing the value of algebraic connectivity can inadvertently reveal sensitive information about the topology of a graph, such as connections in social networks. Therefore, in this work we present a method to release a graph's algebraic connectivity under a graph-theoretic form of differential privacy, called edge differential privacy. Edge differential privacy obfuscates differences among graphs' edge sets and thus conceals the absence or presence of sensitive connections therein. We provide privacy with bounded Laplace noise, which improves accuracy relative to conventional unbounded noise. The private algebraic connectivity values are analytically shown to provide accurate estimates of consensus convergence rates, as well as accurate bounds on the diameter of a graph and the mean distance between its nodes. Simulation results confirm the utility of private algebraic connectivity in these contexts.",
        "published": "2021-04-01T17:50:18Z",
        "link": "http://arxiv.org/abs/2104.00654v1",
        "categories": [
            "cs.CR",
            "cs.MA",
            "cs.SI",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "An active inference model of collective intelligence",
        "authors": [
            "Rafael Kaufmann",
            "Pranav Gupta",
            "Jacob Taylor"
        ],
        "summary": "To date, formal models of collective intelligence have lacked a plausible mathematical description of the relationship between local-scale interactions between highly autonomous sub-system components (individuals) and global-scale behavior of the composite system (the collective). In this paper we use the Active Inference Formulation (AIF), a framework for explaining the behavior of any non-equilibrium steady state system at any scale, to posit a minimal agent-based model that simulates the relationship between local individual-level interaction and collective intelligence (operationalized as system-level performance). We explore the effects of providing baseline AIF agents (Model 1) with specific cognitive capabilities: Theory of Mind (Model 2); Goal Alignment (Model 3), and Theory of Mind with Goal Alignment (Model 4). These stepwise transitions in sophistication of cognitive ability are motivated by the types of advancements plausibly required for an AIF agent to persist and flourish in an environment populated by other AIF agents, and have also recently been shown to map naturally to canonical steps in human cognitive ability. Illustrative results show that stepwise cognitive transitions increase system performance by providing complementary mechanisms for alignment between agents' local and global optima. Alignment emerges endogenously from the dynamics of interacting AIF agents themselves, rather than being imposed exogenously by incentives to agents' behaviors (contra existing computational models of collective intelligence) or top-down priors for collective behavior (contra existing multiscale simulations of AIF). These results shed light on the types of generic information-theoretic patterns conducive to collective intelligence in human and other complex adaptive systems.",
        "published": "2021-04-02T14:32:01Z",
        "link": "http://arxiv.org/abs/2104.01066v1",
        "categories": [
            "cs.SI",
            "cs.AI",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "A Dynamics Perspective of Pursuit-Evasion Games of Intelligent Agents   with the Ability to Learn",
        "authors": [
            "Hao Xiong",
            "Huanhui Cao",
            "Lin Zhang",
            "Wenjie Lu"
        ],
        "summary": "Pursuit-evasion games are ubiquitous in nature and in an artificial world. In nature, pursuer(s) and evader(s) are intelligent agents that can learn from experience, and dynamics (i.e., Newtonian or Lagrangian) is vital for the pursuer and the evader in some scenarios. To this end, this paper addresses the pursuit-evasion game of intelligent agents from the perspective of dynamics. A bio-inspired dynamics formulation of a pursuit-evasion game and baseline pursuit and evasion strategies are introduced at first. Then, reinforcement learning techniques are used to mimic the ability of intelligent agents to learn from experience. Based on the dynamics formulation and reinforcement learning techniques, the effects of improving both pursuit and evasion strategies based on experience on pursuit-evasion games are investigated at two levels 1) individual runs and 2) ranges of the parameters of pursuit-evasion games. Results of the investigation are consistent with nature observations and the natural law - survival of the fittest. More importantly, with respect to the result of a pursuit-evasion game of agents with baseline strategies, this study achieves a different result. It is shown that, in a pursuit-evasion game with a dynamics formulation, an evader is not able to escape from a slightly faster pursuer with an effective learned pursuit strategy, based on agile maneuvers and an effective learned evasion strategy.",
        "published": "2021-04-03T16:36:29Z",
        "link": "http://arxiv.org/abs/2104.01445v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Simple Uncoupled No-Regret Learning Dynamics for Extensive-Form   Correlated Equilibrium",
        "authors": [
            "Gabriele Farina",
            "Andrea Celli",
            "Alberto Marchesi",
            "Nicola Gatti"
        ],
        "summary": "The existence of simple uncoupled no-regret learning dynamics that converge to correlated equilibria in normal-form games is a celebrated result in the theory of multi-agent systems. Specifically, it has been known for more than 20 years that when all players seek to minimize their internal regret in a repeated normal-form game, the empirical frequency of play converges to a normal-form correlated equilibrium. Extensive-form games generalize normal-form games by modeling both sequential and simultaneous moves, as well as imperfect information. Because of the sequential nature and presence of private information in the game, correlation in extensive-form games possesses significantly different properties than its counterpart in normal-form games, many of which are still open research directions. Extensive-form correlated equilibrium (EFCE) has been proposed as the natural extensive-form counterpart to the classical notion of correlated equilibrium in normal-form games. Compared to the latter, the constraints that define the set of EFCEs are significantly more complex, as the correlation device must keep into account the evolution of beliefs of each player as they make observations throughout the game. Due to that significant added complexity, the existence of uncoupled learning dynamics leading to an EFCE has remained a challenging open research question for a long time. In this article, we settle that question by giving the first uncoupled no-regret dynamics that converge to the set of EFCEs in n-player general-sum extensive-form games with perfect recall. We show that each iterate can be computed in time polynomial in the size of the game tree, and that, when all players play repeatedly according to our learning dynamics, the empirical frequency of play is proven to be a O(T^-0.5)-approximate EFCE with high probability after T game repetitions, and an EFCE almost surely in the limit.",
        "published": "2021-04-04T02:26:26Z",
        "link": "http://arxiv.org/abs/2104.01520v2",
        "categories": [
            "cs.GT",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "City-scale Simulation of Covid-19 Pandemic and Intervention Policies   using Agent-based Modelling",
        "authors": [
            "Gaurav Suryawanshi",
            "Varun Madhavan",
            "Adway Mitra",
            "Partha Pratim Chakrabarti"
        ],
        "summary": "During the Covid-19 pandemic, most governments across the world imposed policies like lock-down of public spaces and restrictions on people's movements to minimize the spread of the virus through physical contact. However, such policies have grave social and economic costs, and so it is important to pre-assess their impacts. In this work we aim to visualize the dynamics of the pandemic in a city under different intervention policies, by simulating the behavior of the residents. We develop a very detailed agent-based model for a city, including its residents, physical and social spaces like homes, marketplaces, workplaces, schools/colleges etc. We parameterize our model for Kolkata city in India using ward-level demographic and civic data. We demonstrate that under appropriate choice of parameters, our model is able to reproduce the observed dynamics of the Covid-19 pandemic in Kolkata, and also indicate the counter-factual outcomes of alternative intervention policies.",
        "published": "2021-04-04T17:30:57Z",
        "link": "http://arxiv.org/abs/2104.01650v2",
        "categories": [
            "cs.MA",
            "stat.AP"
        ]
    },
    {
        "title": "NQMIX: Non-monotonic Value Function Factorization for Deep Multi-Agent   Reinforcement Learning",
        "authors": [
            "Quanlin Chen"
        ],
        "summary": "Multi-agent value-based approaches recently make great progress, especially value decomposition methods. However, there are still a lot of limitations in value function factorization. In VDN, the joint action-value function is the sum of per-agent action-value function while the joint action-value function of QMIX is the monotonic mixing of per-agent action-value function. To some extent, QTRAN reduces the limitation of joint action-value functions that can be represented, but it has unsatisfied performance in complex tasks. In this paper, in order to extend the class of joint value functions that can be represented, we propose a novel actor-critic method called NQMIX. NQMIX introduces an off-policy policy gradient on QMIX and modify its network architecture, which can remove the monotonicity constraint of QMIX and implement a non-monotonic value function factorization for the joint action-value function. In addition, NQMIX takes the state-value as the learning target, which overcomes the problem in QMIX that the learning target is overestimated. Furthermore, NQMIX can be extended to continuous action space settings by introducing deterministic policy gradient on itself. Finally, we evaluate our actor-critic methods on SMAC domain, and show that it has a stronger performance than COMA and QMIX on complex maps with heterogeneous agent types. In addition, our ablation results show that our modification of mixer is effective.",
        "published": "2021-04-05T14:56:09Z",
        "link": "http://arxiv.org/abs/2104.01939v4",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Self-Healing First-Order Distributed Optimization",
        "authors": [
            "Israel L. Donato Ridgley",
            "Randy A. Freeman",
            "Kevin M. Lynch"
        ],
        "summary": "In this paper we describe a parameterized family of first-order distributed optimization algorithms that enable a network of agents to collaboratively calculate a decision variable that minimizes the sum of cost functions at each agent. These algorithms are self-healing in that their correctness is guaranteed even if they are initialized randomly, agents drop in or out of the network, local cost functions change, or communication packets are dropped. Our algorithms are the first single-Laplacian methods to exhibit all of these characteristics. We achieve self-healing by sacrificing internal stability, a fundamental trade-off for single-Laplacian methods.",
        "published": "2021-04-05T15:20:02Z",
        "link": "http://arxiv.org/abs/2104.01959v2",
        "categories": [
            "math.OC",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "A novel activity pattern generation incorporating deep learning for   transport demand models",
        "authors": [
            "Danh T. Phan",
            "Hai L. Vu"
        ],
        "summary": "Activity generation plays an important role in activity-based demand modelling systems. While machine learning, especially deep learning, has been increasingly used for mode choice and traffic flow prediction, much less research exploiting the advantage of deep learning for activity generation tasks. This paper proposes a novel activity pattern generation framework by incorporating deep learning with travel domain knowledge. We model each activity schedule as one primary activity tour and several secondary activity tours. We then develop different deep neural networks with entity embedding and random forest models to classify activity type, as well as to predict activity times. The proposed framework can capture the activity patterns for individuals in both training and validation sets. Results show high accuracy for the start time and end time of work and school activities. The framework also replicates the start time patterns of stop-before and stop-after primary work activity well. This provides a promising direction to deploy advanced machine learning methods to generate more reliable activity-travel patterns for transport demand systems and their applications.",
        "published": "2021-04-06T04:07:05Z",
        "link": "http://arxiv.org/abs/2104.02278v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Framework for Inferring Leadership Dynamics of Complex Movement from   Time Series",
        "authors": [
            "Chainarong Amornbunchornvej",
            "Tanya Berger-Wolf"
        ],
        "summary": "Leadership plays a key role in social animals, including humans, decision-making and coalescence in coordinated activities such as hunting, migration, sport, diplomatic negotiation etc. In these coordinated activities, leadership is a process that organizes interactions among members to make a group achieve collective goals. Understanding initiation of coordinated activities allows scientists to gain more insight into social species behaviors. However, by using only time series of activities data, inferring leadership as manifested by the initiation of coordinated activities faces many challenging issues. First, coordinated activities are dynamic and are changing over time. Second, several different coordinated activities might occur simultaneously among subgroups. Third, there is no fundamental concept to describe these activities computationally. In this paper, we formalize Faction Initiator Inference Problem and propose a leadership inference framework as a solution of this problem. The framework makes no assumption about the characteristics of a leader or the parameters of the coordination process. The framework performs better than our non-trivial baseline in both simulated and biological datasets (schools of fish). Moreover, we demonstrate the application of our framework as a tool to study group merging and splitting dynamics on another biological dataset of trajectories of wild baboons. In addition, our problem formalization and framework enable opportunities for scientists to analyze coordinated activities and generate scientific hypotheses about collective behaviors that can be tested statistically and in the field.",
        "published": "2021-04-06T05:14:32Z",
        "link": "http://arxiv.org/abs/2104.02291v1",
        "categories": [
            "cs.SI",
            "cs.MA",
            "06A06, 92B99, 91C99, 68P99",
            "G.3; I.2.3; I.2.6; J.4"
        ]
    },
    {
        "title": "Growing the Simulation Ecosystem: Introducing Mesa Data to Provide   Transparent, Accessible and Extensible Data Pipelines for Simulation   Development",
        "authors": [
            "Thomas Pike",
            "Samantha Golden",
            "Daniel Lowdermilk",
            "Brandon Luong",
            "Benjamin Rosado"
        ],
        "summary": "The Agent Based Model community has a rich and diverse ecosystem of libraries, platforms, and applications to help modelers develop rigorous simulations. Despite this robust and diverse ecosystem, the complexity of life from microbial communities to the global ecosystem still presents substantial challenges in making reusable code that can optimize the ability of the knowledge-sharing and reproducibility. This research seeks to provide new tools to mitigate some of these challenges by offering a vision of a more holistic ecosystem that takes researchers and practitioners from the data collection through validation, with transparent, accessible, and extensible subcomponents. This proposed approach is demonstrated through two data pipelines (crop yield and synthetic population) that take users from data download through the cleaning and processing until users of have data that can be integrated into an ABM. These pipelines are built to be transparent: by walking users step by step through the process, accessible: by being skill scalable so users can leverage them without code or with code, and extensible by being freely available on the coding sharing repository GitHub to facilitate community development. Reusing code that simulates complex phenomena is a significant challenge but one that must be consistently addressed to help the community move forward. This research seeks to aid that progress by offering potential new tools extended from the already robust ecosystem to help the community collaborate more effectively internally and across disciplines.",
        "published": "2021-04-06T21:51:24Z",
        "link": "http://arxiv.org/abs/2104.02809v3",
        "categories": [
            "cs.CY",
            "cs.MA"
        ]
    },
    {
        "title": "Scaling Scaling Laws with Board Games",
        "authors": [
            "Andy L. Jones"
        ],
        "summary": "The largest experiments in machine learning now require resources far beyond the budget of all but a few institutions. Fortunately, it has recently been shown that the results of these huge experiments can often be extrapolated from the results of a sequence of far smaller, cheaper experiments. In this work, we show that not only can the extrapolation be done based on the size of the model, but on the size of the problem as well. By conducting a sequence of experiments using AlphaZero and Hex, we show that the performance achievable with a fixed amount of compute degrades predictably as the game gets larger and harder. Along with our main result, we further show that the test-time and train-time compute available to an agent can be traded off while maintaining performance.",
        "published": "2021-04-07T13:34:25Z",
        "link": "http://arxiv.org/abs/2104.03113v2",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Synthesized Trust Learning from Limited Human Feedback for   Human-Load-Reduced Multi-Robot Deployments",
        "authors": [
            "Yijiang Pang",
            "Chao Huang",
            "Rui Liu"
        ],
        "summary": "Human multi-robot system (MRS) collaboration is demonstrating potentials in wide application scenarios due to the integration of human cognitive skills and a robot team's powerful capability introduced by its multi-member structure. However, due to limited human cognitive capability, a human cannot simultaneously monitor multiple robots and identify the abnormal ones, largely limiting the efficiency of the human-MRS collaboration. There is an urgent need to proactively reduce unnecessary human engagements and further reduce human cognitive loads. Human trust in human MRS collaboration reveals human expectations on robot performance. Based on trust estimation, the work between a human and MRS will be reallocated that an MRS will self-monitor and only request human guidance in critical situations. Inspired by that, a novel Synthesized Trust Learning (STL) method was developed to model human trust in the collaboration. STL explores two aspects of human trust (trust level and trust preference), meanwhile accelerates the convergence speed by integrating active learning to reduce human workload. To validate the effectiveness of the method, tasks \"searching victims in the context of city rescue\" were designed in an open-world simulation environment, and a user study with 10 volunteers was conducted to generate real human trust feedback. The results showed that by maximally utilizing human feedback, the STL achieved higher accuracy in trust modeling with a few human feedback, effectively reducing human interventions needed for modeling an accurate trust, therefore reducing human cognitive load in the collaboration.",
        "published": "2021-04-07T14:32:17Z",
        "link": "http://arxiv.org/abs/2104.03151v2",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Bootstrapping of memetic from genetic evolution via inter-agent   selection pressures",
        "authors": [
            "Nicholas Guttenberg",
            "Marek Rosa"
        ],
        "summary": "We create an artificial system of agents (attention-based neural networks) which selectively exchange messages with each-other in order to study the emergence of memetic evolution and how memetic evolutionary pressures interact with genetic evolution of the network weights. We observe that the ability of agents to exert selection pressures on each-other is essential for memetic evolution to bootstrap itself into a state which has both high-fidelity replication of memes, as well as continuing production of new memes over time. However, in this system there is very little interaction between this memetic 'ecology' and underlying tasks driving individual fitness - the emergent meme layer appears to be neither helpful nor harmful to agents' ability to learn to solve tasks. Sourcecode for these experiments is available at https://github.com/GoodAI/memes",
        "published": "2021-04-07T21:31:05Z",
        "link": "http://arxiv.org/abs/2104.03404v1",
        "categories": [
            "cs.AI",
            "cs.MA",
            "cs.NE"
        ]
    },
    {
        "title": "Learning to Coordinate via Multiple Graph Neural Networks",
        "authors": [
            "Zhiwei Xu",
            "Bin Zhang",
            "Yunpeng Bai",
            "Dapeng Li",
            "Guoliang Fan"
        ],
        "summary": "The collaboration between agents has gradually become an important topic in multi-agent systems. The key is how to efficiently solve the credit assignment problems. This paper introduces MGAN for collaborative multi-agent reinforcement learning, a new algorithm that combines graph convolutional networks and value-decomposition methods. MGAN learns the representation of agents from different perspectives through multiple graph networks, and realizes the proper allocation of attention between all agents. We show the amazing ability of the graph network in representation learning by visualizing the output of the graph network, and therefore improve interpretability for the actions of each agent in the multi-agent system.",
        "published": "2021-04-08T04:33:00Z",
        "link": "http://arxiv.org/abs/2104.03503v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Voluntary safety commitments provide an escape from over-regulation in   AI development",
        "authors": [
            "The Anh Han",
            "Tom Lenaerts",
            "Francisco C. Santos",
            "Luis Moniz Pereira"
        ],
        "summary": "With the introduction of Artificial Intelligence (AI) and related technologies in our daily lives, fear and anxiety about their misuse as well as the hidden biases in their creation have led to a demand for regulation to address such issues. Yet blindly regulating an innovation process that is not well understood, may stifle this process and reduce benefits that society may gain from the generated technology, even under the best intentions. In this paper, starting from a baseline model that captures the fundamental dynamics of a race for domain supremacy using AI technology, we demonstrate how socially unwanted outcomes may be produced when sanctioning is applied unconditionally to risk-taking, i.e. potentially unsafe, behaviours. As an alternative to resolve the detrimental effect of over-regulation, we propose a voluntary commitment approach wherein technologists have the freedom of choice between independently pursuing their course of actions or establishing binding agreements to act safely, with sanctioning of those that do not abide to what they pledged. Overall, this work reveals for the first time how voluntary commitments, with sanctions either by peers or an institution, leads to socially beneficial outcomes in all scenarios envisageable in a short-term race towards domain supremacy through AI technology. These results are directly relevant for the design of governance and regulatory policies that aim to ensure an ethical and responsible AI technology development process.",
        "published": "2021-04-08T12:54:56Z",
        "link": "http://arxiv.org/abs/2104.03741v1",
        "categories": [
            "cs.AI",
            "cs.CY",
            "cs.MA",
            "nlin.AO",
            "nlin.CD"
        ]
    },
    {
        "title": "Exploiting Natural Language for Efficient Risk-Aware Multi-robot SaR   Planning",
        "authors": [
            "Vikram Shree",
            "Beatriz Asfora",
            "Rachel Zheng",
            "Samantha Hong",
            "Jacopo Banfi",
            "Mark Campbell"
        ],
        "summary": "The ability to develop a high-level understanding of a scene, such as perceiving danger levels, can prove valuable in planning multi-robot search and rescue (SaR) missions. In this work, we propose to uniquely leverage natural language descriptions from the mission commander in chief and image data captured by robots to estimate scene danger. Given a description and an image, a state-of-the-art deep neural network is used to assess a corresponding similarity score, which is then converted into a probabilistic distribution of danger levels. Because commonly used visio-linguistic datasets do not represent SaR missions well, we collect a large-scale image-description dataset from synthetic images taken from realistic disaster scenes and use it to train our machine learning model. A risk-aware variant of the Multi-robot Efficient Search Path Planning (MESPP) problem is then formulated to use the danger estimates in order to account for high-risk locations in the environment when planning the searchers' paths. The problem is solved via a distributed approach based on Mixed-Integer Linear Programming. Our experiments demonstrate that our framework allows to plan safer yet highly successful search missions, abiding to the two most important aspects of SaR missions: to ensure both searchers' and victim safety.",
        "published": "2021-04-08T14:41:51Z",
        "link": "http://arxiv.org/abs/2104.03809v1",
        "categories": [
            "cs.RO",
            "cs.HC",
            "cs.MA"
        ]
    },
    {
        "title": "Sequential Online Chore Division for Autonomous Vehicle Convoy Formation",
        "authors": [
            "Harel Yedidsion",
            "Shani Alkoby",
            "Peter Stone"
        ],
        "summary": "Chore division is a class of fair division problems in which some undesirable \"resource\" must be shared among a set of participants, with each participant wanting to get as little as possible. Typically the set of participants is fixed and known at the outset. This paper introduces a novel variant, called sequential online chore division (SOCD), in which participants arrive and depart online, while the chore is being performed: both the total number of participants and their arrival/departure times are initially unknown. In SOCD, exactly one agent must be performing the chore at any give time (e.g. keeping lookout), and switching the performer incurs a cost. In this paper, we propose and analyze three mechanisms for SOCD: one centralized mechanism using side payments, and two distributed ones that seek to balance the participants' loads. Analysis and results are presented in a domain motivated by autonomous vehicle convoy formation, where the chore is leading the convoy so that all followers can enjoy reduced wind resistance.",
        "published": "2021-04-09T02:28:28Z",
        "link": "http://arxiv.org/abs/2104.04159v1",
        "categories": [
            "cs.AI",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Jamming-Resilient Path Planning for Multiple UAVs via Deep Reinforcement   Learning",
        "authors": [
            "Xueyuan Wang",
            "M. Cenk Gursoy",
            "Tugba Erpek",
            "Yalin E. Sagduyu"
        ],
        "summary": "Unmanned aerial vehicles (UAVs) are expected to be an integral part of wireless networks. In this paper, we aim to find collision-free paths for multiple cellular-connected UAVs, while satisfying requirements of connectivity with ground base stations (GBSs) in the presence of a dynamic jammer. We first formulate the problem as a sequential decision making problem in discrete domain, with connectivity, collision avoidance, and kinematic constraints. We, then, propose an offline temporal difference (TD) learning algorithm with online signal-to-interference-plus-noise ratio (SINR) mapping to solve the problem. More specifically, a value network is constructed and trained offline by TD method to encode the interactions among the UAVs and between the UAVs and the environment; and an online SINR mapping deep neural network (DNN) is designed and trained by supervised learning, to encode the influence and changes due to the jammer. Numerical results show that, without any information on the jammer, the proposed algorithm can achieve performance levels close to that of the ideal scenario with the perfect SINR-map. Real-time navigation for multi-UAVs can be efficiently performed with high success rates, and collisions are avoided.",
        "published": "2021-04-09T16:52:33Z",
        "link": "http://arxiv.org/abs/2104.04477v2",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "On the Accuracy of Deterministic Models for Viral Spread on Networks",
        "authors": [
            "Anirudh Sridhar",
            "Soummya Kar"
        ],
        "summary": "We consider the emergent behavior of viral spread when agents in a large population interact with each other over a contact network. When the number of agents is large and the contact network is a complete graph, it is well known that the population behavior -- that is, the fraction of susceptible, infected and recovered agents -- converges to the solution of an ordinary differential equation (ODE) known as the classical SIR model as the population size approaches infinity. In contrast, we study interactions over contact networks with generic topologies and derive conditions under which the population behavior concentrates around either the classic SIR model or other deterministic models. Specifically, we show that when most vertex degrees in the contact network are sufficiently large, the population behavior concentrates around an ODE known as the network SIR model. We then study the short and intermediate-term evolution of the network SIR model and show that if the contact network has an expander-type property or the initial set of infections is well-mixed in the population, the network SIR model reduces to the classical SIR model. To complement these results, we illustrate through simulations that the two models can yield drastically different predictions, hence use of the classical SIR model can be misleading in certain cases.",
        "published": "2021-04-11T04:27:43Z",
        "link": "http://arxiv.org/abs/2104.04913v1",
        "categories": [
            "physics.soc-ph",
            "cs.MA",
            "cs.SI",
            "cs.SY",
            "eess.SY",
            "math.PR"
        ]
    },
    {
        "title": "The Core of Approval Participatory Budgeting with Uniform Costs (or with   up to Four Projects) is Non-Empty",
        "authors": [
            "Reshef Meir"
        ],
        "summary": "In the Approval Participatory Budgeting problem an agent prefers a set of projects $W'$ over $W$ if she approves strictly more projects in $W'$. A set of projects $W$ is in the core, if there is no other set of projects $W'$ and set of agents $K$ that both prefer $W'$ over $W$ and can fund $W'$. It is an open problem whether the core can be empty, even when project costs are uniform. the latter case is known as the multiwinner voting core.   We show that in any instance with uniform costs or with at most four projects (and any number of agents), the core is nonempty.",
        "published": "2021-04-11T19:22:11Z",
        "link": "http://arxiv.org/abs/2104.05082v3",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "A Hierarchical State-Machine-Based Framework for Platoon Manoeuvre   Descriptions",
        "authors": [
            "Corvin Deboeser",
            "Jordan Ivanchev",
            "Thomas Braud",
            "Alois Knoll",
            "David Eckhoff",
            "Alberto Sangiovanni-Vincentelli"
        ],
        "summary": "This paper introduces the SEAD framework that simplifies the process of designing and describing autonomous vehicle platooning manoeuvres. Although a large body of research has been formulating platooning manoeuvres, it is still challenging to design, describe, read, and understand them. This difficulty largely arises from missing formalisation. To fill this gap, we analysed existing ways of describing manoeuvres, derived the causes of difficulty, and designed a framework that simplifies the manoeuvre design process. Alongside, a Manoeuvre Design Language was developed to structurally describe manoeuvres in a machine-readable format. Unlike state-of-the-art manoeuvre descriptions that require one state machine for every participating vehicle, the SEAD framework allows describing any manoeuvre from the single perspective of the platoon leader. %As a proof of concept, the proposed framework was implemented in the mixed traffic simulation environment BEHAVE for an autonomous highway scenario. Using this framework, we implemented several manoeuvres as they were described in literature. To demonstrate the applicability of the framework, an experiment was performed to evaluate the execution time performance of multiple alternatives of the Join-Middle manoeuvre. This proof-of-concept experiment revealed that the manoeuvre execution time can be reduced by 28 \\% through parallelising various steps without considerable secondary effects. We hope that the SEAD framework will pave the way for further research in the area of new manoeuvre design and optimisation by largely simplifying and unifying platooning manoeuvre representation.",
        "published": "2021-04-12T09:25:35Z",
        "link": "http://arxiv.org/abs/2104.05305v1",
        "categories": [
            "cs.MA",
            "cs.CL",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "A coevolutionary approach to deep multi-agent reinforcement learning",
        "authors": [
            "Daan Klijn",
            "A. E. Eiben"
        ],
        "summary": "Traditionally, Deep Artificial Neural Networks (DNN's) are trained through gradient descent. Recent research shows that Deep Neuroevolution (DNE) is also capable of evolving multi-million-parameter DNN's, which proved to be particularly useful in the field of Reinforcement Learning (RL). This is mainly due to its excellent scalability and simplicity compared to the traditional MDP-based RL methods. So far, DNE has only been applied to complex single-agent problems. As evolutionary methods are a natural choice for multi-agent problems, the question arises whether DNE can also be applied in a complex multi-agent setting. In this paper, we describe and validate a new approach based on Coevolution. To validate our approach, we benchmark two Deep Coevolutionary Algorithms on a range of multi-agent Atari games and compare our results against the results of Ape-X DQN. Our results show that these Deep Coevolutionary algorithms (1) can be successfully trained to play various games, (2) outperform Ape-X DQN in some of them, and therefore (3) show that Coevolution can be a viable approach to solving complex multi-agent decision-making problems.",
        "published": "2021-04-12T16:30:03Z",
        "link": "http://arxiv.org/abs/2104.05610v2",
        "categories": [
            "cs.NE",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "A Distributed and Resilient Bargaining Game for Weather-Predictive   Microgrid Energy Cooperation",
        "authors": [
            "Lu An",
            "Jie Duan",
            "Mo-Yuen Chow",
            "Alexandra Duel-Hallen"
        ],
        "summary": "A bargaining game is investigated for cooperative energy management in microgrids. This game incorporates a fully distributed and realistic cooperative power scheduling algorithm (CoDES) as well as a distributed Nash Bargaining Solution (NBS)-based method of allocating the overall power bill resulting from CoDES. A novel weather-based stochastic renewable generation (RG) prediction method is incorporated in the power scheduling. We demonstrate the proposed game using a 4-user grid-connected microgrid model with diverse user demands, storage, and RG profiles and examine the effect of weather prediction on day-ahead power scheduling and cost/profit allocation. Finally, the impact of users' ambivalence about cooperation and /or dishonesty on the bargaining outcome is investigated, and it is shown that the proposed game is resilient to malicious users' attempts to avoid payment of their fair share of the overall bill.",
        "published": "2021-04-12T20:49:19Z",
        "link": "http://arxiv.org/abs/2104.05810v1",
        "categories": [
            "cs.MA",
            "cs.GT",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Reward Mechanism for Blockchains Using Evolutionary Game Theory",
        "authors": [
            "Shashank Motepalli",
            "Hans-Arno Jacobsen"
        ],
        "summary": "Blockchains have witnessed widespread adoption in the past decade in various fields. The growing demand makes their scalability and sustainability challenges more evident than ever. As a result, more and more blockchains have begun to adopt proof-of-stake (PoS) consensus protocols to address those challenges. One of the fundamental characteristics of any blockchain technology is its crypto-economics and incentives. Lately, each PoS blockchain has designed a unique reward mechanism, yet, many of them are prone to free-rider and nothing-at-stake problems. To better understand the ad-hoc design of reward mechanisms, in this paper, we develop a reward mechanism framework that could apply to many PoS blockchains. We formulate the block validation game wherein the rewards are distributed for validating the blocks correctly. Using evolutionary game theory, we analyze how the participants' behaviour could potentially evolve with the reward mechanism. Also, penalties are found to play a central role in maintaining the integrity of blockchains.",
        "published": "2021-04-12T22:38:32Z",
        "link": "http://arxiv.org/abs/2104.05849v2",
        "categories": [
            "cs.GT",
            "cs.CE",
            "cs.MA"
        ]
    },
    {
        "title": "OneVision: Centralized to Distributed Controller Synthesis with Delay   Compensation",
        "authors": [
            "Jiayi Wei",
            "Tongrui Li",
            "Swarat Chaudhuri",
            "Isil Dillig",
            "Joydeep Biswas"
        ],
        "summary": "We propose a new algorithm to simplify the controller development for distributed robotic systems subject to external observations, disturbances, and communication delays. Unlike prior approaches that propose specialized solutions to handling communication latency for specific robotic applications, our algorithm uses an arbitrary centralized controller as the specification and automatically generates distributed controllers with communication management and delay compensation. We formulate our goal as nonlinear optimal control -- using a regret minimizing objective that measures how much the distributed agents behave differently from the delay-free centralized response -- and solve for optimal actions w.r.t. local estimations of this objective using gradient-based optimization. We analyze our proposed algorithm's behavior under a linear time-invariant special case and prove that the closed-loop dynamics satisfy a form of input-to-state stability w.r.t. unexpected disturbances and observations. Our experimental results on both simulated and real-world robotic tasks demonstrate the practical usefulness of our approach and show significant improvement over several baseline approaches.",
        "published": "2021-04-14T02:16:11Z",
        "link": "http://arxiv.org/abs/2104.06588v1",
        "categories": [
            "cs.RO",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Maintenance scheduling of manufacturing systems based on optimal price   of the network",
        "authors": [
            "Pegah Rokhforoz",
            "Olga Fink"
        ],
        "summary": "Goods can exhibit positive externalities impacting decisions of customers in socials networks. Suppliers can integrate these externalities in their pricing strategies to increase their revenue. Besides optimizing the prize, suppliers also have to consider their production and maintenance costs. Predictive maintenance has the potential to reduce the maintenance costs and improve the system availability. To address the joint optimization of pricing with network externalities and predictive maintenance scheduling based on the condition of the system, we propose a bi-level optimization solution based on game theory. In the first level, the manufacturing company decides about the predictive maintenance scheduling of the units and the price of the goods. In the second level, the customers decide about their consumption using an optimization approach in which the objective function depends on their consumption, the consumption levels of other customers who are connected through the graph, and the price of the network which is determined by the supplier. To solve the problem, we propose the leader-multiple-followers game where the supplier as a leader predicts the strategies of the followers. Then, customers as the followers obtain their strategies based on the leader's and other followers' strategies. We demonstrate the effectiveness of our proposed method on a simulated case study. The results demonstrate that knowledge of the social network graph results in an increased revenue compared to the case when the underlying social network graph is not known. Moreover, the results demonstrate that obtaining the predictive maintenance scheduling based on the proposed optimization approach leads to an increased profit compared to the baseline decision-making (perform maintenance at the degradation limit).",
        "published": "2021-04-14T07:01:53Z",
        "link": "http://arxiv.org/abs/2104.06654v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Decomposed Soft Actor-Critic Method for Cooperative Multi-Agent   Reinforcement Learning",
        "authors": [
            "Yuan Pu",
            "Shaochen Wang",
            "Rui Yang",
            "Xin Yao",
            "Bin Li"
        ],
        "summary": "Deep reinforcement learning methods have shown great performance on many challenging cooperative multi-agent tasks. Two main promising research directions are multi-agent value function decomposition and multi-agent policy gradients. In this paper, we propose a new decomposed multi-agent soft actor-critic (mSAC) method, which effectively combines the advantages of the aforementioned two methods. The main modules include decomposed Q network architecture, discrete probabilistic policy and counterfactual advantage function (optinal). Theoretically, mSAC supports efficient off-policy learning and addresses credit assignment problem partially in both discrete and continuous action spaces. Tested on StarCraft II micromanagement cooperative multiagent benchmark, we empirically investigate the performance of mSAC against its variants and analyze the effects of the different components. Experimental results demonstrate that mSAC significantly outperforms policy-based approach COMA, and achieves competitive results with SOTA value-based approach Qmix on most tasks in terms of asymptotic perfomance metric. In addition, mSAC achieves pretty good results on large action space tasks, such as 2c_vs_64zg and MMM2.",
        "published": "2021-04-14T07:02:40Z",
        "link": "http://arxiv.org/abs/2104.06655v2",
        "categories": [
            "cs.AI",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Natural-Language Multi-Agent Simulations of Argumentative Opinion   Dynamics",
        "authors": [
            "Gregor Betz"
        ],
        "summary": "This paper develops a natural-language agent-based model of argumentation (ABMA). Its artificial deliberative agents (ADAs) are constructed with the help of so-called neural language models recently developed in AI and computational linguistics. ADAs are equipped with a minimalist belief system and may generate and submit novel contributions to a conversation. The natural-language ABMA allows us to simulate collective deliberation in English, i.e. with arguments, reasons, and claims themselves -- rather than with their mathematical representations (as in formal models). This paper uses the natural-language ABMA to test the robustness of formal reason-balancing models of argumentation [Maes & Flache 2013, Singer et al. 2019]: First of all, as long as ADAs remain passive, confirmation bias and homophily updating trigger polarization, which is consistent with results from formal models. However, once ADAs start to actively generate new contributions, the evolution of a conservation is dominated by properties of the agents *as authors*. This suggests that the creation of new arguments, reasons, and claims critically affects a conversation and is of pivotal importance for understanding the dynamics of collective deliberation. The paper closes by pointing out further fruitful applications of the model and challenges for future research.",
        "published": "2021-04-14T09:45:22Z",
        "link": "http://arxiv.org/abs/2104.06737v1",
        "categories": [
            "cs.CL",
            "cs.AI",
            "cs.CY",
            "cs.MA",
            "cs.SI"
        ]
    },
    {
        "title": "Pincer-Based vs. Same-Direction Strategies of Search for Smart Evaders   by Swarms of Agents",
        "authors": [
            "Roee M. Francos",
            "Alfred M. Bruckstein"
        ],
        "summary": "Suppose in a given planar region, there are smart mobile evaders and we want to detect them using sweeping agents. We assume that the agents have line sensors of equal length. We propose procedures for designing cooperative sweeping processes that ensure successful completion of the task, thereby deriving conditions on the sweeping speed of the agents and their paths. Successful completion of the task means that evaders with a known limit on their speed cannot escape the sweeping agents. A simpler task for the sweeping swarm is the confinement of the evaders to their initial domain. The feasibility of completing these tasks depends on geometric and dynamic constraints that impose a lower bound on the speed the sweeping agent must have. This critical speed is derived to ensure the satisfaction of the confinement task. Increasing the speed above the lower bound enables the agents to complete the search task as well. We present a quantitative and qualitative comparison analysis between the total search time of same-direction sweep processes and pincer-movement search strategies. We evaluate the different strategies by using two metrics, total search time and the minimal critical speed required for a successful search. We compare two types of pincer-movement search processes, circular and spiral, with their same-direction counterparts, for any even number of sweeping agents. We prove that pincer based strategies provide superior results in all practical scenarios and that the spiral pincer sweep process allows detection of all evaders while sweeping at nearly theoretically optimal speeds.",
        "published": "2021-04-14T16:07:35Z",
        "link": "http://arxiv.org/abs/2104.06940v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "GridToPix: Training Embodied Agents with Minimal Supervision",
        "authors": [
            "Unnat Jain",
            "Iou-Jen Liu",
            "Svetlana Lazebnik",
            "Aniruddha Kembhavi",
            "Luca Weihs",
            "Alexander Schwing"
        ],
        "summary": "While deep reinforcement learning (RL) promises freedom from hand-labeled data, great successes, especially for Embodied AI, require significant work to create supervision via carefully shaped rewards. Indeed, without shaped rewards, i.e., with only terminal rewards, present-day Embodied AI results degrade significantly across Embodied AI problems from single-agent Habitat-based PointGoal Navigation (SPL drops from 55 to 0) and two-agent AI2-THOR-based Furniture Moving (success drops from 58% to 1%) to three-agent Google Football-based 3 vs. 1 with Keeper (game score drops from 0.6 to 0.1). As training from shaped rewards doesn't scale to more realistic tasks, the community needs to improve the success of training with terminal rewards. For this we propose GridToPix: 1) train agents with terminal rewards in gridworlds that generically mirror Embodied AI environments, i.e., they are independent of the task; 2) distill the learned policy into agents that reside in complex visual worlds. Despite learning from only terminal rewards with identical models and RL algorithms, GridToPix significantly improves results across tasks: from PointGoal Navigation (SPL improves from 0 to 64) and Furniture Moving (success improves from 1% to 25%) to football gameplay (game score improves from 0.1 to 0.6). GridToPix even helps to improve the results of shaped reward training.",
        "published": "2021-04-14T17:59:57Z",
        "link": "http://arxiv.org/abs/2105.00931v2",
        "categories": [
            "cs.CV",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Agent-based Framework for Self-Organization of Collective and Autonomous   Shuttle Fleets",
        "authors": [
            "Antonio Bucchiarone",
            "Martina De Sanctis",
            "Nelly Bencomo"
        ],
        "summary": "The mobility of people is at the center of transportation planning and decision-making of the cities of the future. In order to accelerate the transition to zero-emissions and to maximize air quality benefits, smart cities are prioritizing walking, cycling, shared mobility services and public transport over the use of private cars. Extensive progress has been made in autonomous and electric cars. Autonomous Vehicles (AV) are increasingly capable of moving without full control of humans, automating some aspects of driving, such as steering or braking. For these reasons, cities are investing in the infrastructure and technology needed to support connected, multi-modal transit networks that include shared electric Autonomous Vehicles (AV). The relationship between traditional public transport and new mobility services is in the spotlight and need to be rethought. This paper proposes an agent-based simulation framework that allows for the creation and simulation of mobility scenarios to investigate the impact of new mobility modes on a city daily life. It lets traffic planners explore the cooperative integration of AV using a decentralized control approach. A prototype has been implemented and validated with data of the city of Trento.",
        "published": "2021-04-15T14:39:57Z",
        "link": "http://arxiv.org/abs/2104.07494v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Collective Iterative Learning Control: Exploiting Diversity in   Multi-Agent Systems for Reference Tracking Tasks",
        "authors": [
            "Michael Meindl",
            "Fabio Molinari",
            "Dustin Lehmann",
            "Thomas Seel"
        ],
        "summary": "Multi-agent systems (MASs) can autonomously learn to solve previously unknown tasks by means of each agent's individual intelligence as well as by collaborating and exploiting collective intelligence. This article considers a group of autonomous agents learning to track the same given reference trajectory in a possibly small number of trials. We propose a novel collective learning control method that combines iterative learning control (ILC) with a collective update strategy. We derive conditions for desirable convergence properties of such systems. We show that the proposed method allows the collective to combine the advantages of the agents' individual learning strategies and thereby overcomes trade-offs and limitations of single-agent ILC. This benefit is achieved by designing a heterogeneous collective, i.e., a different learning law is assigned to each agent. All theoretical results are confirmed in simulations and experiments with two-wheeled-inverted-pendulum robots (TWIPRs) that jointly learn to perform the desired maneuver.",
        "published": "2021-04-15T17:36:00Z",
        "link": "http://arxiv.org/abs/2104.07620v2",
        "categories": [
            "eess.SY",
            "cs.LG",
            "cs.MA",
            "cs.RO",
            "cs.SY"
        ]
    },
    {
        "title": "Safe Affine Transformation-Based Guidance of a Large-Scale   Multi-Quadcopter System (MQS)",
        "authors": [
            "Hossein Rastgoftar",
            "Ilya Kolmanovsky"
        ],
        "summary": "This paper studies the problem of affine transformation-based guidance of a multi-quadcopter system (MQS) in an obstacle-laden environment. Such MQSs can perform a variety of cooperative tasks including information collection, inspection mapping, disinfection, and firefighting. The MQS affine transformation is an approach to a decentralized leader-follower coordination guided by n +1 leaders, where leaders are located at vertices of an n-D simplex, called leading simplex, at any time t. The remaining agents are followers acquiring the desired affine transformation via local communication. Followers are contained in a rigid-size ball at any time t but they can be distributed either inside or outside the leading simplex. By eigen-decomposition of the affine transformation coordination, safety in a large-scale MQS coordination can be ensured by constraining eigenvalues of the affine transformation. Given the initial and final configurations of the MQS, A-star search is applied to optimally plan safe coordination of a large-scale MQS minimizing the travel distance between the the initial and final configuration. The paper also proposes a proximity-based communication topology for followers to assign communication weights with their in-neighbors and acquire the desired coordination with minimal computation cost.",
        "published": "2021-04-15T19:40:03Z",
        "link": "http://arxiv.org/abs/2104.07741v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Joint Attention for Multi-Agent Coordination and Social Learning",
        "authors": [
            "Dennis Lee",
            "Natasha Jaques",
            "Chase Kew",
            "Jiaxing Wu",
            "Douglas Eck",
            "Dale Schuurmans",
            "Aleksandra Faust"
        ],
        "summary": "Joint attention - the ability to purposefully coordinate attention with another agent, and mutually attend to the same thing -- is a critical component of human social cognition. In this paper, we ask whether joint attention can be useful as a mechanism for improving multi-agent coordination and social learning. We first develop deep reinforcement learning (RL) agents with a recurrent visual attention architecture. We then train agents to minimize the difference between the attention weights that they apply to the environment at each timestep, and the attention of other agents. Our results show that this joint attention incentive improves agents' ability to solve difficult coordination tasks, by reducing the exponential cost of exploring the joint multi-agent action space. Joint attention leads to higher performance than a competitive centralized critic baseline across multiple environments. Further, we show that joint attention enhances agents' ability to learn from experts present in their environment, even when completing hard exploration tasks that do not require coordination. Taken together, these findings suggest that joint attention may be a useful inductive bias for multi-agent learning.",
        "published": "2021-04-15T20:14:19Z",
        "link": "http://arxiv.org/abs/2104.07750v2",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Scaling Beyond Bandwidth Limitations: Wireless Control With Stability   Guarantees Under Overload",
        "authors": [
            "Fabian Mager",
            "Dominik Baumann",
            "Carsten Herrmann",
            "Sebastian Trimpe",
            "Marco Zimmerling"
        ],
        "summary": "An important class of cyber-physical systems relies on multiple agents that jointly perform a task by coordinating their actions over a wireless network. Examples include self-driving cars in intelligent transportation and production robots in smart manufacturing. However, the scalability of existing control-over-wireless solutions is limited as they cannot resolve overload situations in which the communication demand exceeds the available bandwidth. This paper presents a novel co-design of distributed control and wireless communication that overcomes this limitation by dynamically allocating the available bandwidth to agents with the greatest need to communicate. Experiments on a real cyber-physical testbed with 20 agents, each consisting of a low-power wireless embedded device and a cart-pole system, demonstrate that our solution achieves significantly better control performance under overload than the state of the art. We further prove that our co-design guarantees closed-loop stability for physical systems with stochastic linear time-invariant dynamics.",
        "published": "2021-04-16T09:32:11Z",
        "link": "http://arxiv.org/abs/2104.07989v2",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.NI",
            "cs.SY"
        ]
    },
    {
        "title": "Welfare Measure for Resource Allocation with Algorithmic Implementation:   Beyond Average and Max-Min",
        "authors": [
            "Ezra Tampubolon",
            "Holger Boche"
        ],
        "summary": "In this work, we propose an axiomatic approach for measuring the performance/welfare of a system consisting of concurrent agents in a resource-driven system. Our approach provides a unifying view on popular system optimality principles, such as the maximal average/total utilities and the max-min fairness. Moreover, it gives rise to other system optimality notions that have not been fully exploited yet, such as the maximal lowest total subgroup utilities. For the axiomatically defined welfare measures, we provide a generic gradient-based method to find an optimal resource allocation and present a theoretical guarantee for its success. Lastly, we demonstrate the power of our approach through the power control application in wireless networks.",
        "published": "2021-04-16T10:11:01Z",
        "link": "http://arxiv.org/abs/2104.08010v1",
        "categories": [
            "eess.SY",
            "cs.GT",
            "cs.MA",
            "cs.NI",
            "cs.SY"
        ]
    },
    {
        "title": "Why Machine Learning Integrated Patient Flow Simulation?",
        "authors": [
            "Tesfamariam M. Abuhay",
            "Adane Mamuye",
            "Stewart Robinson",
            "Sergey V. Kovalchuk"
        ],
        "summary": "Patient flow analysis can be studied from a clinical and or operational perspective using simulation. Traditional statistical methods such as stochastic distribution methods have been used to construct patient flow simulation submodels such as patient inflow, Length of Stay (LoS), Cost of Treatment (CoT) and Clinical Pathway (CP) models. However, patient inflow demonstrates seasonality, trend and variation over time. LoS, CoT and CP are significantly determined by attributes of patients and clinical and laboratory test results. For this reason, patient flow simulation models constructed using traditional statistical methods are criticized for ignoring heterogeneity and their contribution to personalized and value based healthcare. On the other hand, machine learning methods have proven to be efficient to study and predict admission rate, LoS, CoT, and CP. This paper, hence, describes why coupling machine learning with patient flow simulation is important and proposes a conceptual architecture that shows how to integrate machine learning with patient flow simulation.",
        "published": "2021-04-16T16:23:17Z",
        "link": "http://arxiv.org/abs/2104.08203v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Hercule: Representing and Reasoning about Norms as a Foundation for   Declarative Contracts over Blockchain",
        "authors": [
            "Samuel H. Christie V",
            "Amit K. Chopra",
            "Munindar P. Singh"
        ],
        "summary": "Current blockchain approaches for business contracts are based on smart contracts, namely, software programs placed on a blockchain that are automatically executed to realize a contract. However, smart contracts lack flexibility and interfere with the autonomy of the parties concerned.   We propose Hercule, an approach for declaratively specifying blockchain applications in a manner that reflects business contracts. Hercule represents a contract via regulatory norms that capture the involved parties' expectations of one another. It computes the states of norms (hence, of contracts) from events in the blockchain. Hercule's novelty and significance lie in that it operationalizes declarative contracts over semistructured databases, the underlying representation for practical blockchain such as Hyperledger Fabric and Ethereum. Specifically, it exploits the map-reduce capabilities of such stores to compute norm states.   We demonstrate that our implementation over Hyperledger Fabric can process thousands of events per second, sufficient for many applications.",
        "published": "2021-04-16T20:15:57Z",
        "link": "http://arxiv.org/abs/2104.08355v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Proportionality and Strategyproofness in Multiwinner Elections",
        "authors": [
            "Dominik Peters"
        ],
        "summary": "Multiwinner voting rules can be used to select a fixed-size committee from a larger set of candidates. We consider approval-based committee rules, which allow voters to approve or disapprove candidates. In this setting, several voting rules such as Proportional Approval Voting (PAV) and Phragm\\'en's rules have been shown to produce committees that are proportional, in the sense that they proportionally represent voters' preferences; all of these rules are strategically manipulable by voters. On the other hand, a generalisation of Approval Voting gives a non-proportional but strategyproof voting rule. We show that there is a fundamental tradeoff between these two properties: we prove that no multiwinner voting rule can simultaneously satisfy a weak form of proportionality (a weakening of justified representation) and a weak form of strategyproofness. Our impossibility is obtained using a formulation of the problem in propositional logic and applying SAT solvers; a human-readable version of the computer-generated proof is obtained by extracting a minimal unsatisfiable set (MUS). We also discuss several related axiomatic questions in the domain of committee elections.",
        "published": "2021-04-17T16:40:45Z",
        "link": "http://arxiv.org/abs/2104.08594v2",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Revisiting the Complexity Analysis of Conflict-Based Search: New   Computational Techniques and Improved Bounds",
        "authors": [
            "Ofir Gordon",
            "Yuval Filmus",
            "Oren Salzman"
        ],
        "summary": "The problem of Multi-Agent Path Finding (MAPF) calls for finding a set of conflict-free paths for a fleet of agents operating in a given environment. Arguably, the state-of-the-art approach to computing optimal solutions is Conflict-Based Search (CBS). In this work we revisit the complexity analysis of CBS to provide tighter bounds on the algorithm's run-time in the worst-case. Our analysis paves the way to better pinpoint the parameters that govern (in the worst case) the algorithm's computational complexity.   Our analysis is based on two complementary approaches: In the first approach we bound the run-time using the size of a Multi-valued Decision Diagram (MDD) -- a layered graph which compactly contains all possible single-agent paths between two given vertices for a specific path length.   In the second approach we express the running time by a novel recurrence relation which bounds the algorithm's complexity. We use generating functions-based analysis in order to tightly bound the recurrence.   Using these technique we provide several new upper-bounds on CBS's complexity. The results allow us to improve the existing bound on the running time of CBS for many cases. For example, on a set of common benchmarks we improve the upper-bound by a factor of at least $2^{10^{7}}$.",
        "published": "2021-04-18T07:46:28Z",
        "link": "http://arxiv.org/abs/2104.08759v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.CC",
            "cs.RO"
        ]
    },
    {
        "title": "Autonomous Situational Awareness for UAS Swarms",
        "authors": [
            "Vincent W. Hill",
            "Ryan W. Thomas",
            "Jordan D. Larson"
        ],
        "summary": "This paper describes a technique for the autonomous mission planning of unmanned aerial system swarms. Given a swarm operating in a known area, a central command system generates measurements from the swarm. If those measurements indicate changes to the mission situation such as target movement, the swarm planning is updated to reflect the new situation and guidance updates are broadcast to the swarm. The primary algorithms featured in this work are A* pathfinding and the Generalized Labeled Multi-Bernoulli multi-target tracking method.",
        "published": "2021-04-18T16:41:56Z",
        "link": "http://arxiv.org/abs/2104.08904v1",
        "categories": [
            "cs.RO",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Continuum Deformation Coordination of Multi-Agent Systems Using   Cooperative Localization",
        "authors": [
            "Hossein Rastgoftar",
            "Sergey Nersesov",
            "Hashem Ashrafiuon"
        ],
        "summary": "This paper studies the problem of decentralized continuum deformation coordination of multi-agent systems aided by cooperative localization. We treat agents as particles inside a triangular continuum (deformable body) in a2-D motion space and let the continuum deformation coordination be defined by three leaders located at vertices of a triangle, called the leading triangle. The leaders desired trajectories are assigned as the solution of a constrained optimal control problem such that safety requirements are satisfied in the presence of disturbance and measurement noise. Followers distributed inside the leading tri-angle acquire continuum deformation in a decentralized fashion by integrating cooperative localization and local communication. Specifically, cooperative localization estimates the global positions of all agents using relative position measurements based primarily on proximity of agents. Simulation results are presented for a network of ten agents.",
        "published": "2021-04-20T14:26:46Z",
        "link": "http://arxiv.org/abs/2104.09998v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Game Theory to Study Interactions between Mobility Stakeholders",
        "authors": [
            "Gioele Zardini",
            "Nicolas Lanzetti",
            "Laura Guerrini",
            "Emilio Frazzoli",
            "Florian Dörfler"
        ],
        "summary": "Increasing urbanization and exacerbation of sustainability goals threaten the operational efficiency of current transportation systems and confront cities with complex choices with huge impact on future generations. At the same time, the rise of private, profit-maximizing Mobility Service Providers leveraging public resources, such as ride-hailing companies, entangles current regulation schemes. This calls for tools to study such complex socio-technical problems. In this paper, we provide a game-theoretic framework to study interactions between stakeholders of the mobility ecosystem, modeling regulatory aspects such as taxes and public transport prices, as well as operational matters for Mobility Service Providers such as pricing strategy, fleet sizing, and vehicle design. Our framework is modular and can readily accommodate different types of Mobility Service Providers, actions of municipalities, and low-level models of customers choices in the mobility system. Through both an analytical and a numerical case study for the city of Berlin, Germany, we showcase the ability of our framework to compute equilibria of the problem, to study fundamental tradeoffs, and to inform stakeholders and policy makers on the effects of interventions. Among others, we show tradeoffs between customers satisfaction, environmental impact, and public revenue, as well as the impact of strategic decisions on these metrics.",
        "published": "2021-04-21T07:51:15Z",
        "link": "http://arxiv.org/abs/2104.10394v3",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "math.OC"
        ]
    },
    {
        "title": "Searching with Opponent-Awareness",
        "authors": [
            "Timy Phan"
        ],
        "summary": "We propose Searching with Opponent-Awareness (SOA), an approach to leverage opponent-aware planning without explicit or a priori opponent models for improving performance and social welfare in multi-agent systems. To this end, we develop an opponent-aware MCTS scheme using multi-armed bandits based on Learning with Opponent-Learning Awareness (LOLA) and compare its effectiveness with other bandits, including UCB1. Our evaluations include several different settings and show the benefits of SOA are especially evident with increasing number of agents.",
        "published": "2021-04-21T12:59:47Z",
        "link": "http://arxiv.org/abs/2104.10508v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Optimal communication and control strategies in a multi-agent MDP   problem",
        "authors": [
            "Sagar Sudhakara",
            "Dhruva Kartik",
            "Rahul Jain",
            "Ashutosh Nayyar"
        ],
        "summary": "The problem of controlling multi-agent systems under different models of information sharing among agents has received significant attention in the recent literature. In this paper, we consider a setup where rather than committing to a fixed information sharing protocol (e.g. periodic sharing or no sharing etc), agents can dynamically decide at each time step whether to share information with each other and incur the resulting communication cost. This setup requires a joint design of agents' communication and control strategies in order to optimize the trade-off between communication costs and control objective. We first show that agents can ignore a big part of their private information without compromising the system performance. We then provide a common information approach based solution for the strategy optimization problem. This approach relies on constructing a fictitious POMDP whose solution (obtained via a dynamic program) characterizes the optimal strategies for the agents. We also show that our solution can be easily modified to incorporate constraints on when and how frequently agents can communicate.",
        "published": "2021-04-22T08:27:39Z",
        "link": "http://arxiv.org/abs/2104.10923v1",
        "categories": [
            "math.OC",
            "cs.MA"
        ]
    },
    {
        "title": "Modelling and Verification of Reconfigurable Multi-Agent Systems",
        "authors": [
            "Yehia Abd Alrahman",
            "Nir Piterman"
        ],
        "summary": "We propose a formalism to model and reason about reconfigurable multi-agent systems. In our formalism, agents interact and communicate in different modes so that they can pursue joint tasks; agents may dynamically synchronize, exchange data, adapt their behaviour, and reconfigure their communication interfaces. Inspired by existing multi-robot systems, we represent a system as a set of agents (each with local state), executing independently and only influence each other by means of message exchange. Agents are able to sense their local states and partially their surroundings. We extend LTL to be able to reason explicitly about the intentions of agents in the interaction and their communication protocols. We also study the complexity of satisfiability and model-checking of this extension.",
        "published": "2021-04-22T11:43:09Z",
        "link": "http://arxiv.org/abs/2104.10998v3",
        "categories": [
            "cs.LO",
            "cs.MA"
        ]
    },
    {
        "title": "Birds of a Feather Flock Together: A Close Look at Cooperation Emergence   via Multi-Agent RL",
        "authors": [
            "Heng Dong",
            "Tonghan Wang",
            "Jiayuan Liu",
            "Chi Han",
            "Chongjie Zhang"
        ],
        "summary": "How cooperation emerges is a long-standing and interdisciplinary problem. Game-theoretical studies on social dilemmas reveal that altruistic incentives are critical to the emergence of cooperation but their analyses are limited to stateless games. For more realistic scenarios, multi-agent reinforcement learning has been used to study sequential social dilemmas (SSDs). Recent works show that learning to incentivize other agents can promote cooperation in SSDs. However, we find that, with these incentivizing mechanisms, the team cooperation level does not converge and regularly oscillates between cooperation and defection during learning. We show that a second-order social dilemma resulting from the incentive mechanisms is the main reason for such fragile cooperation. We formally analyze the dynamics of second-order social dilemmas and find that a typical tendency of humans, called homophily, provides a promising solution. We propose a novel learning framework to encourage homophilic incentives and show that it achieves stable cooperation in both SSDs of public goods and tragedy of the commons.",
        "published": "2021-04-23T08:00:45Z",
        "link": "http://arxiv.org/abs/2104.11455v2",
        "categories": [
            "cs.MA",
            "cs.CY",
            "cs.LG"
        ]
    },
    {
        "title": "Leveraging Sharing Communities to Achieve Federated Learning for   Cybersecurity",
        "authors": [
            "Frank W. Bentrem",
            "Michael A. Corsello",
            "Joshua J. Palm"
        ],
        "summary": "Automated cyber threat detection in computer networks is a major challenge in cybersecurity. The cyber domain has inherent challenges that make traditional machine learning techniques problematic, specifically the need to learn continually evolving attacks through global collaboration while maintaining data privacy, and the varying resources available to network owners. We present a scheme to mitigate these difficulties through an architectural approach using community model sharing with a streaming analytic pipeline. Our streaming approach trains models incrementally as each log record is processed, thereby adjusting to concept drift resulting from changing attacks. Further, we designed a community sharing approach which federates learning through merging models without the need to share sensitive cyber-log data. Finally, by standardizing data and Machine Learning processes in a modular way, we provide network security operators the ability to manage cyber threat events and model sensitivity through community member and analytic method weighting in ways that are best suited for their available resources and data.",
        "published": "2021-04-23T18:07:43Z",
        "link": "http://arxiv.org/abs/2104.11763v2",
        "categories": [
            "cs.CR",
            "cs.MA"
        ]
    },
    {
        "title": "Compilation-based Solvers for Multi-Agent Path Finding: a Survey,   Discussion, and Future Opportunities",
        "authors": [
            "Pavel Surynek"
        ],
        "summary": "Multi-agent path finding (MAPF) attracts considerable attention in artificial intelligence community as well as in robotics, and other fields such as warehouse logistics. The task in the standard MAPF is to find paths through which agents can navigate from their starting positions to specified individual goal positions. The combination of two additional requirements makes the problem computationally challenging: (i) agents must not collide with each other and (ii) the paths must be optimal with respect to some objective. Two major approaches to optimal MAPF solving include (1) dedicated search-based methods, which solve MAPF directly, and (2) compilation-based methods that reduce a MAPF instance to an instance in a different well established formalism, for which an efficient solver exists. The compilation-based MAPF solving can benefit from advancements accumulated during the development of the target solver often decades long. We summarize and compare contemporary compilation-based solvers for MAPF using formalisms like ASP, MIP, and SAT. We show the lessons learned from past developments and current trends in the topic and discuss its wider impact.",
        "published": "2021-04-23T20:13:12Z",
        "link": "http://arxiv.org/abs/2104.11809v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Social Distancing via Social Scheduling",
        "authors": [
            "Deepesh Kumar Lall",
            "Garima Shakya",
            "Swaprava Nath"
        ],
        "summary": "Motivated by the need of {\\em social distancing} during a pandemic, we consider an approach to schedule the visitors of a facility (e.g., a general store). Our algorithms take input from the citizens and schedule the store's discrete time-slots based on their importance to visit the facility. Naturally, the formulation applies to several similar problems. We consider {\\em indivisible} job requests that take single or multiple slots to complete. The salient properties of our approach are: it (a)~ensures social distancing by ensuring a maximum population in a given time-slot at the facility, (b)~aims to prioritize individuals based on the importance of the jobs, (c)~maintains truthfulness of the reported importance by adding a {\\em cooling-off} period after their allocated time-slot, during which the individual cannot re-access the same facility, (d)~guarantees voluntary participation of the citizens, and yet (e)~is computationally tractable. The mechanisms we propose are prior-free. We show that the problem becomes NP-complete for indivisible multi-slot demands, and provide a polynomial-time mechanism that is truthful, individually rational, and approximately optimal. Experiments with data collected from a store show that visitors with more important (single-slot) jobs are allocated more preferred slots, which comes at the cost of a longer cooling-off period and significantly reduces social congestion. For the multi-slot jobs, our mechanism yields reasonable approximation while reducing the computation time significantly.",
        "published": "2021-04-24T05:23:35Z",
        "link": "http://arxiv.org/abs/2104.11884v2",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "baller2vec++: A Look-Ahead Multi-Entity Transformer For Modeling   Coordinated Agents",
        "authors": [
            "Michael A. Alcorn",
            "Anh Nguyen"
        ],
        "summary": "In many multi-agent spatiotemporal systems, agents operate under the influence of shared, unobserved variables (e.g., the play a team is executing in a game of basketball). As a result, the trajectories of the agents are often statistically dependent at any given time step; however, almost universally, multi-agent models implicitly assume the agents' trajectories are statistically independent at each time step. In this paper, we introduce baller2vec++, a multi-entity Transformer that can effectively model coordinated agents. Specifically, baller2vec++ applies a specially designed self-attention mask to a mixture of location and \"look-ahead\" trajectory sequences to learn the distributions of statistically dependent agent trajectories. We show that, unlike baller2vec (baller2vec++'s predecessor), baller2vec++ can learn to emulate the behavior of perfectly coordinated agents in a simulated toy dataset. Additionally, when modeling the trajectories of professional basketball players, baller2vec++ outperforms baller2vec by a wide margin.",
        "published": "2021-04-24T16:20:47Z",
        "link": "http://arxiv.org/abs/2104.11980v2",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Influence of group characteristics on agent voting",
        "authors": [
            "Marcin Maleszka"
        ],
        "summary": "A collective of identical agents in a multi-agent system often works together towards the common goal. In situations where no supervisor agents are present to make decisions for the group, these agents must achieve some consensus via negotiations and other types of communications. We have previously shown that the structure of the group and the priority of communication has a high influence on the group decision if consensus theory methods are used. In this paper, we explore the influence of preferential communication channels in asynchronous group communication in situations, where majority vote and dominant value are used. We also show how this relates to consensus approach in such groups and how to use a combination of both approaches to improve performance of real-life multi-agent systems.",
        "published": "2021-04-26T11:12:35Z",
        "link": "http://arxiv.org/abs/2104.12473v1",
        "categories": [
            "cs.MA",
            "I.6.3; J.4"
        ]
    },
    {
        "title": "Computational Performance of Deep Reinforcement Learning to find Nash   Equilibria",
        "authors": [
            "Christoph Graf",
            "Viktor Zobernig",
            "Johannes Schmidt",
            "Claude Klöckl"
        ],
        "summary": "We test the performance of deep deterministic policy gradient (DDPG), a deep reinforcement learning algorithm, able to handle continuous state and action spaces, to learn Nash equilibria in a setting where firms compete in prices. These algorithms are typically considered model-free because they do not require transition probability functions (as in e.g., Markov games) or predefined functional forms. Despite being model-free, a large set of parameters are utilized in various steps of the algorithm. These are e.g., learning rates, memory buffers, state-space dimensioning, normalizations, or noise decay rates and the purpose of this work is to systematically test the effect of these parameter configurations on convergence to the analytically derived Bertrand equilibrium. We find parameter choices that can reach convergence rates of up to 99%. The reliable convergence may make the method a useful tool to study strategic behavior of firms even in more complex settings. Keywords: Bertrand Equilibrium, Competition in Uniform Price Auctions, Deep Deterministic Policy Gradient Algorithm, Parameter Sensitivity Analysis",
        "published": "2021-04-26T22:14:17Z",
        "link": "http://arxiv.org/abs/2104.12895v1",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "econ.TH"
        ]
    },
    {
        "title": "3D Placement and Orientation of mmWave-based UAVs for Guaranteed LoS   Coverage",
        "authors": [
            "Javad Sabzehali",
            "Vijay K. Shah",
            "Harpreet S. Dhillon",
            "Jeffrey H. Reed"
        ],
        "summary": "Unmanned aerial vehicles (UAVs), as aerial base stations, are a promising solution for providing wireless communications, thanks to their high flexibility and autonomy. Moreover, emerging services, such as extended reality, require high-capacity communications. To achieve this, millimeter wave (mmWave), and recently, terahertz bands have been considered for UAV communications. However, communication at these high frequencies requires a line-of-sight (LoS) to the terminals, which may be located in 3D space and may have extremely limited direct-line-of-view (LoV) due to blocking objects, like buildings and trees. In this paper, we investigate the problem of determining 3D placement and orientation of UAVs such that users have guaranteed LoS coverage by at least one UAV and the signal-to-noise ratio (SNR) between the UAV-user pairs are maximized. We formulate the problem as an integer linear programming(ILP) problem and prove its NP-hardness. Next, we propose a low-complexity geometry-based greedy algorithm to solve the problem efficiently. Our simulation results show that the proposed algorithm (almost) always guarantees LoS coverage to all users in all considered simulation settings.",
        "published": "2021-04-27T05:55:18Z",
        "link": "http://arxiv.org/abs/2104.12993v1",
        "categories": [
            "cs.IT",
            "cs.MA",
            "cs.NI",
            "math.IT"
        ]
    },
    {
        "title": "Semi-On-Policy Training for Sample Efficient Multi-Agent Policy   Gradients",
        "authors": [
            "Bozhidar Vasilev",
            "Tarun Gupta",
            "Bei Peng",
            "Shimon Whiteson"
        ],
        "summary": "Policy gradient methods are an attractive approach to multi-agent reinforcement learning problems due to their convergence properties and robustness in partially observable scenarios. However, there is a significant performance gap between state-of-the-art policy gradient and value-based methods on the popular StarCraft Multi-Agent Challenge (SMAC) benchmark. In this paper, we introduce semi-on-policy (SOP) training as an effective and computationally efficient way to address the sample inefficiency of on-policy policy gradient methods. We enhance two state-of-the-art policy gradient algorithms with SOP training, demonstrating significant performance improvements. Furthermore, we show that our methods perform as well or better than state-of-the-art value-based methods on a variety of SMAC tasks.",
        "published": "2021-04-27T19:37:01Z",
        "link": "http://arxiv.org/abs/2104.13446v2",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "A ridesharing simulation platform that considers dynamic supply-demand   interactions",
        "authors": [
            "Rui Yao",
            "Shlomo Bekhor"
        ],
        "summary": "This paper presents a new ridesharing simulation platform that accounts for dynamic driver supply and passenger demand, and complex interactions between drivers and passengers. The proposed simulation platform explicitly considers driver and passenger acceptance/rejection on the matching options, and cancellation before/after being matched. New simulation events, procedures and modules have been developed to handle these realistic interactions. The capabilities of the simulation platform are illustrated using numerical experiments. The experiments confirm the importance of considering supply and demand interactions and provide new insights to ridesharing operations. Results show that increase of driver supply does not always increase matching option accept rate, and larger matching window could have negative impacts on overall ridesharing success rate. These results emphasize the importance of a careful planning of a ridesharing system.",
        "published": "2021-04-27T20:31:55Z",
        "link": "http://arxiv.org/abs/2104.13463v2",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Shared Control of Robot-Robot Collaborative Lifting with Agent Postural   and Force Ergonomic Optimization",
        "authors": [
            "Lorenzo Rapetti",
            "Yeshasvi Tirupachuri",
            "Alberto Ranavolo",
            "Tomohiro Kawakami",
            "Takahide Yoshiike",
            "Daniele Pucci"
        ],
        "summary": "Humans show specialized strategies for efficient collaboration. Transferring similar strategies to humanoid robots can improve their capability to interact with other agents, leading the way to complex collaborative scenarios with multiple agents acting on a shared environment. In this paper we present a control framework for robot-robot collaborative lifting. The proposed shared controller takes into account the joint action of both the robots thanks to a centralized controller that communicates with them, and solves the whole-system optimization. Efficient collaboration is ensured by taking into account the ergonomic requirements of the robots through the optimization of posture and contact forces. The framework is validated in an experimental scenario with two iCub humanoid robots performing different payload lifting sequences.",
        "published": "2021-04-28T08:31:54Z",
        "link": "http://arxiv.org/abs/2104.13630v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Collaborative Human-Agent Planning for Resilience",
        "authors": [
            "Ronal Singh",
            "Tim Miller",
            "Darryn Reid"
        ],
        "summary": "Intelligent agents powered by AI planning assist people in complex scenarios, such as managing teams of semi-autonomous vehicles. However, AI planning models may be incomplete, leading to plans that do not adequately meet the stated objectives, especially in unpredicted situations. Humans, who are apt at identifying and adapting to unusual situations, may be able to assist planning agents in these situations by encoding their knowledge into a planner at run-time. We investigate whether people can collaborate with agents by providing their knowledge to an agent using linear temporal logic (LTL) at run-time without changing the agent's domain model. We presented 24 participants with baseline plans for situations in which a planner had limitations, and asked the participants for workarounds for these limitations. We encoded these workarounds as LTL constraints. Results show that participants' constraints improved the expected return of the plans by 10% ($p < 0.05$) relative to baseline plans, demonstrating that human insight can be used in collaborative planning for resilience. However, participants used more declarative than control constraints over time, but declarative constraints produced plans less similar to the expectation of the participants, which could lead to potential trust issues.",
        "published": "2021-04-29T03:21:31Z",
        "link": "http://arxiv.org/abs/2104.14089v1",
        "categories": [
            "cs.AI",
            "cs.HC",
            "cs.MA"
        ]
    },
    {
        "title": "Convergence Analysis and System Design for Federated Learning over   Wireless Networks",
        "authors": [
            "Shuo Wan",
            "Jiaxun Lu",
            "Pingyi Fan",
            "Yunfeng Shao",
            "Chenghui Peng",
            "Khaled B. letaief"
        ],
        "summary": "Federated learning (FL) has recently emerged as an important and promising learning scheme in IoT, enabling devices to jointly learn a model without sharing their raw data sets. However, as the training data in FL is not collected and stored centrally, FL training requires frequent model exchange, which is largely affected by the wireless communication network. Therein, limited bandwidth and random package loss restrict interactions in training. Meanwhile, the insufficient message synchronization among distributed clients could also affect FL convergence. In this paper, we analyze the convergence rate of FL training considering the joint impact of communication network and training settings. Further by considering the training costs in terms of time and power, the optimal scheduling problems for communication networks are formulated. The developed theoretical results can be used to assist the system parameter selections and explain the principle of how the wireless communication system could influence the distributed training process and network scheduling.",
        "published": "2021-04-30T02:33:29Z",
        "link": "http://arxiv.org/abs/2105.00872v1",
        "categories": [
            "cs.LG",
            "cs.DC",
            "cs.MA",
            "cs.NI",
            "H.1.1; I.2.11"
        ]
    },
    {
        "title": "Unique Ergodicity in the Interconnections of Ensembles with Applications   to Two-Sided Markets",
        "authors": [
            "Wynita M. Griggs",
            "Ramen Ghosh",
            "Jakub Marecek",
            "Robert N. Shorten"
        ],
        "summary": "There has been much recent interest in two-sided markets and dynamics thereof. In a rather a general discrete-time feedback model, which we show conditions that assure that for each agent, there exists the limit of a long-run average allocation of a resource to the agent, which is independent of any initial conditions. We call this property the unique ergodicity.   Our model encompasses two-sided markets and more complicated interconnections of workers and customers, such as in a supply chain. It allows for non-linearity of the response functions of market participants. Finally, it allows for uncertainty in the response of market participants by considering a set of the possible responses to either price or other signals and a measure to sample from these.",
        "published": "2021-04-30T09:21:15Z",
        "link": "http://arxiv.org/abs/2104.14858v2",
        "categories": [
            "math.OC",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Tracking and managing deemed abilities",
        "authors": [
            "Nicolas Troquard"
        ],
        "summary": "Information about the powers and abilities of acting entities is used to coordinate their actions in societies, either physical or digital. Yet, the commonsensical meaning of an acting entity being deemed able to do something is still missing from the existing specification languages for the web or for multi-agent systems. We advance a general purpose abstract logical account of evidence-based ability. A basic model can be thought of as the ongoing trace of a multi-agent system. Every state records systemic confirmations and disconfirmations of whether an acting entity is able to bring about something. Qualitative inductive reasoning is then used in order to infer what acting entities are deemed able to bring about in the multi-agent system. A temporalised modal language is used to talk about deemed ability, actual agency, and confirmation and disconfirmation of deemed ability. What constitutes a confirmation and a disconfirmation is left to the modeller as in general it depends on the application at hand. So to illustrate the methodology we propose two extended examples, one in practical philosophy, the other in system engineering. We first use a logic of agency and ability to obtain a version of Mele's general practical abilities. Then, we look at the management of abilities in a supervised system.",
        "published": "2021-04-30T10:34:00Z",
        "link": "http://arxiv.org/abs/2104.14892v3",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Discrete-Time Mean Field Control with Environment States",
        "authors": [
            "Kai Cui",
            "Anam Tahir",
            "Mark Sinzger",
            "Heinz Koeppl"
        ],
        "summary": "Multi-agent reinforcement learning methods have shown remarkable potential in solving complex multi-agent problems but mostly lack theoretical guarantees. Recently, mean field control and mean field games have been established as a tractable solution for large-scale multi-agent problems with many agents. In this work, driven by a motivating scheduling problem, we consider a discrete-time mean field control model with common environment states. We rigorously establish approximate optimality as the number of agents grows in the finite agent case and find that a dynamic programming principle holds, resulting in the existence of an optimal stationary policy. As exact solutions are difficult in general due to the resulting continuous action space of the limiting mean field Markov decision process, we apply established deep reinforcement learning methods to solve the associated mean field control problem. The performance of the learned mean field control policy is compared to typical multi-agent reinforcement learning approaches and is found to converge to the mean field performance for sufficiently many agents, verifying the obtained theoretical results and reaching competitive solutions.",
        "published": "2021-04-30T10:58:01Z",
        "link": "http://arxiv.org/abs/2104.14900v2",
        "categories": [
            "cs.LG",
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "Noe: Norms Emergence and Robustness Based on Emotions in Multiagent   Systems",
        "authors": [
            "Sz-Ting Tzeng",
            "Nirav Ajmeri",
            "Munindar P. Singh"
        ],
        "summary": "Social norms characterize collective and acceptable group conducts in human society. Furthermore, some social norms emerge from interactions of agents or humans. To achieve agent autonomy and make norm satisfaction explainable, we include emotions into the normative reasoning process, which evaluates whether to comply or violate a norm. Specifically, before selecting an action to execute, an agent observes the environment and infers the state and consequences with its internal states after norm satisfaction or violation of a social norm. Both norm satisfaction and violation provoke further emotions, and the subsequent emotions affect norm enforcement. This paper investigates how modeling emotions affect the emergence and robustness of social norms via social simulation experiments. We find that an ability in agents to consider emotional responses to the outcomes of norm satisfaction and violation (1) promotes norm compliance; and (2) improves societal welfare.",
        "published": "2021-04-30T14:42:22Z",
        "link": "http://arxiv.org/abs/2104.15034v2",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Participatory Budgeting with Donations and Diversity Constraints",
        "authors": [
            "Jiehua Chen",
            "Martin Lackner",
            "Jan Maly"
        ],
        "summary": "Participatory budgeting (PB) is a democratic process where citizens jointly decide on how to allocate public funds to indivisible projects. This paper focuses on PB processes where citizens may give additional money to projects they want to see funded. We introduce a formal framework for this kind of PB with donations. Our framework also allows for diversity constraints, meaning that each project belongs to one or more types, and there are lower and upper bounds on the number of projects of the same type that can be funded. We propose three general classes of methods for aggregating the citizens' preferences in the presence of donations and analyze their axiomatic properties. Furthermore, we investigate the computational complexity of determining the outcome of a PB process with donations and of finding a citizen's optimal donation strategy.",
        "published": "2021-04-30T15:48:25Z",
        "link": "http://arxiv.org/abs/2104.15075v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.CC",
            "cs.DS",
            "cs.GT"
        ]
    },
    {
        "title": "Coupling purposes with status-functions in artificial institutions",
        "authors": [
            "Rafhael R. Cunha",
            "Jomi Fred Hübner",
            "Maiquel de Brito"
        ],
        "summary": "In multi-agent systems, the agents may have goals that depend on a social, shared interpretation about the facts occurring in the system. These are the so-called social goals. Artificial institutions provide such a social interpretation by assigning statuses to the concrete elements that compose the system. These statuses are supposed to enable the assignee element to perform functions that are not exclusively inherent to their design features. However, the enabled functions are not explicit in the existing models of artificial institutions. As a consequence, (i) agents may have difficulties to reasoning about how to achieve their own social goals with the help of artificial institutions and (ii) these institutions are not well instrumented to receive incoming agents, in the case of open systems. Considering those problems, this paper proposes a model to express the functions -- or the purposes -- associated with the status-functions helping the agents to reason about their social goals and the institution. We evaluate the model by using it in some scenarios, showing how the agents can use purposes to reason about the satisfaction of their social goals in institutional contexts and how the institution can be flexible enough to support new agents operating in the system.",
        "published": "2021-04-30T21:10:57Z",
        "link": "http://arxiv.org/abs/2105.00090v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Run-time Norms Synthesis in Multi-Objective Multi-Agent Systems",
        "authors": [
            "Maha Riad",
            "Fatemeh Golpayegani"
        ],
        "summary": "Norms represent behavioural aspects that are encouraged by a social group of agents or the majority of agents in a system. Normative systems enable coordinating synthesised norms of heterogeneous agents in complex multi-agent systems autonomously. In real applications, agents have multiple objectives that may contradict each other or contradict the synthesised norms. Therefore, agents need a mechanism to understand the impact of a suggested norm on their objectives and decide whether or not to adopt it. To address these challenges, a utility based norm synthesis (UNS) model is proposed which allows the agents to coordinate their behaviour while achieving their conflicting objectives. UNS proposes a utility-based case-based reasoning technique, using case-based reasoning for run-time norm synthesising in a centralised approach, and a utility function derived from the objectives of the system and its operating agents to decide whether or not to adopt a norm. The model is evaluated using a two intersecting roads scenario and the results show its efficacy to optimise multiple objectives while adopting synthesised norms.",
        "published": "2021-05-01T00:04:40Z",
        "link": "http://arxiv.org/abs/2105.00124v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "A Framework for Automatic Monitoring of Norms that regulate Time   Constrained Actions",
        "authors": [
            "Nicoletta Fornara",
            "Soheil Roshankish",
            "Marco Colombetti"
        ],
        "summary": "This paper addresses the problem of proposing a model of norms and a framework for automatically computing their violation or fulfilment. The proposed T-NORM model can be used to express abstract norms able to regulate classes of actions that should or should not be performed in a temporal interval. We show how the model can be used to formalize obligations and prohibitions and for inhibiting them by introducing permissions and exemptions. The basic building blocks for norm specification consists of rules with suitably nested components. The activation condition, the regulated actions, and the temporal constrains of norms are specified using the W3C Web Ontology Language (OWL 2). Thanks to this choice, it is possible to use OWL reasoning for computing the effects that the logical implication between actions has on norms fulfilment or violation. The operational semantics of the T-NORM model is specified by providing an unambiguous procedure for translating every norm and every exception into production rules.",
        "published": "2021-05-01T09:29:32Z",
        "link": "http://arxiv.org/abs/2105.00200v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Lecture Notes on Voting Theory",
        "authors": [
            "Davide Grossi"
        ],
        "summary": "These lecture notes have been developed for the course Computational Social Choice of the Artificial Intelligence MSc programme at the University of Groningen. They cover mathematical and algorithmic aspects of voting theory.",
        "published": "2021-05-01T11:19:44Z",
        "link": "http://arxiv.org/abs/2105.00216v1",
        "categories": [
            "cs.MA",
            "econ.TH"
        ]
    },
    {
        "title": "Reducing Bus Bunching with Asynchronous Multi-Agent Reinforcement   Learning",
        "authors": [
            "Jiawei Wang",
            "Lijun Sun"
        ],
        "summary": "The bus system is a critical component of sustainable urban transportation. However, due to the significant uncertainties in passenger demand and traffic conditions, bus operation is unstable in nature and bus bunching has become a common phenomenon that undermines the reliability and efficiency of bus services. Despite recent advances in multi-agent reinforcement learning (MARL) on traffic control, little research has focused on bus fleet control due to the tricky asynchronous characteristic -- control actions only happen when a bus arrives at a bus stop and thus agents do not act simultaneously. In this study, we formulate route-level bus fleet control as an asynchronous multi-agent reinforcement learning (ASMR) problem and extend the classical actor-critic architecture to handle the asynchronous issue. Specifically, we design a novel critic network to effectively approximate the marginal contribution for other agents, in which graph attention neural network is used to conduct inductive learning for policy evaluation. The critic structure also helps the ego agent optimize its policy more efficiently. We evaluate the proposed framework on real-world bus services and actual passenger demand derived from smart card data. Our results show that the proposed model outperforms both traditional headway-based control methods and existing MARL methods.",
        "published": "2021-05-02T02:08:07Z",
        "link": "http://arxiv.org/abs/2105.00376v2",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Multi-Agent Routing and Scheduling Through Coalition Formation",
        "authors": [
            "Luca Capezzuto",
            "Danesh Tarapore",
            "Sarvapali D. Ramchurn"
        ],
        "summary": "In task allocation for real-time domains, such as disaster response, a limited number of agents is deployed across a large area to carry out numerous tasks, each with its prerequisites, profit, time window and workload. To maximize profits while minimizing time penalties, agents need to cooperate by forming, disbanding and reforming coalitions. In this paper, we name this problem Multi-Agent Routing and Scheduling through Coalition formation (MARSC) and show that it generalizes the important Team Orienteering Problem with Time Windows. We propose a binary integer program and an anytime and scalable heuristic to solve it. Using public London Fire Brigade records, we create a dataset with 347588 tasks and a test framework that simulates the mobilization of firefighters. In problems with up to 150 agents and 3000 tasks, our heuristic finds solutions up to 3.25 times better than the Earliest Deadline First approach commonly used in real-time systems. Our results constitute the first large-scale benchmark for the MARSC problem.",
        "published": "2021-05-02T11:53:44Z",
        "link": "http://arxiv.org/abs/2105.00451v2",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Curious Exploration and Return-based Memory Restoration for Deep   Reinforcement Learning",
        "authors": [
            "Saeed Tafazzol",
            "Erfan Fathi",
            "Mahdi Rezaei",
            "Ehsan Asali"
        ],
        "summary": "Reward engineering and designing an incentive reward function are non-trivial tasks to train agents in complex environments. Furthermore, an inaccurate reward function may lead to a biased behaviour which is far from an efficient and optimised behaviour. In this paper, we focus on training a single agent to score goals with binary success/failure reward function in Half Field Offense domain. As the major advantage of this research, the agent has no presumption about the environment which means it only follows the original formulation of reinforcement learning agents. The main challenge of using such a reward function is the high sparsity of positive reward signals. To address this problem, we use a simple prediction-based exploration strategy (called Curious Exploration) along with a Return-based Memory Restoration (RMR) technique which tends to remember more valuable memories. The proposed method can be utilized to train agents in environments with fairly complex state and action spaces. Our experimental results show that many recent solutions including our baseline method fail to learn and perform in complex soccer domain. However, the proposed method can converge easily to the nearly optimal behaviour. The video presenting the performance of our trained agent is available at http://bit.ly/HFO_Binary_Reward.",
        "published": "2021-05-02T16:01:34Z",
        "link": "http://arxiv.org/abs/2105.00499v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Altruism Design in Networked Public Goods Games",
        "authors": [
            "Sixie Yu",
            "David Kempe",
            "Yevgeniy Vorobeychik"
        ],
        "summary": "Many collective decision-making settings feature a strategic tension between agents acting out of individual self-interest and promoting a common good. These include wearing face masks during a pandemic, voting, and vaccination. Networked public goods games capture this tension, with networks encoding strategic interdependence among agents. Conventional models of public goods games posit solely individual self-interest as a motivation, even though altruistic motivations have long been known to play a significant role in agents' decisions. We introduce a novel extension of public goods games to account for altruistic motivations by adding a term in the utility function that incorporates the perceived benefits an agent obtains from the welfare of others, mediated by an altruism graph. Most importantly, we view altruism not as immutable, but rather as a lever for promoting the common good. Our central algorithmic question then revolves around the computational complexity of modifying the altruism network to achieve desired public goods game investment profiles. We first show that the problem can be solved using linear programming when a principal can fractionally modify the altruism network. While the problem becomes in general intractable if the principal's actions are all-or-nothing, we exhibit several tractable special cases.",
        "published": "2021-05-02T16:35:47Z",
        "link": "http://arxiv.org/abs/2105.00505v1",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Hybrid Intelligence",
        "authors": [
            "Dominik Dellermann",
            "Philipp Ebel",
            "Matthias Soellner",
            "Jan Marco Leimeister"
        ],
        "summary": "Research has a long history of discussing what is superior in predicting certain outcomes: statistical methods or the human brain. This debate has repeatedly been sparked off by the remarkable technological advances in the field of artificial intelligence (AI), such as solving tasks like object and speech recognition, achieving significant improvements in accuracy through deep-learning algorithms (Goodfellow et al. 2016), or combining various methods of computational intelligence, such as fuzzy logic, genetic algorithms, and case-based reasoning (Medsker 2012). One of the implicit promises that underlie these advancements is that machines will 1 day be capable of performing complex tasks or may even supersede humans in performing these tasks. This triggers new heated debates of when machines will ultimately replace humans (McAfee and Brynjolfsson 2017). While previous research has proved that AI performs well in some clearly defined tasks such as playing chess, playing Go or identifying objects on images, it is doubted that the development of an artificial general intelligence (AGI) which is able to solve multiple tasks at the same time can be achieved in the near future (e.g., Russell and Norvig 2016). Moreover, the use of AI to solve complex business problems in organizational contexts occurs scarcely, and applications for AI that solve complex problems remain mainly in laboratory settings instead of being implemented in practice. Since the road to AGI is still a long one, we argue that the most likely paradigm for the division of labor between humans and machines in the next decades is Hybrid Intelligence. This concept aims at using the complementary strengths of human intelligence and AI, so that they can perform better than each of the two could separately (e.g., Kamar 2016).",
        "published": "2021-05-03T08:56:09Z",
        "link": "http://arxiv.org/abs/2105.00691v1",
        "categories": [
            "cs.AI",
            "cs.HC",
            "cs.MA"
        ]
    },
    {
        "title": "Mean Field Equilibrium in Multi-Armed Bandit Game with Continuous Reward",
        "authors": [
            "Xiong Wang",
            "Riheng Jia"
        ],
        "summary": "Mean field game facilitates analyzing multi-armed bandit (MAB) for a large number of agents by approximating their interactions with an average effect. Existing mean field models for multi-agent MAB mostly assume a binary reward function, which leads to tractable analysis but is usually not applicable in practical scenarios. In this paper, we study the mean field bandit game with a continuous reward function. Specifically, we focus on deriving the existence and uniqueness of mean field equilibrium (MFE), thereby guaranteeing the asymptotic stability of the multi-agent system. To accommodate the continuous reward function, we encode the learned reward into an agent state, which is in turn mapped to its stochastic arm playing policy and updated using realized observations. We show that the state evolution is upper semi-continuous, based on which the existence of MFE is obtained. As the Markov analysis is mainly for the case of discrete state, we transform the stochastic continuous state evolution into a deterministic ordinary differential equation (ODE). On this basis, we can characterize a contraction mapping for the ODE to ensure a unique MFE for the bandit game. Extensive evaluations validate our MFE characterization, and exhibit tight empirical regret of the MAB problem.",
        "published": "2021-05-03T11:50:06Z",
        "link": "http://arxiv.org/abs/2105.00767v2",
        "categories": [
            "cs.MA",
            "cs.GT",
            "cs.LG"
        ]
    },
    {
        "title": "Towards A Multi-agent System for Online Hate Speech Detection",
        "authors": [
            "Gaurav Sahu",
            "Robin Cohen",
            "Olga Vechtomova"
        ],
        "summary": "This paper envisions a multi-agent system for detecting the presence of hate speech in online social media platforms such as Twitter and Facebook. We introduce a novel framework employing deep learning techniques to coordinate the channels of textual and im-age processing. Our experimental results aim to demonstrate the effectiveness of our methods for classifying online content, training the proposed neural network model to effectively detect hateful instances in the input. We conclude with a discussion of how our system may be of use to provide recommendations to users who are managing online social networks, showcasing the immense potential of intelligent multi-agent systems towards delivering social good.",
        "published": "2021-05-03T19:06:42Z",
        "link": "http://arxiv.org/abs/2105.01129v1",
        "categories": [
            "cs.AI",
            "cs.CL",
            "cs.CV",
            "cs.MA"
        ]
    },
    {
        "title": "Polynomial-Time Algorithms for Multi-Agent Minimal-Capacity Planning",
        "authors": [
            "Murat Cubuktepe",
            "František Blahoudek",
            "Ufuk Topcu"
        ],
        "summary": "We study the problem of minimizing the resource capacity of autonomous agents cooperating to achieve a shared task. More specifically, we consider high-level planning for a team of homogeneous agents that operate under resource constraints in stochastic environments and share a common goal: given a set of target locations, ensure that each location will be visited infinitely often by some agent almost surely. We formalize the dynamics of agents by consumption Markov decision processes. In a consumption Markov decision process, the agent has a resource of limited capacity. Each action of the agent may consume some amount of the resource. To avoid exhaustion, the agent can replenish its resource to full capacity in designated reload states. The resource capacity restricts the capabilities of the agent. The objective is to assign target locations to agents, and each agent is only responsible for visiting the assigned subset of target locations repeatedly. Moreover, the assignment must ensure that the agents can carry out their tasks with minimal resource capacity. We reduce the problem of finding target assignments for a team of agents with the lowest possible capacity to an equivalent graph-theoretical problem. We develop an algorithm that solves this graph problem in time that is \\emph{polynomial} in the number of agents, target locations, and size of the consumption Markov decision process. We demonstrate the applicability and scalability of the algorithm in a scenario where hundreds of unmanned underwater vehicles monitor hundreds of locations in environments with stochastic ocean currents.",
        "published": "2021-05-04T00:30:02Z",
        "link": "http://arxiv.org/abs/2105.01225v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "The distributed dual ascent algorithm is robust to asynchrony",
        "authors": [
            "Mattia Bianchi",
            "Wicak Ananduta",
            "Sergio Grammatico"
        ],
        "summary": "The distributed dual ascent is an established algorithm to solve strongly convex multi-agent optimization problems with separable cost functions, in the presence of coupling constraints. In this paper, we study its asynchronous counterpart. Specifically, we assume that each agent only relies on the outdated information received from some neighbors. Differently from the existing randomized and dual block-coordinate schemes, we show convergence under heterogeneous delays, communication and update frequencies. Consequently, our asynchronous dual ascent algorithm can be implemented without requiring any coordination between the agents.",
        "published": "2021-05-04T09:01:49Z",
        "link": "http://arxiv.org/abs/2105.01372v1",
        "categories": [
            "math.OC",
            "cs.DC",
            "cs.MA"
        ]
    },
    {
        "title": "The Synergy of Complex Event Processing and Tiny Machine Learning in   Industrial IoT",
        "authors": [
            "Haoyu Ren",
            "Darko Anicic",
            "Thomas Runkler"
        ],
        "summary": "Focusing on comprehensive networking, big data, and artificial intelligence, the Industrial Internet-of-Things (IIoT) facilitates efficiency and robustness in factory operations. Various sensors and field devices play a central role, as they generate a vast amount of real-time data that can provide insights into manufacturing. The synergy of complex event processing (CEP) and machine learning (ML) has been developed actively in the last years in IIoT to identify patterns in heterogeneous data streams and fuse raw data into tangible facts. In a traditional compute-centric paradigm, the raw field data are continuously sent to the cloud and processed centrally. As IIoT devices become increasingly pervasive and ubiquitous, concerns are raised since transmitting such amount of data is energy-intensive, vulnerable to be intercepted, and subjected to high latency. The data-centric paradigm can essentially solve these problems by empowering IIoT to perform decentralized on-device ML and CEP, keeping data primarily on edge devices and minimizing communications. However, this is no mean feat because most IIoT edge devices are designed to be computationally constrained with low power consumption. This paper proposes a framework that exploits ML and CEP's synergy at the edge in distributed sensor networks. By leveraging tiny ML and micro CEP, we shift the computation from the cloud to the power-constrained IIoT devices and allow users to adapt the on-device ML model and the CEP reasoning logic flexibly on the fly without requiring to reupload the whole program. Lastly, we evaluate the proposed solution and show its effectiveness and feasibility using an industrial use case of machine safety monitoring.",
        "published": "2021-05-04T14:58:48Z",
        "link": "http://arxiv.org/abs/2105.03371v1",
        "categories": [
            "cs.DC",
            "cs.AI",
            "cs.DB",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Calibration of Human Driving Behavior and Preference Using Naturalistic   Traffic Data",
        "authors": [
            "Qi Dai",
            "Di Shen",
            "Jinhong Wang",
            "Suzhou Huang",
            "Dimitar Filev"
        ],
        "summary": "Understanding human driving behaviors quantitatively is critical even in the era when connected and autonomous vehicles and smart infrastructure are becoming ever more prevalent. This is particularly so as that mixed traffic settings, where autonomous vehicles and human driven vehicles co-exist, are expected to persist for quite some time. Towards this end it is necessary that we have a comprehensive modeling framework for decision-making within which human driving preferences can be inferred statistically from observed driving behaviors in realistic and naturalistic traffic settings. Leveraging a recently proposed computational framework for smart vehicles in a smart world using multi-agent based simulation and optimization, we first recapitulate how the forward problem of driving decision-making is modeled as a state space model. We then show how the model can be inverted to estimate driver preferences from naturalistic traffic data using the standard Kalman filter technique. We explicitly illustrate our approach using the vehicle trajectory data from Sugiyama experiment that was originally meant to demonstrate how stop-and-go shockwave can arise spontaneously without bottlenecks. Not only the estimated state filter can fit the observed data well for each individual vehicle, the inferred utility functions can also re-produce quantitatively similar pattern of the observed collective behaviors. One distinct advantage of our approach is the drastically reduced computational burden. This is possible because our forward model treats driving decision process, which is intrinsically dynamic with multi-agent interactions, as a sequence of independent static optimization problems contingent on the state with a finite look ahead anticipation. Consequently we can practically sidestep solving an interacting dynamic inversion problem that would have been much more computationally demanding.",
        "published": "2021-05-05T01:20:03Z",
        "link": "http://arxiv.org/abs/2105.01820v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Density-Aware Federated Imitation Learning for Connected and Automated   Vehicles with Unsignalized Intersection",
        "authors": [
            "Tianhao Wu",
            "Mingzhi Jiang",
            "Yinhui Han",
            "Zheng Yuan",
            "Lin Zhang"
        ],
        "summary": "Intelligent Transportation System (ITS) has become one of the essential components in Industry 4.0. As one of the critical indicators of ITS, efficiency has attracted wide attention from researchers. However, the next generation of urban traffic carried by multiple transport service providers may prohibit the raw data interaction among multiple regions for privacy reasons, easily ignored in the existing research. This paper puts forward a federated learning-based vehicle control framework to solve the above problem, including interactors, trainers, and an aggregator. In addition, the density-aware model aggregation method is utilized in this framework to improve vehicle control. What is more, to promote the performance of the end-to-end learning algorithm in the safety aspect, this paper proposes an imitation learning algorithm, which can obtain collision avoidance capabilities from a set of collision avoidance rules. Furthermore, a loss-aware experience selection strategy is also explored, reducing the communication overhead between the interactors and the trainers via extra computing. Finally, the experiment results demonstrate that the proposed imitation learning algorithm obtains the ability to avoid collisions and reduces discomfort by 55.71%. Besides, density-aware model aggregation can further reduce discomfort by 41.37%, and the experience selection scheme can reduce the communication overhead by 12.80% while ensuring model convergence.",
        "published": "2021-05-05T06:41:34Z",
        "link": "http://arxiv.org/abs/2105.01889v1",
        "categories": [
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Survey on Multi-Agent Q-Learning frameworks for resource management in   wireless sensor network",
        "authors": [
            "Arvin Tashakori"
        ],
        "summary": "This report aims to survey multi-agent Q-Learning algorithms, analyze different game theory frameworks used, address each framework's applications, and report challenges and future directions. The target application for this study is resource management in the wireless sensor network.   In the first section, the author provided an introduction regarding the applications of wireless sensor networks. After that, the author presented a summary of the Q-Learning algorithm, a well-known classic solution for model-free reinforcement learning problems.   In the third section, the author extended the Q-Learning algorithm for multi-agent scenarios and discussed its challenges.   In the fourth section, the author surveyed sets of game-theoretic frameworks that researchers used to address this problem for resource allocation and task scheduling in the wireless sensor networks. Lastly, the author mentioned some interesting open challenges in this domain.",
        "published": "2021-05-05T23:43:30Z",
        "link": "http://arxiv.org/abs/2105.02371v1",
        "categories": [
            "cs.MA",
            "cs.GT",
            "cs.LG",
            "cs.NI"
        ]
    },
    {
        "title": "Incentivizing Efficient Equilibria in Traffic Networks with Mixed   Autonomy",
        "authors": [
            "Erdem Bıyık",
            "Daniel A. Lazar",
            "Ramtin Pedarsani",
            "Dorsa Sadigh"
        ],
        "summary": "Traffic congestion has large economic and social costs. The introduction of autonomous vehicles can potentially reduce this congestion by increasing road capacity via vehicle platooning and by creating an avenue for influencing people's choice of routes. We consider a network of parallel roads with two modes of transportation: (i) human drivers, who will choose the quickest route available to them, and (ii) a ride hailing service, which provides an array of autonomous vehicle route options, each with different prices, to users. We formalize a model of vehicle flow in mixed autonomy and a model of how autonomous service users make choices between routes with different prices and latencies. Developing an algorithm to learn the preferences of the users, we formulate a planning optimization that chooses prices to maximize a social objective. We demonstrate the benefit of the proposed scheme by comparing the results to theoretical benchmarks which we show can be efficiently calculated.",
        "published": "2021-05-06T03:01:46Z",
        "link": "http://arxiv.org/abs/2106.04678v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG",
            "cs.RO"
        ]
    },
    {
        "title": "Data-Driven Contract Design for Multi-Agent Systems with Collusion   Detection",
        "authors": [
            "Nayara Aguiar",
            "Parv Venkitasubramaniam",
            "Vijay Gupta"
        ],
        "summary": "In applications such as participatory sensing and crowd sensing, self-interested agents exert costly effort towards achieving an objective for the system operator. We study such a setup where a principal incentivizes multiple agents of different types who can collude with each other to derive rent. The principal cannot observe the efforts exerted directly, but only the outcome of the task, which is a noisy function of the effort. The type of each agent influences the effort cost and task output. For a duopoly in which agents are coupled in their payments, we show that if the principal and the agents interact finitely many times, the agents can derive rent by colluding even if the principal knows the types of the agents. However, if the principal and the agents interact infinitely often, the principal can disincentivize agent collusion through a suitable data-driven contract.",
        "published": "2021-05-06T20:00:18Z",
        "link": "http://arxiv.org/abs/2105.02931v1",
        "categories": [
            "eess.SP",
            "cs.MA"
        ]
    },
    {
        "title": "Informational Design of Dynamic Multi-Agent System",
        "authors": [
            "Tao Zhang",
            "Quanyan Zhu"
        ],
        "summary": "This work considers a novel information design problem and studies how the craft of payoff-relevant environmental signals solely can influence the behaviors of intelligent agents. The agents' strategic interactions are captured by a Markov game, in which each agent first selects one external signal from multiple signal sources as additional payoff-relevant information and then takes an action. There is a rational information designer (principal) who possesses one signal source and aims to influence the equilibrium behaviors of the agents by designing the information structure of her signals sent to the agents. We propose a direct information design approach that incentivizes each agent to select the signal sent by the principal, such that the design process avoids the predictions of the agents' strategic selection behaviors. We then introduce the design protocol given a goal of the designer which we refer to as obedient implementability (OIL) and characterize the OIL in a class of obedient sequential Markov perfect equilibria (O-SMPE). A design regime is proposed based on an approach which we refer to as the fixed-point alignment that incentivizes the agents to choose the signal sent by the principal, guarantees that the agents' policy profile of taking actions is the policy component of an O-SMPE and the principal's goal is achieved. We then formulate the principal's optimal goal selection problem in terms of information design and characterize the optimization problem by minimizing the fixed-point misalignments. The proposed approach can be applied to elicit desired behaviors of multi-agent systems in competing as well as cooperating settings and be extended to heterogeneous stochastic games in the complete- and the incomplete-information environments.",
        "published": "2021-05-07T03:46:14Z",
        "link": "http://arxiv.org/abs/2105.03052v2",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "A Bayesian model of information cascades",
        "authors": [
            "Sriashalya Srivathsan",
            "Stephen Cranefield",
            "Jeremy Pitt"
        ],
        "summary": "An information cascade is a circumstance where agents make decisions in a sequential fashion by following other agents. Bikhchandani et al., predict that once a cascade starts it continues, even if it is wrong, until agents receive an external input such as public information. In an information cascade, even if an agent has its own personal choice, it is always overridden by observation of previous agents' actions. This could mean agents end up in a situation where they may act without valuing their own information. As information cascades can have serious social consequences, it is important to have a good understanding of what causes them. We present a detailed Bayesian model of the information gained by agents when observing the choices of other agents and their own private information. Compared to prior work, we remove the high impact of the first observed agent's action by incorporating a prior probability distribution over the information of unobserved agents and investigate an alternative model of choice to that considered in prior work: weighted random choice. Our results show that, in contrast to Bikhchandani's results, cascades will not necessarily occur and adding prior agents' information will delay the effects of cascades.",
        "published": "2021-05-07T11:18:20Z",
        "link": "http://arxiv.org/abs/2105.03166v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Model-based Multi-agent Policy Optimization with Adaptive Opponent-wise   Rollouts",
        "authors": [
            "Weinan Zhang",
            "Xihuai Wang",
            "Jian Shen",
            "Ming Zhou"
        ],
        "summary": "This paper investigates the model-based methods in multi-agent reinforcement learning (MARL). We specify the dynamics sample complexity and the opponent sample complexity in MARL, and conduct a theoretic analysis of return discrepancy upper bound. To reduce the upper bound with the intention of low sample complexity during the whole learning process, we propose a novel decentralized model-based MARL method, named Adaptive Opponent-wise Rollout Policy Optimization (AORPO). In AORPO, each agent builds its multi-agent environment model, consisting of a dynamics model and multiple opponent models, and trains its policy with the adaptive opponent-wise rollout. We further prove the theoretic convergence of AORPO under reasonable assumptions. Empirical experiments on competitive and cooperative tasks demonstrate that AORPO can achieve improved sample efficiency with comparable asymptotic performance over the compared MARL methods.",
        "published": "2021-05-07T16:20:22Z",
        "link": "http://arxiv.org/abs/2105.03363v3",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Scalable, Decentralized Multi-Agent Reinforcement Learning Methods   Inspired by Stigmergy and Ant Colonies",
        "authors": [
            "Austin Anhkhoi Nguyen"
        ],
        "summary": "Bolstering multi-agent learning algorithms to tackle complex coordination and control tasks has been a long-standing challenge of on-going research. Numerous methods have been proposed to help reduce the effects of non-stationarity and unscalability. In this work, we investigate a novel approach to decentralized multi-agent learning and planning that attempts to address these two challenges. In particular, this method is inspired by the cohesion, coordination, and behavior of ant colonies. As a result, these algorithms are designed to be naturally scalable to systems with numerous agents. While no optimality is guaranteed, the method is intended to work well in practice and scale better in efficacy with the number of agents present than others. The approach combines single-agent RL and an ant-colony-inspired decentralized, stigmergic algorithm for multi-agent path planning and environment modification. Specifically, we apply this algorithm in a setting where agents must navigate to a goal location, learning to push rectangular boxes into holes to yield new traversable pathways. It is shown that while the approach yields promising success in this particular environment, it may not be as easily generalized to others. The algorithm designed is notably scalable to numerous agents but is limited in its performance due to its relatively simplistic, rule-based approach. Furthermore, the composability of RL-trained policies is called into question, where, while policies are successful in their training environments, applying trained policies to a larger-scale, multi-agent framework results in unpredictable behavior.",
        "published": "2021-05-08T01:04:51Z",
        "link": "http://arxiv.org/abs/2105.03546v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG",
            "cs.RO"
        ]
    },
    {
        "title": "Solving social dilemmas by reasoning about expectations",
        "authors": [
            "Abira Sengupta",
            "Stephen Cranefield",
            "Jeremy Pitt"
        ],
        "summary": "It has been argued that one role of social constructs, such as institutions, trust and norms, is to coordinate the expectations of autonomous entities in order to resolve collective action situations (such as collective risk dilemmas) through the coordination of behaviour. While much work has addressed the formal representation of these social constructs, in this paper we focus specifically on the formal representation of, and associated reasoning with, the expectations themselves. In particular, we investigate how explicit reasoning about expectations can be used to encode both traditional game theory solution concepts and social mechanisms for the social dilemma situation. We use the Collective Action Simulation Platform (CASP) to model a collective risk dilemma based on a flood plain scenario and show how using expectations in the reasoning mechanisms of the agents making decisions supports the choice of cooperative behaviour.",
        "published": "2021-05-08T01:49:00Z",
        "link": "http://arxiv.org/abs/2105.03552v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Stronger Privacy for Federated Collaborative Filtering with Implicit   Feedback",
        "authors": [
            "Lorenzo Minto",
            "Moritz Haller",
            "Hamed Haddadi",
            "Benjamin Livshits"
        ],
        "summary": "Recommender systems are commonly trained on centrally collected user interaction data like views or clicks. This practice however raises serious privacy concerns regarding the recommender's collection and handling of potentially sensitive data. Several privacy-aware recommender systems have been proposed in recent literature, but comparatively little attention has been given to systems at the intersection of implicit feedback and privacy. To address this shortcoming, we propose a practical federated recommender system for implicit data under user-level local differential privacy (LDP). The privacy-utility trade-off is controlled by parameters $\\epsilon$ and $k$, regulating the per-update privacy budget and the number of $\\epsilon$-LDP gradient updates sent by each user respectively. To further protect the user's privacy, we introduce a proxy network to reduce the fingerprinting surface by anonymizing and shuffling the reports before forwarding them to the recommender. We empirically demonstrate the effectiveness of our framework on the MovieLens dataset, achieving up to Hit Ratio with K=10 (HR@10) 0.68 on 50k users with 5k items. Even on the full dataset, we show that it is possible to achieve reasonable utility with HR@10>0.5 without compromising user privacy.",
        "published": "2021-05-09T13:41:45Z",
        "link": "http://arxiv.org/abs/2105.03941v3",
        "categories": [
            "cs.LG",
            "cs.CR",
            "cs.MA"
        ]
    },
    {
        "title": "Improving Multi-agent Coordination by Learning to Estimate Contention",
        "authors": [
            "Panayiotis Danassis",
            "Florian Wiedemair",
            "Boi Faltings"
        ],
        "summary": "We present a multi-agent learning algorithm, ALMA-Learning, for efficient and fair allocations in large-scale systems. We circumvent the traditional pitfalls of multi-agent learning (e.g., the moving target problem, the curse of dimensionality, or the need for mutually consistent actions) by relying on the ALMA heuristic as a coordination mechanism for each stage game. ALMA-Learning is decentralized, observes only own action/reward pairs, requires no inter-agent communication, and achieves near-optimal (<5% loss) and fair coordination in a variety of synthetic scenarios and a real-world meeting scheduling problem. The lightweight nature and fast learning constitute ALMA-Learning ideal for on-device deployment.",
        "published": "2021-05-09T21:30:48Z",
        "link": "http://arxiv.org/abs/2105.04027v2",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "AoI-Aware Resource Allocation for Platoon-Based C-V2X Networks via   Multi-Agent Multi-Task Reinforcement Learning",
        "authors": [
            "Mohammad Parvini",
            "Mohammad Reza Javan",
            "Nader Mokari",
            "Bijan Abbasi",
            "Eduard A. Jorswieck"
        ],
        "summary": "This paper investigates the problem of age of information (AoI) aware radio resource management for a platooning system. Multiple autonomous platoons exploit the cellular wireless vehicle-to-everything (C-V2X) communication technology to disseminate the cooperative awareness messages (CAMs) to their followers while ensuring timely delivery of safety-critical messages to the Road-Side Unit (RSU). Due to the challenges of dynamic channel conditions, centralized resource management schemes that require global information are inefficient and lead to large signaling overheads. Hence, we exploit a distributed resource allocation framework based on multi-agent reinforcement learning (MARL), where each platoon leader (PL) acts as an agent and interacts with the environment to learn its optimal policy. Existing MARL algorithms consider a holistic reward function for the group's collective success, which often ends up with unsatisfactory results and cannot guarantee an optimal policy for each agent. Consequently, motivated by the existing literature in RL, we propose a novel MARL framework that trains two critics with the following goals: A global critic which estimates the global expected reward and motivates the agents toward a cooperating behavior and an exclusive local critic for each agent that estimates the local individual reward. Furthermore, based on the tasks each agent has to accomplish, the individual reward of each agent is decomposed into multiple sub-reward functions where task-wise value functions are learned separately. Numerical results indicate our proposed algorithm's effectiveness compared with the conventional RL methods applied in this area.",
        "published": "2021-05-10T08:39:56Z",
        "link": "http://arxiv.org/abs/2105.04196v1",
        "categories": [
            "eess.SP",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Practical sufficient conditions for convergence of distributed   optimisation algorithms over communication networks with interference",
        "authors": [
            "Adrian Redder",
            "Arunselvan Ramaswamy",
            "Holger Karl"
        ],
        "summary": "Information exchange over networks can be affected by various forms of delay. This causes challenges for using the network by a multi-agent system to solve a distributed optimisation problem. Distributed optimisation schemes, however, typically do not assume network models that are representative for real-world communication networks, since communication links are most of the time abstracted as lossless. Our objective is therefore to formulate a representative network model and provide practically verifiable network conditions that ensure convergence of distributed algorithms in the presence of interference and possibly unbounded delay. Our network is modelled by a sequence of directed-graphs, where to each network link we associate a process for the instantaneous signal-to-interference-plus-noise ratio. We then formulate practical conditions that can be verified locally and show that the age of information (AoI) associated with data communicated over the network is in $\\mathcal{O}(\\sqrt{n})$. Under these conditions we show that a penalty-based gradient descent algorithm can be used to solve a rich class of stochastic, constrained, distributed optimisation problems. The strength of our result lies in the bridge between practical verifiable network conditions and an abstract optimisation theory. We illustrate numerically that our algorithm converges in an extreme scenario where the average AoI diverges.",
        "published": "2021-05-10T09:45:00Z",
        "link": "http://arxiv.org/abs/2105.04230v1",
        "categories": [
            "math.OC",
            "cs.MA",
            "cs.NI"
        ]
    },
    {
        "title": "On the Role of Incentives in Evolutionary Approaches to Organizational   Design",
        "authors": [
            "Stephan Leitner"
        ],
        "summary": "This paper introduces a model of a stylized organization that is comprised of several departments that autonomously allocate tasks. To do so, the departments either take short-sighted decisions that immediately maximize their utility or take long-sighted decisions that aim at minimizing the interdependencies between tasks. The organization guides the departments' behavior by either an individualistic, a balanced, or an altruistic linear incentive scheme. Even if tasks are perfectly decomposable, altruistic incentive schemes are preferred over individualistic incentive schemes since they substantially increase the organization's performance. Interestingly, if altruistic incentive schemes are effective, short-sighted decisions appear favorable since they do not only increase performance in the short run but also result in significantly higher performances in the long run.",
        "published": "2021-05-10T17:06:50Z",
        "link": "http://arxiv.org/abs/2105.04514v2",
        "categories": [
            "econ.GN",
            "cs.MA",
            "nlin.AO",
            "q-fin.EC",
            "90B70, 91B69, 90B50"
        ]
    },
    {
        "title": "A Social Distancing-Based Facility Location Approach for Combating   COVID-19",
        "authors": [
            "Suman Banerjee",
            "Bithika Pal",
            "Maheswar Singhamahapatra"
        ],
        "summary": "In this paper, we introduce and study the problem of facility location along with the notion of \\emph{`social distancing'}. The input to the problem is the road network of a city where the nodes are the residential zones, edges are the road segments connecting the zones along with their respective distance. We also have the information about the population at each zone, different types of facilities to be opened and in which number, and their respective demands in each zone. The goal of the problem is to locate the facilities such that the people can be served and at the same time the total social distancing is maximized. We formally call this problem as the \\textsc{Social Distancing-Based Facility Location Problem}. We mathematically quantify social distancing for a given allocation of facilities and proposed an optimization model. As the problem is \\textsf{NP-Hard}, we propose a simulation-based and heuristic approach for solving this problem. A detailed analysis of both methods has been done. We perform an extensive set of experiments with synthetic datasets. From the results, we observe that the proposed heuristic approach leads to a better allocation compared to the simulation-based approach.",
        "published": "2021-05-10T18:27:07Z",
        "link": "http://arxiv.org/abs/2105.04598v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "The Influence of Memory in Multi-Agent Consensus",
        "authors": [
            "David Kohan Marzagão",
            "Luciana Basualdo Bonatto",
            "Tiago Madeira",
            "Marcelo Matheus Gauy",
            "Peter McBurney"
        ],
        "summary": "Multi-agent consensus problems can often be seen as a sequence of autonomous and independent local choices between a finite set of decision options, with each local choice undertaken simultaneously, and with a shared goal of achieving a global consensus state. Being able to estimate probabilities for the different outcomes and to predict how long it takes for a consensus to be formed, if ever, are core issues for such protocols.   Little attention has been given to protocols in which agents can remember past or outdated states. In this paper, we propose a framework to study what we call \\emph{memory consensus protocol}. We show that the employment of memory allows such processes to always converge, as well as, in some scenarios, such as cycles, converge faster. We provide a theoretical analysis of the probability of each option eventually winning such processes based on the initial opinions expressed by agents. Further, we perform experiments to investigate network topologies in which agents benefit from memory on the expected time needed for consensus.",
        "published": "2021-05-10T20:59:35Z",
        "link": "http://arxiv.org/abs/2105.04666v1",
        "categories": [
            "cs.AI",
            "cs.MA",
            "I.2.11; G.3"
        ]
    },
    {
        "title": "Lightweight Distributed Gaussian Process Regression for Online Machine   Learning",
        "authors": [
            "Zhenyuan Yuan",
            "Minghui Zhu"
        ],
        "summary": "In this paper, we study the problem where a group of agents aim to collaboratively learn a common static latent function through streaming data. We propose a lightweight distributed Gaussian process regression (GPR) algorithm that is cognizant of agents' limited capabilities in communication, computation and memory. Each agent independently runs agent-based GPR using local streaming data to predict test points of interest; then the agents collaboratively execute distributed GPR to obtain global predictions over a common sparse set of test points; finally, each agent fuses results from distributed GPR with agent-based GPR to refine its predictions. By quantifying the transient and steady-state performances in predictive variance and error, we show that limited inter-agent communication improves learning performances in the sense of Pareto. Monte Carlo simulation is conducted to evaluate the developed algorithm.",
        "published": "2021-05-11T01:13:22Z",
        "link": "http://arxiv.org/abs/2105.04738v5",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Autonomous Situational Awareness for Robotic Swarms in High-Risk   Environments",
        "authors": [
            "Vincent W. Hill",
            "Ryan W. Thomas",
            "Jordan D. Larson"
        ],
        "summary": "This paper describes a technique for the autonomous mission planning of robotic swarms in high risk environments where agent disablement is likely. Given a swarm operating in a known area, a central command system generates measurements from the swarm. If those measurements indicate changes to the mission situation such as target movement or agent loss, the swarm planning is updated to reflect the new situation and guidance updates are broadcast to the swarm. The primary algorithms featured in this work are A* pathfinding and the Generalized Labeled Multi-Bernoulli multi-object tracking method.",
        "published": "2021-05-11T03:03:52Z",
        "link": "http://arxiv.org/abs/2105.04764v1",
        "categories": [
            "cs.RO",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Improving the Transient Times for Distributed Stochastic Gradient   Methods",
        "authors": [
            "Kun Huang",
            "Shi Pu"
        ],
        "summary": "We consider the distributed optimization problem where $n$ agents each possessing a local cost function, collaboratively minimize the average of the $n$ cost functions over a connected network. Assuming stochastic gradient information is available, we study a distributed stochastic gradient algorithm, called exact diffusion with adaptive stepsizes (EDAS) adapted from the Exact Diffusion method and NIDS and perform a non-asymptotic convergence analysis. We not only show that EDAS asymptotically achieves the same network independent convergence rate as centralized stochastic gradient descent (SGD) for minimizing strongly convex and smooth objective functions, but also characterize the transient time needed for the algorithm to approach the asymptotic convergence rate, which behaves as $K_T=\\mathcal{O}\\left(\\frac{n}{1-\\lambda_2}\\right)$, where $1-\\lambda_2$ stands for the spectral gap of the mixing matrix. To the best of our knowledge, EDAS achieves the shortest transient time when the average of the $n$ cost functions is strongly convex and each cost function is smooth. Numerical simulations further corroborate and strengthen the obtained theoretical results.",
        "published": "2021-05-11T08:09:31Z",
        "link": "http://arxiv.org/abs/2105.04851v1",
        "categories": [
            "math.OC",
            "cs.DC",
            "cs.LG",
            "cs.MA",
            "cs.SI"
        ]
    },
    {
        "title": "Hierarchical RNNs-Based Transformers MADDPG for Mixed   Cooperative-Competitive Environments",
        "authors": [
            "Xiaolong Wei",
            "LiFang Yang",
            "Xianglin Huang",
            "Gang Cao",
            "Tao Zhulin",
            "Zhengyang Du",
            "Jing An"
        ],
        "summary": "At present, attention mechanism has been widely applied to the fields of deep learning models. Structural models that based on attention mechanism can not only record the relationships between features position, but also can measure the importance of different features based on their weights. By establishing dynamically weighted parameters for choosing relevant and irrelevant features, the key information can be strengthened, and the irrelevant information can be weakened. Therefore, the efficiency of deep learning algorithms can be significantly elevated and improved. Although transformers have been performed very well in many fields including reinforcement learning, there are still many problems and applications can be solved and made with transformers within this area. MARL (known as Multi-Agent Reinforcement Learning) can be recognized as a set of independent agents trying to adapt and learn through their way to reach the goal. In order to emphasize the relationship between each MDP decision in a certain time period, we applied the hierarchical coding method and validated the effectiveness of this method. This paper proposed a hierarchical transformers MADDPG based on RNN which we call it Hierarchical RNNs-Based Transformers MADDPG(HRTMADDPG). It consists of a lower level encoder based on RNNs that encodes multiple step sizes in each time sequence, and it also consists of an upper sequence level encoder based on transformer for learning the correlations between multiple sequences so that we can capture the causal relationship between sub-time sequences and make HRTMADDPG more efficient.",
        "published": "2021-05-11T09:22:52Z",
        "link": "http://arxiv.org/abs/2105.04888v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "A Reinforcement Learning Environment for Multi-Service UAV-enabled   Wireless Systems",
        "authors": [
            "Damiano Brunori",
            "Stefania Colonnese",
            "Francesca Cuomo",
            "Luca Iocchi"
        ],
        "summary": "We design a multi-purpose environment for autonomous UAVs offering different communication services in a variety of application contexts (e.g., wireless mobile connectivity services, edge computing, data gathering). We develop the environment, based on OpenAI Gym framework, in order to simulate different characteristics of real operational environments and we adopt the Reinforcement Learning to generate policies that maximize some desired performance.The quality of the resulting policies are compared with a simple baseline to evaluate the system and derive guidelines to adopt this technique in different use cases. The main contribution of this paper is a flexible and extensible OpenAI Gym environment, which allows to generate, evaluate, and compare policies for autonomous multi-drone systems in multi-service applications. This environment allows for comparative evaluation and benchmarking of different approaches in a variety of application contexts.",
        "published": "2021-05-11T14:45:24Z",
        "link": "http://arxiv.org/abs/2105.05094v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Visual Perspective Taking for Opponent Behavior Modeling",
        "authors": [
            "Boyuan Chen",
            "Yuhang Hu",
            "Robert Kwiatkowski",
            "Shuran Song",
            "Hod Lipson"
        ],
        "summary": "In order to engage in complex social interaction, humans learn at a young age to infer what others see and cannot see from a different point-of-view, and learn to predict others' plans and behaviors. These abilities have been mostly lacking in robots, sometimes making them appear awkward and socially inept. Here we propose an end-to-end long-term visual prediction framework for robots to begin to acquire both these critical cognitive skills, known as Visual Perspective Taking (VPT) and Theory of Behavior (TOB). We demonstrate our approach in the context of visual hide-and-seek - a game that represents a cognitive milestone in human development. Unlike traditional visual predictive model that generates new frames from immediate past frames, our agent can directly predict to multiple future timestamps (25s), extrapolating by 175% beyond the training horizon. We suggest that visual behavior modeling and perspective taking skills will play a critical role in the ability of physical robots to fully integrate into real-world multi-agent activities. Our website is at http://www.cs.columbia.edu/~bchen/vpttob/.",
        "published": "2021-05-11T16:02:32Z",
        "link": "http://arxiv.org/abs/2105.05145v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.CV",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Mandating Code Disclosure is Unnecessary -- Strict Model Verification   Does Not Require Accessing Original Computer Code",
        "authors": [
            "Sasanka Sekhar Chanda"
        ],
        "summary": "Mandating public availability of computer code underlying computational simulation modeling research ends up doing a disservice to the cause of model verification when inconsistencies between the specifications in the publication text and specifications in the computer code go unchallenged. Conversely, a model is verified when an independent researcher undertakes the set of mental processing tasks necessary to convert natural language specifications in a publication text into computer code instructions that produce numerical or graphical outputs identical to the outputs found in the original publication. The effort towards obtaining convergence with the numerical or graphical outputs directs intensive consideration of the publication text. The original computer code has little role to play in determining the verification status - verified/ failed verification. An insight is obtained that skillful deployment of human intelligence is feasible when effort-directing feedback processes are in place to appropriately go around the human frailty of giving up in the absence of actionable feedback. This principle can be put to use to develop better organizational configurations in business, government and society.",
        "published": "2021-05-11T16:25:19Z",
        "link": "http://arxiv.org/abs/2105.05170v1",
        "categories": [
            "cs.SE",
            "cs.MA"
        ]
    },
    {
        "title": "Identity Concealment Games: How I Learned to Stop Revealing and Love the   Coincidences",
        "authors": [
            "Mustafa O. Karabag",
            "Melkior Ornik",
            "Ufuk Topcu"
        ],
        "summary": "In an adversarial environment, a hostile player performing a task may behave like a non-hostile one in order not to reveal its identity to an opponent. To model such a scenario, we define identity concealment games: zero-sum stochastic reachability games with a zero-sum objective of identity concealment. To measure the identity concealment of the player, we introduce the notion of an average player. The average player's policy represents the expected behavior of a non-hostile player. We show that there exists an equilibrium policy pair for every identity concealment game and give the optimality equations to synthesize an equilibrium policy pair. If the player's opponent follows a non-equilibrium policy, the player can hide its identity better. For this reason, we study how the hostile player may learn the opponent's policy. Since learning via exploration policies would quickly reveal the hostile player's identity to the opponent, we consider the problem of learning a near-optimal policy for the hostile player using the game runs collected under the average player's policy. Consequently, we propose an algorithm that provably learns a near-optimal policy and give an upper bound on the number of sample runs to be collected.",
        "published": "2021-05-12T00:41:58Z",
        "link": "http://arxiv.org/abs/2105.05377v2",
        "categories": [
            "cs.GT",
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "Bregman algorithms for mixed-strategy generalized Nash equilibrium   seeking in a class of mixed-integer games",
        "authors": [
            "Wicak Ananduta",
            "Sergio Grammatico"
        ],
        "summary": "We consider the problem of computing a mixed-strategy generalized Nash equilibrium (MS-GNE) for a class of games where each agent has both continuous and integer decision variables. Specifically, we propose a novel Bregman forward-reflected-backward splitting and design distributed algorithms that exploit the problem structure. Technically, we prove convergence to a variational MS-GNE under mere monotonicity and Lipschitz continuity assumptions, which are typical of continuous GNE problems. Finally, we show the performance of our algorithms via numerical experiments.",
        "published": "2021-05-12T14:23:44Z",
        "link": "http://arxiv.org/abs/2105.05687v3",
        "categories": [
            "math.OC",
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "47N10, 65K10"
        ]
    },
    {
        "title": "On (Coalitional) Exchange-Stable Matching",
        "authors": [
            "Jiehua Chen",
            "Adrian Chmurovic",
            "Fabian Jogl",
            "Manuel Sorge"
        ],
        "summary": "We study (coalitional) exchange stability, which Alcalde [Economic Design, 1995] introduced as an alternative solution concept for matching markets involving property rights, such as assigning persons to two-bed rooms. Here, a matching of a given Stable Marriage or Stable Roommates instance is called coalitional exchange-stable if it does not admit any exchange-blocking coalition, that is, a subset S of agents in which everyone prefers the partner of some other agent in S. The matching is exchange-stable if it does not admit any exchange-blocking pair, that is, an exchange-blocking coalition of size two.   We investigate the computational and parameterized complexity of the Coalitional Exchange-Stable Marriage (resp. Coalitional Exchange Roommates) problem, which is to decide whether a Stable Marriage (resp. Stable Roommates) instance admits a coalitional exchange-stable matching. Our findings resolve an open question and confirm the conjecture of Cechl\\'arov\\'a and Manlove [Discrete Applied Mathematics, 2005] that Coalitional Exchange-Stable Marriage is NP-hard even for complete preferences without ties. We also study bounded-length preference lists and a local-search variant of deciding whether a given matching can reach an exchange-stable one after at most k swaps, where a swap is defined as exchanging the partners of the two agents in an exchange-blocking pair.",
        "published": "2021-05-12T15:17:35Z",
        "link": "http://arxiv.org/abs/2105.05725v2",
        "categories": [
            "cs.GT",
            "cs.DS",
            "cs.MA"
        ]
    },
    {
        "title": "SIDE: State Inference for Partially Observable Cooperative Multi-Agent   Reinforcement Learning",
        "authors": [
            "Zhiwei Xu",
            "Yunpeng Bai",
            "Dapeng Li",
            "Bin Zhang",
            "Guoliang Fan"
        ],
        "summary": "As one of the solutions to the decentralized partially observable Markov decision process (Dec-POMDP) problems, the value decomposition method has achieved significant results recently. However, most value decomposition methods require the fully observable state of the environment during training, but this is not feasible in some scenarios where only incomplete and noisy observations can be obtained. Therefore, we propose a novel value decomposition framework, named State Inference for value DEcomposition (SIDE), which eliminates the need to know the global state by simultaneously seeking solutions to the two problems of optimal control and state inference. SIDE can be extended to any value decomposition method to tackle partially observable problems. By comparing with the performance of different algorithms in StarCraft II micromanagement tasks, we verified that though without accessible states, SIDE can infer the current state that contributes to the reinforcement learning process based on past local observations and even achieve superior results to many baselines in some complex scenarios.",
        "published": "2021-05-13T12:26:02Z",
        "link": "http://arxiv.org/abs/2105.06228v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Emergent Prosociality in Multi-Agent Games Through Gifting",
        "authors": [
            "Woodrow Z. Wang",
            "Mark Beliaev",
            "Erdem Bıyık",
            "Daniel A. Lazar",
            "Ramtin Pedarsani",
            "Dorsa Sadigh"
        ],
        "summary": "Coordination is often critical to forming prosocial behaviors -- behaviors that increase the overall sum of rewards received by all agents in a multi-agent game. However, state of the art reinforcement learning algorithms often suffer from converging to socially less desirable equilibria when multiple equilibria exist. Previous works address this challenge with explicit reward shaping, which requires the strong assumption that agents can be forced to be prosocial. We propose using a less restrictive peer-rewarding mechanism, gifting, that guides the agents toward more socially desirable equilibria while allowing agents to remain selfish and decentralized. Gifting allows each agent to give some of their reward to other agents. We employ a theoretical framework that captures the benefit of gifting in converging to the prosocial equilibrium by characterizing the equilibria's basins of attraction in a dynamical system. With gifting, we demonstrate increased convergence of high risk, general-sum coordination games to the prosocial equilibrium both via numerical analysis and experiments.",
        "published": "2021-05-13T23:28:30Z",
        "link": "http://arxiv.org/abs/2105.06593v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.GT",
            "cs.LG"
        ]
    },
    {
        "title": "Modeling the interplay between epidemics and regional socio-economics",
        "authors": [
            "Jan E. Snellman",
            "Rafael A. Barrio",
            "Kimmo K. Kaski",
            "Maarit J. Käpylä"
        ],
        "summary": "In this study we present a dynamical agent-based model to investigate the interplay between the socio-economy of and SEIRS-type epidemic spreading over a geographical area, divided to smaller area districts and further to smallest area cells. The model treats the populations of cells and authorities of districts as agents, such that the former can reduce their economic activity and the latter can recommend economic activity reduction both with the overall goal to slow down the epidemic spreading. The agents make decisions with the aim of attaining as high socio-economic standings as possible relative to other agents of the same type by evaluating their standings based on the local and regional infection rates, compliance to the authorities' regulations, regional drops in economic activity, and efforts to mitigate the spread of epidemic. We find that the willingness of population to comply with authorities' recommendations has the most drastic effect on the epidemic spreading: periodic waves spread almost unimpeded in non-compliant populations, while in compliant ones the spread is minimal with chaotic spreading pattern and significantly lower infection rates. Health and economic concerns of agents turn out to have lesser roles, the former increasing their efforts and the latter decreasing them.",
        "published": "2021-05-14T08:55:18Z",
        "link": "http://arxiv.org/abs/2105.06718v2",
        "categories": [
            "physics.soc-ph",
            "cs.MA",
            "I.2.11"
        ]
    },
    {
        "title": "Translating Extensive Form Games to Open Games with Agency",
        "authors": [
            "Matteo Capucci",
            "Neil Ghani",
            "Jérémy Ledent",
            "Fredrik Nordvall Forsberg"
        ],
        "summary": "We show open games cover extensive form games with both perfect and imperfect information. Doing so forces us to address two current weaknesses in open games: the lack of a notion of player and their agency within open games, and the lack of choice operators. Using the former we construct the latter, and these choice operators subsume previous proposed operators for open games, thereby making progress towards a core, canonical and ergonomic calculus of game operators. Collectively these innovations increase the level of compositionality of open games, and demonstrate their expressiveness.",
        "published": "2021-05-14T11:15:25Z",
        "link": "http://arxiv.org/abs/2105.06763v2",
        "categories": [
            "cs.GT",
            "cs.MA",
            "math.CT"
        ]
    },
    {
        "title": "Infection in a Confined Space using an Agent-Based Model",
        "authors": [
            "J. A. Sarumi",
            "E. C. Onwubiko",
            "O. L. A. Ogunjimi"
        ],
        "summary": "This study examined a simulated confined space modelled as a hospital waiting area, where people who could have underlying conditions congregate and mix with potentially infectious individuals. It further investigated the impact of the volume of the waiting area, the number of people in the room, the placement of them as well as their weight. The simulation is an agent-based model (ABM).",
        "published": "2021-05-15T00:55:34Z",
        "link": "http://arxiv.org/abs/2105.10339v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Offline Time-Independent Multi-Agent Path Planning",
        "authors": [
            "Keisuke Okumura",
            "François Bonnet",
            "Yasumasa Tamura",
            "Xavier Défago"
        ],
        "summary": "This paper studies a novel planning problem for multiple agents that cannot share holding resources, named OTIMAPP (Offline Time-Independent Multi-Agent Path Planning). Given a graph and a set of start-goal pairs, the problem consists in assigning a path to each agent such that every agent eventually reaches their goal without blocking each other, regardless of how the agents are being scheduled at runtime. The motivation stems from the nature of distributed environments that agents take actions fully asynchronous and have no knowledge about those exact timings of other actors. We present solution conditions, computational complexity, solvers, and robotic applications.",
        "published": "2021-05-15T04:05:01Z",
        "link": "http://arxiv.org/abs/2105.07132v3",
        "categories": [
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Delay Robustness of Consensus Algorithms: Beyond The Uniform   Connectivity (Extended Version)",
        "authors": [
            "Anton V. Proskurnikov",
            "Giuseppe Carlo Calafiore"
        ],
        "summary": "Consensus of autonomous agents is a benchmark problem in multi-agent control. In this paper, we consider continuous-time averaging consensus policies (or Laplacian flows) and their discrete-time counterparts over time-varying graphs in presence of unknown but bounded communication delays. It is known that consensus is established (no matter how large the delays are) if the graph is periodically, or uniformly quasi-strongly connected (UQSC). The UQSC condition is often believed to be the weakest sufficient condition under which consensus can be proved. We show that the UQSC condition can actually be substantially relaxed and replaced by a condition that we call aperiodic quasi-strong connectivity (AQSC), which, in some sense, proves to be very close to the necessary condition of integral connectivity. Furthermore, in some special situations such as undirected or type-symmetric graph, we find a necessary and sufficient condition for consensus in presence of bounded delay; the relevant results have been previously proved only in the undelayed case. The consensus criteria established in this paper generalize a number of results known in the literature.",
        "published": "2021-05-15T09:34:49Z",
        "link": "http://arxiv.org/abs/2105.07183v1",
        "categories": [
            "math.OC",
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "math.DS",
            "nlin.AO"
        ]
    },
    {
        "title": "Distributed Resilient Submodular Action Selection in Adversarial   Environments",
        "authors": [
            "Jun Liu",
            "Lifeng Zhou",
            "Pratap Tokekar",
            "Ryan K. Williams"
        ],
        "summary": "In this letter, we consider a distributed submodular maximization problem for multi-robot systems when attacked by adversaries. One of the major challenges for multi-robot systems is to increase resilience against failures or attacks. This is particularly important for distributed systems under attack as there is no central point of command that can detect, mitigate, and recover from attacks. Instead, a distributed multi-robot system must coordinate effectively to overcome adversarial attacks. In this work, our distributed submodular action selection problem models a broad set of scenarios where each robot in a multi-robot system has multiple action selections that may fulfill a global objective, such as exploration or target tracking. To increase resilience in this context, we propose a fully distributed algorithm to guide each robot's action selection when the system is attacked. The proposed algorithm guarantees performance in a worst-case scenario where up to a portion of the robots malfunction due to attacks. Importantly, the proposed algorithm is also consistent, as it is shown to converge to the same solution as a centralized method. Finally, a distributed resilient multi-robot exploration problem is presented to confirm the performance of the proposed algorithm.",
        "published": "2021-05-15T22:48:34Z",
        "link": "http://arxiv.org/abs/2105.07305v1",
        "categories": [
            "cs.RO",
            "cs.DS",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Robust optimal policies for team Markov games",
        "authors": [
            "Feng Huang",
            "Ming Cao",
            "Long Wang"
        ],
        "summary": "In stochastic dynamic environments, team Markov games have emerged as a versatile paradigm for studying sequential decision-making problems of fully cooperative multi-agent systems. However, the optimality of the derived policies is usually sensitive to model parameters, which are typically unknown and required to be estimated from noisy data in practice. To mitigate the sensitivity of optimal policies to these uncertain parameters, we propose a robust model of team Markov games in this paper, where agents utilize robust optimization approaches to update strategies. This model extends team Markov games to the scenario of incomplete information and meanwhile provides an alternative solution concept of robust team optimality. To seek such a solution, we develop a robust iterative learning algorithm of team policies and prove its convergence. This algorithm, compared with robust dynamic programming, not only possesses a faster convergence rate, but also allows for using approximation calculations to alleviate the curse of dimensionality. Moreover, some numerical simulations are presented to demonstrate the effectiveness of the algorithm by generalizing the game model of sequential social dilemmas to uncertain scenarios.",
        "published": "2021-05-16T10:42:09Z",
        "link": "http://arxiv.org/abs/2105.07405v2",
        "categories": [
            "math.OC",
            "cs.AI",
            "cs.GT",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "How Can Robots Trust Each Other For Better Cooperation? A Relative Needs   Entropy Based Robot-Robot Trust Assessment Model",
        "authors": [
            "Qin Yang",
            "Ramviyas Parasuraman"
        ],
        "summary": "Cooperation in multi-agent and multi-robot systems can help agents build various formations, shapes, and patterns presenting corresponding functions and purposes adapting to different situations. Relationships between agents such as their spatial proximity and functional similarities could play a crucial role in cooperation between agents. Trust level between agents is an essential factor in evaluating their relationships' reliability and stability, much as people do. This paper proposes a new model called Relative Needs Entropy (RNE) to assess trust between robotic agents. RNE measures the distance of needs distribution between individual agents or groups of agents. To exemplify its utility, we implement and demonstrate our trust model through experiments simulating a heterogeneous multi-robot grouping task in a persistent urban search and rescue mission consisting of tasks at two levels of difficulty. The results suggest that RNE trust-Based grouping of robots can achieve better performance and adaptability for diverse task execution compared to the state-of-the-art energy-based or distance-based grouping models.",
        "published": "2021-05-16T14:33:11Z",
        "link": "http://arxiv.org/abs/2105.07443v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.RO"
        ]
    },
    {
        "title": "Analysis of Bitcoin Vulnerability to Bribery Attacks Launched Through   Large Transactions",
        "authors": [
            "Ghader Ebrahimpour",
            "Mohammad Sayad Haghighi"
        ],
        "summary": "Bitcoin uses blockchain technology to maintain transactions order and provides probabilistic guarantee to prevent double-spending, assuming that an attacker's computational power does not exceed %50 of the network power. In this paper, we design a novel bribery attack and show that this guarantee can be hugely undermined. Miners are assumed to be rational in this setup and they are given incentives that are dynamically calculated. In this attack, the adversary misuses the Bitcoin protocol to bribe miners and maximize their gained advantage. We will reformulate the bribery attack to propose a general mathematical foundation upon which we build multiple strategies. We show that, unlike Whale Attack, these strategies are practical. If the rationality assumption holds, this shows how vulnerable blockchain-based systems like Bitcoin are. We suggest a soft fork on Bitcoin to fix this issue at the end.",
        "published": "2021-05-16T19:35:16Z",
        "link": "http://arxiv.org/abs/2105.07501v1",
        "categories": [
            "cs.CR",
            "cs.MA",
            "G.3; H.2; H.4; E.2; E.3; F.2"
        ]
    },
    {
        "title": "A Formal Framework for Reasoning about Agents' Independence in   Self-organizing Multi-agent Systems",
        "authors": [
            "Jieting Luo",
            "Beishui Liao",
            "John-Jules Meyer"
        ],
        "summary": "Self-organization is a process where a stable pattern is formed by the cooperative behavior between parts of an initially disordered system without external control or influence. It has been introduced to multi-agent systems as an internal control process or mechanism to solve difficult problems spontaneously. However, because a self-organizing multi-agent system has autonomous agents and local interactions between them, it is difficult to predict the behavior of the system from the behavior of the local agents we design. This paper proposes a logic-based framework of self-organizing multi-agent systems, where agents interact with each other by following their prescribed local rules. The dependence relation between coalitions of agents regarding their contributions to the global behavior of the system is reasoned about from the structural and semantic perspectives. We show that the computational complexity of verifying such a self-organizing multi-agent system is in exponential time. We then combine our framework with graph theory to decompose a system into different coalitions located in different layers, which allows us to verify agents' full contributions more efficiently. The resulting information about agents' full contributions allows us to understand the complex link between local agent behavior and system level behavior in a self-organizing multi-agent system. Finally, we show how we can use our framework to model a constraint satisfaction problem.",
        "published": "2021-05-17T07:32:43Z",
        "link": "http://arxiv.org/abs/2105.07648v3",
        "categories": [
            "cs.AI",
            "cs.LO",
            "cs.MA"
        ]
    },
    {
        "title": "Mean Field Games Flock! The Reinforcement Learning Way",
        "authors": [
            "Sarah Perrin",
            "Mathieu Laurière",
            "Julien Pérolat",
            "Matthieu Geist",
            "Romuald Élie",
            "Olivier Pietquin"
        ],
        "summary": "We present a method enabling a large number of agents to learn how to flock, which is a natural behavior observed in large populations of animals. This problem has drawn a lot of interest but requires many structural assumptions and is tractable only in small dimensions. We phrase this problem as a Mean Field Game (MFG), where each individual chooses its acceleration depending on the population behavior. Combining Deep Reinforcement Learning (RL) and Normalizing Flows (NF), we obtain a tractable solution requiring only very weak assumptions. Our algorithm finds a Nash Equilibrium and the agents adapt their velocity to match the neighboring flock's average one. We use Fictitious Play and alternate: (1) computing an approximate best response with Deep RL, and (2) estimating the next population distribution with NF. We show numerically that our algorithm learn multi-group or high-dimensional flocking with obstacles.",
        "published": "2021-05-17T15:17:36Z",
        "link": "http://arxiv.org/abs/2105.07933v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Using Distributed Reinforcement Learning for Resource Orchestration in a   Network Slicing Scenario",
        "authors": [
            "Federico Mason",
            "Gianfranco Nencioni",
            "Andrea Zanella"
        ],
        "summary": "The Network Slicing (NS) paradigm enables the partition of physical and virtual resources among multiple logical networks, possibly managed by different tenants. In such a scenario, network resources need to be dynamically allocated according to the slices' requirements. In this paper, we attack the above problem by exploiting a Deep Reinforcement Learning approach. Our framework is based on a distributed architecture, where multiple agents cooperate towards a common goal. The agents' training is carried out following the Advantage Actor Critic algorithm, which allows to handle continuous action spaces. By means of extensive simulations, we show that our approach yields better performance than both a static allocation of system resources and an efficient empirical strategy. At the same time, the proposed system ensures high adaptability to different scenarios without the need for additional training.",
        "published": "2021-05-17T15:34:00Z",
        "link": "http://arxiv.org/abs/2105.07946v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "To be a fast adaptive learner: using game history to defeat opponents",
        "authors": [
            "Guangzhao Cheng",
            "Siliang Tang"
        ],
        "summary": "In many real-world games, such as traders repeatedly bargaining with customers, it is very hard for a single AI trader to make good deals with various customers in a few turns, since customers may adopt different strategies even the strategies they choose are quite simple. In this paper, we model this problem as fast adaptive learning in the finitely repeated games. We believe that past game history plays a vital role in such a learning procedure, and therefore we propose a novel framework (named, F3) to fuse the past and current game history with an Opponent Action Estimator (OAE) module that uses past game history to estimate the opponent's future behaviors. The experiments show that the agent trained by F3 can quickly defeat opponents who adopt unknown new strategies. The F3 trained agent obtains more rewards in a fixed number of turns than the agents that are trained by deep reinforcement learning. Further studies show that the OAE module in F3 contains meta-knowledge that can even be transferred across different games.",
        "published": "2021-05-17T18:40:08Z",
        "link": "http://arxiv.org/abs/2105.08110v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "The Confluence of Networks, Games and Learning",
        "authors": [
            "Tao Li",
            "Guanze Peng",
            "Quanyan Zhu",
            "Tamer Basar"
        ],
        "summary": "Recent years have witnessed significant advances in technologies and services in modern network applications, including smart grid management, wireless communication, cybersecurity as well as multi-agent autonomous systems. Considering the heterogeneous nature of networked entities, emerging network applications call for game-theoretic models and learning-based approaches in order to create distributed network intelligence that responds to uncertainties and disruptions in a dynamic or an adversarial environment. This paper articulates the confluence of networks, games and learning, which establishes a theoretical underpinning for understanding multi-agent decision-making over networks. We provide an selective overview of game-theoretic learning algorithms within the framework of stochastic approximation theory, and associated applications in some representative contexts of modern network systems, such as the next generation wireless communication networks, the smart grid and distributed machine learning. In addition to existing research works on game-theoretic learning over networks, we highlight several new angles and research endeavors on learning in games that are related to recent developments in artificial intelligence. Some of the new angles extrapolate from our own research interests. The overall objective of the paper is to provide the reader a clear picture of the strengths and challenges of adopting game-theoretic learning methods within the context of network systems, and further to identify fruitful future research directions on both theoretical and applied studies.",
        "published": "2021-05-17T20:54:07Z",
        "link": "http://arxiv.org/abs/2105.08158v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Learning to Win, Lose and Cooperate through Reward Signal Evolution",
        "authors": [
            "Rafal Muszynski",
            "Katja Hofmann",
            "Jun Wang"
        ],
        "summary": "Solving a reinforcement learning problem typically involves correctly prespecifying the reward signal from which the algorithm learns. Here, we approach the problem of reward signal design by using an evolutionary approach to perform a search on the space of all possible reward signals. We introduce a general framework for optimizing $N$ goals given $n$ reward signals. Through experiments we demonstrate that such an approach allows agents to learn high-level goals - such as winning, losing and cooperating - from scratch without prespecified reward signals in the game of Pong. Some of the solutions found by the algorithm are surprising, in the sense that they would probably not have been chosen by a person trying to hand-code a given behaviour through a specific reward signal. Furthermore, it seems that the proposed approach may also benefit from higher stability of the training performance when compared with the typical score-based reward signals.",
        "published": "2021-05-17T22:50:47Z",
        "link": "http://arxiv.org/abs/2105.08187v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Permutation Invariant Policy Optimization for Mean-Field Multi-Agent   Reinforcement Learning: A Principled Approach",
        "authors": [
            "Yan Li",
            "Lingxiao Wang",
            "Jiachen Yang",
            "Ethan Wang",
            "Zhaoran Wang",
            "Tuo Zhao",
            "Hongyuan Zha"
        ],
        "summary": "Multi-agent reinforcement learning (MARL) becomes more challenging in the presence of more agents, as the capacity of the joint state and action spaces grows exponentially in the number of agents. To address such a challenge of scale, we identify a class of cooperative MARL problems with permutation invariance, and formulate it as a mean-field Markov decision processes (MDP). To exploit the permutation invariance therein, we propose the mean-field proximal policy optimization (MF-PPO) algorithm, at the core of which is a permutation-invariant actor-critic neural architecture. We prove that MF-PPO attains the globally optimal policy at a sublinear rate of convergence. Moreover, its sample complexity is independent of the number of agents. We validate the theoretical advantages of MF-PPO with numerical experiments in the multi-agent particle environment (MPE). In particular, we show that the inductive bias introduced by the permutation-invariant neural architecture enables MF-PPO to outperform existing competitors with a smaller number of model parameters, which is the key to its generalization performance.",
        "published": "2021-05-18T04:35:41Z",
        "link": "http://arxiv.org/abs/2105.08268v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "BBE: Simulating the Microstructural Dynamics of an In-Play Betting   Exchange via Agent-Based Modelling",
        "authors": [
            "Dave Cliff"
        ],
        "summary": "I describe the rationale for, and design of, an agent-based simulation model of a contemporary online sports-betting exchange: such exchanges, closely related to the exchange mechanisms at the heart of major financial markets, have revolutionized the gambling industry in the past 20 years, but gathering sufficiently large quantities of rich and temporally high-resolution data from real exchanges - i.e., the sort of data that is needed in large quantities for Deep Learning - is often very expensive, and sometimes simply impossible; this creates a need for a plausibly realistic synthetic data generator, which is what this simulation now provides. The simulator, named the \"Bristol Betting Exchange\" (BBE), is intended as a common platform, a data-source and experimental test-bed, for researchers studying the application of AI and machine learning (ML) techniques to issues arising in betting exchanges; and, as far as I have been able to determine, BBE is the first of its kind: a free open-source agent-based simulation model consisting not only of a sports-betting exchange, but also a minimal simulation model of racetrack sporting events (e.g., horse-races or car-races) about which bets may be made, and a population of simulated bettors who each form their own private evaluation of odds and place bets on the exchange before and - crucially - during the race itself (i.e., so-called \"in-play\" betting) and whose betting opinions change second-by-second as each race event unfolds. BBE is offered as a proof-of-concept system that enables the generation of large high-resolution data-sets for automated discovery or improvement of profitable strategies for betting on sporting events via the application of AI/ML and advanced data analytics techniques. This paper offers an extensive survey of relevant literature and explains the motivation and design of BBE, and presents brief illustrative results.",
        "published": "2021-05-18T06:52:08Z",
        "link": "http://arxiv.org/abs/2105.08310v1",
        "categories": [
            "cs.MA",
            "cs.CE",
            "q-fin.CP",
            "q-fin.TR",
            "stat.ML"
        ]
    },
    {
        "title": "Kemeny Consensus Complexity",
        "authors": [
            "Zack Fitzsimmons",
            "Edith Hemaspaandra"
        ],
        "summary": "The computational study of election problems generally focuses on questions related to the winner or set of winners of an election. But social preference functions such as Kemeny rule output a full ranking of the candidates (a consensus). We study the complexity of consensus-related questions, with a particular focus on Kemeny and its qualitative version Slater. The simplest of these questions is the problem of determining whether a ranking is a consensus, and we show that this problem is coNP-complete. We also study the natural question of the complexity of manipulative actions that have a specific consensus as a goal. Though determining whether a ranking is a Kemeny consensus is hard, the optimal action for manipulators is to simply vote their desired consensus. We provide evidence that this simplicity is caused by the combination of election system (Kemeny), manipulative action (manipulation), and manipulative goal (consensus). In the process we provide the first completeness results at the second level of the polynomial hierarchy for electoral manipulation and for optimal solution recognition.",
        "published": "2021-05-18T14:15:03Z",
        "link": "http://arxiv.org/abs/2105.08540v1",
        "categories": [
            "cs.GT",
            "cs.CC",
            "cs.MA"
        ]
    },
    {
        "title": "Graph Neural Networks for Decentralized Multi-Robot Submodular Action   Selection",
        "authors": [
            "Lifeng Zhou",
            "Vishnu D. Sharma",
            "Qingbiao Li",
            "Amanda Prorok",
            "Alejandro Ribeiro",
            "Pratap Tokekar",
            "Vijay Kumar"
        ],
        "summary": "The problem of decentralized multi-robot target tracking asks for jointly selecting actions, e.g., motion primitives, for the robots to maximize target tracking performance with local communications. One major challenge for practical implementations is to make target tracking approaches scalable for large-scale problem instances. In this work, we propose a general-purpose learning architecture toward collaborative target tracking at scale, with decentralized communications. Particularly, our learning architecture leverages a graph neural network (GNN) to capture local interactions of the robots and learns decentralized decision-making for the robots. We train the learning model by imitating an expert solution and implement the resulting model for decentralized action selection involving local observations and communications only. We demonstrate the performance of our GNN-based learning approach in a scenario of active target tracking with large networks of robots. The simulation results show our approach nearly matches the tracking performance of the expert algorithm, and yet runs several orders faster with up to 100 robots. Moreover, it slightly outperforms a decentralized greedy algorithm but runs faster (especially with more than 20 robots). The results also exhibit our approach's generalization capability in previously unseen scenarios, e.g., larger environments and larger networks of robots.",
        "published": "2021-05-18T15:32:07Z",
        "link": "http://arxiv.org/abs/2105.08601v3",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Surprisingly Popular Voting Recovers Rankings, Surprisingly!",
        "authors": [
            "Hadi Hosseini",
            "Debmalya Mandal",
            "Nisarg Shah",
            "Kevin Shi"
        ],
        "summary": "The wisdom of the crowd has long become the de facto approach for eliciting information from individuals or experts in order to predict the ground truth. However, classical democratic approaches for aggregating individual \\emph{votes} only work when the opinion of the majority of the crowd is relatively accurate. A clever recent approach, \\emph{surprisingly popular voting}, elicits additional information from the individuals, namely their \\emph{prediction} of other individuals' votes, and provably recovers the ground truth even when experts are in minority. This approach works well when the goal is to pick the correct option from a small list, but when the goal is to recover a true ranking of the alternatives, a direct application of the approach requires eliciting too much information. We explore practical techniques for extending the surprisingly popular algorithm to ranked voting by partial votes and predictions and designing robust aggregation rules. We experimentally demonstrate that even a little prediction information helps surprisingly popular voting outperform classical approaches.",
        "published": "2021-05-19T20:31:23Z",
        "link": "http://arxiv.org/abs/2105.09386v1",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Human-agent coordination in a group formation game",
        "authors": [
            "Tuomas Takko",
            "Kunal Bhattacharya",
            "Daniel Monsivais",
            "Kimmo Kaski"
        ],
        "summary": "Coordination and cooperation between humans and autonomous agents in cooperative games raises interesting questions of human decision making and behaviour changes. Here we report our findings from a group formation game in a small-world network of different mixes of human and agent players, aiming to achieve connected clusters of the same colour by swapping places with neighbouring players using non-overlapping information. In the experiments the human players are incentivized by rewarding to prioritize their own cluster while the model of agents' decision making is derived from our previous experiment of purely cooperative game between human players. The experiments were performed by grouping the players in three different setups to investigate the overall effect of having cooperative autonomous agents within teams. We observe that the change in the behavior of human subjects adjusts to playing with autonomous agents by being less risk averse, while keeping the overall performance efficient by splitting the behaviour into selfish and cooperative in the two actions performed during the rounds of the game. Moreover, results from two hybrid human-agent setups suggest that the group composition affects the evolution of clusters. Our findings indicate that in purely or lesser cooperative settings, providing more control to humans could help in maximizing the overall performance of hybrid systems.",
        "published": "2021-05-20T14:11:57Z",
        "link": "http://arxiv.org/abs/2105.09764v1",
        "categories": [
            "physics.soc-ph",
            "cs.GT",
            "cs.MA",
            "I.6.0; G.3; J.4"
        ]
    },
    {
        "title": "Epistemic Planning with Attention as a Bounded Resource",
        "authors": [
            "Gaia Belardinelli",
            "Rasmus K. Rendsvig"
        ],
        "summary": "Where information grows abundant, attention becomes a scarce resource. As a result, agents must plan wisely how to allocate their attention in order to achieve epistemic efficiency. Here, we present a framework for multi-agent epistemic planning with attention, based on Dynamic Epistemic Logic (DEL, a powerful formalism for epistemic planning). We identify the framework as a fragment of standard DEL, and consider its plan existence problem. While in the general case undecidable, we show that when attention is required for learning, all instances of the problem are decidable.",
        "published": "2021-05-20T18:14:41Z",
        "link": "http://arxiv.org/abs/2105.09976v1",
        "categories": [
            "cs.AI",
            "cs.LO",
            "cs.MA",
            "econ.TH",
            "math.LO"
        ]
    },
    {
        "title": "Evaluating Strategy Exploration in Empirical Game-Theoretic Analysis",
        "authors": [
            "Yongzhao Wang",
            "Qiurui Ma",
            "Michael P. Wellman"
        ],
        "summary": "In empirical game-theoretic analysis (EGTA), game models are extended iteratively through a process of generating new strategies based on learning from experience with prior strategies. The strategy exploration problem in EGTA is how to direct this process so to construct effective models with minimal iteration. A variety of approaches have been proposed in the literature, including methods based on classic techniques and novel concepts. Comparing the performance of these alternatives can be surprisingly subtle, depending sensitively on criteria adopted and measures employed. We investigate some of the methodological considerations in evaluating strategy exploration, defining key distinctions and identifying a few general principles based on examples and experimental observations. In particular, we emphasize the fact that empirical games create a space of strategies that should be evaluated as a whole. Based on this fact, we suggest that the minimum regret constrained profile (MRCP) provides a particularly robust basis for evaluating a space of strategies, and propose a local search method for MRCP that outperforms previous approaches. However, the computation of MRCP is not always feasible especially in large games. In this scenario, we highlight consistency considerations for comparing across different approaches. Surprisingly, we find that recent works violate these considerations that are necessary for evaluation, which may result in misleading conclusions on the performance of different approaches. For proper evaluation, we propose a new evaluation scheme and demonstrate that our scheme can reveal the true learning performance of different approaches compared to previous evaluation methods.",
        "published": "2021-05-21T15:47:49Z",
        "link": "http://arxiv.org/abs/2105.10423v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Programming and Deployment of Autonomous Swarms using Multi-Agent   Reinforcement Learning",
        "authors": [
            "Jayson Boubin",
            "Codi Burley",
            "Peida Han",
            "Bowen Li",
            "Barry Porter",
            "Christopher Stewart"
        ],
        "summary": "Autonomous systems (AS) carry out complex missions by continuously observing the state of their surroundings and taking actions toward a goal. Swarms of AS working together can complete missions faster and more effectively than single AS alone. To build swarms today, developers handcraft their own software for storing, aggregating, and learning from observations. We present the Fleet Computer, a platform for developing and managing swarms. The Fleet Computer provides a programming paradigm that simplifies multi-agent reinforcement learning (MARL) -- an emerging class of algorithms that coordinate swarms of agents. Using just two programmer-provided functions Map() and Eval(), the Fleet Computer compiles and deploys swarms and continuously updates the reinforcement learning models that govern actions. To conserve compute resources, the Fleet Computer gives priority scheduling to models that contribute to effective actions, drawing a novel link between online learning and resource management. We developed swarms for unmanned aerial vehicles (UAV) in agriculture and for video analytics on urban traffic. Compared to individual AS, our swarms achieved speedup of 4.4X using 4 UAV and 62X using 130 video cameras. Compared to a competing approach for building swarms that is widely used in practice, our swarms were 3X more effective, using 3.9X less energy.",
        "published": "2021-05-21T23:22:43Z",
        "link": "http://arxiv.org/abs/2105.10605v1",
        "categories": [
            "cs.MA",
            "cs.DC"
        ]
    },
    {
        "title": "Searching Collaborative Agents for Multi-plane Localization in 3D   Ultrasound",
        "authors": [
            "Xin Yang",
            "Yuhao Huang",
            "Ruobing Huang",
            "Haoran Dou",
            "Rui Li",
            "Jikuan Qian",
            "Xiaoqiong Huang",
            "Wenlong Shi",
            "Chaoyu Chen",
            "Yuanji Zhang",
            "Haixia Wang",
            "Yi Xiong",
            "Dong Ni"
        ],
        "summary": "3D ultrasound (US) has become prevalent due to its rich spatial and diagnostic information not contained in 2D US. Moreover, 3D US can contain multiple standard planes (SPs) in one shot. Thus, automatically localizing SPs in 3D US has the potential to improve user-independence and scanning-efficiency. However, manual SP localization in 3D US is challenging because of the low image quality, huge search space and large anatomical variability. In this work, we propose a novel multi-agent reinforcement learning (MARL) framework to simultaneously localize multiple SPs in 3D US. Our contribution is four-fold. First, our proposed method is general and it can accurately localize multiple SPs in different challenging US datasets. Second, we equip the MARL system with a recurrent neural network (RNN) based collaborative module, which can strengthen the communication among agents and learn the spatial relationship among planes effectively. Third, we explore to adopt the neural architecture search (NAS) to automatically design the network architecture of both the agents and the collaborative module. Last, we believe we are the first to realize automatic SP localization in pelvic US volumes, and note that our approach can handle both normal and abnormal uterus cases. Extensively validated on two challenging datasets of the uterus and fetal brain, our proposed method achieves the average localization accuracy of 7.03 degrees/1.59mm and 9.75 degrees/1.19mm. Experimental results show that our light-weight MARL model has higher accuracy than state-of-the-art methods.",
        "published": "2021-05-22T02:48:23Z",
        "link": "http://arxiv.org/abs/2105.10626v1",
        "categories": [
            "cs.CV",
            "cs.MA",
            "eess.IV"
        ]
    },
    {
        "title": "Simultaneous Distributed Estimation and Attack Detection/Isolation in   Social Networks: Structural Observability, Kronecker-Product Network, and   Chi-Square Detector",
        "authors": [
            "Mohammadreza Doostmohammadian",
            "Themistoklis Charalambous",
            "Miadreza Shafie-khah",
            "Nader Meskin",
            "Usman A. Khan"
        ],
        "summary": "This paper considers distributed estimation of linear systems when the state observations are corrupted with Gaussian noise of unbounded support and under possible random adversarial attacks. We consider sensors equipped with single time-scale estimators and local chi-square ($\\chi^2$) detectors to simultaneously opserve the states, share information, fuse the noise/attack-corrupted data locally, and detect possible anomalies in their own observations. While this scheme is applicable to a wide variety of systems associated with full-rank (invertible) matrices, we discuss it within the context of distributed inference in social networks. The proposed technique outperforms existing results in the sense that: (i) we consider Gaussian noise with no simplifying upper-bound assumption on the support; (ii) all existing $\\chi^2$-based techniques are centralized while our proposed technique is distributed, where the sensors \\textit{locally} detect attacks, with no central coordinator, using specific probabilistic thresholds; and (iii) no local-observability assumption at a sensor is made, which makes our method feasible for large-scale social networks. Moreover, we consider a Linear Matrix Inequalities (LMI) approach to design block-diagonal gain (estimator) matrices under appropriate constraints for isolating the attacks.",
        "published": "2021-05-22T04:59:15Z",
        "link": "http://arxiv.org/abs/2105.10639v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SI",
            "cs.SY",
            "math.DS"
        ]
    },
    {
        "title": "Attention-based Reinforcement Learning for Real-Time UAV Semantic   Communication",
        "authors": [
            "Won Joon Yun",
            "Byungju Lim",
            "Soyi Jung",
            "Young-Chai Ko",
            "Jihong Park",
            "Joongheon Kim",
            "Mehdi Bennis"
        ],
        "summary": "In this article, we study the problem of air-to-ground ultra-reliable and low-latency communication (URLLC) for a moving ground user. This is done by controlling multiple unmanned aerial vehicles (UAVs) in real time while avoiding inter-UAV collisions. To this end, we propose a novel multi-agent deep reinforcement learning (MADRL) framework, coined a graph attention exchange network (GAXNet). In GAXNet, each UAV constructs an attention graph locally measuring the level of attention to its neighboring UAVs, while exchanging the attention weights with other UAVs so as to reduce the attention mismatch between them. Simulation results corroborates that GAXNet achieves up to 4.5x higher rewards during training. At execution, without incurring inter-UAV collisions, GAXNet achieves 6.5x lower latency with the target 0.0000001 error rate, compared to a state-of-the-art baseline framework.",
        "published": "2021-05-22T12:43:25Z",
        "link": "http://arxiv.org/abs/2105.10716v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "An Efficient Application of Neuroevolution for Competitive Multiagent   Learning",
        "authors": [
            "Unnikrishnan Rajendran Menon",
            "Anirudh Rajiv Menon"
        ],
        "summary": "Multiagent systems provide an ideal environment for the evaluation and analysis of real-world problems using reinforcement learning algorithms. Most traditional approaches to multiagent learning are affected by long training periods as well as high computational complexity. NEAT (NeuroEvolution of Augmenting Topologies) is a popular evolutionary strategy used to obtain the best performing neural network architecture often used to tackle optimization problems in the field of artificial intelligence. This paper utilizes the NEAT algorithm to achieve competitive multiagent learning on a modified pong game environment in an efficient manner. The competing agents abide by different rules while having similar observation space parameters. The proposed algorithm utilizes this property of the environment to define a singular neuroevolutionary procedure that obtains the optimal policy for all the agents. The compiled results indicate that the proposed implementation achieves ideal behaviour in a very short training period when compared to existing multiagent reinforcement learning models.",
        "published": "2021-05-23T10:34:48Z",
        "link": "http://arxiv.org/abs/2105.10907v1",
        "categories": [
            "cs.AI",
            "cs.MA",
            "cs.NE"
        ]
    },
    {
        "title": "Cooperative Multi-Agent Path Finding: Beyond Path Planning and Collision   Avoidance",
        "authors": [
            "Nir Greshler",
            "Ofir Gordon",
            "Oren Salzman",
            "Nahum Shimkin"
        ],
        "summary": "We introduce the Cooperative Multi-Agent Path Finding (Co-MAPF) problem, an extension to the classical MAPF problem, where cooperative behavior is incorporated. In this setting, a group of autonomous agents operate in a shared environment and have to complete cooperative tasks while avoiding collisions with the other agents in the group. This extension naturally models many real-world applications, where groups of agents are required to collaborate in order to complete a given task. To this end, we formalize the Co-MAPF problem and introduce Cooperative Conflict-Based Search (Co-CBS), a CBS-based algorithm for solving the problem optimally for a wide set of Co-MAPF problems. Co-CBS uses a cooperation-planning module integrated into CBS such that cooperation planning is decoupled from path planning. Finally, we present empirical results on several MAPF benchmarks demonstrating our algorithm's properties.",
        "published": "2021-05-23T18:25:46Z",
        "link": "http://arxiv.org/abs/2105.10993v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.RO"
        ]
    },
    {
        "title": "KnowSR: Knowledge Sharing among Homogeneous Agents in Multi-agent   Reinforcement Learning",
        "authors": [
            "Zijian Gao",
            "Kele Xu",
            "Bo Ding",
            "Huaimin Wang",
            "Yiying Li",
            "Hongda Jia"
        ],
        "summary": "Recently, deep reinforcement learning (RL) algorithms have made great progress in multi-agent domain. However, due to characteristics of RL, training for complex tasks would be resource-intensive and time-consuming. To meet this challenge, mutual learning strategy between homogeneous agents is essential, which is under-explored in previous studies, because most existing methods do not consider to use the knowledge of agent models. In this paper, we present an adaptation method of the majority of multi-agent reinforcement learning (MARL) algorithms called KnowSR which takes advantage of the differences in learning between agents. We employ the idea of knowledge distillation (KD) to share knowledge among agents to shorten the training phase. To empirically demonstrate the robustness and effectiveness of KnowSR, we performed extensive experiments on state-of-the-art MARL algorithms in collaborative and competitive scenarios. The results demonstrate that KnowSR outperforms recently reported methodologies, emphasizing the importance of the proposed knowledge sharing for MARL.",
        "published": "2021-05-25T02:19:41Z",
        "link": "http://arxiv.org/abs/2105.11611v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Towards open-ended evolutionary simulator for developing novel tumour   drug delivery systems",
        "authors": [
            "Igor Balaz",
            "Tara Petric",
            "Namid Stillman"
        ],
        "summary": "Tumours behave as moving targets that can evade chemotherapeutic treatments by rapidly acquiring resistance via various mechanisms. In Balaz et al. (2021, Biosystems; 199:104290) we initiated the development of the agent-based open-ended evolutionary simulator of novel drug delivery systems (DDS). It is an agent-based simulator where evolvable agents can change their perception of the environment and thus adapt to tumour mutations. Here we mapped the parameters of evolvable agent properties to the realistic biochemical boundaries and test their efficacy by simulating their behaviour at the cell scale using the stochastic simulator, STEPS. We show that the shape of the parameter space evolved in our simulator is comparable to those obtained by the rational design.",
        "published": "2021-05-25T08:54:17Z",
        "link": "http://arxiv.org/abs/2105.11760v1",
        "categories": [
            "cs.MA",
            "I.6.3; I.2.1"
        ]
    },
    {
        "title": "The Complexity of Subelection Isomorphism Problems",
        "authors": [
            "Piotr Faliszewski",
            "Krzysztof Sornat",
            "Stanisław Szufa"
        ],
        "summary": "We study extensions of the Election Isomorphism problem, focused on the existence of isomorphic subelections. Specifically, we propose the Subelection Isomorphism and the Maximum Common Subelection problems and study their computational complexity and approximability. Using our problems in experiments, we provide some insights into the nature of several statistical models of elections.",
        "published": "2021-05-25T13:27:50Z",
        "link": "http://arxiv.org/abs/2105.11923v2",
        "categories": [
            "cs.GT",
            "cs.MA",
            "68Q17, 68Q25, 68Q27, 68W05, 91B12 (Primary), 68W25, 68T42, 91C05\n  (Secondary)",
            "F.2.2; I.2.11"
        ]
    },
    {
        "title": "Throughput-Fairness Tradeoffs in Mobility Platforms",
        "authors": [
            "Arjun Balasingam",
            "Karthik Gopalakrishnan",
            "Radhika Mittal",
            "Venkat Arun",
            "Ahmed Saeed",
            "Mohammad Alizadeh",
            "Hamsa Balakrishnan",
            "Hari Balakrishnan"
        ],
        "summary": "This paper studies the problem of allocating tasks from different customers to vehicles in mobility platforms, which are used for applications like food and package delivery, ridesharing, and mobile sensing. A mobility platform should allocate tasks to vehicles and schedule them in order to optimize both throughput and fairness across customers. However, existing approaches to scheduling tasks in mobility platforms ignore fairness.   We introduce Mobius, a system that uses guided optimization to achieve both high throughput and fairness across customers. Mobius supports spatiotemporally diverse and dynamic customer demands. It provides a principled method to navigate inherent tradeoffs between fairness and throughput caused by shared mobility. Our evaluation demonstrates these properties, along with the versatility and scalability of Mobius, using traces gathered from ridesharing and aerial sensing applications. Our ridesharing case study shows that Mobius can schedule more than 16,000 tasks across 40 customers and 200 vehicles in an online manner.",
        "published": "2021-05-25T15:04:04Z",
        "link": "http://arxiv.org/abs/2105.11999v1",
        "categories": [
            "cs.CY",
            "cs.MA",
            "cs.NI",
            "cs.RO",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "From Motor Control to Team Play in Simulated Humanoid Football",
        "authors": [
            "Siqi Liu",
            "Guy Lever",
            "Zhe Wang",
            "Josh Merel",
            "S. M. Ali Eslami",
            "Daniel Hennes",
            "Wojciech M. Czarnecki",
            "Yuval Tassa",
            "Shayegan Omidshafiei",
            "Abbas Abdolmaleki",
            "Noah Y. Siegel",
            "Leonard Hasenclever",
            "Luke Marris",
            "Saran Tunyasuvunakool",
            "H. Francis Song",
            "Markus Wulfmeier",
            "Paul Muller",
            "Tuomas Haarnoja",
            "Brendan D. Tracey",
            "Karl Tuyls",
            "Thore Graepel",
            "Nicolas Heess"
        ],
        "summary": "Intelligent behaviour in the physical world exhibits structure at multiple spatial and temporal scales. Although movements are ultimately executed at the level of instantaneous muscle tensions or joint torques, they must be selected to serve goals defined on much longer timescales, and in terms of relations that extend far beyond the body itself, ultimately involving coordination with other agents. Recent research in artificial intelligence has shown the promise of learning-based approaches to the respective problems of complex movement, longer-term planning and multi-agent coordination. However, there is limited research aimed at their integration. We study this problem by training teams of physically simulated humanoid avatars to play football in a realistic virtual environment. We develop a method that combines imitation learning, single- and multi-agent reinforcement learning and population-based training, and makes use of transferable representations of behaviour for decision making at different levels of abstraction. In a sequence of stages, players first learn to control a fully articulated body to perform realistic, human-like movements such as running and turning; they then acquire mid-level football skills such as dribbling and shooting; finally, they develop awareness of others and play as a team, bridging the gap between low-level motor control at a timescale of milliseconds, and coordinated goal-directed behaviour as a team at the timescale of tens of seconds. We investigate the emergence of behaviours at different levels of abstraction, as well as the representations that underlie these behaviours using several analysis techniques, including statistics from real-world sports analytics. Our work constitutes a complete demonstration of integrated decision-making at multiple scales in a physically embodied multi-agent setting. See project video at https://youtu.be/KHMwq9pv7mg.",
        "published": "2021-05-25T20:17:10Z",
        "link": "http://arxiv.org/abs/2105.12196v1",
        "categories": [
            "cs.AI",
            "cs.MA",
            "cs.NE",
            "cs.RO"
        ]
    },
    {
        "title": "Self-Adaptive Swarm System (SASS)",
        "authors": [
            "Qin Yang"
        ],
        "summary": "Distributed artificial intelligence (DAI) studies artificial intelligence entities working together to reason, plan, solve problems, organize behaviors and strategies, make collective decisions and learn. This Ph.D. research proposes a principled Multi-Agent Systems (MAS) cooperation framework -- Self-Adaptive Swarm System (SASS) -- to bridge the fourth level automation gap between perception, communication, planning, execution, decision-making, and learning.",
        "published": "2021-05-25T22:46:36Z",
        "link": "http://arxiv.org/abs/2106.04679v4",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.GT",
            "cs.LG",
            "cs.RO"
        ]
    },
    {
        "title": "Explaining Ridesharing: Selection of Explanations for Increasing User   Satisfaction",
        "authors": [
            "David Zar",
            "Noam Hazon",
            "Amos Azaria"
        ],
        "summary": "Transportation services play a crucial part in the development of modern smart cities. In particular, on-demand ridesharing services, which group together passengers with similar itineraries, are already operating in several metropolitan areas. These services can be of significant social and environmental benefit, by reducing travel costs, road congestion and CO2 emissions.   Unfortunately, despite their advantages, not many people opt to use these ridesharing services. We believe that increasing the user satisfaction from the service will cause more people to utilize it, which, in turn, will improve the quality of the service, such as the waiting time, cost, travel time, and service availability. One possible way for increasing user satisfaction is by providing appropriate explanations comparing the alternative modes of transportation, such as a private taxi ride and public transportation. For example, a passenger may be more satisfied from a shared-ride if she is told that a private taxi ride would have cost her 50% more. Therefore, the problem is to develop an agent that provides explanations that will increase the user satisfaction.   We model our environment as a signaling game and show that a rational agent, which follows the perfect Bayesian equilibrium, must reveal all of the information regarding the possible alternatives to the passenger. In addition, we develop a machine learning based agent that, when given a shared-ride along with its possible alternatives, selects the explanations that are most likely to increase user satisfaction. Using feedback from humans we show that our machine learning based agent outperforms the rational agent and an agent that randomly chooses explanations, in terms of user satisfaction.",
        "published": "2021-05-26T12:03:09Z",
        "link": "http://arxiv.org/abs/2105.12500v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Neural Enhanced Belief Propagation for Cooperative Localization",
        "authors": [
            "Mingchao Liang",
            "Florian Meyer"
        ],
        "summary": "Location-aware networks will introduce innovative services and applications for modern convenience, applied ocean sciences, and public safety. In this paper, we establish a hybrid method for model-based and data-driven inference. We consider a cooperative localization (CL) scenario where the mobile agents in a wireless network aim to localize themselves by performing pairwise observations with other agents and by exchanging location information. A traditional method for distributed CL in large agent networks is belief propagation (BP) which is completely model-based and is known to suffer from providing inconsistent (overconfident) estimates. The proposed approach addresses these limitations by complementing BP with learned information provided by a graph neural network (GNN). We demonstrate numerically that our method can improve estimation accuracy and avoid overconfident beliefs, while its computational complexity remains comparable to BP. Notably, more consistent beliefs are obtained by not explicitly addressing overconfidence in the loss function used for training of the GNN.",
        "published": "2021-05-27T01:42:54Z",
        "link": "http://arxiv.org/abs/2105.12903v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "cs.RO",
            "eess.SP"
        ]
    },
    {
        "title": "A Modular and Transferable Reinforcement Learning Framework for the   Fleet Rebalancing Problem",
        "authors": [
            "Erotokritos Skordilis",
            "Yi Hou",
            "Charles Tripp",
            "Matthew Moniot",
            "Peter Graf",
            "David Biagioni"
        ],
        "summary": "Mobility on demand (MoD) systems show great promise in realizing flexible and efficient urban transportation. However, significant technical challenges arise from operational decision making associated with MoD vehicle dispatch and fleet rebalancing. For this reason, operators tend to employ simplified algorithms that have been demonstrated to work well in a particular setting. To help bridge the gap between novel and existing methods, we propose a modular framework for fleet rebalancing based on model-free reinforcement learning (RL) that can leverage an existing dispatch method to minimize system cost. In particular, by treating dispatch as part of the environment dynamics, a centralized agent can learn to intermittently direct the dispatcher to reposition free vehicles and mitigate against fleet imbalance. We formulate RL state and action spaces as distributions over a grid partitioning of the operating area, making the framework scalable and avoiding the complexities associated with multiagent RL. Numerical experiments, using real-world trip and network data, demonstrate that this approach has several distinct advantages over baseline methods including: improved system cost; high degree of adaptability to the selected dispatch method; and the ability to perform scale-invariant transfer learning between problem instances with similar vehicle and request distributions.",
        "published": "2021-05-27T16:32:28Z",
        "link": "http://arxiv.org/abs/2105.13284v1",
        "categories": [
            "eess.SY",
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Optimization in Open Networks via Dual Averaging",
        "authors": [
            "Yu-Guan Hsieh",
            "Franck Iutzeler",
            "Jérôme Malick",
            "Panayotis Mertikopoulos"
        ],
        "summary": "In networks of autonomous agents (e.g., fleets of vehicles, scattered sensors), the problem of minimizing the sum of the agents' local functions has received a lot of interest. We tackle here this distributed optimization problem in the case of open networks when agents can join and leave the network at any time. Leveraging recent online optimization techniques, we propose and analyze the convergence of a decentralized asynchronous optimization method for open networks.",
        "published": "2021-05-27T17:52:48Z",
        "link": "http://arxiv.org/abs/2105.13348v2",
        "categories": [
            "math.OC",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Towards a Very Large Scale Traffic Simulator for Multi-Agent   Reinforcement Learning Testbeds",
        "authors": [
            "Zijian Hu",
            "Chengxiang Zhuge",
            "Wei Ma"
        ],
        "summary": "Smart traffic control and management become an emerging application for Deep Reinforcement Learning (DRL) to solve traffic congestion problems in urban networks. Different traffic control and management policies can be tested on the traffic simulation. Current DRL-based studies are mainly supported by the microscopic simulation software (e.g., SUMO), while it is not suitable for city-wide control due to the computational burden and gridlock effect. To the best of our knowledge, there is a lack of studies on the large-scale traffic simulator for DRL testbeds, which could further hinder the development of DRL. In view of this, we propose a meso-macro traffic simulator for very large-scale DRL scenarios. The proposed simulator integrates mesoscopic and macroscopic traffic simulation models to improve efficiency and eliminate gridlocks. The mesoscopic link model simulates flow dynamics on roads, and the macroscopic Bathtub model depicts vehicle movement in regions. Moreover, both types of models can be hybridized to accommodate various DRL tasks. This creates portals for mixed transportation applications under different contexts. The result shows that the developed simulator only takes 46 seconds to finish a 24-hour simulation in a very large city with 2.2 million vehicles, which is much faster than SUMO. Additionally, we develop a graphic interface for users to visualize the simulation results in a web explorer. In the future, the developed meso-macro traffic simulator could serve as a new environment for very large-scale DRL problems.",
        "published": "2021-05-28T15:19:43Z",
        "link": "http://arxiv.org/abs/2105.13907v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Distributed adaptive stabilization",
        "authors": [
            "Zhiyong Sun",
            "Anders Rantzer",
            "Zhongkui Li",
            "Anders Robertsson"
        ],
        "summary": "In this paper we consider distributed adaptive stabilization for uncertain multivariable linear systems with a time-varying diagonal matrix gain. We show that uncertain multivariable linear systems are stabilizable by diagonal matrix high gains if the system matrix is an H-matrix with positive diagonal entries. Based on matrix measure and stability theory for diagonally dominant systems, we consider two classes of uncertain linear systems, and derive a threshold condition to ensure their exponential stability by a monotonically increasing diagonal gain matrix. When each individual gain function in the matrix gain is updated by state-dependent functions using only local state information, the boundedness and convergence of both system states and adaptive matrix gains are guaranteed. We apply the adaptive distributed stabilization approach to adaptive synchronization control for large-scale complex networks consisting of nonlinear node dynamics and time-varying coupling weights. A unified framework for adaptive synchronization is proposed that includes several general design approaches for adaptive coupling weights to guarantee network synchronization.",
        "published": "2021-05-28T17:28:29Z",
        "link": "http://arxiv.org/abs/2105.14004v1",
        "categories": [
            "eess.SY",
            "cs.DC",
            "cs.MA",
            "cs.SY",
            "math.OC",
            "nlin.AO"
        ]
    },
    {
        "title": "GINA: Neural Relational Inference From Independent Snapshots",
        "authors": [
            "Gerrit Großmann",
            "Julian Zimmerlin",
            "Michael Backenköhler",
            "Verena Wolf"
        ],
        "summary": "Dynamical systems in which local interactions among agents give rise to complex emerging phenomena are ubiquitous in nature and society. This work explores the problem of inferring the unknown interaction structure (represented as a graph) of such a system from measurements of its constituent agents or individual components (represented as nodes). We consider a setting where the underlying dynamical model is unknown and where different measurements (i.e., snapshots) may be independent (e.g., may stem from different experiments). We propose GINA (Graph Inference Network Architecture), a graph neural network (GNN) to simultaneously learn the latent interaction graph and, conditioned on the interaction graph, the prediction of a node's observable state based on adjacent vertices. GINA is based on the hypothesis that the ground truth interaction graph -- among all other potential graphs -- allows to predict the state of a node, given the states of its neighbors, with the highest accuracy. We test this hypothesis and demonstrate GINA's effectiveness on a wide range of interaction graphs and dynamical processes.",
        "published": "2021-05-29T15:42:33Z",
        "link": "http://arxiv.org/abs/2105.14329v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.IR",
            "cs.MA",
            "physics.soc-ph"
        ]
    },
    {
        "title": "Kolmogorov-Smirnov Test-Based Actively-Adaptive Thompson Sampling for   Non-Stationary Bandits",
        "authors": [
            "Gourab Ghatak",
            "Hardhik Mohanty",
            "Aniq Ur Rahman"
        ],
        "summary": "We consider the non-stationary multi-armed bandit (MAB) framework and propose a Kolmogorov-Smirnov (KS) test based Thompson Sampling (TS) algorithm named TS-KS, that actively detects change points and resets the TS parameters once a change is detected. In particular, for the two-armed bandit case, we derive bounds on the number of samples of the reward distribution to detect the change once it occurs. Consequently, we show that the proposed algorithm has sub-linear regret. Contrary to existing works, our algorithm is able to detect a change when the underlying reward distribution changes even though the mean reward remains the same. Finally, to test the efficacy of the proposed algorithm, we employ it in two case-studies: i) task-offloading scenario in wireless edge-computing, and ii) portfolio optimization. Our results show that the proposed TS-KS algorithm outperforms not only the static TS algorithm but also it performs better than other bandit algorithms designed for non-stationary environments. Moreover, the performance of TS-KS is at par with the state-of-the-art forecasting algorithms such as Facebook-PROPHET and ARIMA.",
        "published": "2021-05-30T17:28:41Z",
        "link": "http://arxiv.org/abs/2105.14586v2",
        "categories": [
            "stat.ML",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Emergence and algorithmic information dynamics of systems and observers",
        "authors": [
            "Felipe S. Abrahão",
            "Hector Zenil"
        ],
        "summary": "Previous work has shown that perturbation analysis in software space can produce candidate computable generative models and uncover possible causal properties from the finite description of an object or system quantifying the algorithmic contribution of each of its elements relative to the whole. One of the challenges for defining emergence is that one observer's prior knowledge may cause a phenomenon to present itself to such observer as emergent while for another as reducible. By formalising the act of observing as mutual perturbations between dynamical systems, we demonstrate that emergence of algorithmic information do depend on the observer's formal knowledge, while robust to other subjective factors, particularly: the choice of the programming language and the measurement method; errors or distortions during the information acquisition; and the informational cost of processing. This is called observer-dependent emergence (ODE). In addition, we demonstrate that the unbounded and fast increase of emergent algorithmic information implies asymptotically observer-independent emergence (AOIE). Unlike ODE, AOIE is a type of emergence for which emergent phenomena will remain considered to be emergent for every formal theory that any observer might devise. We demonstrate the existence of an evolutionary model that displays the diachronic variant of AOIE and a network model that displays the holistic variant of AOIE. Our results show that, restricted to the context of finite discrete deterministic dynamical systems, computable systems, and irreducible information content measures, AOIE is the strongest form of emergence that formal theories can attain.",
        "published": "2021-05-31T04:59:59Z",
        "link": "http://arxiv.org/abs/2105.14707v4",
        "categories": [
            "cs.IT",
            "cs.FL",
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "math.DS",
            "math.IT"
        ]
    },
    {
        "title": "Improving the Accuracy and Efficiency of Online Calibration for   Simulation-based Dynamic Traffic Assignment",
        "authors": [
            "Haizheng Zhang",
            "Ravi Seshadri",
            "A. Arun Prakash",
            "Constantinos Antoniou",
            "Francisco C. Pereira",
            "Moshe Ben-Akiva"
        ],
        "summary": "Simulation-based Dynamic Traffic Assignment models have important applications in real-time traffic management and control. The efficacy of these systems rests on the ability to generate accurate estimates and predictions of traffic states, which necessitates online calibration. A widely used solution approach for online calibration is the Extended Kalman Filter (EKF), which -- although appealing in its flexibility to incorporate any class of parameters and measurements -- poses several challenges with regard to calibration accuracy and scalability, especially in congested situations for large-scale networks. This paper addresses these issues in turn so as to improve the accuracy and efficiency of EKF-based online calibration approaches for large and congested networks. First, the concept of state augmentation is revisited to handle violations of the Markovian assumption typically implicit in online applications of the EKF. Second, a method based on graph-coloring is proposed to operationalize the partitioned finite-difference approach that enhances scalability of the gradient computations.   Several synthetic experiments and a real world case study demonstrate that application of the proposed approaches yields improvements in terms of both prediction accuracy and computational performance. The work has applications in real-world deployments of simulation-based dynamic traffic assignment systems.",
        "published": "2021-05-31T06:05:15Z",
        "link": "http://arxiv.org/abs/2105.14716v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "SHAQ: Incorporating Shapley Value Theory into Multi-Agent Q-Learning",
        "authors": [
            "Jianhong Wang",
            "Yuan Zhang",
            "Yunjie Gu",
            "Tae-Kyun Kim"
        ],
        "summary": "Value factorisation is a useful technique for multi-agent reinforcement learning (MARL) in global reward game, however its underlying mechanism is not yet fully understood. This paper studies a theoretical framework for value factorisation with interpretability via Shapley value theory. We generalise Shapley value to Markov convex game called Markov Shapley value (MSV) and apply it as a value factorisation method in global reward game, which is obtained by the equivalence between the two games. Based on the properties of MSV, we derive Shapley-Bellman optimality equation (SBOE) to evaluate the optimal MSV, which corresponds to an optimal joint deterministic policy. Furthermore, we propose Shapley-Bellman operator (SBO) that is proved to solve SBOE. With a stochastic approximation and some transformations, a new MARL algorithm called Shapley Q-learning (SHAQ) is established, the implementation of which is guided by the theoretical results of SBO and MSV. We also discuss the relationship between SHAQ and relevant value factorisation methods. In the experiments, SHAQ exhibits not only superior performances on all tasks but also the interpretability that agrees with the theoretical analysis. The implementation of this paper is on https://github.com/hsvgbkhgbv/shapley-q-learning.",
        "published": "2021-05-31T14:50:52Z",
        "link": "http://arxiv.org/abs/2105.15013v7",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Composing Networks of Automated Market Makers",
        "authors": [
            "Daniel Engel",
            "Maurice Herlihy"
        ],
        "summary": "Automated market makers (AMMs) are automata that trade electronic assets at rates set by mathematical formulas. AMMs are usually implemented by smart contracts on blockchains. In practice, AMMs are often composed: and outputs from AMMs can be directed into other compatible AMMs. This paper proposes a mathematical model for AMM composition. We define sequential and parallel composition operators for AMMs in a way that ensures that AMMs are closed under composition, in a way that works for \"higher-dimensional\" AMMs that manage more than two asset classes, and so the composition of AMMs in \"stable\" states remains stable.",
        "published": "2021-05-31T20:09:26Z",
        "link": "http://arxiv.org/abs/2106.00083v3",
        "categories": [
            "cs.DC",
            "cs.MA"
        ]
    },
    {
        "title": "Gradient play in stochastic games: stationary points, convergence, and   sample complexity",
        "authors": [
            "Runyu Zhang",
            "Zhaolin Ren",
            "Na Li"
        ],
        "summary": "We study the performance of the gradient play algorithm for stochastic games (SGs), where each agent tries to maximize its own total discounted reward by making decisions independently based on current state information which is shared between agents. Policies are directly parameterized by the probability of choosing a certain action at a given state. We show that Nash equilibria (NEs) and first-order stationary policies are equivalent in this setting, and give a local convergence rate around strict NEs. Further, for a subclass of SGs called Markov potential games (which includes the setting with identical rewards as an important special case), we design a sample-based reinforcement learning algorithm and give a non-asymptotic global convergence rate analysis for both exact gradient play and our sample-based learning algorithm. Our result shows that the number of iterations to reach an $\\epsilon$-NE scales linearly, instead of exponentially, with the number of agents. Local geometry and local stability are also considered, where we prove that strict NEs are local maxima of the total potential function and fully-mixed NEs are saddle points.",
        "published": "2021-06-01T03:03:45Z",
        "link": "http://arxiv.org/abs/2106.00198v5",
        "categories": [
            "cs.LG",
            "cs.GT",
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "Agent mental models and Bayesian rules as a tool to create opinion   dynamics models",
        "authors": [
            "Andre C. R. Martins"
        ],
        "summary": "Traditional models of opinion dynamics provide a simple approach to understanding human behavior in basic social scenarios. However, when it comes to issues such as polarization and extremism, we require a more nuanced understanding of human biases and cognitive tendencies. In this paper, we propose an approach to modeling opinion dynamics by integrating mental models and assumptions of individuals agents using Bayesian-inspired methods. By exploring the relationship between human rationality and Bayesian theory, we demonstrate the efficacy of these methods in describing how opinions evolve. Our analysis leverages the Continuous Opinions and Discrete Actions (CODA) model, applying Bayesian-inspired rules to account for key human behaviors such as confirmation bias, motivated reasoning, and our reluctance to change opinions. Through this, we obtain update rules that offer deeper insights into the dynamics of extreme opinions. Our work sheds light on the role of human biases in shaping opinion dynamics and highlights the potential of Bayesian-inspired modeling to provide more accurate predictions of real-world scenarios.   Keywords: Opinion dynamics, Bayesian methods, Cognition, CODA, Agent-based models",
        "published": "2021-06-01T03:10:31Z",
        "link": "http://arxiv.org/abs/2106.00199v2",
        "categories": [
            "physics.soc-ph",
            "cs.MA",
            "nlin.AO"
        ]
    },
    {
        "title": "Shapley Counterfactual Credits for Multi-Agent Reinforcement Learning",
        "authors": [
            "Jiahui Li",
            "Kun Kuang",
            "Baoxiang Wang",
            "Furui Liu",
            "Long Chen",
            "Fei Wu",
            "Jun Xiao"
        ],
        "summary": "Centralized Training with Decentralized Execution (CTDE) has been a popular paradigm in cooperative Multi-Agent Reinforcement Learning (MARL) settings and is widely used in many real applications. One of the major challenges in the training process is credit assignment, which aims to deduce the contributions of each agent according to the global rewards. Existing credit assignment methods focus on either decomposing the joint value function into individual value functions or measuring the impact of local observations and actions on the global value function. These approaches lack a thorough consideration of the complicated interactions among multiple agents, leading to an unsuitable assignment of credit and subsequently mediocre results on MARL. We propose Shapley Counterfactual Credit Assignment, a novel method for explicit credit assignment which accounts for the coalition of agents. Specifically, Shapley Value and its desired properties are leveraged in deep MARL to credit any combinations of agents, which grants us the capability to estimate the individual credit for each agent. Despite this capability, the main technical difficulty lies in the computational complexity of Shapley Value who grows factorially as the number of agents. We instead utilize an approximation method via Monte Carlo sampling, which reduces the sample complexity while maintaining its effectiveness. We evaluate our method on StarCraft II benchmarks across different scenarios. Our method outperforms existing cooperative MARL algorithms significantly and achieves the state-of-the-art, with especially large margins on tasks with more severe difficulties.",
        "published": "2021-06-01T07:38:34Z",
        "link": "http://arxiv.org/abs/2106.00285v4",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Large-scale, Dynamic and Distributed Coalition Formation with Spatial   and Temporal Constraints",
        "authors": [
            "Luca Capezzuto",
            "Danesh Tarapore",
            "Sarvapali D. Ramchurn"
        ],
        "summary": "The Coalition Formation with Spatial and Temporal constraints Problem (CFSTP) is a multi-agent task allocation problem in which few agents have to perform many tasks, each with its deadline and workload. To maximize the number of completed tasks, the agents need to cooperate by forming, disbanding and reforming coalitions. The original mathematical programming formulation of the CFSTP is difficult to implement, since it is lengthy and based on the problematic Big-M method. In this paper, we propose a compact and easy-to-implement formulation. Moreover, we design D-CTS, a distributed version of the state-of-the-art CFSTP algorithm. Using public London Fire Brigade records, we create a dataset with $347588$ tasks and a test framework that simulates the mobilization of firefighters in dynamic environments. In problems with up to $150$ agents and $3000$ tasks, compared to DSA-SDP, a state-of-the-art distributed algorithm, D-CTS completes $3.79\\% \\pm [42.22\\%, 1.96\\%]$ more tasks, and is one order of magnitude more efficient in terms of communication overhead and time complexity. D-CTS sets the first large-scale, dynamic and distributed CFSTP benchmark.",
        "published": "2021-06-01T10:41:49Z",
        "link": "http://arxiv.org/abs/2106.00379v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "The Impact of Network Connectivity on Collective Learning",
        "authors": [
            "Michael Crosscombe",
            "Jonathan Lawry"
        ],
        "summary": "In decentralised autonomous systems it is the interactions between individual agents which govern the collective behaviours of the system. These local-level interactions are themselves often governed by an underlying network structure. These networks are particularly important for collective learning and decision-making whereby agents must gather evidence from their environment and propagate this information to other agents in the system. Models for collective behaviours may often rely upon the assumption of total connectivity between agents to provide effective information sharing within the system, but this assumption may be ill-advised. In this paper we investigate the impact that the underlying network has on performance in the context of collective learning. Through simulations we study small-world networks with varying levels of connectivity and randomness and conclude that totally-connected networks result in higher average error when compared to networks with less connectivity. Furthermore, we show that networks of high regularity outperform networks with increasing levels of random connectivity.",
        "published": "2021-06-01T17:39:26Z",
        "link": "http://arxiv.org/abs/2106.00655v2",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Energy-aware optimization of UAV base stations placement via   decentralized multi-agent Q-learning",
        "authors": [
            "Babatunji Omoniwa",
            "Boris Galkin",
            "Ivana Dusparic"
        ],
        "summary": "Unmanned aerial vehicles serving as aerial base stations (UAV-BSs) can be deployed to provide wireless connectivity to ground devices in events of increased network demand, points-of-failure in existing infrastructure, or disasters. However, it is challenging to conserve the energy of UAVs during prolonged coverage tasks, considering their limited on-board battery capacity. Reinforcement learning-based (RL) approaches have been previously used to improve energy utilization of multiple UAVs, however, a central cloud controller is assumed to have complete knowledge of the end-devices' locations, i.e., the controller periodically scans and sends updates for UAV decision-making. This assumption is impractical in dynamic network environments with UAVs serving mobile ground devices. To address this problem, we propose a decentralized Q-learning approach, where each UAV-BS is equipped with an autonomous agent that maximizes the connectivity of mobile ground devices while improving its energy utilization. Experimental results show that the proposed design significantly outperforms the centralized approaches in jointly maximizing the number of connected ground devices and the energy utilization of the UAV-BSs.",
        "published": "2021-06-01T22:49:42Z",
        "link": "http://arxiv.org/abs/2106.00845v2",
        "categories": [
            "cs.MA",
            "cs.LG",
            "cs.NI"
        ]
    },
    {
        "title": "Solving Large-Scale Extensive-Form Network Security Games via Neural   Fictitious Self-Play",
        "authors": [
            "Wanqi Xue",
            "Youzhi Zhang",
            "Shuxin Li",
            "Xinrun Wang",
            "Bo An",
            "Chai Kiat Yeo"
        ],
        "summary": "Securing networked infrastructures is important in the real world. The problem of deploying security resources to protect against an attacker in networked domains can be modeled as Network Security Games (NSGs). Unfortunately, existing approaches, including the deep learning-based approaches, are inefficient to solve large-scale extensive-form NSGs. In this paper, we propose a novel learning paradigm, NSG-NFSP, to solve large-scale extensive-form NSGs based on Neural Fictitious Self-Play (NFSP). Our main contributions include: i) reforming the best response (BR) policy network in NFSP to be a mapping from action-state pair to action-value, to make the calculation of BR possible in NSGs; ii) converting the average policy network of an NFSP agent into a metric-based classifier, helping the agent to assign distributions only on legal actions rather than all actions; iii) enabling NFSP with high-level actions, which can benefit training efficiency and stability in NSGs; and iv) leveraging information contained in graphs of NSGs by learning efficient graph node embeddings. Our algorithm significantly outperforms state-of-the-art algorithms in both scalability and solution quality.",
        "published": "2021-06-02T02:22:52Z",
        "link": "http://arxiv.org/abs/2106.00897v1",
        "categories": [
            "cs.AI",
            "cs.GT",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Topology Inference for Network Systems: Causality Perspective and   Non-asymptotic Performance",
        "authors": [
            "Yushan Li",
            "Jianping He",
            "Cailian Chen",
            "Xinping Guan"
        ],
        "summary": "Topology inference for network systems (NSs) plays a crucial role in many areas. This paper advocates a causality-based method based on noisy observations from a single trajectory of a NS, which is represented by the state-space model with general directed topology. Specifically, we first prove its close relationships with the ideal Granger estimator for multiple trajectories and the traditional ordinary least squares (OLS) estimator for a single trajectory. Along with this line, we analyze the non-asymptotic inference performance of the proposed method by taking the OLS estimator as a reference, covering both asymptotically and marginally stable systems. The derived convergence rates and accuracy results suggest the proposed method has better performance in addressing potentially correlated observations and achieves zero inference error asymptotically. Besides, an online/recursive version of our method is established for efficient computation or time-varying cases. Extensions on NSs with nonlinear dynamics are also discussed. Comprehensive tests corroborate the theoretical findings and comparisons with other algorithms highlight the superiority of the proposed method.",
        "published": "2021-06-02T08:54:59Z",
        "link": "http://arxiv.org/abs/2106.01031v2",
        "categories": [
            "eess.SP",
            "cs.MA"
        ]
    },
    {
        "title": "Learning to schedule job-shop problems: Representation and policy   learning using graph neural network and reinforcement learning",
        "authors": [
            "Junyoung Park",
            "Jaehyeong Chun",
            "Sang Hun Kim",
            "Youngkook Kim",
            "Jinkyoo Park"
        ],
        "summary": "We propose a framework to learn to schedule a job-shop problem (JSSP) using a graph neural network (GNN) and reinforcement learning (RL). We formulate the scheduling process of JSSP as a sequential decision-making problem with graph representation of the state to consider the structure of JSSP. In solving the formulated problem, the proposed framework employs a GNN to learn that node features that embed the spatial structure of the JSSP represented as a graph (representation learning) and derive the optimum scheduling policy that maps the embedded node features to the best scheduling action (policy learning). We employ Proximal Policy Optimization (PPO) based RL strategy to train these two modules in an end-to-end fashion. We empirically demonstrate that the GNN scheduler, due to its superb generalization capability, outperforms practically favored dispatching rules and RL-based schedulers on various benchmark JSSP. We also confirmed that the proposed framework learns a transferable scheduling policy that can be employed to schedule a completely new JSSP (in terms of size and parameters) without further training.",
        "published": "2021-06-02T11:40:22Z",
        "link": "http://arxiv.org/abs/2106.01086v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Survey Equivalence: A Procedure for Measuring Classifier Accuracy   Against Human Labels",
        "authors": [
            "Paul Resnick",
            "Yuqing Kong",
            "Grant Schoenebeck",
            "Tim Weninger"
        ],
        "summary": "In many classification tasks, the ground truth is either noisy or subjective. Examples include: which of two alternative paper titles is better? is this comment toxic? what is the political leaning of this news article? We refer to such tasks as survey settings because the ground truth is defined through a survey of one or more human raters. In survey settings, conventional measurements of classifier accuracy such as precision, recall, and cross-entropy confound the quality of the classifier with the level of agreement among human raters. Thus, they have no meaningful interpretation on their own. We describe a procedure that, given a dataset with predictions from a classifier and K ratings per item, rescales any accuracy measure into one that has an intuitive interpretation. The key insight is to score the classifier not against the best proxy for the ground truth, such as a majority vote of the raters, but against a single human rater at a time. That score can be compared to other predictors' scores, in particular predictors created by combining labels from several other human raters. The survey equivalence of any classifier is the minimum number of raters needed to produce the same expected score as that found for the classifier.",
        "published": "2021-06-02T16:07:32Z",
        "link": "http://arxiv.org/abs/2106.01254v1",
        "categories": [
            "cs.LG",
            "cs.HC",
            "cs.MA"
        ]
    },
    {
        "title": "Three-agent Time-constrained Cooperative Pursuit-Evasion",
        "authors": [
            "Abhinav Sinha",
            "Shashi Ranjan Kumar",
            "Dwaipayan Mukherjee"
        ],
        "summary": "This paper considers a pursuit-evasion scenario among three agents -- an evader, a pursuer, and a defender. We design cooperative guidance laws for the evader and the defender team to safeguard the evader from an attacking pursuer. Unlike differential games, optimal control formulations, and other heuristic methods, we propose a novel perspective on designing effective nonlinear feedback control laws for the evader-defender team using a time-constrained guidance approach. The evader lures the pursuer on the collision course by offering itself as bait. At the same time, the defender protects the evader from the pursuer by exercising control over the engagement duration. Depending on the nature of the mission, the defender may choose to take an aggressive or defensive stance. Such consideration widens the applicability of the proposed methods in various three-agent motion planning scenarios such as aircraft defense, asset guarding, search and rescue, surveillance, and secure transportation. We use a fixed-time sliding mode control strategy to design the control laws for the evader-defender team and a nonlinear finite-time disturbance observer to estimate the pursuer's maneuver. Finally, we present simulations to demonstrate favorable performance under various engagement geometries, thus vindicating the efficacy of the proposed designs.",
        "published": "2021-06-03T14:38:37Z",
        "link": "http://arxiv.org/abs/2106.01895v2",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.RO",
            "cs.SY",
            "math.OC"
        ]
    },
    {
        "title": "Iterative Empirical Game Solving via Single Policy Best Response",
        "authors": [
            "Max Olan Smith",
            "Thomas Anthony",
            "Michael P. Wellman"
        ],
        "summary": "Policy-Space Response Oracles (PSRO) is a general algorithmic framework for learning policies in multiagent systems by interleaving empirical game analysis with deep reinforcement learning (Deep RL). At each iteration, Deep RL is invoked to train a best response to a mixture of opponent policies. The repeated application of Deep RL poses an expensive computational burden as we look to apply this algorithm to more complex domains. We introduce two variations of PSRO designed to reduce the amount of simulation required during Deep RL training. Both algorithms modify how PSRO adds new policies to the empirical game, based on learned responses to a single opponent policy. The first, Mixed-Oracles, transfers knowledge from previous iterations of Deep RL, requiring training only against the opponent's newest policy. The second, Mixed-Opponents, constructs a pure-strategy opponent by mixing existing strategy's action-value estimates, instead of their policies. Learning against a single policy mitigates variance in state outcomes that is induced by an unobserved distribution of opponents. We empirically demonstrate that these algorithms substantially reduce the amount of simulation during training required by PSRO, while producing equivalent or better solutions to the game.",
        "published": "2021-06-03T14:44:46Z",
        "link": "http://arxiv.org/abs/2106.01901v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Decentralised Approach for Multi Agent Path Finding",
        "authors": [
            "Shyni Thomas",
            "M. Narasimha Murty"
        ],
        "summary": "Multi Agent Path Finding (MAPF) requires identification of conflict free paths for agents which could be point-sized or with dimensions. In this paper, we propose an approach for MAPF for spatially-extended agents. These find application in real world problems like Convoy Movement Problem, Train Scheduling etc. Our proposed approach, Decentralised Multi Agent Path Finding (DeMAPF), handles MAPF as a sequence of pathplanning and allocation problems which are solved by two sets of agents Travellers and Routers respectively, over multiple iterations. The approach being decentralised allows an agent to solve the problem pertinent to itself, without being aware of other agents in the same set. This allows the agents to be executed on independent machines, thereby leading to scalability to handle large sized problems. We prove, by comparison with other distributed approaches, that the approach leads to a faster convergence to a conflict-free solution, which may be suboptimal, with lesser memory requirement.",
        "published": "2021-06-03T18:07:26Z",
        "link": "http://arxiv.org/abs/2106.05188v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Learning to Draw: Emergent Communication through Sketching",
        "authors": [
            "Daniela Mihai",
            "Jonathon Hare"
        ],
        "summary": "Evidence that visual communication preceded written language and provided a basis for it goes back to prehistory, in forms such as cave and rock paintings depicting traces of our distant ancestors. Emergent communication research has sought to explore how agents can learn to communicate in order to collaboratively solve tasks. Existing research has focused on language, with a learned communication channel transmitting sequences of discrete tokens between the agents. In this work, we explore a visual communication channel between agents that are allowed to draw with simple strokes. Our agents are parameterised by deep neural networks, and the drawing procedure is differentiable, allowing for end-to-end training. In the framework of a referential communication game, we demonstrate that agents can not only successfully learn to communicate by drawing, but with appropriate inductive biases, can do so in a fashion that humans can interpret. We hope to encourage future research to consider visual communication as a more flexible and directly interpretable alternative of training collaborative agents.",
        "published": "2021-06-03T18:17:55Z",
        "link": "http://arxiv.org/abs/2106.02067v2",
        "categories": [
            "cs.CV",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "UAV Swarm Path Planning with Reinforcement Learning for Field   prospecting",
        "authors": [
            "Alejandro Puente-Castro",
            "Daniel Rivero",
            "Alejandro Pazos",
            "Enrique Fernandez-Blanco"
        ],
        "summary": "Unmanned Aerial Vehicle (UAV) swarms adoption shows a steady growth among operators due to the benefits in time and cost arisen from their use. However, this kind of system faces an important problem which is the calculation of many optimal paths for each UAV. Solving this problem would allow a to control many UAVs without human intervention at the same time while saving battery between recharges and performing several tasks simultaneously. The main aim is to develop a system capable of calculating the optimal flight path for a UAV swarm. The aim of these paths is to achieve full coverage of a flight area for tasks such as field prospection. All this, regardless of the size of maps and the number of UAVs in the swarm. It is not necessary to establish targets or any other previous knowledge other than the given map. Experiments have been conducted to determine whether it is optimal to establish a single control for all UAVs in the swarm or a control for each UAV. The results show that it is better to use one control for all UAVs because of the shorter flight time. In addition, the flight time is greatly affected by the size of the map. The results give starting points for future research such as finding the optimal map size for each situation.",
        "published": "2021-06-04T08:04:14Z",
        "link": "http://arxiv.org/abs/2106.02322v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Auction-based and Distributed Optimization Approaches for Scheduling   Observations in Satellite Constellations with Exclusive Orbit Portions",
        "authors": [
            "Gauthier Picard"
        ],
        "summary": "We investigate the use of multi-agent allocation techniques on problems related to Earth observation scenarios with multiple users and satellites. We focus on the problem of coordinating users having reserved exclusive orbit portions and one central planner having several requests that may use some intervals of these exclusives. We define this problem as Earth Observation Satellite Constellation Scheduling Problem (EOSCSP) and map it to a Mixed Integer Linear Program. As to solve EOSCSP, we propose market-based techniques and a distributed problem solving technique based on Distributed Constraint Optimization (DCOP), where agents cooperate to allocate requests without sharing their own schedules. These contributions are experimentally evaluated on randomly generated EOSCSP instances based on real large-scale or highly conflicting observation order books.",
        "published": "2021-06-04T09:34:20Z",
        "link": "http://arxiv.org/abs/2106.03548v3",
        "categories": [
            "cs.AI",
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "On the Strategyproofness of the Geometric Median",
        "authors": [
            "El-Mahdi El-Mhamdi",
            "Sadegh Farhadkhani",
            "Rachid Guerraoui",
            "Lê-Nguyên Hoang"
        ],
        "summary": "The geometric median, an instrumental component of the secure machine learning toolbox, is known to be effective when robustly aggregating models (or gradients), gathered from potentially malicious (or strategic) users. What is less known is the extent to which the geometric median incentivizes dishonest behaviors. This paper addresses this fundamental question by quantifying its strategyproofness. While we observe that the geometric median is not even approximately strategyproof, we prove that it is asymptotically $\\alpha$-strategyproof: when the number of users is large enough, a user that misbehaves can gain at most a multiplicative factor $\\alpha$, which we compute as a function of the distribution followed by the users. We then generalize our results to the case where users actually care more about specific dimensions, determining how this impacts $\\alpha$. We also show how the skewed geometric medians can be used to improve strategyproofness.",
        "published": "2021-06-04T10:17:55Z",
        "link": "http://arxiv.org/abs/2106.02394v4",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Transferable and Distributed User Association Policies for 5G and Beyond   Networks",
        "authors": [
            "Mohamed Sana",
            "Nicola di Pietro",
            "Emilio Calvanese Strinati"
        ],
        "summary": "We study the problem of user association, namely finding the optimal assignment of user equipment to base stations to achieve a targeted network performance. In this paper, we focus on the knowledge transferability of association policies. Indeed, traditional non-trivial user association schemes are often scenario-specific or deployment-specific and require a policy re-design or re-learning when the number or the position of the users change. In contrast, transferability allows to apply a single user association policy, devised for a specific scenario, to other distinct user deployments, without needing a substantial re-learning or re-design phase and considerably reducing its computational and management complexity. To achieve transferability, we first cast user association as a multi-agent reinforcement learning problem. Then, based on a neural attention mechanism that we specifically conceived for this context, we propose a novel distributed policy network architecture, which is transferable among users with zero-shot generalization capability i.e., without requiring additional training.Numerical results show the effectiveness of our solution in terms of overall network communication rate, outperforming centralized benchmarks even when the number of users doubles with respect to the initial training point.",
        "published": "2021-06-04T15:08:39Z",
        "link": "http://arxiv.org/abs/2106.02540v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "cs.NI"
        ]
    },
    {
        "title": "On the Design of Strategic Task Recommendations for Sustainable   Crowdsourcing-Based Content Moderation",
        "authors": [
            "Sainath Sanga",
            "Venkata Sriram Siddhardh Nadendla"
        ],
        "summary": "Crowdsourcing-based content moderation is a platform that hosts content moderation tasks for crowd workers to review user submissions (e.g. text, images and videos) and make decisions regarding the admissibility of the posted content, along with a gamut of other tasks such as image labeling and speech-to-text conversion. In an attempt to reduce cognitive overload at the workers and improve system efficiency, these platforms offer personalized task recommendations according to the worker's preferences. However, the current state-of-the-art recommendation systems disregard the effects on worker's mental health, especially when they are repeatedly exposed to content moderation tasks with extreme content (e.g. violent images, hate-speech). In this paper, we propose a novel, strategic recommendation system for the crowdsourcing platform that recommends jobs based on worker's mental status. Specifically, this paper models interaction between the crowdsourcing platform's recommendation system (leader) and the worker (follower) as a Bayesian Stackelberg game where the type of the follower corresponds to the worker's cognitive atrophy rate and task preferences. We discuss how rewards and costs should be designed to steer the game towards desired outcomes in terms of maximizing the platform's productivity, while simultaneously improving the working conditions of crowd workers.",
        "published": "2021-06-04T20:35:14Z",
        "link": "http://arxiv.org/abs/2106.02708v1",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.CY",
            "cs.MA"
        ]
    },
    {
        "title": "Neural Auto-Curricula",
        "authors": [
            "Xidong Feng",
            "Oliver Slumbers",
            "Ziyu Wan",
            "Bo Liu",
            "Stephen McAleer",
            "Ying Wen",
            "Jun Wang",
            "Yaodong Yang"
        ],
        "summary": "When solving two-player zero-sum games, multi-agent reinforcement learning (MARL) algorithms often create populations of agents where, at each iteration, a new agent is discovered as the best response to a mixture over the opponent population. Within such a process, the update rules of \"who to compete with\" (i.e., the opponent mixture) and \"how to beat them\" (i.e., finding best responses) are underpinned by manually developed game theoretical principles such as fictitious play and Double Oracle. In this paper, we introduce a novel framework -- Neural Auto-Curricula (NAC) -- that leverages meta-gradient descent to automate the discovery of the learning update rule without explicit human design. Specifically, we parameterise the opponent selection module by neural networks and the best-response module by optimisation subroutines, and update their parameters solely via interaction with the game engine, where both players aim to minimise their exploitability. Surprisingly, even without human design, the discovered MARL algorithms achieve competitive or even better performance with the state-of-the-art population-based game solvers (e.g., PSRO) on Games of Skill, differentiable Lotto, non-transitive Mixture Games, Iterated Matching Pennies, and Kuhn Poker. Additionally, we show that NAC is able to generalise from small games to large games, for example training on Kuhn Poker and outperforming PSRO on Leduc Poker. Our work inspires a promising future direction to discover general MARL algorithms solely from data.",
        "published": "2021-06-04T22:30:25Z",
        "link": "http://arxiv.org/abs/2106.02745v2",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Decentralized Q-Learning in Zero-sum Markov Games",
        "authors": [
            "Muhammed O. Sayin",
            "Kaiqing Zhang",
            "David S. Leslie",
            "Tamer Basar",
            "Asuman Ozdaglar"
        ],
        "summary": "We study multi-agent reinforcement learning (MARL) in infinite-horizon discounted zero-sum Markov games. We focus on the practical but challenging setting of decentralized MARL, where agents make decisions without coordination by a centralized controller, but only based on their own payoffs and local actions executed. The agents need not observe the opponent's actions or payoffs, possibly being even oblivious to the presence of the opponent, nor be aware of the zero-sum structure of the underlying game, a setting also referred to as radically uncoupled in the literature of learning in games. In this paper, we develop a radically uncoupled Q-learning dynamics that is both rational and convergent: the learning dynamics converges to the best response to the opponent's strategy when the opponent follows an asymptotically stationary strategy; when both agents adopt the learning dynamics, they converge to the Nash equilibrium of the game. The key challenge in this decentralized setting is the non-stationarity of the environment from an agent's perspective, since both her own payoffs and the system evolution depend on the actions of other agents, and each agent adapts her policies simultaneously and independently. To address this issue, we develop a two-timescale learning dynamics where each agent updates her local Q-function and value function estimates concurrently, with the latter happening at a slower timescale.",
        "published": "2021-06-04T22:42:56Z",
        "link": "http://arxiv.org/abs/2106.02748v2",
        "categories": [
            "cs.GT",
            "cs.LG",
            "cs.MA",
            "math.DS"
        ]
    },
    {
        "title": "MALib: A Parallel Framework for Population-based Multi-agent   Reinforcement Learning",
        "authors": [
            "Ming Zhou",
            "Ziyu Wan",
            "Hanjing Wang",
            "Muning Wen",
            "Runzhe Wu",
            "Ying Wen",
            "Yaodong Yang",
            "Weinan Zhang",
            "Jun Wang"
        ],
        "summary": "Population-based multi-agent reinforcement learning (PB-MARL) refers to the series of methods nested with reinforcement learning (RL) algorithms, which produces a self-generated sequence of tasks arising from the coupled population dynamics. By leveraging auto-curricula to induce a population of distinct emergent strategies, PB-MARL has achieved impressive success in tackling multi-agent tasks. Despite remarkable prior arts of distributed RL frameworks, PB-MARL poses new challenges for parallelizing the training frameworks due to the additional complexity of multiple nested workloads between sampling, training and evaluation involved with heterogeneous policy interactions. To solve these problems, we present MALib, a scalable and efficient computing framework for PB-MARL. Our framework is comprised of three key components: (1) a centralized task dispatching model, which supports the self-generated tasks and scalable training with heterogeneous policy combinations; (2) a programming architecture named Actor-Evaluator-Learner, which achieves high parallelism for both training and sampling, and meets the evaluation requirement of auto-curriculum learning; (3) a higher-level abstraction of MARL training paradigms, which enables efficient code reuse and flexible deployments on different distributed computing paradigms. Experiments on a series of complex tasks such as multi-agent Atari Games show that MALib achieves throughput higher than 40K FPS on a single machine with $32$ CPU cores; 5x speedup than RLlib and at least 3x speedup than OpenSpiel in multi-agent training tasks. MALib is publicly available at https://github.com/sjtu-marl/malib.",
        "published": "2021-06-05T03:27:08Z",
        "link": "http://arxiv.org/abs/2106.07551v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "SURPRISE! and When to Schedule It",
        "authors": [
            "Zhihuan Huang",
            "Shengwei Xu",
            "You Shan",
            "Yuxuan Lu",
            "Yuqing Kong",
            "Tracy Xiao Liu",
            "Grant Schoenebeck"
        ],
        "summary": "Information flow measures, over the duration of a game, the audience's belief of who will win, and thus can reflect the amount of surprise in a game. To quantify the relationship between information flow and audiences' perceived quality, we conduct a case study where subjects watch one of the world's biggest esports events, LOL S10. In addition to eliciting information flow, we also ask subjects to report their rating for each game. We find that the amount of surprise in the end of the game plays a dominant role in predicting the rating. This suggests the importance of incorporating when the surprise occurs, in addition to the amount of surprise, in perceived quality models. For content providers, it implies that everything else being equal, it is better for twists to be more likely to happen toward the end of a show rather than uniformly throughout.",
        "published": "2021-06-05T09:36:27Z",
        "link": "http://arxiv.org/abs/2106.02851v1",
        "categories": [
            "cs.MA",
            "physics.soc-ph"
        ]
    },
    {
        "title": "ScheduleNet: Learn to solve multi-agent scheduling problems with   reinforcement learning",
        "authors": [
            "Junyoung Park",
            "Sanjar Bakhtiyar",
            "Jinkyoo Park"
        ],
        "summary": "We propose ScheduleNet, a RL-based real-time scheduler, that can solve various types of multi-agent scheduling problems. We formulate these problems as a semi-MDP with episodic reward (makespan) and learn ScheduleNet, a decentralized decision-making policy that can effectively coordinate multiple agents to complete tasks. The decision making procedure of ScheduleNet includes: (1) representing the state of a scheduling problem with the agent-task graph, (2) extracting node embeddings for agent and tasks nodes, the important relational information among agents and tasks, by employing the type-aware graph attention (TGA), and (3) computing the assignment probability with the computed node embeddings. We validate the effectiveness of ScheduleNet as a general learning-based scheduler for solving various types of multi-agent scheduling tasks, including multiple salesman traveling problem (mTSP) and job shop scheduling problem (JSP).",
        "published": "2021-06-06T07:08:58Z",
        "link": "http://arxiv.org/abs/2106.03051v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Collective transport via sequential caging",
        "authors": [
            "Vivek Shankar Vardharajan",
            "Karthik Soma",
            "Giovanni Beltrame"
        ],
        "summary": "We propose a decentralized algorithm to collaboratively transport arbitrarily shaped objects using a swarm of robots. Our approach starts with a task allocation phase that sequentially distributes locations around the object to be transported starting from a seed robot that makes first contact with the object. Our approach does not require previous knowledge of the shape of the object to ensure caging. To push the object to a goal location, we estimate the robots required to apply force on the object based on the angular difference between the target and the object. During transport, the robots follow a sequence of intermediate goal locations specifying the required pose of the object at that location. We evaluate our approach in a physics-based simulator with up to 100 robots, using three generic paths. Experiments using a group of KheperaIV robots demonstrate the effectiveness of our approach in a real setting.   Keywords: Collaborative transport, Task Allocation, Caging, Robot Swarms",
        "published": "2021-06-06T14:21:21Z",
        "link": "http://arxiv.org/abs/2106.03132v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "PreferenceNet: Encoding Human Preferences in Auction Design with Deep   Learning",
        "authors": [
            "Neehar Peri",
            "Michael J. Curry",
            "Samuel Dooley",
            "John P. Dickerson"
        ],
        "summary": "The design of optimal auctions is a problem of interest in economics, game theory and computer science. Despite decades of effort, strategyproof, revenue-maximizing auction designs are still not known outside of restricted settings. However, recent methods using deep learning have shown some success in approximating optimal auctions, recovering several known solutions and outperforming strong baselines when optimal auctions are not known. In addition to maximizing revenue, auction mechanisms may also seek to encourage socially desirable constraints such as allocation fairness or diversity. However, these philosophical notions neither have standardization nor do they have widely accepted formal definitions. In this paper, we propose PreferenceNet, an extension of existing neural-network-based auction mechanisms to encode constraints using (potentially human-provided) exemplars of desirable allocations. In addition, we introduce a new metric to evaluate an auction allocations' adherence to such socially desirable constraints and demonstrate that our proposed method is competitive with current state-of-the-art neural-network based auction designs. We validate our approach through human subject research and show that we are able to effectively capture real human preferences. Our code is available at https://github.com/neeharperi/PreferenceNet",
        "published": "2021-06-06T19:29:40Z",
        "link": "http://arxiv.org/abs/2106.03215v2",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Asynchronous speedup in decentralized optimization",
        "authors": [
            "Mathieu Even",
            "Hadrien Hendrikx",
            "Laurent Massoulie"
        ],
        "summary": "In decentralized optimization, nodes of a communication network each possess a local objective function, and communicate using gossip-based methods in order to minimize the average of these per-node functions. While synchronous algorithms are heavily impacted by a few slow nodes or edges in the graph (the \\emph{straggler problem}), their asynchronous counterparts are notoriously harder to parametrize. Indeed, their convergence properties for networks with heterogeneous communication and computation delays have defied analysis so far.   In this paper, we use a \\emph{ continuized} framework to analyze asynchronous algorithms in networks with delays. Our approach yields a precise characterization of convergence time and of its dependency on heterogeneous delays in the network. Our continuized framework benefits from the best of both continuous and discrete worlds: the algorithms it applies to are based on event-driven updates. They are thus essentially discrete and hence readily implementable. Yet their analysis is essentially in continuous time, relying in part on the theory of delayed ODEs.   Our algorithms moreover achieve an \\emph{asynchronous speedup}: their rate of convergence is controlled by the eigengap of the network graph weighted by local delays, instead of the network-wide worst-case delay as in previous analyses. Our methods thus enjoy improved robustness to stragglers.",
        "published": "2021-06-07T13:09:25Z",
        "link": "http://arxiv.org/abs/2106.03585v2",
        "categories": [
            "math.OC",
            "cs.MA",
            "math.PR",
            "stat.ML"
        ]
    },
    {
        "title": "Inferring Objectives in Continuous Dynamic Games from Noise-Corrupted   Partial State Observations",
        "authors": [
            "Lasse Peters",
            "David Fridovich-Keil",
            "Vicenç Rubies-Royo",
            "Claire J. Tomlin",
            "Cyrill Stachniss"
        ],
        "summary": "Robots and autonomous systems must interact with one another and their environment to provide high-quality services to their users. Dynamic game theory provides an expressive theoretical framework for modeling scenarios involving multiple agents with differing objectives interacting over time. A core challenge when formulating a dynamic game is designing objectives for each agent that capture desired behavior. In this paper, we propose a method for inferring parametric objective models of multiple agents based on observed interactions. Our inverse game solver jointly optimizes player objectives and continuous-state estimates by coupling them through Nash equilibrium constraints. Hence, our method is able to directly maximize the observation likelihood rather than other non-probabilistic surrogate criteria. Our method does not require full observations of game states or player strategies to identify player objectives. Instead, it robustly recovers this information from noisy, partial state observations. As a byproduct of estimating player objectives, our method computes a Nash equilibrium trajectory corresponding to those objectives. Thus, it is suitable for downstream trajectory forecasting tasks. We demonstrate our method in several simulated traffic scenarios. Results show that it reliably estimates player objectives from a short sequence of noise-corrupted partial state observations. Furthermore, using the estimated objectives, our method makes accurate predictions of each player's trajectory.",
        "published": "2021-06-07T13:37:42Z",
        "link": "http://arxiv.org/abs/2106.03611v3",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Concave Utility Reinforcement Learning: the Mean-Field Game Viewpoint",
        "authors": [
            "Matthieu Geist",
            "Julien Pérolat",
            "Mathieu Laurière",
            "Romuald Elie",
            "Sarah Perrin",
            "Olivier Bachem",
            "Rémi Munos",
            "Olivier Pietquin"
        ],
        "summary": "Concave Utility Reinforcement Learning (CURL) extends RL from linear to concave utilities in the occupancy measure induced by the agent's policy. This encompasses not only RL but also imitation learning and exploration, among others. Yet, this more general paradigm invalidates the classical Bellman equations, and calls for new algorithms. Mean-field Games (MFGs) are a continuous approximation of many-agent RL. They consider the limit case of a continuous distribution of identical agents, anonymous with symmetric interests, and reduce the problem to the study of a single representative agent in interaction with the full population. Our core contribution consists in showing that CURL is a subclass of MFGs. We think this important to bridge together both communities. It also allows to shed light on aspects of both fields: we show the equivalence between concavity in CURL and monotonicity in the associated MFG, between optimality conditions in CURL and Nash equilibrium in MFG, or that Fictitious Play (FP) for this class of MFGs is simply Frank-Wolfe, bringing the first convergence rate for discrete-time FP for MFGs. We also experimentally demonstrate that, using algorithms recently introduced for solving MFGs, we can address the CURL problem more efficiently.",
        "published": "2021-06-07T16:51:07Z",
        "link": "http://arxiv.org/abs/2106.03787v4",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Improving Social Welfare While Preserving Autonomy via a Pareto Mediator",
        "authors": [
            "Stephen McAleer",
            "John Lanier",
            "Michael Dennis",
            "Pierre Baldi",
            "Roy Fox"
        ],
        "summary": "Machine learning algorithms often make decisions on behalf of agents with varied and sometimes conflicting interests. In domains where agents can choose to take their own action or delegate their action to a central mediator, an open question is how mediators should take actions on behalf of delegating agents. The main existing approach uses delegating agents to punish non-delegating agents in an attempt to get all agents to delegate, which tends to be costly for all. We introduce a Pareto Mediator which aims to improve outcomes for delegating agents without making any of them worse off. Our experiments in random normal form games, a restaurant recommendation game, and a reinforcement learning sequential social dilemma show that the Pareto Mediator greatly increases social welfare. Also, even when the Pareto Mediator is based on an incorrect model of agent utility, performance gracefully degrades to the pre-intervention level, due to the individual autonomy preserved by the voluntary mediator.",
        "published": "2021-06-07T19:34:42Z",
        "link": "http://arxiv.org/abs/2106.03927v1",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Mission Level Uncertainty in Multi-Agent Resource Allocation",
        "authors": [
            "Rohit Konda",
            "Rahul Chandan",
            "Jason R. Marden"
        ],
        "summary": "In recent years, a significant research effort has been devoted to the design of distributed protocols for the control of multi-agent systems, as the scale and limited communication bandwidth characteristic of such systems render centralized control impossible. Given the strict operating conditions, it is unlikely that every agent in a multi-agent system will have local information that is consistent with the true system state. Yet, the majority of works in the literature assume that agents share perfect knowledge of their environment. This paper focuses on understanding the impact that inconsistencies in agents' local information can have on the performance of multi-agent systems. More specifically, we consider the design of multi-agent operations under a game theoretic lens where individual agents are assigned utilities that guide their local decision making. We provide a tractable procedure for designing utilities that optimize the efficiency of the resulting collective behavior (i.e., price of anarchy) for classes of set covering games where the extent of the information inconsistencies is known. In the setting where the extent of the informational inconsistencies is not known, we show -- perhaps surprisingly -- that underestimating the level of uncertainty leads to better price of anarchy than overestimating it.",
        "published": "2021-06-08T00:48:42Z",
        "link": "http://arxiv.org/abs/2106.04029v1",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Multi-Agent Cooperative Bidding Games for Multi-Objective Optimization   in e-Commercial Sponsored Search",
        "authors": [
            "Ziyu Guan",
            "Hongchang Wu",
            "Qingyu Cao",
            "Hao Liu",
            "Wei Zhao",
            "Sheng Li",
            "Cai Xu",
            "Guang Qiu",
            "Jian Xu",
            "Bo Zheng"
        ],
        "summary": "Bid optimization for online advertising from single advertiser's perspective has been thoroughly investigated in both academic research and industrial practice. However, existing work typically assume competitors do not change their bids, i.e., the wining price is fixed, leading to poor performance of the derived solution. Although a few studies use multi-agent reinforcement learning to set up a cooperative game, they still suffer the following drawbacks: (1) They fail to avoid collusion solutions where all the advertisers involved in an auction collude to bid an extremely low price on purpose. (2) Previous works cannot well handle the underlying complex bidding environment, leading to poor model convergence. This problem could be amplified when handling multiple objectives of advertisers which are practical demands but not considered by previous work. In this paper, we propose a novel multi-objective cooperative bid optimization formulation called Multi-Agent Cooperative bidding Games (MACG). MACG sets up a carefully designed multi-objective optimization framework where different objectives of advertisers are incorporated. A global objective to maximize the overall profit of all advertisements is added in order to encourage better cooperation and also to protect self-bidding advertisers. To avoid collusion, we also introduce an extra platform revenue constraint. We analyze the optimal functional form of the bidding formula theoretically and design a policy network accordingly to generate auction-level bids. Then we design an efficient multi-agent evolutionary strategy for model optimization. Offline experiments and online A/B tests conducted on the Taobao platform indicate both single advertiser's objective and global profit have been significantly improved compared to state-of-art methods.",
        "published": "2021-06-08T03:18:28Z",
        "link": "http://arxiv.org/abs/2106.04075v1",
        "categories": [
            "cs.AI",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Time-series Imputation of Temporally-occluded Multiagent Trajectories",
        "authors": [
            "Shayegan Omidshafiei",
            "Daniel Hennes",
            "Marta Garnelo",
            "Eugene Tarassov",
            "Zhe Wang",
            "Romuald Elie",
            "Jerome T. Connor",
            "Paul Muller",
            "Ian Graham",
            "William Spearman",
            "Karl Tuyls"
        ],
        "summary": "In multiagent environments, several decision-making individuals interact while adhering to the dynamics constraints imposed by the environment. These interactions, combined with the potential stochasticity of the agents' decision-making processes, make such systems complex and interesting to study from a dynamical perspective. Significant research has been conducted on learning models for forward-direction estimation of agent behaviors, for example, pedestrian predictions used for collision-avoidance in self-driving cars. However, in many settings, only sporadic observations of agents may be available in a given trajectory sequence. For instance, in football, subsets of players may come in and out of view of broadcast video footage, while unobserved players continue to interact off-screen. In this paper, we study the problem of multiagent time-series imputation, where available past and future observations of subsets of agents are used to estimate missing observations for other agents. Our approach, called the Graph Imputer, uses forward- and backward-information in combination with graph networks and variational autoencoders to enable learning of a distribution of imputed trajectories. We evaluate our approach on a dataset of football matches, using a projective camera module to train and evaluate our model for the off-screen player state estimation setting. We illustrate that our method outperforms several state-of-the-art approaches, including those hand-crafted for football.",
        "published": "2021-06-08T09:58:43Z",
        "link": "http://arxiv.org/abs/2106.04219v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Interpretable agent communication from scratch (with a generic visual   processor emerging on the side)",
        "authors": [
            "Roberto Dessì",
            "Eugene Kharitonov",
            "Marco Baroni"
        ],
        "summary": "As deep networks begin to be deployed as autonomous agents, the issue of how they can communicate with each other becomes important. Here, we train two deep nets from scratch to perform realistic referent identification through unsupervised emergent communication. We show that the largely interpretable emergent protocol allows the nets to successfully communicate even about object types they did not see at training time. The visual representations induced as a by-product of our training regime, moreover, show comparable quality, when re-used as generic visual features, to a recent self-supervised learning model. Our results provide concrete evidence of the viability of (interpretable) emergent deep net communication in a more realistic scenario than previously considered, as well as establishing an intriguing link between this field and self-supervised visual learning.",
        "published": "2021-06-08T11:32:11Z",
        "link": "http://arxiv.org/abs/2106.04258v3",
        "categories": [
            "cs.CL",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "North Carolina COVID-19 Agent-Based Model Framework for Hospitalization   Forecasting Overview, Design Concepts, and Details Protocol",
        "authors": [
            "Kasey Jones",
            "Emily Hadley",
            "Sandy Preiss",
            "Caroline Kery",
            "Peter Baumgartner",
            "Marie Stoner",
            "Sarah Rhea"
        ],
        "summary": "This Overview, Design Concepts, and Details Protocol (ODD) provides a detailed description of an agent-based model (ABM) that was developed to simulate hospitalizations during the COVID-19 pandemic. Using the descriptions of submodels, provided parameters, and the links to data sources, modelers will be able to replicate the creation and results of this model.",
        "published": "2021-06-08T15:43:02Z",
        "link": "http://arxiv.org/abs/2106.04461v1",
        "categories": [
            "cs.AI",
            "cs.MA",
            "stat.AP"
        ]
    },
    {
        "title": "Formal Verification of a Map Merging Protocol in the Multi-Agent   Programming Contest",
        "authors": [
            "Matt Luckcuck",
            "Rafael C. Cardoso"
        ],
        "summary": "Communication is a critical part of enabling multi-agent systems to cooperate. This means that applying formal methods to protocols governing communication within multi-agent systems provides useful confidence in its reliability. In this paper, we describe the formal verification of a complex communication protocol that coordinates agents merging maps of their environment. The protocol was used by the LFC team in the 2019 edition of the Multi-Agent Programming Contest (MAPC). Our specification of the protocol is written in Communicating Sequential Processes (CSP), which is a well-suited approach to specifying agent communication protocols due to its focus on concurrent communicating systems. We validate the specification's behaviour using scenarios where the correct behaviour is known, and verify that eventually all the maps have merged.",
        "published": "2021-06-08T16:49:53Z",
        "link": "http://arxiv.org/abs/2106.04512v2",
        "categories": [
            "cs.MA",
            "cs.LO"
        ]
    },
    {
        "title": "Unifying Behavioral and Response Diversity for Open-ended Learning in   Zero-sum Games",
        "authors": [
            "Xiangyu Liu",
            "Hangtian Jia",
            "Ying Wen",
            "Yaodong Yang",
            "Yujing Hu",
            "Yingfeng Chen",
            "Changjie Fan",
            "Zhipeng Hu"
        ],
        "summary": "Measuring and promoting policy diversity is critical for solving games with strong non-transitive dynamics where strategic cycles exist, and there is no consistent winner (e.g., Rock-Paper-Scissors). With that in mind, maintaining a pool of diverse policies via open-ended learning is an attractive solution, which can generate auto-curricula to avoid being exploited. However, in conventional open-ended learning algorithms, there are no widely accepted definitions for diversity, making it hard to construct and evaluate the diverse policies. In this work, we summarize previous concepts of diversity and work towards offering a unified measure of diversity in multi-agent open-ended learning to include all elements in Markov games, based on both Behavioral Diversity (BD) and Response Diversity (RD). At the trajectory distribution level, we re-define BD in the state-action space as the discrepancies of occupancy measures. For the reward dynamics, we propose RD to characterize diversity through the responses of policies when encountering different opponents. We also show that many current diversity measures fall in one of the categories of BD or RD but not both. With this unified diversity measure, we design the corresponding diversity-promoting objective and population effectivity when seeking the best responses in open-ended learning. We validate our methods in both relatively simple games like matrix game, non-transitive mixture model, and the complex \\textit{Google Research Football} environment. The population found by our methods reveals the lowest exploitability, highest population effectivity in matrix game and non-transitive mixture model, as well as the largest goal difference when interacting with opponents of various levels in \\textit{Google Research Football}.",
        "published": "2021-06-09T10:11:06Z",
        "link": "http://arxiv.org/abs/2106.04958v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.GT",
            "cs.LG"
        ]
    },
    {
        "title": "Information Avoidance and Overvaluation in Sequential Decision Making   under Epistemic Constraints",
        "authors": [
            "Shuo Li",
            "Matteo Pozzi"
        ],
        "summary": "Decision makers involved in the management of civil assets and systems usually take actions under constraints imposed by societal regulations. Some of these constraints are related to epistemic quantities, as the probability of failure events and the corresponding risks. Sensors and inspectors can provide useful information supporting the control process (e.g. the maintenance process of an asset), and decisions about collecting this information should rely on an analysis of its cost and value. When societal regulations encode an economic perspective that is not aligned with that of the decision makers, the Value of Information (VoI) can be negative (i.e., information sometimes hurts), and almost irrelevant information can even have a significant value (either positive or negative), for agents acting under these epistemic constraints. We refer to these phenomena as Information Avoidance (IA) and Information OverValuation (IOV). In this paper, we illustrate how to assess VoI in sequential decision making under epistemic constraints (as those imposed by societal regulations), by modeling a Partially Observable Markov Decision Processes (POMDP) and evaluating non optimal policies via Finite State Controllers (FSCs). We focus on the value of collecting information at current time, and on that of collecting sequential information, we illustrate how these values are related and we discuss how IA and IOV can occur in those settings.",
        "published": "2021-06-09T11:05:13Z",
        "link": "http://arxiv.org/abs/2106.04984v1",
        "categories": [
            "cs.AI",
            "cs.IT",
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "math.IT"
        ]
    },
    {
        "title": "RLupus: Cooperation through emergent communication in The Werewolf   social deduction game",
        "authors": [
            "Nicolo' Brandizzi",
            "Davide Grossi",
            "Luca Iocchi"
        ],
        "summary": "This paper focuses on the emergence of communication to support cooperation in environments modeled as social deduction games (SDG), that are games where players communicate freely to deduce each others' hidden intentions. We first state the problem by giving a general formalization of SDG and a possible solution framework based on reinforcement learning. Next, we focus on a specific SDG, known as The Werewolf, and study if and how various forms of communication influence the outcome of the game. Experimental results show that introducing a communication signal greatly increases the winning chances of a class of players. We also study the effect of the signal's length and range on the overall performance showing a non-linear relationship.",
        "published": "2021-06-09T12:29:29Z",
        "link": "http://arxiv.org/abs/2106.05018v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Visual Sensor Pose Optimisation Using Visibility Models for Smart Cities",
        "authors": [
            "Eduardo Arnold",
            "Sajjad Mozaffari",
            "Mehrdad Dianati",
            "Paul Jennings"
        ],
        "summary": "Visual sensor networks are used for monitoring traffic in large cities and are promised to support automated driving in complex road segments. The pose of these sensors, i.e. position and orientation, directly determines the coverage of the driving environment, and the ability to detect and track objects navigating therein. Existing sensor pose optimisation methods either maximise the coverage of ground surfaces, or consider the visibility of target objects (e.g. cars) as binary variables, which fails to represent their degree of visibility. For example, such formulations fail in cluttered environments where multiple objects occlude each other. This paper proposes two novel sensor pose optimisation methods, one based on gradient-ascent and one using integer programming techniques, which maximise the visibility of multiple target objects. Both methods are based on a rendering engine that provides pixel-level visibility information about the target objects, and thus, can cope with occlusions in cluttered environments. The methods are evaluated in a complex driving environment and show improved visibility of target objects when compared to existing methods. Such methods can be used to guide the cost effective deployment of sensor networks in smart cities to improve the safety and efficiency of traffic monitoring systems.",
        "published": "2021-06-09T18:02:32Z",
        "link": "http://arxiv.org/abs/2106.05308v2",
        "categories": [
            "cs.CV",
            "cs.MA"
        ]
    },
    {
        "title": "Swarm Intelligence for Self-Organized Clustering",
        "authors": [
            "Michael C. Thrun",
            "Alfred Ultsch"
        ],
        "summary": "Algorithms implementing populations of agents which interact with one another and sense their environment may exhibit emergent behavior such as self-organization and swarm intelligence. Here a swarm system, called Databionic swarm (DBS), is introduced which is able to adapt itself to structures of high-dimensional data characterized by distance and/or density-based structures in the data space. By exploiting the interrelations of swarm intelligence, self-organization and emergence, DBS serves as an alternative approach to the optimization of a global objective function in the task of clustering. The swarm omits the usage of a global objective function and is parameter-free because it searches for the Nash equilibrium during its annealing process. To our knowledge, DBS is the first swarm combining these approaches. Its clustering can outperform common clustering methods such as K-means, PAM, single linkage, spectral clustering, model-based clustering, and Ward, if no prior knowledge about the data is available. A central problem in clustering is the correct estimation of the number of clusters. This is addressed by a DBS visualization called topographic map which allows assessing the number of clusters. It is known that all clustering algorithms construct clusters, irrespective of the data set contains clusters or not. In contrast to most other clustering algorithms, the topographic map identifies, that clustering of the data is meaningless if the data contains no (natural) clusters. The performance of DBS is demonstrated on a set of benchmark data, which are constructed to pose difficult clustering problems and in two real-world applications.",
        "published": "2021-06-10T06:21:48Z",
        "link": "http://arxiv.org/abs/2106.05521v1",
        "categories": [
            "cs.NE",
            "cs.AI",
            "cs.MA",
            "stat.ML",
            "68T05 (Primary) 68T42, 91Axx (Secondary)",
            "I.2"
        ]
    },
    {
        "title": "A Continuized View on Nesterov Acceleration for Stochastic Gradient   Descent and Randomized Gossip",
        "authors": [
            "Mathieu Even",
            "Raphaël Berthier",
            "Francis Bach",
            "Nicolas Flammarion",
            "Pierre Gaillard",
            "Hadrien Hendrikx",
            "Laurent Massoulié",
            "Adrien Taylor"
        ],
        "summary": "We introduce the continuized Nesterov acceleration, a close variant of Nesterov acceleration whose variables are indexed by a continuous time parameter. The two variables continuously mix following a linear ordinary differential equation and take gradient steps at random times. This continuized variant benefits from the best of the continuous and the discrete frameworks: as a continuous process, one can use differential calculus to analyze convergence and obtain analytical expressions for the parameters; and a discretization of the continuized process can be computed exactly with convergence rates similar to those of Nesterov original acceleration. We show that the discretization has the same structure as Nesterov acceleration, but with random parameters. We provide continuized Nesterov acceleration under deterministic as well as stochastic gradients, with either additive or multiplicative noise. Finally, using our continuized framework and expressing the gossip averaging problem as the stochastic minimization of a certain energy function, we provide the first rigorous acceleration of asynchronous gossip algorithms.",
        "published": "2021-06-10T08:35:55Z",
        "link": "http://arxiv.org/abs/2106.07644v2",
        "categories": [
            "math.OC",
            "cs.LG",
            "cs.MA",
            "math.PR",
            "stat.ML"
        ]
    },
    {
        "title": "Cooperative Multi-Agent Fairness and Equivariant Policies",
        "authors": [
            "Niko A. Grupen",
            "Bart Selman",
            "Daniel D. Lee"
        ],
        "summary": "We study fairness through the lens of cooperative multi-agent learning. Our work is motivated by empirical evidence that naive maximization of team reward yields unfair outcomes for individual team members. To address fairness in multi-agent contexts, we introduce team fairness, a group-based fairness measure for multi-agent learning. We then prove that it is possible to enforce team fairness during policy optimization by transforming the team's joint policy into an equivariant map. We refer to our multi-agent learning strategy as Fairness through Equivariance (Fair-E) and demonstrate its effectiveness empirically. We then introduce Fairness through Equivariance Regularization (Fair-ER) as a soft-constraint version of Fair-E and show that it reaches higher levels of utility than Fair-E and fairer outcomes than non-equivariant policies. Finally, we present novel findings regarding the fairness-utility trade-off in multi-agent settings; showing that the magnitude of the trade-off is dependent on agent skill.",
        "published": "2021-06-10T13:17:46Z",
        "link": "http://arxiv.org/abs/2106.05727v3",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Metric Policy Representations for Opponent Modeling",
        "authors": [
            "Haobin Jiang",
            "Yifan Yu",
            "Zongqing Lu"
        ],
        "summary": "In multi-agent reinforcement learning, the inherent non-stationarity of the environment caused by other agents' actions posed significant difficulties for an agent to learn a good policy independently. One way to deal with non-stationarity is opponent modeling, by which the agent takes into consideration the influence of other agents' policies. Most existing work relies on predicting other agents' actions or goals, or discriminating between different policies. However, such modeling fails to capture the similarities and differences between policies simultaneously and thus cannot provide enough useful information when generalizing to unseen agents. To address this, we propose a general method to learn representations of other agents' policies, such that the distance between policies is deliberately reflected by the distance between representations, while the policy distance is inferred from the sampled joint action distributions during training. We empirically show that the agent conditioned on the learned policy representation can well generalize to unseen agents in three multi-agent tasks.",
        "published": "2021-06-10T15:09:33Z",
        "link": "http://arxiv.org/abs/2106.05802v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Analysis of Evolved Response Thresholds for Decentralized Dynamic Task   Allocation",
        "authors": [
            "H. David Mathias",
            "Annie S. Wu",
            "Daniel Dang"
        ],
        "summary": "We investigate the application of a multi-objective genetic algorithm to the problem of task allocation in a self-organizing, decentralized, threshold-based swarm. Each agent in our system is capable of performing four tasks with a response threshold for each, and we seek to assign response threshold values to all of the agents a swarm such that the collective behavior of the swarm is optimized. Random assignment of threshold values according to a uniform distribution is known to be effective; however, this method does not consider features of particular problem instances. Dynamic response thresholds have some flexibility to address problem specific features through real-time adaptivity, often improving swarm performance.   In this work, we use a multi-objective genetic algorithm to evolve response thresholds for a simulated swarm engaged in a dynamic task allocation problem: two-dimensional collective tracking. We show that evolved thresholds not only outperform uniformly distributed thresholds and dynamic thresholds but achieve nearly optimal performance on a variety of tracking problem instances (target paths). More importantly, we demonstrate that thresholds evolved for one of several problem instances generalize to all other problem instances eliminating the need to evolve new thresholds for each problem to be solved. We analyze the properties that allow these paths to serve as universal training instances and show that they are quite natural.",
        "published": "2021-06-10T19:53:53Z",
        "link": "http://arxiv.org/abs/2106.06019v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "AI-driven Prices for Externalities and Sustainability in Production   Markets",
        "authors": [
            "Panayiotis Danassis",
            "Aris Filos-Ratsikas",
            "Haipeng Chen",
            "Milind Tambe",
            "Boi Faltings"
        ],
        "summary": "Traditional competitive markets do not account for negative externalities; indirect costs that some participants impose on others, such as the cost of over-appropriating a common-pool resource (which diminishes future stock, and thus harvest, for everyone). Quantifying appropriate interventions to market prices has proven to be quite challenging. We propose a practical approach to computing market prices and allocations via a deep reinforcement learning policymaker agent, operating in an environment of other learning agents. Our policymaker allows us to tune the prices with regard to diverse objectives such as sustainability and resource wastefulness, fairness, buyers' and sellers' welfare, etc. As a highlight of our findings, our policymaker is significantly more successful in maintaining resource sustainability, compared to the market equilibrium outcome, in scarce resource environments.",
        "published": "2021-06-10T21:26:17Z",
        "link": "http://arxiv.org/abs/2106.06060v3",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.GT"
        ]
    },
    {
        "title": "Dynamic Event-Triggered Consensus of Multi-agent Systems on   Matrix-weighted Networks",
        "authors": [
            "Lulu Pan",
            "Haibin Shao",
            "Dewei Li",
            "Lin Liu"
        ],
        "summary": "This paper examines the event-triggered consensus of the multi-agent system on matrix-weighted networks, where the interdependencies among higher-dimensional states of neighboring agents are characterized by matrix-weighted edges in the network. Specifically, a novel distributed dynamic event-triggered coordination strategy is proposed for this category of generalized networks, in which an auxiliary system is employed for each agent to dynamically adjust the triggering threshold, which plays an essential role in guaranteeing that the triggering time sequence does not exhibit Zeno behavior. Distributed event-triggered control protocols are proposed to guarantee leaderless and leader-follower consensus for multi-agent systems on matrix-weighted networks, respectively. Remarkably, the spectrum of matrix-valued weights is crucial in event-triggered mechanism design for matrix-weighted networks, generalizing those results only applicable for scalar-weighted networks. The proposed approach allows each agent to broadcast and receive information only at its triggering instants. Finally, simulation examples are provided to demonstrate the theoretical results.",
        "published": "2021-06-11T06:59:49Z",
        "link": "http://arxiv.org/abs/2106.06198v3",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "On the efficiency of decentralized epidemic management and application   to Covid-19",
        "authors": [
            "Olivier Lindamulage De Silva",
            "Samson Lasaulce",
            "Irinel-Constantin Morărescu"
        ],
        "summary": "In this paper, we introduce a game that allows one to assess the potential loss of efficiency induced by a decentralized control or local management of a global epidemic. Each player typically represents a region or a country which is assumed to choose its control action to implement a tradeoff between socioeconomic aspects and the health aspect. We conduct the Nash equilibrium analysis of this game. Since the analysis is not trivial in general, sufficient conditions for existence and uniqueness are provided. Then we quantify through numerical results the loss induced by decentralization, measured in terms of price of anarchy (PoA) and price of connectedness (PoC). These results allow one to clearly identify scenarios where decentralization is acceptable or not regarding to the retained global efficiency measures.",
        "published": "2021-06-11T08:01:17Z",
        "link": "http://arxiv.org/abs/2106.06220v1",
        "categories": [
            "cs.GT",
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "91A06, 91A10, 91A80"
        ]
    },
    {
        "title": "A Cooperative-Competitive Multi-Agent Framework for Auto-bidding in   Online Advertising",
        "authors": [
            "Chao Wen",
            "Miao Xu",
            "Zhilin Zhang",
            "Zhenzhe Zheng",
            "Yuhui Wang",
            "Xiangyu Liu",
            "Yu Rong",
            "Dong Xie",
            "Xiaoyang Tan",
            "Chuan Yu",
            "Jian Xu",
            "Fan Wu",
            "Guihai Chen",
            "Xiaoqiang Zhu",
            "Bo Zheng"
        ],
        "summary": "In online advertising, auto-bidding has become an essential tool for advertisers to optimize their preferred ad performance metrics by simply expressing high-level campaign objectives and constraints. Previous works designed auto-bidding tools from the view of single-agent, without modeling the mutual influence between agents. In this paper, we instead consider this problem from a distributed multi-agent perspective, and propose a general $\\underline{M}$ulti-$\\underline{A}$gent reinforcement learning framework for $\\underline{A}$uto-$\\underline{B}$idding, namely MAAB, to learn the auto-bidding strategies. First, we investigate the competition and cooperation relation among auto-bidding agents, and propose a temperature-regularized credit assignment to establish a mixed cooperative-competitive paradigm. By carefully making a competition and cooperation trade-off among agents, we can reach an equilibrium state that guarantees not only individual advertiser's utility but also the system performance (i.e., social welfare). Second, to avoid the potential collusion behaviors of bidding low prices underlying the cooperation, we further propose bar agents to set a personalized bidding bar for each agent, and then alleviate the revenue degradation due to the cooperation. Third, to deploy MAAB in the large-scale advertising system with millions of advertisers, we propose a mean-field approach. By grouping advertisers with the same objective as a mean auto-bidding agent, the interactions among the large-scale advertisers are greatly simplified, making it practical to train MAAB efficiently. Extensive experiments on the offline industrial dataset and Alibaba advertising platform demonstrate that our approach outperforms several baseline methods in terms of social welfare and revenue.",
        "published": "2021-06-11T08:07:14Z",
        "link": "http://arxiv.org/abs/2106.06224v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.GT"
        ]
    },
    {
        "title": "Solving Graph-based Public Good Games with Tree Search and Imitation   Learning",
        "authors": [
            "Victor-Alexandru Darvariu",
            "Stephen Hailes",
            "Mirco Musolesi"
        ],
        "summary": "Public goods games represent insightful settings for studying incentives for individual agents to make contributions that, while costly for each of them, benefit the wider society. In this work, we adopt the perspective of a central planner with a global view of a network of self-interested agents and the goal of maximizing some desired property in the context of a best-shot public goods game. Existing algorithms for this known NP-complete problem find solutions that are sub-optimal and cannot optimize for criteria other than social welfare.   In order to efficiently solve public goods games, our proposed method directly exploits the correspondence between equilibria and the Maximal Independent Set (mIS) structural property of graphs. In particular, we define a Markov Decision Process which incrementally generates an mIS, and adopt a planning method to search for equilibria, outperforming existing methods. Furthermore, we devise a graph imitation learning technique that uses demonstrations of the search to obtain a graph neural network parametrized policy which quickly generalizes to unseen game instances. Our evaluation results show that this policy is able to reach 99.5% of the performance of the planning method while being three orders of magnitude faster to evaluate on the largest graphs tested. The methods presented in this work can be applied to a large class of public goods games of potentially high societal impact and more broadly to other graph combinatorial optimization problems.",
        "published": "2021-06-12T12:46:44Z",
        "link": "http://arxiv.org/abs/2106.06762v2",
        "categories": [
            "cs.AI",
            "cs.GT",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "A Game-Theoretic Approach to Multi-Agent Trust Region Optimization",
        "authors": [
            "Ying Wen",
            "Hui Chen",
            "Yaodong Yang",
            "Zheng Tian",
            "Minne Li",
            "Xu Chen",
            "Jun Wang"
        ],
        "summary": "Trust region methods are widely applied in single-agent reinforcement learning problems due to their monotonic performance-improvement guarantee at every iteration. Nonetheless, when applied in multi-agent settings, the guarantee of trust region methods no longer holds because an agent's payoff is also affected by other agents' adaptive behaviors. To tackle this problem, we conduct a game-theoretical analysis in the policy space, and propose a multi-agent trust region learning method (MATRL), which enables trust region optimization for multi-agent learning. Specifically, MATRL finds a stable improvement direction that is guided by the solution concept of Nash equilibrium at the meta-game level. We derive the monotonic improvement guarantee in multi-agent settings and empirically show the local convergence of MATRL to stable fixed points in the two-player rotational differential game. To test our method, we evaluate MATRL in both discrete and continuous multiplayer general-sum games including checker and switch grid worlds, multi-agent MuJoCo, and Atari games. Results suggest that MATRL significantly outperforms strong multi-agent reinforcement learning baselines.",
        "published": "2021-06-12T18:21:26Z",
        "link": "http://arxiv.org/abs/2106.06828v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "A Spatially Dependent Probabilistic Model for House Hunting in Ant   Colonies",
        "authors": [
            "Grace Cai",
            "Wendy Wu",
            "Wayne Zhao",
            "Jiajia Zhao",
            "Nancy Lynch"
        ],
        "summary": "Ant species such as Temnothorax albipennis select a new nest site in a distributed fashion that, if modeled correctly, can serve as useful information for site selection algorithms for robotic swarms and other applications. Studying and replicating the ants' house hunting behavior will also illuminate useful distributed strategies that have evolved in nature. Many of the existing models of househunting behaviour for T. albipennis make the assumption that all candidate nest sites are equally distant from the ants' home nest, or that an ant has an equal probability of finding each candidate nest site. However, realistically this is not the case, as nests that are further away from the home nest and nests that are difficult to access are less likely to be found, even if they are of higher quality. We extend previous house-hunting models to account for a pairwise distance metric between nests, compare our results to those of real colonies, and use our results to examine the effects of house hunting in nests of different spatial orientations. Our incorporation of distances in the ant model appear to match empirical data in situations where a distance-quality tradeoff between nests is relevant. Furthermore, the model continues to be on par with previous house-hunting models in experiments where all candidate nests are equidistant from the home nest, as is typically assumed.",
        "published": "2021-06-12T21:42:51Z",
        "link": "http://arxiv.org/abs/2106.06867v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Compressed Gradient Tracking for Decentralized Optimization Over General   Directed Networks",
        "authors": [
            "Zhuoqing Song",
            "Lei Shi",
            "Shi Pu",
            "Ming Yan"
        ],
        "summary": "In this paper, we propose two communication efficient decentralized optimization algorithms over a general directed multi-agent network. The first algorithm, termed Compressed Push-Pull (CPP), combines the gradient tracking Push-Pull method with communication compression. We show that CPP is applicable to a general class of unbiased compression operators and achieves linear convergence rate for strongly convex and smooth objective functions. The second algorithm is a broadcast-like version of CPP (B-CPP), and it also achieves linear convergence rate under the same conditions on the objective functions. B-CPP can be applied in an asynchronous broadcast setting and further reduce communication costs compared to CPP. Numerical experiments complement the theoretical analysis and confirm the effectiveness of the proposed methods.",
        "published": "2021-06-14T08:53:30Z",
        "link": "http://arxiv.org/abs/2106.07243v4",
        "categories": [
            "math.OC",
            "cs.DC",
            "cs.LG",
            "cs.MA",
            "eess.SP"
        ]
    },
    {
        "title": "Targeted Data Acquisition for Evolving Negotiation Agents",
        "authors": [
            "Minae Kwon",
            "Siddharth Karamcheti",
            "Mariano-Florentino Cuellar",
            "Dorsa Sadigh"
        ],
        "summary": "Successful negotiators must learn how to balance optimizing for self-interest and cooperation. Yet current artificial negotiation agents often heavily depend on the quality of the static datasets they were trained on, limiting their capacity to fashion an adaptive response balancing self-interest and cooperation. For this reason, we find that these agents can achieve either high utility or cooperation, but not both. To address this, we introduce a targeted data acquisition framework where we guide the exploration of a reinforcement learning agent using annotations from an expert oracle. The guided exploration incentivizes the learning agent to go beyond its static dataset and develop new negotiation strategies. We show that this enables our agents to obtain higher-reward and more Pareto-optimal solutions when negotiating with both simulated and human partners compared to standard supervised learning and reinforcement learning methods. This trend additionally holds when comparing agents using our targeted data acquisition framework to variants of agents trained with a mix of supervised learning and reinforcement learning, or to agents using tailored reward functions that explicitly optimize for utility and Pareto-optimality.",
        "published": "2021-06-14T19:45:59Z",
        "link": "http://arxiv.org/abs/2106.07728v2",
        "categories": [
            "cs.AI",
            "cs.CL",
            "cs.MA"
        ]
    },
    {
        "title": "Towards Safe Control of Continuum Manipulator Using Shielded Multiagent   Reinforcement Learning",
        "authors": [
            "Guanglin Ji",
            "Junyan Yan",
            "Jingxin Du",
            "Wanquan Yan",
            "Jibiao Chen",
            "Yongkang Lu",
            "Juan Rojas",
            "Shing Shin Cheng"
        ],
        "summary": "Continuum robotic manipulators are increasingly adopted in minimal invasive surgery. However, their nonlinear behavior is challenging to model accurately, especially when subject to external interaction, potentially leading to poor control performance. In this letter, we investigate the feasibility of adopting a model-free multiagent reinforcement learning (RL), namely multiagent deep Q network (MADQN), to control a 2-degree of freedom (DoF) cable-driven continuum surgical manipulator. The control of the robot is formulated as a one-DoF, one agent problem in the MADQN framework to improve the learning efficiency. Combined with a shielding scheme that enables dynamic variation of the action set boundary, MADQN leads to efficient and importantly safer control of the robot. Shielded MADQN enabled the robot to perform point and trajectory tracking with submillimeter root mean square errors under external loads, soft obstacles, and rigid collision, which are common interaction scenarios encountered by surgical manipulators. The controller was further proven to be effective in a miniature continuum robot with high structural nonlinearitiy, achieving trajectory tracking with submillimeter accuracy under external payload.",
        "published": "2021-06-15T05:55:05Z",
        "link": "http://arxiv.org/abs/2106.07892v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Future urban mobility as a bio-inspired collaborative system of   multi-functional autonomous vehicles",
        "authors": [
            "Naroa Coretti Sánchez",
            "Juan Múgica González",
            "Luis Alonso Pastor",
            "Kent Larson"
        ],
        "summary": "The fast urbanization and climate change challenges require solutions that enable the efficient movement of people and goods in cities. We envision future cities to be composed of high-performing walkable districts where transportation needs could be served by fleets of ultra-lightweight shared and autonomous vehicles. A future in which most vehicles would be autonomous creates a new paradigm for the possible interactions between vehicles. Natural swarms are a great example of how rich interactions can be; they can divide tasks, cluster, build together, or transport cooperatively. The field of swarm robotics has translated some of the behaviors from natural swarms to artificial systems, proving to make systems more flexible, scalable, and robust. Inspired by nature and supported by swarm robotics, this paper proposes a future mobility in which shared, electric, and autonomous vehicles would be multi-functional and behave as a collaborative system. In this future, fleets of multi-functional vehicles would complete different tasks collaboratively, giving a response to the different urban mobility needs. This paper contributes with the proposal of a framework for future urban mobility that integrates current research and mobility trends in a novel and unique way.",
        "published": "2021-06-15T15:13:18Z",
        "link": "http://arxiv.org/abs/2106.09543v2",
        "categories": [
            "cs.MA",
            "cs.RO",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Robust Reinforcement Learning Under Minimax Regret for Green Security",
        "authors": [
            "Lily Xu",
            "Andrew Perrault",
            "Fei Fang",
            "Haipeng Chen",
            "Milind Tambe"
        ],
        "summary": "Green security domains feature defenders who plan patrols in the face of uncertainty about the adversarial behavior of poachers, illegal loggers, and illegal fishers. Importantly, the deterrence effect of patrols on adversaries' future behavior makes patrol planning a sequential decision-making problem. Therefore, we focus on robust sequential patrol planning for green security following the minimax regret criterion, which has not been considered in the literature. We formulate the problem as a game between the defender and nature who controls the parameter values of the adversarial behavior and design an algorithm MIRROR to find a robust policy. MIRROR uses two reinforcement learning-based oracles and solves a restricted game considering limited defender strategies and parameter values. We evaluate MIRROR on real-world poaching data.",
        "published": "2021-06-15T20:11:12Z",
        "link": "http://arxiv.org/abs/2106.08413v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Reinforcement learning for pursuit and evasion of microswimmers at low   Reynolds number",
        "authors": [
            "Francesco Borra",
            "Luca Biferale",
            "Massimo Cencini",
            "Antonio Celani"
        ],
        "summary": "We consider a model of two competing microswimming agents engaged in a pursue-evasion task within a low-Reynolds-number environment. Agents can only perform simple maneuvers and sense hydrodynamic disturbances, which provide ambiguous (partial) information about the opponent's position and motion. We frame the problem as a zero-sum game: The pursuer has to capture the evader in the shortest time, while the evader aims at deferring capture as long as possible. We show that the agents, trained via adversarial reinforcement learning, are able to overcome partial observability by discovering increasingly complex sequences of moves and countermoves that outperform known heuristic strategies and exploit the hydrodynamic environment.",
        "published": "2021-06-16T08:08:40Z",
        "link": "http://arxiv.org/abs/2106.08609v3",
        "categories": [
            "physics.flu-dyn",
            "cs.LG",
            "cs.MA",
            "nlin.CD"
        ]
    },
    {
        "title": "Strategic Behavior is Bliss: Iterative Voting Improves Social Welfare",
        "authors": [
            "Joshua Kavner",
            "Lirong Xia"
        ],
        "summary": "Recent work in iterative voting has defined the additive dynamic price of anarchy (ADPoA) as the difference in social welfare between the truthful and worst-case equilibrium profiles resulting from repeated strategic manipulations. While iterative plurality has been shown to only return alternatives with at most one less initial votes than the truthful winner, it is less understood how agents' welfare changes in equilibrium. To this end, we differentiate agents' utility from their manipulation mechanism and determine iterative plurality's ADPoA in the worst- and average-cases. We first prove that the worst-case ADPoA is linear in the number of agents. To overcome this negative result, we study the average-case ADPoA and prove that equilibrium winners have a constant order welfare advantage over the truthful winner in expectation. Our positive results illustrate the prospect for social welfare to increase due to strategic manipulation.",
        "published": "2021-06-16T15:18:37Z",
        "link": "http://arxiv.org/abs/2106.08853v3",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "A learning agent that acquires social norms from public sanctions in   decentralized multi-agent settings",
        "authors": [
            "Eugene Vinitsky",
            "Raphael Köster",
            "John P. Agapiou",
            "Edgar Duéñez-Guzmán",
            "Alexander Sasha Vezhnevets",
            "Joel Z. Leibo"
        ],
        "summary": "Society is characterized by the presence of a variety of social norms: collective patterns of sanctioning that can prevent miscoordination and free-riding. Inspired by this, we aim to construct learning dynamics where potentially beneficial social norms can emerge. Since social norms are underpinned by sanctioning, we introduce a training regime where agents can access all sanctioning events but learning is otherwise decentralized. This setting is technologically interesting because sanctioning events may be the only available public signal in decentralized multi-agent systems where reward or policy-sharing is infeasible or undesirable. To achieve collective action in this setting we construct an agent architecture containing a classifier module that categorizes observed behaviors as approved or disapproved, and a motivation to punish in accord with the group. We show that social norms emerge in multi-agent systems containing this agent and investigate the conditions under which this helps them achieve socially beneficial outcomes.",
        "published": "2021-06-16T17:57:41Z",
        "link": "http://arxiv.org/abs/2106.09012v5",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Multi-Agent Training beyond Zero-Sum with Correlated Equilibrium   Meta-Solvers",
        "authors": [
            "Luke Marris",
            "Paul Muller",
            "Marc Lanctot",
            "Karl Tuyls",
            "Thore Graepel"
        ],
        "summary": "Two-player, constant-sum games are well studied in the literature, but there has been limited progress outside of this setting. We propose Joint Policy-Space Response Oracles (JPSRO), an algorithm for training agents in n-player, general-sum extensive form games, which provably converges to an equilibrium. We further suggest correlated equilibria (CE) as promising meta-solvers, and propose a novel solution concept Maximum Gini Correlated Equilibrium (MGCE), a principled and computationally efficient family of solutions for solving the correlated equilibrium selection problem. We conduct several experiments using CE meta-solvers for JPSRO and demonstrate convergence on n-player, general-sum games.",
        "published": "2021-06-17T12:34:18Z",
        "link": "http://arxiv.org/abs/2106.09435v3",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.GT",
            "cs.LG"
        ]
    },
    {
        "title": "Modelling resource allocation in uncertain system environment through   deep reinforcement learning",
        "authors": [
            "Neel Gandhi",
            "Shakti Mishra"
        ],
        "summary": "Reinforcement Learning has applications in field of mechatronics, robotics, and other resource-constrained control system. Problem of resource allocation is primarily solved using traditional predefined techniques and modern deep learning methods. The drawback of predefined and most deep learning methods for resource allocation is failing to meet the requirements in cases of uncertain system environment. We can approach problem of resource allocation in uncertain system environment alongside following certain criteria using deep reinforcement learning. Also, reinforcement learning has ability for adapting to new uncertain environment for prolonged period of time. The paper provides a detailed comparative analysis on various deep reinforcement learning methods by applying different components to modify architecture of reinforcement learning with use of noisy layers, prioritized replay, bagging, duelling networks, and other related combination to obtain improvement in terms of performance and reduction of computational cost. The paper identifies problem of resource allocation in uncertain environment could be effectively solved using Noisy Bagging duelling double deep Q network achieving efficiency of 97.7% by maximizing reward with significant exploration in given simulated environment for resource allocation.",
        "published": "2021-06-17T13:13:34Z",
        "link": "http://arxiv.org/abs/2106.09461v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "cs.RO",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Simulation study on the fleet performance of shared autonomous bicycles",
        "authors": [
            "Naroa Coretti Sánchez",
            "Iñigo Martinez",
            "Luis Alonso Pastor",
            "Kent Larson"
        ],
        "summary": "Rethinking cities is now more imperative than ever, as society faces global challenges such as population growth and climate change. The design of cities can not be abstracted from the design of its mobility system, and, therefore, efficient solutions must be found to transport people and goods throughout the city in an ecological way. An autonomous bicycle-sharing system would combine the most relevant benefits of vehicle sharing, electrification, autonomy, and micro-mobility, increasing the efficiency and convenience of bicycle-sharing systems and incentivizing more people to bike and enjoy their cities in an environmentally friendly way. Due to the uniqueness and radical novelty of introducing autonomous driving technology into bicycle-sharing systems and the inherent complexity of these systems, there is a need to quantify the potential impact of autonomy on fleet performance and user experience. This paper presents an ad-hoc agent-based simulator that provides an in-depth understanding of the fleet behavior of autonomous bicycle-sharing systems in realistic scenarios, including a rebalancing system based on demand prediction. In addition, this work describes the impact of different parameters on system efficiency and service quality and quantifies the extent to which an autonomous system would outperform current bicycle-sharing schemes. The obtained results show that with a fleet size three and a half times smaller than a station-based system and eight times smaller than a dockless system, an autonomous system can provide overall improved performance and user experience even with no rebalancing. These findings indicate that the remarkable efficiency of an autonomous bicycle-sharing system could compensate for the additional cost of autonomous bicycles.",
        "published": "2021-06-17T17:47:08Z",
        "link": "http://arxiv.org/abs/2106.09694v2",
        "categories": [
            "cs.CY",
            "cs.MA"
        ]
    },
    {
        "title": "Optimizing robotic swarm based construction tasks",
        "authors": [
            "Teshan Liyanage",
            "Subha Fernando"
        ],
        "summary": "Social insects in nature such as ants, termites and bees construct their colonies collaboratively in a very efficient process. In these swarms, each insect contributes to the construction task individually showing redundant and parallel behavior of individual entities. But the robotics adaptations of these swarm's behaviors haven't yet made it to the real world at a large enough scale of commonly being used due to the limitations in the existing approaches to the swarm robotics construction. This paper presents an approach that combines the existing swarm construction approaches which results in a swarm robotic system, capable of constructing a given 2 dimensional shape in an optimized manner.",
        "published": "2021-06-17T18:07:01Z",
        "link": "http://arxiv.org/abs/2106.09749v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Many Agent Reinforcement Learning Under Partial Observability",
        "authors": [
            "Keyang He",
            "Prashant Doshi",
            "Bikramjit Banerjee"
        ],
        "summary": "Recent renewed interest in multi-agent reinforcement learning (MARL) has generated an impressive array of techniques that leverage deep reinforcement learning, primarily actor-critic architectures, and can be applied to a limited range of settings in terms of observability and communication. However, a continuing limitation of much of this work is the curse of dimensionality when it comes to representations based on joint actions, which grow exponentially with the number of agents. In this paper, we squarely focus on this challenge of scalability. We apply the key insight of action anonymity, which leads to permutation invariance of joint actions, to two recently presented deep MARL algorithms, MADDPG and IA2C, and compare these instantiations to another recent technique that leverages action anonymity, viz., mean-field MARL. We show that our instantiations can learn the optimal behavior in a broader class of agent networks than the mean-field method, using a recently introduced pragmatic domain.",
        "published": "2021-06-17T21:24:29Z",
        "link": "http://arxiv.org/abs/2106.09825v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Meta-control of social learning strategies",
        "authors": [
            "Anil Yaman",
            "Nicolas Bredeche",
            "Onur Çaylak",
            "Joel Z. Leibo",
            "Sang Wan Lee"
        ],
        "summary": "Social learning, copying other's behavior without actual experience, offers a cost-effective means of knowledge acquisition. However, it raises the fundamental question of which individuals have reliable information: successful individuals versus the majority. The former and the latter are known respectively as success-based and conformist social learning strategies. We show here that while the success-based strategy fully exploits the benign environment of low uncertainly, it fails in uncertain environments. On the other hand, the conformist strategy can effectively mitigate this adverse effect. Based on these findings, we hypothesized that meta-control of individual and social learning strategies provides effective and sample-efficient learning in volatile and uncertain environments. Simulations on a set of environments with various levels of volatility and uncertainty confirmed our hypothesis. The results imply that meta-control of social learning affords agents the leverage to resolve environmental uncertainty with minimal exploration cost, by exploiting others' learning as an external knowledge base.",
        "published": "2021-06-18T09:17:21Z",
        "link": "http://arxiv.org/abs/2106.10015v2",
        "categories": [
            "cs.SI",
            "cs.AI",
            "cs.MA",
            "cs.NE"
        ]
    },
    {
        "title": "Towards Distraction-Robust Active Visual Tracking",
        "authors": [
            "Fangwei Zhong",
            "Peng Sun",
            "Wenhan Luo",
            "Tingyun Yan",
            "Yizhou Wang"
        ],
        "summary": "In active visual tracking, it is notoriously difficult when distracting objects appear, as distractors often mislead the tracker by occluding the target or bringing a confusing appearance. To address this issue, we propose a mixed cooperative-competitive multi-agent game, where a target and multiple distractors form a collaborative team to play against a tracker and make it fail to follow. Through learning in our game, diverse distracting behaviors of the distractors naturally emerge, thereby exposing the tracker's weakness, which helps enhance the distraction-robustness of the tracker. For effective learning, we then present a bunch of practical methods, including a reward function for distractors, a cross-modal teacher-student learning strategy, and a recurrent attention mechanism for the tracker. The experimental results show that our tracker performs desired distraction-robust active visual tracking and can be well generalized to unseen environments. We also show that the multi-agent game can be used to adversarially test the robustness of trackers.",
        "published": "2021-06-18T13:05:25Z",
        "link": "http://arxiv.org/abs/2106.10110v1",
        "categories": [
            "cs.CV",
            "cs.AI",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Equilibrium Design for Concurrent Games",
        "authors": [
            "Julian Gutierrez",
            "Muhammad Najib",
            "Giuseppe Perelli",
            "Michael Wooldridge"
        ],
        "summary": "In game theory, mechanism design is concerned with the design of incentives so that a desired outcome of the game can be achieved. In this paper, we study the design of incentives so that a desirable equilibrium is obtained, for instance, an equilibrium satisfying a given temporal logic property -- a problem that we call equilibrium design. We base our study on a framework where system specifications are represented as temporal logic formulae, games as quantitative concurrent game structures, and players' goals as mean-payoff objectives. In particular, we consider system specifications given by LTL and GR(1) formulae, and show that implementing a mechanism to ensure that a given temporal logic property is satisfied on some/every Nash equilibrium of the game, whenever such a mechanism exists, can be done in PSPACE for LTL properties and in NP/$\\Sigma^{P}_{2}$ for GR(1) specifications. We also study the complexity of various related decision and optimisation problems, such as optimality and uniqueness of solutions, and show that the complexities of all such problems lie within the polynomial hierarchy. As an application, equilibrium design can be used as an alternative solution to the rational synthesis and verification problems for concurrent games with mean-payoff objectives whenever no solution exists, or as a technique to repair, whenever possible, concurrent games with undesirable rational outcomes (Nash equilibria) in an optimal way.",
        "published": "2021-06-18T15:45:45Z",
        "link": "http://arxiv.org/abs/2106.10192v1",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.LO",
            "cs.MA"
        ]
    },
    {
        "title": "Proceedings Eighteenth Conference on Theoretical Aspects of Rationality   and Knowledge",
        "authors": [
            "Joseph Halpern",
            "Andrés Perea"
        ],
        "summary": "The TARK conference (Theoretical Aspects of Rationality and Knowledge) is a biannual conference that aims to bring together researchers from a wide variety of fields, including computer science, artificial intelligence, game theory, decision theory, philosophy, logic, linguistics, and cognitive science. Its goal is to further our understanding of interdisciplinary issues involving reasoning about rationality and knowledge.   Topics of interest include, but are not limited to, semantic models for knowledge, belief, awareness and uncertainty, bounded rationality and resource-bounded reasoning, commonsense epistemic reasoning, epistemic logic, epistemic game theory, knowledge and action, applications of reasoning about knowledge and other mental states, belief revision, and foundations of multi-agent systems.   These proceedings contain the papers that have been accepted for presentation at the Eighteenth Conference on Theoretical Aspects of Rationality and Knowledge (TARK 2021), held between June 25 and June 27, 2021, at Tsinghua University at Beijing, China.",
        "published": "2021-06-21T07:01:14Z",
        "link": "http://arxiv.org/abs/2106.10886v1",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Multi-Agent Curricula and Emergent Implicit Signaling",
        "authors": [
            "Niko A. Grupen",
            "Daniel D. Lee",
            "Bart Selman"
        ],
        "summary": "Emergent communication has made strides towards learning communication from scratch, but has focused primarily on protocols that resemble human language. In nature, multi-agent cooperation gives rise to a wide range of communication that varies in structure and complexity. In this work, we recognize the full spectrum of communication that exists in nature and propose studying lower-level communication. Specifically, we study emergent implicit signaling in the context of decentralized multi-agent learning in difficult, sparse reward environments. However, learning to coordinate in such environments is challenging. We propose a curriculum-driven strategy that combines: (i) velocity-based environment shaping, tailored to the skill level of the multi-agent team; and (ii) a behavioral curriculum that helps agents learn successful single-agent behaviors as a precursor to learning multi-agent behaviors. Pursuit-evasion experiments show that our approach learns effective coordination, significantly outperforming sophisticated analytical and learned policies. Our method completes the pursuit-evasion task even when pursuers move at half of the evader's speed, whereas the highest-performing baseline fails at 80% of the evader's speed. Moreover, we examine the use of implicit signals in coordination through position-based social influence. We show that pursuers trained with our strategy exchange more than twice as much information (in bits) than baseline methods, indicating that our method has learned, and relies heavily on, the exchange of implicit signals.",
        "published": "2021-06-21T14:54:07Z",
        "link": "http://arxiv.org/abs/2106.11156v3",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Cogment: Open Source Framework For Distributed Multi-actor Training,   Deployment & Operations",
        "authors": [
            "AI Redefined",
            "Sai Krishna Gottipati",
            "Sagar Kurandwad",
            "Clodéric Mars",
            "Gregory Szriftgiser",
            "François Chabot"
        ],
        "summary": "Involving humans directly for the benefit of AI agents' training is getting traction thanks to several advances in reinforcement learning and human-in-the-loop learning. Humans can provide rewards to the agent, demonstrate tasks, design a curriculum, or act in the environment, but these benefits also come with architectural, functional design and engineering complexities. We present Cogment, a unifying open-source framework that introduces an actor formalism to support a variety of humans-agents collaboration typologies and training approaches. It is also scalable out of the box thanks to a distributed micro service architecture, and offers solutions to the aforementioned complexities.",
        "published": "2021-06-21T18:21:26Z",
        "link": "http://arxiv.org/abs/2106.11345v1",
        "categories": [
            "cs.AI",
            "cs.HC",
            "cs.LG",
            "cs.MA",
            "I.2; I.2.11; D.2.11"
        ]
    },
    {
        "title": "Distributed Heuristic Multi-Agent Path Finding with Communication",
        "authors": [
            "Ziyuan Ma",
            "Yudong Luo",
            "Hang Ma"
        ],
        "summary": "Multi-Agent Path Finding (MAPF) is essential to large-scale robotic systems. Recent methods have applied reinforcement learning (RL) to learn decentralized polices in partially observable environments. A fundamental challenge of obtaining collision-free policy is that agents need to learn cooperation to handle congested situations. This paper combines communication with deep Q-learning to provide a novel learning based method for MAPF, where agents achieve cooperation via graph convolution. To guide RL algorithm on long-horizon goal-oriented tasks, we embed the potential choices of shortest paths from single source as heuristic guidance instead of using a specific path as in most existing works. Our method treats each agent independently and trains the model from a single agent's perspective. The final trained policy is applied to each agent for decentralized execution. The whole system is distributed during training and is trained under a curriculum learning strategy. Empirical evaluation in obstacle-rich environment indicates the high success rate with low average step of our method.",
        "published": "2021-06-21T18:50:58Z",
        "link": "http://arxiv.org/abs/2106.11365v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "A Competitive Analysis of Online Multi-Agent Path Finding",
        "authors": [
            "Hang Ma"
        ],
        "summary": "We study online Multi-Agent Path Finding (MAPF), where new agents are constantly revealed over time and all agents must find collision-free paths to their given goal locations. We generalize existing complexity results of (offline) MAPF to online MAPF. We classify online MAPF algorithms into different categories based on (1) controllability (the set of agents that they can plan paths for at each time) and (2) rationality (the quality of paths they plan) and study the relationships between them. We perform a competitive analysis for each category of online MAPF algorithms with respect to commonly-used objective functions. We show that a naive algorithm that routes newly-revealed agents one at a time in sequence achieves a competitive ratio that is asymptotically bounded from both below and above by the number of agents with respect to flowtime and makespan. We then show a counter-intuitive result that, if rerouting of previously-revealed agents is not allowed, any rational online MAPF algorithms, including ones that plan optimal paths for all newly-revealed agents, have the same asymptotic competitive ratio as the naive algorithm, even on 2D 4-neighbor grids. We also derive constant lower bounds on the competitive ratio of any rational online MAPF algorithms that allow rerouting. The results thus provide theoretical insights into the effectiveness of using MAPF algorithms in an online setting for the first time.",
        "published": "2021-06-22T00:05:29Z",
        "link": "http://arxiv.org/abs/2106.11454v1",
        "categories": [
            "cs.AI",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Uncertainty-Based Semantics for Multi-Agent Knowing How Logics",
        "authors": [
            "Carlos Areces",
            "Raul Fervari",
            "Andrés R. Saravia",
            "Fernando R. Velázquez-Quesada"
        ],
        "summary": "We introduce a new semantics for a multi-agent epistemic operator of knowing how, based on an indistinguishability relation between plans. Our proposal is, arguably, closer to the standard presentation of knowing that modalities in classical epistemic logic. We study the relationship between this semantics and previous approaches, showing that our setting is general enough to capture them. We also define a sound and complete axiomatization, and investigate the computational complexity of its model checking and satisfiability problems.",
        "published": "2021-06-22T02:44:09Z",
        "link": "http://arxiv.org/abs/2106.11492v1",
        "categories": [
            "cs.LO",
            "cs.MA",
            "F.4.1"
        ]
    },
    {
        "title": "Fire!",
        "authors": [
            "Krisztina Fruzsa",
            "Roman Kuznets",
            "Ulrich Schmid"
        ],
        "summary": "In this paper, we provide an epistemic analysis of a simple variant of the fundamental consistent broadcasting primitive for byzantine fault-tolerant asynchronous distributed systems. Our Firing Rebels with Relay (FRR) primitive enables agents with a local preference for acting/not acting to trigger an action (FIRE) at all correct agents, in an all-or-nothing fashion. By using the epistemic reasoning framework for byzantine multi-agent systems introduced in our TARK'19 paper, we develop the necessary and sufficient state of knowledge that needs to be acquired by the agents in order to FIRE. It involves eventual common hope (a modality related to belief), which we show to be attained already by achieving eventual mutual hope in the case of FRR. We also identify subtle variations of the necessary and sufficient state of knowledge for FRR for different assumptions on the local preferences.",
        "published": "2021-06-22T02:45:51Z",
        "link": "http://arxiv.org/abs/2106.11499v1",
        "categories": [
            "cs.DC",
            "cs.LO",
            "cs.MA"
        ]
    },
    {
        "title": "Are the Players in an Interactive Belief Model Meta-certain of the Model   Itself?",
        "authors": [
            "Satoshi Fukuda"
        ],
        "summary": "In an interactive belief model, are the players \"commonly meta-certain\" of the model itself? This paper formalizes such implicit \"common meta-certainty\" assumption. To that end, the paper expands the objects of players' beliefs from events to functions defined on the underlying states. Then, the paper defines a player's belief-generating map: it associates, with each state, whether a player believes each event at that state. The paper formalizes what it means by: \"a player is (meta-)certain of her own belief-generating map\" or \"the players are (meta-)certain of the profile of belief-generating maps (i.e., the model).\" The paper shows: a player is (meta-)certain of her own belief-generating map if and only if her beliefs are introspective. The players are commonly (meta-)certain of the model if and only if, for any event which some player i believes at some state, it is common belief at the state that player i believes the event. This paper then asks whether the \"common meta-certainty\" assumption is needed for an epistemic characterization of game-theoretic solution concepts. The paper shows: if each player is logical and (meta-)certain of her own strategy and belief-generating map, then each player correctly believes her own rationality. Consequently, common belief in rationality alone leads to actions that survive iterated elimination of strictly dominated actions.",
        "published": "2021-06-22T02:46:07Z",
        "link": "http://arxiv.org/abs/2106.11500v1",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Measuring Violations of Positive Involvement in Voting",
        "authors": [
            "Wesley H. Holliday",
            "Eric Pacuit"
        ],
        "summary": "In the context of computational social choice, we study voting methods that assign a set of winners to each profile of voter preferences. A voting method satisfies the property of positive involvement (PI) if for any election in which a candidate x would be among the winners, adding another voter to the election who ranks x first does not cause x to lose. Surprisingly, a number of standard voting methods violate this natural property. In this paper, we investigate different ways of measuring the extent to which a voting method violates PI, using computer simulations. We consider the probability (under different probability models for preferences) of PI violations in randomly drawn profiles vs. profile-coalition pairs (involving coalitions of different sizes). We argue that in order to choose between a voting method that satisfies PI and one that does not, we should consider the probability of PI violation conditional on the voting methods choosing different winners. We should also relativize the probability of PI violation to what we call voter potency, the probability that a voter causes a candidate to lose. Although absolute frequencies of PI violations may be low, after this conditioning and relativization, we see that under certain voting methods that violate PI, much of a voter's potency is turned against them - in particular, against their desire to see their favorite candidate elected.",
        "published": "2021-06-22T02:46:37Z",
        "link": "http://arxiv.org/abs/2106.11502v1",
        "categories": [
            "cs.GT",
            "cs.MA",
            "econ.TH",
            "I.2.11"
        ]
    },
    {
        "title": "Game-Theoretic Models of Moral and Other-Regarding Agents (extended   abstract)",
        "authors": [
            "Gabriel Istrate"
        ],
        "summary": "We investigate Kantian equilibria in finite normal form games, a class of non-Nashian, morally motivated courses of action that was recently proposed in the economics literature. We highlight a number of problems with such equilibria, including computational intractability, a high price of miscoordination, and problematic extension to general normal form games. We give such a generalization based on concept of program equilibria, and point out that that a practically relevant generalization may not exist. To remedy this we propose some general, intuitive, computationally tractable, other-regarding equilibria that are special cases Kantian equilibria, as well as a class of courses of action that interpolates between purely self-regarding and Kantian behavior.",
        "published": "2021-06-22T02:46:52Z",
        "link": "http://arxiv.org/abs/2106.11503v1",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.MA",
            "cs.SI"
        ]
    },
    {
        "title": "A Deontic Stit Logic Based on Beliefs and Expected Utility",
        "authors": [
            "Aldo Iván Ramírez Abarca",
            "Jan Broersen"
        ],
        "summary": "The formalization of action and obligation using logic languages is a topic of increasing relevance in the field of ethics for AI. Having an expressive syntactic and semantic framework to reason about agents' decisions in moral situations allows for unequivocal representations of components of behavior that are relevant when assigning blame (or praise) of outcomes to said agents. Two very important components of behavior in this respect are belief and belief-based action. In this work we present a logic of doxastic oughts by extending epistemic deontic stit theory with beliefs. On one hand, the semantics for formulas involving belief operators is based on probability measures. On the other, the semantics for doxastic oughts relies on a notion of optimality, and the underlying choice rule is maximization of expected utility. We introduce an axiom system for the resulting logic, and we address its soundness, completeness, and decidability results. These results are significant in the line of research that intends to use proof systems of epistemic, doxastic, and deontic logics to help in the testing of ethical behavior of AI through theorem-proving and model-checking.",
        "published": "2021-06-22T02:47:43Z",
        "link": "http://arxiv.org/abs/2106.11506v1",
        "categories": [
            "cs.LO",
            "cs.MA"
        ]
    },
    {
        "title": "MMD-MIX: Value Function Factorisation with Maximum Mean Discrepancy for   Cooperative Multi-Agent Reinforcement Learning",
        "authors": [
            "Zhiwei Xu",
            "Dapeng Li",
            "Yunpeng Bai",
            "Guoliang Fan"
        ],
        "summary": "In the real world, many tasks require multiple agents to cooperate with each other under the condition of local observations. To solve such problems, many multi-agent reinforcement learning methods based on Centralized Training with Decentralized Execution have been proposed. One representative class of work is value decomposition, which decomposes the global joint Q-value $Q_\\text{jt}$ into individual Q-values $Q_a$ to guide individuals' behaviors, e.g. VDN (Value-Decomposition Networks) and QMIX. However, these baselines often ignore the randomness in the situation. We propose MMD-MIX, a method that combines distributional reinforcement learning and value decomposition to alleviate the above weaknesses. Besides, to improve data sampling efficiency, we were inspired by REM (Random Ensemble Mixture) which is a robust RL algorithm to explicitly introduce randomness into the MMD-MIX. The experiments demonstrate that MMD-MIX outperforms prior baselines in the StarCraft Multi-Agent Challenge (SMAC) environment.",
        "published": "2021-06-22T10:21:00Z",
        "link": "http://arxiv.org/abs/2106.11652v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Group mixing drives inequality in face-to-face gatherings",
        "authors": [
            "Marcos Oliveira",
            "Fariba Karimi",
            "Maria Zens",
            "Johann Schaible",
            "Mathieu Génois",
            "Markus Strohmaier"
        ],
        "summary": "Uncovering how inequality emerges from human interaction is imperative for just societies. Here we show that the way social groups interact in face-to-face situations can enable the emergence of disparities in the visibility of social groups. These disparities translate into members of specific social groups having fewer social ties than the average (i.e., degree inequality). We characterize group degree inequality in sensor-based data sets and present a mechanism that explains these disparities as the result of group mixing and group-size imbalance. We investigate how group sizes affect this inequality, thereby uncovering the critical size and mixing conditions in that a critical minority group emerges. If a minority group is larger than this critical size, it can be a well-connected, cohesive group; if it is smaller, minority cohesion widens degree inequality. Finally, we expose the under-representation of individuals in degree rankings due to mixing dynamics and propose a way to reduce such biases.",
        "published": "2021-06-22T11:44:02Z",
        "link": "http://arxiv.org/abs/2106.11688v2",
        "categories": [
            "physics.soc-ph",
            "cs.CY",
            "cs.MA",
            "cs.SI"
        ]
    },
    {
        "title": "Introducing endogenous transport provision in a LUTI model to explore   polycentric governance systems",
        "authors": [
            "Juste Raimbault",
            "Florent Le Néchet"
        ],
        "summary": "Models focusing on interactions between land-use and transportation mostly assume an exogenous provision of transportation infrastructures. We investigate here co-evolutionary processes between land-use and transportation, at the scale of Mega-City Regions, by introducing a toy model of corresponding processes. In particular, our model is specifically tailored to include governance processes ruling the growth of transportation infrastructure. We show through stylised numerical simulations the potentialities of our model to reproduce a variety of dynamics when co-evolution is taken into account. We then apply the model to a case study, by calibrating it for the Pearl River Delta Mega-city Region (China, 1990-2010). To go beyond this first modelling step, we elaborate on the challenges to overcome to go further towards more complex models integrating co-evolution between transportation networks and territories in urban systems.",
        "published": "2021-06-22T18:10:14Z",
        "link": "http://arxiv.org/abs/2106.11996v1",
        "categories": [
            "physics.soc-ph",
            "cs.MA"
        ]
    },
    {
        "title": "Active Exploitation of Redundancies in Reconfigurable Multi-Robot   Systems",
        "authors": [
            "Thomas M. Roehr"
        ],
        "summary": "While traditional robotic systems come with a monolithic system design, reconfigurable multi-robot systems can share and shift physical resources in an on-demand fashion. Multi-robot operations can benefit from this flexibility by actively managing system redundancies depending on current tasks and having more options to respond to failure events. To support this active exploitation of redundancies in robotic systems, this paper details an organization model as basis for planning with reconfigurable multi-robot systems. The model allows to exploit redundancies when optimizing a multi-robot system's probability of survival with respect to a desired mission. The resulting planning approach trades safety against efficiency in robotic operations and thereby offers a new perspective and tool to design and improve multi-robot missions. We use a simulated multi-robot planetary exploration mission to evaluate this approach and highlight an exemplary performance landscape.",
        "published": "2021-06-22T22:09:57Z",
        "link": "http://arxiv.org/abs/2106.12079v1",
        "categories": [
            "cs.RO",
            "cs.MA",
            "I.2.9; I.2.11; B.2.3"
        ]
    },
    {
        "title": "Robust Task Scheduling for Heterogeneous Robot Teams under Capability   Uncertainty",
        "authors": [
            "Bo Fu",
            "William Smith",
            "Denise Rizzo",
            "Matthew Castanier",
            "Maani Ghaffari",
            "Kira Barton"
        ],
        "summary": "This paper develops a stochastic programming framework for multi-agent systems where task decomposition, assignment, and scheduling problems are simultaneously optimized. The framework can be applied to heterogeneous mobile robot teams with distributed sub-tasks. Examples include pandemic robotic service coordination, explore and rescue, and delivery systems with heterogeneous vehicles. Due to their inherent flexibility and robustness, multi-agent systems are applied in a growing range of real-world problems that involve heterogeneous tasks and uncertain information. Most previous works assume one fixed way to decompose a task into roles that can later be assigned to the agents. This assumption is not valid for a complex task where the roles can vary and multiple decomposition structures exist. Meanwhile, it is unclear how uncertainties in task requirements and agent capabilities can be systematically quantified and optimized under a multi-agent system setting. A representation for complex tasks is proposed: agent capabilities are represented as a vector of random distributions, and task requirements are verified by a generalizable binary function. The conditional value at risk (CVaR) is chosen as a metric in the objective function to generate robust plans. An efficient algorithm is described to solve the model, and the whole framework is evaluated in two different practical test cases: capture-the-flag and robotic service coordination during a pandemic (e.g., COVID-19). Results demonstrate that the framework is generalizable, scalable up to 140 agents and 40 tasks for the example test cases, and provides low-cost plans that ensure a high probability of success.",
        "published": "2021-06-23T00:57:53Z",
        "link": "http://arxiv.org/abs/2106.12111v3",
        "categories": [
            "cs.RO",
            "cs.MA",
            "93A16"
        ]
    },
    {
        "title": "From Griefing to Stability in Blockchain Mining Economies",
        "authors": [
            "Yun Kuen Cheung",
            "Stefanos Leonardos",
            "Georgios Piliouras",
            "Shyam Sridhar"
        ],
        "summary": "We study a game-theoretic model of blockchain mining economies and show that griefing, a practice according to which participants harm other participants at some lesser cost to themselves, is a prevalent threat at its Nash equilibria. The proof relies on a generalization of evolutionary stability to non-homogeneous populations via griefing factors (ratios that measure network losses relative to deviator's own losses) which leads to a formal theoretical argument for the dissipation of resources, consolidation of power and high entry barriers that are currently observed in practice.   A critical assumption in this type of analysis is that miners' decisions have significant influence in aggregate network outcomes (such as network hashrate). However, as networks grow larger, the miner's interaction more closely resembles a distributed production economy or Fisher market and its stability properties change. In this case, we derive a proportional response (PR) update protocol which converges to market equilibria at which griefing is irrelevant. Convergence holds for a wide range of miners risk profiles and various degrees of resource mobility between blockchains with different mining technologies. Our empirical findings in a case study with four mineable cryptocurrencies suggest that risk diversification, restricted mobility of resources (as enforced by different mining technologies) and network growth, all are contributing factors to the stability of the inherently volatile blockchain ecosystem.",
        "published": "2021-06-23T11:54:26Z",
        "link": "http://arxiv.org/abs/2106.12332v1",
        "categories": [
            "cs.GT",
            "cs.DC",
            "cs.MA",
            "econ.TH",
            "math.DS",
            "91B54, 91B55, 91A22, 91A26, 91-10,"
        ]
    },
    {
        "title": "Smart Healthcare in the Age of AI: Recent Advances, Challenges, and   Future Prospects",
        "authors": [
            "Mahmoud Nasr",
            "MD. Milon Islam",
            "Shady Shehata",
            "Fakhri Karray",
            "Yuri Quintana"
        ],
        "summary": "The significant increase in the number of individuals with chronic ailments (including the elderly and disabled) has dictated an urgent need for an innovative model for healthcare systems. The evolved model will be more personalized and less reliant on traditional brick-and-mortar healthcare institutions such as hospitals, nursing homes, and long-term healthcare centers. The smart healthcare system is a topic of recently growing interest and has become increasingly required due to major developments in modern technologies, especially in artificial intelligence (AI) and machine learning (ML). This paper is aimed to discuss the current state-of-the-art smart healthcare systems highlighting major areas like wearable and smartphone devices for health monitoring, machine learning for disease diagnosis, and the assistive frameworks, including social robots developed for the ambient assisted living environment. Additionally, the paper demonstrates software integration architectures that are very significant to create smart healthcare systems, integrating seamlessly the benefit of data analytics and other tools of AI. The explained developed systems focus on several facets: the contribution of each developed framework, the detailed working procedure, the performance as outcomes, and the comparative merits and limitations. The current research challenges with potential future directions are addressed to highlight the drawbacks of existing systems and the possible methods to introduce novel frameworks, respectively. This review aims at providing comprehensive insights into the recent developments of smart healthcare systems to equip experts to contribute to the field.",
        "published": "2021-06-24T05:10:47Z",
        "link": "http://arxiv.org/abs/2107.03924v1",
        "categories": [
            "cs.CY",
            "cs.AI",
            "cs.HC",
            "cs.MA",
            "cs.NI"
        ]
    },
    {
        "title": "Awareness Logic: Kripke Lattices as a Middle Ground between Syntactic   and Semantic Models",
        "authors": [
            "Gaia Belardinelli",
            "Rasmus K. Rendsvig"
        ],
        "summary": "The literature on awareness modeling includes both syntax-free and syntax-based frameworks. Heifetz, Meier \\& Schipper (HMS) propose a lattice model of awareness that is syntax-free. While their lattice approach is elegant and intuitive, it precludes the simple option of relying on formal language to induce lattices, and does not explicitly distinguish uncertainty from unawareness. Contra this, the most prominent syntax-based solution, the Fagin-Halpern (FH) model, accounts for this distinction and offers a simple representation of awareness, but lacks the intuitiveness of the lattice structure. Here, we combine these two approaches by providing a lattice of Kripke models, induced by atom subset inclusion, in which uncertainty and unawareness are separate. We show our model equivalent to both HMS and FH models by defining transformations between them which preserve satisfaction of formulas of a language for explicit knowledge, and obtain completeness through our and HMS' results. Lastly, we prove that the Kripke lattice model can be shown equivalent to the FH model (when awareness is propositionally determined) also with respect to the language of the Logic of General Awareness, for which the FH model where originally proposed.",
        "published": "2021-06-24T10:04:44Z",
        "link": "http://arxiv.org/abs/2106.12868v1",
        "categories": [
            "cs.AI",
            "cs.LO",
            "cs.MA",
            "econ.TH",
            "math.LO"
        ]
    },
    {
        "title": "Exploration-Exploitation in Multi-Agent Competition: Convergence with   Bounded Rationality",
        "authors": [
            "Stefanos Leonardos",
            "Georgios Piliouras",
            "Kelly Spendlove"
        ],
        "summary": "The interplay between exploration and exploitation in competitive multi-agent learning is still far from being well understood. Motivated by this, we study smooth Q-learning, a prototypical learning model that explicitly captures the balance between game rewards and exploration costs. We show that Q-learning always converges to the unique quantal-response equilibrium (QRE), the standard solution concept for games under bounded rationality, in weighted zero-sum polymatrix games with heterogeneous learning agents using positive exploration rates. Complementing recent results about convergence in weighted potential games, we show that fast convergence of Q-learning in competitive settings is obtained regardless of the number of agents and without any need for parameter fine-tuning. As showcased by our experiments in network zero-sum games, these theoretical results provide the necessary guarantees for an algorithmic approach to the currently open problem of equilibrium selection in competitive multi-agent settings.",
        "published": "2021-06-24T11:43:38Z",
        "link": "http://arxiv.org/abs/2106.12928v1",
        "categories": [
            "cs.GT",
            "cs.LG",
            "cs.MA",
            "econ.TH",
            "math.DS",
            "93A16, 91A26, 91A68",
            "G.3; J.4; F.2.2"
        ]
    },
    {
        "title": "Factor Graphs for Heterogeneous Bayesian Decentralized Data Fusion",
        "authors": [
            "Ofer Dagan",
            "Nisar R. Ahmed"
        ],
        "summary": "This paper explores the use of factor graphs as an inference and analysis tool for Bayesian peer-to-peer decentralized data fusion. We propose a framework by which agents can each use local factor graphs to represent relevant partitions of a complex global joint probability distribution, thus allowing them to avoid reasoning over the entirety of a more complex model and saving communication as well as computation cost. This allows heterogeneous multi-robot systems to cooperate on a variety of real world, task oriented missions, where scalability and modularity are key. To develop the initial theory and analyze the limits of this approach, we focus our attention on static linear Gaussian systems in tree-structured networks and use Channel Filters (also represented by factor graphs) to explicitly track common information. We discuss how this representation can be used to describe various multi-robot applications and to design and analyze new heterogeneous data fusion algorithms. We validate our method in simulations of a multi-agent multi-target tracking and cooperative multi-agent mapping problems, and discuss the computation and communication gains of this approach.",
        "published": "2021-06-24T19:18:14Z",
        "link": "http://arxiv.org/abs/2106.13285v1",
        "categories": [
            "cs.RO",
            "cs.MA",
            "eess.SP"
        ]
    },
    {
        "title": "Scalable Perception-Action-Communication Loops with Convolutional and   Graph Neural Networks",
        "authors": [
            "Ting-Kuei Hu",
            "Fernando Gama",
            "Tianlong Chen",
            "Wenqing Zheng",
            "Zhangyang Wang",
            "Alejandro Ribeiro",
            "Brian M. Sadler"
        ],
        "summary": "In this paper, we present a perception-action-communication loop design using Vision-based Graph Aggregation and Inference (VGAI). This multi-agent decentralized learning-to-control framework maps raw visual observations to agent actions, aided by local communication among neighboring agents. Our framework is implemented by a cascade of a convolutional and a graph neural network (CNN / GNN), addressing agent-level visual perception and feature learning, as well as swarm-level communication, local information aggregation and agent action inference, respectively. By jointly training the CNN and GNN, image features and communication messages are learned in conjunction to better address the specific task. We use imitation learning to train the VGAI controller in an offline phase, relying on a centralized expert controller. This results in a learned VGAI controller that can be deployed in a distributed manner for online execution. Additionally, the controller exhibits good scaling properties, with training in smaller teams and application in larger teams. Through a multi-agent flocking application, we demonstrate that VGAI yields performance comparable to or better than other decentralized controllers, using only the visual input modality and without accessing precise location or motion state information.",
        "published": "2021-06-24T23:57:21Z",
        "link": "http://arxiv.org/abs/2106.13358v2",
        "categories": [
            "cs.RO",
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "eess.SP",
            "eess.SY"
        ]
    },
    {
        "title": "Policy Regularization via Noisy Advantage Values for Cooperative   Multi-agent Actor-Critic methods",
        "authors": [
            "Jian Hu",
            "Siyue Hu",
            "Shih-wei Liao"
        ],
        "summary": "Recent works have applied the Proximal Policy Optimization (PPO) to the multi-agent cooperative tasks, such as Independent PPO (IPPO); and vanilla Multi-agent PPO (MAPPO) which has a centralized value function. However, previous literature shows that MAPPO may not perform as well as Independent PPO (IPPO) and the Fine-tuned QMIX on Starcraft Multi-Agent Challenge (SMAC). MAPPO-Feature-Pruned (MAPPO-FP) improves the performance of MAPPO by the carefully designed agent-specific features, which may be not friendly to algorithmic utility. By contrast, we find that MAPPO may face the problem of \\textit{The Policies Overfitting in Multi-agent Cooperation(POMAC)}, as they learn policies by the sampled advantage values. Then POMAC may lead to updating the multi-agent policies in a suboptimal direction and prevent the agents from exploring better trajectories. In this paper, to mitigate the multi-agent policies overfitting, we propose a novel policy regularization method, which disturbs the advantage values via random Gaussian noise. The experimental results show that our method outperforms the Fine-tuned QMIX, MAPPO-FP, and achieves SOTA on SMAC without agent-specific features. We open-source the code at \\url{https://github.com/hijkzzz/noisy-mappo}.",
        "published": "2021-06-27T22:50:35Z",
        "link": "http://arxiv.org/abs/2106.14334v14",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Kimera-Multi: Robust, Distributed, Dense Metric-Semantic SLAM for   Multi-Robot Systems",
        "authors": [
            "Yulun Tian",
            "Yun Chang",
            "Fernando Herrera Arias",
            "Carlos Nieto-Granda",
            "Jonathan P. How",
            "Luca Carlone"
        ],
        "summary": "This paper presents Kimera-Multi, the first multi-robot system that (i) is robust and capable of identifying and rejecting incorrect inter and intra-robot loop closures resulting from perceptual aliasing, (ii) is fully distributed and only relies on local (peer-to-peer) communication to achieve distributed localization and mapping, and (iii) builds a globally consistent metric-semantic 3D mesh model of the environment in real-time, where faces of the mesh are annotated with semantic labels. Kimera-Multi is implemented by a team of robots equipped with visual-inertial sensors. Each robot builds a local trajectory estimate and a local mesh using Kimera. When communication is available, robots initiate a distributed place recognition and robust pose graph optimization protocol based on a novel distributed graduated non-convexity algorithm. The proposed protocol allows the robots to improve their local trajectory estimates by leveraging inter-robot loop closures while being robust to outliers. Finally, each robot uses its improved trajectory estimate to correct the local mesh using mesh deformation techniques.   We demonstrate Kimera-Multi in photo-realistic simulations, SLAM benchmarking datasets, and challenging outdoor datasets collected using ground robots. Both real and simulated experiments involve long trajectories (e.g., up to 800 meters per robot). The experiments show that Kimera-Multi (i) outperforms the state of the art in terms of robustness and accuracy, (ii) achieves estimation errors comparable to a centralized SLAM system while being fully distributed, (iii) is parsimonious in terms of communication bandwidth, (iv) produces accurate metric-semantic 3D meshes, and (v) is modular and can be also used for standard 3D reconstruction (i.e., without semantic labels) or for trajectory estimation (i.e., without reconstructing a 3D mesh).",
        "published": "2021-06-28T03:56:40Z",
        "link": "http://arxiv.org/abs/2106.14386v2",
        "categories": [
            "cs.RO",
            "cs.CV",
            "cs.MA"
        ]
    },
    {
        "title": "Approximately Envy-Free Budget-Feasible Allocation",
        "authors": [
            "Jiarui Gan",
            "Bo Li",
            "Xiaowei Wu"
        ],
        "summary": "In the budget-feasible allocation problem, a set of items with varied sizes and values are to be allocated to a group of agents. Each agent has a budget constraint on the total size of items she can receive. The goal is to compute a feasible allocation that is envy-free (EF), in which the agents do not envy each other for the items they receive, nor do they envy a charity, who is endowed with all the unallocated items. Since EF allocations barely exist even without budget constraints, we are interested in the relaxed notion of envy-freeness up to one item (EF1). The computation of both exact and approximate EF1 allocations remains largely open, despite a recent effort by Wu et al. (IJCAI 2021) in showing that any budget-feasible allocation that maximizes the Nash Social Welfare (NSW) is 1/4-approximate EF1. In this paper, we move one step forward by showing that for agents with identical additive valuations, a 1/2-approximate EF1 allocation can be computed in polynomial time. For the uniform-budget and two-agent cases, we propose efficient algorithms for computing an exact EF1 allocation. We also consider the large budget setting, i.e., when the item sizes are infinitesimal compared with the agents' budgets, and show that both the NSW maximizing allocation and the allocation our polynomial-time algorithm computes have an approximation close to 1 regarding EF1.",
        "published": "2021-06-28T07:57:19Z",
        "link": "http://arxiv.org/abs/2106.14446v1",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Dynamic Urban Planning: an Agent-Based Model Coupling Mobility Mode and   Housing Choice. Use case Kendall Square",
        "authors": [
            "Mireia Yurrita",
            "Arnaud Grignard",
            "Luis Alonso",
            "Yan Zhang",
            "Cristian Jara-Figueroa",
            "Markus Elkatsha",
            "Kent Larson"
        ],
        "summary": "As cities become increasingly populated, urban planning plays a key role in ensuring the equitable and inclusive development of metropolitan areas. MIT City Science group created a data-driven tangible platform, CityScope, to help different stakeholders, such as government representatives, urban planners, developers, and citizens, collaboratively shape the urban scenario through the real-time impact analysis of different urban interventions. This paper presents an agent-based model that characterizes citizens' behavioural patterns with respect to housing and mobility choice that will constitute the first step in the development of a dynamic incentive system for an open interactive governance process. The realistic identification and representation of the criteria that affect this decision-making process will help understand and evaluate the impacts of potential housing incentives that aim to promote urban characteristics such as equality, diversity, walkability, and efficiency. The calibration and validation of the model have been performed in a well-known geographic area for the Group: Kendall Square in Cambridge, MA.",
        "published": "2021-06-28T10:54:44Z",
        "link": "http://arxiv.org/abs/2106.14572v1",
        "categories": [
            "cs.MA",
            "cs.CY"
        ]
    },
    {
        "title": "Evolutionary Dynamics and $Φ$-Regret Minimization in Games",
        "authors": [
            "Georgios Piliouras",
            "Mark Rowland",
            "Shayegan Omidshafiei",
            "Romuald Elie",
            "Daniel Hennes",
            "Jerome Connor",
            "Karl Tuyls"
        ],
        "summary": "Regret has been established as a foundational concept in online learning, and likewise has important applications in the analysis of learning dynamics in games. Regret quantifies the difference between a learner's performance against a baseline in hindsight. It is well-known that regret-minimizing algorithms converge to certain classes of equilibria in games; however, traditional forms of regret used in game theory predominantly consider baselines that permit deviations to deterministic actions or strategies. In this paper, we revisit our understanding of regret from the perspective of deviations over partitions of the full \\emph{mixed} strategy space (i.e., probability distributions over pure strategies), under the lens of the previously-established $\\Phi$-regret framework, which provides a continuum of stronger regret measures. Importantly, $\\Phi$-regret enables learning agents to consider deviations from and to mixed strategies, generalizing several existing notions of regret such as external, internal, and swap regret, and thus broadening the insights gained from regret-based analysis of learning algorithms. We prove here that the well-studied evolutionary learning algorithm of replicator dynamics (RD) seamlessly minimizes the strongest possible form of $\\Phi$-regret in generic $2 \\times 2$ games, without any modification of the underlying algorithm itself. We subsequently conduct experiments validating our theoretical results in a suite of 144 $2 \\times 2$ games wherein RD exhibits a diverse set of behaviors. We conclude by providing empirical evidence of $\\Phi$-regret minimization by RD in some larger games, hinting at further opportunity for $\\Phi$-regret based study of such algorithms from both a theoretical and empirical perspective.",
        "published": "2021-06-28T12:48:15Z",
        "link": "http://arxiv.org/abs/2106.14668v1",
        "categories": [
            "cs.GT",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Analysis and Control of Autonomous Mobility-on-Demand Systems",
        "authors": [
            "Gioele Zardini",
            "Nicolas Lanzetti",
            "Marco Pavone",
            "Emilio Frazzoli"
        ],
        "summary": "Challenged by urbanization and increasing travel needs, existing transportation systems need new mobility paradigms. In this article, we present the emerging concept of autonomous mobility-on-demand, whereby centrally orchestrated fleets of autonomous vehicles provide mobility service to customers. We provide a comprehensive review of methods and tools to model and solve problems related to autonomous mobility-on-demand systems. Specifically, we first identify problem settings for their analysis and control, from both operational and planning perspectives. We then review modeling aspects, including transportation networks, transportation demand, congestion, operational constraints, and interactions with existing infrastructure. Thereafter, we provide a systematic analysis of existing solution methods and performance metrics, highlighting trends and trade-offs. Finally, we present various directions for further research.",
        "published": "2021-06-28T16:03:37Z",
        "link": "http://arxiv.org/abs/2106.14827v2",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Smart and Context-Aware System employing Emotions Recognition",
        "authors": [
            "Stuti Sehgal",
            "Harsh Sharma",
            "Akshat Anand"
        ],
        "summary": "People have the ability to make sensible assumptions about other people's emotional states by being sympathetic, and because of our common sense of knowledge and the ability to think visually. Over the years, much research has been done on providing machines with the ability to detect human emotions and to develop automated emotional intelligence systems. The computer's ability to detect human emotions is gaining popularity in creating sensitive systems such as learning environments, health care systems and real-world. Improving people's health has been the subject of much research. This paper describes the formation as conceptual evidence of emotional acquisition and control in intelligent health settings. The authors of this paper aim for an unconventional approach with a friendly look to get emotional scenarios from the system to establish a functional, non-intrusive and emotionally-sensitive environment where users can do their normal activities naturally and see the program only when pleasant mood activating services are received. The context-sensitive system interacts with users to detect and differentiate emotions through facial expressions or speech recognition, to make music recommendations and mood color treatments with the services installed on their IoT devices.",
        "published": "2021-06-29T05:36:19Z",
        "link": "http://arxiv.org/abs/2106.15101v1",
        "categories": [
            "cs.HC",
            "cs.MA"
        ]
    },
    {
        "title": "Deep Multiagent Reinforcement Learning: Challenges and Directions",
        "authors": [
            "Annie Wong",
            "Thomas Bäck",
            "Anna V. Kononova",
            "Aske Plaat"
        ],
        "summary": "This paper surveys the field of deep multiagent reinforcement learning. The combination of deep neural networks with reinforcement learning has gained increased traction in recent years and is slowly shifting the focus from single-agent to multiagent environments. Dealing with multiple agents is inherently more complex as (a) the future rewards depend on multiple players' joint actions and (b) the computational complexity increases. We present the most common multiagent problem representations and their main challenges, and identify five research areas that address one or more of these challenges: centralised training and decentralised execution, opponent modelling, communication, efficient coordination, and reward shaping. We find that many computational studies rely on unrealistic assumptions or are not generalisable to other settings; they struggle to overcome the curse of dimensionality or nonstationarity. Approaches from psychology and sociology capture promising relevant behaviours, such as communication and coordination, to help agents achieve better performance in multiagent settings. We suggest that, for multiagent reinforcement learning to be successful, future research should address these challenges with an interdisciplinary approach to open up new possibilities in multiagent reinforcement learning.",
        "published": "2021-06-29T19:53:15Z",
        "link": "http://arxiv.org/abs/2106.15691v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "cs.NE",
            "A.1; I.2.6; I.2.8; J.4"
        ]
    },
    {
        "title": "Probabilistic Control of Heterogeneous Swarms Subject to Graph Temporal   Logic Specifications: A Decentralized and Scalable Approach",
        "authors": [
            "Franck Djeumou",
            "Zhe Xu",
            "Murat Cubuktepe",
            "Ufuk Topcu"
        ],
        "summary": "We develop a probabilistic control algorithm, $\\texttt{GTLProCo}$, for swarms of agents with heterogeneous dynamics and objectives, subject to high-level task specifications. The resulting algorithm not only achieves decentralized control of the swarm but also significantly improves scalability over state-of-the-art existing algorithms. Specifically, we study a setting in which the agents move along the nodes of a graph, and the high-level task specifications for the swarm are expressed in a recently-proposed language called graph temporal logic (GTL). By constraining the distribution of the swarm over the nodes of the graph, GTL can specify a wide range of properties, including safety, progress, and response. $\\texttt{GTLProCo}$, agnostic to the number of agents comprising the swarm, controls the density distribution of the swarm in a decentralized and probabilistic manner. To this end, it synthesizes a time-varying Markov chain modeling the time evolution of the density distribution under the GTL constraints. We first identify a subset of GTL, namely reach-avoid specifications, for which we can reduce the synthesis of such a Markov chain to either linear or semi-definite programs. Then, in the general case, we formulate the synthesis of the Markov chain as a mixed-integer nonlinear program (MINLP). We exploit the structure of the problem to provide an efficient sequential mixed-integer linear programming scheme with trust regions to solve the MINLP. We empirically demonstrate that our sequential scheme is at least three orders of magnitude faster than off-the-shelf MINLP solvers and illustrate the effectiveness of $\\texttt{GTLProCo}$ in several swarm scenarios.",
        "published": "2021-06-29T21:34:55Z",
        "link": "http://arxiv.org/abs/2106.15729v1",
        "categories": [
            "eess.SY",
            "cs.FL",
            "cs.MA",
            "cs.SY",
            "math.OC"
        ]
    },
    {
        "title": "Faithful Edge Federated Learning: Scalability and Privacy",
        "authors": [
            "Meng Zhang",
            "Ermin Wei",
            "Randall Berry"
        ],
        "summary": "Federated learning enables machine learning algorithms to be trained over a network of multiple decentralized edge devices without requiring the exchange of local datasets. Successfully deploying federated learning requires ensuring that agents (e.g., mobile devices) faithfully execute the intended algorithm, which has been largely overlooked in the literature. In this study, we first use risk bounds to analyze how the key feature of federated learning, unbalanced and non-i.i.d. data, affects agents' incentives to voluntarily participate and obediently follow traditional federated learning algorithms. To be more specific, our analysis reveals that agents with less typical data distributions and relatively more samples are more likely to opt out of or tamper with federated learning algorithms. To this end, we formulate the first faithful implementation problem of federated learning and design two faithful federated learning mechanisms which satisfy economic properties, scalability, and privacy. Further, the time complexity of computing all agents' payments in the number of agents is $\\mathcal{O}(1)$. First, we design a Faithful Federated Learning (FFL) mechanism which approximates the Vickrey-Clarke-Groves (VCG) payments via an incremental computation. We show that it achieves (probably approximate) optimality, faithful implementation, voluntary participation, and some other economic properties (such as budget balance). Second, by partitioning agents into several subsets, we present a scalable VCG mechanism approximation. We further design a scalable and Differentially Private FFL (DP-FFL) mechanism, the first differentially private faithful mechanism, that maintains the economic properties. Our mechanism enables one to make three-way performance tradeoffs among privacy, the iterations needed, and payment accuracy loss.",
        "published": "2021-06-30T08:46:40Z",
        "link": "http://arxiv.org/abs/2106.15905v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.GT",
            "cs.MA",
            "cs.NI"
        ]
    },
    {
        "title": "Agree to Disagree: Subjective Fairness in Privacy-Restricted   Decentralised Conflict Resolution",
        "authors": [
            "Alex Raymond",
            "Matthew Malencia",
            "Guilherme Paulino-Passos",
            "Amanda Prorok"
        ],
        "summary": "Fairness is commonly seen as a property of the global outcome of a system and assumes centralisation and complete knowledge. However, in real decentralised applications, agents only have partial observation capabilities. Under limited information, agents rely on communication to divulge some of their private (and unobservable) information to others. When an agent deliberates to resolve conflicts, limited knowledge may cause its perspective of a correct outcome to differ from the actual outcome of the conflict resolution. This is subjective unfairness.   To enable decentralised, fairness-aware conflict resolution under privacy constraints, we have two contributions: (1) a novel interaction approach and (2) a formalism of the relationship between privacy and fairness. Our proposed interaction approach is an architecture for privacy-aware explainable conflict resolution where agents engage in a dialogue of hypotheses and facts. To measure the privacy-fairness relationship, we define subjective and objective fairness on both the local and global scope and formalise the impact of partial observability due to privacy in these different notions of fairness.   We first study our proposed architecture and the privacy-fairness relationship in the abstract, testing different argumentation strategies on a large number of randomised cultures. We empirically demonstrate the trade-off between privacy, objective fairness, and subjective fairness and show that better strategies can mitigate the effects of privacy in distributed systems. In addition to this analysis across a broad set of randomised abstract cultures, we analyse a case study for a specific scenario: we instantiate our architecture in a multi-agent simulation of prioritised rule-aware collision avoidance with limited information disclosure.",
        "published": "2021-06-30T18:00:47Z",
        "link": "http://arxiv.org/abs/2107.00032v1",
        "categories": [
            "cs.MA",
            "cs.LO",
            "cs.RO",
            "I.2.11; I.2.3; I.2.9"
        ]
    },
    {
        "title": "Joint Optimization of Autonomous Electric Vehicle Fleet Operations and   Charging Station Siting",
        "authors": [
            "Justin Luke",
            "Mauro Salazar",
            "Ram Rajagopal",
            "Marco Pavone"
        ],
        "summary": "Charging infrastructure is the coupling link between power and transportation networks, thus determining charging station siting is necessary for planning of power and transportation systems. While previous works have either optimized for charging station siting given historic travel behavior, or optimized fleet routing and charging given an assumed placement of the stations, this paper introduces a linear program that optimizes for station siting and macroscopic fleet operations in a joint fashion. Given an electricity retail rate and a set of travel demand requests, the optimization minimizes total cost for an autonomous EV fleet comprising of travel costs, station procurement costs, fleet procurement costs, and electricity costs, including demand charges. Specifically, the optimization returns the number of charging plugs for each charging rate (e.g., Level 2, DC fast charging) at each candidate location, as well as the optimal routing and charging of the fleet. From a case-study of an electric vehicle fleet operating in San Francisco, our results show that, albeit with range limitations, small EVs with low procurement costs and high energy efficiencies are the most cost-effective in terms of total ownership costs. Furthermore, the optimal siting of charging stations is more spatially distributed than the current siting of stations, consisting mainly of high-power Level 2 AC stations (16.8 kW) with a small share of DC fast charging stations and no standard 7.7kW Level 2 stations. Optimal siting reduces the total costs, empty vehicle travel, and peak charging load by up to 10%.",
        "published": "2021-07-01T01:25:19Z",
        "link": "http://arxiv.org/abs/2107.00165v2",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.RO",
            "cs.SY"
        ]
    },
    {
        "title": "Distributed Multi-agent Navigation Based on Reciprocal Collision   Avoidance and Locally Confined Multi-agent Path Finding",
        "authors": [
            "Stepan Dergachev",
            "Konstantin Yakovlev"
        ],
        "summary": "Avoiding collisions is the core problem in multi-agent navigation. In decentralized settings, when agents have limited communication and sensory capabilities, collisions are typically avoided in a reactive fashion, relying on local observations/communications. Prominent collision avoidance techniques, e.g. ORCA, are computationally efficient and scale well to a large number of agents. However, in numerous scenarios, involving navigation through the tight passages or confined spaces, deadlocks are likely to occur due to the egoistic behaviour of the agents and as a result, the latter can not achieve their goals. To this end, we suggest an application of the locally confined multi-agent path finding (MAPF) solvers that coordinate sub-groups of the agents that appear to be in a deadlock (to detect the latter we suggest a simple, yet efficient ad-hoc routine). We present a way to build a grid-based MAPF instance, typically required by modern MAPF solvers. We evaluate two of them in our experiments, i.e. Push and Rotate and a bounded-suboptimal version of Conflict Based Search (ECBS), and show that their inclusion into the navigation pipeline significantly increases the success rate, from 15% to 99% in certain cases.",
        "published": "2021-07-01T06:57:32Z",
        "link": "http://arxiv.org/abs/2107.00246v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "SA-MATD3:Self-attention-based multi-agent continuous control method in   cooperative environments",
        "authors": [
            "Kai Liu",
            "Yuyang Zhao",
            "Gang Wang",
            "Bei Peng"
        ],
        "summary": "Cooperative problems under continuous control have always been the focus of multi-agent reinforcement learning. Existing algorithms suffer from the problem of uneven learning degree with the increase of the number of agents. In this paper, a new structure for a multi-agent actor critic is proposed, and the self-attention mechanism is applied in the critic network and the value decomposition method used to solve the uneven problem. The proposed algorithm makes full use of the samples in the replay memory buffer to learn the behavior of a class of agents. First, a new update method is proposed for policy networks that promotes learning efficiency. Second, the utilization of samples is improved, at the same time reflecting the ability of perspective-taking among groups. Finally, the \"deceptive signal\" in training is eliminated and the learning degree among agents is more uniform than in the existing methods. Multiple experiments were conducted in two typical scenarios of a multi-agent particle environment. Experimental results show that the proposed algorithm can perform better than the state-of-the-art ones, and that it exhibits higher learning efficiency with an increasing number of agents.",
        "published": "2021-07-01T08:15:05Z",
        "link": "http://arxiv.org/abs/2107.00284v1",
        "categories": [
            "cs.MA",
            "cs.LG",
            "I.2.6"
        ]
    },
    {
        "title": "A Discrete-time Reputation-based Resilient Consensus Algorithm for   Synchronous or Asynchronous Communications",
        "authors": [
            "Guilherme Ramos",
            "Daniel Silvestre",
            "Carlos Silvestre"
        ],
        "summary": "We tackle the problem of a set of agents achieving resilient consensus in the presence of attacked agents. We present a discrete-time reputation-based consensus algorithm for synchronous and asynchronous networks by developing a local strategy where, at each time, each agent assigns a reputation (between zero and one) to each neighbor. The reputation is then used to weigh the neighbors' values in the update of its state. Under mild assumptions, we show that: (i) the proposed method converges exponentially to the consensus of the regular agents; (ii) if a regular agent identifies a neighbor as an attacked node, then it is indeed an attacked node; (iii) if the consensus value of the normal nodes differs from that of any of the attacked nodes' values, then the reputation that a regular agent assigns to the attacked neighbors goes to zero. Further, we extend our method to achieve resilience in the scenarios where there are noisy nodes, dynamic networks and stochastic node selection. Finally, we illustrate our algorithm with several examples, and we delineate some attacking scenarios that can be dealt by the current proposal but not by the state-of-the-art approaches.",
        "published": "2021-07-01T13:26:57Z",
        "link": "http://arxiv.org/abs/2107.00431v1",
        "categories": [
            "eess.SY",
            "cs.DC",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Enhancing Multi-Robot Perception via Learned Data Association",
        "authors": [
            "Nathaniel Glaser",
            "Yen-Cheng Liu",
            "Junjiao Tian",
            "Zsolt Kira"
        ],
        "summary": "In this paper, we address the multi-robot collaborative perception problem, specifically in the context of multi-view infilling for distributed semantic segmentation. This setting entails several real-world challenges, especially those relating to unregistered multi-agent image data. Solutions must effectively leverage multiple, non-static, and intermittently-overlapping RGB perspectives. To this end, we propose the Multi-Agent Infilling Network: an extensible neural architecture that can be deployed (in a distributed manner) to each agent in a robotic swarm. Specifically, each robot is in charge of locally encoding and decoding visual information, and an extensible neural mechanism allows for an uncertainty-aware and context-based exchange of intermediate features. We demonstrate improved performance on a realistic multi-robot AirSim dataset.",
        "published": "2021-07-01T22:45:26Z",
        "link": "http://arxiv.org/abs/2107.00769v1",
        "categories": [
            "cs.RO",
            "cs.CV",
            "cs.MA"
        ]
    },
    {
        "title": "Overcoming Obstructions via Bandwidth-Limited Multi-Agent Spatial   Handshaking",
        "authors": [
            "Nathaniel Glaser",
            "Yen-Cheng Liu",
            "Junjiao Tian",
            "Zsolt Kira"
        ],
        "summary": "In this paper, we address bandwidth-limited and obstruction-prone collaborative perception, specifically in the context of multi-agent semantic segmentation. This setting presents several key challenges, including processing and exchanging unregistered robotic swarm imagery. To be successful, solutions must effectively leverage multiple non-static and intermittently-overlapping RGB perspectives, while heeding bandwidth constraints and overcoming unwanted foreground obstructions. As such, we propose an end-to-end learn-able Multi-Agent Spatial Handshaking network (MASH) to process, compress, and propagate visual information across a robotic swarm. Our distributed communication module operates directly (and exclusively) on raw image data, without additional input requirements such as pose, depth, or warping data. We demonstrate superior performance of our model compared against several baselines in a photo-realistic multi-robot AirSim environment, especially in the presence of image occlusions. Our method achieves an absolute 11% IoU improvement over strong baselines.",
        "published": "2021-07-01T22:56:47Z",
        "link": "http://arxiv.org/abs/2107.00771v1",
        "categories": [
            "cs.RO",
            "cs.CV",
            "cs.MA"
        ]
    },
    {
        "title": "Reinforcement Learning Provides a Flexible Approach for Realistic Supply   Chain Safety Stock Optimisation",
        "authors": [
            "Edward Elson Kosasih",
            "Alexandra Brintrup"
        ],
        "summary": "Although safety stock optimisation has been studied for more than 60 years, most companies still use simplistic means to calculate necessary safety stock levels, partly due to the mismatch between existing analytical methods' emphases on deriving provably optimal solutions and companies' preferences to sacrifice optimal results in favour of more realistic problem settings. A newly emerging method from the field of Artificial Intelligence (AI), namely Reinforcement Learning (RL), offers promise in finding optimal solutions while accommodating more realistic problem features. Unlike analytical-based models, RL treats the problem as a black-box simulation environment mitigating against the problem of oversimplifying reality. As such, assumptions on stock keeping policy can be relaxed and a higher number of problem variables can be accommodated. While RL has been popular in other domains, its applications in safety stock optimisation remain scarce. In this paper, we investigate three RL methods, namely, Q-Learning, Temporal Difference Advantage Actor-Critic and Multi-agent Temporal Difference Advantage Actor-Critic for optimising safety stock in a linear chain of independent agents. We find that RL can simultaneously optimise both safety stock level and order quantity parameters of an inventory policy, unlike classical safety stock optimisation models where only safety stock level is optimised while order quantity is predetermined based on simple rules. This allows RL to model more complex supply chain procurement behaviour. However, RL takes longer time to arrive at solutions, necessitating future research on identifying and improving trade-offs between the use of AI and mathematical models are needed.",
        "published": "2021-07-02T09:02:01Z",
        "link": "http://arxiv.org/abs/2107.00913v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Hierarchical Planning for Dynamic Resource Allocation in Smart and   Connected Communities",
        "authors": [
            "Geoffrey Pettet",
            "Ayan Mukhopadhyay",
            "Mykel J. Kochenderfer",
            "Abhishek Dubey"
        ],
        "summary": "Resource allocation under uncertainty is a classical problem in city-scale cyber-physical systems. Consider emergency response as an example; urban planners and first responders optimize the location of ambulances to minimize expected response times to incidents such as road accidents. Typically, such problems deal with sequential decision-making under uncertainty and can be modeled as Markov (or semi-Markov) decision processes. The goal of the decision-maker is to learn a mapping from states to actions that can maximize expected rewards. While online, offline, and decentralized approaches have been proposed to tackle such problems, scalability remains a challenge for real-world use-cases. We present a general approach to hierarchical planning that leverages structure in city-level CPS problems for resource allocation. We use emergency response as a case study and show how a large resource allocation problem can be split into smaller problems. We then use Monte-Carlo planning for solving the smaller problems and managing the interaction between them. Finally, we use data from Nashville, Tennessee, a major metropolitan area in the United States, to validate our approach. Our experiments show that the proposed approach outperforms state-of-the-art approaches used in the field of emergency response.",
        "published": "2021-07-02T22:10:49Z",
        "link": "http://arxiv.org/abs/2107.01292v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Traffic Signal Control with Communicative Deep Reinforcement Learning   Agents: a Case Study",
        "authors": [
            "Paolo Fazzini",
            "Isaac Wheeler",
            "Francesco Petracchini"
        ],
        "summary": "In this work we analyze Multi-Agent Advantage Actor-Critic (MA2C) a recently proposed multi-agent reinforcement learning algorithm that can be applied to adaptive traffic signal control (ATSC) problems. To evaluate its potential we compare MA2C with Independent Advantage Actor-Critic (IA2C) and other Reinforcement Learning or heuristic based algorithms. Specifically, we analyze MA2C theoretically with the framework provided by non-Markov decision processes, which allows a deeper insight of the algorithm, and we critically examine the effectiveness and the robustness of the method by testing it in two traffic areas located in Bologna (Italy) simulated in SUMO, a software modeling tool for ATSC problems. Our results indicate that MA2C, trained with pseudo-random vehicle flows, is a promising technique able to outperform the alternative methods.",
        "published": "2021-07-03T05:12:03Z",
        "link": "http://arxiv.org/abs/2107.01347v4",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Mava: a research library for distributed multi-agent reinforcement   learning in JAX",
        "authors": [
            "Ruan de Kock",
            "Omayma Mahjoub",
            "Sasha Abramowitz",
            "Wiem Khlifi",
            "Callum Rhys Tilbury",
            "Claude Formanek",
            "Andries Smit",
            "Arnu Pretorius"
        ],
        "summary": "Multi-agent reinforcement learning (MARL) research is inherently computationally expensive and it is often difficult to obtain a sufficient number of experiment samples to test hypotheses and make robust statistical claims. Furthermore, MARL algorithms are typically complex in their design and can be tricky to implement correctly. These aspects of MARL present a difficult challenge when it comes to creating useful software for advanced research. Our criteria for such software is that it should be simple enough to use to implement new ideas quickly, while at the same time be scalable and fast enough to test those ideas in a reasonable amount of time. In this preliminary technical report, we introduce Mava, a research library for MARL written purely in JAX, that aims to fulfill these criteria. We discuss the design and core features of Mava, and demonstrate its use and performance across a variety of environments. In particular, we show Mava's substantial speed advantage, with improvements of 10-100x compared to other popular MARL frameworks, while maintaining strong performance. This allows for researchers to test ideas in a few minutes instead of several hours. Finally, Mava forms part of an ecosystem of libraries that seamlessly integrate with each other to help facilitate advanced research in MARL. We hope Mava will benefit the community and help drive scientifically sound and statistically robust research in the field. The open-source repository for Mava is available at https://github.com/instadeepai/Mava.",
        "published": "2021-07-03T16:23:31Z",
        "link": "http://arxiv.org/abs/2107.01460v2",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "A Data-Driven Method for Recognizing Automated Negotiation Strategies",
        "authors": [
            "Ming Li",
            "Pradeep K. Murukannaiah",
            "Catholijn M. Jonker"
        ],
        "summary": "Understanding an opponent agent helps in negotiating with it. Existing works on understanding opponents focus on preference modeling (or estimating the opponent's utility function). An important but largely unexplored direction is recognizing an opponent's negotiation strategy, which captures the opponent's tactics, e.g., to be tough at the beginning but to concede toward the deadline. Recognizing complex, state-of-the-art, negotiation strategies is extremely challenging, and simple heuristics may not be adequate for this purpose. We propose a novel data-driven approach for recognizing an opponent's s negotiation strategy. Our approach includes a data generation method for an agent to generate domain-independent sequences by negotiating with a variety of opponents across domains, a feature engineering method for representing negotiation data as time series with time-step features and overall features, and a hybrid (recurrent neural network-based) deep learning method for recognizing an opponent's strategy from the time series of bids. We perform extensive experiments, spanning four problem scenarios, to demonstrate the effectiveness of our approach.",
        "published": "2021-07-03T20:43:47Z",
        "link": "http://arxiv.org/abs/2107.01496v2",
        "categories": [
            "cs.AI",
            "cs.MA",
            "68T42"
        ]
    },
    {
        "title": "Winning at Any Cost -- Infringing the Cartel Prohibition With   Reinforcement Learning",
        "authors": [
            "Michael Schlechtinger",
            "Damaris Kosack",
            "Heiko Paulheim",
            "Thomas Fetzer"
        ],
        "summary": "Pricing decisions are increasingly made by AI. Thanks to their ability to train with live market data while making decisions on the fly, deep reinforcement learning algorithms are especially effective in taking such pricing decisions. In e-commerce scenarios, multiple reinforcement learning agents can set prices based on their competitor's prices. Therefore, research states that agents might end up in a state of collusion in the long run. To further analyze this issue, we build a scenario that is based on a modified version of a prisoner's dilemma where three agents play the game of rock paper scissors. Our results indicate that the action selection can be dissected into specific stages, establishing the possibility to develop collusion prevention systems that are able to recognize situations which might lead to a collusion between competitors. We furthermore provide evidence for a situation where agents are capable of performing a tacit cooperation strategy without being explicitly trained to do so.",
        "published": "2021-07-05T08:21:52Z",
        "link": "http://arxiv.org/abs/2107.01856v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Effects of Smart Traffic Signal Control on Air Quality",
        "authors": [
            "Paolo Fazzini",
            "Marco Torre",
            "Valeria Rizza",
            "Francesco Petracchini"
        ],
        "summary": "Adaptive traffic signal control (ATSC) in urban traffic networks poses a challenging task due to the complicated dynamics arising in traffic systems. In recent years, several approaches based on multi-agent deep reinforcement learning (MARL) have been studied experimentally. These approaches propose distributed techniques in which each signalized intersection is seen as an agent in a stochastic game whose purpose is to optimize the flow of vehicles in its vicinity. In this setting, the systems evolves towards an equilibrium among the agents that shows beneficial for the whole traffic network. A recently developed multi-agent variant of the well-established advantage actor-critic (A2C) algorithm, called MA2C (multi-agent A2C) exploits the promising idea of some communication among the agents. In this view,the agents share their strategies with other neighbor agents, thereby stabilizing the learning process even when the agents grow in number and variety. We experimented MA2C in two traffic networks located in Bologna (Italy) and found that its action translates into a significant decrease of the amount of pollutants released into the environment.",
        "published": "2021-07-06T02:48:42Z",
        "link": "http://arxiv.org/abs/2107.02361v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Efficient Model-Based Multi-Agent Mean-Field Reinforcement Learning",
        "authors": [
            "Barna Pásztor",
            "Ilija Bogunovic",
            "Andreas Krause"
        ],
        "summary": "Learning in multi-agent systems is highly challenging due to several factors including the non-stationarity introduced by agents' interactions and the combinatorial nature of their state and action spaces. In particular, we consider the Mean-Field Control (MFC) problem which assumes an asymptotically infinite population of identical agents that aim to collaboratively maximize the collective reward. In many cases, solutions of an MFC problem are good approximations for large systems, hence, efficient learning for MFC is valuable for the analogous discrete agent setting with many agents. Specifically, we focus on the case of unknown system dynamics where the goal is to simultaneously optimize for the rewards and learn from experience. We propose an efficient model-based reinforcement learning algorithm, $M^3-UCRL$, that runs in episodes, balances between exploration and exploitation during policy learning, and provably solves this problem. Our main theoretical contributions are the first general regret bounds for model-based reinforcement learning for MFC, obtained via a novel mean-field type analysis. To learn the system's dynamics, $M^3-UCRL$ can be instantiated with various statistical models, e.g., neural networks or Gaussian Processes. Moreover, we provide a practical parametrization of the core optimization problem that facilitates gradient-based optimization techniques when combined with differentiable dynamics approximation methods such as neural networks.",
        "published": "2021-07-08T18:01:02Z",
        "link": "http://arxiv.org/abs/2107.04050v2",
        "categories": [
            "stat.ML",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Distributed Coverage Control of Multi-Agent Networks with Guaranteed   Collision Avoidance in Cluttered Environments",
        "authors": [
            "Alaa Z. Abdulghafoor",
            "Efstathios Bakolas"
        ],
        "summary": "We propose a distributed control algorithm for a multi-agent network whose agents deploy over a cluttered region in accordance with a time-varying coverage density function while avoiding collisions with all obstacles they encounter. Our algorithm is built on a two-level characterization of the network. The first level treats the multi-agent network as a whole based on the distribution of the locations of its agents over the spatial domain. In the second level, the network is described in terms of the individual positions of its agents. The aim of the multi-agent network is to attain a spatial distribution that resembles that of a reference coverage density function (high-level problem) by means of local (microscopic) interactions of its agents (low-level problem). In addition, as the agents deploy, they must avoid collisions with all the obstacles in the region at all times. Our approach utilizes a modified version of Voronoi tessellations which are comprised of what we refer to as Obstacle-Aware Voronoi Cells (OAVC) in order to enable coverage control while ensuring obstacle avoidance. We consider two control problems. The first problem which we refer to as the high-level coverage control problem corresponds to an interpolation problem in the class of Gaussian mixtures (no collision avoidance requirement), which we solve analytically. The second problem which we refer to as the low-level coverage control problem corresponds to a distributed control problem (collision avoidance requirement is now enforced at all times) which is solved by utilizing Lloyd's algorithm together with the modified Voronoi tessellation (OAVC) and a time-varying coverage density function which corresponds to the solution of the high-level coverage control problem. Finally, simulation results for coverage in a cluttered environment are provided to demonstrate the efficacy of the proposed approach.",
        "published": "2021-07-08T19:28:24Z",
        "link": "http://arxiv.org/abs/2107.04078v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Intelligent Link Adaptation for Grant-Free Access Cellular Networks: A   Distributed Deep Reinforcement Learning Approach",
        "authors": [
            "Joao V. C. Evangelista",
            "Zeeshan Sattar",
            "Georges Kaddoum",
            "Bassant Selim",
            "Aydin Sarraf"
        ],
        "summary": "With the continuous growth of machine-type devices (MTDs), it is expected that massive machine-type communication (mMTC) will be the dominant form of traffic in future wireless networks. Applications based on this technology, have fundamentally different traffic characteristics from human-to-human (H2H) communication, which involves a relatively small number of devices transmitting large packets consistently. Conversely, in mMTC applications, a very large number of MTDs transmit small packets sporadically. Therefore, conventional grant-based access schemes commonly adopted for H2H service, are not suitable for mMTC, as they incur in a large overhead associated with the channel request procedure. We propose three grant-free distributed optimization architectures that are able to significantly minimize the average power consumption of the network. The problem of physical layer (PHY) and medium access control (MAC) optimization in grant-free random access transmission is is modeled as a partially observable stochastic game (POSG) aimed at minimizing the average transmit power under a per-device delay constraint. The results show that the proposed architectures are able to achieve significantly less average latency than a baseline, while spending less power. Moreover, the proposed architectures are more robust than the baseline, as they present less variance in the performance for different system realizations.",
        "published": "2021-07-08T23:17:15Z",
        "link": "http://arxiv.org/abs/2107.04145v1",
        "categories": [
            "cs.MA",
            "cs.IT",
            "eess.SP",
            "math.IT"
        ]
    },
    {
        "title": "Can We Replicate Real Human Behaviour Using Artificial Neural Networks?",
        "authors": [
            "Georg Jäger",
            "Daniel Reisinger"
        ],
        "summary": "Agent-based modelling is a powerful tool when simulating human systems, yet when human behaviour cannot be described by simple rules or maximising one's own profit, we quickly reach the limits of this methodology. Machine learning has the potential to bridge this gap by providing a link between what people observe and how they act in order to reach their goal. In this paper we use a framework for agent-based modelling that utilizes human values like fairness, conformity and altruism. Using this framework we simulate a public goods game and compare to experimental results. We can report good agreement between simulation and experiment and furthermore find that the presented framework outperforms strict reinforcement learning. Both the framework and the utility function are generic enough that they can be used for arbitrary systems, which makes this method a promising candidate for a foundation of a universal agent-based model.",
        "published": "2021-07-09T07:21:54Z",
        "link": "http://arxiv.org/abs/2107.04267v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "ARC: Adversarially Robust Control Policies for Autonomous Vehicles",
        "authors": [
            "Sampo Kuutti",
            "Saber Fallah",
            "Richard Bowden"
        ],
        "summary": "Deep neural networks have demonstrated their capability to learn control policies for a variety of tasks. However, these neural network-based policies have been shown to be susceptible to exploitation by adversarial agents. Therefore, there is a need to develop techniques to learn control policies that are robust against adversaries. We introduce Adversarially Robust Control (ARC), which trains the protagonist policy and the adversarial policy end-to-end on the same loss. The aim of the protagonist is to maximise this loss, whilst the adversary is attempting to minimise it. We demonstrate the proposed ARC training in a highway driving scenario, where the protagonist controls the follower vehicle whilst the adversary controls the lead vehicle. By training the protagonist against an ensemble of adversaries, it learns a significantly more robust control policy, which generalises to a variety of adversarial strategies. The approach is shown to reduce the amount of collisions against new adversaries by up to 90.25%, compared to the original policy. Moreover, by utilising an auxiliary distillation loss, we show that the fine-tuned control policy shows no drop in performance across its original training distribution.",
        "published": "2021-07-09T15:22:29Z",
        "link": "http://arxiv.org/abs/2107.04487v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Parameterized Complexity of Multi-winner Determination: More Effort   Towards Fixed-Parameter Tractability",
        "authors": [
            "Yongjie Yang",
            "Jianxin Wang"
        ],
        "summary": "We study the parameterized complexity of winner determination problems for three prevalent $k$-committee selection rules, namely the minimax approval voting (MAV), the proportional approval voting (PAV), and the Chamberlin-Courant's approval voting (CCAV). It is known that these problems are computationally hard. Although they have been studied from the parameterized complexity point of view with respect to several natural parameters, many of them turned out to be W[1]-hard or W[2]-hard. Aiming at obtaining plentiful fixed-parameter algorithms, we revisit these problems by considering more natural single parameters, combined parameters, and structural parameters.",
        "published": "2021-07-09T21:21:18Z",
        "link": "http://arxiv.org/abs/2107.04685v5",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Learning-to-Dispatch: Reinforcement Learning Based Flight Planning under   Emergency",
        "authors": [
            "Kai Zhang",
            "Yupeng Yang",
            "Chengtao Xu",
            "Dahai Liu",
            "Houbing Song"
        ],
        "summary": "The effectiveness of resource allocation under emergencies especially hurricane disasters is crucial. However, most researchers focus on emergency resource allocation in a ground transportation system. In this paper, we propose Learning-to-Dispatch (L2D), a reinforcement learning (RL) based air route dispatching system, that aims to add additional flights for hurricane evacuation while minimizing the airspace's complexity and air traffic controller's workload. Given a bipartite graph with weights that are learned from the historical flight data using RL in consideration of short- and long-term gains, we formulate the flight dispatch as an online maximum weight matching problem. Different from the conventional order dispatch problem, there is no actual or estimated index that can evaluate how the additional evacuation flights influence the air traffic complexity. Then we propose a multivariate reward function in the learning phase and compare it with other univariate reward designs to show its superior performance. The experiments using the real-world dataset for Hurricane Irma demonstrate the efficacy and efficiency of our proposed schema.",
        "published": "2021-07-10T19:21:14Z",
        "link": "http://arxiv.org/abs/2107.04897v1",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Distributed Deep Reinforcement Learning for Intelligent Traffic   Monitoring with a Team of Aerial Robots",
        "authors": [
            "Behzad Khamidehi",
            "Elvino S. Sousa"
        ],
        "summary": "This paper studies the traffic monitoring problem in a road network using a team of aerial robots. The problem is challenging due to two main reasons. First, the traffic events are stochastic, both temporally and spatially. Second, the problem has a non-homogeneous structure as the traffic events arrive at different locations of the road network at different rates. Accordingly, some locations require more visits by the robots compared to other locations. To address these issues, we define an uncertainty metric for each location of the road network and formulate a path planning problem for the aerial robots to minimize the network's average uncertainty. We express this problem as a partially observable Markov decision process (POMDP) and propose a distributed and scalable algorithm based on deep reinforcement learning to solve it. We consider two different scenarios depending on the communication mode between the agents (aerial robots) and the traffic management center (TMC). The first scenario assumes that the agents continuously communicate with the TMC to send/receive real-time information about the traffic events. Hence, the agents have global and real-time knowledge of the environment. However, in the second scenario, we consider a challenging setting where the observation of the aerial robots is partial and limited to their sensing ranges. Moreover, in contrast to the first scenario, the information exchange between the aerial robots and the TMC is restricted to specific time instances. We evaluate the performance of our proposed algorithm in both scenarios for a real road network topology and demonstrate its functionality in a traffic monitoring system.",
        "published": "2021-07-10T22:41:32Z",
        "link": "http://arxiv.org/abs/2107.04924v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Potential iLQR: A Potential-Minimizing Controller for Planning   Multi-Agent Interactive Trajectories",
        "authors": [
            "Talha Kavuncu",
            "Ayberk Yaraneri",
            "Negar Mehr"
        ],
        "summary": "Many robotic applications involve interactions between multiple agents where an agent's decisions affect the behavior of other agents. Such behaviors can be captured by the equilibria of differential games which provide an expressive framework for modeling the agents' mutual influence. However, finding the equilibria of differential games is in general challenging as it involves solving a set of coupled optimal control problems. In this work, we propose to leverage the special structure of multi-agent interactions to generate interactive trajectories by simply solving a single optimal control problem, namely, the optimal control problem associated with minimizing the potential function of the differential game. Our key insight is that for a certain class of multi-agent interactions, the underlying differential game is indeed a potential differential game for which equilibria can be found by solving a single optimal control problem. We introduce such an optimal control problem and build on single-agent trajectory optimization methods to develop a computationally tractable and scalable algorithm for planning multi-agent interactive trajectories. We will demonstrate the performance of our algorithm in simulation and show that our algorithm outperforms the state-of-the-art game solvers. To further show the real-time capabilities of our algorithm, we will demonstrate the application of our proposed algorithm in a set of experiments involving interactive trajectories for two quadcopters.",
        "published": "2021-07-10T23:06:24Z",
        "link": "http://arxiv.org/abs/2107.04926v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Open-Loop Equilibrium Strategies for Dynamic Influence Maximization Game   Over Social Networks",
        "authors": [
            "S. Rasoul Etesami"
        ],
        "summary": "We consider the problem of budget allocation for competitive influence maximization over social networks. In this problem, multiple competing parties (players) want to distribute their limited advertising resources over a set of social individuals to maximize their long-run cumulative payoffs. It is assumed that the individuals are connected via a social network and update their opinions based on the classical DeGroot model. The players must decide the budget distribution among the individuals at a finite number of campaign times to maximize their overall payoff given as a function of individuals' opinions. We show that i) the optimal investment strategy for the case of a single-player can be found in polynomial time by solving a concave program, and ii) the open-loop equilibrium strategies for the multiplayer dynamic game can be computed efficiently by following natural regret minimization dynamics. Our results extend the earlier work on the static version of the problem to a dynamic multistage game.",
        "published": "2021-07-11T22:31:08Z",
        "link": "http://arxiv.org/abs/2107.05138v2",
        "categories": [
            "cs.GT",
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "math.OC"
        ]
    },
    {
        "title": "Provider-centric Allocation of Drone Swarm Services",
        "authors": [
            "Balsam Alkouz",
            "Athman Bouguettaya"
        ],
        "summary": "We propose a novel framework for the allocation of drone swarms for delivery services known as Swarm-based Drone-as-a-Service (SDaaS). The allocation framework ensures minimum cost (aka maximum profit) to drone swarm providers while meeting the time requirement of service consumers. The constraints in the delivery environment (e.g., limited recharging pads) are taken into consideration. We propose three algorithms to select the best allocation of drone swarms given a set of requests from multiple consumers. We conduct a set of experiments to evaluate and compare the efficiency of these algorithms considering the provider's profit, feasibility, requests fulfilment, and drones utilization level.",
        "published": "2021-07-12T03:23:58Z",
        "link": "http://arxiv.org/abs/2107.05173v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Information Spread with Error Correction",
        "authors": [
            "Omri Ben-Eliezer",
            "Elchanan Mossel",
            "Madhu Sudan"
        ],
        "summary": "We study the process of information dispersal in a network with communication errors and local error-correction. Specifically we consider a simple model where a single bit of information initially known to a single source is dispersed through the network, and communication errors lead to differences in the agents' opinions on this information.   Naturally, such errors can very quickly make the communication completely unreliable, and in this work we study to what extent this unreliability can be mitigated by local error-correction, where nodes periodically correct their opinion based on the opinion of (some subset of) their neighbors. We analyze how the error spreads in the \"early stages\" of information dispersal by monitoring the average opinion, i.e., the fraction of agents that have the correct information among all nodes that hold an opinion at a given time. Our main results show that even with significant effort in error-correction, tiny amounts of noise can lead the average opinion to be nearly uncorrelated with the truth in early stages. We also propose some local methods to help agents gauge when the information they have has stabilized.",
        "published": "2021-07-13T19:58:18Z",
        "link": "http://arxiv.org/abs/2107.06362v1",
        "categories": [
            "cs.SI",
            "cs.GT",
            "cs.MA",
            "math.PR"
        ]
    },
    {
        "title": "Communication-Efficient Hierarchical Federated Learning for IoT   Heterogeneous Systems with Imbalanced Data",
        "authors": [
            "Alaa Awad Abdellatif",
            "Naram Mhaisen",
            "Amr Mohamed",
            "Aiman Erbad",
            "Mohsen Guizani",
            "Zaher Dawy",
            "Wassim Nasreddine"
        ],
        "summary": "Federated learning (FL) is a distributed learning methodology that allows multiple nodes to cooperatively train a deep learning model, without the need to share their local data. It is a promising solution for telemonitoring systems that demand intensive data collection, for detection, classification, and prediction of future events, from different locations while maintaining a strict privacy constraint. Due to privacy concerns and critical communication bottlenecks, it can become impractical to send the FL updated models to a centralized server. Thus, this paper studies the potential of hierarchical FL in IoT heterogeneous systems and propose an optimized solution for user assignment and resource allocation on multiple edge nodes. In particular, this work focuses on a generic class of machine learning models that are trained using gradient-descent-based schemes while considering the practical constraints of non-uniformly distributed data across different users. We evaluate the proposed system using two real-world datasets, and we show that it outperforms state-of-the-art FL solutions. In particular, our numerical results highlight the effectiveness of our approach and its ability to provide 4-6% increase in the classification accuracy, with respect to hierarchical FL schemes that consider distance-based user assignment. Furthermore, the proposed approach could significantly accelerate FL training and reduce communication overhead by providing 75-85% reduction in the communication rounds between edge nodes and the centralized server, for the same model accuracy.",
        "published": "2021-07-14T08:32:39Z",
        "link": "http://arxiv.org/abs/2107.06548v1",
        "categories": [
            "cs.LG",
            "cs.DC",
            "cs.MA",
            "cs.NI"
        ]
    },
    {
        "title": "Simulating transmission scenarios of the Delta variant of SARS-CoV-2 in   Australia",
        "authors": [
            "Sheryl L. Chang",
            "Oliver M. Cliff",
            "Cameron Zachreson",
            "Mikhail Prokopenko"
        ],
        "summary": "An outbreak of the Delta (B.1.617.2) variant of SARS-CoV-2 that began around mid-June 2021 in Sydney, Australia, quickly developed into a nation-wide epidemic. The ongoing epidemic is of major concern as the Delta variant is more infectious than previous variants that circulated in Australia in 2020. Using a re-calibrated agent-based model, we explored a feasible range of non-pharmaceutical interventions, including case isolation, home quarantine, school closures, and stay-at-home restrictions (i.e., \"social distancing\"). Our modelling indicated that the levels of reduced interactions in workplaces and across communities attained in Sydney and other parts of the nation were inadequate for controlling the outbreak. A counter-factual analysis suggested that if 70% of the population followed tight stay-at-home restrictions, then at least 45 days would have been needed for new daily cases to fall from their peak to below ten per day. Our model predicted that, under a progressive vaccination rollout, if 40-50% of the Australian population follow stay-at-home restrictions, the incidence will peak by mid-October 2021: the peak in incidence across the nation was indeed observed in mid-October. We also quantified an expected burden on the healthcare system and potential fatalities across Australia.",
        "published": "2021-07-14T11:36:00Z",
        "link": "http://arxiv.org/abs/2107.06617v6",
        "categories": [
            "q-bio.PE",
            "cs.MA"
        ]
    },
    {
        "title": "Social nucleation: Group formation as a phase transition",
        "authors": [
            "Frank Schweitzer",
            "Georges Andres"
        ],
        "summary": "The spontaneous formation and subsequent growth, dissolution, merger and competition of social groups bears similarities to physical phase transitions in metastable finite systems. We examine three different scenarios, percolation, spinodal decomposition and nucleation, to describe the formation of social groups of varying size and density. In our agent-based model, we use a feedback between the opinions of agents and their ability to establish links. Groups can restrict further link formation, but agents can also leave if costs exceed the group benefits. We identify the critical parameters for costs/benefits and social influence to obtain either one large group or the stable coexistence of several groups with different opinions. Analytic investigations allow to derive different critical densities that control the formation and coexistence of groups. Our novel approach sheds new light on the early stage of network growth and the emergence of large connected components.",
        "published": "2021-07-14T13:37:07Z",
        "link": "http://arxiv.org/abs/2107.06696v3",
        "categories": [
            "physics.soc-ph",
            "cond-mat.other",
            "cs.MA"
        ]
    },
    {
        "title": "Scalable Evaluation of Multi-Agent Reinforcement Learning with Melting   Pot",
        "authors": [
            "Joel Z. Leibo",
            "Edgar Duéñez-Guzmán",
            "Alexander Sasha Vezhnevets",
            "John P. Agapiou",
            "Peter Sunehag",
            "Raphael Koster",
            "Jayd Matyas",
            "Charles Beattie",
            "Igor Mordatch",
            "Thore Graepel"
        ],
        "summary": "Existing evaluation suites for multi-agent reinforcement learning (MARL) do not assess generalization to novel situations as their primary objective (unlike supervised-learning benchmarks). Our contribution, Melting Pot, is a MARL evaluation suite that fills this gap, and uses reinforcement learning to reduce the human labor required to create novel test scenarios. This works because one agent's behavior constitutes (part of) another agent's environment. To demonstrate scalability, we have created over 80 unique test scenarios covering a broad range of research topics such as social dilemmas, reciprocity, resource sharing, and task partitioning. We apply these test scenarios to standard MARL training algorithms, and demonstrate how Melting Pot reveals weaknesses not apparent from training performance alone.",
        "published": "2021-07-14T17:22:14Z",
        "link": "http://arxiv.org/abs/2107.06857v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Asynchronous games on Petri nets and ATL",
        "authors": [
            "Federica Adobbati",
            "Luca Bernardinello",
            "Lucia Pomello"
        ],
        "summary": "We define a game on distributed Petri nets, where several players interact with each other, and with an environment. The players, or users, have perfect knowledge of the current state, and pursue a common goal. Such goal is expressed by Alternating-time Temporal Logic (ATL). The users have a winning strategy if they can cooperate to reach their goal, no matter how the environment behaves. We show that such a game can be translated into a game on concurrent game structures (introduced in order to give a semantics to ATL). We compare our game with the game on concurrent game structures and discuss the differences between the two approaches. Finally, we show that, when we consider memoryless strategies and a fragment of ATL, we can construct a concurrent game structure from the Petri net, such that an ATL formula is verified on the net if, and only if, it is verified on the game structure.",
        "published": "2021-07-14T17:35:03Z",
        "link": "http://arxiv.org/abs/2107.06866v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Architecture of Automated Crypto-Finance Agent",
        "authors": [
            "Ali Raheman",
            "Anton Kolonin",
            "Ben Goertzel",
            "Gergely Hegykozi",
            "Ikram Ansari"
        ],
        "summary": "We present the cognitive architecture of an autonomous agent for active portfolio management in decentralized finance, involving activities such as asset selection, portfolio balancing, liquidity provision, and trading. Partial implementation of the architecture is provided and supplied with preliminary results and conclusions.",
        "published": "2021-07-16T08:57:50Z",
        "link": "http://arxiv.org/abs/2107.07769v4",
        "categories": [
            "cs.AI",
            "cs.CE",
            "cs.MA"
        ]
    },
    {
        "title": "Robust Risk-Sensitive Reinforcement Learning Agents for Trading Markets",
        "authors": [
            "Yue Gao",
            "Kry Yik Chau Lui",
            "Pablo Hernandez-Leal"
        ],
        "summary": "Trading markets represent a real-world financial application to deploy reinforcement learning agents, however, they carry hard fundamental challenges such as high variance and costly exploration. Moreover, markets are inherently a multiagent domain composed of many actors taking actions and changing the environment. To tackle these type of scenarios agents need to exhibit certain characteristics such as risk-awareness, robustness to perturbations and low learning variance. We take those as building blocks and propose a family of four algorithms. First, we contribute with two algorithms that use risk-averse objective functions and variance reduction techniques. Then, we augment the framework to multi-agent learning and assume an adversary which can take over and perturb the learning process. Our third and fourth algorithms perform well under this setting and balance theoretical guarantees with practical use. Additionally, we consider the multi-agent nature of the environment and our work is the first one extending empirical game theory analysis for multi-agent learning by considering risk-sensitive payoffs.",
        "published": "2021-07-16T19:15:13Z",
        "link": "http://arxiv.org/abs/2107.08083v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Decentralized Multi-Agent Reinforcement Learning for Task Offloading   Under Uncertainty",
        "authors": [
            "Yuanchao Xu",
            "Amal Feriani",
            "Ekram Hossain"
        ],
        "summary": "Multi-Agent Reinforcement Learning (MARL) is a challenging subarea of Reinforcement Learning due to the non-stationarity of the environments and the large dimensionality of the combined action space. Deep MARL algorithms have been applied to solve different task offloading problems. However, in real-world applications, information required by the agents (i.e. rewards and states) are subject to noise and alterations. The stability and the robustness of deep MARL to practical challenges is still an open research problem. In this work, we apply state-of-the art MARL algorithms to solve task offloading with reward uncertainty. We show that perturbations in the reward signal can induce decrease in the performance compared to learning with perfect rewards. We expect this paper to stimulate more research in studying and addressing the practical challenges of deploying deep MARL solutions in wireless communications systems.",
        "published": "2021-07-16T20:49:30Z",
        "link": "http://arxiv.org/abs/2107.08114v2",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Communicating via Markov Decision Processes",
        "authors": [
            "Samuel Sokota",
            "Christian Schroeder de Witt",
            "Maximilian Igl",
            "Luisa Zintgraf",
            "Philip Torr",
            "Martin Strohmeier",
            "J. Zico Kolter",
            "Shimon Whiteson",
            "Jakob Foerster"
        ],
        "summary": "We consider the problem of communicating exogenous information by means of Markov decision process trajectories. This setting, which we call a Markov coding game (MCG), generalizes both source coding and a large class of referential games. MCGs also isolate a problem that is important in decentralized control settings in which cheap-talk is not available -- namely, they require balancing communication with the associated cost of communicating. We contribute a theoretically grounded approach to MCGs based on maximum entropy reinforcement learning and minimum entropy coupling that we call MEME. Due to recent breakthroughs in approximation algorithms for minimum entropy coupling, MEME is not merely a theoretical algorithm, but can be applied to practical settings. Empirically, we show both that MEME is able to outperform a strong baseline on small MCGs and that MEME is able to achieve strong performance on extremely large MCGs. To the latter point, we demonstrate that MEME is able to losslessly communicate binary images via trajectories of Cartpole and Pong, while simultaneously achieving the maximal or near maximal expected returns, and that it is even capable of performing well in the presence of actuator noise.",
        "published": "2021-07-17T17:44:30Z",
        "link": "http://arxiv.org/abs/2107.08295v2",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Pre-trained Language Models as Prior Knowledge for Playing Text-based   Games",
        "authors": [
            "Ishika Singh",
            "Gargi Singh",
            "Ashutosh Modi"
        ],
        "summary": "Recently, text world games have been proposed to enable artificial agents to understand and reason about real-world scenarios. These text-based games are challenging for artificial agents, as it requires an understanding of and interaction using natural language in a partially observable environment. Agents observe the environment via textual descriptions designed to be challenging enough for even human players. Past approaches have not paid enough attention to the language understanding capability of the proposed agents. Typically, these approaches train from scratch, an agent that learns both textual representations and the gameplay online during training using a temporal loss function. Given the sample-inefficiency of RL approaches, it is inefficient to learn rich enough textual representations to be able to understand and reason using the textual observation in such a complicated game environment setting. In this paper, we improve the semantic understanding of the agent by proposing a simple RL with LM framework where we use transformer-based language models with Deep RL models. We perform a detailed study of our framework to demonstrate how our model outperforms all existing agents on the popular game, Zork1, to achieve a score of 44.7, which is 1.6 higher than the state-of-the-art model. Overall, our proposed approach outperforms 4 games out of the 14 text-based games, while performing comparable to the state-of-the-art models on the remaining games.",
        "published": "2021-07-18T10:28:48Z",
        "link": "http://arxiv.org/abs/2107.08408v2",
        "categories": [
            "cs.CL",
            "cs.AI",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "A Multi-UAV System for Exploration and Target Finding in Cluttered and   GPS-Denied Environments",
        "authors": [
            "Xiaolong Zhu",
            "Fernando Vanegas",
            "Felipe Gonzalez",
            "Conrad Sanderson"
        ],
        "summary": "The use of multi-rotor Unmanned Aerial Vehicles (UAVs) for search and rescue as well as remote sensing is rapidly increasing. Multi-rotor UAVs, however, have limited endurance. The range of UAV applications can be widened if teams of multiple UAVs are used. We propose a framework for a team of UAVs to cooperatively explore and find a target in complex GPS-denied environments with obstacles. The team of UAVs autonomously navigates, explores, detects, and finds the target in a cluttered environment with a known map. Examples of such environments include indoor scenarios, urban or natural canyons, caves, and tunnels, where the GPS signal is limited or blocked. The framework is based on a probabilistic decentralised Partially Observable Markov Decision Process which accounts for the uncertainties in sensing and the environment. The team can cooperate efficiently, with each UAV sharing only limited processed observations and their locations during the mission. The system is simulated using the Robotic Operating System and Gazebo. Performance of the system with an increasing number of UAVs in several indoor scenarios with obstacles is tested. Results indicate that the proposed multi-UAV system has improvements in terms of time-cost, the proportion of search area surveyed, as well as successful rates for search and rescue missions.",
        "published": "2021-07-19T12:54:04Z",
        "link": "http://arxiv.org/abs/2107.08834v1",
        "categories": [
            "cs.RO",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "T-RECS: A Simulation Tool to Study the Societal Impact of Recommender   Systems",
        "authors": [
            "Eli Lucherini",
            "Matthew Sun",
            "Amy Winecoff",
            "Arvind Narayanan"
        ],
        "summary": "Simulation has emerged as a popular method to study the long-term societal consequences of recommender systems. This approach allows researchers to specify their theoretical model explicitly and observe the evolution of system-level outcomes over time. However, performing simulation-based studies often requires researchers to build their own simulation environments from the ground up, which creates a high barrier to entry, introduces room for implementation error, and makes it difficult to disentangle whether observed outcomes are due to the model or the implementation.   We introduce T-RECS, an open-sourced Python package designed for researchers to simulate recommendation systems and other types of sociotechnical systems in which an algorithm mediates the interactions between multiple stakeholders, such as users and content creators. To demonstrate the flexibility of T-RECS, we perform a replication of two prior simulation-based research on sociotechnical systems. We additionally show how T-RECS can be used to generate novel insights with minimal overhead. Our tool promotes reproducibility in this area of research, provides a unified language for simulating sociotechnical systems, and removes the friction of implementing simulations from scratch.",
        "published": "2021-07-19T15:16:44Z",
        "link": "http://arxiv.org/abs/2107.08959v2",
        "categories": [
            "cs.CY",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Rational Verification for Probabilistic Systems",
        "authors": [
            "Julian Gutierrez",
            "Lewis Hammond",
            "Anthony W. Lin",
            "Muhammad Najib",
            "Michael Wooldridge"
        ],
        "summary": "Rational verification is the problem of determining which temporal logic properties will hold in a multi-agent system, under the assumption that agents in the system act rationally, by choosing strategies that collectively form a game-theoretic equilibrium. Previous work in this area has largely focussed on deterministic systems. In this paper, we develop the theory and algorithms for rational verification in probabilistic systems. We focus on concurrent stochastic games (CSGs), which can be used to model uncertainty and randomness in complex multi-agent environments. We study the rational verification problem for both non-cooperative games and cooperative games in the qualitative probabilistic setting. In the former case, we consider LTL properties satisfied by the Nash equilibria of the game and in the latter case LTL properties satisfied by the core. In both cases, we show that the problem is 2EXPTIME-complete, thus not harder than the much simpler verification problem of model checking LTL properties of systems modelled as Markov decision processes (MDPs).",
        "published": "2021-07-19T19:24:16Z",
        "link": "http://arxiv.org/abs/2107.09119v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.GT",
            "cs.LO"
        ]
    },
    {
        "title": "Using reinforcement learning to autonomously identify sources of error   for agents in group missions",
        "authors": [
            "Keishu Utimula",
            "Ken-taro Hayaschi",
            "Trevor J. Bihl",
            "Kenta Hongo",
            "Ryo Maezono"
        ],
        "summary": "When agents swarm to execute a mission, some of them frequently exhibit sudden failure, as observed from the command base. It is generally difficult to determine whether a failure is caused by actuators (hypothesis, $h_a$) or sensors (hypothesis, $h_s$) by solely relying on the communication between the command base and concerning agent. However, by instigating collusion between the agents, the cause of failure can be identified; in other words, we expect to detect corresponding displacements for $h_a$ but not for $h_s$. In this study, we considered the question as to whether artificial intelligence can autonomously generate an action plan $\\boldsymbol{g}$ to pinpoint the cause as aforedescribed. Because the expected response to $\\boldsymbol{g}$ generally depends upon the adopted hypothesis [let the difference be denoted by $D(\\boldsymbol{g})$], a formulation that uses $D\\left(\\boldsymbol{g}\\right)$ to pinpoint the cause can be made. Although a $\\boldsymbol{g}^*$ that maximizes $D(\\boldsymbol{g})$ would be a suitable action plan for this task, such an optimization is difficult to achieve using the conventional gradient method, as $D(\\boldsymbol{g})$ becomes nonzero in rare events such as collisions with other agents, and most swarm actions $\\boldsymbol{g}$ give $D(\\boldsymbol{g})=0$. In other words, throughout almost the entire space of $\\boldsymbol{g}$, $D(\\boldsymbol{g})$ has zero gradient, and the gradient method is not applicable. To overcome this problem, we formulated an action plan using Q-table reinforcement learning. Surprisingly, the optimal action plan generated via reinforcement learning presented a human-like solution to pinpoint the problem by colliding other agents with the failed agent. Using this simple prototype, we demonstrated the potential of applying Q-table reinforcement learning methods to plan autonomous actions to pinpoint the causes of failure.",
        "published": "2021-07-20T02:40:19Z",
        "link": "http://arxiv.org/abs/2107.09232v4",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Cluster Consensus on Matrix-weighted Switching Networks",
        "authors": [
            "Lulu Pan",
            "Haibin Shao",
            "Mehran Mesbahi",
            "Dewei Li",
            "Yugeng Xi"
        ],
        "summary": "This paper examines the cluster consensus problem of multi-agent systems on matrix-weighted switching networks. Necessary and/or sufficient conditions under which cluster consensus can be achieved are obtained and quantitative characterization of the steady-state of the cluster consensus are provided as well. Specifically, if the underlying network switches amongst finite number of networks, a necessary condition for cluster consensus of multi-agent system on switching matrix-weighted networks is firstly presented, it is shown that the steady-state of the system lies in the intersection of the null space of matrix-valued Laplacians corresponding to all switching networks. Second, if the underlying network switches amongst infinite number of networks, the matrix-weighted integral network is employed to provide sufficient conditions for cluster consensus and the quantitative characterization of the corresponding steady-state of the multi-agent system, using null space analysis of matrix-valued Laplacian related of integral network associated with the switching networks. In particular, conditions for the bipartite consensus under the matrix-weighted switching networks are examined. Simulation results are finally provided to demonstrate the theoretical analysis.",
        "published": "2021-07-20T07:20:23Z",
        "link": "http://arxiv.org/abs/2107.09292v2",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Learning Altruistic Behaviours in Reinforcement Learning without   External Rewards",
        "authors": [
            "Tim Franzmeyer",
            "Mateusz Malinowski",
            "João F. Henriques"
        ],
        "summary": "Can artificial agents learn to assist others in achieving their goals without knowing what those goals are? Generic reinforcement learning agents could be trained to behave altruistically towards others by rewarding them for altruistic behaviour, i.e., rewarding them for benefiting other agents in a given situation. Such an approach assumes that other agents' goals are known so that the altruistic agent can cooperate in achieving those goals. However, explicit knowledge of other agents' goals is often difficult to acquire. In the case of human agents, their goals and preferences may be difficult to express fully; they might be ambiguous or even contradictory. Thus, it is beneficial to develop agents that do not depend on external supervision and learn altruistic behaviour in a task-agnostic manner. We propose to act altruistically towards other agents by giving them more choice and allowing them to achieve their goals better. Some concrete examples include opening a door for others or safeguarding them to pursue their objectives without interference. We formalize this concept and propose an altruistic agent that learns to increase the choices another agent has by preferring to maximize the number of states that the other agent can reach in its future. We evaluate our approach in three different multi-agent environments where another agent's success depends on altruistic behaviour. Finally, we show that our unsupervised agents can perform comparably to agents explicitly trained to work cooperatively, in some cases even outperforming them.",
        "published": "2021-07-20T16:19:39Z",
        "link": "http://arxiv.org/abs/2107.09598v4",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "A Cooperative Optimal Mining Model for Bitcoin",
        "authors": [
            "David Lajeunesse",
            "Hugo D. Scolnik"
        ],
        "summary": "We analyze Bitcoin mining from the perspective of a game and propose an optimal mining model that maximizes profits of pools and miners. The model is a two-stage Stackelberg game in which each stage forms a sub-game. In stage I, pools are the leaders who assign a computing power to be consumed by miners. In stage II, miners decide of their power consumption and distribution. They find themselves in a social dilemma in which they must choose between mining in solo, therefore prioritizing their individual preferences, and participating in a pool for the collective interest. The model relies on a pool protocol based on a simulated game in which the miners compete for the reward won by the pool. The solutions for the stage I sub-game and the simulated protocol game are unique and stable Nash equilibriums while the stage II sub-game leads to a stable cooperative equilibrium only when miners choose their strategies according to certain criteria. We conclude that the cooperative optimal mining model has the potential to favor Bitcoin decentralization and stability. Mainly, the social dilemma faced by miners together with the balance of incentives ensure a certain distribution of the network computing power between pools and solo miners, while equilibriums in the game solutions provide stability to the system.",
        "published": "2021-07-20T18:20:20Z",
        "link": "http://arxiv.org/abs/2107.09707v1",
        "categories": [
            "cs.GT",
            "cs.CR",
            "cs.DC",
            "cs.MA"
        ]
    },
    {
        "title": "Improved Reinforcement Learning in Cooperative Multi-agent Environments   Using Knowledge Transfer",
        "authors": [
            "Mahnoosh Mahdavimoghaddam",
            "Amin Nikanjam",
            "Monireh Abdoos"
        ],
        "summary": "Nowadays, cooperative multi-agent systems are used to learn how to achieve goals in large-scale dynamic environments. However, learning in these environments is challenging: from the effect of search space size on learning time to inefficient cooperation among agents. Moreover, reinforcement learning algorithms may suffer from a long time of convergence in such environments. In this paper, a communication framework is introduced. In the proposed communication framework, agents learn to cooperate effectively and also by introduction of a new state calculation method the size of state space will decline considerably. Furthermore, a knowledge-transferring algorithm is presented to share the gained experiences among the different agents, and develop an effective knowledge-fusing mechanism to fuse the knowledge learnt utilizing the agents' own experiences with the knowledge received from other team members. Finally, the simulation results are provided to indicate the efficacy of the proposed method in the complex learning task. We have evaluated our approach on the shepherding problem and the results show that the learning process accelerates by making use of the knowledge transferring mechanism and the size of state space has declined by generating similar states based on state abstraction concept.",
        "published": "2021-07-20T23:42:39Z",
        "link": "http://arxiv.org/abs/2107.09807v5",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Strategic Mitigation of Agent Inattention in Drivers with Open-Quantum   Cognition Models",
        "authors": [
            "Qizi Zhang",
            "Venkata Sriram Siddhardh Nadendla",
            "S. N. Balakrishnan",
            "Jerome Busemeyer"
        ],
        "summary": "State-of-the-art driver-assist systems have failed to effectively mitigate driver inattention and had minimal impacts on the ever-growing number of road mishaps (e.g. life loss, physical injuries due to accidents caused by various factors that lead to driver inattention). This is because traditional human-machine interaction settings are modeled in classical and behavioral game-theoretic domains which are technically appropriate to characterize strategic interaction between either two utility maximizing agents, or human decision makers. Therefore, in an attempt to improve the persuasive effectiveness of driver-assist systems, we develop a novel strategic and personalized driver-assist system which adapts to the driver's mental state and choice behavior. First, we propose a novel equilibrium notion in human-system interaction games, where the system maximizes its expected utility and human decisions can be characterized using any general decision model. Then we use this novel equilibrium notion to investigate the strategic driver-vehicle interaction game where the car presents a persuasive recommendation to steer the driver towards safer driving decisions. We assume that the driver employs an open-quantum system cognition model, which captures complex aspects of human decision making such as violations to classical law of total probability and incompatibility of certain mental representations of information. We present closed-form expressions for players' final responses to each other's strategies so that we can numerically compute both pure and mixed equilibria. Numerical results are presented to illustrate both kinds of equilibria.",
        "published": "2021-07-21T06:02:03Z",
        "link": "http://arxiv.org/abs/2107.09888v1",
        "categories": [
            "eess.SY",
            "cs.AI",
            "cs.GT",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Risk-Based Safety Envelopes for Autonomous Vehicles Under Perception   Uncertainty",
        "authors": [
            "Julian Bernhard",
            "Patrick Hart",
            "Amit Sahu",
            "Christoph Schöller",
            "Michell Guzman Cancimance"
        ],
        "summary": "Ensuring the safety of autonomous vehicles, given the uncertainty in sensing other road users, is an open problem. Moreover, separate safety specifications for perception and planning components raise how to assess the overall system safety. This work provides a probabilistic approach to calculate safety envelopes under perception uncertainty. The probabilistic envelope definition is based on a risk threshold. It limits the cumulative probability that the actual safety envelope in a fully observable environment is larger than an applied envelope and is solved using iterative worst-case analysis of envelopes. Our approach extends non-probabilistic envelopes - in this work, the Responsibility-Sensitive Safety (RSS) - to handle uncertainties. To evaluate our probabilistic envelope approach, we compare it in a simulated highway merging scenario against several baseline safety architectures. Our evaluation shows that our model allows adjusting safety and performance based on a chosen risk level and the amount of perception uncertainty. We conclude with an outline of how to formally argue safety under perception uncertainty using our formulation of envelope violation risk.",
        "published": "2021-07-21T07:36:50Z",
        "link": "http://arxiv.org/abs/2107.09918v1",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "I.2.9; G.3"
        ]
    },
    {
        "title": "Multi-Agent Belief Sharing through Autonomous Hierarchical Multi-Level   Clustering",
        "authors": [
            "Mirco Theile",
            "Jonathan Ponniah",
            "Or Dantsker",
            "Marco Caccamo"
        ],
        "summary": "Coordination in multi-agent systems is challenging for agile robots such as unmanned aerial vehicles (UAVs), where relative agent positions frequently change due to unconstrained movement. The problem is exacerbated through the individual take-off and landing of agents for battery recharging leading to a varying number of active agents throughout the whole mission. This work proposes autonomous hierarchical multi-level clustering (MLC), which forms a clustering hierarchy utilizing decentralized methods. Through periodic cluster maintenance executed by cluster-heads, stable multi-level clustering is achieved. The resulting hierarchy is used as a backbone to solve the communication problem for locally-interactive applications such as UAV tracking problems. Using observation aggregation, compression, and dissemination, agents share local observations throughout the hierarchy, giving every agent a total system belief with spatially dependent resolution and freshness. Extensive simulations show that MLC yields a stable cluster hierarchy under different motion patterns and that the proposed belief sharing is highly applicable in wildfire front monitoring scenarios.",
        "published": "2021-07-21T09:37:21Z",
        "link": "http://arxiv.org/abs/2107.09973v1",
        "categories": [
            "cs.RO",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Peer Selection with Noisy Assessments",
        "authors": [
            "Omer Lev",
            "Nicholas Mattei",
            "Paolo Turrini",
            "Stanislav Zhydkov"
        ],
        "summary": "In the peer selection problem a group of agents must select a subset of themselves as winners for, e.g., peer-reviewed grants or prizes. Here, we take a Condorcet view of this aggregation problem, i.e., that there is a ground-truth ordering over the agents and we wish to select the best set of agents, subject to the noisy assessments of the peers. Given this model, some agents may be unreliable, while others might be self-interested, attempting to influence the outcome in their favour. In this paper we extend PeerNomination, the most accurate peer reviewing algorithm to date, into WeightedPeerNomination, which is able to handle noisy and inaccurate agents. To do this, we explicitly formulate assessors' reliability weights in a way that does not violate strategyproofness, and use this information to reweight their scores. We show analytically that a weighting scheme can improve the overall accuracy of the selection significantly. Finally, we implement several instances of reweighting methods and show empirically that our methods are robust in the face of noisy assessments.",
        "published": "2021-07-21T14:47:11Z",
        "link": "http://arxiv.org/abs/2107.10121v1",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.MA",
            "91A80, 91B10, 91B12, 91B14",
            "J.4; I.2"
        ]
    },
    {
        "title": "An agent-based model for modal shift in public transport",
        "authors": [
            "Thibaut Barbet",
            "Amine Nacer-Weill",
            "Changtao Yang",
            "Juste Raimbault"
        ],
        "summary": "Modal shift in public transport as a consequence of a disruption on a line has in some cases unforeseen consequences such as an increase in congestion in the rest of the network. How information is provided to users and their behavior plays a central role in such configurations. We introduce here a simple and stylised agent-based model aimed at understanding the impact of behavioural parameters on modal shift. The model is applied on a case study based on a stated preference survey for a segment of Paris suburban train network. We systematically explore the parameter space and show non-trivial patterns of congestion for some values of discrete choice parameters linked to perceived wait time and congestion. We also apply a genetic optimisation algorithm to the model to search for optimal compromises between congestion in different modes.",
        "published": "2021-07-23T18:02:24Z",
        "link": "http://arxiv.org/abs/2107.11399v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Federated Learning with Fair Worker Selection: A Multi-Round Submodular   Maximization Approach",
        "authors": [
            "Fengjiao Li",
            "Jia Liu",
            "Bo Ji"
        ],
        "summary": "In this paper, we study the problem of fair worker selection in Federated Learning systems, where fairness serves as an incentive mechanism that encourages more workers to participate in the federation. Considering the achieved training accuracy of the global model as the utility of the selected workers, which is typically a monotone submodular function, we formulate the worker selection problem as a new multi-round monotone submodular maximization problem with cardinality and fairness constraints. The objective is to maximize the time-average utility over multiple rounds subject to an additional fairness requirement that each worker must be selected for a certain fraction of time. While the traditional submodular maximization with a cardinality constraint is already a well-known NP-Hard problem, the fairness constraint in the multi-round setting adds an extra layer of difficulty. To address this novel challenge, we propose three algorithms: Fair Continuous Greedy (FairCG1 and FairCG2) and Fair Discrete Greedy (FairDG), all of which satisfy the fairness requirement whenever feasible. Moreover, we prove nontrivial lower bounds on the achieved time-average utility under FairCG1 and FairCG2. In addition, by giving a higher priority to fairness, FairDG ensures a stronger short-term fairness guarantee, which holds in every round. Finally, we perform extensive simulations to verify the effectiveness of the proposed algorithms in terms of the time-average utility and fairness satisfaction.",
        "published": "2021-07-25T05:17:34Z",
        "link": "http://arxiv.org/abs/2107.11728v1",
        "categories": [
            "cs.GT",
            "cs.DC",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Distributed Neighbor Selection in Multi-agent Networks",
        "authors": [
            "Haibin Shao",
            "Lulu Pan",
            "Mehran Mesbahi",
            "Yugeng Xi",
            "Dewei Li"
        ],
        "summary": "Achieving consensus via nearest neighbor rules is an important prerequisite for multi-agent networks to accomplish collective tasks. A common assumption in consensus setup is that each agent interacts with all its neighbors. This paper examines whether network functionality and performance can be maintained-and even enhanced-when agents interact only with a subset of their respective (available) neighbors. As shown in the paper, the answer to this inquiry is affirmative. In this direction, we show that by exploring the monotonicity property of the Laplacian eigenvectors, a neighbor selection rule with guaranteed performance enhancements, can be realized for consensus-type networks. For distributed implementation, a quantitative connection between entries of Laplacian eigenvectors and the \"relative rate of change\" in the state between neighboring agents is further established; this connection facilitates a distributed algorithm for each agent to identify \"favorable\" neighbors to interact with. Multi-agent networks with and without external influence are examined, as well as extensions to signed networks. This paper underscores the utility of Laplacian eigenvectors in the context of distributed neighbor selection, providing novel insights into distributed data-driven control of multi-agent systems.",
        "published": "2021-07-26T08:23:04Z",
        "link": "http://arxiv.org/abs/2107.12022v2",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "The Holy Grail of Multi-Robot Planning: Learning to Generate   Online-Scalable Solutions from Offline-Optimal Experts",
        "authors": [
            "Amanda Prorok",
            "Jan Blumenkamp",
            "Qingbiao Li",
            "Ryan Kortvelesy",
            "Zhe Liu",
            "Ethan Stump"
        ],
        "summary": "Many multi-robot planning problems are burdened by the curse of dimensionality, which compounds the difficulty of applying solutions to large-scale problem instances. The use of learning-based methods in multi-robot planning holds great promise as it enables us to offload the online computational burden of expensive, yet optimal solvers, to an offline learning procedure. Simply put, the idea is to train a policy to copy an optimal pattern generated by a small-scale system, and then transfer that policy to much larger systems, in the hope that the learned strategy scales, while maintaining near-optimal performance. Yet, a number of issues impede us from leveraging this idea to its full potential. This blue-sky paper elaborates some of the key challenges that remain.",
        "published": "2021-07-26T14:59:46Z",
        "link": "http://arxiv.org/abs/2107.12254v1",
        "categories": [
            "cs.RO",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "A rigorous formulation of and partial results on Lorenz's \"consensus   strikes back\" phenomenon for the Hegselmann-Krause model",
        "authors": [
            "Edvin Wedin"
        ],
        "summary": "In a 2006 paper, Jan Lorenz observed a curious behaviour in numerical simulations of the Hegselmann-Krause model: Under some circumstances, making agents more closed-minded can produce a consensus from a dense configuration of opinions which otherwise leads to fragmentation. Suppose one considers initial opinions equally spaced on an interval of length $L$. As first observed by Lorenz, simulations suggest that there are three intervals $[0, L_1)$, $(L_1, L_2)$ and $(L_2, L_3)$, with $L_1 \\approx 5.23$, $L_2 \\approx 5.67$ and $L_3 \\approx 6.84$ such that, when the number of agents is sufficiently large, consensus occurs in the first and third intervals, whereas for the second interval the system fragments into three clusters. In this paper, we prove consensus for $L \\leq 5.2$ and for $L$ sufficiently close to 6. These proofs include large computations and in principle the set of $L$ for which consensus can be proven using our approach may be extended with the use of more computing power. We also prove that the set of $L$ for which consensus occurs is open. Moreover, we prove that, when consensus is assured for the equally spaced systems, this in turn implies asymptotic almost sure consensus for the same values of $L$ when initial opinions are drawn independently and uniformly at random. We thus conjecture a pair of phase transitions, making precise the formulation of Lorenz's \"consensus strikes back\" hypothesis. Our approach makes use of the continuous agent model introduced by Blondel, Hendrickx and Tsitsiklis. Indeed, one contribution of the paper is to provide a presentation of the relationships between the three different models with equally spaced, uniformly random and continuous agents, respectively, which is more rigorous than what can be found in the existing literature.",
        "published": "2021-07-26T15:50:55Z",
        "link": "http://arxiv.org/abs/2107.12906v1",
        "categories": [
            "math.DS",
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "math.CO",
            "91D30, 93A16, 60C05"
        ]
    },
    {
        "title": "Resilient Distributed Averaging",
        "authors": [
            "Mostafa Safi",
            "Seyed Mehran Dibaji"
        ],
        "summary": "In this paper, a fully distributed averaging algorithm in the presence of adversarial Byzantine agents is proposed. The algorithm is based on a resilient retrieval procedure, where all non-Byzantine nodes send their own initial values and retrieve those of other agents. We establish that the convergence of the proposed algorithm relies on strong robustness of the graph for locally bounded adversaries. A topology analysis in terms of time complexity and relation between connectivity metrics is also presented. Simulation results are provided to verify the effectiveness of the proposed algorithms under prescribed graph conditions.",
        "published": "2021-07-26T19:39:41Z",
        "link": "http://arxiv.org/abs/2107.12450v1",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Linear Quadratic Regulator Design for Multi-input Systems with A   Distributed Cooperative Strategy",
        "authors": [
            "Peihu Duan",
            "Lidong He",
            "Zhisheng Duan",
            "Ling Shi"
        ],
        "summary": "In this paper, a cooperative Linear Quadratic Regulator (LQR) problem is investigated for multi-input systems, where each input is generated by an agent in a network. The input matrices are different and locally possessed by the corresponding agents respectively, which can be regarded as different ways for agents to control the multi-input system. By embedding a fully distributed information fusion strategy, a novel cooperative LQR-based controller is proposed. Each agent only needs to communicate with its neighbors, rather than sharing information globally in a network. Moreover, only the joint controllability is required, which allows the multi-input system to be uncontrollable for every single agent or even all its neighbors. In particular, only one-time information exchange is necessary at every control step, which significantly reduces the communication consumption. It is proved that the boundedness (convergence) of the controller gains is guaranteed for time-varying (time-invariant) systems. Furthermore, the control performance of the entire system is ensured. Generally, the proposed controller achieves a better trade-off between the control performance and the communication overhead, compared with the existing centralized/decentralized/consensus-based LQR controllers. Finally, the effectiveness of the theoretical results is illustrated by several comparative numerical examples.",
        "published": "2021-07-27T04:53:50Z",
        "link": "http://arxiv.org/abs/2107.12596v2",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Open-Ended Learning Leads to Generally Capable Agents",
        "authors": [
            "Open Ended Learning Team",
            "Adam Stooke",
            "Anuj Mahajan",
            "Catarina Barros",
            "Charlie Deck",
            "Jakob Bauer",
            "Jakub Sygnowski",
            "Maja Trebacz",
            "Max Jaderberg",
            "Michael Mathieu",
            "Nat McAleese",
            "Nathalie Bradley-Schmieg",
            "Nathaniel Wong",
            "Nicolas Porcel",
            "Roberta Raileanu",
            "Steph Hughes-Fitt",
            "Valentin Dalibard",
            "Wojciech Marian Czarnecki"
        ],
        "summary": "In this work we create agents that can perform well beyond a single, individual task, that exhibit much wider generalisation of behaviour to a massive, rich space of challenges. We define a universe of tasks within an environment domain and demonstrate the ability to train agents that are generally capable across this vast space and beyond. The environment is natively multi-agent, spanning the continuum of competitive, cooperative, and independent games, which are situated within procedurally generated physical 3D worlds. The resulting space is exceptionally diverse in terms of the challenges posed to agents, and as such, even measuring the learning progress of an agent is an open research problem. We propose an iterative notion of improvement between successive generations of agents, rather than seeking to maximise a singular objective, allowing us to quantify progress despite tasks being incomparable in terms of achievable rewards. We show that through constructing an open-ended learning process, which dynamically changes the training task distributions and training objectives such that the agent never stops learning, we achieve consistent learning of new behaviours. The resulting agent is able to score reward in every one of our humanly solvable evaluation levels, with behaviour generalising to many held-out points in the universe of tasks. Examples of this zero-shot generalisation include good performance on Hide and Seek, Capture the Flag, and Tag. Through analysis and hand-authored probe tasks we characterise the behaviour of our agent, and find interesting emergent heuristic behaviours such as trial-and-error experimentation, simple tool use, option switching, and cooperation. Finally, we demonstrate that the general capabilities of this agent could unlock larger scale transfer of behaviour through cheap finetuning.",
        "published": "2021-07-27T13:30:07Z",
        "link": "http://arxiv.org/abs/2107.12808v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Multi Agent System for Machine Learning Under Uncertainty in Cyber   Physical Manufacturing System",
        "authors": [
            "Bang Xiang Yong",
            "Alexandra Brintrup"
        ],
        "summary": "Recent advancements in predictive machine learning has led to its application in various use cases in manufacturing. Most research focused on maximising predictive accuracy without addressing the uncertainty associated with it. While accuracy is important, focusing primarily on it poses an overfitting danger, exposing manufacturers to risk, ultimately hindering the adoption of these techniques. In this paper, we determine the sources of uncertainty in machine learning and establish the success criteria of a machine learning system to function well under uncertainty in a cyber-physical manufacturing system (CPMS) scenario. Then, we propose a multi-agent system architecture which leverages probabilistic machine learning as a means of achieving such criteria. We propose possible scenarios for which our proposed architecture is useful and discuss future work. Experimentally, we implement Bayesian Neural Networks for multi-tasks classification on a public dataset for the real-time condition monitoring of a hydraulic system and demonstrate the usefulness of the system by evaluating the probability of a prediction being accurate given its uncertainty. We deploy these models using our proposed agent-based framework and integrate web visualisation to demonstrate its real-time feasibility.",
        "published": "2021-07-28T10:28:05Z",
        "link": "http://arxiv.org/abs/2107.13252v1",
        "categories": [
            "cs.MA",
            "cs.LG"
        ]
    },
    {
        "title": "Social groups in pedestrian crowds: Review of their influence on the   dynamics and their modelling",
        "authors": [
            "Alexandre Nicolas",
            "Fadratul Hafinaz"
        ],
        "summary": "Pedestrians are often encountered walking in the company of some social relations, rather than alone. The social groups thus formed, in variable proportions depending on the context, are not randomly organised but exhibit distinct features, such as the well-known tendency of 3-member groups to be arranged in a V-shape. The existence of group structures is thus likely to impact the collective dynamics of the crowd, possibly in a critical way when emergency situations are considered. After turning a blind eye to these group aspects for years, endeavours to model groups in crowd simulation software have thrived in the past decades. This fairly short review opens on a description of their empirical characteristics and their impact on the global flow. Then, it aims to offer a pedagogical discussion of the main strategies to model such groups, within different types of models, in order to provide guidance for prospective modellers.",
        "published": "2021-07-28T11:36:55Z",
        "link": "http://arxiv.org/abs/2107.13293v1",
        "categories": [
            "physics.soc-ph",
            "cs.MA"
        ]
    },
    {
        "title": "Operationally-Safe Peer-to-Peer Energy Trading in Distribution Grids: A   Game-Theoretic Market-Clearing Mechanism",
        "authors": [
            "Giuseppe Belgioioso",
            "Wicak Ananduta",
            "Sergio Grammatico",
            "Carlos Ocampo-Martinez"
        ],
        "summary": "In future distribution grids, prosumers (i.e., energy consumers with storage and/or production capabilities) will trade energy with each other and with the main grid. To ensure an efficient and safe operation of energy trading, in this paper, we formulate a peer-to-peer energy market of prosumers as a generalized aggregative game, in which a network operator is only responsible for the operational constraints of the system. We design a distributed market-clearing mechanism with convergence guarantee to an economically-efficient and operationally-safe configuration (i.e., a variational generalized Nash equilibrium). Numerical studies on the IEEE 37-bus testcase show the scalability of the proposed approach and suggest that active participation in the market is beneficial for both prosumers and the network operator.",
        "published": "2021-07-28T15:50:53Z",
        "link": "http://arxiv.org/abs/2107.13444v3",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY",
            "math.OC"
        ]
    },
    {
        "title": "Strategic Voting in the Context of Negotiating Teams",
        "authors": [
            "Leora Schmerler",
            "Noam Hazon"
        ],
        "summary": "A negotiating team is a group of two or more agents who join together as a single negotiating party because they share a common goal related to the negotiation. Since a negotiating team is composed of several stakeholders, represented as a single negotiating party, there is need for a voting rule for the team to reach decisions. In this paper, we investigate the problem of strategic voting in the context of negotiating teams. Specifically, we present a polynomial-time algorithm that finds a manipulation for a single voter when using a positional scoring rule. We show that the problem is still tractable when there is a coalition of manipulators that uses a x-approval rule. The coalitional manipulation problem becomes computationally hard when using Borda, but we provide a polynomial-time algorithm with the following guarantee: given a manipulable instance with k manipulators, the algorithm finds a successful manipulation with at most one additional manipulator. Our results hold for both constructive and destructive manipulations.",
        "published": "2021-07-29T15:25:31Z",
        "link": "http://arxiv.org/abs/2107.14097v2",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Survey of Recent Multi-Agent Reinforcement Learning Algorithms Utilizing   Centralized Training",
        "authors": [
            "Piyush K. Sharma",
            "Rolando Fernandez",
            "Erin Zaroukian",
            "Michael Dorothy",
            "Anjon Basak",
            "Derrik E. Asher"
        ],
        "summary": "Much work has been dedicated to the exploration of Multi-Agent Reinforcement Learning (MARL) paradigms implementing a centralized learning with decentralized execution (CLDE) approach to achieve human-like collaboration in cooperative tasks. Here, we discuss variations of centralized training and describe a recent survey of algorithmic approaches. The goal is to explore how different implementations of information sharing mechanism in centralized learning may give rise to distinct group coordinated behaviors in multi-agent systems performing cooperative tasks.",
        "published": "2021-07-29T20:29:12Z",
        "link": "http://arxiv.org/abs/2107.14316v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Simulation as Experiment: An Empirical Critique of Simulation Research   on Recommender Systems",
        "authors": [
            "Amy A. Winecoff",
            "Matthew Sun",
            "Eli Lucherini",
            "Arvind Narayanan"
        ],
        "summary": "Simulation can enable the study of recommender system (RS) evolution while circumventing many of the issues of empirical longitudinal studies; simulations are comparatively easier to implement, are highly controlled, and pose no ethical risk to human participants. How simulation can best contribute to scientific insight about RS alongside qualitative and quantitative empirical approaches is an open question. Philosophers and researchers have long debated the epistemological nature of simulation compared to wholly theoretical or empirical methods. Simulation is often implicitly or explicitly conceptualized as occupying a middle ground between empirical and theoretical approaches, allowing researchers to realize the benefits of both. However, what is often ignored in such arguments is that without firm grounding in any single methodological tradition, simulation studies have no agreed upon scientific norms or standards, resulting in a patchwork of theoretical motivations, approaches, and implementations that are difficult to reconcile. In this position paper, we argue that simulation studies of RS are conceptually similar to empirical experimental approaches and therefore can be evaluated using the standards of empirical research methods. Using this empirical lens, we argue that the combination of high heterogeneity in approaches and low transparency in methods in simulation studies of RS has limited their interpretability, generalizability, and replicability. We contend that by adopting standards and practices common in empirical disciplines, simulation researchers can mitigate many of these weaknesses.",
        "published": "2021-07-29T21:05:01Z",
        "link": "http://arxiv.org/abs/2107.14333v1",
        "categories": [
            "cs.CY",
            "cs.MA"
        ]
    },
    {
        "title": "Distributed Event- and Self-Triggered Coverage Control with Speed   Constrained Unicycle Robots",
        "authors": [
            "Yuni Zhou",
            "Lingxuan Kong",
            "Stefan Sosnowski",
            "Qingchen Liu",
            "Sandra Hirche"
        ],
        "summary": "Voronoi coverage control is a particular problem of importance in the area of multi-robot systems, which considers a network of multiple autonomous robots, tasked with optimally covering a large area. This is a common task for fleets of fixed-wing Unmanned Aerial Vehicles (UAVs), which are described in this work by a unicycle model with constant forward-speed constraints. We develop event-based control/communication algorithms to relax the resource requirements on wireless communication and control actuators, an important feature for battery-driven or otherwise energy-constrained systems. To overcome the drawback that the event-triggered algorithm requires continuous measurement of system states, we propose a self-triggered algorithm to estimate the next triggering time. Hardware experiments illustrate the theoretical results.",
        "published": "2021-07-30T12:34:09Z",
        "link": "http://arxiv.org/abs/2107.14580v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Strategically Efficient Exploration in Competitive Multi-agent   Reinforcement Learning",
        "authors": [
            "Robert Loftin",
            "Aadirupa Saha",
            "Sam Devlin",
            "Katja Hofmann"
        ],
        "summary": "High sample complexity remains a barrier to the application of reinforcement learning (RL), particularly in multi-agent systems. A large body of work has demonstrated that exploration mechanisms based on the principle of optimism under uncertainty can significantly improve the sample efficiency of RL in single agent tasks. This work seeks to understand the role of optimistic exploration in non-cooperative multi-agent settings. We will show that, in zero-sum games, optimistic exploration can cause the learner to waste time sampling parts of the state space that are irrelevant to strategic play, as they can only be reached through cooperation between both players. To address this issue, we introduce a formal notion of strategically efficient exploration in Markov games, and use this to develop two strategically efficient learning algorithms for finite Markov games. We demonstrate that these methods can be significantly more sample efficient than their optimistic counterparts.",
        "published": "2021-07-30T15:22:59Z",
        "link": "http://arxiv.org/abs/2107.14698v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "68T05",
            "I.2.6"
        ]
    },
    {
        "title": "Iterative Deliberation via Metric Aggregation",
        "authors": [
            "Gil Ben Zvi",
            "Eyal Leizerovich",
            "Nimrod Talmon"
        ],
        "summary": "We investigate an iterative deliberation process for an agent community wishing to make a joint decision. We develop a general model consisting of a community of n agents, each with their initial ideal point in some metric space (X, d), such that in each iteration of the iterative deliberation process, all agents move slightly closer to the current winner, according to some voting rule R. For several natural metric spaces and suitable voting rules for them, we identify conditions under which such an iterative deliberation process is guaranteed to converge.",
        "published": "2021-07-31T19:47:07Z",
        "link": "http://arxiv.org/abs/2108.00314v2",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Desperate Times Call for Desperate Measures: Towards Risk-Adaptive Task   Allocation",
        "authors": [
            "Max Rudolph",
            "Sonia Chernova",
            "Harish Ravichandar"
        ],
        "summary": "Multi-robot task allocation (MRTA) problems involve optimizing the allocation of robots to tasks. MRTA problems are known to be challenging when tasks require multiple robots and the team is composed of heterogeneous robots. These challenges are further exacerbated when we need to account for uncertainties encountered in the real-world. In this work, we address coalition formation in heterogeneous multi-robot teams with uncertain capabilities. We specifically focus on tasks that require coalitions to collectively satisfy certain minimum requirements. Existing approaches to uncertainty-aware task allocation either maximize expected pay-off (risk-neutral approaches) or improve worst-case or near-worst-case outcomes (risk-averse approaches). Within the context of our problem, we demonstrate the inherent limitations of unilaterally ignoring or avoiding risk and show that these approaches can in fact reduce the probability of satisfying task requirements. Inspired by models that explain foraging behaviors in animals, we develop a risk-adaptive approach to task allocation. Our approach adaptively switches between risk-averse and risk-seeking behavior in order to maximize the probability of satisfying task requirements. Comprehensive numerical experiments conclusively demonstrate that our risk-adaptive approach outperforms risk-neutral and risk-averse approaches. We also demonstrate the effectiveness of our approach using a simulated multi-robot emergency response scenario.",
        "published": "2021-08-01T00:42:59Z",
        "link": "http://arxiv.org/abs/2108.00346v2",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Agent-aware State Estimation in Autonomous Vehicles",
        "authors": [
            "Shane Parr",
            "Ishan Khatri",
            "Justin Svegliato",
            "Shlomo Zilberstein"
        ],
        "summary": "Autonomous systems often operate in environments where the behavior of multiple agents is coordinated by a shared global state. Reliable estimation of the global state is thus critical for successfully operating in a multi-agent setting. We introduce agent-aware state estimation -- a framework for calculating indirect estimations of state given observations of the behavior of other agents in the environment. We also introduce transition-independent agent-aware state estimation -- a tractable class of agent-aware state estimation -- and show that it allows the speed of inference to scale linearly with the number of agents in the environment. As an example, we model traffic light classification in instances of complete loss of direct observation. By taking into account observations of vehicular behavior from multiple directions of traffic, our approach exhibits accuracy higher than that of existing traffic light-only HMM methods on a real-world autonomous vehicle data set under a variety of simulated occlusion scenarios.",
        "published": "2021-08-01T05:31:00Z",
        "link": "http://arxiv.org/abs/2108.00366v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Stable Voting",
        "authors": [
            "Wesley H. Holliday",
            "Eric Pacuit"
        ],
        "summary": "We propose a new single-winner voting system using ranked ballots: Stable Voting. The motivating principle of Stable Voting is that if a candidate A would win without another candidate B in the election, and A beats B in a head-to-head majority comparison, then A should still win in the election with B included (unless there is another candidate A' who has the same kind of claim to winning, in which case a tiebreaker may choose between such candidates). We call this principle Stability for Winners (with Tiebreaking). Stable Voting satisfies this principle while also having a remarkable ability to avoid tied outcomes in elections even with small numbers of voters.",
        "published": "2021-08-01T21:06:56Z",
        "link": "http://arxiv.org/abs/2108.00542v9",
        "categories": [
            "econ.TH",
            "cs.GT",
            "cs.MA",
            "91B12, 91B14, 91B10",
            "I.2.11"
        ]
    },
    {
        "title": "Risk Adversarial Learning System for Connected and Autonomous Vehicle   Charging",
        "authors": [
            "Md. Shirajum Munir",
            "Ki Tae Kim",
            "Kyi Thar",
            "Dusit Niyato",
            "Choong Seon Hong"
        ],
        "summary": "In this paper, the design of a rational decision support system (RDSS) for a connected and autonomous vehicle charging infrastructure (CAV-CI) is studied. In the considered CAV-CI, the distribution system operator (DSO) deploys electric vehicle supply equipment (EVSE) to provide an EV charging facility for human-driven connected vehicles (CVs) and autonomous vehicles (AVs). The charging request by the human-driven EV becomes irrational when it demands more energy and charging period than its actual need. Therefore, the scheduling policy of each EVSE must be adaptively accumulated the irrational charging request to satisfy the charging demand of both CVs and AVs. To tackle this, we formulate an RDSS problem for the DSO, where the objective is to maximize the charging capacity utilization by satisfying the laxity risk of the DSO. Thus, we devise a rational reward maximization problem to adapt the irrational behavior by CVs in a data-informed manner. We propose a novel risk adversarial multi-agent learning system (RAMALS) for CAV-CI to solve the formulated RDSS problem. In RAMALS, the DSO acts as a centralized risk adversarial agent (RAA) for informing the laxity risk to each EVSE. Subsequently, each EVSE plays the role of a self-learner agent to adaptively schedule its own EV sessions by coping advice from RAA. Experiment results show that the proposed RAMALS affords around 46.6% improvement in charging rate, about 28.6% improvement in the EVSE's active charging time and at least 33.3% more energy utilization, as compared to a currently deployed ACN EVSE system, and other baselines.",
        "published": "2021-08-02T02:38:15Z",
        "link": "http://arxiv.org/abs/2108.01466v2",
        "categories": [
            "cs.AI",
            "cs.CE",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Learning who is in the market from time series: market participant   discovery through adversarial calibration of multi-agent simulators",
        "authors": [
            "Victor Storchan",
            "Svitlana Vyetrenko",
            "Tucker Balch"
        ],
        "summary": "In electronic trading markets often only the price or volume time series, that result from interaction of multiple market participants, are directly observable. In order to test trading strategies before deploying them to real-time trading, multi-agent market environments calibrated so that the time series that result from interaction of simulated agents resemble historical are often used. To ensure adequate testing, one must test trading strategies in a variety of market scenarios -- which includes both scenarios that represent ordinary market days as well as stressed markets (most recently observed due to the beginning of COVID pandemic). In this paper, we address the problem of multi-agent simulator parameter calibration to allow simulator capture characteristics of different market regimes. We propose a novel two-step method to train a discriminator that is able to distinguish between \"real\" and \"fake\" price and volume time series as a part of GAN with self-attention, and then utilize it within an optimization framework to tune parameters of a simulator model with known agent archetypes to represent a market scenario. We conclude with experimental results that demonstrate effectiveness of our method.",
        "published": "2021-08-02T06:53:37Z",
        "link": "http://arxiv.org/abs/2108.00664v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "q-fin.TR"
        ]
    },
    {
        "title": "Flip Learning: Erase to Segment",
        "authors": [
            "Yuhao Huang",
            "Xin Yang",
            "Yuxin Zou",
            "Chaoyu Chen",
            "Jian Wang",
            "Haoran Dou",
            "Nishant Ravikumar",
            "Alejandro F Frangi",
            "Jianqiao Zhou",
            "Dong Ni"
        ],
        "summary": "Nodule segmentation from breast ultrasound images is challenging yet essential for the diagnosis. Weakly-supervised segmentation (WSS) can help reduce time-consuming and cumbersome manual annotation. Unlike existing weakly-supervised approaches, in this study, we propose a novel and general WSS framework called Flip Learning, which only needs the box annotation. Specifically, the target in the label box will be erased gradually to flip the classification tag, and the erased region will be considered as the segmentation result finally. Our contribution is three-fold. First, our proposed approach erases on superpixel level using a Multi-agent Reinforcement Learning framework to exploit the prior boundary knowledge and accelerate the learning process. Second, we design two rewards: classification score and intensity distribution reward, to avoid under- and over-segmentation, respectively. Third, we adopt a coarse-to-fine learning strategy to reduce the residual errors and improve the segmentation performance. Extensively validated on a large dataset, our proposed approach achieves competitive performance and shows great potential to narrow the gap between fully-supervised and weakly-supervised learning.",
        "published": "2021-08-02T09:56:10Z",
        "link": "http://arxiv.org/abs/2108.00752v1",
        "categories": [
            "cs.CV",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Coalitional Control for Self-Organizing Agents",
        "authors": [
            "Filiberto Fele",
            "Ezequiel Debada",
            "José M. Maestre",
            "Eduardo F. Camacho"
        ],
        "summary": "Coalitional control is concerned with the management of multi-agent systems where cooperation cannot be taken for granted (due to, e.g., market competition, logistics). This paper proposes a model predictive control (MPC) framework aimed at large-scale dynamically-coupled systems whose individual components, possessing a limited model of the system, are controlled independently, pursuing possibly competing objectives. The emergence of cooperating clusters of controllers is contemplated through an autonomous negotiation protocol, based on the characterization as a coalitional game of the benefit derived by a broader feedback and the alignment of the individual objectives. Specific mechanisms for the cooperative benefit redistribution that relax the cognitive requirements of the game are employed to compensate for possible local cost increases due to cooperation. As a result, the structure of the overall MPC feedback can be adapted online to the degree of interaction between different parts of the system, while satisfying the individual interests of the agents. A wide-area control application for the power grid with the objective of minimizing frequency deviations and undesired inter-area power transfers is used as study case.",
        "published": "2021-08-02T12:08:23Z",
        "link": "http://arxiv.org/abs/2108.00802v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY",
            "math.OC"
        ]
    },
    {
        "title": "2-D Directed Formation Control Based on Bipolar Coordinates",
        "authors": [
            "Farhad Mehdifar",
            "Charalampos P. Bechlioulis",
            "Julien M. Hendrickx",
            "Dimos V. Dimarogonas"
        ],
        "summary": "This work proposes a novel 2-D formation control scheme for acyclic triangulated directed graphs (a class of minimally acyclic persistent graphs) based on bipolar coordinates with (almost) global convergence to the desired shape. Prescribed performance control is employed to devise a decentralized control law that avoids singularities and introduces robustness against external disturbances while ensuring predefined transient and steady-state performance for the closed-loop system. Furthermore, it is shown that the proposed formation control scheme can handle formation maneuvering, scaling, and orientation specifications simultaneously. Additionally, the proposed control law is implementable in agents' arbitrarily oriented local coordinate frames using only low-cost onboard vision sensors, which are favorable for practical applications. Finally, a formation maneuvering simulation study verifies the proposed approach.",
        "published": "2021-08-02T14:09:55Z",
        "link": "http://arxiv.org/abs/2108.00916v3",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.RO",
            "cs.SY"
        ]
    },
    {
        "title": "Tuning Cooperative Behavior in Games with Nonlinear Opinion Dynamics",
        "authors": [
            "Shinkyu Park",
            "Anastasia Bizyaeva",
            "Mari Kawakatsu",
            "Alessio Franci",
            "Naomi Ehrich Leonard"
        ],
        "summary": "We examine the tuning of cooperative behavior in repeated multi-agent games using an analytically tractable, continuous-time, nonlinear model of opinion dynamics. Each modeled agent updates its real-valued opinion about each available strategy in response to payoffs and other agent opinions, as observed over a network. We show how the model provides a principled and systematic means to investigate behavior of agents that select strategies using rationality and reciprocity, key features of human decision-making in social dilemmas. For two-strategy games, we use bifurcation analysis to prove conditions for the bistability of two equilibria and conditions for the first (second) equilibrium to reflect all agents favoring the first (second) strategy. We prove how model parameters, e.g., level of attention to opinions of others (reciprocity), network structure, and payoffs, influence dynamics and, notably, the size of the region of attraction to each stable equilibrium. We provide insights by examining the tuning of the bistability of mutual cooperation and mutual defection and their regions of attraction for the repeated prisoner's dilemma and the repeated multi-agent public goods game. Our results generalize to games with more strategies, heterogeneity, and additional feedback dynamics, such as those designed to elicit cooperation.",
        "published": "2021-08-02T15:11:16Z",
        "link": "http://arxiv.org/abs/2108.00966v3",
        "categories": [
            "physics.soc-ph",
            "cs.MA",
            "cs.SI",
            "math.DS",
            "math.OC"
        ]
    },
    {
        "title": "Escaping Arrow's Theorem: The Advantage-Standard Model",
        "authors": [
            "Wesley H. Holliday",
            "Mikayla Kelley"
        ],
        "summary": "There is an extensive literature in social choice theory studying the consequences of weakening the assumptions of Arrow's Impossibility Theorem. Much of this literature suggests that there is no escape from Arrow-style impossibility theorems, while remaining in an ordinal preference setting, unless one drastically violates the Independence of Irrelevant Alternatives (IIA). In this paper, we present a more positive outlook. We propose a model of comparing candidates in elections, which we call the Advantage-Standard (AS) model. The requirement that a collective choice rule (CCR) be representable by the AS model captures a key insight of IIA but is weaker than IIA; yet it is stronger than what is known in the literature as weak IIA (two profiles alike on $x,y$ cannot have opposite strict social preferences on $x$ and $y$). In addition to motivating violations of IIA, the AS model makes intelligible violations of another Arrovian assumption: the negative transitivity of the strict social preference relation $P$. While previous literature shows that only weakening IIA to weak IIA or only weakening negative transitivity of $P$ to acyclicity still leads to impossibility theorems, we show that jointly weakening IIA to AS representability and weakening negative transitivity of $P$ leads to no such impossibility theorems. Indeed, we show that several appealing CCRs are AS representable, including even transitive CCRs.",
        "published": "2021-08-02T19:24:16Z",
        "link": "http://arxiv.org/abs/2108.01134v4",
        "categories": [
            "econ.TH",
            "cs.MA",
            "91B12, 91B14, 91B10",
            "I.2.11"
        ]
    },
    {
        "title": "SABER: Data-Driven Motion Planner for Autonomously Navigating   Heterogeneous Robots",
        "authors": [
            "Alexander Schperberg",
            "Stephanie Tsuei",
            "Stefano Soatto",
            "Dennis Hong"
        ],
        "summary": "We present an end-to-end online motion planning framework that uses a data-driven approach to navigate a heterogeneous robot team towards a global goal while avoiding obstacles in uncertain environments. First, we use stochastic model predictive control (SMPC) to calculate control inputs that satisfy robot dynamics, and consider uncertainty during obstacle avoidance with chance constraints. Second, recurrent neural networks are used to provide a quick estimate of future state uncertainty considered in the SMPC finite-time horizon solution, which are trained on uncertainty outputs of various simultaneous localization and mapping algorithms. When two or more robots are in communication range, these uncertainties are then updated using a distributed Kalman filtering approach. Lastly, a Deep Q-learning agent is employed to serve as a high-level path planner, providing the SMPC with target positions that move the robots towards a desired global goal. Our complete methods are demonstrated on a ground and aerial robot simultaneously (code available at: https://github.com/AlexS28/SABER).",
        "published": "2021-08-03T02:56:21Z",
        "link": "http://arxiv.org/abs/2108.01262v1",
        "categories": [
            "cs.RO",
            "cs.CV",
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "RAIN: Reinforced Hybrid Attention Inference Network for Motion   Forecasting",
        "authors": [
            "Jiachen Li",
            "Fan Yang",
            "Hengbo Ma",
            "Srikanth Malla",
            "Masayoshi Tomizuka",
            "Chiho Choi"
        ],
        "summary": "Motion forecasting plays a significant role in various domains (e.g., autonomous driving, human-robot interaction), which aims to predict future motion sequences given a set of historical observations. However, the observed elements may be of different levels of importance. Some information may be irrelevant or even distracting to the forecasting in certain situations. To address this issue, we propose a generic motion forecasting framework (named RAIN) with dynamic key information selection and ranking based on a hybrid attention mechanism. The general framework is instantiated to handle multi-agent trajectory prediction and human motion forecasting tasks, respectively. In the former task, the model learns to recognize the relations between agents with a graph representation and to determine their relative significance. In the latter task, the model learns to capture the temporal proximity and dependency in long-term human motions. We also propose an effective double-stage training pipeline with an alternating training strategy to optimize the parameters in different modules of the framework. We validate the framework on both synthetic simulations and motion forecasting benchmarks in different domains, demonstrating that our method not only achieves state-of-the-art forecasting performance, but also provides interpretable and reasonable hybrid attention weights.",
        "published": "2021-08-03T06:30:30Z",
        "link": "http://arxiv.org/abs/2108.01316v1",
        "categories": [
            "cs.CV",
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Dynamic communication topologies for distributed heuristics in energy   system optimization algorithms",
        "authors": [
            "Stefanie Holly",
            "Astrid Nieße"
        ],
        "summary": "The communication topology is an essential aspect in designing distributed optimization heuristics. It can influence the exploration and exploitation of the search space and thus the optimization performance in terms of solution quality, convergence speed and collaboration costs, all relevant aspects for applications operating critical infrastructure in energy systems. In this work, we present an approach for adapting the communication topology during runtime, based on the principles of simulated annealing. We compare the approach to common static topologies regarding the performance of an exemplary distributed optimization heuristic. Finally, we investigate the correlations between fitness landscape properties and defined performance metrics.",
        "published": "2021-08-03T09:30:56Z",
        "link": "http://arxiv.org/abs/2108.01380v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Featured Team Automata",
        "authors": [
            "Maurice H. ter Beek",
            "Guillermina Cledou",
            "Rolf Hennicker",
            "José Proença"
        ],
        "summary": "We propose featured team automata to support variability in the development and analysis of teams, which are systems of reactive components that communicate according to specified synchronisation types. A featured team automaton concisely describes a family of concrete product models for specific configurations determined by feature selection. We focus on the analysis of communication-safety properties, but doing so product-wise quickly becomes impractical. Therefore, we investigate how to lift notions of receptiveness (no message loss) to the level of family models. We show that featured (weak) receptiveness of featured team automata characterises (weak) receptiveness for all product instantiations. A prototypical tool supports the developed theory.",
        "published": "2021-08-03T23:05:09Z",
        "link": "http://arxiv.org/abs/2108.01784v1",
        "categories": [
            "cs.FL",
            "cs.MA"
        ]
    },
    {
        "title": "Emergent Discrete Communication in Semantic Spaces",
        "authors": [
            "Mycal Tucker",
            "Huao Li",
            "Siddharth Agrawal",
            "Dana Hughes",
            "Katia Sycara",
            "Michael Lewis",
            "Julie Shah"
        ],
        "summary": "Neural agents trained in reinforcement learning settings can learn to communicate among themselves via discrete tokens, accomplishing as a team what agents would be unable to do alone. However, the current standard of using one-hot vectors as discrete communication tokens prevents agents from acquiring more desirable aspects of communication such as zero-shot understanding. Inspired by word embedding techniques from natural language processing, we propose neural agent architectures that enables them to communicate via discrete tokens derived from a learned, continuous space. We show in a decision theoretic framework that our technique optimizes communication over a wide range of scenarios, whereas one-hot tokens are only optimal under restrictive assumptions. In self-play experiments, we validate that our trained agents learn to cluster tokens in semantically-meaningful ways, allowing them communicate in noisy environments where other techniques fail. Lastly, we demonstrate both that agents using our method can effectively respond to novel human communication and that humans can understand unlabeled emergent agent communication, outperforming the use of one-hot communication.",
        "published": "2021-08-04T03:32:48Z",
        "link": "http://arxiv.org/abs/2108.01828v3",
        "categories": [
            "cs.LG",
            "cs.CL",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Offline Decentralized Multi-Agent Reinforcement Learning",
        "authors": [
            "Jiechuan Jiang",
            "Zongqing Lu"
        ],
        "summary": "In many real-world multi-agent cooperative tasks, due to high cost and risk, agents cannot continuously interact with the environment and collect experiences during learning, but have to learn from offline datasets. However, the transition dynamics in the dataset of each agent can be much different from the ones induced by the learned policies of other agents in execution, creating large errors in value estimates. Consequently, agents learn uncoordinated low-performing policies. In this paper, we propose a framework for offline decentralized multi-agent reinforcement learning, which exploits value deviation and transition normalization to deliberately modify the transition probabilities. Value deviation optimistically increases the transition probabilities of high-value next states, and transition normalization normalizes the transition probabilities of next states. They together enable agents to learn high-performing and coordinated policies. Theoretically, we prove the convergence of Q-learning under the altered non-stationary transition dynamics. Empirically, we show that the framework can be easily built on many existing offline reinforcement learning algorithms and achieve substantial improvement in a variety of multi-agent tasks.",
        "published": "2021-08-04T03:53:33Z",
        "link": "http://arxiv.org/abs/2108.01832v2",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Model-Based Opponent Modeling",
        "authors": [
            "Xiaopeng Yu",
            "Jiechuan Jiang",
            "Wanpeng Zhang",
            "Haobin Jiang",
            "Zongqing Lu"
        ],
        "summary": "When one agent interacts with a multi-agent environment, it is challenging to deal with various opponents unseen before. Modeling the behaviors, goals, or beliefs of opponents could help the agent adjust its policy to adapt to different opponents. In addition, it is also important to consider opponents who are learning simultaneously or capable of reasoning. However, existing work usually tackles only one of the aforementioned types of opponents. In this paper, we propose model-based opponent modeling (MBOM), which employs the environment model to adapt to all kinds of opponents. MBOM simulates the recursive reasoning process in the environment model and imagines a set of improving opponent policies. To effectively and accurately represent the opponent policy, MBOM further mixes the imagined opponent policies according to the similarity with the real behaviors of opponents. Empirically, we show that MBOM achieves more effective adaptation than existing methods in a variety of tasks, respectively with different types of opponents, i.e., fixed policy, na\\\"ive learner, and reasoning learner.",
        "published": "2021-08-04T04:42:43Z",
        "link": "http://arxiv.org/abs/2108.01843v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Resource-Aware Adaptation of Heterogeneous Strategies for Coalition   Formation",
        "authors": [
            "Anusha Srikanthan",
            "Harish Ravichandar"
        ],
        "summary": "Existing approaches to coalition formation often assume that requirements associated with tasks are precisely specified by the human operator. However, prior work has demonstrated that humans, while extremely adept at solving complex problems, struggle to explicitly state their solution strategy. Further, existing approaches often ignore the fact that experts may utilize different, but equally-valid, solutions (i.e., heterogeneous strategies) to the same problem. In this work, we propose a two-part framework to address these challenges. First, we tackle the challenge of inferring implicit strategies directly from expert demonstrations of coalition formation. To this end, we model and infer such heterogeneous strategies as capability-based requirements associated with each task. Next, we propose a method capable of adaptively selecting one of the inferred strategies that best suits the target team without requiring additional training. Specifically, we formulate and solve a constrained optimization problem that simultaneously selects the most appropriate strategy given the target team's capabilities, and allocates its constituents into appropriate coalitions. We evaluate our approach against several baselines, including some that resemble existing approaches, using detailed numerical simulations, StarCraft II battles, and a multi-robot emergency-response scenario. Our results indicate that our framework consistently outperforms all baselines in terms of requirement satisfaction, resource utilization, and task success rates.",
        "published": "2021-08-05T16:53:28Z",
        "link": "http://arxiv.org/abs/2108.02733v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Reinforcement Learning for Intelligent Healthcare Systems: A   Comprehensive Survey",
        "authors": [
            "Alaa Awad Abdellatif",
            "Naram Mhaisen",
            "Zina Chkirbene",
            "Amr Mohamed",
            "Aiman Erbad",
            "Mohsen Guizani"
        ],
        "summary": "The rapid increase in the percentage of chronic disease patients along with the recent pandemic pose immediate threats on healthcare expenditure and elevate causes of death. This calls for transforming healthcare systems away from one-on-one patient treatment into intelligent health systems, to improve services, access and scalability, while reducing costs. Reinforcement Learning (RL) has witnessed an intrinsic breakthrough in solving a variety of complex problems for diverse applications and services. Thus, we conduct in this paper a comprehensive survey of the recent models and techniques of RL that have been developed/used for supporting Intelligent-healthcare (I-health) systems. This paper can guide the readers to deeply understand the state-of-the-art regarding the use of RL in the context of I-health. Specifically, we first present an overview for the I-health systems challenges, architecture, and how RL can benefit these systems. We then review the background and mathematical modeling of different RL, Deep RL (DRL), and multi-agent RL models. After that, we provide a deep literature review for the applications of RL in I-health systems. In particular, three main areas have been tackled, i.e., edge intelligence, smart core network, and dynamic treatment regimes. Finally, we highlight emerging challenges and outline future research directions in driving the future success of RL in I-health systems, which opens the door for exploring some interesting and unsolved problems.",
        "published": "2021-08-05T18:47:17Z",
        "link": "http://arxiv.org/abs/2108.04087v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Building a Foundation for Data-Driven, Interpretable, and Robust Policy   Design using the AI Economist",
        "authors": [
            "Alexander Trott",
            "Sunil Srinivasa",
            "Douwe van der Wal",
            "Sebastien Haneuse",
            "Stephan Zheng"
        ],
        "summary": "Optimizing economic and public policy is critical to address socioeconomic issues and trade-offs, e.g., improving equality, productivity, or wellness, and poses a complex mechanism design problem. A policy designer needs to consider multiple objectives, policy levers, and behavioral responses from strategic actors who optimize for their individual objectives. Moreover, real-world policies should be explainable and robust to simulation-to-reality gaps, e.g., due to calibration issues. Existing approaches are often limited to a narrow set of policy levers or objectives that are hard to measure, do not yield explicit optimal policies, or do not consider strategic behavior, for example. Hence, it remains challenging to optimize policy in real-world scenarios. Here we show that the AI Economist framework enables effective, flexible, and interpretable policy design using two-level reinforcement learning (RL) and data-driven simulations. We validate our framework on optimizing the stringency of US state policies and Federal subsidies during a pandemic, e.g., COVID-19, using a simulation fitted to real data. We find that log-linear policies trained using RL significantly improve social welfare, based on both public health and economic outcomes, compared to past outcomes. Their behavior can be explained, e.g., well-performing policies respond strongly to changes in recovery and vaccination rates. They are also robust to calibration errors, e.g., infection rates that are over or underestimated. As of yet, real-world policymaking has not seen adoption of machine learning methods at large, including RL and AI-driven simulations. Our results show the potential of AI to guide policy design and improve social welfare amidst the complexity of the real world.",
        "published": "2021-08-06T01:30:41Z",
        "link": "http://arxiv.org/abs/2108.02904v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "econ.EM",
            "econ.GN",
            "q-fin.EC"
        ]
    },
    {
        "title": "Artificial Intelligence-Driven Customized Manufacturing Factory: Key   Technologies, Applications, and Challenges",
        "authors": [
            "Jiafu Wan",
            "Xiaomin Li",
            "Hong-Ning Dai",
            "Andrew Kusiak",
            "Miguel Martínez-García",
            "Di Li"
        ],
        "summary": "The traditional production paradigm of large batch production does not offer flexibility towards satisfying the requirements of individual customers. A new generation of smart factories is expected to support new multi-variety and small-batch customized production modes. For that, Artificial Intelligence (AI) is enabling higher value-added manufacturing by accelerating the integration of manufacturing and information communication technologies, including computing, communication, and control. The characteristics of a customized smart factory are to include self-perception, operations optimization, dynamic reconfiguration, and intelligent decision-making. The AI technologies will allow manufacturing systems to perceive the environment, adapt to external needs, and extract the processed knowledge, including business models, such as intelligent production, networked collaboration, and extended service models.   This paper focuses on the implementation of AI in customized manufacturing (CM). The architecture of an AI-driven customized smart factory is presented. Details of intelligent manufacturing devices, intelligent information interaction, and the construction of a flexible manufacturing line are showcased. The state-of-the-art AI technologies of potential use in CM, i.e., machine learning, multi-agent systems, Internet of Things, big data, and cloud-edge computing are surveyed. The AI-enabled technologies in a customized smart factory are validated with a case study of customized packaging. The experimental results have demonstrated that the AI-assisted CM offers the possibility of higher production flexibility and efficiency. Challenges and solutions related to AI in CM are also discussed.",
        "published": "2021-08-07T07:14:36Z",
        "link": "http://arxiv.org/abs/2108.03383v2",
        "categories": [
            "cs.AI",
            "cs.MA",
            "cs.RO",
            "68T40, 68T42, 68T05",
            "I.2.1; I.2.11; I.2.9"
        ]
    },
    {
        "title": "Game Theory and Machine Learning in UAVs-Assisted Wireless Communication   Networks: A Survey",
        "authors": [
            "M. Zhou",
            "Y. Guan",
            "M. Hayajneh",
            "K. Niu",
            "C. Abdallah"
        ],
        "summary": "In recent years, Unmanned Aerial Vehicles (UAVs) have been used in fields such as architecture, business delivery, military and civilian theaters, and many others. With increased applications comes the increased demand for advanced algorithms for resource allocation and energy management. As is well known, game theory and machine learning are two powerful tools already widely used in the wireless communication field and there are numerous surveys of game theory and machine learning usage in wireless communication. Existing surveys however focus either on game theory or machine learning and due to this fact, the current article surveys both game-theoretic and machine learning algorithms for use by UAVs in Wireless Communication Networks (U-WCNs). We also discuss how to combine game theory and machine learning for solving problems in U-WCNs and identify several future research directions.",
        "published": "2021-08-07T18:11:40Z",
        "link": "http://arxiv.org/abs/2108.03495v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Covert, Low-Delay, Coded Message Passing in Mobile (IoT) Networks",
        "authors": [
            "Pei Peng",
            "Emina Soljanin"
        ],
        "summary": "We introduce a gossip-like protocol for covert message passing between Alice and Bob as they move in an area watched over by a warden Willie. The area hosts a multitude of Internet of (Battlefield) Things (Io\\b{eta}T) objects. Alice and Bob perform random walks on a random regular graph. The Io\\b{eta}T objects reside on the vertices of this graph, and some can serve as relays between Alice and Bob. The protocol starts with Alice splitting her message into small chunks, which she can covertly deposit to the relays she encounters. The protocol ends with Bob collecting the chunks. Alice may encode her data before the dissemination. Willie can either perform random walks as Alice and Bob do or conduct uniform surveillance of the area. In either case, he can only observe one relay at a time. We evaluate the system performance by the covertness probability and the message passing delay. In our protocol, Alice splits her message to increase the covertness probability and adds (coded) redundancy to reduce the transmission delay. The performance metrics depend on the graph, communications delay, and code parameters. We show that, in most scenarios, it is impossible to find the design parameters that simultaneously maximize the covertness probability and minimize the message delay.",
        "published": "2021-08-07T22:14:46Z",
        "link": "http://arxiv.org/abs/2108.03530v2",
        "categories": [
            "cs.IT",
            "cs.MA",
            "math.IT"
        ]
    },
    {
        "title": "Mis-spoke or mis-lead: Achieving Robustness in Multi-Agent Communicative   Reinforcement Learning",
        "authors": [
            "Wanqi Xue",
            "Wei Qiu",
            "Bo An",
            "Zinovi Rabinovich",
            "Svetlana Obraztsova",
            "Chai Kiat Yeo"
        ],
        "summary": "Recent studies in multi-agent communicative reinforcement learning (MACRL) have demonstrated that multi-agent coordination can be greatly improved by allowing communication between agents. Meanwhile, adversarial machine learning (ML) has shown that ML models are vulnerable to attacks. Despite the increasing concern about the robustness of ML algorithms, how to achieve robust communication in multi-agent reinforcement learning has been largely neglected. In this paper, we systematically explore the problem of adversarial communication in MACRL. Our main contributions are threefold. First, we propose an effective method to perform attacks in MACRL, by learning a model to generate optimal malicious messages. Second, we develop a defence method based on message reconstruction, to maintain multi-agent coordination under message attacks. Third, we formulate the adversarial communication problem as a two-player zero-sum game and propose a game-theoretical method R-MACRL to improve the worst-case defending performance. Empirical results demonstrate that many state-of-the-art MACRL methods are vulnerable to message attacks, and our method can significantly improve their robustness.",
        "published": "2021-08-09T04:41:47Z",
        "link": "http://arxiv.org/abs/2108.03803v2",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Scaling New Peaks: A Viewership-centric Approach to Automated Content   Curation",
        "authors": [
            "Subhabrata Majumdar",
            "Deirdre Paul",
            "Eric Zavesky"
        ],
        "summary": "Summarizing video content is important for video streaming services to engage the user in a limited time span. To this end, current methods involve manual curation or using passive interest cues to annotate potential high-interest segments to form the basis of summarized videos, and are costly and unreliable. We propose a viewership-driven, automated method that accommodates a range of segment identification goals. Using satellite television viewership data as a source of ground truth for viewer interest, we apply statistical anomaly detection on a timeline of viewership metrics to identify 'seed' segments of high viewer interest. These segments are post-processed using empirical rules and several sources of content metadata, e.g. shot boundaries, adding in personalization aspects to produce the final highlights video.   To demonstrate the flexibility of our approach, we present two case studies, on the United States Democratic Presidential Debate on 19th December 2019, and Wimbledon Women's Final 2019. We perform qualitative comparisons with their publicly available highlights, as well as early vs. late viewership comparisons for insights into possible media and social influence on viewing behavior.",
        "published": "2021-08-09T17:17:29Z",
        "link": "http://arxiv.org/abs/2108.04187v1",
        "categories": [
            "cs.MM",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Conditions for Stability in Strategic Matching",
        "authors": [
            "James P. Bailey",
            "Craig A. Tovey"
        ],
        "summary": "We consider the stability of matchings when individuals strategically submit preference information to a publicly known algorithm. Most pure Nash equilibria of the ensuing game yield a matching that is unstable with respect to the individuals' sincere preferences. We introduce a well-supported minimal dishonesty constraint, and obtain conditions under which every pure Nash equilibrium yields a matching that is stable with respect to the sincere preferences. The conditions on the matching algorithm are to be either fully-randomized, or monotonic and independent of non-spouses (INS), an IIA-like property. These conditions are significant because they support the use of algorithms other than the Gale-Shapley (man-optimal) algorithm for kidney exchange and other applications. We prove that the Gale-Shapley algorithm always yields the woman-optimal matching when individuals are minimally dishonest. However, we give a negative answer to one of Gusfield and Irving's open questions: there is no monotonic INS or fully-randomized stable matching algorithm that is certain to yield the egalitarian-optimal matching when individuals are strategic and minimally dishonest. Finally, we show that these results extend to the student placement problem, where women are polyandrous but must be honest but do not extend to the admissions problem, where women are both polyandrous and strategic.",
        "published": "2021-08-09T23:14:04Z",
        "link": "http://arxiv.org/abs/2108.04381v1",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Decentralized Observation of Discrete-Event Systems: At Least One Can   Tell",
        "authors": [
            "Stavros Tripakis",
            "Karen Rudie"
        ],
        "summary": "We introduce a new decentralized observation condition which we call \"at least one can tell\" (OCT) and which attempts to capture the idea that for any possible behavior that a system can generate, at least one decentralized observation agent can tell whether that behavior was \"good\" or \"bad\", for given formal specifications of \"good\" and \"bad\". We provide several equivalent formulations of the OCT condition, and we relate it to (and show that it is different from) previously introduced joint observability. In fact, contrary to joint observability which is undecidable, we show that the OCT condition is decidable. We also show that when the condition holds, finite-state decentralized observers exist.",
        "published": "2021-08-10T09:07:00Z",
        "link": "http://arxiv.org/abs/2108.04523v1",
        "categories": [
            "cs.FL",
            "cs.LO",
            "cs.MA",
            "cs.SE",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Land use change in agricultural systems: an integrated ecological-social   simulation model of farmer decisions and cropping system performance based on   a cellular automata approach",
        "authors": [
            "Diego Ferraro",
            "Daniela Blanco",
            "Sebastián Pessah",
            "Rodrigo Castro"
        ],
        "summary": "Agricultural systems experience land-use changes that are driven by population growth and intensification of technological inputs. This results in land-use and cover change (LUCC) dynamics representing a complex landscape transformation process. In order to study the LUCC process we developed a spatially explicit agent-based model in the form of a Cellular Automata implemented with the Cell-DEVS formalism. The resulting model called AgroDEVS is used for predicting LUCC dynamics along with their associated economic and environmental changes. AgroDEVS is structured using behavioral rules and functions representing a) crop yields, b) weather conditions, c) economic profit, d) farmer preferences, e) technology level adoption and f) natural resources consumption based on embodied energy accounting. Using data from a typical location of the Pampa region (Argentina) for the 1988-2015 period, simulation exercises showed that the economic goals were achieved, on average, each 6 out of 10 years, but the environmental thresholds were only achieved in 1.9 out of 10 years. In a set of 50-years simulations, LUCC patterns quickly converge towards the most profitable crop sequences, with no noticeable tradeoff between the economic and environmental conditions.",
        "published": "2021-08-10T21:22:49Z",
        "link": "http://arxiv.org/abs/2109.01031v2",
        "categories": [
            "econ.GN",
            "cs.MA",
            "q-fin.EC"
        ]
    },
    {
        "title": "Graph Attention Network-based Multi-agent Reinforcement Learning for   Slicing Resource Management in Dense Cellular Network",
        "authors": [
            "Yan Shao",
            "Rongpeng Li",
            "Bing Hu",
            "Yingxiao Wu",
            "Zhifeng Zhao",
            "Honggang Zhang"
        ],
        "summary": "Network slicing (NS) management devotes to providing various services to meet distinct requirements over the same physical communication infrastructure and allocating resources on demands. Considering a dense cellular network scenario that contains several NS over multiple base stations (BSs), it remains challenging to design a proper real-time inter-slice resource management strategy, so as to cope with frequent BS handover and satisfy the fluctuations of distinct service requirements. In this paper, we propose to formulate this challenge as a multi-agent reinforcement learning (MARL) problem in which each BS represents an agent. Then, we leverage graph attention network (GAT) to strengthen the temporal and spatial cooperation between agents. Furthermore, we incorporate GAT into deep reinforcement learning (DRL) and correspondingly design an intelligent real-time inter-slice resource management strategy. More specially, we testify the universal effectiveness of GAT for advancing DRL in the multi-agent system, by applying GAT on the top of both the value-based method deep Q-network (DQN) and a combination of policy-based and value-based method advantage actor-critic (A2C). Finally, we verify the superiority of the GAT-based MARL algorithms through extensive simulations.",
        "published": "2021-08-11T07:02:52Z",
        "link": "http://arxiv.org/abs/2108.05063v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Prioritized SIPP for Multi-Agent Path Finding With Kinematic Constraints",
        "authors": [
            "Zain Alabedeen Ali",
            "Konstantin Yakovlev"
        ],
        "summary": "Multi-Agent Path Finding (MAPF) is a long-standing problem in Robotics and Artificial Intelligence in which one needs to find a set of collision-free paths for a group of mobile agents (robots) operating in the shared workspace. Due to its importance, the problem is well-studied and multiple optimal and approximate algorithms are known. However, many of them abstract away from the kinematic constraints and assume that the agents can accelerate/decelerate instantaneously. This complicates the application of the algorithms on the real robots. In this paper, we present a method that mitigates this issue to a certain extent. The suggested solver is essentially, a prioritized planner based on the well-known Safe Interval Path Planning (SIPP) algorithm. Within SIPP we explicitly reason about the speed and the acceleration thus the constructed plans directly take kinematic constraints of agents into account. We suggest a range of heuristic functions for that setting and conduct a thorough empirical evaluation of the suggested algorithm.",
        "published": "2021-08-11T10:42:11Z",
        "link": "http://arxiv.org/abs/2108.05145v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "COVINS: Visual-Inertial SLAM for Centralized Collaboration",
        "authors": [
            "Patrik Schmuck",
            "Thomas Ziegler",
            "Marco Karrer",
            "Jonathan Perraudin",
            "Margarita Chli"
        ],
        "summary": "Collaborative SLAM enables a group of agents to simultaneously co-localize and jointly map an environment, thus paving the way to wide-ranging applications of multi-robot perception and multi-user AR experiences by eliminating the need for external infrastructure or pre-built maps. This article presents COVINS, a novel collaborative SLAM system, that enables multi-agent, scalable SLAM in large environments and for large teams of more than 10 agents. The paradigm here is that each agent runs visual-inertial odomety independently onboard in order to ensure its autonomy, while sharing map information with the COVINS server back-end running on a powerful local PC or a remote cloud server. The server back-end establishes an accurate collaborative global estimate from the contributed data, refining the joint estimate by means of place recognition, global optimization and removal of redundant data, in order to ensure an accurate, but also efficient SLAM process. A thorough evaluation of COVINS reveals increased accuracy of the collaborative SLAM estimates, as well as efficiency in both removing redundant information and reducing the coordination overhead, and demonstrates successful operation in a large-scale mission with 12 agents jointly performing SLAM.",
        "published": "2021-08-12T13:50:44Z",
        "link": "http://arxiv.org/abs/2108.05756v1",
        "categories": [
            "cs.RO",
            "cs.CV",
            "cs.MA"
        ]
    },
    {
        "title": "Screenline-based Two-step Calibration and its application to an   agent-based urban freight simulator",
        "authors": [
            "Yusuke Hara",
            "Takanori Sakai",
            "André Romano Alho",
            "Moshe Ben-Akiva"
        ],
        "summary": "Calibration is an essential process to make an agent-based simulator operational. Especially, the calibration for freight demand is challenging due to the model complexity and the shortage of available freight demand data compared with passenger data. This paper proposes a novel calibration method that relies solely on screenline counts, named Screenline-based Two-step Calibration (SLTC). SLTC consists of two parts: (1) tour-based demand adjustment and (2) model parameter updates. The former generates screenline-based tours by cloning/removing instances of the simulated goods vehicle tours, aiming to minimize the gaps between the observed and the simulated screenline counts. The latter updates the parameters of the commodity flow model which generates inputs to simulate goods vehicle tours. To demonstrate the practicality of the proposed method, we apply it to an agent-based urban freight simulator, SimMobility Freight. The result shows that SLTC allows the simulator to replicate the observed screenline counts with reasonable computational cost for calibration.",
        "published": "2021-08-12T23:08:31Z",
        "link": "http://arxiv.org/abs/2108.05995v1",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Bridging the gap between emotion and joint action",
        "authors": [
            "M. M. N. Bieńkiewicz",
            "A. Smykovskyi",
            "T. Olugbade",
            "S. Janaqi",
            "A. Camurri",
            "N. Bianchi-Berthouze",
            "M. Björkman",
            "B. G. Bardy"
        ],
        "summary": "Our daily human life is filled with a myriad of joint action moments, be it children playing, adults working together (i.e., team sports), or strangers navigating through a crowd. Joint action brings individuals (and embodiment of their emotions) together, in space and in time. Yet little is known about how individual emotions propagate through embodied presence in a group, and how joint action changes individual emotion. In fact, the multi-agent component is largely missing from neuroscience-based approaches to emotion, and reversely joint action research has not found a way yet to include emotion as one of the key parameters to model socio-motor interaction. In this review, we first identify the gap and then stockpile evidence showing strong entanglement between emotion and acting together from various branches of sciences. We propose an integrative approach to bridge the gap, highlight five research avenues to do so in behavioral neuroscience and digital sciences, and address some of the key challenges in the area faced by modern societies.",
        "published": "2021-08-13T14:21:37Z",
        "link": "http://arxiv.org/abs/2108.06264v1",
        "categories": [
            "q-bio.NC",
            "cs.LG",
            "cs.MA",
            "cs.RO",
            "math.DS"
        ]
    },
    {
        "title": "A Microscopic Pandemic Simulator for Pandemic Prediction Using Scalable   Million-Agent Reinforcement Learning",
        "authors": [
            "Zhenggang Tang",
            "Kai Yan",
            "Liting Sun",
            "Wei Zhan",
            "Changliu Liu"
        ],
        "summary": "Microscopic epidemic models are powerful tools for government policy makers to predict and simulate epidemic outbreaks, which can capture the impact of individual behaviors on the macroscopic phenomenon. However, existing models only consider simple rule-based individual behaviors, limiting their applicability. This paper proposes a deep-reinforcement-learning-powered microscopic model named Microscopic Pandemic Simulator (MPS). By replacing rule-based agents with rational agents whose behaviors are driven to maximize rewards, the MPS provides a better approximation of real world dynamics. To efficiently simulate with massive amounts of agents in MPS, we propose Scalable Million-Agent DQN (SMADQN). The MPS allows us to efficiently evaluate the impact of different government strategies. This paper first calibrates the MPS against real-world data in Allegheny, US, then demonstratively evaluates two government strategies: information disclosure and quarantine. The results validate the effectiveness of the proposed method. As a broad impact, this paper provides novel insights for the application of DRL in large scale agent-based networks such as economic and social networks.",
        "published": "2021-08-14T17:07:25Z",
        "link": "http://arxiv.org/abs/2108.06589v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "A Fast Algorithm for Computing the Deficiency Number of a Mahjong Hand",
        "authors": [
            "Xueqing Yan",
            "Yongming Li",
            "Sanjiang Li"
        ],
        "summary": "The tile-based multiplayer game Mahjong is widely played in Asia and has also become increasingly popular worldwide. Face-to-face or online, each player begins with a hand of 13 tiles and players draw and discard tiles in turn until they complete a winning hand. An important notion in Mahjong is the deficiency number (a.k.a. shanten number in Japanese Mahjong) of a hand, which estimates how many tile changes are necessary to complete the hand into a winning hand. The deficiency number plays an essential role in major decision-making tasks such as selecting a tile to discard. This paper proposes a fast algorithm for computing the deficiency number of a Mahjong hand. Compared with the baseline algorithm, the new algorithm is usually 100 times faster and, more importantly, respects the agent's knowledge about available tiles. The algorithm can be used as a basic procedure in all Mahjong variants by both rule-based and machine learning-based Mahjong AI.",
        "published": "2021-08-15T22:44:14Z",
        "link": "http://arxiv.org/abs/2108.06832v1",
        "categories": [
            "cs.AI",
            "cs.DM",
            "cs.MA"
        ]
    },
    {
        "title": "Tracking Multiple Fast Targets With Swarms: Interplay Between Social   Interaction and Agent Memory",
        "authors": [
            "Hian Lee Kwa",
            "Jabez Leong Kit",
            "Roland Bouffanais"
        ],
        "summary": "The task of searching for and tracking of multiple targets is a challenging one. However, most works in this area do not consider evasive targets that move faster than the agents comprising the multi-robot system. This is due to the assumption that the movement patterns of such targets, combined with their excessive speed, would make the task nearly impossible to accomplish. In this work, we show that this is not the case and we propose a decentralized search and tracking strategy in which the level of exploration and exploitation carried out by the swarm is adjustable. By tuning a swarm's exploration and exploitation dynamics, we demonstrate that there exists an optimal balance between the level of exploration and exploitation performed. This optimum maximizes its tracking performance and changes depending on the number of targets and the targets' movement profiles. We also show that the use of agent-based memory is critical in enabling the tracking of an evasive target. The obtained simulation results are validated through experimental tests with a decentralized swarm of six robots tracking a virtual fast-moving target.",
        "published": "2021-08-16T14:43:13Z",
        "link": "http://arxiv.org/abs/2108.07122v1",
        "categories": [
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Agentization of Two Population-Driven Models of Mathematical Biology",
        "authors": [
            "John C. Stevenson"
        ],
        "summary": "Single species population models and discrete stochastic gene frequency models are two standards of mathematical biology important for the evolution of populations. An agent based model is presented which reproduces these models and then explores where these models agree and disagree under relaxed specifications. For the population models, the requirement of homogeneous mixing prevents prediction of extinctions due to local resource depletion. These models also suggest equilibrium based on attainment of constant population levels though underlying population characteristics may be nowhere close to equilibrium. The discrete stochastic gene frequency models assume well mixed populations at constant levels. The models' predictions for non-constant populations in strongly oscillating and chaotic regimes are surprisingly good, only diverging from the ABM at the most chaotic levels.",
        "published": "2021-08-16T19:22:08Z",
        "link": "http://arxiv.org/abs/2108.08916v2",
        "categories": [
            "q-bio.PE",
            "cs.MA",
            "physics.soc-ph"
        ]
    },
    {
        "title": "Encirclement Guaranteed Cooperative Pursuit with Robust Model Predictive   Control",
        "authors": [
            "Chen Wang",
            "Hua Chen",
            "Jia Pan",
            "Wei Zhang"
        ],
        "summary": "This paper studies a novel encirclement guaranteed cooperative pursuit problem involving $N$ pursuers and a single evader in an unbounded two-dimensional game domain. Throughout the game, the pursuers are required to maintain encirclement of the evader, i.e., the evader should always stay inside the convex hull generated by all the pursuers, in addition to achieving the classical capture condition. To tackle this challenging cooperative pursuit problem, a robust model predictive control (RMPC) based formulation framework is first introduced, which simultaneously accounts for the encirclement and capture requirements under the assumption that the evader's action is unavailable to all pursuers. Despite the reformulation, the resulting RMPC problem involves a bilinear constraint due to the encirclement requirement. To further handle such a bilinear constraint, a novel encirclement guaranteed partitioning scheme is devised that simplifies the original bilinear RMPC problem to a number of linear tube MPC (TMPC) problems solvable in a decentralized manner. Simulation experiments demonstrate the effectiveness of the proposed solution framework. Furthermore, comparisons with existing approaches show that the explicit consideration of the encirclement condition significantly improves the chance of successful capture of the evader in various scenarios.",
        "published": "2021-08-17T04:47:30Z",
        "link": "http://arxiv.org/abs/2108.07445v1",
        "categories": [
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Is Nash Equilibrium Approximator Learnable?",
        "authors": [
            "Zhijian Duan",
            "Wenhan Huang",
            "Dinghuai Zhang",
            "Yali Du",
            "Jun Wang",
            "Yaodong Yang",
            "Xiaotie Deng"
        ],
        "summary": "In this paper, we investigate the learnability of the function approximator that approximates Nash equilibrium (NE) for games generated from a distribution. First, we offer a generalization bound using the Probably Approximately Correct (PAC) learning model. The bound describes the gap between the expected loss and empirical loss of the NE approximator. Afterward, we prove the agnostic PAC learnability of the Nash approximator. In addition to theoretical analysis, we demonstrate an application of NE approximator in experiments. The trained NE approximator can be used to warm-start and accelerate classical NE solvers. Together, our results show the practicability of approximating NE through function approximation.",
        "published": "2021-08-17T07:06:46Z",
        "link": "http://arxiv.org/abs/2108.07472v6",
        "categories": [
            "cs.GT",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Reconfigurable Broadcast Networks and Asynchronous Shared-Memory Systems   are Equivalent (Long Version)",
        "authors": [
            "A. R. Balasubramanian",
            "Chana Weil-Kennedy"
        ],
        "summary": "We show the equivalence of two distributed computing models, namely reconfigurable broadcast networks (RBN) and asynchronous shared-memory systems (ASMS), that were introduced independently. Both RBN and ASMS are systems in which a collection of anonymous, finite-state processes run the same protocol. In RBN, the processes communicate by selective broadcast: a process can broadcast a message which is received by all of its neighbors, and the set of neighbors of a process can change arbitrarily over time. In ASMS, the processes communicate by shared memory: a process can either write to or read from a shared register. Our main result is that RBN and ASMS can simulate each other, i.e. they are equivalent with respect to parameterized reachability, where we are given two (possibly infinite) sets of configurations C and C' defined by upper and lower bounds on the number of processes in each state and we would like to decide if some configuration in C can reach some configuration in C'. Using this simulation equivalence, we transfer results of RBN to ASMS and vice versa. Finally, we show that RBN and ASMS can simulate a third distributed model called immediate observation (IO) nets. Moreover, for a slightly stronger notion of simulation (which is satisfied by all the simulations given in this paper), we show that IO nets cannot simulate RBN.",
        "published": "2021-08-17T08:52:36Z",
        "link": "http://arxiv.org/abs/2108.07510v2",
        "categories": [
            "cs.LO",
            "cs.DC",
            "cs.MA"
        ]
    },
    {
        "title": "Simulation and estimation of an agent-based market-model with a matching   engine",
        "authors": [
            "Ivan Jericevich",
            "Patrick Chang",
            "Tim Gebbie"
        ],
        "summary": "An agent-based model with interacting low frequency liquidity takers inter-mediated by high-frequency liquidity providers acting collectively as market makers can be used to provide realistic simulated price impact curves. This is possible when agent-based model interactions occur asynchronously via order matching using a matching engine in event time to replace sequential calendar time market clearing. Here the matching engine infrastructure has been modified to provide a continuous feed of order confirmations and updates as message streams in order to conform more closely to live trading environments. The resulting trade and quote message data from the simulations are then aggregated, calibrated and visualised. Various stylised facts are presented along with event visualisations and price impact curves. We argue that additional realism in modelling can be achieved with a small set of agent parameters and simple interaction rules once interactions are reactive, asynchronous and in event time. We argue that the reactive nature of market agents may be a fundamental property of financial markets and when accounted for can allow for parsimonious modelling without recourse to additional sources of noise.",
        "published": "2021-08-17T15:24:45Z",
        "link": "http://arxiv.org/abs/2108.07806v2",
        "categories": [
            "q-fin.TR",
            "cs.MA",
            "q-fin.CP"
        ]
    },
    {
        "title": "Developer Operations and Engineering Multi-Agent Systems",
        "authors": [
            "Timotheus Kampik",
            "Cleber Jorge Amaral",
            "Jomi Fred Hübner"
        ],
        "summary": "In this paper, we propose the integration of approaches to Engineering Multi-Agent Systems (EMAS) with the Developer Operations (DevOps) industry best practice. Whilst DevOps facilitates the organizational autonomy of software teams, as well as the technological automation of testing, deployment, and operations pipelines, EMAS and the agent-oriented programming paradigm help instill autonomy into software artifacts. We discuss the benefits of integrating DevOps and EMAS, for example by highlighting the need for agent-oriented abstractions for quality assurance and test automation approaches. More generally, we introduce an agent-oriented perspective on the DevOps life-cycle and list a range of research challenges that are relevant for the integration of the DevOps and EMAS perspectives.",
        "published": "2021-08-18T12:37:45Z",
        "link": "http://arxiv.org/abs/2108.08117v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "LOKI: Long Term and Key Intentions for Trajectory Prediction",
        "authors": [
            "Harshayu Girase",
            "Haiming Gang",
            "Srikanth Malla",
            "Jiachen Li",
            "Akira Kanehara",
            "Karttikeya Mangalam",
            "Chiho Choi"
        ],
        "summary": "Recent advances in trajectory prediction have shown that explicit reasoning about agents' intent is important to accurately forecast their motion. However, the current research activities are not directly applicable to intelligent and safety critical systems. This is mainly because very few public datasets are available, and they only consider pedestrian-specific intents for a short temporal horizon from a restricted egocentric view. To this end, we propose LOKI (LOng term and Key Intentions), a novel large-scale dataset that is designed to tackle joint trajectory and intention prediction for heterogeneous traffic agents (pedestrians and vehicles) in an autonomous driving setting. The LOKI dataset is created to discover several factors that may affect intention, including i) agent's own will, ii) social interactions, iii) environmental constraints, and iv) contextual information. We also propose a model that jointly performs trajectory and intention prediction, showing that recurrently reasoning about intention can assist with trajectory prediction. We show our method outperforms state-of-the-art trajectory prediction methods by upto $27\\%$ and also provide a baseline for frame-wise intention estimation.",
        "published": "2021-08-18T16:57:03Z",
        "link": "http://arxiv.org/abs/2108.08236v3",
        "categories": [
            "cs.CV",
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Settling the Variance of Multi-Agent Policy Gradients",
        "authors": [
            "Jakub Grudzien Kuba",
            "Muning Wen",
            "Yaodong Yang",
            "Linghui Meng",
            "Shangding Gu",
            "Haifeng Zhang",
            "David Henry Mguni",
            "Jun Wang"
        ],
        "summary": "Policy gradient (PG) methods are popular reinforcement learning (RL) methods where a baseline is often applied to reduce the variance of gradient estimates. In multi-agent RL (MARL), although the PG theorem can be naturally extended, the effectiveness of multi-agent PG (MAPG) methods degrades as the variance of gradient estimates increases rapidly with the number of agents. In this paper, we offer a rigorous analysis of MAPG methods by, firstly, quantifying the contributions of the number of agents and agents' explorations to the variance of MAPG estimators. Based on this analysis, we derive the optimal baseline (OB) that achieves the minimal variance. In comparison to the OB, we measure the excess variance of existing MARL algorithms such as vanilla MAPG and COMA. Considering using deep neural networks, we also propose a surrogate version of OB, which can be seamlessly plugged into any existing PG methods in MARL. On benchmarks of Multi-Agent MuJoCo and StarCraft challenges, our OB technique effectively stabilises training and improves the performance of multi-agent PPO and COMA algorithms by a significant margin.",
        "published": "2021-08-19T10:49:10Z",
        "link": "http://arxiv.org/abs/2108.08612v3",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "An Agent-Based Model of COVID-19 Diffusion to Plan and Evaluate   Intervention Policies",
        "authors": [
            "Gianpiero Pescarmona",
            "Pietro Terna",
            "Alberto Acquadro",
            "Paolo Pescarmona",
            "Giuseppe Russo",
            "Emilio Sulis",
            "Stefano Terna"
        ],
        "summary": "A model of interacting agents, following plausible behavioral rules into a world where the Covid-19 epidemic is affecting the actions of everyone. The model works with (i) infected agents categorized as symptomatic or asymptomatic and (ii) the places of contagion specified in a detailed way. The infection transmission is related to three factors: the characteristics of both the infected person and the susceptible one, plus those of the space in which contact occurs. The model includes the structural data of Piedmont, an Italian region, but we can easily calibrate it for other areas. The micro-based structure of the model allows factual, counterfactual, and conditional simulations to investigate both the spontaneous or controlled development of the epidemic. The model is generative of complex epidemic dynamics emerging from the consequences of agents' actions and interactions, with high variability in outcomes and stunning realistic reproduction of the successive contagion waves in the reference region. There is also an inverse generative side of the model, coming from the idea of using genetic algorithms to construct a meta-agent to optimize the vaccine distribution. This agent takes into account groups' characteristics -- by age, fragility, work conditions -- to minimize the number of symptomatic people.",
        "published": "2021-08-19T19:23:17Z",
        "link": "http://arxiv.org/abs/2108.08885v1",
        "categories": [
            "cs.MA",
            "cs.CY"
        ]
    },
    {
        "title": "Temporal Induced Self-Play for Stochastic Bayesian Games",
        "authors": [
            "Weizhe Chen",
            "Zihan Zhou",
            "Yi Wu",
            "Fei Fang"
        ],
        "summary": "One practical requirement in solving dynamic games is to ensure that the players play well from any decision point onward. To satisfy this requirement, existing efforts focus on equilibrium refinement, but the scalability and applicability of existing techniques are limited. In this paper, we propose Temporal-Induced Self-Play (TISP), a novel reinforcement learning-based framework to find strategies with decent performances from any decision point onward. TISP uses belief-space representation, backward induction, policy learning, and non-parametric approximation. Building upon TISP, we design a policy-gradient-based algorithm TISP-PG. We prove that TISP-based algorithms can find approximate Perfect Bayesian Equilibrium in zero-sum one-sided stochastic Bayesian games with finite horizon. We test TISP-based algorithms in various games, including finitely repeated security games and a grid-world game. The results show that TISP-PG is more scalable than existing mathematical programming-based methods and significantly outperforms other learning-based methods.",
        "published": "2021-08-21T05:36:42Z",
        "link": "http://arxiv.org/abs/2108.09444v1",
        "categories": [
            "cs.MA",
            "cs.GT",
            "cs.LG",
            "I.2.11"
        ]
    },
    {
        "title": "Heterogeneous Graph Attention Networks for Learning Diverse   Communication",
        "authors": [
            "Esmaeil Seraj",
            "Zheyuan Wang",
            "Rohan Paleja",
            "Matthew Sklar",
            "Anirudh Patel",
            "Matthew Gombolay"
        ],
        "summary": "Multi-agent teaming achieves better performance when there is communication among participating agents allowing them to coordinate their actions for maximizing shared utility. However, when collaborating a team of agents with different action and observation spaces, information sharing is not straightforward and requires customized communication protocols, depending on sender and receiver types. Without properly modeling such heterogeneity in agents, communication becomes less helpful and could even deteriorate the multi-agent cooperation performance. We propose heterogeneous graph attention networks, called HetNet, to learn efficient and diverse communication models for coordinating heterogeneous agents towards accomplishing tasks that are of collaborative nature. We propose a Multi-Agent Heterogeneous Actor-Critic (MAHAC) learning paradigm to obtain collaborative per-class policies and effective communication protocols for composite robot teams. Our proposed framework is evaluated against multiple baselines in a complex environment in which agents of different types must communicate and cooperate to satisfy the objectives. Experimental results show that HetNet outperforms the baselines in learning sophisticated multi-agent communication protocols by achieving $\\sim$10\\% improvements in performance metrics.",
        "published": "2021-08-21T19:35:30Z",
        "link": "http://arxiv.org/abs/2108.09568v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "A Simplicial Model for $KB4_n$: Epistemic Logic with Agents that May Die",
        "authors": [
            "Éric Goubault",
            "Jérémy Ledent",
            "Sergio Rajsbaum"
        ],
        "summary": "The standard semantics of multi-agent epistemic logic S5 is based on Kripke models whose accessibility relations are reflexive, symmetric and transitive. This one dimensional structure contains implicit higher-dimensional information beyond pairwise interactions, that we formalized as pure simplicial models in a previous work (Information and Computation, 2021). Here we extend the theory to encompass simplicial models that are not necessarily pure. The corresponding class of Kripke models are those where the accessibility relation is symmetric and transitive, but might not be reflexive. Such models correspond to the epistemic logic KB4 . Impure simplicial models arise in situations where two possible worlds may not have the same set of agents. We illustrate it with distributed computing examples of synchronous systems where processes may crash.",
        "published": "2021-08-23T17:10:13Z",
        "link": "http://arxiv.org/abs/2108.10293v3",
        "categories": [
            "cs.LO",
            "cs.AI",
            "cs.DC",
            "cs.MA",
            "math.LO",
            "68R99, 68Q85, 68T27, 57Z25",
            "F.4.1; I.2.4"
        ]
    },
    {
        "title": "Gender-based occupational segregation: a bit string approach",
        "authors": [
            "Joana Passinhas",
            "Tanya Araújo"
        ],
        "summary": "The systematic differences of gender representation across occupations, gender-based occupational segregation, has been suggested as one of the most important determinants of the still existing gender wage gap. Despite some signs of a decreasing trend, there is evidence that occupational gendered segregation is persistent even though gender differences in human capital variables have been disappearing. Using an agent-based model we provide a framework that introduces discriminatory behavior based on labour market theories of discrimination where workers and firms can exhibit gendered preferences. The introduction of discriminatory behavior transforms the otherwise random dynamics of occupational choice into a persistent gender-based occupational segregation consistent with empirical evidence.",
        "published": "2021-08-23T18:07:28Z",
        "link": "http://arxiv.org/abs/2108.10343v1",
        "categories": [
            "cs.SI",
            "cs.MA",
            "nlin.AO",
            "68U99",
            "I.6"
        ]
    },
    {
        "title": "Human operator cognitive availability aware Mixed-Initiative control",
        "authors": [
            "Giannis Petousakis",
            "Manolis Chiou",
            "Grigoris Nikolaou",
            "Rustam Stolkin"
        ],
        "summary": "This paper presents a Cognitive Availability Aware Mixed-Initiative Controller for remotely operated mobile robots. The controller enables dynamic switching between different levels of autonomy (LOA), initiated by either the AI or the human operator. The controller leverages a state-of-the-art computer vision method and an off-the-shelf web camera to infer the cognitive availability of the operator and inform the AI-initiated LOA switching. This constitutes a qualitative advancement over previous Mixed-Initiative (MI) controllers. The controller is evaluated in a disaster response experiment, in which human operators have to conduct an exploration task with a remote robot. MI systems are shown to effectively assist the operators, as demonstrated by quantitative and qualitative results in performance and workload. Additionally, some insights into the experimental difficulties of evaluating complex MI controllers are presented.",
        "published": "2021-08-26T16:21:56Z",
        "link": "http://arxiv.org/abs/2108.11885v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.HC",
            "cs.MA"
        ]
    },
    {
        "title": "Dynamics of Wealth Inequality in Simple Artificial Societies",
        "authors": [
            "John C. Stevenson"
        ],
        "summary": "A simple generative model of a foraging society generates significant wealth inequalities from identical agents on an equal opportunity landscape. These inequalities arise in both equilibrium and non-equilibrium regimes with some societies essentially never reaching equilibrium. Reproduction costs mitigate inequality beyond their affect on intrinsic growth rate. The highest levels of inequality are found during non-equilibrium regimes. Inequality in dynamic regimes is driven by factors different than those driving steady state inequality. Evolutionary pressures drive the intrinsic growth rate as high as possible, leading to a tragedy of the commons.",
        "published": "2021-08-26T16:30:33Z",
        "link": "http://arxiv.org/abs/2108.11892v2",
        "categories": [
            "physics.soc-ph",
            "cs.MA",
            "econ.GN",
            "q-fin.EC"
        ]
    },
    {
        "title": "Commutative Monoid Formalism for Weighted Coupled Cell Networks and   Invariant Synchrony Patterns",
        "authors": [
            "Pedro M. Sequeira",
            "António P. Aguiar",
            "João Hespanha"
        ],
        "summary": "This paper presents a framework based on matrices of monoids for the study of coupled cell networks. We formally prove within the proposed framework, that the set of results about invariant synchrony patterns for unweighted networks also holds for the weighted case. Moreover, the approach described allows us to reason about any multiedge and multiedge-type network as if it was single edge and single-edge-type. Several examples illustrate the concepts described. Additionally, an improvement of the coarsest invariant refinement algorithm to find balanced partitions is presented that exhibits a worst-case complexity of $ \\mathbf{O}(\\vert\\mathcal{C}\\vert^3) $, where $\\mathcal{C}$ denotes the set of cells.",
        "published": "2021-08-26T18:43:18Z",
        "link": "http://arxiv.org/abs/2108.11991v1",
        "categories": [
            "cs.MA",
            "math.DS",
            "34A34, 34C45"
        ]
    },
    {
        "title": "Distributed Swarm Collision Avoidance Based on Angular Calculations",
        "authors": [
            "SeyedZahir Qazavi",
            "Samaneh Hosseini Semnani"
        ],
        "summary": "Collision avoidance is one of the most important topics in the robotics field. The goal is to move the robots from initial locations to target locations such that they follow shortest non-colliding paths in the shortest time and with the least amount of energy. In this paper, a distributed and real-time algorithm for dense and complex 2D and 3D environments is proposed. This algorithm uses angular calculations to select the optimal direction for the movement of each robot and it has been shown that these separate calculations lead to a form of cooperative behavior among agents. We evaluated the proposed approach on various simulation and experimental scenarios and compared the results with FMP and ORCA, two important algorithms in this field. The results show that the proposed approach is at least 25% faster than ORCA and at least 7% faster than FMP and also more reliable than both methods. The proposed method is shown to enable fully autonomous navigation of a swarm of crazyflies.",
        "published": "2021-08-29T23:12:38Z",
        "link": "http://arxiv.org/abs/2108.12934v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Learning Meta Representations for Agents in Multi-Agent Reinforcement   Learning",
        "authors": [
            "Shenao Zhang",
            "Li Shen",
            "Lei Han",
            "Li Shen"
        ],
        "summary": "In multi-agent reinforcement learning, the behaviors that agents learn in a single Markov Game (MG) are typically confined to the given agent number. Every single MG induced by varying the population may possess distinct optimal joint strategies and game-specific knowledge, which are modeled independently in modern multi-agent reinforcement learning algorithms. In this work, our focus is on creating agents that can generalize across population-varying MGs. Instead of learning a unimodal policy, each agent learns a policy set comprising effective strategies across a variety of games. To achieve this, we propose Meta Representations for Agents (MRA) that explicitly models the game-common and game-specific strategic knowledge. By representing the policy sets with multi-modal latent policies, the game-common strategic knowledge and diverse strategic modes are discovered through an iterative optimization procedure. We prove that by approximately maximizing the resulting constrained mutual information objective, the policies can reach Nash Equilibrium in every evaluation MG when the latent space is sufficiently large. When deploying MRA in practical settings with limited latent space sizes, fast adaptation can be achieved by leveraging the first-order gradient information. Extensive experiments demonstrate the effectiveness of MRA in improving training performance and generalization ability in challenging evaluation games.",
        "published": "2021-08-30T04:30:53Z",
        "link": "http://arxiv.org/abs/2108.12988v3",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Multi-Agent Simulation for AI Behaviour Discovery in Operations Research",
        "authors": [
            "Michael Papasimeon",
            "Lyndon Benke"
        ],
        "summary": "We describe ACE0, a lightweight platform for evaluating the suitability and viability of AI methods for behaviour discovery in multiagent simulations. Specifically, ACE0 was designed to explore AI methods for multi-agent simulations used in operations research studies related to new technologies such as autonomous aircraft. Simulation environments used in production are often high-fidelity, complex, require significant domain knowledge and as a result have high R&D costs. Minimal and lightweight simulation environments can help researchers and engineers evaluate the viability of new AI technologies for behaviour discovery in a more agile and potentially cost effective manner. In this paper we describe the motivation for the development of ACE0.We provide a technical overview of the system architecture, describe a case study of behaviour discovery in the aerospace domain, and provide a qualitative evaluation of the system. The evaluation includes a brief description of collaborative research projects with academic partners, exploring different AI behaviour discovery methods.",
        "published": "2021-08-30T15:14:06Z",
        "link": "http://arxiv.org/abs/2108.13296v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "I.2.11"
        ]
    },
    {
        "title": "CWmin Estimation and Collision Identification in Wi-Fi Systems",
        "authors": [
            "Amir-Hossein Yazdani-Abyaneh",
            "Marwan Krunz"
        ],
        "summary": "Wi-Fi networks are susceptible to aggressive behavior caused by selfish or malicious devices that reduce their minimum contention window size (CWmin) to below the standard CWmin. In this paper, we propose a scheme called Minimum Contention Window Estimation (CWE) to detect aggressive stations with low CWmin's, where the AP estimates the CWmin value of all stations transmitting uplink by monitoring their backoff values over a period of time and keeping track of the idle time each station spends during backoff. To correctly estimate each backoff value, we present a cross-correlation-based technique that uses the frequency offset between the AP and each station to identify stations involved in uplink collisions. The AP constructs empirical distributions for the monitored backoff values and compares them with a set of nominal PMF's, created via Markov analysis of the DCF protocol to estimate CWmin of various stations. After detecting the aggressive stations, the AP can choose to stop serving those stations. Simulation results show that the accuracy of our collision detection technique is 96%, 94%, and 88% when there are 3, 6, and 9 stations in the WLAN, respectively. For the former WLAN settings, the estimation accuracy of CWE scheme is 100%, 98.81%, and 96.3%, respectively.",
        "published": "2021-08-31T00:13:05Z",
        "link": "http://arxiv.org/abs/2108.13560v1",
        "categories": [
            "cs.NI",
            "cs.MA",
            "cs.SY",
            "eess.SP",
            "eess.SY"
        ]
    },
    {
        "title": "A New Approach to Multilinear Dynamical Systems and Control",
        "authors": [
            "Randy C. Hoover",
            "Kyle Caudle",
            "Karen Braman"
        ],
        "summary": "The current paper presents a new approach to multilinear dynamical systems analysis and control. The approach is based upon recent developments in tensor decompositions and a newly defined algebra of circulants. In particular, it is shown that under the right tensor multiplication operator, a third order tensor can be written as a product of third order tensors that is analogous to a traditional matrix eigenvalue decomposition where the \"eigenvectors\" become eigenmatrices and the \"eigenvalues\" become eigen-tuples. This new development allows for a proper tensor eigenvalue decomposition to be defined and has natural extension to linear systems theory through a \\textit{tensor-exponential}. Through this framework we extend many of traditional techniques used in linear system theory to their multilinear counterpart.",
        "published": "2021-08-31T02:08:28Z",
        "link": "http://arxiv.org/abs/2108.13583v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "math.DS"
        ]
    },
    {
        "title": "Development of User-friendly Smart Grid Architecture",
        "authors": [
            "Swaroop Mishra"
        ],
        "summary": "As systems like smart grid continue to become complex on a daily basis, emerging issues demand complex solutions that can deal with parameters in multiple domains of engineering. The complex solutions further demand a friendly interface for the users to express their requirements. Cyber-Physical systems deals with the study of techniques that are committed to modeling, simulating and solving the problems that emerge from a multi-disciplinary outlook towards futuristic systems. This thesis is mainly concerned with the development of user-friendly cyber-physical frameworks that can tackle various issues faced by the utilities and users of smart grid through a suitable choice of smart microgrid architecture.",
        "published": "2021-08-31T08:32:23Z",
        "link": "http://arxiv.org/abs/2108.13677v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "WarpDrive: Extremely Fast End-to-End Deep Multi-Agent Reinforcement   Learning on a GPU",
        "authors": [
            "Tian Lan",
            "Sunil Srinivasa",
            "Huan Wang",
            "Stephan Zheng"
        ],
        "summary": "Deep reinforcement learning (RL) is a powerful framework to train decision-making models in complex environments. However, RL can be slow as it requires repeated interaction with a simulation of the environment. In particular, there are key system engineering bottlenecks when using RL in complex environments that feature multiple agents with high-dimensional state, observation, or action spaces. We present WarpDrive, a flexible, lightweight, and easy-to-use open-source RL framework that implements end-to-end deep multi-agent RL on a single GPU (Graphics Processing Unit), built on PyCUDA and PyTorch. Using the extreme parallelization capability of GPUs, WarpDrive enables orders-of-magnitude faster RL compared to common implementations that blend CPU simulations and GPU models. Our design runs simulations and the agents in each simulation in parallel. It eliminates data copying between CPU and GPU. It also uses a single simulation data store on the GPU that is safely updated in-place. WarpDrive provides a lightweight Python interface and flexible environment wrappers that are easy to use and extend. Together, this allows the user to easily run thousands of concurrent multi-agent simulations and train on extremely large batches of experience. Through extensive experiments, we verify that WarpDrive provides high-throughput and scales almost linearly to many agents and parallel environments. For example, WarpDrive yields 2.9 million environment steps/second with 2000 environments and 1000 agents (at least 100x higher throughput compared to a CPU implementation) in a benchmark Tag simulation. As such, WarpDrive is a fast and extensible multi-agent RL platform to significantly accelerate research and development.",
        "published": "2021-08-31T16:59:27Z",
        "link": "http://arxiv.org/abs/2108.13976v3",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "V2X Communication Between Connected and Automated Vehicles (CAVs) and   Unmanned Aerial Vehicles (UAVs)",
        "authors": [
            "Ozgenur Kavas-Torris",
            "Sukru Yaren Gelbal",
            "Mustafa Ridvan Cantas",
            "Bilin Aksun-Guvenc",
            "Levent Guvenc"
        ],
        "summary": "Connectivity between ground vehicles can be utilized and expanded to include aerial vehicles for coordinated missions. Using Vehicle-to-Everything (V2X) communication technologies, a communication link can be established between Connected and Autonomous vehicles (CAVs) and Unmanned Aerial vehicles (UAVs). Hardware implementation and testing of a ground to air communication link is crucial for real-life applications. Two different communication links were established, Dedicated Short Range communication (DSRC) and 4G internet based WebSocket communication. Both links were tested separately both for stationary and dynamic test cases. One step further, both links were used together for a real-life use case scenario called Quick Clear demonstration. The aim was to first send ground vehicle location information from the CAV to the UAV through DSRC communication. On the UAV side, the connection between the DSRC modem and Raspberry Pi companion computer was established through User Datagram Protocol (UDP) to get the CAV location information to the companion computer. Raspberry Pi handles 2 different connection, it first connects to a traffic contingency management system (CMP) through Transmission Control Protocol (TCP) to send CAV and UAV location information to the CMP. Secondly, Raspberry Pi uses a WebSocket communication to connect to a web server to send photos taken by an on-board camera the UAV has. Quick Clear demo was conducted both for stationary test and dynamic flight tests. The results show that this communication structure can be utilized for real-life scenarios.",
        "published": "2021-09-01T01:36:55Z",
        "link": "http://arxiv.org/abs/2109.00145v2",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.RO",
            "cs.SY"
        ]
    },
    {
        "title": "Fairness based Multi-Preference Resource Allocation in Decentralised   Open Markets",
        "authors": [
            "Pankaj Mishra",
            "Ahmed Moustafa",
            "Takayuki Ito"
        ],
        "summary": "In this work, we focus on resource allocation in a decentralised open market. In decentralised open markets consists of multiple vendors and multiple dynamically-arriving buyers, thus makes the market complex and dynamic. Because, in these markets, negotiations among vendors and buyers take place over multiple conflicting issues such as price, scalability, robustness, delay, etc. As a result, optimising the resource allocation in such open markets becomes directly dependent on two key decisions, which are; incorporating a different kind of buyers' preferences, and fairness based vendor elicitation strategy. Towards this end, in this work, we propose a three-step resource allocation approach that employs a reverse-auction paradigm. At the first step, priority label is attached to each bidding vendor based on the proposed priority mechanism. Then, at the second step, the preference score is calculated for all the different kinds of preferences of the buyers. Finally, at the third step, based on the priority label of the vendor and the preference score winner is determined. Finally, we compare the proposed approach with two state-of-the-art resource pricing and allocation strategies. The experimental results show that the proposed approach outperforms the other two resource allocation approaches in terms of the independent utilities of buyers and the overall utility of the open market.",
        "published": "2021-09-01T06:29:06Z",
        "link": "http://arxiv.org/abs/2109.00207v1",
        "categories": [
            "cs.GT",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "GRAL: Localization of Floating Wireless Sensors in Pipe Networks",
        "authors": [
            "Martin Haug",
            "Felix Lorenz",
            "Lauritz Thamsen"
        ],
        "summary": "Mobile wireless sensors are increasingly recognized as a valuable tool for monitoring critical infrastructures. An important use case is the discovery of leaks and inflows in pipe networks using a swarm of floating sensor nodes. While passively drifting along, the devices must track their individual positions so critical points can later be located. Since pipelines are often situated in inaccessible places, large portions of the network can be shielded from radio and satellite signals, rendering conventional positioning systems ineffective.   In this paper, we propose a novel algorithm for assigning location estimates to recorded measurements once the sensor node leaves the inaccessible area and transmits them via a gateway. The solution is range-free and makes use of a priori information about the target pipeline network. We further describe two extended variants of our algorithm which use data of encounters with other sensor nodes to improve accuracy. Finally, we evaluate all variants with respect to various network topologies and different numbers of mobile nodes in a simulation. The results show that our algorithm localizes measurements with an average accuracy between 4.81% and 7.58%, depending on the variability of flow speed and the sparsity of reference points.",
        "published": "2021-09-01T10:19:35Z",
        "link": "http://arxiv.org/abs/2109.00294v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Can Decentralized Control Outperform Centralized? The Role of   Communication Latency",
        "authors": [
            "Luca Ballotta",
            "Mihailo R. Jovanović",
            "Luca Schenato"
        ],
        "summary": "In this paper, we examine the influence of communication latency on performance of networked control systems. Even though distributed control architectures offer advantages in terms of communication, maintenance costs, and scalability, it is an open question how communication latency that varies with network topology influences closed-loop performance. For networks in which delays increase with the number of links, we establish the existence of a fundamental performance trade-off that arises from control architecture. In particular, we utilize consensus dynamics with single- and double-integrator agents to show that, if delays increase fast enough, a sparse controller with nearest neighbor interactions can outperform the centralized one with all-to-all communication topology.",
        "published": "2021-09-01T12:44:00Z",
        "link": "http://arxiv.org/abs/2109.00359v5",
        "categories": [
            "math.OC",
            "cs.MA",
            "93B70 (Primary) 93C43 (Secondary)",
            "C.2.1"
        ]
    },
    {
        "title": "MACRPO: Multi-Agent Cooperative Recurrent Policy Optimization",
        "authors": [
            "Eshagh Kargar",
            "Ville Kyrki"
        ],
        "summary": "This work considers the problem of learning cooperative policies in multi-agent settings with partially observable and non-stationary environments without a communication channel. We focus on improving information sharing between agents and propose a new multi-agent actor-critic method called \\textit{Multi-Agent Cooperative Recurrent Proximal Policy Optimization} (MACRPO). We propose two novel ways of integrating information across agents and time in MACRPO: First, we use a recurrent layer in critic's network architecture and propose a new framework to use a meta-trajectory to train the recurrent layer. This allows the network to learn the cooperation and dynamics of interactions between agents, and also handle partial observability. Second, we propose a new advantage function that incorporates other agents' rewards and value functions. We evaluate our algorithm on three challenging multi-agent environments with continuous and discrete action spaces, Deepdrive-Zero, Multi-Walker, and Particle environment. We compare the results with several ablations and state-of-the-art multi-agent algorithms such as QMIX and MADDPG and also single-agent methods with shared parameters between agents such as IMPALA and APEX. The results show superior performance against other algorithms. The code is available online at https://github.com/kargarisaac/macrpo.",
        "published": "2021-09-02T12:43:35Z",
        "link": "http://arxiv.org/abs/2109.00882v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.GT",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Multi-Agent Inverse Reinforcement Learning: Suboptimal Demonstrations   and Alternative Solution Concepts",
        "authors": [
            "Sage Bergerson"
        ],
        "summary": "Multi-agent inverse reinforcement learning (MIRL) can be used to learn reward functions from agents in social environments. To model realistic social dynamics, MIRL methods must account for suboptimal human reasoning and behavior. Traditional formalisms of game theory provide computationally tractable behavioral models, but assume agents have unrealistic cognitive capabilities. This research identifies and compares mechanisms in MIRL methods which a) handle noise, biases and heuristics in agent decision making and b) model realistic equilibrium solution concepts. MIRL research is systematically reviewed to identify solutions for these challenges. The methods and results of these studies are analyzed and compared based on factors including performance accuracy, efficiency, and descriptive quality. We found that the primary methods for handling noise, biases and heuristics in MIRL were extensions of Maximum Entropy (MaxEnt) IRL to multi-agent settings. We also found that many successful solution concepts are generalizations of the traditional Nash Equilibrium (NE). These solutions include the correlated equilibrium, logistic stochastic best response equilibrium and entropy regularized mean field NE. Methods which use recursive reasoning or updating also perform well, including the feedback NE and archive multi-agent adversarial IRL. Success in modeling specific biases and heuristics in single-agent IRL and promising results using a Theory of Mind approach in MIRL imply that modeling specific biases and heuristics may be useful. Flexibility and unbiased inference in the identified alternative solution concepts suggest that a solution concept which has both recursive and generalized characteristics may perform well at modeling realistic social interactions.",
        "published": "2021-09-02T19:15:29Z",
        "link": "http://arxiv.org/abs/2109.01178v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "COVID-19 Vaccine Hesitancy and Information Diffusion: An Agent-based   Modeling Approach",
        "authors": [
            "Pooria Taghizadeh Naderi",
            "Ali Asgary",
            "Jude Kong",
            "Jianhong Wu",
            "Fattaneh Taghiyareh"
        ],
        "summary": "Despite the unprecedented success in the rapid development of several effective vaccines against the Cov-SARS-2, global vaccination rollout efforts suffer from vaccine distribution inequality and vaccine acceptance, leading to insufficient public immunity provided by the vaccine products. While a major current focus in vaccine acceptance research is how to model and inform vaccine acceptance based on social-demographic parameters, characteristics of vaccine acceptance are not well understood and in particular, it is not known whether and how information diffusion influences vaccine acceptance. This study examines how information diffusion can change vaccine acceptance by developing a comprehensive computational model with an agent-based simulation technique to overcome the modeling and quantification complexity associated with socio-demographics, vaccine types, population statistics, and information diffusion. Our analyses, calibrated by the vaccine acceptance survey data from the provinces and territories of Canada, provide clear evidence that the propagation of information can greatly influence vaccine acceptance rates. The results illustrate that spread of negative messages about the COVID-19 vaccines can cause significant vaccine hesitancy that challenges the goal of a high public immunity provided by the vaccines. Our findings might help solve the vaccine hesitancy problem by focusing more on individuals' opinions and behavior.",
        "published": "2021-09-02T19:18:36Z",
        "link": "http://arxiv.org/abs/2109.01182v1",
        "categories": [
            "physics.soc-ph",
            "cs.MA",
            "cs.SI"
        ]
    },
    {
        "title": "Event-Based Communication in Distributed Q-Learning",
        "authors": [
            "Daniel Jarne Ornia",
            "Manuel Mazo Jr"
        ],
        "summary": "We present an approach to reduce the communication of information needed on a Distributed Q-Learning system inspired by Event Triggered Control (ETC) techniques. We consider a baseline scenario of a distributed Q-learning problem on a Markov Decision Process (MDP). Following an event-based approach, N agents explore the MDP and communicate experiences to a central learner only when necessary, which performs updates of the actor Q functions. We design an Event Based distributed Q learning system (EBd-Q), and derive convergence guarantees with respect to a vanilla Q-learning algorithm. We present experimental results showing that event-based communication results in a substantial reduction of data transmission rates in such distributed systems. Additionally, we discuss what effects (desired and undesired) these event-based approaches have on the learning processes studied, and how they can be applied to more complex multi-agent systems.",
        "published": "2021-09-03T10:06:53Z",
        "link": "http://arxiv.org/abs/2109.01417v4",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "On the Complexity of Computing Markov Perfect Equilibrium in General-Sum   Stochastic Games",
        "authors": [
            "Xiaotie Deng",
            "Ningyuan Li",
            "David Mguni",
            "Jun Wang",
            "Yaodong Yang"
        ],
        "summary": "Similar to the role of Markov decision processes in reinforcement learning, Stochastic Games (SGs) lay the foundation for the study of multi-agent reinforcement learning (MARL) and sequential agent interactions. In this paper, we derive that computing an approximate Markov Perfect Equilibrium (MPE) in a finite-state discounted Stochastic Game within the exponential precision is \\textbf{PPAD}-complete. We adopt a function with a polynomially bounded description in the strategy space to convert the MPE computation to a fixed-point problem, even though the stochastic game may demand an exponential number of pure strategies, in the number of states, for each agent. The completeness result follows the reduction of the fixed-point problem to {\\sc End of the Line}. Our results indicate that finding an MPE in SGs is highly unlikely to be \\textbf{NP}-hard unless \\textbf{NP}=\\textbf{co-NP}. Our work offers confidence for MARL research to study MPE computation on general-sum SGs and to develop fruitful algorithms as currently on zero-sum SGs.",
        "published": "2021-09-04T05:47:59Z",
        "link": "http://arxiv.org/abs/2109.01795v2",
        "categories": [
            "cs.GT",
            "cs.CC",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "A Case Study of Agent-Based Models for Evolutionary Game Theory",
        "authors": [
            "Jacobus Smit",
            "Ed Plumb"
        ],
        "summary": "Evolutionary game theory is a mathematical toolkit to analyse the interactions that an individual agent has in a population and how the composition of strategies in this population evolves over time. While it can provide neat solutions to simple problems, in more complicated situations where assumptions such as infinite population size may be relaxed, deriving analytic solutions can be intractable. In this short paper, we present a game with complex interactions and examine how an agent-based model may be used as a heuristic technique to find evolutionarily stable states.",
        "published": "2021-09-04T11:46:02Z",
        "link": "http://arxiv.org/abs/2109.01849v1",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "GamePlan: Game-Theoretic Multi-Agent Planning with Human Drivers at   Intersections, Roundabouts, and Merging",
        "authors": [
            "Rohan Chandra",
            "Dinesh Manocha"
        ],
        "summary": "We present a new method for multi-agent planning involving human drivers and autonomous vehicles (AVs) in unsignaled intersections, roundabouts, and during merging. In multi-agent planning, the main challenge is to predict the actions of other agents, especially human drivers, as their intentions are hidden from other agents. Our algorithm uses game theory to develop a new auction, called GamePlan, that directly determines the optimal action for each agent based on their driving style (which is observable via commonly available sensors). GamePlan assigns a higher priority to more aggressive or impatient drivers and a lower priority to more conservative or patient drivers; we theoretically prove that such an approach is game-theoretically optimal prevents collisions and deadlocks. We compare our approach with prior state-of-the-art auction techniques including economic auctions, time-based auctions (first-in first-out), and random bidding and show that each of these methods result in collisions among agents when taking into account driver behavior. We compare with methods based on DRL, deep learning, and game theory and present our benefits over these approaches. Finally, we show that our approach can be implemented in the real-world with human drivers.",
        "published": "2021-09-04T16:26:31Z",
        "link": "http://arxiv.org/abs/2109.01896v5",
        "categories": [
            "cs.RO",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Soft Hierarchical Graph Recurrent Networks for Many-Agent Partially   Observable Environments",
        "authors": [
            "Zhenhui Ye",
            "Xiaohong Jiang",
            "Guanghua Song",
            "Bowei Yang"
        ],
        "summary": "The recent progress in multi-agent deep reinforcement learning(MADRL) makes it more practical in real-world tasks, but its relatively poor scalability and the partially observable constraints raise challenges to its performance and deployment. Based on our intuitive observation that the human society could be regarded as a large-scale partially observable environment, where each individual has the function of communicating with neighbors and remembering its own experience, we propose a novel network structure called hierarchical graph recurrent network(HGRN) for multi-agent cooperation under partial observability. Specifically, we construct the multi-agent system as a graph, use the hierarchical graph attention network(HGAT) to achieve communication between neighboring agents, and exploit GRU to enable agents to record historical information. To encourage exploration and improve robustness, we design a maximum-entropy learning method to learn stochastic policies of a configurable target action entropy. Based on the above technologies, we proposed a value-based MADRL algorithm called Soft-HGRN and its actor-critic variant named SAC-HRGN. Experimental results based on three homogeneous tasks and one heterogeneous environment not only show that our approach achieves clear improvements compared with four baselines, but also demonstrates the interpretability, scalability, and transferability of the proposed model. Ablation studies prove the function and necessity of each component.",
        "published": "2021-09-05T09:51:25Z",
        "link": "http://arxiv.org/abs/2109.02032v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Multi-Agent Variational Occlusion Inference Using People as Sensors",
        "authors": [
            "Masha Itkina",
            "Ye-Ji Mun",
            "Katherine Driggs-Campbell",
            "Mykel J. Kochenderfer"
        ],
        "summary": "Autonomous vehicles must reason about spatial occlusions in urban environments to ensure safety without being overly cautious. Prior work explored occlusion inference from observed social behaviors of road agents, hence treating people as sensors. Inferring occupancy from agent behaviors is an inherently multimodal problem; a driver may behave similarly for different occupancy patterns ahead of them (e.g., a driver may move at constant speed in traffic or on an open road). Past work, however, does not account for this multimodality, thus neglecting to model this source of aleatoric uncertainty in the relationship between driver behaviors and their environment. We propose an occlusion inference method that characterizes observed behaviors of human agents as sensor measurements, and fuses them with those from a standard sensor suite. To capture the aleatoric uncertainty, we train a conditional variational autoencoder with a discrete latent space to learn a multimodal mapping from observed driver trajectories to an occupancy grid representation of the view ahead of the driver. Our method handles multi-agent scenarios, combining measurements from multiple observed drivers using evidential theory to solve the sensor fusion problem. Our approach is validated on a cluttered, real-world intersection, outperforming baselines and demonstrating real-time capable performance. Our code is available at https://github.com/sisl/MultiAgentVariationalOcclusionInference .",
        "published": "2021-09-05T21:56:54Z",
        "link": "http://arxiv.org/abs/2109.02173v3",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.CV",
            "cs.LG",
            "cs.MA",
            "I.2.9; I.2.10"
        ]
    },
    {
        "title": "Do interactions among unequal agents undermine those of low status?",
        "authors": [
            "Guillaume Deffuant",
            "Thibaut Roubin"
        ],
        "summary": "We consider a recent model in which agents hold opinions about each other and influence each other's opinions during random pair interactions. When the opinions are initially close, on the short term, all the opinions tend to increase over time. On the contrary, when the opinions are initially very unequal, the opinions about agents of high status increase, but the opinions about agents of low status tend to stagnate without gossip and to decrease with gossip. We derive a moment approximation of the average opinion changes that explains these observations.",
        "published": "2021-09-07T10:18:01Z",
        "link": "http://arxiv.org/abs/2109.02976v1",
        "categories": [
            "physics.soc-ph",
            "cs.MA"
        ]
    },
    {
        "title": "Modelling Strategic Deceptive Planning in Adversarial Multi-Agent   Systems",
        "authors": [
            "Lyndon Benke",
            "Michael Papasimeon",
            "Tim Miller"
        ],
        "summary": "Deception is virtually ubiquitous in warfare, and should be a central consideration for military operations research. However, studies of agent behaviour in simulated operations have typically neglected to include explicit models of deception. This paper proposes that a computational model that approximates the human deceptive planning process would enable the authentic representation of strategic deception in multi-agent systems. The proposed deceptive planning model provides a framework for studying, explaining, and discovering deceptive behaviours, enabling the generation of novel solutions to adversarial planning problems.",
        "published": "2021-09-07T13:49:02Z",
        "link": "http://arxiv.org/abs/2109.03092v1",
        "categories": [
            "cs.MA",
            "I.2.11"
        ]
    },
    {
        "title": "On the Approximation of Cooperative Heterogeneous Multi-Agent   Reinforcement Learning (MARL) using Mean Field Control (MFC)",
        "authors": [
            "Washim Uddin Mondal",
            "Mridul Agarwal",
            "Vaneet Aggarwal",
            "Satish V. Ukkusuri"
        ],
        "summary": "Mean field control (MFC) is an effective way to mitigate the curse of dimensionality of cooperative multi-agent reinforcement learning (MARL) problems. This work considers a collection of $N_{\\mathrm{pop}}$ heterogeneous agents that can be segregated into $K$ classes such that the $k$-th class contains $N_k$ homogeneous agents. We aim to prove approximation guarantees of the MARL problem for this heterogeneous system by its corresponding MFC problem. We consider three scenarios where the reward and transition dynamics of all agents are respectively taken to be functions of $(1)$ joint state and action distributions across all classes, $(2)$ individual distributions of each class, and $(3)$ marginal distributions of the entire population. We show that, in these cases, the $K$-class MARL problem can be approximated by MFC with errors given as $e_1=\\mathcal{O}(\\frac{\\sqrt{|\\mathcal{X}|}+\\sqrt{|\\mathcal{U}|}}{N_{\\mathrm{pop}}}\\sum_{k}\\sqrt{N_k})$, $e_2=\\mathcal{O}(\\left[\\sqrt{|\\mathcal{X}|}+\\sqrt{|\\mathcal{U}|}\\right]\\sum_{k}\\frac{1}{\\sqrt{N_k}})$ and $e_3=\\mathcal{O}\\left(\\left[\\sqrt{|\\mathcal{X}|}+\\sqrt{|\\mathcal{U}|}\\right]\\left[\\frac{A}{N_{\\mathrm{pop}}}\\sum_{k\\in[K]}\\sqrt{N_k}+\\frac{B}{\\sqrt{N_{\\mathrm{pop}}}}\\right]\\right)$, respectively, where $A, B$ are some constants and $|\\mathcal{X}|,|\\mathcal{U}|$ are the sizes of state and action spaces of each agent. Finally, we design a Natural Policy Gradient (NPG) based algorithm that, in the three cases stated above, can converge to an optimal MARL policy within $\\mathcal{O}(e_j)$ error with a sample complexity of $\\mathcal{O}(e_j^{-3})$, $j\\in\\{1,2,3\\}$, respectively.",
        "published": "2021-09-09T03:52:49Z",
        "link": "http://arxiv.org/abs/2109.04024v3",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "DROP: Deep relocating option policy for optimal ride-hailing vehicle   repositioning",
        "authors": [
            "Xinwu Qian",
            "Shuocheng Guo",
            "Vaneet Aggarwal"
        ],
        "summary": "In a ride-hailing system, an optimal relocation of vacant vehicles can significantly reduce fleet idling time and balance the supply-demand distribution, enhancing system efficiency and promoting driver satisfaction and retention. Model-free deep reinforcement learning (DRL) has been shown to dynamically learn the relocating policy by actively interacting with the intrinsic dynamics in large-scale ride-hailing systems. However, the issues of sparse reward signals and unbalanced demand and supply distribution place critical barriers in developing effective DRL models. Conventional exploration strategy (e.g., the $\\epsilon$-greedy) may barely work under such an environment because of dithering in low-demand regions distant from high-revenue regions. This study proposes the deep relocating option policy (DROP) that supervises vehicle agents to escape from oversupply areas and effectively relocate to potentially underserved areas. We propose to learn the Laplacian embedding of a time-expanded relocation graph, as an approximation representation of the system relocation policy. The embedding generates task-agnostic signals, which in combination with task-dependent signals, constitute the pseudo-reward function for generating DROPs. We present a hierarchical learning framework that trains a high-level relocation policy and a set of low-level DROPs. The effectiveness of our approach is demonstrated using a custom-built high-fidelity simulator with real-world trip record data. We report that DROP significantly improves baseline models with 15.7% more hourly revenue and can effectively resolve the dithering issue in low-demand areas.",
        "published": "2021-09-09T10:20:53Z",
        "link": "http://arxiv.org/abs/2109.04149v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "DAN: Decentralized Attention-based Neural Network for the MinMax   Multiple Traveling Salesman Problem",
        "authors": [
            "Yuhong Cao",
            "Zhanhong Sun",
            "Guillaume Sartoretti"
        ],
        "summary": "The multiple traveling salesman problem (mTSP) is a well-known NP-hard problem with numerous real-world applications. In particular, this work addresses MinMax mTSP, where the objective is to minimize the max tour length among all agents. Many robotic deployments require recomputing potentially large mTSP instances frequently, making the natural trade-off between computing time and solution quality of great importance. However, exact and heuristic algorithms become inefficient as the number of cities increases, due to their computational complexity. Encouraged by the recent developments in deep reinforcement learning (dRL), this work approaches the mTSP as a cooperative task and introduces DAN, a decentralized attention-based neural method that aims at tackling this key trade-off. In DAN, agents learn fully decentralized policies to collaboratively construct a tour, by predicting each other's future decisions. Our model relies on the Transformer architecture and is trained using multi-agent RL with parameter sharing, providing natural scalability to the numbers of agents and cities. Our experimental results on small- to large-scale mTSP instances ($50$ to $1000$ cities and $5$ to $20$ agents) show that DAN is able to match or outperform state-of-the-art solvers while keeping planning times low. In particular, given the same computation time budget, DAN outperforms all conventional and dRL-based baselines on larger-scale instances (more than 100 cities, more than 5 agents), and exhibits enhanced agent collaboration. A video explaining our approach and presenting our results is available at \\url{https://youtu.be/xi3cLsDsLvs}.",
        "published": "2021-09-09T12:26:04Z",
        "link": "http://arxiv.org/abs/2109.04205v2",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Solving Simultaneous Target Assignment and Path Planning Efficiently   with Time-Independent Execution",
        "authors": [
            "Keisuke Okumura",
            "Xavier Défago"
        ],
        "summary": "Real-time planning for a combined problem of target assignment and path planning for multiple agents, also known as the unlabeled version of Multi-Agent Path Finding (MAPF), is crucial for high-level coordination in multi-agent systems, e.g., pattern formation by robot swarms. This paper studies two aspects of unlabeled-MAPF: (1) offline scenario: solving large instances by centralized approaches with small computation time, and (2) online scenario: executing unlabeled-MAPF despite timing uncertainties of real robots.   For this purpose, we propose TSWAP, a novel sub-optimal complete algorithm, which takes an arbitrary initial target assignment then repeats one-timestep path planning with target swapping. TSWAP can adapt to both offline and online scenarios. We empirically demonstrate that Offline TSWAP is highly scalable; providing near-optimal solutions while reducing runtime by orders of magnitude compared to existing approaches. In addition, we present the benefits of Online TSWAP, such as delay tolerance, through real-robot demos.",
        "published": "2021-09-09T13:34:08Z",
        "link": "http://arxiv.org/abs/2109.04264v3",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "1st-Order Dynamics on Nonlinear Agents for Resource Allocation over   Uniformly-Connected Networks",
        "authors": [
            "Mohammadreza Doostmohammadian",
            "Alireza Aghasi",
            "Maria Vrakopoulou",
            "Themistoklis Charalambous"
        ],
        "summary": "A general nonlinear $1$st-order consensus-based solution for distributed constrained convex optimization is proposed with network resource allocation applications. The solution is used to optimize continuously-differentiable strictly convex cost functions over weakly-connected undirected networks, while it is anytime feasible and models various nonlinearities to account for imperfections and constraints on the (physical model of) agents in terms of limited actuation capabilities, e.g., quantization and saturation. Due to such inherent nonlinearities, the existing linear solutions considering ideal agent models may not necessarily converge with guaranteed optimality and anytime feasibility. Some applications also impose specific nonlinearities, e.g., convergence in fixed/finite-time or sign-based robust disturbance-tolerant dynamics. Our proposed distributed protocol generalizes such nonlinear models. Putting convex set analysis together with nonsmooth Lyapunov analysis, we prove convergence, (i) regardless of the particular type of nonlinearity, and (ii) with weak network-connectivity requirements (uniform-connectivity).",
        "published": "2021-09-10T12:11:33Z",
        "link": "http://arxiv.org/abs/2109.04822v2",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY",
            "math.DS",
            "math.OC"
        ]
    },
    {
        "title": "Learning to Swarm with Knowledge-Based Neural Ordinary Differential   Equations",
        "authors": [
            "Tom Z. Jiahao",
            "Lishuo Pan",
            "M. Ani Hsieh"
        ],
        "summary": "Understanding decentralized dynamics from collective behaviors in swarms is crucial for informing robot controller designs in artificial swarms and multiagent robotic systems. However, the complexity in agent-to-agent interactions and the decentralized nature of most swarms pose a significant challenge to the extraction of single-robot control laws from global behavior. In this work, we consider the important task of learning decentralized single-robot controllers based solely on the state observations of a swarm's trajectory. We present a general framework by adopting knowledge-based neural ordinary differential equations (KNODE) -- a hybrid machine learning method capable of combining artificial neural networks with known agent dynamics. Our approach distinguishes itself from most prior works in that we do not require action data for learning. We apply our framework to two different flocking swarms in 2D and 3D respectively, and demonstrate efficient training by leveraging the graphical structure of the swarms' information network. We further show that the learnt single-robot controllers can not only reproduce flocking behavior in the original swarm but also scale to swarms with more robots.",
        "published": "2021-09-10T15:17:52Z",
        "link": "http://arxiv.org/abs/2109.04927v3",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Learning Selective Communication for Multi-Agent Path Finding",
        "authors": [
            "Ziyuan Ma",
            "Yudong Luo",
            "Jia Pan"
        ],
        "summary": "Learning communication via deep reinforcement learning (RL) or imitation learning (IL) has recently been shown to be an effective way to solve Multi-Agent Path Finding (MAPF). However, existing communication based MAPF solvers focus on broadcast communication, where an agent broadcasts its message to all other or predefined agents. It is not only impractical but also leads to redundant information that could even impair the multi-agent cooperation. A succinct communication scheme should learn which information is relevant and influential to each agent's decision making process. To address this problem, we consider a request-reply scenario and propose Decision Causal Communication (DCC), a simple yet efficient model to enable agents to select neighbors to conduct communication during both training and execution. Specifically, a neighbor is determined as relevant and influential only when the presence of this neighbor causes the decision adjustment on the central agent. This judgment is learned only based on agent's local observation and thus suitable for decentralized execution to handle large scale problems. Empirical evaluation in obstacle-rich environment indicates the high success rate with low communication overhead of our method.",
        "published": "2021-09-12T03:07:20Z",
        "link": "http://arxiv.org/abs/2109.05413v2",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "DynSTGAT: Dynamic Spatial-Temporal Graph Attention Network for Traffic   Signal Control",
        "authors": [
            "Libing Wu",
            "Min Wang",
            "Dan Wu",
            "Jia Wu"
        ],
        "summary": "Adaptive traffic signal control plays a significant role in the construction of smart cities. This task is challenging because of many essential factors, such as cooperation among neighboring intersections and dynamic traffic scenarios. First, to facilitate cooperation of traffic signals, existing work adopts graph neural networks to incorporate the temporal and spatial influences of the surrounding intersections into the target intersection, where spatial-temporal information is used separately. However, one drawback of these methods is that the spatial-temporal correlations are not adequately exploited to obtain a better control scheme. Second, in a dynamic traffic environment, the historical state of the intersection is also critical for predicting future signal switching. Previous work mainly solves this problem using the current intersection's state, neglecting the fact that traffic flow is continuously changing both spatially and temporally and does not handle the historical state.   In this paper, we propose a novel neural network framework named DynSTGAT, which integrates dynamic historical state into a new spatial-temporal graph attention network to address the above two problems. More specifically, our DynSTGAT model employs a novel multi-head graph attention mechanism, which aims to adequately exploit the joint relations of spatial-temporal information. Then, to efficiently utilize the historical state information of the intersection, we design a sequence model with the temporal convolutional network (TCN) to capture the historical information and further merge it with the spatial information to improve its performance. Extensive experiments conducted in the multi-intersection scenario on synthetic data and real-world data confirm that our method can achieve superior performance in travel time and throughput against the state-of-the-art methods.",
        "published": "2021-09-12T11:27:27Z",
        "link": "http://arxiv.org/abs/2109.05491v2",
        "categories": [
            "cs.LG",
            "cs.MA",
            "68Txx"
        ]
    },
    {
        "title": "Learning Robot Swarm Tactics over Complex Adversarial Environments",
        "authors": [
            "Amir Behjat",
            "Hemanth Manjunatha",
            "Prajit KrisshnaKumar",
            "Apurv Jani",
            "Leighton Collins",
            "Payam Ghassemi",
            "Joseph Distefano",
            "David Doermann",
            "Karthik Dantu",
            "Ehsan Esfahani",
            "Souma Chowdhury"
        ],
        "summary": "To accomplish complex swarm robotic missions in the real world, one needs to plan and execute a combination of single robot behaviors, group primitives such as task allocation, path planning, and formation control, and mission-specific objectives such as target search and group coverage. Most such missions are designed manually by teams of robotics experts. Recent work in automated approaches to learning swarm behavior has been limited to individual primitives with sparse work on learning complete missions. This paper presents a systematic approach to learn tactical mission-specific policies that compose primitives in a swarm to accomplish the mission efficiently using neural networks with special input and output encoding. To learn swarm tactics in an adversarial environment, we employ a combination of 1) map-to-graph abstraction, 2) input/output encoding via Pareto filtering of points of interest and clustering of robots, and 3) learning via neuroevolution and policy gradient approaches. We illustrate this combination as critical to providing tractable learning, especially given the computational cost of simulating swarm missions of this scale and complexity. Successful mission completion outcomes are demonstrated with up to 60 robots. In addition, a close match in the performance statistics in training and testing scenarios shows the potential generalizability of the proposed framework.",
        "published": "2021-09-13T01:35:05Z",
        "link": "http://arxiv.org/abs/2109.05663v1",
        "categories": [
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Constraint-Driven Optimal Control of Multi-Agent Systems: A Highway   Platooning Case Study",
        "authors": [
            "Logan E. Beaver",
            "Andreas A. Malikopoulos"
        ],
        "summary": "Platooning has been exploited as a method for vehicles to minimize energy consumption. In this article, we present a constraint-driven optimal control framework that yields emergent platooning behavior for connected and automated vehicles operating in an open transportation system. Our approach combines recent insights in constraint-driven optimal control with the physical aerodynamic interactions between vehicles in a highway setting. The result is a set of equations that describes when platooning is an appropriate strategy, as well as a descriptive optimal control law that yields emergent platooning behavior. Finally, we demonstrate these properties in simulation.",
        "published": "2021-09-13T14:06:31Z",
        "link": "http://arxiv.org/abs/2109.05988v3",
        "categories": [
            "cs.RO",
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "A Scalable Last-Mile Delivery Service: From Simulation to Scaled   Experiment",
        "authors": [
            "Meera Ratnagiri",
            "Clare O'Dwyer",
            "Logan E. Beaver",
            "Heeseung Bang",
            "Behdad Chalaki",
            "Andreas A. Malikopoulos"
        ],
        "summary": "In this paper, we investigate the problem of a last-mile delivery service that selects up to $N$ available vehicles to deliver $M$ packages from a centralized depot to $M$ delivery locations. The objective of the last-mile delivery service is to jointly maximize customer satisfaction (minimize delivery time) and minimize operating cost (minimize total travel time) by selecting the optimal number of vehicles to perform the deliveries. We model this as an assignment (vehicles to packages) and path planning (determining the delivery order and route) problem, which is equivalent to the NP-hard multiple traveling salesperson problem. We propose a scalable heuristic algorithm, which sacrifices some optimality to achieve a reasonable computational cost for a high number of packages. The algorithm combines hierarchical clustering with a greedy search. To validate our approach, we compare the results of our simulation to experiments in a $1$:$25$ scale robotic testbed for future mobility systems.",
        "published": "2021-09-13T14:13:51Z",
        "link": "http://arxiv.org/abs/2109.05995v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Specification and Validation of Autonomous Driving Systems: A Multilevel   Semantic Framework",
        "authors": [
            "Marius Bozga",
            "Joseph Sifakis"
        ],
        "summary": "Autonomous Driving Systems (ADS) are critical dynamic reconfigurable agent systems whose specification and validation raises extremely challenging problems. The paper presents a multilevel semantic framework for the specification of ADS and discusses associated validation problems. The framework relies on a formal definition of maps modeling the physical environment in which vehicles evolve. Maps are directed metric graphs whose nodes represent positions and edges represent segments of roads. We study basic properties of maps including their geometric consistency. Furthermore, we study position refinement and segment abstraction relations allowing multilevel representation from purely topological to detailed geometric. We progressively define first order logics for modeling families of maps and distributions of vehicles over maps. These are Configuration Logics, which in addition to the usual logical connectives are equipped with a coalescing operator to build configurations of models. We study their semantics and basic properties. We illustrate their use for the specification of traffic rules and scenarios characterizing sequences of scenes. We study various aspects of the validation problem including run-time verification and satisfiability of specifications. Finally, we show links of our framework with practical validation needs for ADS and advocate its adequacy for addressing the many facets of this challenge.",
        "published": "2021-09-14T07:20:56Z",
        "link": "http://arxiv.org/abs/2109.06478v1",
        "categories": [
            "cs.MA",
            "cs.LO",
            "cs.SE"
        ]
    },
    {
        "title": "Vision Transformer for Learning Driving Policies in Complex Multi-Agent   Environments",
        "authors": [
            "Eshagh Kargar",
            "Ville Kyrki"
        ],
        "summary": "Driving in a complex urban environment is a difficult task that requires a complex decision policy. In order to make informed decisions, one needs to gain an understanding of the long-range context and the importance of other vehicles. In this work, we propose to use Vision Transformer (ViT) to learn a driving policy in urban settings with birds-eye-view (BEV) input images. The ViT network learns the global context of the scene more effectively than with earlier proposed Convolutional Neural Networks (ConvNets). Furthermore, ViT's attention mechanism helps to learn an attention map for the scene which allows the ego car to determine which surrounding cars are important to its next decision. We demonstrate that a DQN agent with a ViT backbone outperforms baseline algorithms with ConvNet backbones pre-trained in various ways. In particular, the proposed method helps reinforcement learning algorithms to learn faster, with increased performance and less data than baselines.",
        "published": "2021-09-14T08:18:47Z",
        "link": "http://arxiv.org/abs/2109.06514v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Exploration in Deep Reinforcement Learning: From Single-Agent to   Multiagent Domain",
        "authors": [
            "Jianye Hao",
            "Tianpei Yang",
            "Hongyao Tang",
            "Chenjia Bai",
            "Jinyi Liu",
            "Zhaopeng Meng",
            "Peng Liu",
            "Zhen Wang"
        ],
        "summary": "Deep Reinforcement Learning (DRL) and Deep Multi-agent Reinforcement Learning (MARL) have achieved significant successes across a wide range of domains, including game AI, autonomous vehicles, robotics, and so on. However, DRL and deep MARL agents are widely known to be sample inefficient that millions of interactions are usually needed even for relatively simple problem settings, thus preventing the wide application and deployment in real-industry scenarios. One bottleneck challenge behind is the well-known exploration problem, i.e., how efficiently exploring the environment and collecting informative experiences that could benefit policy learning towards the optimal ones. This problem becomes more challenging in complex environments with sparse rewards, noisy distractions, long horizons, and non-stationary co-learners. In this paper, we conduct a comprehensive survey on existing exploration methods for both single-agent and multi-agent RL. We start the survey by identifying several key challenges to efficient exploration. Beyond the above two main branches, we also include other notable exploration methods with different ideas and techniques. In addition to algorithmic analysis, we provide a comprehensive and unified empirical comparison of different exploration methods for DRL on a set of commonly used benchmarks. According to our algorithmic and empirical investigation, we finally summarize the open problems of exploration in DRL and deep MARL and point out a few future directions.",
        "published": "2021-09-14T13:16:33Z",
        "link": "http://arxiv.org/abs/2109.06668v6",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Reactive and Safe Road User Simulations using Neural Barrier   Certificates",
        "authors": [
            "Yue Meng",
            "Zengyi Qin",
            "Chuchu Fan"
        ],
        "summary": "Reactive and safe agent modelings are important for nowadays traffic simulator designs and safe planning applications. In this work, we proposed a reactive agent model which can ensure safety without comprising the original purposes, by learning only high-level decisions from expert data and a low-level decentralized controller guided by the jointly learned decentralized barrier certificates. Empirical results show that our learned road user simulation models can achieve a significant improvement in safety comparing to state-of-the-art imitation learning and pure control-based methods, while being similar to human agents by having smaller errors to the expert data. Moreover, our learned reactive agents are shown to generalize better to unseen traffic conditions, and react better to other road users and therefore can help understand challenging planning problems pragmatically.",
        "published": "2021-09-14T13:45:37Z",
        "link": "http://arxiv.org/abs/2109.06689v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Modeling the effects of environmental and perceptual uncertainty using   deterministic reinforcement learning dynamics with partial observability",
        "authors": [
            "Wolfram Barfuss",
            "Richard P. Mann"
        ],
        "summary": "Assessing the systemic effects of uncertainty that arises from agents' partial observation of the true states of the world is critical for understanding a wide range of scenarios. Yet, previous modeling work on agent learning and decision-making either lacks a systematic way to describe this source of uncertainty or puts the focus on obtaining optimal policies using complex models of the world that would impose an unrealistically high cognitive demand on real agents. In this work we aim to efficiently describe the emergent behavior of biologically plausible and parsimonious learning agents faced with partially observable worlds. Therefore we derive and present deterministic reinforcement learning dynamics where the agents observe the true state of the environment only partially. We showcase the broad applicability of our dynamics across different classes of partially observable agent-environment systems. We find that partial observability creates unintuitive benefits in a number of specific contexts, pointing the way to further research on a general understanding of such effects. For instance, partially observant agents can learn better outcomes faster, in a more stable way and even overcome social dilemmas. Furthermore, our method allows the application of dynamical systems theory to partially observable multiagent leaning. In this regard we find the emergence of catastrophic limit cycles, a critical slowing down of the learning processes between reward regimes and the separation of the learning dynamics into fast and slow directions, all caused by partial observability. Therefore, the presented dynamics have the potential to become a formal, yet practical, lightweight and robust tool for researchers in biology, social science and machine learning to systematically investigate the effects of interacting partially observant agents.",
        "published": "2021-09-15T12:50:58Z",
        "link": "http://arxiv.org/abs/2109.07259v2",
        "categories": [
            "nlin.AO",
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "physics.soc-ph"
        ]
    },
    {
        "title": "Back to the Future: Efficient, Time-Consistent Solutions in Reach-Avoid   Games",
        "authors": [
            "Dennis R. Anthony",
            "Duy P. Nguyen",
            "David Fridovich-Keil",
            "Jaime F. Fisac"
        ],
        "summary": "We study the class of reach-avoid dynamic games in which multiple agents interact noncooperatively, and each wishes to satisfy a distinct target criterion while avoiding a failure criterion. Reach-avoid games are commonly used to express safety-critical optimal control problems found in mobile robot motion planning. Here, we focus on finding time-consistent solutions, in which future motion plans remain optimal even when a robot diverges from the plan early on due to, e.g., intrinsic dynamic uncertainty or extrinsic environment disturbances. Our main contribution is a computationally-efficient algorithm for multi-agent reach-avoid games which renders time-consistent solutions for all players. We demonstrate our approach in two- and three-player simulated driving scenarios, in which our method provides safe control strategies for all agents.",
        "published": "2021-09-16T02:21:08Z",
        "link": "http://arxiv.org/abs/2109.07673v3",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.RO",
            "cs.SY"
        ]
    },
    {
        "title": "DMAPF: A Decentralized and Distributed Solver for Multi-Agent Path   Finding Problem with Obstacles",
        "authors": [
            "Poom Pianpak",
            "Tran Cao Son"
        ],
        "summary": "Multi-Agent Path Finding (MAPF) is a problem of finding a sequence of movements for agents to reach their assigned location without collision. Centralized algorithms usually give optimal solutions, but have difficulties to scale without employing various techniques - usually with a sacrifice of optimality; but solving MAPF problems with the number of agents greater than a thousand remains a challenge nevertheless. To tackle the scalability issue, we present DMAPF - a decentralized and distributed MAPF solver, which is a continuation of our recently published work, ros-dmapf. We address the issues of ros-dmapf where it (i) only works in maps without obstacles; and (ii) has a low success rate with dense maps. Given a MAPF problem, both ros-dmapf and DMAPF divide the map spatially into subproblems, but the latter further divides each subproblem into disconnected regions called areas. Each subproblem is assigned to a distributed solver, which then individually creates an abstract plan - a sequence of areas that an agent needs to visit - for each agent in it, and interleaves agent migration with movement planning. Answer Set Programming, which is known for its performance in small but complex problems, is used in many parts including problem division, abstract planning, border assignment for the migration, and movement planning. Robot Operating System is used to facilitate communication between the solvers and to enable the opportunity to integrate with robotic systems. DMAPF introduces a new interaction protocol between the solvers, and mechanisms that together result in a higher success rate and better solution quality without sacrificing much of the performance. We implement and experimentally validate DMAPF by comparing it with other state-of-the-art MAPF solvers and the results show that our system achieves better scalability.",
        "published": "2021-09-17T01:47:00Z",
        "link": "http://arxiv.org/abs/2109.08288v1",
        "categories": [
            "cs.MA",
            "cs.DC",
            "cs.LO"
        ]
    },
    {
        "title": "A Logic-based Multi-agent System for Ethical Monitoring and Evaluation   of Dialogues",
        "authors": [
            "Abeer Dyoub",
            "Stefania Costantini",
            "Ivan Letteri",
            "Francesca A. Lisi"
        ],
        "summary": "Dialogue Systems are tools designed for various practical purposes concerning human-machine interaction. These systems should be built on ethical foundations because their behavior may heavily influence a user (think especially about children). The primary objective of this paper is to present the architecture and prototype implementation of a Multi Agent System (MAS) designed for ethical monitoring and evaluation of a dialogue system. A prototype application, for monitoring and evaluation of chatting agents' (human/artificial) ethical behavior in an online customer service chat point w.r.t their institution/company's codes of ethics and conduct, is developed and presented. Future work and open issues with this research are discussed.",
        "published": "2021-09-17T01:48:50Z",
        "link": "http://arxiv.org/abs/2109.08294v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "I.2;I.2.11;I.2.6;I.3.8"
        ]
    },
    {
        "title": "Flexible and Explainable Solutions for Multi-Agent Path Finding Problems",
        "authors": [
            "Aysu Bogatarkan"
        ],
        "summary": "The multi-agent path finding (MAPF) problem is a combinatorial search problem that aims at finding paths for multiple agents (e.g., robots) in an environment (e.g., an autonomous warehouse) such that no two agents collide with each other, and subject to some constraints on the lengths of paths. The real-world applications of MAPF require flexibility (e.g., solving variations of MAPF) as well as explainability. In this study, both of these challenges are addressed and some flexible and explainable solutions for MAPF and its variants are introduced.",
        "published": "2021-09-17T01:50:01Z",
        "link": "http://arxiv.org/abs/2109.08299v1",
        "categories": [
            "cs.AI",
            "cs.LO",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Comprehensive Multi-Agent Epistemic Planning",
        "authors": [
            "Francesco Fabiano"
        ],
        "summary": "Over the last few years, the concept of Artificial Intelligence has become central in different tasks concerning both our daily life and several working scenarios. Among these tasks automated planning has always been central in the AI research community. In particular, this manuscript is focused on a specialized kind of planning known as Multi-agent Epistemic Planning (MEP). Epistemic Planning (EP) refers to an automated planning setting where the agent reasons in the space of knowledge/beliefs states and tries to find a plan to reach a desirable state from a starting one. Its general form, the MEP problem, involves multiple agents who need to reason about both the state of the world and the information flows between agents. To tackle the MEP problem several tools have been developed and, while the diversity of approaches has led to a deeper understanding of the problem space, each proposed tool lacks some abilities and does not allow for a comprehensive investigation of the information flows. That is why, the objective of our work is to formalize an environment where a complete characterization of the agents' knowledge/beliefs interaction and update is possible. In particular, we aim to achieve such goal by defining a new action-based language for multi-agent epistemic planning and to implement an epistemic planner based on it. This solver should provide a tool flexible enough to reason on different domains, e.g., economy, security, justice and politics, where considering others' knowledge/beliefs could lead to winning strategies.",
        "published": "2021-09-17T01:50:18Z",
        "link": "http://arxiv.org/abs/2109.08301v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Finite Model Property and Bisimulation for LFD",
        "authors": [
            "Raoul Koudijs"
        ],
        "summary": "Recently, Baltag and van Benthem introduced a decidable logic of functional dependence (LFD) that extends the logic of Cylindrical Relativized Set Algebras (CRS) with atomic local dependence statements. Its semantics can be given in terms of generalised assignment models or their modal counterparts, hence the logic is both a first-order and a modal logic. We show that LFD has the finite model property (FMP) using Herwig's theorem on extending partial isomorphisms, and prove a bisimulation invariance theorem characterizing LFD as a fragment of first-order logic.",
        "published": "2021-09-17T02:29:22Z",
        "link": "http://arxiv.org/abs/2109.08313v1",
        "categories": [
            "cs.LO",
            "cs.MA",
            "F.4.1"
        ]
    },
    {
        "title": "Reconfigurable Broadcast Networks and Asynchronous Shared-Memory Systems   are Equivalent",
        "authors": [
            "A. R. Balasubramanian",
            "Chana Weil-Kennedy"
        ],
        "summary": "We show the equivalence of two distributed computing models, namely reconfigurable broadcast networks (RBN) and asynchronous shared-memory systems (ASMS), that were introduced independently. Both RBN and ASMS are systems in which a collection of anonymous, finite-state processes run the same protocol. In RBN, the processes communicate by selective broadcast: a process can broadcast a message which is received by all of its neighbors, and the set of neighbors of a process can change arbitrarily over time. In ASMS, the processes communicate by shared memory: a process can either write to or read from a shared register. Our main result is that RBN and ASMS can simulate each other, i.e. they are equivalent with respect to parameterized reachability, where we are given two (possibly infinite) sets of configurations C and C' defined by upper and lower bounds on the number of processes in each state and we would like to decide if some configuration in C can reach some configuration in C'. Using this simulation equivalence, we transfer results of RBN to ASMS and vice versa. Finally, we show that RBN and ASMS can simulate a third distributed model called immediate observation (IO) nets. Moreover, for a slightly stronger notion of simulation (which is satisfied by all the simulations given in this paper), we show that IO nets cannot simulate RBN.",
        "published": "2021-09-17T02:30:55Z",
        "link": "http://arxiv.org/abs/2109.08315v1",
        "categories": [
            "cs.LO",
            "cs.DC",
            "cs.MA"
        ]
    },
    {
        "title": "Security Analysis of Distributed Ledgers and Blockchains through   Agent-based Simulation",
        "authors": [
            "Luca Serena",
            "Gabriele D'Angelo",
            "Stefano Ferretti"
        ],
        "summary": "In this paper we describe LUNES-Blockchain, an agent-based simulator of blockchains that relies on Parallel and Distributed Simulation (PADS) techniques to obtain high scalability. The software is organized as a multi-level simulator that permits to simulate a virtual environment, made of many nodes running the protocol of a specific Distributed Ledger Technology (DLT), such as the Bitcoin or the Ethereum blockchains. This virtual environment is executed on top of a lower-level Peer-to-Peer (P2P) network overlay, which can be structured based on different topologies and with a given number of nodes and edges. Functionalities at different levels of abstraction are managed separately, by different software modules and with different time granularity. This allows for accurate simulations, where (and when) it is needed, and enhances the simulation performance. Using LUNES-Blockchain, it is possible to simulate different types of attacks on the DLT. In this paper, we specifically focus on the P2P layer, considering the selfish mining, the 51% attack and the Sybil attack. For which concerns selfish mining and the 51% attack, our aim is to understand how much the hash-rate (i.e. a general measure of the processing power in the blockchain network) of the attacker can influence the outcome of the misbehaviour. On the other hand, in the filtering denial of service (i.e. Sybil Attack), we investigate which dissemination protocol in the underlying P2P network makes the system more resilient to a varying number of nodes that drop the messages. The results confirm the viability of the simulation-based techniques for the investigation of security aspects of DLTs.",
        "published": "2021-09-17T05:51:28Z",
        "link": "http://arxiv.org/abs/2109.08358v1",
        "categories": [
            "cs.CR",
            "cs.DC",
            "cs.MA",
            "cs.PF"
        ]
    },
    {
        "title": "Coordinated Random Access for Industrial IoT With Correlated Traffic By   Reinforcement-Learning",
        "authors": [
            "Alberto Rech",
            "Stefano Tomasin"
        ],
        "summary": "We propose a coordinated random access scheme for industrial internet-of-things (IIoT) scenarios, with machine-type devices (MTDs) generating sporadic correlated traffic. This occurs, e.g., when external events trigger data generation at multiple MTDs simultaneously. Time is divided into frames, each split into slots and each MTD randomly selects one slot for (re)transmission, with probability density functions (PDFs) specific of both the MTD and the number of the current retransmission. PDFs are locally optimized to minimize the probability of packet collision. The optimization problem is modeled as a repeated Markov game with incomplete information, and the linear reward-inaction algorithm is used at each MTD, which provably converges to a deterministic (suboptimal) slot assignment. We compare our solution with both the slotted ALOHA and the min-max pairwise correlation random access schemes, showing that our approach achieves a higher network throughput with moderate traffic intensity.",
        "published": "2021-09-17T07:45:39Z",
        "link": "http://arxiv.org/abs/2109.08389v1",
        "categories": [
            "cs.NI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "How Does Facebook Retain Segregated Friendship? An Agent-Based Model   Approach",
        "authors": [
            "Firman M. Firmansyah"
        ],
        "summary": "Facebook, the largest social networking site in the world, has overcome the structural barriers that historically constrain individuals to reach out to different others. Through the platform, people from all walks of life and virtually any location can develop diverse friendships online. However, friendships on Facebook have been as segregated as friendships in real life. This research sought to understand why the leading social networking site intended to 'bring the world closer together' retains segregated friendship. In doing so, we employed a series of agent-based simulations based on the Framework for Intergroup Relations and Multiple Affiliations Networks (FIRMAN). As demonstrated, Facebook has primarily enhanced users' capacity to maintain a larger number of friendships (tie capacity), while has done little to empower users' ability to accept diversity and befriend different others (tie outreachability). Facebook must focus on the latter should they truly wish to contribute to the development of a more inclusive society. While in this study we focus on ethnically segregated friendship on Facebook, we argue that the same explanation may also hold for racially and ideologically segregated friendships on other bi-directional social networking sites.",
        "published": "2021-09-18T07:26:19Z",
        "link": "http://arxiv.org/abs/2109.08862v1",
        "categories": [
            "cs.SI",
            "cs.CY",
            "cs.MA"
        ]
    },
    {
        "title": "Greedy UnMixing for Q-Learning in Multi-Agent Reinforcement Learning",
        "authors": [
            "Chapman Siu",
            "Jason Traish",
            "Richard Yi Da Xu"
        ],
        "summary": "This paper introduces Greedy UnMix (GUM) for cooperative multi-agent reinforcement learning (MARL). Greedy UnMix aims to avoid scenarios where MARL methods fail due to overestimation of values as part of the large joint state-action space. It aims to address this through a conservative Q-learning approach through restricting the state-marginal in the dataset to avoid unobserved joint state action spaces, whilst concurrently attempting to unmix or simplify the problem space under the centralized training with decentralized execution paradigm. We demonstrate the adherence to Q-function lower bounds in the Q-learning for MARL scenarios, and demonstrate superior performance to existing Q-learning MARL approaches as well as more general MARL algorithms over a set of benchmark MARL tasks, despite its relative simplicity compared with state-of-the-art approaches.",
        "published": "2021-09-19T00:35:18Z",
        "link": "http://arxiv.org/abs/2109.09034v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Regularize! Don't Mix: Multi-Agent Reinforcement Learning without   Explicit Centralized Structures",
        "authors": [
            "Chapman Siu",
            "Jason Traish",
            "Richard Yi Da Xu"
        ],
        "summary": "We propose using regularization for Multi-Agent Reinforcement Learning rather than learning explicit cooperative structures called {\\em Multi-Agent Regularized Q-learning} (MARQ). Many MARL approaches leverage centralized structures in order to exploit global state information or removing communication constraints when the agents act in a decentralized manner. Instead of learning redundant structures which is removed during agent execution, we propose instead to leverage shared experiences of the agents to regularize the individual policies in order to promote structured exploration. We examine several different approaches to how MARQ can either explicitly or implicitly regularize our policies in a multi-agent setting. MARQ aims to address these limitations in the MARL context through applying regularization constraints which can correct bias in off-policy out-of-distribution agent experiences and promote diverse exploration. Our algorithm is evaluated on several benchmark multi-agent environments and we show that MARQ consistently outperforms several baselines and state-of-the-art algorithms; learning in fewer steps and converging to higher returns.",
        "published": "2021-09-19T00:58:38Z",
        "link": "http://arxiv.org/abs/2109.09038v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Learning Multi-agent Action Coordination via Electing First-move Agent",
        "authors": [
            "Jingqing Ruan",
            "Linghui Meng",
            "Xuantang Xiong",
            "Dengpeng Xing",
            "Bo Xu"
        ],
        "summary": "Learning to coordinate actions among agents is essential in complicated multi-agent systems. Prior works are constrained mainly by the assumption that all agents act simultaneously, and asynchronous action coordination between agents is rarely considered. This paper introduces a bi-level multi-agent decision hierarchy for coordinated behavior planning. We propose a novel election mechanism in which we adopt a graph convolutional network to model the interaction among agents and elect a first-move agent for asynchronous guidance. We also propose a dynamically weighted mixing network to effectively reduce the misestimation of the value function during training. This work is the first to explicitly model the asynchronous multi-agent action coordination, and this explicitness enables to choose the optimal first-move agent. The results on Cooperative Navigation and Google Football demonstrate that the proposed algorithm can achieve superior performance in cooperative environments. Our code is available at \\url{https://github.com/Amanda-1997/EFA-DWM}.",
        "published": "2021-09-20T05:25:32Z",
        "link": "http://arxiv.org/abs/2110.08126v3",
        "categories": [
            "cs.MA",
            "cs.GT"
        ]
    },
    {
        "title": "Distributed Detection and Mitigation of Biasing Attacks over Multi-Agent   Networks",
        "authors": [
            "Mohammadreza Doostmohammadian",
            "Houman Zarrabi",
            "Hamid R. Rabiee",
            "Usman A. Khan",
            "Themistoklis Charalambous"
        ],
        "summary": "This paper proposes a distributed attack detection and mitigation technique based on distributed estimation over a multi-agent network, where the agents take partial system measurements susceptible to (possible) biasing attacks. In particular, we assume that the system is not locally observable via the measurements in the direct neighborhood of any agent. First, for performance analysis in the attack-free case, we show that the proposed distributed estimation is unbiased with bounded mean-square deviation in steady-state. Then, we propose a residual-based strategy to locally detect possible attacks at agents. In contrast to the deterministic thresholds in the literature assuming an upper bound on the noise support, we define the thresholds on the residuals in a probabilistic sense. After detecting and isolating the attacked agent, a system-digraph-based mitigation strategy is proposed to replace the attacked measurement with a new observationally-equivalent one to recover potential observability loss. We adopt a graph-theoretic method to classify the agents based on their measurements, to distinguish between the agents recovering the system rank-deficiency and the ones recovering output-connectivity of the system digraph. The attack detection/mitigation strategy is specifically described for each type, which is of polynomial-order complexity for large-scale applications. Illustrative simulations support our theoretical results.",
        "published": "2021-09-20T07:13:34Z",
        "link": "http://arxiv.org/abs/2109.09329v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY",
            "eess.SP"
        ]
    },
    {
        "title": "Modular Design Patterns for Hybrid Actors",
        "authors": [
            "André Meyer-Vitali",
            "Wico Mulder",
            "Maaike H. T. de Boer"
        ],
        "summary": "Recently, a boxology (graphical language) with design patterns for hybrid AI was proposed, combining symbolic and sub-symbolic learning and reasoning. In this paper, we extend this boxology with actors and their interactions. The main contributions of this paper are: 1) an extension of the taxonomy to describe distributed hybrid AI systems with actors and interactions; and 2) showing examples using a few design patterns relevant in multi-agent systems and human-agent interaction.",
        "published": "2021-09-20T07:19:54Z",
        "link": "http://arxiv.org/abs/2109.09331v2",
        "categories": [
            "cs.AI",
            "cs.MA",
            "cs.SE"
        ]
    },
    {
        "title": "Generalization in Mean Field Games by Learning Master Policies",
        "authors": [
            "Sarah Perrin",
            "Mathieu Laurière",
            "Julien Pérolat",
            "Romuald Élie",
            "Matthieu Geist",
            "Olivier Pietquin"
        ],
        "summary": "Mean Field Games (MFGs) can potentially scale multi-agent systems to extremely large populations of agents. Yet, most of the literature assumes a single initial distribution for the agents, which limits the practical applications of MFGs. Machine Learning has the potential to solve a wider diversity of MFG problems thanks to generalizations capacities. We study how to leverage these generalization properties to learn policies enabling a typical agent to behave optimally against any population distribution. In reference to the Master equation in MFGs, we coin the term ``Master policies'' to describe them and we prove that a single Master policy provides a Nash equilibrium, whatever the initial distribution. We propose a method to learn such Master policies. Our approach relies on three ingredients: adding the current population distribution as part of the observation, approximating Master policies with neural networks, and training via Reinforcement Learning and Fictitious Play. We illustrate on numerical examples not only the efficiency of the learned Master policy but also its generalization capabilities beyond the distributions used for training.",
        "published": "2021-09-20T17:47:34Z",
        "link": "http://arxiv.org/abs/2109.09717v1",
        "categories": [
            "cs.LG",
            "cs.GT",
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "I Know You Can't See Me: Dynamic Occlusion-Aware Safety Validation of   Strategic Planners for Autonomous Vehicles Using Hypergames",
        "authors": [
            "Maximilian Kahn",
            "Atrisha Sarkar",
            "Krzysztof Czarnecki"
        ],
        "summary": "A particular challenge for both autonomous and human driving is dealing with risk associated with dynamic occlusion, i.e., occlusion caused by other vehicles in traffic. Based on the theory of hypergames, we develop a novel multi-agent dynamic occlusion risk (DOR) measure for assessing situational risk in dynamic occlusion scenarios. Furthermore, we present a white-box, scenario-based, accelerated safety validation framework for assessing safety of strategic planners in AV. Based on evaluation over a large naturalistic database, our proposed validation method achieves a 4000% speedup compared to direct validation on naturalistic data, a more diverse coverage, and ability to generalize beyond the dataset and generate commonly observed dynamic occlusion crashes in traffic in an automated manner.",
        "published": "2021-09-20T19:38:14Z",
        "link": "http://arxiv.org/abs/2109.09807v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Robust Multi-Robot Active Target Tracking Against Sensing and   Communication Attacks",
        "authors": [
            "Lifeng Zhou",
            "Vijay Kumar"
        ],
        "summary": "The problem of multi-robot target tracking asks for actively planning the joint motion of robots to track targets. In this paper, we focus on such target tracking problems in adversarial environments, where attacks or failures may deactivate robots' sensors and communications. In contrast to the previous works that consider no attacks or sensing attacks only, we formalize the first robust multi-robot tracking framework that accounts for any fixed numbers of worst-case sensing and communication attacks. To secure against such attacks, we design the first robust planning algorithm, named Robust Active Target Tracking (RATT), which approximates the communication attacks to equivalent sensing attacks and then optimizes against the approximated and original sensing attacks. We show that RATT provides provable suboptimality bounds on the tracking quality for any non-decreasing objective function. Our analysis utilizes the notations of curvature for set functions introduced in combinatorial optimization. In addition, RATT runs in polynomial time and terminates with the same running time as state-of-the-art algorithms for (non-robust) target tracking. Finally, we evaluate RATT with both qualitative and quantitative simulations across various scenarios. In the evaluations, RATT exhibits a tracking quality that is near-optimal and superior to varying non-robust heuristics. We also demonstrate RATT's superiority and robustness against varying attack models (e.g., worst-case and bounded rational attacks).",
        "published": "2021-09-20T20:48:05Z",
        "link": "http://arxiv.org/abs/2109.09838v1",
        "categories": [
            "cs.RO",
            "cs.DS",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Generalized dynamic cognitive hierarchy models for strategic driving   behavior",
        "authors": [
            "Atrisha Sarkar",
            "Kate Larson",
            "Krzysztof Czarnecki"
        ],
        "summary": "While there has been an increasing focus on the use of game theoretic models for autonomous driving, empirical evidence shows that there are still open questions around dealing with the challenges of common knowledge assumptions as well as modeling bounded rationality. To address some of these practical challenges, we develop a framework of generalized dynamic cognitive hierarchy for both modelling naturalistic human driving behavior as well as behavior planning for autonomous vehicles (AV). This framework is built upon a rich model of level-0 behavior through the use of automata strategies, an interpretable notion of bounded rationality through safety and maneuver satisficing, and a robust response for planning. Based on evaluation on two large naturalistic datasets as well as simulation of critical traffic scenarios, we show that i) automata strategies are well suited for level-0 behavior in a dynamic level-k framework, and ii) the proposed robust response to a heterogeneous population of strategic and non-strategic reasoners can be an effective approach for game theoretic planning in AV.",
        "published": "2021-09-20T21:49:52Z",
        "link": "http://arxiv.org/abs/2109.09861v2",
        "categories": [
            "cs.AI",
            "cs.GT",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Enriching a CP-Net by Asymmetric Merging",
        "authors": [
            "Stijn Henckens",
            "Mostafa Mohajeri Parizi",
            "Giovanni Sileno"
        ],
        "summary": "Conditional ceteris paribus preference networks (CP-nets) are commonly used to capture qualitative conditional preferences. In many use cases, when the preferential structure of an agent is incomplete, information from other preferential structures (e.g. that of other users) preferences can be used to fill in the gaps. Earlier works proposed methods to symmetrically merge multiple incomplete CP-nets by means of voting semantics. However, the merged CP-net can contain preference relations that do not fit to a given user's original preference profile. This paper proposes an asymmetric merging (or enriching) method to obtain and fill-in preference relations of a user's CP-net from another CP-net in a way that preserves the original preference relations.",
        "published": "2021-09-21T11:44:11Z",
        "link": "http://arxiv.org/abs/2109.10110v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Locality Matters: A Scalable Value Decomposition Approach for   Cooperative Multi-Agent Reinforcement Learning",
        "authors": [
            "Roy Zohar",
            "Shie Mannor",
            "Guy Tennenholtz"
        ],
        "summary": "Cooperative multi-agent reinforcement learning (MARL) faces significant scalability issues due to state and action spaces that are exponentially large in the number of agents. As environments grow in size, effective credit assignment becomes increasingly harder and often results in infeasible learning times. Still, in many real-world settings, there exist simplified underlying dynamics that can be leveraged for more scalable solutions. In this work, we exploit such locality structures effectively whilst maintaining global cooperation. We propose a novel, value-based multi-agent algorithm called LOMAQ, which incorporates local rewards in the Centralized Training Decentralized Execution paradigm. Additionally, we provide a direct reward decomposition method for finding these local rewards when only a global signal is provided. We test our method empirically, showing it scales well compared to other methods, significantly improving performance and convergence speed.",
        "published": "2021-09-22T10:08:15Z",
        "link": "http://arxiv.org/abs/2109.10632v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "stat.ML"
        ]
    },
    {
        "title": "Constrained multi-agent ergodic area surveying control based on finite   element approximation of the potential field",
        "authors": [
            "Stefan Ivić",
            "Ante Sikirica",
            "Bojan Crnković"
        ],
        "summary": "Heat Equation Driven Area Coverage (HEDAC) is a state-of-the-art multi-agent ergodic motion control guided by a gradient of a potential field. A finite element method is hereby implemented to obtain a solution of the Helmholtz partial differential equation, which models the potential field for surveying motion control. This allows us to survey arbitrarily shaped domains and to include obstacles in an elegant and robust manner intrinsic to HEDAC's fundamental idea. For a simple kinematic motion, the obstacles and boundary avoidance constraints are successfully handled by directing the agent motion with the gradient of the potential. However, including additional constraints, such as the minimal clearance distance from stationary and moving obstacles and the minimal path curvature radius, requires further alternations of the control algorithm. We introduce a relatively simple yet robust approach for handling these constraints by formulating a straightforward optimization problem based on collision-free escape route maneuvers. This approach provides a guaranteed collision avoidance mechanism while being computationally inexpensive as a result of the optimization problem partitioning. The proposed motion control is evaluated in three realistic surveying scenarios simulations, showing the effectiveness of the surveying and the robustness of the control algorithm. Furthermore, potential maneuvering difficulties due to improperly defined surveying scenarios are highlighted and we provide guidelines on how to overpass them. The results are promising and indicate real-world applicability of the proposed constrained multi-agent motion control for autonomous surveying and potentially other HEDAC utilizations.",
        "published": "2021-09-22T14:23:20Z",
        "link": "http://arxiv.org/abs/2109.10756v4",
        "categories": [
            "math.OC",
            "cs.MA",
            "cs.RO",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Towards Multi-Agent Reinforcement Learning using Quantum Boltzmann   Machines",
        "authors": [
            "Tobias Müller",
            "Christoph Roch",
            "Kyrill Schmid",
            "Philipp Altmann"
        ],
        "summary": "Reinforcement learning has driven impressive advances in machine learning. Simultaneously, quantum-enhanced machine learning algorithms using quantum annealing underlie heavy developments. Recently, a multi-agent reinforcement learning (MARL) architecture combining both paradigms has been proposed. This novel algorithm, which utilizes Quantum Boltzmann Machines (QBMs) for Q-value approximation has outperformed regular deep reinforcement learning in terms of time-steps needed to converge. However, this algorithm was restricted to single-agent and small 2x2 multi-agent grid domains. In this work, we propose an extension to the original concept in order to solve more challenging problems. Similar to classic DQNs, we add an experience replay buffer and use different networks for approximating the target and policy values. The experimental results show that learning becomes more stable and enables agents to find optimal policies in grid-domains with higher complexity. Additionally, we assess how parameter sharing influences the agents behavior in multi-agent domains. Quantum sampling proves to be a promising method for reinforcement learning tasks, but is currently limited by the QPU size and therefore by the size of the input and Boltzmann machine.",
        "published": "2021-09-22T17:59:24Z",
        "link": "http://arxiv.org/abs/2109.10900v2",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Trust Region Policy Optimisation in Multi-Agent Reinforcement Learning",
        "authors": [
            "Jakub Grudzien Kuba",
            "Ruiqing Chen",
            "Muning Wen",
            "Ying Wen",
            "Fanglei Sun",
            "Jun Wang",
            "Yaodong Yang"
        ],
        "summary": "Trust region methods rigorously enabled reinforcement learning (RL) agents to learn monotonically improving policies, leading to superior performance on a variety of tasks. Unfortunately, when it comes to multi-agent reinforcement learning (MARL), the property of monotonic improvement may not simply apply; this is because agents, even in cooperative games, could have conflicting directions of policy updates. As a result, achieving a guaranteed improvement on the joint policy where each agent acts individually remains an open challenge. In this paper, we extend the theory of trust region learning to MARL. Central to our findings are the multi-agent advantage decomposition lemma and the sequential policy update scheme. Based on these, we develop Heterogeneous-Agent Trust Region Policy Optimisation (HATPRO) and Heterogeneous-Agent Proximal Policy Optimisation (HAPPO) algorithms. Unlike many existing MARL algorithms, HATRPO/HAPPO do not need agents to share parameters, nor do they need any restrictive assumptions on decomposibility of the joint value function. Most importantly, we justify in theory the monotonic improvement property of HATRPO/HAPPO. We evaluate the proposed methods on a series of Multi-Agent MuJoCo and StarCraftII tasks. Results show that HATRPO and HAPPO significantly outperform strong baselines such as IPPO, MAPPO and MADDPG on all tested tasks, therefore establishing a new state of the art.",
        "published": "2021-09-23T09:44:35Z",
        "link": "http://arxiv.org/abs/2109.11251v2",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "An Efficient Simulation-Based Travel Demand Calibration Algorithm for   Large-Scale Metropolitan Traffic Models",
        "authors": [
            "Neha Arora",
            "Yi-fan Chen",
            "Sanjay Ganapathy",
            "Yechen Li",
            "Ziheng Lin",
            "Carolina Osorio",
            "Andrew Tomkins",
            "Iveel Tsogsuren"
        ],
        "summary": "Metropolitan scale vehicular traffic modeling is used by a variety of private and public sector urban mobility stakeholders to inform the design and operations of road networks. High-resolution stochastic traffic simulators are increasingly used to describe detailed demand-supply interactions. The design of efficient calibration techniques remains a major challenge. This paper considers a class of high-dimensional calibration problems known as origin-destination (OD) calibration. We formulate the problem as a continuous simulation-based optimization problem. Our proposed algorithm builds upon recent metamodel methods that tackle the simulation-based problem by solving a sequence of approximate analytical optimization problems, which rely on the use of analytical network models. In this paper, we formulate a network model defined as a system of linear equations, the dimension of which scales linearly with the number of roads with field data and independently of the dimension of the route choice set. This makes the approach suitable for large-scale metropolitan networks. The approach has enhanced efficiency compared with past metamodel formulations that are based on systems of nonlinear, rather than linear, equations. It also has enhanced efficiency compared to traditional calibration methods that resort to simulation-based estimates of traffic assignment matrices, while the proposed approach uses analytical approximations of these matrices. We benchmark the approach considering a peak period Salt Lake City case study and calibrate based on field vehicular count data. The new formulation yields solutions with good performance and is suitable for large-scale road networks.",
        "published": "2021-09-23T14:22:37Z",
        "link": "http://arxiv.org/abs/2109.11392v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Dimension-Free Rates for Natural Policy Gradient in Multi-Agent   Reinforcement Learning",
        "authors": [
            "Carlo Alfano",
            "Patrick Rebeschini"
        ],
        "summary": "Cooperative multi-agent reinforcement learning is a decentralized paradigm in sequential decision making where agents distributed over a network iteratively collaborate with neighbors to maximize global (network-wide) notions of rewards. Exact computations typically involve a complexity that scales exponentially with the number of agents. To address this curse of dimensionality, we design a scalable algorithm based on the Natural Policy Gradient framework that uses local information and only requires agents to communicate with neighbors within a certain range. Under standard assumptions on the spatial decay of correlations for the transition dynamics of the underlying Markov process and the localized learning policy, we show that our algorithm converges to the globally optimal policy with a dimension-free statistical and computational complexity, incurring a localization error that does not depend on the number of agents and converges to zero exponentially fast as a function of the range of communication.",
        "published": "2021-09-23T23:38:15Z",
        "link": "http://arxiv.org/abs/2109.11692v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "math.ST",
            "stat.ML",
            "stat.TH"
        ]
    },
    {
        "title": "Distributed Estimation of Sparse Inverse Covariances",
        "authors": [
            "Tong Yao",
            "Shreyas Sundaram"
        ],
        "summary": "Learning the relationships between various entities from time-series data is essential in many applications. Gaussian graphical models have been studied to infer these relationships. However, existing algorithms process data in a batch at a central location, limiting their applications in scenarios where data is gathered by different agents. In this paper, we propose a distributed sparse inverse covariance algorithm to learn the network structure (i.e., dependencies among observed entities) in real-time from data collected by distributed agents. Our approach is built on an online graphical alternating minimization algorithm, augmented with a consensus term that allows agents to learn the desired structure cooperatively. We allow the system designer to select the number of communication rounds and optimization steps per data point. We characterize the rate of convergence of our algorithm and provide simulations on synthetic datasets.",
        "published": "2021-09-24T15:26:41Z",
        "link": "http://arxiv.org/abs/2109.12020v2",
        "categories": [
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Towards a Multi-Agent System Architecture for Supply Chain Management",
        "authors": [
            "Carlos R. Jaimez-González",
            "Wulfrano A. Luna-Ramírez"
        ],
        "summary": "Individual business processes have been changing since the Internet was created, and they are now oriented towards a more distributed and collaborative business model, in an e-commerce environment that adapts itself to the competitive and changing market conditions. This paper presents a multi-agent system architecture for supply chain management, which explores different strategies and offers solutions in a distributed e-commerce environment. The system is designed to support different types of interfaces, which allow interoperating with other business models already developed. In order to show how the entire multi-agent system is being developed, the implementation of a collaborative agent is presented and explained.",
        "published": "2021-09-24T17:53:42Z",
        "link": "http://arxiv.org/abs/2110.08125v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Beyond Robustness: A Taxonomy of Approaches towards Resilient   Multi-Robot Systems",
        "authors": [
            "Amanda Prorok",
            "Matthew Malencia",
            "Luca Carlone",
            "Gaurav S. Sukhatme",
            "Brian M. Sadler",
            "Vijay Kumar"
        ],
        "summary": "Robustness is key to engineering, automation, and science as a whole. However, the property of robustness is often underpinned by costly requirements such as over-provisioning, known uncertainty and predictive models, and known adversaries. These conditions are idealistic, and often not satisfiable. Resilience on the other hand is the capability to endure unexpected disruptions, to recover swiftly from negative events, and bounce back to normality. In this survey article, we analyze how resilience is achieved in networks of agents and multi-robot systems that are able to overcome adversity by leveraging system-wide complementarity, diversity, and redundancy - often involving a reconfiguration of robotic capabilities to provide some key ability that was not present in the system a priori. As society increasingly depends on connected automated systems to provide key infrastructure services (e.g., logistics, transport, and precision agriculture), providing the means to achieving resilient multi-robot systems is paramount. By enumerating the consequences of a system that is not resilient (fragile), we argue that resilience must become a central engineering design consideration. Towards this goal, the community needs to gain clarity on how it is defined, measured, and maintained. We address these questions across foundational robotics domains, spanning perception, control, planning, and learning. One of our key contributions is a formal taxonomy of approaches, which also helps us discuss the defining factors and stressors for a resilient system. Finally, this survey article gives insight as to how resilience may be achieved. Importantly, we highlight open problems that remain to be tackled in order to reap the benefits of resilient robotic systems.",
        "published": "2021-09-25T11:25:02Z",
        "link": "http://arxiv.org/abs/2109.12343v1",
        "categories": [
            "cs.RO",
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Modelling the transition to a low-carbon energy supply",
        "authors": [
            "Alexander Kell"
        ],
        "summary": "A transition to a low-carbon electricity supply is crucial to limit the impacts of climate change. Reducing carbon emissions could help prevent the world from reaching a tipping point, where runaway emissions are likely. Runaway emissions could lead to extremes in weather conditions around the world -- especially in problematic regions unable to cope with these conditions. However, the movement to a low-carbon energy supply can not happen instantaneously due to the existing fossil-fuel infrastructure and the requirement to maintain a reliable energy supply. Therefore, a low-carbon transition is required, however, the decisions various stakeholders should make over the coming decades to reduce these carbon emissions are not obvious. This is due to many long-term uncertainties, such as electricity, fuel and generation costs, human behaviour and the size of electricity demand. A well choreographed low-carbon transition is, therefore, required between all of the heterogenous actors in the system, as opposed to changing the behaviour of a single, centralised actor. The objective of this thesis is to create a novel, open-source agent-based model to better understand the manner in which the whole electricity market reacts to different factors using state-of-the-art machine learning and artificial intelligence methods. In contrast to other works, this thesis looks at both the long-term and short-term impact that different behaviours have on the electricity market by using these state-of-the-art methods.",
        "published": "2021-09-25T12:37:05Z",
        "link": "http://arxiv.org/abs/2111.00987v1",
        "categories": [
            "econ.GN",
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "q-fin.EC"
        ]
    },
    {
        "title": "LINDA: Multi-Agent Local Information Decomposition for Awareness of   Teammates",
        "authors": [
            "Jiahan Cao",
            "Lei Yuan",
            "Jianhao Wang",
            "Shaowei Zhang",
            "Chongjie Zhang",
            "Yang Yu",
            "De-Chuan Zhan"
        ],
        "summary": "In cooperative multi-agent reinforcement learning (MARL), where agents only have access to partial observations, efficiently leveraging local information is critical. During long-time observations, agents can build \\textit{awareness} for teammates to alleviate the problem of partial observability. However, previous MARL methods usually neglect this kind of utilization of local information. To address this problem, we propose a novel framework, multi-agent \\textit{Local INformation Decomposition for Awareness of teammates} (LINDA), with which agents learn to decompose local information and build awareness for each teammate. We model the awareness as stochastic random variables and perform representation learning to ensure the informativeness of awareness representations by maximizing the mutual information between awareness and the actual trajectory of the corresponding agent. LINDA is agnostic to specific algorithms and can be flexibly integrated to different MARL methods. Sufficient experiments show that the proposed framework learns informative awareness from local partial observations for better collaboration and significantly improves the learning performance, especially on challenging tasks.",
        "published": "2021-09-26T06:46:51Z",
        "link": "http://arxiv.org/abs/2109.12508v3",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Distributed Stabilization of Signed Networks via Self-loop Compensation",
        "authors": [
            "Haibin Shao",
            "Lulu Pan"
        ],
        "summary": "This paper examines the stability and distributed stabilization of signed multi-agent networks. Here, positive semidefiniteness is not inherent for signed Laplacians, which renders the stability and consensus of this category of networks intricate. First, we examine the stability of signed networks by introducing a novel graph-theoretic objective negative cut set, which implies that manipulating negative edge weights cannot change a unstable network into a stable one. Then, inspired by the diagonal dominance and stability of matrices, a local state damping mechanism is introduced using self-loop compensation. The self-loop compensation is only active for those agents who are incident to negative edges and can stabilize signed networks in a fully distributed manner. Quantitative connections between self-loop compensation and the stability of the compensated signed network are established for a tradeoff between compensation efforts and network stability. Necessary and/or sufficient conditions for predictable cluster consensus of compensated signed networks are provided. The optimality of self-loop compensation is discussed. Furthermore, we extend our results to directed signed networks where the symmetry of signed Laplacian is not free. The correlation between the stability of the compensated dynamics obtained by self-loop compensation and eventually positivity is further discussed. Novel insights into the stability of multi-agent systems on signed networks in terms of self-loop compensation are offered. Simulation examples are provided to demonstrate the theoretical results.",
        "published": "2021-09-26T10:47:04Z",
        "link": "http://arxiv.org/abs/2109.12555v7",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Robust Coordination of Linear Threshold Dynamics on Directed Weighted   Networks",
        "authors": [
            "Laura Arditti",
            "Giacomo Como",
            "Fabio Fagnani",
            "Martina Vanelli"
        ],
        "summary": "We study asynchronous dynamics in a network of interacting agents updating their binary states according to a time-varying threshold rule. Specifically, agents revise their state asynchronously by comparing the weighted average of the current states of their neighbors in the interaction network with possibly heterogeneous time-varying threshold values. Such thresholds are determined by an exogenous signal representing an external influence field modeling the different agents' biases towards one state with respect to the other one. We prove necessary and sufficient conditions for global stability of consensus equilibria, i.e., equilibria where all agents have the same state, robustly with respect to the (constant or time-varying) external field. Our results apply to general weighted directed interaction networks and build on super-modularity properties of certain network coordination games whose best response dynamics coincide with the linear threshold dynamics. In particular, we introduce a novel notion of robust improvement paths for such games and characterize conditions for their existence.",
        "published": "2021-09-26T19:50:01Z",
        "link": "http://arxiv.org/abs/2109.12685v3",
        "categories": [
            "cs.GT",
            "cs.MA",
            "cs.SI",
            "cs.SY",
            "eess.SY",
            "math.DS",
            "91A06, 91A10, 91A13, 91A40"
        ]
    },
    {
        "title": "Equilibria and learning dynamics in mixed network   coordination/anti-coordination games",
        "authors": [
            "Laura Arditti",
            "Giacomo Como",
            "Fabio Fagnani",
            "Martina Vanelli"
        ],
        "summary": "Whilst network coordination games and network anti-coordination games have received a considerable amount of attention in the literature, network games with coexisting coordinating and anti-coordinating players are known to exhibit more complex behaviors. In fact, depending on the network structure, such games may even fail to have pure-strategy Nash equilibria. An example is represented by the well-known matching pennies (discoordination) game.   In this work, we first provide graph-theoretic conditions for the existence of pure-strategy Nash equilibria in mixed network coordination/anti-coordination games of arbitrary size. For the case where such conditions are met, we then study the asymptotic behavior of best-response dynamics and provide sufficient conditions for finite-time convergence to the set of Nash equilibria. Our results build on an extension and refinement of the notion of network cohesiveness and on the formulation of the new concept of network indecomposibility.",
        "published": "2021-09-26T20:13:19Z",
        "link": "http://arxiv.org/abs/2109.12692v3",
        "categories": [
            "cs.GT",
            "cs.MA",
            "cs.SI",
            "cs.SY",
            "eess.SY",
            "math.DS",
            "91A06, 91A10, 91A13, 91A40"
        ]
    },
    {
        "title": "The use of multi-agent systems for modeling technological processes",
        "authors": [
            "Sergey Petrovich Bobkov",
            "Irina Aleksandrovna Astrakhantseva"
        ],
        "summary": "The article is devoted to the issues of using discrete simulation models for modeling some basic technological processes. In the scientific work, models in the form of multi-agent systems have been investigated, which allow us to consider a continuous environment as a set of interacting elements (agents), the behavior of which obeys local functions. The authors describe the basic techniques and general methodology for the development of deterministic agent-based models. The paper considers the use of multi-agent systems for modeling thermal conductivity, taking into account the nonlinearity of the process, in homogeneity of the material and the presence of volumetric heat sources of variable power in it. The obtained scientific results are in good agreement with the generally accepted classical approaches and do not contradict the provisions adopted in the theory of thermal phenomena.",
        "published": "2021-09-27T17:16:49Z",
        "link": "http://arxiv.org/abs/2109.13196v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Cooperative Object Transportation using Gibbs Random Fields",
        "authors": [
            "Paulo Rezeck",
            "Renato M. Assunção",
            "Luiz Chaimowicz"
        ],
        "summary": "This paper presents a novel methodology that allows a swarm of robots to perform a cooperative transportation task. Our approach consists of modeling the swarm as a {\\em Gibbs Random Field} (GRF), taking advantage of this framework's locality properties. By setting appropriate potential functions, robots can dynamically navigate, form groups, and perform cooperative transportation in a completely decentralized fashion. Moreover, these behaviors emerge from the local interactions without the need for explicit communication or coordination. To evaluate our methodology, we perform a series of simulations and proof-of-concept experiments in different scenarios. Our results show that the method is scalable, adaptable, and robust to failures and changes in the environment.",
        "published": "2021-09-28T13:53:41Z",
        "link": "http://arxiv.org/abs/2109.13734v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Information-Bottleneck-Based Behavior Representation Learning for   Multi-agent Reinforcement learning",
        "authors": [
            "Yue Jin",
            "Shuangqing Wei",
            "Jian Yuan",
            "Xudong Zhang"
        ],
        "summary": "In multi-agent deep reinforcement learning, extracting sufficient and compact information of other agents is critical to attain efficient convergence and scalability of an algorithm. In canonical frameworks, distilling of such information is often done in an implicit and uninterpretable manner, or explicitly with cost functions not able to reflect the relationship between information compression and utility in representation. In this paper, we present Information-Bottleneck-based Other agents' behavior Representation learning for Multi-agent reinforcement learning (IBORM) to explicitly seek low-dimensional mapping encoder through which a compact and informative representation relevant to other agents' behaviors is established. IBORM leverages the information bottleneck principle to compress observation information, while retaining sufficient information relevant to other agents' behaviors used for cooperation decision. Empirical results have demonstrated that IBORM delivers the fastest convergence rate and the best performance of the learned policies, as compared with implicit behavior representation learning and explicit behavior representation learning without explicitly considering information compression and utility.",
        "published": "2021-09-29T04:22:49Z",
        "link": "http://arxiv.org/abs/2109.14188v1",
        "categories": [
            "cs.LG",
            "cs.IT",
            "cs.MA",
            "math.IT"
        ]
    },
    {
        "title": "Majority Vote in Social Networks: Make Random Friends or Be Stubborn to   Overpower Elites",
        "authors": [
            "Charlotte Out",
            "Ahad N. Zehmakan"
        ],
        "summary": "Consider a graph $G$, representing a social network. Assume that initially each node is colored either black or white, which corresponds to a positive or negative opinion regarding a consumer product or a technological innovation. In the majority model, in each round all nodes simultaneously update their color to the most frequent color among their connections.   Experiments on the graph data from the real world social networks (SNs) suggest that if all nodes in an extremely small set of high-degree nodes, often referred to as the elites, agree on a color, that color becomes the dominant color at the end of the process. We propose two countermeasures that can be adopted by individual nodes relatively easily and guarantee that the elites will not have this disproportionate power to engineer the dominant output color. The first countermeasure essentially requires each node to make some new connections at random while the second one demands the nodes to be more reluctant towards changing their color (opinion). We verify their effectiveness and correctness both theoretically and experimentally.   We also investigate the majority model and a variant of it when the initial coloring is random on the real world SNs and several random graph models. In particular, our results on the Erd\\H{o}s-R\\'{e}nyi and regular random graphs confirm or support several theoretical findings or conjectures by the prior work regarding the threshold behavior of the process.   Finally, we provide theoretical and experimental evidence for the existence of a poly-logarithmic bound on the expected stabilization time of the majority model.",
        "published": "2021-09-29T08:21:11Z",
        "link": "http://arxiv.org/abs/2109.14265v1",
        "categories": [
            "cs.SI",
            "cs.MA"
        ]
    },
    {
        "title": "A Spatial Agent-Based Model for Preemptive Evacuation Decisions During   Typhoon",
        "authors": [
            "Rey C. Rodrigueza",
            "Maria Regina Justina E. Estuar"
        ],
        "summary": "Natural disasters continue to cause tremendous damage to human lives and properties. The Philippines, due to its geographic location, is considered a natural disaster-prone country experiencing an average of 20 tropical cyclones annually. Understanding what factors significantly affect decision making during crucial evacuation stages could help in making decisions on how to prepare for disasters, how to act appropriately and strategically respond during and after a calamity. In this work, an agent-based model for preemptive evacuation decisions during typhoon is presented. In the model, civilians are represented by households and their evacuation decisions were based from calculated perceived risk. Also, rescuer and shelter manager agents were included as facilitators during the preemptive evacuation process. National and municipal census data were employed in the model, particularly for the demographics of household agents. Further, geospatial data of a village in a typhoon-susceptible municipality was used to represent the environment. The decision to evacuate or not to evacuate depends on the agent's perceived risk which also depends on three decision factors: characteristics of the decision maker (CDM); capacity related factors (CRF); and hazard related factors (HRF). Finally, the number of households who decided to evacuate or opted to stay as influenced by the model`s decision factors were determined during simulations. Sensitivity analysis using linear regression shows that all parameters used in the model are significant in the evacuation decision of household agents.",
        "published": "2021-09-29T14:48:28Z",
        "link": "http://arxiv.org/abs/2109.14459v1",
        "categories": [
            "cs.MA",
            "68U99",
            "I.6.5"
        ]
    },
    {
        "title": "Adversarial Linear-Quadratic Mean-Field Games over Multigraphs",
        "authors": [
            "Muhammad Aneeq uz Zaman",
            "Sujay Bhatt",
            "Tamer Başar"
        ],
        "summary": "In this paper, we propose a game between an exogenous adversary and a network of agents connected via a multigraph. The multigraph is composed of (1) a global graph structure, capturing the virtual interactions among the agents, and (2) a local graph structure, capturing physical/local interactions among the agents. The aim of each agent is to achieve consensus with the other agents in a decentralized manner by minimizing a local cost associated with its local graph and a global cost associated with the global graph. The exogenous adversary, on the other hand, aims to maximize the average cost incurred by all agents in the multigraph. We derive Nash equilibrium policies for the agents and the adversary in the Mean-Field Game setting, when the agent population in the global graph is arbitrarily large and the ``homogeneous mixing\" hypothesis holds on local graphs. This equilibrium is shown to be unique and the equilibrium Markov policies for each agent depend on the local state of the agent, as well as the influences on the agent by the local and global mean fields.",
        "published": "2021-09-29T14:51:01Z",
        "link": "http://arxiv.org/abs/2109.14461v2",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Random coordinate descent algorithm for open multi-agent systems with   complete topology and homogeneous agents",
        "authors": [
            "Charles Monnoyer de Galland",
            "Renato Vizuete",
            "Julien M. Hendrickx",
            "Paolo Frasca",
            "Elena Panteley"
        ],
        "summary": "We study the convergence in expectation of the Random Coordinate Descent algorithm (RCD) for solving optimal resource allocations problems in open multi-agent systems, i.e., multi-agent systems that are subject to arrivals and departures of agents. Assuming all local functions are strongly-convex and smooth, and their minimizers lie in a given ball, we analyse the evolution of the distance to the minimizer in expectation when the system is occasionally subject to replacements in addition to the usual iterations of the RCD algorithm. We focus on complete graphs where all agents interact with each other with the same probability, and provide conditions to guarantee convergence in open system. Finally, a discussion around the tightness of our results is provided.",
        "published": "2021-09-29T15:50:11Z",
        "link": "http://arxiv.org/abs/2109.14510v1",
        "categories": [
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "Sequential Estimation under Multiple Resources: a Bandit Point of View",
        "authors": [
            "Alireza Masoumian",
            "Shayan Kiyani",
            "Mohammad Hossein Yassaee"
        ],
        "summary": "The problem of Sequential Estimation under Multiple Resources (SEMR) is defined in a federated setting. SEMR could be considered as the intersection of statistical estimation and bandit theory. In this problem, an agent is confronting with k resources to estimate a parameter $\\theta$. The agent should continuously learn the quality of the resources by wisely choosing them and at the end, proposes an estimator based on the collected data. In this paper, we assume that the resources' distributions are Gaussian. The quality of the final estimator is evaluated by its mean squared error. Also, we restrict our class of estimators to unbiased estimators in order to define a meaningful notion of regret. The regret measures the performance of the agent by the variance of the final estimator in comparison to the optimal variance. We propose a lower bound to determine the fundamental limit of the setting even in the case that the distributions are not Gaussian. Also, we offer an order-optimal algorithm to achieve this lower bound.",
        "published": "2021-09-29T20:19:09Z",
        "link": "http://arxiv.org/abs/2109.14703v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.DC",
            "cs.MA",
            "math.ST",
            "stat.TH"
        ]
    },
    {
        "title": "Decentralized Role Assignment in Multi-Agent Teams via Empirical   Game-Theoretic Analysis",
        "authors": [
            "Fengjun Yang",
            "Negar Mehr",
            "Mac Schwager"
        ],
        "summary": "We propose a method, based on empirical game theory, for a robot operating as part of a team to choose its role within the team without explicitly communicating with team members, by leveraging its knowledge about the team structure. To do this, we formulate the role assignment problem as a dynamic game, and borrow tools from empirical game-theoretic analysis to analyze such games. Based on this game-theoretic formulation, we propose a distributed controller for each robot to dynamically decide on the best role to take. We demonstrate our method in simulations of a collaborative planar manipulation scenario in which each agent chooses from a set of feedback control policies at each instant. The agents can effectively collaborate without communication to manipulate the object while also avoiding collisions using our method.",
        "published": "2021-09-29T23:07:18Z",
        "link": "http://arxiv.org/abs/2109.14755v1",
        "categories": [
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "A Social Cognitive Heuristic for Adaptive Data Dissemination in Mobile   Opportunistic Networks",
        "authors": [
            "Matteo Mordacchini",
            "Andrea Passarella",
            "Marco Conti"
        ],
        "summary": "It is commonly agreed that data will be one of the cornerstones of Future Internet systems. In this context, mobile Opportunistic Networks (ONs) are one of the key paradigms to support, in a self-organising and decentralised manner, the growth of data generated by localized interactions between users mobile devices, and between them and nearby devices such as IoT nodes. In ONs, the spontaneous collaboration among mobile devices is exploited to disseminate data toward interested users. However, the limited resources and knowledge available at each node, and the vast amount of data available, make it difficult to devise efficient schemes to accomplish this task. Recent solutions propose to equip each device with data filtering methods derived from human data processing schemes, known as Cognitive Heuristics, i.e. very effective methods used by the brain to quickly drop useless information, while keeping the most relevant one. These solutions can become less effective when facing dynamic scenarios or situations where nodes cannot fully collaborate. One of the reasons is that the solutions proposed so far do not take take into account the social structure of the environment where the nodes move in. To be more effective, the selection of information performed by each node should take into consideration this dimension of the environment. In this paper we propose a social-based data dissemination scheme, based on the cognitive Social Circle Heuristic. This evaluation method exploits the structure of the social environment to make inferences about the relevance of discovered information. We show how the Social Circle Heuristic, coupled with a cognitive-based community detection scheme, can be exploited to design an effective data dissemination algorithm for ONs. We provide a detailed analysis of the performance of the proposed solution via simulation.",
        "published": "2021-09-30T09:43:16Z",
        "link": "http://arxiv.org/abs/2109.14958v1",
        "categories": [
            "cs.NI",
            "cs.DC",
            "cs.HC",
            "cs.MA",
            "I.6.1; I.6.5; I.2.11"
        ]
    },
    {
        "title": "Linear Differential Games for Cooperative Behavior Planning of   Autonomous Vehicles Using Mixed-Integer Programming",
        "authors": [
            "Tobias Kessler",
            "Klemens Esterle",
            "Alois Knoll"
        ],
        "summary": "Cooperatively planning for multiple agents has been proposed as a promising method for strategic and motion planning for automated vehicles. By taking into account the intent of every agent, the ego agent can incorporate future interactions with human-driven vehicles into its planning. The problem is often formulated as a multi-agent game and solved using iterative algorithms operating on a discretized action or state space. Even if converging to a Nash equilibrium, the result will often be only sub-optimal. In this paper, we define a linear differential game for a set of interacting agents and solve it to optimality using mixed-integer programming. A disjunctive formulation of the orientation allows us to formulate linear constraints to prevent agent-to-agent collision while preserving the non-holonomic motion properties of the vehicle model. Soft constraints account for prediction errors. We then define a joint cost function, where a cooperation factor can adapt between altruistic, cooperative, and egoistic behavior. We study the influence of the cooperation factor to solve scenarios, where interaction between the agents is necessary to solve them successfully. The approach is then evaluated in a racing scenario, where we show the applicability of the formulation in a closed-loop receding horizon replanning fashion. By accounting for inaccuracies in the cooperative assumption and the actual behavior, we can indeed successfully plan an optimal control strategy interacting closely with other agents.",
        "published": "2021-09-30T13:33:03Z",
        "link": "http://arxiv.org/abs/2109.15122v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Modeling Interactions of Autonomous Vehicles and Pedestrians with Deep   Multi-Agent Reinforcement Learning for Collision Avoidance",
        "authors": [
            "Raphael Trumpp",
            "Harald Bayerlein",
            "David Gesbert"
        ],
        "summary": "Reliable pedestrian crash avoidance mitigation (PCAM) systems are crucial components of safe autonomous vehicles (AVs). The nature of the vehicle-pedestrian interaction where decisions of one agent directly affect the other agent's optimal behavior, and vice versa, is a challenging yet often neglected aspect of such systems. We address this issue by modeling a Markov decision process (MDP) for a simulated AV-pedestrian interaction at an unmarked crosswalk. The AV's PCAM decision policy is learned through deep reinforcement learning (DRL). Since modeling pedestrians realistically is challenging, we compare two levels of intelligent pedestrian behavior. While the baseline model follows a predefined strategy, our advanced pedestrian model is defined as a second DRL agent. This model captures continuous learning and the uncertainty inherent in human behavior, making the AV-pedestrian interaction a deep multi-agent reinforcement learning (DMARL) problem. We benchmark the developed PCAM systems according to the collision rate and the resulting traffic flow efficiency with a focus on the influence of observation uncertainty on the decision-making of the agents. The results show that the AV is able to completely mitigate collisions under the majority of the investigated conditions and that the DRL pedestrian model learns an intelligent crossing behavior.",
        "published": "2021-09-30T17:06:39Z",
        "link": "http://arxiv.org/abs/2109.15266v3",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Decentralized Graph-Based Multi-Agent Reinforcement Learning Using   Reward Machines",
        "authors": [
            "Jueming Hu",
            "Zhe Xu",
            "Weichang Wang",
            "Guannan Qu",
            "Yutian Pang",
            "Yongming Liu"
        ],
        "summary": "In multi-agent reinforcement learning (MARL), it is challenging for a collection of agents to learn complex temporally extended tasks. The difficulties lie in computational complexity and how to learn the high-level ideas behind reward functions. We study the graph-based Markov Decision Process (MDP) where the dynamics of neighboring agents are coupled. We use a reward machine (RM) to encode each agent's task and expose reward function internal structures. RM has the capacity to describe high-level knowledge and encode non-Markovian reward functions. We propose a decentralized learning algorithm to tackle computational complexity, called decentralized graph-based reinforcement learning using reward machines (DGRM), that equips each agent with a localized policy, allowing agents to make decisions independently, based on the information available to the agents. DGRM uses the actor-critic structure, and we introduce the tabular Q-function for discrete state problems. We show that the dependency of Q-function on other agents decreases exponentially as the distance between them increases. Furthermore, the complexity of DGRM is related to the local information size of the largest $\\kappa$-hop neighborhood, and DGRM can find an $O(\\rho^{\\kappa+1})$-approximation of a stationary point of the objective function. To further improve efficiency, we also propose the deep DGRM algorithm, using deep neural networks to approximate the Q-function and policy function to solve large-scale or continuous state problems. The effectiveness of the proposed DGRM algorithm is evaluated by two case studies, UAV package delivery and COVID-19 pandemic mitigation. Experimental results show that local information is sufficient for DGRM and agents can accomplish complex tasks with the help of RM. DGRM improves the global accumulated reward by 119% compared to the baseline in the case of COVID-19 pandemic mitigation.",
        "published": "2021-09-30T21:41:55Z",
        "link": "http://arxiv.org/abs/2110.00096v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Emergence of Theory of Mind Collaboration in Multiagent Systems",
        "authors": [
            "Luyao Yuan",
            "Zipeng Fu",
            "Linqi Zhou",
            "Kexin Yang",
            "Song-Chun Zhu"
        ],
        "summary": "Currently, in the study of multiagent systems, the intentions of agents are usually ignored. Nonetheless, as pointed out by Theory of Mind (ToM), people regularly reason about other's mental states, including beliefs, goals, and intentions, to obtain performance advantage in competition, cooperation or coalition. However, due to its intrinsic recursion and intractable modeling of distribution over belief, integrating ToM in multiagent planning and decision making is still a challenge. In this paper, we incorporate ToM in multiagent partially observable Markov decision process (POMDP) and propose an adaptive training algorithm to develop effective collaboration between agents with ToM. We evaluate our algorithms with two games, where our algorithm surpasses all previous decentralized execution algorithms without modeling ToM.",
        "published": "2021-09-30T23:28:00Z",
        "link": "http://arxiv.org/abs/2110.00121v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.CY"
        ]
    },
    {
        "title": "Learner to learner fuzzy profiles similarity using a hybrid interaction   analysis grid",
        "authors": [
            "Chabane Khentout",
            "Khadidja Harbouche",
            "Mahieddine Djoudi"
        ],
        "summary": "The analysis of remote discussions is not yet at the same level as the face-to-face ones. The present paper aspires twofold. On the one hand, it attempts to establish a suitable environment of interaction and collaboration among learners by using the speech acts via a semi structured synchronous communication tool. On the other, it aims to define behavioral profiles and interpersonal skills hybrid grid by matching the BALES' IPA and PLETY's analysis system. By applying the fuzzy logic, we formalize human reasoning and, thus, giving very appreciable flexibility to the reasoning that use it, which makes it possible to take into account imprecisions and uncertainties. In addition, the educational data mining techniques are used to optimize the mapping of behaviors to learner's profile, with similarity-based clustering, using Eros and PCA measures. In order to show the validity of our system, we performed an experiment on real-world data. The results show, among others: (1) the usefulness of fuzzy logic to properly translate the profile text descriptions into a mathematical format, (2) an irregularity in the behavior of the learners, (3) the correlation between the profiles, (4) the superiority of Eros method to the PCA factor in precision.",
        "published": "2021-10-01T08:01:41Z",
        "link": "http://arxiv.org/abs/2110.00247v1",
        "categories": [
            "cs.AI",
            "cs.IR",
            "cs.MA"
        ]
    },
    {
        "title": "Divergence-Regularized Multi-Agent Actor-Critic",
        "authors": [
            "Kefan Su",
            "Zongqing Lu"
        ],
        "summary": "Entropy regularization is a popular method in reinforcement learning (RL). Although it has many advantages, it alters the RL objective of the original Markov Decision Process (MDP). Though divergence regularization has been proposed to settle this problem, it cannot be trivially applied to cooperative multi-agent reinforcement learning (MARL). In this paper, we investigate divergence regularization in cooperative MARL and propose a novel off-policy cooperative MARL framework, divergence-regularized multi-agent actor-critic (DMAC). Theoretically, we derive the update rule of DMAC which is naturally off-policy and guarantees monotonic policy improvement and convergence in both the original MDP and divergence-regularized MDP. We also give a bound of the discrepancy between the converged policy and optimal policy in the original MDP. DMAC is a flexible framework and can be combined with many existing MARL algorithms. Empirically, we evaluate DMAC in a didactic stochastic game and StarCraft Multi-Agent Challenge and show that DMAC substantially improves the performance of existing MARL algorithms.",
        "published": "2021-10-01T10:27:42Z",
        "link": "http://arxiv.org/abs/2110.00304v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Temporal Graphs and Temporal Network Characteristics for Bio-Inspired   Networks During Optimization",
        "authors": [
            "N. DiBrita",
            "K. Eledlebi",
            "H. Hildmann",
            "L. Culley",
            "A. F. Isakovic"
        ],
        "summary": "Temporal network analysis and time evolution of network characteristics are powerful tools in describing the changing topology of dynamic networks. This paper uses such approaches to better visualize and provide analytical measures for the changes in performance that we observed in Voronoi-type spatial coverage, particularly for the example of time evolving networks with a changing number of wireless sensors being deployed. Specifically, our analysis focuses on the role different combinations of impenetrable obstacles and environmental noise play in connectivity and overall network structure. It is shown how the use of (i) temporal network graphs, and (ii) network centrality and regularity measures illustrate the differences between various options developed for the balancing act of energy and time efficiency in network coverage. Lastly, we compare the outcome of these measures with the less abstract classification variables, such as percent area covered, and cumulative distance travelled.",
        "published": "2021-10-01T16:16:11Z",
        "link": "http://arxiv.org/abs/2110.00506v1",
        "categories": [
            "cs.MA",
            "cs.SI"
        ]
    },
    {
        "title": "Partner-Aware Algorithms in Decentralized Cooperative Bandit Teams",
        "authors": [
            "Erdem Bıyık",
            "Anusha Lalitha",
            "Rajarshi Saha",
            "Andrea Goldsmith",
            "Dorsa Sadigh"
        ],
        "summary": "When humans collaborate with each other, they often make decisions by observing others and considering the consequences that their actions may have on the entire team, instead of greedily doing what is best for just themselves. We would like our AI agents to effectively collaborate in a similar way by capturing a model of their partners. In this work, we propose and analyze a decentralized Multi-Armed Bandit (MAB) problem with coupled rewards as an abstraction of more general multi-agent collaboration. We demonstrate that na\\\"ive extensions of single-agent optimal MAB algorithms fail when applied for decentralized bandit teams. Instead, we propose a Partner-Aware strategy for joint sequential decision-making that extends the well-known single-agent Upper Confidence Bound algorithm. We analytically show that our proposed strategy achieves logarithmic regret, and provide extensive experiments involving human-AI and human-robot collaboration to validate our theoretical findings. Our results show that the proposed partner-aware strategy outperforms other known methods, and our human subject studies suggest humans prefer to collaborate with AI agents implementing our partner-aware strategy.",
        "published": "2021-10-02T08:17:30Z",
        "link": "http://arxiv.org/abs/2110.00751v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "cs.RO",
            "stat.ML"
        ]
    },
    {
        "title": "AB-Mapper: Attention and BicNet Based Multi-agent Path Finding for   Dynamic Crowded Environment",
        "authors": [
            "Huifeng Guan",
            "Yuan Gao",
            "Min Zhao",
            "Yong Yang",
            "Fuqin Deng",
            "Tin Lun Lam"
        ],
        "summary": "Multi-agent path finding in dynamic crowded environments is of great academic and practical value for multi-robot systems in the real world. To improve the effectiveness and efficiency of communication and learning process during path planning in dynamic crowded environments, we introduce an algorithm called Attention and BicNet based Multi-agent path planning with effective reinforcement (AB-Mapper)under the actor-critic reinforcement learning framework. In this framework, on the one hand, we utilize the BicNet with communication function in the actor-network to achieve intra team coordination. On the other hand, we propose a centralized critic network that can selectively allocate attention weights to surrounding agents. This attention mechanism allows an individual agent to automatically learn a better evaluation of actions by also considering the behaviours of its surrounding agents. Compared with the state-of-the-art method Mapper,our AB-Mapper is more effective (85.86% vs. 81.56% in terms of success rate) in solving the general path finding problems with dynamic obstacles. In addition, in crowded scenarios, our method outperforms the Mapper method by a large margin,reaching a stunning gap of more than 40% for each experiment.",
        "published": "2021-10-02T08:56:01Z",
        "link": "http://arxiv.org/abs/2110.00760v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Optimizing Urban Mobility Restrictions: a Multi-Agent System (MAS) for   SARS-CoV-2",
        "authors": [
            "Simone Azeglio",
            "Matteo Fordiani"
        ],
        "summary": "Infectious epidemics can be simulated by employing dynamical processes as interactions on network structures. Here, we introduce techniques from the Multi-Agent System (MAS) domain in order to account for individual level characterization of societal dynamics for the SARS-CoV-2 pandemic. We hypothesize that a MAS model which considers rich spatial demographics, hourly mobility data and daily contagion information from the metropolitan area of Toronto can explain significant emerging behavior. To investigate this hypothesis we designed, with our modeling framework of choice, GAMA, an accurate environment which can be tuned to reproduce mobility and healthcare data, in our case coming from TomTom's API and Toronto's Open Data. We observed that some interesting contagion phenomena are directly influenced by mobility restrictions and curfew policies. We conclude that while our model is able to reproduce non-trivial emerging properties, large-scale simulation are needed to further investigate the role of different parameters. Finally, providing such an end-to-end model can be critical for policy-makers to compare their outcomes with past strategies in order to devise better plans for future measures.",
        "published": "2021-10-03T13:55:16Z",
        "link": "http://arxiv.org/abs/2110.01006v1",
        "categories": [
            "physics.soc-ph",
            "cs.MA"
        ]
    },
    {
        "title": "Behaviour-conditioned policies for cooperative reinforcement learning   tasks",
        "authors": [
            "Antti Keurulainen",
            "Isak Westerlund",
            "Ariel Kwiatkowski",
            "Samuel Kaski",
            "Alexander Ilin"
        ],
        "summary": "The cooperation among AI systems, and between AI systems and humans is becoming increasingly important. In various real-world tasks, an agent needs to cooperate with unknown partner agent types. This requires the agent to assess the behaviour of the partner agent during a cooperative task and to adjust its own policy to support the cooperation. Deep reinforcement learning models can be trained to deliver the required functionality but are known to suffer from sample inefficiency and slow learning. However, adapting to a partner agent behaviour during the ongoing task requires ability to assess the partner agent type quickly. We suggest a method, where we synthetically produce populations of agents with different behavioural patterns together with ground truth data of their behaviour, and use this data for training a meta-learner. We additionally suggest an agent architecture, which can efficiently use the generated data and gain the meta-learning capability. When an agent is equipped with such a meta-learner, it is capable of quickly adapting to cooperation with unknown partner agent types in new situations. This method can be used to automatically form a task distribution for meta-training from emerging behaviours that arise, for example, through self-play.",
        "published": "2021-10-04T09:16:41Z",
        "link": "http://arxiv.org/abs/2110.01266v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Collective eXplainable AI: Explaining Cooperative Strategies and Agent   Contribution in Multiagent Reinforcement Learning with Shapley Values",
        "authors": [
            "Alexandre Heuillet",
            "Fabien Couthouis",
            "Natalia Díaz-Rodríguez"
        ],
        "summary": "While Explainable Artificial Intelligence (XAI) is increasingly expanding more areas of application, little has been applied to make deep Reinforcement Learning (RL) more comprehensible. As RL becomes ubiquitous and used in critical and general public applications, it is essential to develop methods that make it better understood and more interpretable. This study proposes a novel approach to explain cooperative strategies in multiagent RL using Shapley values, a game theory concept used in XAI that successfully explains the rationale behind decisions taken by Machine Learning algorithms. Through testing common assumptions of this technique in two cooperation-centered socially challenging multi-agent environments environments, this article argues that Shapley values are a pertinent way to evaluate the contribution of players in a cooperative multi-agent RL context. To palliate the high overhead of this method, Shapley values are approximated using Monte Carlo sampling. Experimental results on Multiagent Particle and Sequential Social Dilemmas show that Shapley values succeed at estimating the contribution of each agent. These results could have implications that go beyond games in economics, (e.g., for non-discriminatory decision making, ethical and responsible AI-derived decisions or policy making under fairness constraints). They also expose how Shapley values only give general explanations about a model and cannot explain a single run, episode nor justify precise actions taken by agents. Future work should focus on addressing these critical aspects.",
        "published": "2021-10-04T10:28:57Z",
        "link": "http://arxiv.org/abs/2110.01307v1",
        "categories": [
            "cs.AI",
            "cs.GT",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Stochastic Multiplicative Weights Updates in Zero-Sum Games",
        "authors": [
            "James P. Bailey",
            "Sai Ganesh Nagarajan",
            "Georgios Piliouras"
        ],
        "summary": "We study agents competing against each other in a repeated network zero-sum game while applying the multiplicative weights update (MWU) algorithm with fixed learning rates. In our implementation, agents select their strategies probabilistically in each iteration and update their weights/strategies using the realized vector payoff of all strategies, i.e., stochastic MWU with full information. We show that the system results in an irreducible Markov chain where agent strategies diverge from the set of Nash equilibria. Further, we show that agents will play pure strategies with probability 1 in the limit.",
        "published": "2021-10-05T16:05:07Z",
        "link": "http://arxiv.org/abs/2110.02134v1",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Influencing Towards Stable Multi-Agent Interactions",
        "authors": [
            "Woodrow Z. Wang",
            "Andy Shih",
            "Annie Xie",
            "Dorsa Sadigh"
        ],
        "summary": "Learning in multi-agent environments is difficult due to the non-stationarity introduced by an opponent's or partner's changing behaviors. Instead of reactively adapting to the other agent's (opponent or partner) behavior, we propose an algorithm to proactively influence the other agent's strategy to stabilize -- which can restrain the non-stationarity caused by the other agent. We learn a low-dimensional latent representation of the other agent's strategy and the dynamics of how the latent strategy evolves with respect to our robot's behavior. With this learned dynamics model, we can define an unsupervised stability reward to train our robot to deliberately influence the other agent to stabilize towards a single strategy. We demonstrate the effectiveness of stabilizing in improving efficiency of maximizing the task reward in a variety of simulated environments, including autonomous driving, emergent communication, and robotic manipulation. We show qualitative results on our website: https://sites.google.com/view/stable-marl/.",
        "published": "2021-10-05T16:46:04Z",
        "link": "http://arxiv.org/abs/2110.08229v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Decentralized Cooperative Lane Changing at Freeway Weaving Areas Using   Multi-Agent Deep Reinforcement Learning",
        "authors": [
            "Yi Hou",
            "Peter Graf"
        ],
        "summary": "Frequent lane changes during congestion at freeway bottlenecks such as merge and weaving areas further reduce roadway capacity. The emergence of deep reinforcement learning (RL) and connected and automated vehicle technology provides a possible solution to improve mobility and energy efficiency at freeway bottlenecks through cooperative lane changing. Deep RL is a collection of machine-learning methods that enables an agent to improve its performance by learning from the environment. In this study, a decentralized cooperative lane-changing controller was developed using proximal policy optimization by adopting a multi-agent deep RL paradigm. In the decentralized control strategy, policy learning and action reward are evaluated locally, with each agent (vehicle) getting access to global state information. Multi-agent deep RL requires lower computational resources and is more scalable than single-agent deep RL, making it a powerful tool for time-sensitive applications such as cooperative lane changing. The results of this study show that cooperative lane changing enabled by multi-agent deep RL yields superior performance to human drivers in term of traffic throughput, vehicle speed, number of stops per vehicle, vehicle fuel efficiency, and emissions. The trained RL policy is transferable and can be generalized to uncongested, moderately congested, and extremely congested traffic conditions.",
        "published": "2021-10-05T18:29:13Z",
        "link": "http://arxiv.org/abs/2110.08124v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Robustness and sample complexity of model-based MARL for general-sum   Markov games",
        "authors": [
            "Jayakumar Subramanian",
            "Amit Sinha",
            "Aditya Mahajan"
        ],
        "summary": "Multi-agent reinforcement learning (MARL) is often modeled using the framework of Markov games (also called stochastic games or dynamic games). Most of the existing literature on MARL concentrates on zero-sum Markov games but is not applicable to general-sum Markov games. It is known that the best-response dynamics in general-sum Markov games are not a contraction. Therefore, different equilibria in general-sum Markov games can have different values. Moreover, the Q-function is not sufficient to completely characterize the equilibrium. Given these challenges, model based learning is an attractive approach for MARL in general-sum Markov games.   In this paper, we investigate the fundamental question of \\emph{sample complexity} for model-based MARL algorithms in general-sum Markov games. We show two results. We first use Hoeffding inequality based bounds to show that $\\tilde{\\mathcal{O}}( (1-\\gamma)^{-4} \\alpha^{-2})$ samples per state-action pair are sufficient to obtain a $\\alpha$-approximate Markov perfect equilibrium with high probability, where $\\gamma$ is the discount factor, and the $\\tilde{\\mathcal{O}}(\\cdot)$ notation hides logarithmic terms. We then use Bernstein inequality based bounds to show that $\\tilde{\\mathcal{O}}( (1-\\gamma)^{-1} \\alpha^{-2} )$ samples are sufficient. To obtain these results, we study the robustness of Markov perfect equilibrium to model approximations. We show that the Markov perfect equilibrium of an approximate (or perturbed) game is always an approximate Markov perfect equilibrium of the original game and provide explicit bounds on the approximation error. We illustrate the results via a numerical example.",
        "published": "2021-10-05T20:50:21Z",
        "link": "http://arxiv.org/abs/2110.02355v2",
        "categories": [
            "cs.GT",
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "math.OC"
        ]
    },
    {
        "title": "$O\\left(1/T\\right)$ Time-Average Convergence in a Generalization of   Multiagent Zero-Sum Games",
        "authors": [
            "James P. Bailey"
        ],
        "summary": "We introduce a generalization of zero-sum network multiagent matrix games and prove that alternating gradient descent converges to the set of Nash equilibria at rate $O(1/T)$ for this set of games. Alternating gradient descent obtains this convergence guarantee while using fixed learning rates that are four times larger than the optimistic variant of gradient descent. Experimentally, we show with 97.5% confidence that, on average, these larger learning rates result in time-averaged strategies that are 2.585 times closer to the set of Nash equilibria than optimistic gradient descent.",
        "published": "2021-10-06T03:29:21Z",
        "link": "http://arxiv.org/abs/2110.02482v1",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Cooperative Multi-Agent Actor-Critic for Privacy-Preserving Load   Scheduling in a Residential Microgrid",
        "authors": [
            "Zhaoming Qin",
            "Nanqing Dong",
            "Eric P. Xing",
            "Junwei Cao"
        ],
        "summary": "As a scalable data-driven approach, multi-agent reinforcement learning (MARL) has made remarkable advances in solving the cooperative residential load scheduling problems. However, the common centralized training strategy of MARL algorithms raises privacy risks for involved households. In this work, we propose a privacy-preserving multi-agent actor-critic framework where the decentralized actors are trained with distributed critics, such that both the decentralized execution and the distributed training do not require the global state information. The proposed framework can preserve the privacy of the households while simultaneously learn the multi-agent credit assignment mechanism implicitly. The simulation experiments demonstrate that the proposed framework significantly outperforms the existing privacy-preserving actor-critic framework, and can achieve comparable performance to the state-of-the-art actor-critic framework without privacy constraints.",
        "published": "2021-10-06T14:05:26Z",
        "link": "http://arxiv.org/abs/2110.02784v1",
        "categories": [
            "cs.MA",
            "cs.CR",
            "cs.LG"
        ]
    },
    {
        "title": "Multi-Agent Constrained Policy Optimisation",
        "authors": [
            "Shangding Gu",
            "Jakub Grudzien Kuba",
            "Munning Wen",
            "Ruiqing Chen",
            "Ziyan Wang",
            "Zheng Tian",
            "Jun Wang",
            "Alois Knoll",
            "Yaodong Yang"
        ],
        "summary": "Developing reinforcement learning algorithms that satisfy safety constraints is becoming increasingly important in real-world applications. In multi-agent reinforcement learning (MARL) settings, policy optimisation with safety awareness is particularly challenging because each individual agent has to not only meet its own safety constraints, but also consider those of others so that their joint behaviour can be guaranteed safe. Despite its importance, the problem of safe multi-agent learning has not been rigorously studied; very few solutions have been proposed, nor a sharable testing environment or benchmarks. To fill these gaps, in this work, we formulate the safe MARL problem as a constrained Markov game and solve it with policy optimisation methods. Our solutions -- Multi-Agent Constrained Policy Optimisation (MACPO) and MAPPO-Lagrangian -- leverage the theories from both constrained policy optimisation and multi-agent trust region learning. Crucially, our methods enjoy theoretical guarantees of both monotonic improvement in reward and satisfaction of safety constraints at every iteration. To examine the effectiveness of our methods, we develop the benchmark suite of Safe Multi-Agent MuJoCo that involves a variety of MARL baselines. Experimental results justify that MACPO/MAPPO-Lagrangian can consistently satisfy safety constraints, meanwhile achieving comparable performance to strong baselines.",
        "published": "2021-10-06T14:17:09Z",
        "link": "http://arxiv.org/abs/2110.02793v2",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "No-Press Diplomacy from Scratch",
        "authors": [
            "Anton Bakhtin",
            "David Wu",
            "Adam Lerer",
            "Noam Brown"
        ],
        "summary": "Prior AI successes in complex games have largely focused on settings with at most hundreds of actions at each decision point. In contrast, Diplomacy is a game with more than 10^20 possible actions per turn. Previous attempts to address games with large branching factors, such as Diplomacy, StarCraft, and Dota, used human data to bootstrap the policy or used handcrafted reward shaping. In this paper, we describe an algorithm for action exploration and equilibrium approximation in games with combinatorial action spaces. This algorithm simultaneously performs value iteration while learning a policy proposal network. A double oracle step is used to explore additional actions to add to the policy proposals. At each state, the target state value and policy for the model training are computed via an equilibrium search procedure. Using this algorithm, we train an agent, DORA, completely from scratch for a popular two-player variant of Diplomacy and show that it achieves superhuman performance. Additionally, we extend our methods to full-scale no-press Diplomacy and for the first time train an agent from scratch with no human data. We present evidence that this agent plays a strategy that is incompatible with human-data bootstrapped agents. This presents the first strong evidence of multiple equilibria in Diplomacy and suggests that self play alone may be insufficient for achieving superhuman performance in Diplomacy.",
        "published": "2021-10-06T17:12:50Z",
        "link": "http://arxiv.org/abs/2110.02924v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Two-Bit Aggregation for Communication Efficient and Differentially   Private Federated Learning",
        "authors": [
            "Mohammad Aghapour",
            "Aidin Ferdowsi",
            "Walid Saad"
        ],
        "summary": "In federated learning (FL), a machine learning model is trained on multiple nodes in a decentralized manner, while keeping the data local and not shared with other nodes. However, FL requires the nodes to also send information on the model parameters to a central server for aggregation. However, the information sent from the nodes to the server may reveal some details about each node's local data, thus raising privacy concerns. Furthermore, the repetitive uplink transmission from the nodes to the server may result in a communication overhead and network congestion. To address these two challenges, in this paper, a novel two-bit aggregation algorithm is proposed with guaranteed differential privacy and reduced uplink communication overhead. Extensive experiments demonstrate that the proposed aggregation algorithm can achieve the same performance as state-of-the-art approaches on datasets such as MNIST, Fashion MNIST, CIFAR-10, and CIFAR-100, while ensuring differential privacy and improving communication efficiency.",
        "published": "2021-10-06T19:03:58Z",
        "link": "http://arxiv.org/abs/2110.03017v1",
        "categories": [
            "cs.LG",
            "cs.CR",
            "cs.DC",
            "cs.MA"
        ]
    },
    {
        "title": "Online Markov Decision Processes with Non-oblivious Strategic Adversary",
        "authors": [
            "Le Cong Dinh",
            "David Henry Mguni",
            "Long Tran-Thanh",
            "Jun Wang",
            "Yaodong Yang"
        ],
        "summary": "We study a novel setting in Online Markov Decision Processes (OMDPs) where the loss function is chosen by a non-oblivious strategic adversary who follows a no-external regret algorithm. In this setting, we first demonstrate that MDP-Expert, an existing algorithm that works well with oblivious adversaries can still apply and achieve a policy regret bound of $\\mathcal{O}(\\sqrt{T \\log(L)}+\\tau^2\\sqrt{ T \\log(|A|)})$ where $L$ is the size of adversary's pure strategy set and $|A|$ denotes the size of agent's action space. Considering real-world games where the support size of a NE is small, we further propose a new algorithm: MDP-Online Oracle Expert (MDP-OOE), that achieves a policy regret bound of $\\mathcal{O}(\\sqrt{T\\log(L)}+\\tau^2\\sqrt{ T k \\log(k)})$ where $k$ depends only on the support size of the NE. MDP-OOE leverages the key benefit of Double Oracle in game theory and thus can solve games with prohibitively large action space. Finally, to better understand the learning dynamics of no-regret methods, under the same setting of no-external regret adversary in OMDPs, we introduce an algorithm that achieves last-round convergence result to a NE. To our best knowledge, this is first work leading to the last iteration result in OMDPs.",
        "published": "2021-10-07T16:32:37Z",
        "link": "http://arxiv.org/abs/2110.03604v3",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "School Virus Infection Simulator for Customizing School Schedules During   COVID-19",
        "authors": [
            "Satoshi Takahashi",
            "Masaki Kitazawa",
            "Atsushi Yoshikawa"
        ],
        "summary": "During the Coronavirus 2019 (the covid-19) pandemic, schools continuously strive to provide consistent education to their students. Teachers and education policymakers are seeking ways to re-open schools, as it is necessary for community and economic development. However, in light of the pandemic, schools require customized schedules that can address the health concerns and safety of the students considering classroom sizes, air conditioning equipment, classroom systems, e.g., self-contained or compartmentalized. To solve this issue, we developed the School-Virus-Infection-Simulator (SVIS) for teachers and education policymakers. SVIS simulates the spread of infection at a school considering the students' lesson schedules, classroom volume, air circulation rates in classrooms, and infectability of the students. Thus, teachers and education policymakers can simulate how their school schedules can impact current health concerns. We then demonstrate the impact of several school schedules in self-contained and departmentalized classrooms and evaluate them in terms of the maximum number of students infected simultaneously and the percentage of face-to-face lessons. The results show that increasing classroom ventilation rate is effective, however, the impact is not stable compared to customizing school schedules, in addition, school schedules can differently impact the maximum number of students infected depending on whether classrooms are self-contained or compartmentalized. It was found that one of school schedules had a higher maximum number of students infected, compared to schedules with a higher percentage of face-to-face lessons. SVIS and the simulation results can help teachers and education policymakers plan school schedules appropriately in order to reduce the maximum number of students infected, while also maintaining a certain percentage of face-to-face lessons.",
        "published": "2021-10-07T16:49:27Z",
        "link": "http://arxiv.org/abs/2110.03615v2",
        "categories": [
            "cs.MA",
            "cs.CY"
        ]
    },
    {
        "title": "Nash Convergence of Mean-Based Learning Algorithms in First Price   Auctions",
        "authors": [
            "Xiaotie Deng",
            "Xinyan Hu",
            "Tao Lin",
            "Weiqiang Zheng"
        ],
        "summary": "Understanding the convergence properties of learning dynamics in repeated auctions is a timely and important question in the area of learning in auctions, with numerous applications in, e.g., online advertising markets. This work focuses on repeated first price auctions where bidders with fixed values for the item learn to bid using mean-based algorithms -- a large class of online learning algorithms that include popular no-regret algorithms such as Multiplicative Weights Update and Follow the Perturbed Leader. We completely characterize the learning dynamics of mean-based algorithms, in terms of convergence to a Nash equilibrium of the auction, in two senses: (1) time-average: the fraction of rounds where bidders play a Nash equilibrium approaches 1 in the limit; (2)last-iterate: the mixed strategy profile of bidders approaches a Nash equilibrium in the limit. Specifically, the results depend on the number of bidders with the highest value: - If the number is at least three, the bidding dynamics almost surely converges to a Nash equilibrium of the auction, both in time-average and in last-iterate. - If the number is two, the bidding dynamics almost surely converges to a Nash equilibrium in time-average but not necessarily in last-iterate. - If the number is one, the bidding dynamics may not converge to a Nash equilibrium in time-average nor in last-iterate. Our discovery opens up new possibilities in the study of convergence dynamics of learning algorithms.",
        "published": "2021-10-08T06:01:27Z",
        "link": "http://arxiv.org/abs/2110.03906v4",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "econ.TH"
        ]
    },
    {
        "title": "Computing an Optimal Pitching Strategy in a Baseball At-Bat",
        "authors": [
            "Connor Douglas",
            "Everett Witt",
            "Mia Bendy",
            "Yevgeniy Vorobeychik"
        ],
        "summary": "The field of quantitative analytics has transformed the world of sports over the last decade. To date, these analytic approaches are statistical at their core, characterizing what is and what was, while using this information to drive decisions about what to do in the future. However, as we often view team sports, such as soccer, hockey, and baseball, as pairwise win-lose encounters, it seems natural to model these as zero-sum games. We propose such a model for one important class of sports encounters: a baseball at-bat, which is a matchup between a pitcher and a batter. Specifically, we propose a novel model of this encounter as a zero-sum stochastic game, in which the goal of the batter is to get on base, an outcome the pitcher aims to prevent. The value of this game is the on-base percentage (i.e., the probability that the batter gets on base). In principle, this stochastic game can be solved using classical approaches. The main technical challenges lie in predicting the distribution of pitch locations as a function of pitcher intention, predicting the distribution of outcomes if the batter decides to swing at a pitch, and characterizing the level of patience of a particular batter. We address these challenges by proposing novel pitcher and batter representations as well as a novel deep neural network architecture for outcome prediction. Our experiments using Kaggle data from the 2015 to 2018 Major League Baseball seasons demonstrate the efficacy of the proposed approach.",
        "published": "2021-10-08T18:09:08Z",
        "link": "http://arxiv.org/abs/2110.04321v1",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Analyzing the performance of distributed conflict resolution among   autonomous vehicles",
        "authors": [
            "Ítalo Romani de Oliveira"
        ],
        "summary": "This paper presents a study on how cooperation versus non-cooperation, and centralization versus distribution impact the performance of a traffic game of autonomous vehicles. A model using a particle-based, Lagrange representation, is developed, instead of a Eulerian, flow-based one, usual in routing problems of the game-theoretical approach. This choice allows representation of phenomena such as fuel exhaustion, vehicle collision, and wave propagation. The elements necessary to represent interactions in a multi-agent transportation system are defined, including a distributed, priority-based resource allocation protocol, where resources are nodes and links in a spatial network and individual routing strategies are performed. A fuel consumption dynamics is developed in order to account for energy cost and vehicles having limited range. The analysis shows that only the scenarios with cooperative resource allocation can achieve optimal values of either collective cost or equity coefficient, corresponding respectively to the centralized and to the distributed cases.",
        "published": "2021-10-08T19:51:52Z",
        "link": "http://arxiv.org/abs/2110.08127v1",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "DeepABM: Scalable, efficient and differentiable agent-based simulations   via graph neural networks",
        "authors": [
            "Ayush Chopra",
            "Esma Gel",
            "Jayakumar Subramanian",
            "Balaji Krishnamurthy",
            "Santiago Romero-Brufau",
            "Kalyan S. Pasupathy",
            "Thomas C. Kingsley",
            "Ramesh Raskar"
        ],
        "summary": "We introduce DeepABM, a framework for agent-based modeling that leverages geometric message passing of graph neural networks for simulating action and interactions over large agent populations. Using DeepABM allows scaling simulations to large agent populations in real-time and running them efficiently on GPU architectures. To demonstrate the effectiveness of DeepABM, we build DeepABM-COVID simulator to provide support for various non-pharmaceutical interventions (quarantine, exposure notification, vaccination, testing) for the COVID-19 pandemic, and can scale to populations of representative size in real-time on a GPU. Specifically, DeepABM-COVID can model 200 million interactions (over 100,000 agents across 180 time-steps) in 90 seconds, and is made available online to help researchers with modeling and analysis of various interventions. We explain various components of the framework and discuss results from one research study to evaluate the impact of delaying the second dose of the COVID-19 vaccine in collaboration with clinical and public health experts. While we simulate COVID-19 spread, the ideas introduced in the paper are generic and can be easily extend to other forms of agent-based simulations. Furthermore, while beyond scope of this document, DeepABM enables inverse agent-based simulations which can be used to learn physical parameters in the (micro) simulations using gradient-based optimization with large-scale real-world (macro) data. We are optimistic that the current work can have interesting implications for bringing ABM and AI communities closer.",
        "published": "2021-10-09T00:46:13Z",
        "link": "http://arxiv.org/abs/2110.04421v1",
        "categories": [
            "cs.MA",
            "cs.LG"
        ]
    },
    {
        "title": "Multi-Agent MDP Homomorphic Networks",
        "authors": [
            "Elise van der Pol",
            "Herke van Hoof",
            "Frans A. Oliehoek",
            "Max Welling"
        ],
        "summary": "This paper introduces Multi-Agent MDP Homomorphic Networks, a class of networks that allows distributed execution using only local information, yet is able to share experience between global symmetries in the joint state-action space of cooperative multi-agent systems. In cooperative multi-agent systems, complex symmetries arise between different configurations of the agents and their local observations. For example, consider a group of agents navigating: rotating the state globally results in a permutation of the optimal joint policy. Existing work on symmetries in single agent reinforcement learning can only be generalized to the fully centralized setting, because such approaches rely on the global symmetry in the full state-action spaces, and these can result in correspondences across agents. To encode such symmetries while still allowing distributed execution we propose a factorization that decomposes global symmetries into local transformations. Our proposed factorization allows for distributing the computation that enforces global symmetries over local agents and local interactions. We introduce a multi-agent equivariant policy network based on this factorization. We show empirically on symmetric multi-agent problems that globally symmetric distributable policies improve data efficiency compared to non-equivariant baselines.",
        "published": "2021-10-09T07:46:25Z",
        "link": "http://arxiv.org/abs/2110.04495v2",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Transaction Fees on a Honeymoon: Ethereum's EIP-1559 One Month Later",
        "authors": [
            "Daniël Reijsbergen",
            "Shyam Sridhar",
            "Barnabé Monnot",
            "Stefanos Leonardos",
            "Stratis Skoulakis",
            "Georgios Piliouras"
        ],
        "summary": "Ethereum Improvement Proposal (EIP) 1559 was recently implemented to transform Ethereum's transaction fee market. EIP-1559 utilizes an algorithmic update rule with a constant learning rate to estimate a base fee. The base fee reflects prevailing network conditions and hence provides a more reliable oracle for current gas prices.   Using on-chain data from the period after its launch, we evaluate the impact of EIP-1559 on the user experience and market performance. Our empirical findings suggest that although EIP-1559 achieves its goals on average, short-term behavior is marked by intense, chaotic oscillations in block sizes (as predicted by our recent theoretical dynamical system analysis [1]) and slow adjustments during periods of demand bursts (e.g., NFT drops). Both phenomena lead to unwanted inter-block variability in mining rewards. To address this issue, we propose an alternative base fee adjustment rule in which the learning rate varies according to an additive increase, multiplicative decrease (AIMD) update scheme. Our simulations show that the latter robustly outperforms the EIP-1559 protocol under various demand scenarios. These results provide evidence that variable learning rate mechanisms may constitute a promising alternative to the default EIP-1559-based format and contribute to the ongoing discussion on the design of more efficient transaction fee markets.",
        "published": "2021-10-10T10:17:07Z",
        "link": "http://arxiv.org/abs/2110.04753v3",
        "categories": [
            "cs.GT",
            "cs.MA",
            "cs.SI",
            "math.DS",
            "91A80, 91-10, 91B26"
        ]
    },
    {
        "title": "Achieving safe minimum circle circumnavigation around multiple targets:   a dynamic compensation approach",
        "authors": [
            "Chao Wang",
            "Yingjing Shi",
            "Rui Li",
            "Yongduan Song"
        ],
        "summary": "Minimum circle circumnavigation is proposed in this paper, which is of special value in target monitoring, capturing and/or attacking. In this paper, a safe minimum circle circumnavigation of multiple targets based on bearing measurements is studied. In contrast with the traditional circumnavigation problem, with the new pattern, one agent is able to enclose multiple targets along a minimum circle with the desired enclosing distance and tangential speed. To achieve the minimum circle circumnavigation, an algorithm including dynamic compensators and a control protocol is proposed, by which collision is avoided between the agent and the multiple targets during the whole moving process. Moreover, the control protocol developed for a single agent is further extended to the scenarios of multiple agents by adding a coordination mechanism into the tangential velocity term, which drives the agents to distribute evenly on each expected circular orbit with the same radius or different radius. Simulations results illustrate the effectiveness of the proposed methods.",
        "published": "2021-10-11T09:13:06Z",
        "link": "http://arxiv.org/abs/2110.05103v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Decentralized sliding-mode control laws for the bearing-based formation   tracking problem",
        "authors": [
            "Dung Van Vu",
            "Minh Hoang Trinh"
        ],
        "summary": "This paper studies the time-varying bearing-based tracking of leader-follower formations. The desired constraints between agents are specified by bearing vectors, and several leaders are moving with a bounded reference velocity. Each followers can measure the relative positions of its neighbors, its own velocities, and receive information from their neighbors. Under the assumptions that the desired formation is infinitesimally bearing rigid and the local reference frames of followers are aligned with each other, two control laws are presented in this paper based on sliding mode control approach. Stability analyses are given based on Lyapunov stability theory and supported by numerical simulations.",
        "published": "2021-10-11T11:00:56Z",
        "link": "http://arxiv.org/abs/2110.05153v1",
        "categories": [
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "Dynamic Median Consensus Over Random Networks",
        "authors": [
            "Shuhua Yu",
            "Yuan Chen",
            "Soummya Kar"
        ],
        "summary": "This paper studies the problem of finding the median of N distinct numbers distributed across networked agents. Each agent updates its estimate for the median from noisy local observations of one of the N numbers and information from neighbors. We consider an undirected random network that is connected on average, and a noisy observation sequence that has finite variance and almost surely decaying bias. We present a consensus+innovations algorithm with clipped innovations. Under some regularity assumptions on the network and observation model, we show that each agent's local estimate converges to the set of median(s) almost surely at an asymptotic sublinear rate. Numerical experiments demonstrate the effectiveness of the presented algorithm.",
        "published": "2021-10-11T14:38:20Z",
        "link": "http://arxiv.org/abs/2110.05317v1",
        "categories": [
            "math.OC",
            "cs.MA"
        ]
    },
    {
        "title": "Calibrate your listeners! Robust communication-based training for   pragmatic speakers",
        "authors": [
            "Rose E. Wang",
            "Julia White",
            "Jesse Mu",
            "Noah D. Goodman"
        ],
        "summary": "To be good conversational partners, natural language processing (NLP) systems should be trained to produce contextually useful utterances. Prior work has investigated training NLP systems with communication-based objectives, where a neural listener stands in as a communication partner. However, these systems commonly suffer from semantic drift where the learned language diverges radically from natural language. We propose a method that uses a population of neural listeners to regularize speaker training. We first show that language drift originates from the poor uncertainty calibration of a neural listener, which makes high-certainty predictions on novel sentences. We explore ensemble- and dropout-based populations of listeners and find that the former results in better uncertainty quantification. We evaluate both population-based objectives on reference games, and show that the ensemble method with better calibration enables the speaker to generate pragmatic utterances while scaling to a large vocabulary and generalizing to new games and listeners.",
        "published": "2021-10-11T17:07:38Z",
        "link": "http://arxiv.org/abs/2110.05422v1",
        "categories": [
            "cs.CL",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Learning to Coordinate in Multi-Agent Systems: A Coordinated   Actor-Critic Algorithm and Finite-Time Guarantees",
        "authors": [
            "Siliang Zeng",
            "Tianyi Chen",
            "Alfredo Garcia",
            "Mingyi Hong"
        ],
        "summary": "Multi-agent reinforcement learning (MARL) has attracted much research attention recently. However, unlike its single-agent counterpart, many theoretical and algorithmic aspects of MARL have not been well-understood. In this paper, we study the emergence of coordinated behavior by autonomous agents using an actor-critic (AC) algorithm. Specifically, we propose and analyze a class of coordinated actor-critic algorithms (CAC) in which individually parametrized policies have a {\\it shared} part (which is jointly optimized among all agents) and a {\\it personalized} part (which is only locally optimized). Such kind of {\\it partially personalized} policy allows agents to learn to coordinate by leveraging peers' past experience and adapt to individual tasks. The flexibility in our design allows the proposed MARL-CAC algorithm to be used in a {\\it fully decentralized} setting, where the agents can only communicate with their neighbors, as well as a {\\it federated} setting, where the agents occasionally communicate with a server while optimizing their (partially personalized) local models. Theoretically, we show that under some standard regularity assumptions, the proposed MARL-CAC algorithm requires $\\mathcal{O}(\\epsilon^{-\\frac{5}{2}})$ samples to achieve an $\\epsilon$-stationary solution (defined as the solution whose squared norm of the gradient of the objective function is less than $\\epsilon$). To the best of our knowledge, this work provides the first finite-sample guarantee for decentralized AC algorithm with partially personalized policies.",
        "published": "2021-10-11T20:26:16Z",
        "link": "http://arxiv.org/abs/2110.05597v2",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Provably Efficient Reinforcement Learning in Decentralized General-Sum   Markov Games",
        "authors": [
            "Weichao Mao",
            "Tamer Başar"
        ],
        "summary": "This paper addresses the problem of learning an equilibrium efficiently in general-sum Markov games through decentralized multi-agent reinforcement learning. Given the fundamental difficulty of calculating a Nash equilibrium (NE), we instead aim at finding a coarse correlated equilibrium (CCE), a solution concept that generalizes NE by allowing possible correlations among the agents' strategies. We propose an algorithm in which each agent independently runs optimistic V-learning (a variant of Q-learning) to efficiently explore the unknown environment, while using a stabilized online mirror descent (OMD) subroutine for policy updates. We show that the agents can find an $\\epsilon$-approximate CCE in at most $\\widetilde{O}( H^6S A /\\epsilon^2)$ episodes, where $S$ is the number of states, $A$ is the size of the largest individual action space, and $H$ is the length of an episode. This appears to be the first sample complexity result for learning in generic general-sum Markov games. Our results rely on a novel investigation of an anytime high-probability regret bound for OMD with a dynamic learning rate and weighted regret, which would be of independent interest. One key feature of our algorithm is that it is fully \\emph{decentralized}, in the sense that each agent has access to only its local information, and is completely oblivious to the presence of others. This way, our algorithm can readily scale up to an arbitrary number of agents, without suffering from the exponential dependence on the number of agents.",
        "published": "2021-10-12T02:01:22Z",
        "link": "http://arxiv.org/abs/2110.05682v3",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "On Improving Model-Free Algorithms for Decentralized Multi-Agent   Reinforcement Learning",
        "authors": [
            "Weichao Mao",
            "Lin F. Yang",
            "Kaiqing Zhang",
            "Tamer Başar"
        ],
        "summary": "Multi-agent reinforcement learning (MARL) algorithms often suffer from an exponential sample complexity dependence on the number of agents, a phenomenon known as \\emph{the curse of multiagents}. In this paper, we address this challenge by investigating sample-efficient model-free algorithms in \\emph{decentralized} MARL, and aim to improve existing algorithms along this line. For learning (coarse) correlated equilibria in general-sum Markov games, we propose \\emph{stage-based} V-learning algorithms that significantly simplify the algorithmic design and analysis of recent works, and circumvent a rather complicated no-\\emph{weighted}-regret bandit subroutine. For learning Nash equilibria in Markov potential games, we propose an independent policy gradient algorithm with a decentralized momentum-based variance reduction technique. All our algorithms are decentralized in that each agent can make decisions based on only its local information. Neither communication nor centralized coordination is required during learning, leading to a natural generalization to a large number of agents. We also provide numerical simulations to corroborate our theoretical findings.",
        "published": "2021-10-12T02:45:12Z",
        "link": "http://arxiv.org/abs/2110.05707v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Learning Efficient Multi-Agent Cooperative Visual Exploration",
        "authors": [
            "Chao Yu",
            "Xinyi Yang",
            "Jiaxuan Gao",
            "Huazhong Yang",
            "Yu Wang",
            "Yi Wu"
        ],
        "summary": "We tackle the problem of cooperative visual exploration where multiple agents need to jointly explore unseen regions as fast as possible based on visual signals. Classical planning-based methods often suffer from expensive computation overhead at each step and a limited expressiveness of complex cooperation strategy. By contrast, reinforcement learning (RL) has recently become a popular paradigm for tackling this challenge due to its modeling capability of arbitrarily complex strategies and minimal inference overhead. In this paper, we extend the state-of-the-art single-agent visual navigation method, Active Neural SLAM (ANS), to the multi-agent setting by introducing a novel RL-based planning module, Multi-agent Spatial Planner (MSP).MSP leverages a transformer-based architecture, Spatial-TeamFormer, which effectively captures spatial relations and intra-agent interactions via hierarchical spatial self-attentions. In addition, we also implement a few multi-agent enhancements to process local information from each agent for an aligned spatial representation and more precise planning. Finally, we perform policy distillation to extract a meta policy to significantly improve the generalization capability of final policy. We call this overall solution, Multi-Agent Active Neural SLAM (MAANS). MAANS substantially outperforms classical planning-based baselines for the first time in a photo-realistic 3D simulator, Habitat. Code and videos can be found at https://sites.google.com/view/maans.",
        "published": "2021-10-12T04:48:10Z",
        "link": "http://arxiv.org/abs/2110.05734v3",
        "categories": [
            "cs.CV",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Interpretation of Emergent Communication in Heterogeneous Collaborative   Embodied Agents",
        "authors": [
            "Shivansh Patel",
            "Saim Wani",
            "Unnat Jain",
            "Alexander Schwing",
            "Svetlana Lazebnik",
            "Manolis Savva",
            "Angel X. Chang"
        ],
        "summary": "Communication between embodied AI agents has received increasing attention in recent years. Despite its use, it is still unclear whether the learned communication is interpretable and grounded in perception. To study the grounding of emergent forms of communication, we first introduce the collaborative multi-object navigation task CoMON. In this task, an oracle agent has detailed environment information in the form of a map. It communicates with a navigator agent that perceives the environment visually and is tasked to find a sequence of goals. To succeed at the task, effective communication is essential. CoMON hence serves as a basis to study different communication mechanisms between heterogeneous agents, that is, agents with different capabilities and roles. We study two common communication mechanisms and analyze their communication patterns through an egocentric and spatial lens. We show that the emergent communication can be grounded to the agent observations and the spatial structure of the 3D environment. Video summary: https://youtu.be/kLv2rxO9t0g",
        "published": "2021-10-12T06:56:11Z",
        "link": "http://arxiv.org/abs/2110.05769v1",
        "categories": [
            "cs.CV",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Directionality Reinforcement Learning to Operate Multi-Agent System   without Communication",
        "authors": [
            "Fumito Uwano",
            "Keiki Takadama"
        ],
        "summary": "This paper establishes directionality reinforcement learning (DRL) technique to propose the complete decentralized multi-agent reinforcement learning method which can achieve cooperation based on each agent's learning: no communication and no observation. Concretely, DRL adds the direction \"agents have to learn to reach the farthest goal among reachable ones\" to learning agents to operate the agents cooperatively. Furthermore, to investigate the effectiveness of the DRL, this paper compare Q-learning agent with DRL with previous learning agent in maze problems. Experimental results derive that (1) DRL performs better than the previous method in terms of the spending time, (2) the direction makes agents learn yielding action for others, and (3) DRL suggests achieving multiagent learning with few costs for any number of agents.",
        "published": "2021-10-12T07:05:56Z",
        "link": "http://arxiv.org/abs/2110.05773v1",
        "categories": [
            "cs.MA",
            "68T42",
            "I.2; I.2.11"
        ]
    },
    {
        "title": "Decentralized Connectivity Maintenance for Multi-robot Systems Under   Motion and Sensing Uncertainties",
        "authors": [
            "Akshay Shetty",
            "Timmy Hussain",
            "Grace Gao"
        ],
        "summary": "Communication connectivity is desirable for safe and efficient operation of multi-robot systems. While decentralized algorithms for connectivity maintenance have been explored in recent literature, the majority of these works do not account for robot motion and sensing uncertainties. These uncertainties are inherent in practical robots and result in robots deviating from their desired positions which could potentially result in a loss of connectivity. In this paper we present a Decentralized Connectivity Maintenance algorithm accounting for robot motion and sensing Uncertainties (DCMU). We first propose a novel weighted graph definition for the multi-robot system that accounts for the aforementioned uncertainties along with realistic connectivity constraints such as line-of-sight connectivity and collision avoidance. Next we design a decentralized gradient-based controller for connectivity maintenance where we derive the gradients of our weighted graph edge weights required for computing the control. Finally, we perform multiple simulations to validate the connectivity maintenance performance of our DCMU algorithm under robot motion and sensing uncertainties and show an improvement compared to previous work.",
        "published": "2021-10-12T20:40:33Z",
        "link": "http://arxiv.org/abs/2110.06342v2",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "GridLearn: Multiagent Reinforcement Learning for Grid-Aware Building   Energy Management",
        "authors": [
            "Aisling Pigott",
            "Constance Crozier",
            "Kyri Baker",
            "Zoltan Nagy"
        ],
        "summary": "Increasing amounts of distributed generation in distribution networks can provide both challenges and opportunities for voltage regulation across the network. Intelligent control of smart inverters and other smart building energy management systems can be leveraged to alleviate these issues. GridLearn is a multiagent reinforcement learning platform that incorporates both building energy models and power flow models to achieve grid level goals, by controlling behind-the-meter resources. This study demonstrates how multi-agent reinforcement learning can preserve building owner privacy and comfort while pursuing grid-level objectives. Building upon the CityLearn framework which considers RL for building-level goals, this work expands the framework to a network setting where grid-level goals are additionally considered. As a case study, we consider voltage regulation on the IEEE-33 bus network using controllable building loads, energy storage, and smart inverters. The results show that the RL agents nominally reduce instances of undervoltages and reduce instances of overvoltages by 34%.",
        "published": "2021-10-12T23:19:29Z",
        "link": "http://arxiv.org/abs/2110.06396v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Efficient Linearizability Checking for Actor-based Systems",
        "authors": [
            "Mohammed S. Al-Mahfoudh",
            "Ryan Stutsman",
            "Ganesh Gopalakrishnan"
        ],
        "summary": "Recent demand for distributed software had led to a surge in popularity in actor-based frameworks. However, even with the stylized message passing model of actors, writing correct distributed software is still difficult. We present our work on linearizability checking in DS2, an integrated framework for specifying, synthesizing, and testing distributed actor systems. The key insight of our approach is that often subcomponents of distributed actor systems represent common algorithms or data structures (e.g.\\ a distributed hash table or tree) that can be validated against a simple sequential model of the system. This makes it easy for developers to validate their concurrent actor systems without complex specifications. DS2 automatically explores the concurrent schedules that system could arrive at, and it compares observed output of the system to ensure it is equivalent to what the sequential implementation could have produced. We describe DS2's linearizability checking and test it on several concurrent replication algorithms from the literature. We explore in detail how different algorithms for enumerating the model schedule space fare in finding bugs in actor systems, and we present our own refinements on algorithms for exploring actor system schedules that we show are effective in finding bugs.",
        "published": "2021-10-13T00:09:48Z",
        "link": "http://arxiv.org/abs/2110.06407v2",
        "categories": [
            "cs.DC",
            "cs.MA",
            "cs.SE"
        ]
    },
    {
        "title": "Towards a fully RL-based Market Simulator",
        "authors": [
            "Leo Ardon",
            "Nelson Vadori",
            "Thomas Spooner",
            "Mengda Xu",
            "Jared Vann",
            "Sumitra Ganesh"
        ],
        "summary": "We present a new financial framework where two families of RL-based agents representing the Liquidity Providers and Liquidity Takers learn simultaneously to satisfy their objective. Thanks to a parametrized reward formulation and the use of Deep RL, each group learns a shared policy able to generalize and interpolate over a wide range of behaviors. This is a step towards a fully RL-based market simulator replicating complex market conditions particularly suited to study the dynamics of the financial market under various scenarios.",
        "published": "2021-10-13T16:14:19Z",
        "link": "http://arxiv.org/abs/2110.06829v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG",
            "q-fin.TR"
        ]
    },
    {
        "title": "HAVEN: Hierarchical Cooperative Multi-Agent Reinforcement Learning with   Dual Coordination Mechanism",
        "authors": [
            "Zhiwei Xu",
            "Yunpeng Bai",
            "Bin Zhang",
            "Dapeng Li",
            "Guoliang Fan"
        ],
        "summary": "Recently, some challenging tasks in multi-agent systems have been solved by some hierarchical reinforcement learning methods. Inspired by the intra-level and inter-level coordination in the human nervous system, we propose a novel value decomposition framework HAVEN based on hierarchical reinforcement learning for fully cooperative multi-agent problems. To address the instability arising from the concurrent optimization of policies between various levels and agents, we introduce the dual coordination mechanism of inter-level and inter-agent strategies by designing reward functions in a two-level hierarchy. HAVEN does not require domain knowledge and pre-training, and can be applied to any value decomposition variant. Our method achieves desirable results on different decentralized partially observable Markov decision process domains and outperforms other popular multi-agent hierarchical reinforcement learning algorithms.",
        "published": "2021-10-14T10:43:47Z",
        "link": "http://arxiv.org/abs/2110.07246v3",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Provably Efficient Multi-Agent Reinforcement Learning with Fully   Decentralized Communication",
        "authors": [
            "Justin Lidard",
            "Udari Madhushani",
            "Naomi Ehrich Leonard"
        ],
        "summary": "A challenge in reinforcement learning (RL) is minimizing the cost of sampling associated with exploration. Distributed exploration reduces sampling complexity in multi-agent RL (MARL). We investigate the benefits to performance in MARL when exploration is fully decentralized. Specifically, we consider a class of online, episodic, tabular $Q$-learning problems under time-varying reward and transition dynamics, in which agents can communicate in a decentralized manner.We show that group performance, as measured by the bound on regret, can be significantly improved through communication when each agent uses a decentralized message-passing protocol, even when limited to sending information up to its $\\gamma$-hop neighbors. We prove regret and sample complexity bounds that depend on the number of agents, communication network structure and $\\gamma.$ We show that incorporating more agents and more information sharing into the group learning scheme speeds up convergence to the optimal policy. Numerical simulations illustrate our results and validate our theoretical claims.",
        "published": "2021-10-14T14:27:27Z",
        "link": "http://arxiv.org/abs/2110.07392v2",
        "categories": [
            "cs.LG",
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "The Neural MMO Platform for Massively Multiagent Research",
        "authors": [
            "Joseph Suarez",
            "Yilun Du",
            "Clare Zhu",
            "Igor Mordatch",
            "Phillip Isola"
        ],
        "summary": "Neural MMO is a computationally accessible research platform that combines large agent populations, long time horizons, open-ended tasks, and modular game systems. Existing environments feature subsets of these properties, but Neural MMO is the first to combine them all. We present Neural MMO as free and open source software with active support, ongoing development, documentation, and additional training, logging, and visualization tools to help users adapt to this new setting. Initial baselines on the platform demonstrate that agents trained in large populations explore more and learn a progression of skills. We raise other more difficult problems such as many-team cooperation as open research questions which Neural MMO is well-suited to answer. Finally, we discuss current limitations of the platform, potential mitigations, and plans for continued development.",
        "published": "2021-10-14T17:54:49Z",
        "link": "http://arxiv.org/abs/2110.07594v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "An Artificial Bee Colony Based Algorithm for Continuous Distributed   Constraint Optimization Problems",
        "authors": [
            "K. M. Merajul Arefin",
            "Mashrur Rashik",
            "Saaduddin Mahmud",
            "Md. Mosaddek Khan"
        ],
        "summary": "Distributed Constraint Optimization Problems (DCOPs) are a frequently used framework in which a set of independent agents choose values from their respective discrete domains to maximize their utility. Although this formulation is typically appropriate, there are a number of real-world applications in which the decision variables are continuous-valued and the constraints are represented in functional form. To address this, Continuous Distributed Constraint Optimization Problems (C-DCOPs), an extension of the DCOPs paradigm, have recently grown the interest of the multi-agent systems field. To date, among different approaches, population-based algorithms are shown to be most effective for solving C-DCOPs. Considering the potential of population-based approaches, we propose a new C-DCOPs solver inspired by a well-known population-based algorithm Artificial Bee Colony (ABC). Additionally, we provide a new exploration method that aids in the further improvement of the algorithm's solution quality. Finally, We theoretically prove that our approach is an anytime algorithm and empirically show it produces significantly better results than the state-of-the-art C-DCOPs algorithms.",
        "published": "2021-10-15T00:16:52Z",
        "link": "http://arxiv.org/abs/2110.07780v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Anomaly Detection in Multi-Agent Trajectories for Automated Driving",
        "authors": [
            "Julian Wiederer",
            "Arij Bouazizi",
            "Marco Troina",
            "Ulrich Kressel",
            "Vasileios Belagiannis"
        ],
        "summary": "Human drivers can recognise fast abnormal driving situations to avoid accidents. Similar to humans, automated vehicles are supposed to perform anomaly detection. In this work, we propose the spatio-temporal graph auto-encoder for learning normal driving behaviours. Our innovation is the ability to jointly learn multiple trajectories of a dynamic number of agents. To perform anomaly detection, we first estimate a density function of the learned trajectory feature representation and then detect anomalies in low-density regions. Due to the lack of multi-agent trajectory datasets for anomaly detection in automated driving, we introduce our dataset using a driving simulator for normal and abnormal manoeuvres. Our evaluations show that our approach learns the relation between different agents and delivers promising results compared to the related works. The code, simulation and the dataset are publicly available on https://github.com/againerju/maad_highway.",
        "published": "2021-10-15T08:07:31Z",
        "link": "http://arxiv.org/abs/2110.07922v2",
        "categories": [
            "cs.RO",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Simulation of emergence in artificial societies: a practical model-based   approach with the EB-DEVS formalism",
        "authors": [
            "Daniel Foguelman",
            "Esteban Lanzarotti",
            "Emanuel Ferreyra",
            "Rodrigo Castro"
        ],
        "summary": "Modelling and simulation of complex systems is key to exploring and understanding social processes, benefiting from formal mechanisms to derive global-level properties from local-level interactions. In this paper we extend the body of knowledge on formal methods in complex systems by applying EB-DEVS, a novel formalism tailored for the modelling, simulation and live identification of emergent properties. We guide the reader through the implementation of different classical models for varied social systems to introduce good modelling practices and showcase the advantages and limitations of modelling emergence with EB-DEVS, in particular through its live emergence detection capability. This work provides case study-driven evidence for the neatness and compactness of the approach to modelling communication structures that can be explicit or implicit, static or dynamic, with or without multilevel interactions, and with weak or strong emergent behaviour. Throughout examples we show that EB-DEVS permits conceptualising the analysed societies by incorporating emergent behaviour when required, namely by integrating as a macro-level aggregate the Gini index in the Sugarscape model, Fads and Fashion in the Dissemination of Culture model, size-biased degree distribution in a Preferential Attachment model, happiness index in the Segregation model and quarantines in the SIR epidemic model. In each example we discuss the role of communication structures in the development of multilevel simulation models, and illustrate how micro-macro feedback loops enable the modelling of macro-level properties. Our results stress the relevance of multilevel features to support a robust approach in the modelling and simulation of complex systems.",
        "published": "2021-10-15T15:55:16Z",
        "link": "http://arxiv.org/abs/2110.08170v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "nlin.AO"
        ]
    },
    {
        "title": "MLFC: From 10 to 50 Planners in the Multi-Agent Programming Contest",
        "authors": [
            "Rafael C. Cardoso",
            "Angelo Ferrando",
            "Fabio Papacchini",
            "Matt Luckcuck",
            "Sven Linker",
            "Terry R. Payne"
        ],
        "summary": "In this paper, we describe the strategies used by our team, MLFC, that led us to achieve the 2nd place in the 15th edition of the Multi-Agent Programming Contest. The scenario used in the contest is an extension of the previous edition (14th) \"Agents Assemble\" wherein two teams of agents move around a 2D grid and compete to assemble complex block structures. We discuss the languages and tools used during the development of our team. Then, we summarise the main strategies that were carried over from our previous participation in the 14th edition and list the limitations (if any) of using these strategies in the latest contest edition. We also developed new strategies that were made specifically for the extended scenario: cartography (determining the size of the map); formal verification of the map merging protocol (to provide assurances that it works when increasing the number of agents); plan cache (efficiently scaling the number of planners); task achievement (forming groups of agents to achieve tasks); and bullies (agents that focus on stopping agents from the opposing team). Finally, we give a brief overview of our performance in the contest and discuss what we believe were our shortcomings.",
        "published": "2021-10-15T15:59:08Z",
        "link": "http://arxiv.org/abs/2110.08172v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Collaborating with Humans without Human Data",
        "authors": [
            "DJ Strouse",
            "Kevin R. McKee",
            "Matt Botvinick",
            "Edward Hughes",
            "Richard Everett"
        ],
        "summary": "Collaborating with humans requires rapidly adapting to their individual strengths, weaknesses, and preferences. Unfortunately, most standard multi-agent reinforcement learning techniques, such as self-play (SP) or population play (PP), produce agents that overfit to their training partners and do not generalize well to humans. Alternatively, researchers can collect human data, train a human model using behavioral cloning, and then use that model to train \"human-aware\" agents (\"behavioral cloning play\", or BCP). While such an approach can improve the generalization of agents to new human co-players, it involves the onerous and expensive step of collecting large amounts of human data first. Here, we study the problem of how to train agents that collaborate well with human partners without using human data. We argue that the crux of the problem is to produce a diverse set of training partners. Drawing inspiration from successful multi-agent approaches in competitive domains, we find that a surprisingly simple approach is highly effective. We train our agent partner as the best response to a population of self-play agents and their past checkpoints taken throughout training, a method we call Fictitious Co-Play (FCP). Our experiments focus on a two-player collaborative cooking simulator that has recently been proposed as a challenge problem for coordination with humans. We find that FCP agents score significantly higher than SP, PP, and BCP when paired with novel agent and human partners. Furthermore, humans also report a strong subjective preference to partnering with FCP agents over all baselines.",
        "published": "2021-10-15T16:03:57Z",
        "link": "http://arxiv.org/abs/2110.08176v2",
        "categories": [
            "cs.LG",
            "cs.HC",
            "cs.MA"
        ]
    },
    {
        "title": "ToM2C: Target-oriented Multi-agent Communication and Cooperation with   Theory of Mind",
        "authors": [
            "Yuanfei Wang",
            "Fangwei Zhong",
            "Jing Xu",
            "Yizhou Wang"
        ],
        "summary": "Being able to predict the mental states of others is a key factor to effective social interaction. It is also crucial for distributed multi-agent systems, where agents are required to communicate and cooperate. In this paper, we introduce such an important social-cognitive skill, i.e. Theory of Mind (ToM), to build socially intelligent agents who are able to communicate and cooperate effectively to accomplish challenging tasks. With ToM, each agent is capable of inferring the mental states and intentions of others according to its (local) observation. Based on the inferred states, the agents decide \"when\" and with \"whom\" to share their intentions. With the information observed, inferred, and received, the agents decide their sub-goals and reach a consensus among the team. In the end, the low-level executors independently take primitive actions to accomplish the sub-goals. We demonstrate the idea in two typical target-oriented multi-agent tasks: cooperative navigation and multi-sensor target coverage. The experiments show that the proposed model not only outperforms the state-of-the-art methods on reward and communication efficiency, but also shows good generalization across different scales of the environment.",
        "published": "2021-10-15T18:29:55Z",
        "link": "http://arxiv.org/abs/2111.09189v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Local Advantage Actor-Critic for Robust Multi-Agent Deep Reinforcement   Learning",
        "authors": [
            "Yuchen Xiao",
            "Xueguang Lyu",
            "Christopher Amato"
        ],
        "summary": "Policy gradient methods have become popular in multi-agent reinforcement learning, but they suffer from high variance due to the presence of environmental stochasticity and exploring agents (i.e., non-stationarity), which is potentially worsened by the difficulty in credit assignment. As a result, there is a need for a method that is not only capable of efficiently solving the above two problems but also robust enough to solve a variety of tasks. To this end, we propose a new multi-agent policy gradient method, called Robust Local Advantage (ROLA) Actor-Critic. ROLA allows each agent to learn an individual action-value function as a local critic as well as ameliorating environment non-stationarity via a novel centralized training approach based on a centralized critic. By using this local critic, each agent calculates a baseline to reduce variance on its policy gradient estimation, which results in an expected advantage action-value over other agents' choices that implicitly improves credit assignment. We evaluate ROLA across diverse benchmarks and show its robustness and effectiveness over a number of state-of-the-art multi-agent policy gradient algorithms.",
        "published": "2021-10-16T19:03:34Z",
        "link": "http://arxiv.org/abs/2110.08642v3",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Coordinated Multi-Agent Pathfinding for Drones and Trucks over Road   Networks",
        "authors": [
            "Shushman Choudhury",
            "Kiril Solovey",
            "Mykel Kochenderfer",
            "Marco Pavone"
        ],
        "summary": "We address the problem of routing a team of drones and trucks over large-scale urban road networks. To conserve their limited flight energy, drones can use trucks as temporary modes of transit en route to their own destinations. Such coordination can yield significant savings in total vehicle distance traveled, i.e., truck travel distance and drone flight distance, compared to operating drones and trucks independently. But it comes at the potentially prohibitive computational cost of deciding which trucks and drones should coordinate and when and where it is most beneficial to do so. We tackle this fundamental trade-off by decoupling our overall intractable problem into tractable sub-problems that we solve stage-wise. The first stage solves only for trucks, by computing paths that make them more likely to be useful transit options for drones. The second stage solves only for drones, by routing them over a composite of the road network and the transit network defined by truck paths from the first stage. We design a comprehensive algorithmic framework that frames each stage as a multi-agent path-finding problem and implement two distinct methods for solving them. We evaluate our approach on extensive simulations with up to $100$ agents on the real-world Manhattan road network containing nearly $4500$ vertices and $10000$ edges. Our framework saves on more than $50\\%$ of vehicle distance traveled compared to independently solving for trucks and drones, and computes solutions for all settings within $5$ minutes on commodity hardware.",
        "published": "2021-10-17T12:00:30Z",
        "link": "http://arxiv.org/abs/2110.08802v2",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "On-line Optimal Ranging Sensor Deployment for Robotic Exploration",
        "authors": [
            "Luca Santoro",
            "Davide Brunelli",
            "Daniele Fontanelli"
        ],
        "summary": "Navigation in an unknown environment without any preexisting positioning infrastructure has always been hard for mobile robots. This paper presents a self-deployable ultra wideband UWB infrastructure by mobile agents, that permits a dynamic placement and runtime extension of UWB anchors infrastructure while the robot explores the new environment. We provide a detailed analysis of the uncertainty of the positioning system while the UWB infrastructure grows. Moreover, we developed a genetic algorithm that minimizes the deployment of new anchors, saving energy and resources on the mobile robot and maximizing the time of the mission. Although the presented approach is general for any class of mobile system, we run simulations and experiments with indoor drones. Results demonstrate that maximum positioning uncertainty is always controlled under the user's threshold, using the Geometric Dilution of Precision (GDoP).",
        "published": "2021-10-17T15:39:56Z",
        "link": "http://arxiv.org/abs/2110.08853v1",
        "categories": [
            "cs.RO",
            "cs.MA",
            "J.7"
        ]
    },
    {
        "title": "EmbRace: Accelerating Sparse Communication for Distributed Training of   NLP Neural Networks",
        "authors": [
            "Shengwei Li",
            "Zhiquan Lai",
            "Dongsheng Li",
            "Yiming Zhang",
            "Xiangyu Ye",
            "Yabo Duan"
        ],
        "summary": "Distributed data-parallel training has been widely adopted for deep neural network (DNN) models. Although current deep learning (DL) frameworks scale well for dense models like image classification models, we find that these DL frameworks have relatively low scalability for sparse models like natural language processing (NLP) models that have highly sparse embedding tables. Most existing works overlook the sparsity of model parameters thus suffering from significant but unnecessary communication overhead. In this paper, we propose EmbRace, an efficient communication framework to accelerate communications of distributed training for sparse models. EmbRace introduces Sparsity-aware Hybrid Communication, which integrates AlltoAll and model parallelism into data-parallel training, so as to reduce the communication overhead of highly sparse parameters. To effectively overlap sparse communication with both backward and forward computation, EmbRace further designs a 2D Communication Scheduling approach which optimizes the model computation procedure, relaxes the dependency of embeddings, and schedules the sparse communications of each embedding row with a priority queue. We have implemented a prototype of EmbRace based on PyTorch and Horovod, and conducted comprehensive evaluations with four representative NLP models. Experimental results show that EmbRace achieves up to 2.41X speedup compared to the state-of-the-art distributed training baselines.",
        "published": "2021-10-18T09:35:40Z",
        "link": "http://arxiv.org/abs/2110.09132v2",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "MTP: Multi-Hypothesis Tracking and Prediction for Reduced Error   Propagation",
        "authors": [
            "Xinshuo Weng",
            "Boris Ivanovic",
            "Marco Pavone"
        ],
        "summary": "Recently, there has been tremendous progress in developing each individual module of the standard perception-planning robot autonomy pipeline, including detection, tracking, prediction of other agents' trajectories, and ego-agent trajectory planning. Nevertheless, there has been less attention given to the principled integration of these components, particularly in terms of the characterization and mitigation of cascading errors. This paper addresses the problem of cascading errors by focusing on the coupling between the tracking and prediction modules. First, by using state-of-the-art tracking and prediction tools, we conduct a comprehensive experimental evaluation of how severely errors stemming from tracking can impact prediction performance. On the KITTI and nuScenes datasets, we find that predictions consuming tracked trajectories as inputs (the typical case in practice) can experience a significant (even order of magnitude) drop in performance in comparison to the idealized setting where ground truth past trajectories are used as inputs. To address this issue, we propose a multi-hypothesis tracking and prediction framework. Rather than relying on a single set of tracking results for prediction, our framework simultaneously reasons about multiple sets of tracking results, thereby increasing the likelihood of including accurate tracking results as inputs to prediction. We show that this framework improves overall prediction performance over the standard single-hypothesis tracking-prediction pipeline by up to 34.2% on the nuScenes dataset, with even more significant improvements (up to ~70%) when restricting the evaluation to challenging scenarios involving identity switches and fragments -- all with an acceptable computation overhead.",
        "published": "2021-10-18T17:30:59Z",
        "link": "http://arxiv.org/abs/2110.09481v1",
        "categories": [
            "cs.CV",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Improved cooperation by balancing exploration and exploitation in   intertemporal social dilemma tasks",
        "authors": [
            "Zhenbo Cheng",
            "Xingguang Liu",
            "Leilei Zhang",
            "Hangcheng Meng",
            "Qin Li",
            "Xiao Gang"
        ],
        "summary": "When an individual's behavior has rational characteristics, this may lead to irrational collective actions for the group. A wide range of organisms from animals to humans often evolve the social attribute of cooperation to meet this challenge. Therefore, cooperation among individuals is of great significance for allowing social organisms to adapt to changes in the natural environment. Based on multi-agent reinforcement learning, we propose a new learning strategy for achieving coordination by incorporating a learning rate that can balance exploration and exploitation. We demonstrate that agents that use the simple strategy improve a relatively collective return in a decision task called the intertemporal social dilemma, where the conflict between the individual and the group is particularly sharp. We also explore the effects of the diversity of learning rates on the population of reinforcement learning agents and show that agents trained in heterogeneous populations develop particularly coordinated policies relative to those trained in homogeneous populations.",
        "published": "2021-10-19T08:40:56Z",
        "link": "http://arxiv.org/abs/2111.09152v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.CY"
        ]
    },
    {
        "title": "State-based Episodic Memory for Multi-Agent Reinforcement Learning",
        "authors": [
            "Xiao Ma",
            "Wu-Jun Li"
        ],
        "summary": "Multi-agent reinforcement learning (MARL) algorithms have made promising progress in recent years by leveraging the centralized training and decentralized execution (CTDE) paradigm. However, existing MARL algorithms still suffer from the sample inefficiency problem. In this paper, we propose a simple yet effective approach, called state-based episodic memory (SEM), to improve sample efficiency in MARL. SEM adopts episodic memory (EM) to supervise the centralized training procedure of CTDE in MARL. To the best of our knowledge, SEM is the first work to introduce EM into MARL. We can theoretically prove that, when using for MARL, SEM has lower space complexity and time complexity than state and action based EM (SAEM), which is originally proposed for single-agent reinforcement learning. Experimental results on StarCraft multi-agent challenge (SMAC) show that introducing episodic memory into MARL can improve sample efficiency and SEM can reduce storage cost and time cost compared with SAEM.",
        "published": "2021-10-19T09:39:19Z",
        "link": "http://arxiv.org/abs/2110.09817v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Socialbots on Fire: Modeling Adversarial Behaviors of Socialbots via   Multi-Agent Hierarchical Reinforcement Learning",
        "authors": [
            "Thai Le",
            "Long Tran-Thanh",
            "Dongwon Lee"
        ],
        "summary": "Socialbots are software-driven user accounts on social platforms, acting autonomously (mimicking human behavior), with the aims to influence the opinions of other users or spread targeted misinformation for particular goals. As socialbots undermine the ecosystem of social platforms, they are often considered harmful. As such, there have been several computational efforts to auto-detect the socialbots. However, to our best knowledge, the adversarial nature of these socialbots has not yet been studied. This begs a question \"can adversaries, controlling socialbots, exploit AI techniques to their advantage?\" To this question, we successfully demonstrate that indeed it is possible for adversaries to exploit computational learning mechanism such as reinforcement learning (RL) to maximize the influence of socialbots while avoiding being detected. We first formulate the adversarial socialbot learning as a cooperative game between two functional hierarchical RL agents. While one agent curates a sequence of activities that can avoid the detection, the other agent aims to maximize network influence by selectively connecting with right users. Our proposed policy networks train with a vast amount of synthetic graphs and generalize better than baselines on unseen real-life graphs both in terms of maximizing network influence (up to +18%) and sustainable stealthiness (up to +40% undetectability) under a strong bot detector (with 90% detection accuracy). During inference, the complexity of our approach scales linearly, independent of a network's structure and the virality of news. This makes our approach a practical adversarial attack when deployed in a real-life setting.",
        "published": "2021-10-20T16:49:26Z",
        "link": "http://arxiv.org/abs/2110.10655v2",
        "categories": [
            "cs.SI",
            "cs.AI",
            "cs.CR",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Quantifying the sustainability impact of Google Maps: A case study of   Salt Lake City",
        "authors": [
            "Neha Arora",
            "Theophile Cabannes",
            "Sanjay Ganapathy",
            "Yechen Li",
            "Preston McAfee",
            "Marc Nunkesser",
            "Carolina Osorio",
            "Andrew Tomkins",
            "Iveel Tsogsuren"
        ],
        "summary": "Google Maps uses current and historical traffic trends to provide routes to drivers. In this paper, we use microscopic traffic simulation to quantify the improvements to both travel time and CO$_2$ emissions from Google Maps real-time navigation. A case study in Salt Lake City shows that Google Maps users are, on average, saving 1.7% of CO$_2$ emissions and 6.5% travel time. If we restrict to the users for which Google Maps finds a different route than their original route, the average savings are 3.4% of CO$_2$ emissions and 12.5% of travel time. These results are based on traffic conditions observed during the Covid-19 pandemic. As congestion gradually builds back up to pre-pandemic levels, it is expected to lead to even greater savings in emissions.",
        "published": "2021-10-21T04:42:17Z",
        "link": "http://arxiv.org/abs/2111.03426v1",
        "categories": [
            "physics.soc-ph",
            "cs.MA"
        ]
    },
    {
        "title": "On games and simulators as a platform for development of artificial   intelligence for command and control",
        "authors": [
            "Vinicius G. Goecks",
            "Nicholas Waytowich",
            "Derrik E. Asher",
            "Song Jun Park",
            "Mark Mittrick",
            "John Richardson",
            "Manuel Vindiola",
            "Anne Logie",
            "Mark Dennison",
            "Theron Trout",
            "Priya Narayanan",
            "Alexander Kott"
        ],
        "summary": "Games and simulators can be a valuable platform to execute complex multi-agent, multiplayer, imperfect information scenarios with significant parallels to military applications: multiple participants manage resources and make decisions that command assets to secure specific areas of a map or neutralize opposing forces. These characteristics have attracted the artificial intelligence (AI) community by supporting development of algorithms with complex benchmarks and the capability to rapidly iterate over new ideas. The success of artificial intelligence algorithms in real-time strategy games such as StarCraft II have also attracted the attention of the military research community aiming to explore similar techniques in military counterpart scenarios. Aiming to bridge the connection between games and military applications, this work discusses past and current efforts on how games and simulators, together with the artificial intelligence algorithms, have been adapted to simulate certain aspects of military missions and how they might impact the future battlefield. This paper also investigates how advances in virtual reality and visual augmentation systems open new possibilities in human interfaces with gaming platforms and their military parallels.",
        "published": "2021-10-21T17:39:58Z",
        "link": "http://arxiv.org/abs/2110.11305v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "I.2.6; I.6.3; A.1"
        ]
    },
    {
        "title": "Statistical discrimination in learning agents",
        "authors": [
            "Edgar A. Duéñez-Guzmán",
            "Kevin R. McKee",
            "Yiran Mao",
            "Ben Coppin",
            "Silvia Chiappa",
            "Alexander Sasha Vezhnevets",
            "Michiel A. Bakker",
            "Yoram Bachrach",
            "Suzanne Sadedin",
            "William Isaac",
            "Karl Tuyls",
            "Joel Z. Leibo"
        ],
        "summary": "Undesired bias afflicts both human and algorithmic decision making, and may be especially prevalent when information processing trade-offs incentivize the use of heuristics. One primary example is \\textit{statistical discrimination} -- selecting social partners based not on their underlying attributes, but on readily perceptible characteristics that covary with their suitability for the task at hand. We present a theoretical model to examine how information processing influences statistical discrimination and test its predictions using multi-agent reinforcement learning with various agent architectures in a partner choice-based social dilemma. As predicted, statistical discrimination emerges in agent policies as a function of both the bias in the training population and of agent architecture. All agents showed substantial statistical discrimination, defaulting to using the readily available correlates instead of the outcome relevant features. We show that less discrimination emerges with agents that use recurrent neural networks, and when their training environment has less bias. However, all agent algorithms we tried still exhibited substantial bias after learning in biased training populations.",
        "published": "2021-10-21T18:28:57Z",
        "link": "http://arxiv.org/abs/2110.11404v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.GT",
            "cs.MA",
            "68T07 (Primary) 91A26, 91-10, 93A16 (Secondary)",
            "I.2.11; I.2.0"
        ]
    },
    {
        "title": "An Economy of Neural Networks: Learning from Heterogeneous Experiences",
        "authors": [
            "Artem Kuriksha"
        ],
        "summary": "This paper proposes a new way to model behavioral agents in dynamic macro-financial environments. Agents are described as neural networks and learn policies from idiosyncratic past experiences. I investigate the feedback between irrationality and past outcomes in an economy with heterogeneous shocks similar to Aiyagari (1994). In the model, the rational expectations assumption is seriously violated because learning of a decision rule for savings is unstable. Agents who fall into learning traps save either excessively or save nothing, which provides a candidate explanation for several empirical puzzles about wealth distribution. Neural network agents have a higher average MPC and exhibit excess sensitivity of consumption. Learning can negatively affect intergenerational mobility.",
        "published": "2021-10-22T04:21:51Z",
        "link": "http://arxiv.org/abs/2110.11582v1",
        "categories": [
            "econ.GN",
            "cs.MA",
            "q-fin.EC"
        ]
    },
    {
        "title": "Measuring the Non-Transitivity in Chess",
        "authors": [
            "Ricky Sanjaya",
            "Jun Wang",
            "Yaodong Yang"
        ],
        "summary": "It has long been believed that Chess is the \\emph{Drosophila} of Artificial Intelligence (AI). Studying Chess can productively provide valid knowledge about complex systems. Although remarkable progress has been made on solving Chess, the geometrical landscape of Chess in the strategy space is still mysterious. Judging on AI-generated strategies, researchers hypothesised that the strategy space of Chess possesses a spinning top geometry, with the upright axis representing the \\emph{transitive} dimension (e.g., A beats B, B beats C, A beats C), and the radial axis representing the \\emph{non-transitive} dimension (e.g., A beats B, B beats C, C beats A). However, it is unclear whether such a hypothesis holds for real-world strategies. In this paper, we quantify the non-transitivity in Chess through real-world data from human players. Specifically, we performed two ways of non-transitivity quantifications -- Nash Clustering and counting the number of Rock-Paper-Scissor cycles -- on over one billion match data from Lichess and FICS. Our findings positively indicate that the strategy space occupied by real-world Chess strategies demonstrates a spinning top geometry, and more importantly, there exists a strong connection between the degree of non-transitivity and the progression of a Chess player's rating. In particular, high degrees of non-transitivity tend to prevent human players from making progress on their Elo rating, whereas progressions are easier to make at the level of ratings where the degree of non-transitivity is lower. Additionally, we also investigate the implication of the degree of non-transitivity for population-based training methods. By considering \\emph{fixed-memory Fictitious Play} as a proxy, we reach the conclusion that maintaining large-size and diverse populations of strategies is imperative to training effective AI agents in solving Chess types of games.",
        "published": "2021-10-22T12:15:42Z",
        "link": "http://arxiv.org/abs/2110.11737v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Adaptability of Improved NEAT in Variable Environments",
        "authors": [
            "Destiny Bailey"
        ],
        "summary": "A large challenge in Artificial Intelligence (AI) is training control agents that can properly adapt to variable environments. Environments in which the conditions change can cause issues for agents trying to operate in them. Building algorithms that can train agents to operate in these environments and properly deal with the changing conditions is therefore important. NeuroEvolution of Augmenting Topologies (NEAT) was a novel Genetic Algorithm (GA) when it was created, but has fallen aside with newer GAs outperforming it. This paper furthers the research on this subject by implementing various versions of improved NEAT in a variable environment to determine if NEAT can perform well in these environments. The improvements included, in every combination, are: recurrent connections, automatic feature selection, and increasing population size. The recurrent connections improvement performed extremely well. The automatic feature selection improvement was found to be detrimental to performance, and the increasing population size improvement lowered performance a small amount, but decreased computation requirements noticeably.",
        "published": "2021-10-22T15:33:51Z",
        "link": "http://arxiv.org/abs/2201.07977v2",
        "categories": [
            "cs.NE",
            "cs.MA"
        ]
    },
    {
        "title": "Solving N-player dynamic routing games with congestion: a mean field   approach",
        "authors": [
            "Theophile Cabannes",
            "Mathieu Lauriere",
            "Julien Perolat",
            "Raphael Marinier",
            "Sertan Girgin",
            "Sarah Perrin",
            "Olivier Pietquin",
            "Alexandre M. Bayen",
            "Eric Goubault",
            "Romuald Elie"
        ],
        "summary": "The recent emergence of navigational tools has changed traffic patterns and has now enabled new types of congestion-aware routing control like dynamic road pricing. Using the fundamental diagram of traffic flows - applied in macroscopic and mesoscopic traffic modeling - the article introduces a new N-player dynamic routing game with explicit congestion dynamics. The model is well-posed and can reproduce heterogeneous departure times and congestion spill back phenomena. However, as Nash equilibrium computations are PPAD-complete, solving the game becomes intractable for large but realistic numbers of vehicles N. Therefore, the corresponding mean field game is also introduced. Experiments were performed on several classical benchmark networks of the traffic community: the Pigou, Braess, and Sioux Falls networks with heterogeneous origin, destination and departure time tuples. The Pigou and the Braess examples reveal that the mean field approximation is generally very accurate and computationally efficient as soon as the number of vehicles exceeds a few dozen. On the Sioux Falls network (76 links, 100 time steps), this approach enables learning traffic dynamics with more than 14,000 vehicles.",
        "published": "2021-10-22T17:52:32Z",
        "link": "http://arxiv.org/abs/2110.11943v2",
        "categories": [
            "math.DS",
            "cs.MA",
            "cs.NI",
            "cs.SY",
            "eess.SY",
            "math.OC"
        ]
    },
    {
        "title": "Deep Structured Teams in Arbitrary-Size Linear Networks: Decentralized   Estimation, Optimal Control and Separation Principle",
        "authors": [
            "Jalal Arabneydi",
            "Amir G. Aghdam"
        ],
        "summary": "In this article, we introduce decentralized Kalman filters for linear quadratic deep structured teams. The agents in deep structured teams are coupled in dynamics, costs and measurements through a set of linear regressions of the states and actions (also called deep states and deep actions). The information structure is decentralized, where every agent observes a noisy measurement of its local state and the global deep state. Since the number of agents is often very large in deep structured teams, any naive approach to finding an optimal Kalman filter suffers from the curse of dimensionality. Moreover, due to the decentralized nature of information structure, the resultant optimization problem is non-convex, in general, where non-linear strategies can outperform linear ones. However, we prove that the optimal strategy is linear in the local state estimate as well as the deep state estimate and can be efficiently computed by two scale-free Riccati equations and Kalman filters. We propose a bi-level orthogonal approach across both space and time levels based on a gauge transformation technique to achieve the above result.   We also establish a separation principle between optimal control and optimal estimation. Furthermore, we show that as the number of agents goes to infinity, the Kalman gain associated with the deep state estimate converges to zero at a rate inversely proportional to the number of agents. This leads to a fully decentralized approximate strategy where every agent predicts the deep state by its conditional and unconditional expected value, also known as the certainty equivalence approximation and (weighted) mean-field approximation, respectively.",
        "published": "2021-10-23T13:31:40Z",
        "link": "http://arxiv.org/abs/2110.12217v1",
        "categories": [
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "Characterizing The Limits of Linear Modeling of Non-Linear Swarm   Behaviors",
        "authors": [
            "John Harwell",
            "Angel Sylvester",
            "Maria Gini"
        ],
        "summary": "We study the limits of linear modeling of swarm behavior by characterizing the inflection point beyond which linear models of swarm collective behavior break down. The problem we consider is a central place object gathering task. We design a linear model which strives to capture the underlying dynamics of object gathering in robot swarms from first principles, rather than extensively relying on post-hoc model fitting. We evaluate our model with swarms of up to 8,000 robots in simulation, demonstrating that it accurately captures underlying swarm behavioral dynamics when the swarm can be approximated using the mean-field model, and when it cannot, and finite-size effects are present. We further apply our model to swarms exhibiting non-linear behaviors, and show that it still provides accurate predictions in some scenarios, thereby establishing better practical limits on linear modeling of swarm behaviors.",
        "published": "2021-10-23T22:05:01Z",
        "link": "http://arxiv.org/abs/2110.12307v2",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Observable and Attention-Directing BDI Agents for Human-Autonomy Teaming",
        "authors": [
            "Blair Archibald",
            "Muffy Calder",
            "Michele Sevegnani",
            "Mengwei Xu"
        ],
        "summary": "Human-autonomy teaming (HAT) scenarios feature humans and autonomous agents collaborating to meet a shared goal. For effective collaboration, the agents must be transparent and able to share important information about their operation with human teammates. We address the challenge of transparency for Belief-Desire-Intention agents defined in the Conceptual Agent Notation (CAN) language. We extend the semantics to model agents that are observable (i.e. the internal state of tasks is available), and attention-directing (i.e. specific states can be flagged to users), and provide an executable semantics via an encoding in Milner's bigraphs. Using an example of unmanned aerial vehicles, the BigraphER tool, and PRISM, we show and verify how the extensions work in practice.",
        "published": "2021-10-25T01:47:53Z",
        "link": "http://arxiv.org/abs/2110.12579v1",
        "categories": [
            "cs.MA",
            "cs.HC",
            "cs.PL"
        ]
    },
    {
        "title": "Towards a Formalisation of Justification and Justifiability",
        "authors": [
            "Willem Hagemann"
        ],
        "summary": "We introduce the logic QKSD which is a normal multi-modal logic over finitely many modalities that additionally supports bounded quantification of modalities. An important feature of this logic is that it allows to quantify over the information components of systems and, hence, can be used to derive justifications. We compare the proposed logic with Artemov's justification logic and also report on a prototypical implementation of a satisfiability solver of this logic and show some examples.",
        "published": "2021-10-25T01:54:02Z",
        "link": "http://arxiv.org/abs/2110.12581v1",
        "categories": [
            "cs.LO",
            "cs.MA"
        ]
    },
    {
        "title": "Complete Agent-driven Model-based System Testing for Autonomous Systems",
        "authors": [
            "Kerstin I. Eder",
            "Wen-ling Huang",
            "Jan Peleska"
        ],
        "summary": "In this position paper, a novel approach to testing complex autonomous transportation systems (ATS) in the automotive, avionic, and railway domains is described. It is intended to mitigate some of the most critical problems regarding verification and validation (V&V) effort for ATS. V&V is known to become infeasible for complex ATS, when using conventional methods only. The approach advocated here uses complete testing methods on the module level, because these establish formal proofs for the logical correctness of the software. Having established logical correctness, system-level tests are performed in simulated cloud environments and on the target system. To give evidence that 'sufficiently many' system tests have been performed with the target system, a formally justified coverage criterion is introduced. To optimise the execution of very large system test suites, we advocate an online testing approach where multiple tests are executed in parallel, and test steps are identified on-the-fly. The coordination and optimisation of these executions is achieved by an agent-based approach. Each aspect of the testing approach advocated here is shown to either be consistent with existing standards for development and V&V of safety-critical transportation systems, or it is justified why it should become acceptable in future revisions of the applicable standards.",
        "published": "2021-10-25T01:55:24Z",
        "link": "http://arxiv.org/abs/2110.12586v1",
        "categories": [
            "cs.SE",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Formal Guarantees of Timely Progress for Distributed Knowledge   Propagation",
        "authors": [
            "Saswata Paul",
            "Stacy Patterson",
            "Carlos Varela"
        ],
        "summary": "Autonomous air traffic management (ATM) operations for urban air mobility (UAM) will necessitate the use of distributed protocols for decentralized coordination between aircraft. As UAM operations are time-critical, it will be imperative to have formal guarantees of progress for the distributed protocols used in ATM. Under asynchronous settings, message transmission and processing delays are unbounded, making it impossible to provide deterministic bounds on the time required to make progress. We present an approach for formally guaranteeing timely progress in a Two-Phase Acknowledge distributed knowledge propagation protocol by probabilistically modeling the delays using theories of the Multicopy Two-Hop Relay protocol and the M/M/1 queue system. The guarantee states a probabilistic upper bound to the time for progress as a function of the probabilities of the total transmission and processing delays being less than two given values. We also showcase the development of a library of formal theories, that is tailored towards reasoning about timely progress in distributed protocols deployed in airborne networks, in the Athena proof assistant.",
        "published": "2021-10-25T01:55:41Z",
        "link": "http://arxiv.org/abs/2110.12587v1",
        "categories": [
            "cs.DC",
            "cs.LO",
            "cs.MA",
            "cs.SE"
        ]
    },
    {
        "title": "Common Information based Approximate State Representations in   Multi-Agent Reinforcement Learning",
        "authors": [
            "Hsu Kao",
            "Vijay Subramanian"
        ],
        "summary": "Due to information asymmetry, finding optimal policies for Decentralized Partially Observable Markov Decision Processes (Dec-POMDPs) is hard with the complexity growing doubly exponentially in the horizon length. The challenge increases greatly in the multi-agent reinforcement learning (MARL) setting where the transition probabilities, observation kernel, and reward function are unknown. Here, we develop a general compression framework with approximate common and private state representations, based on which decentralized policies can be constructed. We derive the optimality gap of executing dynamic programming (DP) with the approximate states in terms of the approximation error parameters and the remaining time steps. When the compression is exact (no error), the resulting DP is equivalent to the one in existing work. Our general framework generalizes a number of methods proposed in the literature. The results shed light on designing practically useful deep-MARL network structures under the \"centralized learning distributed execution\" scheme.",
        "published": "2021-10-25T02:32:06Z",
        "link": "http://arxiv.org/abs/2110.12603v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "Medium Access Control protocol for Collaborative Spectrum Learning in   Wireless Networks",
        "authors": [
            "Tomer Boyarski",
            "Wenbo Wang",
            "Amir Leshem"
        ],
        "summary": "In recent years there is a growing effort to provide learning algorithms for spectrum collaboration. In this paper we present a medium access control protocol which allows spectrum collaboration with minimal regret and high spectral efficiency in highly loaded networks. We present a fully-distributed algorithm for spectrum collaboration in congested ad-hoc networks. The algorithm jointly solves both the channel allocation and access scheduling problems. We prove that the algorithm has an optimal logarithmic regret. Based on the algorithm we provide a medium access control protocol which allows distributed implementation of the algorithm in ad-hoc networks. The protocol utilizes single-channel opportunistic carrier sensing to carry out a low-complexity distributed auction in time and frequency. We also discuss practical implementation issues such as bounded frame size and speed of convergence. Computer simulations comparing the algorithm to state-of-the-art distributed medium access control protocols show the significant advantage of the proposed scheme.",
        "published": "2021-10-25T10:11:57Z",
        "link": "http://arxiv.org/abs/2111.12581v2",
        "categories": [
            "cs.NI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Parallel Feedforward Compensation for Output Synchronization: Fully   Distributed Control and Indefinite Laplacian",
        "authors": [
            "Mengmou Li",
            "Ioannis Lestas",
            "Li Qiu"
        ],
        "summary": "This work is associated with the use of parallel feedforward compensators (PFCs) for the problem of output synchronization over heterogeneous agents and the benefits this approach can provide. Specifically, it addresses the addition of stable PFCs on agents that interact with each other using diffusive couplings. The value in the application of such PFC is twofold. Firstly, it has been an issue that output synchronization among passivity-short systems requires global information for the design of controllers in the cases when initial conditions need to be taken into account, such as average consensus and distributed optimization. We show that a stable PFC can be designed to passivate a passivity-short system while its output asymptotically vanishes as its input tends to zero. As a result, output synchronization is achieved among these systems by fully distributed controls without altering the original consensus results. Secondly, in the literature of output synchronization over signed weighted graphs, it is generally required that the graph Laplacian be positive semidefinite, i.e., $L \\geq 0$ for undirected graphs or $L + L^T \\geq 0$ for balanced directed graphs. We show that the PFC serves as output feedback to the communication graph to enhance the robustness against negative weight edges. As a result, output synchronization is achieved over a signed weighted and balanced graph, even if the corresponding Laplacian is not positive semidefinite.",
        "published": "2021-10-25T10:33:18Z",
        "link": "http://arxiv.org/abs/2110.12787v3",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Towards Realistic Market Simulations: a Generative Adversarial Networks   Approach",
        "authors": [
            "Andrea Coletta",
            "Matteo Prata",
            "Michele Conti",
            "Emanuele Mercanti",
            "Novella Bartolini",
            "Aymeric Moulin",
            "Svitlana Vyetrenko",
            "Tucker Balch"
        ],
        "summary": "Simulated environments are increasingly used by trading firms and investment banks to evaluate trading strategies before approaching real markets. Backtesting, a widely used approach, consists of simulating experimental strategies while replaying historical market scenarios. Unfortunately, this approach does not capture the market response to the experimental agents' actions. In contrast, multi-agent simulation presents a natural bottom-up approach to emulating agent interaction in financial markets. It allows to set up pools of traders with diverse strategies to mimic the financial market trader population, and test the performance of new experimental strategies. Since individual agent-level historical data is typically proprietary and not available for public use, it is difficult to calibrate multiple market agents to obtain the realism required for testing trading strategies. To addresses this challenge we propose a synthetic market generator based on Conditional Generative Adversarial Networks (CGANs) trained on real aggregate-level historical data. A CGAN-based \"world\" agent can generate meaningful orders in response to an experimental agent. We integrate our synthetic market generator into ABIDES, an open source simulator of financial markets. By means of extensive simulations we show that our proposal outperforms previous work in terms of stylized facts reflecting market responsiveness and realism.",
        "published": "2021-10-25T22:01:07Z",
        "link": "http://arxiv.org/abs/2110.13287v1",
        "categories": [
            "cs.AI",
            "cs.CE",
            "cs.LG",
            "cs.MA",
            "q-fin.TR",
            "I.2, I.6",
            "I.2; I.6"
        ]
    },
    {
        "title": "Self-aware Social Learning over Graphs",
        "authors": [
            "Konstantinos Ntemos",
            "Virginia Bordignon",
            "Stefan Vlaski",
            "Ali H. Sayed"
        ],
        "summary": "In this paper we study the problem of social learning under multiple true hypotheses and self-interested agents which exchange information over a graph. In this setup, each agent receives data that might be generated from a different hypothesis (or state) than the data other agents receive. In contrast to the related literature in social learning, which focuses on showing that the network achieves consensus, here we study the case where every agent is self-interested and wants to find the hypothesis that generates its own observations. However, agents do not know which ones of their peers wants to find the same state with them and as a result they do not know which agents they should cooperate with. To this end, we propose a scheme with adaptive combination weights and study the consistency of the agents' learning process. The scheme allows each agent to identify and collaborate with neighbors that observe the same hypothesis, while excluding others, thus resulting in improved performance compared to both non-cooperative learning and cooperative social learning solutions. We analyze the asymptotic behavior of agents' beliefs under the proposed social learning algorithm and provide sufficient conditions that enable all agents to correctly identify their true hypotheses. The theoretical analysis is corroborated by numerical simulations.",
        "published": "2021-10-25T22:08:03Z",
        "link": "http://arxiv.org/abs/2110.13292v1",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Institutional Incentives for the Evolution of Committed Cooperation:   Ensuring Participation is as Important as Enhancing Compliance",
        "authors": [
            "The Anh Han"
        ],
        "summary": "Both conventional wisdom and empirical evidence suggests that arranging a prior commitment or agreement before an interaction enhances the chance of reaching mutual cooperation. Yet it is not clear what mechanisms can promote the participation in and compliance with such a commitment, especially when the former is costly and deviating from the latter is profitable. Prior work either considers regimented commitments where compensation is assumed enforceable from dishonest committers, or assume implicit commitments from every individual (so they are all in and thus being treated as such). Here we develop a theory of participation and compliance with respect to an explicit prior commitment under institutional incentives where individuals, at first, decide whether or not to join a cooperative agreement to play a one-shot social dilemma game. Using a mathematical model, we determine when participating in a costly commitment and complying with it, is an evolutionary stable strategy (ESS) when playing against all other possible strategies, and results in high levels of cooperation in the population. We show that, given a sufficient budget for providing incentives, reward of commitment compliant behaviours better promotes cooperation than punishment of non-compliant ones. Moreover, by sparing part of this budget for rewarding those who are willing to participate in a commitment, the overall frequency of cooperation can be significantly enhanced, for both reward and punishment. Finally, we find that, surprisingly, the presence of errors in a participation decision favours evolutionary stability of commitment compliant strategies and higher levels of cooperation.",
        "published": "2021-10-25T22:42:14Z",
        "link": "http://arxiv.org/abs/2110.13307v2",
        "categories": [
            "math.DS",
            "cs.MA",
            "nlin.AO",
            "q-bio.PE"
        ]
    },
    {
        "title": "Multi-Agent Advisor Q-Learning",
        "authors": [
            "Sriram Ganapathi Subramanian",
            "Matthew E. Taylor",
            "Kate Larson",
            "Mark Crowley"
        ],
        "summary": "In the last decade, there have been significant advances in multi-agent reinforcement learning (MARL) but there are still numerous challenges, such as high sample complexity and slow convergence to stable policies, that need to be overcome before wide-spread deployment is possible. However, many real-world environments already, in practice, deploy sub-optimal or heuristic approaches for generating policies. An interesting question that arises is how to best use such approaches as advisors to help improve reinforcement learning in multi-agent domains. In this paper, we provide a principled framework for incorporating action recommendations from online sub-optimal advisors in multi-agent settings. We describe the problem of ADvising Multiple Intelligent Reinforcement Agents (ADMIRAL) in nonrestrictive general-sum stochastic game environments and present two novel Q-learning based algorithms: ADMIRAL - Decision Making (ADMIRAL-DM) and ADMIRAL - Advisor Evaluation (ADMIRAL-AE), which allow us to improve learning by appropriately incorporating advice from an advisor (ADMIRAL-DM), and evaluate the effectiveness of an advisor (ADMIRAL-AE). We analyze the algorithms theoretically and provide fixed-point guarantees regarding their learning in general-sum stochastic games. Furthermore, extensive experiments illustrate that these algorithms: can be used in a variety of environments, have performances that compare favourably to other related baselines, can scale to large state-action spaces, and are robust to poor advice from advisors.",
        "published": "2021-10-26T00:21:15Z",
        "link": "http://arxiv.org/abs/2111.00345v6",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Event-triggered Consensus of Matrix-weighted Networks Subject to   Actuator Saturation",
        "authors": [
            "Lulu Pan",
            "Haibin Shao",
            "Yuanlong Li",
            "Dewei Li",
            "Yugeng Xi"
        ],
        "summary": "The ubiquitous interdependencies among higher-dimensional states of neighboring agents can be characterized by matrix-weighted networks. This paper examines event-triggered global consensus of matrix-weighted networks subject to actuator saturation. Specifically, a distributed dynamic event-triggered coordination strategy, whose design involves sampled state of agents, saturation constraint and auxiliary systems, is proposed for this category of generalized network to guarantee its global consensus. Under the proposed event-triggered coordination strategy, sufficient conditions are derived to guarantee the leaderless and leader-follower global consensus of the multi-agent systems on matrix-weighted networks, respectively. The Zeno phenomenon can be excluded for both cases under the proposed coordination strategy. It turns out that the spectral properties of matrix-valued weights are crucial in event-triggered mechanism design for matrix-weighted networks with actuator saturation constraint. Finally, simulations are provided to demonstrate the effectiveness of proposed event-triggered coordination strategy. This work provides a more general design framework compared with existing results that are only applicable to scalar-weighted networks.",
        "published": "2021-10-26T02:03:47Z",
        "link": "http://arxiv.org/abs/2110.13356v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Applications of Multi-Agent Reinforcement Learning in Future Internet: A   Comprehensive Survey",
        "authors": [
            "Tianxu Li",
            "Kun Zhu",
            "Nguyen Cong Luong",
            "Dusit Niyato",
            "Qihui Wu",
            "Yang Zhang",
            "Bing Chen"
        ],
        "summary": "Future Internet involves several emerging technologies such as 5G and beyond 5G networks, vehicular networks, unmanned aerial vehicle (UAV) networks, and Internet of Things (IoTs). Moreover, future Internet becomes heterogeneous and decentralized with a large number of involved network entities. Each entity may need to make its local decision to improve the network performance under dynamic and uncertain network environments. Standard learning algorithms such as single-agent Reinforcement Learning (RL) or Deep Reinforcement Learning (DRL) have been recently used to enable each network entity as an agent to learn an optimal decision-making policy adaptively through interacting with the unknown environments. However, such an algorithm fails to model the cooperations or competitions among network entities, and simply treats other entities as a part of the environment that may result in the non-stationarity issue. Multi-agent Reinforcement Learning (MARL) allows each network entity to learn its optimal policy by observing not only the environments, but also other entities' policies. As a result, MARL can significantly improve the learning efficiency of the network entities, and it has been recently used to solve various issues in the emerging networks. In this paper, we thus review the applications of MARL in the emerging networks. In particular, we provide a tutorial of MARL and a comprehensive survey of applications of MARL in next generation Internet. In particular, we first introduce single-agent RL and MARL. Then, we review a number of applications of MARL to solve emerging issues in future Internet. The issues consist of network access, transmit power control, computation offloading, content caching, packet routing, trajectory design for UAV-aided networks, and network security issues.",
        "published": "2021-10-26T08:26:55Z",
        "link": "http://arxiv.org/abs/2110.13484v3",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "A Reinforcement Learning Approach for Re-allocating Drone Swarm Services",
        "authors": [
            "Balsam Alkouz",
            "Athman Bouguettaya"
        ],
        "summary": "We propose a novel framework for the re-allocation of drone swarms for delivery services known as Swarm-based Drone-as-a-Service (SDaaS). The re-allocation framework ensures maximum profit to drone swarm providers while meeting the time requirement of service consumers. The constraints in the delivery environment (e.g., limited recharging pads) are taken into consideration. We utilize reinforcement learning (RL) to select the best allocation and scheduling of drone swarms given a set of requests from multiple consumers. We conduct a set of experiments to evaluate and compare the efficiency of the proposed approach considering the provider's profit and run-time efficiency.",
        "published": "2021-10-26T09:31:02Z",
        "link": "http://arxiv.org/abs/2110.13525v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Playing Coopetitive Polymatrix Games with Small Manipulation Cost",
        "authors": [
            "Shivakumar Mahesh",
            "Nicholas Bishop",
            "Le Cong Dinh",
            "Long Tran-Thanh"
        ],
        "summary": "Iterated coopetitive games capture the situation when one must efficiently balance between cooperation and competition with the other agents over time in order to win the game (e.g., to become the player with highest total utility). Achieving this balance is typically very challenging or even impossible when explicit communication is not feasible (e.g., negotiation or bargaining are not allowed). In this paper we investigate how an agent can achieve this balance to win in iterated coopetitive polymatrix games, without explicit communication. In particular, we consider a 3-player repeated game setting in which our agent is allowed to (slightly) manipulate the underlying game matrices of the other agents for which she pays a manipulation cost, while the other agents satisfy weak behavioural assumptions. We first propose a payoff matrix manipulation scheme and sequence of strategies for our agent that provably guarantees that the utility of any opponent would converge to a value we desire. We then use this scheme to design winning policies for our agent. We also prove that these winning policies can be found in polynomial running time. We then turn to demonstrate the efficiency of our framework in several concrete coopetitive polymatrix games, and prove that the manipulation costs needed to win are bounded above by small budgets. For instance, in the social distancing game, a polymatrix version of the lemonade stand coopetitive game, we showcase a policy with an infinitesimally small manipulation cost per round, along with a provable guarantee that, using this policy leads our agent to win in the long-run. Note that our findings can be trivially extended to $n$-player game settings as well (with $n > 3$).",
        "published": "2021-10-26T09:48:20Z",
        "link": "http://arxiv.org/abs/2110.13532v2",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Collective decision-making under changing social environments among   agents adapted to sparse connectivity",
        "authors": [
            "Richard P. Mann"
        ],
        "summary": "Humans and other animals often follow the decisions made by others because these are indicative of the quality of possible choices, resulting in `social response rules': observed relationships between the probability that an agent will make a specific choice and the decisions other individuals have made. The form of social responses can be understood by considering the behaviour of rational agents that seek to maximise their expected utility using both social and private information. Previous derivations of social responses assume that agents observe all others within a group, but real interaction networks are often characterised by sparse connectivity. Here I analyse the observable behaviour of rational agents that attend to the decisions made by a subset of others in the group. This reveals an adaptive strategy in sparsely-connected networks based on highly-simplified social information: the difference in the observed number of agents choosing each option. Where agents employ this strategy, collective outcomes and decision-making efficacy are controlled by the social connectivity at the time of the decision, rather than that to which the agents are accustomed, providing an important caveat for sociality observed in the laboratory and suggesting a basis for the social dynamics of highly-connected online communities.",
        "published": "2021-10-26T10:11:04Z",
        "link": "http://arxiv.org/abs/2110.13543v1",
        "categories": [
            "physics.soc-ph",
            "cs.MA",
            "q-bio.QM"
        ]
    },
    {
        "title": "Dynamic population-based meta-learning for multi-agent communication   with natural language",
        "authors": [
            "Abhinav Gupta",
            "Marc Lanctot",
            "Angeliki Lazaridou"
        ],
        "summary": "In this work, our goal is to train agents that can coordinate with seen, unseen as well as human partners in a multi-agent communication environment involving natural language. Previous work using a single set of agents has shown great progress in generalizing to known partners, however it struggles when coordinating with unfamiliar agents. To mitigate that, recent work explored the use of population-based approaches, where multiple agents interact with each other with the goal of learning more generic protocols. These methods, while able to result in good coordination between unseen partners, still only achieve so in cases of simple languages, thus failing to adapt to human partners using natural language. We attribute this to the use of static populations and instead propose a dynamic population-based meta-learning approach that builds such a population in an iterative manner. We perform a holistic evaluation of our method on two different referential games, and show that our agents outperform all prior work when communicating with seen partners and humans. Furthermore, we analyze the natural language generation skills of our agents, where we find that our agents also outperform strong baselines. Finally, we test the robustness of our agents when communicating with out-of-population agents and carefully test the importance of each component of our method through ablation studies.",
        "published": "2021-10-27T07:50:02Z",
        "link": "http://arxiv.org/abs/2110.14241v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.CL",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Multi-Agent Reinforcement Learning for Active Voltage Control on Power   Distribution Networks",
        "authors": [
            "Jianhong Wang",
            "Wangkun Xu",
            "Yunjie Gu",
            "Wenbin Song",
            "Tim C. Green"
        ],
        "summary": "This paper presents a problem in power networks that creates an exciting and yet challenging real-world scenario for application of multi-agent reinforcement learning (MARL). The emerging trend of decarbonisation is placing excessive stress on power distribution networks. Active voltage control is seen as a promising solution to relieve power congestion and improve voltage quality without extra hardware investment, taking advantage of the controllable apparatuses in the network, such as roof-top photovoltaics (PVs) and static var compensators (SVCs). These controllable apparatuses appear in a vast number and are distributed in a wide geographic area, making MARL a natural candidate. This paper formulates the active voltage control problem in the framework of Dec-POMDP and establishes an open-source environment. It aims to bridge the gap between the power community and the MARL community and be a drive force towards real-world applications of MARL algorithms. Finally, we analyse the special characteristics of the active voltage control problems that cause challenges (e.g. interpretability) for state-of-the-art MARL approaches, and summarise the potential directions.",
        "published": "2021-10-27T09:31:22Z",
        "link": "http://arxiv.org/abs/2110.14300v5",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Model based Multi-agent Reinforcement Learning with Tensor   Decompositions",
        "authors": [
            "Pascal Van Der Vaart",
            "Anuj Mahajan",
            "Shimon Whiteson"
        ],
        "summary": "A challenge in multi-agent reinforcement learning is to be able to generalize over intractable state-action spaces. Inspired from Tesseract [Mahajan et al., 2021], this position paper investigates generalisation in state-action space over unexplored state-action pairs by modelling the transition and reward functions as tensors of low CP-rank. Initial experiments on synthetic MDPs show that using tensor decompositions in a model-based reinforcement learning algorithm can lead to much faster convergence if the true transition and reward functions are indeed of low rank.",
        "published": "2021-10-27T15:36:25Z",
        "link": "http://arxiv.org/abs/2110.14524v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Reinforcement Learning in Factored Action Spaces using Tensor   Decompositions",
        "authors": [
            "Anuj Mahajan",
            "Mikayel Samvelyan",
            "Lei Mao",
            "Viktor Makoviychuk",
            "Animesh Garg",
            "Jean Kossaifi",
            "Shimon Whiteson",
            "Yuke Zhu",
            "Animashree Anandkumar"
        ],
        "summary": "We present an extended abstract for the previously published work TESSERACT [Mahajan et al., 2021], which proposes a novel solution for Reinforcement Learning (RL) in large, factored action spaces using tensor decompositions. The goal of this abstract is twofold: (1) To garner greater interest amongst the tensor research community for creating methods and analysis for approximate RL, (2) To elucidate the generalised setting of factored action spaces where tensor decompositions can be used. We use cooperative multi-agent reinforcement learning scenario as the exemplary setting where the action space is naturally factored across agents and learning becomes intractable without resorting to approximation on the underlying hypothesis space for candidate solutions.",
        "published": "2021-10-27T15:49:52Z",
        "link": "http://arxiv.org/abs/2110.14538v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "V-Learning -- A Simple, Efficient, Decentralized Algorithm for   Multiagent RL",
        "authors": [
            "Chi Jin",
            "Qinghua Liu",
            "Yuanhao Wang",
            "Tiancheng Yu"
        ],
        "summary": "A major challenge of multiagent reinforcement learning (MARL) is the curse of multiagents, where the size of the joint action space scales exponentially with the number of agents. This remains to be a bottleneck for designing efficient MARL algorithms even in a basic scenario with finitely many states and actions. This paper resolves this challenge for the model of episodic Markov games. We design a new class of fully decentralized algorithms -- V-learning, which provably learns Nash equilibria (in the two-player zero-sum setting), correlated equilibria and coarse correlated equilibria (in the multiplayer general-sum setting) in a number of samples that only scales with $\\max_{i\\in[m]} A_i$, where $A_i$ is the number of actions for the $i^{\\rm th}$ player. This is in sharp contrast to the size of the joint action space which is $\\prod_{i=1}^m A_i$. V-learning (in its basic form) is a new class of single-agent RL algorithms that convert any adversarial bandit algorithm with suitable regret guarantees into a RL algorithm. Similar to the classical Q-learning algorithm, it performs incremental updates to the value functions. Different from Q-learning, it only maintains the estimates of V-values instead of Q-values. This key difference allows V-learning to achieve the claimed guarantees in the MARL setting by simply letting all agents run V-learning independently.",
        "published": "2021-10-27T16:25:55Z",
        "link": "http://arxiv.org/abs/2110.14555v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.GT",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Paving the Way for Consensus: Convergence of Block Gossip Algorithms",
        "authors": [
            "Jamie Haddock",
            "Benjamin Jarman",
            "Chen Yap"
        ],
        "summary": "Gossip protocols are popular methods for average consensus problems in distributed computing. We prove new convergence guarantees for a variety of such protocols, including path, clique, and synchronous pairwise gossip. These arise by exploiting the connection between these protocols and the block randomized Kaczmarz method for solving linear systems. Moreover, we extend existing convergence results for block randomized Kaczmarz to allow for a more general choice of blocks, rank-deficient systems, and provide a tighter convergence rate guarantee. We furthermore apply this analysis to inconsistent consensus models and obtain similar guarantees. An extensive empirical analysis of these methods is provided for a variety of synthetic networks.",
        "published": "2021-10-27T17:29:37Z",
        "link": "http://arxiv.org/abs/2110.14609v1",
        "categories": [
            "math.OC",
            "cs.DC",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "ABIDES-Gym: Gym Environments for Multi-Agent Discrete Event Simulation   and Application to Financial Markets",
        "authors": [
            "Selim Amrouni",
            "Aymeric Moulin",
            "Jared Vann",
            "Svitlana Vyetrenko",
            "Tucker Balch",
            "Manuela Veloso"
        ],
        "summary": "Model-free Reinforcement Learning (RL) requires the ability to sample trajectories by taking actions in the original problem environment or a simulated version of it. Breakthroughs in the field of RL have been largely facilitated by the development of dedicated open source simulators with easy to use frameworks such as OpenAI Gym and its Atari environments. In this paper we propose to use the OpenAI Gym framework on discrete event time based Discrete Event Multi-Agent Simulation (DEMAS). We introduce a general technique to wrap a DEMAS simulator into the Gym framework. We expose the technique in detail and implement it using the simulator ABIDES as a base. We apply this work by specifically using the markets extension of ABIDES, ABIDES-Markets, and develop two benchmark financial markets OpenAI Gym environments for training daily investor and execution agents. As a result, these two environments describe classic financial problems with a complex interactive market behavior response to the experimental agent's action.",
        "published": "2021-10-27T21:05:08Z",
        "link": "http://arxiv.org/abs/2110.14771v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "q-fin.TR"
        ]
    },
    {
        "title": "Fair Incentives for Repeated Engagement",
        "authors": [
            "Daniel Freund",
            "Chamsi Hssaine"
        ],
        "summary": "We study a decision-maker's problem of finding optimal monetary incentive schemes for retention when faced with agents whose participation decisions (stochastically) depend on the incentive they receive. Our focus is on policies constrained to fulfill two fairness properties that preclude outcomes wherein different groups of agents experience different treatment on average. We formulate the problem as a high-dimensional stochastic optimization problem, and study it through the use of a closely related deterministic variant. We show that the optimal static solution to this deterministic variant is asymptotically optimal for the dynamic problem under fairness constraints. Though solving for the optimal static solution gives rise to a non-convex optimization problem, we uncover a structural property that allows us to design a tractable, fast-converging heuristic policy. Traditional schemes for retention ignore fairness constraints; indeed, the goal in these is to use differentiation to incentivize repeated engagement with the system. Our work (i) shows that even in the absence of explicit discrimination, dynamic policies may unintentionally discriminate between agents of different types by varying the type composition of the system, and (ii) presents an asymptotically optimal policy to avoid such discriminatory outcomes.",
        "published": "2021-10-28T04:13:53Z",
        "link": "http://arxiv.org/abs/2111.00002v3",
        "categories": [
            "cs.GT",
            "cs.LG",
            "cs.MA",
            "math.OC",
            "math.PR"
        ]
    },
    {
        "title": "Integrated Task Assignment and Path Planning for Capacitated Multi-Agent   Pickup and Delivery",
        "authors": [
            "Zhe Chen",
            "Javier Alonso-Mora",
            "Xiaoshan Bai",
            "Daniel D. Harabor",
            "Peter J. Stuckey"
        ],
        "summary": "Multi-agent Pickup and Delivery (MAPD) is a challenging industrial problem where a team of robots is tasked with transporting a set of tasks, each from an initial location and each to a specified target location. Appearing in the context of automated warehouse logistics and automated mail sortation, MAPD requires first deciding which robot is assigned what task (i.e., Task Assignment or TA) followed by a subsequent coordination problem where each robot must be assigned collision-free paths so as to successfully complete its assignment (i.e., Multi-Agent Path Finding or MAPF). Leading methods in this area solve MAPD sequentially: first assigning tasks, then assigning paths. In this work we propose a new coupled method where task assignment choices are informed by actual delivery costs instead of by lower-bound estimates. The main ingredients of our approach are a marginal-cost assignment heuristic and a meta-heuristic improvement strategy based on Large Neighbourhood Search. As a further contribution, we also consider a variant of the MAPD problem where each robot can carry multiple tasks instead of just one. Numerical simulations show that our approach yields efficient and timely solutions and we report significant improvement compared with other recent methods from the literature.",
        "published": "2021-10-28T05:08:30Z",
        "link": "http://arxiv.org/abs/2110.14891v1",
        "categories": [
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Decentralized Feature-Distributed Optimization for Generalized Linear   Models",
        "authors": [
            "Brighton Ancelin",
            "Sohail Bahmani",
            "Justin Romberg"
        ],
        "summary": "We consider the \"all-for-one\" decentralized learning problem for generalized linear models. The features of each sample are partitioned among several collaborating agents in a connected network, but only one agent observes the response variables. To solve the regularized empirical risk minimization in this distributed setting, we apply the Chambolle--Pock primal--dual algorithm to an equivalent saddle-point formulation of the problem. The primal and dual iterations are either in closed-form or reduce to coordinate-wise minimization of scalar convex functions. We establish convergence rates for the empirical risk minimization under two different assumptions on the loss function (Lipschitz and square root Lipschitz), and show how they depend on the characteristics of the design matrix and the Laplacian of the network.",
        "published": "2021-10-28T16:42:47Z",
        "link": "http://arxiv.org/abs/2110.15283v1",
        "categories": [
            "math.OC",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Learning to Ground Multi-Agent Communication with Autoencoders",
        "authors": [
            "Toru Lin",
            "Minyoung Huh",
            "Chris Stauffer",
            "Ser-Nam Lim",
            "Phillip Isola"
        ],
        "summary": "Communication requires having a common language, a lingua franca, between agents. This language could emerge via a consensus process, but it may require many generations of trial and error. Alternatively, the lingua franca can be given by the environment, where agents ground their language in representations of the observed world. We demonstrate a simple way to ground language in learned representations, which facilitates decentralized multi-agent communication and coordination. We find that a standard representation learning algorithm -- autoencoding -- is sufficient for arriving at a grounded common language. When agents broadcast these representations, they learn to understand and respond to each other's utterances and achieve surprisingly strong task performance across a variety of multi-agent communication environments.",
        "published": "2021-10-28T17:57:26Z",
        "link": "http://arxiv.org/abs/2110.15349v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.CL",
            "cs.MA"
        ]
    },
    {
        "title": "Mixed Cooperative-Competitive Communication Using Multi-Agent   Reinforcement Learning",
        "authors": [
            "Astrid Vanneste",
            "Wesley Van Wijnsberghe",
            "Simon Vanneste",
            "Kevin Mets",
            "Siegfried Mercelis",
            "Steven Latré",
            "Peter Hellinckx"
        ],
        "summary": "By using communication between multiple agents in multi-agent environments, one can reduce the effects of partial observability by combining one agent's observation with that of others in the same dynamic environment. While a lot of successful research has been done towards communication learning in cooperative settings, communication learning in mixed cooperative-competitive settings is also important and brings its own complexities such as the opposing team overhearing the communication. In this paper, we apply differentiable inter-agent learning (DIAL), designed for cooperative settings, to a mixed cooperative-competitive setting. We look at the difference in performance between communication that is private for a team and communication that can be overheard by the other team. Our research shows that communicating agents are able to achieve similar performance to fully observable agents after a given training period in our chosen environment. Overall, we find that sharing communication across teams results in decreased performance for the communicating team in comparison to results achieved with private communication.",
        "published": "2021-10-29T13:25:07Z",
        "link": "http://arxiv.org/abs/2110.15762v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Learning to Communicate with Reinforcement Learning for an Adaptive   Traffic Control System",
        "authors": [
            "Simon Vanneste",
            "Gauthier de Borrekens",
            "Stig Bosmans",
            "Astrid Vanneste",
            "Kevin Mets",
            "Siegfried Mercelis",
            "Steven Latré",
            "Peter Hellinckx"
        ],
        "summary": "Recent work in multi-agent reinforcement learning has investigated inter agent communication which is learned simultaneously with the action policy in order to improve the team reward. In this paper, we investigate independent Q-learning (IQL) without communication and differentiable inter-agent learning (DIAL) with learned communication on an adaptive traffic control system (ATCS). In real world ATCS, it is impossible to present the full state of the environment to every agent so in our simulation, the individual agents will only have a limited observation of the full state of the environment. The ATCS will be simulated using the Simulation of Urban MObility (SUMO) traffic simulator in which two connected intersections are simulated. Every intersection is controlled by an agent which has the ability to change the direction of the traffic flow. Our results show that a DIAL agent outperforms an independent Q-learner on both training time and on maximum achieved reward as it is able to share relevant information with the other agents.",
        "published": "2021-10-29T13:46:15Z",
        "link": "http://arxiv.org/abs/2110.15779v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Profit equitably: An investigation of market maker's impact on equitable   outcomes",
        "authors": [
            "Kshama Dwarakanath",
            "Svitlana S Vyetrenko",
            "Tucker Balch"
        ],
        "summary": "We look at discovering the impact of market microstructure on equitability for market participants at public exchanges such as the New York Stock Exchange or NASDAQ. Are these environments equitable venues for low-frequency participants (such as retail investors)? In particular, can market makers contribute to equitability for these agents? We use a simulator to assess the effect a market marker can have on equality of outcomes for consumer or retail traders by adjusting its parameters. Upon numerically quantifying market equitability by the entropy of the price returns distribution of consumer agents, we demonstrate that market makers indeed support equitability and that a negative correlation is observed between the profits of the market maker and equitability. We then use multi objective reinforcement learning to concurrently optimize for the two objectives of consumer agent equitability and market maker profitability, which leads us to learn policies that facilitate lower market volatility and tighter spreads for comparable profit levels.",
        "published": "2021-10-29T21:50:47Z",
        "link": "http://arxiv.org/abs/2111.00094v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Top-k Dynamic Service Composition in Skyway Networks",
        "authors": [
            "Babar Shahzaad",
            "Athman Bouguettaya"
        ],
        "summary": "We propose a novel top-k service composition framework for drone services under a dynamic environment. We develop a system model for formal modelling of drone services in a skyway network. The composition process is accomplished in two phases, i.e., computing top-k compositions and extending and ranking top-k compositions using probabilistic wait and recharge times under congestion conditions. We propose a top-k composition algorithm to compute the best service composition plan meeting user's requirements. A set of experiments with a real dataset is conducted to demonstrate the effectiveness of the proposed approach.",
        "published": "2021-10-30T20:43:52Z",
        "link": "http://arxiv.org/abs/2111.09153v1",
        "categories": [
            "cs.MA",
            "cs.DC"
        ]
    },
    {
        "title": "Decentralized Multi-Agent Reinforcement Learning: An Off-Policy Method",
        "authors": [
            "Kuo Li",
            "Qing-Shan Jia"
        ],
        "summary": "We discuss the problem of decentralized multi-agent reinforcement learning (MARL) in this work. In our setting, the global state, action, and reward are assumed to be fully observable, while the local policy is protected as privacy by each agent, and thus cannot be shared with others. There is a communication graph, among which the agents can exchange information with their neighbors. The agents make individual decisions and cooperate to reach a higher accumulated reward.   Towards this end, we first propose a decentralized actor-critic (AC) setting. Then, the policy evaluation and policy improvement algorithms are designed for discrete and continuous state-action-space Markov Decision Process (MDP) respectively. Furthermore, convergence analysis is given under the discrete-space case, which guarantees that the policy will be reinforced by alternating between the processes of policy evaluation and policy improvement. In order to validate the effectiveness of algorithms, we design experiments and compare them with previous algorithms, e.g., Q-learning \\cite{watkins1992q} and MADDPG \\cite{lowe2017multi}. The results show that our algorithms perform better from the aspects of both learning speed and final performance. Moreover, the algorithms can be executed in an off-policy manner, which greatly improves the data efficiency compared with on-policy algorithms.",
        "published": "2021-10-31T09:08:46Z",
        "link": "http://arxiv.org/abs/2111.00438v1",
        "categories": [
            "cs.MA",
            "cs.LG"
        ]
    },
    {
        "title": "Bayesian optimization of distributed neurodynamical controller models   for spatial navigation",
        "authors": [
            "Armin Hadzic",
            "Grace M. Hwang",
            "Kechen Zhang",
            "Kevin M. Schultz",
            "Joseph D. Monaco"
        ],
        "summary": "Dynamical systems models for controlling multi-agent swarms have demonstrated advances toward resilient, decentralized navigation algorithms. We previously introduced the NeuroSwarms controller, in which agent-based interactions were modeled by analogy to neuronal network interactions, including attractor dynamics and phase synchrony, that have been theorized to operate within hippocampal place-cell circuits in navigating rodents. This complexity precludes linear analyses of stability, controllability, and performance typically used to study conventional swarm models. Further, tuning dynamical controllers by hand or grid search is often inadequate due to the complexity of objectives, dimensionality of model parameters, and computational costs of simulation-based sampling. Here, we present a framework for tuning dynamical controller models of autonomous multi-agent systems based on Bayesian Optimization (BayesOpt). Our approach utilizes a task-dependent objective function to train Gaussian Processes (GPs) as surrogate models to achieve adaptive and efficient exploration of a dynamical controller model's parameter space. We demonstrate this approach by studying an objective function selecting for NeuroSwarms behaviors that cooperatively localize and capture spatially distributed rewards under time pressure. We generalized task performance across environments by combining scores for simulations in distinct geometries. To validate search performance, we compared high-dimensional clustering for high- vs. low-likelihood parameter points by visualizing sample trajectories in Uniform Manifold Approximation and Projection (UMAP) embeddings. Our findings show that adaptive, sample-efficient evaluation of the self-organizing behavioral capacities of complex systems, including dynamical swarm controllers, can accelerate the translation of neuroscientific theory to applied domains.",
        "published": "2021-10-31T21:43:06Z",
        "link": "http://arxiv.org/abs/2111.00599v1",
        "categories": [
            "cs.MA",
            "cs.LG",
            "cs.NE",
            "q-bio.NC",
            "q-bio.QM"
        ]
    },
    {
        "title": "Decentralized Cooperative Reinforcement Learning with Hierarchical   Information Structure",
        "authors": [
            "Hsu Kao",
            "Chen-Yu Wei",
            "Vijay Subramanian"
        ],
        "summary": "Multi-agent reinforcement learning (MARL) problems are challenging due to information asymmetry. To overcome this challenge, existing methods often require high level of coordination or communication between the agents. We consider two-agent multi-armed bandits (MABs) and Markov decision processes (MDPs) with a hierarchical information structure arising in applications, which we exploit to propose simpler and more efficient algorithms that require no coordination or communication. In the structure, in each step the ``leader\" chooses her action first, and then the ``follower\" decides his action after observing the leader's action. The two agents observe the same reward (and the same state transition in the MDP setting) that depends on their joint action. For the bandit setting, we propose a hierarchical bandit algorithm that achieves a near-optimal gap-independent regret of $\\widetilde{\\mathcal{O}}(\\sqrt{ABT})$ and a near-optimal gap-dependent regret of $\\mathcal{O}(\\log(T))$, where $A$ and $B$ are the numbers of actions of the leader and the follower, respectively, and $T$ is the number of steps. We further extend to the case of multiple followers and the case with a deep hierarchy, where we both obtain near-optimal regret bounds. For the MDP setting, we obtain $\\widetilde{\\mathcal{O}}(\\sqrt{H^7S^2ABT})$ regret, where $H$ is the number of steps per episode, $S$ is the number of states, $T$ is the number of episodes. This matches the existing lower bound in terms of $A, B$, and $T$.",
        "published": "2021-11-01T09:18:07Z",
        "link": "http://arxiv.org/abs/2111.00781v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "Investigation of Independent Reinforcement Learning Algorithms in   Multi-Agent Environments",
        "authors": [
            "Ken Ming Lee",
            "Sriram Ganapathi Subramanian",
            "Mark Crowley"
        ],
        "summary": "Independent reinforcement learning algorithms have no theoretical guarantees for finding the best policy in multi-agent settings. However, in practice, prior works have reported good performance with independent algorithms in some domains and bad performance in others. Moreover, a comprehensive study of the strengths and weaknesses of independent algorithms is lacking in the literature. In this paper, we carry out an empirical comparison of the performance of independent algorithms on four PettingZoo environments that span the three main categories of multi-agent environments, i.e., cooperative, competitive, and mixed. We show that in fully-observable environments, independent algorithms can perform on par with multi-agent algorithms in cooperative and competitive settings. For the mixed environments, we show that agents trained via independent algorithms learn to perform well individually, but fail to learn to cooperate with allies and compete with enemies. We also show that adding recurrence improves the learning of independent algorithms in cooperative partially observable environments.",
        "published": "2021-11-01T17:14:38Z",
        "link": "http://arxiv.org/abs/2111.01100v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "ArchABM: an agent-based simulator of human interaction with the built   environment. $CO_2$ and viral load analysis for indoor air quality",
        "authors": [
            "Iñigo Martinez",
            "Jan L. Bruse",
            "Ane M. Florez-Tapia",
            "Elisabeth Viles",
            "Igor G. Olaizola"
        ],
        "summary": "Recent evidence suggests that SARS-CoV-2, which is the virus causing a global pandemic in 2020, is predominantly transmitted via airborne aerosols in indoor environments. This calls for novel strategies when assessing and controlling a building's indoor air quality (IAQ). IAQ can generally be controlled by ventilation and/or policies to regulate human-building-interaction. However, in a building, occupants use rooms in different ways, and it may not be obvious which measure or combination of measures leads to a cost- and energy-effective solution ensuring good IAQ across the entire building. Therefore, in this article, we introduce a novel agent-based simulator, ArchABM, designed to assist in creating new or adapt existing buildings by estimating adequate room sizes, ventilation parameters and testing the effect of policies while taking into account IAQ as a result of complex human-building interaction patterns. A recently published aerosol model was adapted to calculate time-dependent carbon dioxide ($CO_2$) and virus quanta concentrations in each room and inhaled $CO_2$ and virus quanta for each occupant over a day as a measure of physiological response. ArchABM is flexible regarding the aerosol model and the building layout due to its modular architecture, which allows implementing further models, any number and size of rooms, agents, and actions reflecting human-building interaction patterns. We present a use case based on a real floor plan and working schedules adopted in our research center. This study demonstrates how advanced simulation tools can contribute to improving IAQ across a building, thereby ensuring a healthy indoor environment.",
        "published": "2021-11-02T10:38:29Z",
        "link": "http://arxiv.org/abs/2111.01484v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.CY"
        ]
    },
    {
        "title": "Strategyproof and Proportionally Fair Facility Location",
        "authors": [
            "Haris Aziz",
            "Alexander Lam",
            "Barton E. Lee",
            "Toby Walsh"
        ],
        "summary": "We focus on a simple, one-dimensional collective decision problem (often referred to as the facility location problem) and explore issues of strategyproofness and proportionality-based fairness. We introduce and analyze a hierarchy of proportionality-based fairness axioms of varying strength: Individual Fair Share (IFS), Unanimous Fair Share (UFS), Proportionality (as in Freeman et al, 2021), and Proportional Fairness (PF). For each axiom, we characterize the family of mechanisms that satisfy the axiom and strategyproofness. We show that imposing strategyproofness renders many of the axioms to be equivalent: the family of mechanisms that satisfy proportionality, unanimity, and strategyproofness is equivalent to the family of mechanisms that satisfy UFS and strategyproofness, which, in turn, is equivalent to the family of mechanisms that satisfy PF and strategyproofness. Furthermore, there is a unique such mechanism: the Uniform Phantom mechanism, which is studied in Freeman et al. (2021). We also characterize the outcomes of the Uniform Phantom mechanism as the unique (pure) equilibrium outcome for any mechanism that satisfies continuity, strict monotonicity, and UFS. Finally, we analyze the approximation guarantees, in terms of optimal social welfare and minimum total cost, obtained by mechanisms that are strategyproof and satisfy each proportionality-based fairness axiom. We show that the Uniform Phantom mechanism provides the best approximation of the optimal social welfare (and also minimum total cost) among all mechanisms that satisfy UFS.",
        "published": "2021-11-02T12:41:32Z",
        "link": "http://arxiv.org/abs/2111.01566v3",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.MA",
            "econ.TH"
        ]
    },
    {
        "title": "Execution Order Matters in Greedy Algorithms with Limited Information",
        "authors": [
            "Rohit Konda",
            "David Grimsman",
            "Jason Marden"
        ],
        "summary": "In this work, we study the multi-agent decision problem where agents try to coordinate to optimize a given system-level objective. While solving for the global optimal is intractable in many cases, the greedy algorithm is a well-studied and efficient way to provide good approximate solutions - notably for submodular optimization problems. Executing the greedy algorithm requires the agents to be ordered and execute a local optimization based on the solutions of the previous agents. However, in limited information settings, passing the solution from the previous agents may be nontrivial, as some agents may not be able to directly communicate with each other. Thus the communication time required to execute the greedy algorithm is closely tied to the order that the agents are given. In this work, we characterize interplay between the communication complexity and agent orderings by showing that the complexity using the best ordering is O(n) and increases considerably to O(n^2) when using the worst ordering. Motivated by this, we also propose an algorithm that can find an ordering and execute the greedy algorithm quickly, in a distributed fashion. We also show that such an execution of the greedy algorithm is advantageous over current methods for distributed submodular maximization.",
        "published": "2021-11-02T17:39:52Z",
        "link": "http://arxiv.org/abs/2111.09154v3",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "A Framework for Real-World Multi-Robot Systems Running Decentralized   GNN-Based Policies",
        "authors": [
            "Jan Blumenkamp",
            "Steven Morad",
            "Jennifer Gielis",
            "Qingbiao Li",
            "Amanda Prorok"
        ],
        "summary": "GNNs are a paradigm-shifting neural architecture to facilitate the learning of complex multi-agent behaviors. Recent work has demonstrated remarkable performance in tasks such as flocking, multi-agent path planning and cooperative coverage. However, the policies derived through GNN-based learning schemes have not yet been deployed to the real-world on physical multi-robot systems. In this work, we present the design of a system that allows for fully decentralized execution of GNN-based policies. We create a framework based on ROS2 and elaborate its details in this paper. We demonstrate our framework on a case-study that requires tight coordination between robots, and present first-of-a-kind results that show successful real-world deployment of GNN-based policies on a decentralized multi-robot system relying on Adhoc communication. A video demonstration of this case-study, as well as the accompanying source code repository, can be found online. https://www.youtube.com/watch?v=COh-WLn4iO4 https://github.com/proroklab/ros2_multi_agent_passage https://github.com/proroklab/rl_multi_agent_passage",
        "published": "2021-11-02T17:53:54Z",
        "link": "http://arxiv.org/abs/2111.01777v2",
        "categories": [
            "cs.RO",
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Obvious Manipulability of Voting Rules",
        "authors": [
            "Haris Aziz",
            "Alexander Lam"
        ],
        "summary": "The Gibbard-Satterthwaite theorem states that no unanimous and non-dictatorial voting rule is strategyproof. We revisit voting rules and consider a weaker notion of strategyproofness called not obvious manipulability that was proposed by Troyan and Morrill (2020). We identify several classes of voting rules that satisfy this notion. We also show that several voting rules including k-approval fail to satisfy this property. We characterize conditions under which voting rules are obviously manipulable. One of our insights is that certain rules are obviously manipulable when the number of alternatives is relatively large compared to the number of voters. In contrast to the Gibbard-Satterthwaite theorem, many of the rules we examined are not obviously manipulable. This reflects the relatively easier satisfiability of the notion and the zero information assumption of not obvious manipulability, as opposed to the perfect information assumption of strategyproofness. We also present algorithmic results for computing obvious manipulations and report on experiments.",
        "published": "2021-11-03T02:41:48Z",
        "link": "http://arxiv.org/abs/2111.01983v3",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.MA",
            "econ.TH"
        ]
    },
    {
        "title": "Online Learning in Periodic Zero-Sum Games",
        "authors": [
            "Tanner Fiez",
            "Ryann Sim",
            "Stratis Skoulakis",
            "Georgios Piliouras",
            "Lillian Ratliff"
        ],
        "summary": "A seminal result in game theory is von Neumann's minmax theorem, which states that zero-sum games admit an essentially unique equilibrium solution. Classical learning results build on this theorem to show that online no-regret dynamics converge to an equilibrium in a time-average sense in zero-sum games. In the past several years, a key research direction has focused on characterizing the day-to-day behavior of such dynamics. General results in this direction show that broad classes of online learning dynamics are cyclic, and formally Poincar\\'{e} recurrent, in zero-sum games. We analyze the robustness of these online learning behaviors in the case of periodic zero-sum games with a time-invariant equilibrium. This model generalizes the usual repeated game formulation while also being a realistic and natural model of a repeated competition between players that depends on exogenous environmental variations such as time-of-day effects, week-to-week trends, and seasonality. Interestingly, time-average convergence may fail even in the simplest such settings, in spite of the equilibrium being fixed. In contrast, using novel analysis methods, we show that Poincar\\'{e} recurrence provably generalizes despite the complex, non-autonomous nature of these dynamical systems.",
        "published": "2021-11-05T10:36:16Z",
        "link": "http://arxiv.org/abs/2111.03377v1",
        "categories": [
            "cs.GT",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Learning to Cooperate with Unseen Agent via Meta-Reinforcement Learning",
        "authors": [
            "Rujikorn Charakorn",
            "Poramate Manoonpong",
            "Nat Dilokthanakul"
        ],
        "summary": "Ad hoc teamwork problem describes situations where an agent has to cooperate with previously unseen agents to achieve a common goal. For an agent to be successful in these scenarios, it has to have a suitable cooperative skill. One could implement cooperative skills into an agent by using domain knowledge to design the agent's behavior. However, in complex domains, domain knowledge might not be available. Therefore, it is worthwhile to explore how to directly learn cooperative skills from data. In this work, we apply meta-reinforcement learning (meta-RL) formulation in the context of the ad hoc teamwork problem. Our empirical results show that such a method could produce robust cooperative agents in two cooperative environments with different cooperative circumstances: social compliance and language interpretation. (This is a full paper of the extended abstract version.)",
        "published": "2021-11-05T12:01:28Z",
        "link": "http://arxiv.org/abs/2111.03431v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Learning equilibria with personalized incentives in a class of   nonmonotone games",
        "authors": [
            "Filippo Fabiani",
            "Andrea Simonetto",
            "Paul J. Goulart"
        ],
        "summary": "We consider quadratic, nonmonotone generalized Nash equilibrium problems with symmetric interactions among the agents. Albeit this class of games is known to admit a potential function, its formal expression can be unavailable in several real-world applications. For this reason, we propose a two-layer Nash equilibrium seeking scheme in which a central coordinator exploits noisy feedback from the agents to design personalized incentives for them. By making use of those incentives, the agents compute a solution to an extended game, and then return feedback measures to the coordinator. We show that our algorithm returns an equilibrium if the coordinator is endowed with standard learning policies, and corroborate our results on a numerical instance of a hypomonotone game.",
        "published": "2021-11-06T11:18:59Z",
        "link": "http://arxiv.org/abs/2111.03854v2",
        "categories": [
            "math.OC",
            "cs.GT",
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Meta Cross-Modal Hashing on Long-Tailed Data",
        "authors": [
            "Runmin Wang",
            "Guoxian Yu",
            "Carlotta Domeniconi",
            "Xiangliang Zhang"
        ],
        "summary": "Due to the advantage of reducing storage while speeding up query time on big heterogeneous data, cross-modal hashing has been extensively studied for approximate nearest neighbor search of multi-modal data. Most hashing methods assume that training data is class-balanced.However, in practice, real world data often have a long-tailed distribution. In this paper, we introduce a meta-learning based cross-modal hashing method (MetaCMH) to handle long-tailed data. Due to the lack of training samples in the tail classes, MetaCMH first learns direct features from data in different modalities, and then introduces an associative memory module to learn the memory features of samples of the tail classes. It then combines the direct and memory features to obtain meta features for each sample. For samples of the head classes of the long tail distribution, the weight of the direct features is larger, because there are enough training data to learn them well; while for rare classes, the weight of the memory features is larger. Finally, MetaCMH uses a likelihood loss function to preserve the similarity in different modalities and learns hash functions in an end-to-end fashion. Experiments on long-tailed datasets show that MetaCMH performs significantly better than state-of-the-art methods, especially on the tail classes.",
        "published": "2021-11-07T13:31:16Z",
        "link": "http://arxiv.org/abs/2111.04086v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.DB",
            "cs.MA"
        ]
    },
    {
        "title": "Trust-aware Control for Intelligent Transportation Systems",
        "authors": [
            "Mingxi Cheng",
            "Junyao Zhang",
            "Shahin Nazarian",
            "Jyotirmoy Deshmukh",
            "Paul Bogdan"
        ],
        "summary": "Many intelligent transportation systems are multi-agent systems, i.e., both the traffic participants and the subsystems within the transportation infrastructure can be modeled as interacting agents. The use of AI-based methods to achieve coordination among the different agents systems can provide greater safety over transportation systems containing only human-operated vehicles, and also improve the system efficiency in terms of traffic throughput, sensing range, and enabling collaborative tasks. However, increased autonomy makes the transportation infrastructure vulnerable to compromised vehicular agents or infrastructure. This paper proposes a new framework by embedding the trust authority into transportation infrastructure to systematically quantify the trustworthiness of agents using an epistemic logic known as subjective logic. In this paper, we make the following novel contributions: (i) We propose a framework for using the quantified trustworthiness of agents to enable trust-aware coordination and control. (ii) We demonstrate how to synthesize trust-aware controllers using an approach based on reinforcement learning. (iii) We comprehensively analyze an autonomous intersection management (AIM) case study and develop a trust-aware version called AIM-Trust that leads to lower accident rates in scenarios consisting of a mixture of trusted and untrusted agents.",
        "published": "2021-11-08T03:02:25Z",
        "link": "http://arxiv.org/abs/2111.04248v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Variational Automatic Curriculum Learning for Sparse-Reward Cooperative   Multi-Agent Problems",
        "authors": [
            "Jiayu Chen",
            "Yuanxin Zhang",
            "Yuanfan Xu",
            "Huimin Ma",
            "Huazhong Yang",
            "Jiaming Song",
            "Yu Wang",
            "Yi Wu"
        ],
        "summary": "We introduce a curriculum learning algorithm, Variational Automatic Curriculum Learning (VACL), for solving challenging goal-conditioned cooperative multi-agent reinforcement learning problems. We motivate our paradigm through a variational perspective, where the learning objective can be decomposed into two terms: task learning on the current task distribution, and curriculum update to a new task distribution. Local optimization over the second term suggests that the curriculum should gradually expand the training tasks from easy to hard. Our VACL algorithm implements this variational paradigm with two practical components, task expansion and entity progression, which produces training curricula over both the task configurations as well as the number of entities in the task. Experiment results show that VACL solves a collection of sparse-reward problems with a large number of agents. Particularly, using a single desktop machine, VACL achieves 98% coverage rate with 100 agents in the simple-spread benchmark and reproduces the ramp-use behavior originally shown in OpenAI's hide-and-seek project. Our project website is at https://sites.google.com/view/vacl-neurips-2021.",
        "published": "2021-11-08T16:35:08Z",
        "link": "http://arxiv.org/abs/2111.04613v2",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Reinforcement Learning for Mixed Autonomy Intersections",
        "authors": [
            "Zhongxia Yan",
            "Cathy Wu"
        ],
        "summary": "We propose a model-free reinforcement learning method for controlling mixed autonomy traffic in simulated traffic networks with through-traffic-only two-way and four-way intersections. Our method utilizes multi-agent policy decomposition which allows decentralized control based on local observations for an arbitrary number of controlled vehicles. We demonstrate that, even without reward shaping, reinforcement learning learns to coordinate the vehicles to exhibit traffic signal-like behaviors, achieving near-optimal throughput with 33-50% controlled vehicles. With the help of multi-task learning and transfer learning, we show that this behavior generalizes across inflow rates and size of the traffic network. Our code, models, and videos of results are available at https://github.com/ZhongxiaYan/mixed_autonomy_intersections.",
        "published": "2021-11-08T18:03:18Z",
        "link": "http://arxiv.org/abs/2111.04686v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Cutting a Cake Is Not Always a 'Piece of Cake': A Closer Look at the   Foundations of Cake-Cutting Through the Lens of Measure Theory",
        "authors": [
            "Peter Kern",
            "Daniel Neugebauer",
            "Jörg Rothe",
            "René L. Schilling",
            "Dietrich Stoyan",
            "Robin Weishaupt"
        ],
        "summary": "Cake-cutting is a playful name for the fair division of a heterogeneous, divisible good among agents, a well-studied problem at the intersection of mathematics, economics, and artificial intelligence. The cake-cutting literature is rich and edifying. However, different model assumptions are made in its many papers, in particular regarding the set of allowed pieces of cake that are to be distributed among the agents and regarding the agents' valuation functions by which they measure these pieces. We survey the commonly used definitions in the cake-cutting literature, highlight their strengths and weaknesses, and make some recommendations on what definitions could be most reasonably used when looking through the lens of measure theory.",
        "published": "2021-11-09T20:18:41Z",
        "link": "http://arxiv.org/abs/2111.05402v2",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Uncoupled Bandit Learning towards Rationalizability: Benchmarks,   Barriers, and Algorithms",
        "authors": [
            "Jibang Wu",
            "Haifeng Xu",
            "Fan Yao"
        ],
        "summary": "Under the uncoupled learning setup, the last-iterate convergence guarantee towards Nash equilibrium is shown to be impossible in many games. This work studies the last-iterate convergence guarantee in general games toward rationalizability, a key solution concept in epistemic game theory that relaxes the stringent belief assumptions in both Nash and correlated equilibrium. This learning task naturally generalizes best arm identification problems, due to the intrinsic connections between rationalizable action profiles and the elimination of iteratively dominated actions. Despite a seemingly simple task, our first main result is a surprisingly negative one; that is, a large and natural class of no regret algorithms, including the entire family of Dual Averaging algorithms, provably take exponentially many rounds to reach rationalizability. Moreover, algorithms with the stronger no swap regret also suffer similar exponential inefficiency. To overcome these barriers, we develop a new algorithm that adjusts Exp3 with Diminishing Historical rewards (termed Exp3-DH); Exp3-DH gradually forgets history at carefully tailored rates. We prove that when all agents run Exp3-DH (a.k.a., self-play in multi-agent learning), all iteratively dominated actions can be eliminated within polynomially many rounds. Our experimental results further demonstrate the efficiency of Exp3-DH, and that state-of-the-art bandit algorithms, even those developed specifically for learning in games, fail to reach rationalizability efficiently.",
        "published": "2021-11-10T02:10:07Z",
        "link": "http://arxiv.org/abs/2111.05486v3",
        "categories": [
            "cs.GT",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "DeCOM: Decomposed Policy for Constrained Cooperative Multi-Agent   Reinforcement Learning",
        "authors": [
            "Zhaoxing Yang",
            "Rong Ding",
            "Haiming Jin",
            "Yifei Wei",
            "Haoyi You",
            "Guiyun Fan",
            "Xiaoying Gan",
            "Xinbing Wang"
        ],
        "summary": "In recent years, multi-agent reinforcement learning (MARL) has presented impressive performance in various applications. However, physical limitations, budget restrictions, and many other factors usually impose \\textit{constraints} on a multi-agent system (MAS), which cannot be handled by traditional MARL frameworks. Specifically, this paper focuses on constrained MASes where agents work \\textit{cooperatively} to maximize the expected team-average return under various constraints on expected team-average costs, and develops a \\textit{constrained cooperative MARL} framework, named DeCOM, for such MASes. In particular, DeCOM decomposes the policy of each agent into two modules, which empowers information sharing among agents to achieve better cooperation. In addition, with such modularization, the training algorithm of DeCOM separates the original constrained optimization into an unconstrained optimization on reward and a constraints satisfaction problem on costs. DeCOM then iteratively solves these problems in a computationally efficient manner, which makes DeCOM highly scalable. We also provide theoretical guarantees on the convergence of DeCOM's policy update algorithm. Finally, we validate the effectiveness of DeCOM with various types of costs in both toy and large-scale (with 500 agents) environments.",
        "published": "2021-11-10T12:31:30Z",
        "link": "http://arxiv.org/abs/2111.05670v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "PowerGridworld: A Framework for Multi-Agent Reinforcement Learning in   Power Systems",
        "authors": [
            "David Biagioni",
            "Xiangyu Zhang",
            "Dylan Wald",
            "Deepthi Vaidhynathan",
            "Rohit Chintala",
            "Jennifer King",
            "Ahmed S. Zamzam"
        ],
        "summary": "We present the PowerGridworld software package to provide users with a lightweight, modular, and customizable framework for creating power-systems-focused, multi-agent Gym environments that readily integrate with existing training frameworks for reinforcement learning (RL). Although many frameworks exist for training multi-agent RL (MARL) policies, none can rapidly prototype and develop the environments themselves, especially in the context of heterogeneous (composite, multi-device) power systems where power flow solutions are required to define grid-level variables and costs. PowerGridworld is an open-source software package that helps to fill this gap. To highlight PowerGridworld's key features, we present two case studies and demonstrate learning MARL policies using both OpenAI's multi-agent deep deterministic policy gradient (MADDPG) and RLLib's proximal policy optimization (PPO) algorithms. In both cases, at least some subset of agents incorporates elements of the power flow solution at each time step as part of their reward (negative cost) structures.",
        "published": "2021-11-10T22:22:07Z",
        "link": "http://arxiv.org/abs/2111.05969v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Multi-agent Reinforcement Learning for Cooperative Lane Changing of   Connected and Autonomous Vehicles in Mixed Traffic",
        "authors": [
            "Wei Zhou",
            "Dong Chen",
            "Jun Yan",
            "Zhaojian Li",
            "Huilin Yin",
            "Wanchen Ge"
        ],
        "summary": "Autonomous driving has attracted significant research interests in the past two decades as it offers many potential benefits, including releasing drivers from exhausting driving and mitigating traffic congestion, among others. Despite promising progress, lane-changing remains a great challenge for autonomous vehicles (AV), especially in mixed and dynamic traffic scenarios. Recently, reinforcement learning (RL), a powerful data-driven control method, has been widely explored for lane-changing decision makings in AVs with encouraging results demonstrated. However, the majority of those studies are focused on a single-vehicle setting, and lane-changing in the context of multiple AVs coexisting with human-driven vehicles (HDVs) have received scarce attention. In this paper, we formulate the lane-changing decision making of multiple AVs in a mixed-traffic highway environment as a multi-agent reinforcement learning (MARL) problem, where each AV makes lane-changing decisions based on the motions of both neighboring AVs and HDVs. Specifically, a multi-agent advantage actor-critic network (MA2C) is developed with a novel local reward design and a parameter sharing scheme. In particular, a multi-objective reward function is proposed to incorporate fuel efficiency, driving comfort, and safety of autonomous driving. Comprehensive experimental results, conducted under three different traffic densities and various levels of human driver aggressiveness, show that our proposed MARL framework consistently outperforms several state-of-the-art benchmarks in terms of efficiency, safety and driver comfort.",
        "published": "2021-11-11T17:17:24Z",
        "link": "http://arxiv.org/abs/2111.06318v2",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "DPLL(MAPF): an Integration of Multi-Agent Path Finding and SAT Solving   Technologies",
        "authors": [
            "Martin Čapek",
            "Pavel Surynek"
        ],
        "summary": "In multi-agent path finding (MAPF), the task is to find non-conflicting paths for multiple agents from their initial positions to given individual goal positions. MAPF represents a classical artificial intelligence problem often addressed by heuristic-search. An important alternative to search-based techniques is compilation of MAPF to a different formalism such as Boolean satisfiability (SAT). Contemporary SAT-based approaches to MAPF regard the SAT solver as an external tool whose task is to return an assignment of all decision variables of a Boolean model of input MAPF. We present in this short paper a novel compilation scheme called DPLL(MAPF) in which the consistency checking of partial assignments of decision variables with respect to the MAPF rules is integrated directly into the SAT solver. This scheme allows for far more automated compilation where the SAT solver and the consistency checking procedure work together simultaneously to create the Boolean model and to search for its satisfying assignment.",
        "published": "2021-11-11T23:06:00Z",
        "link": "http://arxiv.org/abs/2111.06494v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Collaboration Promotes Group Resilience in Multi-Agent AI",
        "authors": [
            "Sarah Keren",
            "Matthias Gerstgrasser",
            "Ofir Abu",
            "Jeffrey Rosenschein"
        ],
        "summary": "AI agents need to be robust to unexpected changes in their environment in order to safely operate in real-world scenarios. While some work has been done on this type of robustness in the single-agent case, in this work we introduce the idea that collaboration with other agents can help agents adapt to environment perturbations in multi-agent reinforcement learning settings. We first formalize this notion of resilience of a group of agents. We then empirically evaluate different collaboration protocols and examine their effect on resilience. We see that all of the collaboration approaches considered lead to greater resilience compared to baseline, in line with our hypothesis. We discuss future direction and the general relevance of the concept of resilience introduced in this work.",
        "published": "2021-11-12T09:03:19Z",
        "link": "http://arxiv.org/abs/2111.06614v2",
        "categories": [
            "cs.LG",
            "cs.MA",
            "I.2.11, I.2.6"
        ]
    },
    {
        "title": "Posetal Games: Efficiency, Existence, and Refinement of Equilibria in   Games with Prioritized Metrics",
        "authors": [
            "Alessandro Zanardi",
            "Gioele Zardini",
            "Sirish Srinivasan",
            "Saverio Bolognani",
            "Andrea Censi",
            "Florian Dörfler",
            "Emilio Frazzoli"
        ],
        "summary": "Modern applications require robots to comply with multiple, often conflicting rules and to interact with the other agents. We present Posetal Games as a class of games in which each player expresses a preference over the outcomes via a partially ordered set of metrics. This allows one to combine hierarchical priorities of each player with the interactive nature of the environment. By contextualizing standard game theoretical notions, we provide two sufficient conditions on the preference of the players to prove existence of pure Nash Equilibria in finite action sets. Moreover, we define formal operations on the preference structures and link them to a refinement of the game solutions, showing how the set of equilibria can be systematically shrunk. The presented results are showcased in a driving game where autonomous vehicles select from a finite set of trajectories. The results demonstrate the interpretability of results in terms of minimum-rank-violation for each player.",
        "published": "2021-11-13T11:48:11Z",
        "link": "http://arxiv.org/abs/2111.07099v1",
        "categories": [
            "cs.MA",
            "cs.RO",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "What Should We Optimize in Participatory Budgeting? An Experimental   Study",
        "authors": [
            "Ariel Rosenfeld",
            "Nimrod Talmon"
        ],
        "summary": "Participatory Budgeting (PB) is a process in which voters decide how to allocate a common budget; most commonly it is done by ordinary people -- in particular, residents of some municipality -- to decide on a fraction of the municipal budget. From a social choice perspective, existing research on PB focuses almost exclusively on designing computationally-efficient aggregation methods that satisfy certain axiomatic properties deemed \"desirable\" by the research community. Our work complements this line of research through a user study (N = 215) involving several experiments aimed at identifying what potential voters (i.e., non-experts) deem fair or desirable in simple PB settings. Our results show that some modern PB aggregation techniques greatly differ from users' expectations, while other, more standard approaches, provide more aligned results. We also identify a few possible discrepancies between what non-experts consider \\say{desirable} and how they perceive the notion of \"fairness\" in the PB context. Taken jointly, our results can be used to help the research community identify appropriate PB aggregation methods to use in practice.",
        "published": "2021-11-14T10:46:03Z",
        "link": "http://arxiv.org/abs/2111.07308v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.GT"
        ]
    },
    {
        "title": "Relative Distributed Formation and Obstacle Avoidance with Multi-agent   Reinforcement Learning",
        "authors": [
            "Yuzi Yan",
            "Xiaoxiang Li",
            "Xinyou Qiu",
            "Jiantao Qiu",
            "Jian Wang",
            "Yu Wang",
            "Yuan Shen"
        ],
        "summary": "Multi-agent formation as well as obstacle avoidance is one of the most actively studied topics in the field of multi-agent systems. Although some classic controllers like model predictive control (MPC) and fuzzy control achieve a certain measure of success, most of them require precise global information which is not accessible in harsh environments. On the other hand, some reinforcement learning (RL) based approaches adopt the leader-follower structure to organize different agents' behaviors, which sacrifices the collaboration between agents thus suffering from bottlenecks in maneuverability and robustness. In this paper, we propose a distributed formation and obstacle avoidance method based on multi-agent reinforcement learning (MARL). Agents in our system only utilize local and relative information to make decisions and control themselves distributively. Agent in the multi-agent system will reorganize themselves into a new topology quickly in case that any of them is disconnected. Our method achieves better performance regarding formation error, formation convergence rate and on-par success rate of obstacle avoidance compared with baselines (both classic control methods and another RL-based method). The feasibility of our method is verified by both simulation and hardware implementation with Ackermann-steering vehicles.",
        "published": "2021-11-14T13:02:45Z",
        "link": "http://arxiv.org/abs/2111.07334v1",
        "categories": [
            "eess.SY",
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "cs.RO",
            "cs.SY"
        ]
    },
    {
        "title": "A distributed, plug-n-play algorithm for multi-robot applications with a   priori non-computable objective functions",
        "authors": [
            "Athanasios Ch. Kapoutsis",
            "Savvas A. Chatzichristofis",
            "Elias B. Kosmatopoulos"
        ],
        "summary": "This paper presents a distributed algorithm applicable to a wide range of practical multi-robot applications. In such multi-robot applications, the user-defined objectives of the mission can be cast as a general optimization problem, without explicit guidelines of the subtasks per different robot. Owing to the unknown environment, unknown robot dynamics, sensor nonlinearities, etc., the analytic form of the optimization cost function is not available a priori. Therefore, standard gradient-descent-like algorithms are not applicable to these problems. To tackle this, we introduce a new algorithm that carefully designs each robot's subcost function, the optimization of which can accomplish the overall team objective. Upon this transformation, we propose a distributed methodology based on the cognitive-based adaptive optimization (CAO) algorithm, that is able to approximate the evolution of each robot's cost function and to adequately optimize its decision variables (robot actions). The latter can be achieved by online learning only the problem-specific characteristics that affect the accomplishment of mission objectives. The overall, low-complexity algorithm can straightforwardly incorporate any kind of operational constraint, is fault-tolerant, and can appropriately tackle time-varying cost functions. A cornerstone of this approach is that it shares the same convergence characteristics as those of block coordinate descent algorithms. The proposed algorithm is evaluated in three heterogeneous simulation set-ups under multiple scenarios, against both general-purpose and problem-specific algorithms. Source code is available at https://github.com/athakapo/A-distributed-plug-n-play-algorithm-for-multi-robot-applications.",
        "published": "2021-11-14T20:40:00Z",
        "link": "http://arxiv.org/abs/2111.07441v2",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Learning Equilibria in Mean-Field Games: Introducing Mean-Field PSRO",
        "authors": [
            "Paul Muller",
            "Mark Rowland",
            "Romuald Elie",
            "Georgios Piliouras",
            "Julien Perolat",
            "Mathieu Lauriere",
            "Raphael Marinier",
            "Olivier Pietquin",
            "Karl Tuyls"
        ],
        "summary": "Recent advances in multiagent learning have seen the introduction ofa family of algorithms that revolve around the population-based trainingmethod PSRO, showing convergence to Nash, correlated and coarse corre-lated equilibria. Notably, when the number of agents increases, learningbest-responses becomes exponentially more difficult, and as such ham-pers PSRO training methods. The paradigm of mean-field games pro-vides an asymptotic solution to this problem when the considered gamesare anonymous-symmetric. Unfortunately, the mean-field approximationintroduces non-linearities which prevent a straightforward adaptation ofPSRO. Building upon optimization and adversarial regret minimization,this paper sidesteps this issue and introduces mean-field PSRO, an adap-tation of PSRO which learns Nash, coarse correlated and correlated equi-libria in mean-field games. The key is to replace the exact distributioncomputation step by newly-defined mean-field no-adversarial-regret learn-ers, or by black-box optimization. We compare the asymptotic complexityof the approach to standard PSRO, greatly improve empirical bandit con-vergence speed by compressing temporal mixture weights, and ensure itis theoretically robust to payoff noise. Finally, we illustrate the speed andaccuracy of mean-field PSRO on several mean-field games, demonstratingconvergence to strong and weak equilibria.",
        "published": "2021-11-16T10:47:41Z",
        "link": "http://arxiv.org/abs/2111.08350v2",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Modelling airborne transmission of SARS-CoV-2 at a local scale",
        "authors": [
            "Simon Rahn",
            "Marion Gödel",
            "Gerta Köster",
            "Gesine Hofinger"
        ],
        "summary": "The coronavirus disease (COVID-19) pandemic has changed our lives and still poses a challenge to science. Numerous studies have contributed to a better understanding of the pandemic. In particular, inhalation of aerosolised pathogens has been identified as essential for transmission. This information is crucial to slow the spread, but the individual likelihood of becoming infected in everyday situations remains uncertain. Mathematical models help estimate such risks. In this study, we propose how to model airborne transmission of SARS-CoV-2 at a local scale. In this regard, we combine microscopic crowd simulation with a new model for disease transmission. Inspired by compartmental models, we describe agents' health status as susceptible, exposed, infectious or recovered. Infectious agents exhale pathogens bound to persistent aerosols, whereas susceptible agents absorb pathogens when moving through an aerosol cloud left by the infectious agent. The transmission depends on the pathogen load of the aerosol cloud, which changes over time. We propose a 'high risk' benchmark scenario to distinguish critical from non-critical situations. Simulating indoor situations show that the new model is suitable to evaluate the risk of exposure qualitatively and, thus, enables scientists or even decision-makers to better assess the spread of COVID-19 and similar diseases.",
        "published": "2021-11-16T15:20:48Z",
        "link": "http://arxiv.org/abs/2111.08547v2",
        "categories": [
            "q-bio.PE",
            "cs.MA"
        ]
    },
    {
        "title": "Polymatrix Competitive Gradient Descent",
        "authors": [
            "Jeffrey Ma",
            "Alistair Letcher",
            "Florian Schäfer",
            "Yuanyuan Shi",
            "Anima Anandkumar"
        ],
        "summary": "Many economic games and machine learning approaches can be cast as competitive optimization problems where multiple agents are minimizing their respective objective function, which depends on all agents' actions. While gradient descent is a reliable basic workhorse for single-agent optimization, it often leads to oscillation in competitive optimization. In this work we propose polymatrix competitive gradient descent (PCGD) as a method for solving general sum competitive optimization involving arbitrary numbers of agents. The updates of our method are obtained as the Nash equilibria of a local polymatrix approximation with a quadratic regularization, and can be computed efficiently by solving a linear system of equations. We prove local convergence of PCGD to stable fixed points for $n$-player general-sum games, and show that it does not require adapting the step size to the strength of the player-interactions. We use PCGD to optimize policies in multi-agent reinforcement learning and demonstrate its advantages in Snake, Markov soccer and an electricity market game. Agents trained by PCGD outperform agents trained with simultaneous gradient descent, symplectic gradient adjustment, and extragradient in Snake and Markov soccer games and on the electricity market game, PCGD trains faster than both simultaneous gradient descent and the extragradient method.",
        "published": "2021-11-16T15:42:36Z",
        "link": "http://arxiv.org/abs/2111.08565v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "SEIHAI: A Sample-efficient Hierarchical AI for the MineRL Competition",
        "authors": [
            "Hangyu Mao",
            "Chao Wang",
            "Xiaotian Hao",
            "Yihuan Mao",
            "Yiming Lu",
            "Chengjie Wu",
            "Jianye Hao",
            "Dong Li",
            "Pingzhong Tang"
        ],
        "summary": "The MineRL competition is designed for the development of reinforcement learning and imitation learning algorithms that can efficiently leverage human demonstrations to drastically reduce the number of environment interactions needed to solve the complex \\emph{ObtainDiamond} task with sparse rewards. To address the challenge, in this paper, we present \\textbf{SEIHAI}, a \\textbf{S}ample-\\textbf{e}ff\\textbf{i}cient \\textbf{H}ierarchical \\textbf{AI}, that fully takes advantage of the human demonstrations and the task structure. Specifically, we split the task into several sequentially dependent subtasks, and train a suitable agent for each subtask using reinforcement learning and imitation learning. We further design a scheduler to select different agents for different subtasks automatically. SEIHAI takes the first place in the preliminary and final of the NeurIPS-2020 MineRL competition.",
        "published": "2021-11-17T01:36:40Z",
        "link": "http://arxiv.org/abs/2111.08857v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "cs.RO",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Search and Rescue in a Maze-like Environment with Ant and Dijkstra   Algorithms",
        "authors": [
            "Z. Husain",
            "A. Al Zaabi",
            "H. Hildmann",
            "F. Saffre",
            "D. Ruta",
            "A. F. Isakovic"
        ],
        "summary": "With the growing reliability of modern Ad Hoc Networks, it is encouraging to analyze potential involvement of autonomous Ad Hoc agents in critical situations where human involvement could be perilous. One such critical scenario is the Search and Rescue effort in the event of a disaster where timely discovery and help deployment is of utmost importance. This paper demonstrates the applicability of a bio-inspired technique, namely Ant Algorithms (AA), in optimizing the search time for a near optimal path to a trapped victim, followed by the application of Dijkstra's algorithm in the rescue phase. The inherent exploratory nature of AA is put to use for a faster mapping and coverage of the unknown search space. Four different AA are implemented, with different effects of the pheromone in play. An inverted AA, with repulsive pheromones, was found to be the best fit for this particular application. After considerable exploration, upon discovery of the victim, the autonomous agents further facilitate the rescue process by forming a relay network, using the already deployed resources. Hence, the paper discusses a detailed decision making model of the swarm, segmented into two primary phases, responsible for the search and rescue respectively. Different aspects of the performance of the agent swarm are analyzed, as a function of the spatial dimensions, the complexity of the search space, the deployed search group size, and the signal permeability of the obstacles in the area.",
        "published": "2021-11-17T03:18:03Z",
        "link": "http://arxiv.org/abs/2111.08882v1",
        "categories": [
            "cs.MA",
            "cs.SI"
        ]
    },
    {
        "title": "Preference Communication in Multi-Objective Normal-Form Games",
        "authors": [
            "Willem Röpke",
            "Diederik M. Roijers",
            "Ann Nowé",
            "Roxana Rădulescu"
        ],
        "summary": "We consider preference communication in two-player multi-objective normal-form games. In such games, the payoffs resulting from joint actions are vector-valued. Taking a utility-based approach, we assume there exists a utility function for each player which maps vectors to scalar utilities and consider agents that aim to maximise the utility of expected payoff vectors. As agents typically do not know their opponent's utility function or strategy, they must learn policies to interact with each other. Inspired by Stackelberg games, we introduce four novel preference communication protocols to aid agents in arriving at adequate solutions. Each protocol describes a specific approach for one agent to communicate preferences over their actions and how another agent responds. Additionally, to study when communication emerges, we introduce a communication protocol where agents must learn when to communicate. These protocols are subsequently evaluated on a set of five benchmark games against baseline agents that do not communicate. We find that preference communication can alter the learning process and lead to the emergence of cyclic policies which had not been previously observed in this setting. We further observe that the resulting policies can heavily depend on the characteristics of the game that is played. Lastly, we find that communication naturally emerges in both cooperative and self-interested settings.",
        "published": "2021-11-17T15:30:41Z",
        "link": "http://arxiv.org/abs/2111.09191v2",
        "categories": [
            "cs.GT",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Monitoring Over the Long Term: Intermittent Deployment and Sensing   Strategies for Multi-Robot Teams",
        "authors": [
            "Jun Liu",
            "Ryan K. Williams"
        ],
        "summary": "In this paper, we formulate and solve the intermittent deployment problem, which yields strategies that couple \\emph{when} heterogeneous robots should sense an environmental process, with where a deployed team should sense in the environment. As a motivation, suppose that a spatiotemporal process is slowly evolving and must be monitored by a multi-robot team, e.g., unmanned aerial vehicles monitoring pasturelands in a precision agriculture context. In such a case, an intermittent deployment strategy is necessary as persistent deployment or monitoring is not cost-efficient for a slowly evolving process. At the same time, the problem of where to sense once deployed must be solved as process observations yield useful feedback for determining effective future deployment and monitoring decisions. In this context, we model the environmental process to be monitored as a spatiotemporal Gaussian process with mutual information as a criterion to measure our understanding of the environment. To make the sensing resource-efficient, we demonstrate how to use matroid constraints to impose a diverse set of homogeneous and heterogeneous constraints. In addition, to reflect the cost-sensitive nature of real-world applications, we apply budgets on the cost of deployed heterogeneous robot teams. To solve the resulting problem, we exploit the theories of submodular optimization and matroids and present a greedy algorithm with bounds on sub-optimality. Finally, Monte Carlo simulations demonstrate the correctness of the proposed method.",
        "published": "2021-11-17T20:46:25Z",
        "link": "http://arxiv.org/abs/2111.09386v1",
        "categories": [
            "cs.RO",
            "cs.DS",
            "cs.MA"
        ]
    },
    {
        "title": "Submodular Optimization for Coupled Task Allocation and Intermittent   Deployment Problems",
        "authors": [
            "Jun Liu",
            "Ryan K. Williams"
        ],
        "summary": "In this paper, we demonstrate a formulation for optimizing coupled submodular maximization problems with provable sub-optimality bounds. In robotics applications, it is quite common that optimization problems are coupled with one another and therefore cannot be solved independently. Specifically, we consider two problems coupled if the outcome of the first problem affects the solution of a second problem that operates over a longer time scale. For example, in our motivating problem of environmental monitoring, we posit that multi-robot task allocation will potentially impact environmental dynamics and thus influence the quality of future monitoring, here modeled as a multi-robot intermittent deployment problem. The general theoretical approach for solving this type of coupled problem is demonstrated through this motivating example. Specifically, we propose a method for solving coupled problems modeled by submodular set functions with matroid constraints. A greedy algorithm for solving this class of problem is presented, along with sub-optimality guarantees. Finally, practical optimality ratios are shown through Monte Carlo simulations to demonstrate that the proposed algorithm can generate near-optimal solutions with high efficiency.",
        "published": "2021-11-17T20:46:42Z",
        "link": "http://arxiv.org/abs/2111.09387v1",
        "categories": [
            "cs.RO",
            "cs.DS",
            "cs.MA"
        ]
    },
    {
        "title": "Low Precision Decentralized Distributed Training over IID and non-IID   Data",
        "authors": [
            "Sai Aparna Aketi",
            "Sangamesh Kodge",
            "Kaushik Roy"
        ],
        "summary": "Decentralized distributed learning is the key to enabling large-scale machine learning (training) on edge devices utilizing private user-generated local data, without relying on the cloud. However, the practical realization of such on-device training is limited by the communication and compute bottleneck. In this paper, we propose and show the convergence of low precision decentralized training that aims to reduce the computational complexity and communication cost of decentralized training. Many feedback-based compression techniques have been proposed in the literature to reduce communication costs. To the best of our knowledge, there is no work that applies and shows compute efficient training techniques such as quantization, pruning, etc., for peer-to-peer decentralized learning setups. Since real-world applications have a significant skew in the data distribution, we design \"Range-EvoNorm\" as the normalization activation layer which is better suited for low precision training over non-IID data. Moreover, we show that the proposed low precision training can be used in synergy with other communication compression methods decreasing the communication cost further. Our experiments indicate that 8-bit decentralized training has minimal accuracy loss compared to its full precision counterpart even with non-IID data. However, when low precision training is accompanied by communication compression through sparsification we observe a 1-2% drop in accuracy. The proposed low precision decentralized training decreases computational complexity, memory usage, and communication cost by 4x and compute energy by a factor of ~20x, while trading off less than a $1\\%$ accuracy for both IID and non-IID data. In particular, with higher skew values, we observe an increase in accuracy (by ~ 0.5%) with low precision training, indicating the regularization effect of the quantization.",
        "published": "2021-11-17T20:48:09Z",
        "link": "http://arxiv.org/abs/2111.09389v3",
        "categories": [
            "cs.LG",
            "cs.CV",
            "cs.MA"
        ]
    },
    {
        "title": "SpeedyIBL: A Comprehensive, Precise, and Fast Implementation of   Instance-Based Learning Theory",
        "authors": [
            "Thuy Ngoc Nguyen",
            "Duy Nhat Phan",
            "Cleotilde Gonzalez"
        ],
        "summary": "Instance-Based Learning Theory (IBLT) is a comprehensive account of how humans make decisions from experience during dynamic tasks. Since it was first proposed almost two decades ago, multiple computational models have been constructed based on IBLT (i.e., IBL models). These models have been demonstrated to be very successful in explaining and predicting human decisions in multiple decision making contexts. However, as IBLT has evolved, the initial description of the theory has become less precise, and it is unclear how its demonstration can be expanded to more complex, dynamic, and multi-agent environments. This paper presents an updated version of the current theoretical components of IBLT in a comprehensive and precise form. It also provides an advanced implementation of the full set of theoretical mechanisms, SpeedyIBL, to unlock the capabilities of IBLT to handle a diverse taxonomy of individual and multi-agent decision-making problems. SpeedyIBL addresses a practical computational issue in past implementations of IBL models, the curse of exponential growth, that emerges from memory-based tabular computations. When more observations accumulate over time, there is an exponential growth of the memory of instances that leads directly to an exponential slow down of the computational time. Thus, SpeedyIBL leverages parallel computation with vectorization to speed up the execution time of IBL models. We evaluate the robustness of SpeedyIBL over an existing implementation of IBLT in decision games of increased complexity. The results not only demonstrate the applicability of IBLT through a wide range of decision making tasks, but also highlight the improvement of SpeedyIBL over its prior implementation as the complexity of decision features and number of agents increase. The library is open sourced for the use of the broad research community.",
        "published": "2021-11-19T15:18:00Z",
        "link": "http://arxiv.org/abs/2111.10268v2",
        "categories": [
            "cs.IR",
            "cs.MA"
        ]
    },
    {
        "title": "Improving Spectral Efficiency of Wireless Networks through Democratic   Spectrum Sharing",
        "authors": [
            "Aniq Ur Rahman",
            "Mustafa A. Kishk",
            "Mohamed-Slim Alouini"
        ],
        "summary": "Wireless devices need spectrum to communicate. With the increase in the number of devices competing for the same spectrum, it has become nearly impossible to support the throughput requirements of all the devices through current spectrum sharing methods. In this work, we look at the problem of spectrum resource contention fundamentally, taking inspiration from the principles of globalization. We develop a distributed algorithm whereby the wireless nodes democratically share the spectrum resources and improve their spectral efficiency and throughput without additional power or spectrum resources. We validate the performance of our proposed democratic spectrum sharing (DSS) algorithm over real-world Wi-Fi networks and on synthetically generated networks with varying design parameters. Compared to the greedy approach, DSS achieves significant gains in throughput (~60%), area spectral efficiency ($\\sim$50\\%) and fairness in datarate distribution (~20%). Due to the distributed nature of the proposed algorithm, we can apply it to wireless networks of any size and density.",
        "published": "2021-11-20T12:04:43Z",
        "link": "http://arxiv.org/abs/2111.10570v1",
        "categories": [
            "cs.NI",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "The downside of heterogeneity: How established relations counteract   systemic adaptivity in tasks assignments",
        "authors": [
            "Giona Casiraghi",
            "Christian Zingg",
            "Frank Schweitzer"
        ],
        "summary": "We study the lock-in effect in a network of task assignments. Agents have a heterogeneous fitness for solving tasks and can redistribute unfinished tasks to other agents. They learn over time to whom to reassign tasks and preferably choose agents with higher fitness. A lock-in occurs if reassignments can no longer adapt. Agents overwhelmed with tasks then fail, leading to failure cascades. We find that the probability for lock-ins and systemic failures increase with the heterogeneity in fitness values. To study this dependence, we use the Shannon entropy of the network of task assignments. A detailed discussion links our findings to the problem of resilience and observations in social systems.",
        "published": "2021-11-20T18:05:51Z",
        "link": "http://arxiv.org/abs/2111.10648v1",
        "categories": [
            "physics.soc-ph",
            "cs.MA"
        ]
    },
    {
        "title": "A Blockchain-Based Approach for Collaborative Formalization of   Mathematics and Programs",
        "authors": [
            "Jin Xing Lim",
            "Barnabé Monnot",
            "Shaowei Lin",
            "Georgios Piliouras"
        ],
        "summary": "Formalization of mathematics is the process of digitizing mathematical knowledge, which allows for formal proof verification as well as efficient semantic searches. Given the large and ever-increasing gap between the set of formalized and unformalized mathematical knowledge, there is a clear need to encourage more computer scientists and mathematicians to solve and formalize mathematical problems together. With blockchain technology, we are able to decentralize this process, provide time-stamped verification of authorship and encourage collaboration through implementation of incentive mechanisms via smart contracts. Currently, the formalization of mathematics is done through the use of proof assistants, which can be used to verify programs and protocols as well. Furthermore, with the advancement in artificial intelligence (AI), particularly machine learning, we can apply automated AI reasoning tools in these proof assistants and (at least partially) automate the process of synthesizing proofs. In our paper, we demonstrate a blockchain-based system for collaborative formalization of mathematics and programs incorporating both human labour as well as automated AI tools. We explain how Token-Curated Registries (TCR) and smart contracts are used to ensure appropriate documents are recorded and encourage collaboration through implementation of incentive mechanisms respectively. Using an illustrative example, we show how formalized proofs of different sorting algorithms can be produced collaboratively in our proposed blockchain system.",
        "published": "2021-11-21T14:01:02Z",
        "link": "http://arxiv.org/abs/2111.10824v1",
        "categories": [
            "cs.MA",
            "cs.GT",
            "cs.LO"
        ]
    },
    {
        "title": "Renewable energy integration and microgrid energy trading using   multi-agent deep reinforcement learning",
        "authors": [
            "Daniel J. B. Harrold",
            "Jun Cao",
            "Zhong Fan"
        ],
        "summary": "In this paper, multi-agent reinforcement learning is used to control a hybrid energy storage system working collaboratively to reduce the energy costs of a microgrid through maximising the value of renewable energy and trading. The agents must learn to control three different types of energy storage system suited for short, medium, and long-term storage under fluctuating demand, dynamic wholesale energy prices, and unpredictable renewable energy generation. Two case studies are considered: the first looking at how the energy storage systems can better integrate renewable energy generation under dynamic pricing, and the second with how those same agents can be used alongside an aggregator agent to sell energy to self-interested external microgrids looking to reduce their own energy bills. This work found that the centralised learning with decentralised execution of the multi-agent deep deterministic policy gradient and its state-of-the-art variants allowed the multi-agent methods to perform significantly better than the control from a single global agent. It was also found that using separate reward functions in the multi-agent approach performed much better than using a single control agent. Being able to trade with the other microgrids, rather than just selling back to the utility grid, also was found to greatly increase the grid's savings.",
        "published": "2021-11-21T21:11:00Z",
        "link": "http://arxiv.org/abs/2111.10898v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Elephant-Human Conflict Mitigation: An Autonomous UAV Approach",
        "authors": [
            "Weiyun Jiang",
            "Yukai Yang",
            "Yogananda Isukapalli"
        ],
        "summary": "Elephant-human conflict (EHC) is one of the major problems in most African and Asian countries. As humans overutilize natural resources for their development, elephants' living area continues to decrease; this leads elephants to invade the human living area and raid crops more frequently, costing millions of dollars annually. To mitigate EHC, in this paper, we propose an original solution that comprises of three parts: a compact custom low-power GPS tag that is installed on the elephants, a receiver stationed in the human living area that detects the elephants' presence near a farm, and an autonomous unmanned aerial vehicle (UAV) system that tracks and herds the elephants away from the farms. By utilizing proportional-integral-derivative controller and machine learning algorithms, we obtain accurate tracking trajectories at a real-time processing speed of 32 FPS. Our proposed autonomous system can save over 68 % cost compared with human-controlled UAVs in mitigating EHC.",
        "published": "2021-11-22T02:44:20Z",
        "link": "http://arxiv.org/abs/2201.02584v1",
        "categories": [
            "cs.MA",
            "cs.RO",
            "eess.IV"
        ]
    },
    {
        "title": "Multi-lingual agents through multi-headed neural networks",
        "authors": [
            "J. D. Thomas",
            "R. Santos-Rodríguez",
            "R. Piechocki",
            "M. Anca"
        ],
        "summary": "This paper considers cooperative Multi-Agent Reinforcement Learning, focusing on emergent communication in settings where multiple pairs of independent learners interact at varying frequencies. In this context, multiple distinct and incompatible languages can emerge. When an agent encounters a speaker of an alternative language, there is a requirement for a period of adaptation before they can efficiently converse. This adaptation results in the emergence of a new language and the forgetting of the previous language. In principle, this is an example of the Catastrophic Forgetting problem which can be mitigated by enabling the agents to learn and maintain multiple languages. We take inspiration from the Continual Learning literature and equip our agents with multi-headed neural networks which enable our agents to be multi-lingual. Our method is empirically validated within a referential MNIST based communication game and is shown to be able to maintain multiple languages where existing approaches cannot.",
        "published": "2021-11-22T11:39:42Z",
        "link": "http://arxiv.org/abs/2111.11129v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Off-Policy Correction For Multi-Agent Reinforcement Learning",
        "authors": [
            "Michał Zawalski",
            "Błażej Osiński",
            "Henryk Michalewski",
            "Piotr Miłoś"
        ],
        "summary": "Multi-agent reinforcement learning (MARL) provides a framework for problems involving multiple interacting agents. Despite apparent similarity to the single-agent case, multi-agent problems are often harder to train and analyze theoretically. In this work, we propose MA-Trace, a new on-policy actor-critic algorithm, which extends V-Trace to the MARL setting. The key advantage of our algorithm is its high scalability in a multi-worker setting. To this end, MA-Trace utilizes importance sampling as an off-policy correction method, which allows distributing the computations with no impact on the quality of training. Furthermore, our algorithm is theoretically grounded - we prove a fixed-point theorem that guarantees convergence. We evaluate the algorithm extensively on the StarCraft Multi-Agent Challenge, a standard benchmark for multi-agent algorithms. MA-Trace achieves high performance on all its tasks and exceeds state-of-the-art results on some of them.",
        "published": "2021-11-22T14:23:13Z",
        "link": "http://arxiv.org/abs/2111.11229v3",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "I.2"
        ]
    },
    {
        "title": "Convergence of sequences: a survey",
        "authors": [
            "Barbara Franci",
            "Sergio Grammatico"
        ],
        "summary": "Convergent sequences of real numbers play a fundamental role in many different problems in system theory, e.g., in Lyapunov stability analysis, as well as in optimization theory and computational game theory. In this survey, we provide an overview of the literature on convergence theorems and their connection with Fejer monotonicity in the deterministic and stochastic settings, and we show how to exploit these results.",
        "published": "2021-11-22T17:31:49Z",
        "link": "http://arxiv.org/abs/2111.11374v1",
        "categories": [
            "math.OC",
            "cs.MA"
        ]
    },
    {
        "title": "Universal Swarm Computing by Nanorobots",
        "authors": [
            "Alireza Rowhanimanesh",
            "Mohammad-R Akbarzadeh-T"
        ],
        "summary": "Realization of universal computing units for nanorobots is highly promising in creating new and wide arrays of applications, particularly in the realm of distributed computation. However, such realization is also a challenging problem due to the physical limitations of nanometer-sized designs such as in computation, sensory and perception as well as actuation. This paper proposes a theoretical foundation for solving this problem based on a novel notion of distributed swarm computing by basis agents (BAs). The proposed BA is an abstract model for nanorobots that can compute a very simple basis function called B-function. It is mathematically shown here that a swarm of BAs has the universal function approximation property and can accurately approximate functions. It is then analytically demonstrated that a swarm of BAs can be easily reprogrammed to compute desired functions simply by adjusting the concentrations of BAs in the environment. We further propose a specific structure for BAs which enable them to perform distributed computing such as in the aqueous environment of living tissues and nanomedicine. The hardware complexity of this structure aims to remain low to be more reasonably realizable by today technology. Finally, the performance of the proposed approach is illustrated by a simulation example.",
        "published": "2021-11-22T20:00:27Z",
        "link": "http://arxiv.org/abs/2111.11503v1",
        "categories": [
            "eess.SY",
            "cs.ET",
            "cs.MA",
            "cs.RO",
            "cs.SY"
        ]
    },
    {
        "title": "Status-quo policy gradient in Multi-Agent Reinforcement Learning",
        "authors": [
            "Pinkesh Badjatiya",
            "Mausoom Sarkar",
            "Nikaash Puri",
            "Jayakumar Subramanian",
            "Abhishek Sinha",
            "Siddharth Singh",
            "Balaji Krishnamurthy"
        ],
        "summary": "Individual rationality, which involves maximizing expected individual returns, does not always lead to high-utility individual or group outcomes in multi-agent problems. For instance, in multi-agent social dilemmas, Reinforcement Learning (RL) agents trained to maximize individual rewards converge to a low-utility mutually harmful equilibrium. In contrast, humans evolve useful strategies in such social dilemmas. Inspired by ideas from human psychology that attribute this behavior to the status-quo bias, we present a status-quo loss (SQLoss) and the corresponding policy gradient algorithm that incorporates this bias in an RL agent. We demonstrate that agents trained with SQLoss learn high-utility policies in several social dilemma matrix games (Prisoner's Dilemma, Stag Hunt matrix variant, Chicken Game). We show how SQLoss outperforms existing state-of-the-art methods to obtain high-utility policies in visual input non-matrix games (Coin Game and Stag Hunt visual input variant) using pre-trained cooperation and defection oracles. Finally, we show that SQLoss extends to a 4-agent setting by demonstrating the emergence of cooperative behavior in the popular Braess' paradox.",
        "published": "2021-11-23T07:22:05Z",
        "link": "http://arxiv.org/abs/2111.11692v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Automaton of molecular perceptions in biochemical reactions",
        "authors": [
            "Stefano Maestri",
            "Emanuela Merelli"
        ],
        "summary": "Local interactions among biomolecules, and the role played by their environment, have gained increasing attention in modelling biochemical reactions. By defining the automaton of molecular perceptions, we explore an agent-based representation of the behaviour of biomolecules in living cells. Our approach considers the capability of a molecule to perceive its surroundings a key property of bimolecular interactions, which we investigate from a theoretical perspective. Graph-based reaction systems are then leveraged to abstract enzyme regulation as a result of the influence exerted by the environment on a catalysed reaction. By combining these methods, we aim at overcoming some limitations of current kinetic models, which do not take into account local molecular interactions and the way they are affected by the reaction environment.",
        "published": "2021-11-23T10:15:03Z",
        "link": "http://arxiv.org/abs/2111.11760v1",
        "categories": [
            "cs.CE",
            "cs.MA",
            "J.3; I.6.0"
        ]
    },
    {
        "title": "How does AI play football? An analysis of RL and real-world football   strategies",
        "authors": [
            "Atom Scott",
            "Keisuke Fujii",
            "Masaki Onishi"
        ],
        "summary": "Recent advances in reinforcement learning (RL) have made it possible to develop sophisticated agents that excel in a wide range of applications. Simulations using such agents can provide valuable information in scenarios that are difficult to scientifically experiment in the real world. In this paper, we examine the play-style characteristics of football RL agents and uncover how strategies may develop during training. The learnt strategies are then compared with those of real football players. We explore what can be learnt from the use of simulated environments by using aggregated statistics and social network analysis (SNA). As a result, we found that (1) there are strong correlations between the competitiveness of an agent and various SNA metrics and (2) aspects of the RL agents play style become similar to real world footballers as the agent becomes more competitive. We discuss further advances that may be necessary to improve our understanding necessary to fully utilise RL for the analysis of football.",
        "published": "2021-11-24T08:44:23Z",
        "link": "http://arxiv.org/abs/2111.12340v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Engineering and Implementation of SimAEN",
        "authors": [
            "Gwendolyn Gettliffe",
            "Adam Norige",
            "Ted Londner",
            "Jonathan Saunders",
            "Dieter Schuldt",
            "William Streilein"
        ],
        "summary": "This paper presents SimAEN, an agent-based simulation whose purpose is to assist public health in understanding and controlling AEN. SimAEN models a population of interacting individuals, or 'agents', in which COVID-19 is spreading. These individuals interact with a public health system that includes Automated Exposure Notifiation (AEN) and Manual Contact Tracing (MCT). These interactions influence when individuals enter and leave quarantine, affecting the spread of the simulated disease. Over 70 user-configurable parameters influence the outcome of SimAEN's simulations. These parameters allow the user to tailor SimAEN to a specific public health jurisdiction and to test the effects of various interventions, including different sensitivity settings of AEN.",
        "published": "2021-11-24T22:38:20Z",
        "link": "http://arxiv.org/abs/2111.12825v2",
        "categories": [
            "q-bio.QM",
            "cs.MA"
        ]
    },
    {
        "title": "Distributed Policy Gradient with Variance Reduction in Multi-Agent   Reinforcement Learning",
        "authors": [
            "Xiaoxiao Zhao",
            "Jinlong Lei",
            "Li Li",
            "Jie Chen"
        ],
        "summary": "This paper studies a distributed policy gradient in collaborative multi-agent reinforcement learning (MARL), where agents over a communication network aim to find the optimal policy to maximize the average of all agents' local returns. Due to the non-concave performance function of policy gradient, the existing distributed stochastic optimization methods for convex problems cannot be directly used for policy gradient in MARL. This paper proposes a distributed policy gradient with variance reduction and gradient tracking to address the high variances of policy gradient, and utilizes importance weight to solve the {distribution shift} problem in the sampling process. We then provide an upper bound on the mean-squared stationary gap, which depends on the number of iterations, the mini-batch size, the epoch size, the problem parameters, and the network topology. We further establish the sample and communication complexity to obtain an $\\epsilon$-approximate stationary point. Numerical experiments are performed to validate the effectiveness of the proposed algorithm.",
        "published": "2021-11-25T08:07:30Z",
        "link": "http://arxiv.org/abs/2111.12961v3",
        "categories": [
            "cs.MA",
            "cs.LG",
            "math.OC"
        ]
    },
    {
        "title": "Towards an Adaptive and Normative Multi-Agent System Metamodel and   Language: Existing Approaches and Research Opportunities",
        "authors": [
            "Marx Viana",
            "Paulo Alencar",
            "Carlos Lucena"
        ],
        "summary": "Several Multi-Agent System (MAS) metamodels and languages have been proposed in the literature to support the development of agent-based applications. MAS metamodels are used to capture a collection of concepts the relevant entities and relationships in the MAS domain, which include entities such as agent, message, role, action and plan, and relationships that represent, for example, that a role is responsible for one or more tasks. In addition, to models, MAS modeling languages have also been used to support the development of MASs in a wide variety of domains, including social networking, robotics, security and smart city environments. However, there is a lack of support in these models and languages for abstractions involving norms and adaptations as well as their interactions. This paper presents a survey of some existing metamodels and languages and compares their expressiveness using abstractions related to agents, norms and adaptation. The comparison serves as a basis for the definition of a new MAS metamodeling.",
        "published": "2021-11-25T13:48:18Z",
        "link": "http://arxiv.org/abs/2111.13084v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Unravelling multi-agent ranked delegations",
        "authors": [
            "Rachael Colley",
            "Umberto Grandi",
            "Arianna Novaro"
        ],
        "summary": "We introduce a voting model with multi-agent ranked delegations. This model generalises liquid democracy in two aspects: first, an agent's delegation can use the votes of multiple other agents to determine their own -- for instance, an agent's vote may correspond to the majority outcome of the votes of a trusted group of agents; second, agents can submit a ranking over multiple delegations, so that a backup delegation can be used when their preferred delegations are involved in cycles. The main focus of this paper is the study of unravelling procedures that transform the delegation ballots received from the agents into a profile of direct votes, from which a winning alternative can then be determined by using a standard voting rule. We propose and study six such unravelling procedures, two based on optimisation and four using a greedy approach. We study both algorithmic and axiomatic properties, as well as related computational complexity problems of our unravelling procedures for different restrictions on the types of ballots that the agents can submit.",
        "published": "2021-11-25T15:58:39Z",
        "link": "http://arxiv.org/abs/2111.13145v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Hidden Markov Modeling over Graphs",
        "authors": [
            "Mert Kayaalp",
            "Virginia Bordignon",
            "Stefan Vlaski",
            "Ali H. Sayed"
        ],
        "summary": "This work proposes a multi-agent filtering algorithm over graphs for finite-state hidden Markov models (HMMs), which can be used for sequential state estimation or for tracking opinion formation over dynamic social networks. We show that the difference from the optimal centralized Bayesian solution is asymptotically bounded for geometrically ergodic transition models. Experiments illustrate the theoretical findings and in particular, demonstrate the superior performance of the proposed algorithm compared to a state-of-the-art social learning algorithm.",
        "published": "2021-11-26T17:39:30Z",
        "link": "http://arxiv.org/abs/2111.13626v2",
        "categories": [
            "eess.SP",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Normative Disagreement as a Challenge for Cooperative AI",
        "authors": [
            "Julian Stastny",
            "Maxime Riché",
            "Alexander Lyzhov",
            "Johannes Treutlein",
            "Allan Dafoe",
            "Jesse Clifton"
        ],
        "summary": "Cooperation in settings where agents have both common and conflicting interests (mixed-motive environments) has recently received considerable attention in multi-agent learning. However, the mixed-motive environments typically studied have a single cooperative outcome on which all agents can agree. Many real-world multi-agent environments are instead bargaining problems (BPs): they have several Pareto-optimal payoff profiles over which agents have conflicting preferences. We argue that typical cooperation-inducing learning algorithms fail to cooperate in BPs when there is room for normative disagreement resulting in the existence of multiple competing cooperative equilibria, and illustrate this problem empirically. To remedy the issue, we introduce the notion of norm-adaptive policies. Norm-adaptive policies are capable of behaving according to different norms in different circumstances, creating opportunities for resolving normative disagreement. We develop a class of norm-adaptive policies and show in experiments that these significantly increase cooperation. However, norm-adaptiveness cannot address residual bargaining failure arising from a fundamental tradeoff between exploitability and cooperative robustness.",
        "published": "2021-11-27T11:37:42Z",
        "link": "http://arxiv.org/abs/2111.13872v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.GT",
            "cs.LG"
        ]
    },
    {
        "title": "Resource-Aware Asynchronous Online Federated Learning for Nonlinear   Regression",
        "authors": [
            "Francois Gauthier",
            "Vinay Chakravarthi Gogineni",
            "Stefan Werner",
            "Yih-Fang Huang",
            "Anthony Kuh"
        ],
        "summary": "Many assumptions in the federated learning literature present a best-case scenario that can not be satisfied in most real-world applications. An asynchronous setting reflects the realistic environment in which federated learning methods must be able to operate reliably. Besides varying amounts of non-IID data at participants, the asynchronous setting models heterogeneous client participation due to available computational power and battery constraints and also accounts for delayed communications between clients and the server. To reduce the communication overhead associated with asynchronous online federated learning (ASO-Fed), we use the principles of partial-sharing-based communication. In this manner, we reduce the communication load of the participants and, therefore, render participation in the learning task more accessible. We prove the convergence of the proposed ASO-Fed and provide simulations to analyze its behavior further. The simulations reveal that, in the asynchronous setting, it is possible to achieve the same convergence as the federated stochastic gradient (Online-FedSGD) while reducing the communication tenfold.",
        "published": "2021-11-27T16:41:30Z",
        "link": "http://arxiv.org/abs/2111.13931v1",
        "categories": [
            "cs.LG",
            "cs.DC",
            "cs.MA",
            "cs.SY",
            "eess.SP",
            "eess.SY"
        ]
    },
    {
        "title": "Evaluating Generalization and Transfer Capacity of Multi-Agent   Reinforcement Learning Across Variable Number of Agents",
        "authors": [
            "Bengisu Guresti",
            "Nazim Kemal Ure"
        ],
        "summary": "Multi-agent Reinforcement Learning (MARL) problems often require cooperation among agents in order to solve a task. Centralization and decentralization are two approaches used for cooperation in MARL. While fully decentralized methods are prone to converge to suboptimal solutions due to partial observability and nonstationarity, the methods involving centralization suffer from scalability limitations and lazy agent problem. Centralized training decentralized execution paradigm brings out the best of these two approaches; however, centralized training still has an upper limit of scalability not only for acquired coordination performance but also for model size and training time. In this work, we adopt the centralized training with decentralized execution paradigm and investigate the generalization and transfer capacity of the trained models across variable number of agents. This capacity is assessed by training variable number of agents in a specific MARL problem and then performing greedy evaluations with variable number of agents for each training configuration. Thus, we analyze the evaluation performance for each combination of agent count for training versus evaluation. We perform experimental evaluations on predator prey and traffic junction environments and demonstrate that it is possible to obtain similar or higher evaluation performance by training with less agents. We conclude that optimal number of agents to perform training may differ from the target number of agents and argue that transfer across large number of agents can be a more efficient solution to scaling up than directly increasing number of agents during training.",
        "published": "2021-11-28T15:29:46Z",
        "link": "http://arxiv.org/abs/2111.14177v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Frontier-led Swarming: Robust Multi-Robot Coverage of Unknown   Environments",
        "authors": [
            "Vu Phi Tran",
            "Matthew A. Garratt",
            "Kathryn Kasmarik",
            "Sreenatha G. Anavatti"
        ],
        "summary": "This paper proposes a novel swarm-based control algorithm for exploration and coverage of unknown environments, while maintaining a formation that permits short-range communication. The algorithm combines two elements: swarm rules for maintaining a close-knit formation and frontier search for driving exploration and coverage. Inspired by natural systems in which large numbers of simple agents (e.g., schooling fish, flocking birds, swarming insects) perform complicated collective behaviors for efficiency and safety, the first element uses three simple rules to maintain a swarm formation. The second element provides a means to select promising regions to explore (and cover) by minimising a cost function involving robots' relative distance to frontier cells and the frontier's size. We tested the performance of our approach on heterogeneous and homogeneous groups of mobile robots in different environments. We measure both coverage performance and swarm formation statistics as indicators of the robots' ability to explore effectively while maintaining a formation conducive to short-range communication. Through a series of comparison experiments, we demonstrate that our proposed strategy has superior performance to recently presented map coverage methodologies and conventional swarming methods.",
        "published": "2021-11-29T01:56:21Z",
        "link": "http://arxiv.org/abs/2111.14295v2",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "How Can Creativity Occur in Multi-Agent Systems?",
        "authors": [
            "Ted Fujimoto"
        ],
        "summary": "Complex systems show how surprising and beautiful phenomena can emerge from structures or agents following simple rules. With the recent success of deep reinforcement learning (RL), a natural path forward would be to use the capabilities of multiple deep RL agents to produce emergent behavior of greater benefit and sophistication. In general, this has proved to be an unreliable strategy without significant computation due to the difficulties inherent in multi-agent RL training. In this paper, we propose some criteria for creativity in multi-agent RL. We hope this proposal will give artists applying multi-agent RL a starting point, and provide a catalyst for further investigation guided by philosophical discussion.",
        "published": "2021-11-29T03:19:09Z",
        "link": "http://arxiv.org/abs/2111.14310v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Adversarial Attacks in Cooperative AI",
        "authors": [
            "Ted Fujimoto",
            "Arthur Paul Pedersen"
        ],
        "summary": "Single-agent reinforcement learning algorithms in a multi-agent environment are inadequate for fostering cooperation. If intelligent agents are to interact and work together to solve complex problems, methods that counter non-cooperative behavior are needed to facilitate the training of multiple agents. This is the goal of cooperative AI. Recent research in adversarial machine learning, however, shows that models (e.g., image classifiers) can be easily deceived into making inferior decisions. Meanwhile, an important line of research in cooperative AI has focused on introducing algorithmic improvements that accelerate learning of optimally cooperative behavior. We argue that prominent methods of cooperative AI are exposed to weaknesses analogous to those studied in prior machine learning research. More specifically, we show that three algorithms inspired by human-like social intelligence are, in principle, vulnerable to attacks that exploit weaknesses introduced by cooperative AI's algorithmic improvements and report experimental findings that illustrate how these vulnerabilities can be exploited in practice.",
        "published": "2021-11-29T07:34:12Z",
        "link": "http://arxiv.org/abs/2111.14833v3",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Final Adaptation Reinforcement Learning for N-Player Games",
        "authors": [
            "Wolfgang Konen",
            "Samineh Bagheri"
        ],
        "summary": "This paper covers n-tuple-based reinforcement learning (RL) algorithms for games. We present new algorithms for TD-, SARSA- and Q-learning which work seamlessly on various games with arbitrary number of players. This is achieved by taking a player-centered view where each player propagates his/her rewards back to previous rounds. We add a new element called Final Adaptation RL (FARL) to all these algorithms. Our main contribution is that FARL is a vitally important ingredient to achieve success with the player-centered view in various games. We report results on seven board games with 1, 2 and 3 players, including Othello, ConnectFour and Hex. In most cases it is found that FARL is important to learn a near-perfect playing strategy. All algorithms are available in the GBG framework on GitHub.",
        "published": "2021-11-29T08:36:39Z",
        "link": "http://arxiv.org/abs/2111.14375v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Multi-UAV Conflict Resolution with Graph Convolutional Reinforcement   Learning",
        "authors": [
            "Ralvi Isufaj",
            "Marsel Omeri",
            "Miquel Angel Piera"
        ],
        "summary": "Safety is the primary concern when it comes to air traffic. In-flight safety between Unmanned Aircraft Vehicles (UAVs) is ensured through pairwise separation minima, utilizing conflict detection and resolution methods. Existing methods mainly deal with pairwise conflicts, however due to an expected increase in traffic density, encounters with more than two UAVs are likely to happen. In this paper, we model multi-UAV conflict resolution as a multi-agent reinforcement learning problem. We implement an algorithm based on graph neural networks where cooperative agents can communicate to jointly generate resolution maneuvers. The model is evaluated in scenarios with 3 and 4 present agents. Results show that agents are able to successfully solve the multi-UAV conflicts through a cooperative strategy.",
        "published": "2021-11-29T15:29:32Z",
        "link": "http://arxiv.org/abs/2111.14598v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Learning Graphon Mean Field Games and Approximate Nash Equilibria",
        "authors": [
            "Kai Cui",
            "Heinz Koeppl"
        ],
        "summary": "Recent advances at the intersection of dense large graph limits and mean field games have begun to enable the scalable analysis of a broad class of dynamical sequential games with large numbers of agents. So far, results have been largely limited to graphon mean field systems with continuous-time diffusive or jump dynamics, typically without control and with little focus on computational methods. We propose a novel discrete-time formulation for graphon mean field games as the limit of non-linear dense graph Markov games with weak interaction. On the theoretical side, we give extensive and rigorous existence and approximation properties of the graphon mean field solution in sufficiently large systems. On the practical side, we provide general learning schemes for graphon mean field equilibria by either introducing agent equivalence classes or reformulating the graphon mean field system as a classical mean field system. By repeatedly finding a regularized optimal control solution and its generated mean field, we successfully obtain plausible approximate Nash equilibria in otherwise infeasible large dense graph games with many agents. Empirically, we are able to demonstrate on a number of examples that the finite-agent behavior comes increasingly close to the mean field behavior for our computed equilibria as the graph or system size grows, verifying our theory. More generally, we successfully apply policy gradient reinforcement learning in conjunction with sequential Monte Carlo methods.",
        "published": "2021-11-29T16:16:11Z",
        "link": "http://arxiv.org/abs/2112.01280v3",
        "categories": [
            "cs.GT",
            "cs.LG",
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "Beyond Time-Average Convergence: Near-Optimal Uncoupled Online Learning   via Clairvoyant Multiplicative Weights Update",
        "authors": [
            "Georgios Piliouras",
            "Ryann Sim",
            "Stratis Skoulakis"
        ],
        "summary": "In this paper, we provide a novel and simple algorithm, Clairvoyant Multiplicative Weights Updates (CMWU) for regret minimization in general games. CMWU effectively corresponds to the standard MWU algorithm but where all agents, when updating their mixed strategies, use the payoff profiles based on tomorrow's behavior, i.e. the agents are clairvoyant. CMWU achieves constant regret of $\\ln(m)/\\eta$ in all normal-form games with m actions and fixed step-sizes $\\eta$. Although CMWU encodes in its definition a fixed point computation, which in principle could result in dynamics that are neither computationally efficient nor uncoupled, we show that both of these issues can be largely circumvented. Specifically, as long as the step-size $\\eta$ is upper bounded by $\\frac{1}{(n-1)V}$, where $n$ is the number of agents and $[0,V]$ is the payoff range, then the CMWU updates can be computed linearly fast via a contraction map. This implementation results in an uncoupled online learning dynamic that admits a $O (\\log T)$-sparse sub-sequence where each agent experiences at most $O(nV\\log m)$ regret. This implies that the CMWU dynamics converge with rate $O(nV \\log m \\log T / T)$ to a \\textit{Coarse Correlated Equilibrium}. The latter improves on the current state-of-the-art convergence rate of \\textit{uncoupled online learning dynamics} \\cite{daskalakis2021near,anagnostides2021near}.",
        "published": "2021-11-29T17:42:24Z",
        "link": "http://arxiv.org/abs/2111.14737v4",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "econ.TH"
        ]
    },
    {
        "title": "MAMRL: Exploiting Multi-agent Meta Reinforcement Learning in WAN Traffic   Engineering",
        "authors": [
            "Shan Sun",
            "Mariam Kiran",
            "Wei Ren"
        ],
        "summary": "Traffic optimization challenges, such as load balancing, flow scheduling, and improving packet delivery time, are difficult online decision-making problems in wide area networks (WAN). Complex heuristics are needed for instance to find optimal paths that improve packet delivery time and minimize interruptions which may be caused by link failures or congestion. The recent success of reinforcement learning (RL) algorithms can provide useful solutions to build better robust systems that learn from experience in model-free settings.   In this work, we consider a path optimization problem, specifically for packet routing, in large complex networks. We develop and evaluate a model-free approach, applying multi-agent meta reinforcement learning (MAMRL) that can determine the next-hop of each packet to get it delivered to its destination with minimum time overall. Specifically, we propose to leverage and compare deep policy optimization RL algorithms for enabling distributed model-free control in communication networks and present a novel meta-learning-based framework, MAMRL, for enabling quick adaptation to topology changes. To evaluate the proposed framework, we simulate with various WAN topologies. Our extensive packet-level simulation results show that compared to classical shortest path and traditional reinforcement learning approaches, MAMRL significantly reduces the average packet delivery time even when network demand increases; and compared to a non-meta deep policy optimization algorithm, our results show the reduction of packet loss in much fewer episodes when link failures occur while offering comparable average packet delivery time.",
        "published": "2021-11-30T03:01:01Z",
        "link": "http://arxiv.org/abs/2111.15087v1",
        "categories": [
            "cs.NI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "The Power of Communication in a Distributed Multi-Agent System",
        "authors": [
            "Philipp Dominic Siedler"
        ],
        "summary": "Single-Agent (SA) Reinforcement Learning systems have shown outstanding re-sults on non-stationary problems. However, Multi-Agent Reinforcement Learning(MARL) can surpass SA systems generally and when scaling. Furthermore, MAsystems can be super-powered by collaboration, which can happen through ob-serving others, or a communication system used to share information betweencollaborators. Here, we developed a distributed MA learning mechanism withthe ability to communicate based on decentralised partially observable Markovdecision processes (Dec-POMDPs) and Graph Neural Networks (GNNs). Minimis-ing the time and energy consumed by training Machine Learning models whileimproving performance can be achieved by collaborative MA mechanisms. Wedemonstrate this in a real-world scenario, an offshore wind farm, including a set ofdistributed wind turbines, where the objective is to maximise collective efficiency.Compared to a SA system, MA collaboration has shown significantly reducedtraining time and higher cumulative rewards in unseen and scaled scenarios.",
        "published": "2021-11-30T18:00:58Z",
        "link": "http://arxiv.org/abs/2111.15611v3",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Coordinated Multi-Robot Trajectory Tracking Control over Sampled   Communication",
        "authors": [
            "Enrica Rossi",
            "Marco Tognon",
            "Luca Ballotta",
            "Ruggero Carli",
            "Juan Cortés",
            "Antonio Franchi",
            "Luca Schenato"
        ],
        "summary": "In this paper, we propose an inverse-kinematics controller for a class of multi-robot systems in the scenario of sampled communication. The goal is to make a group of robots perform trajectory tracking in a coordinated way when the sampling time of communications is much larger than the sampling time of low-level controllers, disrupting theoretical convergence guarantees of standard control design in continuous time. Given a desired trajectory in configuration space which is precomputed offline, the proposed controller receives configuration measurements, possibly via wireless, to re-compute velocity references for the robots, which are tracked by a low-level controller. We propose joint design of a sampled proportional feedback plus a novel continuous-time feedforward that linearizes the dynamics around the reference trajectory: this method is amenable to distributed communication implementation where only one broadcast transmission is needed per sample. Also, we provide closed-form expressions for instability and stability regions and convergence rate in terms of proportional gain $k$ and sampling period $T$. We test the proposed control strategy via numerical simulations in the scenario of cooperative aerial manipulation of a cable-suspended load using a realistic simulator (Fly-Crane). Finally, we compare our proposed controller with centralized approaches that adapt the feedback gain online through smart heuristics, and show that it achieves comparable performance.",
        "published": "2021-11-30T23:13:28Z",
        "link": "http://arxiv.org/abs/2112.00165v5",
        "categories": [
            "cs.RO",
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "70B15, 70E60, 70Q05, 93C85, 93A16",
            "I.2.9; I.2.8; J.2"
        ]
    },
    {
        "title": "Exploring Social Posterior Collapse in Variational Autoencoder for   Interaction Modeling",
        "authors": [
            "Chen Tang",
            "Wei Zhan",
            "Masayoshi Tomizuka"
        ],
        "summary": "Multi-agent behavior modeling and trajectory forecasting are crucial for the safe navigation of autonomous agents in interactive scenarios. Variational Autoencoder (VAE) has been widely applied in multi-agent interaction modeling to generate diverse behavior and learn a low-dimensional representation for interacting systems. However, existing literature did not formally discuss if a VAE-based model can properly encode interaction into its latent space. In this work, we argue that one of the typical formulations of VAEs in multi-agent modeling suffers from an issue we refer to as social posterior collapse, i.e., the model is prone to ignoring historical social context when predicting the future trajectory of an agent. It could cause significant prediction errors and poor generalization performance. We analyze the reason behind this under-explored phenomenon and propose several measures to tackle it. Afterward, we implement the proposed framework and experiment on real-world datasets for multi-agent trajectory prediction. In particular, we propose a novel sparse graph attention message-passing (sparse-GAMP) layer, which helps us detect social posterior collapse in our experiments. In the experiments, we verify that social posterior collapse indeed occurs. Also, the proposed measures are effective in alleviating the issue. As a result, the model attains better generalization performance when historical social context is informative for prediction.",
        "published": "2021-12-01T06:20:58Z",
        "link": "http://arxiv.org/abs/2112.00298v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Multi-Agent Transfer Learning in Reinforcement Learning-Based   Ride-Sharing Systems",
        "authors": [
            "Alberto Castagna",
            "Ivana Dusparic"
        ],
        "summary": "Reinforcement learning (RL) has been used in a range of simulated real-world tasks, e.g., sensor coordination, traffic light control, and on-demand mobility services. However, real world deployments are rare, as RL struggles with dynamic nature of real world environments, requiring time for learning a task and adapting to changes in the environment. Transfer Learning (TL) can help lower these adaptation times. In particular, there is a significant potential of applying TL in multi-agent RL systems, where multiple agents can share knowledge with each other, as well as with new agents that join the system. To obtain the most from inter-agent transfer, transfer roles (i.e., determining which agents act as sources and which as targets), as well as relevant transfer content parameters (e.g., transfer size) should be selected dynamically in each particular situation. As a first step towards fully dynamic transfers, in this paper we investigate the impact of TL transfer parameters with fixed source and target roles. Specifically, we label every agent-environment interaction with agent's epistemic confidence, and we filter the shared examples using varying threshold levels and sample sizes. We investigate impact of these parameters in two scenarios, a standard predator-prey RL benchmark and a simulation of a ride-sharing system with 200 vehicle agents and 10,000 ride-requests.",
        "published": "2021-12-01T11:23:40Z",
        "link": "http://arxiv.org/abs/2112.00424v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Collective discrete optimisation as judgment aggregation",
        "authors": [
            "Linus Boes",
            "Rachael Colley",
            "Umberto Grandi",
            "Jerome Lang",
            "Arianna Novaro"
        ],
        "summary": "Many important collective decision-making problems can be seen as multi-agent versions of discrete optimisation problems. Participatory budgeting, for instance, is the collective version of the knapsack problem; other examples include collective scheduling, and collective spanning trees. Rather than developing a specific model, as well as specific algorithmic techniques, for each of these problems, we propose to represent and solve them in the unifying framework of judgment aggregation with weighted issues. We provide a modular definition of collective discrete optimisation (CDO) rules based on coupling a set scoring function with an operator, and we show how they generalise several existing procedures developed for specific CDO problems. We also give an implementation based on integer linear programming (ILP) and test it on the problem of collective spanning trees.",
        "published": "2021-12-01T15:40:23Z",
        "link": "http://arxiv.org/abs/2112.00574v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Conditional Expectation based Value Decomposition for Scalable On-Demand   Ride Pooling",
        "authors": [
            "Avinandan Bose",
            "Pradeep Varakantham"
        ],
        "summary": "Owing to the benefits for customers (lower prices), drivers (higher revenues), aggregation companies (higher revenues) and the environment (fewer vehicles), on-demand ride pooling (e.g., Uber pool, Grab Share) has become quite popular. The significant computational complexity of matching vehicles to combinations of requests has meant that traditional ride pooling approaches are myopic in that they do not consider the impact of current matches on future value for vehicles/drivers. Recently, Neural Approximate Dynamic Programming (NeurADP) has employed value decomposition with Approximate Dynamic Programming (ADP) to outperform leading approaches by considering the impact of an individual agent's (vehicle) chosen actions on the future value of that agent. However, in order to ensure scalability and facilitate city-scale ride pooling, NeurADP completely ignores the impact of other agents actions on individual agent/vehicle value. As demonstrated in our experimental results, ignoring the impact of other agents actions on individual value can have a significant impact on the overall performance when there is increased competition among vehicles for demand. Our key contribution is a novel mechanism based on computing conditional expectations through joint conditional probabilities for capturing dependencies on other agents actions without increasing the complexity of training or decision making. We show that our new approach, Conditional Expectation based Value Decomposition (CEVD) outperforms NeurADP by up to 9.76% in terms of overall requests served, which is a significant improvement on a city wide benchmark taxi dataset.",
        "published": "2021-12-01T15:53:16Z",
        "link": "http://arxiv.org/abs/2112.00579v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.CY",
            "cs.MA"
        ]
    },
    {
        "title": "Empirical Game-Theoretic Analysis for Mean Field Games",
        "authors": [
            "Yongzhao Wang",
            "Michael P. Wellman"
        ],
        "summary": "We present a simulation-based approach for solution of mean field games (MFGs), using the framework of empirical game-theoretical analysis (EGTA). Our primary method employs a version of the double oracle, iteratively adding strategies based on best response to the equilibrium of the empirical MFG among strategies considered so far. We present Fictitious Play (FP) and Replicator Dynamics as two subroutines for computing the empirical game equilibrium. Each subroutine is implemented with a query-based method rather than maintaining an explicit payoff matrix as in typical EGTA methods due to a representation issue we highlight for MFGs. By introducing game model learning and regularization, we significantly improve the sample efficiency of the primary method without sacrificing the overall learning performance. Theoretically, we prove that a Nash equilibrium (NE) exists in the empirical MFG and show the convergence of iterative EGTA to NE of the full MFG with either subroutine. We test the performance of iterative EGTA in various games and show that it outperforms directly applying FP to MFGs in terms of iterations of strategy introduction.",
        "published": "2021-12-02T00:48:19Z",
        "link": "http://arxiv.org/abs/2112.00900v5",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Reward-Free Attacks in Multi-Agent Reinforcement Learning",
        "authors": [
            "Ted Fujimoto",
            "Timothy Doster",
            "Adam Attarian",
            "Jill Brandenberger",
            "Nathan Hodas"
        ],
        "summary": "We investigate how effective an attacker can be when it only learns from its victim's actions, without access to the victim's reward. In this work, we are motivated by the scenario where the attacker wants to behave strategically when the victim's motivations are unknown. We argue that one heuristic approach an attacker can use is to maximize the entropy of the victim's policy. The policy is generally not obfuscated, which implies it may be extracted simply by passively observing the victim. We provide such a strategy in the form of a reward-free exploration algorithm that maximizes the attacker's entropy during the exploration phase, and then maximizes the victim's empirical entropy during the planning phase. In our experiments, the victim agents are subverted through policy entropy maximization, implying an attacker might not need access to the victim's reward to succeed. Hence, reward-free attacks, which are based only on observing behavior, show the feasibility of an attacker to act strategically without knowledge of the victim's motives even if the victim's reward information is protected.",
        "published": "2021-12-02T02:36:09Z",
        "link": "http://arxiv.org/abs/2112.00940v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Personalized Federated Learning of Driver Prediction Models for   Autonomous Driving",
        "authors": [
            "Manabu Nakanoya",
            "Junha Im",
            "Hang Qiu",
            "Sachin Katti",
            "Marco Pavone",
            "Sandeep Chinchali"
        ],
        "summary": "Autonomous vehicles (AVs) must interact with a diverse set of human drivers in heterogeneous geographic areas. Ideally, fleets of AVs should share trajectory data to continually re-train and improve trajectory forecasting models from collective experience using cloud-based distributed learning. At the same time, these robots should ideally avoid uploading raw driver interaction data in order to protect proprietary policies (when sharing insights with other companies) or protect driver privacy from insurance companies. Federated learning (FL) is a popular mechanism to learn models in cloud servers from diverse users without divulging private local data. However, FL is often not robust -- it learns sub-optimal models when user data comes from highly heterogeneous distributions, which is a key hallmark of human-robot interactions. In this paper, we present a novel variant of personalized FL to specialize robust robot learning models to diverse user distributions. Our algorithm outperforms standard FL benchmarks by up to 2x in real user studies that we conducted where human-operated vehicles must gracefully merge lanes with simulated AVs in the standard CARLA and CARLO AV simulators.",
        "published": "2021-12-02T03:19:21Z",
        "link": "http://arxiv.org/abs/2112.00956v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "cs.NI",
            "cs.RO"
        ]
    },
    {
        "title": "Distributed Control for a Robotic Swarm to Pass through a Curve Virtual   Tube",
        "authors": [
            "Quan Quan",
            "Yan Gao",
            "Chenggang Bai"
        ],
        "summary": "Robotic swarm systems are now becoming increasingly attractive for many challenging applications. The main task for any robot is to reach the destination while keeping a safe separation from other robots and obstacles. In many scenarios, robots need to move within a narrow corridor, through a window or a doorframe. In order to guide all robots to move in a cluttered environment, a curve virtual tube with no obstacle inside is carefully designed in this paper. There is no obstacle inside the tube, namely the area inside the tube can be seen as a safety zone. Then, a distributed swarm controller is proposed with three elaborate control terms: a line approaching term, a robot avoidance term and a tube keeping term. Formal analysis and proofs are made to show that the curve virtual tube passing problem can be solved in a finite time. For the convenience in practical use, a modified controller with an approximate control performance is put forward. Finally, the effectiveness of the proposed method is validated by numerical simulations and real experiments. To show the advantages of the proposed method, the comparison between our method and the control barrier function method is also presented in terms of calculation speed.",
        "published": "2021-12-02T06:33:36Z",
        "link": "http://arxiv.org/abs/2112.01006v2",
        "categories": [
            "cs.RO",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "How global observation works in Federated Learning: Integrating vertical   training into Horizontal Federated Learning",
        "authors": [
            "Shuo Wan",
            "Jiaxun Lu",
            "Pingyi Fan",
            "Yunfeng Shao",
            "Chenghui Peng",
            "Khaled B. Letaief"
        ],
        "summary": "Federated learning (FL) has recently emerged as a transformative paradigm that jointly train a model with distributed data sets in IoT while avoiding the need for central data collection. Due to the limited observation range, such data sets can only reflect local information, which limits the quality of trained models. In practice, the global information and local observations would require a joint consideration for learning to make a reasonable policy. However, in horizontal FL, the central agency only acts as a model aggregator without utilizing its global observation to further improve the model. This could significantly degrade the performance in some missions such as traffic flow prediction in network systems, where the global information may enhance the accuracy. Meanwhile, the global feature may not be directly transmitted to agents for data security. How to utilize the global observation residing in the central agency while protecting its safety thus rises up as an important problem in FL. In this paper, we develop a vertical-horizontal federated learning (VHFL) process, where the global feature is shared with the agents in a procedure similar to that of vertical FL without any extra communication rounds. By considering the delay and packet loss, we will analyze VHFL convergence and validate its performance by experiments. It is shown that the proposed VHFL could enhance the accuracy compared with horizontal FL while still protecting the security of global data.",
        "published": "2021-12-02T08:02:57Z",
        "link": "http://arxiv.org/abs/2112.01039v3",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.DC",
            "cs.MA",
            "cs.NI"
        ]
    },
    {
        "title": "Multi-Agent Intention Sharing via Leader-Follower Forest",
        "authors": [
            "Zeyang Liu",
            "Lipeng Wan",
            "Xue sui",
            "Kewu Sun",
            "Xuguang Lan"
        ],
        "summary": "Intention sharing is crucial for efficient cooperation under partially observable environments in multi-agent reinforcement learning (MARL). However, message deceiving, i.e., a mismatch between the propagated intentions and the final decisions, may happen when agents change strategies simultaneously according to received intentions. Message deceiving leads to potential miscoordination and difficulty for policy learning. This paper proposes the leader-follower forest (LFF) to learn the hierarchical relationship between agents based on interdependencies, achieving one-sided intention sharing in multi-agent communication. By limiting the flowings of intentions through directed edges, intention sharing via LFF (IS-LFF) can eliminate message deceiving effectively and achieve better coordination. In addition, a twostage learning algorithm is proposed to train the forest and the agent network. We evaluate IS-LFF on multiple partially observable MARL benchmarks, and the experimental results show that our method outperforms state-of-the-art communication algorithms.",
        "published": "2021-12-02T09:37:29Z",
        "link": "http://arxiv.org/abs/2112.01078v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Control of over-redundant cooperative manipulation via sampled   communication",
        "authors": [
            "Enrica Rossi",
            "Marco Tognon",
            "Ruggero Carli",
            "Antonio Franchi",
            "Luca Schenato"
        ],
        "summary": "In this work we consider the problem of mobile robots that need to manipulate/transport an object via cables or robotic arms. We consider the scenario where the number of manipulating robots is redundant, i.e. a desired object configuration can be obtained by different configurations of the robots. The objective of this work is to show that communication can be used to implement cooperative local feedback controllers in the robots to improve disturbance rejection and reduce structural stress in the object. In particular we consider the realistic scenario where measurements are sampled and transmitted over wireless, and the sampling period is comparable with the system dynamics time constants. We first propose a kinematic model which is consistent with the overall systems dynamics under high-gain control and then we provide sufficient conditions for the exponential stability and monotonic decrease of the configuration error under different norms. Finally, we test the proposed controllers on the full dynamical systems showing the benefit of local communication.",
        "published": "2021-12-02T10:33:09Z",
        "link": "http://arxiv.org/abs/2112.01107v1",
        "categories": [
            "cs.RO",
            "cs.MA",
            "93A16"
        ]
    },
    {
        "title": "Multi-scale simulation of COVID-19 epidemics",
        "authors": [
            "Benoit Doussin",
            "Carole Adam",
            "Didier Georges"
        ],
        "summary": "Over a year after the start of the COVID-19 epidemics, we are still facing the virus and it is hard to correctly predict its future spread over weeks to come, as well as the impacts of potential political interventions. Current epidemic models mainly fall in two approaches: compartmental models, divide the population in epidemiological classes and rely on the mathematical resolution of differential equations to give a macroscopic view of the epidemical dynamics, allowing to evaluate its spread a posteriori; agent-based models are computer models that give a microscopic view of the situation, since each human is modelled as one autonomous agent, allowing to study the epidemical dynamics in relation to (heterogeneous) individual behaviours. In this work, we compared both methodologies and combined them to try and take advantage of the benefits of each, and to overcome their limits. In particular, agent-based simulation can be used to refine the values of the parameters of a compartmental model, or to predict how these values evolve depending on sanitary policies applied. In this report we discuss the conditions of such a combination of approaches, and future improvements.",
        "published": "2021-12-02T12:34:11Z",
        "link": "http://arxiv.org/abs/2112.01167v1",
        "categories": [
            "cs.MA",
            "cs.CY",
            "physics.soc-ph",
            "q-bio.PE"
        ]
    },
    {
        "title": "Resonating Minds -- Emergent Collaboration Through Hierarchical Active   Inference",
        "authors": [
            "Jan Pöppel",
            "Sebastian Kahl",
            "Stefan Kopp"
        ],
        "summary": "Working together on complex collaborative tasks requires agents to coordinate their actions. Doing this explicitly or completely prior to the actual interaction is not always possible nor sufficient. Agents also need to continuously understand the current actions of others and quickly adapt their own behavior appropriately. Here we investigate how efficient, automatic coordination processes at the level of mental states (intentions, goals), which we call belief resonance, can lead to collaborative situated problem-solving. We present a model of hierarchical active inference for collaborative agents (HAICA). It combines efficient Bayesian Theory of Mind processes with a perception-action system based on predictive processing and active inference. Belief resonance is realized by letting the inferred mental states of one agent influence another agent's predictive beliefs about its own goals and intentions. This way, the inferred mental states influence the agent's own task behavior without explicit collaborative reasoning. We implement and evaluate this model in the Overcooked domain, in which two agents with varying degrees of belief resonance team up to fulfill meal orders. Our results demonstrate that agents based on HAICA achieve a team performance comparable to recent state of the art approaches, while incurring much lower computational costs. We also show that belief resonance is especially beneficial in settings were the agents have asymmetric knowledge about the environment. The results indicate that belief resonance and active inference allow for quick and efficient agent coordination, and thus can serve as a building block for collaborative cognitive agents.",
        "published": "2021-12-02T13:23:44Z",
        "link": "http://arxiv.org/abs/2112.01210v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Push-sum Distributed Dual Averaging for Convex Optimization in   Multi-agent Systems with Communication Delays",
        "authors": [
            "Cong Wang",
            "Shengyuan Xu",
            "Deming Yuan",
            "Baoyong Zhang",
            "Zhengqiang Zhang"
        ],
        "summary": "The distributed convex optimization problem over the multi-agent system is considered in this paper, and it is assumed that each agent possesses its own cost function and communicates with its neighbours over a sequence of time-varying directed graphs. However, due to some reasons there exist communication delays while agents receive information from other agents, and we are going to seek the optimal value of the sum of agents' loss functions in this case. We desire to handle this problem with the push-sum distributed dual averaging (PS-DDA) algorithm. It is proved that this algorithm converges and the error decays at a rate $\\mathcal{O}\\left(T^{-0.5}\\right)$ with proper step size, where $T$ is iteration span. The main result presented in this paper also illustrates the convergence of the proposed algorithm is related to the maximum value of the communication delay on one edge. We finally apply the theoretical results to numerical simulations to show the PS-DDA algorithm's performance.",
        "published": "2021-12-03T06:12:28Z",
        "link": "http://arxiv.org/abs/2112.01731v2",
        "categories": [
            "math.OC",
            "cs.MA"
        ]
    },
    {
        "title": "Episodic Policy Gradient Training",
        "authors": [
            "Hung Le",
            "Majid Abdolshah",
            "Thommen K. George",
            "Kien Do",
            "Dung Nguyen",
            "Svetha Venkatesh"
        ],
        "summary": "We introduce a novel training procedure for policy gradient methods wherein episodic memory is used to optimize the hyperparameters of reinforcement learning algorithms on-the-fly. Unlike other hyperparameter searches, we formulate hyperparameter scheduling as a standard Markov Decision Process and use episodic memory to store the outcome of used hyperparameters and their training contexts. At any policy update step, the policy learner refers to the stored experiences, and adaptively reconfigures its learning algorithm with the new hyperparameters determined by the memory. This mechanism, dubbed as Episodic Policy Gradient Training (EPGT), enables an episodic learning process, and jointly learns the policy and the learning algorithm's hyperparameters within a single run. Experimental results on both continuous and discrete environments demonstrate the advantage of using the proposed method in boosting the performance of various policy gradient algorithms.",
        "published": "2021-12-03T11:15:32Z",
        "link": "http://arxiv.org/abs/2112.01853v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Learning a Robust Multiagent Driving Policy for Traffic Congestion   Reduction",
        "authors": [
            "Yulin Zhang",
            "William Macke",
            "Jiaxun Cui",
            "Daniel Urieli",
            "Peter Stone"
        ],
        "summary": "In most modern cities, traffic congestion is one of the most salient societal challenges. Past research has shown that inserting a limited number of autonomous vehicles (AVs) within the traffic flow, with driving policies learned specifically for the purpose of reducing congestion, can significantly improve traffic conditions. However, to date these AV policies have generally been evaluated under the same limited conditions under which they were trained. On the other hand, to be considered for practical deployment, they must be robust to a wide variety of traffic conditions. This article establishes for the first time that a multiagent driving policy can be trained in such a way that it generalizes to different traffic flows, AV penetration, and road geometries, including on multi-lane roads. Inspired by our successful results in a high-fidelity microsimulation, this article further contributes a novel extension of the well-known Cell Transmission Model (CTM) that, unlike past CTMs, is suitable for modeling congestion in traffic networks, and is thus suitable for studying congestion-reduction policies such as those considered in this article.",
        "published": "2021-12-03T18:53:34Z",
        "link": "http://arxiv.org/abs/2112.03759v3",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Distributed Adaptive Learning Under Communication Constraints",
        "authors": [
            "Marco Carpentiero",
            "Vincenzo Matta",
            "Ali H. Sayed"
        ],
        "summary": "This work examines adaptive distributed learning strategies designed to operate under communication constraints. We consider a network of agents that must solve an online optimization problem from continual observation of streaming data. The agents implement a distributed cooperative strategy where each agent is allowed to perform local exchange of information with its neighbors. In order to cope with communication constraints, the exchanged information must be unavoidably compressed. We propose a diffusion strategy nicknamed as ACTC (Adapt-Compress-Then-Combine), which relies on the following steps: i) an adaptation step where each agent performs an individual stochastic-gradient update with constant step-size; ii) a compression step that leverages a recently introduced class of stochastic compression operators; and iii) a combination step where each agent combines the compressed updates received from its neighbors. The distinguishing elements of this work are as follows. First, we focus on adaptive strategies, where constant (as opposed to diminishing) step-sizes are critical to respond in real time to nonstationary variations. Second, we consider the general class of directed graphs and left-stochastic combination policies, which allow us to enhance the interplay between topology and learning. Third, in contrast with related works that assume strong convexity for all individual agents' cost functions, we require strong convexity only at a network level, a condition satisfied even if a single agent has a strongly-convex cost and the remaining agents have non-convex costs. Fourth, we focus on a diffusion (as opposed to consensus) strategy. Under the demanding setting of compressed information, we establish that the ACTC iterates fluctuate around the desired optimizer, achieving remarkable savings in terms of bits exchanged between neighboring agents.",
        "published": "2021-12-03T19:23:48Z",
        "link": "http://arxiv.org/abs/2112.02129v1",
        "categories": [
            "cs.LG",
            "cs.IT",
            "cs.MA",
            "math.IT",
            "math.OC",
            "stat.ML"
        ]
    },
    {
        "title": "Efficient Calibration of Multi-Agent Simulation Models from Output   Series with Bayesian Optimization",
        "authors": [
            "Yuanlu Bai",
            "Henry Lam",
            "Svitlana Vyetrenko",
            "Tucker Balch"
        ],
        "summary": "Multi-agent simulation is commonly used across multiple disciplines, specifically in artificial intelligence in recent years, which creates an environment for downstream machine learning or reinforcement learning tasks. In many practical scenarios, however, only the output series that result from the interactions of simulation agents are observable. Therefore, simulators need to be calibrated so that the simulated output series resemble historical -- which amounts to solving a complex simulation optimization problem. In this paper, we propose a simple and efficient framework for calibrating simulator parameters from historical output series observations. First, we consider a novel concept of eligibility set to bypass the potential non-identifiability issue. Second, we generalize the two-sample Kolmogorov-Smirnov (K-S) test with Bonferroni correction to test the similarity between two high-dimensional distributions, which gives a simple yet effective distance metric between the output series sample sets. Third, we suggest using Bayesian optimization (BO) and trust-region BO (TuRBO) to minimize the aforementioned distance metric. Finally, we demonstrate the efficiency of our framework using numerical experiments both on a multi-agent financial market simulator.",
        "published": "2021-12-03T22:57:46Z",
        "link": "http://arxiv.org/abs/2112.03874v2",
        "categories": [
            "q-fin.ST",
            "cs.AI",
            "cs.CE",
            "cs.LG",
            "cs.MA",
            "stat.ME"
        ]
    },
    {
        "title": "Cooperation, Retaliation and Forgiveness in Revision Games",
        "authors": [
            "Dong Hao",
            "Qi Shi",
            "Jinyan Su",
            "Bo An"
        ],
        "summary": "Revision game is a very new model formulating the real-time situation where players dynamically prepare and revise their actions in advance before a deadline when payoffs are realized. It is at the cutting edge of dynamic game theory and can be applied in many real-world scenarios, such as eBay auction, stock market, election, online games, crowdsourcing, etc. In this work, we novelly identify a class of strategies for revision games which are called Limited Retaliation strategies. An limited retaliation strategy stipulates that, (1) players first follow a recommended cooperative plan; (2) if anyone deviates from the plan, the limited retaliation player retaliates by using the defection action for a limited duration; (3) after the retaliation, the limited retaliation player returns to the cooperative plan. A limited retaliation strategy has three key features. It is cooperative, sustaining a high level of social welfare. It is vengeful, deterring the opponent from betrayal by threatening with a future retaliation. It is yet forgiving, since it resumes cooperation after a proper retaliation. The cooperativeness and vengefulness make it constitute cooperative subgame perfect equilibrium, while the forgiveness makes it tolerate occasional mistakes. limited retaliation strategies show significant advantages over Grim Trigger, which is currently the only known strategy for revision games. Besides its contribution as a new robust and welfare-optimizing equilibrium strategy, our results about limited retaliation strategy can also be used to explain how easy cooperation can happen, and why forgiveness emerges in real-world multi-agent interactions. In addition, limited retaliation strategies are simple to derive and computationally efficient, making it easy for algorithm design and implementation in many multi-agent systems.",
        "published": "2021-12-04T07:40:09Z",
        "link": "http://arxiv.org/abs/2112.02271v4",
        "categories": [
            "cs.GT",
            "cs.MA",
            "econ.TH"
        ]
    },
    {
        "title": "LIGS: Learnable Intrinsic-Reward Generation Selection for Multi-Agent   Learning",
        "authors": [
            "David Henry Mguni",
            "Taher Jafferjee",
            "Jianhong Wang",
            "Oliver Slumbers",
            "Nicolas Perez-Nieves",
            "Feifei Tong",
            "Li Yang",
            "Jiangcheng Zhu",
            "Yaodong Yang",
            "Jun Wang"
        ],
        "summary": "Efficient exploration is important for reinforcement learners to achieve high rewards. In multi-agent systems, coordinated exploration and behaviour is critical for agents to jointly achieve optimal outcomes. In this paper, we introduce a new general framework for improving coordination and performance of multi-agent reinforcement learners (MARL). Our framework, named Learnable Intrinsic-Reward Generation Selection algorithm (LIGS) introduces an adaptive learner, Generator that observes the agents and learns to construct intrinsic rewards online that coordinate the agents' joint exploration and joint behaviour. Using a novel combination of MARL and switching controls, LIGS determines the best states to learn to add intrinsic rewards which leads to a highly efficient learning process. LIGS can subdivide complex tasks making them easier to solve and enables systems of MARL agents to quickly solve environments with sparse rewards. LIGS can seamlessly adopt existing MARL algorithms and, our theory shows that it ensures convergence to policies that deliver higher system performance. We demonstrate its superior performance in challenging tasks in Foraging and StarCraft II.",
        "published": "2021-12-05T16:50:23Z",
        "link": "http://arxiv.org/abs/2112.02618v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Learning Swarm Interaction Dynamics from Density Evolution",
        "authors": [
            "Christos Mavridis",
            "Amoolya Tirumalai",
            "John Baras"
        ],
        "summary": "We consider the problem of understanding the coordinated movements of biological or artificial swarms. In this regard, we propose a learning scheme to estimate the coordination laws of the interacting agents from observations of the swarm's density over time. We describe the dynamics of the swarm based on pairwise interactions according to a Cucker-Smale flocking model, and express the swarm's density evolution as the solution to a system of mean-field hydrodynamic equations. We propose a new family of parametric functions to model the pairwise interactions, which allows for the mean-field macroscopic system of integro-differential equations to be efficiently solved as an augmented system of PDEs. Finally, we incorporate the augmented system in an iterative optimization scheme to learn the dynamics of the interacting agents from observations of the swarm's density evolution over time. The results of this work can offer an alternative approach to study how animal flocks coordinate, create new control schemes for large networked systems, and serve as a central part of defense mechanisms against adversarial drone attacks.",
        "published": "2021-12-05T20:18:48Z",
        "link": "http://arxiv.org/abs/2112.02675v1",
        "categories": [
            "eess.SY",
            "cs.LG",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Unfairness Despite Awareness: Group-Fair Classification with Strategic   Agents",
        "authors": [
            "Andrew Estornell",
            "Sanmay Das",
            "Yang Liu",
            "Yevgeniy Vorobeychik"
        ],
        "summary": "The use of algorithmic decision making systems in domains which impact the financial, social, and political well-being of people has created a demand for these decision making systems to be \"fair\" under some accepted notion of equity. This demand has in turn inspired a large body of work focused on the development of fair learning algorithms which are then used in lieu of their conventional counterparts. Most analysis of such fair algorithms proceeds from the assumption that the people affected by the algorithmic decisions are represented as immutable feature vectors. However, strategic agents may possess both the ability and the incentive to manipulate this observed feature vector in order to attain a more favorable outcome. We explore the impact that strategic agent behavior could have on fair classifiers and derive conditions under which this behavior leads to fair classifiers becoming less fair than their conventional counterparts under the same measure of fairness that the fair classifier takes into account. These conditions are related to the the way in which the fair classifier remedies unfairness on the original unmanipulated data: fair classifiers which remedy unfairness by becoming more selective than their conventional counterparts are the ones that become less fair than their counterparts when agents are strategic. We further demonstrate that both the increased selectiveness of the fair classifier, and consequently the loss of fairness, arises when performing fair learning on domains in which the advantaged group is overrepresented in the region near (and on the beneficial side of) the decision boundary of conventional classifiers. Finally, we observe experimentally, using several datasets and learning methods, that this fairness reversal is common, and that our theoretical characterization of the fairness reversal conditions indeed holds in most such cases.",
        "published": "2021-12-06T02:42:43Z",
        "link": "http://arxiv.org/abs/2112.02746v1",
        "categories": [
            "cs.MA",
            "cs.CY",
            "cs.GT",
            "cs.LG"
        ]
    },
    {
        "title": "Learning-based Measurement Scheduling for Loosely-Coupled Cooperative   Localization",
        "authors": [
            "Jianan Zhu",
            "Solmaz S. Kia"
        ],
        "summary": "In cooperative localization, communicating mobile agents use inter-agent relative measurements to improve their dead-reckoning-based global localization. Measurement scheduling enables an agent to decide which subset of available inter-agent relative measurements it should process when its computational resources are limited. Optimal measurement scheduling is an NP-hard combinatorial optimization problem. The so-called sequential greedy (SG) algorithm is a popular suboptimal polynomial-time solution for this problem. However, the merit function evaluation for the SG algorithms requires access to the state estimate vector and error covariance matrix of all the landmark agents (teammates that an agent can take measurements from). This paper proposes a measurement scheduling for CL that follows the SG approach but reduces the communication and computation cost by using a neural network-based surrogate model as a proxy for the SG algorithm's merit function. The significance of this model is that it is driven by local information and only a scalar metadata from the landmark agents. This solution addresses the time and memory complexity issues of running the SG algorithm in three ways: (a) reducing the inter-agent communication message size, (b) decreasing the complexity of function evaluations by using a simpler surrogate (proxy) function, (c) reducing the required memory size.Simulations demonstrate our results.",
        "published": "2021-12-06T08:06:29Z",
        "link": "http://arxiv.org/abs/2112.02843v1",
        "categories": [
            "cs.RO",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Offline Pre-trained Multi-Agent Decision Transformer: One Big Sequence   Model Tackles All SMAC Tasks",
        "authors": [
            "Linghui Meng",
            "Muning Wen",
            "Yaodong Yang",
            "Chenyang Le",
            "Xiyun Li",
            "Weinan Zhang",
            "Ying Wen",
            "Haifeng Zhang",
            "Jun Wang",
            "Bo Xu"
        ],
        "summary": "Offline reinforcement learning leverages previously-collected offline datasets to learn optimal policies with no necessity to access the real environment. Such a paradigm is also desirable for multi-agent reinforcement learning (MARL) tasks, given the increased interactions among agents and with the enviroment. Yet, in MARL, the paradigm of offline pre-training with online fine-tuning has not been studied, nor datasets or benchmarks for offline MARL research are available. In this paper, we facilitate the research by providing large-scale datasets, and use them to examine the usage of the Decision Transformer in the context of MARL. We investigate the generalisation of MARL offline pre-training in the following three aspects: 1) between single agents and multiple agents, 2) from offline pretraining to the online fine-tuning, and 3) to that of multiple downstream tasks with few-shot and zero-shot capabilities. We start by introducing the first offline MARL dataset with diverse quality levels based on the StarCraftII environment, and then propose the novel architecture of multi-agent decision transformer (MADT) for effective offline learning. MADT leverages transformer's modelling ability of sequence modelling and integrates it seamlessly with both offline and online MARL tasks. A crucial benefit of MADT is that it learns generalisable policies that can transfer between different types of agents under different task scenarios. On StarCraft II offline dataset, MADT outperforms the state-of-the-art offline RL baselines. When applied to online tasks, the pre-trained MADT significantly improves sample efficiency, and enjoys strong performance both few-short and zero-shot cases. To our best knowledge, this is the first work that studies and demonstrates the effectiveness of offline pre-trained models in terms of sample efficiency and generalisability enhancements in MARL.",
        "published": "2021-12-06T08:11:05Z",
        "link": "http://arxiv.org/abs/2112.02845v3",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "A Synergy of Institutional Incentives and Networked Structures in   Evolutionary Game Dynamics of Multi-agent Systems",
        "authors": [
            "Ik Soo Lim",
            "Valerio Capraro"
        ],
        "summary": "Understanding the emergence of prosocial behaviours (e.g., cooperation and trust) among self-interested agents is an important problem in many disciplines. Network structure and institutional incentives (e.g., punishing antisocial agents) are known to promote prosocial behaviours, when acting in isolation, one mechanism being present at a time. Here we study the interplay between these two mechanisms to see whether they are independent, interfering or synergetic. Using evolutionary game theory, we show that punishing antisocial agents and a regular networked structure not only promote prosocial behaviours among agents playing the trust game, but they also interplay with each other, leading to interference or synergy, depending on the game parameters. Synergy emerges on a wider range of parameters than interference does. In this domain, the combination of incentives and networked structure improves the efficiency of incentives, yielding prosocial behaviours at a lower cost than the incentive does alone. This has a significant implication in the promotion of prosocial behaviours in multi-agent systems.",
        "published": "2021-12-06T15:23:23Z",
        "link": "http://arxiv.org/abs/2112.03112v2",
        "categories": [
            "physics.soc-ph",
            "cs.GT",
            "cs.MA",
            "q-bio.PE"
        ]
    },
    {
        "title": "A Survey of Verification, Validation and Testing Solutions for Smart   Contracts",
        "authors": [
            "Chaïmaa Benabbou",
            "Önder Gürcan"
        ],
        "summary": "Smart contracts are programs stored on a blockchain that run when predetermined conditions are met. However, designing and implementing a smart contract is not trivial since upon deployment on a blockchain, it is no longer possible to modify it (neither for improving nor for bug fixing). It is only possible by deploying a new version of the smart contract which is costly (deployment cost for the new contract and destruction cost for the old contract). To this end, there are many solutions for testing the smart contracts before their deployment. Since realizing bug-free smart contracts increase the reliability, as well as reduce the cost, testing is an essential activity. In this paper, we group the existing solutions that attempt to tackle smart contract testing into following categories: public test networks, security analysis tools, blockchain emulators and blockchain simulators. Then, we analyze these solutions, categorize them and show what their pros and cons are.",
        "published": "2021-12-07T00:00:34Z",
        "link": "http://arxiv.org/abs/2112.03426v1",
        "categories": [
            "cs.SE",
            "cs.DC",
            "cs.MA"
        ]
    },
    {
        "title": "Peer-to-Peer Energy Trading in a Microgrid Leveraged by Smart Contracts",
        "authors": [
            "Guilherme Vieira",
            "Jie Zhang"
        ],
        "summary": "The current electricity networks were not initially designed for the high integration of variable generation technologies. They suffer significant losses due to the combustion of fossil fuels, the long-distance transmission, and distribution of the power to the network. Recently, \\emph{prosumers}, both consumers and producers, emerge with the increasing affordability to invest in domestic solar systems. Prosumers may trade within their communities to better manage their demand and supply as well as providing social and economic benefits. In this paper, we explore the use of Blockchain technologies and auction mechanisms to facilitate autonomous peer-to-peer energy trading within microgrids. We design two frameworks that utilize the smart contract functionality in Ethereum and employ the continuous double auction and uniform-price double-sided auction mechanisms, respectively. We validate our design by conducting A/B tests to compare the performance of different frameworks on a real-world dataset. The key characteristics of the two frameworks and several cost analyses are presented for comparison. Our results demonstrate that a P2P trading platform that integrates the blockchain technologies and agent-based systems is promising to complement the current centralized energy grid. We also identify a number of limitations, alternative solutions, and directions for future work.",
        "published": "2021-12-07T00:25:00Z",
        "link": "http://arxiv.org/abs/2201.04944v1",
        "categories": [
            "cs.MA",
            "cs.GT"
        ]
    },
    {
        "title": "Self-Organized Polynomial-Time Coordination Graphs",
        "authors": [
            "Qianlan Yang",
            "Weijun Dong",
            "Zhizhou Ren",
            "Jianhao Wang",
            "Tonghan Wang",
            "Chongjie Zhang"
        ],
        "summary": "Coordination graph is a promising approach to model agent collaboration in multi-agent reinforcement learning. It conducts a graph-based value factorization and induces explicit coordination among agents to complete complicated tasks. However, one critical challenge in this paradigm is the complexity of greedy action selection with respect to the factorized values. It refers to the decentralized constraint optimization problem (DCOP), which and whose constant-ratio approximation are NP-hard problems. To bypass this systematic hardness, this paper proposes a novel method, named Self-Organized Polynomial-time Coordination Graphs (SOP-CG), which uses structured graph classes to guarantee the accuracy and the computational efficiency of collaborated action selection. SOP-CG employs dynamic graph topology to ensure sufficient value function expressiveness. The graph selection is unified into an end-to-end learning paradigm. In experiments, we show that our approach learns succinct and well-adapted graph topologies, induces effective coordination, and improves performance across a variety of cooperative multi-agent tasks.",
        "published": "2021-12-07T07:42:40Z",
        "link": "http://arxiv.org/abs/2112.03547v4",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "The Partially Observable Asynchronous Multi-Agent Cooperation Challenge",
        "authors": [
            "Meng Yao",
            "Qiyue Yin",
            "Jun Yang",
            "Tongtong Yu",
            "Shengqi Shen",
            "Junge Zhang",
            "Bin Liang",
            "Kaiqi Huang"
        ],
        "summary": "Multi-agent reinforcement learning (MARL) has received increasing attention for its applications in various domains. Researchers have paid much attention on its partially observable and cooperative settings for meeting real-world requirements. For testing performance of different algorithms, standardized environments are designed such as the StarCraft Multi-Agent Challenge, which is one of the most successful MARL benchmarks. To our best knowledge, most of current environments are synchronous, where agents execute actions in the same pace. However, heterogeneous agents usually have their own action spaces and there is no guarantee for actions from different agents to have the same executed cycle, which leads to asynchronous multi-agent cooperation. Inspired from the Wargame, a confrontation game between two armies abstracted from real world environment, we propose the first Partially Observable Asynchronous multi-agent Cooperation challenge (POAC) for the MARL community. Specifically, POAC supports two teams of heterogeneous agents to fight with each other, where an agent selects actions based on its own observations and cooperates asynchronously with its allies. Moreover, POAC is a light weight, flexible and easy to use environment, which can be configured by users to meet different experimental requirements such as self-play model, human-AI model and so on. Along with our benchmark, we offer six game scenarios of varying difficulties with the built-in rule-based AI as opponents. Finally, since most MARL algorithms are designed for synchronous agents, we revise several representatives to meet the asynchronous setting, and the relatively poor experimental results validate the challenge of POAC. Source code is released in \\url{http://turingai.ia.ac.cn/data\\_center/show}.",
        "published": "2021-12-07T16:35:14Z",
        "link": "http://arxiv.org/abs/2112.03809v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Greedy-based Value Representation for Optimal Coordination in   Multi-agent Reinforcement Learning",
        "authors": [
            "Lipeng Wan",
            "Zeyang Liu",
            "Xingyu Chen",
            "Han Wang",
            "Xuguang Lan"
        ],
        "summary": "Due to the representation limitation of the joint Q value function, multi-agent reinforcement learning methods with linear value decomposition (LVD) or monotonic value decomposition (MVD) suffer from relative overgeneralization. As a result, they can not ensure optimal consistency (i.e., the correspondence between individual greedy actions and the maximal true Q value). In this paper, we derive the expression of the joint Q value function of LVD and MVD. According to the expression, we draw a transition diagram, where each self-transition node (STN) is a possible convergence. To ensure optimal consistency, the optimal node is required to be the unique STN. Therefore, we propose the greedy-based value representation (GVR), which turns the optimal node into an STN via inferior target shaping and further eliminates the non-optimal STNs via superior experience replay. In addition, GVR achieves an adaptive trade-off between optimality and stability. Our method outperforms state-of-the-art baselines in experiments on various benchmarks. Theoretical proofs and empirical results on matrix games demonstrate that GVR ensures optimal consistency under sufficient exploration.",
        "published": "2021-12-08T18:26:26Z",
        "link": "http://arxiv.org/abs/2112.04454v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Learning Generalizable Multi-Lane Mixed-Autonomy Behaviors in Single   Lane Representations of Traffic",
        "authors": [
            "Abdul Rahman Kreidieh",
            "Yibo Zhao",
            "Samyak Parajuli",
            "Alexandre Bayen"
        ],
        "summary": "Reinforcement learning techniques can provide substantial insights into the desired behaviors of future autonomous driving systems. By optimizing for societal metrics of traffic such as increased throughput and reduced energy consumption, such methods can derive maneuvers that, if adopted by even a small portion of vehicles, may significantly improve the state of traffic for all vehicles involved. These methods, however, are hindered in practice by the difficulty of designing efficient and accurate models of traffic, as well as the challenges associated with optimizing for the behaviors of dozens of interacting agents. In response to these challenges, this paper tackles the problem of learning generalizable traffic control strategies in simple representations of vehicle driving dynamics. In particular, we look to mixed-autonomy ring roads as depictions of instabilities that result in the formation of congestion. Within this problem, we design a curriculum learning paradigm that exploits the natural extendability of the network to effectively learn behaviors that reduce congestion over long horizons. Next, we study the implications of modeling lane changing on the transferability of policies. Our findings suggest that introducing lane change behaviors that even approximately match trends in more complex systems can significantly improve the generalizability of subsequent learned models to more accurate multi-lane models of traffic.",
        "published": "2021-12-09T04:02:27Z",
        "link": "http://arxiv.org/abs/2112.04688v2",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Cooperative Multi-Agent Reinforcement Learning with Hypergraph   Convolution",
        "authors": [
            "Yunpeng Bai",
            "Chen Gong",
            "Bin Zhang",
            "Guoliang Fan",
            "Xinwen Hou",
            "Yu Liu"
        ],
        "summary": "Recent years have witnessed the great success of multi-agent systems (MAS). Value decomposition, which decomposes joint action values into individual action values, has been an important work in MAS. However, many value decomposition methods ignore the coordination among different agents, leading to the notorious \"lazy agents\" problem. To enhance the coordination in MAS, this paper proposes HyperGraph CoNvolution MIX (HGCN-MIX), a method that incorporates hypergraph convolution with value decomposition. HGCN-MIX models agents as well as their relationships as a hypergraph, where agents are nodes and hyperedges among nodes indicate that the corresponding agents can coordinate to achieve larger rewards. Then, it trains a hypergraph that can capture the collaborative relationships among agents. Leveraging the learned hypergraph to consider how other agents' observations and actions affect their decisions, the agents in a MAS can better coordinate. We evaluate HGCN-MIX in the StarCraft II multi-agent challenge benchmark. The experimental results demonstrate that HGCN-MIX can train joint policies that outperform or achieve a similar level of performance as the current state-of-the-art techniques. We also observe that HGCN-MIX has an even more significant improvement of performance in the scenarios with a large amount of agents. Besides, we conduct additional analysis to emphasize that when the hypergraph learns more relationships, HGCN-MIX can train stronger joint policies.",
        "published": "2021-12-09T08:40:38Z",
        "link": "http://arxiv.org/abs/2112.06771v2",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Justifying the Dependability and Security of Business-Critical   Blockchain-based Applications",
        "authors": [
            "Pierre-Yves Piriou",
            "Olivier Boudeville",
            "Gilles Deleuze",
            "Sara Tucci-Piergiovanni",
            "Önder Gürcan"
        ],
        "summary": "In the industry, blockchains are increasingly used as the backbone of product and process traceability. Blockchain-based traceability participates in the demonstration of product and/or process compliance with existing safety standards or quality criteria. In this perspective, services and applications built on top of blockchains are business-critical applications, because an intended failure or corruption of the system can lead to an important reputation loss regarding the products or the processes involved. The development of a blockchain-based business-critical application must be then conducted carefully, requiring a thorough justification of its dependability and security. To this end, this paper encourages an engineering perspective rooted in well-understood tools and concepts borrowed from the engineering of safety-critical systems. Concretely, we use a justification framework, called CAE (Claim, Argument, Evidence), by following an approach based on assurance cases, in order to provide convincing arguments that a business-critical blockchain-based application is dependable and secure. The application of this approach is sketched with a case study based on the blockchain HYPERLEDGER FABRIC.",
        "published": "2021-12-09T09:07:23Z",
        "link": "http://arxiv.org/abs/2112.04778v1",
        "categories": [
            "cs.SE",
            "cs.CR",
            "cs.DC",
            "cs.MA"
        ]
    },
    {
        "title": "Paradigms of Computational Agency",
        "authors": [
            "Srinath Srinivasa",
            "Jayati Deshmukh"
        ],
        "summary": "Agent-based models have emerged as a promising paradigm for addressing ever increasing complexity of information systems. In its initial days in the 1990s when object-oriented modeling was at its peak, an agent was treated as a special kind of \"object\" that had a persistent state and its own independent thread of execution. Since then, agent-based models have diversified enormously to even open new conceptual insights about the nature of systems in general. This paper presents a perspective on the disparate ways in which our understanding of agency, as well as computational models of agency have evolved. Advances in hardware like GPUs, that brought neural networks back to life, may also similarly infuse new life into agent-based models, as well as pave the way for advancements in research on Artificial General Intelligence (AGI).",
        "published": "2021-12-10T14:42:49Z",
        "link": "http://arxiv.org/abs/2112.05575v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "A General Auxiliary Controller for Multi-agent Flocking",
        "authors": [
            "Jinfan Zhou",
            "Jiyu Cheng",
            "Lin Zhang",
            "Wei Zhang"
        ],
        "summary": "We aim to improve the performance of multi-agent flocking behavior by quantifying the structural significance of each agent. We designed a confidence score(ConfScore) to measure the spatial significance of each agent. The score will be used by an auxiliary controller to refine the velocity of agents. The agents will be enforced to follow the motion of the leader agents whose ConfScores are high. We demonstrate the efficacy of the auxiliary controller by applying it to several existing algorithms including learning-based and non-learning-based methods. Furthermore, we examined how the auxiliary controller can help improve the performance under different settings of communication radius, number of agents and maximum initial velocity.",
        "published": "2021-12-11T16:51:00Z",
        "link": "http://arxiv.org/abs/2112.06023v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Autonomous Racing with Multiple Vehicles using a Parallelized   Optimization with Safety Guarantee using Control Barrier Functions",
        "authors": [
            "Suiyi He",
            "Jun Zeng",
            "Koushil Sreenath"
        ],
        "summary": "This paper presents a novel planning and control strategy for competing with multiple vehicles in a car racing scenario. The proposed racing strategy switches between two modes. When there are no surrounding vehicles, a learning-based model predictive control (MPC) trajectory planner is used to guarantee that the ego vehicle achieves better lap timing performance. When the ego vehicle is competing with other surrounding vehicles to overtake, an optimization-based planner generates multiple dynamically-feasible trajectories through parallel computation. Each trajectory is optimized under a MPC formulation with different homotopic Bezier-curve reference paths lying laterally between surrounding vehicles. The time-optimal trajectory among these different homotopic trajectories is selected and a low-level MPC controller with control barrier function constraints for obstacle avoidance is used to guarantee system's safety-critical performance. The proposed algorithm has the capability to generate collision-free trajectories and track them while enhancing the lap timing performance with steady low computational complexity, outperforming existing approaches in both timing and performance for a autonomous racing environment. To demonstrate the performance of our racing strategy, we simulate with multiple randomly generated moving vehicles on the track and test the ego vehicle's overtake maneuvers.",
        "published": "2021-12-13T06:25:16Z",
        "link": "http://arxiv.org/abs/2112.06435v3",
        "categories": [
            "cs.RO",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "On Nash Equilibria in Normal-Form Games With Vectorial Payoffs",
        "authors": [
            "Willem Röpke",
            "Diederik M. Roijers",
            "Ann Nowé",
            "Roxana Rădulescu"
        ],
        "summary": "We provide an in-depth study of Nash equilibria in multi-objective normal form games (MONFGs), i.e., normal form games with vectorial payoffs. Taking a utility-based approach, we assume that each player's utility can be modelled with a utility function that maps a vector to a scalar utility. In the case of a mixed strategy, it is meaningful to apply such a scalarisation both before calculating the expectation of the payoff vector as well as after. This distinction leads to two optimisation criteria. With the first criterion, players aim to optimise the expected value of their utility function applied to the payoff vectors obtained in the game. With the second criterion, players aim to optimise the utility of expected payoff vectors given a joint strategy. Under this latter criterion, it was shown that Nash equilibria need not exist. Our first contribution is to provide a sufficient condition under which Nash equilibria are guaranteed to exist. Secondly, we show that when Nash equilibria do exist under both criteria, no equilibrium needs to be shared between the two criteria, and even the number of equilibria can differ. Thirdly, we contribute a study of pure strategy Nash equilibria under both criteria. We show that when assuming quasiconvex utility functions for players, the sets of pure strategy Nash equilibria under both optimisation criteria are equivalent. This result is further extended to games in which players adhere to different optimisation criteria. Finally, given these theoretical results, we construct an algorithm to compute all pure strategy Nash equilibria in MONFGs where players have a quasiconvex utility function.",
        "published": "2021-12-13T09:23:29Z",
        "link": "http://arxiv.org/abs/2112.06500v4",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Frontiers in Collective Intelligence: A Workshop Report",
        "authors": [
            "Tyler Millhouse",
            "Melanie Moses",
            "Melanie Mitchell"
        ],
        "summary": "In August of 2021, the Santa Fe Institute hosted a workshop on collective intelligence as part of its Foundations of Intelligence project. This project seeks to advance the field of artificial intelligence by promoting interdisciplinary research on the nature of intelligence. The workshop brought together computer scientists, biologists, philosophers, social scientists, and others to share their insights about how intelligence can emerge from interactions among multiple agents--whether those agents be machines, animals, or human beings. In this report, we summarize each of the talks and the subsequent discussions. We also draw out a number of key themes and identify important frontiers for future research.",
        "published": "2021-12-13T18:23:09Z",
        "link": "http://arxiv.org/abs/2112.06864v2",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Multi-Robot On-site Shared Analytics Information and Computing",
        "authors": [
            "Joshua Vander Hook",
            "Federico Rossi",
            "Tiago Vaquero",
            "Martina Troesch",
            "Marc Sanchez Net",
            "Joshua Schoolcraft",
            "Jean-Pierre de la Croix",
            "Steve Chien"
        ],
        "summary": "Computation load-sharing across a network of heterogeneous robots is a promising approach to increase robots capabilities and efficiency as a team in extreme environments. However, in such environments, communication links may be intermittent and connections to the cloud or internet may be nonexistent. In this paper we introduce a communication-aware, computation task scheduling problem for multi-robot systems and propose an integer linear program (ILP) that optimizes the allocation of computational tasks across a network of heterogeneous robots, accounting for the networked robots' computational capabilities and for available (and possibly time-varying) communication links. We consider scheduling of a set of inter-dependent required and optional tasks modeled by a dependency graph. We present a consensus-backed scheduling architecture for shared-world, distributed systems. We validate the ILP formulation and the distributed implementation in different computation platforms and in simulated scenarios with a bias towards lunar or planetary exploration scenarios. Our results show that the proposed implementation can optimize schedules to allow a threefold increase the amount of rewarding tasks performed (e.g., science measurements) compared to an analogous system with no computational load-sharing.",
        "published": "2021-12-13T18:36:01Z",
        "link": "http://arxiv.org/abs/2112.06879v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "PantheonRL: A MARL Library for Dynamic Training Interactions",
        "authors": [
            "Bidipta Sarkar",
            "Aditi Talati",
            "Andy Shih",
            "Dorsa Sadigh"
        ],
        "summary": "We present PantheonRL, a multiagent reinforcement learning software package for dynamic training interactions such as round-robin, adaptive, and ad-hoc training. Our package is designed around flexible agent objects that can be easily configured to support different training interactions, and handles fully general multiagent environments with mixed rewards and n agents. Built on top of StableBaselines3, our package works directly with existing powerful deep RL algorithms. Finally, PantheonRL comes with an intuitive yet functional web user interface for configuring experiments and launching multiple asynchronous jobs. Our package can be found at https://github.com/Stanford-ILIAD/PantheonRL.",
        "published": "2021-12-13T21:08:43Z",
        "link": "http://arxiv.org/abs/2112.07013v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Meta-CPR: Generalize to Unseen Large Number of Agents with Communication   Pattern Recognition Module",
        "authors": [
            "Wei-Cheng Tseng",
            "Wei Wei",
            "Da-Cheng Juan",
            "Min Sun"
        ],
        "summary": "Designing an effective communication mechanism among agents in reinforcement learning has been a challenging task, especially for real-world applications. The number of agents can grow or an environment sometimes needs to interact with a changing number of agents in real-world scenarios. To this end, a multi-agent framework needs to handle various scenarios of agents, in terms of both scales and dynamics, for being practical to real-world applications. We formulate the multi-agent environment with a different number of agents as a multi-tasking problem and propose a meta reinforcement learning (meta-RL) framework to tackle this problem. The proposed framework employs a meta-learned Communication Pattern Recognition (CPR) module to identify communication behavior and extract information that facilitates the training process. Experimental results are poised to demonstrate that the proposed framework (a) generalizes to an unseen larger number of agents and (b) allows the number of agents to change between episodes. The ablation study is also provided to reason the proposed CPR design and show such design is effective.",
        "published": "2021-12-14T08:23:04Z",
        "link": "http://arxiv.org/abs/2112.07222v3",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Learning to Guide and to Be Guided in the Architect-Builder Problem",
        "authors": [
            "Paul Barde",
            "Tristan Karch",
            "Derek Nowrouzezahrai",
            "Clément Moulin-Frier",
            "Christopher Pal",
            "Pierre-Yves Oudeyer"
        ],
        "summary": "We are interested in interactive agents that learn to coordinate, namely, a $builder$ -- which performs actions but ignores the goal of the task, i.e. has no access to rewards -- and an $architect$ which guides the builder towards the goal of the task. We define and explore a formal setting where artificial agents are equipped with mechanisms that allow them to simultaneously learn a task while at the same time evolving a shared communication protocol. Ideally, such learning should only rely on high-level communication priors and be able to handle a large variety of tasks and meanings while deriving communication protocols that can be reused across tasks. We present the Architect-Builder Problem (ABP): an asymmetrical setting in which an architect must learn to guide a builder towards constructing a specific structure. The architect knows the target structure but cannot act in the environment and can only send arbitrary messages to the builder. The builder on the other hand can act in the environment, but receives no rewards nor has any knowledge about the task, and must learn to solve it relying only on the messages sent by the architect. Crucially, the meaning of messages is initially not defined nor shared between the agents but must be negotiated throughout learning. Under these constraints, we propose Architect-Builder Iterated Guiding (ABIG), a solution to ABP where the architect leverages a learned model of the builder to guide it while the builder uses self-imitation learning to reinforce its guided behavior. We analyze the key learning mechanisms of ABIG and test it in 2D tasks involving grasping cubes, placing them at a given location, or building various shapes. ABIG results in a low-level, high-frequency, guiding communication protocol that not only enables an architect-builder pair to solve the task at hand, but that can also generalize to unseen tasks.",
        "published": "2021-12-14T12:57:27Z",
        "link": "http://arxiv.org/abs/2112.07342v5",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "On Improving Resource Allocations by Sharing",
        "authors": [
            "Robert Bredereck",
            "Andrzej Kaczmarczyk",
            "Junjie Luo",
            "Rolf Niedermeier",
            "Florian Sachse"
        ],
        "summary": "Given an initial resource allocation, where some agents may envy others or where a different distribution of resources might lead to higher social welfare, our goal is to improve the allocation without reassigning resources. We consider a sharing concept allowing resources being shared with social network neighbors of the resource owners. To this end, we introduce a formal model that allows a central authority to compute an optimal sharing between neighbors based on an initial allocation. Advocating this point of view, we focus on the most basic scenario where a resource may be shared by two neighbors in a social network and each agent can participate in a bounded number of sharings. We present algorithms for optimizing utilitarian and egalitarian social welfare of allocations and for reducing the number of envious agents. In particular, we examine the computational complexity with respect to several natural parameters. Furthermore, we study cases with restricted social network structures and, among others, devise polynomial-time algorithms in path- and tree-like (hierarchical) social networks.",
        "published": "2021-12-14T16:41:08Z",
        "link": "http://arxiv.org/abs/2112.07525v1",
        "categories": [
            "cs.GT",
            "cs.CY",
            "cs.MA",
            "cs.SI",
            "J.4; G.2.3; G.2.2; F.2.2"
        ]
    },
    {
        "title": "Modeling Strong and Human-Like Gameplay with KL-Regularized Search",
        "authors": [
            "Athul Paul Jacob",
            "David J. Wu",
            "Gabriele Farina",
            "Adam Lerer",
            "Hengyuan Hu",
            "Anton Bakhtin",
            "Jacob Andreas",
            "Noam Brown"
        ],
        "summary": "We consider the task of building strong but human-like policies in multi-agent decision-making problems, given examples of human behavior. Imitation learning is effective at predicting human actions but may not match the strength of expert humans, while self-play learning and search techniques (e.g. AlphaZero) lead to strong performance but may produce policies that are difficult for humans to understand and coordinate with. We show in chess and Go that regularizing search based on the KL divergence from an imitation-learned policy results in higher human prediction accuracy and stronger performance than imitation learning alone. We then introduce a novel regret minimization algorithm that is regularized based on the KL divergence from an imitation-learned policy, and show that using this algorithm for search in no-press Diplomacy yields a policy that matches the human prediction accuracy of imitation learning while being substantially stronger.",
        "published": "2021-12-14T16:52:49Z",
        "link": "http://arxiv.org/abs/2112.07544v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.GT",
            "cs.LG"
        ]
    },
    {
        "title": "Cooperation for Scalable Supervision of Autonomy in Mixed Traffic",
        "authors": [
            "Cameron Hickert",
            "Sirui Li",
            "Cathy Wu"
        ],
        "summary": "Advances in autonomy offer the potential for dramatic positive outcomes in a number of domains, yet enabling their safe deployment remains an open problem. This work's motivating question is: In safety-critical settings, can we avoid the need to have one human supervise one machine at all times? The work formalizes this scalable supervision problem by considering remotely located human supervisors and investigating how autonomous agents can cooperate to achieve safety. This article focuses on the safety-critical context of autonomous vehicles (AVs) merging into traffic consisting of a mixture of AVs and human drivers. The analysis establishes high reliability upper bounds on human supervision requirements. It further shows that AV cooperation can improve supervision reliability by orders of magnitude and counterintuitively requires fewer supervisors (per AV) as more AVs are adopted. These analytical results leverage queuing-theoretic analysis, order statistics, and a conservative, reachability-based approach. A key takeaway is the potential value of cooperation in enabling the deployment of autonomy at scale. While this work focuses on AVs, the scalable supervision framework may be of independent interest to a broader array of autonomous control challenges.",
        "published": "2021-12-14T17:18:48Z",
        "link": "http://arxiv.org/abs/2112.07569v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "How and Why to Manipulate Your Own Agent: On the Incentives of Users of   Learning Agents",
        "authors": [
            "Yoav Kolumbus",
            "Noam Nisan"
        ],
        "summary": "The usage of automated learning agents is becoming increasingly prevalent in many online economic applications such as online auctions and automated trading. Motivated by such applications, this paper is dedicated to fundamental modeling and analysis of the strategic situations that the users of automated learning agents are facing. We consider strategic settings where several users engage in a repeated online interaction, assisted by regret-minimizing learning agents that repeatedly play a \"game\" on their behalf. We propose to view the outcomes of the agents' dynamics as inducing a \"meta-game\" between the users. Our main focus is on whether users can benefit in this meta-game from \"manipulating\" their own agents by misreporting their parameters to them. We define a general framework to model and analyze these strategic interactions between users of learning agents for general games and analyze the equilibria induced between the users in three classes of games. We show that, generally, users have incentives to misreport their parameters to their own agents, and that such strategic user behavior can lead to very different outcomes than those anticipated by standard analysis.",
        "published": "2021-12-14T18:35:32Z",
        "link": "http://arxiv.org/abs/2112.07640v4",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Learning Connectivity-Maximizing Network Configurations",
        "authors": [
            "Daniel Mox",
            "Vijay Kumar",
            "Alejandro Ribeiro"
        ],
        "summary": "In this letter we propose a data-driven approach to optimizing the algebraic connectivity of a team of robots. While a considerable amount of research has been devoted to this problem, we lack a method that scales in a manner suitable for online applications for more than a handful of agents. To that end, we propose a supervised learning approach with a convolutional neural network (CNN) that learns to place communication agents from an expert that uses an optimization-based strategy. We demonstrate the performance of our CNN on canonical line and ring topologies, 105k randomly generated test cases, and larger teams not seen during training. We also show how our system can be applied to dynamic robot teams through a Unity-based simulation. After training, our system produces connected configurations over an order of magnitude faster than the optimization-based scheme for teams of 10-20 agents.",
        "published": "2021-12-14T18:59:01Z",
        "link": "http://arxiv.org/abs/2112.07663v2",
        "categories": [
            "cs.RO",
            "cs.LG",
            "cs.MA",
            "cs.NI"
        ]
    },
    {
        "title": "Assessing Human Interaction in Virtual Reality With Continually Learning   Prediction Agents Based on Reinforcement Learning Algorithms: A Pilot Study",
        "authors": [
            "Dylan J. A. Brenneis",
            "Adam S. Parker",
            "Michael Bradley Johanson",
            "Andrew Butcher",
            "Elnaz Davoodi",
            "Leslie Acker",
            "Matthew M. Botvinick",
            "Joseph Modayil",
            "Adam White",
            "Patrick M. Pilarski"
        ],
        "summary": "Artificial intelligence systems increasingly involve continual learning to enable flexibility in general situations that are not encountered during system training. Human interaction with autonomous systems is broadly studied, but research has hitherto under-explored interactions that occur while the system is actively learning, and can noticeably change its behaviour in minutes. In this pilot study, we investigate how the interaction between a human and a continually learning prediction agent develops as the agent develops competency. Additionally, we compare two different agent architectures to assess how representational choices in agent design affect the human-agent interaction. We develop a virtual reality environment and a time-based prediction task wherein learned predictions from a reinforcement learning (RL) algorithm augment human predictions. We assess how a participant's performance and behaviour in this task differs across agent types, using both quantitative and qualitative analyses. Our findings suggest that human trust of the system may be influenced by early interactions with the agent, and that trust in turn affects strategic behaviour, but limitations of the pilot study rule out any conclusive statement. We identify trust as a key feature of interaction to focus on when considering RL-based technologies, and make several recommendations for modification to this study in preparation for a larger-scale investigation. A video summary of this paper can be found at https://youtu.be/oVYJdnBqTwQ .",
        "published": "2021-12-14T22:46:44Z",
        "link": "http://arxiv.org/abs/2112.07774v2",
        "categories": [
            "cs.AI",
            "cs.HC",
            "cs.MA"
        ]
    },
    {
        "title": "Finite-Sample Analysis of Decentralized Q-Learning for Stochastic Games",
        "authors": [
            "Zuguang Gao",
            "Qianqian Ma",
            "Tamer Başar",
            "John R. Birge"
        ],
        "summary": "Learning in stochastic games is arguably the most standard and fundamental setting in multi-agent reinforcement learning (MARL). In this paper, we consider decentralized MARL in stochastic games in the non-asymptotic regime. In particular, we establish the finite-sample complexity of fully decentralized Q-learning algorithms in a significant class of general-sum stochastic games (SGs) - weakly acyclic SGs, which includes the common cooperative MARL setting with an identical reward to all agents (a Markov team problem) as a special case. We focus on the practical while challenging setting of fully decentralized MARL, where neither the rewards nor the actions of other agents can be observed by each agent. In fact, each agent is completely oblivious to the presence of other decision makers. Both the tabular and the linear function approximation cases have been considered. In the tabular setting, we analyze the sample complexity for the decentralized Q-learning algorithm to converge to a Markov perfect equilibrium (Nash equilibrium). With linear function approximation, the results are for convergence to a linear approximated equilibrium - a new notion of equilibrium that we propose - which describes that each agent's policy is a best reply (to other agents) within a linear space. Numerical experiments are also provided for both settings to demonstrate the results.",
        "published": "2021-12-15T03:33:39Z",
        "link": "http://arxiv.org/abs/2112.07859v2",
        "categories": [
            "cs.GT",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Learning to Share in Multi-Agent Reinforcement Learning",
        "authors": [
            "Yuxuan Yi",
            "Ge Li",
            "Yaowei Wang",
            "Zongqing Lu"
        ],
        "summary": "In this paper, we study the problem of networked multi-agent reinforcement learning (MARL), where a number of agents are deployed as a partially connected network and each interacts only with nearby agents. Networked MARL requires all agents to make decisions in a decentralized manner to optimize a global objective with restricted communication between neighbors over the network. Inspired by the fact that sharing plays a key role in human's learning of cooperation, we propose LToS, a hierarchically decentralized MARL framework that enables agents to learn to dynamically share reward with neighbors so as to encourage agents to cooperate on the global objective through collectives. For each agent, the high-level policy learns how to share reward with neighbors to decompose the global objective, while the low-level policy learns to optimize the local objective induced by the high-level policies in the neighborhood. The two policies form a bi-level optimization and learn alternately. We empirically demonstrate that LToS outperforms existing methods in both social dilemma and networked MARL scenarios across scales.",
        "published": "2021-12-16T08:43:20Z",
        "link": "http://arxiv.org/abs/2112.08702v2",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Distributed event-triggered flocking control of Lagrangian systems",
        "authors": [
            "Ernesto Aranda-Escolástico",
            "Leonardo J. Colombo",
            "María Guinaldo"
        ],
        "summary": "In this paper, an event-triggered control protocol is developed to investigate flocking control of Lagrangian systems, where event-triggering conditions are proposed to determine when the velocities of the agents are transmitted to their neighbours. In particular, the proposed controller is distributed, since it only depends on the available information of each agent on their own reference frame. In addition, we derive sufficient conditions to avoid Zeno behaviour. Numerical simulations are provided to show the effectiveness of the proposed control law.",
        "published": "2021-12-16T12:18:51Z",
        "link": "http://arxiv.org/abs/2112.08827v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Centralizing State-Values in Dueling Networks for Multi-Robot   Reinforcement Learning Mapless Navigation",
        "authors": [
            "Enrico Marchesini",
            "Alessandro Farinelli"
        ],
        "summary": "We study the problem of multi-robot mapless navigation in the popular Centralized Training and Decentralized Execution (CTDE) paradigm. This problem is challenging when each robot considers its path without explicitly sharing observations with other robots and can lead to non-stationary issues in Deep Reinforcement Learning (DRL). The typical CTDE algorithm factorizes the joint action-value function into individual ones, to favor cooperation and achieve decentralized execution. Such factorization involves constraints (e.g., monotonicity) that limit the emergence of novel behaviors in an individual as each agent is trained starting from a joint action-value. In contrast, we propose a novel architecture for CTDE that uses a centralized state-value network to compute a joint state-value, which is used to inject global state information in the value-based updates of the agents. Consequently, each model computes its gradient update for the weights, considering the overall state of the environment. Our idea follows the insights of Dueling Networks as a separate estimation of the joint state-value has both the advantage of improving sample efficiency, while providing each robot information whether the global state is (or is not) valuable. Experiments in a robotic navigation task with 2 4, and 8 robots, confirm the superior performance of our approach over prior CTDE methods (e.g., VDN, QMIX).",
        "published": "2021-12-16T16:47:00Z",
        "link": "http://arxiv.org/abs/2112.09012v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG",
            "cs.RO"
        ]
    },
    {
        "title": "Decentralized Mean Field Games",
        "authors": [
            "Sriram Ganapathi Subramanian",
            "Matthew E. Taylor",
            "Mark Crowley",
            "Pascal Poupart"
        ],
        "summary": "Multiagent reinforcement learning algorithms have not been widely adopted in large scale environments with many agents as they often scale poorly with the number of agents. Using mean field theory to aggregate agents has been proposed as a solution to this problem. However, almost all previous methods in this area make a strong assumption of a centralized system where all the agents in the environment learn the same policy and are effectively indistinguishable from each other. In this paper, we relax this assumption about indistinguishable agents and propose a new mean field system known as Decentralized Mean Field Games, where each agent can be quite different from others. All agents learn independent policies in a decentralized fashion, based on their local observations. We define a theoretical solution concept for this system and provide a fixed point guarantee for a Q-learning based algorithm in this system. A practical consequence of our approach is that we can address a `chicken-and-egg' problem in empirical mean field reinforcement learning algorithms. Further, we provide Q-learning and actor-critic algorithms that use the decentralized mean field learning approach and give stronger performances compared to common baselines in this area. In our setting, agents do not need to be clones of each other and learn in a fully decentralized fashion. Hence, for the first time, we show the application of mean field learning methods in fully competitive environments, large-scale continuous action space environments, and other environments with heterogeneous agents. Importantly, we also apply the mean field method in a ride-sharing problem using a real-world dataset. We propose a decentralized solution to this problem, which is more practical than existing centralized training methods.",
        "published": "2021-12-16T18:30:48Z",
        "link": "http://arxiv.org/abs/2112.09099v5",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Learning from Heterogeneous Data Based on Social Interactions over   Graphs",
        "authors": [
            "Virginia Bordignon",
            "Stefan Vlaski",
            "Vincenzo Matta",
            "Ali H. Sayed"
        ],
        "summary": "This work proposes a decentralized architecture, where individual agents aim at solving a classification problem while observing streaming features of different dimensions and arising from possibly different distributions. In the context of social learning, several useful strategies have been developed, which solve decision making problems through local cooperation across distributed agents and allow them to learn from streaming data. However, traditional social learning strategies rely on the fundamental assumption that each agent has significant prior knowledge of the underlying distribution of the observations. In this work we overcome this issue by introducing a machine learning framework that exploits social interactions over a graph, leading to a fully data-driven solution to the distributed classification problem. In the proposed social machine learning (SML) strategy, two phases are present: in the training phase, classifiers are independently trained to generate a belief over a set of hypotheses using a finite number of training samples; in the prediction phase, classifiers evaluate streaming unlabeled observations and share their instantaneous beliefs with neighboring classifiers. We show that the SML strategy enables the agents to learn consistently under this highly-heterogeneous setting and allows the network to continue learning even during the prediction phase when it is deciding on unlabeled samples. The prediction decisions are used to continually improve performance thereafter in a manner that is markedly different from most existing static classification schemes where, following training, the decisions on unlabeled data are not re-used to improve future performance.",
        "published": "2021-12-17T12:47:18Z",
        "link": "http://arxiv.org/abs/2112.09483v2",
        "categories": [
            "cs.LG",
            "cs.MA",
            "eess.SP"
        ]
    },
    {
        "title": "Distributed design of deterministic discrete-time privacy preserving   average consensus for multi-agent systems through network augmentation",
        "authors": [
            "Guilherme Ramos",
            "A. Pedro Aguiar",
            "Soummya Kar",
            "Sérgio Pequito"
        ],
        "summary": "Average consensus protocols emerge with a central role in distributed systems and decision-making such as distributed information fusion, distributed optimization, distributed estimation, and control. A key advantage of these protocols is that agents exchange and reveal their state information only to their neighbors. Yet, it can raise privacy concerns in situations where the agents' states contain sensitive information. In this paper, we propose a novel (noiseless) privacy preserving distributed algorithms for multi-agent systems to reach an average consensus. The main idea of the algorithms is that each agent runs a (small) network with a crafted structure and dynamics to form a network of networks (i.e., the connection between the newly created networks and their interconnections respecting the initial network connections). Together with a re-weighting of the dynamic parameters dictating the inter-agent dynamics and the initial states, we show that it is possible to ensure that the value of each node converges to the consensus value of the original network. Furthermore, we show that, under mild assumptions, it is possible to craft the dynamics such that the design can be achieved in a distributed fashion. Finally, we illustrate the proposed algorithm with examples.",
        "published": "2021-12-18T12:10:31Z",
        "link": "http://arxiv.org/abs/2112.09914v1",
        "categories": [
            "math.OC",
            "cs.CR",
            "cs.MA"
        ]
    },
    {
        "title": "RoboAssembly: Learning Generalizable Furniture Assembly Policy in a   Novel Multi-robot Contact-rich Simulation Environment",
        "authors": [
            "Mingxin Yu",
            "Lin Shao",
            "Zhehuan Chen",
            "Tianhao Wu",
            "Qingnan Fan",
            "Kaichun Mo",
            "Hao Dong"
        ],
        "summary": "Part assembly is a typical but challenging task in robotics, where robots assemble a set of individual parts into a complete shape. In this paper, we develop a robotic assembly simulation environment for furniture assembly. We formulate the part assembly task as a concrete reinforcement learning problem and propose a pipeline for robots to learn to assemble a diverse set of chairs. Experiments show that when testing with unseen chairs, our approach achieves a success rate of 74.5% under the object-centric setting and 50.0% under the full setting. We adopt an RRT-Connect algorithm as the baseline, which only achieves a success rate of 18.8% after a significantly longer computation time. Supplemental materials and videos are available on our project webpage.",
        "published": "2021-12-19T13:20:45Z",
        "link": "http://arxiv.org/abs/2112.10143v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.CV",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "A Predictive Autonomous Decision Aid for Calibrating Human-Autonomy   Reliance in Multi-Agent Task Assignment",
        "authors": [
            "Larkin Heintzman",
            "Ryan K. Williams"
        ],
        "summary": "In this work, we develop a game-theoretic modeling of the interaction between a human operator and an autonomous decision aid when they collaborate in a multi-agent task allocation setting. In this setting, we propose a decision aid that is designed to calibrate the operator's reliance on the aid through a sequence of interactions to improve overall human-autonomy team performance. The autonomous decision aid employs a long short-term memory (LSTM) neural network for human action prediction and a Bayesian parameter filtering method to improve future interactions, resulting in an aid that can adapt to the dynamics of human reliance. The proposed method is then tested against a large set of simulated human operators from the choice prediction competition (CPC18) data set, and shown to significantly improve human-autonomy interactions when compared to a myopic decision aid that only suggests predicted human actions without an understanding of reliance.",
        "published": "2021-12-19T20:36:49Z",
        "link": "http://arxiv.org/abs/2112.10252v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "CGIBNet: Bandwidth-constrained Communication with Graph Information   Bottleneck in Multi-Agent Reinforcement Learning",
        "authors": [
            "Qi Tian",
            "Kun Kuang",
            "Baoxiang Wang",
            "Furui Liu",
            "Fei Wu"
        ],
        "summary": "Communication is one of the core components for cooperative multi-agent reinforcement learning (MARL). The communication bandwidth, in many real applications, is always subject to certain constraints. To improve communication efficiency, in this article, we propose to simultaneously optimize whom to communicate with and what to communicate for each agent in MARL. By initiating the communication between agents with a directed complete graph, we propose a novel communication model, named Communicative Graph Information Bottleneck Network (CGIBNet), to simultaneously compress the graph structure and the node information with the graph information bottleneck principle. The graph structure compression is designed to cut the redundant edges for determining whom to communicate with. The node information compression aims to address the problem of what to communicate via learning compact node representations. Moreover, CGIBNet is the first universal module for bandwidth-constrained communication, which can be applied to various training frameworks (i.e., policy-based and value-based MARL frameworks) and communication modes (i.e., single-round and multi-round communication). Extensive experiments are conducted in Traffic Control and StarCraft II environments. The results indicate that our method can achieve better performance in bandwidth-constrained settings compared with state-of-the-art algorithms.",
        "published": "2021-12-20T07:53:44Z",
        "link": "http://arxiv.org/abs/2112.10374v4",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Adaptive Incentive Design with Multi-Agent Meta-Gradient Reinforcement   Learning",
        "authors": [
            "Jiachen Yang",
            "Ethan Wang",
            "Rakshit Trivedi",
            "Tuo Zhao",
            "Hongyuan Zha"
        ],
        "summary": "Critical sectors of human society are progressing toward the adoption of powerful artificial intelligence (AI) agents, which are trained individually on behalf of self-interested principals but deployed in a shared environment. Short of direct centralized regulation of AI, which is as difficult an issue as regulation of human actions, one must design institutional mechanisms that indirectly guide agents' behaviors to safeguard and improve social welfare in the shared environment. Our paper focuses on one important class of such mechanisms: the problem of adaptive incentive design, whereby a central planner intervenes on the payoffs of an agent population via incentives in order to optimize a system objective. To tackle this problem in high-dimensional environments whose dynamics may be unknown or too complex to model, we propose a model-free meta-gradient method to learn an adaptive incentive function in the context of multi-agent reinforcement learning. Via the principle of online cross-validation, the incentive designer explicitly accounts for its impact on agents' learning and, through them, the impact on future social welfare. Experiments on didactic benchmark problems show that the proposed method can induce selfish agents to learn near-optimal cooperative behavior and significantly outperform learning-oblivious baselines. When applied to a complex simulated economy, the proposed method finds tax policies that achieve better trade-off between economic productivity and equality than baselines, a result that we interpret via a detailed behavioral analysis.",
        "published": "2021-12-20T21:07:44Z",
        "link": "http://arxiv.org/abs/2112.10859v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Polarize, Catalyze, Stabilize: How a minority of norm internalizers   amplify group selection and punishment",
        "authors": [
            "Victor Vikram Odouard",
            "Diana Smirnova",
            "Shimon Edelman"
        ],
        "summary": "Many mechanisms behind the evolution of cooperation, such as reciprocity, indirect reciprocity, and altruistic punishment, require group knowledge of individual actions. But what keeps people cooperating when no one is looking? Conformist norm internalization, the tendency to abide by the behavior of the majority of the group, even when it is individually harmful, could be the answer. In this paper, we analyze a world where (1) there is group selection and punishment by indirect reciprocity but (2) many actions (half) go unobserved, and therefore unpunished. Can norm internalization fill this \"observation gap\" and lead to high levels of cooperation, even when agents may in principle cooperate only when likely to be caught and punished? Specifically, we seek to understand whether adding norm internalization to the strategy space in a public goods game can lead to higher levels of cooperation when both norm internalization and cooperation start out rare. We found the answer to be positive, but, interestingly, not because norm internalizers end up making up a substantial fraction of the population, nor because they cooperate much more than other agent types. Instead, norm internalizers, by polarizing, catalyzing, and stabilizing cooperation, can increase levels of cooperation of other agent types, while only making up a minority of the population themselves.",
        "published": "2021-12-22T04:35:23Z",
        "link": "http://arxiv.org/abs/2112.11664v6",
        "categories": [
            "q-bio.PE",
            "cs.MA"
        ]
    },
    {
        "title": "FLoBC: A Decentralized Blockchain-Based Federated Learning Framework",
        "authors": [
            "Mohamed Ghanem",
            "Fadi Dawoud",
            "Habiba Gamal",
            "Eslam Soliman",
            "Hossam Sharara",
            "Tamer El-Batt"
        ],
        "summary": "The rapid expansion of data worldwide invites the need for more distributed solutions in order to apply machine learning on a much wider scale. The resultant distributed learning systems can have various degrees of centralization. In this work, we demonstrate our solution FLoBC for building a generic decentralized federated learning system using blockchain technology, accommodating any machine learning model that is compatible with gradient descent optimization. We present our system design comprising the two decentralized actors: trainer and validator, alongside our methodology for ensuring reliable and efficient operation of said system. Finally, we utilize FLoBC as an experimental sandbox to compare and contrast the effects of trainer-to-validator ratio, reward-penalty policy, and model synchronization schemes on the overall system performance, ultimately showing by example that a decentralized federated learning system is indeed a feasible alternative to more centralized architectures.",
        "published": "2021-12-22T13:36:49Z",
        "link": "http://arxiv.org/abs/2112.11873v2",
        "categories": [
            "cs.DC",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Evaluating the Robustness of Deep Reinforcement Learning for Autonomous   Policies in a Multi-agent Urban Driving Environment",
        "authors": [
            "Aizaz Sharif",
            "Dusica Marijan"
        ],
        "summary": "Deep reinforcement learning is actively used for training autonomous car policies in a simulated driving environment. Due to the large availability of various reinforcement learning algorithms and the lack of their systematic comparison across different driving scenarios, we are unsure of which ones are more effective for training autonomous car software in single-agent as well as multi-agent driving environments. A benchmarking framework for the comparison of deep reinforcement learning in a vision-based autonomous driving will open up the possibilities for training better autonomous car driving policies. To address these challenges, we provide an open and reusable benchmarking framework for systematic evaluation and comparative analysis of deep reinforcement learning algorithms for autonomous driving in a single- and multi-agent environment. Using the framework, we perform a comparative study of discrete and continuous action space deep reinforcement learning algorithms. We also propose a comprehensive multi-objective reward function designed for the evaluation of deep reinforcement learning-based autonomous driving agents. We run the experiments in a vision-only high-fidelity urban driving simulated environments. The results indicate that only some of the deep reinforcement learning algorithms perform consistently better across single and multi-agent scenarios when trained in various multi-agent-only environment settings. For example, A3C- and TD3-based autonomous cars perform comparatively better in terms of more robust actions and minimal driving errors in both single and multi-agent scenarios. We conclude that different deep reinforcement learning algorithms exhibit different driving and testing performance in different scenarios, which underlines the need for their systematic comparative analysis. The benchmarking framework proposed in this paper facilitates such a comparison.",
        "published": "2021-12-22T15:14:50Z",
        "link": "http://arxiv.org/abs/2112.11947v3",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Compromised ACC vehicles can degrade current mixed-autonomy traffic   performance while remaining stealthy against detection",
        "authors": [
            "George Gunter",
            "Huichen Li",
            "Avesta Hojjati",
            "Matthew Nice",
            "Matthew Bunting",
            "Carl A. Gunter",
            "Bo Li",
            "Jonathan Sprinkle",
            "Daniel Work"
        ],
        "summary": "We demonstrate that a supply-chain level compromise of the adaptive cruise control (ACC) capability on equipped vehicles can be used to significantly degrade system level performance of current day mixed-autonomy freeway networks. Via a simple threat model which causes random deceleration attacks (RDAs), compromised vehicles create congestion waves in the traffic that decrease average speed and network throughput. We use a detailed and realistic traffic simulation environment to quantify the impacts of the attack on a model of a real high-volume freeway in the United States. We find that the effect of the attack depends both on the level of underlying traffic congestion, and what percentage of ACC vehicles can be compromised. In moderate congestion regimes the attack can degrade mean commuter speed by over 7%. In high density regimes overall network throughput can be reduced by up to 3%. And, in moderate to high congestion regimes, it can cost commuters on the network over 300 USD/km hr. All of these results motivate that the proposed attack is able to significantly degrade performance of the traffic network.   We also develop an anomaly detection technique that uses GPS traces on vehicles to identify malicious/compromised vehicles. We employ this technique on data from the simulation experiments and find that it is unable to identify compromised ACCs compared to benign/normal drivers. That is, these attacks are stealthy to detection. Stronger attacks can be accurately labeled as malicious, motivating that there is a limit to how impactful attacks can be before they are no longer stealthy.   Finally, we experimentally execute the attack on a real and commercially available ACC vehicle, demonstrating the possible real world feasibility of an RDA.",
        "published": "2021-12-22T15:58:22Z",
        "link": "http://arxiv.org/abs/2112.11986v1",
        "categories": [
            "cs.CR",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "IDCAIS: Inter-Defender Collision-Aware Interception Strategy against   Multiple Attackers",
        "authors": [
            "Vishnu S. Chipade",
            "Dimitra Panagou"
        ],
        "summary": "In the prior literature on multi-agent area defense games, the assignments of the defenders to the attackers are done based on a cost metric associated only with the interception of the attackers. In contrast to that, this paper presents an Inter-Defender Collision-Aware Interception Strategy (IDCAIS) for defenders to intercept attackers in order to defend a protected area, such that the defender-to-attacker assignment protocol not only takes into account an interception-related cost but also takes into account any possible future collisions among the defenders on their optimal interception trajectories. In particular, in this paper, the defenders are assigned to intercept attackers using a mixed-integer quadratic program (MIQP) that: 1) minimizes the sum of times taken by defenders to capture the attackers under time-optimal control, as well as 2) helps eliminate or delay possible future collisions among the defenders on the optimal trajectories. To prevent inevitable collisions on optimal trajectories or collisions arising due to time-sub-optimal behavior by the attackers, a minimally augmented control using exponential control barrier function (ECBF) is also provided. Simulations show the efficacy of the approach.",
        "published": "2021-12-22T18:00:51Z",
        "link": "http://arxiv.org/abs/2112.12098v2",
        "categories": [
            "eess.SY",
            "cs.GT",
            "cs.MA",
            "cs.RO",
            "cs.SY"
        ]
    },
    {
        "title": "A Synthetic Prediction Market for Estimating Confidence in Published   Work",
        "authors": [
            "Sarah Rajtmajer",
            "Christopher Griffin",
            "Jian Wu",
            "Robert Fraleigh",
            "Laxmaan Balaji",
            "Anna Squicciarini",
            "Anthony Kwasnica",
            "David Pennock",
            "Michael McLaughlin",
            "Timothy Fritton",
            "Nishanth Nakshatri",
            "Arjun Menon",
            "Sai Ajay Modukuri",
            "Rajal Nivargi",
            "Xin Wei",
            "C. Lee Giles"
        ],
        "summary": "Explainably estimating confidence in published scholarly work offers opportunity for faster and more robust scientific progress. We develop a synthetic prediction market to assess the credibility of published claims in the social and behavioral sciences literature. We demonstrate our system and detail our findings using a collection of known replication projects. We suggest that this work lays the foundation for a research agenda that creatively uses AI for peer review.",
        "published": "2021-12-23T19:11:54Z",
        "link": "http://arxiv.org/abs/2201.06924v1",
        "categories": [
            "cs.CY",
            "cs.AI",
            "cs.IR",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Intersection focused Situation Coverage-based Verification and   Validation Framework for Autonomous Vehicles Implemented in CARLA",
        "authors": [
            "Zaid Tahir",
            "Rob Alexander"
        ],
        "summary": "Autonomous Vehicles (AVs) i.e., self-driving cars, operate in a safety critical domain, since errors in the autonomous driving software can lead to huge losses. Statistically, road intersections which are a part of the AVs operational design domain (ODD), have some of the highest accident rates. Hence, testing AVs to the limits on road intersections and assuring their safety on road intersections is pertinent, and thus the focus of this paper. We present a situation coverage-based (SitCov) AV-testing framework for the verification and validation (V&V) and safety assurance of AVs, developed in an open-source AV simulator named CARLA. The SitCov AV-testing framework focuses on vehicle-to-vehicle interaction on a road intersection under different environmental and intersection configuration situations, using situation coverage criteria for automatic test suite generation for safety assurance of AVs. We have developed an ontology for intersection situations, and used it to generate a situation hyperspace i.e., the space of all possible situations arising from that ontology. For the evaluation of our SitCov AV-testing framework, we have seeded multiple faults in our ego AV, and compared situation coverage based and random situation generation. We have found that both generation methodologies trigger around the same number of seeded faults, but the situation coverage-based generation tells us a lot more about the weaknesses of the autonomous driving algorithm of our ego AV, especially in edge-cases. Our code is publicly available online, anyone can use our SitCov AV-testing framework and use it or build further on top of it. This paper aims to contribute to the domain of V&V and development of AVs, not only from a theoretical point of view, but also from the viewpoint of an open-source software contribution and releasing a flexible/effective tool for V&V and development of AVs.",
        "published": "2021-12-24T02:56:56Z",
        "link": "http://arxiv.org/abs/2112.14706v2",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA",
            "cs.SE"
        ]
    },
    {
        "title": "Technological Approach to Mind Everywhere (TAME): an   experimentally-grounded framework for understanding diverse bodies and minds",
        "authors": [
            "Michael Levin"
        ],
        "summary": "Synthetic biology and bioengineering provide the opportunity to create novel embodied cognitive systems (otherwise known as minds) in a very wide variety of chimeric architectures combining evolved and designed material and software. These advances are disrupting familiar concepts in the philosophy of mind, and require new ways of thinking about and comparing truly diverse intelligences, whose composition and origin are not like any of the available natural model species. In this Perspective, I introduce TAME - Technological Approach to Mind Everywhere - a framework for understanding and manipulating cognition in unconventional substrates. TAME formalizes a non-binary (continuous), empirically-based approach to strongly embodied agency. When applied to regenerating/developmental systems, TAME suggests a perspective on morphogenesis as an example of basal cognition. The deep symmetry between problem-solving in anatomical, physiological, transcriptional, and 3D (traditional behavioral) spaces drives specific hypotheses by which cognitive capacities can scale during evolution. An important medium exploited by evolution for joining active subunits into greater agents is developmental bioelectricity, implemented by pre-neural use of ion channels and gap junctions to scale cell-level feedback loops into anatomical homeostasis. This architecture of multi-scale competency of biological systems has important implications for plasticity of bodies and minds, greatly potentiating evolvability. Considering classical and recent data from the perspectives of computational science, evolutionary biology, and basal cognition, reveals a rich research program with many implications for cognitive science, evolutionary biology, regenerative medicine, and artificial intelligence.",
        "published": "2021-12-24T14:11:05Z",
        "link": "http://arxiv.org/abs/2201.10346v1",
        "categories": [
            "q-bio.TO",
            "cs.MA",
            "q-bio.CB"
        ]
    },
    {
        "title": "Lyapunov Exponents for Diversity in Differentiable Games",
        "authors": [
            "Jonathan Lorraine",
            "Paul Vicol",
            "Jack Parker-Holder",
            "Tal Kachman",
            "Luke Metz",
            "Jakob Foerster"
        ],
        "summary": "Ridge Rider (RR) is an algorithm for finding diverse solutions to optimization problems by following eigenvectors of the Hessian (\"ridges\"). RR is designed for conservative gradient systems (i.e., settings involving a single loss function), where it branches at saddles - easy-to-find bifurcation points. We generalize this idea to non-conservative, multi-agent gradient systems by proposing a method - denoted Generalized Ridge Rider (GRR) - for finding arbitrary bifurcation points. We give theoretical motivation for our method by leveraging machinery from the field of dynamical systems. We construct novel toy problems where we can visualize new phenomena while giving insight into high-dimensional problems of interest. Finally, we empirically evaluate our method by finding diverse solutions in the iterated prisoners' dilemma and relevant machine learning problems including generative adversarial networks.",
        "published": "2021-12-24T22:48:14Z",
        "link": "http://arxiv.org/abs/2112.14570v1",
        "categories": [
            "cs.GT",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "A Survey of Event-triggered Control for Nonlinear Multiagent Systems   with Guaranteed Steady-State Performance",
        "authors": [
            "Gurmu Meseret Debele"
        ],
        "summary": "With the gradual advancement of a novel idea of the distributed control of the multiagent systems, an event-triggered control protocol has received significant research attention, especially in designing the controller for the nonlinear multiagent system. Compared to other widely used control conditions, the event-triggered control of the nonlinear system has a significant capability to improve resource utilization in real-life scenarios such as using and controlling the intelligent control input of each agent. It is worth mentioning that a group of interconnected agents have a network communication topology to transmit the feedback information state across the networked link. The transmission of information among a group of agents ensures that each agent reaches the consensus agreement cooperatively. The cooperative protocol of the distributed control of nonlinear multiagent system also ensures the proper information flow between each agent, irrespective of communication delays, variability of environment, and switching of the communication topology via the event-triggered control protocol. Consequently, event-triggered control for nonlinear multi-agent systems via steady-state performance will be investigated in this paper. The steady-state performances of a nonlinear closed-loop system demonstrate the stabilization, output regulation, and output synchronization problem of the nonlinear system using proper control protocol to achieve a consensus in a multiagent system will also be discussed. Based on the steady-state conditions of the nonlinear system, the consensus agreement among the agents will be realized.",
        "published": "2021-12-27T08:10:03Z",
        "link": "http://arxiv.org/abs/2112.13560v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Towards the Verification of Strategic Properties in Multi-Agent Systems   with Imperfect Information",
        "authors": [
            "Angelo Ferrando",
            "Vadim Malvone"
        ],
        "summary": "In logics for the strategic reasoning the main challenge is represented by their verification in contexts of imperfect information and perfect recall. In this work, we show a technique to approximate the verification of Alternating-time Temporal Logic (ATL*) under imperfect information and perfect recall, which is known to be undecidable. Given a model M and a formula $\\varphi$, we propose a verification procedure that generates sub-models of M in which each sub-model M' satisfies a sub-formula $\\varphi'$ of $\\varphi$ and the verification of $\\varphi'$ in M' is decidable. Then, we use CTL* model checking to provide a verification result of $\\varphi$ on M. We prove that our procedure is in the same class of complexity of ATL* model checking under perfect information and perfect recall, we present a tool that implements our procedure, and provide experimental results.",
        "published": "2021-12-27T11:54:28Z",
        "link": "http://arxiv.org/abs/2112.13621v1",
        "categories": [
            "cs.MA",
            "cs.LO"
        ]
    },
    {
        "title": "Multiagent Transition Systems for Composing Fault-Resilient Protocol   Stacks",
        "authors": [
            "Ehud Shapiro"
        ],
        "summary": "We present a novel mathematical framework for the specification and analysis of fault-resilient distributed protocols and their implementations, with the following components: 1. Transition systems that allow the specification and analysis of computations with safety and liveness faults and their fault resilience. 2. Notions of safe, live and complete implementations among transition systems and their composition, with which the correctness (safety and liveness) and completeness of a protocol stack as a whole follows from each protocol implementing correctly and completely the protocol above it in the stack. 3. Applying the notion of monotonicity, pertinent to histories of distributed computing systems, to ease the specification and proof of correctness of implementations among distributed computing systems. 4. Multiagent transition systems, further characterized as centralized/distributed and synchronous/asynchronous; safety and liveness fault-resilience of implementations among them and their composition. The framework is being employed in the specification of a grassroots ordering consensus protocol stack, with a grassroots dissemination protocol and its implementation of grassroots social networking and of sovereign cryptocurrencies, and an efficient Byzantine atomic broadcast protocols as initial applications.",
        "published": "2021-12-27T13:19:26Z",
        "link": "http://arxiv.org/abs/2112.13650v17",
        "categories": [
            "cs.DC",
            "cs.FL",
            "cs.MA"
        ]
    },
    {
        "title": "A Review on Controllability of Multi-Agent Systems using Switched   Network",
        "authors": [
            "Javeria Noor"
        ],
        "summary": "Controllability refers to a situation in which a Multi-agent System may be steered from one state to another using specified rules. As a result, there is belief in achieving a given condition by explicit advances. The level of dynamism in the topology and the level of determinism in the environment are two fundamental criteria that determine multi-agent system controllability. The topology of a powerful multi-agent system changes on a regular basis, altering the connections between agents and hence their cooperative effort. This survey focuses on the controllability of MAS in a switching network with a leader that follows the closest neighbour collaboration rule. The leader/pioneer is a single agent that functions as an output to control other agents/members. Because the results of activities are unknown under non-deterministic situations, agents must choose new activities after observing the aftereffects of their prior actions, which causes time delay and limits agent proactivity. Controllability is often achieved in a concentrated manner in the literature, where a certain leader educates supporters how to achieve a specific goal. Controllability has different applications which incorporates managing airplane, vehicle, and robots.",
        "published": "2021-12-27T13:48:51Z",
        "link": "http://arxiv.org/abs/2112.13675v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Reachability Analysis for FollowerStopper: Safety Analysis and   Experimental Results",
        "authors": [
            "Fang-Chieh Chou",
            "Marsalis Gibson",
            "Rahul Bhadani",
            "Alexandre M. Bayen",
            "Jonathan Sprinkle"
        ],
        "summary": "Motivated by earlier work and the developer of a new algorithm, the FollowerStopper, this article uses reachability analysis to verify the safety of the FollowerStopper algorithm, which is a controller designed for dampening stop- and-go traffic waves. With more than 1100 miles of driving data collected by our physical platform, we validate our analysis results by comparing it to human driving behaviors. The FollowerStopper controller has been demonstrated to dampen stop-and-go traffic waves at low speed, but previous analysis on its relative safety has been limited to upper and lower bounds of acceleration. To expand upon previous analysis, reachability analysis is used to investigate the safety at the speeds it was originally tested and also at higher speeds. Two formulations of safety analysis with different criteria are shown: distance-based and time headway-based. The FollowerStopper is considered safe with distance-based criterion. However, simulation results demonstrate that the FollowerStopper is not representative of human drivers - it follows too closely behind vehicles, specifically at a distance human would deem as unsafe. On the other hand, under the time headway-based safety analysis, the FollowerStopper is not considered safe anymore. A modified FollowerStopper is proposed to satisfy time-based safety criterion. Simulation results of the proposed FollowerStopper shows that its response represents human driver behavior better.",
        "published": "2021-12-29T00:56:34Z",
        "link": "http://arxiv.org/abs/2112.14345v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.RO",
            "cs.SY"
        ]
    },
    {
        "title": "Modeling Prejudice and Its Effect on Societal Prosperity",
        "authors": [
            "Deep Inder Mohan",
            "Arjun Verma",
            "Shrisha Rao"
        ],
        "summary": "Existing studies on prejudice, which is important in multi-group dynamics in societies, focus on the social-psychological knowledge behind the processes involving prejudice and its propagation. We instead create a multi-agent framework that simulates the propagation of prejudice and measures its tangible impact on the prosperity of individuals as well as of larger social structures, including groups and factions within. Groups in society help us define prejudice, and factions represent smaller tight-knit circles of individuals with similar opinions. We model social interactions using the Continuous Prisoner's Dilemma (CPD) and a type of agent called a prejudiced agent, whose cooperation is affected by a prejudice attribute, updated over time based both on the agent's own experiences and those of others in its faction. Our simulations show that modeling prejudice as an exclusively out-group phenomenon generates implicit in-group promotion, which eventually leads to higher relative prosperity of the prejudiced population. This skew in prosperity is shown to be correlated to factors such as size difference between groups and the number of prejudiced agents in a group. Although prejudiced agents achieve higher prosperity within prejudiced societies, their presence degrades the overall prosperity levels of their societies. Our proposed system model can serve as a basis for promoting a deeper understanding of origins, propagation, and ramifications of prejudice through rigorous simulative studies grounded in apt theoretical backgrounds. This can help conduct impactful research on prominent social issues such as racism, religious discrimination, and unfair immigrant treatment. This model can also serve as a foundation to study other socio-psychological phenomena in tandem with prejudice such as the distribution of wealth, social status, and ethnocentrism in a society.",
        "published": "2021-12-29T19:36:00Z",
        "link": "http://arxiv.org/abs/2112.14801v1",
        "categories": [
            "cs.MA",
            "cs.GT"
        ]
    },
    {
        "title": "AutoCast: Scalable Infrastructure-less Cooperative Perception for   Distributed Collaborative Driving",
        "authors": [
            "Hang Qiu",
            "Pohan Huang",
            "Namo Asavisanu",
            "Xiaochen Liu",
            "Konstantinos Psounis",
            "Ramesh Govindan"
        ],
        "summary": "Autonomous vehicles use 3D sensors for perception. Cooperative perception enables vehicles to share sensor readings with each other to improve safety. Prior work in cooperative perception scales poorly even with infrastructure support. AutoCast enables scalable infrastructure-less cooperative perception using direct vehicle-to-vehicle communication. It carefully determines which objects to share based on positional relationships between traffic participants, and the time evolution of their trajectories. It coordinates vehicles and optimally schedules transmissions in a distributed fashion. Extensive evaluation results under different scenarios show that, unlike competing approaches, AutoCast can avoid crashes and near-misses which occur frequently without cooperative perception, its performance scales gracefully in dense traffic scenarios providing 2-4x visibility into safety critical objects compared to existing cooperative perception schemes, its transmission schedules can be completed on the real radio testbed, and its scheduling algorithm is near-optimal with negligible computation overhead.",
        "published": "2021-12-30T07:06:23Z",
        "link": "http://arxiv.org/abs/2112.14947v1",
        "categories": [
            "cs.NI",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Multi-Agent Reinforcement Learning via Adaptive Kalman Temporal   Difference and Successor Representation",
        "authors": [
            "Mohammad Salimibeni",
            "Arash Mohammadi",
            "Parvin Malekzadeh",
            "Konstantinos N. Plataniotis"
        ],
        "summary": "Distributed Multi-Agent Reinforcement Learning (MARL) algorithms has attracted a surge of interest lately mainly due to the recent advancements of Deep Neural Networks (DNNs). Conventional Model-Based (MB) or Model-Free (MF) RL algorithms are not directly applicable to the MARL problems due to utilization of a fixed reward model for learning the underlying value function. While DNN-based solutions perform utterly well when a single agent is involved, such methods fail to fully generalize to the complexities of MARL problems. In other words, although recently developed approaches based on DNNs for multi-agent environments have achieved superior performance, they are still prone to overfiting, high sensitivity to parameter selection, and sample inefficiency. The paper proposes the Multi-Agent Adaptive Kalman Temporal Difference (MAK-TD) framework and its Successor Representation-based variant, referred to as the MAK-SR. Intuitively speaking, the main objective is to capitalize on unique characteristics of Kalman Filtering (KF) such as uncertainty modeling and online second order learning. The proposed MAK-TD/SR frameworks consider the continuous nature of the action-space that is associated with high dimensional multi-agent environments and exploit Kalman Temporal Difference (KTD) to address the parameter uncertainty. By leveraging the KTD framework, SR learning procedure is modeled into a filtering problem, where Radial Basis Function (RBF) estimators are used to encode the continuous space into feature vectors. On the other hand, for learning localized reward functions, we resort to Multiple Model Adaptive Estimation (MMAE), to deal with the lack of prior knowledge on the observation noise covariance and observation mapping function. The proposed MAK-TD/SR frameworks are evaluated via several experiments, which are implemented through the OpenAI Gym MARL benchmarks.",
        "published": "2021-12-30T18:21:53Z",
        "link": "http://arxiv.org/abs/2112.15156v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "eess.SP"
        ]
    },
    {
        "title": "Distributed Random Reshuffling over Networks",
        "authors": [
            "Kun Huang",
            "Xiao Li",
            "Andre Milzarek",
            "Shi Pu",
            "Junwen Qiu"
        ],
        "summary": "In this paper, we consider distributed optimization problems where $n$ agents, each possessing a local cost function, collaboratively minimize the average of the local cost functions over a connected network. To solve the problem, we propose a distributed random reshuffling (D-RR) algorithm that invokes the random reshuffling (RR) update in each agent. We show that D-RR inherits favorable characteristics of RR for both smooth strongly convex and smooth nonconvex objective functions. In particular, for smooth strongly convex objective functions, D-RR achieves $\\mathcal{O}(1/T^2)$ rate of convergence (where $T$ counts epoch number) in terms of the squared distance between the iterate and the global minimizer. When the objective function is assumed to be smooth nonconvex, we show that D-RR drives the squared norm of gradient to $0$ at a rate of $\\mathcal{O}(1/T^{2/3})$. These convergence results match those of centralized RR (up to constant factors) and outperform the distributed stochastic gradient descent (DSGD) algorithm if we run a relatively large number of epochs. Finally, we conduct a set of numerical experiments to illustrate the efficiency of the proposed D-RR method on both strongly convex and nonconvex distributed optimization problems.",
        "published": "2021-12-31T03:59:37Z",
        "link": "http://arxiv.org/abs/2112.15287v5",
        "categories": [
            "math.OC",
            "cs.DC",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Social Neuro AI: Social Interaction as the \"dark matter\" of AI",
        "authors": [
            "Samuele Bolotta",
            "Guillaume Dumas"
        ],
        "summary": "This article introduces a three-axis framework indicating how AI can be informed by biological examples of social learning mechanisms. We argue that the complex human cognitive architecture owes a large portion of its expressive power to its ability to engage in social and cultural learning. However, the field of AI has mostly embraced a solipsistic perspective on intelligence. We thus argue that social interactions not only are largely unexplored in this field but also are an essential element of advanced cognitive ability, and therefore constitute metaphorically the dark matter of AI. In the first section, we discuss how social learning plays a key role in the development of intelligence. We do so by discussing social and cultural learning theories and empirical findings from social neuroscience. Then, we discuss three lines of research that fall under the umbrella of Social NeuroAI and can contribute to developing socially intelligent embodied agents in complex environments. First, neuroscientific theories of cognitive architecture, such as the global workspace theory and the attention schema theory, can enhance biological plausibility and help us understand how we could bridge individual and social theories of intelligence. Second, intelligence occurs in time as opposed to over time, and this is naturally incorporated by dynamical systems. Third, embodiment has been demonstrated to provide more sophisticated array of communicative signals. To conclude, we discuss the example of active inference, which offers powerful insights for developing agents that possess biological realism, can self-organize in time, and are socially embodied.",
        "published": "2021-12-31T13:41:53Z",
        "link": "http://arxiv.org/abs/2112.15459v3",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Optimal Segmented Linear Regression for Financial Time Series   Segmentation",
        "authors": [
            "Chi-Jen Wu",
            "Wei-Sheng Zeng",
            "Jan-Ming Ho"
        ],
        "summary": "Given a financial time series data, one of the most fundamental and interesting challenges is the need to learn the stock dynamics signals in a financial time series data. A good example is to represent the time series in line segments which is often used as a pre-processing step for learning marketing signal patterns in financial computing. In this paper, we focus on the problem of computing the optimal segmentations of such time series based on segmented linear regression models. The major contribution of this paper is to define the problem of Multi-Segment Linear Regression (MSLR) of computing the optimal segmentation of a financial time series, denoted as the MSLR problem, such that the global mean square error of segmented linear regression is minimized. We present an optimum algorithm with two-level dynamic programming (DP) design and show the optimality of OMSLR algorithm. The two-level DP design of OMSLR algorithm can mitigate the complexity for searching the best trading strategies in financial markets. It runs in O($kn^2$) time, where $n$ is the length of the time series sequence and $k$ is the number of non-overlapping segments that cover all data points.",
        "published": "2021-01-02T05:07:52Z",
        "link": "http://arxiv.org/abs/2101.00370v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A comparison of matrix-free isogeometric Galerkin and collocation   methods for Karhunen--Loève expansion",
        "authors": [
            "Michal Lukasz Mika",
            "René Rinke Hiemstra",
            "Thomas Joseph Robert Hughes",
            "Dominik Schillinger"
        ],
        "summary": "Numerical computation of the Karhunen--Lo\\`eve expansion is computationally challenging in terms of both memory requirements and computing time. We compare two state-of-the-art methods that claim to efficiently solve for the K--L expansion: (1) the matrix-free isogeometric Galerkin method using interpolation based quadrature proposed by the authors in [1] and (2) our new matrix-free implementation of the isogeometric collocation method proposed in [2]. Two three-dimensional benchmark problems indicate that the Galerkin method performs significantly better for smooth covariance kernels, while the collocation method performs slightly better for rough covariance kernels.",
        "published": "2021-01-03T14:31:27Z",
        "link": "http://arxiv.org/abs/2101.00629v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "An efficient monolithic solution scheme for FE$^2$ problems",
        "authors": [
            "Nils Lange",
            "Geralf Hütter",
            "Björn Kiefer"
        ],
        "summary": "The FE$^2$ method is a very flexible but computationally expensive tool for multiscale simulations. In conventional implementations, the microscopic displacements are iteratively solved for within each macroscopic iteration loop, although the macroscopic strains imposed as boundary conditions at the micro-scale only represent estimates. In order to reduce the number of expensive micro-scale iterations, the present contribution presents a monolithic FE$^2$ scheme, for which the displacements at the micro-scale and at the macro-scale are solved for in a common Newton-Raphson loop. In this case, the linear system of equations within each iteration is solved by static condensation, so that only very limited modifications to the conventional, staggered scheme are necessary. The proposed monolithic FE$^2$ algorithm is implemented into the commercial FE code Abaqus. Benchmark examples demonstrate that the monolithic scheme saves up to ~60% of computational costs.",
        "published": "2021-01-04T14:10:53Z",
        "link": "http://arxiv.org/abs/2101.01802v2",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Optimization and variational principles for the shear strength reduction   method",
        "authors": [
            "Stanislav Sysala",
            "Eva Hrubešová",
            "Zdeněk Michalec",
            "Franz Tschuchnigg"
        ],
        "summary": "This paper is focused on the definition, analysis and numerical solution of a new optimization variant (OPT) of the shear strength reduction (SSR) problem with applications to slope stability problems. This new variant is derived on the basis of recent results by Tschuchnigg et al. 2015, where limit analysis and a modified Davis approach were used for approximation of the standard SSR method. The OPT-SSR method computes the factor of safety without performing an elasto-plastic analysis, similarly as in limit analysis. It is shown that this optimization problem is well-defined. Next, the duality between the static and kinematic principles of OPT-SSR is derived. For the numerical solution, a regularization method is introduced and analyzed. This method is combined with the finite element method, mesh adaptivity and a damped Newton method. In-house codes (Matlab) are used for the implementation of this solution concept. Finally, two slope stability problems are considered, one of which follows from analysis of a real slope. The softwares packages Plaxis and Comsol Multiphysics are used for comparison of the results.",
        "published": "2021-01-04T14:27:26Z",
        "link": "http://arxiv.org/abs/2101.01005v2",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "A numerical scheme for filter boundary conditions in topology   optimization on regular and irregular meshes",
        "authors": [
            "Prabhat Kumar",
            "Eduardo Fernández"
        ],
        "summary": "In density-based topology optimization, design variables associated to the boundaries of the design domain require unique treatment to negate boundary effects arising from the filtering technique. An effective approach to deal with filtering boundary conditions is to extend the design domain beyond the borders using void densities. Although the approach is easy to implement, it introduces extra computational cost required to store the additional Finite Elements (FEs). This work proposes a numerical technique for the density filter that emulates an extension of the design domain, thus, it avoids boundary effects without demanding additional computational cost, besides it is very simple to implement on both regular and irregular meshes. The numerical scheme is demonstrated using the compliance minimization problem on two-dimensional design domains. In addition, this article presents a discussion regarding the use of a real extension of the design domain, where the Finite Element Analysis (FEA) and volume restriction are influenced. Through a quantitative study, it is shown that affecting FEA or volume restriction with an extension of the FE mesh promotes the disconnection of material from the boundaries of the design domain, which is interpreted as a numerical instability promoting convergence towards local optimums.",
        "published": "2021-01-04T17:41:34Z",
        "link": "http://arxiv.org/abs/2101.01122v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "math.OC"
        ]
    },
    {
        "title": "An asymptotically compatible treatment of traction loading in linearly   elastic peridynamic fracture",
        "authors": [
            "Yue Yu",
            "Huaiqian You",
            "Nathaniel Trask"
        ],
        "summary": "Meshfree discretizations of state-based peridynamic models are attractive due to their ability to naturally describe fracture of general materials. However, two factors conspire to prevent meshfree discretizations of state-based peridynamics from converging to corresponding local solutions as resolution is increased: quadrature error prevents an accurate prediction of bulk mechanics, and the lack of an explicit boundary representation presents challenges when applying traction loads. In this paper, we develop a reformulation of the linear peridynamic solid (LPS) model to address these shortcomings, using improved meshfree quadrature, a reformulation of the nonlocal dilitation, and a consistent handling of the nonlocal traction condition to construct a model with rigorous accuracy guarantees. In particular, these improvements are designed to enforce discrete consistency in the presence of evolving fractures, whose {\\it a priori} unknown location render consistent treatment difficult. In the absence of fracture, when a corresponding classical continuum mechanics model exists, our improvements provide asymptotically compatible convergence to corresponding local solutions, eliminating surface effects and issues with traction loading which have historically plagued peridynamic discretizations. When fracture occurs, our formulation automatically provides a sharp representation of the fracture surface by breaking bonds, avoiding the loss of mass. We provide rigorous error analysis and demonstrate convergence for a number of benchmarks, including manufactured solutions, free-surface, nonhomogeneous traction loading, and composite material problems. Finally, we validate simulations of brittle fracture against a recent experiment of dynamic crack branching in soda-lime glass, providing evidence that the scheme yields accurate predictions for practical engineering problems.",
        "published": "2021-01-05T09:57:25Z",
        "link": "http://arxiv.org/abs/2101.01434v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "math.AP"
        ]
    },
    {
        "title": "Design and Analysis of a Synthetic Prediction Market using Dynamic   Convex Sets",
        "authors": [
            "Nishanth Nakshatri",
            "Arjun Menon",
            "C. Lee Giles",
            "Sarah Rajtmajer",
            "Christopher Griffin"
        ],
        "summary": "We present a synthetic prediction market whose agent purchase logic is defined using a sigmoid transformation of a convex semi-algebraic set defined in feature space. Asset prices are determined by a logarithmic scoring market rule. Time varying asset prices affect the structure of the semi-algebraic sets leading to time-varying agent purchase rules. We show that under certain assumptions on the underlying geometry, the resulting synthetic prediction market can be used to arbitrarily closely approximate a binary function defined on a set of input data. We also provide sufficient conditions for market convergence and show that under certain instances markets can exhibit limit cycles in asset spot price. We provide an evolutionary algorithm for training agent parameters to allow a market to model the distribution of a given data set and illustrate the market approximation using two open source data sets. Results are compared to standard machine learning methods.",
        "published": "2021-01-05T21:11:13Z",
        "link": "http://arxiv.org/abs/2101.01787v1",
        "categories": [
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "Large-Scale Extended Granger Causality for Classification of Marijuana   Users From Functional MRI",
        "authors": [
            "M. Ali Vosoughi",
            "Axel Wismuller"
        ],
        "summary": "It has been shown in the literature that marijuana use is associated with changes in brain network connectivity. We propose large-scale Extended Granger Causality (lsXGC) and investigate whether it can capture such changes using resting-state fMRI. This method combines dimension reduction with source time-series augmentation and uses predictive time-series modeling for estimating directed causal relationships among fMRI time-series. It is a multivariate approach, since it is capable of identifying the interdependence of time-series in the presence of all other time-series of the underlying dynamic system. Here, we investigate whether this model can serve as a biomarker for classifying marijuana users from typical controls using 126 adult subjects with a childhood diagnosis of ADHD from the Addiction Connectome Preprocessed Initiative (ACPI) database. We use brain connections estimated by lsXGC as features for classification. After feature extraction, we perform feature selection by Kendall's-tau rank correlation coefficient followed by classification using a support vector machine. As a reference method, we compare our results with cross-correlation, which is typically used in the literature as a standard measure of functional connectivity. Within a cross-validation scheme of 100 different training/test (90%/10%) data splits, we obtain a mean accuracy range of [0.714, 0.985] and a mean Area Under the receiver operating characteristic Curve (AUC) range of [0.779, 0.999] across all tested numbers of features for lsXGC, which is significantly better than results obtained with cross-correlation, namely mean accuracy of [0.728, 0.912] and mean AUC of [0.825, 0.969]. Our results suggest the applicability of lsXGC as a potential biomarker for marijuana use.",
        "published": "2021-01-06T00:40:47Z",
        "link": "http://arxiv.org/abs/2101.01832v1",
        "categories": [
            "cs.LG",
            "cs.CE",
            "eess.IV"
        ]
    },
    {
        "title": "Attention-based Convolutional Autoencoders for 3D-Variational Data   Assimilation",
        "authors": [
            "Julian Mack",
            "Rossella Arcucci",
            "Miguel Molina-Solana",
            "Yi-Ke Guo"
        ],
        "summary": "We propose a new 'Bi-Reduced Space' approach to solving 3D Variational Data Assimilation using Convolutional Autoencoders. We prove that our approach has the same solution as previous methods but has significantly lower computational complexity; in other words, we reduce the computational cost without affecting the data assimilation accuracy. We tested the new method with data from a real-world application: a pollution model of a site in Elephant and Castle, London and found that we could reduce the size of the background covariance matrix representation by O(10^3) and, at the same time, increase our data assimilation accuracy with respect to existing reduced space methods.",
        "published": "2021-01-06T16:23:58Z",
        "link": "http://arxiv.org/abs/2101.02121v1",
        "categories": [
            "cs.LG",
            "cs.CE"
        ]
    },
    {
        "title": "Fast Parallel Newton-Raphson Power Flow Solver for Large Number of   System Calculations with CPU and GPU",
        "authors": [
            "Zhenqi Wang",
            "Sebastian Wende-von Berg",
            "Martin Braun"
        ],
        "summary": "To analyze large sets of grid states, e.g. when evaluating the impact from the uncertainties of the renewable generation with probabilistic Monte Carlo simulation or in stationary time series simulation, large number of power flow calculations have to be performed. For the application in real-time grid operation, grid planning and in further cases when computational time is critical, a novel approach on simultaneous parallelization of many Newton-Raphson power flow calculations on CPU and with GPU-acceleration is proposed. The result shows a speed-up of over x100 comparing to the open-source tool pandapower, when performing repetitive power flows of system with admittance matrix of the same sparsity pattern on both CPU and GPU. The speed-up relies on the algorithm improvement and highly optimized parallelization strategy, which can reduce the repetitive work and saturate the high hardware computational capability of modern CPUs and GPUs well. This is achieved with the proposed batched sparse matrix operation and batched linear solver based on LU-refactorization. The batched linear solver shows a large performance improvement comparing to the state-of-the-art linear system solver KLU library and a better saturation of the GPU performance with small problem scale. Finally, the method of integrating the proposed solver into pandapower is presented, thus the parallel power flow solver with outstanding performance can be easily applied in challenging real-life grid operation and innovative researches e.g. data-driven machine learning studies.",
        "published": "2021-01-06T21:27:06Z",
        "link": "http://arxiv.org/abs/2101.02270v3",
        "categories": [
            "cs.CE",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Multidimensional coupling: A variationally consistent approach to   fiber-reinforced materials",
        "authors": [
            "Ustim Khristenko",
            "Stefan Schuß",
            "Melanie Krüger",
            "Felix Schmidt",
            "Barbara Wohlmuth",
            "Christian Hesch"
        ],
        "summary": "A novel mathematical model for fiber-reinforced materials is proposed. It is based on a 1-dimensional beam model for the thin fiber structures, a flexible and general 3-dimensional elasticity model for the matrix and an overlapping domain decomposition approach. From a computational point of view, this is motivated by the fact that matrix and fibers can easily meshed independently. Our main interest is in fiber reinforce polymers where the Young's modulus are quite different. Thus the modeling error from the overlapping approach is of no significance. The coupling conditions acknowledge both, the forces and the moments of the beam model and transfer them to the background material. A suitable static condensation procedure is applied to remove the beam balance equations. The condensed system then forms our starting point for a numerical approximation in terms of isogeometric analysis. The choice of our discrete basis functions of higher regularity is motivated by the fact, that as a result of the static condensation, we obtain second gradient terms in fiber direction. Eventually, a series of benchmark tests demonstrate the flexibility and robustness of the proposed methodology. As a proof-of-concept, we show that our new model is able to capture bending, torsion and shear dominated situations.",
        "published": "2021-01-07T13:03:03Z",
        "link": "http://arxiv.org/abs/2101.02527v3",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Oscillatory Residual Stresses in Steady Angular Channel Extrusion",
        "authors": [
            "Arunava Ray",
            "Pritam Chakraborty",
            "Anindya Chatterjee"
        ],
        "summary": "Angular channel extrusion has evolved as processes that can induce significant strengthening of the formed product through grain refinement. However, significant residual stresses are developed in the extruded product whose quantification is necessary for accurate process design and subsequent heat treatment. Experimental evaluation of residual stress provides the through thickness (normal) variation at chosen sampling points on the formed product and may provide inaccurate estimates if variations along the extrusion (longitudinal) directions are present. Process models can complement the experimental measurements and improve the estimates of residual stress distribution. While models of this process have been developed, very few of them have been applied to understand the variation of residual stress in the formed products. The present work aims to address this limitation by providing a complete map of residual stress distribution in angular extrusion process through numerical simulations. Interestingly, our simulations show that the angular channel extruded product can have significant longitudinal variation of residual stress depending on the extrusion ratio and strain hardening rate. Detailed analyses of the process reveals that these spatial oscillations occur due to cyclic movement of the contact location between the die and the top-billet surface in the exit channel. The outcome of this study suggests that accurate measurement technique of residual stress field in angular channel extruded products should consider the possibility of longitudinal variations. The findings can be extended to other continuous forming processes as well.",
        "published": "2021-01-07T15:17:11Z",
        "link": "http://arxiv.org/abs/2101.02584v1",
        "categories": [
            "cs.CE",
            "J.2"
        ]
    },
    {
        "title": "Deep Generative Model for Efficient 3D Airfoil Parameterization and   Generation",
        "authors": [
            "Wei Chen",
            "Arun Ramamurthy"
        ],
        "summary": "In aerodynamic shape optimization, the convergence and computational cost are greatly affected by the representation capacity and compactness of the design space. Previous research has demonstrated that using a deep generative model to parameterize two-dimensional (2D) airfoils achieves high representation capacity/compactness, which significantly benefits shape optimization. In this paper, we propose a deep generative model, Free-Form Deformation Generative Adversarial Networks (FFD-GAN), that provides an efficient parameterization for three-dimensional (3D) aerodynamic/hydrodynamic shapes like aircraft wings, turbine blades, car bodies, and hulls. The learned model maps a compact set of design variables to 3D surface points representing the shape. We ensure the surface smoothness and continuity of generated geometries by incorporating an FFD layer into the generative model. We demonstrate FFD-GAN's performance using a wing shape design example. The results show that FFD-GAN can generate realistic designs and form a reasonable parameterization. We further demonstrate FFD-GAN's high representation compactness and capacity by testing its design space coverage, the feasibility ratio of the design space, and its performance in design optimization. We demonstrate that over 94% feasibility ratio is achieved among wings randomly generated by the FFD-GAN, while FFD and B-spline only achieve less than 31%. We also show that the FFD-GAN leads to an order of magnitude faster convergence in a wing shape optimization problem, compared to the FFD and the B-spline parameterizations.",
        "published": "2021-01-07T19:55:23Z",
        "link": "http://arxiv.org/abs/2101.02744v1",
        "categories": [
            "cs.LG",
            "cs.CE",
            "cs.CG"
        ]
    },
    {
        "title": "Quasi-static crack propagation with a Griffith criterion using a   variational discrete element method",
        "authors": [
            "Frédéric Marazzato",
            "Alexandre Ern",
            "Laurent Monasse"
        ],
        "summary": "A variational discrete element method is applied to simulate quasi-static crack propagation. Cracks are considered to propagate between the mesh cells through the mesh facets. The elastic behaviour is parametrized by the continuous mechanical parameters (Young modulus and Poisson ratio). A discrete energetic cracking criterion coupled to a discrete kinking criterion guide the cracking process. Two-dimensional numerical examples are presented to illustrate the robustness and versatility of the method.",
        "published": "2021-01-07T21:01:40Z",
        "link": "http://arxiv.org/abs/2101.02763v3",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Topology Optimization with linearized buckling criteria in 250 lines of   Matlab",
        "authors": [
            "Federico Ferrari",
            "Ole Sigmund",
            "James K. Guest"
        ],
        "summary": "We present a 250 line Matlab code for topology optimization for linearized buckling criteria. The code is conceived to handle stiffness, volume and Buckling Load Factors (BLFs) either as the objective function or as constraints. We use the Kreisselmeier-Steinhauser aggregation function in order to reduce multiple objectives (viz. constraints) to a single, differentiable one. Then, the problem is sequentially approximated by using MMA-like expansions and an OC-like scheme is tailored to update the variables. The inspection of the stress stiffness matrix leads to a vectorized implementation for its efficient construction and for the sensitivity analysis of the BLFs. This, coupled with the efficiency improvements already presented by Ferrari and Sigmund 2020, cuts all the computational bottlenecks associated with setting up the buckling analysis and allows buckling topology optimization problems of an interesting size to be solved on a laptop. The efficiency and flexibility of the code is demonstrated over a few structural design examples and some ideas are given for possible extensions.",
        "published": "2021-01-08T11:55:24Z",
        "link": "http://arxiv.org/abs/2101.02973v1",
        "categories": [
            "math.OC",
            "cs.CE",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Iterative Rational Krylov Algorithms for model reduction of a class of   constrained structural dynamic system with Engineering applications",
        "authors": [
            "Xin Du",
            "M. Monir Uddiny",
            "A. Mostakim Fonyz",
            "Md. Tanzim Hossainx",
            "Md. Nazmul Islam Shuzan"
        ],
        "summary": "This paper discusses model order reduction of large sparse second-order index-3 differential algebraic equations (DAEs) by applying Iterative Rational Krylov Algorithm (IRKA). In general, such DAEs arise in constraint mechanics, multibody dynamics, mechatronics and many other branches of sciences and technologies. By deecting the algebraic equations the second-order index-3 system can be altered into an equivalent standard second-order system. This can be done by projecting the system onto the null space of the constraint matrix. However, creating the projector is computationally expensive and it yields huge bottleneck during the implementation. This paper shows how to find a reduce order model without projecting the system onto the null space of the constraint matrix explicitly. To show the efficiency of the theoretical works we apply them to several data of second-order index-3 models and experimental resultants are discussed in the paper.",
        "published": "2021-01-08T15:16:34Z",
        "link": "http://arxiv.org/abs/2101.03053v1",
        "categories": [
            "math.OC",
            "cs.CE",
            "math.DS"
        ]
    },
    {
        "title": "New commodity representations for multicommodity network flow problems:   An application to the fixed-charge network design problem",
        "authors": [
            "Ahmad Kazemi",
            "Pierre Le Bodic",
            "Andreas Ernst",
            "Mohan Krishnamoorthy"
        ],
        "summary": "When solving hard multicommodity network flow problems using an LP-based approach, the number of commodities is a driving factor in the speed at which the LP can be solved, as it is linear in the number of constraints and variables. The conventional approach to improve the solve time of the LP relaxation of a Mixed Integer Programming (MIP) model that encodes such an instance is to aggregate all commodities that have the same origin or the same destination. However, the bound of the resulting LP relaxation can significantly worsen, which tempers the efficiency of aggregating techniques. In this paper, we introduce the concept of partial aggregation of commodities that aggregates commodities over a subset of the network instead of the conventional aggregation over the entire underlying network. This offers a high level of control on the trade-off between size of the aggregated MIP model and quality of its LP bound. We apply the concept of partial aggregation to two different MIP models for the multicommodity network design problem. Our computational study on benchmark instances confirms that the trade-off between solve time and LP bound can be controlled by the level of aggregation, and that choosing a good trade-off can allow us to solve the original large-scale problems faster than without aggregation or with full aggregation.",
        "published": "2021-01-11T05:33:14Z",
        "link": "http://arxiv.org/abs/2101.03707v1",
        "categories": [
            "math.OC",
            "cs.CE",
            "90B10, 90B06"
        ]
    },
    {
        "title": "IFOSMONDI Co-simulation Algorithm with Jacobian-Free Methods in PETSc",
        "authors": [
            "Yohan Eguillon",
            "Bruno Lacabanne",
            "Damien Tromeur-Dervout"
        ],
        "summary": "IFOSMONDI iterative algorithm for implicit co-simulation of coupled physical systems (introduced by the authors in july 2019 during the Simultech conference, p.176-186) enables us to solve the nonlinear coupling function while keeping the smoothness of interfaces without introducing a delay. Moreover, it automatically adapts the size of the steps between data exchanges among the systems according to the difficulty of the solving of the coupling constraint. The latter was solved by a fixed-point algorithm in the original implementation whereas this paper introduces the JFM version (standing for Jacobian-Free Methods). Most implementations of Newton-like methods require a jacobian matrix which can be difficult to compute in the co-simulation context, except in the case where the interfaces are represented by a Zero-Order-Hold (ZOH). As far as IFOSMONDI coupling algorithm uses Hermite interpolation for smoothness enhancement (up to Third-Order-Hold), we propose hereafter a new formulation of the non-linear coupling function including both the values and the time-derivatives of the coupling variables. This formulation is well designed for solving the coupling through jacobian-free Newton type methods. Consequently, successive function evaluations consist in multiple simulations of the systems on a co-simulation time step using rollback. The orchestrator-workers structure of the algorithm enables us to combine the PETSc framework on the orchestrator side for the non-linear Newton-type solvers with the parallel integrations of the systems on the workers side thanks to MPI processes. Different nonlinear methods will be compared to one another and to the original fixed-point implementation on a newly proposed 2-systems academic test-case (mass-spring-damper type) with direct feedthrough on both sides.",
        "published": "2021-01-11T09:42:06Z",
        "link": "http://arxiv.org/abs/2101.04485v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "cs.PF"
        ]
    },
    {
        "title": "On-the-fly Reduced Order Modeling of Passive and Reactive Species via   Time-Dependent Manifolds",
        "authors": [
            "Donya Ramezanian",
            "Arash G. Nouri",
            "Hessam Babaee"
        ],
        "summary": "One of the principal barriers in developing accurate and tractable predictive models in turbulent flows with a large number of species is to track every species by solving a separate transport equation, which can be computationally impracticable. In this paper, we present an on-the-fly reduced order modeling of reactive as well as passive transport equations to reduce the computational cost. The presented approach seeks a low-rank decomposition of the species to three time-dependent components: (i) a set of orthonormal spatial modes, (ii) a low-rank factorization of the instantaneous species correlation matrix, and (iii) a set of orthonormal species modes, which represent a low-dimensional time-dependent manifold. Our approach bypasses the need to solve the full-dimensional species to generate high-fidelity data - as it is commonly performed in data-driven dimension reduction techniques such as the principle component analysis. Instead, the low-rank components are directly extracted from the species transport equation. The evolution equations for the three components are obtained from optimality conditions of a variational principle. The time-dependence of the three components enables an on-the-fly adaptation of the low-rank decomposition to transient changes in the species. Several demonstration cases of reduced order modeling of passive and reactive transport equations are presented.",
        "published": "2021-01-11T12:32:15Z",
        "link": "http://arxiv.org/abs/2101.03847v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Automated Synthesis of Steady-State Continuous Processes using   Reinforcement Learning",
        "authors": [
            "Quirin Göttl",
            "Dominik G. Grimm",
            "Jakob Burger"
        ],
        "summary": "Automated flowsheet synthesis is an important field in computer-aided process engineering. The present work demonstrates how reinforcement learning can be used for automated flowsheet synthesis without any heuristics of prior knowledge of conceptual design. The environment consists of a steady-state flowsheet simulator that contains all physical knowledge. An agent is trained to take discrete actions and sequentially built up flowsheets that solve a given process problem. A novel method named SynGameZero is developed to ensure good exploration schemes in the complex problem. Therein, flowsheet synthesis is modelled as a game of two competing players. The agent plays this game against itself during training and consists of an artificial neural network and a tree search for forward planning. The method is applied successfully to a reaction-distillation process in a quaternary system.",
        "published": "2021-01-12T11:49:34Z",
        "link": "http://arxiv.org/abs/2101.04422v2",
        "categories": [
            "cs.CE",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Airfoil GAN: Encoding and Synthesizing Airfoils for Aerodynamic Shape   Optimization",
        "authors": [
            "Yuyang Wang",
            "Kenji Shimada",
            "Amir Barati Farimani"
        ],
        "summary": "The current design of aerodynamic shapes, like airfoils, involves computationally intensive simulations to explore the possible design space. Usually, such design relies on the prior definition of design parameters and places restrictions on synthesizing novel shapes. In this work, we propose a data-driven shape encoding and generating method, which automatically learns representations from existing airfoils and uses the learned representations to generate new airfoils. The representations are then used in the optimization of synthesized airfoil shapes based on their aerodynamic performance. Our model is built upon VAEGAN, a neural network that combines Variational Autoencoder with Generative Adversarial Network and is trained by the gradient-based technique. Our model can (1) encode the existing airfoil into a latent vector and reconstruct the airfoil from that, (2) generate novel airfoils by randomly sampling the latent vectors and mapping the vectors to the airfoil coordinate domain, and (3) synthesize airfoils with desired aerodynamic properties by optimizing learned features via a genetic algorithm. Our experiments show that the learned features encode shape information thoroughly and comprehensively without predefined design parameters. By interpolating/extrapolating feature vectors or sampling from Gaussian noises, the model can automatically synthesize novel airfoil shapes, some of which possess competitive or even better aerodynamic properties comparing to airfoils used for model training purposes. By optimizing shapes on the learned latent domain via a genetic algorithm, synthesized airfoils can evolve to target aerodynamic properties. This demonstrates an efficient learning-based airfoil design framework, which encodes and optimizes the airfoil on the latent domain and synthesizes promising airfoil candidates for required aerodynamic performance.",
        "published": "2021-01-12T21:25:45Z",
        "link": "http://arxiv.org/abs/2101.04757v2",
        "categories": [
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "Bayesian neural networks for weak solution of PDEs with uncertainty   quantification",
        "authors": [
            "Xiaoxuan Zhang",
            "Krishna Garikipati"
        ],
        "summary": "Solving partial differential equations (PDEs) is the canonical approach for understanding the behavior of physical systems. However, large scale solutions of PDEs using state of the art discretization techniques remains an expensive proposition. In this work, a new physics-constrained neural network (NN) approach is proposed to solve PDEs without labels, with a view to enabling high-throughput solutions in support of design and decision-making. Distinct from existing physics-informed NN approaches, where the strong form or weak form of PDEs are used to construct the loss function, we write the loss function of NNs based on the discretized residual of PDEs through an efficient, convolutional operator-based, and vectorized implementation. We explore an encoder-decoder NN structure for both deterministic and probabilistic models, with Bayesian NNs (BNNs) for the latter, which allow us to quantify both epistemic uncertainty from model parameters and aleatoric uncertainty from noise in the data. For BNNs, the discretized residual is used to construct the likelihood function. In our approach, both deterministic and probabilistic convolutional layers are used to learn the applied boundary conditions (BCs) and to detect the problem domain. As both Dirichlet and Neumann BCs are specified as inputs to NNs, a single NN can solve for similar physics, but with different BCs and on a number of problem domains. The trained surrogate PDE solvers can also make interpolating and extrapolating (to a certain extent) predictions for BCs that they were not exposed to during training. Such surrogate models are of particular importance for problems, where similar types of PDEs need to be repeatedly solved for many times with slight variations. We demonstrate the capability and performance of the proposed framework by applying it to steady-state diffusion, linear elasticity, and nonlinear elasticity.",
        "published": "2021-01-13T04:57:51Z",
        "link": "http://arxiv.org/abs/2101.04879v1",
        "categories": [
            "cs.CE",
            "cs.LG",
            "physics.comp-ph"
        ]
    },
    {
        "title": "A quasi-conservative DG-ALE method for multi-component flows using the   non-oscillatory kinetic flux",
        "authors": [
            "Dongmi Luo",
            "Shiyi Li",
            "Weizhang Huang",
            "Jianxian Qiu",
            "Yibing Chen"
        ],
        "summary": "A high-order quasi-conservative discontinuous Galerkin (DG) method is proposed for the numerical simulation of compressible multi-component flows. A distinct feature of the method is a predictor-corrector strategy to define the grid velocity. A Lagrangian mesh is first computed based on the flow velocity and then used as an initial mesh in a moving mesh method (the moving mesh partial differential equation or MMPDE method ) to improve its quality. The fluid dynamic equations are discretized in the direct arbitrary Lagrangian-Eulerian framework using DG elements and the non-oscillatory kinetic flux while the species equation is discretized using a quasi-conservative DG scheme to avoid numerical oscillations near material interfaces. A selection of one- and two-dimensional examples are presented to verify the convergence order and the constant-pressure-velocity preservation property of the method. They also demonstrate that the incorporation of the Lagrangian meshing with the MMPDE moving mesh method works well to concentrate mesh points in regions of shocks and material interfaces.",
        "published": "2021-01-13T06:07:18Z",
        "link": "http://arxiv.org/abs/2101.04897v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Computer Architecture-Aware Optimisation of DNA Analysis Systems",
        "authors": [
            "Hasindu Gamaarachchi"
        ],
        "summary": "DNA sequencing is revolutionising the field of medicine. DNA sequencers, the machines which perform DNA sequencing, have evolved from the size of a fridge to that of a mobile phone over the last two decades. The cost of sequencing a human genome also has reduced from billions of dollars to hundreds of dollars. Despite these improvements, DNA sequencers output hundreds or thousands of gigabytes of data that must be analysed on computers to discover meaningful information with biological implications. Unfortunately, the analysis techniques have not kept the pace with rapidly improving sequencing technologies. Consequently, even today, the process of DNA analysis is performed on high-performance computers, just as it was a couple of decades ago. Such high-performance computers are not portable. Consequently, the full utility of an ultra-portable sequencer for sequencing in-the-field or at the point-of-care is limited by the lack of portable lightweight analytic techniques. This thesis proposes computer architecture-aware optimisation of DNA analysis software. DNA analysis software is inevitably convoluted due to the complexity associated with biological data. Modern computer architectures are also complex. Performing architecture-aware optimisations requires the synergistic use of knowledge from both domains, (i.e, DNA sequence analysis and computer architecture). This thesis aims to draw the two domains together. In this thesis, gold-standard DNA sequence analysis workflows are systematically examined for algorithmic components that cause performance bottlenecks. Identified bottlenecks are resolved through architecture-aware optimisations at different levels, i.e., memory, cache, register and processor. The optimised software tools are used in complete end-to-end analysis workflows and their efficacy is demonstrated by running on prototypical embedded systems.",
        "published": "2021-01-13T11:29:12Z",
        "link": "http://arxiv.org/abs/2101.05012v1",
        "categories": [
            "q-bio.GN",
            "cs.CE",
            "J.3; C.3; C.4"
        ]
    },
    {
        "title": "A novel approach to fluid-structure interaction simulations involving   large translation and contact",
        "authors": [
            "Daniel Hilger",
            "Norbert Hosters",
            "Fabian Key",
            "Stefanie Elgeti",
            "Marek Behr"
        ],
        "summary": "In this work, we present a novel method for the mesh update in flow problems with moving boundaries, the phantom domain deformation mesh update method (PD-DMUM). The PD-DMUM is designed to avoid remeshing; even in the event of large, unidirectional displacements of boundaries. The method combines the concept of two mesh adaptation approaches: (1) The virtual ring shear-slip mesh updatemethod (VR-SSMUM); and (2) the elastic mesh update method (EMUM). As in the VR-SSMUM, the PD-DMUMextends the fluid domain by a phantom domain; the PD-DMUM can thus locally adapt the element density. Combined with the EMUM, the PD-DMUMallows the consideration of arbitrary boundary movements. In this work, we apply the PD-DMUM in two test cases. Within the first test case, we validate the PD-DMUM in a 2D Poiseuille flow on a moving background mesh. Subsequently the fluid-structure interaction (FSI) problem in the second test case serves as a proof of concept. More, we stress the advantages of the novel method with regard to conventional mesh update approaches.",
        "published": "2021-01-13T14:18:31Z",
        "link": "http://arxiv.org/abs/2101.05090v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Certifiable Risk-Based Engineering Design Optimization",
        "authors": [
            "Anirban Chaudhuri",
            "Boris Kramer",
            "Matthew Norton",
            "Johannes O. Royset",
            "Karen Willcox"
        ],
        "summary": "Reliable, risk-averse design of complex engineering systems with optimized performance requires dealing with uncertainties. A conventional approach is to add safety margins to a design that was obtained from deterministic optimization. Safer engineering designs require appropriate cost and constraint function definitions that capture the \\textit{risk} associated with unwanted system behavior in the presence of uncertainties. The paper proposes two notions of certifiability. The first is based on accounting for the magnitude of failure to ensure data-informed conservativeness. The second is the ability to provide optimization convergence guarantees by preserving convexity. Satisfying these notions leads to \\textit{certifiable} risk-based design optimization (CRiBDO). In the context of CRiBDO, risk measures based on superquantile (a.k.a.\\ conditional value-at-risk) and buffered probability of failure are analyzed. CRiBDO is contrasted with reliability-based design optimization (RBDO), where uncertainties are accounted for via the probability of failure, through a structural and a thermal design problem. A reformulation of the short column structural design problem leading to a convex CRiBDO problem is presented. The CRiBDO formulations capture more information about the problem to assign the appropriate conservativeness, exhibit superior optimization convergence by preserving properties of underlying functions, and alleviate the adverse effects of choosing hard failure thresholds required in RBDO.",
        "published": "2021-01-13T15:23:15Z",
        "link": "http://arxiv.org/abs/2101.05129v2",
        "categories": [
            "math.OC",
            "cs.CE",
            "physics.data-an",
            "stat.CO"
        ]
    },
    {
        "title": "High-order FDTD schemes for Maxwell's interface problems with   discontinuous coefficients and complex interfaces based on the Correction   Function Method",
        "authors": [
            "Yann-Meing Law",
            "Jean-Christophe Nave"
        ],
        "summary": "We propose high-order FDTD schemes based on the Correction Function Method (CFM) for Maxwell's interface problems with discontinuous coefficients and complex interfaces. The key idea of the CFM is to model the correction function near an interface to retain the order of a finite difference approximation. For this, we solve a system of PDEs based on the original problem by minimizing an energy functional. The CFM is applied to the standard Yee scheme and a fourth-order FDTD scheme. The proposed CFM-FDTD schemes are verified in 2-D using the transverse magnetic mode (TM$_z$). Numerical examples include scattering of magnetic and non-magnetic dielectric cylinders, and problems with manufactured solutions using various complex interfaces and discontinuous piecewise varying coefficients. Long-time simulations are also performed to provide numerical evidences of the stability of the proposed numerical approach. The proposed CFM-FDTD schemes achieve up to fourth-order convergence in $L^2$-norm and provide approximations devoid of spurious oscillations.",
        "published": "2021-01-14T01:56:50Z",
        "link": "http://arxiv.org/abs/2101.05417v2",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "35Q61, 78M20, 65M06, 78A45"
        ]
    },
    {
        "title": "A Novel Physics-Based and Data-Supported Microstructure Model for   Part-Scale Simulation of Laser Powder Bed Fusion of Ti-6Al-4V",
        "authors": [
            "Jonas Nitzler",
            "Christoph Meier",
            "Kei W. Müller",
            "Wolfgang A. Wall",
            "Neil E. Hodge"
        ],
        "summary": "The elasto-plastic material behavior, material strength and failure modes of metals fabricated by additive manufacturing technologies are significantly determined by the underlying process-specific microstructure evolution. In this work a novel physics-based and data-supported phenomenological microstructure model for Ti-6Al-4V is proposed that is suitable for the part-scale simulation of selective laser melting processes. The model predicts spatially homogenized phase fractions of the most relevant microstructural species, namely the stable $\\beta$-phase, the stable $\\alpha_{\\text{s}}$-phase as well as the metastable Martensite $\\alpha_{\\text{m}}$-phase, in a physically consistent manner. In particular, the modeled microstructure evolution, in form of diffusion-based and non-diffusional transformations, is a pure consequence of energy and mobility competitions among the different species, without the need for heuristic transformation criteria as often applied in existing models. The mathematically consistent formulation of the evolution equations in rate form renders the model suitable for the practically relevant scenario of temperature- or time-dependent diffusion coefficients, arbitrary temperature profiles, and multiple coexisting phases. Due to its physically motivated foundation, the proposed model requires only a minimal number of free parameters, which are determined in an inverse identification process considering a broad experimental data basis in form of time-temperature transformation diagrams. Subsequently, the predictive ability of the model is demonstrated by means of continuous cooling transformation diagrams, showing that experimentally observed characteristics such as critical cooling rates emerge naturally from the proposed microstructure model, instead of being enforced as heuristic transformation criteria.",
        "published": "2021-01-14T18:44:56Z",
        "link": "http://arxiv.org/abs/2101.05787v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Two Chebyshev Spectral Methods for Solving Normal Modes in Atmospheric   Acoustics",
        "authors": [
            "Tu Houwang",
            "Wang Yongxian",
            "Xiao Wenbin",
            "Lan Qiang",
            "Liu Wei"
        ],
        "summary": "The normal mode model is important in computational atmospheric acoustics. It is often used to compute the atmospheric acoustic field under a harmonic point source. Its solution consists of a set of discrete modes radiating into the upper atmosphere, usually related to the continuous spectrum. In this article, we present two spectral methods, the Chebyshev--Tau and Chebyshev--Collocation methods, to solve for the atmospheric acoustic normal modes, and corresponding programs were developed. The two spectral methods successfully transform the problem of searching for the modal wavenumbers in the complex plane into a simple dense matrix eigenvalue problem by projecting the governing equation onto a set of orthogonal bases, which can be easily solved through linear algebra methods. After obtaining the eigenvalues and eigenvectors, the horizontal wavenumbers and their corresponding modes can be obtained with simple processing. Numerical experiments were examined for both downwind and upwind conditions to verify the effectiveness of the methods. The running time data indicated that both spectral methods proposed in this article are faster than the Legendre--Galerkin spectral method proposed previously.",
        "published": "2021-01-15T03:16:24Z",
        "link": "http://arxiv.org/abs/2101.05951v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Is it a great Autonomous FX Trading Strategy or you are just fooling   yourself",
        "authors": [
            "Murilo Sibrao Bernardini",
            "Paulo Andre Lima de Castro"
        ],
        "summary": "In this paper, we propose a method for evaluating autonomous trading strategies that provides realistic expectations, regarding the strategy's long-term performance. This method addresses This method addresses many pitfalls that currently fool even experienced software developers and researchers, not to mention the customers that purchase these products. We present the results of applying our method to several famous autonomous trading strategies, which are used to manage a diverse selection of financial assets. The results show that many of these published strategies are far from being reliable vehicles for financial investment. Our method exposes the difficulties involved in building a reliable, long-term strategy and provides a means to compare potential strategies and select the most promising one by establishing minimal periods and requirements for the test executions. There are many developers that create software to buy and sell financial assets autonomously and some of them present great performance when simulating with historical price series (commonly called backtests). Nevertheless, when these strategies are used in real markets (or data not used in their training or evaluation), quite often they perform very poorly. The proposed method can be used to evaluate potential strategies. In this way, the method helps to tell if you really have a great trading strategy or you are just fooling yourself.",
        "published": "2021-01-15T13:25:15Z",
        "link": "http://arxiv.org/abs/2101.07217v2",
        "categories": [
            "cs.SE",
            "cs.AI",
            "cs.CE"
        ]
    },
    {
        "title": "A Stable Mixed FE Method for Nearly Incompressible Linear Elastostatics",
        "authors": [
            "Eirik Valseth",
            "Albert Romkes",
            "Austin R. Kaul",
            "Clint Dawson"
        ],
        "summary": "We present a new, stable, mixed finite element (FE) method for linear elastostatics of nearly incompressible solids. The method is the automatic variationally stable FE (AVS-FE) method of Calo, Romkes and Valseth, in which we consider a Petrov-Galerkin weak formulation where the stress and displacement variables are in the space H(div)xH1, respectively. This allows us to employ a fully conforming FE discretization for any elastic solid using classical FE subspaces of H(div) and H1. Hence, the resulting FE approximation yields both continuous stresses and displacements.   To ensure stability of the method, we employ the philosophy of the discontinuous Petrov-Galerkin (DPG) method of Demkowicz and Gopalakrishnan and use optimal test spaces. Thus, the resulting FE discretization is stable even as the Poisson ratio approaches 0.5, and the system of linear algebraic equations is symmetric and positive definite. Our method also comes with a built-in a posteriori error estimator as well as well as indicators which are used to drive mesh adaptive refinements. We present several numerical verifications of our method including comparisons to existing FE technologies.",
        "published": "2021-01-15T20:47:30Z",
        "link": "http://arxiv.org/abs/2101.06297v2",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "A Novel Modeling and Simulation Approach for the Hindered Mobility of   Charged Particles in Biological Hydrogels",
        "authors": [
            "Maximilian J. Grill",
            "Jonas F. Eichinger",
            "Jonas Koban",
            "Christoph Meier",
            "Oliver Lieleg",
            "Wolfgang A. Wall"
        ],
        "summary": "This article presents a novel computational model to study the selective filtering of biological hydrogels due to the surface charge and size of diffusing particles. It is the first model that includes the random 3D fiber orientation and connectivity of the biopolymer network and that accounts for elastic deformations of the fibers by means of beam theory. As a key component of the model, novel formulations are proposed both for the electrostatic and repulsive steric interactions between a spherical particle and a beam. In addition to providing a thorough validation of the model, the presented computational studies yield new insights into the underlying mechanisms of hindered particle mobility, especially regarding the influence of the aforementioned aspects that are unique to this model. It is found that the precise distribution of fiber and thus charge agglomerations in the network have a crucial influence on the mobility of oppositely charged particles and gives rise to distinct motion patterns. Considering the high practical significance for instance with respect to targeted drug release or infection defense, the provided proof of concept motivates further advances of the model toward a truly predictive computational tool that allows a case- and patient-specific assessment for real (biological) systems.",
        "published": "2021-01-17T19:23:11Z",
        "link": "http://arxiv.org/abs/2101.06756v1",
        "categories": [
            "physics.bio-ph",
            "cond-mat.soft",
            "cs.CE"
        ]
    },
    {
        "title": "Optical Flow Method for Measuring Deformation of Soil Specimen Subjected   to Torsional Shearing",
        "authors": [
            "Piotr E. Srokosz",
            "Marcin Bujko",
            "Marta Bocheńska",
            "Rafał Ossowski"
        ],
        "summary": "In this study optical flow method was used for soil small deformation measurement in laboratory tests. The main objective was to observe how the deformation distributes along the whole height of cylindrical soil specimen subjected to torsional shearing (TS test). The experiments were conducted on dry non-cohesive soil specimens under two values of isotropic pressure. Specimens were loaded with low-amplitude cyclic torque to analyze the deformation within the small strain range (0.001-0.01%). Optical flow method variant by Ce Liu (2009) was used for motion estimation from series of images. This algorithm uses scale-invariant feature transform (SIFT) for image feature extraction and coarse-to-fine matching scheme for faster calculations. The results were validated with the Particle Image Velocimetry (PIV). The results show that the displacement distribution deviates from commonly assumed linearity. Moreover, the observed deformation mechanisms analysis suggest that the shear modulus $G$ commonly determined through TS tests can be considerably overestimated.",
        "published": "2021-01-18T11:12:46Z",
        "link": "http://arxiv.org/abs/2101.07005v2",
        "categories": [
            "cs.CE",
            "cs.CV"
        ]
    },
    {
        "title": "Cell division in deep material networks applied to multiscale strain   localization modeling",
        "authors": [
            "Zeliang Liu"
        ],
        "summary": "Despite the increasing importance of strain localization modeling (e.g., failure analysis) in computer-aided engineering, there is a lack of effective approaches to capturing relevant material behaviors consistently across multiple length scales. We aim to address this gap within the framework of deep material networks (DMN) -- a machine learning model with embedded mechanics in the building blocks. A new cell-division scheme is proposed to track the scale transition through the network, and its consistency is ensured by the physics of fitting parameters. Essentially, each microscale node in the bottom layer is described by an ellipsoidal cell with its dimensions back-propagated from the macroscale material point. New crack surfaces in the cell are modeled by enriching cohesive layers, and failure algorithms are developed for crack initiation and evolution in the implicit DMN analysis. Besides studies on a single material point, we apply the multiscale model to concurrent multiscale simulations for the dynamic crush of a particle-reinforced composite tube and various tests on carbon fiber reinforced polymer composites. For the latter, experimental validations on an off-axis tensile test specimen are also provided.",
        "published": "2021-01-18T18:24:51Z",
        "link": "http://arxiv.org/abs/2101.07226v2",
        "categories": [
            "cs.CE",
            "cs.LG",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Combined Newton-Raphson and Streamlines-Upwind Petrov-Galerkin   iterations for nano-particles transport in buoyancy driven flow",
        "authors": [
            "M. K. Riahi",
            "M. Ali",
            "Y. Addad",
            "E. Abu-Nada"
        ],
        "summary": "The present study deals with the finite element discretization of nanofluid convective transport in an enclosure with variable properties. We study the Buongiorno model, which couples the Navier-Stokes equations for the base fluid, an advective-diffusion equation for the heat transfer, and an advection dominated nanoparticle fraction concentration subject to thermophoresis and Brownian motion forces. We develop an iterative numerical scheme that combines Newton's method (dedicated to the resolution of the momentum and energy equations) with the transport equation that governs the nanoparticles concentration in the enclosure. We show that Stream Upwind Petrov-Galerkin regularization approach is required to solve properly the ill-posed Buongiorno transport model being tackled as a variational problem under mean value constraint. Non-trivial numerical computations are reported to show the effectiveness of our proposed numerical approach in its ability to provide reasonably good agreement with the experimental results available in the literature. The numerical experiments demonstrate that by accounting for only the thermophoresis and Brownian motion forces in the concentration transport equation, the model is not able to reproduce the heat transfer impairment due to the presence of suspended nanoparticles in the base fluid. It reveals, however, the significant role that these two terms play in the vicinity of the hot and cold walls.",
        "published": "2021-01-19T08:10:31Z",
        "link": "http://arxiv.org/abs/2101.07501v1",
        "categories": [
            "physics.flu-dyn",
            "cs.CE",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Multiobjective Multitasking Optimization Based on Decomposition with   Dual Neighborhoods",
        "authors": [
            "Xianpeng Wang",
            "Zhiming Dong",
            "Lixin Tang",
            "Qingfu Zhang"
        ],
        "summary": "This paper proposes a multiobjective multitasking optimization evolutionary algorithm based on decomposition with dual neighborhood. In our proposed algorithm, each subproblem not only maintains a neighborhood based on the Euclidean distance among weight vectors within its own task, but also keeps a neighborhood with subproblems of other tasks. Gray relation analysis is used to define neighborhood among subproblems of different tasks. In such a way, relationship among different subproblems can be effectively exploited to guide the search. Experimental results show that our proposed algorithm outperforms four state-of-the-art multiobjective multitasking evolutionary algorithms and a traditional decomposition-based multiobjective evolutionary algorithm on a set of test problems.",
        "published": "2021-01-19T10:18:47Z",
        "link": "http://arxiv.org/abs/2101.07548v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Fast formation and assembly of isogeometric Galerkin matrices for   trimmed patches",
        "authors": [
            "Benjamin Marussig"
        ],
        "summary": "This work explores the application of the fast assembly and formation strategy from [8, 17] to trimmed bi-variate parameter spaces. Two concepts for the treatment of basis functions cut by the trimming curve are investigated: one employs a hybrid Gauss-point-based approach, and the other computes discontinuous weighted quadrature rules. The concepts' accuracy and efficiency are examined for the formation of mass matrices and their application to L2-projection. Significant speed-ups compared to standard element by element finite element formation are observed. There is no clear preference between the concepts proposed. While the discontinuous weighted scheme scales favorably with the degree of the basis, it also requires additional effort for computing the quadrature weights. The hybrid Gauss approach does not have this overhead, which is determined by the complexity of the trimming curve. Hence, it is well-suited for moderate degrees, whereas discontinuous-weightedquadrature has potential for high degrees, in particular, if the related weights are computed in parallel.",
        "published": "2021-01-20T10:14:41Z",
        "link": "http://arxiv.org/abs/2101.08053v1",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Multi-Scale Games: Representing and Solving Games on Networks with Group   Structure",
        "authors": [
            "Kun Jin",
            "Yevgeniy Vorobeychik",
            "Mingyan Liu"
        ],
        "summary": "Network games provide a natural machinery to compactly represent strategic interactions among agents whose payoffs exhibit sparsity in their dependence on the actions of others. Besides encoding interaction sparsity, however, real networks often exhibit a multi-scale structure, in which agents can be grouped into communities, those communities further grouped, and so on, and where interactions among such groups may also exhibit sparsity. We present a general model of multi-scale network games that encodes such multi-level structure. We then develop several algorithmic approaches that leverage this multi-scale structure, and derive sufficient conditions for convergence of these to a Nash equilibrium. Our numerical experiments demonstrate that the proposed approaches enable orders of magnitude improvements in scalability when computing Nash equilibria in such games. For example, we can solve previously intractable instances involving up to 1 million agents in under 15 minutes.",
        "published": "2021-01-20T20:46:44Z",
        "link": "http://arxiv.org/abs/2101.08314v1",
        "categories": [
            "cs.CE",
            "econ.TH"
        ]
    },
    {
        "title": "Quadratic Residual Networks: A New Class of Neural Networks for Solving   Forward and Inverse Problems in Physics Involving PDEs",
        "authors": [
            "Jie Bu",
            "Anuj Karpatne"
        ],
        "summary": "We propose quadratic residual networks (QRes) as a new type of parameter-efficient neural network architecture, by adding a quadratic residual term to the weighted sum of inputs before applying activation functions. With sufficiently high functional capacity (or expressive power), we show that it is especially powerful for solving forward and inverse physics problems involving partial differential equations (PDEs). Using tools from algebraic geometry, we theoretically demonstrate that, in contrast to plain neural networks, QRes shows better parameter efficiency in terms of network width and depth thanks to higher non-linearity in every neuron. Finally, we empirically show that QRes shows faster convergence speed in terms of number of training epochs especially in learning complex patterns.",
        "published": "2021-01-20T23:54:55Z",
        "link": "http://arxiv.org/abs/2101.08366v2",
        "categories": [
            "cs.LG",
            "cs.CE"
        ]
    },
    {
        "title": "On the Use of Computational Fluid Dynamics (CFD) Modelling to Design   Improved Dry Powder Inhalers",
        "authors": [
            "David F Fletcher",
            "Vishal Chaugule",
            "Larissa Gomes dos Reis",
            "Paul M Young",
            "Daniela Traini",
            "Julio Soria"
        ],
        "summary": "Purpose: Computational Fluid Dynamics (CFD) simulations are performed to investigate the impact of adding a grid to a two-inlet dry powder inhaler (DPI). The purpose of the paper is to show the importance of the correct choice of closure model and modeling approach, as well as to perform validation against particle dispersion data obtained from in-vitro studies and flow velocity data obtained from particle image velocimetry (PIV) experiments. Methods: CFD simulations are performed using the Ansys Fluent 2020R1 software package. Two RANS turbulence models (realisable $k - \\epsilon$ and $k - \\omega$ SST) and the Stress Blended Eddy Simulation (SBES) models are considered. Lagrangian particle tracking for both carrier and fine particles is also performed. Results: Excellent comparison with the PIV data is found for the SBES approach and the particle tracking data are consistent with the dispersion results, given the simplicity of the assumptions made. Conclusions: This work shows the importance of selecting the correct turbulence modelling approach and boundary conditions to obtain good agreement with PIV data for the flow-field exiting the device. With this validated, the model can be used with much higher confidence to explore the fluid and particle dynamics within the device.",
        "published": "2021-01-21T06:14:48Z",
        "link": "http://arxiv.org/abs/2101.10441v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A Gauss-Seidel projection method with the minimal number of updates for   stray field in micromagnetic simulations",
        "authors": [
            "Panchi Li",
            "Zetao Ma",
            "Rui Du",
            "Jingrun Chen"
        ],
        "summary": "Magnetization dynamics in magnetic materials is often modeled by the Landau-Lifshitz equation, which is solved numerically in general. In micromagnetic simulations, the computational cost relies heavily on the time-marching scheme and the evaluation of stray field. Explicit marching schemes are efficient but suffer from severe stability constraints, while nonlinear systems of equations have to be solved in implicit schemes though they are unconditionally stable. A better compromise between stability and efficiency is the semi-implicit scheme, such as the Gauss-Seidel projection method (GSPM) and the second-order backward differentiation formula scheme (BDF2). At each marching step, GSPM solves several linear systems of equations with constant coefficients and updates the stray field several times, while BDF2 updates the stray field only once but solves a larger linear system of equations with variable coefficients and a nonsymmetric structure. In this work, we propose a new method, dubbed as GSPM-BDF2, by combing the advantages of both GSPM and BDF2. Like GSPM, this method is first-order accurate in time and second-order accurate in space, and is unconditionally stable with respect to the damping parameter. However, GSPM-BDF2 updates the stray field only once per time step, leading to an efficiency improvement of about $60\\%$ than the state-of-the-art GSPM for micromagnetic simulations. For Standard Problem \\#4 and \\#5 from National Institute of Standards and Technology, GSPM-BDF2 reduces the computational time over the popular software OOMMF by $82\\%$ and $96\\%$, respectively. Thus, the proposed method provides a more efficient choice for micromagnetic simulations.",
        "published": "2021-01-21T12:31:00Z",
        "link": "http://arxiv.org/abs/2101.08574v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Meshless Fragile Points Methods Based on Petrov-Galerkin Weak-Forms for   Transient Heat Conduction Problems in Complex Anisotropic Nonhomogeneous   Media",
        "authors": [
            "Yue Guan",
            "Satya N. Atluri"
        ],
        "summary": "Three kinds of Fragile Points Methods based on Petrov-Galerkin weak-forms (PG-FPMs) are proposed for analyzing heat conduction problems in nonhomogeneous anisotropic media. This is a follow-up of the previous study on the original FPM based on a symmetric Galerkin weak-form. The trial function is piecewise-continuous, written as local Taylor expansions at the Fragile Points. A modified Radial Basis Function-based Differential Quadrature (RBF-DQ) method is employed for establishing the local approximation. The Dirac delta function, Heaviside step function, and the local fundamental solution of the governing equation are alternatively used as test functions. Vanishing or pure contour integral formulation in subdomains or on local boundaries can be obtained. Extensive numerical examples in 2D and 3D are provided as validations. The collocation method (PG-FPM-1) is superior in transient analysis with arbitrary point distribution and domain partition. The finite volume method (PG-FPM-2) shows the best efficiency, saving 25% to 50% computational time comparing with the Galerkin FPM. The singular solution method (PG-FPM-3) is highly efficient in steady-state analysis. The anisotropy and nonhomogeneity give rise to no difficulties in all the methods. The proposed PG-FPM approaches represent an improvement to the original Galerkin FPM, as well as to other meshless methods in earlier literature.",
        "published": "2021-01-22T00:24:22Z",
        "link": "http://arxiv.org/abs/2101.08897v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Propagation and reconstruction of re-entry uncertainties using   continuity equation and simplicial interpolation",
        "authors": [
            "Mirko Trisolini",
            "Camilla Colombo"
        ],
        "summary": "This work proposes a continuum-based approach for the propagation of uncertainties in the initial conditions and parameters for the analysis and prediction of spacecraft re-entries. Using the continuity equation together with the re-entry dynamics, the joint probability distribution of the uncertainties is propagated in time for specific sampled points. At each time instant, the joint probability distribution function is then reconstructed from the scattered data using a gradient-enhanced linear interpolation based on a simplicial representation of the state space. Uncertainties in the initial conditions at re-entry and in the ballistic coefficient for three representative test cases are considered: a three-state and a six-state steep Earth re-entry and a six-state unguided lifting entry at Mars. The paper shows the comparison of the proposed method with Monte Carlo based techniques in terms of quality of the obtained marginal distributions and runtime as a function of the number of samples used.",
        "published": "2021-01-22T10:17:52Z",
        "link": "http://arxiv.org/abs/2101.10825v1",
        "categories": [
            "cs.CE",
            "astro-ph.EP",
            "astro-ph.IM",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Bending behavior of additively manufactured lattice structures:   numerical characterization and experimental validation",
        "authors": [
            "Nina Korshunova",
            "Gianluca Alaimo",
            "Seyyed Bahram Hosseini",
            "Massimo Carraturo",
            "Alessandro Reali",
            "Jarkko Niiranen",
            "Ferdinando Auricchio",
            "Ernst Rank",
            "Stefan Kollmannsberger"
        ],
        "summary": "Selective Laser Melting (SLM) technology has undergone significant development in the past years providing unique flexibility for the fabrication of complex metamaterials such as octet-truss lattices. However, the microstructure of the final parts can exhibit significant variations due to the high complexity of the manufacturing process. Consequently, the mechanical behavior of these lattices is strongly dependent on the process-induced defects, raising the importance on the incorporation of as-manufactured geometries into the computational structural analysis. This, in turn, challenges the traditional mesh-conforming methods making the computational costs prohibitively large. In the present work, an immersed image-to-analysis framework is applied to efficiently evaluate the bending behavior of AM lattices. To this end, we employ the Finite Cell Method (FCM) to perform a three-dimensional numerical analysis of the three-point bending test of a lattice structure and compare the as-designed to as-manufactured effective properties. Furthermore, we undertake a comprehensive study on the applicability of dimensionally reduced beam models to the prediction of the bending behavior of lattice beams and validate classical and strain gradient beam theories applied in combination with the FCM. The numerical findings suggest that the SLM octet-truss lattices exhibit size effects, thus, requiring a flexible framework to incorporate high-order continuum theories.",
        "published": "2021-01-22T10:20:50Z",
        "link": "http://arxiv.org/abs/2101.09034v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "An ensemble solver for segregated cardiovascular FSI",
        "authors": [
            "Xue Li",
            "Daniele E. Schiavazzi"
        ],
        "summary": "Computational models are increasingly used for diagnosis and treatment of cardiovascular disease. To provide a quantitative hemodynamic understanding that can be effectively used in the clinic, it is crucial to quantify the variability in the outputs from these models due to multiple sources of uncertainty. To quantify this variability, the analyst invariably needs to generate a large collection of high-fidelity model solutions, typically requiring a substantial computational effort. In this paper, we show how an explicit-in-time ensemble cardiovascular solver offers superior performance with respect to the embarrassingly parallel solution with implicit-in-time algorithms, typical of an inner-outer loop paradigm for non-intrusive uncertainty propagation. We discuss in detail the numerics and efficient distributed implementation of a segregated FSI cardiovascular solver on both CPU and GPU systems, and demonstrate its applicability to idealized and patient-specific cardiovascular models, analyzed under steady and pulsatile flow conditions.",
        "published": "2021-01-22T11:35:52Z",
        "link": "http://arxiv.org/abs/2101.09059v3",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Variational Framework for Structure-Preserving Electromagnetic   Particle-In-Cell Methods",
        "authors": [
            "Martin Campos Pinto",
            "Katharina Kormann",
            "Eric Sonnendrücker"
        ],
        "summary": "In this article we apply a discrete action principle for the Vlasov--Maxwell equations in a structure-preserving particle-field discretization framework. In this framework the finite-dimensional electromagnetic potentials and fields are represented in a discrete de Rham sequence involving general finite element spaces, and the particle-field coupling is represented by a set of projection operators that commute with the differential operators. With a minimal number of assumptions which allow for a variety of finite elements and shape functions for the particles, we show that the resulting variational scheme has a general discrete Poisson structure and thus leads to a semi-discrete Hamiltonian system. By introducing discrete interior products we derive a second type of space discretization which is momentum preserving, based on the same finite elements and shape functions. We illustrate our method by applying it to spline finite elements, and to a new spectral discretization where the particle-field coupling relies on discrete Fourier transforms.",
        "published": "2021-01-22T17:58:31Z",
        "link": "http://arxiv.org/abs/2101.09247v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "math-ph",
            "math.MP",
            "35Q70 (Primary), 65P10, 35Q61 (Secondary)"
        ]
    },
    {
        "title": "F3ORNITS: A Flexible Variable Step Size Non-Iterative Co-simulation   Method handling Subsystems with Hybrid Advanced Capabilities",
        "authors": [
            "Yohan Eguillon",
            "Bruno Lacabanne",
            "Damien Tromeur-Dervout"
        ],
        "summary": "This paper introduces the F3ORNITS non-iterative co-simulation algorithm in which F3 stands for the 3 flexible aspects of the method: flexible polynomial order representation of coupling variables, flexible time-stepper applying variable co-simulation step size rules on subsystems allowing it and flexible scheduler orchestrating the meeting times among the subsystems and capable of asynchronousness when subsystems constraints requires it. The motivation of the F3ORNITS method is to accept any kind of co-simulation model, including any kind of subsystem, regardless on their available capabilities. Indeed, one the major problems in industry is that the subsystems usually have constraints or lack of advanced capabilities making it impossible to implement most of the advanced co-simulation algorithms on them. The method makes it possible to preserve the dynamics of the coupling constraints when necessary as well as to avoid breaking C1 smoothness at communication times, and also to adapt the co-simulation step size in a way that is robust both to zero-crossing variables (contrary to classical relative error-based criteria) and to jumps. Two test cases are presented to illustrate the robustness of the F3ORNITS method as well as its higher accuracy than the non-iterative Jacobi coupling algorithm (the most commonly used method in industry) for a smaller number of co-simulation steps.",
        "published": "2021-01-22T19:58:24Z",
        "link": "http://arxiv.org/abs/2101.09309v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "cs.PF"
        ]
    },
    {
        "title": "Predicting the Mechanical Properties of Biopolymer Gels Using Neural   Networks Trained on Discrete Fiber Network Data",
        "authors": [
            "Yue Leng",
            "Vahidullah Tac",
            "Sarah Calve",
            "Adrian Buganza Tepole"
        ],
        "summary": "Biopolymer gels, such as those made out of fibrin or collagen, are widely used in tissue engineering applications and biomedical research. Moreover, fibrin naturally assembles into gels in vivo during wound healing and thrombus formation. Macroscale biopolymer gel mechanics are dictated by the microscale fiber network. Hence, accurate description of biopolymer gels can be achieved using representative volume elements (RVE) that explicitly model the discrete fiber networks of the microscale. These RVE models, however, cannot be efficiently used to model the macroscale due to the challenges and computational demands of multiscale coupling. Here, we propose the use of an artificial, fully connected neural network (FCNN) to efficiently capture the behavior of the RVE models. The FCNN was trained on 1100 fiber networks subjected to 121 biaxial deformations. The stress data from the RVE, together with the total energy and the condition of incompressibility of the surrounding matrix, were used to determine the derivatives of an unknown strain energy function with respect to the deformation invariants. During training, the loss function was modified to ensure convexity of the strain energy function and symmetry of its Hessian. A general FCNN model was coded into a user material subroutine (UMAT) in the software Abaqus. In this work, the FCNN trained on the discrete fiber network data was used in finite element simulations of fibrin gels using our UMAT. We anticipate that this work will enable further integration of machine learning tools with computational mechanics. It will also improve computational modeling of biological materials characterized by a multiscale structure.",
        "published": "2021-01-23T23:52:33Z",
        "link": "http://arxiv.org/abs/2101.11712v2",
        "categories": [
            "q-bio.QM",
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "A continuum and computational framework for viscoelastodynamics: finite   deformation linear models",
        "authors": [
            "Ju Liu",
            "Marcos Latorre",
            "Alison L. Marsden"
        ],
        "summary": "This work concerns the continuum basis and numerical formulation for deformable materials with viscous dissipative mechanisms. We derive a viscohyperelastic modeling framework based on fundamental thermomechanical principles. Since most large deformation problems exhibit the isochoric property, our modeling work is constructed based on the Gibbs free energy in order to develop a continuum theory using the pressure-primitive variables, which is known to be well-behaved in the incompressible limit. With a general theory presented, we focus on a family of free energies that leads to the so-called finite deformation linear model. Our derivation elucidates the origin of the evolution equations of that model, which was originally proposed heuristically. In our derivation, the thermodynamic inconsistency is clarified and rectified. We then discuss the relaxation property of the non-equilibrium stress in the thermodynamic equilibrium limit and its implication on the form of free energy. A modified version of the identical polymer chain model is then proposed, with a special case being the model proposed by G. Holzapfel and J. Simo. Based on the consistent modeling framework, a provably energy stable numerical scheme is constructed for incompressible viscohyperelasticity using inf-sup stable elements. In particular, we adopt a suite of smooth generalization of the Taylor-Hood element based on Non-Uniform Rational B-Splines (NURBS) for spatial discretization. The temporal discretization is performed via the generalized-alpha scheme. We present a suite of numerical results to corroborate the proposed numerical properties, including the nonlinear stability, robustness under large deformation, and the stress accuracy resolved by the higher-order elements.",
        "published": "2021-01-25T22:01:14Z",
        "link": "http://arxiv.org/abs/2101.10439v2",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Model-free Data-Driven simulation of inelastic materials using   structured data sets, tangent space information and transition rules",
        "authors": [
            "Kerem Ciftci",
            "Klaus Hackl"
        ],
        "summary": "Model-free data-driven computational mechanics replaces phenomenological constitutive functions by numerical simulations based on data sets of representative samples in stress-strain space. The distance of strain and stress pairs from the data set is minimized, subject to equilibrium and compatibility constraints. Although this method operates well for non-linear elastic problems, there are challenges dealing with history-dependent materials, since one and the same point in stress-strain space might correspond to different material behaviour.In recent literature, this issue has been treated by including local histories into the data set. However, there is still the necessity to include models for the evolution of specific internal variables. Thus, a mixed formulation of classical and data-driven modeling is obtained. In the presented approach, the data set is augmented with directions in the tangent space of points in stress-strain space. Moreover, the data set is divided into subsets corresponding to different material behaviour. Based on this classification, transition rules map the modeling points to the various subsets. The approach will be applied to non-linear elasticity and elasto-plasticity with isotropic hardening.",
        "published": "2021-01-26T11:50:19Z",
        "link": "http://arxiv.org/abs/2101.10730v2",
        "categories": [
            "cs.CE",
            "74D10",
            "I.6.3; J.2"
        ]
    },
    {
        "title": "Modeling cardiac muscle fibers in ventricular and atrial   electrophysiology simulations",
        "authors": [
            "Roberto Piersanti",
            "Pasquale C. Africa",
            "Marco Fedele",
            "Christian Vergara",
            "Luca Dedè",
            "Antonio F. Corno",
            "Alfio Quarteroni"
        ],
        "summary": "Since myocardial fibers drive the electric signal propagation throughout the myocardium, accurately modeling their arrangement is essential for simulating heart electrophysiology (EP). Rule-Based-Methods (RBMs) represent a commonly used strategy to include cardiac fibers in computational models. A particular class of such methods is known as Laplace-Dirichlet-Rule-Based-Methods (LDRBMs) since they rely on the solution of Laplace problems. In this work we provide a unified framework, based on LDRBMs, for generating full heart muscle fibers. First, we review existing ventricular LDRBMs providing a communal mathematical description and introducing also some modeling improvements with respect to the existing literature. We then carry out a systematic comparison of LDRBMs based on meaningful biomarkers produced by numerical EP simulations. Next we propose, for the first time, a LDRBM to be used for generating atrial fibers. The new method, tested both on idealized and realistic atrial models, can be applied to any arbitrary geometries. Finally, we present numerical results obtained in a realistic whole heart where fibers are included for all the four chambers using the discussed LDRBMs.",
        "published": "2021-01-26T17:37:47Z",
        "link": "http://arxiv.org/abs/2101.10960v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Accurate and Efficient Simulations of Hamiltonian Mechanical Systems   with Discontinuous Potentials",
        "authors": [
            "Molei Tao",
            "Shi Jin"
        ],
        "summary": "This article considers Hamiltonian mechanical systems with potential functions admitting jump discontinuities. The focus is on accurate and efficient numerical approximations of their solutions, which will be defined via the laws of reflection and refraction. Despite of the success of symplectic integrators for smooth mechanical systems, their construction for the discontinuous ones is nontrivial, and numerical convergence order can be impaired too. Several rather-usable numerical methods are proposed, including: a first-order symplectic integrator for general problems, a third-order symplectic integrator for problems with only one linear interface, arbitrarily high-order reversible integrators for general problems (no longer symplectic), and an adaptive time-stepping version of the previous high-order method. Interestingly, whether symplecticity leads to favorable long time performance is no longer clear due to discontinuity, as traditional Hamiltonian backward error analysis does not apply any more. Therefore, at this stage, our recommended default method is the last one. Various numerical evidence, on the order of convergence, long time performance, momentum map conservation, and consistency with the computationally-expensive penalty method, are supplied. A complex problem, namely the Sauteed Mushroom, is also proposed and numerically investigated, for which multiple bifurcations between trapped and ergodic dynamics are observed.",
        "published": "2021-01-26T19:00:03Z",
        "link": "http://arxiv.org/abs/2101.11018v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "math.DS",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Multigrid reduction preconditioning framework for coupled processes in   porous and fractured media",
        "authors": [
            "Quan M. Bui",
            "Francois P. Hamon",
            "Nicola Castelletto",
            "Daniel Osei-Kuffuor",
            "Randolph R. Settgast",
            "Joshua A. White"
        ],
        "summary": "Many subsurface engineering applications involve tight-coupling between fluid flow, solid deformation, fracturing, and similar processes. To better understand the complex interplay of different governing equations, and therefore design efficient and safe operations, numerical simulations are widely used. Given the relatively long time-scales of interest, fully-implicit time-stepping schemes are often necessary to avoid time-step stability restrictions. A major computational bottleneck for these methods, however, is the linear solver. These systems are extremely large and ill-conditioned. Because of the wide range of processes and couplings that may be involved--e.g. formation and propagation of fractures, deformation of the solid porous medium, viscous flow of one or more fluids in the pores and fractures, complicated well sources and sinks, etc.--it is difficult to develop general-purpose but scalable linear solver frameworks. This challenge is further aggravated by the range of different discretization schemes that may be adopted, which have a direct impact on the linear system structure. To address this obstacle, we describe a flexible framework based on multigrid reduction that can produce purely algebraic preconditioners for a wide spectrum of relevant physics and discretizations. We demonstrate its broad applicability by constructing scalable preconditioners for several problems, notably: a hybrid discretization of single-phase flow, compositional multiphase flow with complex wells, and hydraulic fracturing simulations. Extension to other systems can be handled quite naturally. We demonstrate the efficiency and scalability of the resulting solvers through numerical examples of difficult, field-scale problems.",
        "published": "2021-01-27T19:11:47Z",
        "link": "http://arxiv.org/abs/2101.11649v3",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "65Z05, 65F08, 65F50"
        ]
    },
    {
        "title": "Non-intrusive reduced order modeling of poroelasticity of heterogeneous   media based on a discontinuous Galerkin approximation",
        "authors": [
            "T. Kadeethum",
            "F. Ballarin",
            "N. Bouklas"
        ],
        "summary": "We present a non-intrusive model reduction framework for linear poroelasticity problems in heterogeneous porous media using proper orthogonal decomposition (POD) and neural networks, based on the usual offline-online paradigm. As the conductivity of porous media can be highly heterogeneous and span several orders of magnitude, we utilize the interior penalty discontinuous Galerkin (DG) method as a full order solver to handle discontinuity and ensure local mass conservation during the offline stage. We then use POD as a data compression tool and compare the nested POD technique, in which time and uncertain parameter domains are compressed consecutively, to the classical POD method in which all domains are compressed simultaneously. The neural networks are finally trained to map the set of uncertain parameters, which could correspond to material properties, boundary conditions, or geometric characteristics, to the collection of coefficients calculated from an $L^2$ projection over the reduced basis. We then perform a non-intrusive evaluation of the neural networks to obtain coefficients corresponding to new values of the uncertain parameters during the online stage. We show that our framework provides reasonable approximations of the DG solution, but it is significantly faster. Moreover, the reduced order framework can capture sharp discontinuities of both displacement and pressure fields resulting from the heterogeneity in the media conductivity, which is generally challenging for intrusive reduced order methods. The sources of error are presented, showing that the nested POD technique is computationally advantageous and still provides comparable accuracy to the classical POD method. We also explore the effect of different choices of the hyperparameters of the neural network on the framework performance.",
        "published": "2021-01-28T04:21:06Z",
        "link": "http://arxiv.org/abs/2101.11810v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.LG",
            "cs.NA"
        ]
    },
    {
        "title": "A Momentum-Conserving Implicit Material Point Method for Surface   Energies with Spatial Gradients",
        "authors": [
            "Jingyu Chen",
            "Victoria Kala",
            "Alan Marquez-Razon",
            "Elias Gueidon",
            "David A. B. Hyde",
            "Joseph Teran"
        ],
        "summary": "We present a novel Material Point Method (MPM) discretization of surface tension forces that arise from spatially varying surface energies. These variations typically arise from surface energy dependence on temperature and/or concentration. Furthermore, since the surface energy is an interfacial property depending on the types of materials on either side of an interface, spatial variation is required for modeling the contact angle at the triple junction between a liquid, solid and surrounding air. Our discretization is based on the surface energy itself, rather than on the associated traction condition most commonly used for discretization with particle methods. Our energy based approach automatically captures surface gradients without the explicit need to resolve them as in traction condition based approaches. We include an implicit discretization of thermomechanical material coupling with a novel particle-based enforcement of Robin boundary conditions associated with convective heating. Lastly, we design a particle resampling approach needed to achieve perfect conservation of linear and angular momentum with AffineParticle-In-Cell (APIC) [Jiang et al. 2015]. We show that our approach enables implicit time stepping for complex behaviors like the Marangoni effect and hydrophobicity/hydrophilicity. We demonstrate the robustness and utility of our method by simulating materials that exhibit highly diverse degrees of surface tension and thermomechanical effects, such as water, wine and wax.",
        "published": "2021-01-29T05:18:12Z",
        "link": "http://arxiv.org/abs/2101.12408v1",
        "categories": [
            "cs.GR",
            "cs.CE",
            "I.3.0; I.6.0"
        ]
    },
    {
        "title": "On the periodicity of cardiovascular fluid dynamics simulations",
        "authors": [
            "Martin R. Pfaller",
            "Jonathan Pham",
            "Nathan M. Wilson",
            "David W. Parker",
            "Alison L. Marsden"
        ],
        "summary": "Three-dimensional cardiovascular fluid dynamics simulations typically require computation of several cardiac cycles before they reach a periodic solution, rendering them computationally expensive. Furthermore, there is currently no standardized method to determine whether a simulation has yet reached that periodic state. In this work, we propose use of the asymptotic error measure to quantify the difference between simulation results and their ideal periodic state using lumped-parameter modeling. We further show that initial conditions are crucial in reducing computational time and develop an automated framework to generate appropriate initial conditions from a one-dimensional model of blood flow. We demonstrate the performance of our initialization method using six patient-specific models from the Vascular Model Repository. In our examples, our initialization protocol achieves periodic convergence within one or two cardiac cycles, leading to a significant reduction in computational cost compared to standard methods. All computational tools used in this work are implemented in the open-source software platform SimVascular. Automatically generated initial conditions have the potential to significantly reduce computation time in cardiovascular fluid dynamics simulations.",
        "published": "2021-01-29T23:23:02Z",
        "link": "http://arxiv.org/abs/2102.00107v1",
        "categories": [
            "cs.CE",
            "physics.med-ph"
        ]
    },
    {
        "title": "A Novel Use of Discrete Wavelet Transform Features in the Prediction of   Epileptic Seizures from EEG Data",
        "authors": [
            "Cyrille Feudjio",
            "Victoire Djimna Noyum",
            "Younous Perieukeu Mofendjou",
            "Rockefeller",
            "Ernest Fokoué"
        ],
        "summary": "This paper demonstrates the predictive superiority of discrete wavelet transform (DWT) over previously used methods of feature extraction in the diagnosis of epileptic seizures from EEG data. Classification accuracy, specificity, and sensitivity are used as evaluation metrics. We specifically show the immense potential of 2 combinations (DWT-db4 combined with SVM and DWT-db2 combined with RF) as compared to others when it comes to diagnosing epileptic seizures either in the balanced or the imbalanced dataset. The results also highlight that MFCC performs less than all the DWT used in this study and that, The mean-differences are statistically significant respectively in the imbalanced and balanced dataset. Finally, either in the balanced or the imbalanced dataset, the feature extraction techniques, the models, and the interaction between them have a statistically significant effect on the classification accuracy.",
        "published": "2021-01-31T17:21:10Z",
        "link": "http://arxiv.org/abs/2102.01647v1",
        "categories": [
            "cs.CE",
            "cs.LG",
            "eess.SP",
            "stat.OT"
        ]
    },
    {
        "title": "Integration of activation maps of epicardial veins in computational   cardiac electrophysiology",
        "authors": [
            "Simone Stella",
            "Christian Vergara",
            "Massimiliano Maines",
            "Domenico Catanzariti",
            "Pasquale C. Africa",
            "Cristina Demattè",
            "Maurizio Centonze",
            "Fabio Nobile",
            "Maurizio Del Greco",
            "Alfio Quarteroni"
        ],
        "summary": "In this work we address the issue of validating the monodomain equation used in combination with the Bueno-Orovio ionic model for the prediction of the activation times in cardiac electro-physiology of the left ventricle. To this aim, we consider our patients who suffered from Left Bundle Branch Block (LBBB). We use activation maps performed at the septum as input data for the model and maps at the epicardial veins for the validation. In particular, a first set (half) of the latter are used to estimate the conductivities of the patient and a second set (the remaining half) to compute the errors of the numerical simulations. We find an excellent agreement between measures and numerical results. Our validated computational tool could be used to accurately predict activation times at the epicardial veins with a short mapping, i.e. by using only a part (the most proximal) of the standard acquisition points, thus reducing the invasive procedure and exposure to radiation.",
        "published": "2021-01-31T17:32:50Z",
        "link": "http://arxiv.org/abs/2102.00498v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "High Resolution 3D Ultrasonic Breast Imaging by Time-Domain Full   Waveform Inversion",
        "authors": [
            "Felix Lucka",
            "Mailyn Pérez-Liva",
            "Bradley E. Treeby",
            "Ben T. Cox"
        ],
        "summary": "Ultrasound tomography (UST) scanners allow quantitative images of the human breast's acoustic properties to be derived with potential applications in screening, diagnosis and therapy planning. Time domain full waveform inversion (TD-FWI) is a promising UST image formation technique that fits the parameter fields of a wave physics model by gradient-based optimization. For high resolution 3D UST, it holds three key challenges: Firstly, its central building block, the computation of the gradient for a single US measurement, has a restrictively large memory footprint. Secondly, this building block needs to be computed for each of the $10^3-10^4$ measurements, resulting in a massive parallel computation usually performed on large computational clusters for days. Lastly, the structure of the underlying optimization problem may result in slow progression of the solver and convergence to a local minimum. In this work, we design and evaluate a comprehensive computational strategy to overcome these challenges: Firstly, we exploit a gradient computation based on time reversal that dramatically reduces the memory footprint at the expense of one additional wave simulation per source. Secondly, we break the dependence on the number of measurements by using source encoding (SE) to compute stochastic gradient estimates. Also we describe a more accurate, TD-specific SE technique with a finer variance control and use a state-of-the-art stochastic LBFGS method. Lastly, we design an efficient TD multi-grid scheme together with preconditioning to speed up the convergence while avoiding local minima. All components are evaluated in extensive numerical proof-of-concept studies simulating a bowl-shaped 3D UST breast scanner prototype. Finally, we demonstrate that their combination allows us to obtain an accurate 442x442x222 voxel image with a resolution of 0.5mm using Matlab on a single GPU within 24h.",
        "published": "2021-02-01T10:38:11Z",
        "link": "http://arxiv.org/abs/2102.00755v4",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "math.OC"
        ]
    },
    {
        "title": "An enhanced parametric nonlinear reduced order model for imperfect   structures using Neumann expansion",
        "authors": [
            "Jacopo Marconi",
            "Paolo Tiso",
            "Davide E. Quadrelli",
            "Francesco Braghin"
        ],
        "summary": "We present an enhanced version of the parametric nonlinear reduced order model for shape imperfections in structural dynamics we studied in a previous work [1]. The model is computed intrusively and with no training using information about the nominal geometry of the structure and some user-defined displacement fields representing shape defects, i.e. small deviations from the nominal geometry parametrized by their respective amplitudes. The linear superposition of these artificial displacements describe the defected geometry and can be embedded in the strain formulation in such a way that, in the end, nonlinear internal elastic forces can be expressed as a polynomial function of both these defect fields and the actual displacement field. This way, a tensorial representation of the internal forces can be obtained and, owning the reduction in size of the model given by a Galerkin projection, high simulation speed-ups can be achieved. We show that by adopting a rigorous deformation framework we are able to achieve better accuracy as compared to the previous work. In particular, exploiting Neumann expansion in the definition of the Green-Lagrange strain tensor, we show that our previous model is a lower order approximation with respect to the one we present now. Two numerical examples of a clamped beam and a MEMS gyroscope finally demonstrate the benefits of the method in terms of speed and increased accuracy.",
        "published": "2021-02-02T20:24:02Z",
        "link": "http://arxiv.org/abs/2102.01739v1",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "A Data-Driven Approach to Violin Making",
        "authors": [
            "Sebastian Gonzalez",
            "Davide Salvi",
            "Daniel Baeza",
            "Fabio Antonacci",
            "Augusto Sarti"
        ],
        "summary": "Of all the characteristics of a violin, those that concern its shape are probably the most important ones, as the violin maker has complete control over them. Contemporary violin making, however, is still based more on tradition than understanding, and a definitive scientific study of the specific relations that exist between shape and vibrational properties is yet to come and sorely missed. In this article, using standard statistical learning tools, we show that the modal frequencies of violin tops can, in fact, be predicted from geometric parameters, and that artificial intelligence can be successfully applied to traditional violin making. We also study how modal frequencies vary with the thicknesses of the plate (a process often referred to as {\\em plate tuning}) and discuss the complexity of this dependency. Finally, we propose a predictive tool for plate tuning, which takes into account material and geometric parameters.",
        "published": "2021-02-03T00:42:08Z",
        "link": "http://arxiv.org/abs/2102.04254v1",
        "categories": [
            "cs.CE",
            "cs.AI",
            "cs.LG",
            "cs.SD",
            "eess.AS"
        ]
    },
    {
        "title": "Deep Hedging under Rough Volatility",
        "authors": [
            "Blanka Horvath",
            "Josef Teichmann",
            "Zan Zuric"
        ],
        "summary": "We investigate the performance of the Deep Hedging framework under training paths beyond the (finite dimensional) Markovian setup. In particular we analyse the hedging performance of the original architecture under rough volatility models with view to existing theoretical results for those. Furthermore, we suggest parsimonious but suitable network architectures capable of capturing the non-Markoviantity of time-series. Secondly, we analyse the hedging behaviour in these models in terms of P\\&L distributions and draw comparisons to jump diffusion models if the the rebalancing frequency is realistically small.",
        "published": "2021-02-03T09:27:16Z",
        "link": "http://arxiv.org/abs/2102.01962v1",
        "categories": [
            "q-fin.CP",
            "cs.CE",
            "91-08"
        ]
    },
    {
        "title": "Aitken-Schwarz heterogeneous Domain Decomposition for EMT-TS Simulation",
        "authors": [
            "Héléna Schourick",
            "Damien Tromeur-Dervout",
            "Laurent Chedot"
        ],
        "summary": "In this paper, a Schwarz heterogeneous domain decomposition method (DDM) is used to co-simulate an RLC electrical circuit where a part of the domain is modeled with Electro-Magnetic Transients (EMT) modeling and the other part with dynamic phasor (TS) modeling. Domain partitioning is not based on cutting at transmission lines which introduces a physical delay on the dynamics of the solution, as is usually done, but only on connectivity considerations. We show the convergence property of the homogeneous DDM EMT-EMT and TS-TS and of the heterogeneous DDM TS-EMT, with and without overlap and we use the pure linear divergence/convergence of the method to accelerate it toward the searched solution with the Aitken's acceleration of the convergence technique.",
        "published": "2021-02-04T09:33:11Z",
        "link": "http://arxiv.org/abs/2102.02507v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "65B05, 65L80, 65F10",
            "G.1.7; I.6.5"
        ]
    },
    {
        "title": "Accurate numerical simulation of electrodiffusion and water movement in   brain tissue",
        "authors": [
            "Ada J. Ellingsrud",
            "Nicolas Boullé",
            "Patrick E. Farrell",
            "Marie E. Rognes"
        ],
        "summary": "Mathematical modelling of ionic electrodiffusion and water movement is emerging as a powerful avenue of investigation to provide new physiological insight into brain homeostasis. However, in order to provide solid answers and resolve controversies, the accuracy of the predictions is essential. Ionic electrodiffusion models typically comprise non-trivial systems of non-linear and highly coupled partial and ordinary differential equations that govern phenomena on disparate time scales. Here, we study numerical challenges related to approximating these systems. We consider a homogenized model for electrodiffusion and osmosis in brain tissue and present and evaluate different associated finite element-based splitting schemes in terms of their numerical properties, including accuracy, convergence, and computational efficiency for both idealized scenarios and for the physiologically relevant setting of cortical spreading depression (CSD). We find that the schemes display optimal convergence rates in space for problems with smooth manufactured solutions. However, the physiological CSD setting is challenging: we find that the accurate computation of CSD wave characteristics (wave speed and wave width) requires a very fine spatial and fine temporal resolution.",
        "published": "2021-02-04T10:56:35Z",
        "link": "http://arxiv.org/abs/2102.02539v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "A simple artificial damping method for total Lagrangian smoothed   particle hydrodynamics",
        "authors": [
            "Chi Zhang",
            "Yujie Zhu",
            "Yongchuan Yu",
            "Massoud Rezavand",
            "Xiangyu Hu"
        ],
        "summary": "In this paper, we present a simple artificial damping method to enhance the robustness of total Lagrangian smoothed particle hydrodynamics (TL-SPH). Specifically, an artificial damping stress based on the Kelvin-Voigt type damper with a scaling factor imitating a von Neumann-Richtmyer type artificial viscosity is introduced in the constitutive equation to alleviate the spurious oscillation in the vicinity of the sharp spatial gradients. After validating the robustness and accuracy of the present method with a set of benchmark tests with very challenging cases, we demonstrate its potentials in the field of bio-mechanics by simulating the deformation of complex stent structures.",
        "published": "2021-02-05T09:57:16Z",
        "link": "http://arxiv.org/abs/2102.04898v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Two-grid method on unstructured tetrahedra: Applying computational   geometry to staggered solution of coupled flow and mechanics problems",
        "authors": [
            "Saumik Dana",
            "Xiaoxi Zhao",
            "Birendra Jha"
        ],
        "summary": "We develop a computational framework that leverages the features of sophisticated software tools and numerics to tackle some of the pressing issues in the realm of earth sciences. The algorithms to handle the physics of multiphase flow, concomitant geomechanics all the way to the surface of the earth and the complex geometries of field cases with surfaces of discontinuity are stacked on top of each other in a modular fashion which allows for easy use to the end user. The current focus of the framework is to provide the user with tools for assessing seismic risks associated with energy technologies as well as for use in generating forward simulations in inversion analysis from data obtained using GPS and InSAR. In this work, we focus on one critical aspect in the development of the framework: the use of computational geometry in a two-grid method for unstructured tetrahedral meshes",
        "published": "2021-02-07T20:24:50Z",
        "link": "http://arxiv.org/abs/2102.04455v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Generalised correlated batched bandits via the ARC algorithm with   application to dynamic pricing",
        "authors": [
            "Samuel Cohen",
            "Tanut Treetanthiploet"
        ],
        "summary": "The Asymptotic Randomised Control (ARC) algorithm provides a rigorous approximation to the optimal strategy for a wide class of Bayesian bandits, while retaining low computational complexity. In particular, the ARC approach provides nearly optimal choices even when the payoffs are correlated or more than the reward is observed. The algorithm is guaranteed to asymptotically optimise the expected discounted payoff, with error depending on the initial uncertainty of the bandit. In this paper, we extend the ARC framework to consider a batched bandit problem where observations arrive from a generalised linear model. In particular, we develop a large sample approximation to allow correlated and generally distributed observation. We apply this to a classic dynamic pricing problem based on a Bayesian hierarchical model and demonstrate that the ARC algorithm outperforms alternative approaches.",
        "published": "2021-02-08T14:54:26Z",
        "link": "http://arxiv.org/abs/2102.04263v2",
        "categories": [
            "math.OC",
            "cs.CE",
            "cs.LG",
            "econ.GN",
            "q-fin.EC",
            "stat.ML",
            "62J12, 90B50, 91B38, 93C41"
        ]
    },
    {
        "title": "Hierarchical a posteriori error estimation of Bank-Weiser type in the   FEniCS Project",
        "authors": [
            "Raphaël Bulle",
            "Jack S. Hale",
            "Alexei Lozinski",
            "Stéphane P. A. Bordas",
            "Franz Chouly"
        ],
        "summary": "In the seminal paper of Bank and Weiser [Math. Comp., 44 (1985), pp.283-301] a new a posteriori estimator was introduced. This estimator requires the solution of a local Neumann problem on every cell of the finite element mesh. Despite the promise of Bank-Weiser type estimators, namely locality, computational efficiency, and asymptotic sharpness, they have seen little use in practical computational problems. The focus of this contribution is to describe a novel implementation of hierarchical estimators of the Bank-Weiser type in a modern high-level finite element software with automatic code generation capabilities. We show how to use the estimator to drive (goal-oriented) adaptive mesh refinement and to mixed approximations of the nearly-incompressible elasticity problems. We provide comparisons with various other used estimators. An open-source implementation based on the FEniCS Project finite element software is provided as supplementary material.",
        "published": "2021-02-08T17:09:15Z",
        "link": "http://arxiv.org/abs/2102.04360v2",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Bayesian Poroelastic Aquifer Characterization from InSAR Surface   Deformation Data Part II: Quantifying the Uncertainty",
        "authors": [
            "Amal Alghamdi",
            "Marc Hesse",
            "Jingyi Chen",
            "Umberto Villa",
            "Omar Ghattas"
        ],
        "summary": "Uncertainty quantification of groundwater (GW) aquifer parameters is critical for efficient management and sustainable extraction of GW resources. These uncertainties are introduced by the data, model, and prior information on the parameters. Here we develop a Bayesian inversion framework that uses Interferometric Synthetic Aperture Radar (InSAR) surface deformation data to infer the laterally heterogeneous permeability of a transient linear poroelastic model of a confined GW aquifer. The Bayesian solution of this inverse problem takes the form of a posterior probability density of the permeability. Exploring this posterior using classical Markov chain Monte Carlo (MCMC) methods is computationally prohibitive due to the large dimension of the discretized permeability field and the expense of solving the poroelastic forward problem. However, in many partial differential equation (PDE)-based Bayesian inversion problems, the data are only informative in a few directions in parameter space. For the poroelasticity problem, we prove this property theoretically for a one-dimensional problem and demonstrate it numerically for a three-dimensional aquifer model. We design a generalized preconditioned Crank--Nicolson (gpCN) MCMC method that exploits this intrinsic low dimensionality by using a low-rank based Laplace approximation of the posterior as a proposal, which we build scalably. The feasibility of our approach is demonstrated through a real GW aquifer test in Nevada. The inherently two dimensional nature of InSAR surface deformation data informs a sufficient number of modes of the permeability field to allow detection of major structures within the aquifer, significantly reducing the uncertainty in the pressure and the displacement quantities of interest.",
        "published": "2021-02-08T23:47:34Z",
        "link": "http://arxiv.org/abs/2102.04577v1",
        "categories": [
            "physics.geo-ph",
            "cs.CE"
        ]
    },
    {
        "title": "Simulating dense granular flow using the $μ$($I$)-rheology within a   space-time framework",
        "authors": [
            "Linda Gesenhues",
            "Marek Behr"
        ],
        "summary": "A space-time framework is applied to simulate dense granular flow. Two different numerical experiments are performed: a column collapse and a dam break on an inclined plane. The experiments are modeled as two-phase flows. The dense granular material is represented by a constitutive model, the $\\mu$($I$)-rheology, that is based on the Coulomb's friction law, such that the normal stress applied by the pressure is related to the tangential stress. The model represents a complex shear thinning viscoplastic material behavior. The interface between the dense granular material and the surrounding light fluid is captured with a level set function. Due to discontinuities close to the the interface, the mesh requires a sufficient resolution. The space-time approach allows unstructured meshes in time and, therefore a well refined mesh in the temporal direction around the interface. In this study, results and performance of a flat and a simplex space time discretization are verified and analyzed.",
        "published": "2021-02-09T08:36:21Z",
        "link": "http://arxiv.org/abs/2102.04701v1",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Structure-preserving Model Reduction of Parametric Power Networks",
        "authors": [
            "Bita Safaee",
            "Serkan Gugercin"
        ],
        "summary": "We develop a structure-preserving parametric model reduction approach for linearized swing equations where parametrization corresponds to variations in operating conditions. We employ a global basis approach to develop the parametric reduced model in which we concatenate the local bases obtained via $\\mathcal{H}_2$-based interpolatory model reduction. The residue of the underlying dynamics corresponding to the simple pole at zero varies with the parameters. Therefore, to have bounded $\\mathcal{H}_2$ and $\\mathcal{H}_\\infty$ errors, the reduced model residue for the pole at zero should match the original one over the entire parameter domain. Our framework achieves this goal by enriching the global basis based on a residue analysis. The effectiveness of the proposed method is illustrated through two numerical examples.",
        "published": "2021-02-09T23:20:58Z",
        "link": "http://arxiv.org/abs/2102.05179v1",
        "categories": [
            "eess.SY",
            "cs.CE",
            "cs.SY"
        ]
    },
    {
        "title": "A positivity-preserving high-order weighted compact nonlinear scheme for   compressible gas-liquid flows",
        "authors": [
            "Man Long Wong",
            "Jordan B. Angel",
            "Michael F. Barad",
            "Cetin C. Kiris"
        ],
        "summary": "We present a robust, highly accurate, and efficient positivity- and boundedness-preserving diffuse interface method for the simulations of compressible gas-liquid two-phase flows with the five-equation model by Allaire et al. using high-order finite difference weighted compact nonlinear scheme (WCNS) in the explicit form. The equation of states of gas and liquid are given by the ideal gas and stiffened gas laws respectively. Under a mild assumption on the relative magnitude between the ratios of specific heats of the gas and liquid, we can construct limiting procedures for the fifth order incremental-stencil WCNS (WCNS-IS) with the first order Harten-Lax-van Leer contact (HLLC) flux such that positive partial densities and squared speed of sound can be ensured in the solutions, together with bounded volume fractions and mass fractions. The limiting procedures are discretely conservative for all conservative equations in the five-equation model and can also be easily extended for any other conservative finite difference or finite volume scheme. Numerical tests with liquid water and air are reported to demonstrate the robustness and high accuracy of the WCNS-IS with the positivity- and boundedness-preserving limiters even under extreme conditions.",
        "published": "2021-02-10T07:01:00Z",
        "link": "http://arxiv.org/abs/2102.05287v1",
        "categories": [
            "physics.comp-ph",
            "cs.CE",
            "physics.flu-dyn"
        ]
    },
    {
        "title": "Computationally Efficient Multiscale Neural Networks Applied To Fluid   Flow In Complex 3D Porous Media",
        "authors": [
            "Javier Santos",
            "Ying Yin",
            "Honggeun Jo",
            "Wen Pan",
            "Qinjun Kang",
            "Hari Viswanathan",
            "Masa Prodanovic",
            "Michael Pyrcz",
            "Nicholas Lubbers"
        ],
        "summary": "The permeability of complex porous materials can be obtained via direct flow simulation, which provides the most accurate results, but is very computationally expensive. In particular, the simulation convergence time scales poorly as simulation domains become tighter or more heterogeneous. Semi-analytical models that rely on averaged structural properties (i.e. porosity and tortuosity) have been proposed, but these features only summarize the domain, resulting in limited applicability. On the other hand, data-driven machine learning approaches have shown great promise for building more general models by virtue of accounting for the spatial arrangement of the domains solid boundaries. However, prior approaches building on the Convolutional Neural Network (ConvNet) literature concerning 2D image recognition problems do not scale well to the large 3D domains required to obtain a Representative Elementary Volume (REV). As such, most prior work focused on homogeneous samples, where a small REV entails that that the global nature of fluid flow could be mostly neglected, and accordingly, the memory bottleneck of addressing 3D domains with ConvNets was side-stepped. Therefore, important geometries such as fractures and vuggy domains could not be well-modeled. In this work, we address this limitation with a general multiscale deep learning model that is able to learn from porous media simulation data. By using a coupled set of neural networks that view the domain on different scales, we enable the evaluation of large images in approximately one second on a single Graphics Processing Unit. This model architecture opens up the possibility of modeling domain sizes that would not be feasible using traditional direct simulation tools on a desktop computer.",
        "published": "2021-02-10T23:38:36Z",
        "link": "http://arxiv.org/abs/2102.07625v1",
        "categories": [
            "physics.geo-ph",
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "Brain Modelling as a Service: The Virtual Brain on EBRAINS",
        "authors": [
            "Michael Schirner",
            "Lia Domide",
            "Dionysios Perdikis",
            "Paul Triebkorn",
            "Leon Stefanovski",
            "Roopa Pai",
            "Paula Popa",
            "Bogdan Valean",
            "Jessica Palmer",
            "Chloê Langford",
            "André Blickensdörfer",
            "Michiel van der Vlag",
            "Sandra Diaz-Pier",
            "Alexander Peyser",
            "Wouter Klijn",
            "Dirk Pleiter",
            "Anne Nahm",
            "Oliver Schmid",
            "Marmaduke Woodman",
            "Lyuba Zehl",
            "Jan Fousek",
            "Spase Petkoski",
            "Lionel Kusch",
            "Meysam Hashemi",
            "Daniele Marinazzo",
            "Jean-François Mangin",
            "Agnes Flöel",
            "Simisola Akintoye",
            "Bernd Carsten Stahl",
            "Michael Cepic",
            "Emily Johnson",
            "Gustavo Deco",
            "Anthony R. McIntosh",
            "Claus C. Hilgetag",
            "Marc Morgan",
            "Bernd Schuller",
            "Alex Upton",
            "Colin McMurtrie",
            "Timo Dickscheid",
            "Jan G. Bjaalie",
            "Katrin Amunts",
            "Jochen Mersmann",
            "Viktor Jirsa",
            "Petra Ritter"
        ],
        "summary": "The Virtual Brain (TVB) is now available as open-source cloud ecosystem on EBRAINS, a shared digital research platform for brain science. It offers services for constructing, simulating and analysing brain network models (BNMs) including the TVB network simulator; magnetic resonance imaging (MRI) processing pipelines to extract structural and functional connectomes; multiscale co-simulation of spiking and large-scale networks; a domain specific language for automatic high-performance code generation from user-specified models; simulation-ready BNMs of patients and healthy volunteers; Bayesian inference of epilepsy spread; data and code for mouse brain simulation; and extensive educational material. TVB cloud services facilitate reproducible online collaboration and discovery of data assets, models, and software embedded in scalable and secure workflows, a precondition for research on large cohort data sets, better generalizability and clinical translation.",
        "published": "2021-02-11T08:33:50Z",
        "link": "http://arxiv.org/abs/2102.05888v2",
        "categories": [
            "cs.CE",
            "cs.CR",
            "cs.DC",
            "q-bio.NC",
            "q-bio.QM"
        ]
    },
    {
        "title": "Development of a Fully-Coupled Harmonic Balance Method and a Refined   Energy Method for the Computation of Flutter-Induced Limit Cycle Oscillations   of Bladed Disks with Nonlinear Friction Contacts",
        "authors": [
            "Christian Berthold",
            "Johann Gross",
            "Christian Frey",
            "Malte Krack"
        ],
        "summary": "Flutter stability is a dominant design constraint of modern gas and steam turbines. To further increase the feasible design space, flutter-tolerant designs are currently explored, which may undergo Limit Cycle Oscillations (LCOs) of acceptable, yet not vanishing, level. Bounded self-excited oscillations are a priori a nonlinear phenomenon, and can thus only be explained by nonlinear interactions such as dry stick-slip friction in mechanical joints. The currently available simulation methods for blade flutter account for nonlinear interactions, at most, in only one domain, the structure or the fluid, and assume the behavior in the other domain as linear. In this work, we develop a fully-coupled nonlinear frequency domain method which is capable of resolving nonlinear flow and structural effects. We demonstrate the computational performance of this method for a state-of-the-art aeroelastic model of a shrouded turbine blade row. Besides simulating limit cycles, we predict, for the first time, the phenomenon of nonlinear instability, i.e., a situation where the equilibrium point is locally stable, but for sufficiently strong perturbation (caused e.g. by an impact), the dry frictional dissipation cannot bound the flutter vibrations. This implies that linearized theory does not necessary lead to a conservative design of turbine blades. We show that this phenomenon is due to the nonlinear contact interactions at the tip shrouds, which cause a change of the vibrational deflection shape and frequency, which in turn leads to a loss of aeroelastic stability. Finally, we extend the well-known energy method to capture these effects, and conclude that it provides a good approximation and is useful for initializing the fully-coupled solver.",
        "published": "2021-02-11T12:46:49Z",
        "link": "http://arxiv.org/abs/2102.05978v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Full waveform inversion using extended and simultaneous sources",
        "authors": [
            "Sagi Buchatsky",
            "Eran Treister"
        ],
        "summary": "PDE-constrained optimization problems are often treated using the reduced formulation where the PDE constraints are eliminated. This approach is known to be more computationally feasible than other alternatives at large scales. However, the elimination of the constraints forces the optimization process to fulfill the constraints at all times. In some problems this may lead to a highly non-linear objective, which is hard to solve. An example to such a problem, which we focus on in this work, is Full Waveform Inversion (FWI), which appears in seismic exploration of oil and gas reservoirs, and medical imaging. In an attempt to relieve the non-linearity of FWI, several approaches suggested to expand the optimization search space and relax the PDE constraints. This comes, however, with severe memory and computational costs, which we aim to reduce. In this work we adopt the expanded search space approach, and suggest a new formulation of FWI using extended source functions. To make the source-extended problem more feasible in memory and computations, we couple the source extensions in the form of a low-rank matrix. This way, we have a large-but-manageable additional parameter space, which has a rather low memory footprint, and is much more suitable for solving large scale instances of the problem than the full rank additional space. In addition, we show how our source-extended approach is applied together with the popular simultaneous sources technique -- a stochastic optimization technique that significantly reduces the computations needed for FWI inversions. We demonstrate our approaches for solving FWI problems using 2D and 3D models with high frequency data only.",
        "published": "2021-02-11T14:02:58Z",
        "link": "http://arxiv.org/abs/2102.06014v2",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA",
            "86A22, 86A15, 65M32, 65N22, 35Q86, 35R30"
        ]
    },
    {
        "title": "A fast algorithm for solving a three-dimensional inverse multiple   frequency problems of scalar acoustics in a cylindrical region",
        "authors": [
            "Anatoly B. Bakushinsky",
            "Alexander S. Leonov"
        ],
        "summary": "A new algorithm for the stable solution of a three-dimensional scalar inverse problem of acoustic sounding of an inhomogeneous medium in a cylindrical region is proposed. The data of the problem is the complex amplitude of the wave field, measured outside the region of acoustic inhomogeneities in a cylindrical layer. Using the Fourier transform and Fourier series, the inverse problem is reduced to solving a set of one-dimensional Fredholm integral equations of the first kind, to the subsequent calculation of the complex amplitude of the wave field in the region of inhomogeneity, and then to finding the required sound velocity field in this region. The algorithm allows solving the inverse problem on a personal computer of average performance for sufficiently fine three-dimensional grids in tens of seconds. A numerical study of the accuracy of the proposed algorithm for solving model inverse problems at various frequencies is carried out, and the issues of stability of the algorithm with respect to data perturbations are investigated.",
        "published": "2021-02-11T17:31:11Z",
        "link": "http://arxiv.org/abs/2102.06141v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "65R20, 65R30, 65R32"
        ]
    },
    {
        "title": "Semi-linear Poisson-mediated Flocking in a Cucker-Smale Model",
        "authors": [
            "Christos N. Mavridis",
            "Amoolya Tirumalai",
            "John S. Baras",
            "Ion Matei"
        ],
        "summary": "We propose a family of compactly supported parametric interaction functions in the general Cucker-Smale flocking dynamics such that the mean-field macroscopic system of mass and momentum balance equations with non-local damping terms can be converted from a system of partial integro-differential equations to an augmented system of partial differential equations in a compact set. We treat the interaction functions as Green's functions for an operator corresponding to a semi-linear Poisson equation and compute the density and momentum in a translating reference frame, i.e. one that is taken in reference to the flock's centroid. This allows us to consider the dynamics in a fixed, flock-centered compact set without loss of generality. We approach the computation of the non-local damping using the standard finite difference treatment of the chosen differential operator, resulting in a tridiagonal system which can be solved quickly.",
        "published": "2021-02-11T17:50:01Z",
        "link": "http://arxiv.org/abs/2102.08772v1",
        "categories": [
            "cs.CE",
            "cs.SY",
            "eess.SY",
            "math.AP"
        ]
    },
    {
        "title": "Calculation of Photocarrier Generation from Optical Absorption for   Time-domain Simulation of Optoelectronic Devices",
        "authors": [
            "Liang Chen",
            "Hakan Bagci"
        ],
        "summary": "Photocarrier generation rate in optoelectronic materials is often calculated using the Poynting vector in the frequency domain. However, this approach is not accurate in time-domain simulations of photoconductive devices because the instantaneous Poynting vector does not distinguish between power flux densities of optical and low-frequency electromagnetic fields. The latter is generated by photocurrents and is not supposed to contribute to the photocarrier generation since the corresponding photon energy is smaller than the bandgap energy of the optoelectronic material. In this work, an optical absorption-based model is proposed to accurately calculate the generation rate in time-domain simulations. The proposed approach considers the material dispersion near the optical frequency corresponding to the bandgap energy of the optoelectronic material. The instantaneous optical absorption is calculated from the polarization current density associated with the dispersion model. Then, the optical absorption is used to calculate the generation rate. Numerical examples show that the proposed approach is more accurate than the Poynting vector-based method in calculating the instantaneous optical absorption. The proposed method is further validated against experimental results by modeling a photoconductive device. In the multiphysics simulation, the Poynting vector-based method overestimates the carrier generation rate and even generates divergent carrier densities when the low-frequency fields are strong, while the proposed method produces results that match with experimental measurements well.",
        "published": "2021-02-12T18:58:27Z",
        "link": "http://arxiv.org/abs/2102.06702v2",
        "categories": [
            "physics.optics",
            "cs.CE",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Multimodal Mobility Systems: Joint Optimization of Transit Network   Design and Pricing",
        "authors": [
            "Qi Luo",
            "Samitha Samaranayake",
            "Siddhartha Banerjee"
        ],
        "summary": "The performance of multimodal mobility systems relies on the seamless integration of conventional mass transit services and the advent of Mobility-on-Demand (MoD) services. Prior work is limited to individually improving various transport networks' operations or linking a new mode to an existing system. In this work, we attempt to solve transit network design and pricing problems of multimodal mobility systems en masse. An operator (public transit agency or private transit operator) determines the frequency settings of the mass transit system, flows of the MoD service, and prices for each trip to optimize the overall welfare. A primal-dual approach, inspired by the market design literature, yields a compact mixed integer linear programming (MILP) formulation. However, a key computational challenge remains in allocating an exponential number of hybrid modes accessible to travelers. We provide a tractable solution approach through a decomposition scheme and approximation algorithm that accelerates the computation and enables optimization of large-scale problem instances. Using a case study in Nashville, Tennessee, we demonstrate the value of the proposed model. We also show that our algorithm reduces the average runtime by 60\\% compared to advanced MILP solvers. This result seeks to establish a generic and simple-to-implement way of revamping and redesigning regional mobility systems in order to meet the increase in travel demand and integrate traditional fixed-line mass transit systems with new demand-responsive services.",
        "published": "2021-02-15T03:10:30Z",
        "link": "http://arxiv.org/abs/2102.07317v3",
        "categories": [
            "cs.CE",
            "cs.SY",
            "eess.SY",
            "math.OC"
        ]
    },
    {
        "title": "Surface Warping Incorporating Machine Learning Assisted Domain   Likelihood Estimation: A New Paradigm in Mine Geology Modelling and   Automation",
        "authors": [
            "Raymond Leung",
            "Mehala Balamurali",
            "Alexander Lowe"
        ],
        "summary": "This paper illustrates an application of machine learning (ML) within a complex system that performs grade estimation. In surface mining, assay measurements taken from production drilling often provide useful information that allows initially inaccurate surfaces created using sparse exploration data to be revised and subsequently improved. Recently, a Bayesian warping technique has been proposed to reshape modeled surfaces using geochemical and spatial constraints imposed by newly acquired blasthole data. This paper focuses on incorporating machine learning into this warping framework to make the likelihood computation generalizable. The technique works by adjusting the position of vertices on the surface to maximize the integrity of modeled geological boundaries with respect to sparse geochemical observations. Its foundation is laid by a Bayesian derivation in which the geological domain likelihood given the chemistry, p(g|c), plays a similar role to p(y(c)|g). This observation allows a manually calibrated process centered around the latter to be automated since ML techniques may be used to estimate the former in a data-driven way. Machine learning performance is evaluated for gradient boosting, neural network, random forest and other classifiers in a binary and multi-class context using precision and recall rates. Once ML likelihood estimators are integrated in the surface warping framework, surface shaping performance is evaluated using unseen data by examining the categorical distribution of test samples located above and below the warped surface. Large-scale validation experiments are performed to assess the overall efficacy of ML assisted surface warping as a fully integrated component within an ore grade estimation system where the posterior mean is obtained via Gaussian Process inference with a Matern 3/2 kernel.",
        "published": "2021-02-15T10:37:52Z",
        "link": "http://arxiv.org/abs/2103.03923v3",
        "categories": [
            "physics.geo-ph",
            "cs.CE",
            "cs.LG",
            "I.3.5; I.2.1; G.3; J.2"
        ]
    },
    {
        "title": "Efficient solvers for shallow-water Saint-Venant equations and debris   transportation-deposition models",
        "authors": [
            "Florian De Vuyst"
        ],
        "summary": "This research is aimed at achieving an efficient digital infrastructure for evaluating risks and damages caused by tsunami flooding. It is mainly focused on the suitable modeling of debris dynamics for a simple (but accurate enough) assessment of damages. For different reasons including computational performance and Big Data management issues, we focus our research on Eulerian debris flow modeling. Rather than using complex multiphase debris models, we rather use an empirical transportation and deposition model that takes into account the interaction with the main water flow, friction/contact with the ground but also debris interaction. In particular, for debris interaction, we have used ideas coming from vehicular traffic flow modeling. We introduce a velocity regularization term similar to the so-called ``anticipation term'' in traffic flow modeling that takes into account the local flow between neighboring debris and makes the problem mathematically well-posed. It prevents from the generation of ``Dirac measures of debris'' at shock waves. As a result, the model is able to capture emerging phenomenons like debris aggregation and accumulations, and possibly to react on the main flow by creating hills of debris and make the main stream deviate. We also discuss the way to derive quantities of interest (QoI), especially ``damage functions'' from the debris density and momentum fields. We believe that this original unexplored debris approach can lead to a valuable analysis of tsunami flooding damage assessment with Physics-based damage functions. Numerical experiments show the nice behaviour of the numerical solvers, including the solution of Saint-Venant's shallow water equations and debris dynamics equations.",
        "published": "2021-02-15T11:09:35Z",
        "link": "http://arxiv.org/abs/2102.07457v1",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "An electromechanically coupled beam model for dielectric elastomer   actuators",
        "authors": [
            "Dengpeng Huang",
            "Sigrid Leyendecker"
        ],
        "summary": "In this work, the Cosserat formulation of geometrically exact beam dynamics is extended by adding the electric potential as an additional degree of freedom to account for the electromechanical coupling in the Dielectric Elastomer Actuators (DEAs). To be able to generate complex beam deformations via dielectric actuator, a linear distribution of electric potential on the beam cross section is proposed. Based on this electric potential, the electric field and the strain-like electrical variable are defined for the beam, where the strain-like electrical variable is work-conjugated to the electric displacement. The electromechanically coupled strain energy for the beam is derived consistently from continuum electromechanics, which leads to the direct application of the material models in the continuum to the beam model. The electromechanically coupled problem in beam dynamics is first spatially semidiscretized by 1D finite elements and then solved via variational time integration. By applying different electrical boundary conditions, different deformations of the beam are obtained in the numerical examples, including contraction, shear, bending and torsion. The damping effect induced by the viscosity as well as the total energy of the beam are evaluated. The deformations of the electromechanically coupled beam model are compared with the results of the 3D finite element model, where a good agreement of the deformations in the beam model and that in the 3D finite element model is observed. However, less degrees of freedom are required to resolve the complex deformations in the beam model.",
        "published": "2021-02-15T14:32:29Z",
        "link": "http://arxiv.org/abs/2103.06373v1",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "A three-dimensional hybrid finite element -- spectral boundary integral   method for modeling earthquakes in complex unbounded domains",
        "authors": [
            "Gabriele Albertini",
            "Ahmed Elbanna",
            "David S. Kammer"
        ],
        "summary": "We present a 3D hybrid method which combines the Finite Element Method (FEM) and the Spectral Boundary Integral method (SBIM) to model nonlinear problems in unbounded domains. The flexibility of FEM is used to model the complex, heterogeneous, and nonlinear part -- such as the dynamic rupture along a fault with near fault plasticity -- and the high accuracy and computational efficiency of SBIM is used to simulate the exterior half spaces perfectly truncating all incident waves. The exact truncation allows us to greatly reduce the domain of spatial discretization compared to a traditional FEM approach, leading to considerable savings in computational cost and memory requirements. The coupling of FEM and SBIM is achieved by the exchange of traction and displacement boundary conditions at the computationally defined boundary. The method is suited to implementation on massively parallel computers. We validate the developed method by means of a benchmark problem. Three more complex examples with a low velocity fault zone, low velocity off-fault inclusion, and interaction of multiple faults, respectively, demonstrate the capability of the hybrid scheme in solving problems of very large sizes. Finally, we discuss potential applications of the hybrid method for problems in geophysics and engineering.",
        "published": "2021-02-15T19:41:01Z",
        "link": "http://arxiv.org/abs/2102.08756v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Spectral formulation of the boundary integral equation method for   antiplane problems",
        "authors": [
            "Kunnath Ranjith"
        ],
        "summary": "A spectral formulation of the boundary integral equation method for antiplane problems is presented. The boundary integral equation method relates the slip and the shear stress at an interface between two half-planes. It involves evaluating a space-time convolution of the shear stress or the slip at the interface. In the spectral formulation, the convolution with respect to the spatial coordinate is performed in the spectral domain. This leads to greater numerical efficiency. Prior work on the spectral formulation of the boundary integral equation method has performed the elastodynamic convolution of the slip at the interface. In the present work, the convolution is performed of the shear stress at the interface. The spectral formulation is developed both for an interface between identical solids and for a bi-material interface. It is validated by numerically calculating the response of the interface to harmonic and to impulsive disturbances and comparing with known analytical solutions. To illustrate use of the method, dynamic slip rupture propagation with a slip-weakening friction law is simulated.",
        "published": "2021-02-16T12:18:12Z",
        "link": "http://arxiv.org/abs/2102.10101v3",
        "categories": [
            "cs.CE",
            "cond-mat.mtrl-sci",
            "physics.geo-ph"
        ]
    },
    {
        "title": "A Bayesian Approach for Inferring Sea Ice Loads",
        "authors": [
            "Matthew Parno",
            "Taylor Hodgdon",
            "Brendan West",
            "Devin O'Connor",
            "Arnold Song"
        ],
        "summary": "The Earth's climate is rapidly changing and some of the most drastic changes can be seen in the Arctic, where sea ice extent has diminished considerably in recent years. As the Arctic climate continues to change, gathering in situ sea ice measurements is increasingly important for understanding the complex evolution of the Arctic ice pack. To date, observations of ice stresses in the Arctic have been spatially and temporally sparse. We propose a measurement framework that would instrument existing sea ice buoys with strain gauges. This measurement framework uses a Bayesian inference approach to infer ice loads acting on the buoy from a set of strain gauge measurements. To test our framework, strain measurements were collected from an experiment where a buoy was frozen into ice that was subsequently compressed to simulate convergent sea ice conditions. A linear elastic finite element model was used to describe the response of the deformable buoy to mechanical loading, allowing us to link the observed strain on the buoy interior to the applied load on the buoy exterior.   The approach presented in this paper presents an instrumentation framework that could use existing buoy platforms as in situ sensors of internal stresses in the ice pack.",
        "published": "2021-02-16T20:51:45Z",
        "link": "http://arxiv.org/abs/2102.08444v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Validation and parameter optimization of a hybrid embedded/homogenized   solid tumor perfusion model",
        "authors": [
            "Johannes Kremheller",
            "Sebastian Brandstaeter",
            "Bernhard A. Schrefler",
            "Wolfgang A. Wall"
        ],
        "summary": "The goal of this paper is to investigate the validity of a hybrid embedded/homogenized in-silico approach for modeling perfusion through solid tumors. The rationale behind this novel idea is that only the larger blood vessels have to be explicitly resolved while the smaller scales of the vasculature are homogenized. As opposed to typical discrete or fully-resolved 1D-3D models, the required data can be obtained with in-vivo imaging techniques since the morphology of the smaller vessels is not necessary. By contrast, the larger vessels, whose topology and structure is attainable non-invasively, are resolved and embedded as one-dimensional inclusions into the three-dimensional tissue domain which is modeled as a porous medium. A sound mortar-type formulation is employed to couple the two representations of the vasculature. We validate the hybrid model and optimize its parameters by comparing its results to a corresponding fully-resolved model based on several well-defined metrics. These tests are performed on a complex data set of three different tumor types with heterogeneous vascular architectures. The correspondence of the hybrid model in terms of mean representative elementary volume blood and interstitial fluid pressures is excellent with relative errors of less than 4%. Larger, but less important and explicable errors are present in terms of blood flow in the smaller, homogenized vessels. We finally discuss and demonstrate how the hybrid model can be further improved to apply it for studies on tumor perfusion and the efficacy of drug delivery.",
        "published": "2021-02-17T07:29:09Z",
        "link": "http://arxiv.org/abs/2102.08613v2",
        "categories": [
            "cs.CE",
            "physics.bio-ph"
        ]
    },
    {
        "title": "Accelerated Simulations of Molecular Systems through Learning of their   Effective Dynamics",
        "authors": [
            "Pantelis R. Vlachas",
            "Julija Zavadlav",
            "Matej Praprotnik",
            "Petros Koumoutsakos"
        ],
        "summary": "Simulations are vital for understanding and predicting the evolution of complex molecular systems. However, despite advances in algorithms and special purpose hardware, accessing the timescales necessary to capture the structural evolution of bio-molecules remains a daunting task. In this work we present a novel framework to advance simulation timescales by up to three orders of magnitude, by learning the effective dynamics (LED) of molecular systems. LED augments the equation-free methodology by employing a probabilistic mapping between coarse and fine scales using mixture density network (MDN) autoencoders and evolves the non-Markovian latent dynamics using long short-term memory MDNs. We demonstrate the effectiveness of LED in the M\\\"ueller-Brown potential, the Trp Cage protein, and the alanine dipeptide. LED identifies explainable reduced-order representations and can generate, at any instant, the respective all-atom molecular trajectories. We believe that the proposed framework provides a dramatic increase to simulation capabilities and opens new horizons for the effective modeling of complex molecular systems.",
        "published": "2021-02-17T15:15:37Z",
        "link": "http://arxiv.org/abs/2102.08810v1",
        "categories": [
            "physics.comp-ph",
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "Efficient and robust numerical treatment of a gradient-enhanced damage   model at large deformations",
        "authors": [
            "Philipp Junker",
            "Johannes Riesselmann",
            "Daniel Balzani"
        ],
        "summary": "The modeling of damage processes in materials constitutes an ill-posed mathematical problem which manifests in mesh-dependent finite element results. The loss of ellipticity of the discrete system of equations is counteracted by regularization schemes of which the gradient enhancement of the strain energy density is often used. In this contribution, we present an extension of the efficient numerical treatment, which has been proposed in [1], to materials that are subjected to large deformations. Along with the model derivation, we present a technique for element erosion in the case of severely damaged materials. Efficiency and robustness of our approach is demonstrated by two numerical examples.",
        "published": "2021-02-17T15:27:36Z",
        "link": "http://arxiv.org/abs/2102.08819v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A matrix approach to detect temporal behavioral patterns at electric   vehicle charging stations",
        "authors": [
            "Milan Straka",
            "Lucia Piatriková",
            "Peter van Bokhoven",
            "Ľuboš Buzna"
        ],
        "summary": "Based on the electric vehicle (EV) arrival times and the duration of EV connection to the charging station, we identify charging patterns and derive groups of charging stations with similar charging patterns applying two approaches. The ruled based approach derives the charging patterns by specifying a set of time intervals and a threshold value. In the second approach, we combine the modified l-p norm (as a matrix dissimilarity measure) with hierarchical clustering and apply them to automatically identify charging patterns and groups of charging stations associated with such patterns. A dataset collected in a large network of public charging stations is used to test both approaches. Using both methods, we derived charging patterns. The first, rule-based approach, performed well at deriving predefined patterns and the latter, hierarchical clustering, showed the capability of delivering unexpected charging patterns.",
        "published": "2021-02-18T10:37:32Z",
        "link": "http://arxiv.org/abs/2102.09260v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.CE",
            "stat.ML"
        ]
    },
    {
        "title": "Analysis of Growing Tumor on the Flow Velocity of Cerebrospinal Fluid in   Human Brain Using Computational Modeling and Fluid-Structure Interaction",
        "authors": [
            "Muhammad Uzair-Ul-Haq",
            "Ali Ahmed",
            "Zartasha Mustansar",
            "Arslan Shaukat",
            "Lee Margetts",
            "Asim Waris",
            "Faizan Nadeem"
        ],
        "summary": "Cerebrospinal fluid (CSF) plays a pivotal role in normal functioning of Brain. Intracranial compartments such as blood, brain and CSF are incompressible in nature. Therefore, if a volume imbalance in one of the aforenoted compartments is observed, the other reaches out to maintain net change to zero. Whereas, CSF has higher compliance over long term. However, if the CSF flow is obstructed in the ventricles, this compliance may get exhausted early. Brain tumor on the other hand poses a similar challenge towards destabilization of CSF flow by compressing any section of ventricles thereby ensuing obstruction. To avoid invasive procedures to study effects of tumor on CSF flow, numerical-based methods such as Finite element modeling (FEM) are used which provide excellent description of underlying pathological interaction. A 3D fluid-structure interaction (FSI) model is developed to study the effect of tumor growth on the flow of cerebrospinal fluid in ventricle system. The FSI model encapsulates all the physiological parameters which may be necessary in analyzing intraventricular CSF flow behavior. Findings of the model show that brain tumor affects CSF flow parameters by deforming the walls of ventricles in this case accompanied by a mean rise of 74.23% in CSF flow velocity and considerable deformation on the walls of ventricles.",
        "published": "2021-02-19T04:42:55Z",
        "link": "http://arxiv.org/abs/2102.09742v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Numerical study of COVID-19 spatial-temporal spreading in London",
        "authors": [
            "J. Zheng",
            "X. Wu",
            "F. Fang",
            "J. Li",
            "Z. Wang",
            "H. Xiao",
            "J. Zhu",
            "C. C. Pain",
            "P. F. Linden",
            "B. Xiang"
        ],
        "summary": "Recent study reported that an aerosolised virus (COVID-19) can survive in the air for a few hours. It is highly possible that people get infected with the disease by breathing and contact with items contaminated by the aerosolised virus. However, the aerosolised virus transmission and trajectories in various meteorological environments remain unclear. This paper has investigated the movement of aerosolised viruses from a high concentration source across a dense urban area. The case study looks at the highly air polluted areas of London: University College Hospital (UCH) and King Cross and St Pancras International Station (KCSPI). We explored the spread and decay of COVID-19 released from the hospital and railway stations with the prescribed meteorological conditions. The study has three key findings: the primary result is that it is possible for the virus to travel from meters up to hundred meters from the source location. The secondary finding shows viruses released into the atmosphere from entry and exit points at KCSPI remain trapped within a small radial distance of < 50m. This strengthens the case for the use of face coverings to reduce the infection rate. The final finding shows that there are different levels of risk at various door locations for UCH, depending on which door is used there can be a higher concentration of COVID-19. Although our results are based on London, since the fundamental knowledge processes are the same, our study can be further extended to other locations (especially the highly air polluted areas) in the world.",
        "published": "2021-02-19T12:50:15Z",
        "link": "http://arxiv.org/abs/2102.09902v2",
        "categories": [
            "physics.med-ph",
            "cs.CE",
            "physics.flu-dyn"
        ]
    },
    {
        "title": "Fast and Accurate Uncertainty Quantification for the ECG with Random   Electrodes Location",
        "authors": [
            "Michael Multerer",
            "Simone Pezzuto"
        ],
        "summary": "The standard electrocardiogram (ECG) is a point-wise evaluation of the body potential at certain given locations. These locations are subject to uncertainty and may vary from patient to patient or even for a single patient. In this work, we estimate the uncertainty in the ECG induced by uncertain electrode positions when the ECG is derived from the forward bidomain model. In order to avoid the high computational cost associated to the solution of the bidomain model in the entire torso, we propose a low-rank approach to solve the uncertainty quantification (UQ) problem. More precisely, we exploit the sparsity of the ECG and the lead field theory to translate it into a set of deterministic, time-independent problems, whose solution is eventually used to evaluate expectation and covariance of the ECG. We assess the approach with numerical experiments in a simple geometry.",
        "published": "2021-02-19T14:47:52Z",
        "link": "http://arxiv.org/abs/2102.09960v2",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Computational modeling of degradation process of biodegradable magnesium   biomaterials",
        "authors": [
            "Mojtaba Barzegari",
            "Di Mei",
            "Sviatlana V. Lamaka",
            "Liesbet Geris"
        ],
        "summary": "Despite the advantages of using biodegradable metals in implant design, their uncontrolled degradation and release remain a challenge in practical applications. A validated computational model of the degradation process can facilitate the tuning of implant biodegradation by changing design properties. In this study, a physicochemical model was developed by deriving a mathematical description of the chemistry of magnesium biodegradation and implementing it in a 3D computational model. The model parameters were calibrated using the experimental data of hydrogen evolution by performing a Bayesian optimization routine. The model was validated by comparing the predicted change of pH in saline and buffered solutions with the experimentally obtained values from corrosion tests, showing maximum 5% of difference, demonstrating the model's validity to be used for practical cases.",
        "published": "2021-02-19T17:51:50Z",
        "link": "http://arxiv.org/abs/2102.10064v1",
        "categories": [
            "cs.CE",
            "cond-mat.mtrl-sci"
        ]
    },
    {
        "title": "Phase-field modeling on the diffusion-driven processes in metallic   conductors and lithium-ion batteries",
        "authors": [
            "Jay Santoki"
        ],
        "summary": "Diffusion-driven processes are important phenomena of materials science in the field of energy conversion and transmission. During the conversion from chemical energy to electrical energy, the species diffusion is generally linked to the rate of exchange, and hence to the performance of the conversion device. Alternatively, the transmission of the electric field diffuses the species when it passes through any medium. The consequences of this effect can be regulated to attune surface nano-patterns. Otherwise, uncontrolled morphologies may lead to permanent degradation of the metallic conductors. Therefore, the understanding of the material behavior, in the presence of the driving forces of the diffusional species, is of scientific interest. The presented dissertation proposes to investigate one example of species diffusion in each case, during energy conversion and transmission. Specifically, the objective of the study is to explore the lithium insertion into the cathode electrode of lithium-ion batteries and the morphological evolution of inclusions, while propagating under the electromigration in the metallic conductors. The presented dissertation demonstrates that the phase-field methods are able to elegantly capture the essential physics of the diffusion-driven phenomena discussed above.",
        "published": "2021-02-20T10:31:41Z",
        "link": "http://arxiv.org/abs/2102.10310v1",
        "categories": [
            "physics.app-ph",
            "cond-mat.mtrl-sci",
            "cs.CE",
            "nlin.PS"
        ]
    },
    {
        "title": "A unified construction of all-speed HLL-type schemes for hypersonic   heating computations",
        "authors": [
            "Wenjia Xie",
            "Zhengyu Tian",
            "Ye Zhang",
            "Hang Yu"
        ],
        "summary": "In this paper, a unified framework to develop all-speed HLL-type schemes for hypersonic heating computations is constructed. Such a unified construction method combines two effective improving techniques: a shock robustness improvement and a low-Mach number fix. It is implemented by properly modifying the approximate solutions of the local Riemann problem in the HLL framework, resulting in two all-speed HLL-type schemes, namely ASHLLC and ASHLLEM solvers. Results from both numerical analysis and experiments demonstrate that the newly proposed schemes not only preserve desirable properties of their original versions, but are also able to provide accurate and robust solutions for complex flows ranging from low-Mach number incompressible to hypersonic compressible regimes. Thus, both the ASHLLC and ASHLLEM schemes can be used as reliable methods for hypersonic heating computations.",
        "published": "2021-02-20T13:37:18Z",
        "link": "http://arxiv.org/abs/2103.06374v1",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Remote Renewable Hubs For Carbon-Neutral Synthetic Fuel Production",
        "authors": [
            "Mathias Berger",
            "David Radu",
            "Ghislain Detienne",
            "Thierry Deschuyteneer",
            "Aurore Richel",
            "Damien Ernst"
        ],
        "summary": "This paper studies the economics of carbon-neutral synthetic fuel production from renewable electricity in remote areas where high-quality renewable resources are abundant. To this end, a graph-based optimisation modelling framework directly applicable to the strategic planning of remote renewable energy supply chains is proposed. More precisely, a hypergraph abstraction of planning problems is introduced, wherein nodes can be viewed as optimisation subproblems with their own parameters, variables, constraints and local objective. Nodes typically represent a subsystem such as a technology, a plant or a process. Hyperedges, on the other hand, express the connectivity between subsystems. The framework is leveraged to study the economics of carbon-neutral synthetic methane production from solar and wind energy in North Africa and its delivery to Northwestern European markets. The full supply chain is modelled in an integrated fashion, which makes it possible to accurately capture the interaction between various technologies on an hourly time scale. Results suggest that the cost of synthetic methane production and delivery would be slightly under 150 EUR/MWh (higher heating value) by 2030 for a system supplying 10 TWh annually and relying on a combination of solar photovoltaic and wind power plants, assuming a uniform weighted average cost of capital of 7%. A comprehensive sensitivity analysis is also carried out in order to assess the impact of various techno-economic parameters and assumptions on synthetic methane cost, including the availability of wind power plants, the investment costs of electrolysis, methanation and direct air capture plants, their operational flexibility, the energy consumption of direct air capture plants, and financing costs.",
        "published": "2021-02-22T21:45:44Z",
        "link": "http://arxiv.org/abs/2102.11375v2",
        "categories": [
            "eess.SY",
            "cs.CE",
            "cs.SY"
        ]
    },
    {
        "title": "Twelve Ways To Fool The Masses When Giving Parallel-In-Time Results",
        "authors": [
            "Sebastian Goetschel",
            "Michael Minion",
            "Daniel Ruprecht",
            "Robert Speck"
        ],
        "summary": "Getting good speedup -- let alone high parallel efficiency -- for parallel-in-time (PinT) integration examples can be frustratingly difficult. The high complexity and large number of parameters in PinT methods can easily (and unintentionally) lead to numerical experiments that overestimate the algorithm's performance. In the tradition of Bailey's article \"Twelve ways to fool the masses when giving performance results on parallel computers\", we discuss and demonstrate pitfalls to avoid when evaluating performance of PinT methods. Despite being written in a light-hearted tone, this paper is intended to raise awareness that there are many ways to unintentionally fool yourself and others and that by avoiding these fallacies more meaningful PinT performance results can be obtained.",
        "published": "2021-02-23T12:54:39Z",
        "link": "http://arxiv.org/abs/2102.11670v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Inferring temporal dynamics from cross-sectional data using Langevin   dynamics",
        "authors": [
            "Pritha Dutta",
            "Rick Quax",
            "Loes Crielaard",
            "Peter M. A. Sloot"
        ],
        "summary": "Cross-sectional studies are widely prevalent since they are more feasible to conduct compared to longitudinal studies. However, cross-sectional data lack the temporal information required to study the evolution of the underlying processes. Nevertheless, this is essential to develop predictive computational models which is the first step towards causal modelling. We propose a method for inferring computational models from cross-sectional data using Langevin dynamics. This method can be applied to any system that can be described as effectively following a free energy landscape, such as protein folding, stem cell differentiation and reprogramming, and social systems involving human interaction and social norms. A crucial assumption in our method is that the data-points are gathered from a system in (local) equilibrium. The result is a set of stochastic differential equations which capture the temporal dynamics, by assuming that groups of data-points are subject to the same free energy landscape and amount of noise. Our method is a 'baseline' method which initiates the development of computational models which can be iteratively enhanced through the inclusion of expert knowledge. We validate the proposed method against two population-based longitudinal datasets and observe significant predictive power in comparison with random choice algorithms. We also show how the predictive power of our 'baseline' model can be enhanced by incorporating domain expert knowledge. Our method addresses an important obstacle for model development in fields dominated by cross-sectional datasets.",
        "published": "2021-02-23T13:43:15Z",
        "link": "http://arxiv.org/abs/2102.11690v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A discontinuous Galerkin method based on a hierarchical orthogonal basis   for Lagrangian hydrodynamics on curvilinear grids",
        "authors": [
            "Xiaodong Liu",
            "Nathaniel R. Morgan",
            "Evan J. Lieberman",
            "Donald E. Burton"
        ],
        "summary": "We present a new high-order accurate Lagrangian discontinuous Galerkin (DG) hydrodynamic method to simulate material dynamics (for e.g., gasses, fluids, and solids) with up to fourth-order accuracy on cubic meshes. The variables, such as specific volume, velocity, specific total energy, and deformation gradient fields within a cell, are represented with a polynomial constructed from a novel hierarchical orthogonal basis about the center of mass, which decouples the moments of the solution because the mass matrix is diagonal. The discontinuity in the polynomials at the cell boundary is addressed by solving a multi-directional Riemann problem at the vertices of the cell and a 1D Riemann problem at additional non-vertex quadrature points along the edges so that the surface integral is exact for the polynomial order. The uniqueness lies in that the vertices of the curvilinear grid work as the quadrature points for the surface integral of DG methods. To ensure robust mesh motion, the pressure for the Riemann problem accounts for the difference between the density variation over the cell and a density field from subcell mesh stabilization (SMS). The accuracy and robustness of the new high-order accurate Lagrangian DG hydrodynamic method is demonstrated by simulating a diverse suite of challenging test problems covering gas and solid dynamic problems on curved grids.",
        "published": "2021-02-23T14:40:43Z",
        "link": "http://arxiv.org/abs/2103.02043v1",
        "categories": [
            "physics.comp-ph",
            "cs.CE"
        ]
    },
    {
        "title": "Quantitative in vivo imaging to enable tumor forecasting and treatment   optimization",
        "authors": [
            "Guillermo Lorenzo",
            "David A. Hormuth II",
            "Angela M. Jarrett",
            "Ernesto A. B. F. Lima",
            "Shashank Subramanian",
            "George Biros",
            "J. Tinsley Oden",
            "Thomas J. R. Hughes",
            "Thomas E. Yankeelov"
        ],
        "summary": "Current clinical decision-making in oncology relies on averages of large patient populations to both assess tumor status and treatment outcomes. However, cancers exhibit an inherent evolving heterogeneity that requires an individual approach based on rigorous and precise predictions of cancer growth and treatment response. To this end, we advocate the use of quantitative in vivo imaging data to calibrate mathematical models for the personalized forecasting of tumor development. In this chapter, we summarize the main data types available from both common and emerging in vivo medical imaging technologies, and how these data can be used to obtain patient-specific parameters for common mathematical models of cancer. We then outline computational methods designed to solve these models, thereby enabling their use for producing personalized tumor forecasts in silico, which, ultimately, can be used to not only predict response, but also optimize treatment. Finally, we discuss the main barriers to making the above paradigm a clinical reality.",
        "published": "2021-02-24T23:32:48Z",
        "link": "http://arxiv.org/abs/2102.12602v1",
        "categories": [
            "q-bio.TO",
            "cs.CE",
            "q-bio.QM"
        ]
    },
    {
        "title": "Machine Learning-Based Optimal Mesh Generation in Computational Fluid   Dynamics",
        "authors": [
            "Keefe Huang",
            "Moritz Krügener",
            "Alistair Brown",
            "Friedrich Menhorn",
            "Hans-Joachim Bungartz",
            "Dirk Hartmann"
        ],
        "summary": "Computational Fluid Dynamics (CFD) is a major sub-field of engineering. Corresponding flow simulations are typically characterized by heavy computational resource requirements. Often, very fine and complex meshes are required to resolve physical effects in an appropriate manner. Since all CFD algorithms scale at least linearly with the size of the underlying mesh discretization, finding an optimal mesh is key for computational efficiency.   One methodology used to find optimal meshes is goal-oriented adaptive mesh refinement. However, this is typically computationally demanding and only available in a limited number of tools. Within this contribution, we adopt a machine learning approach to identify optimal mesh densities. We generate optimized meshes using classical methodologies and propose to train a convolutional network predicting optimal mesh densities given arbitrary geometries. The proposed concept is validated along 2d wind tunnel simulations with more than 60,000 simulations. Using a training set of 20,000 simulations we achieve accuracies of more than 98.7%.   Corresponding predictions of optimal meshes can be used as input for any mesh generation and CFD tool. Thus without complex computations, any CFD engineer can start his predictions from a high quality mesh.",
        "published": "2021-02-25T15:25:17Z",
        "link": "http://arxiv.org/abs/2102.12923v1",
        "categories": [
            "cs.LG",
            "cs.CE",
            "physics.flu-dyn"
        ]
    },
    {
        "title": "An Advection-Diffusion based Filter for Machinable Designs in Topology   Optimization",
        "authors": [
            "Lukas Christian Høghøj",
            "Erik Albert Träff"
        ],
        "summary": "This paper introduces a simple formulation for topology optimization problems ensuring manufacturability by machining. The method distinguishes itself from existing methods by using the advection-diffusion equation with Robin boundary conditions to perform a filtering of the design variables. The proposed approach is less computationally expensive than the traditional methods used. Furthermore, the approach is easy to implement on unstructured meshes and in a distributed memory setting. Finally, the proposed approach can be performed with few to no continuation steps in any system parameters. Applications are demonstrated with topology optimization on unstructured meshes with up to 64 million elements and up to 29 milling tool directions.",
        "published": "2021-02-25T17:03:34Z",
        "link": "http://arxiv.org/abs/2102.12999v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Inverse deformation analysis: an experimental and numerical assessment   using the FEniCS Project",
        "authors": [
            "Arnaud Mazier",
            "Alexandre Bilger",
            "Antonio E. Forte",
            "Igor Peterlik",
            "Jack S. Hale",
            "Stéphane P. A. Bordas",
            ".",
            "Institute of Computational Engineering",
            "Department of Engineering",
            "University of Luxembourg",
            "Esch-sur-Alzette",
            "Luxembourg.",
            "Harvard University",
            "Cambridge",
            "USA.",
            "Department of Electronics",
            "Information",
            "Bioengineering",
            "Politecnico di Milano",
            "Milan",
            "Italy.",
            "Institute of Computer Science",
            "Masaryk University",
            "Czech Republic.",
            "Institute of Research",
            "Development Duy Tan University",
            "Danang",
            "Vietnam"
        ],
        "summary": "In this paper, we develop a framework for solving inverse deformation problems using the FEniCS Project finite element software. We validate our approach with experimental imaging data acquired from a soft silicone beam under gravity. In contrast with inverse iterative algorithms that require multiple solutions of a standard elasticity problem, the proposed method can compute the undeformed configuration by solving only one modified elasticity problem. This modified problem has a complexity comparable to the standard one. The framework is implemented within an open-source pipeline enabling the direct and inverse deformation simulation directly from imaging data. We use the high-level Unified Form Language (UFL) of the FEniCS Project to express the finite element model in variational form and to automatically derive the consistent Jacobian. Consequently, the design of the pipeline is flexible: for example, it allows the modification of the constitutive models by changing a single line of code. We include a complete working example showing the inverse deformation of a beam deformed by gravity as supplementary material.",
        "published": "2021-02-26T13:20:36Z",
        "link": "http://arxiv.org/abs/2102.13455v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Time Matters: Exploring the Effects of Urgency and Reaction Speed in   Automated Traders",
        "authors": [
            "Henry Hanifan",
            "Ben Watson",
            "John Cartlidge",
            "Dave Cliff"
        ],
        "summary": "We consider issues of time in automated trading strategies in simulated financial markets containing a single exchange with public limit order book and continuous double auction matching. In particular, we explore two effects: (i) reaction speed - the time taken for trading strategies to calculate a response to market events; and (ii) trading urgency - the sensitivity of trading strategies to approaching deadlines. Much of the literature on trading agents focuses on optimising pricing strategies only and ignores the effects of time, while real-world markets continue to experience a race to zero latency, as automated trading systems compete to quickly access information and act in the market ahead of others. We demonstrate that modelling reaction speed can significantly alter previously published results, with simple strategies such as SHVR outperforming more complex adaptive algorithms such as AA. We also show that adding a pace parameter to ZIP traders (ZIP-Pace, or ZIPP) can create a sense of urgency that significantly improves profitability.",
        "published": "2021-02-28T19:38:52Z",
        "link": "http://arxiv.org/abs/2103.00600v1",
        "categories": [
            "cs.MA",
            "cs.CE",
            "q-fin.CP",
            "q-fin.TR"
        ]
    },
    {
        "title": "Low-Order Modeling and High-Fidelity Simulations for the Prediction of   Combustion Instabilities in Liquid Rocket Engines and Gas Turbines",
        "authors": [
            "Charlelie Laurent"
        ],
        "summary": "Combustion instabilities are a major concern in the design of Liquid Rocket Engines (LREs) and gas turbines. During this PhD work, several directions were explored to understand and mitigate their effects. First, more efficient and robust numerical methods for their prediction in complex combustors were designed. In this matter, a novel type of modal expansion, named a frame expansion and comparable to the classical Galerkin expansion, was introduced to build more accurate acoustic Low-Order Models (LOMs), able to account for the full geometrical complexity of industrial combustors. In particular, the frame expansion is able to accurately represent the acoustic velocity field near non-rigid-wall boundaries, a crucial ability that the Galerkin method lacks. An entire class of novel numerical methods, based on the frame expansion, were then designed and combined with the state-space formalism to build acoustic networks of complex systems. The second ingredient in the prediction of thermoacoustic instabilities is the flame dynamics modeling. This work dealt with this problem, in the specific case of a cryogenic coaxial jet-flame characteristic of a LRE. Flame dynamics driving phenomena were identified thanks to three-dimensional Large Eddy Simulations (LES) of the Mascotte experimental test rig where both reactants (CH4 and O2) are injected in transcritical conditions. Several LES with harmonic modulation of the fuel inflow at various frequencies and amplitudes were performed in order to evaluate the flame response to acoustic oscillations and compute a Flame Transfer Function (FTF). The stabilization of this flame in the near-injector region, which is of primary importance on the overall flame dynamics, was also investigated thanks to multi-physics two-dimensional Direct Numerical Simulations (DNS), where a conjugate heat transfer problem is resolved at the injector lip.",
        "published": "2021-03-01T14:31:14Z",
        "link": "http://arxiv.org/abs/2103.01038v1",
        "categories": [
            "physics.flu-dyn",
            "cs.CE"
        ]
    },
    {
        "title": "High-productivity, high-performance workflow for virus-scale   electrostatic simulations with Bempp-Exafmm",
        "authors": [
            "Tingyu Wang",
            "Christopher D. Cooper",
            "Timo Betcke",
            "Lorena A. Barba"
        ],
        "summary": "Biomolecular electrostatics is key in protein function and the chemical processes affecting it. Implicit-solvent models via the Poisson-Boltzmann (PB) equation provide insights with less computational cost than atomistic models, making large-system studies -- at the scale of viruses -- accessible to more researchers. Here we present a high-productivity and high-performance linear PB solver based on Exafmm, a fast multipole method library, and Bempp, a Galerkin boundary element method package. The workflow integrates an easy-to-use Python interface with optimized computational kernels, and can be run interactively via Jupyter notebooks, for faster prototyping. Our results show the capability of the software, confirm code correctness, and assess performance with between 8,000 and 2 million elements. Showcasing the power of this interactive computing platform, we study the conditioning of two variants of the boundary integral formulation with just a few lines of code. Mesh-refinement studies confirm convergence as $1/N$, for $N$ boundary elements, and a comparison with results from the trusted APBS code using various proteins shows agreement. Our binding energy calculations using 9 various complexes align with the results from using five other grid-based PB solvers. Performance results include timings, breakdowns, and computational complexity. Exafmm offers evaluation speeds of just a few seconds for tens of millions of points, and $\\mathcal{O}(N)$ scaling. The trend observed in our performance comparison with APBS demonstrates the advantage of Bempp-Exafmm in applications involving larger structures or requiring higher accuracy. Computing the solvation free energy of a Zika virus, represented by 1.6 million atoms and 10 million boundary elements, took 80-min runtime on a single compute node (dual 20-core).",
        "published": "2021-03-01T14:43:27Z",
        "link": "http://arxiv.org/abs/2103.01048v3",
        "categories": [
            "physics.comp-ph",
            "cs.CE",
            "physics.bio-ph"
        ]
    },
    {
        "title": "Task-parallel in-situ temporal compression of large-scale computational   fluid dynamics data",
        "authors": [
            "Heather Pacella",
            "Alec Dunton",
            "Alireza Doostan",
            "Gianluca Iaccarino"
        ],
        "summary": "Present day computational fluid dynamics simulations generate extremely large amounts of data, sometimes on the order of TB/s. Often, a significant fraction of this data is discarded because current storage systems are unable to keep pace. To address this, data compression algorithms can be applied to data arrays containing flow quantities of interest to reduce the overall amount of storage. Compression methods either exactly reconstruct the original dataset (lossless compression) or provide an approximate representation of the original dataset (lossy compression). The matrix column interpolative decomposition (ID) can be implemented as a type of lossy compression for data matrices that factors the original data matrix into a product of two smaller factor matrices. One of these matrices consists of a subset of the columns of the original data matrix, while the other is a coefficient matrix which approximates the columns of the original data matrix as linear combinations of the selected columns. Motivating this work is the observation that the structure of ID algorithms makes them a natural fit for the asynchronous nature of task-based parallelism; they are able to operate independently on sub-domains of the system of interest and, as a result, provide varied levels of compression. Using the task-based Legion programming model, a single-pass ID algorithm (SPID) for CFD applications is implemented. Performance studies, scalability, and the accuracy of the compression algorithms are presented for an analytical Taylor-Green vortex problem, followed by a large-scale implementation of a compressible Taylor-Green vortex using a high-order Navier-Stokes solver. In both cases, compression factors exceeding 100 are achieved with relative errors at or below 10e-3. Moreover, strong and weak scaling results demonstrate that introducing SPID to solvers leads to negligible increases in runtime.",
        "published": "2021-03-02T00:38:02Z",
        "link": "http://arxiv.org/abs/2103.01380v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Computing foaming flows across scales: from breaking waves to   microfluidics",
        "authors": [
            "Petr Karnakov",
            "Sergey Litvinov",
            "Petros Koumoutsakos"
        ],
        "summary": "Crashing ocean waves, cappuccino froths and microfluidic bubble crystals are examples of foamy flows. Foamy flows are critical in numerous natural and industrial processes and remain notoriously difficult to compute as they involve coupled, multiscale physical processes. Computations need to resolve the interactions of the bubbles with the fluid and complex boundaries, while capturing the drainage and rupture of the microscopic liquid films at their interface. We present a novel multilayer simulation framework (Multi-VOF) that advances the state of the art in simulation capabilities of foamy flows. The framework introduces a novel scheme for the distinct handling of multiple neighboring bubbles and a new regularization method that produces sharp interfaces and removes spurious fragments. Multi-VOF is verified and validated with experimental results and complemented with open source, efficient scalable software. We demonstrate capturing of bubble crystalline structures in realistic microfluidics devices and foamy flows involving tens of thousands of bubbles in a waterfall. The present multilayer framework extends the classical volume-of-fluid methodology and allows for unprecedented large scale, predictive simulations of flows with multiple interfaces.",
        "published": "2021-03-02T06:53:24Z",
        "link": "http://arxiv.org/abs/2103.01513v1",
        "categories": [
            "physics.comp-ph",
            "cs.CE",
            "cs.NA",
            "math.NA",
            "physics.flu-dyn"
        ]
    },
    {
        "title": "The LOB Recreation Model: Predicting the Limit Order Book from TAQ   History Using an Ordinary Differential Equation Recurrent Neural Network",
        "authors": [
            "Zijian Shi",
            "Yu Chen",
            "John Cartlidge"
        ],
        "summary": "In an order-driven financial market, the price of a financial asset is discovered through the interaction of orders - requests to buy or sell at a particular price - that are posted to the public limit order book (LOB). Therefore, LOB data is extremely valuable for modelling market dynamics. However, LOB data is not freely accessible, which poses a challenge to market participants and researchers wishing to exploit this information. Fortunately, trades and quotes (TAQ) data - orders arriving at the top of the LOB, and trades executing in the market - are more readily available. In this paper, we present the LOB recreation model, a first attempt from a deep learning perspective to recreate the top five price levels of the LOB for small-tick stocks using only TAQ data. Volumes of orders sitting deep in the LOB are predicted by combining outputs from: (1) a history compiler that uses a Gated Recurrent Unit (GRU) module to selectively compile prediction relevant quote history; (2) a market events simulator, which uses an Ordinary Differential Equation Recurrent Neural Network (ODE-RNN) to simulate the accumulation of net order arrivals; and (3) a weighting scheme to adaptively combine the predictions generated by (1) and (2). By the paradigm of transfer learning, the source model trained on one stock can be fine-tuned to enable application to other financial assets of the same class with much lower demand on additional data. Comprehensive experiments conducted on two real world intraday LOB datasets demonstrate that the proposed model can efficiently recreate the LOB with high accuracy using only TAQ data as input.",
        "published": "2021-03-02T12:07:43Z",
        "link": "http://arxiv.org/abs/2103.01670v1",
        "categories": [
            "q-fin.TR",
            "cs.CE",
            "cs.NE",
            "q-fin.ST"
        ]
    },
    {
        "title": "Pricing high-dimensional Bermudan options with hierarchical tensor   formats",
        "authors": [
            "Christian Bayer",
            "Martin Eigel",
            "Leon Sallandt",
            "Philipp Trunschke"
        ],
        "summary": "An efficient compression technique based on hierarchical tensors for popular option pricing methods is presented. It is shown that the \"curse of dimensionality\" can be alleviated for the computation of Bermudan option prices with the Monte Carlo least-squares approach as well as the dual martingale method, both using high-dimensional tensorized polynomial expansions. This discretization allows for a simple and computationally cheap evaluation of conditional expectations. Complexity estimates are provided as well as a description of the optimization procedures in the tensor train format. Numerical experiments illustrate the favourable accuracy of the proposed methods. The dynamical programming method yields results comparable to recent Neural Network based methods.",
        "published": "2021-03-02T18:46:28Z",
        "link": "http://arxiv.org/abs/2103.01934v2",
        "categories": [
            "q-fin.CP",
            "cs.CE",
            "cs.NA",
            "math.NA",
            "91G60 (Primary) 62J02, 15A69 (Secondary)"
        ]
    },
    {
        "title": "Projection-tree reduced order modeling for fast N-body computations",
        "authors": [
            "Steven N. Rodriguez",
            "Athanasios P. Iliopoulos",
            "Kevin T. Carlberg",
            "Steven L. Brunton",
            "John C. Steuben",
            "John G. Michopoulos"
        ],
        "summary": "This work presents a data-driven reduced-order modeling framework to accelerate the computations of $N$-body dynamical systems and their pair-wise interactions. The proposed framework differs from traditional acceleration methods, like the Barnes-Hut method, which requires online tree building of the state space, or the fast-multipole method, which requires rigorous $a$ $priori$ analysis of governing kernels and online tree building. Our approach combines Barnes-Hut hierarchical decomposition, dimensional compression via the least-squares Petrov-Galerkin (LSPG) projection, and hyper-reduction by way of the Gauss-Newton with approximated tensor (GNAT) approach. The resulting $projection-tree$ reduced order model (PTROM) enables a drastic reduction in operational count complexity by constructing sparse hyper-reduced pairwise interactions of the $N$-body dynamical system. As a result, the presented framework is capable of achieving an operational count complexity that is independent of $N$, the number of bodies in the numerical domain. Capabilities of the PTROM method are demonstrated on the two-dimensional fluid-dynamic Biot-Savart kernel within a parametric and reproductive setting. Results show the PTROM is capable of achieving over 2000$\\times$ wall-time speed-up with respect to the full-order model, where the speed-up increases with $N$. The resulting solution delivers quantities of interest with errors that are less than 0.1$\\%$ with respect to full-order model.",
        "published": "2021-03-02T19:04:17Z",
        "link": "http://arxiv.org/abs/2103.01983v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A massively parallel Eulerian-Lagrangian method for advection-dominated   transport in viscous fluids",
        "authors": [
            "Nils Kohl",
            "Marcus Mohr",
            "Sebastian Eibl",
            "Ulrich Rüde"
        ],
        "summary": "Motivated by challenges in Earth mantle convection, we present a massively parallel implementation of an Eulerian-Lagrangian method for the advection-diffusion equation in the advection-dominated regime. The advection term is treated by a particle-based, characteristics method coupled to a block-structured finite-element framework. Its numerical and computational performance is evaluated in multiple, two- and three-dimensional benchmarks, including curved geometries, discontinuous solutions, pure advection, and it is applied to a coupled non-linear system modeling buoyancy-driven convection in Stokes flow. We demonstrate the parallel performance in a strong and weak scaling experiment, with scalability to up to $147,456$ parallel processes, solving for more than $5.2 \\times 10^{10}$ (52 billion) degrees of freedom per time-step.",
        "published": "2021-03-03T13:26:52Z",
        "link": "http://arxiv.org/abs/2103.02388v1",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA",
            "65M25, 65Y05, 65M60"
        ]
    },
    {
        "title": "IH-GAN: A Conditional Generative Model for Implicit Surface-Based   Inverse Design of Cellular Structures",
        "authors": [
            "Jun Wang",
            "Wei Wayne Chen",
            "Daicong Da",
            "Mark Fuge",
            "Rahul Rai"
        ],
        "summary": "Variable-density cellular structures can overcome connectivity and manufacturability issues of topologically optimized structures, particularly those represented as discrete density maps. However, the optimization of such cellular structures is challenging due to the multiscale design problem. Past work addressing this problem generally either only optimizes the volume fraction of single-type unit cells but ignores the effects of unit cell geometry on properties, or considers the geometry-property relation but builds this relation via heuristics. In contrast, we propose a simple yet more principled way to accurately model the property to geometry mapping using a conditional deep generative model, named Inverse Homogenization Generative Adversarial Network (IH-GAN). It learns the conditional distribution of unit cell geometries given properties and can realize the one-to-many mapping from properties to geometries. We further reduce the complexity of IH-GAN by using the implicit function parameterization to represent unit cell geometries. Results show that our method can 1) generate various unit cells that satisfy given material properties with high accuracy ($R^2$-scores between target properties and properties of generated unit cells $>98\\%$) and 2) improve the optimized structural performance over the conventional variable-density single-type structure. In the minimum compliance example, our IH-GAN generated structure achieves a $79.7\\%$ reduction in concentrated stress and an extra $3.03\\%$ reduction in displacement. In the target deformation examples, our IH-GAN generated structure reduces the target matching error by $86.4\\%$ and $79.6\\%$ for two test cases, respectively. We also demonstrated that the connectivity issue for multi-type unit cells can be solved by transition layer blending.",
        "published": "2021-03-03T18:39:25Z",
        "link": "http://arxiv.org/abs/2103.02588v5",
        "categories": [
            "cs.CE",
            "cs.LG",
            "stat.ML"
        ]
    },
    {
        "title": "Pandemic Drugs at Pandemic Speed: Infrastructure for Accelerating   COVID-19 Drug Discovery with Hybrid Machine Learning- and Physics-based   Simulations on High Performance Computers",
        "authors": [
            "Agastya P. Bhati",
            "Shunzhou Wan",
            "Dario Alfè",
            "Austin R. Clyde",
            "Mathis Bode",
            "Li Tan",
            "Mikhail Titov",
            "Andre Merzky",
            "Matteo Turilli",
            "Shantenu Jha",
            "Roger R. Highfield",
            "Walter Rocchia",
            "Nicola Scafuri",
            "Sauro Succi",
            "Dieter Kranzlmüller",
            "Gerald Mathias",
            "David Wifling",
            "Yann Donon",
            "Alberto Di Meglio",
            "Sofia Vallecorsa",
            "Heng Ma",
            "Anda Trifan",
            "Arvind Ramanathan",
            "Tom Brettin",
            "Alexander Partin",
            "Fangfang Xia",
            "Xiaotan Duan",
            "Rick Stevens",
            "Peter V. Coveney"
        ],
        "summary": "The race to meet the challenges of the global pandemic has served as a reminder that the existing drug discovery process is expensive, inefficient and slow. There is a major bottleneck screening the vast number of potential small molecules to shortlist lead compounds for antiviral drug development. New opportunities to accelerate drug discovery lie at the interface between machine learning methods, in this case developed for linear accelerators, and physics-based methods. The two in silico methods, each have their own advantages and limitations which, interestingly, complement each other. Here, we present an innovative infrastructural development that combines both approaches to accelerate drug discovery. The scale of the potential resulting workflow is such that it is dependent on supercomputing to achieve extremely high throughput. We have demonstrated the viability of this workflow for the study of inhibitors for four COVID-19 target proteins and our ability to perform the required large-scale calculations to identify lead antiviral compounds through repurposing on a variety of supercomputers.",
        "published": "2021-03-04T05:43:18Z",
        "link": "http://arxiv.org/abs/2103.02843v2",
        "categories": [
            "cs.DC",
            "cs.CE",
            "cs.LG",
            "physics.bio-ph",
            "q-bio.QM"
        ]
    },
    {
        "title": "An FFT framework for simulating non-local ductile failure in   heterogeneous materials",
        "authors": [
            "M. Magri",
            "S. Lucarini",
            "G. Lemoine",
            "L. Adam",
            "J. Segurado"
        ],
        "summary": "The simulation of fracture using continuum ductile damage models attains a pathological discretization dependence caused by strain localization, after loss of ellipticity of the problem, in regions whose size is connected to the spatial discretization. Implicit gradient techniques suppress this problem introducing some inelastic non-local fields and solving an enriched formulation where the classical balance of linear momentum is fully coupled with a Helmholtz-type equation for each of the non-local variable. Such Helmholtz-type equations determine the distribution of the non-local fields in bands whose width is controlled by a characteristic length, independently on the spatial discretization. The numerical resolution of this coupled problem using the Finite Element method is computationally very expensive and its use to simulate the damage process in 3D multi-phase microstructures becomes prohibitive. In this work, we propose a novel FFT-based iterative algorithm for simulating gradient ductile damage in computational homogenization problems. In particular, the Helmholtz-type equation of the implicit gradient approach is properly generalized to model the regularization of damage in multi-phase media, where multiple damage variables and different characteristic lengths may come into play. In the proposed iterative algorithm, two distinct problems are solved in a staggered fashion: (i) a conventional mechanical problem via a FFT-Galerkin solver with mixed macroscopic loading control and (ii) the generalized Helmholtz-type equation using a Krylov-based algorithm combined with an efficient pre-conditioner. The numerical implementation is firstly validated. Finally, the robustness and efficiency of the algorithm is demonstrated in the simulation of failure of complex 3D particle reinforced composites characterized by millions of degrees of freedom.",
        "published": "2021-03-04T18:54:54Z",
        "link": "http://arxiv.org/abs/2103.04770v1",
        "categories": [
            "cs.CE",
            "cond-mat.mtrl-sci",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Finding Efficient Trade-offs in Multi-Fidelity Response Surface Modeling",
        "authors": [
            "Sander van Rijn",
            "Sebastian Schmitt",
            "Matthijs van Leeuwen",
            "Thomas Bäck"
        ],
        "summary": "In the context of optimization approaches to engineering applications, time-consuming simulations are often utilized which can be configured to deliver solutions for various levels of accuracy, commonly referred to as different fidelity levels. It is common practice to train hierarchical surrogate models on the objective functions in order to speed-up the optimization process. These operate under the assumption that there is a correlation between the high- and low-fidelity versions of the problem that can be exploited to cheaply gain information. In the practical scenario where the computational budget has to be allocated between multiple fidelities, limited guidelines are available to help make that division. In this paper we evaluate a range of different choices for a two-fidelity setup that provide helpful intuitions about the trade-off between evaluating in high- or low-fidelity. We present a heuristic method based on subsampling from an initial Design of Experiments (DoE) to find a suitable division of the computational budget between the fidelity levels. This enables the setup of multi-fidelity optimizations which utilize the available computational budget efficiently, independent of the multi-fidelity model used.",
        "published": "2021-03-04T19:29:15Z",
        "link": "http://arxiv.org/abs/2103.03280v4",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Thermodynamic topology optimization for hardening materials",
        "authors": [
            "Miriam Kick",
            "Philipp Junker"
        ],
        "summary": "Topology optimization is an important basis for the design of components. Here, the optimal structure is found within a design space subject to boundary conditions. Thereby, the specific material law has a strong impact on the final design. An important kind of material behavior is hardening: then a, for instance, linear-elastic structure is not optimal if plastic deformation will be induced by the loads. Since hardening behavior has a remarkable impact on the resultant stress field, it needs to be accounted for during topology optimization. In this contribution, we present an extension of the thermodynamic topology optimization that accounts for this non-linear material behavior due to the evolution of plastic strains. For this purpose, we develop a novel surrogate model that allows to compute the plastic strain tensor corresponding to the current structure design for arbitrary hardening behavior. We show the agreement of the model with the classic plasticity model for monotonic loading. Furthermore, we demonstrate the interaction of the topology optimization for hardening material behavior results in structural changes.",
        "published": "2021-03-05T09:52:51Z",
        "link": "http://arxiv.org/abs/2103.03567v4",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Foundations of Population-Based SHM, Part IV: The Geometry of Spaces of   Structures and their Feature Spaces",
        "authors": [
            "George Tsialiamanis",
            "Charilaos Mylonas",
            "Eleni Chatzi",
            "Nikolaos Dervilis",
            "David J. Wagg",
            "Keith Worden"
        ],
        "summary": "One of the requirements of the population-based approach to Structural Health Monitoring (SHM) proposed in the earlier papers in this sequence, is that structures be represented by points in an abstract space. Furthermore, these spaces should be metric spaces in a loose sense; i.e. there should be some measure of distance applicable to pairs of points; similar structures should then be close in the metric. However, this geometrical construction is not enough for the framing of problems in data-based SHM, as it leaves undefined the notion of feature spaces. Interpreting the feature values on a structure-by-structure basis as a type of field over the space of structures, it seems sensible to borrow an idea from modern theoretical physics, and define feature assignments as sections in a vector bundle over the structure space. With this idea in place, one can interpret the effect of environmental and operational variations as gauge degrees of freedom, as in modern gauge field theories. This paper will discuss the various geometrical structures required for an abstract theory of feature spaces in SHM, and will draw analogies with how these structures have shown their power in modern physics. In the second part of the paper, the problem of determining the normal condition cross section of a feature bundle is addressed. The solution is provided by the application of Graph Neural Networks (GNN), a versatile non-Euclidean machine learning algorithm which is not restricted to inputs and outputs from vector spaces. In particular, the algorithm is well suited to operating directly on the sort of graph structures which are an important part of the proposed framework for PBSHM. The solution of the normal section problem is demonstrated for a heterogeneous population of truss structures for which the feature of interest is the first natural frequency.",
        "published": "2021-03-05T13:28:51Z",
        "link": "http://arxiv.org/abs/2103.03655v1",
        "categories": [
            "stat.ML",
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "An assessment of phase field fracture: crack initiation and growth",
        "authors": [
            "P. K. Kristensen",
            "C. F. Niordson",
            "E. Martínez-Pañeda"
        ],
        "summary": "The phase field paradigm, in combination with a suitable variational structure, has opened a path for using Griffith's energy balance to predict the fracture of solids. These so-called phase field fracture methods have gained significant popularity over the past decade, and are now part of commercial finite element packages and engineering fitness-for-service assessments. Crack paths can be predicted, in arbitrary geometries and dimensions, based on a global energy minimisation - without the need for \\textit{ad hoc} criteria. In this work, we review the fundamentals of phase field fracture methods and examine their capabilities in delivering predictions in agreement with the classical fracture mechanics theory pioneered by Griffith. The two most widely used phase field fracture models are implemented in the context of the finite element method, and several paradigmatic boundary value problems are addressed to gain insight into their predictive abilities across all cracking stages; both the initiation of growth and stable crack propagation are investigated. In addition, we examine the effectiveness of phase field models with an internal material length scale in capturing size effects and the transition flaw size concept. Our results show that phase field fracture methods satisfactorily approximate classical fracture mechanics predictions and can also reconcile stress and toughness criteria for fracture. The accuracy of the approximation is however dependent on modelling and constitutive choices; we provide a rationale for these differences and identify suitable approaches for delivering phase field fracture predictions that are in good agreement with well-established fracture mechanics paradigms.",
        "published": "2021-03-06T07:27:55Z",
        "link": "http://arxiv.org/abs/2103.05443v2",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA",
            "physics.app-ph"
        ]
    },
    {
        "title": "Clifford wavelets for fetal ECG extraction",
        "authors": [
            "Malika Jallouli",
            "Sabrine Arfaoui",
            "Anouar Ben Mabrouk",
            "Carlo Cattani"
        ],
        "summary": "Analysis of the fetal heart rate during pregnancy is essential for monitoring the proper development of the fetus. Current fetal heart monitoring techniques lack the accuracy in fetal heart rate monitoring and features acquisition, resulting in diagnostic medical issues. The challenge lies in the extraction of the fetal ECG from the mother's ECG during pregnancy. This approach has the advantage of being a reliable and non-invasive technique. For this aim, we propose in this paper a wavelet/multi-wavelet method allowing to extract perfectly the feta ECG parameters from the abdominal mother ECG. The method is essentially due to the exploitation of Clifford wavelets as recent variants in the field. We prove that these wavelets are more efficient and performing against classical ones. The experimental results are therefore due to two basic classes of wavelets and multi-wavelets. A first-class is the classical Haar Schauder, and a second one is due to Clifford valued wavelets and multi-wavelets. These results showed that wavelets/multiwavelets are already good bases for the FECG processing, provided that Clifford ones are the best.",
        "published": "2021-03-06T10:02:57Z",
        "link": "http://arxiv.org/abs/2103.04085v2",
        "categories": [
            "physics.med-ph",
            "cs.CE",
            "42C40, 92C55"
        ]
    },
    {
        "title": "Simulating linear kinematic features in viscous-plastic sea ice models   on quadrilateral and triangular grids",
        "authors": [
            "C. Mehlmann",
            "S. Danilov",
            "M. Losch",
            "J. F. Lemieux",
            "N. Hutter",
            "T. Richter",
            "P. Blain",
            "E. C. Hunke",
            "P Korn"
        ],
        "summary": "Linear Kinematic Features (LKFs) are found everywhere in the Arctic sea ice cover. They are strongly localized deformations often associated with the formation of leads and pressure ridges. Viscous-plastic sea ice models start to generate LKFs at high spatial grid resolution, typically with a grid spacing below 5 km. Besides grid spacing, other aspects of a numerical implementation, such as discretization details, may affect the number and definition of simulated LKFs. To explore these effects, the solutions of sea ice models with different grid spacings, mesh types, and numerical discretization techniques are compared in an idealized configuration, which could also serve as a benchmark problem in the future. The A, B, and C-grid discretizations of sea ice dynamics on quadrilateral meshes leads to a similar number of LKFs as the A-grid approximation on triangular meshes (with the same number of vertices). The discretization on an Arakawa CD-grid on both structured quadrilateral and triangular meshes resolves the same number of LKFs as conventional Arakawa A-grid, B-grid, and C-grid approaches, but on two times coarser meshes. This is due to the fact that the CD-grid approach has a higher number of degrees of freedom to discretize the velocity field. Due to its enhanced resolving properties, the CD-grid discretization is an attractive alternative to conventional discretizations.",
        "published": "2021-03-07T19:22:27Z",
        "link": "http://arxiv.org/abs/2103.04431v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "physics.ao-ph"
        ]
    },
    {
        "title": "Robust and stochastic compliance-based topology optimization with   finitely many loading scenarios",
        "authors": [
            "Mohamed Tarek",
            "Tapabrata Ray"
        ],
        "summary": "In this paper, the problem of load uncertainty in compliance problems is addressed where the uncertainty is described in the form of a set of finitely many loading scenarios. Computationally more efficient methods are proposed to exactly evaluate and differentiate: 1) the mean compliance, or 2) any scalar-valued function of the individual load compliances such as the weighted sum of the mean and standard deviation. The computational time complexities of all the proposed algorithms are analyzed, compared with the naive approaches and then experimentally verified. Finally, a mean compliance minimization problem, a risk-averse compliance minimization problem and a maximum compliance constrained problem are solved to showcase the efficacy of the proposed algorithms. The maximum compliance constrained problem is solved using the augmented Lagrangian method and the method proposed for handling scalar-valued functions of the load compliances, where the scalar-valued function is the augmented Lagrangian function.",
        "published": "2021-03-08T08:21:09Z",
        "link": "http://arxiv.org/abs/2103.04594v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Quasi-structured quadrilateral meshing in Gmsh -- a robust pipeline for   complex CAD models",
        "authors": [
            "Maxence Reberol",
            "Christos Georgiadis",
            "Jean-François Remacle"
        ],
        "summary": "We propose an end-to-end pipeline to robustly generate high-quality quadrilateral meshes for complex CAD models. An initial quad-dominant mesh is generated with frontal point insertion guided by a locally integrable cross field and a scalar size map adapted to the small CAD features. After triangle combination and midpoint-subdivision into an all-quadrilateral mesh, the topology of the mesh is modified to reduce the number of irregular vertices. The idea is to preserve the irregular vertices matching cross-field singularities and to eliminate the others. The topological modifications are either local and based on disk quadrangulations, or more global with the remeshing of patches of quads according to predefined patterns. Validity of the quad mesh is guaranteed by monitoring element quality during all operations and reverting the changes when necessary. Advantages of our approach include robustness, strict respect of the CAD features and support for user-prescribed size constraints. The quad mesher, which is available in Gmsh, is validated and illustrated on two datasets of CAD models.",
        "published": "2021-03-08T10:23:55Z",
        "link": "http://arxiv.org/abs/2103.04652v1",
        "categories": [
            "cs.CE",
            "cs.CG",
            "cs.MS"
        ]
    },
    {
        "title": "Will it Crease or Cease? A study of Debulking of Air Pockets in   Automated Prepreg Composite Layup",
        "authors": [
            "Christian Krogh",
            "Johnny Jakobsen",
            "Jakob Wilm"
        ],
        "summary": "Automatic draping of carbon-fiber prepreg plies for the aerospace industry is a promising technique for lowering the manufacturing costs and to this end, a thorough in-process quality control is crucial. In this paper, out-of-plane defects in the layup are investigated. After draping, air pockets are occasionally encountered. The question is, if such apparent defects can be mitigated sufficiently during vacuum debulking. The 3D topology is measured by means of a structured-light 3D scanner and air pockets are segmented. An approximate mass-spring ply model is used to study the behavior of the air pockets during application of vacuum pressure. The model is computationally fast and will indicate online whether the air pocket will be removed or manual intervention is required. Upon comparing the model predictions with experimental data, it is shown that the system is capable of correctly predicting 13 out of 14 air pockets in a test layup.",
        "published": "2021-03-09T07:48:24Z",
        "link": "http://arxiv.org/abs/2103.05275v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "PGD-based advanced nonlinear multiparametric regressions for   constructing metamodels at the scarce-data limit",
        "authors": [
            "Abel Sancarlos",
            "Victor Champaney",
            "Jean-Louis Duval",
            "Elias Cueto",
            "Francisco Chinesta"
        ],
        "summary": "Regressions created from experimental or simulated data enable the construction of metamodels, widely used in a variety of engineering applications. Many engineering problems involve multi-parametric physics whose corresponding multi-parametric solutions can be viewed as a sort of computational vademecum that, once computed offline, can be then used in a variety of real-time engineering applications including optimization, inverse analysis, uncertainty propagation or simulation based control. Sometimes, these multi-parametric problems can be solved by using advanced model order reduction -- MOR -- techniques. However, when the solution of these multi-parametric problems becomes cumbersome, one possibility consists in solving the problem for a sample of the parametric values, and then creating a regression from all the computed solutions, to finally infer the solution for any choice of the problem parameters. However, addressing high-dimensionality at the low data limit, ensuring accuracy and avoiding overfitting constitutes a difficult challenge. The present paper aims at proposing and discussing different PGD-based advanced regressions enabling the just referred features.",
        "published": "2021-03-09T11:11:17Z",
        "link": "http://arxiv.org/abs/2103.05358v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Portfolio risk allocation through Shapley value",
        "authors": [
            "Patrick S. Hagan",
            "Andrew Lesniewski",
            "Georgios E. Skoufis",
            "Diana E. Woodward"
        ],
        "summary": "We argue that using the Shapley value of cooperative game theory as the scheme for risk allocation among non-orthogonal risk factors is a natural way of interpreting the contribution made by each of such factors to overall portfolio risk. We discuss a Shapley value scheme for allocating risk to non-orthogonal greeks in a portfolio of derivatives. Such a situation arises, for example, when using a stochastic volatility model to capture option volatility smile. We also show that Shapley value allows for a natural method of interpreting components of enterprise risk measures such as VaR and ES. For all applications discussed, we derive explicit formulas and / or numerical algorithms to calculate the allocations.",
        "published": "2021-03-09T14:36:16Z",
        "link": "http://arxiv.org/abs/2103.05453v1",
        "categories": [
            "q-fin.CP",
            "cs.CE",
            "econ.EM",
            "math.OC"
        ]
    },
    {
        "title": "COVID-19: Optimal Allocation of Ventilator Supply under Uncertainty and   Risk",
        "authors": [
            "Xuecheng Yin",
            "I. Esra Buyuktahtakin",
            "Bhumi P. Patel"
        ],
        "summary": "This study presents a new risk-averse multi-stage stochastic epidemics-ventilator-logistics compartmental model to address the resource allocation challenges of mitigating COVID-19. This epidemiological logistics model involves the uncertainty of untested asymptomatic infections and incorporates short-term human migration. Disease transmission is also forecasted through a new formulation of transmission rates that evolve over space and time with respect to various non-pharmaceutical interventions, such as wearing masks, social distancing, and lockdown. The proposed multi-stage stochastic model overviews different scenarios on the number of asymptomatic individuals while optimizing the distribution of resources, such as ventilators, to minimize the total expected number of newly infected and deceased people. The Conditional Value at Risk (CVaR) is also incorporated into the multi-stage mean-risk model to allow for a trade-off between the weighted expected loss due to the outbreak and the expected risks associated with experiencing disastrous pandemic scenarios. We apply our multi-stage mean-risk epidemics-ventilator-logistics model to the case of controlling the COVID-19 in highly-impacted counties of New York and New Jersey. We calibrate, validate, and test our model using actual infection, population, and migration data. The results indicate that short-term migration influences the transmission of the disease significantly. The optimal number of ventilators allocated to each region depends on various factors, including the number of initial infections, disease transmission rates, initial ICU capacity, the population of a geographical location, and the availability of ventilator supply. Our data-driven modeling framework can be adapted to study the disease transmission dynamics and logistics of other similar epidemics and pandemics.",
        "published": "2021-03-10T01:48:35Z",
        "link": "http://arxiv.org/abs/2103.06813v1",
        "categories": [
            "stat.AP",
            "cs.CE",
            "q-bio.PE"
        ]
    },
    {
        "title": "An FFT-based method for computing the effective crack energy of a   heterogeneous material on a combinatorially consistent grid",
        "authors": [
            "Felix Ernesti",
            "Matti Schneider"
        ],
        "summary": "We introduce an FFT-based solver for the combinatorial continuous maximum flow discretization applied to computing the minimum cut through heterogeneous microstructures. Recently, computational methods were introduced for computing the effective crack energy of periodic and random media. These were based on the continuous minimum cut-maximum flow duality of G. Strang, and made use of discretizations based on trigonometric polynomials and finite elements. For maximum flow problems on graphs, node-based discretization methods avoid metrication artifacts associated to edge-based discretizations. We discretize the minimum cut problem on heterogeneous microstructures by the combinatorial continuous maximum flow discretization introduced by Couprie et al. Furthermore, we introduce an associated FFT-based ADMM solver and provide several adaptive strategies for choosing numerical parameters. We demonstrate the salient features of the proposed approach on problems of industrial scale.",
        "published": "2021-03-10T09:55:01Z",
        "link": "http://arxiv.org/abs/2103.05968v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Compression of volume-surface integral equation matrices via Tucker   decomposition for magnetic resonance applications",
        "authors": [
            "Ilias I. Giannakopoulos",
            "Georgy D. Guryev",
            "Jose E. C. Serralles",
            "Ioannis P. Georgakis",
            "Luca Daniel",
            "Jacob K. White",
            "Riccardo Lattanzi"
        ],
        "summary": "In this work, we propose a method for the compression of the coupling matrix in volume\\hyp surface integral equation (VSIE) formulations. VSIE methods are used for electromagnetic analysis in magnetic resonance imaging (MRI) applications, for which the coupling matrix models the interactions between the coil and the body. We showed that these effects can be represented as independent interactions between remote elements in 3D tensor formats, and subsequently decomposed with the Tucker model. Our method can work in tandem with the adaptive cross approximation technique to provide fast solutions of VSIE problems. We demonstrated that our compression approaches can enable the use of VSIE matrices of prohibitive memory requirements, by allowing the effective use of modern graphical processing units (GPUs) to accelerate the arising matrix\\hyp vector products. This is critical to enable numerical MRI simulations at clinical voxel resolutions in a feasible computation time. In this paper, we demonstrate that the VSIE matrix\\hyp vector products needed to calculate the electromagnetic field produced by an MRI coil inside a numerical body model with $1$ mm$^3$ voxel resolution, could be performed in $\\sim 33$ seconds in a GPU, after compressing the associated coupling matrix from $\\sim 80$ TB to $\\sim 43$ MB.",
        "published": "2021-03-11T00:20:27Z",
        "link": "http://arxiv.org/abs/2103.06393v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "ANN-aided incremental multiscale-remodelling-based finite strain   poroelasticity",
        "authors": [
            "Hamidreza Dehghani",
            "Andreas Zilian"
        ],
        "summary": "Mechanical modelling of poroelastic media under finite strain is usually carried out via phenomenological models neglecting complex micro-macro scales interdependency. One reason is that the mathematical two-scale analysis is only straightforward assuming infinitesimal strain theory. Exploiting the potential of ANNs for fast and reliable upscaling and localisation procedures, we propose an incremental numerical approach that considers rearrangement of the cell properties based on its current deformation, which leads to the remodelling of the macroscopic model after each time increment. This computational framework is valid for finite strain and large deformation problems while it ensures infinitesimal strain increments within time steps. The full effects of the interdependency between the properties and response of macro and micro scales are considered for the first time providing more accurate predictive analysis of fluid-saturated porous media which is studied via a numerical consolidation example. Furthermore, the (nonlinear) deviation from Darcy's law is captured in fluid filtration numerical analyses. Finally, the brain tissue mechanical response under uniaxial cyclic test is simulated and studied.",
        "published": "2021-03-11T09:52:12Z",
        "link": "http://arxiv.org/abs/2103.06569v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Explicit topology optimization through moving node approach: beam   elements recognition",
        "authors": [
            "Ghislain Raze",
            "Joseph Morlier"
        ],
        "summary": "Structural optimization (topology, shapes, sizing) is an important tool for facilitating the emergence of new concepts in structural design. Normally, topology optimization is carried out at the early stage of design and then shape and sizing design are performed sequentially. Unlike traditional topology optimization method, explicit methodologies have attracted a great deal of attention because of the advantages of shortcuting the costly CAD/CAE processes while dealing with low order number of design variables compared to implicit method (such as SIMP). This paper aims at presenting an adaptation of a flow-inspired approach so-called Moving Node Approach (MNA) in topology optimization. In this approach, the discretization is decoupled from the material distribution and the final objective is to recognize the best beam assembly while minimizing compliance. The paradigm has here changed and new design variables are used such as nodes location, elements length/orientation and size providing a lower number of design variables than pixels-based. The methodology is validated using 2 classical testcases in the field of Topology Optimization: the Cantilever beam and the L-Shape problem.",
        "published": "2021-03-11T17:10:12Z",
        "link": "http://arxiv.org/abs/2103.08347v1",
        "categories": [
            "math.OC",
            "cs.CE"
        ]
    },
    {
        "title": "SuperMeshing: A New Deep Learning Architecture for Increasing the Mesh   Density of Metal Forming Stress Field with Attention Mechanism and Perceptual   Features",
        "authors": [
            "Qingfeng Xu",
            "Zhenguo Nie",
            "Handing Xu",
            "Haosu Zhou",
            "Xinjun Liu"
        ],
        "summary": "In stress field analysis, the finite element analysis is a crucial approach, in which the mesh-density has a significant impact on the results. High mesh density usually contributes authentic to simulation results but costs more computing resources, leading to curtailing efficiency during the design process. To eliminate this drawback, we propose a new data-driven mesh-density boost model named SuperMeshingNet that strengthens the advantages of finite element analysis (FEA) with low mesh-density as inputs to the deep learning model, which consisting of Res-UNet architecture, to acquire high-density stress field instantaneously, shortening computing time and cost automatically. Moreover, the attention mechanism and the perceptual features are utilized, enhancing the performance of SuperMeshingNet. Compared to the baseline that applied the linear interpolation method, SuperMeshingNet achieves a prominent reduction in the mean squared error (MSE) and mean absolute error (MAE) on test data, which contains prior unseen cases. Based on the data set of metal forming, the comparable experiments are proceeded to demonstrate the high quality and superior precision of the reconstructed results generated by our model. The well-trained model can successfully show more excellent performance than the baseline and other methods on the multiple scaled mesh-density, including $2\\times$, $4\\times$, and $8\\times$. With the refined result owning broaden scaling of mesh density and high precision, the FEA process can be accelerated with seldom cost on computation resources. We publicly share our work with full detail of implementation at https://github.com/zhenguonie/2021_SuperMeshing_2D_Metal_Forming",
        "published": "2021-03-12T06:02:30Z",
        "link": "http://arxiv.org/abs/2104.09276v1",
        "categories": [
            "cs.CE",
            "cs.LG",
            "14J60 (Primary) 14F05, 14J26 (Secondary)",
            "F.2.2; I.2.7"
        ]
    },
    {
        "title": "Interface spaces based on physics for multiscale mixed methods applied   to flows in fractured-like porous media",
        "authors": [
            "Franciane F. Rocha",
            "Fabricio S. Sousa",
            "Roberto F. Ausas",
            "Felipe Pereira",
            "Gustavo C. Buscaglia"
        ],
        "summary": "It is well known that domain-decomposition-based multiscale mixed methods rely on interface spaces, defined on the skeleton of the decomposition, to connect the solution among the non-overlapping subdomains. Usual spaces, such as polynomial-based ones, cannot properly represent high-contrast channelized features such as fractures (high permeability) and barriers (low permeability) for flows in heterogeneous porous media. We propose here new interface spaces, which are based on physics, to deal with permeability fields in the simultaneous presence of fractures and barriers, accommodated respectively, by the pressure and flux spaces. Existing multiscale methods based on mixed formulations can take advantage of the proposed interface spaces, however, in order to present and test our results, we use the newly developed Multiscale Robin Coupled Method (MRCM) [Guiraldello, et al., J. Comput. Phys., 355 (2018) pp. 1-21], which generalizes most well-known multiscale mixed methods, and allows for the independent choice of the pressure and flux interface spaces. An adaptive version of the MRCM [Rocha, et al., J. Comput. Phys., 409 (2020), 109316] is considered that automatically selects the physics-based pressure space for fractured structures and the physics-based flux space for regions with barriers, resulting in a procedure with unprecedented accuracy. The features of the proposed approach are investigated through several numerical simulations of single-phase and two-phase flows, in different heterogeneous porous media. The adaptive MRCM combined with the interface spaces based on physics provides promising results for challenging problems with the simultaneous presence of fractures and barriers.",
        "published": "2021-03-12T16:18:18Z",
        "link": "http://arxiv.org/abs/2103.07377v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Discovery of Physics and Characterization of Microstructure from Data   with Bayesian Hidden Physics Models",
        "authors": [
            "Steven Atkinson",
            "Yiming Zhang",
            "Liping Wang"
        ],
        "summary": "There has been a surge in the interest of using machine learning techniques to assist in the scientific process of formulating knowledge to explain observational data. We demonstrate the use of Bayesian Hidden Physics Models to first uncover the physics governing the propagation of acoustic impulses in metallic specimens using data obtained from a pristine sample. We then use the learned physics to characterize the microstructure of a separate specimen with a surface-breaking crack flaw. Remarkably, we find that the physics learned from the first specimen allows us to understand the backscattering observed in the latter sample, a qualitative feature that is wholly absent from the specimen from which the physics were inferred. The backscattering is explained through inhomogeneities of a latent spatial field that can be recognized as the speed of sound in the media.",
        "published": "2021-03-12T19:47:06Z",
        "link": "http://arxiv.org/abs/2103.07502v1",
        "categories": [
            "cs.LG",
            "cs.CE"
        ]
    },
    {
        "title": "Representative volume elements for matrix-inclusion composites -- a   computational study on periodizing the ensemble",
        "authors": [
            "Matti Schneider",
            "Marc Josien",
            "Felix Otto"
        ],
        "summary": "We investigate volume-element sampling strategies for the stochastic homogenization of particle-reinforced composites and show, via computational experiments, that an improper treatment of particles intersecting the boundary of the computational cell may affect the accuracy of the computed effective properties. Motivated by recent results on a superior convergence rate of the systematic error for periodized ensembles compared to taking snapshots of ensembles, we conduct computational experiments for microstructures with circular, spherical and cylindrical inclusions and monitor the systematic errors in the effective thermal conductivity for snapshots of ensembles compared to working with microstructures sampled from periodized ensembles. We observe that the standard deviation of the apparent properties computed on microstructures sampled from the periodized ensembles decays at the scaling expected from the central limit theorem. In contrast, the standard deviation for the snapshot ensembles shows an inferior decay rate at high filler content. The latter effect is caused by additional long-range correlations that necessarily appear in particle-reinforced composites at high, industrially relevant, volume fractions. Periodized ensembles, however, appear to be less affected by these correlations. Our findings provide guidelines for working with digital volume images of material microstructures and the design of representative volume elements for computational homogenization.",
        "published": "2021-03-13T06:04:43Z",
        "link": "http://arxiv.org/abs/2103.07627v1",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.AP",
            "math.NA",
            "74Q05",
            "G.1.8; G.3; I.6.3; J.2"
        ]
    },
    {
        "title": "Large-scale Recommendation for Portfolio Optimization",
        "authors": [
            "Robin Swezey",
            "Bruno Charron"
        ],
        "summary": "Individual investors are now massively using online brokers to trade stocks with convenient interfaces and low fees, albeit losing the advice and personalization traditionally provided by full-service brokers. We frame the problem faced by online brokers of replicating this level of service in a low-cost and automated manner for a very large number of users. Because of the care required in recommending financial products, we focus on a risk-management approach tailored to each user's portfolio and risk profile. We show that our hybrid approach, based on Modern Portfolio Theory and Collaborative Filtering, provides a sound and effective solution. The method is applicable to stocks as well as other financial assets, and can be easily combined with various financial forecasting models. We validate our proposal by comparing it with several baselines in a domain expert-based study.",
        "published": "2021-03-13T18:22:48Z",
        "link": "http://arxiv.org/abs/2103.07768v1",
        "categories": [
            "cs.AI",
            "cs.CE",
            "cs.IR",
            "cs.LG"
        ]
    },
    {
        "title": "An SPH framework for fluid-solid and contact interaction problems   including thermo-mechanical coupling and reversible phase transitions",
        "authors": [
            "Sebastian L. Fuchs",
            "Christoph Meier",
            "Wolfgang A. Wall",
            "Christian J. Cyron"
        ],
        "summary": "The present work proposes an approach for fluid-solid and contact interaction problems including thermo-mechanical coupling and reversible phase transitions. The solid field is assumed to consist of several arbitrarily-shaped, undeformable but mobile rigid bodies, that are evolved in time individually and allowed to get into mechanical contact with each other. The fluid field generally consists of multiple liquid or gas phases. All fields are spatially discretized using the method of smoothed particle hydrodynamics (SPH). This approach is especially suitable in the context of continually changing interface topologies and dynamic phase transitions without the need for additional methodological and computational effort for interface tracking as compared to mesh- or grid-based methods. Proposing a concept for the parallelization of the computational framework, in particular concerning a computationally efficient evaluation of rigid body motion, is an essential part of this work. Finally, the accuracy and robustness of the proposed framework is demonstrated by several numerical examples in two and three dimensions, involving multiple rigid bodies, two-phase flow, and reversible phase transitions, with a focus on two potential application scenarios in the fields of engineering and biomechanics: powder bed fusion additive manufacturing (PBFAM) and disintegration of food boluses in the human stomach. The efficiency of the parallel computational framework is demonstrated by a strong scaling analysis.",
        "published": "2021-03-14T13:39:56Z",
        "link": "http://arxiv.org/abs/2103.07925v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "An FE-DMN method for the multiscale analysis of fiber reinforced plastic   components",
        "authors": [
            "Sebastian Gajek",
            "Matti Schneider",
            "Thomas Böhlke"
        ],
        "summary": "In this work, we propose a fully coupled multiscale strategy for components made from short fiber reinforced composites, where each Gauss point of the macroscopic finite element model is equipped with a deep material network (DMN) which covers the different fiber orientation states varying within the component. These DMNs need to be identified by linear elastic precomputations on representative volume elements, and serve as high-fidelity surrogates for full-field simulations on microstructures with inelastic constituents. We discuss how to extend direct DMNs to account for varying fiber orientation, and propose a simplified sampling strategy which significantly speeds up the training process. To enable concurrent multiscale simulations, evaluating the DMNs efficiently is crucial. We discuss dedicated techniques for exploiting sparsity and high-performance linear algebra modules, and demonstrate the power of the proposed approach on an industrial-scale three-dimensional component. Indeed, the DMN is capable of accelerating two-scale simulations significantly, providing possible speed-ups of several magnitudes.",
        "published": "2021-03-15T10:06:11Z",
        "link": "http://arxiv.org/abs/2103.08253v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Online Learning with Radial Basis Function Networks",
        "authors": [
            "Gabriel Borrageiro",
            "Nick Firoozye",
            "Paolo Barucca"
        ],
        "summary": "Financial time series are characterised by their nonstationarity and autocorrelation. Even if these time series are differenced, technically ensuring their stationarity, they experience regular covariate shifts and concept drifts. Against this backdrop, we combine feature representation transfer with sequential optimisation to provide multi-horizon returns forecasts. Our online learning rbfnet outperforms a random-walk baseline and several powerful batch learners. The rbfnets we formulate are naturally designed to measure the similarity between test samples and continuously updated prototypes that capture the characteristics of the feature space.",
        "published": "2021-03-15T14:39:40Z",
        "link": "http://arxiv.org/abs/2103.08414v8",
        "categories": [
            "cs.CE",
            "cs.LG",
            "q-fin.TR"
        ]
    },
    {
        "title": "A novel approach for the efficient modeling of material dissolution in   electrochemical machining",
        "authors": [
            "Tim van der Velden",
            "Bob Rommes",
            "Andreas Klink",
            "Stefanie Reese",
            "Johanna Waimann"
        ],
        "summary": "This work presents a novel approach to efficiently model anodic dissolution in electrochemical machining. Earlier modeling approaches employ a strict space discretization of the anodic surface that is associated with a remeshing procedure at every time step. Besides that, the presented model is formulated by means of effective material parameters. Thereby, it allows to use a constant mesh for the entire simulation and, thus, decreases the computational costs. Based on Faraday's law of electrolysis, an effective dissolution level is introduced, which describes the ratio of a dissolved volume and its corresponding reference volume. This inner variable allows the modeling of the complex dissolution process without the necessity of computationally expensive remeshing by controlling the effective material parameters. Additionally, full coupling of the thermoelectric problem is considered and its linearization and numerical implementation are presented. The model shows good agreement with analytical and experimental validation examples by yielding realistic results. Furthermore, simulations of a pulsed electrochemical machining process yield a process signature of the surface roughness related to the specific accumulated electric charge. The numerical examples confirm the simulation's computational efficiency and accurate modeling qualities.",
        "published": "2021-03-15T14:56:43Z",
        "link": "http://arxiv.org/abs/2103.08426v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Deep learning of material transport in complex neurite networks",
        "authors": [
            "Angran Li",
            "Amir Barati Farimani",
            "Yongjie Jessica Zhang"
        ],
        "summary": "Neurons exhibit complex geometry in their branched networks of neurites which is essential to the function of individual neuron but also brings challenges to transport a wide variety of essential materials throughout their neurite networks for their survival and function. While numerical methods like isogeometric analysis (IGA) have been used for modeling the material transport process via solving partial differential equations (PDEs), they require long computation time and huge computation resources to ensure accurate geometry representation and solution, thus limit their biomedical application. Here we present a graph neural network (GNN)-based deep learning model to learn the IGA-based material transport simulation and provide fast material concentration prediction within neurite networks of any topology. Given input boundary conditions and geometry configurations, the well-trained model can predict the dynamical concentration change during the transport process with an average error less than 10% and 120~330 times faster compared to IGA simulations. The effectiveness of the proposed model is demonstrated within several complex neurite networks.",
        "published": "2021-03-15T19:05:09Z",
        "link": "http://arxiv.org/abs/2103.08654v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A splitting random-choice dynamic relaxation method for smoothed   particle hydrodynamics",
        "authors": [
            "Yujie Zhu",
            "Chi Zhang",
            "Xiangyu Hu"
        ],
        "summary": "For conventional smoothed particle hydrodynamics (SPH), obtaining the static solution of a problem is time-consuming. To address this drawback, we propose an efficient dynamic relaxation method by adding large artificial-viscosity-based damping into the momentum conservation equation. Then, operator splitting methods are introduced to discretize the added viscous term for relaxing the time-step limit. To further improve the convergence rate, a random-choice strategy is adopted, in which the viscous term is imposed randomly rather than at every time step. In addition, to avoid the thread-conflict induced by applying shared-memory parallelization to accelerate implicit method, a splitting cell-linked list scheme is devised. A number of benchmark tests suggest that the present method helps systems achieve equilibrium state efficiently.",
        "published": "2021-03-16T09:30:16Z",
        "link": "http://arxiv.org/abs/2103.08932v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Computational Homogenization of Concrete in the Cyber   Size-Resolution-Discretization (SRD) Parameter Space",
        "authors": [
            "Ajinkya Gote",
            "Andreas Fischer",
            "Chuanzeng Zhang",
            "Bernhard Eidel"
        ],
        "summary": "Micro- and mesostructures of multiphase materials obtained from tomography and image acquisition are an ever more important database for simulation analyses. Huge data sets for reconstructed 3d volumes typically as voxel grids call for criteria and measures to find an affordable balance of accuracy and efficiency. The present work shows for a 3d mesostructure of concrete in the elastic deformation range, how the computational complexity in analyses of numerical homogenization can be reduced at controlled errors. Reduction is systematically applied to specimen size S, resolution R, and discretization D, which span the newly introduced SRD parameter space. Key indicators for accuracy are (i) the phase fractions, (ii) the homogenized elasticity tensor, (iii) its invariance with respect to the applied boundary conditions and (iv) the total error as well as spatial error distributions, which are computed and estimated. Pre-analyses in the 2d SRD parameter sub-space explore the transferability to the 3d case. Beyond the concrete specimen undergoing elastic deformations in the present work, the proposed concept enables accuracy-efficiency balances for various classes of heterogeneous materials in different deformation regimes and thus contributes to build comprehensive digital twins of materials with validated attributes.",
        "published": "2021-03-16T10:32:19Z",
        "link": "http://arxiv.org/abs/2103.08957v1",
        "categories": [
            "cs.CE",
            "74B05, 74Q15, 74Q20, 74Q20"
        ]
    },
    {
        "title": "A massively parallel explicit solver for elasto-dynamic problems   exploiting octree meshes",
        "authors": [
            "Junqi Zhang",
            "Ankit Ankit",
            "Hauke Gravenkamp",
            "Sascha Eisenträger",
            "Chongmin Song"
        ],
        "summary": "Typical areas of application of explicit dynamics are impact, crash test, and most importantly, wave propagation simulations. Due to the numerically highly demanding nature of these problems, efficient automatic mesh generators and transient solvers are required. To this end, a parallel explicit solver exploiting the advantages of balanced octree meshes is introduced. To avoid the hanging nodes problem encountered in standard finite element analysis (FEA), the scaled boundary finite element method (SBFEM) is deployed as a spatial discretization scheme. Consequently, arbitrarily shaped star-convex polyhedral elements are straightforwardly generated. Considering the scaling and transformation of octree cells, the stiffness and mass matrices of a limited number of unique cell patterns are pre-computed. A recently proposed mass lumping technique is extended to 3D yielding a well-conditioned diagonal mass matrix. This enables us to leverage the advantages of explicit time integrator, i.e., it is possible to efficiently compute the nodal displacements without the need for solving a system of linear equations. We implement the proposed scheme together with a central difference method (CDM) in a distributed computing environment. The performance of our parallel explicit solver is evaluated by means of several numerical benchmark examples, including complex geometries and various practical applications. A significant speedup is observed for these examples with up to one billion of degrees of freedom and running on up to 16,384 computing cores.",
        "published": "2021-03-16T14:29:22Z",
        "link": "http://arxiv.org/abs/2103.09100v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Uncertainty quantification of microstructure variability and mechanical   behaviour of additively manufactured lattice structures",
        "authors": [
            "Nina Korshunova",
            "Iason Papaioannou",
            "Stefan Kollmannsberger",
            "Daninel Straub",
            "Ernst Rank"
        ],
        "summary": "Process-induced defects are the leading cause of discrepancies between as-designed and as-manufactured additive manufacturing (AM) product behavior. Especially for metal lattices, the variations in the printed geometry cannot be neglected. Therefore, the evaluation of the influence of microstructural variability on their mechanical behavior is crucial for the quality assessment of the produced structures. Commonly, the as-manufactured geometry can be obtained by computed tomography (CT). However, to incorporate all process-induced defects into the numerical analysis is often computationally demanding. Thus, commonly this task is limited to a predefined set of considered variations, such as strut size or strut diameter. In this work, a CT-based binary random field is proposed to generate statistically equivalent geometries of periodic metal lattices. The proposed random field model in combination with the Finite Cell Method (FCM), an immersed boundary method, allows to efficiently evaluate the influence of the underlying microstructure on the variability of the mechanical behavior of AM products. Numerical analysis of two lattices manufactured at different scales shows an excellent agreement with experimental data. Furthermore, it provides a unique insight into the effects of the process on the occurring geometrical variations and final mechanical behavior.",
        "published": "2021-03-17T10:26:52Z",
        "link": "http://arxiv.org/abs/2103.09550v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Data-driven nonintrusive reduced order modeling for dynamical systems   with moving boundaries using Gaussian process regression",
        "authors": [
            "Zhan Ma",
            "Wenxiao Pan"
        ],
        "summary": "We present a data-driven nonintrusive model order reduction method for dynamical systems with moving boundaries. The proposed method draws on the proper orthogonal decomposition, Gaussian process regression, and moving least squares interpolation. It combines several attributes that are not simultaneously satisfied in the existing model order reduction methods for dynamical systems with moving boundaries. Specifically, the method requires only snapshot data of state variables at discrete time instances and the parameters that characterize the boundaries, but not further knowledge of the full-order model and the underlying governing equations. The dynamical systems can be generally nonlinear. The movements of boundaries are not limited to prescribed or periodic motions but can be free motions. In addition, we numerically investigate the ability of the reduced order model constructed by the proposed method to forecast the full-order solutions for future times beyond the range of snapshot data. The error analysis for the proposed reduced order modeling and the criteria to determine the furthest forecast time are also provided. Through numerical experiments, we assess the accuracy and efficiency of the proposed method in several benchmark problems. The snapshot data used to construct and validate the reduced order model are from analytical/numerical solutions and experimental measurements.",
        "published": "2021-03-17T17:23:50Z",
        "link": "http://arxiv.org/abs/2103.09790v1",
        "categories": [
            "cs.CE",
            "math.DS"
        ]
    },
    {
        "title": "MARS: Markov Molecular Sampling for Multi-objective Drug Discovery",
        "authors": [
            "Yutong Xie",
            "Chence Shi",
            "Hao Zhou",
            "Yuwei Yang",
            "Weinan Zhang",
            "Yong Yu",
            "Lei Li"
        ],
        "summary": "Searching for novel molecules with desired chemical properties is crucial in drug discovery. Existing work focuses on developing neural models to generate either molecular sequences or chemical graphs. However, it remains a big challenge to find novel and diverse compounds satisfying several properties. In this paper, we propose MARS, a method for multi-objective drug molecule discovery. MARS is based on the idea of generating the chemical candidates by iteratively editing fragments of molecular graphs. To search for high-quality candidates, it employs Markov chain Monte Carlo sampling (MCMC) on molecules with an annealing scheme and an adaptive proposal. To further improve sample efficiency, MARS uses a graph neural network (GNN) to represent and select candidate edits, where the GNN is trained on-the-fly with samples from MCMC. Experiments show that MARS achieves state-of-the-art performance in various multi-objective settings where molecular bio-activity, drug-likeness, and synthesizability are considered. Remarkably, in the most challenging setting where all four objectives are simultaneously optimized, our approach outperforms previous methods significantly in comprehensive evaluations. The code is available at https://github.com/yutxie/mars.",
        "published": "2021-03-18T10:04:15Z",
        "link": "http://arxiv.org/abs/2103.10432v1",
        "categories": [
            "q-bio.BM",
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "A geometrically adapted reduced set of frequencies for a FFT-based   microstructure simulation",
        "authors": [
            "Christian Gierden",
            "Johanna Waimann",
            "Bob Svendsen",
            "Stefanie Reese"
        ],
        "summary": "We present a modified model order reduction (MOR) technique for the FFT-based simulation of composite microstructures. It utilizes the earlier introduced MOR technique (Kochmann et al. [2019]), which is based on solving the Lippmann-Schwinger equation in Fourier space by a reduced set of frequencies. Crucial for the accuracy of this MOR technique is on the one hand the amount of used frequencies and on the other hand the choice of frequencies used within the simulation. Kochmann et al. [2019] defined the reduced set of frequencies by using a fixed sampling pattern, which is most general but leads to poor microstructural results when considering only a few frequencies. Consequently, a reconstruction algorithm based on the TV1-algorithm [Candes et al., 2006] was used in a post-processing step to generate highly resolved micromechanical fields. The present work deals with a modified sampling pattern generation for this MOR technique. Based on the idea, that the micromechanical material response strongly depends on the phase-wise material behavior, we propose the usage of sampling patterns adapted to the spatial arrangement of the individual phases. This leads to significantly improved microscopic and overall results. Hence, the time-consuming reconstruction in the post-processing step that was necessary in the earlier work is no longer required. To show the adaptability and robustness of this new choice of sampling patterns, several two dimensional examples are investigated. In addition, also the 3D extension of the algorithm is presented.",
        "published": "2021-03-18T12:12:42Z",
        "link": "http://arxiv.org/abs/2103.10203v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "How to Compute Invariant Manifolds and their Reduced Dynamics in   High-Dimensional Finite-Element Models",
        "authors": [
            "Shobhit Jain",
            "George Haller"
        ],
        "summary": "Invariant manifolds are important constructs for the quantitative and qualitative understanding of nonlinear phenomena in dynamical systems. In nonlinear damped mechanical systems, for instance, spectral submanifolds have emerged as useful tools for the computation of forced response curves, backbone curves, detached resonance curves (isolas) via exact reduced-order models. For conservative nonlinear mechanical systems, Lyapunov subcenter manifolds and their reduced dynamics provide a way to identify nonlinear amplitude-frequency relationships in the form of conservative backbone curves. Despite these powerful predictions offered by invariant manifolds, their use has largely been limited to low-dimensional academic examples. This is because several challenges render their computation unfeasible for realistic engineering structures described by finite-element models. In this work, we address these computational challenges and develop methods for computing invariant manifolds and their reduced dynamics in very high-dimensional nonlinear systems arising from spatial discretization of the governing partial differential equations. We illustrate our computational algorithms on finite-element models of mechanical structures that range from a simple beam containing tens of degrees of freedom to an aircraft wing containing more than a hundred-thousand degrees of freedom.",
        "published": "2021-03-18T14:01:11Z",
        "link": "http://arxiv.org/abs/2103.10264v2",
        "categories": [
            "cs.CE",
            "math.DS"
        ]
    },
    {
        "title": "Data-driven Coarse-grained Modeling of Non-equilibrium Systems",
        "authors": [
            "Shu Wang",
            "Zhan Ma",
            "Wenxiao Pan"
        ],
        "summary": "Modeling a high-dimensional Hamiltonian system in reduced dimensions with respect to coarse-grained (CG) variables can greatly reduce computational cost and enable efficient bottom-up prediction of main features of the system for many applications. However, it usually experiences significantly altered dynamics due to loss of degrees of freedom upon coarse-graining. To establish CG models that can faithfully preserve dynamics, previous efforts mainly focused on equilibrium systems. In contrast, various soft matter systems are known out of equilibrium. Therefore, the present work concerns non-equilibrium systems and enables accurate and efficient CG modeling that preserves non-equilibrium dynamics and is generally applicable to any non-equilibrium process and any observable of interest. To this end, the dynamic equation of a CG variable is built in the form of the non-stationary generalized Langevin equation (nsGLE) to account for the dependence of non-equilibrium processes on the initial conditions, where the two-time memory kernel is determined from the data of the two-time auto-correlation function of the non-equilibrium trajectory-averaged observable of interest. By embedding the non-stationary non-Markovian process in an extended stochastic framework, an explicit form of the non-stationary random noise in the nsGLE is introduced, and the cost is significantly reduced for solving the nsGLE to predict the non-equilibrium dynamics of the CG variable. To prove and exploit the equivalence of the nsGLE and extended dynamics, the memory kernel is parameterized in a two-time exponential expansion. A data-driven hybrid optimization process is proposed for the parameterization, a non-convex and high-dimensional optimization problem.",
        "published": "2021-03-18T17:10:13Z",
        "link": "http://arxiv.org/abs/2103.10381v2",
        "categories": [
            "cs.CE",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Model Order Reduction based on Direct Normal Form: Application to Large   Finite Element MEMS Structures Featuring Internal Resonance",
        "authors": [
            "Andrea Opreni",
            "Alessandra Vizzaccaro",
            "Attilio Frangi",
            "Cyril Touzé"
        ],
        "summary": "Dimensionality reduction in mechanical vibratory systems poses challenges for distributed structures including geometric nonlinearities, mainly because of the lack of invariance of the linear subspaces. A reduction method based on direct normal form computation for large finite element (FE) models is here detailed. The main advantage resides in operating directly from the physical space, hence avoiding the computation of the complete eigenfunctions spectrum. Explicit solutions are given, thus enabling a fully non-intrusive version of the reduction method. The reduced dynamics is obtained from the normal form of the geometrically nonlinear mechanical problem, free of non-resonant monomials, and truncated to the selected master coordinates, thus making a direct link with the parametrisation of invariant manifolds. The method is fully expressed with a complex-valued formalism by detailing the homological equations in a systematic manner, and the link with real-valued expressions is established. A special emphasis is put on the treatment of second-order internal resonances and the specific case of a 1:2 resonance is made explicit. Finally, applications to large-scale models of Micro-Electro-Mechanical structures featuring 1:2 and 1:3 resonances are reported, along with considerations on computational efficiency.",
        "published": "2021-03-18T22:14:22Z",
        "link": "http://arxiv.org/abs/2103.10545v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "math.DS"
        ]
    },
    {
        "title": "Transfer Learning of Memory Kernels in Coarse-grained Modeling",
        "authors": [
            "Zhan Ma",
            "Shu Wang",
            "Minhee Kim",
            "Kaibo Liu",
            "Chun-Long Chen",
            "Wenxiao Pan"
        ],
        "summary": "The present work concerns the transferability of coarse-grained (CG) modeling in reproducing the dynamic properties of the reference atomistic systems across a range of parameters. In particular, we focus on implicit-solvent CG modeling of polymer solutions. The CG model is based on the generalized Langevin equation, where the memory kernel plays the critical role in determining the dynamics in all time scales. Thus, we propose methods for transfer learning of memory kernels. The key ingredient of our methods is Gaussian process regression. By integration with the model order reduction via proper orthogonal decomposition and the active learning technique, the transfer learning can be practically efficient and requires minimum training data. Through two example polymer solution systems, we demonstrate the accuracy and efficiency of the proposed transfer learning methods in the construction of transferable memory kernels. The transferability allows for out-of-sample predictions, even in the extrapolated domain of parameters. Built on the transferable memory kernels, the CG models can reproduce the dynamic properties of polymers in all time scales at different thermodynamic conditions (such as temperature and solvent viscosity) and for different systems with varying concentrations and lengths of polymers.",
        "published": "2021-03-19T01:05:14Z",
        "link": "http://arxiv.org/abs/2103.10578v1",
        "categories": [
            "cs.CE",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Multicriteria asset allocation in practice",
        "authors": [
            "Kerstin Dächert",
            "Ria Grindel",
            "Elisabeth Leoff",
            "Jonas Mahnkopp",
            "Florian Schirra",
            "Jörg Wenzel"
        ],
        "summary": "In this paper we consider the strategic asset allocation of an insurance company. This task can be seen as a special case of portfolio optimization. In the 1950s, Markowitz proposed to formulate portfolio optimization as a bicriteria optimization problem considering risk and return as objectives. However, recent developments in the field of insurance require four and more objectives to be considered, among them the so-called solvency ratio that stems from the Solvency II directive of the European Union issued in 2009. Moreover, the distance to the current portfolio plays an important role. While literature on portfolio optimization with three objectives is already scarce, applications with four and more objectives have not yet been solved so far by multi-objective approaches based on scalarizations. However, recent algorithmic improvements in the field of exact multi-objective methods allow the incorporation of many objectives and the generation of well-spread representations within few iterations. We describe the implementation of such an algorithm for a strategic asset allocation with four objective functions and demonstrate its usefulness for the practitioner. Our approach is in operative use in a German insurance company. Our partners report a significant improvement in their decision making process since, due to the proper integration of the new objectives, the software proposes portfolios of much better quality than before within short running time.",
        "published": "2021-03-19T15:42:08Z",
        "link": "http://arxiv.org/abs/2103.10958v1",
        "categories": [
            "cs.CE",
            "q-fin.PM"
        ]
    },
    {
        "title": "Optimal Clearing Payments in a Financial Contagion Model",
        "authors": [
            "Giuseppe Calafiore",
            "Giulia Fracastoro",
            "Anton V. Proskurnikov"
        ],
        "summary": "Financial networks are characterized by complex structures of mutual obligations. These obligations are fulfilled entirely or in part (when defaults occur) via a mechanism called clearing, which determines a set of payments that settle the claims by respecting rules such as limited liability, absolute priority, and proportionality (pro-rated payments). In the presence of shocks on the financial system, however, the clearing mechanism may lead to cascaded defaults and eventually to financial disaster. In this paper, we first study the clearing model under pro-rated payments of Eisenberg and Noe, and we derive novel necessary and sufficient conditions for the uniqueness of the clearing payments, valid for an arbitrary topology of the financial network. Then, we argue that the proportionality rule is one of the factors responsible for cascaded defaults, and that the overall system loss can be reduced if this rule is lifted. The proposed approach thus shifts the focus from the individual interest to the overall system's interest to control and contain adverse effects of cascaded failures, and we show that clearing payments in this setting can be computed by solving suitable convex optimization problems.",
        "published": "2021-03-19T15:50:47Z",
        "link": "http://arxiv.org/abs/2103.10872v3",
        "categories": [
            "math.OC",
            "cs.CE",
            "q-fin.MF",
            "q-fin.RM"
        ]
    },
    {
        "title": "Parameterised-Response Zero-Intelligence Traders",
        "authors": [
            "Dave Cliff"
        ],
        "summary": "I introduce PRZI (Parameterised-Response Zero Intelligence), a new form of zero-intelligence trader intended for use in simulation studies of the dynamics of continuous double auction markets. Like Gode & Sunder's classic ZIC trader, PRZI generates quote-prices from a random distribution over some specified domain of allowable quote-prices. Unlike ZIC, which uses a uniform distribution to generate prices, the probability distribution in a PRZI trader is parameterised in such a way that its probability mass function (PMF) is determined by a real-valued control variable s in the range [-1.0, +1.0] that determines the _strategy_ for that trader. When s=0, a PRZI trader is identical to ZIC, with a uniform PMF; but when |s|=~1 the PRZI trader's PMF becomes maximally skewed to one extreme or the other of the price-range, thereby making its quote-prices more or less urgent, biasing the quote-price distribution toward or away from the trader's limit-price. To explore the co-evolutionary dynamics of populations of PRZI traders that dynamically adapt their strategies, I show results from long-term market experiments in which each trader uses a simple stochastic hill-climber algorithm to repeatedly evaluate alternative s-values and choose the most profitable at any given time. In these experiments the profitability of any particular s-value may be non-stationary because the profitability of one trader's strategy at any one time can depend on the mix of strategies being played by the other traders at that time, which are each themselves continuously adapting. Results from these market experiments demonstrate that the population of traders' strategies can exhibit rich dynamics, with periods of stability lasting over hundreds of thousands of trader interactions interspersed by occasional periods of change. Python source-code for the work reported here has been made publicly available on GitHub.",
        "published": "2021-03-21T08:43:39Z",
        "link": "http://arxiv.org/abs/2103.11341v7",
        "categories": [
            "q-fin.TR",
            "cs.CE",
            "cs.GT",
            "cs.MA",
            "econ.TH"
        ]
    },
    {
        "title": "Reduced basis methods for numerical room acoustic simulations with   parametrized boundaries",
        "authors": [
            "Hermes Sampedro Llopis",
            "Allan P. Engsig-Karup",
            "Cheol-Ho Jeong",
            "Finnur Pind",
            "Jan S. Hesthaven"
        ],
        "summary": "The use of model-based numerical simulation of wave propagation in rooms for engineering applications requires that acoustic conditions for multiple parameters are evaluated iteratively and this is computationally expensive. We present a reduced basis methods (RBM) to achieve a computational cost reduction relative to a traditional full order model (FOM), for wave-based room acoustic simulations with parametrized boundary conditions. In this study, the FOM solver is based on the spectral element method, however other numerical methods could be applied. The RBM reduces the computational burden by solving the problem in a low-dimensional subspace for parametrized frequency-independent and frequency-dependent boundary conditions. The problem is formulated and solved in the Laplace domain, which ensures the stability of the reduced order model based on the RBM approach. We study the potential of the proposed RBM framework in terms of computational efficiency, accuracy and storage requirements and we show that the RBM leads to 100-fold speed-ups for a 2D case with an upper frequency of 2kHz and around 1000-fold speed-ups for an analogous 3D case with an upper frequency of 1kHz. While the FOM simulations needed to construct the ROM are expensive, we demonstrate that despite this cost, the ROM has a potential of three orders of magnitude faster than the FOM when four different boundary conditions are simulated per room surface. Moreover, results show that the storage model for the ROM is relatively high but affordable for the presented 2D and 3D cases.",
        "published": "2021-03-22T11:13:21Z",
        "link": "http://arxiv.org/abs/2103.11730v2",
        "categories": [
            "cs.SD",
            "cs.CE",
            "eess.AS"
        ]
    },
    {
        "title": "A computational framework for modeling cell-matrix interactions in soft   biological tissues",
        "authors": [
            "Jonas F. Eichinger",
            "Maximilian J. Grill",
            "Iman Davoodi Kermani",
            "Roland C. Aydin",
            "Wolfgang A. Wall",
            "Jay D. Humphrey",
            "Christian J. Cyron"
        ],
        "summary": "Living soft tissues appear to promote the development and maintenance of a preferred mechanical state within a defined tolerance around a so-called set-point. This phenomenon is often referred to as mechanical homeostasis. In contradiction to the prominent role of mechanical homeostasis in various (patho)physiological processes, its underlying micromechanical mechanisms acting on the level of individual cells and fibers remain poorly understood, especially, how these mechanisms on the microscale lead to what we macroscopically call mechanical homeostasis. Here, we present a novel finite element based computational framework that is constructed bottom up, that is, it models key mechanobiological mechanisms such as actin cytoskeleton contraction and molecular clutch behavior of individual cells interacting with a reconstructed three-dimensional extracellular fiber matrix. The framework reproduces many experimental observations regarding mechanical homeostasis on short time scales (hours), in which the deposition and degradation of extracellular matrix can largely be neglected. This model can serve as a systematic tool for future in silico studies of the origin of the numerous still unexplained experimental observations about mechanical homeostasis.",
        "published": "2021-03-24T11:31:21Z",
        "link": "http://arxiv.org/abs/2103.13110v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Realistic Differentially-Private Transmission Power Flow Data Release",
        "authors": [
            "David Smith",
            "Frederik Geth",
            "Elliott Vercoe",
            "Andrew Feutrill",
            "Ming Ding",
            "Jonathan Chan",
            "James Foster",
            "Thierry Rakotoarivelo"
        ],
        "summary": "For the modeling, design and planning of future energy transmission networks, it is vital for stakeholders to access faithful and useful power flow data, while provably maintaining the privacy of business confidentiality of service providers. This critical challenge has recently been somewhat addressed in [1]. This paper significantly extends this existing work. First, we reduce the potential leakage information by proposing a fundamentally different post-processing method, using public information of grid losses rather than power dispatch, which achieve a higher level of privacy protection. Second, we protect more sensitive parameters, i.e., branch shunt susceptance in addition to series impedance (complete pi-model). This protects power flow data for the transmission high-voltage networks, using differentially private transformations that maintain the optimal power flow consistent with, and faithful to, expected model behaviour. Third, we tested our approach at a larger scale than previous work, using the PGLib-OPF test cases [10]. This resulted in the successful obfuscation of up to a 4700-bus system, which can be successfully solved with faithfulness of parameters and good utility to data analysts. Our approach addresses a more feasible and realistic scenario, and provides higher than state-of-the-art privacy guarantees, while maintaining solvability, fidelity and feasibility of the system.",
        "published": "2021-03-25T04:04:12Z",
        "link": "http://arxiv.org/abs/2103.14036v1",
        "categories": [
            "cs.CR",
            "cs.AI",
            "cs.CE"
        ]
    },
    {
        "title": "ReaDmE: Read-Rate Based Dynamic Execution Scheduling for Intermittent   RF-Powered Devices",
        "authors": [
            "Yang Su",
            "Damith C. Ranasinghe"
        ],
        "summary": "This paper presents a method for remotely and dynamically determining the execution schedule of long-running tasks on intermittently powered devices such as computational RFID. Our objective is to prevent brown-out events caused by sudden power-loss due to the intermittent nature of the powering channel. We formulate, validate and demonstrate that the read-rate measured from an RFID reader (number of successful interrogations per second) can provide an adequate means of estimating the powering channel condition for passively powered CRFID devices. This method is attractive because it can be implemented without imposing an added burden on the device or requiring additional hardware. We further propose ReaDmE, a dynamic execution scheduling scheme to mitigate brownout events to support long-run execution of complex tasks, such as cryptographic algorithms, on CRFID. Experimental results demonstrate that the ReaDmE method can improve CRFID's long-run execution success rate by 20% at the critical operational range or reduce time overhead by up to 23% compared to previous execution scheduling methods.",
        "published": "2021-03-26T11:22:56Z",
        "link": "http://arxiv.org/abs/2103.14404v2",
        "categories": [
            "cs.PF",
            "cs.CE"
        ]
    },
    {
        "title": "A Novel $p$-Harmonic Descent Approach Applied to Fluid Dynamic Shape   Optimization",
        "authors": [
            "Peter Marvin Müller",
            "Niklas Kühl",
            "Martin Siebenborn",
            "Klaus Deckelnick",
            "Michael Hinze",
            "Thomas Rung"
        ],
        "summary": "We introduce a novel method for the implementation of shape optimziation in fluid dynamics applications, where we propose to use the shape derivative to determine deformation fields with the help of the $p-$ Laplacian for $p > 2$. This approach is closely related to the computation of steepest descent directions of the shape functional in the $W^{1,\\infty}-$ topology. Our approach is demonstrated for shape optimization related to drag-minimal free floating bodies. The method is validated against existing approaches with respect to convergence of the optimization algorithm, the obtained shape, and regarding the quality of the computational grid after large deformations. Our numerical results strongly indicate that shape optimization related to the $W^{1,\\infty}$-topology -- though numerically more demanding -- seems to be superior over the classical approaches invoking Hilbert space methods, concerning the convergence, the obtained shapes and the mesh quality after large deformations, in particular when the optimal shape features sharp corners.",
        "published": "2021-03-26T21:06:35Z",
        "link": "http://arxiv.org/abs/2103.14735v1",
        "categories": [
            "math.OC",
            "cs.CE",
            "35Q93, 49Q10, 35R30, 49K20"
        ]
    },
    {
        "title": "Deep Hedging of Derivatives Using Reinforcement Learning",
        "authors": [
            "Jay Cao",
            "Jacky Chen",
            "John Hull",
            "Zissis Poulos"
        ],
        "summary": "This paper shows how reinforcement learning can be used to derive optimal hedging strategies for derivatives when there are transaction costs. The paper illustrates the approach by showing the difference between using delta hedging and optimal hedging for a short position in a call option when the objective is to minimize a function equal to the mean hedging cost plus a constant times the standard deviation of the hedging cost. Two situations are considered. In the first, the asset price follows a geometric Brownian motion. In the second, the asset price follows a stochastic volatility process. The paper extends the basic reinforcement learning approach in a number of ways. First, it uses two different Q-functions so that both the expected value of the cost and the expected value of the square of the cost are tracked for different state/action combinations. This approach increases the range of objective functions that can be used. Second, it uses a learning algorithm that allows for continuous state and action space. Third, it compares the accounting P&L approach (where the hedged position is valued at each step) and the cash flow approach (where cash inflows and outflows are used). We find that a hybrid approach involving the use of an accounting P&L approach that incorporates a relatively simple valuation model works well. The valuation model does not have to correspond to the process assumed for the underlying asset price.",
        "published": "2021-03-29T07:43:30Z",
        "link": "http://arxiv.org/abs/2103.16409v1",
        "categories": [
            "q-fin.CP",
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "A thermodynamic framework for unified continuum models for the healing   of damaged soft biological tissue",
        "authors": [
            "Di Zuo",
            "Yiqian He",
            "Stéphane Avril",
            "Haitian Yang",
            "Klaus Hackl"
        ],
        "summary": "When they are damaged or injured, soft biological tissues are able to self-repair and heal. Mechanics is critical during the healing process, as the damaged extracellular matrix (ECM) tends to be replaced with a new undamaged ECM supporting homeostatic stresses. Computational modeling has been commonly used to simulate the healing process. However, there is a pressing need to have a unified thermodynamics theory for healing. From the viewpoint of continuum damage mechanics, some key parameters related to healing processes, for instance, the volume fraction of newly grown soft tissue and the growth deformation, can be regarded as internal variables and have related evolution equations. This paper is aiming to establish this unified framework inspired by thermodynamics for continuum damage models for the healing of soft biological tissues. The significant advantage of the proposed model is that no \\textit{ad hoc} equations are required for describing the healing process. Therefore, this new model is more concise and offers a universal approach to simulate the healing process. Three numerical examples are provided to demonstrate the effectiveness of the proposed model, which is in good agreement with the existing works, including an application for balloon angioplasty in an arteriosclerotic artery with a fiber cap.",
        "published": "2021-03-29T10:34:25Z",
        "link": "http://arxiv.org/abs/2103.15481v1",
        "categories": [
            "cs.CE",
            "physics.med-ph"
        ]
    },
    {
        "title": "Geometrically exact static isogeometric analysis of arbitrarily curved   plane Bernoulli-Euler beam",
        "authors": [
            "A. Borković",
            "B. Marussig",
            "G. Radenković"
        ],
        "summary": "We present a geometrically exact nonlinear analysis of elastic in-plane beams in the context of finite but small strain theory. The formulation utilizes the full beam metric and obtains the complete analytic elastic constitutive model by employing the exact relation between the reference and equidistant strains. Thus, we account for the nonlinear strain distribution over the thickness of a beam. In addition to the full analytical constitutive model, four simplified ones are presented. Their comparison provides a thorough examination of the influence of a beam's metric on the structural response. We show that the appropriate formulation depends on the curviness of a beam at all configurations. Furthermore, the nonlinear distribution of strain along the thickness of strongly curved beams must be considered to obtain a complete and accurate response.",
        "published": "2021-03-29T10:51:20Z",
        "link": "http://arxiv.org/abs/2103.15493v1",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Mixed-precision for Linear Solvers in Global Geophysical Flows",
        "authors": [
            "Jan Ackmann",
            "Peter D. Düben",
            "Tim N. Palmer",
            "Piotr K. Smolarkiewicz"
        ],
        "summary": "Semi-implicit time-stepping schemes for atmosphere and ocean models require elliptic solvers that work efficiently on modern supercomputers. This paper reports our study of the potential computational savings when using mixed precision arithmetic in the elliptic solvers. The essential components of a representative elliptic solver are run at precision levels as low as half (16 bits), and accompanied with a detailed evaluation of the impact of reduced precision on the solver convergence and the solution quality.   A detailed inquiry into reduced precision requires a model configuration that is meaningful but cheaper to run and easier to evaluate than full atmosphere/ocean models. This study is therefore conducted in the context of a novel semi-implicit shallow-water model on the sphere, purposely designed to mimic numerical intricacies of modern all-scale weather and climate (W&C) models with the numerical stability independent on celerity of all wave motions. The governing algorithm of the shallow-water model is based on the non-oscillatory MPDATA methods for geophysical flows, whereas the resulting elliptic problem employs a strongly preconditioned non-symmetric Krylov-subspace solver GCR, proven in advanced atmospheric applications. The classical longitude/latitude grid is deliberately chosen to retain the stiffness of global W&C models posed in thin spherical shells as well as to better understand the performance of reduced-precision arithmetic in the vicinity of grid singularities. Precision reduction is done on a software level, using an emulator. The reduced-precision experiments are conducted for established dynamical-core test-cases, like the Rossby-Haurwitz wave number 4 and a zonal orographic flow.   The study shows that selected key components of the elliptic solver, most prominently the preconditioning, can be performed at the level of half precision.",
        "published": "2021-03-30T07:11:26Z",
        "link": "http://arxiv.org/abs/2103.16120v1",
        "categories": [
            "physics.comp-ph",
            "cs.CE",
            "cs.NA",
            "math.NA",
            "physics.ao-ph",
            "physics.flu-dyn"
        ]
    },
    {
        "title": "Adaptive surrogates of crashworthiness models for multi-purpose   engineering analyses accounting for uncertainty",
        "authors": [
            "Marc Rocas",
            "Alberto García-González",
            "Xabier Larrayoz",
            "Pedro Díez"
        ],
        "summary": "Uncertainty Quantification (UQ) is a booming discipline for complex computational models based on the analysis of robustness, reliability and credibility. UQ analysis for nonlinear crash models with high dimensional outputs presents important challenges. In crashworthiness, nonlinear structural behaviours with multiple hidden modes require expensive models (18 hours for a single run). Surrogate models (metamodels) allow substituting the full order model, introducing a response surface for a reduced training set of numerical experiments. Moreover, uncertain input and large number of degrees of freedom result in high dimensional problems, which derives to a bottle neck that blocks the computational efficiency of the metamodels. Kernel Principal Component Analysis (kPCA) is a multidimensionality reduction technique for non-linear problems, with the advantage of capturing the most relevant information from the response and improving the efficiency of the metamodel. Aiming to compute the minimum number of samples with the full order model. The proposed methodology is tested with a practical industrial problem that arises from the automotive industry.",
        "published": "2021-03-30T09:36:09Z",
        "link": "http://arxiv.org/abs/2103.16202v1",
        "categories": [
            "cs.CE",
            "60H35, 62-08"
        ]
    },
    {
        "title": "FastCTF: A Robust Solver for Conduction Transfer Function Coefficients   and Thermal Response Factors",
        "authors": [
            "Khodr Jaber"
        ],
        "summary": "Conduction transfer functions (CTF) are commonly used in the building services to quickly estimate hourly conduction heat loads through multilayered walls without resorting to expensive, time-consuming solutions of the heat equation. It is essential for any software developed for this purpose to be able to simulate walls of varying weight with a high degree of accuracy. A robust algorithm for computing CTF coefficients and thermal response factors based on power series expansions of solutions of the governing equations in the complex s-domain is presented and validated. These series expansions are used to to construct Pad\\'e approximants of the system's transfer functions, which greatly simplifies the inversion of the solution from the complex domain to the time domain, and allows for an easy recovery of a time series representation via the Z-transform. The algorithm is also implemented in an open-source C++ code. Its performance is validated with respect to exact theoretical frequency characteristics and its results are compared with data generated by previously established methods for computing CTF coefficients / response factors.",
        "published": "2021-03-30T13:03:36Z",
        "link": "http://arxiv.org/abs/2103.16312v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Lipschitz regularization for softening material models: the Lip-field   approach",
        "authors": [
            "Nicolas Moes",
            "Nicolas Chevaugeon"
        ],
        "summary": "Softening material models are known to trigger spurious localizations.This may be shown theoretically by the existence of solutions with zero dissipation when localization occurs and numerically with spurious mesh dependency and localization in a single layer of elements. We introduce in this paper a new way to avoid spurious localization. The idea is to enforce a Lipschitz regularity on the internal variables responsible for the material softening. The regularity constraint introduces the needed length scale in the material formulation. Moreover, we prove bounds on the domain affected by this constraint. A first one-dimensional finite element implementation is proposed for softening elasticity and softening plasticity.",
        "published": "2021-03-30T13:43:05Z",
        "link": "http://arxiv.org/abs/2103.16345v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "On the space-time discretization of variational retarded potential   boundary integral equations",
        "authors": [
            "Dominik Pölz",
            "Martin Schanz"
        ],
        "summary": "This paper discusses the practical development of space-time boundary element methods for the wave equation in three spatial dimensions. The employed trial spaces stem from simplex meshes of the lateral boundary of the space-time cylinder. This approach conforms genuinely to the distinguished structure of the solution operators of the wave equation, so-called retarded potentials. Since the numerical evaluation of the arising integrals is intricate, the bulk of this work is constituted by ideas about quadrature techniques for retarded layer potentials and associated energetic bilinear forms. Finally, we glimpse at algorithmic aspects regarding the efficient implementation of retarded potentials in the space-time setting. The proposed methods are verified by means of numerical experiments, which illustrate their capacity.",
        "published": "2021-03-31T06:48:52Z",
        "link": "http://arxiv.org/abs/2103.16841v2",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "35L05, 65M38, 65R20"
        ]
    },
    {
        "title": "The Homogenous Properties of Automated Market Makers",
        "authors": [
            "Johannes Rude Jensen",
            "Mohsen Pourpouneh",
            "Kurt Nielsen",
            "Omri Ross"
        ],
        "summary": "Automated market makers (AMM) have grown to obtain significant market share within the cryptocurrency ecosystem, resulting in a proliferation of new products pursuing exotic strategies for horizontal differentiation. Yet, their theoretical properties are curiously homogeneous when a set of basic assumptions are met. In this paper, we start by presenting a universal approach to deriving a formula for liquidity provisioning for AMMs. Next, we show that the constant function market maker and token swap market maker models are theoretically equivalent when liquidity reserves are uniform. Proceeding with an examination of AMM market microstructure, we show how non-linear price effect translates into slippage for traders and impermanent losses for liquidity providers. We proceed by showing how impermanent losses are a function of both volatility and market depth and discuss the implications of these findings within the context of the literature.",
        "published": "2021-03-31T09:39:10Z",
        "link": "http://arxiv.org/abs/2105.02782v1",
        "categories": [
            "q-fin.TR",
            "cs.CE"
        ]
    },
    {
        "title": "Physics-Based Modeling and Predictive Simulation of Powder Bed Fusion   Additive Manufacturing Across Length Scales",
        "authors": [
            "Christoph Meier",
            "Sebastian L. Fuchs",
            "Nils Much",
            "Jonas Nitzler",
            "Ryan W. Penny",
            "Patrick M. Praegla",
            "Sebastian D. Pröll",
            "Yushen Sun",
            "Reimar Weissbach",
            "Magdalena Schreter",
            "Neil E. Hodge",
            "A. John Hart",
            "Wolfgang A. Wall"
        ],
        "summary": "Powder bed fusion additive manufacturing (PBFAM) of metals has the potential to enable new paradigms of product design, manufacturing and supply chains while accelerating the realization of new technologies in the medical, aerospace, and other industries. Currently, wider adoption of PBFAM is held back by difficulty in part qualification, high production costs and low production rates, as extensive process tuning, post-processing, and inspection are required before a final part can be produced and deployed. Physics-based modeling and predictive simulation of PBFAM offers the potential to advance fundamental understanding of physical mechanisms that initiate process instabilities and cause defects. In turn, these insights can help link process and feedstock parameters with resulting part and material properties, thereby predicting optimal processing conditions and inspiring the development of improved processing hardware, strategies and materials. This work presents recent developments of our research team in the modeling of metal PBFAM processes spanning length scales, namely mesoscale powder modeling, mesoscale melt pool modeling, macroscale thermo-solid-mechanical modeling and microstructure modeling. Ongoing work in experimental validation of these models is also summarized. In conclusion, we discuss the interplay of these individual submodels within an integrated overall modeling approach, along with future research directions.",
        "published": "2021-03-31T11:00:04Z",
        "link": "http://arxiv.org/abs/2103.16982v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "PySDM v1: particle-based cloud modelling package for warm-rain   microphysics and aqueous chemistry",
        "authors": [
            "Piotr Bartman",
            "Oleksii Bulenok",
            "Kamil Górski",
            "Anna Jaruga",
            "Grzegorz Łazarski",
            "Michael Olesik",
            "Bartosz Piasecki",
            "Clare E. Singer",
            "Aleksandra Talar",
            "Sylwester Arabas"
        ],
        "summary": "PySDM is an open-source Python package for simulating the dynamics of particles undergoing condensational and collisional growth, interacting with a fluid flow and subject to chemical composition changes. It is intended to serve as a building block for process-level as well as computational-fluid-dynamics simulation systems involving representation of a continuous phase (air) and a dispersed phase (aerosol), with PySDM being responsible for representation of the dispersed phase. The PySDM package core is a Pythonic high-performance implementation of the Super-Droplet Method (SDM) Monte-Carlo algorithm for representing collisional growth, hence the name. PySDM has two alternative parallel number-crunching backends available: multi-threaded CPU backend based on Numba and GPU-resident backend built on top of ThrustRTC. The usage examples are built on top of four simple atmospheric cloud modelling frameworks: box, adiabatic parcel, single-column and 2D prescribed flow kinematic models. In addition, the package ships with tutorial code depicting how PySDM can be used from Julia and Matlab.",
        "published": "2021-03-31T17:37:09Z",
        "link": "http://arxiv.org/abs/2103.17238v2",
        "categories": [
            "physics.ao-ph",
            "cs.CE"
        ]
    },
    {
        "title": "An efficient 146-line 3D sensitivity analysis code of stress-based   topology optimization written in MATLAB",
        "authors": [
            "Hao Deng",
            "Praveen S. Vulimiri",
            "Albert C. To"
        ],
        "summary": "This paper presents an efficient and compact MATLAB code for three-dimensional stress-based sensitivity analysis. The 146 lines code includes the finite element analysis and p-norm stress sensitivity analysis based on the adjoint method. The 3D sensitivity analysis for p-norm global stress measure is derived and explained in detail accompanied by corresponding MATLAB code. The correctness of the analytical sensitivity is verified by comparison with finite difference approximation. The nonlinear optimization solver is chosen as the Method of moving asymptotes (MMA). Three typical volume-constrained stress minimization problems are presented to verify the effectiveness of sensitivity analysis code. The MATLAB code presented in this paper can be extended to resolve different stress related 3D topology optimization problems. The complete program for sensitivity analysis is given in the Appendix and is intended for educational purposes only.",
        "published": "2021-04-02T19:18:38Z",
        "link": "http://arxiv.org/abs/2104.01210v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Homogenization of the vibro-acoustic transmission on periodically   perforated elastic plates with arrays of resonators",
        "authors": [
            "Eduard Rohan",
            "Vladimír Lukeš"
        ],
        "summary": "Based on our previous work, we propose a homogenized model of acoustic waves propagating through periodically perforated elastic plates with metamaterial properties due to embedded arrays of soft elastic inclusions serving for resonators. Such structures enable to suppress the acoustic transmission for selected frequency bands. Homogenization of the vibro-acoustic fluid-structure interaction problem in a 3D complex geometry of the transmission layer leads to effective transmission conditions prescribed on the acoustic meta-surface associated with the mid-plane of the Reissner-Mindlin plate. Asymptotic analysis with respect to the layer thickness, proportional to the plate thickness and to the perforation period, yields an implicit Dirichlet-to-Neumann operator defined on the homogenized metasurface. An efficient method is proposed for computing frequency-dependent effective parameters involved in the homogenized model of the layer. These can change their signs, thus modifying the acoustic impedance and the effective mass of the metasurface. The global problem of the acoustic wave propagation in a waveguide fitted with the plate is solved using the finite element method. The homogenized interface allows for a significant reduction of the computational model. Numerical illustrations are presented.",
        "published": "2021-04-03T10:12:24Z",
        "link": "http://arxiv.org/abs/2104.01367v1",
        "categories": [
            "physics.comp-ph",
            "cs.CE",
            "cs.NA",
            "math.AP",
            "math.NA",
            "35B27, 74Q05, 74F10"
        ]
    },
    {
        "title": "Semi matrix-free twogrid shifted Laplacian preconditioner for the   Helmholtz equation with near optimal shifts",
        "authors": [
            "Daniel Drzisga",
            "Tobias Köppl",
            "Barbara Wohlmuth"
        ],
        "summary": "Due to its significance in terms of wave phenomena a considerable effort has been put into the design of preconditioners for the Helmholtz equation. One option to derive a preconditioner is to apply a multigrid method on a shifted operator. In such an approach, the wavenumber is shifted by some imaginary value. This step is motivated by the observation that the shifted problem can be more efficiently handled by iterative solvers when compared to the standard Helmholtz equation. However, up to now, it is not obvious what the best strategy for the choice of the shift parameter is. It is well known that a good shift parameter depends sensitively on the wavenumber and the discretization parameters such as the order and the mesh size. Therefore, we study the choice of a near optimal complex shift such that an FGMRES solver converges with fewer iterations. Our goal is to provide a map which returns the near optimal shift for the preconditioner depending on the wavenumber and the mesh size. In order to compute this map, a data driven approach is considered: We first generate many samples, and in a second step, we perform a nonlinear regression on this data. With this representative map, the near optimal shift can be obtained by a simple evaluation. Our preconditioner is based on a twogrid V-cycle applied to the shifted problem, allowing us to implement a semi matrix-free method. The performance of our preconditioned FGMRES solver is illustrated by several benchmark problems with heterogeneous wavenumbers in two and three space dimensions.",
        "published": "2021-04-03T16:12:14Z",
        "link": "http://arxiv.org/abs/2104.01439v1",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Principal Component Analysis Applied to Gradient Fields in Band Gap   Optimization Problems for Metamaterials",
        "authors": [
            "Giorgio Gnecco",
            "Andrea Bacigalupo",
            "Francesca Fantoni",
            "Daniela Selvi"
        ],
        "summary": "A promising technique for the spectral design of acoustic metamaterials is based on the formulation of suitable constrained nonlinear optimization problems. Unfortunately, the straightforward application of classical gradient-based iterative optimization algorithms to the numerical solution of such problems is typically highly demanding, due to the complexity of the underlying physical models. Nevertheless, supervised machine learning techniques can reduce such a computational effort, e.g., by replacing the original objective functions of such optimization problems with more-easily computable approximations. In this framework, the present article describes the application of a related unsupervised machine learning technique, namely, principal component analysis, to approximate the gradient of the objective function of a band gap optimization problem for an acoustic metamaterial, with the aim of making the successive application of a gradient-based iterative optimization algorithm faster. Numerical results show the effectiveness of the proposed method.",
        "published": "2021-04-04T11:13:37Z",
        "link": "http://arxiv.org/abs/2104.02588v6",
        "categories": [
            "cs.CE",
            "cs.LG",
            "cs.SD",
            "eess.AS"
        ]
    },
    {
        "title": "AuTO: A Framework for Automatic differentiation in Topology Optimization",
        "authors": [
            "Aaditya Chandrasekhar",
            "Saketh Sridhara",
            "Krishnan Suresh"
        ],
        "summary": "A critical step in topology optimization (TO) is finding sensitivities. Manual derivation and implementation of the sensitivities can be quite laborious and error-prone, especially for non-trivial objectives, constraints and material models. An alternate approach is to utilize automatic differentiation (AD). While AD has been around for decades, and has also been applied in TO, wider adoption has largely been absent.   In this educational paper, we aim to reintroduce AD for TO, and make it easily accessible through illustrative codes. In particular, we employ JAX, a high-performance Python library for automatically computing sensitivities from a user defined TO problem. The resulting framework, referred to here as AuTO, is illustrated through several examples in compliance minimization, compliant mechanism design and microstructural design.",
        "published": "2021-04-05T15:36:17Z",
        "link": "http://arxiv.org/abs/2104.01965v1",
        "categories": [
            "cs.MS",
            "cs.CE",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Simultaneous reconstruction of conductivity, boundary shape and contact   impedances in electrical impedance tomography",
        "authors": [
            "J. P. Agnelli",
            "V. Kolehmainen",
            "M. Lassas",
            "P. Ola",
            "S. Siltanen"
        ],
        "summary": "The objective of electrical impedance tomography (EIT) is to reconstruct the internal conductivity of a physical body based on current and voltage measurements at the boundary of the body. In many medical applications the exact shape of the domain boundary and contact impedances are not available. This is problematic as even small errors in the boundary shape of the computation domain or in the contact impedance values can produce large artifacts in the reconstructed images which results in a loss of relevant information. A method is proposed that simultaneously reconstructs the conductivity, the contact impedances and the boundary shape from EIT data. The approach consists of three steps: first, the unknown contact impedances and an anisotropic conductivity reproducing the measured EIT data in a model domain are computed. Second, using isothermal coordinates, a deformation is constructed that makes the conductivity isotropic. The final step minimizes the error of true and reconstructed known geometric properties (like the electrode lengths) using conformal deformations. The feasibility of the method is illustrated with experimental EIT data, with robust and accurate reconstructions of both conductivity and boundary shape.",
        "published": "2021-04-05T17:46:15Z",
        "link": "http://arxiv.org/abs/2104.02043v2",
        "categories": [
            "math.OC",
            "cs.CE",
            "35R30, 65N21, 65J20, 30C35"
        ]
    },
    {
        "title": "Hyperloop System Optimization",
        "authors": [
            "Philippe Kirschen",
            "Edward Burnell"
        ],
        "summary": "Hyperloop system design is a uniquely coupled problem because it involves the simultaneous design of a complex, high-performance vehicle and its accompanying infrastructure. In the clean-sheet design of this new mode of high-speed mass transportation there is an excellent opportunity for the application of rigorous system optimization techniques. This work presents a system optimization tool, HOPS, that has been adopted as a central component of the Virgin Hyperloop design process. We discuss the choice of objective function, the use of a convex optimization technique called geometric programming, and the level of modeling fidelity that has allowed us to capture the system's many intertwined, and often recursive, design relationships. We also highlight the ways in which the tool has been used. Because organizational confidence in a model is as vital as its technical merit, we close with discussion of the measures taken to build stakeholder trust in HOPS.",
        "published": "2021-04-06T04:08:57Z",
        "link": "http://arxiv.org/abs/2104.03907v3",
        "categories": [
            "cs.CE",
            "math.OC"
        ]
    },
    {
        "title": "Hybrid QSS and Dynamic Extended-Term Simulation Based on Holomorphic   Embedding",
        "authors": [
            "Rui Yao",
            "Feng Qiu"
        ],
        "summary": "Power system simulations that extend over a time period of minutes, hours, or even longer are called extended-term simulations. As power systems evolve into complex systems with increasing interdependencies and richer dynamic behaviors across a wide range of timescales, extended-term simulation is needed for many power system analysis tasks (e.g., resilience analysis, renewable energy integration, cascading failures), and there is an urgent need for efficient and robust extended-term simulation approaches. The conventional approaches are insufficient for dealing with the extended-term simulation of multi-timescale processes. This paper proposes an extended-term simulation approach based on the holomorphic embedding (HE) methodology. Its accuracy and computational efficiency are backed by HE's high accuracy in event-driven simulation, larger and adaptive time steps, and flexible switching between full-dynamic and quasi-steady-state (QSS) models. We used this proposed extended-term simulation approach to evaluate bulk power system restoration plans, and it demonstrates satisfactory accuracy and efficiency in this complex simulation task.",
        "published": "2021-04-07T03:01:32Z",
        "link": "http://arxiv.org/abs/2104.02877v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Finite Variation Sensitivity Analysis for Discrete Topology Optimization   of Continuum Structures",
        "authors": [
            "Daniel Candeloro Cunha",
            "Breno Vincenzo de Almeida",
            "Heitor Nigro Lopes",
            "Renato Pavanello"
        ],
        "summary": "This paper proposes two novel approaches to perform more suitable sensitivity analyses for discrete topology optimization methods. To properly support them, we introduce a more formal description of the Bi-directional Evolutionary Structural Optimization (BESO) method, in which the sensitivity analysis is based on finite variations of the objective function. The proposed approaches are compared to a naive strategy; to the conventional strategy, referred to as First-Order Continuous Interpolation (FOCI) approach; and to a strategy previously developed by other researchers, referred to as High-Order Continuous Interpolation (HOCI) approach. The novel Woodbury approach provides exact sensitivity values and is a better alternative to HOCI. Although HOCI and Woodbury approaches may be computationally prohibitive, they provide useful expressions for a better understanding of the problem. The novel Conjugate Gradient Method (CGM) approach provides sensitivity values with arbitrary precision and is computationally viable for a small number of steps. The CGM approach is a better alternative to FOCI since, for appropriate initial conditions, it is always more accurate than the conventional strategy. The standard compliance minimization problem with volume constraint is considered to illustrate the methodology. Numerical examples are presented together with a broad discussion about BESO-type methods.",
        "published": "2021-04-07T18:22:50Z",
        "link": "http://arxiv.org/abs/2104.04571v2",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA",
            "math.OC"
        ]
    },
    {
        "title": "Displacement-Driven Approach to Nonlocal Elasticity",
        "authors": [
            "Sansit Patnaik",
            "Sai Sidhardh",
            "Fabio Semperlotti"
        ],
        "summary": "This study presents a physically consistent displacement-driven reformulation of the concept of action-at-a-distance, which is at the foundation of nonlocal elasticity. In contrast to existing approaches that adopts an integral stress-strain constitutive relation, the displacement-driven approach is predicated on an integral strain-displacement relation. The most remarkable consequence of this reformulation is that the (total) strain energy is guaranteed to be convex and positive-definite without imposing any constraint on the symmetry of the kernels. This feature is critical to enable the application of nonlocal formulations to general continua exhibiting asymmetric interactions; ultimately a manifestation of material heterogeneity. Remarkably, the proposed approach also enables a strong satisfaction of the locality recovery condition and of the laws of thermodynamics, which are not foregone conclusions in most classical nonlocal elasticity theories. Additionally, the formulation is frame-invariant and the nonlocal operator remains physically consistent at boundaries. The study is complemented by a detailed analysis of the dynamic response of the nonlocal continuum and of its intrinsic dispersion leading to the consideration that the choice of nonlocal kernels should depend on the specific material. Examples of exponential or power-law kernels are presented in order to demonstrate the applicability of the method to different classes of nonlocal media. The ability to admit generalized kernels reinforces the generalized nature of the displacement-driven approach over existing integral methodologies, which typically lead to simplified differential models based on exponential kernels. The theoretical formulation is also leveraged to simulate the static response of nonlocal beams and plates illustrating the intrinsic consistency of the approach, which is free from unwanted boundary effects.",
        "published": "2021-04-08T00:28:12Z",
        "link": "http://arxiv.org/abs/2104.05818v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "physics.app-ph"
        ]
    },
    {
        "title": "A unified Abaqus implementation of the phase field fracture method using   only a user material subroutine",
        "authors": [
            "Yousef Navidtehrani",
            "Covadonga Betegón",
            "Emilio Martínez-Pañeda"
        ],
        "summary": "We present a simple and robust implementation of the phase field fracture method in Abaqus. Unlike previous works, only a user material (UMAT) subroutine is used. This is achieved by exploiting the analogy between the phase field balance equation and heat transfer, which avoids the need for a user element mesh and enables taking advantage of Abaqus' in-built features. A unified theoretical framework and its implementation are presented, suitable for any arbitrary choice of crack density function and fracture driving force. Specifically, the framework is exemplified with the so-called AT1, AT2 and phase field-cohesive zone models (PF-CZM). Both staggered and monolithic solution schemes are handled. We demonstrate the potential and robustness of this new implementation by addressing several paradigmatic 2D and 3D boundary value problems. The numerical examples show how the current implementation can be used to reproduce numerical and experimental results from the literature, and efficiently capture advanced features such as complex crack trajectories, crack nucleation from arbitrary sites and contact problems. The code developed can be downloaded from www.empaneda.com/codes.",
        "published": "2021-04-08T10:07:52Z",
        "link": "http://arxiv.org/abs/2104.04152v1",
        "categories": [
            "cs.CE",
            "cond-mat.mtrl-sci",
            "physics.app-ph"
        ]
    },
    {
        "title": "Residual Gaussian Process: A Tractable Nonparametric Bayesian Emulator   for Multi-fidelity Simulations",
        "authors": [
            "Wei W. Xing",
            "Akeel A. Shah",
            "Peng Wang",
            "Shandian Zhe Qian Fu",
            "Robert. M. Kirby"
        ],
        "summary": "Challenges in multi-fidelity modeling relate to accuracy, uncertainty estimation and high-dimensionality. A novel additive structure is introduced in which the highest fidelity solution is written as a sum of the lowest fidelity solution and residuals between the solutions at successive fidelity levels, with Gaussian process priors placed over the low fidelity solution and each of the residuals. The resulting model is equipped with a closed-form solution for the predictive posterior, making it applicable to advanced, high-dimensional tasks that require uncertainty estimation. Its advantages are demonstrated on univariate benchmarks and on three challenging multivariate problems. It is shown how active learning can be used to enhance the model, especially with a limited computational budget. Furthermore, error bounds are derived for the mean prediction in the univariate case.",
        "published": "2021-04-08T12:57:46Z",
        "link": "http://arxiv.org/abs/2104.03743v1",
        "categories": [
            "cs.LG",
            "cs.CE",
            "stat.AP"
        ]
    },
    {
        "title": "Improving Solar Cell Metallization Designs using Convolutional Neural   Networks",
        "authors": [
            "Sumit Bhattacharya",
            "Devanshu Arya",
            "Debjani Bhowmick",
            "Rajat Mani Thomas",
            "Deepak Kumar Gupta"
        ],
        "summary": "Optimizing the design of solar cell metallizations is one of the ways to improve the performance of solar cells. Recently, it has been shown that Topology Optimization (TO) can be used to design complex metallization patterns for solar cells that lead to improved performance. TO generates unconventional design patterns that cannot be obtained with the traditional shape optimization methods. In this paper, we show that this design process can be improved further using a deep learning inspired strategy. We present SolarNet, a CNN-based reparameterization scheme that can be used to obtain improved metallization designs. SolarNet modifies the optimization domain such that rather than optimizing the electrode material distribution directly, the weights of a CNN model are optimized. The design generated by CNN is then evaluated using the physics equations, which in turn generates gradients for backpropagation. SolarNet is trained end-to-end involving backpropagation through the solar cell model as well as the CNN pipeline. Through application on solar cells of different shapes as well as different busbar geometries, we demonstrate that SolarNet improves the performance of solar cells compared to the traditional TO approach.",
        "published": "2021-04-08T19:24:45Z",
        "link": "http://arxiv.org/abs/2104.04017v1",
        "categories": [
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "Laplace-Beltrami based Multi-Resolution Shape Reconstruction on   Subdivision Surfaces",
        "authors": [
            "A. M. A. Alsnayyan",
            "B. Shanker"
        ],
        "summary": "The eigenfunctions of the Laplace-Beltrami operator have widespread applications in a number of disciplines of engineering, computer vision/graphics, machine learning, etc. These eigenfunctions or manifold harmonics, provide the means to smoothly interpolate data on a manifold. They are highly effective, specifically as it relates to geometry representation and editing; manifold harmonics form a natural basis for multi-resolution representation (and editing) of complex surfaces and functioned defined therein. In this paper, we seek to develop the framework to exploit the benefits of manifold harmonics for shape reconstruction. To this end, we develop a highly compressible, multi-resolution shape reconstruction scheme using manifold harmonics. The method relies on subdivision basis sets to construct both boundary element isogeometric methods for analysis and surface finite elements to construct manifold harmonics. We pair this technique with the volumetric source reconstruction method to determine an initial starting point. Examples presented highlight efficacy of the approach in the presence of noisy data, including significant reduction in the number of degrees of freedom for complex objects, the accuracy of reconstruction, and multi-resolution capabilities.",
        "published": "2021-04-08T19:56:19Z",
        "link": "http://arxiv.org/abs/2104.04027v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "The virtual element method for the coupled system of   magneto-hydrodynamics",
        "authors": [
            "Sebastian Naranjo-Alvarez",
            "Vrushali Bokil",
            "Vitaliy Gyrya",
            "Gianmarco Manzini"
        ],
        "summary": "In this work, we review the framework of the Virtual Element Method (VEM) for a model in magneto-hydrodynamics (MHD), that incorporates a coupling between electromagnetics and fluid flow, and allows us to construct novel discretizations for simulating realistic phenomenon in MHD. First, we study two chains of spaces approximating the electromagnetic and fluid flow components of the model. Then, we show that this VEM approximation will yield divergence free discrete magnetic fields, an important property in any simulation in MHD. We present a linearization strategy to solve the VEM approximation which respects the divergence free condition on the magnetic field. This linearization will require that, at each non-linear iteration, a linear system be solved. We study these linear systems and show that they represent well-posed saddle point problems. We conclude by presenting numerical experiments exploring the performance of the VEM applied to the subsystem describing the electromagnetics. The first set of experiments provide evidence regarding the speed of convergence of the method as well as the divergence-free condition on the magnetic field. In the second set we present a model for magnetic reconnection in a mesh that includes a series of hanging nodes, which we use to calibrate the resolution of the method. The magnetic reconnection phenomenon happens near the center of the domain where the mesh resolution is finer and high resolution is achieved.",
        "published": "2021-04-08T22:07:36Z",
        "link": "http://arxiv.org/abs/2104.04096v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "What do cells regulate in soft tissues on short time scales?",
        "authors": [
            "Jonas F. Eichinger",
            "Daniel Paukner",
            "Roland C. Aydin",
            "Wolfgang A. Wall",
            "Jay D. Humphrey",
            "Christian J. Cyron"
        ],
        "summary": "Cells within living soft biological tissues seem to promote the maintenance of a mechanical state within a defined range near a so-called set-point. This mechanobiological process is often referred to as mechanical homeostasis. During this process, cells intimately interact with the fibers of the surrounding extracellular matrix (ECM). It remains poorly understood, however, what individual cells actually regulate during these interactions, and how these micromechanical regulations are translated to tissue level to lead to what we macroscopically call mechanical homeostasis. Herein, we examine this question by a combination of experiments, theoretical analysis and computational modeling. We demonstrate that on short time scales (hours) - during which deposition and degradation of ECM fibers can largely be neglected - cells appear to regulate neither the stress / strain in the ECM nor their own shape, but rather only the contractile forces that they exert on the surrounding ECM.",
        "published": "2021-04-09T14:22:27Z",
        "link": "http://arxiv.org/abs/2104.05580v1",
        "categories": [
            "q-bio.CB",
            "cs.CE"
        ]
    },
    {
        "title": "Learning constitutive models from microstructural simulations via a   non-intrusive reduced basis method",
        "authors": [
            "Theron Guo",
            "Ondřej Rokoš",
            "Karen Veroy"
        ],
        "summary": "In order to optimally design materials, it is crucial to understand the structure-property relations in the material by analyzing the effect of microstructure parameters on the macroscopic properties. In computational homogenization, the microstructure is thus explicitly modeled inside the macrostructure, leading to a coupled two-scale formulation. Unfortunately, the high computational costs of such multiscale simulations often render the solution of design, optimization, or inverse problems infeasible. To address this issue, we propose in this work a non-intrusive reduced basis method to construct inexpensive surrogates for parametrized microscale problems; the method is specifically well-suited for multiscale simulations since the coupled simulation is decoupled into two independent problems: (1) solving the microscopic problem for different (loading or material) parameters and learning a surrogate model from the data; and (2) solving the macroscopic problem with the learned material model. The proposed method has three key features. First, the microscopic stress field can be fully recovered. Second, the method is able to accurately predict the stress field for a wide range of material parameters; furthermore, the derivatives of the effective stress with respect to the material parameters are available and can be readily utilized in solving optimization problems. Finally, it is more data efficient, i.e. requiring less training data, as compared to directly performing a regression on the effective stress. For the microstructures in the two test problems considered, the mean approximation error of the effective stress is as low as 0.1% despite using a relatively small training dataset. Embedded into the macroscopic problem, the reduced order model leads to an online speed up of approximately three orders of magnitude while maintaining a high accuracy as compared to the FE$^2$ solver.",
        "published": "2021-04-09T15:58:54Z",
        "link": "http://arxiv.org/abs/2104.04451v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Quantum Prisoner's Dilemma and High Frequency Trading on the Quantum   Cloud",
        "authors": [
            "Faisal Shah Khan",
            "Ning Bao"
        ],
        "summary": "High-frequency trading (HFT) offers an excellent user case and a potential killer application of the commercially available, first generation quasi-quantum communication and computation technologies. To this end, we offer here a simple but complete game-theoretic model of HFT as the famous two player game, Prisoner's Dilemma. We explore the implementation of HFT as a game on the (quasi) quantum cloud using the Eisert, Wilkens, and Lewenstein quantum mediated communication protocol, and how this implementation can increase transaction speed and improve the lot of the players in HFT. Using cooperative game-theoretic reasoning, we also note that in the near future when the internet is properly quantum, players will be able to achieve Pareto-optimality in HFT as an instance of reinforced learning.",
        "published": "2021-04-10T01:45:37Z",
        "link": "http://arxiv.org/abs/2104.04663v1",
        "categories": [
            "quant-ph",
            "cs.CE",
            "cs.GT"
        ]
    },
    {
        "title": "A modeling and simulation study of anaerobic digestion in plug-flow   reactors",
        "authors": [
            "D. B. Panaro",
            "M. R. Mattei",
            "G. Esposito",
            "J. P. Steyer",
            "F. Capone",
            "L. Frunzo"
        ],
        "summary": "A mathematical model for anaerobic digestion in plug-flow reactors is proposed on the basis of mass balance considerations. The model consists of a system of parabolic partial differential equations for the variables representing the concentrations of the bio-components constituting the waste matrix and takes into account convective and diffusive phenomena. The plug-flow reactor is modelled as a one-dimensional domain; the waste matrix moves in the direction of the reactor axis and undergoes diffusive phenomena which reproduce the movement of the bio-components along the reactor axis due to a gradient in concentration. The velocity characterizing the convection of the waste matrix is not fixed a priori but it is considered as an additional unknown of the mathematical problem. The variation in the convective velocity allows to account the mass variation occurring along a plug-flow reactor due to the conversion of solids. The equation governing the convective velocity is derived by considering the density of the waste matrix within the reactor constant over time and the sum of the volume fractions of the bio-components constituting the waste matrix constrained to unity. The waste matrix undergoes biochemical transformations catalysed by anaerobic microbial species which lead to the production of gaseous methane, the final product of the anaerobic digestion process. Biochemical processes are modelled using a simplified scheme and a differential equation is used to describe the dynamics of the produced gaseous methane. A finite difference scheme is used for the numerical integration. Model consistency is showed through numerical simulations which investigate the effect of the variation of some operating parameters on process performance. The model is then applied to a real case scenario of engineering interest. Simulations produce results in good agreement with experimental observations.",
        "published": "2021-04-10T14:22:16Z",
        "link": "http://arxiv.org/abs/2104.04774v1",
        "categories": [
            "physics.bio-ph",
            "cs.CE",
            "35Q92, 35Q35"
        ]
    },
    {
        "title": "Inspection of ratcheting models for pathological error sensitivity and   overparametrization",
        "authors": [
            "A. A. Kaygorodtseva",
            "A. V. Shutov"
        ],
        "summary": "Accurate analysis of plastic strain accumulation under stress-controlled cyclic loading is vital for numerous engineering applications. Typically, models of plastic ratcheting are calibrated against available experimental data. Since actual experiments are not exactly accurate, one should check the identification protocols for pathological dependencies on experimental errors. In this paper, a step-by-step algorithm is presented to estimate the sensitivities of identified material parameters. As a part of the sensitivity analysis method, a new mechanics-based metric in the space of material parameters is proposed especially for ratcheting-related applications. The sensitivity of material parameters to experimental errors is estimated, based on this metric. For demonstration purposes, the accumulation of irreversible strain in the titanium alloy VT6 (Russian analog of Ti-6Al-4V) is analysed. Three types of phenomenological models of plastic ratcheting are considered. They are the Armstrong-Frederick model as well as the first and the second Ohno-Wang models. Based on real data, a new rule of isotropic hardening is proposed for greater accuracy of simulation. The ability of the sensitivity analysis to determine reliable and unreliable parameters is demonstrated. The plausibility of the new method is checked by alternative approaches, like the consideration of correlation matrices and validation of identified parameters on \"unseen\" data. A relation between pathological error sensitivity and overparametrization is established.",
        "published": "2021-04-11T08:06:19Z",
        "link": "http://arxiv.org/abs/2105.01737v1",
        "categories": [
            "cs.CE",
            "cond-mat.mtrl-sci",
            "stat.AP",
            "74C05, 62P30"
        ]
    },
    {
        "title": "Analyzing Thermal Buckling in Curvilinearly Stiffened Composite Plates   with Arbitrary Shaped Cutouts Using Isogeometric Level Set Method",
        "authors": [
            "Balakrishnan Devarajan"
        ],
        "summary": "In this paper we develop a new simple and effective isogeometric analysis for modeling thermal buckling of stiffened laminated composite plates with cutouts using level sets. We employ a first order shear deformation theory to approximate the displacement field of the stiffeners and the plate. Numerical modeling with a treatment of trimmed objects, such as internal cutouts in terms of NURBS-based isogeometric analysis presents several challenges, primarily due to need for using the tensor product of the NURBS basis functions. Due to this feature, the refinement operations can only be performed globally on the domain and not locally around the cutout. The new approach can overcome the drawbacks in modeling complex geometries with multiple-patches as the level sets are used to describe the internal cutouts; while the numerical integration is used only inside the physical domain. Results of parametric studies are presented which show the influence of ply orientation, size and orientation of the cutout and the position and profile of the curvilinear stiffeners. The numerical examples show high reliability and efficiency of the present method compared with other published solutions and ABAQUS.",
        "published": "2021-04-11T22:56:25Z",
        "link": "http://arxiv.org/abs/2104.05132v3",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Reward Mechanism for Blockchains Using Evolutionary Game Theory",
        "authors": [
            "Shashank Motepalli",
            "Hans-Arno Jacobsen"
        ],
        "summary": "Blockchains have witnessed widespread adoption in the past decade in various fields. The growing demand makes their scalability and sustainability challenges more evident than ever. As a result, more and more blockchains have begun to adopt proof-of-stake (PoS) consensus protocols to address those challenges. One of the fundamental characteristics of any blockchain technology is its crypto-economics and incentives. Lately, each PoS blockchain has designed a unique reward mechanism, yet, many of them are prone to free-rider and nothing-at-stake problems. To better understand the ad-hoc design of reward mechanisms, in this paper, we develop a reward mechanism framework that could apply to many PoS blockchains. We formulate the block validation game wherein the rewards are distributed for validating the blocks correctly. Using evolutionary game theory, we analyze how the participants' behaviour could potentially evolve with the reward mechanism. Also, penalties are found to play a central role in maintaining the integrity of blockchains.",
        "published": "2021-04-12T22:38:32Z",
        "link": "http://arxiv.org/abs/2104.05849v2",
        "categories": [
            "cs.GT",
            "cs.CE",
            "cs.MA"
        ]
    },
    {
        "title": "Using Machine Learning at Scale in HPC Simulations with SmartSim: An   Application to Ocean Climate Modeling",
        "authors": [
            "Sam Partee",
            "Matthew Ellis",
            "Alessandro Rigazzi",
            "Scott Bachman",
            "Gustavo Marques",
            "Andrew Shao",
            "Benjamin Robbins"
        ],
        "summary": "We demonstrate the first climate-scale, numerical ocean simulations improved through distributed, online inference of Deep Neural Networks (DNN) using SmartSim. SmartSim is a library dedicated to enabling online analysis and Machine Learning (ML) for traditional HPC simulations. In this paper, we detail the SmartSim architecture and provide benchmarks including online inference with a shared ML model on heterogeneous HPC systems. We demonstrate the capability of SmartSim by using it to run a 12-member ensemble of global-scale, high-resolution ocean simulations, each spanning 19 compute nodes, all communicating with the same ML architecture at each simulation timestep. In total, 970 billion inferences are collectively served by running the ensemble for a total of 120 simulated years. Finally, we show our solution is stable over the full duration of the model integrations, and that the inclusion of machine learning has minimal impact on the simulation runtimes.",
        "published": "2021-04-13T19:27:28Z",
        "link": "http://arxiv.org/abs/2104.09355v1",
        "categories": [
            "cs.CE",
            "cs.DC",
            "cs.LG",
            "physics.ao-ph"
        ]
    },
    {
        "title": "GSEIM: A General-purpose Simulator with Explicit and Implicit Methods",
        "authors": [
            "Mahesh B. Patil",
            "Ruchita D. Korgaonkar",
            "Kumar Appaiah"
        ],
        "summary": "A new simulation package, GSEIM, for solving a set of ordinary differential equations is presented. The organisation of the program is illustrated with the help of a block diagram. Various features of GSEIM are discussed. Two ways of incorporating new elements in GSEIM, viz., as a template and as a subcircuit, are explained by taking a specific example. Simulation examples are described to bring out the capabilities of GSEIM.",
        "published": "2021-04-14T04:51:38Z",
        "link": "http://arxiv.org/abs/2104.06621v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Improving Optimal Power Flow Relaxations Using 3-Cycle Second-Order Cone   Constraints",
        "authors": [
            "Frederik Geth",
            "James Foster"
        ],
        "summary": "This paper develops a novel second order cone relaxation of the semidefinite programming formulation of optimal power flow, that does not imply the `angle relaxation'. We build on a technique developed by Kim et al., extend it for complex matrices, and apply it to 3x3 positive semidefinite matrices to generate novel second-order cone constraints that augment upon the well-known 2x2 principal-minor based second-order cone constraints. Finally, we apply it to optimal power flow in meshed networks and provide numerical illustrations.",
        "published": "2021-04-14T08:37:43Z",
        "link": "http://arxiv.org/abs/2104.06695v1",
        "categories": [
            "math.OC",
            "cs.CE"
        ]
    },
    {
        "title": "Existence, Uniqueness and Numerical Modeling of Wine Fermentation Based   on Integro-Differential Equations",
        "authors": [
            "Christina Schenk",
            "Volker H. Schulz"
        ],
        "summary": "Predictive modeling is the key factor for saving time and resources with respect to manufacturing processes such as fermentation processes arising e.g.\\ in food and chemical manufacturing processes. According to Zhang et al. (2002), the open-loop dynamics of yeast are highly dependent on the initial cell mass distribution. This can be modeled via population balance models describing the single-cell behavior of the yeast cell. There have already been several population balance models for wine fermentation in the literature. However, the new model introduced in this paper is much more detailed than the ones studied previously. This new model for the white wine fermentation process is based on a combination of components previously introduced in literature. It turns it into a system of highly nonlinear weakly hyperbolic partial/ordinary integro-differential equations. This model becomes very challenging from a theoretical and numerical point of view. Existence and uniqueness of solutions to a simplified version of the introduced problem is studied based on semigroup theory. For its numerical solution a numerical methodology based on a finite volume scheme combined with a time implicit scheme is derived. The impact of the initial cell mass distribution on the solution is studied and underlined with numerical results. The detailed model is compared to a simpler model based on ordinary differential equations. The observed differences for different initial distributions and the different models turn out to be smaller than expected. The outcomes of this paper are very interesting and useful for applied mathematicians, winemakers and process engineers.",
        "published": "2021-04-14T11:07:34Z",
        "link": "http://arxiv.org/abs/2104.06777v1",
        "categories": [
            "math.AP",
            "cs.CE",
            "cs.NA",
            "math.NA",
            "q-bio.CB",
            "q-bio.PE"
        ]
    },
    {
        "title": "MoSES_2PDF: A GIS-Compatible GPU-accelerated High-Performance Simulation   Tool for Grain-Fluid Shallow Flows",
        "authors": [
            "Chi-Jyun Ko",
            "Po-Chih Chen",
            "Hock-Kiet Wong",
            "Yih-Chin Tai"
        ],
        "summary": "We introduce a GPU-accelerated simulation tool, named Modeling on Shallow Flows with Efficient Simulation for Two-Phase Debris Flows (MoSES_2PDF), of which the input and output data can be linked to the GIS system for engineering application. MoSES_2PDF is developed based on the CUDA structure so that it can well run with different NVIDIA GPU cards, once the CUDA vers. 9.2 (or higher) is installed. The performance of the MoSES_2PDF is evaluated, and it is found that the present GPU-CUDA implementation can enhance efficiency by up to 230 folds, depending on the PC/workstations, models of GPU card, and the mesh numbers in the computation domain. Two numerical examples are illustrated with two distinct initial inflow conditions, which are included in two modes of MoSES_2PDF, respectively. In the numerical example of a large-scale event, the 2009 Hsiaolin event, the results computed by two distinct NVIDIA GPU cards (RTX-2080-Ti and Tesla-V100) are found to be identical but only tiny deviation is figured out in comparison with the results computed by the conventional single-core CPU-code. It is speculated to be caused by the different structures in the source codes and some float/double operations. In addition to the illustration in the GIS system, the computed results by MoSES\\_2PDF can also be shown with animated 3D graphics in the ANSI-Platform, where the user can interact with 3D scenes. The feasibility, features, and facilities of MoSES\\_2PDF are demonstrated with respect to the two numerical examples concerning two real events.",
        "published": "2021-04-14T11:19:39Z",
        "link": "http://arxiv.org/abs/2104.06784v1",
        "categories": [
            "cs.CE",
            "physics.geo-ph"
        ]
    },
    {
        "title": "The mixed deep energy method for resolving concentration features in   finite strain hyperelasticity",
        "authors": [
            "Jan N. Fuhg",
            "Nikolaos Bouklas"
        ],
        "summary": "The introduction of Physics-informed Neural Networks (PINNs) has led to an increased interest in deep neural networks as universal approximators of PDEs in the solid mechanics community. Recently, the Deep Energy Method (DEM) has been proposed. DEM is based on energy minimization principles, contrary to PINN which is based on the residual of the PDEs. A significant advantage of DEM, is that it requires the approximation of lower order derivatives compared to formulations that are based on strong form residuals. However both DEM and classical PINN formulations struggle to resolve fine features of the stress and displacement fields, for example concentration features in solid mechanics applications. We propose an extension to the Deep Energy Method (DEM) to resolve these features for finite strain hyperelasticity. The developed framework termed mixed Deep Energy Method (mDEM) introduces stress measures as an additional output of the NN to the recently introduced pure displacement formulation. Using this approach, Neumann boundary conditions are approximated more accurately and the accuracy around spatial features which are typically responsible for high concentrations is increased. In order to make the proposed approach more versatile, we introduce a numerical integration scheme based on Delaunay integration, which enables the mDEM framework to be used for random training point position sets commonly needed for computational domains with stress concentrations. We highlight the advantages of the proposed approach while showing the shortcomings of classical PINN and DEM formulations. The method is offering comparable results to Finite-Element Method (FEM) on the forward calculation of challenging computational experiments involving domains with fine geometric features and concentrated loads.",
        "published": "2021-04-15T22:43:23Z",
        "link": "http://arxiv.org/abs/2104.09623v1",
        "categories": [
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "Interval-censored Hawkes processes",
        "authors": [
            "Marian-Andrei Rizoiu",
            "Alexander Soen",
            "Shidi Li",
            "Pio Calderon",
            "Leanne Dong",
            "Aditya Krishna Menon",
            "Lexing Xie"
        ],
        "summary": "Interval-censored data solely records the aggregated counts of events during specific time intervals - such as the number of patients admitted to the hospital or the volume of vehicles passing traffic loop detectors - and not the exact occurrence time of the events. It is currently not understood how to fit the Hawkes point processes to this kind of data. Its typical loss function (the point process log-likelihood) cannot be computed without exact event times. Furthermore, it does not have the independent increments property to use the Poisson likelihood. This work builds a novel point process, a set of tools, and approximations for fitting Hawkes processes within interval-censored data scenarios. First, we define the Mean Behavior Poisson process (MBPP), a novel Poisson process with a direct parameter correspondence to the popular self-exciting Hawkes process. We fit MBPP in the interval-censored setting using an interval-censored Poisson log-likelihood (IC-LL). We use the parameter equivalence to uncover the parameters of the associated Hawkes process. Second, we introduce two novel exogenous functions to distinguish the exogenous from the endogenous events. We propose the multi-impulse exogenous function - for when the exogenous events are observed as event time - and the latent homogeneous Poisson process exogenous function - for when the exogenous events are presented as interval-censored volumes. Third, we provide several approximation methods to estimate the intensity and compensator function of MBPP when no analytical solution exists. Fourth and finally, we connect the interval-censored loss of MBPP to a broader class of Bregman divergence-based functions. Using the connection, we show that the popularity estimation algorithm Hawkes Intensity Process (HIP) is a particular case of the MBPP. We verify our models through empirical testing on synthetic data and real-world data.",
        "published": "2021-04-16T07:29:04Z",
        "link": "http://arxiv.org/abs/2104.07932v4",
        "categories": [
            "cs.LG",
            "cs.CE",
            "stat.ML"
        ]
    },
    {
        "title": "The direct force correction based framework for general co-rotational   analysis",
        "authors": [
            "Ziyun Kan",
            "Kaijun Dong",
            "Biaosong Chen",
            "Haijun Peng",
            "Xueguan Song"
        ],
        "summary": "The use of nonlinear projection matrix in co-rotational (CR) analysis was pioneered by Rankin and Nour-Omid in 1990s (Computers & Structures, 30 (1988) 257-267; Comput. Methods Appl. Mech. Engrg., 93 (1991) 353-384), and has almost became a standard manner for CR formulations deduction over the past thirty years. This matrix however relies heavily on a hysterical and sophisticated derivation of the variation of the local displacements to the global ones, leading to complicated expressions for the internal force vector and the tangent stiffness matrix, which may devalue the simplicity and convenience for the original intention of using CR approach. This paper begins by making a discussion on existing element independent CR formulation and the objective is to develop a new and simple framework for general CR analysis that avoids using conventional nonlinear projection matrix. Multiple numerical examples involving various kinds of elements and different choices of element local CR frame are presented to demonstrate the performance of the proposed framework. The outcomes show that for all the examples the accuracy of the results are comparable with those obtained in conjunction with conventional nonlinear projection matrix.",
        "published": "2021-04-16T13:17:21Z",
        "link": "http://arxiv.org/abs/2104.07668v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A simple and robust Abaqus implementation of the phase field fracture   method",
        "authors": [
            "Yousef Navidtehrani",
            "Covadonga Betegón",
            "Emilio Martínez-Pañeda"
        ],
        "summary": "The phase field fracture method is attracting significant interest. Phase field approaches have enabled predicting - on arbitrary geometries and dimensions - complex fracture phenomena such as crack branching, coalescence, deflection and nucleation. In this work, we present a simple and robust implementation of the phase field fracture method in the commercial finite element package Abaqus. The implementation exploits the analogy between the phase field evolution law and the heat transfer equation, enabling the use of Abaqus' in-built features and circumventing the need for defining user elements. The framework is general, and is shown to accommodate different solution schemes (staggered and monolithic), as well as various constitutive choices for preventing damage under compression. The robustness and applicability of the numerical framework presented is demonstrated by addressing several 2D and 3D boundary value problems of particular interest. Focus is on the solution of paradigmatic case studies that are known to be particularly demanding from a convergence perspective. The results reveal that our phase field fracture implementation can be readily combined with other advanced computational features, such as contact, and deliver robust and precise solutions. The code developed can be downloaded from www.empaneda.com/codes.",
        "published": "2021-04-16T14:29:20Z",
        "link": "http://arxiv.org/abs/2104.08132v1",
        "categories": [
            "cs.CE",
            "cond-mat.mtrl-sci",
            "physics.app-ph"
        ]
    },
    {
        "title": "Coupling of complex function theory and finite element method for crack   propagation through energetic formulation: conformal mapping approach and   reduction to a Riemann-Hilbert problem",
        "authors": [
            "Dmitrii Legatiuk",
            "Daniel Weisz-Patrault"
        ],
        "summary": "In this paper we present a theoretical background of a coupled analytical-numerical approach to model a crack propagation process in two-dimensional bounded domains. The goal of the coupled analytical-numerical approach is to obtain the correct solution behaviour near the crack tip by help of the analytical solution constructed by using tools of the complex function theory and couple it continuously with the finite element solution in the region far from singularity. In this way, crack propagation could be modelled without using remeshing. Possible directions of crack growth can be calculated through the minimization of the total energy composed of the potential energy and the dissipated energy based on the energy release rate. Within this setting, an analytical solution of a mixed boundary value problem based on complex analysis and conformal mapping techniques is presented in a circular region containing an arbitrary crack path. More precisely, the linear elastic problem is transformed into a Riemann-Hilbert problem in the unit disk for holomorphic functions. Utilising advantages of the analytical solution in the region near the crack tip, the total energy could be evaluated within short computation times for various crack kink angles and lengths leading to a potentially efficient way of computing the minimization procedure. To this end, the paper presents a general strategy of the new coupled approach for crack propagation modelling. Additionally, we also discuss obstacles on the way of practical realisation of this strategy.",
        "published": "2021-04-16T17:46:45Z",
        "link": "http://arxiv.org/abs/2104.08260v1",
        "categories": [
            "math.CV",
            "cs.CE",
            "cs.NA",
            "math.NA",
            "30B40, 30C20, 30E10, 35Q15, 35Q74, 74H10, 74R10"
        ]
    },
    {
        "title": "Machine learning-assisted surrogate construction for full-core fuel   performance analysis",
        "authors": [
            "Yifeng Che",
            "Joseph Yurko",
            "Koroush Shirvan"
        ],
        "summary": "Accurately predicting the behavior of a nuclear reactor requires multiphysics simulation of coupled neutronics, thermal-hydraulics and fuel thermo-mechanics. The fuel thermo-mechanical response provides essential information for operational limits and safety analysis. Traditionally, fuel performance analysis is performed standalone, using calculated spatial-temporal power distribution and thermal boundary conditions from the coupled neutronics-thermal-hydraulics simulation as input. Such one-way coupling is result of the high cost induced by the full-core fuel performance analysis, which provides more realistic and accurate prediction of the core-wide response than the \"peak rod\" analysis. It is therefore desirable to improve the computational efficiency of full-core fuel performance modeling by constructing fast-running surrogate, such that fuel performance modeling can be utilized in the core reload design optimization. This work presents methodologies for full-core surrogate construction based on several realistic equilibrium PWR core designs. As a fast and conventional approach, look-up tables are only effective for certain fuel performance quantities of interest (QoIs). Several representative machine-learning algorithms are introduced to capture the complicated physics for other fuel performance QoIs. Rule-based model is useful as a feature extraction technique to account for the spatial-temporal complexity of operating conditions. Constructed surrogates achieve at least ten thousand time acceleration with satisfying prediction accuracy. Current work lays foundation for tighter coupling of fuel performance modeling into the core design optimization framework. It also sets stage for full-core fuel performance analysis with BISON where the computational cost becomes more burdensome.",
        "published": "2021-04-17T17:02:50Z",
        "link": "http://arxiv.org/abs/2104.09499v1",
        "categories": [
            "cs.CE",
            "cs.LG",
            "I.2.6, I.6.3"
        ]
    },
    {
        "title": "Digital twins with distributed particle simulation for mine-to-mill   material tracking",
        "authors": [
            "Martin Servin",
            "Folke Vesterlund",
            "Erik Wallin"
        ],
        "summary": "Systems for transport and processing of granular media are challenging to analyse, operate and optimise. In the mining and mineral processing industries these systems are chains of processes with complex interplay between the equipment, control, and the processed material. The material properties have natural variations that are usually only known at certain locations. Therefore, we explore a material-oriented approach to digital twins with a particle representation of the granular media. In digital form, the material is treated as pseudo-particles, each representing a large collection of real particles of various sizes, shapes and, mineral properties. Movements and changes in the state of the material are determined by the combined data from control systems, sensors, vehicle telematics, and simulation models at locations where no real sensors can see. The particle-based representation enables material tracking along the chain of processes. Each digital particle can act as a carrier of observational data generated by the equipment as it interacts with the real material. This makes it possible to better learn material properties from process observations, and to predict the effect on downstream processes. We test the technique on a mining simulator and demonstrate analysis that can be performed using data from cross-system material tracking.",
        "published": "2021-04-19T08:08:52Z",
        "link": "http://arxiv.org/abs/2104.09111v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Uncertainty Quantification in Friction Model for Earthquakes using   Bayesian inference",
        "authors": [
            "Saumik Dana",
            "Karthik Reddy Lyathakula"
        ],
        "summary": "This work presents a framework to inversely quantify uncertainty in the model parameters of the friction model using earthquake data via the Bayesian inference. The forward model is the popular rate- and state- friction (RSF) model along with the spring slider damper idealization. The inverse model is to determine the model parameters using the earthquake data as the response of the RSF model. The conventional solution to the inverse problem is the deterministic parameter values, which may not represent the true value, and quantifying uncertainty in the model parameters increases confidence in the estimation. The uncertainty in the model parameters is estimated by the posterior distribution obtained through the Bayesian inversion.",
        "published": "2021-04-19T09:29:57Z",
        "link": "http://arxiv.org/abs/2104.11156v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Efficient formulation of a geometrically nonlinear beam element",
        "authors": [
            "Milan Jirásek",
            "Emma La Malfa Ribolla",
            "Martin Horák"
        ],
        "summary": "The paper presents a two-dimensional geometrically nonlinear formulation of a beam element that can accommodate arbitrarily large rotations of cross sections. The formulation is based on the integrated form of equilibrium equations, which are combined with the kinematic equations and generalized material equations, leading to a set of three first-order differential equations. These equations are then discretized by finite differences and the boundary value problem is converted into an initial value problem using a technique inspired by the shooting method. Accuracy of the numerical approximation is conveniently increased by refining the integration scheme on the element level while the number of global degrees of freedom is kept constant, which leads to high computational efficiency. The element has been implemented into an open-source finite element code. Numerical examples show a favorable comparison with standard beam elements formulated in the finite-strain framework and with analytical solutions.",
        "published": "2021-04-19T13:08:31Z",
        "link": "http://arxiv.org/abs/2104.09262v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Randomized Algorithms for Scientific Computing (RASC)",
        "authors": [
            "Aydin Buluc",
            "Tamara G. Kolda",
            "Stefan M. Wild",
            "Mihai Anitescu",
            "Anthony DeGennaro",
            "John Jakeman",
            "Chandrika Kamath",
            "Ramakrishnan Kannan",
            "Miles E. Lopes",
            "Per-Gunnar Martinsson",
            "Kary Myers",
            "Jelani Nelson",
            "Juan M. Restrepo",
            "C. Seshadhri",
            "Draguna Vrabie",
            "Brendt Wohlberg",
            "Stephen J. Wright",
            "Chao Yang",
            "Peter Zwart"
        ],
        "summary": "Randomized algorithms have propelled advances in artificial intelligence and represent a foundational research area in advancing AI for Science. Future advancements in DOE Office of Science priority areas such as climate science, astrophysics, fusion, advanced materials, combustion, and quantum computing all require randomized algorithms for surmounting challenges of complexity, robustness, and scalability. This report summarizes the outcomes of that workshop, \"Randomized Algorithms for Scientific Computing (RASC),\" held virtually across four days in December 2020 and January 2021.",
        "published": "2021-04-19T18:59:26Z",
        "link": "http://arxiv.org/abs/2104.11079v3",
        "categories": [
            "cs.AI",
            "cs.CE"
        ]
    },
    {
        "title": "Computing Arlequin coupling coefficient for concurrent FE-MD approaches",
        "authors": [
            "Wenzhe Shan",
            "Udo Nackenhorst"
        ],
        "summary": "Arlequin coupling coefficient is essential for concurrent FE-MD models with overlapping domains, but the calculation of its value is quite difficult when the geometry of the coupling region is complicated. In this work, we introduce a general procedure for the preprocessing of a concurrent FE-MD model, given that the mesh and atoms have already been created. The procedure is independent of the geometry of the coupling region and can be used for both 2D and 3D problems. The procedure includes steps of determining the relative positions of atoms inside the FE elements in the coupling region, as well as computing the Arlequin coupling coefficient for an arbitrary point inside the coupling region or on its boundary. Two approaches are provided for determining the coefficient: the direct approach and the temperature approach.",
        "published": "2021-04-20T03:49:08Z",
        "link": "http://arxiv.org/abs/2104.09746v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Interpolation of Microscale Stress and Strain Fields Based on Mechanical   Models",
        "authors": [
            "Wenzhe Shan",
            "Udo Nackenhorst"
        ],
        "summary": "In this short contribution we introduce a new procedure to recover the stress and strain fields for particle systems by mechanical models. Numerical tests for simple loading conditions have shown an excellent match between the estimated values and the reference values. The estimated stress field is also consistent with the so called Quasicontinuum stress field, which suggests its potential application for scale bridging techniques. The estimated stress fields for complicated loading conditions such as defect and indentation are also demonstrated",
        "published": "2021-04-20T04:01:58Z",
        "link": "http://arxiv.org/abs/2104.09749v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Fluid-beam interaction: Capturing the effect of embedded slender bodies   on global fluid flow and vice versa",
        "authors": [
            "Nora Hagmeyer",
            "Matthias Mayr",
            "Ivo Steinbrecher",
            "Alexander Popp"
        ],
        "summary": "This work addresses research questions arising from the application of geometrically exact beam theory in the context of fluid-structure interaction (FSI). Geometrically exact beam theory has proven to be a computationally efficient way to model the behavior of slender structures while leading to rather well-posed problem descriptions. In particular, we propose a mixed-dimensional embedded finite element approach for the coupling of one-dimensional geometrically exact beam equations to a three-dimensional background fluid mesh, referred to as fluid-beam interaction (FBI) in analogy to the well-established notion of FSI. Here, the fluid is described by the incompressible isothermal Navier-Stokes equations for Newtonian fluids. In particular, we present algorithmic aspects regarding the solution of the resulting one-way coupling schemes and, through selected numerical examples, analyze their spatial convergence behavior as well as their suitability not only as stand-alone methods but also for an extension to a full two-way coupling scheme.",
        "published": "2021-04-20T09:14:10Z",
        "link": "http://arxiv.org/abs/2104.09844v3",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Developing a New Tool to Implement Computer-Supported Active Learning   Strategies in the Engineering Classroom",
        "authors": [
            "Juan M. Tizón",
            "Pablo Sierra",
            "Luis Sánchez de León",
            "Emilio Navarro",
            "Javier Vilá",
            "José F. Moral"
        ],
        "summary": "Successful implementation of active learning strategies in the engineering classroom -- and in particular in certain subjects which are highly technological in nature such as, for instance, rocket engines and space propulsion -- means overcoming certain challenges that arise from the fact that these are extremely complex systems to analyze. In this paper, we address the specific means to overcome one of such challenges: the lack of readily available software tools that are suitable for implementing this sort of teaching strategies within the engineering training. In particular, we develop a new tool for the modeling and simulation of liquid-propellant rocket engines specially tailored for the classroom, taking a systematic approach to the development of such tool based on the needs of modern teaching practices. After a thorough review of the available literature on the topic, the few most critical features that our tool should have in order to serve its purported goal are identified. Subsequently, a pilot experience to assess the impact of the usage of said tool on the learners' performance was carried out, showcasing excellent results, both in terms of the students' perceived quality of their training as well as in terms of their grade of retention and understanding of the matter. The conclusions of this study, especially the guidelines for the development of software tools aimed at the classroom, nevertheless, should be applicable to any other highly technological discipline, extending the scope of this paper beyond merely the subject of rocket science in engineering.",
        "published": "2021-04-20T16:56:05Z",
        "link": "http://arxiv.org/abs/2104.10118v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Rapid feasibility assessment of components formed through hot stamping:   A deep learning approach",
        "authors": [
            "Hamid Reza Attar",
            "Haosu Zhou",
            "Alistair Foster",
            "Nan Li"
        ],
        "summary": "The novel non-isothermal Hot Forming and cold die Quenching (HFQ) process can enable the cost-effective production of complex shaped, high strength aluminium alloy panel components. However, the unfamiliarity of designing for the new process prevents its widescale adoption in industrial settings. Recent research efforts focus on the development of advanced material models for finite element simulations, used to assess the feasibility of new component designs for the HFQ process. However, FE simulations take place late in design processes, require forming process expertise and are unsuitable for early-stage design explorations. To address these limitations, this study presents a novel application of a Convolutional Neural Network (CNN) based surrogate as a means of rapid manufacturing feasibility assessment for components to be formed using the HFQ process. A diverse dataset containing variations in component geometry, blank shapes, and processing parameters, together with corresponding physical fields is generated and used to train the model. The results show that near indistinguishable full field predictions are obtained in real time from the model when compared with HFQ simulations. This technique provides an invaluable tool to aid component design and decision making at the onset of a design process for complex-shaped components formed under HFQ conditions.",
        "published": "2021-04-20T21:40:11Z",
        "link": "http://arxiv.org/abs/2104.13199v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Cyclic Arbitrage in Decentralized Exchanges",
        "authors": [
            "Ye Wang",
            "Yan Chen",
            "Haotian Wu",
            "Liyi Zhou",
            "Shuiguang Deng",
            "Roger Wattenhofer"
        ],
        "summary": "Decentralized Exchanges (DEXes) enable users to create markets for exchanging any pair of cryptocurrencies. The direct exchange rate of two tokens may not match the cross-exchange rate in the market, and such price discrepancies open up arbitrage possibilities with trading through different cryptocurrencies cyclically. In this paper, we conduct a systematic investigation on cyclic arbitrages in DEXes. We propose a theoretical framework for studying cyclic arbitrage. With our framework, we analyze the profitability conditions and optimal trading strategies of cyclic transactions. We further examine exploitable arbitrage opportunities and the market size of cyclic arbitrages with transaction-level data of Uniswap V2. We find that traders have executed 292,606 cyclic arbitrages over eleven months and exploited more than 138 million USD in revenue. However, the revenue of the most profitable unexploited opportunity is persistently higher than 1 ETH (4,000 USD), which indicates that DEX markets may not be efficient enough. By analyzing how traders implement cyclic arbitrages, we find that traders can utilize smart contracts to issue atomic transactions and the atomic implementations could mitigate users' financial loss in cyclic arbitrage from the price impact.",
        "published": "2021-04-21T10:42:39Z",
        "link": "http://arxiv.org/abs/2105.02784v3",
        "categories": [
            "q-fin.TR",
            "cs.CE",
            "cs.CR"
        ]
    },
    {
        "title": "Machine-Learning Assisted Optimization Strategies for Phase Change   Materials Embedded within Electronic Packages",
        "authors": [
            "Meghavin Bhatasana",
            "Amy Marconnet"
        ],
        "summary": "Leveraging the latent heat of phase change materials (PCMs) can reduce the peak temperatures and transient variations in temperature in electronic devices. But as the power levels increase, the thermal conduction pathway from the heat source to the heat sink limits the effectiveness of these systems. In this work, we evaluate embedding the PCM within the silicon device layer of an electronic device to minimize the thermal resistance between the source and the PCM to minimize this thermal resistance and enhance the thermal performance of the device. The geometry and material properties of the embedded PCM regions are optimized using a combination of parametric and machine learning algorithms. For a fixed geometry, considering commercially available materials, Solder 174 significantly outperforms other organic and metallic PCMs. Also with a fixed geometry, the optimal melting points to minimize the peak temperature is higher than the optimal melting point to minimize the amplitude of the transient temperature oscillation, and both optima increase with increasing heater power. Extending beyond conventional optimization strategies, genetic algorithms and particle swarm optimization with and without neural network surrogate models are used to enable optimization of many geometric and material properties. For the test case evaluated, the optimized geometries and properties are similar between all ML-assisted algorithms, but the computational time depends on the technique. Ultimately, the optimized design with embedded phase change materials reduces the maximum temperature rise by 19% and the fluctuations by up to 88% compared to devices without PCM.",
        "published": "2021-04-21T19:20:04Z",
        "link": "http://arxiv.org/abs/2104.14433v1",
        "categories": [
            "cs.CE",
            "cs.ET",
            "cs.LG"
        ]
    },
    {
        "title": "Development of Aircraft Spoiler Demonstrators for Cost-Efficient   Investigations of SHM Technologies under Quasi-Realistic Loading Conditions",
        "authors": [
            "Markus Winklberger",
            "Christoph Kralovec",
            "Martin Schagerl"
        ],
        "summary": "An idealized 1:2 scale demonstrator and a numerical parameter optimization algorithm are proposed to closely reproduce the deformation shape and, thus, spatial strain directions of a real aerodynamically loaded civil aircraft spoiler using only four concentrated loads. Cost-efficient experimental studies on demonstrators of increasing complexity are required to transfer knowledge from coupons to full-scale structures and to build up confidence in novel structural health monitoring (SHM) technologies. Especially for testing novel sensor systems that depend on or are affected by mechanical strains, e.g., strain-based SHM methods, it is essential that the considered lab-scale structures reflect the strain states of the real structure at operational loading conditions. Finite element simulations with detailed models were performed for static strength analysis and for comparison to experimental measurements. The simulated and measured deformations and spatial strain directions of the idealized demonstrator correlated well with the numerical results of the real aircraft spoiler. Thus, using the developed idealized demonstrator, strain-based SHM systems can be tested under conditions that reflect operational aerodynamic pressure loads, while the test effort and costs are significantly reduced. Furthermore, the presented loading optimization algorithm can be easily adapted to mimic other pressure loads in plate-like structures to reproduce specific structural conditions.",
        "published": "2021-04-22T06:52:43Z",
        "link": "http://arxiv.org/abs/2104.10763v2",
        "categories": [
            "cs.CE",
            "cs.RO",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Digestive System Dynamics in Molecular Communication Perspectives",
        "authors": [
            "Dixon Vimalajeewa",
            "Sasitharan Balasubramaniam"
        ],
        "summary": "Consumption of food in excess of the required optimal nutritional requirements has already resulted in a global crisis and this is from the perspective of human health, such as obesity, as well as food waste and sustainability. In order to minimize the impact of these issues, there is a need to develop novel innovative and effective solutions that can optimally match the food consumption to the demand. This requires accurate understanding of the food digestion dynamics and its impact on each individual's physiological characteristics. This study proposes a model to characterize digestive system dynamics by using concepts from the field of Molecular Communications (MC), and this includes integrating advection-diffusion and reaction mechanisms and its role in characterizing the digestion process as a communication system. The model is then used to explore starch digestion dynamics by using communication system metrics such as delay and path loss. Our simulations found that the long gastric emptying time increases the delay in starch digestion and in turn the glucose production and absorption into the blood stream. At the same time, the enzyme activity on the hydrolyzed starch directly impacts the path loss, as higher reaction rates and lower half saturation concentration of starch results in lower path loss. Our work can lead to provide insights formulated for each individuals by creating a digital twin digestion model",
        "published": "2021-04-22T14:00:30Z",
        "link": "http://arxiv.org/abs/2104.11082v1",
        "categories": [
            "cs.CE",
            "q-bio.TO"
        ]
    },
    {
        "title": "Bayesian inversion for unified ductile phase-field fracture",
        "authors": [
            "Nima Noii",
            "Amirreza Khodadadian",
            "Jacinto Ulloa",
            "Fadi Aldakheel",
            "Thomas Wick",
            "Stijn Francois",
            "Peter Wriggers"
        ],
        "summary": "The prediction of crack initiation and propagation in ductile failure processes are challenging tasks for the design and fabrication of metallic materials and structures on a large scale. Numerical aspects of ductile failure dictate a sub-optimal calibration of plasticity- and fracture-related parameters for a large number of material properties. These parameters enter the system of partial differential equations as a forward model. In this work, we develop a step-wise Bayesian inversion framework for ductile fracture to provide accurate knowledge regarding the effective mechanical parameters. To this end, synthetic and experimental observations are used to estimate the posterior density of the unknowns. To model the ductile failure behavior of solid materials, we rely on the phase-field approach to fracture, for which we present a unified formulation that allows recovering different models on a variational basis. In the variational framework, incremental minimization principles for a class of gradient-type dissipative materials are used to derive the governing equations. The overall formulation is revisited and extended to the case of anisotropic ductile fracture. Three different models are subsequently recovered by certain choices of parameters and constitutive functions, which are later assessed through Bayesian inversion techniques. To estimate the posterior density function of ductile material parameters, three common Markov chain Monte Carlo (MCMC) techniques are employed: (i) the Metropolis-Hastings algorithm, (ii) delayed-rejection adaptive Metropolis, and (iii) ensemble Kalman filter combined with MCMC. To examine the computational efficiency of the MCMC methods, we employ the R-convergence tool.",
        "published": "2021-04-22T15:03:53Z",
        "link": "http://arxiv.org/abs/2104.11114v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "A continuous fracture front tracking algorithm with multi layer tip   elements (MuLTipEl) for a plane strain hydraulic fracture",
        "authors": [
            "E. V. Dontsov"
        ],
        "summary": "The problem of a plane strain hydraulic fracture propagating in a layered formation is considered. Fracture toughness, in-situ stress, and leak-off coefficient are assumed to vary by layer, while the elastic properties are kept constant throughout the domain for simplicity. The purpose of this study is to develop a numerical algorithm based on a fixed mesh approach, which is capable to solve the above problem accurately using elements which can even be larger than the layer size. In order to do this, the concept of fictitious tip stress is first introduced for determining the fracture front location. In this technique, an additional stress is applied to the tip element with the purpose to suppress opening and to mimic width corresponding to the actual fracture front location. A theoretical basis for this concept has been established and it is further calibrated for piece-wise constant elements. Once the ability to track the crack front location is developed, the effect of layers is included by vary properties as a function of front location. Several numerical examples benchmarking the numerical solution, as well as highlighting capabilities of the algorithm to tackle multiple thin layers accurately are presented.",
        "published": "2021-04-22T17:19:34Z",
        "link": "http://arxiv.org/abs/2104.11184v1",
        "categories": [
            "physics.geo-ph",
            "cs.CE",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Low Rank Approximation in Simulations of Quantum Algorithms",
        "authors": [
            "Linjian Ma",
            "Chao Yang"
        ],
        "summary": "Simulating quantum algorithms on classical computers is challenging when the system size, i.e., the number of qubits used in the quantum algorithm, is moderately large. However, some quantum algorithms and the corresponding quantum circuits can be simulated efficiently on a classical computer if the input quantum state is a low-rank tensor and all intermediate states of the quantum algorithm can be represented or approximated by low-rank tensors. In this paper, we examine the possibility of simulating a few quantum algorithms by using low-rank canonical polyadic (CP) decomposition to represent the input and all intermediate states of these algorithms. Two rank reduction algorithms are used to enable efficient simulation. We show that some of the algorithms preserve the low-rank structure of the input state and can thus be efficiently simulated on a classical computer. However, the rank of the intermediate states in other quantum algorithms can increase rapidly, making efficient simulation more difficult. To some extent, such difficulty reflects the advantage or superiority of a quantum computer over a classical computer. As a result, understanding the low-rank structure of a quantum algorithm allows us to identify algorithms that can benefit significantly from quantum computers.",
        "published": "2021-04-23T03:12:52Z",
        "link": "http://arxiv.org/abs/2104.11396v1",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Fleet management for ride-pooling with meeting points at scale: a case   study in the five boroughs of New York City",
        "authors": [
            "Motahare Mounesan",
            "Vindula Jayawardana",
            "Yaocheng Wu",
            "Samitha Samaranayake",
            "Huy T. Vo"
        ],
        "summary": "Introducing meeting points to ride-pooling (RP) services has been shown to increase the satisfaction level of both riders and service providers. Passengers may choose to walk to a meeting point for a cost reduction. Drivers may also get matched with more riders without making additional stops. There are economic benefits of using ride-pooling with meeting points (RPMP) compared to the traditional RP services. Many RPMP models have been proposed to better understand their benefits. However, most prior works study RPMP either with a restricted set of parameters or at a small scale due to the expensive computation involved. In this paper, we propose STaRS+, a scalable RPMP framework that is based on a comprehensive integer linear programming model. The high scalability of STaRS+ is achieved by utilizing a heuristic optimization strategy along with a novel shortest-path caching scheme. We applied our model to the NYC metro area to evaluate the scalability of the framework and demonstrate the importance of city-scale simulations. Our results show that city-scale simulations can reveal valuable insights for city planners that are not always visible at smaller scales. To the best of our knowledge, STaRS+ is the first study on the RPMP that can solve large-scale instances on the order of the entire NYC metro area.",
        "published": "2021-04-25T04:01:26Z",
        "link": "http://arxiv.org/abs/2105.00994v1",
        "categories": [
            "eess.SY",
            "cs.CE",
            "cs.SY",
            "physics.soc-ph"
        ]
    },
    {
        "title": "Free Vibration analysis of Curvilinearly Stiffened Composite plates with   an arbitrarily shaped cutout using Isogeometric Analysis",
        "authors": [
            "Balakrishnan Devarajan"
        ],
        "summary": "This paper focuses on the isogeometric vibration analysis of curvilinearly stiffened composite panels. The stiffness matrices and the mass matrices are derived using the first-order shear deformation theory (FSDT). The present method models the plate and the stiffener separately, which allows the stiffener element nodes to not coincide with the plate shell-element nodes. The stiffness and mass matrices of a stiffener are transformed to those of the plate through the displacement compatibility conditions at the plate/stiffener interface by interpolation using NURBS basis functions. Cutouts are modeled using a single NURBS patch generated by creating a ruled surface between two curves. The proposed formulation is first validated by comparing it with available literature. The effects of width-to-thickness ratio, fiber orientation, ply layups, shape and size of the cutouts and the boundary conditions on the response of stiffened composite plates are then analyzed and the numerical results are used to derive useful conclusions.",
        "published": "2021-04-26T20:15:39Z",
        "link": "http://arxiv.org/abs/2104.12856v4",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Vibration Analysis of Timoshenko Beams using Isogeometric Analysis",
        "authors": [
            "Balakrishnan Devarajan"
        ],
        "summary": "In this paper, the finite free-form beam element is formulated by the isogeometric approach based on the Timoshenko beam theory to investigate the free vibration behavior of the beams. The non-uniform rational B-splines (NURBS) functions which define the geometry of the beam are used as the basis functions for the finite element analysis. In order to enrich the basis functions and to increase the accuracy of the solution fields, the h-, p-, and k-refinement techniques are implemented. The geometry and curvature of the beams are modelled in a unique way based on NURBS. All the effects of the the shear deformation, and the rotary inertia are taken into consideration by the present isogeometric model. Results of the beams for non-dimensional frequencies are compared with other available results in order to show the accuracy and efficiency of the present isogeometric approach. From numerical results, the present element can produce very accurate values of natural frequencies and the mode shapes due to exact definition of the geometry. With higher order basis functions, there is no shear locking phenomenon in very thin beam situations. Finally, the benchmark tests described in this study are provided as future reference solutions for Timoshenko beam vibration problem.",
        "published": "2021-04-26T20:27:36Z",
        "link": "http://arxiv.org/abs/2104.12860v4",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "SuperVoxHenry Tucker-Enhanced and FFT-Accelerated Inductance Extraction   for Voxelized Superconducting Structures",
        "authors": [
            "Mingyu Wang",
            "Cheng Qian",
            "Enrico Di Lorenzo",
            "Luis J. Gomez",
            "Vladimir Okhmatovski",
            "Abdulkadir C. Yucel"
        ],
        "summary": "This paper introduces SuperVoxHenry, an inductance extraction simulator for analyzing voxelized superconducting structures. SuperVoxHenry extends the capabilities of the inductance extractor VoxHenry for analyzing the superconducting structures by incorporating the following enhancements. 1. SuperVoxHenry utilizes a two-fluid model to account for normal currents and supercurrents. 2. SuperVoxHenry introduces the Tucker decompositions to reduce the memory requirement of circulant tensors as well as the setup time of the simulator. 3. SuperVoxHenry incorporates an aggregation-based algebraic multigrid technique to obtain the sparse preconditioner.",
        "published": "2021-04-27T02:34:48Z",
        "link": "http://arxiv.org/abs/2105.08627v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "An isogeometric boundary element method for three-dimensional   doubly-periodic layered structures in electromagnetics",
        "authors": [
            "Toru Takahashi",
            "Tetsuro Hirai",
            "Hiroshi Isakari",
            "Toshiro Matsumoto"
        ],
        "summary": "This paper proposes an isogeometric boundary element method (IGBEM) to solve the electromagnetic scattering problems for three-dimensional doubly-periodic multi-layered structures. The main concerns are the constructions of (i) an open surface (between two layers) and (ii) a vector basis function with using the B-spline functions. Regarding (i), we considered an algorithm to generate a doubly-periodic open surface with the tensor product of the B-spline functions of any degree. Regarding (ii), we employed the vector basis function based on the B-spline functions, which was proposed by Buffa et al. (2010), and adapted it to the underlying periodic problems so that it can satisfy the quasi-periodic condition on the boundary of an open surface. The proposed IGBEM worked for solving some numerical examples satisfactorily and proved the applicability to plasmonic simulations.",
        "published": "2021-04-27T03:09:24Z",
        "link": "http://arxiv.org/abs/2105.00853v2",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "A data-driven and model-based accelerated Hamiltonian Monte Carlo method   for Bayesian elliptic inverse problems",
        "authors": [
            "Sijing Li",
            "Cheng Zhang",
            "Zhiwen Zhang",
            "Hongkai Zhao"
        ],
        "summary": "In this paper, we consider a Bayesian inverse problem modeled by elliptic partial differential equations (PDEs). Specifically, we propose a data-driven and model-based approach to accelerate the Hamiltonian Monte Carlo (HMC) method in solving large-scale Bayesian inverse problems. The key idea is to exploit (model-based) and construct (data-based) the intrinsic approximate low-dimensional structure of the underlying problem which consists of two components - a training component that computes a set of data-driven basis to achieve significant dimension reduction in the solution space, and a fast solving component that computes the solution and its derivatives for a newly sampled elliptic PDE with the constructed data-driven basis. Hence we achieve an effective data and model-based approach for the Bayesian inverse problem and overcome the typical computational bottleneck of HMC - repeated evaluation of the Hamiltonian involving the solution (and its derivatives) modeled by a complex system, a multiscale elliptic PDE in our case. We present numerical examples to demonstrate the accuracy and efficiency of the proposed method.",
        "published": "2021-04-27T09:37:18Z",
        "link": "http://arxiv.org/abs/2104.13070v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "physics.comp-ph"
        ]
    },
    {
        "title": "An optimal control approach to determine resistance-type boundary   conditions from in-vivo data for cardiovascular simulations",
        "authors": [
            "Elisa Fevola",
            "Francesco Ballarin",
            "Laura Jiménez-Juan",
            "Stephen Fremes",
            "Stefano Grivet-Talocia",
            "Gianluigi Rozza",
            "Piero Triverio"
        ],
        "summary": "The choice of appropriate boundary conditions is a fundamental step in computational fluid dynamics (CFD) simulations of the cardiovascular system. Boundary conditions, in fact, highly affect the computed pressure and flow rates, and consequently haemodynamic indicators such as wall shear stress, which are of clinical interest. Devising automated procedures for the selection of boundary conditions is vital to achieve repeatable simulations. However, the most common techniques do not automatically assimilate patient-specific data, relying instead on expensive and time-consuming manual tuning procedures. In this work, we propose a technique for the automated estimation of outlet boundary conditions based on optimal control. The values of resistive boundary conditions are set as control variables and optimized to match available patient-specific data. Experimental results on four aortic arches demonstrate that the proposed framework can assimilate 4D-Flow MRI data more accurately than two other common techniques based on Murray's law and Ohm's law.",
        "published": "2021-04-27T15:54:45Z",
        "link": "http://arxiv.org/abs/2104.13284v2",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "math.OC"
        ]
    },
    {
        "title": "Mesoscale simulation of woven composite design decisions",
        "authors": [
            "Lincoln N. Collins",
            "Scott A. Roberts"
        ],
        "summary": "Characterizing the connection between material design decisions/parameters and their effective properties allows for accelerated materials development and optimization. We present a global sensitivity analysis of woven composite thermophysical properties, including density, volume fraction, thermal conductivity, specific heat, moduli, permeability, and tortuosity, predicted using mesoscale finite element simulations. The mesoscale simulations use microscale approximations for the tow and matrix phases. We performed Latin hypercube sampling of viable input parameter ranges, and the resulting effective property distributions are analyzed using a surrogate model to determine the correlations between material parameters and responses, interactions between properties, and finally Sobol' indices and sensitivities. We demonstrate that both constituent physical properties and the mesoscale geometry strongly influence the composite material properties.",
        "published": "2021-04-28T03:30:26Z",
        "link": "http://arxiv.org/abs/2104.13554v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A Non-Nested Multilevel Method for Meshless Solution of the Poisson   Equation in Heat Transfer and Fluid Flow",
        "authors": [
            "Anand Radhakrishnan",
            "Michael Xu",
            "Shantanu Shahane",
            "Surya Pratap Vanka"
        ],
        "summary": "We present a non-nested multilevel algorithm for solving the Poisson equation discretized at scattered points using polyharmonic radial basis function (PHS-RBF) interpolations. We append polynomials to the radial basis functions to achieve exponential convergence of discretization errors. The interpolations are performed over local clouds of points and the Poisson equation is collocated at each of the scattered points, resulting in a sparse set of discrete equations for the unkown variables. To solve this set of equations, we have developed a non-nested multilevel algorithm utilizing multiple independently generated coarse sets of points. The restriction and prolongation operators are also constructed with the same RBF interpolations procedure. The performance of the algorithm for Dirichlet and all-Neumann boundary conditions is evaluated in three model geometries using a manufactured solution. For Dirichlet boundary conditions, rapid convergence is observed using SOR point solver as the relaxation scheme. For cases of all-Neumann boundary conditions, convergence is seen to slow down with the degree of the appended polynomial. However, when the multilevel procedure is combined with a GMRES algorithm, the convergence is seen to significantly improve. The GMRES accelerated multilevel algorithm is included in a fractional step method to solve incompressible Navier-Stokes equations.",
        "published": "2021-04-28T13:38:29Z",
        "link": "http://arxiv.org/abs/2104.13758v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Reduced order models from computed states of physical systems using   non-local calculus on finite weighted graphs",
        "authors": [
            "Matthew Duschenes",
            "Krishna Garikipati"
        ],
        "summary": "Partial differential equation-based numerical solution frameworks for initial and boundary value problems have attained a high degree of complexity. Applied to a wide range of physics with the ultimate goal of enabling engineering solutions, these approaches encompass a spectrum of spatiotemporal discretization techniques that leverage solver technology and high performance computing. While high-fidelity solutions can be achieved using these approaches, they come at a high computational expense and complexity. Systems with billions of solution unknowns are now routine. The expense and complexity do not lend themselves to typical engineering design and decision-making, which must instead rely on reduced-order models. Here we present an approach to reduced-order modelling that builds off of recent graph theoretic work for representation, exploration, and analysis on computed states of physical systems (Banerjee et al., Comp. Meth. App. Mech. Eng., 351, 501-530, 2019). We extend a non-local calculus on finite weighted graphs to build such models by exploiting first order dynamics, polynomial expansions, and Taylor series. Some aspects of the non-local calculus related to consistency of the models are explored. Details on the numerical implementations and the software library that has been developed for non-local calculus on graphs are described. Finally, we present examples of applications to various quantities of interest in mechano-chemical systems.",
        "published": "2021-04-28T22:24:56Z",
        "link": "http://arxiv.org/abs/2105.01740v2",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Fast and accurate solvers for simulating Janus particle suspensions in   Stokes flow",
        "authors": [
            "Ryan Kohl",
            "Eduardo Corona",
            "Vani Cheruvu",
            "Shravan Veerapaneni"
        ],
        "summary": "We present a novel computational framework for simulating suspensions of rigid spherical Janus particles in Stokes flow. We show that long-range Janus particle interactions for a wide array of applications may be resolved using fast, spectrally accurate boundary integral methods tailored to polydisperse suspensions of spherical particles. These are incorporated into our rigid body Stokes platform. Our approach features the use of spherical harmonic expansions for spectrally accurate integral operator evaluation, complementarity-based collision resolution, and optimal O(n) scaling with the number of particles when accelerated via fast summation techniques. We demonstrate the flexibility of our platform through three key examples of Janus particle systems prominent in biomedical applications: amphiphilic, bipolar electric and phoretic particles. We formulate Janus particle interactions in boundary integral form and showcase characteristic self-assembly and complex collective behavior for each particle type.",
        "published": "2021-04-29T01:13:53Z",
        "link": "http://arxiv.org/abs/2104.14068v1",
        "categories": [
            "physics.flu-dyn",
            "cond-mat.soft",
            "cs.CE",
            "cs.NA",
            "math.NA",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Adaptive Partitioning Strategy for High-Dimensional Discrete   Simulation-based Optimization Problems",
        "authors": [
            "Jing Lu",
            "Tianli Zhou",
            "Carolina Osorio"
        ],
        "summary": "In this paper, we introduce a technique to enhance the computational efficiency of solution algorithms for high-dimensional discrete simulation-based optimization problems. The technique is based on innovative adaptive partitioning strategies that partition the feasible region using solutions that has already been simulated as well as prior knowledge of the problem of interesting. We integrate the proposed strategies with the Empirical Stochastic Branch-and-Bound framework proposed by Xu and Nelson (2013). This combination leads to a general-purpose discrete simulation-based optimization algorithm that is both globally convergent and has good small sample (finite-time) performance. The proposed general-purpose discrete simulation-based optimization algorithm is validated on a synthetic discrete simulation-based optimization problem and is then used to address a real-world car-sharing fleet assignment problem. Experiment results show that the proposed strategy can increase the algorithm efficiency significantly.",
        "published": "2021-04-29T05:34:19Z",
        "link": "http://arxiv.org/abs/2104.14119v2",
        "categories": [
            "math.OC",
            "cs.CE",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Quantum Quantitative Trading: High-Frequency Statistical Arbitrage   Algorithm",
        "authors": [
            "Xi-Ning Zhuang",
            "Zhao-Yun Chen",
            "Yu-Chun Wu",
            "Guo-Ping Guo"
        ],
        "summary": "Quantitative trading is an integral part of financial markets with high calculation speed requirements, while no quantum algorithms have been introduced into this field yet. We propose quantum algorithms for high-frequency statistical arbitrage trading in this work by utilizing variable time condition number estimation and quantum linear regression.The algorithm complexity has been reduced from the classical benchmark O(N^2d) to O(sqrt(d)(kappa)^2(log(1/epsilon))^2 )). It shows quantum advantage, where N is the length of trading data, and d is the number of stocks, kappa is the condition number and epsilon is the desired precision. Moreover, two tool algorithms for condition number estimation and cointegration test are developed.",
        "published": "2021-04-29T09:09:28Z",
        "link": "http://arxiv.org/abs/2104.14214v1",
        "categories": [
            "quant-ph",
            "cs.CE",
            "q-fin.CP",
            "q-fin.TR"
        ]
    },
    {
        "title": "Parallel Projection---An Improved Return Mapping Algorithm for Finite   Element Modeling of Shape Memory Alloys",
        "authors": [
            "Ziliang Kang",
            "Daniel A. Tortorelli",
            "Kai A. James"
        ],
        "summary": "We present a novel finite element analysis of inelastic structures containing Shape Memory Alloys (SMAs). Phenomenological constitutive models for SMAs lead to material nonlinearities, that require substantial computational effort to resolve. Finite element analysis methods, which rely on Gauss quadrature integration schemes, must solve two sets of coupled differential equations: one at the global level and the other at the local, i.e. Gauss point level. In contrast to the conventional return mapping algorithm, which solves these two sets of coupled differential equations separately using a nested Newton procedure, we propose a scheme to solve the local and global differential equations simultaneously. In the process we also derive closed-form expressions used to update the internal/constitutive state variables, and unify the popular closest-point and cutting plane methods with our formulas. Numerical testing indicates that our method allows for larger thermomechanical loading steps and provides increased computational efficiency, over the standard return mapping algorithm.",
        "published": "2021-04-29T15:44:09Z",
        "link": "http://arxiv.org/abs/2104.14424v2",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Grid-Free Computation of Probabilistic Safety with Malliavin Calculus",
        "authors": [
            "Francesco Cosentino",
            "Harald Oberhauser",
            "Alessandro Abate"
        ],
        "summary": "This work concerns continuous-time, continuous-space stochastic dynamical systems described by stochastic differential equations (SDE). It presents a new approach to compute probabilistic safety regions, namely sets of initial conditions of the SDE associated to trajectories that are safe with a probability larger than a given threshold. The approach introduces a functional that is minimised at the border of the probabilistic safety region, then solves an optimisation problem using techniques from Malliavin Calculus, which computes such region. Unlike existing results in the literature, the new approach allows one to compute probabilistic safety regions without gridding the state space of the SDE.",
        "published": "2021-04-29T22:55:38Z",
        "link": "http://arxiv.org/abs/2104.14691v2",
        "categories": [
            "math.PR",
            "cs.CE"
        ]
    },
    {
        "title": "Towards an Extrinsic, CG-XFEM Approach Based on Hierarchical Enrichments   for Modeling Progressive Fracture",
        "authors": [
            "M. Keith Ballard",
            "Roman Amici",
            "Varun Shankar",
            "Lauren A. Ferguson",
            "Michael Braginsky",
            "Robert M. Kirby"
        ],
        "summary": "We propose an extrinsic, continuous-Galerkin (CG), extended finite element method (XFEM) that generalizes the work of Hansbo and Hansbo to allow multiple Heaviside enrichments within a single element in a hierarchical manner. This approach enables complex, evolving XFEM surfaces in 3D that cannot be captured using existing CG-XFEM approaches. We describe an implementation of the method for 3D static elasticity with linearized strain for modeling open cracks as a salient step towards modeling progressive fracture. The implementation includes a description of the finite element model, hybrid implicit/explicit representation of enrichments, numerical integration method, and novel degree-of-freedom (DoF) enumeration algorithm. This algorithm supports an arbitrary number of enrichments within an element, while simultaneously maintaining a CG solution across elements. Additionally, our approach easily allows an implementation suitable for distributed computing systems. Enabled by the DoF enumeration algorithm, the proposed method lays the groundwork for a computational tool that efficiently models progressive fracture. To facilitate a discussion of the complex enrichment hierarchies, we develop enrichment diagrams to succinctly describe and visualize the relationships between the enrichments (and the fields they create) within an element. This also provides a unified language for discussing extrinsic XFEM methods in the literature. We compare several methods, relying on the enrichment diagrams to highlight their nuanced differences.",
        "published": "2021-04-30T00:38:09Z",
        "link": "http://arxiv.org/abs/2104.14704v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A Gradient-based Deep Neural Network Model for Simulating Multiphase   Flow in Porous Media",
        "authors": [
            "Bicheng Yan",
            "Dylan Robert Harp",
            "Rajesh J. Pawar"
        ],
        "summary": "Simulation of multiphase flow in porous media is crucial for the effective management of subsurface energy and environment related activities. The numerical simulators used for modeling such processes rely on spatial and temporal discretization of the governing partial-differential equations (PDEs) into algebraic systems via numerical methods. These simulators usually require dedicated software development and maintenance, and suffer low efficiency from a runtime and memory standpoint. Therefore, developing cost-effective, data-driven models can become a practical choice since deep learning approaches are considered to be universal approximations. In this paper, we describe a gradient-based deep neural network (GDNN) constrained by the physics related to multiphase flow in porous media. We tackle the nonlinearity of flow in porous media induced by rock heterogeneity, fluid properties and fluid-rock interactions by decomposing the nonlinear PDEs into a dictionary of elementary differential operators. We use a combination of operators to handle rock spatial heterogeneity and fluid flow by advection. Since the augmented differential operators are inherently related to the physics of fluid flow, we treat them as first principles prior knowledge to regularize the GDNN training. We use the example of pressure management at geologic CO2 storage sites, where CO2 is injected in saline aquifers and brine is produced, and apply GDNN to construct a predictive model that is trained from physics-based simulation data and emulates the physics process. We demonstrate that GDNN can effectively predict the nonlinear patterns of subsurface responses including the temporal-spatial evolution of the pressure and saturation plumes. GDNN has great potential to tackle challenging problems that are governed by highly nonlinear physics and enables development of data-driven models with higher fidelity.",
        "published": "2021-04-30T02:14:00Z",
        "link": "http://arxiv.org/abs/2105.02652v1",
        "categories": [
            "physics.comp-ph",
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "Single-Source SIE for Two-Dimensional Arbitrarily Connected Penetrable   and PEC Objects with Nonconformal Meshes",
        "authors": [
            "Zekun Zhu",
            "Aipeng Sun",
            "Xiaochao Zhou",
            "Shunchuan Yang",
            "Zhizhang",
            "Chen"
        ],
        "summary": "We proposed a simple and efficient modular single-source surface integral equation (SS-SIE) formulation for electromagnetic analysis of arbitrarily connected penetrable and perfectly electrical conductor (PEC) objects in two-dimensional space. In this formulation, a modular equivalent model for each penetrable object consisting of the composite structure is first independently constructed through replacing it by the background medium, no matter whether it is surrounded by the background medium, other media, or partially connected objects, and enforcing an equivalent electric current density on the boundary to remain fields in the exterior region unchanged. Then, by combining all the modular models and any possible PEC objects together, an equivalent model for the composite structure can be derived. The troublesome junction handling techniques are not needed and non-conformal meshes are intrinsically supported. The proposed SS-SIE formulation is simple to implement, efficient, and flexible, which shows significant performance improvement in terms of CPU time compared with the original SS-SIE formulation and the Poggio-Miller-Chang-Harrington-Wu-Tsai (PMCHWT) formulation. Several numerical examples including the coated dielectric cuboid, the large lossy objects, the planar layered dielectric structure, and the partially connected dielectric and PEC structure are carried out to validate its accuracy, efficiency and robustness.",
        "published": "2021-04-30T08:03:50Z",
        "link": "http://arxiv.org/abs/2104.14817v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Applying physics-based loss functions to neural networks for improved   generalizability in mechanics problems",
        "authors": [
            "Samuel J. Raymond",
            "David B. Camarillo"
        ],
        "summary": "Physics-Informed Machine Learning (PIML) has gained momentum in the last 5 years with scientists and researchers aiming to utilize the benefits afforded by advances in machine learning, particularly in deep learning. With large scientific data sets with rich spatio-temporal data and high-performance computing providing large amounts of data to be inferred and interpreted, the task of PIML is to ensure that these predictions, categorizations, and inferences are enforced by, and conform to the limits imposed by physical laws. In this work a new approach to utilizing PIML is discussed that deals with the use of physics-based loss functions. While typical usage of physical equations in the loss function requires complex layers of derivatives and other functions to ensure that the known governing equation is satisfied, here we show that a similar level of enforcement can be found by implementing more simpler loss functions on specific kinds of output data. The generalizability that this approach affords is shown using examples of simple mechanical models that can be thought of as sufficiently simplified surrogate models for a wide class of problems.",
        "published": "2021-04-30T20:31:09Z",
        "link": "http://arxiv.org/abs/2105.00075v2",
        "categories": [
            "physics.comp-ph",
            "cs.CE",
            "cs.LG",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Angle dependence in coupling conditions for shallow water equations at   canal junctions",
        "authors": [
            "Maya Briani",
            "Gabriella Puppo",
            "Magali Ribot"
        ],
        "summary": "In this paper we propose a numerical Riemann problem solver at the junction of one dimensional shallow-water canal networks. The junction conditions take into account the angles with which the channels intersect and include the possibility of canals with different sections. The solver is illustrated with several numerical tests which underline the importance of the angle dependence to obtain reliable solutions.",
        "published": "2021-05-01T15:25:11Z",
        "link": "http://arxiv.org/abs/2105.01741v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "math-ph",
            "math.MP",
            "65M08, 76G, 35M13"
        ]
    },
    {
        "title": "Time-periodic steady-state solution of fluid-structure interaction and   cardiac flow problems through multigrid-reduction-in-time",
        "authors": [
            "Andreas Hessenthaler",
            "Robert D. Falgout",
            "Jacob B. Schroder",
            "Adelaide de Vecchi",
            "David Nordsletten",
            "Oliver Röhrle"
        ],
        "summary": "In this paper, a time-periodic MGRIT algorithm is proposed as a means to reduce the time-to-solution of numerical algorithms by exploiting the time periodicity inherent to many applications in science and engineering. The time-periodic MGRIT algorithm is applied to a variety of linear and nonlinear single- and multiphysics problems that are periodic-in-time. It is demonstrated that the proposed parallel-in-time algorithm can obtain the same time-periodic steady-state solution as sequential time-stepping. It is shown that the required number of MGRIT iterations can be estimated a priori and that the new MGRIT variant can significantly and consistently reduce the time-to-solution compared to sequential time-stepping, irrespective of the number of dimensions, linear or nonlinear PDE models, single-physics or coupled problems and the employed computing resources. The numerical experiments demonstrate that the time-periodic MGRIT algorithm enables a greater level of parallelism yielding faster turnaround, and thus, facilitating more complex and more realistic problems to be solved.",
        "published": "2021-05-01T17:13:58Z",
        "link": "http://arxiv.org/abs/2105.00305v3",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A Bayesian Method for Estimating Uncertainty in Excavated Material",
        "authors": [
            "Mehala Balamurali"
        ],
        "summary": "This paper proposes a method to probabilistically quantify the moments (mean and variance) of excavated material during excavation by aggregating the prior moments of the grade blocks around the given bucket dig location. By modelling the moments as random probability density functions (pdf) at sampled locations, a formulation of the sums of Gaussian based uncertainty estimation is presented that jointly estimates the location pdfs, as well as the prior values for uncertainty coming from ore body knowledge (obk) sub block models. The moments calculated at each random location is a single Gaussian and they are the components of Gaussian mixture distribution. The overall uncertainty of the excavated material at the given bucket location is represented by the Gaussian Mixture Model (GMM) and therefore moment matching method is proposed to estimate the moments of the reduced GMM. The method was tested in a region at a Pilbara iron ore deposit situated in the Brockman Iron Formation of the Hamersley Province, Western Australia, and suggests a frame work to quantify the uncertainty in the excavated material that hasn't been studied anywhere in the literature yet.",
        "published": "2021-05-03T02:07:36Z",
        "link": "http://arxiv.org/abs/2105.00600v1",
        "categories": [
            "stat.AP",
            "cs.CE"
        ]
    },
    {
        "title": "A rigged model of the breast for preoperative surgical planning",
        "authors": [
            "Arnaud Mazier",
            "Sophie Ribes",
            "Benjamin Gilles",
            "Stéphane P. A Bordas",
            "."
        ],
        "summary": "In breast surgical practice, drawing is part of the preoperative planning procedure and is essential for a successful operation. In this study, we design a pipeline to assist surgeons with patient-specific breast surgical drawings. We use a deformable torso model containing the surgical patterns to match any breast surface scan. To be compatible with surgical timing, we build an articulated model through a skinning process coupled with shape deformers to enhance a fast registration process. On one hand, the scalable bones of the skinning account for pose and morphological variations of the patients. On the other hand, pre-designed artistic blendshapes create a linear space for guaranteeing anatomical variations. Then, we apply meaningful constraints to the model to find a trade-off between precision and speed. The experiments were conducted on 7 patients, in 2 different poses (prone and supine) with a breast size ranging from 36A and 42C (US/UK bra sizing). The acquisitions were obtained using the depth camera Structure Sensor, and the breast scans were acquired in less than 1 minute. The result is a registration method converging within a few seconds (3 maximum), reaching a Mean Absolute Error of 2.3 mm for mesh registration and 8.0 mm for breast anatomical landmarks. Compared to the existing literature, our model can be personalized and does not require any database. Finally, our registered model can be used to transfer surgical reference patterns onto any patient in any position.",
        "published": "2021-05-03T11:45:06Z",
        "link": "http://arxiv.org/abs/2105.00763v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "[Re] Three-dimensional wake topology and propulsive performance of   low-aspect-ratio pitching-rolling plates",
        "authors": [
            "Olivier Mesnard",
            "Lorena A. Barba"
        ],
        "summary": "This article reports on a full replication study in computational fluid dynamics, using an immersed boundary method to obtain the flow around a pitching and rolling elliptical wing. As in the original study, the computational experiments investigate the wake topology and aerodynamic forces, looking at the effect of: Reynolds number (100--400), Strouhal number (0.4--1.2), aspect ratio, and rolling/pitching phase difference. We also include a grid-independence study (from 5 to 72 million grid cells). The trends in aerodynamic performance and the characteristics of the wake topology were replicated, despite some differences in results. We declare the replication successful, and make fully available all the digital artifacts and workflow definitions, including software build recipes and container images, as well as secondary data and post-processing code. Run times for each computational experiment were between 8.1 and 13.8 hours to complete 5 flapping cycles, using two compute nodes with dual 20-core 3.7GHz Intel Xeon Gold 6148 CPUs and two NVIDIA V100 GPU devices each.",
        "published": "2021-05-03T12:29:15Z",
        "link": "http://arxiv.org/abs/2105.00775v1",
        "categories": [
            "physics.flu-dyn",
            "cs.CE"
        ]
    },
    {
        "title": "Revisiting high-order Taylor methods for astrodynamics and celestial   mechanics",
        "authors": [
            "Francesco Biscani",
            "Dario Izzo"
        ],
        "summary": "We present heyoka, a new, modern and general-purpose implementation of Taylor's integration method for the numerical solution of ordinary differential equations. Detailed numerical tests focused on difficult high-precision gravitational problems in astrodynamics and celestial mechanics show how our general-purpose integrator is competitive with and often superior to state-of-the-art specialised symplectic and non-symplectic integrators in both speed and accuracy. In particular, we show how Taylor methods are capable of satisfying Brouwer's law for the conservation of energy in long-term integrations of planetary systems over billions of dynamical timescales. We also show how close encounters are modelled accurately during simulations of the formation of the Kirkwood gaps and of Apophis' 2029 close encounter with the Earth (where heyoka surpasses the speed and accuracy of domain-specific methods). heyoka can be used from both C++ and Python, and it is publicly available as an open-source project.",
        "published": "2021-05-03T12:52:49Z",
        "link": "http://arxiv.org/abs/2105.00800v1",
        "categories": [
            "astro-ph.EP",
            "astro-ph.IM",
            "cs.CE",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Embedded training of neural-network sub-grid-scale turbulence models",
        "authors": [
            "Jonathan F. MacArt",
            "Justin Sirignano",
            "Jonathan B. Freund"
        ],
        "summary": "The weights of a deep neural network model are optimized in conjunction with the governing flow equations to provide a model for sub-grid-scale stresses in a temporally developing plane turbulent jet at Reynolds number $Re_0=6\\,000$. The objective function for training is first based on the instantaneous filtered velocity fields from a corresponding direct numerical simulation, and the training is by a stochastic gradient descent method, which uses the adjoint Navier--Stokes equations to provide the end-to-end sensitivities of the model weights to the velocity fields. In-sample and out-of-sample testing on multiple dual-jet configurations show that its required mesh density in each coordinate direction for prediction of mean flow, Reynolds stresses, and spectra is half that needed by the dynamic Smagorinsky model for comparable accuracy. The same neural-network model trained directly to match filtered sub-grid-scale stresses -- without the constraint of being embedded within the flow equations during the training -- fails to provide a qualitatively correct prediction. The coupled formulation is generalized to train based only on mean-flow and Reynolds stresses, which are more readily available in experiments. The mean-flow training provides a robust model, which is important, though a somewhat less accurate prediction for the same coarse meshes, as might be anticipated due to the reduced information available for training in this case. The anticipated advantage of the formulation is that the inclusion of resolved physics in the training increases its capacity to extrapolate. This is assessed for the case of passive scalar transport, for which it outperforms established models due to improved mixing predictions.",
        "published": "2021-05-03T17:28:39Z",
        "link": "http://arxiv.org/abs/2105.01030v1",
        "categories": [
            "physics.flu-dyn",
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "Operator Splitting for Adaptive Radiation Therapy with Nonlinear Health   Dynamics",
        "authors": [
            "Anqi Fu",
            "Lei Xing",
            "Stephen Boyd"
        ],
        "summary": "We present an optimization-based approach to radiation treatment planning over time. Our approach formulates treatment planning as an optimal control problem with nonlinear patient health dynamics derived from the standard linear-quadratic cell survival model. As the formulation is nonconvex, we propose a method for obtaining an approximate solution by solving a sequence of convex optimization problems. This method is fast, efficient, and robust to model error, adapting readily to changes in the patient's health between treatment sessions. Moreover, we show that it can be combined with the operator splitting method ADMM to produce an algorithm that is highly scalable and can handle large clinical cases. We introduce an open-source Python implementation of our algorithm, AdaRad, and demonstrate its performance on several examples.",
        "published": "2021-05-04T04:54:00Z",
        "link": "http://arxiv.org/abs/2105.01286v2",
        "categories": [
            "physics.med-ph",
            "cs.CE",
            "math.OC",
            "90C26 (Primary), 90C06, 90C90 (Secondary)",
            "G.4; J.2; J.3"
        ]
    },
    {
        "title": "Bayesian inference of an uncertain generalized diffusion operator",
        "authors": [
            "Teresa Portone",
            "Robert D. Moser"
        ],
        "summary": "This paper defines a novel Bayesian inverse problem to infer an infinite-dimensional uncertain operator appearing in a differential equation, whose action on an observable state variable affects its dynamics. Inference is made tractable by parametrizing the operator using its eigendecomposition. The plausibility of operator inference in the sparse data regime is explored in terms of an uncertain, generalized diffusion operator appearing in an evolution equation for a contaminant's transport through a heterogeneous porous medium. Sparse data are augmented with prior information through the imposition of deterministic constraints on the eigendecomposition and the use of qualitative information about the system in the definition of the prior distribution. Limited observations of the state variable's evolution are used as data for inference, and the dependence on the solution of the inverse problem is studied as a function of the frequency of observations, as well as on whether or not the data is collected as a spatial or time series.",
        "published": "2021-05-05T00:32:28Z",
        "link": "http://arxiv.org/abs/2105.01807v2",
        "categories": [
            "stat.AP",
            "cs.CE"
        ]
    },
    {
        "title": "Space-time multilevel quadrature methods and their application for   cardiac electrophysiology",
        "authors": [
            "Seif Ben Bader",
            "Helmut Harbrecht",
            "Rolf Krause",
            "Michael Multerer",
            "Alessio Quaglino",
            "Marc Schmidlin"
        ],
        "summary": "We present a novel approach which aims at high-performance uncertainty quantification for cardiac electrophysiology simulations. Employing the monodomain equation to model the transmembrane potential inside the cardiac cells, we evaluate the effect of spatially correlated perturbations of the heart fibers on the statistics of the resulting quantities of interest. Our methodology relies on a close integration of multilevel quadrature methods, parallel iterative solvers and space-time finite element discretizations, allowing for a fully parallelized framework in space, time and stochastics. Extensive numerical studies are presented to evaluate convergence rates and to compare the performance of classical Monte Carlo methods such as standard Monte Carlo (MC) and quasi-Monte Carlo (QMC), as well as multilevel strategies, i.e. multilevel Monte Carlo (MLMC) and multilevel quasi-Monte Carlo (MLQMC) on hierarchies of nested meshes. Finally, we employ a recently suggested variant of the multilevel approach for non-nested meshes to deal with a realistic heart geometry.",
        "published": "2021-05-05T12:03:11Z",
        "link": "http://arxiv.org/abs/2105.02007v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Technical Report: Virtual X-ray imaging for higher-order finite element   results",
        "authors": [
            "Maximilian Bittens"
        ],
        "summary": "This work describes and demonstrates the operation of a virtual X-ray algorithm operating on finite-element post-processing results which allows for higher polynomial orders in geometry representation as well as density distribution. A nested hierarchy of oriented bounding boxes is used for preselecting candidate elements undergoing a ray-casting procedure. The exact intersection points of the ray with the finite element are not computed, instead the ray is discretized by a sequence of points. The element-local coordinates of each discretized point are determined using a local Newton-iteration and the resulting densities are accumulated. This procedure results in highly accurate virtual X-ray images of finite element models.",
        "published": "2021-05-06T13:31:58Z",
        "link": "http://arxiv.org/abs/2105.02651v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Deep Graph Convolutional Reinforcement Learning for Financial Portfolio   Management -- DeepPocket",
        "authors": [
            "Farzan Soleymani",
            "Eric Paquet"
        ],
        "summary": "Portfolio management aims at maximizing the return on investment while minimizing risk by continuously reallocating the assets forming the portfolio. These assets are not independent but correlated during a short time period. A graph convolutional reinforcement learning framework called DeepPocket is proposed whose objective is to exploit the time-varying interrelations between financial instruments. These interrelations are represented by a graph whose nodes correspond to the financial instruments while the edges correspond to a pair-wise correlation function in between assets. DeepPocket consists of a restricted, stacked autoencoder for feature extraction, a convolutional network to collect underlying local information shared among financial instruments, and an actor-critic reinforcement learning agent. The actor-critic structure contains two convolutional networks in which the actor learns and enforces an investment policy which is, in turn, evaluated by the critic in order to determine the best course of action by constantly reallocating the various portfolio assets to optimize the expected return on investment. The agent is initially trained offline with online stochastic batching on historical data. As new data become available, it is trained online with a passive concept drift approach to handle unexpected changes in their distributions. DeepPocket is evaluated against five real-life datasets over three distinct investment periods, including during the Covid-19 crisis, and clearly outperformed market indexes.",
        "published": "2021-05-06T15:07:36Z",
        "link": "http://arxiv.org/abs/2105.08664v1",
        "categories": [
            "q-fin.CP",
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "Vibration Analysis of Piezoelectric Kirchhoff-Love Shells based on   Catmull-Clark Subdivision Surfaces",
        "authors": [
            "Zhaowei Liu",
            "Andrew McBride",
            "Prashant Saxena",
            "Luca Heltai",
            "Yilin Qu",
            "Paul Steinmann"
        ],
        "summary": "An isogeometric Galerkin approach for analysing the free vibrations of piezoelectric shells is presented. The shell kinematics is specialised to infinitesimal deformations and follow the Kirchhoff-Love hypothesis. Both the geometry and physical fields are discretised using Catmull-Clark subdivision bases. It provides the required C1 continuous discretisation for the Kirchhoff-Love theory. The crystalline structure of piezoelectric materials is described using an anisotropic constitutive relation. Hamilton's variational principle is applied to the dynamic analysis to derive the weak form of the governing equations. The coupled eigenvalue problem is formulated by considering the problem of harmonic vibration in the absence of external load. The formulation for the purely elastic case is verified using a spherical thin shell benchmark. Thereafter, the piezoelectric effect and vibration modes of a transverse isotropic curved plate are analysed and evaluated for the Scordelis-Lo roof problem. Finally, the eigenvalue analysis of a CAD model of a piezoelectric speaker shell structure showcases the ability of the proposed method to handle complex geometries.",
        "published": "2021-05-06T23:55:48Z",
        "link": "http://arxiv.org/abs/2105.09288v1",
        "categories": [
            "math.NA",
            "cond-mat.mtrl-sci",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Modeling of Spiral Structure in a Multi-Component Milky~Way-Like Galaxy",
        "authors": [
            "Sergey Khrapov",
            "Alexander Khoperskov",
            "Vladimir Korchagin"
        ],
        "summary": "Using recent observational data, we construct a set of multi-component equilibrium models of the disk of a Milky Way-like galaxy. The disk dynamics are studied using collisionless-gaseous numerical simulations, based on the joined integration of the equations of motion for the collision-less particles using direct integration of gravitational interaction and the gaseous SPH-particles. We find that after approximately one Gyr, a prominent central bar is formed having a semi-axis length of about three kpc, together with a multi-armed spiral pattern represented by a superposition of $m=$ 2-, 3-, and 4-armed spirals. The spiral structure and the bar exist for at least 3 Gyr in our simulations. The existence of the Milky Way bar imposes limitations on the density distributions in the subsystems of the Milky Way galaxy. We find that a bar does not form if the radial scale length of the density distribution in the disk exceeds 2.6 kpc. As expected, the bar formation is also suppressed by a compact massive stellar bulge. We also demonstrate that the maximum value in the rotation curve of the disk of the Milky Way galaxy, as found in its central regions, is explained by non-circular motion due to the presence of a bar and its orientation relative to an observer.",
        "published": "2021-05-07T12:11:59Z",
        "link": "http://arxiv.org/abs/2105.03198v1",
        "categories": [
            "astro-ph.GA",
            "cs.CE"
        ]
    },
    {
        "title": "Numerical studies of CO$_2$ leakage remediation by micp-based plugging   technology",
        "authors": [
            "David Landa-Marbán",
            "Kundan Kumar",
            "Svenn Tveit",
            "Sarah Eileen Gasda"
        ],
        "summary": "Microbially induced calcite precipitation (MICP) is a technology for sealing leakage paths to ensure the safe storage of CO$_2$ in geological formations. In this work we introduce a numerical simulator of MICP for field-scale studies. This simulator is implemented in the open porous media (OPM) framework. We compare the numerical results to simulations using an upgraded implementation of the mathematical model in the MATLAB reservoir simulation toolbox (MRST). Finally, we consider a 3D system consisting of two aquifers separated by caprock with a leakage path across the width of the reservoir. We study a strategy where microbial solution is injected only at the beginning of the treatment and subsequently either growth solution or cementation solution is injected for biofilm development or calcite precipitation. By applying this strategy, the numerical results show that the MICP technology could be used to seal these leakage paths.",
        "published": "2021-05-07T12:35:37Z",
        "link": "http://arxiv.org/abs/2105.04382v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Local approximate Gaussian process regression for data-driven   constitutive laws: Development and comparison with neural networks",
        "authors": [
            "Jan Niklas Fuhg",
            "Michele Marino",
            "Nikolaos Bouklas"
        ],
        "summary": "Hierarchical computational methods for multiscale mechanics such as the FE$^2$ and FE-FFT methods are generally accompanied by high computational costs. Data-driven approaches are able to speed the process up significantly by enabling to incorporate the effective micromechanical response in macroscale simulations without the need of performing additional computations at each Gauss point explicitly. Traditionally artificial neural networks (ANNs) have been the surrogate modeling technique of choice in the solid mechanics community. However they suffer from severe drawbacks due to their parametric nature and suboptimal training and inference properties for the investigated datasets in a three dimensional setting. These problems can be avoided using local approximate Gaussian process regression (laGPR). This method can allow the prediction of stress outputs at particular strain space locations by training local regression models based on Gaussian processes, using only a subset of the data for each local model, offering better and more reliable accuracy than ANNs. A modified Newton-Raphson approach is proposed to accommodate for the local nature of the laGPR approximation when solving the global structural problem in a FE setting. Hence, the presented work offers a complete and general framework enabling multiscale calculations combining a data-driven constitutive prediction using laGPR, and macroscopic calculations using an FE scheme that we test for finite-strain three-dimensional hyperelastic problems.",
        "published": "2021-05-07T14:49:28Z",
        "link": "http://arxiv.org/abs/2105.04554v1",
        "categories": [
            "cs.CE",
            "cs.AI",
            "stat.ML",
            "35Q74 (Primary), 35Q62",
            "J.2; I.2.6; G.1.8"
        ]
    },
    {
        "title": "A level-set based space-time finite element approach to the modelling of   solidification and melting processes",
        "authors": [
            "Leonardo Boledi",
            "Benjamin Terschanski",
            "Stefanie Elgeti",
            "Julia Kowalski"
        ],
        "summary": "We present a strategy for the numerical solution of convection-coupled phase-transition problems, with focus on solidification and melting. We solve for the temperature and flow fields over time. The position of the phase-change interface is tracked with a level-set method, which requires knowledge of the heat-flux discontinuity at the interface. In order to compute the heat-flux jump, we build upon the ghost-cell approach and extend it to the space-time finite element method. This technique does not require a local enrichment of the basis functions, such as methods like extended finite elements, and it can be easily implemented in already existing finite element codes. Verification cases for the 1D Stefan problem and the lid-driven cavity melting problem are provided. Furthermore, we show a more elaborate 2D case in view of complex applications.",
        "published": "2021-05-07T17:07:48Z",
        "link": "http://arxiv.org/abs/2105.09286v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "physics.comp-ph"
        ]
    },
    {
        "title": "SimJEB: Simulated Jet Engine Bracket Dataset",
        "authors": [
            "Eamon Whalen",
            "Azariah Beyene",
            "Caitlin Mueller"
        ],
        "summary": "This paper introduces the Simulated Jet Engine Bracket Dataset (SimJEB): a new, public collection of crowdsourced mechanical brackets and accompanying structural simulations. SimJEB is applicable to a wide range of geometry processing tasks; the complexity of the shapes in SimJEB offer a challenge to automated geometry cleaning and meshing, while categorical labels and structural simulations facilitate classification and regression (i.e. engineering surrogate modeling). In contrast to existing shape collections, SimJEB's models are all designed for the same engineering function and thus have consistent structural loads and support conditions. On the other hand, SimJEB models are more complex, diverse, and realistic than the synthetically generated datasets commonly used in parametric surrogate model evaluation. The designs in SimJEB were derived from submissions to the GrabCAD Jet Engine Bracket Challenge: an open engineering design competition with over 700 hand-designed CAD entries from 320 designers representing 56 countries. Each model has been cleaned, categorized, meshed, and simulated with finite element analysis according to the original competition specifications. The result is a collection of 381 diverse, high-quality and application-focused designs for advancing geometric deep learning, engineering surrogate modeling, automated cleaning and related geometry processing tasks.",
        "published": "2021-05-07T23:24:21Z",
        "link": "http://arxiv.org/abs/2105.03534v2",
        "categories": [
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "Real-Time Prediction of Probabilistic Crack Growth with a Helicopter   Component Digital Twin",
        "authors": [
            "Xuan Zhou",
            "Shuangxin He",
            "Leiting Dong",
            "Satya N. Atluri"
        ],
        "summary": "To deploy the airframe digital twin or to conduct probabilistic evaluations of the remaining life of a structural component, a (near) real-time crack-growth simulation method is critical. In this paper, a reduced-order simulation approach is developed to achieve this goal by leveraging two methods. On the one hand, the symmetric Galerkin boundary element method - finite element method (SGBEM-FEM) coupling method is combined with parametric modeling to generate the database of computed stress intensity factors for cracks with various sizes/shapes in a complex structural component, by which hundreds of samples are automatically simulated within a day. On the other hand, machine learning methods are applied to establish the relation between crack sizes/shapes and crack-front stress intensity factors. By combining the reduced-order computational model with load inputs and fatigue growth laws, a real-time prediction of probabilistic crack growth in complex structures with minimum computational burden is realized. In an example of a round-robin helicopter component, even though the fatigue crack growth is simulated cycle by cycle, the simulation is faster than real-time (as compared with the physical test). The proposed approach is a key simulation technology toward realizing the digital twin of complex structures, which further requires fusion of model predictions with flight/inspection/monitoring data.",
        "published": "2021-05-08T10:42:28Z",
        "link": "http://arxiv.org/abs/2105.03668v3",
        "categories": [
            "physics.app-ph",
            "cs.CE",
            "physics.data-an"
        ]
    },
    {
        "title": "ELMOPP: An Application of Graph Theory and Machine Learning to Traffic   Light Coordination",
        "authors": [
            "Fareed Sheriff"
        ],
        "summary": "Traffic light management is a broad subject with various papers published that put forth algorithms to efficiently manage traffic using traffic lights. Two such algorithms are the OAF (oldest arrival first) and ITLC (intelligent traffic light controller) algorithms. However, many traffic light algorithms do not consider future traffic flow and therefore cannot mitigate traffic in such a way as to reduce future traffic in the present. This paper presents the Edge Load Management and Optimization through Pseudoflow Prediction (ELMOPP) algorithm, which aims to solve problems detailed in previous algorithms; through machine learning with nested long short-term memory (NLSTM) modules and graph theory, the algorithm attempts to predict the near future using past data and traffic patterns to inform its real-time decisions and better mitigate traffic by predicting future traffic flow based on past flow and using those predictions to both maximize present traffic flow and decrease future traffic congestion. Furthermore, while ITLC and OAF require the use of GPS transponders; and GPS, speed sensors, and radio, respectively, ELMOPP only uses traffic light camera footage, something that is almost always readily available in contrast to GPS and speed sensors. ELMOPP was tested against the ITLC and OAF traffic management algorithms using a simulation modeled after the one presented in the ITLC paper, a single-intersection simulation, and the collected data supports the conclusion that ELMOPP statistically significantly outperforms both algorithms in throughput rate, a measure of how many vehicles are able to exit inroads every second.",
        "published": "2021-05-08T20:57:29Z",
        "link": "http://arxiv.org/abs/2106.10104v1",
        "categories": [
            "cs.CE",
            "cs.CY",
            "C.3; J.2; J.7"
        ]
    },
    {
        "title": "Infill topology and shape optimisation of lattice-skin structures",
        "authors": [
            "Xiao Xiao",
            "Fehmi Cirak"
        ],
        "summary": "Lattice-skin structures composed of a thin-shell skin and a lattice infill are widespread in nature and large-scale engineering due to their efficiency and exceptional mechanical properties. Recent advances in additive manufacturing, or 3D printing, make it possible to create lattice-skin structures of almost any size with arbitrary shape and geometric complexity. We propose a novel gradient-based approach to optimising both the shape and infill of lattice-skin structures to improve their efficiency further. The respective gradients are computed by fully considering the lattice-skin coupling while the lattice topology and shape optimisation problems are solved in a sequential manner. The shell is modelled as a Kirchhoff-Love shell and analysed using isogeometric subdivision surfaces, whereas the lattice is modelled as a pin-jointed truss. The lattice consists of many cells, possibly of different sizes, with each containing a small number of struts. We propose a penalisation approach akin to the SIMP (solid isotropic material with penalisation) method for topology optimisation of the lattice. Furthermore, a corresponding sensitivity filter and a lattice extraction technique are introduced to ensure the stability of the optimisation process and to eliminate scattered struts of small cross-sectional areas. The developed topology optimisation technique is suitable for non-periodic, non-uniform lattices. For shape optimisation of both the shell and the lattice, the geometry of the lattice-skin structure is parameterised using the free-form deformation technique. The topology and shape optimisation problems are solved in an iterative, sequential manner. The effectiveness of the proposed approach and the influence of different algorithmic parameters are demonstrated with several numerical examples.",
        "published": "2021-05-09T20:33:26Z",
        "link": "http://arxiv.org/abs/2105.04017v3",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Designing Air Flow with Surrogate-assisted Phenotypic Niching",
        "authors": [
            "Alexander Hagg",
            "Dominik Wilde",
            "Alexander Asteroth",
            "Thomas Bäck"
        ],
        "summary": "In complex, expensive optimization domains we often narrowly focus on finding high performing solutions, instead of expanding our understanding of the domain itself. But what if we could quickly understand the complex behaviors that can emerge in said domains instead? We introduce surrogate-assisted phenotypic niching, a quality diversity algorithm which allows to discover a large, diverse set of behaviors by using computationally expensive phenotypic features. In this work we discover the types of air flow in a 2D fluid dynamics optimization problem. A fast GPU-based fluid dynamics solver is used in conjunction with surrogate models to accurately predict fluid characteristics from the shapes that produce the air flow. We show that these features can be modeled in a data-driven way while sampling to improve performance, rather than explicitly sampling to improve feature models. Our method can reduce the need to run an infeasibly large set of simulations while still being able to design a large diversity of air flows and the shapes that cause them. Discovering diversity of behaviors helps engineers to better understand expensive domains and their solutions.",
        "published": "2021-05-10T10:45:28Z",
        "link": "http://arxiv.org/abs/2105.04256v1",
        "categories": [
            "cs.NE",
            "cs.CE",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "A shape optimisation with the isogeometric boundary element method and   adjoint variable method for the three-dimensional Helmholtz equation",
        "authors": [
            "Toru Takahashi",
            "Daisuke Sato",
            "Hiroshi Isakari",
            "Toshiro Matsumoto"
        ],
        "summary": "This paper presents a shape optimisation system to design the shape of an acoustically-hard object in the three-dimensional open space. Boundary element method (BEM) is suitable to analyse such an exterior field. However, the conventional BEM, which is based on piecewise polynomial shape and interpolation functions, can require many design variables because they are usually chosen as a part of the nodes of the underlying boundary element mesh. In addition, it is not easy for the conventional method to compute the gradient of the sound pressure on the surface, which is necessary to compute the shape derivative of our interest, of a given object. To overcome these issues, we employ the isogeometric boundary element method (IGBEM), which was developed in our previous work. With using the IGBEM, we can design the shape of surfaces through control points of the NURBS surfaces of the target object. We integrate the IGBEM with the nonlinear programming software through the adjoint variable method (AVM), where the resulting adjoint boundary value problem can be also solved by the IGBEM with a slight modification. The numerical verification and demonstration validate our shape optimisation framework.",
        "published": "2021-05-10T15:43:54Z",
        "link": "http://arxiv.org/abs/2105.04456v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Constraint-Based Inference of Heuristics for Foreign Exchange Trade   Model Optimization",
        "authors": [
            "Nikolay Ivanov",
            "Qiben Yan"
        ],
        "summary": "The Foreign Exchange (Forex) is a large decentralized market, on which trading analysis and algorithmic trading are popular. Research efforts have been focusing on proof of efficiency of certain technical indicators. We demonstrate, however, that the values of indicator functions are not reproducible and often reduce the number of trade opportunities, compared to price-action trading.   In this work, we develop two dataset-agnostic Forex trading heuristic templates with high rate of trading signals. In order to determine most optimal parameters for the given heuristic prototypes, we perform a machine learning simulation of 10 years of Forex price data over three low-margin instruments and 6 different OHLC granularities. As a result, we develop a specific and reproducible list of most optimal trade parameters found for each instrument-granularity pair, with 118 pips of average daily profit for the optimized configuration.",
        "published": "2021-05-11T00:36:02Z",
        "link": "http://arxiv.org/abs/2105.14194v1",
        "categories": [
            "q-fin.ST",
            "cs.AI",
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "Discovery of Nonlinear Dynamical Systems using a Runge-Kutta Inspired   Dictionary-based Sparse Regression Approach",
        "authors": [
            "Pawan Goyal",
            "Peter Benner"
        ],
        "summary": "Discovering dynamical models to describe underlying dynamical behavior is essential to draw decisive conclusions and engineering studies, e.g., optimizing a process. Experimental data availability notwithstanding has increased significantly, but interpretable and explainable models in science and engineering yet remain incomprehensible. In this work, we blend machine learning and dictionary-based learning with numerical analysis tools to discover governing differential equations from noisy and sparsely-sampled measurement data. We utilize the fact that given a dictionary containing huge candidate nonlinear functions, dynamical models can often be described by a few appropriately chosen candidates. As a result, we obtain interpretable and parsimonious models which are prone to generalize better beyond the sampling regime. Additionally, we integrate a numerical integration framework with dictionary learning that yields differential equations without requiring or approximating derivative information at any stage. Hence, it is utterly effective in corrupted and sparsely-sampled data. We discuss its extension to governing equations, containing rational nonlinearities that typically appear in biological networks. Moreover, we generalized the method to governing equations that are subject to parameter variations and externally controlled inputs. We demonstrate the efficiency of the method to discover a number of diverse differential equations using noisy measurements, including a model describing neural dynamics, chaotic Lorenz model, Michaelis-Menten Kinetics, and a parameterized Hopf normal form.",
        "published": "2021-05-11T08:46:51Z",
        "link": "http://arxiv.org/abs/2105.04869v1",
        "categories": [
            "cs.LG",
            "cs.CE"
        ]
    },
    {
        "title": "Stable finite difference methods for Kirchhoff-Love plates on   overlapping grids",
        "authors": [
            "Longfei Li",
            "Hangjie Ji",
            "Qi Tang"
        ],
        "summary": "In this work, we propose and develop efficient and accurate numerical methods for solving the Kirchhoff-Love plate model in domains with complex geometries. The algorithms proposed here employ curvilinear finite-difference methods for spatial discretization of the governing PDEs on general composite overlapping grids. The coupling of different components of the composite overlapping grid is through numerical interpolations. However, interpolations introduce perturbation to the finite-difference discretization, which causes numerical instability for time-stepping schemes used to advance the resulted semi-discrete system. To address the instability, we propose to add a fourth-order hyper-dissipation to the spatially discretized system to stabilize its time integration; this additional dissipation term captures the essential upwinding effect of the original upwind scheme. The investigation of strategies for incorporating the upwind dissipation term into several time-stepping schemes (both explicit and implicit) leads to the development of four novel algorithms. For each algorithm, formulas for determining a stable time step and a sufficient dissipation coefficient on curvilinear grids are derived by performing a local Fourier analysis. Quadratic eigenvalue problems for a simplified model plate in 1D domain are considered to reveal the weak instability due to the presence of interpolating equations in the spatial discretization. This model problem is further investigated for the stabilization effects of the proposed algorithms. Carefully designed numerical experiments are carried out to validate the accuracy and stability of the proposed algorithms, followed by two benchmark problems to demonstrate the capability and efficiency of our approach for solving realistic applications. Results that concern the performance of the proposed algorithms are also presented.",
        "published": "2021-05-12T02:13:33Z",
        "link": "http://arxiv.org/abs/2105.05401v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "A local-global generalized multiscale finite element method for highly   heterogeneous stochastic groundwater flow problems",
        "authors": [
            "Yiran Wang",
            "Eric Chung",
            "Shubin Fu"
        ],
        "summary": "In this paper, we propose a local-global multiscale method for highly heterogeneous stochastic groundwater flow problems under the framework of reduced basis method and the generalized multiscale finite element method (GMsFEM). Due to incomplete characterization of the medium properties of the groundwater flow problems, random variables are used to parameterize the uncertainty. As a result, solving the problem repeatedly is required to obtain statistical quantities. Besides, the medium properties are usually highly heterogeneous, which will result in a large linear system that needs to be solved. Therefore, it is intrinsically inevitable to seek a computational-efficient model reduction method to overcome the difficulty. We will explore the combination of the reduced basis method and the GMsFEM. In particular, we will use residual-driven basis functions, which are key ingredients in GMsFEM. This local-global multiscale method is more efficient than applying the GMsFEM or reduced basis method individually. We first construct parameter-independent multiscale basis functions that include both local and global information of the permeability fields, and then use these basis functions to construct several global snapshots and global basis functions for fast online computation with different parameter inputs. We provide rigorous analysis of the proposed method and extensive numerical examples to demonstrate the accuracy and efficiency of the local-global multiscale method.",
        "published": "2021-05-12T03:25:40Z",
        "link": "http://arxiv.org/abs/2105.05413v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "A monolithic fluid-porous structure interaction finite element method",
        "authors": [
            "Alexander Lozovskiy",
            "Maxim A. Olshanskii",
            "Yuri V. Vassilevski"
        ],
        "summary": "The paper introduces a fully discrete quasi-Lagrangian finite element method for a monolithic formulation of a fluid-porous structure interaction problem. The method is second order in time and allows a standard $P_2-P_1$ (Taylor--Hood) finite element spaces for fluid problems in both fluid and porous domains. The performance of the method is illustrated on a series of numerical experiments.",
        "published": "2021-05-12T07:51:29Z",
        "link": "http://arxiv.org/abs/2105.05487v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "physics.comp-ph",
            "76S05"
        ]
    },
    {
        "title": "A Mathematical Definition of Particle Methods",
        "authors": [
            "Johannes Bamme",
            "Ivo F. Sbalzarini"
        ],
        "summary": "We provide a formal definition for a class of algorithms known as \"particle methods\". Particle methods are used in scientific computing. They include popular simulation methods, such as Discrete Element Methods (DEM), Molecular Dynamics (MD), Particle Strength Exchange (PSE), and Smoothed Particle Hydrodynamics (SPH), but also particle-based image processing methods, point-based computer graphics, and computational optimization algorithms using point samples. All of these rest on a common concept, which we here formally define. The presented definition of particle methods makes it possible to distinguish what formally constitutes a particle method, and what not. It also enables us to define different sub-classes of particle methods that differ with respect to their computational complexity and power. Our definition is purely formal, independent of any application. After stating the definition, we therefore illustrate how several well-known particle methods can be formalized in our framework, and we show how the formal definition can be used to formulate novel particle methods for non-canonical problems.",
        "published": "2021-05-12T13:09:31Z",
        "link": "http://arxiv.org/abs/2105.05637v1",
        "categories": [
            "cs.DS",
            "cs.CE"
        ]
    },
    {
        "title": "Combining Set Propagation with Finite Element Methods for Time   Integration in Transient Solid Mechanics Problems",
        "authors": [
            "Marcelo Forets",
            "Daniel Freire Caporale",
            "Jorge M. Pérez Zerpa"
        ],
        "summary": "The Finite Element Method (FEM) is the gold standard for spatial discretization in numerical simulations for a wide spectrum of real-world engineering problems. Prototypical areas of interest include linear heat transfer and linear structural dynamics problems modeled with partial differential equations (PDEs). While different algorithms for direct integration of the equations of motion exist, exploring all feasible behaviors for varying loads, initial states and fluxes in models with large numbers of degrees of freedom remains a challenging task. In this article we propose a novel approach, based in set propagation methods and motivated by recent advances in the field of Reachability Analysis. Assuming a set of initial states and inputs, the proposed method consists in the construction of a union of sets (flowpipe) that enclose the infinite number of solutions of the spatially discretized PDE. We present the numerical results obtained in five examples to illustrate the capabilities of our approach, and compare its performance against reference numerical integration methods. We conclude that, for problems with single known initial conditions, the proposed method is accurate. For problems with uncertain initial conditions included in sets, the proposed method can compute all the solutions of the system more efficiently than numerical integration methods.",
        "published": "2021-05-12T17:56:07Z",
        "link": "http://arxiv.org/abs/2105.05841v2",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Composing Modeling and Simulation with Machine Learning in Julia",
        "authors": [
            "Chris Rackauckas",
            "Ranjan Anantharaman",
            "Alan Edelman",
            "Shashi Gowda",
            "Maja Gwozdz",
            "Anand Jain",
            "Chris Laughman",
            "Yingbo Ma",
            "Francesco Martinuzzi",
            "Avik Pal",
            "Utkarsh Rajput",
            "Elliot Saba",
            "Viral B. Shah"
        ],
        "summary": "In this paper we introduce JuliaSim, a high-performance programming environment designed to blend traditional modeling and simulation with machine learning. JuliaSim can build accelerated surrogates from component-based models, such as those conforming to the FMI standard, using continuous-time echo state networks (CTESN). The foundation of this environment, ModelingToolkit.jl, is an acausal modeling language which can compose the trained surrogates as components within its staged compilation process. As a complementary factor we present the JuliaSim model library, a standard library with differential-algebraic equations and pre-trained surrogates, which can be composed using the modeling system for design, optimization, and control. We demonstrate the effectiveness of the surrogate-accelerated modeling and simulation approach on HVAC dynamics by showing that the CTESN surrogates accurately capture the dynamics of a HVAC cycle at less than 4\\% error while accelerating its simulation by 340x. We illustrate the use of surrogate acceleration in the design process via global optimization of simulation parameters using the embedded surrogate, yielding a speedup of two orders of magnitude to find the optimum. We showcase the surrogate deployed in a co-simulation loop, as a drop-in replacement for one of the coupled FMUs, allowing engineers to effectively explore the design space of a coupled system. Together this demonstrates a workflow for automating the integration of machine learning techniques into traditional modeling and simulation processes.",
        "published": "2021-05-12T20:21:50Z",
        "link": "http://arxiv.org/abs/2105.05946v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "SPUX Framework: a Scalable Package for Bayesian Uncertainty   Quantification and Propagation",
        "authors": [
            "Jonas Šukys",
            "Marco Bacci"
        ],
        "summary": "We present SPUX - a modular framework for Bayesian inference enabling uncertainty quantification and propagation in linear and nonlinear, deterministic and stochastic models, and supporting Bayesian model selection. SPUX can be coupled to any serial or parallel application written in any programming language, (e.g. including Python, R, Julia, C/C++, Fortran, Java, or a binary executable), scales effortlessly from serial runs on a personal computer to parallel high performance computing clusters, and aims to provide a platform particularly suited to support and foster reproducibility in computational science. We illustrate SPUX capabilities for a simple yet representative random walk model, describe how to couple different types of user applications, and showcase several readily available examples from environmental sciences. In addition to available state-of-the-art numerical inference algorithms including EMCEE, PMCMC (PF) and SABC, the open source nature of the SPUX framework and the explicit description of the hierarchical parallel SPUX executors should also greatly simplify the implementation and usage of other inference and optimization techniques.",
        "published": "2021-05-12T21:16:24Z",
        "link": "http://arxiv.org/abs/2105.05969v1",
        "categories": [
            "stat.CO",
            "cs.CE",
            "cs.MS"
        ]
    },
    {
        "title": "A general and fast convolution-based method for peridynamics:   applications to elasticity and brittle fracture",
        "authors": [
            "Siavash Jafarzadeh",
            "Farzaneh Mousavi",
            "Adam Larios",
            "Florin Bobaru"
        ],
        "summary": "We introduce a general and fast convolution-based method (FCBM) for peridynamics (PD). Expressing the PD integrals in terms of convolutions and computing them by fast Fourier transform (FFT), we reduce the computational complexity of PD models from O(N^2) to O(Nlog_2 N), with N being the total number of discretization nodes. Initial neighbor identification and storing neighbor information is not required, and, as a consequence, memory allocation scales with O(N) instead of O(N^2), common for existing methods. The method is applicable to bounded domains with arbitrary shapes and boundary conditions via an embedded constraint (EC) approach. We explain the FCBM-EC formulation for certain bond-based and state-based, linear and nonlinear PD models of elasticity and dynamic brittle fracture, as applications. We solve a 3D elastostatic problem and show that the FCBM reduces the computational time from days to hours and from years to days, compared with the original meshfree discretization for PD models. Large-scale computations of PD models are feasible with the new method, and we demonstrate its versatility by simulating, with ease, the difficult problem of multiple crack branching in a brittle plate.",
        "published": "2021-05-13T03:12:19Z",
        "link": "http://arxiv.org/abs/2105.06055v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "The cross-sectional distribution of portfolio returns and applications",
        "authors": [
            "Ludovic Calès",
            "Apostolos Chalkis",
            "Ioannis Z. Emiris"
        ],
        "summary": "This paper aims to develop new mathematical and computational tools for modeling the distribution of portfolio returns across portfolios. We establish relevant mathematical formulas and propose efficient algorithms, drawing upon powerful techniques in computational geometry and the literature on splines, to compute the probability density function, the cumulative distribution function, and the k-th moment of the probability function. Our algorithmic tools and implementations efficiently handle portfolios with 10000 assets, and compute moments of order k up to 40 in a few seconds, thus handling real-life scenarios. We focus on the long-only strategy which is the most common type of investment, i.e. on portfolios whose weights are non-negative and sum up to 1; our approach is readily generalizable. Thus, we leverage a geometric representation of the stock market, where the investment set defines a simplex polytope. The cumulative distribution function corresponds to a portfolio score capturing the percentage of portfolios yielding a return not exceeding a given value. We introduce closed-form analytic formulas for the first 4 moments of the cross-sectional returns distribution, as well as a novel algorithm to compute all higher moments. We show that the first 4 moments are a direct mapping of the asset returns' moments. All of our algorithms and solutions are fully general and include the special case of equal asset returns, which was sometimes excluded in previous works. Finally, we apply our portfolio score in the design of new performance measures and asset management. We found our score-based optimal portfolios less concentrated than the mean-variance portfolio and much less risky in terms of ranking.",
        "published": "2021-05-13T22:29:12Z",
        "link": "http://arxiv.org/abs/2105.06573v1",
        "categories": [
            "cs.CE",
            "econ.TH",
            "stat.AP",
            "62P20, 62-08, 52-08",
            "G.3; I.6"
        ]
    },
    {
        "title": "Learning Unknown from Correlations: Graph Neural Network for   Inter-novel-protein Interaction Prediction",
        "authors": [
            "Guofeng Lv",
            "Zhiqiang Hu",
            "Yanguang Bi",
            "Shaoting Zhang"
        ],
        "summary": "The study of multi-type Protein-Protein Interaction (PPI) is fundamental for understanding biological processes from a systematic perspective and revealing disease mechanisms. Existing methods suffer from significant performance degradation when tested in unseen dataset. In this paper, we investigate the problem and find that it is mainly attributed to the poor performance for inter-novel-protein interaction prediction. However, current evaluations overlook the inter-novel-protein interactions, and thus fail to give an instructive assessment. As a result, we propose to address the problem from both the evaluation and the methodology. Firstly, we design a new evaluation framework that fully respects the inter-novel-protein interactions and gives consistent assessment across datasets. Secondly, we argue that correlations between proteins must provide useful information for analysis of novel proteins, and based on this, we propose a graph neural network based method (GNN-PPI) for better inter-novel-protein interaction prediction. Experimental results on real-world datasets of different scales demonstrate that GNN-PPI significantly outperforms state-of-the-art PPI prediction methods, especially for the inter-novel-protein interaction prediction.",
        "published": "2021-05-14T08:42:55Z",
        "link": "http://arxiv.org/abs/2105.06709v3",
        "categories": [
            "cs.LG",
            "cs.CE"
        ]
    },
    {
        "title": "Partitioned Deep Learning of Fluid-Structure Interaction",
        "authors": [
            "Amin Totounferoush",
            "Axel Schumacher",
            "Miriam Schulte"
        ],
        "summary": "We present a partitioned neural network-based framework for learning of fluid-structure interaction (FSI) problems. We decompose the simulation domain into two smaller sub-domains, i.e., fluid and solid domains, and incorporate an independent neural network for each. A library is used to couple the two networks which takes care of boundary data communication, data mapping and equation coupling. Simulation data are used for training of the both neural networks. We use a combination of convolutional and recurrent neural networks (CNN and RNN) to account for both spatial and temporal connectivity. A quasi-Newton method is used to accelerate the FSI coupling convergence. We observe a very good agreement between the results of the presented framework and the classical numerical methods for simulation of 1d fluid flow inside an elastic tube. This work is a preliminary step for using neural networks to speed-up the FSI coupling convergence by providing an accurate initial guess in each time step for classical numerical solvers",
        "published": "2021-05-14T12:09:03Z",
        "link": "http://arxiv.org/abs/2105.06785v1",
        "categories": [
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "Circumferential Crack Modeling of Thin Cylindrical Shells in Modal   Deformation",
        "authors": [
            "Ali Alijani",
            "Olga Barrera",
            "Stephane P. A. Bordas"
        ],
        "summary": "An innovative technique, called conversion, is introduced to model circumferential cracks in thin cylindrical shells. The semi-analytical finite element method is applied to investigate the modal deformation of the cylinder. An element including the crack is divided into three sub-elements with four nodes in which the stiffness matrix is enriched. The crack characteristics are included in the finite element method relations through conversion matrices and a rotational spring corresponding to the crack. Conversion matrices obtained by applying continuity conditions at the crack tip are used to transform displacements of the middle nodes to those of the main nodes. Moreover, another technique, called spring set, is represented based on a set of springs to model the crack as a separated element. Components of the stiffness matrix related to the separated element are incorporated while the geometric boundary conditions at the crack tip are satisfied. The effects of the circumferential mode number, the crack depth and the length of the cylinder on the critical buckling load are investigated. Experimental tests, ABAQUS modeling and results from literature are used to verify and validate the results and derived relations. In addition, the crack effect on the natural frequency is examined using the vibration analysis based on the conversion technique.",
        "published": "2021-05-15T20:18:12Z",
        "link": "http://arxiv.org/abs/2105.07290v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "A non-intrusive reduced-order modelling for uncertainty propagation of   time-dependent problems using a B-splines Bézier elements-based method and   Proper Orthogonal Decomposition: application to dam-break flows",
        "authors": [
            "Azzedine Abdedou",
            "Azzeddine Soulaïmani"
        ],
        "summary": "A proper orthogonal decomposition-based B-splines B\\'ezier elements method (POD-BSBEM) is proposed as a non-intrusive reduced-order model for uncertainty propagation analysis for stochastic time-dependent problems. The method uses a two-step proper orthogonal decomposition (POD) technique to extract the reduced basis from a collection of high-fidelity solutions called snapshots. A third POD level is then applied on the data of the projection coefficients associated with the reduced basis to separate the time-dependent modes from the stochastic parametrized coefficients. These are approximated in the stochastic parameter space using B-splines basis functions defined in the corresponding B\\'ezier element. The accuracy and the efficiency of the proposed method are assessed using benchmark steady-state and time-dependent problems and compared to the reduced order model-based artificial neural network (POD-ANN) and to the full-order model-based polynomial chaos expansion (Full-PCE). The POD-BSBEM is then applied to analyze the uncertainty propagation through a flood wave flow stemming from a hypothetical dam-break in a river with a complex bathymetry. The results confirm the ability of the POD-BSBEM to accurately predict the statistical moments of the output quantities of interest with a substantial speed-up for both offline and online stages compared to other techniques.",
        "published": "2021-05-15T20:28:19Z",
        "link": "http://arxiv.org/abs/2105.09300v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Efficient yield optimization with limited gradient information",
        "authors": [
            "Mona Fuhrländer",
            "Sebastian Schöps"
        ],
        "summary": "In this work an efficient strategy for yield optimization with uncertain and deterministic optimization variables is presented. The gradient based adaptive Newton-Monte Carlo method is modified, such that it can handle variables with (uncertain parameters) and without (deterministic parameters) analytical gradient information. This mixed strategy is numerically compared to derivative free approaches.",
        "published": "2021-05-17T13:14:49Z",
        "link": "http://arxiv.org/abs/2105.07799v1",
        "categories": [
            "cs.CE",
            "60G15, 60H35, 65K99, 78M31,",
            "G.1.1; G.1.2; G.1.6; G.3"
        ]
    },
    {
        "title": "Generalized smoothed particle hydrodynamics with overset methods in   total Lagrangian formulations",
        "authors": [
            "Huachao Deng",
            "Yoshiaki Abe",
            "Tomonaga Okabe"
        ],
        "summary": "This study proposes a generalized coordinates based smoothed particle hydrodynamics (GSPH) method with overset methods using a Total Lagrangian (TL) formulation for large deformation and crack propagation problems. In the proposed GSPH, the physical space is decomposed into multiple domains, each of which is mapped to a local coordinate space (generalized space) to avoid coordinate singularities as well as to flexibly change the spatial resolution. The smoothed particle hydrodynamics (SPH) particles are then non-uniformly, e.g., typically in the boundary-conforming way, distributed in the physical space while they are defined uniformly in each generalized space similarly to the normal SPH method, which are numerically related by a coordinate transformation matrix. By solving a governing equation in each generalized space, the shape and size of the SPH kernel can be spatially changed in the physical space so that a spatial resolution is adaptively varied a priori depending on the deformation characteristics, and thus, a low-cost calculation with the less number of particles is achieved in complex shape structures.",
        "published": "2021-05-18T03:09:56Z",
        "link": "http://arxiv.org/abs/2105.10035v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "BBE: Simulating the Microstructural Dynamics of an In-Play Betting   Exchange via Agent-Based Modelling",
        "authors": [
            "Dave Cliff"
        ],
        "summary": "I describe the rationale for, and design of, an agent-based simulation model of a contemporary online sports-betting exchange: such exchanges, closely related to the exchange mechanisms at the heart of major financial markets, have revolutionized the gambling industry in the past 20 years, but gathering sufficiently large quantities of rich and temporally high-resolution data from real exchanges - i.e., the sort of data that is needed in large quantities for Deep Learning - is often very expensive, and sometimes simply impossible; this creates a need for a plausibly realistic synthetic data generator, which is what this simulation now provides. The simulator, named the \"Bristol Betting Exchange\" (BBE), is intended as a common platform, a data-source and experimental test-bed, for researchers studying the application of AI and machine learning (ML) techniques to issues arising in betting exchanges; and, as far as I have been able to determine, BBE is the first of its kind: a free open-source agent-based simulation model consisting not only of a sports-betting exchange, but also a minimal simulation model of racetrack sporting events (e.g., horse-races or car-races) about which bets may be made, and a population of simulated bettors who each form their own private evaluation of odds and place bets on the exchange before and - crucially - during the race itself (i.e., so-called \"in-play\" betting) and whose betting opinions change second-by-second as each race event unfolds. BBE is offered as a proof-of-concept system that enables the generation of large high-resolution data-sets for automated discovery or improvement of profitable strategies for betting on sporting events via the application of AI/ML and advanced data analytics techniques. This paper offers an extensive survey of relevant literature and explains the motivation and design of BBE, and presents brief illustrative results.",
        "published": "2021-05-18T06:52:08Z",
        "link": "http://arxiv.org/abs/2105.08310v1",
        "categories": [
            "cs.MA",
            "cs.CE",
            "q-fin.CP",
            "q-fin.TR",
            "stat.ML"
        ]
    },
    {
        "title": "Efficient sequential PLIC interface positioning for enhanced performance   of the three-phase VoF Method",
        "authors": [
            "Johannes Kromer",
            "Johanna Potyka",
            "Kathrin Schulte",
            "Dieter Bothe"
        ],
        "summary": "This paper presents an efficient algorithm for the sequential positioning, also called nested dissection, of two planes in an arbitrary polyhedron. Two planar interfaces are positioned such that the first plane truncates a given volume from this arbitrary polyhedron and the next plane truncates a second given volume from the residual polyhedron. This is a relevant task in the numerical simulation of three-phase flows when resorting to the geometric Volume-of-Fluid (VoF) method with a Piecewise Linear Interface Calculation (PLIC). An efficient algorithm for this task significantly speeds up the three-phase PLIC algorithm. The present study describes a method based on a recursive application of the Gaussian divergence theorem, where the fact that the truncated polyhedron shares multiple faces with the original polyhedron can be exploited to reduce the computational effort. A careful choice of the coordinate system origin for the volume computation allows for successive positioning of two planes without reestablishing polyhedron connectivity. Combined with a highly efficient root finding, this results in a significant performance gain in the reconstruction of the three-phase interface configurations.   The performance of the new method is assessed in a series of carefully designed numerical experiments. Compared to a conventional decomposition-based approach, the number of iterations and, thus, of the required truncations was reduced by up to an order of magnitude. The PLIC positioning run-time was reduced by about 90% in our reference implementation. Integrated into the multi-phase flow solver Free Surface 3D (FS3D), an overall performance gain of about 20% was achieved. Allowing for simple integration into existing numerical schemes, the proposed algorithm is self-contained (example Fortran Module see https://doi.org/10.18419/darus-2488), requiring no external decomposition libraries.",
        "published": "2021-05-19T07:52:00Z",
        "link": "http://arxiv.org/abs/2105.08972v3",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Preconditioning for a pressure-robust HDG discretization of the Stokes   equations",
        "authors": [
            "Sander Rhebergen",
            "Garth N. Wells"
        ],
        "summary": "We introduce a new preconditioner for a recently developed pressure-robust hybridized discontinuous Galerkin (HDG) finite element discretization of the Stokes equations. A feature of HDG methods is the straightforward elimination of degrees-of-freedom defined on the interior of an element. In our previous work (J. Sci. Comput., 77(3):1936--1952, 2018) we introduced a preconditioner for the case in which only the degrees-of-freedom associated with the element velocity were eliminated via static condensation. In this work we introduce a preconditioner for the statically condensed system in which the element pressure degrees-of-freedom are also eliminated. In doing so the number of globally coupled degrees-of-freedom are reduced, but at the expense of a more difficult problem to analyse. We will show, however, that the Schur complement of the statically condensed system is spectrally equivalent to a simple trace pressure mass matrix. This result is used to formulate a new, provably optimal preconditioner. Through numerical examples in two- and three-dimensions we show that the new preconditioned iterative method converges in fewer iterations, has superior conservation properties for inexact solves, and is faster in CPU time when compared to our previous preconditioner.",
        "published": "2021-05-19T14:17:19Z",
        "link": "http://arxiv.org/abs/2105.09152v2",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "65F08, 65N30, 76D07"
        ]
    },
    {
        "title": "An examination of local strain fields evolution in ductile cast iron   through micromechanical simulations based on 3D imaging",
        "authors": [
            "Victor Manuel Trejo Navas",
            "Ante Buljac",
            "François Hild",
            "Thilo F. Morgeneyer",
            "Marc Bernacki",
            "Pierre-Olivier Bouchard"
        ],
        "summary": "Microscopic digital volume correlation (DVC) and finite element precoalescence strain evaluations are compared for two nodular cast iron specimens. Displacement fields from \\textit{in-situ} 3D synchrotron laminography images are obtained by DVC. Subsequently the microstructure is explicitely meshed from the images considering nodules as voids. Boundary conditions are applied from the DVC measurement. Image segmentation-related uncertainties are taken into account and observed to be negligible with respect to the differences between strain levels. Macroscopic as well as local strain levels in coalescing ligaments between voids nucleated at large graphite nodules are compared. Macroscopic strain levels are consistently predicted. A very good agreement is observed for one of the specimens, while the strain levels for the second specimen presents some discrepancies. Limitations of the modeling and numerical framework are discussed in light of these differences. A discussion of the use of strain as coalescence indicator is initiated.",
        "published": "2021-05-19T14:52:03Z",
        "link": "http://arxiv.org/abs/2105.09859v3",
        "categories": [
            "cond-mat.mtrl-sci",
            "cs.CE"
        ]
    },
    {
        "title": "On the nonlinear stochastic dynamics of a continuous system with   discrete attached elements",
        "authors": [
            "Americo Cunha Jr",
            "Rubens Sampaio"
        ],
        "summary": "This paper presents a theoretical study on the influence of a discrete element in the nonlinear dynamics of a continuous mechanical system subject to randomness in the model parameters. This system is composed by an elastic bar, attached to springs and a lumped mass, with a random elastic modulus and subjected to a Gaussian white-noise distributed external force. One can note that the dynamic behavior of the bar is significantly altered when the lumped mass is varied, becoming, on the right extreme and for large values of the concentrated mass, similar to a mass-spring system. It is also observed that the system response is more influenced by the randomness for small values of the lumped mass. The study conducted also show an irregular distribution of energy through the spectrum of frequencies, asymmetries and multimodal behavior in the probability distributions of the lumped mass velocity.",
        "published": "2021-05-21T01:26:57Z",
        "link": "http://arxiv.org/abs/2105.10084v1",
        "categories": [
            "cond-mat.stat-mech",
            "cs.CE",
            "math.DS",
            "stat.AP",
            "stat.CO",
            "70Lxx",
            "I.6.6"
        ]
    },
    {
        "title": "Addressing the Multiplicity of Solutions in Optical Lens Design as a   Niching Evolutionary Algorithms Computational Challenge",
        "authors": [
            "Anna V. Kononova",
            "Ofer M. Shir",
            "Teus Tukker",
            "Pierluigi Frisco",
            "Shutong Zeng",
            "Thomas Bäck"
        ],
        "summary": "Optimal Lens Design constitutes a fundamental, long-standing real-world optimization challenge. Potentially large number of optima, rich variety of critical points, as well as solid understanding of certain optimal designs per simple problem instances, provide altogether the motivation to address it as a niching challenge. This study applies established Niching-CMA-ES heuristic to tackle this design problem (6-dimensional Cooke triplet) in a simulation-based fashion. The outcome of employing Niching-CMA-ES `out-of-the-box' proves successful, and yet it performs best when assisted by a local searcher which accurately drives the search into optima. The obtained search-points are corroborated based upon concrete knowledge of this problem-instance, accompanied by gradient and Hessian calculations for validation. We extensively report on this computational campaign, which overall resulted in (i) the location of 19 out of 21 known minima within a single run, (ii) the discovery of 540 new optima. These are new minima similar in shape to 21 theoretical solutions, but some of them have better merit function value (unknown heretofore), (iii) the identification of numerous infeasibility pockets throughout the domain (also unknown heretofore). We conclude that niching mechanism is well-suited to address this problem domain, and hypothesize on the apparent multidimensional structures formed by the attained new solutions.",
        "published": "2021-05-21T19:10:54Z",
        "link": "http://arxiv.org/abs/2105.10541v1",
        "categories": [
            "cs.CE",
            "cs.AI"
        ]
    },
    {
        "title": "Explainable Enterprise Credit Rating via Deep Feature Crossing Network",
        "authors": [
            "Weiyu Guo",
            "Zhijiang Yang",
            "Shu Wu",
            "Fu Chen"
        ],
        "summary": "Due to the powerful learning ability on high-rank and non-linear features, deep neural networks (DNNs) are being applied to data mining and machine learning in various fields, and exhibit higher discrimination performance than conventional methods. However, the applications based on DNNs are rare in enterprise credit rating tasks because most of DNNs employ the \"end-to-end\" learning paradigm, which outputs the high-rank representations of objects and predictive results without any explanations. Thus, users in the financial industry cannot understand how these high-rank representations are generated, what do they mean and what relations exist with the raw inputs. Then users cannot determine whether the predictions provided by DNNs are reliable, and not trust the predictions providing by such \"black box\" models. Therefore, in this paper, we propose a novel network to explicitly model the enterprise credit rating problem using DNNs and attention mechanisms. The proposed model realizes explainable enterprise credit ratings. Experimental results obtained on real-world enterprise datasets verify that the proposed approach achieves higher performance than conventional methods, and provides insights into individual rating results and the reliability of model training.",
        "published": "2021-05-22T02:41:50Z",
        "link": "http://arxiv.org/abs/2105.13843v1",
        "categories": [
            "cs.LG",
            "cs.CE"
        ]
    },
    {
        "title": "Projection-Based Reduced Order Model and Machine Learning Closure for   Transient Simulations of High-Re Flows",
        "authors": [
            "My Ha Dao",
            "Hoang Huy Nguyen"
        ],
        "summary": "The paper presents a Projection-Based Reduced-Order Model for simulations of high Reynolds turbulent flows. The PBROM are enhanced by incorporating various models of turbulent viscosity and residual closures to model the effects of interactions among the modes and energy dissipations. Remarkable improvements in prediction accuracies are achieved with a suitable turbulent viscosity model and a residual closure. The enhanced PBROM models are demonstrated for high-Re flows past a cylinder in two- and three- dimensions. These enhancements have shown capable of capturing complex flow features and removing unnecessary ones, while not affecting the efficiency of the overall model.",
        "published": "2021-05-23T04:15:38Z",
        "link": "http://arxiv.org/abs/2105.10854v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A hybrid discrete-continuum approach to model hydro-mechanical behaviour   of soil during desiccation",
        "authors": [
            "Khoa M. Tran",
            "Ha H. Bui",
            "Giang D. Nguyen"
        ],
        "summary": "Desiccation cracking in clayey soils occurs when they lose moisture, leading to an increase in their compressibility and hydraulic conductivity and hence significant reduction of soil strength. The prediction of desiccation cracking in soils is challenging due to the lack of insights into the complex coupled hydro-mechanical process at the grain scale. In this paper, a new hybrid discrete-continuum numerical framework, capable of capturing hydro-mechanical behaviour of soil at both grain and macro scales, is proposed for predicting desiccation cracking in clayey soil. In this framework, a soil layer is represented by an assembly of DEM particles, each occupies an equivalent continuum space and carries physical properties governing unsaturated flow. These particles move freely in the computational space following the discrete element method (DEM), while their contact network and the continuum mixture theory are used to model the unsaturated flow. The dependence of particle-to-particle contact behaviour on water content is represented by a cohesive-frictional contact model, whose material properties are governed by the water content. In parallel with the theoretical development is a series of experiments on 3D soil desiccation cracking to determine essential properties and provide data for the validation of mechanical and physical behaviour. Very good agreement in both physical behaviour (e.g. evolution of water content) and mechanical behaviour (e.g. occurrence and development of cracks, and distribution of compressive and tensile strains) demonstrates that the proposed framework is capable of capturing the hydro-mechanical behaviour of soil during desiccation. The capability of the proposed framework facilitates numerical experiments for insights into the hydro-mechanical behaviour of unsaturated soils that have not been possible before.",
        "published": "2021-05-25T23:29:45Z",
        "link": "http://arxiv.org/abs/2106.04676v1",
        "categories": [
            "physics.geo-ph",
            "cs.CE",
            "cs.NA",
            "math.NA",
            "physics.flu-dyn"
        ]
    },
    {
        "title": "Optimal Transport Based Refinement of Physics-Informed Neural Networks",
        "authors": [
            "Vaishnav Tadiparthi",
            "Raktim Bhattacharya"
        ],
        "summary": "In this paper, we propose a refinement strategy to the well-known Physics-Informed Neural Networks (PINNs) for solving partial differential equations (PDEs) based on the concept of Optimal Transport (OT).   Conventional black-box PINNs solvers have been found to suffer from a host of issues: spectral bias in fully-connected architectures, unstable gradient pathologies, as well as difficulties with convergence and accuracy.   Current network training strategies are agnostic to dimension sizes and rely on the availability of powerful computing resources to optimize through a large number of collocation points.   This is particularly challenging when studying stochastic dynamical systems with the Fokker-Planck-Kolmogorov Equation (FPKE), a second-order PDE which is typically solved in high-dimensional state space.   While we focus exclusively on the stationary form of the FPKE, positivity and normalization constraints on its solution make it all the more unfavorable to solve directly using standard PINNs approaches.   To mitigate the above challenges, we present a novel training strategy for solving the FPKE using OT-based sampling to supplement the existing PINNs framework.   It is an iterative approach that induces a network trained on a small dataset to add samples to its training dataset from regions where it nominally makes the most error.   The new samples are found by solving a linear programming problem at every iteration.   The paper is complemented by an experimental evaluation of the proposed method showing its applicability on a variety of stochastic systems with nonlinear dynamics.",
        "published": "2021-05-26T02:51:20Z",
        "link": "http://arxiv.org/abs/2105.12307v2",
        "categories": [
            "cs.CE",
            "cs.LG",
            "cs.NE",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "BioNavi-NP: Biosynthesis Navigator for Natural Products",
        "authors": [
            "Shuangjia Zheng",
            "Tao Zeng",
            "Chengtao Li",
            "Binghong Chen",
            "Connor W. Coley",
            "Yuedong Yang",
            "Ruibo Wu"
        ],
        "summary": "Nature, a synthetic master, creates more than 300,000 natural products (NPs) which are the major constituents of FDA-proved drugs owing to the vast chemical space of NPs. To date, there are fewer than 30,000 validated NPs compounds involved in about 33,000 known enzyme catalytic reactions, and even fewer biosynthetic pathways are known with complete cascade-connected enzyme catalysis. Therefore, it is valuable to make computer-aided bio-retrosynthesis predictions. Here, we develop BioNavi-NP, a navigable and user-friendly toolkit, which is capable of predicting the biosynthetic pathways for NPs and NP-like compounds through a novel (AND-OR Tree)-based planning algorithm, an enhanced molecular Transformer neural network, and a training set that combines general organic transformations and biosynthetic steps. Extensive evaluations reveal that BioNavi-NP generalizes well to identifying the reported biosynthetic pathways for 90% of test compounds and recovering the verified building blocks for 73%, significantly outperforming conventional rule-based approaches. Moreover, BioNavi-NP also shows an outstanding capacity of biologically plausible pathways enumeration. In this sense, BioNavi-NP is a leading-edge toolkit to redesign complex biosynthetic pathways of natural products with applications to total or semi-synthesis and pathway elucidation or reconstruction.",
        "published": "2021-05-26T12:04:38Z",
        "link": "http://arxiv.org/abs/2105.13121v1",
        "categories": [
            "q-bio.QM",
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "An Introduction To Regret Minimization In Algorithmic Trading: A Survey   of Universal Portfolio Techniques",
        "authors": [
            "Thomas Orton"
        ],
        "summary": "In financial investing, universal portfolios are a means of constructing portfolios which guarantee a certain level of performance relative to a baseline, while making no statistical assumptions about the future market data. They fall under the broad category of regret minimization algorithms. This document covers an introduction and survey to universal portfolio techniques, covering some of the basic concepts and proofs in the area. Topics include: Constant Rebalanced Portfolios, Cover's Algorithm, Incorporating Transaction Costs, Efficient Computation of Portfolios, Including Side Information, and Follow The Leader Algorithm.",
        "published": "2021-05-26T15:38:29Z",
        "link": "http://arxiv.org/abs/2105.13126v1",
        "categories": [
            "cs.CE",
            "q-fin.PM"
        ]
    },
    {
        "title": "Calibrating Over-Parametrized Simulation Models: A Framework via   Eligibility Set",
        "authors": [
            "Yuanlu Bai",
            "Tucker Balch",
            "Haoxian Chen",
            "Danial Dervovic",
            "Henry Lam",
            "Svitlana Vyetrenko"
        ],
        "summary": "Stochastic simulation aims to compute output performance for complex models that lack analytical tractability. To ensure accurate prediction, the model needs to be calibrated and validated against real data. Conventional methods approach these tasks by assessing the model-data match via simple hypothesis tests or distance minimization in an ad hoc fashion, but they can encounter challenges arising from non-identifiability and high dimensionality. In this paper, we investigate a framework to develop calibration schemes that satisfy rigorous frequentist statistical guarantees, via a basic notion that we call eligibility set designed to bypass non-identifiability via a set-based estimation. We investigate a feature extraction-then-aggregation approach to construct these sets that target at multivariate outputs. We demonstrate our methodology on several numerical examples, including an application to calibration of a limit order book market simulator (ABIDES).",
        "published": "2021-05-27T00:59:29Z",
        "link": "http://arxiv.org/abs/2105.12893v1",
        "categories": [
            "stat.ME",
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "Neural Options Pricing",
        "authors": [
            "Timothy DeLise"
        ],
        "summary": "This research investigates pricing financial options based on the traditional martingale theory of arbitrage pricing applied to neural SDEs. We treat neural SDEs as universal It\\^o process approximators. In this way we can lift all assumptions on the form of the underlying price process, and compute theoretical option prices numerically. We propose a variation of the SDE-GAN approach by implementing the Wasserstein distance metric as a loss function for training. Furthermore, it is conjectured that the error of the option price implied by the learnt model can be bounded by the very Wasserstein distance metric that was used to fit the empirical data.",
        "published": "2021-05-27T17:22:30Z",
        "link": "http://arxiv.org/abs/2105.13320v1",
        "categories": [
            "q-fin.MF",
            "cs.CE",
            "cs.LG",
            "q-fin.CP"
        ]
    },
    {
        "title": "Computational modeling of the nonlinear stochastic dynamics of   horizontal drillstrings",
        "authors": [
            "Americo Cunha Jr",
            "Christian Soize",
            "Rubens Sampaio"
        ],
        "summary": "This work intends to analyze the nonlinear stochastic dynamics of drillstrings in horizontal configuration. For this purpose, it considers a beam theory, with effects of rotatory inertia and shear deformation, which is capable of reproducing the large displacements that the beam undergoes. The friction and shock effects, due to beam/borehole wall transversal impacts, as well as the force and torque induced by bit-rock interaction, are also considered in the model. Uncertainties of bit-rock interaction model are taken into account using a parametric probabilistic approach. Numerical simulations have shown that the mechanical system of interest has a very rich nonlinear stochastic dynamics, which generate phenomena such as bit-bounce, stick-slip, and transverse impacts. A study aiming to maximize the drilling process efficiency, varying drillstring velocities of translation and rotation is presented. Also, the work presents the definition and solution of two optimizations problems, one deterministic and one robust, where the objective is to maximize drillstring rate of penetration into the soil respecting its structural limits.",
        "published": "2021-05-27T21:22:56Z",
        "link": "http://arxiv.org/abs/2105.13454v1",
        "categories": [
            "cs.CE",
            "math-ph",
            "math.MP",
            "physics.class-ph",
            "stat.AP",
            "70Kxx",
            "I.6.5"
        ]
    },
    {
        "title": "Enhancing the performance of a bistable energy harvesting device via the   cross-entropy method",
        "authors": [
            "Americo Cunha Jr"
        ],
        "summary": "This work deals with the solution of a non-convex optimization problem to enhance the performance of an energy harvesting device, which involves a nonlinear objective function and a discontinuous constraint. This optimization problem, which seeks to find a suitable configuration of parameters that maximize the electrical power recovered by a bistable energy harvesting system, is formulated in terms of the dynamical system response and a binary classifier obtained from 0 to 1 test for chaos. A stochastic solution strategy that combines penalization and the cross-entropy method is proposed and numerically tested. Computational experiments are conducted to address the performance of the proposed optimization approach by comparison with a reference solution, obtained via an exhaustive search in a refined numerical mesh. The obtained results illustrate the effectiveness and robustness of the cross-entropy optimization strategy (even in the presence of noise or in moderately higher dimensions), showing that the proposed framework may be a very useful and powerful tool to solve optimization problems involving nonlinear energy harvesting dynamical systems.",
        "published": "2021-05-27T21:47:20Z",
        "link": "http://arxiv.org/abs/2105.13459v1",
        "categories": [
            "cs.CE",
            "math.DS",
            "nlin.CD",
            "physics.comp-ph",
            "37N15",
            "J.2"
        ]
    },
    {
        "title": "Assessment of a transient homogeneous reactor through in situ adaptive   tabulation",
        "authors": [
            "Americo Cunha Jr",
            "Luis Fernando Figueira da Silva"
        ],
        "summary": "The development of computational models for the numerical simulation of chemically reacting flows operating in the turbulent regime requires the solution of partial differential equations that represent the balance of mass, linear momentum, chemical species, and energy. The chemical reactions of the model may involve detailed reaction mechanisms for the description of the physicochemical phenomena. One of the biggest challenges is the stiffness of the numerical simulation of these models and the nonlinear nature of species rate of reaction. This work presents a study of in situ adaptive tabulation (ISAT) technique, focusing on the accuracy, efficiency, and memory usage in the simulation of homogeneous stirred reactor models using simple and complex reaction mechanisms. The combustion of carbon monoxide with oxygen and methane with air mixtures are considered, using detailed reaction mechanisms with 4 and 53 species, 3 and 325 reactions, respectively. The results of these simulations indicate that the developed implementation of ISAT technique has a absolute global error smaller than 1 %. Moreover, ISAT technique provides gains, in terms of computational time, of up to 80% when compared with the direct integration of the full chemical kinetics. However, in terms of memory usage the present implementation of ISAT technique is found to be excessively demanding.",
        "published": "2021-05-27T22:09:41Z",
        "link": "http://arxiv.org/abs/2106.00755v1",
        "categories": [
            "physics.flu-dyn",
            "cs.CE",
            "math.DS",
            "stat.CO",
            "37N10",
            "I.6.5"
        ]
    },
    {
        "title": "Towards real time assessment of earthfill dams via Model Order Reduction",
        "authors": [
            "Christina Nasikaa",
            "Pedro Diez",
            "Pierre Gerard",
            "Thierry J. Massart",
            "Sergio Zlotnik"
        ],
        "summary": "The use of Internet of Things (IoT) technologies is becoming a preferred solution for the assessment of tailings dams' safety. Real-time sensor monitoring proves to be a key tool for reducing the risk related to these ever-evolving earth-fill structures, that exhibit a high rate of sudden and hazardous failures. In order to optimally exploit real-time embankment monitoring, one major hindrance has to be overcome: the creation of a supporting numerical model for stability analysis, with rapid-enough response to perform data assimilation in real time. A model should be built, such that its response can be obtained faster than the physical evolution of the analyzed phenomenon. In this work, Reduced Order Modelling (ROM) is used to boost computational efficiency in solving the coupled hydro-mechanical system of equations governing the problem. The Reduced Basis method is applied to the coupled hydro-mechanical equations that govern the groundwater flow, that are made non-linear as a result of considering an unsaturated soil. The resulting model's performance is assessed by solving a 2D and a 3D problem relevant to tailings dams' safety. The ROM technique achieves a speedup of 3 to 15 times with respect to the full-order model (FOM) while maintaining high levels of accuracy.",
        "published": "2021-05-28T14:38:30Z",
        "link": "http://arxiv.org/abs/2106.02687v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Logspace Sequential Quadratic Programming for Design Optimization",
        "authors": [
            "Cody Karcher"
        ],
        "summary": "A novel approach to exploiting the log-convex structure present in many design problems is developed by modifying the classical Sequential Quadratic Programming (SQP) algorithm. The modified algorithm, Logspace Sequential Quadratic Programming (LSQP), inherits some of the computational efficiency exhibited by log-convex methods such as Geometric Programing and Signomial Programing, but retains the the natural integration of black box analysis methods from SQP. As a result, significant computational savings is achieved without the need to invasively modify existing black box analysis methods prevalent in practical design problems. In the cases considered here, the LSQP algorithm shows a 40-70% reduction in number of iterations compared to SQP.",
        "published": "2021-05-30T06:49:26Z",
        "link": "http://arxiv.org/abs/2105.14441v3",
        "categories": [
            "cs.CE",
            "math.OC"
        ]
    },
    {
        "title": "A Hybrid SIE-PDE Formulation Without Boundary Condition Requirement for   Transverse Magnetic Electromagnetic Analysis",
        "authors": [
            "Aipeng Sun",
            "Zekun Zhu",
            "Shunchuan Yang",
            "Zhizhang",
            "Chen"
        ],
        "summary": "A hybrid surface integral equation partial differential equation (SIE-PDE) formulation without the boundary condition requirement is proposed to solve the transverse magnetic (TM) electromagnetic problems. In the proposed formulation, the computational domain is decomposed into two overlapping domains: the SIE and PDE domains. In the SIE domain, complex structures with piecewise homogeneous media, e.g., highly conductive media, are included. An equivalent model for those structures is constructed by replacing them with the background medium and introducing a surface equivalent electric current density on an enclosed boundary to represent their electromagnetic effects. The remaining computational domain and homogeneous background medium replaced domain consist of the PDE domain, in which inhomogeneous or non-isotropic media are included. Through combining the surface equivalent electric current density and the inhomogeneous Helmholtz equation, a hybrid SIE-PDE formulation is derived. It requires no boundary conditions, and is mathematically equivalent to the original physical model. Through careful construction of basis functions to expand electric fields and the equivalent current density, the discretized formulation is made compatible with the SIE and PDE domain interface. The accuracy and efficiency are validated through two numerical examples. Results show that the proposed SIE-PDE formulation can obtain accurate results, and significant performance improvements in terms of CPU time and memory consumption compared with the FEM are achieved.",
        "published": "2021-05-30T08:23:51Z",
        "link": "http://arxiv.org/abs/2105.14461v2",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Introducing \"Neuromorphic Computing and Engineering\"",
        "authors": [
            "Giacomo Indiveri"
        ],
        "summary": "The standard nature of computing is currently being challenged by a range of problems that start to hinder technological progress. One of the strategies being proposed to address some of these problems is to develop novel brain-inspired processing methods and technologies, and apply them to a wide range of application scenarios. This is an extremely challenging endeavor that requires researchers in multiple disciplines to combine their efforts and co-design at the same time the processing methods, the supporting computing architectures, and their underlying technologies. The journal ``Neuromorphic Computing and Engineering'' (NCE) has been launched to support this new community in this effort and provide a forum and repository for presenting and discussing its latest advances. Through close collaboration with our colleagues on the editorial team, the scope and characteristics of NCE have been designed to ensure it serves a growing transdisciplinary and dynamic community across academia and industry.",
        "published": "2021-05-30T20:12:27Z",
        "link": "http://arxiv.org/abs/2106.01329v1",
        "categories": [
            "cs.DC",
            "cs.AR",
            "cs.CE",
            "cs.NE",
            "q-bio.NC"
        ]
    },
    {
        "title": "Insights into the performance of loosely-coupled FSI schemes based on   Robin boundary conditions",
        "authors": [
            "Chennakesava Kadapa"
        ],
        "summary": "Robin boundary conditions are a natural consequence of employing Nitsche's method for imposing the kinematic velocity constraint at the fluid-solid interface. Loosely-coupled FSI schemes based on Dirichlet-Robin or Robin-Robin coupling have been demonstrated to improve the stability of such schemes with respect to added-mass. This paper aims to offer some numerical insights into the performance characteristics of such loosely-coupled FSI schemes based on Robin boundary conditions. Using numerical examples, we demonstrate that the improved stability due to the added damping term is actually at the expense of important dynamic characteristics of the structural sub-problem.",
        "published": "2021-05-31T09:45:02Z",
        "link": "http://arxiv.org/abs/2105.14831v1",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "SBML2Modelica: integrating biochemical models within open-standard   simulation ecosystems",
        "authors": [
            "Filippo Maggioli",
            "Toni Mancini",
            "Enrico Tronci"
        ],
        "summary": "Motivation: SBML is the most widespread language for the definition of biochemical models. Although dozens of SBML simulators are available, there is a general lack of support to the integration of SBML models within open-standard general-purpose simulation ecosystems. This hinders co-simulation and integration of SBML models within larger model networks, in order to, e.g. enable in silico clinical trials of drugs, pharmacological protocols, or engineering artefacts such as biomedical devices against Virtual Physiological Human models. Modelica is one of the most popular existing open-standard general-purpose simulation languages, supported by many simulators. Modelica models are especially suited for the definition of complex networks of heterogeneous models from virtually all application domains. Models written in Modelica (and in 100+ other languages) can be readily exported into black-box Functional Mock-Up Units (FMUs), and seamlessly co-simulated and integrated into larger model networks within open-standard language-independent simulation ecosystems.   Results: In order to enable SBML model integration within heterogeneous model networks, we present SBML2Modelica, a software system translating SBML models into well-structured, user-intelligible, easily modifiable Modelica models. SBML2Modelica is SBML Level 3 Version 2-compliant and succeeds on 96.47% of the SBML Test Suite Core (with a few rare, intricate and easily avoidable combinations of constructs unsupported and cleanly signalled to the user). Our experimental campaign on 613 models from the BioModels database (with up to 5438 variables) shows that the major open-source (general-purpose) Modelica and FMU simulators achieve performance comparable to state-of-the-art specialized SBML simulators.   Availability and implementation: https://bitbucket.org/mclab/sbml2modelica",
        "published": "2021-06-01T00:21:54Z",
        "link": "http://arxiv.org/abs/2106.02609v1",
        "categories": [
            "q-bio.MN",
            "cs.CE",
            "q-bio.QM"
        ]
    },
    {
        "title": "Responses to COVID-19 with Probabilistic Programming",
        "authors": [
            "Assem Zhunis",
            "Tung-Duong Mai",
            "Sundong Kim"
        ],
        "summary": "The COVID-19 pandemic left its unique mark on the 21st century as one of the most significant disasters in history, triggering governments all over the world to respond with a wide range of interventions. However, these restrictions come with a substantial price tag. It is crucial for governments to form anti-virus strategies that balance the trade-off between protecting public health and minimizing the economic cost. This work proposes a probabilistic programming method to quantify the efficiency of major non-pharmaceutical interventions. We present a generative simulation model that accounts for the economic and human capital cost of adopting such strategies, and provide an end-to-end pipeline to simulate the virus spread and the incurred loss of various policy combinations. By investigating the national response in 10 countries covering four continents, we found that social distancing coupled with contact tracing is the most successful policy, reducing the virus transmission rate by 96\\% along with a 98\\% reduction in economic and human capital loss. Together with experimental results, we open-sourced a framework to test the efficacy of each policy combination.",
        "published": "2021-06-01T02:40:49Z",
        "link": "http://arxiv.org/abs/2106.00192v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "All-Hex Meshing Strategies For Densely Packed Spheres",
        "authors": [
            "Yu-Hsiang Lan",
            "Paul Fischer",
            "Elia Merzari",
            "Misun Min"
        ],
        "summary": "We develop an all-hex meshing strategy for the interstitial space in beds of densely packed spheres that is tailored to turbulent flow simulations based on the spectral element method (SEM). The SEM achieves resolution through elevated polynomial order N and requires two to three orders of magnitude fewer elements than standard finite element approaches do. These reduced element counts place stringent requirements on mesh quality and conformity. Our meshing algorithm is based on a Voronoi decomposition of the sphere centers. Facets of the Voronoi cells are tessellated into quads that are swept to the sphere surface to generate a high-quality base mesh. Refinements to the algorithm include edge collapse to remove slivers, node insertion to balance resolution, localized refinement in the radial direction about each sphere, and mesh optimization. We demonstrate geometries with 10^2-10^5 spheres using approximately 300 elements per sphere (for three radial layers), along with mesh quality metrics, timings, flow simulations, and solver performance.",
        "published": "2021-06-01T02:49:50Z",
        "link": "http://arxiv.org/abs/2106.00196v2",
        "categories": [
            "cs.CE",
            "76-10",
            "D.0; F.2; I.6; J.2"
        ]
    },
    {
        "title": "On the Stability of Mixed Finite-Element Formulations for   High-Temperature Superconductors",
        "authors": [
            "Julien Dular",
            "Mane Harutyunyan",
            "Lorenzo Bortot",
            "Sebastian Schöps",
            "Benoit Vanderheyden",
            "Christophe Geuzaine"
        ],
        "summary": "In this work, we present and analyze the numerical stability of two coupled finite element formulations. The first one is the h-a-formulation and is well suited for modeling systems with superconductors and ferromagnetic materials. The second one, the so-called t-a-formulation with thin-shell approximation, applies for systems with thin superconducting domains. Both formulations involve two coupled unknown fields and are mixed on the coupling interfaces. Function spaces in mixed formulations must satisfy compatibility conditions to ensure stability of the problem and reliability of the numerical solution. We propose stable choices of function spaces using hierarchical basis functions and demonstrate the effectiveness of the approach on simple 2D examples.",
        "published": "2021-06-01T08:43:25Z",
        "link": "http://arxiv.org/abs/2106.00313v2",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "physics.acc-ph"
        ]
    },
    {
        "title": "Debt Swapping for Risk Mitigation in Financial Networks",
        "authors": [
            "Pál András Papp",
            "Roger Wattenhofer"
        ],
        "summary": "We study financial networks where banks are connected by debt contracts. We consider the operation of debt swapping when two creditor banks decide to exchange an incoming payment obligation, thus leading to a locally different network structure. We say that a swap is positive if it is beneficial for both of the banks involved; we can interpret this notion either with respect to the amount of assets received by the banks, or their exposure to different shocks that might hit the system.   We analyze various properties of these swapping operations in financial networks. We first show that there can be no positive swap for any pair of banks in a static financial system, or when a shock hits each bank in the network proportionally. We then study worst-case shock models, when a shock of given size is distributed in the worst possible way for a specific bank. If the goal of banks is to minimize their losses in such a worst-case setting, then a positive swap can indeed exist. We analyze the effects of such a positive swap on other banks of the system, the computational complexity of finding a swap, and special cases where a swap can be found efficiently. Finally, we also present some results for more complex swapping operations when the banks swap multiple contracts, or when more than two banks participate in the swap.",
        "published": "2021-06-01T12:42:34Z",
        "link": "http://arxiv.org/abs/2107.05359v1",
        "categories": [
            "q-fin.RM",
            "cs.CE",
            "q-fin.PM",
            "91G45",
            "J.4"
        ]
    },
    {
        "title": "Robust design optimisation of continuous flow polymerase chain reaction   thermal flow systems",
        "authors": [
            "Yongxing Wang",
            "Hazim A. Hamad",
            "Jochen Voss",
            "Harvey M. Thompson"
        ],
        "summary": "This paper presents an efficient methodology for the robust optimisation of Continuous Flow Polymerase Chain Reaction (CFPCR) devices. It enables the effects of uncertainties in device geometry, due to manufacturing tolerances, on the competing objectives of minimising the temperature deviations within the CFPCR thermal zones, together with minimising the pressure drop across the device, to be explored. We first validate that our training data from conjugate heat transfer simulations of the CFPCR thermal flow problems is noise free and then combine a deterministic surrogate model, based on the mean of a Gaussian Process Regression (GPR) simulator, with Polynomial Chaos Expansions (PCE) to propagate the manufacturing uncertainties in the geometry design variables into the optimisation outputs. The resultant probabilistic model is used to solve a series of robust optimisation problems. The influence of the robust problem formulation and constraints on the design conservatism of the robust optima in comparison with the corresponding deterministic cases is explored briefly.",
        "published": "2021-06-01T15:33:45Z",
        "link": "http://arxiv.org/abs/2106.00570v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A reduced 3D-0D FSI model of the aortic valve including leaflets   curvature",
        "authors": [
            "Ivan Fumagalli"
        ],
        "summary": "In the present work, we propose a novel lumped-parameter model for the description of the aortic valve dynamics, including elastic effects associated to the leaflets' curvature. The introduction of a lumped-parameter model based on momentum balance entails an easier calibration of the parameter models, that are instead typically numerous in phenomenological-based models. This model is coupled with 3D Navier-Stokes equations describing the blood flow, where the valve surface is represented by a resistive method, and valve leaflets velocity is taken into consideration. The resulting reduced fluid-structure interaction problem has a computational cost that is comparable with the solution of a prescribed-motion fluid dynamics problem. A SUPG-PSPG stabilized finite element scheme is adopted for the discretization of the coupled problem, and the computational results show the suitability of the system in representing the leaflets motion, the blood flow in the ascending aorta, and the pressure jump across the leaflets.",
        "published": "2021-06-01T15:34:09Z",
        "link": "http://arxiv.org/abs/2106.00571v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "An Extendible, Graph-Neural-Network-Based Approach for Accurate Force   Field Development of Large Flexible Organic Molecules",
        "authors": [
            "Xufei Wang",
            "Yuanda Xu",
            "Han Zheng",
            "Kuang Yu"
        ],
        "summary": "An accurate force field is the key to the success of all molecular mechanics simulations on organic polymers and biomolecules. Accuracy beyond density functional theory is often needed to describe the intermolecular interactions, while most correlated wavefunction (CW) methods are prohibitively expensive for large molecules. Therefore, it posts a great challenge to develop an extendible ab initio force field for large flexible organic molecules at CW level of accuracy. In this work, we face this challenge by combining the physics-driven nonbonding potential with a data-driven subgraph neural network bonding model (named sGNN). Tests on polyethylene glycol polymer chains show that our strategy is highly accurate and robust for molecules of different sizes. Therefore, we can develop the force field from small molecular fragments (with sizes easily accessible to CW methods) and safely transfer it to large polymers, thus opening a new path to the next-generation organic force fields.",
        "published": "2021-06-02T04:12:54Z",
        "link": "http://arxiv.org/abs/2106.00927v1",
        "categories": [
            "physics.chem-ph",
            "cond-mat.soft",
            "cs.CE",
            "cs.LG",
            "physics.comp-ph"
        ]
    },
    {
        "title": "A monolithic one-velocity-field optimal control formulation for   fluid-structure interaction problems with large solid deformation",
        "authors": [
            "Yongxing Wang"
        ],
        "summary": "In this article, we formulate a monolithic optimal control method for general time-dependent Fluid-Structure Interaction (FSI) systems with large solid deformation. We consider a displacement-tracking type of objective with a constraint of the solid velocity, tackle the time-dependent control problems by a piecewise-in-time control, cope with large solid displacement using a one-velocity fictitious domain method, and solve the fully-coupled FSI and the corresponding adjoint equations in a monolithic manner. We implement the proposed method in the open-source software package FreeFEM++ and assess it by three numerical experiments, in the aspects of stability of the numerical scheme for different regularisation parameters, and efficiency of reducing the objective function with control of the solid velocity.",
        "published": "2021-06-02T06:56:08Z",
        "link": "http://arxiv.org/abs/2106.00982v1",
        "categories": [
            "cs.CE",
            "math.OC"
        ]
    },
    {
        "title": "A Molecular Hyper-message Passing Network with Functional Group   Information",
        "authors": [
            "Fangying Chen",
            "Junyoung Park",
            "Jinkyoo Park"
        ],
        "summary": "We proposed the molecular hyper-message passing network (MolHMPN) that predicts the properties of a molecule with prior knowledge-guided subgraph. Modeling higher-order connectivities in molecules is necessary as changes in both the pair-wise and higher-order interactions among atoms results in the change of molecular properties. Many approaches have attempted to model the higher-order connectivities. However, those methods relied heavily on data-driven approaches, and it is difficult to determine if the utilized subgraphs contain any properties of interest or have any significance on the molecular properties. Hence, we propose MolHMPN to utilize the functional group prior knowledge and model the pair-wise and higher-order connectivities among the atoms in a molecule. Molecules can contain many types of functional groups, which affect the properties the molecules. For example, the toxicity of a molecule is associated with toxicophores, such as nitroaromatic groups and thiourea. MolHMPN uses functional groups to construct hypergraphs, modifies the hypergraph using domain knowledge-guided modification scheme, embeds the graph and hypergraph inputs using a hypergraph message passing (HyperMP) layer, and uses the updated graph and hypergraph embeddings to predict the properties of the molecules. Our model provides a way to utilize prior knowledge in chemistry for molecular properties prediction tasks, and balance between the usage of prior knowledge and data-driven modification adaptively. We show that our model is able to outperform the other baseline methods for most of the dataset, and show that using domain knowledge-guided data-learning iseffective.",
        "published": "2021-06-02T08:49:24Z",
        "link": "http://arxiv.org/abs/2106.01028v3",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Maximizing Extractable Value from Automated Market Makers",
        "authors": [
            "Massimo Bartoletti",
            "James Hsin-yu Chiang",
            "Alberto Lluch-Lafuente"
        ],
        "summary": "Automated Market Makers (AMMs) are decentralized applications that allow users to exchange crypto-tokens without the need for a matching exchange order. AMMs are one of the most successful DeFi use cases: indeed, major AMM platforms process a daily volume of transactions worth USD billions. Despite their popularity, AMMs are well-known to suffer from transaction-ordering issues: adversaries can influence the ordering of user transactions, and possibly front-run them with their own, to extract value from AMMs, to the detriment of users. We devise an effective procedure to construct a strategy through which an adversary can maximize the value extracted from user transactions.",
        "published": "2021-06-02T10:32:05Z",
        "link": "http://arxiv.org/abs/2106.01870v4",
        "categories": [
            "cs.CR",
            "cs.CE",
            "cs.FL",
            "cs.GT",
            "68N30",
            "I.6.4"
        ]
    },
    {
        "title": "Numerical valuation of American basket options via partial differential   complementarity problems",
        "authors": [
            "Karel in 't Hout",
            "Jacob Snoeijer"
        ],
        "summary": "We study the principal component analysis based approach introduced by Reisinger & Wittum (2007) and the comonotonic approach considered by Hanbali & Linders (2019) for the approximation of American basket option values via multidimensional partial differential complementarity problems (PDCPs). Both approximation approaches require the solution of just a limited number of low-dimensional PDCPs. It is demonstrated by ample numerical experiments that they define approximations that lie close to each other. Next, an efficient discretisation of the pertinent PDCPs is presented that leads to a favourable convergence behaviour.",
        "published": "2021-06-02T14:44:55Z",
        "link": "http://arxiv.org/abs/2106.01200v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "q-fin.CP"
        ]
    },
    {
        "title": "Influence Estimation and Maximization via Neural Mean-Field Dynamics",
        "authors": [
            "Shushan He",
            "Hongyuan Zha",
            "Xiaojing Ye"
        ],
        "summary": "We propose a novel learning framework using neural mean-field (NMF) dynamics for inference and estimation problems on heterogeneous diffusion networks. Our new framework leverages the Mori-Zwanzig formalism to obtain an exact evolution equation of the individual node infection probabilities, which renders a delay differential equation with memory integral approximated by learnable time convolution operators. Directly using information diffusion cascade data, our framework can simultaneously learn the structure of the diffusion network and the evolution of node infection probabilities. Connections between parameter learning and optimal control are also established, leading to a rigorous and implementable algorithm for training NMF. Moreover, we show that the projected gradient descent method can be employed to solve the challenging influence maximization problem, where the gradient is computed extremely fast by integrating NMF forward in time just once in each iteration. Extensive empirical studies show that our approach is versatile and robust to variations of the underlying diffusion network models, and significantly outperform existing approaches in accuracy and efficiency on both synthetic and real-world data.",
        "published": "2021-06-03T00:02:05Z",
        "link": "http://arxiv.org/abs/2106.02608v1",
        "categories": [
            "cs.LG",
            "cs.CE",
            "cs.NA",
            "cs.SI",
            "math.NA",
            "math.OC",
            "68U35, 65D99, 65Z05"
        ]
    },
    {
        "title": "Data-Driven Design-by-Analogy: State of the Art and Future Directions",
        "authors": [
            "Shuo Jiang",
            "Jie Hu",
            "Kristin L. Wood",
            "Jianxi Luo"
        ],
        "summary": "Design-by-Analogy (DbA) is a design methodology wherein new solutions, opportunities or designs are generated in a target domain based on inspiration drawn from a source domain; it can benefit designers in mitigating design fixation and improving design ideation outcomes. Recently, the increasingly available design databases and rapidly advancing data science and artificial intelligence technologies have presented new opportunities for developing data-driven methods and tools for DbA support. In this study, we survey existing data-driven DbA studies and categorize individual studies according to the data, methods, and applications in four categories, namely, analogy encoding, retrieval, mapping, and evaluation. Based on both nuanced organic review and structured analysis, this paper elucidates the state of the art of data-driven DbA research to date and benchmarks it with the frontier of data science and AI research to identify promising research opportunities and directions for the field. Finally, we propose a future conceptual data-driven DbA system that integrates all propositions.",
        "published": "2021-06-03T04:35:34Z",
        "link": "http://arxiv.org/abs/2106.01592v1",
        "categories": [
            "cs.AI",
            "cs.CE"
        ]
    },
    {
        "title": "Partial Optimal Transport for a Constant-Volume Lagrangian Mesh with   Free Boundaries",
        "authors": [
            "Bruno Lévy"
        ],
        "summary": "This article introduces a representation of dynamic meshes, adapted to some numerical simulations that require controlling the volume of objects with free boundaries, such as incompressible fluid simulation, some astrophysical simulations at cosmological scale, and shape/topology optimization. The algorithm decomposes the simulated object into a set of convex cells called a Laguerre diagram, parameterized by the position of $N$ points in 3D and $N$ additional parameters that control the volumes of the cells. These parameters are found as the (unique) solution of a convex optimization problem -- semi-discrete Monge-Amp\\`ere equation -- stemming from optimal transport theory. In this article, this setting is extended to objects with free boundaries and arbitrary topology, evolving in a domain of arbitrary shape, by solving a partial optimal transport problem. The resulting Lagrangian scheme makes it possible to accurately control the volume of the object, while precisely tracking interfaces, interactions, collisions, and topology changes.",
        "published": "2021-06-03T09:39:06Z",
        "link": "http://arxiv.org/abs/2106.03936v1",
        "categories": [
            "physics.flu-dyn",
            "cs.CE",
            "7401, 76M25, 76F65",
            "J.2; I.3"
        ]
    },
    {
        "title": "Comparative study and limits of different level-set formulations for the   modeling of anisotropic grain growth",
        "authors": [
            "Brayan Murgas",
            "Sebastian Florez",
            "Nathalie Bozzolo",
            "Julien Fausty",
            "Marc Bernacki"
        ],
        "summary": "Four different finite element level-set (FE-LS) formulations are compared for the modeling of grain growth in the context of polycrystalline structures and, moreover, two of them are presented for the first time using anisotropic grain boundary (GB) energy and mobility. Mean values and distributions are compared using the four formulations. First, we present the strong and weak formulations for the different models and the crystallographic parameters used at the mesoscopic scale. Second, some Grim Reaper analytical cases are presented and compared with the simulation results, here the evolutions of individual multiple junctions are followed. Additionally, large scale simulations are presented. Anisotropic GB energy and mobility are respectively defined as functions of the misorientation/inclination and disorientation. The evolution of the disorientation distribution function (DDF) is computed and its evolution is in accordance with prior works. We found that the formulation called \"Anisotropic\" is the more physical one but it could be replaced at the mesoscopic scale by an Isotropic formulation for simple microstructures presenting an initial Mackenzie-type DDF.",
        "published": "2021-06-03T13:45:52Z",
        "link": "http://arxiv.org/abs/2106.03565v1",
        "categories": [
            "cond-mat.mtrl-sci",
            "cs.CE"
        ]
    },
    {
        "title": "Elasticity Based Demand Forecasting and Price Optimization for Online   Retail",
        "authors": [
            "Chengcheng Liu",
            "Mátyás A. Sustik"
        ],
        "summary": "We study a problem of an online retailer who observes the unit sales of a product, and dynamically changes the retail price, in order to maximize the expected revenue. Assuming the demand of the product is price sensitive, we are interested in the optimal pricing policy when future demand is uncertain. We build a system to investigate the relationship between retail price and demand and estimate the demand function. The system predicts demand and revenue at a given retail price. We formulate a revenue maximization problem over a discrete finite time horizon with discrete retail price. The optimal pricing policy is solved based on the predicted demand and revenue values. With computational experiments, we investigate the effect of optimal pricing policy to inventory management.",
        "published": "2021-06-03T22:23:32Z",
        "link": "http://arxiv.org/abs/2106.08274v2",
        "categories": [
            "eess.SY",
            "cs.CE",
            "cs.SY",
            "math.OC"
        ]
    },
    {
        "title": "Tensegrity system dynamics based on finite element method",
        "authors": [
            "Shuo Ma",
            "Muhao Chen",
            "Robert E. Skelton"
        ],
        "summary": "This study presents a finite element analysis approach to non-linear and linearized tensegrity dynamics based on the Lagrangian method with nodal coordinate vectors as the generalized coordinates. In this paper, nonlinear tensegrity dynamics with and without constraints are first derived. The equilibrium equations in three standard forms (in terms of nodal coordinate, force density, and force vectors) and the compatibility equation are also given. Then, we present the linearized dynamics and modal analysis equations with and without constraints. The developed approach is capable of conducting the following comprehensive dynamics studies for any tensegrity structures accurately: 1. Performing rigid body dynamics with acceptable errors, which is achieved by setting relatively high stiffness for bars in the simulation. 2. Simulating FEM dynamics accurately, where bars and strings can have elastic or plastic deformations. 3. Dealing with various kinds of boundary conditions, for example, fixing or applying static/dynamic loads at any nodes in any direction (i.e., gravitational force, some specified forces, or arbitrary seismic vibrations). 4. Conducting accurate modal analysis, including natural frequency and corresponding modes. Three examples, a double pendulum, a cantilever truss with external force, and a double prism tensegrity tower, are carefully selected and studied. The results are compared with rigid body dynamics and FEM software ANSYS. This study provides a deep insight into structures, materials, performances, as well as an interface towards integrating control theories.",
        "published": "2021-06-03T23:47:22Z",
        "link": "http://arxiv.org/abs/2106.02176v1",
        "categories": [
            "physics.app-ph",
            "cs.CE"
        ]
    },
    {
        "title": "Projection-Based Reduced Order Model for Simulations of Nonlinear Flows   with Multiple Moving Objects",
        "authors": [
            "My Ha Dao"
        ],
        "summary": "This paper presents a reduced order approach for transient modeling of multiple moving objects in nonlinear crossflows. The Proper Orthogonal Decomposition method and the Galerkin projection are used to construct a reduced version of the nonlinear Navier-Stokes equations. The Galerkin projection implemented in OpenFOAM platform allows accurate impositions of arbitrary time-dependent boundary conditions at the moving boundaries. A modelling technique based on moving domain and immersed boundary techniques is proposed to overcome the challenge of handling moving boundaries due to movements of the multiple objects. The model is demonstrated capable to capture the complex flow fields past one and two oscillating cylinders and the forces acting on the cylinders. Simulation time could be reduced by more than three orders for a small case on a fine mesh as compared to an existing method and could be more for large cases. In general, the simulation time of the reduced model is of order of seconds as compared to hours of the full order Computational Fluid Dynamics models.",
        "published": "2021-06-04T08:38:23Z",
        "link": "http://arxiv.org/abs/2106.02338v1",
        "categories": [
            "physics.flu-dyn",
            "cs.CE"
        ]
    },
    {
        "title": "Principled Data Completion of Network Constraints for Day Ahead Auctions   in Power Markets",
        "authors": [
            "Ioan Alexandru Puiu",
            "Raphael Andreas Hauser"
        ],
        "summary": "Network constraints play a key role in the price finding mechanism for European Power Markets, but historical data is very sparse and usually insufficient for many quantitative applications. We reconstruct the constraints data, known as the Power Transmission Distribution Factors (PTDFs) and Remaining Available Margins (RAMs), by first recovering the underlying time dependent signals known as the Generation Shift Keys (GSKs) and Phase Angles (PAs), and the electricity grid characteristics, via a mathematical optimisation problem. This is solved by exploiting marginal convexity in certain subspaces via alternating minimisation. The GSKs and PAs are then mapped to the PTDFs and RAMs, using the grid structure. Our reconstruction achieves good in-sample and out-of-sample relative errors for the PTDFs and RAMs. We further show that our model outperforms the naive approach, and that the reconstructed GSKs and PAs recover specific structure.",
        "published": "2021-06-04T21:41:00Z",
        "link": "http://arxiv.org/abs/2106.04310v1",
        "categories": [
            "eess.SY",
            "cs.CE",
            "cs.SY"
        ]
    },
    {
        "title": "Leveraging spectral analysis to elucidate membrane locking and unlocking   in isogeometric finite element formulations of the curved Euler-Bernoulli   beam",
        "authors": [
            "Thi-Hoa Nguyen",
            "René R. Hiemstra",
            "Dominik Schillinger"
        ],
        "summary": "In this paper, we take a fresh look at using spectral analysis for assessing locking phenomena in finite element formulations. We propose to \"measure\" locking by comparing the difference between eigenvalue and mode error curves computed on coarse meshes with \"asymptotic\" error curves computed on \"overkill\" meshes, both plotted with respect to the normalized mode number. To demonstrate the intimate relation between membrane locking and spectral accuracy, we focus on the example of a circular ring discretized with isogeometric curved Euler-Bernoulli beam elements. We show that the transverse-displacement-dominating modes are locking-prone, while the circumferential-displacement-dominating modes are naturally locking-free. We use eigenvalue and mode errors to assess five isogeometric finite element formulations in terms of their locking-related efficiency: the displacement-based formulation with full and reduced integration and three locking-free formulations based on the B-bar, discrete strain gap and Hellinger-Reissner methods. Our study shows that spectral analysis uncovers locking-related effects across the spectrum of eigenvalues and eigenmodes, rigorously characterizing membrane locking in the displacement-based formulation and unlocking in the locking-free formulations.",
        "published": "2021-06-06T13:09:28Z",
        "link": "http://arxiv.org/abs/2106.03114v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Multi-agent Modeling of Hazard-Household-Infrastructure Nexus for   Equitable Resilience Assessment",
        "authors": [
            "Amir Esmalian",
            "Wanqiu Wang",
            "Ali Mostafavi"
        ],
        "summary": "To enable integrating social equity considerations in infrastructure resilience assessments, this study created a new computational multi-agent simulation model which enables integrated assessment of hazard, infrastructure system, and household elements and their interactions. With a focus on hurricane-induced power outages, the model consists of three elements: 1) the hazard component simulates exposure of the community to a hurricane with varying intensity levels; 2) the physical infrastructure component simulates the power network and its probabilistic failures and restoration under different hazard scenarios; and 3) the households component captures the dynamic processes related to preparation, information seeking, and response actions of households facing hurricane-induced power outages. We used empirical data from household surveys in conjunction with theoretical decision-making models to abstract and simulate the underlying mechanisms affecting experienced hardship of households. The multi-agent simulation model was then tested in the context of Harris County, Texas, and verified and validated using empirical results from Hurricane Harvey in 2017. Then, the model was used to examine effects of different factors such as forewarning durations, social network types, and restoration and resource allocation strategies on reducing the societal impacts of service disruptions in an equitable manner. The results show that improving the restoration prioritization strategy to focus on vulnerable populations is an effective approach, especially during high-intensity events. The results show the capability of the proposed computational model for capturing the dynamic and complex interactions in the nexus of humans, hazards, and infrastructure systems to better integrate human-centric aspects in resilience planning and into assessment of infrastructure systems in disasters.",
        "published": "2021-06-06T15:51:32Z",
        "link": "http://arxiv.org/abs/2106.03160v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "DPER: Efficient Parameter Estimation for Randomly Missing Data",
        "authors": [
            "Thu Nguyen",
            "Khoi Minh Nguyen-Duy",
            "Duy Ho Minh Nguyen",
            "Binh T. Nguyen",
            "Bruce Alan Wade"
        ],
        "summary": "The missing data problem has been broadly studied in the last few decades and has various applications in different areas such as statistics or bioinformatics. Even though many methods have been developed to tackle this challenge, most of those are imputation techniques that require multiple iterations through the data before yielding convergence. In addition, such approaches may introduce extra biases and noises to the estimated parameters. In this work, we propose novel algorithms to find the maximum likelihood estimates (MLEs) for a one-class/multiple-class randomly missing data set under some mild assumptions. As the computation is direct without any imputation, our algorithms do not require multiple iterations through the data, thus promising to be less time-consuming than other methods while maintaining superior estimation performance. We validate these claims by empirical results on various data sets of different sizes and release all codes in a GitHub repository to contribute to the research community related to this problem.",
        "published": "2021-06-06T16:37:48Z",
        "link": "http://arxiv.org/abs/2106.05190v1",
        "categories": [
            "stat.ML",
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "Traction chain networks: Insights beyond force chain networks for   non-spherical particle systems",
        "authors": [
            "Daniel N. Wilke"
        ],
        "summary": "Force chain networks are generally applied in granular materials to gain insight into inter-particle granular contact. For conservative spherical particle systems, i.e. frictionless and undamped, force chains are information complete due to symmetries resulting from isotropy and constant curvature of a sphere. In fact, for conservative spherical particle systems, given the geometry and material, the force chain network uniquely defines the contact state that includes elastic forces, penetration distance, overlap volume, contact areas and contact pressures in a particle system. This is, however, not the case for conservative non-spherical particle systems. The reason is that a force chain network is not sufficient to uniquely define the contact state in a conservative non-spherical particle system. Additional information is required to define the contact state of non-spherical granular systems. Traction chain networks are proposed to complement force chain networks for the improved quantification of the state of contact of a granular system.",
        "published": "2021-06-07T16:33:39Z",
        "link": "http://arxiv.org/abs/2106.03771v1",
        "categories": [
            "cond-mat.soft",
            "cs.CE",
            "physics.comp-ph",
            "70-10, 37M05",
            "J.2; I.6.6; I.6.4"
        ]
    },
    {
        "title": "Super-resolving star clusters with sheaves",
        "authors": [
            "Michael Robinson",
            "Christopher Capraro"
        ],
        "summary": "This article explains an optimization-based approach for counting and localizing stars within a small cluster, based on photon counts in a focal plane array. The array need not be arranged in any particular way, and relatively small numbers of photons are required in order to ensure convergence. The stars can be located close to one another, as the location and brightness errors were found to be low when the separation was larger than $0.2$ Rayleigh radii. To ensure generality of our approach, it was constructed as a special case of a general theory built upon topological signal processing using the mathematics of sheaves.",
        "published": "2021-06-08T15:24:20Z",
        "link": "http://arxiv.org/abs/2106.08123v1",
        "categories": [
            "astro-ph.IM",
            "cs.CE",
            "math.MG",
            "85-08",
            "I.4.8"
        ]
    },
    {
        "title": "Non-Autoregressive Electron Redistribution Modeling for Reaction   Prediction",
        "authors": [
            "Hangrui Bi",
            "Hengyi Wang",
            "Chence Shi",
            "Connor Coley",
            "Jian Tang",
            "Hongyu Guo"
        ],
        "summary": "Reliably predicting the products of chemical reactions presents a fundamental challenge in synthetic chemistry. Existing machine learning approaches typically produce a reaction product by sequentially forming its subparts or intermediate molecules. Such autoregressive methods, however, not only require a pre-defined order for the incremental construction but preclude the use of parallel decoding for efficient computation. To address these issues, we devise a non-autoregressive learning paradigm that predicts reaction in one shot. Leveraging the fact that chemical reactions can be described as a redistribution of electrons in molecules, we formulate a reaction as an arbitrary electron flow and predict it with a novel multi-pointer decoding network. Experiments on the USPTO-MIT dataset show that our approach has established a new state-of-the-art top-1 accuracy and achieves at least 27 times inference speedup over the state-of-the-art methods. Also, our predictions are easier for chemists to interpret owing to predicting the electron flows.",
        "published": "2021-06-08T16:39:08Z",
        "link": "http://arxiv.org/abs/2106.07801v1",
        "categories": [
            "physics.chem-ph",
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "A 2D front-tracking Lagrangian model for the modeling of anisotropic   grain growth",
        "authors": [
            "Sebastian Florez",
            "Julien Fausty",
            "Karen Alvarado",
            "Brayan Murgas",
            "Marc Bernacki"
        ],
        "summary": "Grain growth is a well-known and complex phenomenon occurring during annealing of all polycrystalline materials. Its numerical modeling is a complex task when anisotropy sources such as grain orientation and grain boundary inclination have to be taken into account. This article presents the application of the front-tracking methodology ToRealMotion introduced in previous works, to the context of anisotropic grain boundary motion at the mesoscopic scale. The new formulation of boundary migration can take into account any source of anisotropy both at grain boundaries as well as at multiple junctions (MJs) (intersection point of three or more grain boundaries). Special attention is given to the decomposition of high-order MJs for which an algorithm is proposed based on local grain boundary energy minimisation. Numerical tests are provided using highly heterogeneous configurations, and comparisons with a recently developed Finite-Element Level-Set (FE-LS) approach are given. Finally, the computational performance of the model will be studied comparing the CPU-times obtained with the same model but in an isotropic context.",
        "published": "2021-06-09T08:26:16Z",
        "link": "http://arxiv.org/abs/2106.04892v2",
        "categories": [
            "cond-mat.mtrl-sci",
            "cs.CE"
        ]
    },
    {
        "title": "Verification of asymptotic homogenization method developed for periodic   architected materials in strain gradient continuum",
        "authors": [
            "Hua Yang",
            "Bilen Emek Abali",
            "Wolfgang H. Müller",
            "Salma Barboura",
            "Jia Li"
        ],
        "summary": "Strain gradient theory is an accurate model for capturing the size effect and localization phenomena. However, the challenge in identification of corresponding constitutive parameters limits the practical application of the theory. We present and utilize asymptotic homogenization herein. All parameters in rank four, five, and six tensors are determined with the demonstrated computational approach. Examples for epoxy carbon fiber composite, metal matrix composite, and aluminum foam illustrate the effectiveness and versatility of the proposed method. The influences of volume fraction of matrix, the stack of RVEs, and the varying unit cell lengths on the identified parameters are investigated. The homogenization computational tool is applicable to a wide class materials and makes use of open-source codes in FEniCS. We make all of the codes publicly available in order to encourage a transparent scientific exchange.",
        "published": "2021-06-09T16:02:59Z",
        "link": "http://arxiv.org/abs/2106.05158v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Nonlinear mixed-dimension model for embedded tubular networks with   application to root water uptake",
        "authors": [
            "Timo Koch",
            "Hanchuan Wu",
            "Martin Schneider"
        ],
        "summary": "We present a numerical scheme for the solution of nonlinear mixed-dimensional PDEs describing coupled processes in embedded tubular network system in exchange with a bulk domain. Such problems arise in various biological and technical applications such as in the modeling of root-water uptake, heat exchangers, or geothermal wells. The nonlinearity appears in form of solution-dependent parameters such as pressure-dependent permeability or temperature-dependent thermal conductivity. We derive and analyse a numerical scheme based on distributing the bulk-network coupling source term by a smoothing kernel with local support. By the use of local analytical solutions, interface unknowns and fluxes at the bulk-network interface can be accurately reconstructed from coarsely resolved numerical solutions in the bulk domain. Numerical examples give confidence in the robustness of the method and show the results in comparison to previously published methods. The new method outperforms these existing methods in accuracy and efficiency. In a root water uptake scenario, we accurately estimate the transpiration rate using only a few thousand 3D mesh cells and a structured cube grid whereas other state-of-the-art numerical schemes require millions of cells and local grid refinement to reach comparable accuracy.",
        "published": "2021-06-10T01:45:13Z",
        "link": "http://arxiv.org/abs/2106.05452v2",
        "categories": [
            "cs.CE",
            "76Z99"
        ]
    },
    {
        "title": "Superscalability of the random batch Ewald method",
        "authors": [
            "Jiuyang Liang",
            "Pan Tan",
            "Yue Zhao",
            "Lei Li",
            "Shi Jin",
            "Liang Hong",
            "Zhenli Xu"
        ],
        "summary": "Coulomb interaction, following an inverse-square force-law, quantifies the amount of force between two stationary and electrically charged particles. The long-range nature of Coulomb interactions poses a major challenge to molecular dynamics simulations which are major tools for problems at the nano-/micro- scale. Various algorithms are developed to calculate the pairwise Coulomb interactions to a linear scaling but the poor scalability limits the size of simulated systems. Here, we conduct an efficient molecular dynamics algorithm with the random batch Ewald method on all-atom systems where the complete Fourier components in the Coulomb interaction are replaced by randomly selected mini-batches. By simulating the $N$-body systems up to 100 million particles using $10$ thousand CPU cores, we show that this algorithm furnishes $O(N)$ complexity, almost perfect scalability and an order of magnitude faster computational speed when compared to the existing state-of-the-art algorithms. Further examinations of our algorithm on distinct systems, including pure water, micro-phase-separated electrolyte and protein solution demonstrate that the spatiotemporal information on all time and length scales investigated and thermodynamic quantities derived from our algorithm are in perfect agreement with those obtained from the existing algorithms. Therefore, our algorithm provides a breakthrough solution on scalability of computing the Coulomb interaction. It is particularly useful and cost-effective to simulate ultra-large systems, which was either impossible or very costing to conduct using existing algorithms, thus would benefit the broad community of sciences.",
        "published": "2021-06-10T04:50:23Z",
        "link": "http://arxiv.org/abs/2106.05494v2",
        "categories": [
            "physics.comp-ph",
            "cs.CE"
        ]
    },
    {
        "title": "Statistical behaviour of interfaces subjected to curvature flow and   torque effects applied to microstructural evolutions",
        "authors": [
            "Sebastian Florez",
            "Karen Alvarado",
            "Brayan Murgas",
            "Nathalie Bozzolo",
            "Dominique Chatain",
            "Carl E. Krill III",
            "Mingyan Wang",
            "Greg S. Rhorer",
            "Marc Bernacki"
        ],
        "summary": "The movement of grain boundaries in pure metals and alloys with a low concentration of dislocations has been historically proved to follow curvature flow behavior. This mechanism is typically known as grain growth (GG). However, recent 3D in-situ experimental results tend to question this global picture concerning the influence of the curvature on the kinetics of interface migration. This article explains, thanks to 2D anisotropic full-field simulations, how the torque effects can complexify these discussions. It is then illustrated that neglecting torque effects in full-field formulations remains potentially a strong hypothesis. The apparent mobility can be much more complex than expected without necessarily questioning the influence of the curvature on the local kinetic equation.",
        "published": "2021-06-10T09:19:11Z",
        "link": "http://arxiv.org/abs/2106.05605v3",
        "categories": [
            "cond-mat.mtrl-sci",
            "cs.CE"
        ]
    },
    {
        "title": "Real-time simulation of parameter-dependent fluid flows through deep   learning-based reduced order models",
        "authors": [
            "Stefania Fresca",
            "Andrea Manzoni"
        ],
        "summary": "Simulating fluid flows in different virtual scenarios is of key importance in engineering applications. However, high-fidelity, full-order models relying, e.g., on the finite element method, are unaffordable whenever fluid flows must be simulated in almost real-time. Reduced order models (ROMs) relying, e.g., on proper orthogonal decomposition (POD) provide reliable approximations to parameter-dependent fluid dynamics problems in rapid times. However, they might require expensive hyper-reduction strategies for handling parameterized nonlinear terms, and enriched reduced spaces (or Petrov-Galerkin projections) if a mixed velocity-pressure formulation is considered, possibly hampering the evaluation of reliable solutions in real-time. Dealing with fluid-structure interactions entails even higher difficulties. The proposed deep learning (DL)-based ROMs overcome all these limitations by learning in a non-intrusive way both the nonlinear trial manifold and the reduced dynamics. To do so, they rely on deep neural networks, after performing a former dimensionality reduction through POD enhancing their training times substantially. The resulting POD-DL-ROMs are shown to provide accurate results in almost real-time for the flow around a cylinder benchmark, the fluid-structure interaction between an elastic beam attached to a fixed, rigid block and a laminar incompressible flow, and the blood flow in a cerebral aneurysm.",
        "published": "2021-06-10T13:07:33Z",
        "link": "http://arxiv.org/abs/2106.05722v1",
        "categories": [
            "physics.flu-dyn",
            "cs.CE",
            "cs.LG",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Ensemble inversion for brain tumor growth models with mass effect",
        "authors": [
            "Shashank Subramanian",
            "Klaudius Scheufele",
            "Naveen Himthani",
            "Christos Davatzikos",
            "George Biros"
        ],
        "summary": "We propose a method for extracting physics-based biomarkers from a single multiparametric Magnetic Resonance Imaging (mpMRI) scan bearing a glioma tumor. We account for mass effect, the deformation of brain parenchyma due to the growing tumor, which on its own is an important radiographic feature but its automatic quantification remains an open problem. In particular, we calibrate a partial differential equation (PDE) tumor growth model that captures mass effect, parameterized by a single scalar parameter, tumor proliferation, migration, while localizing the tumor initiation site. The single-scan calibration problem is severely ill-posed because the precancerous, healthy, brain anatomy is unknown. To address the ill-posedness, we introduce an ensemble inversion scheme that uses a number of normal subject brain templates as proxies for the healthy precancer subject anatomy. We verify our solver on a synthetic dataset and perform a retrospective analysis on a clinical dataset of 216 glioblastoma (GBM) patients. We analyze the reconstructions using our calibrated biophysical model and demonstrate that our solver provides both global and local quantitative measures of tumor biophysics and mass effect. We further highlight the improved performance in model calibration through the inclusion of mass effect in tumor growth models -- including mass effect in the model leads to 10% increase in average dice coefficients for patients with significant mass effect. We further evaluate our model by introducing novel biophysics-based features and using them for survival analysis. Our preliminary analysis suggests that including such features can improve patient stratification and survival prediction.",
        "published": "2021-06-10T19:40:03Z",
        "link": "http://arxiv.org/abs/2106.06016v1",
        "categories": [
            "physics.med-ph",
            "cs.CE",
            "q-bio.TO"
        ]
    },
    {
        "title": "A Single-Layer Dual-Mesh Boundary Element Method for Multiscale   Electromagnetic Modeling of Penetrable Objects in Layered Media",
        "authors": [
            "Shashwat Sharma",
            "Piero Triverio"
        ],
        "summary": "A surface integral representation of Maxwell's equations allows the efficient electromagnetic (EM) modeling of three-dimensional structures with a two-dimensional discretization, via the boundary element method (BEM). However, existing BEM formulations either lead to a poorly conditioned system matrix for multiscale problems, or are computationally expensive for objects embedded in layered substrates. This article presents a new BEM formulation which leverages the surface equivalence principle and Buffa-Christiansen basis functions defined on a dual mesh, to obtain a well-conditioned system matrix suitable for multiscale EM modeling. Unlike existing methods involving dual meshes, the proposed formulation avoids the double-layer potential operator for the surrounding medium, which may be a stratified substrate requiring the use of an advanced Green's function. This feature greatly alleviates the computational expense associated with the use of Buffa-Christiansen functions. Numerical examples drawn from several applications, including remote sensing, chip-level EM analysis, and metasurface modeling, demonstrate speed-ups ranging from 3x to 7x compared to state-of-the-art formulations.",
        "published": "2021-06-11T06:14:58Z",
        "link": "http://arxiv.org/abs/2106.06184v2",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Multiscale modeling of cancellous bone considering full coupling of   mechanical, electrical and magnetic effects",
        "authors": [
            "Mischa Blaszczyk",
            "Klaus Hackl"
        ],
        "summary": "Modeling of cancellous bone has important applications in the detection and treatment of fatigue fractures and diseases like osteoporosis. In this paper, we present a fully coupled multiscale approach considering mechanical, electrical and magnetic effects by using the multiscale finite element method and a two-phase material model on the microscale. We show numerical results for both scales, including calculations for a femur bone, comparing a healthy bone to ones affected by different stages of osteoporosis. Here, the magnetic field strength resulting from a small mechanical impact decreases drastically for later stages of the disease, confirming experimental research.",
        "published": "2021-06-11T12:30:00Z",
        "link": "http://arxiv.org/abs/2106.06343v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Projection-based resolved interface mixed-dimension method for embedded   tubular network systems",
        "authors": [
            "Timo Koch"
        ],
        "summary": "We present a flexible discretization technique for computational models of thin tubular networks embedded in a bulk domain, for example a porous medium. These systems occur in the simulation of fluid flow in vascularized biological tissue, root water and nutrient uptake in soil, hydrological or petroleum wells in rock formations, or heat transport in micro-cooling devices. The key processes, such as heat and mass transfer, are usually dominated by the exchange between the network system and the embedding domain. By explicitly resolving the interface between these domains with the computational mesh, we can accurately describe these processes. The network is efficiently described by a network of line segments. Coupling terms are evaluated by projection of the interface variables. The new method is naturally applicable for nonlinear and time-dependent problems and can therefore be used as a reference method in the development of novel implicit interface 1D-3D methods and in the design of verification benchmarks for embedded tubular network methods. Implicit interface, not resolving the bulk-network interface explicitly have proven to be very efficient but have only been mathematically analyzed for linear elliptic problems so far. Using two application scenarios, fluid perfusion of vascularized tissue and root water uptake from soil, we investigate the effect of some common modeling assumptions of implicit interface methods numerically.",
        "published": "2021-06-11T12:57:37Z",
        "link": "http://arxiv.org/abs/2106.06358v1",
        "categories": [
            "cs.CE",
            "76S05"
        ]
    },
    {
        "title": "Real-time thermoacoustic data assimilation",
        "authors": [
            "Andrea Nóvoa",
            "Luca Magri"
        ],
        "summary": "Low-order thermoacoustic models are qualitatively correct, but they are typically quantitatively inaccurate. We propose a time-domain bias-aware method to make qualitatively low--order models quantitatively (more) accurate. First, we develop a Bayesian ensemble data assimilation method for a low-order model to self-adapt and self-correct any time that reference data becomes available. Second, we apply the methodology to infer the thermoacoustic states and heat release parameters on the fly without storing data (real-time). We perform twin experiments using synthetic acoustic pressure measurements to analyse the performance of data assimilation in all nonlinear thermoacoustic regimes, from limit cycles to chaos, and interpret the results physically. Third, we propose practical rules for thermoacoustic data assimilation. An increase, reject, inflate strategy is proposed to deal with the rich nonlinear behaviour; and physical time scales for assimilation are proposed in non-chaotic regimes (with the Nyquist-Shannon criterion) and in chaotic regimes (with the Lyapunov time). Fourth, we perform data assimilation using data from a higher-fidelity model. We introduce an echo state network to estimate in real-time the forecast bias, which is the model error of the low-fidelity model. We show that (i) the correct acoustic pressure, parameters, and model bias can be accurately inferred; (ii) the learning is robust as it can tackle large uncertainties in the observations (up to 50% the mean values); (iii) the uncertainty of the prediction and parameters is naturally part of the output; and (iv) both the time-accurate solution and statistics can be successfully inferred. Data assimilation opens up new possibility for real-time prediction of thermoacoustics by synergistically combining physical knowledge and experimental data.",
        "published": "2021-06-11T14:06:59Z",
        "link": "http://arxiv.org/abs/2106.06409v3",
        "categories": [
            "physics.flu-dyn",
            "cs.CE",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Multivariate Pair Trading by Volatility & Model Adaption Trade-off",
        "authors": [
            "Chenyanzi Yu",
            "Tianyang Xie"
        ],
        "summary": "Pair trading is one of the most discussed topics among financial researches. Despite a growing base of work, portfolio management for multivariate time series is rarely discussed. On the other hand, most researches focus on refining strategy rules instead of finding the optimal portfolio weight. In this paper, we brought up a simple yet profitable strategy called Volatility & Model Adaption Trade-off (VMAT) to leverage the issues. Experiment studies show its superior profit performance over baselines.",
        "published": "2021-06-11T15:57:33Z",
        "link": "http://arxiv.org/abs/2106.09132v1",
        "categories": [
            "q-fin.PM",
            "cs.CE"
        ]
    },
    {
        "title": "Data-Driven Multiscale Design of Cellular Composites with Multiclass   Microstructures for Natural Frequency Maximization",
        "authors": [
            "Liwei Wang",
            "Anton van Beek",
            "Daicong Da",
            "Yu-Chin Chan",
            "Ping Zhu",
            "Wei Chen"
        ],
        "summary": "For natural frequency optimization of engineering structures, cellular composites have been shown to possess an edge over solid. However, existing multiscale design methods for cellular composites are either computationally exhaustive or confined to a single class of microstructures. In this paper, we propose a data-driven topology optimization (TO) approach to enable the multiscale design of cellular structures with various choices of microstructure classes. The key component is a newly proposed latent-variable Gaussian process (LVGP) model through which different classes of microstructures are mapped into a low-dimensional continuous latent space. It provides an interpretable distance metric between classes and captures their effects on the homogenized stiffness tensors. By introducing latent vectors as design variables, a differentiable transition of stiffness matrix between classes can be easily achieved with an analytical gradient. After integrating LVGP with the density-based TO, an efficient data-driven cellular composite optimization process is developed to enable concurrent exploration of microstructure concepts and the associated volume fractions for natural frequency optimization. Examples reveal that the proposed cellular designs with multiclass microstructures achieve higher natural frequencies than both single-scale and single-class designs. This framework can be easily extended to other multi-scale TO problems, such as thermal compliance and dynamic response optimization.",
        "published": "2021-06-11T15:59:33Z",
        "link": "http://arxiv.org/abs/2106.06478v1",
        "categories": [
            "cs.CE",
            "cs.LG",
            "stat.ML"
        ]
    },
    {
        "title": "CatBoost model with synthetic features in application to loan risk   assessment of small businesses",
        "authors": [
            "Haoxue Wang",
            "Liexin Cheng"
        ],
        "summary": "Loan risk for small businesses has long been a complex problem worthy of exploring. Predicting the loan risk can benefit entrepreneurship by developing more jobs for the society. CatBoost (Categorical Boosting) is a powerful machine learning algorithm suitable for dataset with many categorical variables like the dataset for forecasting loan risk. In this paper, we identify the important risk factors that contribute to loan status classification problem. Then we compare the performance between boosting-type algorithms(especially CatBoost) with other traditional yet popular ones. The dataset we adopt in the research comes from the U.S. Small Business Administration (SBA) and holds a very large sample size (899,164 observations and 27 features). In order to make the best use of the important features in the dataset, we propose a technique named \"synthetic generation\" to develop more combined features based on arithmetic operation, which ends up improving the accuracy and AUC of the original CatBoost model. We obtain a high accuracy of 95.84% and well-performed AUC of 98.80% compared with the existent literature of related research.",
        "published": "2021-06-15T08:17:00Z",
        "link": "http://arxiv.org/abs/2106.07954v3",
        "categories": [
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "Graphical Gaussian Process Regression Model for Aqueous Solvation Free   Energy Prediction of Organic Molecules in Redox Flow Battery",
        "authors": [
            "Peiyuan Gao",
            "Xiu Yang",
            "Yu-Hang Tang",
            "Muqing Zheng",
            "Amity Anderson",
            "Vijayakumar Murugesan",
            "Aaron Hollas",
            "Wei Wang"
        ],
        "summary": "The solvation free energy of organic molecules is a critical parameter in determining emergent properties such as solubility, liquid-phase equilibrium constants, and pKa and redox potentials in an organic redox flow battery. In this work, we present a machine learning (ML) model that can learn and predict the aqueous solvation free energy of an organic molecule using Gaussian process regression method based on a new molecular graph kernel. To investigate the performance of the ML model on electrostatic interaction, the nonpolar interaction contribution of solvent and the conformational entropy of solute in solvation free energy, three data sets with implicit or explicit water solvent models, and contribution of conformational entropy of solute are tested. We demonstrate that our ML model can predict the solvation free energy of molecules at chemical accuracy with a mean absolute error of less than 1 kcal/mol for subsets of the QM9 dataset and the Freesolv database. To solve the general data scarcity problem for a graph-based ML model, we propose a dimension reduction algorithm based on the distance between molecular graphs, which can be used to examine the diversity of the molecular data set. It provides a promising way to build a minimum training set to improve prediction for certain test sets where the space of molecular structures is predetermined.",
        "published": "2021-06-15T13:48:26Z",
        "link": "http://arxiv.org/abs/2106.08146v1",
        "categories": [
            "cs.CE",
            "cs.LG",
            "physics.chem-ph"
        ]
    },
    {
        "title": "An improved Material Mask Overlay Strategy for the desired discreteness   of pressure-loaded optimized topologies",
        "authors": [
            "Prabhat Kumar",
            "Anupam Saxena"
        ],
        "summary": "This paper presents a Material Mask Overlay topology optimization approach with the improved material assignment at the element level for achieving the desired discreteness of the optimized designs for pressure-loaded problems. Hexagonal elements are employed to parametrize the design domain. Such elements provide nonsingular local connectivity; thus, checkerboard patterns and point connections inherently get subdued. Elliptical negative masks are used to find the optimized material layout. Each mask is represented via seven parameters that describe the location, shape, orientation, material dilation, and erosion variables of the mask. The latter two variables are systematically varied in conjunction with a grayscale measure constraint to achieve the solutions' sought 0-1 nature. Darcy's law with a drainage term is used to model the pressure load. The obtained pressure field is converted into the consistent nodal forces using Wachspress shape functions. Sensitivities of the objective and pressure load are evaluated using the adjoint-variable method. The efficacy and robustness of the approach are demonstrated by solving various pressure-loaded structures and pressure-driven compliant mechanisms. Compliance is minimized for loadbearing structures, whereas a multicriteria objective is minimized for mechanism designs. The boundary smoothing scheme is implemented within each optimization iteration to subdue the designs' undulated boundaries.",
        "published": "2021-06-17T04:49:39Z",
        "link": "http://arxiv.org/abs/2106.09245v3",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Scale-invariant multilevel Monte Carlo method and application to linear   elasticity",
        "authors": [
            "Sharana Kumar Shivanand",
            "Bojana Rosić"
        ],
        "summary": "We propose a novel scale-invariant version of the mean and variance multi-level Monte Carlo estimate. The computation cost across grid levels is optimised using a normalized error based on t-statistics. By doing so, the algorithm achieves convergence independent of the physical scale at which the estimate is computed. The effectiveness of this algorithm is demonstrated through testing on a linear elastic example, where material uncertainty incorporating both heterogeneity and anisotropy is considered in the constitutive law.",
        "published": "2021-06-17T13:23:08Z",
        "link": "http://arxiv.org/abs/2106.13723v2",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Rotation Invariant Graph Neural Networks using Spin Convolutions",
        "authors": [
            "Muhammed Shuaibi",
            "Adeesh Kolluru",
            "Abhishek Das",
            "Aditya Grover",
            "Anuroop Sriram",
            "Zachary Ulissi",
            "C. Lawrence Zitnick"
        ],
        "summary": "Progress towards the energy breakthroughs needed to combat climate change can be significantly accelerated through the efficient simulation of atomic systems. Simulation techniques based on first principles, such as Density Functional Theory (DFT), are limited in their practical use due to their high computational expense. Machine learning approaches have the potential to approximate DFT in a computationally efficient manner, which could dramatically increase the impact of computational simulations on real-world problems. Approximating DFT poses several challenges. These include accurately modeling the subtle changes in the relative positions and angles between atoms, and enforcing constraints such as rotation invariance or energy conservation. We introduce a novel approach to modeling angular information between sets of neighboring atoms in a graph neural network. Rotation invariance is achieved for the network's edge messages through the use of a per-edge local coordinate frame and a novel spin convolution over the remaining degree of freedom. Two model variants are proposed for the applications of structure relaxation and molecular dynamics. State-of-the-art results are demonstrated on the large-scale Open Catalyst 2020 dataset. Comparisons are also performed on the MD17 and QM9 datasets.",
        "published": "2021-06-17T14:59:34Z",
        "link": "http://arxiv.org/abs/2106.09575v1",
        "categories": [
            "cs.LG",
            "cs.CE",
            "I.2.6; J.2"
        ]
    },
    {
        "title": "Generating various airfoil shapes with required lift coefficient using   conditional variational autoencoders",
        "authors": [
            "Kazuo Yonekura",
            "Kazunari Wada",
            "Katsuyuki Suzuki"
        ],
        "summary": "Multiple shapes must be obtained in the mechanical design process to satisfy the required design specifications. The inverse design problem has been analyzed in previous studies to obtain such shapes. However, finding multiple shapes in a short computation period is difficult while using the conventional methods. This paper proposes the use of the conditional variational autoencoders (CVAE) with normal distribution, denoted by N-CVAE, along with the von Mises-Fischer distribution, denoted by S-CVAE, to find multiple solutions for the inverse design problems. Both the CVAE models embed shapes into a latent space. The S-CVAE enables the separation of data in the latent space, whereas the N-CVAE embeds the data in a narrow space. These different features are used for various tasks in this study. In one of the tasks, the dataset consists of only one type of data and generates similar airfoils. Here, S-CVAE outperforms N-CVAE because it can separate the data. Another task involves combining different types of airfoils and generating new types of data. N-CVAE is useful in this instance since it embeds different shapes in the same latent area, due to which, the model outputs intermediate shapes of different types. The shape-generation capability of S-CVAE and N-CVAE are experimentally compared in this study.",
        "published": "2021-06-18T03:50:40Z",
        "link": "http://arxiv.org/abs/2106.09901v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "FinGAT: Financial Graph Attention Networks for Recommending Top-K   Profitable Stocks",
        "authors": [
            "Yi-Ling Hsu",
            "Yu-Che Tsai",
            "Cheng-Te Li"
        ],
        "summary": "Financial technology (FinTech) has drawn much attention among investors and companies. While conventional stock analysis in FinTech targets at predicting stock prices, less effort is made for profitable stock recommendation. Besides, in existing approaches on modeling time series of stock prices, the relationships among stocks and sectors (i.e., categories of stocks) are either neglected or pre-defined. Ignoring stock relationships will miss the information shared between stocks while using pre-defined relationships cannot depict the latent interactions or influence of stock prices between stocks. In this work, we aim at recommending the top-K profitable stocks in terms of return ratio using time series of stock prices and sector information. We propose a novel deep learning-based model, Financial Graph Attention Networks (FinGAT), to tackle the task under the setting that no pre-defined relationships between stocks are given. The idea of FinGAT is three-fold. First, we devise a hierarchical learning component to learn short-term and long-term sequential patterns from stock time series. Second, a fully-connected graph between stocks and a fully-connected graph between sectors are constructed, along with graph attention networks, to learn the latent interactions among stocks and sectors. Third, a multi-task objective is devised to jointly recommend the profitable stocks and predict the stock movement. Experiments conducted on Taiwan Stock, S&P 500, and NASDAQ datasets exhibit remarkable recommendation performance of our FinGAT, comparing to state-of-the-art methods.",
        "published": "2021-06-18T14:51:14Z",
        "link": "http://arxiv.org/abs/2106.10159v1",
        "categories": [
            "cs.LG",
            "cs.CE",
            "cs.IR",
            "cs.SI"
        ]
    },
    {
        "title": "Interval and fuzzy physics-informed neural networks for uncertain fields",
        "authors": [
            "Jan Niklas Fuhg",
            "Ioannis Kalogeris",
            "Amélie Fau",
            "Nikolaos Bouklas"
        ],
        "summary": "Temporally and spatially dependent uncertain parameters are regularly encountered in engineering applications. Commonly these uncertainties are accounted for using random fields and processes, which require knowledge about the appearing probability distributions functions that is not readily available. In these cases non-probabilistic approaches such as interval analysis and fuzzy set theory are helpful uncertainty measures. Partial differential equations involving fuzzy and interval fields are traditionally solved using the finite element method where the input fields are sampled using some basis function expansion methods. This approach however is problematic, as it is reliant on knowledge about the spatial correlation fields. In this work we utilize physics-informed neural networks (PINNs) to solve interval and fuzzy partial differential equations. The resulting network structures termed interval physics-informed neural networks (iPINNs) and fuzzy physics-informed neural networks (fPINNs) show promising results for obtaining bounded solutions of equations involving spatially and/or temporally uncertain parameter fields. In contrast to finite element approaches, no correlation length specification of the input fields as well as no Monte-Carlo simulations are necessary. In fact, information about the input interval fields is obtained directly as a byproduct of the presented solution scheme. Furthermore, all major advantages of PINNs are retained, i.e. meshfree nature of the scheme, and ease of inverse problem set-up.",
        "published": "2021-06-18T21:06:42Z",
        "link": "http://arxiv.org/abs/2106.13727v2",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.LG",
            "cs.NA",
            "35Q74",
            "J.2; I.2.8"
        ]
    },
    {
        "title": "Linking ghost penalty and aggregated unfitted methods",
        "authors": [
            "Santiago Badia",
            "Eric Neiva",
            "Francesc Verdugo"
        ],
        "summary": "In this work, we analyse the links between ghost penalty stabilisation and aggregation-based discrete extension operators for the numerical approximation of elliptic partial differential equations on unfitted meshes. We explore the behavior of ghost penalty methods in the limit as the penalty parameter goes to infinity, which returns a strong version of these methods. We observe that these methods suffer locking in that limit. On the contrary, aggregated finite element spaces are locking-free because they can be expressed as an extension operator from well-posed to ill-posed degrees of freedom. Next, we propose novel ghost penalty methods that penalise the distance between the solution and its aggregation-based discrete extension. These methods are locking-free and converge to aggregated finite element methods in the infinite penalty parameter limit. We include an exhaustive set of numerical experiments in which we compare weak (ghost penalty) and strong (aggregated finite elements) schemes in terms of error quantities, condition numbers and sensitivity with respect to penalty coefficients on different geometries, intersection locations and mesh topologies.",
        "published": "2021-06-19T10:23:04Z",
        "link": "http://arxiv.org/abs/2106.13728v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Stein particle filtering",
        "authors": [
            "Jiaojiao Fan",
            "Amirhossein Taghvaei",
            "Yongxin Chen"
        ],
        "summary": "We present a new particle filtering algorithm for nonlinear systems in the discrete-time setting. Our algorithm is based on the Stein variational gradient descent (SVGD) framework, which is a general approach to sample from a target distribution. We merge the standard two-step paradigm in particle filtering into one step so that SVGD can be used. A distinguishing feature of the proposed algorithm is that, unlike most particle filtering methods, all the particles at any time step are equally weighted and thus no update on the weights is needed. We further extended our algorithm to allow for updating previous particles within a sliding window. This strategy may improve the reliability of the algorithm with respect to unexpected disturbance in the dynamics or outlier-measurements. The efficacy of the proposed algorithms is illustrated through several numerical examples in comparison with a standard particle filtering method.",
        "published": "2021-06-19T20:41:19Z",
        "link": "http://arxiv.org/abs/2106.10568v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Polyconvex anisotropic hyperelasticity with neural networks",
        "authors": [
            "Dominik K. Klein",
            "Mauricio Fernández",
            "Robert J. Martin",
            "Patrizio Neff",
            "Oliver Weeger"
        ],
        "summary": "In the present work, two machine learning based constitutive models for finite deformations are proposed. Using input convex neural networks, the models are hyperelastic, anisotropic and fulfill the polyconvexity condition, which implies ellipticity and thus ensures material stability. The first constitutive model is based on a set of polyconvex, anisotropic and objective invariants. The second approach is formulated in terms of the deformation gradient, its cofactor and determinant, uses group symmetrization to fulfill the material symmetry condition, and data augmentation to fulfill objectivity approximately. The extension of the dataset for the data augmentation approach is based on mechanical considerations and does not require additional experimental or simulation data. The models are calibrated with highly challenging simulation data of cubic lattice metamaterials, including finite deformations and lattice instabilities. A moderate amount of calibration data is used, based on deformations which are commonly applied in experimental investigations. While the invariant-based model shows drawbacks for several deformation modes, the model based on the deformation gradient alone is able to reproduce and predict the effective material behavior very well and exhibits excellent generalization capabilities. In addition, the models are calibrated with transversely isotropic data, generated with an analytical polyconvex potential. For this case, both models show excellent results, demonstrating the straightforward applicability of the polyconvex neural network constitutive models to other symmetry groups.",
        "published": "2021-06-20T15:33:31Z",
        "link": "http://arxiv.org/abs/2106.14623v2",
        "categories": [
            "cond-mat.mtrl-sci",
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "Efficient Wildland Fire Simulation via Nonlinear Model Order Reduction",
        "authors": [
            "Felix Black",
            "Philipp Schulze",
            "Benjamin Unger"
        ],
        "summary": "We propose a new hyper-reduction method for a recently introduced nonlinear model reduction framework based on dynamically transformed basis functions and especially well-suited for advection-dominated systems. Furthermore, we discuss applying this new method to a wildland fire model whose dynamics feature traveling combustion waves and local ignition and is thus challenging for classical model reduction schemes based on linear subspaces. The new hyper-reduction framework allows us to construct parameter-dependent reduced-order models (ROMs) with efficient offline/online decomposition. The numerical experiments demonstrate that the ROMs obtained by the novel method outperform those obtained by a classical approach using the proper orthogonal decomposition and the discrete empirical interpolation method in terms of run time and accuracy.",
        "published": "2021-06-21T19:32:24Z",
        "link": "http://arxiv.org/abs/2106.11381v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "80A25, 37L65, 35Q79"
        ]
    },
    {
        "title": "MegazordNet: combining statistical and machine learning standpoints for   time series forecasting",
        "authors": [
            "Angelo Garangau Menezes",
            "Saulo Martiello Mastelini"
        ],
        "summary": "Forecasting financial time series is considered to be a difficult task due to the chaotic feature of the series. Statistical approaches have shown solid results in some specific problems such as predicting market direction and single-price of stocks; however, with the recent advances in deep learning and big data techniques, new promising options have arises to tackle financial time series forecasting. Moreover, recent literature has shown that employing a combination of statistics and machine learning may improve accuracy in the forecasts in comparison to single solutions. Taking into consideration the mentioned aspects, in this work, we proposed the MegazordNet, a framework that explores statistical features within a financial series combined with a structured deep learning model for time series forecasting. We evaluated our approach predicting the closing price of stocks in the S&P 500 using different metrics, and we were able to beat single statistical and machine learning methods.",
        "published": "2021-06-23T15:06:54Z",
        "link": "http://arxiv.org/abs/2107.01017v1",
        "categories": [
            "q-fin.ST",
            "cs.AI",
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "On the calculation of neutron sources generating steady prescribed power   distributions in subcritical systems using multigroup X,Y-geometry discrete   ordinates models",
        "authors": [
            "Leonardo",
            "R. C. Moraes",
            "Hermes Alves Filho",
            "Ricardo C. Barros"
        ],
        "summary": "In this paper a methodology is described to estimate multigroup neutron source distributions which must be added into a subcritical system to drive it to a steady state prescribed power distribution. This work has been motivated by the principle of operation of the ADS (Accelerator Driven System) reactors, which have subcritical cores stabilized by the action of external sources. We use the energy multigroup two-dimensional neutron transport equation in the discrete ordinates formulation (SN) and the equation which is adjoint to it, whose solution is interpreted here as a distribution measuring the importance of the angular flux of neutrons to a linear functional. These equations are correlated through a reciprocity relation, leading to a relationship between the interior sources of neutrons and the power produced by unit length of height of the domain. A coarse-mesh numerical method of the spectral nodal class, referred to as adjoint response matrix constant-nodal method, is applied to numerically solve the adjoint SN equations. Numerical experiments are performed to analyze the accuracy of the present methodology so as to illustrate its potential practical applications.",
        "published": "2021-06-23T21:56:52Z",
        "link": "http://arxiv.org/abs/2106.12668v1",
        "categories": [
            "nucl-th",
            "cs.CE"
        ]
    },
    {
        "title": "Optimisation of spatially varying orthotropic porous structures based on   conformal mapping",
        "authors": [
            "Shaoshuai Li",
            "Yichao Zhu",
            "Xu Guo"
        ],
        "summary": "In this article, a compliance minimisation scheme for designing spatially varying orthotropic porous structures is proposed. With the utilisation of conformal mapping, the porous structures here can be generated by two controlling field variables, the (logarithm of) the local scaling factor and the rotational angle of the matrix cell, and they are interrelated through the Cauchy-Riemann equations. Thus the design variables are simply reduced to the logarithm values of the local scaling factor on selected boundary points. Other attractive features shown by the present method are summarised as follows. Firstly, with the condition of total differential automatically met by the two controlling field variables, the integrability problem which necessitates post-processing treatments in many other similar methods can be resolved naturally. Secondly, according to the maximum principle for harmonic functions, the minimum feature size can be explicitly monitored during optimisation. Thirdly, the rotational symmetry possessed by the matrix cell can be fully exploited in the context of conformal mapping, and the computational cost for solving the cell problems for the homogenised elasticity tensor is maximally abased. In particular, when the design domain takes a rectangle shape, analytical expressions for the controlling fields are available. The homogenised results are shown, both theoretically and numerically, to converge to the corresponding fine-scale results, and the effectiveness of the proposed work is further demonstrated with more numerical examples.",
        "published": "2021-06-24T04:44:26Z",
        "link": "http://arxiv.org/abs/2107.03899v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "The maximum discrete surface-to-volume ratio of space-filling curve   partitions",
        "authors": [
            "Maximilien Gadouleau",
            "Tobias Weinzierl"
        ],
        "summary": "Space-filling curves (SFCs) are used in high performance computing to distribute a computational domain or its mesh, respectively, amongst different compute units, i.e.~cores or nodes or accelerators. The part of the domain allocated to each compute unit is called a partition. Besides the balancing of the work, the communication cost to exchange data between units determines the quality of a chosen partition. This cost can be approximated by the surface-to-volume ratio of partitions: the volume represents the amount of local work, while the surface represents the amount of data to be transmitted. Empirical evidence suggests that space-filling curves yield advantageous surface-to-volume ratios. Formal proofs are available only for regular grids. We investigate the surface-to-volume ratio of space-filling curve partitions for adaptive grids and derive the maximum surface-to-volume ratio as a function of the number of cells in the partition. In order to prove our main theorem, we construct a new framework for the study of adaptive grids, notably introducing the concepts of a shape and of classified partitions. The new methodological framework yields insight about the SFC-induced partition character even if the grids refine rather aggressively in localised areas: it quantifies the obtained surface-to-volume ratio. This framework thus has the potential to guide the design of better load balancing algorithms on the long term.",
        "published": "2021-06-24T09:34:01Z",
        "link": "http://arxiv.org/abs/2106.12856v1",
        "categories": [
            "cs.CE",
            "cs.CG",
            "68R01, 05B25, 68U05"
        ]
    },
    {
        "title": "Learning Multiple Stock Trading Patterns with Temporal Routing Adaptor   and Optimal Transport",
        "authors": [
            "Hengxu Lin",
            "Dong Zhou",
            "Weiqing Liu",
            "Jiang Bian"
        ],
        "summary": "Successful quantitative investment usually relies on precise predictions of the future movement of the stock price. Recently, machine learning based solutions have shown their capacity to give more accurate stock prediction and become indispensable components in modern quantitative investment systems. However, the i.i.d. assumption behind existing methods is inconsistent with the existence of diverse trading patterns in the stock market, which inevitably limits their ability to achieve better stock prediction performance. In this paper, we propose a novel architecture, Temporal Routing Adaptor (TRA), to empower existing stock prediction models with the ability to model multiple stock trading patterns. Essentially, TRA is a lightweight module that consists of a set of independent predictors for learning multiple patterns as well as a router to dispatch samples to different predictors. Nevertheless, the lack of explicit pattern identifiers makes it quite challenging to train an effective TRA-based model. To tackle this challenge, we further design a learning algorithm based on Optimal Transport (OT) to obtain the optimal sample to predictor assignment and effectively optimize the router with such assignment through an auxiliary loss term. Experiments on the real-world stock ranking task show that compared to the state-of-the-art baselines, e.g., Attention LSTM and Transformer, the proposed method can improve information coefficient (IC) from 0.053 to 0.059 and 0.051 to 0.056 respectively. Our dataset and code used in this work are publicly available: https://github.com/microsoft/qlib/tree/main/examples/benchmarks/TRA.",
        "published": "2021-06-24T12:19:45Z",
        "link": "http://arxiv.org/abs/2106.12950v2",
        "categories": [
            "cs.LG",
            "cs.CE",
            "q-fin.ST"
        ]
    },
    {
        "title": "Regularisation for PCA- and SVD-type matrix factorisations",
        "authors": [
            "Abdolrahman Khoshrou",
            "Eric J. Pauwels"
        ],
        "summary": "Singular Value Decomposition (SVD) and its close relative, Principal Component Analysis (PCA), are well-known linear matrix decomposition techniques that are widely used in applications such as dimension reduction and clustering. However, an important limitation of SVD/PCA is its sensitivity to noise in the input data. In this paper, we take another look at the problem of regularisation and show that different formulations of the minimisation problem lead to qualitatively different solutions.",
        "published": "2021-06-24T12:25:12Z",
        "link": "http://arxiv.org/abs/2106.12955v1",
        "categories": [
            "cs.CV",
            "cs.CE"
        ]
    },
    {
        "title": "Free surface flow through rigid porous media -- An overview and   comparison of formulations",
        "authors": [
            "Wibke Düsterhöft-Wriggers",
            "Antonia Larese",
            "Thomas Rung",
            "Eugenio Oñate"
        ],
        "summary": "In many applications free surface flow through rigid porous media has to be modeled. Examples refer to coastal engineering applications as well as geotechnical or biomedical applications. Albeit the frequent applications, slight inconsistencies in the formulation of the governing equations can be found in the literature. The main goal of this paper is to identify these differences and provide a quantitative assessment of different approaches. Following a review of the different formulations, simulation results obtained from three alternative formulations are compared with experimental and numerical data. Results obtained by 2D and 3D test cases indicate that the predictive differences returned by the different formulations remain small for most applications, in particular for small porous Reynolds number ReP < 5000. Thus it seems justified to select a formulation that supports an efficient algorithm and coding structure.",
        "published": "2021-06-24T18:39:17Z",
        "link": "http://arxiv.org/abs/2106.13267v1",
        "categories": [
            "physics.flu-dyn",
            "cs.CE"
        ]
    },
    {
        "title": "Spectral concepts in genome informational analysis",
        "authors": [
            "Vincenzo Bonnici",
            "Giuditta Franco",
            "Vincenzo Manca"
        ],
        "summary": "The concept of k-spectrum for genomes is here investigated as a basic tool to analyze genomes. Related spectral notions based on k-mers are introduced with some related mathematical properties which are relevant for informational analysis of genomes. Procedures to generate spectral segmentations of genomes are provided and are tested (under several values of length k for k-mers) on cases of real genomes, such as some human chromosomes and Saccharomyces cerevisiae.",
        "published": "2021-06-25T10:00:55Z",
        "link": "http://arxiv.org/abs/2106.15351v1",
        "categories": [
            "cs.CE",
            "q-bio.GN"
        ]
    },
    {
        "title": "SnakeLines: integrated set of computational pipelines for sequencing   reads",
        "authors": [
            "Jaroslav Budis",
            "Werner Krampl",
            "Marcel Kucharik",
            "Rastislav Hekel",
            "Adrian Goga",
            "Michal Lichvar",
            "David Smolak",
            "Miroslav Bohmer",
            "Andrej Balaz",
            "Frantisek Duris",
            "Juraj Gazdarica",
            "Katarina Soltys",
            "Jan Turna",
            "Jan Radvanszky",
            "Tomas Szemes"
        ],
        "summary": "Background: With the rapid growth of massively parallel sequencing technologies, still more laboratories are utilizing sequenced DNA fragments for genomic analyses. Interpretation of sequencing data is, however, strongly dependent on bioinformatics processing, which is often too demanding for clinicians and researchers without a computational background. Another problem represents the reproducibility of computational analyses across separated computational centers with inconsistent versions of installed libraries and bioinformatics tools.   Results: We propose an easily extensible set of computational pipelines, called SnakeLines, for processing sequencing reads; including mapping, assembly, variant calling, viral identification, transcriptomics, metagenomics, and methylation analysis. Individual steps of an analysis, along with methods and their parameters can be readily modified in a single configuration file. Provided pipelines are embedded in virtual environments that ensure isolation of required resources from the host operating system, rapid deployment, and reproducibility of analysis across different Unix-based platforms.   Conclusion: SnakeLines is a powerful framework for the automation of bioinformatics analyses, with emphasis on a simple set-up, modifications, extensibility, and reproducibility.   Keywords: Computational pipeline, framework, massively parallel sequencing, reproducibility, virtual environment",
        "published": "2021-06-25T14:10:19Z",
        "link": "http://arxiv.org/abs/2106.13649v1",
        "categories": [
            "q-bio.GN",
            "cs.CE"
        ]
    },
    {
        "title": "Reducing Boolean Networks with Backward Boolean Equivalence",
        "authors": [
            "Georgios Argyris",
            "Alberto Lluch Lafuente",
            "Mirco Tribastone",
            "Max Tschaikowski",
            "Andrea Vandin"
        ],
        "summary": "Boolean Networks (BNs) are established models to qualitatively describe biological systems. The analysis of BNs might be infeasible for medium to large BNs due to the state-space explosion problem. We propose a novel reduction technique called \\emph{Backward Boolean Equivalence} (BBE), which preserves some properties of interest of BNs. In particular, reduced BNs provide a compact representation by grouping variables that, if initialized equally, are always updated equally. The resulting reduced state space is a subset of the original one, restricted to identical initialization of grouped variables. The corresponding trajectories of the original BN can be exactly restored. We show the effectiveness of BBE by performing a large-scale validation on the whole GINsim BN repository. In selected cases, we show how our method enables analyses that would be otherwise intractable. Our method complements, and can be combined with, other reduction methods found in the literature.",
        "published": "2021-06-25T14:54:39Z",
        "link": "http://arxiv.org/abs/2106.15476v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Convergence Analysis and Numerical Studies for Linearly Elastic   Peridynamics with Dirichlet-Type Boundary Conditions",
        "authors": [
            "Mikil Foss",
            "Petronela Radu",
            "Yue Yu"
        ],
        "summary": "The nonlocal models of peridynamics have successfully predicted fractures and deformations for a variety of materials. In contrast to local mechanics, peridynamic boundary conditions must be defined on a finite volume region outside the body. Therefore, theoretical and numerical challenges arise in order to properly formulate Dirichlet-type nonlocal boundary conditions, while connecting them to the local counterparts. While a careless imposition of local boundary conditions leads to a smaller effective material stiffness close to the boundary and an artificial softening of the material, several strategies were proposed to avoid this unphysical surface effect.   In this work, we study convergence of solutions to nonlocal state-based linear elastic model to their local counterparts as the interaction horizon vanishes, under different formulations and smoothness assumptions for nonlocal Dirichlet-type boundary conditions. Our results provide explicit rates of convergence that are sensitive to the compatibility of the nonlocal boundary data and the extension of the solution for the local model. In particular, under appropriate assumptions, constant extensions yield $\\frac{1}{2}$ order convergence rates and linear extensions yield $\\frac{3}{2}$ order convergence rates. With smooth extensions, these rates are improved to quadratic convergence. We illustrate the theory for any dimension $d\\geq 2$ and numerically verify the convergence rates with a number of two dimensional benchmarks, including linear patch tests, manufactured solutions, and domains with curvilinear surfaces. Numerical results show a first order convergence for constant extensions and second order convergence for linear extensions, which suggests a possible room of improvement in the future convergence analysis.",
        "published": "2021-06-25T20:40:42Z",
        "link": "http://arxiv.org/abs/2106.13878v1",
        "categories": [
            "math.AP",
            "cs.CE",
            "cs.NA",
            "math.NA",
            "45A05, 45K05, 47G10, 74G65, 74B15, 74H15",
            "G.1.9; J.2"
        ]
    },
    {
        "title": "Analyzing and predicting non-equilibrium many-body dynamics via dynamic   mode decomposition",
        "authors": [
            "Jia Yin",
            "Yang-hao Chan",
            "Felipe da Jornada",
            "Diana Qiu",
            "Chao Yang",
            "Steven G. Louie"
        ],
        "summary": "Simulating the dynamics of a nonequilibrium quantum many-body system by computing the two-time Green's function associated with such a system is computationally challenging. However, we are often interested in the time diagonal of such a Green's function or time dependent physical observables that are functions of one time. In this paper, we discuss the possibility of using dynamic model decomposition (DMD), a data-driven model order reduction technique, to characterize one-time observables associated with the nonequilibrium dynamics using snapshots computed within a small time window. The DMD method allows us to efficiently predict long time dynamics from a limited number of trajectory samples. We demonstrate the effectiveness of DMD on a model two-band system. We show that, in the equilibrium limit, the DMD analysis yields results that are consistent with those produced from a linear response analysis. In the nonequilibrium case, the extrapolated dynamics produced by DMD is more accurate than a special Fourier extrapolation scheme presented in this paper. We point out a potential pitfall of the standard DMD method caused by insufficient spatial/momentum resolution of the discretization scheme. We show how this problem can be overcome by using a variant of the DMD method known as higher order DMD.",
        "published": "2021-06-26T05:53:27Z",
        "link": "http://arxiv.org/abs/2107.09635v1",
        "categories": [
            "cond-mat.stat-mech",
            "cond-mat.str-el",
            "cs.CE"
        ]
    },
    {
        "title": "A linear phase evolution model for reduction of temporal unwrapping and   field estimation errors in multi-echo GRE",
        "authors": [
            "Joseph Suresh Paul",
            "Sreekanth Madhusoodhanan"
        ],
        "summary": "This article aims at developing a model based optimization for reduction of temporal unwrapping and field estimation errors in multi-echo acquisition of Gradient Echo sequence. Using the assumption that the phase is linear along the temporal dimension, the field estimation is performed by application of unity rank approximation to the Hankel matrix formed using the complex exponential of the channel combined phase at each echo time. For the purpose of maintaining consistency with the observed complex data, the linear phase evolution model is formulated as an optimization problem with a cost function that involves a fidelity term and a unity rank prior, implemented using alternating minimization. Itoh s algorithm applied to the multi-echo phase estimated from this linear phase evolution model is able to reduce the unwrapping errors as compared to the unwrapping when directly applied to the measured phase. Secondly, the improved accuracy of the frequency fit in comparison to estimation using weighted least-square regression and penalized maximum likelihood is demonstrated using numerical simulation of field perturbation due to magnetic susceptibility effect. It is shown that the field can be estimated with 80 percent reduction in mean absolute error in comparison to wLSR and 66 percent reduction with respect to penalized maximum likelihood. The improvement in performance becomes more pronounced with increasing strengths of field gradient magnitudes and echo spacing.",
        "published": "2021-06-26T09:33:29Z",
        "link": "http://arxiv.org/abs/2107.00615v1",
        "categories": [
            "physics.med-ph",
            "cs.CE",
            "eess.SP",
            "J.2"
        ]
    },
    {
        "title": "Robust Multi-echo GRE Phase processing using a unity rank enforced   complex exponential model",
        "authors": [
            "Joseph Suresh Paul",
            "Sreekanth Madhusoodhanan"
        ],
        "summary": "Purpose: Develop a processing scheme for Gradient Echo (GRE) phase to enable restoration of susceptibility-related (SuR) features in regions affected by imperfect phase unwrapping, background suppression and low signal-to-noise ratio (SNR) due to phase dispersion. Theory and Methods: The predictable components sampled across the echo dimension in a multi-echo GRE sequence are recovered by rank minimizing a Hankel matrix formed using the complex exponential of the background suppressed phase. To estimate the single frequency component that relates to the susceptibility induced field, it is required to maintain consistency with the measured phase after background suppression, penalized by a unity rank approximation (URA) prior. This is formulated as an optimization problem, implemented using the alternating direction method of multiplier (ADMM). Results: With in vivo multi-echo GRE data, the magnitude susceptibility weighted image (SWI) reconstructed using URA prior shows additional venous structures that are obscured due to phase dispersion and noise in regions subject to remnant non-local field variations. The performance is compared with the susceptibility map weighted imaging (SMWI) and the standard SWI. It is also shown using numerical simulation that quantitative susceptibility map (QSM) computed from the reconstructed phase exhibits reduced artifacts and quantification error. In vivo experiments reveal iron depositions in insular, motor cortex and superior frontal gyrus that are not identified in standard QSM. Conclusion: URA processed GRE phase is less sensitive to imperfections in the phase pre-processing techniques, and thereby enable robust estimation of SWI and QSM.",
        "published": "2021-06-26T10:22:37Z",
        "link": "http://arxiv.org/abs/2106.15472v1",
        "categories": [
            "physics.med-ph",
            "cs.CE",
            "J.2"
        ]
    },
    {
        "title": "Optimization of a Moving Sensor Trajectory for Observing a Point Scalar   Source in Turbulent Flow",
        "authors": [
            "Constantinos F. Panagiotou",
            "Davide Cerizza",
            "Tamer A. Zaki",
            "Yosuke Hasegawa"
        ],
        "summary": "We propose a strategy for optimizing a sensor trajectory in order to estimate the time dependence of a localized scalar source in turbulent channel flow. The approach leverages the view of the adjoint scalar field as the sensitivity of measurement to a possible source. A cost functional is constructed so that the optimal sensor trajectory maintains a high sensitivity and low temporal variation in the measured signal, for a given source location. This naturally leads to the adjoint-of-adjoint equation based on which the sensor trajectory is iteratively optimized. It is shown that the estimation performance based on the measurement obtained by a sensor moving along the optimal trajectory is drastically improved from that achieved with a stationary sensor. It is also shown that the ratio of the fluctuation and the mean of the sensitivity for a given sensor trajectory can be used as a diagnostic tool to evaluate the resultant performance. Based on this finding, we propose a new cost functional which only includes the ratio without any adjustable parameters, and demonstrate its effectiveness in predicting the time dependence of scalar release from the source.",
        "published": "2021-06-26T10:43:32Z",
        "link": "http://arxiv.org/abs/2106.13996v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Inferring a Continuous Distribution of Atom Coordinates from Cryo-EM   Images using VAEs",
        "authors": [
            "Dan Rosenbaum",
            "Marta Garnelo",
            "Michal Zielinski",
            "Charlie Beattie",
            "Ellen Clancy",
            "Andrea Huber",
            "Pushmeet Kohli",
            "Andrew W. Senior",
            "John Jumper",
            "Carl Doersch",
            "S. M. Ali Eslami",
            "Olaf Ronneberger",
            "Jonas Adler"
        ],
        "summary": "Cryo-electron microscopy (cryo-EM) has revolutionized experimental protein structure determination. Despite advances in high resolution reconstruction, a majority of cryo-EM experiments provide either a single state of the studied macromolecule, or a relatively small number of its conformations. This reduces the effectiveness of the technique for proteins with flexible regions, which are known to play a key role in protein function. Recent methods for capturing conformational heterogeneity in cryo-EM data model it in volume space, making recovery of continuous atomic structures challenging. Here we present a fully deep-learning-based approach using variational auto-encoders (VAEs) to recover a continuous distribution of atomic protein structures and poses directly from picked particle images and demonstrate its efficacy on realistic simulated data. We hope that methods built on this work will allow incorporation of stronger prior information about protein structure and enable better understanding of non-rigid protein structures.",
        "published": "2021-06-26T22:55:46Z",
        "link": "http://arxiv.org/abs/2106.14108v1",
        "categories": [
            "cs.CE",
            "eess.IV"
        ]
    },
    {
        "title": "A direct Jacobian total Lagrangian explicit dynamics finite element   algorithm for real-time simulation of hyperelastic materials",
        "authors": [
            "Jinao Zhang"
        ],
        "summary": "This paper presents a novel direct Jacobian total Lagrangian explicit dynamics (DJ-TLED) finite element algorithm for real-time nonlinear mechanics simulation. The nodal force contributions are expressed using only the Jacobian operator, instead of the deformation gradient tensor and finite deformation tensor, for fewer computational operations at run-time. Owing to this proposed Jacobian formulation, novel expressions are developed for strain invariants and constant components, which are also based on the Jacobian operator. Results show that the proposed DJ-TLED consumed between 0.70x and 0.88x CPU solution times compared to state-of-the-art TLED and achieved up to 121.72x and 94.26x speed improvements in tetrahedral and hexahedral meshes, respectively, using GPU acceleration. Compared to TLED, the most notable difference is that the notions of stress and strain are not explicitly visible in the proposed DJ-TLED but embedded implicitly in the formulation of nodal forces. Such a force formulation can be beneficial for fast deformation computation and can be particularly useful if the displacement field is of primary interest, which is demonstrated using a neurosurgical simulation of brain deformations for image-guided neurosurgery. The present work contributes towards a comprehensive DJ-TLED algorithm concerning isotropic and anisotropic hyperelastic constitutive models and GPU implementation. The source code is available at https://github.com/jinaojakezhang/DJTLED.",
        "published": "2021-06-27T10:33:46Z",
        "link": "http://arxiv.org/abs/2106.14189v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Higher-dimensional power diagrams for semi-discrete optimal transport",
        "authors": [
            "Philip Claude Caplan"
        ],
        "summary": "Efficient algorithms for solving optimal transport problems are important for measuring and optimizing distances between functions. In the $L^2$ semi-discrete context, this problem consists of finding a map from a continuous density function to a discrete set of points so as to minimize the transport cost, using the squared Euclidean distance as the cost function. This has important applications in image stippling, clustering, resource allocation and in generating blue noise point distributions for rendering. Recent algorithms have been developed for solving the semi-discrete problem in $2d$ and $3d$, however, algorithms in higher dimensions have yet to be demonstrated, which rely on the efficient calculation of the power diagram (Laguerre diagram) in higher dimensions. Here, we introduce an algorithm for computing power diagrams, which extends to any topological dimension. We first evaluate the performance of the algorithm in $2d-6d$. We then restrict our attention to four-dimensional settings, demonstrating that our power diagrams can be used to solve optimal quantization and semi-discrete optimal transport problems, whereby a prescribed mass of each power cell is achieved by computing an optimized power diagram.",
        "published": "2021-06-28T14:00:09Z",
        "link": "http://arxiv.org/abs/2106.14730v1",
        "categories": [
            "cs.CG",
            "cs.CE"
        ]
    },
    {
        "title": "Predicting Surface Heat Flux on Complex Systems via Conv-LSTM",
        "authors": [
            "Yinpeng Wang",
            "Nianru Wang",
            "Qiang Ren"
        ],
        "summary": "Existing algorithms with iterations as the principle for 3D inverse heat conduction problems (IHCPs) are usually time-consuming. With the recent advancements in deep learning techniques, it is possible to apply the neural network to compute IHCPs. In this paper, a new framework based on Convolutional-LSTM is introduced to predict the transient heat flux via measured temperature. The inverse heat conduction models concerned in this work have 3D complex structures with non-linear boundary conditions and thermophysical parameters. In order to reach high precision, a forward solver based on the finite element method is utilized to generate sufficient data for training. The fully trained framework can provide accurate predictions efficiently once the measured temperature and models are acquired. It is believed that the proposed framework offers a new pattern for real-time heat flux inversion.",
        "published": "2021-06-29T06:50:00Z",
        "link": "http://arxiv.org/abs/2107.02763v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Quasi-3-D Spectral Wavelet Method for a Thermal Quench Simulation",
        "authors": [
            "Jonas Bundschuh",
            "Laura A. M. D'Angelo",
            "Herbert De Gersem"
        ],
        "summary": "The finite element method is widely used in simulations of various fields. However, when considering domains whose extent differs strongly in different spatial directions a finite element simulation becomes computationally very expensive due to the large number of degrees of freedom. An example of such a domain are the cables inside of the magnets of particle accelerators. For translationally invariant domains, this work proposes a quasi-3-D method. Thereby, a 2-D finite element method with a nodal basis in the cross-section is combined with a spectral method with a wavelet basis in the longitudinal direction. Furthermore, a spectral method with a wavelet basis and an adaptive and time-dependent resolution is presented. All methods are verified. As an example the hot-spot propagation due to a quench in Rutherford cables is simulated successfully.",
        "published": "2021-06-29T10:11:48Z",
        "link": "http://arxiv.org/abs/2106.15222v2",
        "categories": [
            "cs.CE",
            "G.1.8"
        ]
    },
    {
        "title": "Convolutional Sparse Coding Fast Approximation with Application to   Seismic Reflectivity Estimation",
        "authors": [
            "Deborah Pereg",
            "Israel Cohen",
            "Anthony A. Vassiliou"
        ],
        "summary": "In sparse coding, we attempt to extract features of input vectors, assuming that the data is inherently structured as a sparse superposition of basic building blocks. Similarly, neural networks perform a given task by learning features of the training data set. Recently both data-driven and model-driven feature extracting methods have become extremely popular and have achieved remarkable results. Nevertheless, practical implementations are often too slow to be employed in real-life scenarios, especially for real-time applications. We propose a speed-up upgraded version of the classic iterative thresholding algorithm, that produces a good approximation of the convolutional sparse code within 2-5 iterations. The speed advantage is gained mostly from the observation that most solvers are slowed down by inefficient global thresholding. The main idea is to normalize each data point by the local receptive field energy, before applying a threshold. This way, the natural inclination towards strong feature expressions is suppressed, so that one can rely on a global threshold that can be easily approximated, or learned during training. The proposed algorithm can be employed with a known predetermined dictionary, or with a trained dictionary. The trained version is implemented as a neural net designed as the unfolding of the proposed solver. The performance of the proposed solution is demonstrated via the seismic inversion problem in both synthetic and real data scenarios. We also provide theoretical guarantees for a stable support recovery. Namely, we prove that under certain conditions the true support is perfectly recovered within the first iteration.",
        "published": "2021-06-29T12:19:07Z",
        "link": "http://arxiv.org/abs/2106.15296v1",
        "categories": [
            "cs.LG",
            "cs.CE",
            "cs.CV"
        ]
    },
    {
        "title": "The Performance Impact of Newton Iterations per Solver Call in   Partitioned Fluid-Structure Interaction",
        "authors": [
            "Thomas Spenke",
            "Norbert Hosters",
            "Marek Behr"
        ],
        "summary": "The cost of a partitioned fluid-structure interaction scheme is typically assessed by the number of coupling iterations required per time step, while ignoring the Newton loops within the nonlinear sub-solvers. In this work, we discuss why these single-field iterations deserve more attention when evaluating the coupling's efficiency and how to find the optimal number of Newton steps per coupling iteration.",
        "published": "2021-06-30T09:31:10Z",
        "link": "http://arxiv.org/abs/2106.15930v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Relational VAE: A Continuous Latent Variable Model for Graph Structured   Data",
        "authors": [
            "Charilaos Mylonas",
            "Imad Abdallah",
            "Eleni Chatzi"
        ],
        "summary": "Graph Networks (GNs) enable the fusion of prior knowledge and relational reasoning with flexible function approximations. In this work, a general GN-based model is proposed which takes full advantage of the relational modeling capabilities of GNs and extends these to probabilistic modeling with Variational Bayes (VB). To that end, we combine complementary pre-existing approaches on VB for graph data and propose an approach that relies on graph-structured latent and conditioning variables. It is demonstrated that Neural Processes can also be viewed through the lens of the proposed model. We show applications on the problem of structured probability density modeling for simulated and real wind farm monitoring data, as well as on the meta-learning of simulated Gaussian Process data. We release the source code, along with the simulated datasets.",
        "published": "2021-06-30T13:24:27Z",
        "link": "http://arxiv.org/abs/2106.16049v1",
        "categories": [
            "cs.CE",
            "cs.LG",
            "stat.ML"
        ]
    },
    {
        "title": "Efficient Analysis of Chemical Reaction Networks Dynamics based on   Input-Output Monotonicity",
        "authors": [
            "Lucia Nasti",
            "Roberta Gori",
            "Paolo Milazzo",
            "Federico Poloni"
        ],
        "summary": "Motivation: A Chemical Reaction Network (CRN) is a set of chemical reactions, which can be very complex and difficult to analyze. Indeed, dynamical properties of CRNs can be described by a set of non-linear differential equations that rarely can be solved in closed-form, but that can instead be used to reason on the system dynamics. In this context, one of the possible approaches is to perform numerical simulations, which may require a high computational effort. In particular, in order to investigate some dynamical properties, such as robustness or global sensitivity, many simulations have to be performed by varying the initial concentration of chemical species. Results: In order to reduce the computational effort required when many simulations are needed to assess a property, we exploit a new notion of monotonicity of the output of the system (the concentration of a target chemical species at the steady-state) with respect to the input (the initial concentration of another chemical species). To assess such monotonicity behavior, we propose a new graphical approach that allows us to state sufficient conditions for ensuring that the monotonicity property holds. Our sufficient conditions allow us to efficiently verify the monotonicity property by exploring a graph constructed on the basis of the reactions involved in the network. Once established, our monotonicity property allows us to drastically reduce the number of simulations required to assess some dynamical properties of the CRN.",
        "published": "2021-07-01T08:18:36Z",
        "link": "http://arxiv.org/abs/2107.00289v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Benchmarking (multi)wavelet-based dynamic and static non-uniform grid   solvers for flood inundation modelling",
        "authors": [
            "Mohammad Kazem Sharifian",
            "Georges Kesserwani"
        ],
        "summary": "This paper explores static non-uniform grid solvers that adapt three raster-based flood models on an optimised non-uniform grid: the second-order discontinuous Galerkin (DG2) model representing the modelled data as piecewise-planar fields, the first-order finite volume (FV1) model using piecewise-constant fields, and the local inertial (ACC) model only evolving piecewise-constant water depth fields. The optimised grid is generated by applying the multiresolution analysis (MRA) of multiwavelets (MWs) to piecewise-planar representation of raster-formatted topography data, for more sensible grid coarsening based on one user-specified parameter. Two adaptive solvers are also explored that apply the MRA of MWs and of Haar wavelets (HWs) to, respectively, scale and adapt the DG2 (MWDG2) and FV1 (HWFV1) modelled data dynamically in time. The performance of the non-uniform grid and adaptive solvers is assessed in terms of flood depth and extent, velocities, and CPU runtimes, with reference to the raster-based DG2 model predictions on their finest resolution grid. The assessments considered three large-scale flooding scenarios, involving rapid and slow-to-gradual flows. MWDG2 is found to be the most favourable choice when modelling rapid flows, where it excels in capturing small velocity variations. For slow-to-gradual flows, the adaptive solvers deliver less accurate outcomes, and their efficiency can be hampered by overhead costs of the dynamic MRA. Instead, non-uniform DG2 is recommended to capture urban flow interactions more accurately. Non-uniform ACC is 5 times faster to run than non-uniform DG2 but delivers close flooding depth and extent predictions, thus is more attractive for fluvial/pluvial flood simulation over large areas.",
        "published": "2021-07-01T11:38:40Z",
        "link": "http://arxiv.org/abs/2107.02750v1",
        "categories": [
            "cs.CE",
            "physics.flu-dyn"
        ]
    },
    {
        "title": "From Epidemic to Pandemic Modelling",
        "authors": [
            "Shannon Connolly",
            "David Gilbert",
            "Monika Heiner"
        ],
        "summary": "We present a methodology for systematically extending epidemic models to multilevel and multiscale spatio-temporal pandemic ones. Our approach builds on the use of coloured stochastic and continuous Petri nets facilitating the sound component-based extension of basic SIR models to include population stratification and also spatio-geographic information and travel connections, represented as graphs, resulting in robust stratified pandemic metapopulation models. This method is inherently easy to use, producing scalable and reusable models with a high degree of clarity and accessibility which can be read either in a deterministic or stochastic paradigm. Our method is supported by a publicly available platform PetriNuts; it enables the visual construction and editing of models; deterministic, stochastic and hybrid simulation as well as structural and behavioural analysis. All the models are available as supplementary material, ensuring reproducibility.",
        "published": "2021-07-01T13:43:52Z",
        "link": "http://arxiv.org/abs/2107.00835v1",
        "categories": [
            "q-bio.PE",
            "cs.CE"
        ]
    },
    {
        "title": "Forecasting Thermoacoustic Instabilities in Liquid Propellant Rocket   Engines Using Multimodal Bayesian Deep Learning",
        "authors": [
            "Ushnish Sengupta",
            "Günther Waxenegger-Wilfing",
            "Jan Martin",
            "Justin Hardi",
            "Matthew P. Juniper"
        ],
        "summary": "The 100 MW cryogenic liquid oxygen/hydrogen multi-injector combustor BKD operated by the DLR Institute of Space Propulsion is a research platform that allows the study of thermoacoustic instabilities under realistic conditions, representative of small upper stage rocket engines. We use data from BKD experimental campaigns in which the static chamber pressure and fuel-oxidizer ratio are varied such that the first tangential mode of the combustor is excited under some conditions. We train an autoregressive Bayesian neural network model to forecast the amplitude of the dynamic pressure time series, inputting multiple sensor measurements (injector pressure/ temperature measurements, static chamber pressure, high-frequency dynamic pressure measurements, high-frequency OH* chemiluminescence measurements) and future flow rate control signals. The Bayesian nature of our algorithms allows us to work with a dataset whose size is restricted by the expense of each experimental run, without making overconfident extrapolations. We find that the networks are able to accurately forecast the evolution of the pressure amplitude and anticipate instability events on unseen experimental runs 500 milliseconds in advance. We compare the predictive accuracy of multiple models using different combinations of sensor inputs. We find that the high-frequency dynamic pressure signal is particularly informative. We also use the technique of integrated gradients to interpret the influence of different sensor inputs on the model prediction. The negative log-likelihood of data points in the test dataset indicates that predictive uncertainties are well-characterized by our Bayesian model and simulating a sensor failure event results as expected in a dramatic increase in the epistemic component of the uncertainty.",
        "published": "2021-07-01T18:28:13Z",
        "link": "http://arxiv.org/abs/2107.06396v2",
        "categories": [
            "physics.flu-dyn",
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "On the Bike Spreading Problem",
        "authors": [
            "Elia Costa",
            "Francesco Silvestri"
        ],
        "summary": "A free-floating bike-sharing system (FFBSS) is a dockless rental system where an individual can borrow a bike and returns it anywhere, within the service area. To improve the rental service, available bikes should be distributed over the entire service area: a customer leaving from any position is then more likely to find a near bike and then to use the service. Moreover, spreading bikes among the entire service area increases urban spatial equity since the benefits of FFBSS are not a prerogative of just a few zones. For guaranteeing such distribution, the FFBSS operator can use vans to manually relocate bikes, but it incurs high economic and environmental costs. We propose a novel approach that exploits the existing bike flows generated by customers to distribute bikes. More specifically, by envisioning the problem as an Influence Maximization problem, we show that it is possible to position batches of bikes on a small number of zones, and then the daily use of FFBSS will efficiently spread these bikes on a large area. We show that detecting these zones is NP-complete, but there exists a simple and efficient $1-1/e$ approximation algorithm; our approach is then evaluated on a dataset of rides from the free-floating bike-sharing system of the city of Padova.",
        "published": "2021-07-01T22:14:31Z",
        "link": "http://arxiv.org/abs/2107.00761v2",
        "categories": [
            "cs.DS",
            "cs.CE",
            "cs.LG",
            "cs.SI",
            "math.OC"
        ]
    },
    {
        "title": "Robust multigrid techniques for augmented Lagrangian preconditioning of   incompressible Stokes equations with extreme viscosity variations",
        "authors": [
            "Yu-hsuan Shih",
            "Georg Stadler",
            "Florian Wechsung"
        ],
        "summary": "We present augmented Lagrangian Schur complement preconditioners and robust multigrid methods for incompressible Stokes problems with extreme viscosity variations. Such Stokes systems arise, for instance, upon linearization of nonlinear viscous flow problems, and they can have severely inhomogeneous and anisotropic coefficients. Using an augmented Lagrangian formulation for the incompressibility constraint makes the Schur complement easier to approximate, but results in a nearly singular (1,1)-block in the Stokes system. We present eigenvalue estimates for the quality of the Schur complement approximation. To cope with the near-singularity of the (1,1)-block, we extend a multigrid scheme with a discretization-dependent smoother and transfer operators from triangular/tetrahedral to the quadrilateral/hexahedral finite element discretizations $[\\mathbb{Q}_k]^d\\times \\mathbb{P}_{k-1}^{\\text{disc}}$, $k\\geq 2$, $d=2,3$. Using numerical examples with scalar and with anisotropic fourth-order tensor viscosity arising from linearization of a viscoplastic constitutive relation, we confirm the robustness of the multigrid scheme and the overall efficiency of the solver. We present scalability results using up to 28,672 parallel tasks for problems with up to 1.6 billion unknowns and a viscosity contrast up to ten orders of magnitude.",
        "published": "2021-07-02T04:27:20Z",
        "link": "http://arxiv.org/abs/2107.00820v2",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "65F08, 65F10, 65N55, 65Y05, 76D07"
        ]
    },
    {
        "title": "A Novel Deep Reinforcement Learning Based Stock Direction Prediction   using Knowledge Graph and Community Aware Sentiments",
        "authors": [
            "Anil Berk Altuner",
            "Zeynep Hilal Kilimci"
        ],
        "summary": "Stock market prediction has been an important topic for investors, researchers, and analysts. Because it is affected by too many factors, stock market prediction is a difficult task to handle. In this study, we propose a novel method that is based on deep reinforcement learning methodologies for the direction prediction of stocks using sentiments of community and knowledge graph. For this purpose, we firstly construct a social knowledge graph of users by analyzing relations between connections. After that, time series analysis of related stock and sentiment analysis is blended with deep reinforcement methodology. Turkish version of Bidirectional Encoder Representations from Transformers (BerTurk) is employed to analyze the sentiments of the users while deep Q-learning methodology is used for the deep reinforcement learning side of the proposed model to construct the deep Q network. In order to demonstrate the effectiveness of the proposed model, Garanti Bank (GARAN), Akbank (AKBNK), T\\\"urkiye \\.I\\c{s} Bankas{\\i} (ISCTR) stocks in Istanbul Stock Exchange are used as a case study. Experiment results show that the proposed novel model achieves remarkable results for stock market prediction task.",
        "published": "2021-07-02T09:39:41Z",
        "link": "http://arxiv.org/abs/2107.00931v1",
        "categories": [
            "cs.AI",
            "cs.CE",
            "cs.LG",
            "cs.SI"
        ]
    },
    {
        "title": "Structural biology in the clouds: The WeNMR-EOSC Ecosystem",
        "authors": [
            "Rodrigo Vargas Honorato",
            "Panagiotis I. Koukos",
            "Brian Jiménez-García",
            "Andrei Tsaregorodtsev",
            "Marco Verlato",
            "Andrea Giachetti",
            "Antonio Rosato",
            "Alexandre M. J. J. Bonvin"
        ],
        "summary": "Structural biology aims at characterizing the structural and dynamic properties of biological macromolecules at atomic details. Gaining insight into three dimensional structures of biomolecules and their interactions is critical for understanding the vast majority of cellular processes, with direct applications in health and food sciences. Since 2010, the WeNMR project (www.wenmr.eu) has implemented numerous web-based services to facilitate the use of advanced computational tools by researchers in the field, using the high throughput computing infrastructure provided by EGI. These services have been further developed in subsequent initiatives under H2020 projects and are now operating as Thematic Services in the European Open Science Cloud (EOSC) portal (www.eosc-portal.eu), sending >12 millions of jobs and using around 4000 CPU-years per year. Here we review 10 years of successful e-infrastructure solutions serving a large worldwide community of over 23,000 users to date, providing them with user-friendly, web-based solutions that run complex workflows in structural biology. The current set of active WeNMR portals are described, together with the complex backend machinery that allows distributed computing resources to be harvested efficiently.",
        "published": "2021-07-02T13:04:31Z",
        "link": "http://arxiv.org/abs/2107.01056v1",
        "categories": [
            "q-bio.BM",
            "cs.CE",
            "cs.DC"
        ]
    },
    {
        "title": "Efficient and Accurate Adaptive Resolution for Weakly-Compressible SPH",
        "authors": [
            "Abhinav Muta",
            "Prabhu Ramachandran"
        ],
        "summary": "In this paper we propose an accurate, and computationally efficient method for incorporating adaptive spatial resolution into weakly-compressible Smoothed Particle Hydrodynamics (SPH) schemes. Particles are adaptively split and merged in an accurate manner. Critically, the method ensures that the number of neighbors of each particle is optimal, leading to an efficient algorithm. A set of background particles is used to specify either geometry-based spatial resolution, where the resolution is a function of distance to a solid body, or solution-based adaptive resolution, where the resolution is a function of the computed solution. This allows us to simulate problems using particles having length variations of the order of 1:250 with much fewer particles than currently reported with other techniques. The method is designed to automatically adapt when any solid bodies move. The algorithms employed are fully parallel. We consider a suite of benchmark problems to demonstrate the accuracy of the approach. We then consider the classic problem of the flow past a circular cylinder at a range of Reynolds numbers and show that the proposed method produces accurate results with a significantly reduced number of particles. We provide an open source implementation and a fully reproducible manuscript.",
        "published": "2021-07-04T07:56:49Z",
        "link": "http://arxiv.org/abs/2107.01276v5",
        "categories": [
            "physics.flu-dyn",
            "cs.CE"
        ]
    },
    {
        "title": "ParDen: Surrogate Assisted Hyper-Parameter Optimisation for Portfolio   Selection",
        "authors": [
            "Terence van Zyl",
            "Matthew Woolway",
            "Andrew Paskaramoorthy"
        ],
        "summary": "Portfolio optimisation is a multi-objective optimisation problem (MOP), where an investor aims to optimise the conflicting criteria of maximising a portfolio's expected return whilst minimising its risk and other costs. However, selecting a portfolio is a computationally expensive problem because of the cost associated with performing multiple evaluations on test data (\"backtesting\") rather than solving the convex optimisation problem itself. In this research, we present ParDen, an algorithm for the inclusion of any discriminative or generative machine learning model as a surrogate to mitigate the computationally expensive backtest procedure. In addition, we compare the performance of alternative metaheuristic algorithms: NSGA-II, R-NSGA-II, NSGA-III, R-NSGA-III, U-NSGA-III, MO-CMA-ES, and COMO-CMA-ES. We measure performance using multi-objective performance indicators, including Generational Distance Plus, Inverted Generational Distance Plus and Hypervolume. We also consider meta-indicators, Success Rate and Average Executions to Success Rate, of the Hypervolume to provide more insight into the quality of solutions. Our results show that ParDen can reduce the number of evaluations required by almost a third while obtaining an improved Pareto front over the state-of-the-art for the problem of portfolio selection.",
        "published": "2021-07-05T16:27:18Z",
        "link": "http://arxiv.org/abs/2107.02121v1",
        "categories": [
            "cs.CE",
            "90-02",
            "J.2"
        ]
    },
    {
        "title": "OptiMic: A tool to generate optimized polycrystalline microstructures   for materials simulations",
        "authors": [
            "Prince Henry Serrao",
            "Stefan Sandfeld",
            "Aruna Prakash"
        ],
        "summary": "Polycrystal microstructures, with their distinct physical, chemical, structural and topological entities, play an important role in determining the effective properties of materials. Particularly for computational studies, the well-known Voronoi tessellation technique is regularly used for obtaining microstructures. Standard Voronoi tessellations, however, exhibit statistics that are generally far removed from those in real microstructures. Nevertheless, such tessellations can be optimized to obtain certain key features and statistics seen in real microstructures. In this work, we develop the open-source software package OptiMic that enables the generation of optimized microstructures for both finite element as well as atomistic simulations. OptiMic allows for both monodispersive grains as well as irregular grains obtained currently via Voronoi tessellations. These initial microstructures can then be optimized to reflect desired statistical features. A key feature of the tool is that it gives the user extensive control on the optimization process via customizable cost functions. The software currently performs tessellations with the Voronoi method and can be easily extended to include other methods like grain-growth, phase-field etc.",
        "published": "2021-07-06T08:15:49Z",
        "link": "http://arxiv.org/abs/2107.02460v1",
        "categories": [
            "cond-mat.mtrl-sci",
            "cs.CE",
            "82-08"
        ]
    },
    {
        "title": "Progress and opportunities in modelling environmentally assisted   cracking",
        "authors": [
            "Emilio Martínez-Pañeda"
        ],
        "summary": "Environmentally assisted cracking phenomena are widespread across the transport, defence, energy and construction sectors. However, predicting environmentally assisted fractures is a highly cross-disciplinary endeavour that requires resolving the multiple material-environment interactions taking place. In this manuscript, an overview is given of recent breakthroughs in the modelling of environmentally assisted cracking. The focus is on the opportunities created by two recent developments: phase field and multi-physics modelling. The possibilities enabled by the confluence of phase field methods and electro-chemo-mechanics modelling are discussed in the context of three environmental assisted cracking phenomena of particular engineering interest: hydrogen embrittlement, localised corrosion and corrosion fatigue. Mechanical processes such as deformation and fracture can be coupled with chemical phenomena like local reactions, ionic transport and hydrogen uptake and diffusion. Moreover, these can be combined with the prediction of an evolving interface, such as a growing pit or a crack, as dictated by a phase field variable that evolves based on thermodynamics and local kinetics. Suitable for both microstructural and continuum length scales, this new generation of simulation-based, multi-physics phase field models can open new modelling horizons and enable Virtual Testing in harmful environments.",
        "published": "2021-07-06T13:16:36Z",
        "link": "http://arxiv.org/abs/2108.00816v1",
        "categories": [
            "cond-mat.mtrl-sci",
            "cs.CE"
        ]
    },
    {
        "title": "Efficient topology optimization using compatibility projection in   micromechanical homogenization",
        "authors": [
            "Indre Jödicke",
            "Richard J. Leute",
            "Till Junge",
            "Lars Pastewka"
        ],
        "summary": "The adjoint method allows efficient calculation of the gradient with respect to the design variables of a topology optimization problem. This method is almost exclusively used in combination with traditional Finite-Element-Analysis, whereas Fourier-based solvers have recently shown large efficiency gains for homogenization problems. In this paper, we derive the discrete adjoint method for Fourier-based solvers that employ compatibility projection. We demonstrate the method on the optimization of composite materials and auxetic metamaterials, where void regions are modelled with zero stiffness.",
        "published": "2021-07-07T09:08:25Z",
        "link": "http://arxiv.org/abs/2107.04123v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Predicting Risk-adjusted Returns using an Asset Independent   Regime-switching Model",
        "authors": [
            "Nicklas Werge"
        ],
        "summary": "Financial markets tend to switch between various market regimes over time, making stationarity-based models unsustainable. We construct a regime-switching model independent of asset classes for risk-adjusted return predictions based on hidden Markov models. This framework can distinguish between market regimes in a wide range of financial markets such as the commodity, currency, stock, and fixed income market. The proposed method employs sticky features that directly affect the regime stickiness and thereby changing turnover levels. An investigation of our metric for risk-adjusted return predictions is conducted by analyzing daily financial market changes for almost twenty years. Empirical demonstrations of out-of-sample observations obtain an accurate detection of bull, bear, and high volatility periods, improving risk-adjusted returns while keeping a preferable turnover level.",
        "published": "2021-07-07T10:23:59Z",
        "link": "http://arxiv.org/abs/2107.05535v1",
        "categories": [
            "q-fin.CP",
            "cs.CE",
            "cs.LG",
            "q-fin.PM"
        ]
    },
    {
        "title": "Data-driven Modeling of the Mechanical Behavior of Anisotropic Soft   Biological Tissue",
        "authors": [
            "Vahidullah Tac",
            "Vivek D. Sree",
            "Manuel K. Rausch",
            "Adrian B. Tepole"
        ],
        "summary": "Constitutive models that describe the mechanical behavior of soft tissues have advanced greatly over the past few decades. These expert models are generalizable and require the calibration of a number of parameters to fit experimental data. However, inherent pitfalls stemming from the restriction to a specific functional form include poor fits to the data, non-uniqueness of fit, and high sensitivity to parameters. In this study we design and train fully connected neural networks as material models to replace or augment expert models. To guarantee objectivity, the neural network takes isochoric strain invariants as inputs, and outputs the value of strain energy and its derivatives with respect to the invariants. Convexity of the material model is enforced through the loss function. Direct prediction of the derivative functions -- rather than just predicting the energy -- serves two purposes: it provides flexibility during training, and it enables the calculation of the elasticity tensor through back-propagation. We showcase the ability of the neural network to learn the mechanical behavior of porcine and murine skin from biaxial test data. Crucially, we show that a multi-fidelity scheme which combines high fidelity experimental data with low fidelity analytical data yields the best performance. The neural network material model can then be interpreted as the best extension of an expert model: it learns the features that an expert has encoded in the analytical model while fitting the experimental data better. Finally, we implemented a general user material subroutine (UMAT) for the finite element software Abaqus and thereby make our advances available to the broader computational community. We expect that the methods and software generated in this work will broaden the use of data-driven constitutive models in biomedical applications.",
        "published": "2021-07-08T01:58:05Z",
        "link": "http://arxiv.org/abs/2107.05388v1",
        "categories": [
            "q-bio.QM",
            "cond-mat.soft",
            "cs.CE"
        ]
    },
    {
        "title": "Topological synthesis of fluidic pressure-actuated robust compliant   mechanisms",
        "authors": [
            "Prabhat Kumar",
            "Matthijs Langelaar"
        ],
        "summary": "This paper presents a robust density-based topology optimization approach for synthesizing pressure-actuated compliant mechanisms. To ensure functionality under manufacturing inaccuracies, the robust or three-field formulation is employed, involving dilated, intermediate and eroded realizations of the design. Darcy's law in conjunction with a conceptualized drainage term is used to model the pressure load as a function of the design vector. The consistent nodal loads are evaluated from the obtained pressure field using the standard finite element method. The objective and load sensitivities are obtained using the adjoint-variable approach. A multi-criteria objective involving both the stiffness and flexibility of the mechanism is employed in the robust formulation, and min-max optimization problems are solved to obtain pressure-actuated inverter, gripper, and contractor compliant mechanisms with different minimum feature sizes. Limitations of the linear elasticity assumptions while designing mechanisms are identified with high pressure loads. Challenges involved in designing finite deformable pressure-actuated compliant mechanisms are presented.",
        "published": "2021-07-08T05:52:41Z",
        "link": "http://arxiv.org/abs/2107.03618v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A macroscopic approach for stress driven anisotropic growth in   bioengineered soft tissues",
        "authors": [
            "L. Lamm",
            "H. Holthusen",
            "T. Brepols",
            "S. Jockenhövel",
            "S. Reese"
        ],
        "summary": "The simulation of growth processes within soft biological tissues is of utmost importance for many applications in the medical sector. Within this contribution we propose a new macroscopic approach fro modelling stress-driven volumetric growth occurring in soft tissues. Instead of using the standard approach of a-priori defining the structure of the growth tensor, we postulate the existance of a general growth potential. Such a potential describes all eligable homeostatic stress states that can ultimately be reached as a result of the growth process. Making use of well established methods from visco-plasticity, the evolution of the growth related right Cauchy-Green tensor is subsequently defined as a time dependent associative evolution law with respect to the introduced potential. This approach naturally leads to a formulation that is able to cover both, isotropic and anisotropic growth related changes in geometry. It furthermore allows the model to flexibly adapt to changing boundary and loading conditions. Besides the theoretical development, we also describe the algorithmic implementation and furthermore compare the newly derived model with a standard formulation of isotropic growth.",
        "published": "2021-07-08T09:21:33Z",
        "link": "http://arxiv.org/abs/2107.03698v1",
        "categories": [
            "cs.CE",
            "cond-mat.soft"
        ]
    },
    {
        "title": "On Mesh Deformation Techniques for Topology Optimization of   Fluid-Structure Interaction Problems",
        "authors": [
            "Mohamed Abdelhamid",
            "Aleksander Czekanski"
        ],
        "summary": "Fluid-structure interactions are a widespread phenomenon in nature. Although their numerical modeling have come a long way, the application of numerical design tools to these multiphysics problems is still lagging behind. Gradient-based optimization is the most popular approach in topology optimization currently. Hence, it's a necessity to utilize mesh deformation techniques that have continuous, smooth derivatives. In this work, we address mesh deformation techniques for structured, quadrilateral meshes. We discuss and comment on two legacy mesh deformation techniques; namely the spring analogy model and the linear elasticity model. In addition, we propose a new technique based on the Yeoh hyperelasticity model. We focus on mesh quality as a gateway to mesh admissibility. We propose layered selective stiffening such that the elements adjacent to the fluid-structure interface - where the bulk of the mesh distortion occurs - are stiffened in consecutive layers. The legacy and the new models are able to sustain large deformations without deprecating the mesh quality, and the results are enhanced with using layered selective stiffening.",
        "published": "2021-07-09T13:55:24Z",
        "link": "http://arxiv.org/abs/2107.05570v2",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "math.OC"
        ]
    },
    {
        "title": "Revisiting Non-Convexity in Topology Optimization of Compliance   Minimization Problems",
        "authors": [
            "Mohamed Abdelhamid",
            "Aleksander Czekanski"
        ],
        "summary": "Purpose: This is an attempt to better bridge the gap between the mathematical and the engineering/physical aspects of the topic. We trace the different sources of non-convexification in the context of topology optimization problems starting from domain discretization, passing through penalization for discreteness and effects of filtering methods, and end with a note on continuation methods. Design/Methodology/Approach: Starting from the global optimum of the compliance minimization problem, we employ analytical tools to investigate how intermediate density penalization affects the convexity of the problem, the potential penalization-like effects of various filtering techniques, how continuation methods can be used to approach the global optimum, and how the initial guess has some weight in determining the final optimum. Findings: The non-convexification effects of the penalization of intermediate density elements simply overshadows any other type of non-convexification introduced into the problem, mainly due to its severity and locality. Continuation methods are strongly recommended to overcome the problem of local minima, albeit its step and convergence criteria are left to the user depending on the type of application. Originality/Value: In this article, we present a comprehensive treatment of the sources of non-convexity in density-based topology optimization problems, with a focus on linear elastic compliance minimization. We put special emphasis on the potential penalization-like effects of various filtering techniques through a detailed mathematical treatment.",
        "published": "2021-07-09T14:44:48Z",
        "link": "http://arxiv.org/abs/2107.04468v2",
        "categories": [
            "math.OC",
            "cs.CE"
        ]
    },
    {
        "title": "Global sensitivity analysis of asymmetric energy harvesters",
        "authors": [
            "João Pedro Norenberg",
            "Americo Cunha Jr",
            "Samuel da Silva",
            "Paulo Sérgio Varoto"
        ],
        "summary": "Parametric variability is inevitable in actual energy harvesters. It can significantly affect crucial aspects of the system performance, especially in harvesting systems that present geometric parameters, material properties, or excitation conditions that are susceptible to small perturbations. This work aims to develop an investigation to identify the most critical parameters in the dynamic behavior of asymmetric bistable energy harvesters with nonlinear piezoelectric coupling, considering the variability of their physical and excitation properties. For this purpose, a global sensitivity analysis based on orthogonal variance decomposition, employing Sobol indices, is performed to quantify the effect of the harvester parameters on the variance of the recovered power. This technique quantifies the variance concerning each parameter individually and collectively regarding the total variation of the model. The results indicate that the frequency and amplitude of excitation, asymmetric terms and electrical proprieties of the piezoelectric coupling are the most critical parameters that affect the mean power harvested. It is also shown that the order of importance of the parameters can change according to the stability of the harvester's dynamic response. In this way, a better understanding of the system under analysis is obtained since the study allows the identification of vital parameters that rule the change of dynamic behavior and therefore constitutes a powerful tool in the robust design, optimization, and response prediction of nonlinear harvesters.",
        "published": "2021-07-09T19:45:33Z",
        "link": "http://arxiv.org/abs/2107.04647v2",
        "categories": [
            "eess.SY",
            "cs.CE",
            "cs.SY",
            "math.DS",
            "physics.class-ph",
            "stat.AP",
            "37N15",
            "I.6.3"
        ]
    },
    {
        "title": "Eighty Years of the Finite Element Method: Birth, Evolution, and Future",
        "authors": [
            "Wing Kam Liu",
            "Shaofan Li",
            "Harold Park"
        ],
        "summary": "This year marks the eightieth anniversary of the invention of the finite element method (FEM). FEM has become the computational workhorse for engineering design analysis and scientific modeling of a wide range of physical processes, including material and structural mechanics, fluid flow and heat conduction, various biological processes for medical diagnosis and surgery planning, electromagnetics and semi-conductor circuit and chip design and analysis, additive manufacturing, i.e. virtually every conceivable problem that can be described by partial differential equations (PDEs). FEM has fundamentally revolutionized the way we do scientific modeling and engineering design, ranging from automobiles, aircraft, marine structures, bridges, highways, and high-rise buildings. Associated with the development of finite element methods has been the concurrent development of an engineering science discipline called computational mechanics, or computational science and engineering.   In this paper, we present a historical perspective on the developments of finite element methods mainly focusing on its applications and related developments in solid and structural mechanics, with limited discussions to other fields in which it has made significant impact, such as fluid mechanics, heat transfer, and fluid-structure interaction. To have a complete storyline, we divide the development of the finite element method into four time periods: I. (1941-1965) Early years of FEM; II. (1966-1991) Golden age of FEM; III. (1992-2017) Large scale, industrial applications of FEM and development of material modeling, and IV (2018-) the state-of-the-art FEM technology for the current and future eras of FEM research. Note that this paper may not strictly follow the chronological order of FEM developments, because often time these developments were interwoven across different time periods.",
        "published": "2021-07-11T04:03:05Z",
        "link": "http://arxiv.org/abs/2107.04960v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA"
        ]
    },
    {
        "title": "Smoothed Bernstein Online Aggregation for Day-Ahead Electricity Demand   Forecasting",
        "authors": [
            "Florian Ziel"
        ],
        "summary": "We present a winning method of the IEEE DataPort Competition on Day-Ahead Electricity Demand Forecasting: Post-COVID Paradigm. The day-ahead load forecasting approach is based on online forecast combination of multiple point prediction models. It contains four steps: i) data cleaning and preprocessing, ii) a holiday adjustment procedure, iii) training of individual forecasting models, iv) forecast combination by smoothed Bernstein Online Aggregation (BOA). The approach is flexible and can quickly adopt to new energy system situations as they occurred during and after COVID-19 shutdowns. The pool of individual prediction models ranges from rather simple time series models to sophisticated models like generalized additive models (GAMs) and high-dimensional linear models estimated by lasso. They incorporate autoregressive, calendar and weather effects efficiently. All steps contain novel concepts that contribute to the excellent forecasting performance of the proposed method. This holds particularly for the holiday adjustment procedure and the fully adaptive smoothed BOA approach.",
        "published": "2021-07-13T17:51:21Z",
        "link": "http://arxiv.org/abs/2107.06268v1",
        "categories": [
            "cs.LG",
            "cs.CE",
            "cs.SY",
            "eess.SY",
            "stat.AP",
            "stat.ML",
            "62M10, 62J07, 62P30, 62P12, 37M10",
            "G.3; I.5"
        ]
    },
    {
        "title": "Scalable Biophysical Simulations of the Neuromuscular System",
        "authors": [
            "Benjamin Maier"
        ],
        "summary": "The human neuromuscular system consisting of skeletal muscles and neural circuits is a complex system that is not yet fully understood. Surface electromyography (EMG) can be used to study muscle behavior from the outside. Computer simulations with detailed biophysical models provide a non-invasive tool to interpret EMG signals and gain new insights into the system. The numerical solution of such multi-scale models imposes high computational work loads, which restricts their application to short simulation time spans or coarse resolutions. We tackled this challenge by providing scalable software employing instruction-level and task-level parallelism, suitable numerical methods and efficient data handling. We implemented a comprehensive, state-of-the-art, multi-scale multi-physics model framework that can simulate surface EMG signals and muscle contraction as a result of neuromuscular stimulation.   This work describes the model framework and its numerical discretization, develops new algorithms for mesh generation and parallelization, covers the use and implementation of our software OpenDiHu, and evaluates its computational performance in numerous use cases. We obtain a speedup of several hundred compared to a baseline solver from the literature and demonstrate, that our distributed-memory parallelization and the use of High Performance Computing resources enables us to simulate muscular surface EMG of the biceps brachii muscle with realistic muscle fiber counts of several hundred thousands. We find that certain model effects are only visible with such high resolution. In conclusion, our software contributes to more realistic simulations of the neuromuscular system and provides a tool for applied researchers to complement in vivo experiments with in-silico studies. It can serve as a building block to set up comprehensive models for more organs in the musculoskeletal system.",
        "published": "2021-07-13T19:12:46Z",
        "link": "http://arxiv.org/abs/2107.07104v1",
        "categories": [
            "cs.DC",
            "cs.CE",
            "cs.NA",
            "math.NA",
            "physics.bio-ph",
            "q-bio.QM",
            "F.2.1; J.2; J.3"
        ]
    },
    {
        "title": "The nonlinear dynamics of a bistable energy harvesting system with   colored noise disturbances",
        "authors": [
            "Vinicius Gonçalves Lopes",
            "João Victor L. L. Peterson",
            "Americo Cunha Jr"
        ],
        "summary": "This paper deals with the nonlinear stochastic dynamics of a piezoelectric energy harvesting system subjected to a harmonic external excitation disturbed by Gaussian colored noise. A parametric analysis is conducted, where the effects of the standard deviation and the correlation time of colored noise on the system response are investigated. The numerical results suggest a strong influence of noise on the system response for higher values of correlation time and standard deviation, and a low (noise level independent) influence for low values of correlation time.",
        "published": "2021-07-14T05:00:26Z",
        "link": "http://arxiv.org/abs/2107.14045v1",
        "categories": [
            "cond-mat.stat-mech",
            "cs.CE",
            "physics.class-ph",
            "stat.AP",
            "37N15",
            "I.6.6"
        ]
    },
    {
        "title": "Behavior Analysis and Design of Concrete-Filled Steel Circular-Tube   Short Columns Subjected to Axial Compression",
        "authors": [
            "Duc-Duy Pham",
            "Phu-Cuong Nguyen"
        ],
        "summary": "In this paper, a new finite element (FE) model using ABAQUS software was developed to investigate the compressive behavior of Concrete-Filled Steel Circular-Tube (CFSCT) columns. Experimental studies indicated that the confinement offered by the circular steel tube in a CFSCT column increased both the strength and ductility of the filled concrete. Base on the database of 663 test results CFSCT columns under axial compression are collected from the available literature, a formula to determine the lateral confining pressures on concrete. Concrete-Damaged Plasticity Model (CDPM) and parameters are available in ABAQUS are used in the analysis. From results analysis, a proposed formula for predicting ultimate load by determining intensification and diminution for concrete and steel. The proposed formula is then compared with the FE model, the previous study, and the design code current in strength prediction of CFSCT columns under compression. The comparative result shows that the FE model, the proposed formula is more stable and accurate than the previous study and current standards when using material normal or high strength.",
        "published": "2021-07-14T05:13:30Z",
        "link": "http://arxiv.org/abs/2107.06488v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "eess.SP"
        ]
    },
    {
        "title": "Quantification of parametric uncertainties induced by irregular soil   loading in orchard tower sprayer nonlinear dynamics",
        "authors": [
            "Americo Cunha Jr",
            "Jorge Luis Palacios Felix",
            "José Manoel Balthazar"
        ],
        "summary": "This paper deals with the nonlinear stochastic dynamics of an orchard tower sprayer subjected to random excitations due to soil irregularities. A consistent stochastic model of uncertainties is constructed to describe random loadings and to predict variabilities in mechanical system response. The dynamics is addressed in time and frequency domains. Monte Carlo method is employed to compute the propagation of uncertainties through the stochastic model. Numerical simulations reveals a very rich dynamics, which is able to produce chaos. This numerical study also indicates that lateral vibrations follow a direct energy cascade law. A probabilistic analysis reveals the possibility of large lateral vibrations during the equipment operation.",
        "published": "2021-07-14T05:26:38Z",
        "link": "http://arxiv.org/abs/2107.12142v1",
        "categories": [
            "cs.CE",
            "37N15",
            "I.6.6"
        ]
    },
    {
        "title": "Financial Network Games",
        "authors": [
            "Panagiotis Kanellopoulos",
            "Maria Kyropoulou",
            "Hao Zhou"
        ],
        "summary": "We study financial systems from a game-theoretic standpoint. A financial system is represented by a network, where nodes correspond to firms, and directed labeled edges correspond to debt contracts between them. The existence of cycles in the network indicates that a payment of a firm to one of its lenders might result to some incoming payment. So, if a firm cannot fully repay its debt, then the exact (partial) payments it makes to each of its creditors can affect the cash inflow back to itself. We naturally assume that the firms are interested in their financial well-being (utility) which is aligned with the amount of incoming payments they receive from the network. This defines a game among the firms, that can be seen as utility-maximizing agents who can strategize over their payments.   We are the first to study financial network games that arise under a natural set of payment strategies called priority-proportional payments. We investigate the existence and (in)efficiency of equilibrium strategies, under different assumptions on how the firms' utility is defined, on the types of debt contracts allowed between the firms, and on the presence of other financial features that commonly arise in practice. Surprisingly, even if all firms' strategies are fixed, the existence of a unique payment profile is not guaranteed. So, we also investigate the existence and computation of valid payment profiles for fixed payment strategies.",
        "published": "2021-07-14T11:50:54Z",
        "link": "http://arxiv.org/abs/2107.06623v1",
        "categories": [
            "cs.GT",
            "cs.CE",
            "q-fin.RM"
        ]
    },
    {
        "title": "Higgs Boson Classification: Brain-inspired BCPNN Learning with   StreamBrain",
        "authors": [
            "Martin Svedin",
            "Artur Podobas",
            "Steven W. D. Chien",
            "Stefano Markidis"
        ],
        "summary": "One of the most promising approaches for data analysis and exploration of large data sets is Machine Learning techniques that are inspired by brain models. Such methods use alternative learning rules potentially more efficiently than established learning rules. In this work, we focus on the potential of brain-inspired ML for exploiting High-Performance Computing (HPC) resources to solve ML problems: we discuss the BCPNN and an HPC implementation, called StreamBrain, its computational cost, suitability to HPC systems. As an example, we use StreamBrain to analyze the Higgs Boson dataset from High Energy Physics and discriminate between background and signal classes in collisions of high-energy particle colliders. Overall, we reach up to 69.15% accuracy and 76.4% Area Under the Curve (AUC) performance.",
        "published": "2021-07-14T13:08:19Z",
        "link": "http://arxiv.org/abs/2107.06676v2",
        "categories": [
            "cs.LG",
            "cs.CE",
            "cs.DC",
            "cs.NE"
        ]
    },
    {
        "title": "Numerical investigation of reversed gas feed configurations for Hall   thrusters",
        "authors": [
            "Stefano Boccelli",
            "Thierry E. Magin",
            "Aldo Frezzotti"
        ],
        "summary": "A reversed gas feed configuration for Hall thrusters is proposed and studied numerically. As an alternative to standard direct injection, we investigate the effect of injecting the propellant near the channel exit and directing it backwards, towards the anode. The resulting neutral density and average velocity fields are studied with the Direct Simulation Monte Carlo method for both cold and warm anode conditions. The residence time of neutral particles inside the channel and in the ionization region is computed using a test-particle Monte Carlo method. The computations indicate that the reversed injection allows for increasing the mass utilization efficiency of a standard feed configuration from 2-5% to a maximum of 20-30% depending on the initial efficiency.",
        "published": "2021-07-14T13:50:01Z",
        "link": "http://arxiv.org/abs/2107.09446v1",
        "categories": [
            "physics.plasm-ph",
            "cs.CE",
            "physics.flu-dyn"
        ]
    },
    {
        "title": "Non-intrusive polynomial chaos expansion for topology optimization using   polygonal meshes",
        "authors": [
            "Nilton Cuellar",
            "Anderson Pereira",
            "Ivan F. M. Menezes",
            "Americo Cunha Jr"
        ],
        "summary": "This paper deals with the applications of stochastic spectral methods for structural topology optimization in the presence of uncertainties. A non-intrusive polynomial chaos expansion is integrated into a topology optimization algorithm to calculate low-order statistical moments of the mechanical-mathematical model response. This procedure, known as robust topology optimization, can optimize the mean of the compliance while simultaneously minimizing its standard deviation. In order to address possible variabilities in the loads applied to the mechanical system of interest, magnitude and direction of the external forces are assumed to be uncertain. In this probabilistic framework, forces are described as a random field or a set of random variables. Representation of the random objects and propagation of load uncertainties through the model are efficiently done through Karhunen-Lo\\`{e}ve and polynomial chaos expansions. We take advantage of using polygonal elements, which have been shown to be effective in suppressing checkerboard patterns and reducing mesh dependency in the solution of topology optimization problems. Accuracy and applicability of the proposed methodology are demonstrated by means of several topology optimization examples. The obtained results, which are in excellent agreement with reference solutions computed via Monte Carlo method, show that load uncertainties play an important role in optimal design of structural systems, so that they must be taken into account to ensure a reliable optimization process.",
        "published": "2021-07-14T15:56:27Z",
        "link": "http://arxiv.org/abs/2108.01616v1",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA",
            "math.OC",
            "stat.CO",
            "stat.ME",
            "90-08",
            "I.6.5"
        ]
    },
    {
        "title": "Optimal sports betting strategies in practice: an experimental review",
        "authors": [
            "Matej Uhrín",
            "Gustav Šourek",
            "Ondřej Hubáček",
            "Filip Železný"
        ],
        "summary": "We investigate the most popular approaches to the problem of sports betting investment based on modern portfolio theory and the Kelly criterion. We define the problem setting, the formal investment strategies, and review their common modifications used in practice. The underlying purpose of the reviewed modifications is to mitigate the additional risk stemming from the unrealistic mathematical assumptions of the formal strategies. We test the resulting methods using a unified evaluation protocol for three sports: horse racing, basketball and soccer. The results show the practical necessity of the additional risk-control methods and demonstrate their individual benefits. Particularly, we show that an adaptive variant of the popular ``fractional Kelly'' method is a very suitable choice across a wide range of settings.",
        "published": "2021-07-15T15:09:47Z",
        "link": "http://arxiv.org/abs/2107.08827v1",
        "categories": [
            "q-fin.PM",
            "cs.CE",
            "q-fin.RM"
        ]
    },
    {
        "title": "Predicting Daily Trading Volume via Various Hidden States",
        "authors": [
            "Shaojun Ma",
            "Pengcheng Li"
        ],
        "summary": "Predicting intraday trading volume plays an important role in trading alpha research. Existing methods such as rolling means(RM) and a two-states based Kalman Filtering method have been presented in this topic. We extend two states into various states in Kalman Filter framework to improve the accuracy of prediction. Specifically, for different stocks we utilize cross validation and determine best states number by minimizing mean squared error of the trading volume. We demonstrate the effectivity of our method through a series of comparison experiments and numerical analysis.",
        "published": "2021-07-16T02:53:33Z",
        "link": "http://arxiv.org/abs/2107.07678v1",
        "categories": [
            "q-fin.ST",
            "cs.CE"
        ]
    },
    {
        "title": "Optimizing Build Orientation for Support Removal using Multi-Axis   Machining",
        "authors": [
            "Amir M. Mirzendehdel",
            "Morad Behandish",
            "Saigopal Nelaturi"
        ],
        "summary": "Parts fabricated by additive manufacturing (AM) are often fabricated first as a near-net shape, a combination of intended nominal geometry and sacrificial support structures, which need to be removed in a subsequent post-processing stage using subtractive manufacturing (SM). In this paper, we present a framework for optimizing the build orientation with respect to removability of support structures. In particular, given a general multi-axis machining setup and sampled build orientations, we define a Pareto-optimality criterion based on the total support volume and the \"secluded\" support volume defined as the support volume that is not accessible by a given set of machining tools. Since total support volume mainly depends on the build orientation and the secluded volume is dictated by the machining setup, in many cases the two objectives are competing and their trade-off needs to be taken into account. The accessibility analysis relies on the inaccessibility measure field (IMF), which is a continuous field in the Euclidean space that quantifies the inaccessibility of each point given a collection of tools and fixturing devices. The value of IMF at each point indicates the minimum possible volumetric collision between objects in relative motion including the part, fixtures, and the tools, over all possible tool orientations and sharp points on the tool. We also propose an automated support removal planning algorithm based on IMF, where a sequence of actions are provided in terms of the fixturing devices, cutting tools, and tool orientation at each step. In our approach, each step is chosen based on the maximal removable volume to iteratively remove accessible supports. The effectiveness of the proposed approach is demonstrated through benchmark examples in 2D and realistic examples in 3D.",
        "published": "2021-07-16T03:24:51Z",
        "link": "http://arxiv.org/abs/2107.07686v1",
        "categories": [
            "cs.CE",
            "cs.CG"
        ]
    },
    {
        "title": "Topology optimization using the unsmooth variational topology   optimization (UNVARTOP) method. An educational implementation in Matlab",
        "authors": [
            "Daniel Yago",
            "Juan Cante",
            "Oriol Lloberas-Valls",
            "Javier Oliver"
        ],
        "summary": "This paper presents an efficient and comprehensive MATLAB code to solve two-dimensional structural topology optimization problems, including minimum mean compliance, compliant mechanism synthesis and multi-load compliance problems. The Unsmooth Variational Topology Optimization (UNVARTOP) method, developed by the authors in a previous work, is used in the topology optimization code, based on the finite element method (FEM), to compute the sensitivity and update the topology. The paper also includes instructions to improve the bisection algorithm, modify the computation of the Lagrangian multiplier by using an Augmented Lagrangian to impose the constraint, implement heat conduction problems and extend the code to three-dimensional topology optimization problems. The code, intended for students and newcomers in topology optimization, is included as an appendix (Appendix A) and it can be downloaded from https://github.com/DanielYago together with supplementary material.",
        "published": "2021-07-16T08:39:47Z",
        "link": "http://arxiv.org/abs/2107.07763v1",
        "categories": [
            "cs.CE",
            "cs.MS"
        ]
    },
    {
        "title": "Architecture of Automated Crypto-Finance Agent",
        "authors": [
            "Ali Raheman",
            "Anton Kolonin",
            "Ben Goertzel",
            "Gergely Hegykozi",
            "Ikram Ansari"
        ],
        "summary": "We present the cognitive architecture of an autonomous agent for active portfolio management in decentralized finance, involving activities such as asset selection, portfolio balancing, liquidity provision, and trading. Partial implementation of the architecture is provided and supplied with preliminary results and conclusions.",
        "published": "2021-07-16T08:57:50Z",
        "link": "http://arxiv.org/abs/2107.07769v4",
        "categories": [
            "cs.AI",
            "cs.CE",
            "cs.MA"
        ]
    },
    {
        "title": "Physics-informed graph neural Galerkin networks: A unified framework for   solving PDE-governed forward and inverse problems",
        "authors": [
            "Han Gao",
            "Matthew J. Zahr",
            "Jian-Xun Wang"
        ],
        "summary": "Despite the great promise of the physics-informed neural networks (PINNs) in solving forward and inverse problems, several technical challenges are present as roadblocks for more complex and realistic applications. First, most existing PINNs are based on point-wise formulation with fully-connected networks to learn continuous functions, which suffer from poor scalability and hard boundary enforcement. Second, the infinite search space over-complicates the non-convex optimization for network training. Third, although the convolutional neural network (CNN)-based discrete learning can significantly improve training efficiency, CNNs struggle to handle irregular geometries with unstructured meshes. To properly address these challenges, we present a novel discrete PINN framework based on graph convolutional network (GCN) and variational structure of PDE to solve forward and inverse partial differential equations (PDEs) in a unified manner. The use of a piecewise polynomial basis can reduce the dimension of search space and facilitate training and convergence. Without the need of tuning penalty parameters in classic PINNs, the proposed method can strictly impose boundary conditions and assimilate sparse data in both forward and inverse settings. The flexibility of GCNs is leveraged for irregular geometries with unstructured meshes. The effectiveness and merit of the proposed method are demonstrated over a variety of forward and inverse computational mechanics problems governed by both linear and nonlinear PDEs.",
        "published": "2021-07-16T20:23:52Z",
        "link": "http://arxiv.org/abs/2107.12146v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Refactoring the MPS/University of Chicago Radiative MHD(MURaM) Model for   GPU/CPU Performance Portability Using OpenACC Directives",
        "authors": [
            "Eric Wright",
            "Damien Przybylski",
            "Matthias Rempel",
            "Cena Miller",
            "Supreeth Suresh",
            "Shiquan Su",
            "Richard Loft",
            "Sunita Chandrasekaran"
        ],
        "summary": "The MURaM (Max Planck University of Chicago Radiative MHD) code is a solar atmosphere radiative MHD model that has been broadly applied to solar phenomena ranging from quiet to active sun, including eruptive events such as flares and coronal mass ejections. The treatment of physics is sufficiently realistic to allow for the synthesis of emission from visible light to extreme UV and X-rays, which is critical for a detailed comparison with available and future multi-wavelength observations. This component relies critically on the radiation transport solver (RTS) of MURaM; the most computationally intensive component of the code. The benefits of accelerating RTS are multiple fold: A faster RTS allows for the regular use of the more expensive multi-band radiation transport needed for comparison with observations, and this will pave the way for the acceleration of ongoing improvements in RTS that are critical for simulations of the solar chromosphere. We present challenges and strategies to accelerate a multi-physics, multi-band MURaM using a directive-based programming model, OpenACC in order to maintain a single source code across CPUs and GPUs. Results for a $288^3$ test problem show that MURaM with the optimized RTS routine achieves 1.73x speedup using a single NVIDIA V100 GPU over a fully subscribed 40-core Intel Skylake CPU node and with respect to the number of simulation points (in millions) per second, a single NVIDIA V100 GPU is equivalent to 69 Skylake cores. We also measure parallel performance on up to 96 GPUs and present weak and strong scaling results.",
        "published": "2021-07-16T23:35:14Z",
        "link": "http://arxiv.org/abs/2107.08145v1",
        "categories": [
            "physics.space-ph",
            "cs.CE",
            "cs.MS"
        ]
    },
    {
        "title": "A new Method for the in vivo identification of material properties of   the human eye. Feasibility analysis based on synthetic data",
        "authors": [
            "Stefan Muench",
            "Mike Roellig",
            "Daniel Balzani"
        ],
        "summary": "This paper proposes a new method for in vivo and almost real-time identification of biomechanical properties of the human cornea based on non-contact tonometer data. Further goal is to demonstrate the method's functionality based on synthetic data serving as reference. For this purpose, a finite element model of the human eye is constructed to synthetically generate displacement full-fields from different datasets with keratoconus-like degradations. Then, a new approach based on the equilibrium gap method (EGM) combined with a mechanical morphing approach is proposed and used to identify the material parameters from virtual test data sets. In a further step, random absolute noise is added to the virtual test data to investigate the sensitivity of the new approach to noise. As a result, the proposed method shows a relevant accuracy in identifying material parameters based on displacement full fields. At the same time, the method turns out to work almost in real-time (order of a few minutes on a regular work station) and is thus much faster than inverse problems solved by typical forward approaches. On the other hand, the method shows a noticeable sensitivity to rather small noise amplitudes. However, analysis show that the accuracy is sufficient for the identification of diseased tissue properties.",
        "published": "2021-07-17T09:23:37Z",
        "link": "http://arxiv.org/abs/2107.08208v1",
        "categories": [
            "cs.CE",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Compressed Monte Carlo with application in particle filtering",
        "authors": [
            "Luca Martino",
            "Víctor Elvira"
        ],
        "summary": "Bayesian models have become very popular over the last years in several fields such as signal processing, statistics, and machine learning. Bayesian inference requires the approximation of complicated integrals involving posterior distributions. For this purpose, Monte Carlo (MC) methods, such as Markov Chain Monte Carlo and importance sampling algorithms, are often employed. In this work, we introduce the theory and practice of a Compressed MC (C-MC) scheme to compress the statistical information contained in a set of random samples. In its basic version, C-MC is strictly related to the stratification technique, a well-known method used for variance reduction purposes. Deterministic C-MC schemes are also presented, which provide very good performance. The compression problem is strictly related to the moment matching approach applied in different filtering techniques, usually called as Gaussian quadrature rules or sigma-point methods. C-MC can be employed in a distributed Bayesian inference framework when cheap and fast communications with a central processor are required. Furthermore, C-MC is useful within particle filtering and adaptive IS algorithms, as shown by three novel schemes introduced in this work. Six numerical results confirm the benefits of the introduced schemes, outperforming the corresponding benchmark methods. A related code is also provided.",
        "published": "2021-07-18T14:32:04Z",
        "link": "http://arxiv.org/abs/2107.08459v1",
        "categories": [
            "stat.CO",
            "cs.CE",
            "stat.ML"
        ]
    },
    {
        "title": "Compressed particle methods for expensive models with application in   Astronomy and Remote Sensing",
        "authors": [
            "Luca Martino",
            "Víctor Elvira",
            "Javier López-Santiago",
            "Gustau Camps-Valls"
        ],
        "summary": "In many inference problems, the evaluation of complex and costly models is often required. In this context, Bayesian methods have become very popular in several fields over the last years, in order to obtain parameter inversion, model selection or uncertainty quantification. Bayesian inference requires the approximation of complicated integrals involving (often costly) posterior distributions. Generally, this approximation is obtained by means of Monte Carlo (MC) methods. In order to reduce the computational cost of the corresponding technique, surrogate models (also called emulators) are often employed. Another alternative approach is the so-called Approximate Bayesian Computation (ABC) scheme. ABC does not require the evaluation of the costly model but the ability to simulate artificial data according to that model. Moreover, in ABC, the choice of a suitable distance between real and artificial data is also required. In this work, we introduce a novel approach where the expensive model is evaluated only in some well-chosen samples. The selection of these nodes is based on the so-called compressed Monte Carlo (CMC) scheme. We provide theoretical results supporting the novel algorithms and give empirical evidence of the performance of the proposed method in several numerical experiments. Two of them are real-world applications in astronomy and satellite remote sensing.",
        "published": "2021-07-18T14:45:23Z",
        "link": "http://arxiv.org/abs/2107.08465v1",
        "categories": [
            "cs.CE",
            "stat.CO",
            "stat.ML"
        ]
    },
    {
        "title": "Structural Design Recommendations in the Early Design Phase using   Machine Learning",
        "authors": [
            "Spyridon Ampanavos",
            "Mehdi Nourbakhsh",
            "Chin-Yi Cheng"
        ],
        "summary": "Structural engineering knowledge can be of significant importance to the architectural design team during the early design phase. However, architects and engineers do not typically work together during the conceptual phase; in fact, structural engineers are often called late into the process. As a result, updates in the design are more difficult and time-consuming to complete. At the same time, there is a lost opportunity for better design exploration guided by structural feedback. In general, the earlier in the design process the iteration happens, the greater the benefits in cost efficiency and informed de-sign exploration, which can lead to higher-quality creative results. In order to facilitate an informed exploration in the early design stage, we suggest the automation of fundamental structural engineering tasks and introduce ApproxiFramer, a Machine Learning-based system for the automatic generation of structural layouts from building plan sketches in real-time. The system aims to assist architects by presenting them with feasible structural solutions during the conceptual phase so that they proceed with their design with adequate knowledge of its structural implications. In this paper, we describe the system and evaluate the performance of a proof-of-concept implementation in the domain of orthogonal, metal, rigid structures. We trained a Convolutional Neural Net to iteratively generate structural design solutions for sketch-level building plans using a synthetic dataset and achieved an average error of 2.2% in the predicted positions of the columns.",
        "published": "2021-07-19T01:02:14Z",
        "link": "http://arxiv.org/abs/2107.08567v1",
        "categories": [
            "cs.LG",
            "cs.CE"
        ]
    },
    {
        "title": "On a Class of Polar Log-Aesthetic Curves",
        "authors": [
            "Victor Parque"
        ],
        "summary": "Curves are essential concepts that enable compounded aesthetic curves, e.g., to assemble complex silhouettes, match a specific curvature profile in industrial design, and construct smooth, comfortable, and safe trajectories in vehicle-robot navigation systems. New mechanisms able to encode, generate, evaluate, and deform aesthetic curves are expected to improve the throughput and the quality of industrial design. In recent years, the study of (log) aesthetic curves have attracted the community's attention due to its ubiquity in natural phenomena such as bird eggs, butterfly wings, falcon flights, and manufactured products such as Japanese swords and automobiles.   A (log) aesthetic curve renders a logarithmic curvature graph approximated by a straight line, and polar aesthetic curves enable to mode user-defined dynamics of the polar tangential angle in the polar coordinate system. As such, the curvature profile often becomes a by-product of the tangential angle.   In this paper, we extend the concept of polar aesthetic curves and establish the analytical formulations to construct aesthetic curves with user-defined criteria. In particular, we propose the closed-form analytic characterizations of polar log-aesthetic curves meeting user-defined criteria of curvature profiles and dynamics of polar tangential angles. We present numerical examples portraying the feasibility of rendering the logarithmic curvature graphs represented by a straight line. Our approach enables the seamless characterization of aesthetic curves in the polar coordinate system, which can model aesthetic shapes with desirable aesthetic curvature profiles.",
        "published": "2021-07-19T06:54:15Z",
        "link": "http://arxiv.org/abs/2107.09489v1",
        "categories": [
            "cs.CG",
            "cs.CE",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "AI in Finance: Challenges, Techniques and Opportunities",
        "authors": [
            "Longbing Cao"
        ],
        "summary": "AI in finance broadly refers to the applications of AI techniques in financial businesses. This area has been lasting for decades with both classic and modern AI techniques applied to increasingly broader areas of finance, economy and society. In contrast to either discussing the problems, aspects and opportunities of finance that have benefited from specific AI techniques and in particular some new-generation AI and data science (AIDS) areas or reviewing the progress of applying specific techniques to resolving certain financial problems, this review offers a comprehensive and dense roadmap of the overwhelming challenges, techniques and opportunities of AI research in finance over the past decades. The landscapes and challenges of financial businesses and data are firstly outlined, followed by a comprehensive categorization and a dense overview of the decades of AI research in finance. We then structure and illustrate the data-driven analytics and learning of financial businesses and data. The comparison, criticism and discussion of classic vs. modern AI techniques for finance are followed. Lastly, open issues and opportunities address future AI-empowered finance and finance-motivated AI research.",
        "published": "2021-07-20T01:39:10Z",
        "link": "http://arxiv.org/abs/2107.09051v1",
        "categories": [
            "q-fin.CP",
            "cs.AI",
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "Similarity metrics for Different Market Scenarios in Abides",
        "authors": [
            "Diego Pino",
            "Javier García",
            "Fernando Fernández",
            "Svitlana S Vyetrenko"
        ],
        "summary": "Markov Decision Processes (MDPs) are an effective way to formally describe many Machine Learning problems. In fact, recently MDPs have also emerged as a powerful framework to model financial trading tasks. For example, financial MDPs can model different market scenarios. However, the learning of a (near-)optimal policy for each of these financial MDPs can be a very time-consuming process, especially when nothing is known about the policy to begin with. An alternative approach is to find a similar financial MDP for which we have already learned its policy, and then reuse such policy in the learning of a new policy for a new financial MDP. Such a knowledge transfer between market scenarios raises several issues. On the one hand, how to measure the similarity between financial MDPs. On the other hand, how to use this similarity measurement to effectively transfer the knowledge between financial MDPs. This paper addresses both of these issues. Regarding the first one, this paper analyzes the use of three similarity metrics based on conceptual, structural and performance aspects of the financial MDPs. Regarding the second one, this paper uses Probabilistic Policy Reuse to balance the exploitation/exploration in the learning of a new financial MDP according to the similarity of the previous financial MDPs whose knowledge is reused.",
        "published": "2021-07-20T09:18:06Z",
        "link": "http://arxiv.org/abs/2107.09352v1",
        "categories": [
            "cs.CE",
            "cs.AI"
        ]
    },
    {
        "title": "Towards Lower-Dose PET using Physics-Based Uncertainty-Aware Multimodal   Learning with Robustness to Out-of-Distribution Data",
        "authors": [
            "Viswanath P. Sudarshan",
            "Uddeshya Upadhyay",
            "Gary F. Egan",
            "Zhaolin Chen",
            "Suyash P. Awate"
        ],
        "summary": "Radiation exposure in positron emission tomography (PET) imaging limits its usage in the studies of radiation-sensitive populations, e.g., pregnant women, children, and adults that require longitudinal imaging. Reducing the PET radiotracer dose or acquisition time reduces photon counts, which can deteriorate image quality. Recent deep-neural-network (DNN) based methods for image-to-image translation enable the mapping of low-quality PET images (acquired using substantially reduced dose), coupled with the associated magnetic resonance imaging (MRI) images, to high-quality PET images. However, such DNN methods focus on applications involving test data that match the statistical characteristics of the training data very closely and give little attention to evaluating the performance of these DNNs on new out-of-distribution (OOD) acquisitions. We propose a novel DNN formulation that models the (i) underlying sinogram-based physics of the PET imaging system and (ii) the uncertainty in the DNN output through the per-voxel heteroscedasticity of the residuals between the predicted and the high-quality reference images. Our sinogram-based uncertainty-aware DNN framework, namely, suDNN, estimates a standard-dose PET image using multimodal input in the form of (i) a low-dose/low-count PET image and (ii) the corresponding multi-contrast MRI images, leading to improved robustness of suDNN to OOD acquisitions. Results on in vivo simultaneous PET-MRI, and various forms of OOD data in PET-MRI, show the benefits of suDNN over the current state of the art, quantitatively and qualitatively.",
        "published": "2021-07-21T06:18:10Z",
        "link": "http://arxiv.org/abs/2107.09892v1",
        "categories": [
            "eess.IV",
            "cs.CE",
            "cs.CV",
            "cs.LG"
        ]
    },
    {
        "title": "Terahertz Meets Untrusted UAV-Relaying: Minimum Secrecy Energy   Efficiency Maximization via Trajectory and Communication Co-design",
        "authors": [
            "Milad Tatar Mamaghani",
            "Yi Hong"
        ],
        "summary": "Unmanned aerial vehicles (UAVs) and Terahertz (THz) technology are envisioned to play paramount roles in next-generation wireless communications. In this paper, we present a novel secure UAV-assisted mobile relaying system operating at THz bands for data acquisition from multiple ground user equipments (UEs) towards a destination. We assume that the UAV-mounted relay may act, besides providing relaying services, as a potential eavesdropper called the untrusted UAV-relay (UUR). To safeguard end-to-end communications, we present a secure two-phase transmission strategy with cooperative jamming. Then, we devise an optimization framework in terms of a new measure $-$ secrecy energy efficiency (SEE), defined as the ratio of achievable average secrecy rate to average system power consumption, which enables us to obtain the best possible security level while taking UUR's inherent flight power limitation into account. For the sake of quality of service fairness amongst all the UEs, we aim to maximize the minimum SEE (MSEE) performance via the joint design of key system parameters, including UUR's trajectory and velocity, communication scheduling, and network power allocation. Since the formulated problem is a mixed-integer nonconvex optimization and computationally intractable, we decouple it into four subproblems and propose alternative algorithms to solve it efficiently via greedy/sequential block successive convex approximation and non-linear fractional programming techniques. Numerical results demonstrate significant MSEE performance improvement of our designs compared to other known benchmarks.",
        "published": "2021-07-21T06:25:31Z",
        "link": "http://arxiv.org/abs/2107.09896v4",
        "categories": [
            "cs.IT",
            "cs.CE",
            "cs.NI",
            "eess.SP",
            "math.IT"
        ]
    },
    {
        "title": "CNN-based Realized Covariance Matrix Forecasting",
        "authors": [
            "Yanwen Fang",
            "Philip L. H. Yu",
            "Yaohua Tang"
        ],
        "summary": "It is well known that modeling and forecasting realized covariance matrices of asset returns play a crucial role in the field of finance. The availability of high frequency intraday data enables the modeling of the realized covariance matrices directly. However, most of the models available in the literature depend on strong structural assumptions and they often suffer from the curse of dimensionality. We propose an end-to-end trainable model built on the CNN and Convolutional LSTM (ConvLSTM) which does not require to make any distributional or structural assumption but could handle high-dimensional realized covariance matrices consistently. The proposed model focuses on local structures and spatiotemporal correlations. It learns a nonlinear mapping that connect the historical realized covariance matrices to the future one. Our empirical studies on synthetic and real-world datasets demonstrate its excellent forecasting ability compared with several advanced volatility models.",
        "published": "2021-07-22T12:02:24Z",
        "link": "http://arxiv.org/abs/2107.10602v1",
        "categories": [
            "cs.CE",
            "cs.AI"
        ]
    },
    {
        "title": "Establishing Digital Recognition and Identification of Microscopic   Objects for Implementation of Artificial Intelligence (AI) Guided   Microassembly",
        "authors": [
            "Tuo Zhou",
            "Shih-Yuan Yu",
            "Matthew Michaels",
            "Fangzhou Du",
            "Lawrence Kulinsky",
            "Mohammad Abdullah Al Faruque"
        ],
        "summary": "s miniaturization of electrical and mechanical components used in modern technology progresses, there is an increasing need for high-throughput and low-cost micro-scale assembly techniques. Many current micro-assembly methods are serial in nature, resulting in unfeasibly low throughput. Additionally, the need for increasingly smaller tools to pick and place individual microparts makes these methods cost prohibitive. Alternatively, parallel self-assembly or directed-assembly techniques can be employed by utilizing forces dominant at the micro and nano scales such as electro-kinetic, thermal, and capillary forces. However, these forces are governed by complex equations and often act on microparts simultaneously and competitively, making modeling and simulation difficult. The research in this paper presents a novel phenomenological approach to directed micro-assembly through the use of artificial intelligence to correlate micro-particle movement via dielectrophoretic and electro-osmotic forces in response to varying frequency of an applied non-uniform electric field. This research serves as a proof of concept of the application of artificial intelligence to create high yield low-cost micro-assembly techniques, which will prove useful in a variety of fields including micro-electrical-mechanical systems (MEMS), biotechnology, and tissue engineering.",
        "published": "2021-07-22T17:25:09Z",
        "link": "http://arxiv.org/abs/2107.10823v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Whole Heart Mesh Generation For Image-Based Computational Simulations By   Learning Free-From Deformations",
        "authors": [
            "Fanwei Kong",
            "Shawn C. Shadden"
        ],
        "summary": "Image-based computer simulation of cardiac function can be used to probe the mechanisms of (patho)physiology, and guide diagnosis and personalized treatment of cardiac diseases. This paradigm requires constructing simulation-ready meshes of cardiac structures from medical image data--a process that has traditionally required significant time and human effort, limiting large-cohort analyses and potential clinical translations. We propose a novel deep learning approach to reconstruct simulation-ready whole heart meshes from volumetric image data. Our approach learns to deform a template mesh to the input image data by predicting displacements of multi-resolution control point grids. We discuss the methods of this approach and demonstrate its application to efficiently create simulation-ready whole heart meshes for computational fluid dynamics simulations of the cardiac flow. Our source code is available at https://github.com/fkong7/HeartFFDNet.",
        "published": "2021-07-22T17:53:28Z",
        "link": "http://arxiv.org/abs/2107.10839v1",
        "categories": [
            "eess.IV",
            "cs.CE",
            "physics.med-ph"
        ]
    },
    {
        "title": "Additive manufacturing process design with differentiable simulations",
        "authors": [
            "Mojtaba Mozaffar",
            "Jian Cao"
        ],
        "summary": "We present a novel computational paradigm for process design in manufacturing processes that incorporates simulation responses to optimize manufacturing process parameters in high-dimensional temporal and spatial design spaces. We developed a differentiable finite element analysis framework using automatic differentiation which allows accurate optimization of challenging process parameters such as time-series laser power. We demonstrate the capability of our proposed method through three illustrative case studies in additive manufacturing for: (i) material and process parameter inference using partial observable data, (ii) controlling time-series thermal behavior, and (iii) stabilizing melt pool depth. This research opens new avenues for high-dimensional manufacturing design using solid mechanics simulation tools such as finite element methods. Our codes are made publicly available for the research community at https://github.com/mojtabamozaffar/differentiable-simulation-am.",
        "published": "2021-07-22T20:40:39Z",
        "link": "http://arxiv.org/abs/2107.10919v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A Predictive Multiphase Model of Silica Aerogels for Building Envelope   Insulations",
        "authors": [
            "Jingye Tan",
            "Pedram Maleki",
            "Lu An",
            "Massimigliano Di Luigi",
            "Umberto Villa",
            "Chi Zhou",
            "Shenqiang Ren",
            "Danial Faghihi"
        ],
        "summary": "This work develops a multiphase thermomechanical model of porous silica aerogel and implements an uncertainty analysis framework consisting of the Sobol methods for global sensitivity analyses and Bayesian inference using a set of experimental data of silica aerogel. A notable feature of this work is implementing a new noise model within the Bayesian inversion to account for data uncertainty and modeling error. The hyper-parameters in the likelihood balance data misfit and prior contribution to the parameter posteriors and prevent their biased estimation. The results indicate that the uncertainty in solid conductivity and elasticity are the most influential parameters affecting the model output variance. Also, the Bayesian inference shows that despite the microstructural randomness in the thermal measurements, the model captures the data with 2% error. However, the model is inadequate in simulating the stress-strain measurements resulting in significant uncertainty in the computational prediction of a building insulation component.",
        "published": "2021-07-22T21:11:48Z",
        "link": "http://arxiv.org/abs/2107.12182v2",
        "categories": [
            "cond-mat.mtrl-sci",
            "cs.CE"
        ]
    },
    {
        "title": "Adaptively Weighted Top-N Recommendation for Organ Matching",
        "authors": [
            "Parshin Shojaee",
            "Xiaoyu Chen",
            "Ran Jin"
        ],
        "summary": "Reducing the shortage of organ donations to meet the demands of patients on the waiting list has being a major challenge in organ transplantation. Because of the shortage, organ matching decision is the most critical decision to assign the limited viable organs to the most suitable patients. Currently, organ matching decisions were only made by matching scores calculated via scoring models, which are built by the first principles. However, these models may disagree with the actual post-transplantation matching performance (e.g., patient's post-transplant quality of life (QoL) or graft failure measurements). In this paper, we formulate the organ matching decision-making as a top-N recommendation problem and propose an Adaptively Weighted Top-N Recommendation (AWTR) method. AWTR improves performance of the current scoring models by using limited actual matching performance in historical data set as well as the collected covariates from organ donors and patients. AWTR sacrifices the overall recommendation accuracy by emphasizing the recommendation and ranking accuracy for top-N matched patients. The proposed method is validated in a simulation study, where KAS [60] is used to simulate the organ-patient recommendation response. The results show that our proposed method outperforms seven state-of-the-art top-N recommendation benchmark methods.",
        "published": "2021-07-23T00:42:01Z",
        "link": "http://arxiv.org/abs/2107.10971v1",
        "categories": [
            "cs.LG",
            "cs.CE"
        ]
    },
    {
        "title": "A simple yet consistent constitutive law and mortar-based layer coupling   schemes for thermomechanical macroscale simulations of metal additive   manufacturing processes",
        "authors": [
            "Sebastian D. Proell",
            "Wolfgang A. Wall",
            "Christoph Meier"
        ],
        "summary": "This article proposes a coupled thermomechanical finite element model tailored to the macroscale simulation of metal additive manufacturing processes such as selective laser melting. A first focus lies on the derivation of a consistent constitutive law on basis of a Voigt-type spatial homogenization procedure across the relevant phases, powder, melt and solid. The proposed constitutive law accounts for the irreversibility of phase change and consistently represents thermally induced residual stresses. In particular, the incorporation of a reference strain term, formulated in rate form, allows to consistently enforce a stress-free configuration for newly solidifying material at melt temperature. Application to elementary test cases demonstrates the validity of the proposed constitutive law and allows for a comparison with analytical and reference solutions. Moreover, these elementary solidification scenarios give detailed insights and foster understanding of basic mechanisms of residual stress generation in melting and solidification problems with localized, moving heat sources. As a second methodological aspect, dual mortar mesh tying strategies are proposed for the coupling of successively applied powder layers. This approach allows for very flexible mesh generation for complex geometries. As compared to collocation-type coupling schemes, e.g., based on hanging nodes, these mortar methods enforce the coupling conditions between non-matching meshes in an $L^2$-optimal manner. The combination of the proposed constitutive law and mortar mesh tying approach is validated on realistic three-dimensional examples, representing a first step towards part-scale predictions.",
        "published": "2021-07-23T08:17:44Z",
        "link": "http://arxiv.org/abs/2107.11067v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Consistent coupling of positions and rotations for embedding 1D Cosserat   beams into 3D solid volumes",
        "authors": [
            "Ivo Steinbrecher",
            "Alexander Popp",
            "Christoph Meier"
        ],
        "summary": "This article proposes a mortar type finite element formulation for consistently embedding curved, slender beams, i.e. 1D Cosserat continua, into 3D solid volumes. A consistent 1D-3D coupling scheme for this problem type is proposed, which enforces both positional and rotational constraints. Since Boltzmann continua exhibit no inherent rotational degrees of freedom, suitable definitions of orthonormal triads are investigated that are representative for the orientation of material directions in the 3D solid. The rotation tensor defined by the polar decomposition of the deformation gradient is demonstrated to represent these material directions in a L2-optimal manner. Subsequently, objective rotational coupling constraints between beam and solid are formulated and enforced in a variationally consistent framework. Eventually, finite element discretization of all primary fields results in an embedded mortar formulation for rotational and translational constraint enforcement. Based on carefully chosen numerical test cases, the proposed scheme is demonstrated to exhibit a consistent spatial convergence behavior and to offer the up-scaling potential for studying real-life engineering applications such as fiber-reinforced composite materials.",
        "published": "2021-07-23T11:58:30Z",
        "link": "http://arxiv.org/abs/2107.11151v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Finite Element Formulations for Beam-to-Solid Interaction -- From   Embedded Fibers Towards Contact",
        "authors": [
            "Alexander Popp",
            "Ivo Steinbrecher"
        ],
        "summary": "Contact and related phenomena, such as friction, wear or elastohydrodynamic lubrication, remain as one of the most challenging problem classes in nonlinear solid and structural mechanics. In the context of their computational treatment with finite element methods (FEM) or isogeometric analysis (IGA), the inherent non-smoothness of contact conditions, the design of robust discretization approaches as well as the implementation of efficient solution schemes seem to provide a never ending source of hard nuts to crack. This is particularly true for the case of beam-to-solid interaction with its mixed-dimensional 1D-3D contact models. Therefore, this contribution gives an overview of current steps being taken, starting from state-of-the-art beam-to-beam (1D) and solid-to-solid (3D) contact algorithms, towards a truly general 1D-3D beam-to-solid contact formulation.",
        "published": "2021-07-23T12:05:53Z",
        "link": "http://arxiv.org/abs/2107.11158v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Non-intrusive reduced order modeling of natural convection in porous   media using convolutional autoencoders: comparison with linear subspace   techniques",
        "authors": [
            "T. Kadeethum",
            "F. Ballarin",
            "Y. Choi",
            "D. O'Malley",
            "H. Yoon",
            "N. Bouklas"
        ],
        "summary": "Natural convection in porous media is a highly nonlinear multiphysical problem relevant to many engineering applications (e.g., the process of $\\mathrm{CO_2}$ sequestration). Here, we present a non-intrusive reduced order model of natural convection in porous media employing deep convolutional autoencoders for the compression and reconstruction and either radial basis function (RBF) interpolation or artificial neural networks (ANNs) for mapping parameters of partial differential equations (PDEs) on the corresponding nonlinear manifolds. To benchmark our approach, we also describe linear compression and reconstruction processes relying on proper orthogonal decomposition (POD) and ANNs. We present comprehensive comparisons among different models through three benchmark problems. The reduced order models, linear and nonlinear approaches, are much faster than the finite element model, obtaining a maximum speed-up of $7 \\times 10^{6}$ because our framework is not bound by the Courant-Friedrichs-Lewy condition; hence, it could deliver quantities of interest at any given time contrary to the finite element model. Our model's accuracy still lies within a mean squared error of 0.07 (two-order of magnitude lower than the maximum value of the finite element results) in the worst-case scenario. We illustrate that, in specific settings, the nonlinear approach outperforms its linear counterpart and vice versa. We hypothesize that a visual comparison between principal component analysis (PCA) or t-Distributed Stochastic Neighbor Embedding (t-SNE) could indicate which method will perform better prior to employing any specific compression strategy.",
        "published": "2021-07-23T20:58:15Z",
        "link": "http://arxiv.org/abs/2107.11460v2",
        "categories": [
            "cs.CE",
            "cs.LG",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Efficient Inverse Design of 2D Elastic Metamaterial Systems Using   Invertible Neural Networks",
        "authors": [
            "Manaswin Oddiraju",
            "Amir Behjat",
            "Mostafa Nouh",
            "Souma Chowdhury"
        ],
        "summary": "Locally resonant elastic metamaterials (LREM) can be designed, by optimizing the geometry of the constituent self-repeating unit cells, to potentially damp out vibration in selected frequency ranges, thus yielding desired bandgaps. However, it remains challenging to quickly arrive at unit cell designs that satisfy any requested bandgap specifications within a given global frequency range. This paper develops a computationally efficient framework for (fast) inverse design of LREM, by integrating a new type of machine learning models called invertible neural networks or INN. An INN can be trained to predict the bandgap bounds as a function of the unit cell design, and interestingly at the same time it learns to predict the unit cell design given a bandgap, when executed in reverse. In our case the unit cells are represented in terms of the width's of the outer matrix and middle soft filler layer of the unit cell. Training data on the frequency response of the unit cell is provided by Bloch dispersion analyses. The trained INN is used to instantaneously retrieve feasible (or near feasible) inverse designs given a specified bandgap constraint, which is then used to initialize a forward constrained optimization (based on sequential quadratic programming) to find the bandgap satisfying unit cell with minimum mass. Case studies show favorable performance of this approach, in terms of the bandgap characteristics and minimized mass, when compared to the median scenario over ten randomly initialized optimizations for the same specified bandgaps. Further analysis using FEA verify the bandgap performance of a finite structure comprised of $8\\times 8$ arrangement of the unit cells obtained with INN-accelerated inverse design.",
        "published": "2021-07-24T01:31:10Z",
        "link": "http://arxiv.org/abs/2107.11503v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Mathematical Modeling of Heat Conduction",
        "authors": [
            "Abdul Aziz Momin",
            "Nikhil Shende",
            "Abhijna Anamtatmakula",
            "Emily Ganguly",
            "Ashwin Gurbani",
            "Chaitanya A Joshi",
            "Yogesh Y Mahajan"
        ],
        "summary": "This report describes a mathematical model of heat conduction. The differential equation for heat conduction in one dimensional rod has been derived. The explicit finite difference numerical method is used to solve this differential equation. Then for simulation, a code was written in using python libraries via Jupyter notebook. The simulation carried out for Aluminum, Copper and Mild Steel rods and results were discussed.",
        "published": "2021-07-25T06:20:16Z",
        "link": "http://arxiv.org/abs/2107.11737v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A brief note on understanding neural networks as Gaussian processes",
        "authors": [
            "Mengwu Guo"
        ],
        "summary": "As a generalization of the work in [Lee et al., 2017], this note briefly discusses when the prior of a neural network output follows a Gaussian process, and how a neural-network-induced Gaussian process is formulated. The posterior mean functions of such a Gaussian process regression lie in the reproducing kernel Hilbert space defined by the neural-network-induced kernel. In the case of two-layer neural networks, the induced Gaussian processes provide an interpretation of the reproducing kernel Hilbert spaces whose union forms a Barron space.",
        "published": "2021-07-25T21:06:58Z",
        "link": "http://arxiv.org/abs/2107.11892v1",
        "categories": [
            "cs.LG",
            "cs.CE",
            "stat.ML"
        ]
    },
    {
        "title": "Trade When Opportunity Comes: Price Movement Forecasting via   Locality-Aware Attention and Iterative Refinement Labeling",
        "authors": [
            "Liang Zeng",
            "Lei Wang",
            "Hui Niu",
            "Ruchen Zhang",
            "Ling Wang",
            "Jian Li"
        ],
        "summary": "Price movement forecasting, aimed at predicting financial asset trends based on current market information, has achieved promising advancements through machine learning (ML) methods. Most existing ML methods, however, struggle with the extremely low signal-to-noise ratio and stochastic nature of financial data, often mistaking noises for real trading signals without careful selection of potentially profitable samples. To address this issue, we propose LARA, a novel price movement forecasting framework with two main components: Locality-Aware Attention (LA-Attention) and Iterative Refinement Labeling (RA-Labeling). (1) LA-Attention, enhanced by metric learning techniques, automatically extracts the potentially profitable samples through masked attention scheme and task-specific distance metrics. (2) RA-Labeling further iteratively refines the noisy labels of potentially profitable samples, and combines the learned predictors robust to the unseen and noisy samples. In a set of experiments on three real-world financial markets: stocks, cryptocurrencies, and ETFs, LARA significantly outperforms several machine learning based methods on the Qlib quantitative investment platform. Extensive ablation studies confirm LARA's superior ability in capturing more reliable trading opportunities.",
        "published": "2021-07-26T05:52:42Z",
        "link": "http://arxiv.org/abs/2107.11972v4",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.CE",
            "q-fin.ST"
        ]
    },
    {
        "title": "Identification of parameters in the torsional dynamics of a drilling   process through Bayesian statistics",
        "authors": [
            "Mario Germán Sandoval",
            "Americo Cunha Jr",
            "Rubens Sampaio"
        ],
        "summary": "This work presents the estimation of the parameters of an experimental setup, which is modeled as a system with three degrees of freedom, composed by a shaft, two rotors, and a DC motor, that emulates a drilling process. A Bayesian technique is used in the estimation process, to take into account the uncertainties and variabilities intrinsic to the measurement taken, which are modeled as a noise of Gaussian nature. With this procedure it is expected to check the reliability of the nominal values of the physical parameters of the test rig. An estimation process assuming that nine parameters of the experimental apparatus are unknown is conducted, and the results show that for some quantities the relative deviation with respect to the nominal values is very high. This deviation evidentiates a strong deficiency in the mathematical model used to describe the dynamic behavior of the experimental apparatus.",
        "published": "2021-07-27T03:14:09Z",
        "link": "http://arxiv.org/abs/2107.13535v1",
        "categories": [
            "stat.ME",
            "cs.CE",
            "physics.data-an",
            "stat.AP",
            "37N15",
            "I.6.6"
        ]
    },
    {
        "title": "Effect of an attached end mass in the dynamics of uncertainty nonlinear   continuous random system",
        "authors": [
            "Americo Cunha Jr",
            "Rubens Sampaio"
        ],
        "summary": "This work studies the dynamics of a one dimensional elastic bar with random elastic modulus and prescribed boundary conditions, say, fixed at one end, and attached to a lumped mass and two springs (one linear and another nonlinear) on the other extreme. The system analysis assumes that the elastic modulus has gamma probability distribution and uses Monte Carlo simulations to compute the propagation of uncertainty in this continuous--discrete system. After describing the deterministic and the stochastic modeling of the system, some configurations of the model are analyzed in order to characterize the effect of the lumped mass in the overall behavior of this dynamical system.",
        "published": "2021-07-27T03:24:31Z",
        "link": "http://arxiv.org/abs/2107.12574v1",
        "categories": [
            "math.DS",
            "cs.CE",
            "physics.class-ph",
            "37N15",
            "I.6.6"
        ]
    },
    {
        "title": "Bayesian Optimisation for Sequential Experimental Design with   Applications in Additive Manufacturing",
        "authors": [
            "Mimi Zhang",
            "Andrew Parnell",
            "Dermot Brabazon",
            "Alessio Benavoli"
        ],
        "summary": "Bayesian optimization (BO) is an approach to globally optimizing black-box objective functions that are expensive to evaluate. BO-powered experimental design has found wide application in materials science, chemistry, experimental physics, drug development, etc. This work aims to bring attention to the benefits of applying BO in designing experiments and to provide a BO manual, covering both methodology and software, for the convenience of anyone who wants to apply or learn BO. In particular, we briefly explain the BO technique, review all the applications of BO in additive manufacturing, compare and exemplify the features of different open BO libraries, unlock new potential applications of BO to other types of data (e.g., preferential output). This article is aimed at readers with some understanding of Bayesian methods, but not necessarily with knowledge of additive manufacturing; the software performance overview and implementation instructions are instrumental for any experimental-design practitioner. Moreover, our review in the field of additive manufacturing highlights the current knowledge and technological trends of BO. This article has a supplementary material online.",
        "published": "2021-07-27T13:30:56Z",
        "link": "http://arxiv.org/abs/2107.12809v4",
        "categories": [
            "cs.LG",
            "cs.CE"
        ]
    },
    {
        "title": "Dynamic optimal congestion pricing in multi-region urban networks by   application of a Multi-Layer-Neural network",
        "authors": [
            "Alexander Genser",
            "Anastasios Kouvelas"
        ],
        "summary": "Traffic management by applying congestion pricing is a measure for mitigating congestion in protected city corridors. As a promising tool, pricing improves the level of service in a network and reduces travel delays. However, real-world implementations are restricted to static pricing, i.e., the price is fixed and not responsive to the prevailing regional traffic conditions. Dynamic pricing overcomes these limitations but also affects the users route choices. This work uses dynamic pricing's influence and predicts pricing functions to aim for a system optimal traffic distribution. The framework models a large-scale network where every region is considered homogeneous, allowing for the Macroscopic Fundamental Diagram (MFD) application. We compute Dynamic System Optimum (DSO) and a Quasi Dynamic User Equilibrium (QDUE) of the macroscopic model by formulating a linear optimization problem and utilizing the Dijkstra algorithm and a Multinomial Logit model (MNL), respectively. The equilibria allow us to find an optimal pricing methodology by training Multi-Layer-Neural (MLN) network models. We test our framework on a case study in Zurich, Switzerland, and showcase that (a) our neural network model learns the complex user behavior and (b) allows predicting optimal pricing functions. Results show a significant performance improvement when operating a transportation network in the DSO and highlight how dynamic pricing influences the user's route choice behavior towards the system optimal equilibrium.",
        "published": "2021-07-27T14:16:59Z",
        "link": "http://arxiv.org/abs/2107.14585v1",
        "categories": [
            "cs.RO",
            "cs.CE"
        ]
    },
    {
        "title": "Abordagem probabilística para análise de confiabilidade de dados   gerados em sequenciamentos multiplex na plataforma ABI SOLiD",
        "authors": [
            "Fabio M. F. Lobato",
            "Carlos D. N. Damasceno",
            "Péricles L. Machado",
            "Nandamudi L. Vijaykumar",
            "André R. dos Santos",
            "Sylvain H. Darnet",
            "André N. A. Gonçalves",
            "Dayse O. de Alencar",
            "Ádamo L. de Santana"
        ],
        "summary": "The next-generation sequencers such as Illumina and SOLiD platforms generate a large amount of data, commonly above 10 Gigabytes of text files. Particularly, the SOLiD platform allows the sequencing of multiple samples in a single run, called multiplex run, through a tagging system called Barcode. This feature requires a computational process for separation of the data sample because the sequencer provides a mixture of all samples in a single output. This process must be secure to avoid any harm that may scramble further analysis. In this context, realized the need to develop a probabilistic model capable of assigning a degree of confidence in the marking system used in multiplex sequencing. The results confirmed the adequacy of the model obtained, which allows, among other things, to guide a process of filtering the data and evaluation of the sequencing protocol used.",
        "published": "2021-07-27T15:33:42Z",
        "link": "http://arxiv.org/abs/2107.13537v2",
        "categories": [
            "q-bio.GN",
            "cs.CE"
        ]
    },
    {
        "title": "Three-Dimensional Central Moment Lattice Boltzmann Method on a Cuboid   Lattice for Anisotropic and Inhomogeneous Flows",
        "authors": [
            "Eman Yahia",
            "William Schupbach",
            "Kannan Premnath"
        ],
        "summary": "We present a new 3D lattice Boltzmann (LB) algorithm based on central moments for the D3Q27 lattice using a cuboid grid, which is parameterized by two grid aspect ratios that are related to the ratios of the particle speeds with respect to that along a reference coordinate direction. The use of the cuboid lattice grid enables the method to compute flows having different characteristic length scales in different directions more efficiently. It is constructed to simulate the Navier-Stokes equations consistently via introducing counteracting corrections to the second order moment equilibria obtained via a Chapman-Enskog analysis that eliminate the errors associated with the grid anisotropy and the non-Galilean invariant terms. The implementation is shown to be compact and modular, with an interpretation based on special matrices, admitting ready extension of the standard algorithm for the cubic lattice to the cuboid lattice via appropriate scaling of moments based on grid aspect ratios before and after collision step and equilibria corrections. The resulting formulation is general in that the same grid corrections developed for the D3Q27 lattice for recovering the correct viscous stress tensor is applicable for other lattice subsets, and a variety of collision models, including those based on the relaxation of raw moments, central moments and cumulants, as well as their special case involving the distribution functions. The cuboid central moment LBM is validated against a variety of benchmark flows, and when used in lieu of the corresponding raw moment formulation for simulating shear flows, we show that it results in significant improvements in numerical stability. Finally, we demonstrate that our cuboid LB approach is efficient in simulating anisotropic shear flow problems with significant savings in computational cost and memory storage when compared to that based on the cubic lattice.",
        "published": "2021-07-27T20:46:10Z",
        "link": "http://arxiv.org/abs/2107.14774v2",
        "categories": [
            "cs.CE",
            "nlin.CG",
            "physics.comp-ph",
            "physics.flu-dyn"
        ]
    },
    {
        "title": "Mechanical Cloak via Data-Driven Aperiodic Metamaterial Design",
        "authors": [
            "Liwei Wang",
            "Jagannadh Boddapati",
            "Ke Liu",
            "Ping Zhu",
            "Chiara Daraio",
            "Wei Chen"
        ],
        "summary": "Mechanical cloaks are materials engineered to manipulate the elastic response around objects to make them indistinguishable from their homogeneous surroundings. Typically, methods based on material-parameter transformations are used to design optical, thermal and electric cloaks. However, they are not applicable in designing mechanical cloaks, since continuum-mechanics equations are not form-invariant under general coordinate transformations. As a result, existing design methods for mechanical cloaks have so far been limited to a narrow selection of voids with simple shapes. To address this challenge, we present a systematic, data-driven design approach to create mechanical cloaks composed of aperiodic metamaterials using a large pre-computed unit cell database. Our method is flexible to allow the design of cloaks with various boundary conditions, multiple loadings, different shapes and numbers of voids, and different homogeneous surroundings. It enables a concurrent optimization of both topology and properties distribution of the cloak. Compared to conventional fixed-shape solutions, this results in an overall better cloaking performance, and offers unparalleled versatility. Experimental measurements on 3D-printed structures further confirm the validity of the proposed approach. Our research illustrates the benefits of data-driven approaches in quickly responding to new design scenarios and resolving the computational challenge associated with multiscale designs of functional structures. It could be generalized to accommodate other applications that require heterogeneous property distribution, such as soft robots and implants design.",
        "published": "2021-07-28T03:14:44Z",
        "link": "http://arxiv.org/abs/2107.13147v2",
        "categories": [
            "physics.app-ph",
            "cond-mat.mtrl-sci",
            "cs.CE"
        ]
    },
    {
        "title": "Combining Machine Learning Classifiers for Stock Trading with Effective   Feature Extraction",
        "authors": [
            "A. K. M. Amanat Ullah",
            "Fahim Imtiaz",
            "Miftah Uddin Md Ihsan",
            "Md. Golam Rabiul Alam",
            "Mahbub Majumdar"
        ],
        "summary": "The unpredictability and volatility of the stock market render it challenging to make a substantial profit using any generalised scheme. Many previous studies tried different techniques to build a machine learning model, which can make a significant profit in the US stock market by performing live trading. However, very few studies have focused on the importance of finding the best features for a particular trading period. Our top approach used the performance to narrow down the features from a total of 148 to about 30. Furthermore, the top 25 features were dynamically selected before each time training our machine learning model. It uses ensemble learning with four classifiers: Gaussian Naive Bayes, Decision Tree, Logistic Regression with L1 regularization, and Stochastic Gradient Descent, to decide whether to go long or short on a particular stock. Our best model performed daily trade between July 2011 and January 2019, generating 54.35% profit. Finally, our work showcased that mixtures of weighted classifiers perform better than any individual predictor of making trading decisions in the stock market.",
        "published": "2021-07-28T03:22:58Z",
        "link": "http://arxiv.org/abs/2107.13148v3",
        "categories": [
            "q-fin.TR",
            "cs.CE",
            "cs.LG"
        ]
    },
    {
        "title": "A mechanism-based multi-trap phase field model for hydrogen assisted   fracture",
        "authors": [
            "M. Isfandbod",
            "E. Martínez-Pañeda"
        ],
        "summary": "We present a new mechanistic, phase field-based formulation for predicting hydrogen embrittlement. The multi-physics model developed incorporates, for the first time, a Taylor-based dislocation model to resolve the mechanics of crack tip deformation. This enables capturing the role of dislocation hardening mechanisms in elevating the tensile stress, hydrogen concentration and dislocation trap density within tens of microns ahead of the crack tip. The constitutive strain gradient plasticity model employed is coupled to a phase field formulation, to simulate the fracture process, and to a multi-trap hydrogen transport model. The analysis of stationary and propagating cracks reveals that the modelling framework presented is capable of adequately capturing the sensitivity to the hydrogen concentration, the loading rate, the material strength and the plastic length scale. In addition, model predictions are compared to experimental data of notch tensile strength versus hydrogen content on a high-strength steel; a very good agreement is attained. We define and implement both atomistic-based and phenomenological hydrogen degradation laws and discuss similarities, differences and implications for the development of parameter-free hydrogen embrittlement models.",
        "published": "2021-07-28T06:31:21Z",
        "link": "http://arxiv.org/abs/2108.00856v1",
        "categories": [
            "cond-mat.mtrl-sci",
            "cs.CE",
            "physics.app-ph"
        ]
    },
    {
        "title": "A mechanism-based gradient damage model for metallic fracture",
        "authors": [
            "S. S. Shishvan",
            "S. Assadpour-asl",
            "E. Martínez-Pañeda"
        ],
        "summary": "A new gradient-based formulation for predicting fracture in elastic-plastic solids is presented. Damage is captured by means of a phase field model that considers both the elastic and plastic works as driving forces for fracture. Material deformation is characterised by a mechanism-based strain gradient constitutive model. This non-local plastic-damage formulation is numerically implemented and used to simulate fracture in several paradigmatic boundary value problems. The case studies aim at shedding light into the role of the plastic and fracture length scales. It is found that the role of plastic strain gradients is two-fold. When dealing with sharp defects like cracks, plastic strain gradients elevate local stresses and facilitate fracture. However, in the presence of non-sharp defects failure is driven by the localisation of plastic flow, which is delayed due to the additional work hardening introduced by plastic strain gradients.",
        "published": "2021-07-28T07:18:36Z",
        "link": "http://arxiv.org/abs/2108.04908v1",
        "categories": [
            "cs.CE",
            "cond-mat.mtrl-sci",
            "physics.app-ph"
        ]
    },
    {
        "title": "Second-order phase-field formulations for anisotropic brittle fracture",
        "authors": [
            "Tymofiy Gerasimov",
            "Laura De Lorenzis"
        ],
        "summary": "We address brittle fracture in anisotropic materials featuring two-fold and four-fold symmetric fracture toughness. For these two classes, we develop two variational phase-field models based on the family of regularizations proposed by Focardi (Focardi, M. On the variational approximation of free-discontinuity problems in the vectorial case. Math. Models Methods App. Sci., 11:663{684, 2001), for which Gamma-convergence results hold. Since both models are of second order, as opposed to the previously available fourth-order models for four-fold symmetric fracture toughness, they do not require basis functions of C1-continuity nor mixed variational principles for finite element discretization. For the four-fold symmetric formulation we show that the standard quadratic degradation function is unsuitable and devise a procedure to derive a suitable one. The performance of the new models is assessed via several numerical examples that simulate anisotropic fracture under anti-plane shear loading. For both formulations at fixed displacements (i.e. within an alternate minimization procedure), we also provide some existence and uniqueness results for the phase-field solution.",
        "published": "2021-07-28T11:21:48Z",
        "link": "http://arxiv.org/abs/2107.13280v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Enumeration and Identification of Unique 3D Spatial Topologies of   Interconnected Engineering Systems Using Spatial Graphs",
        "authors": [
            "Satya R. T. Peddada",
            "Nathan M. Dunfield",
            "Lawrence E. Zeidner",
            "Zane R. Givans",
            "Kai A. James",
            "James T. Allison"
        ],
        "summary": "Systematic enumeration and identification of unique 3D spatial topologies of complex engineering systems (such as automotive cooling systems, electric power trains, satellites, and aero-engines) are essential to navigation of these expansive design spaces with the goal of identifying new spatial configurations that can satisfy challenging system requirements. However, efficient navigation through discrete 3D spatial topology (ST) options is a very challenging problem due to its combinatorial nature and can quickly exceed human cognitive abilities at even moderate complexity levels. This article presents a new, efficient, and scalable design framework that leverages mathematical spatial graph theory to represent, enumerate, and identify distinctive 3D topological classes for a generic 3D engineering system, given its system architecture (SA) -- its components and their interconnections. First, spatial graph diagrams (SGDs) are generated for a given SA from zero to a specified maximum number of interconnect crossings. Then, corresponding Yamada polynomials for all the planar SGDs are generated. SGDs are categorized into topological classes, each of which shares a unique Yamada polynomial. Finally, within each topological class, 3D geometric models are generated using the spatial graph diagrams (SGDs) having different numbers of interconnect crossings. Selected case studies are presented to illustrate the different features of our proposed framework, including an industrial engineering design application: ST enumeration of a 3D automotive fuel cell cooling system (AFCS). Design guidelines are also provided for practicing engineers to aid the application of this framework to different types of real-world problems such as configuration design and spatial packaging optimization.",
        "published": "2021-07-29T03:20:54Z",
        "link": "http://arxiv.org/abs/2107.13724v2",
        "categories": [
            "cs.CE",
            "math.GT",
            "57K12 (Primary) 57K14 (Secondary)",
            "J.6; J.2"
        ]
    },
    {
        "title": "Three-Dimensional Data-Driven Magnetostatic Field Computation using   Real-World Measurement Data",
        "authors": [
            "Armin Galetzka",
            "Dimitrios Loukrezis",
            "Herbert De Gersem"
        ],
        "summary": "This paper presents a practical case study of a data-driven magnetostatic finite element solver applied to a real-world three-dimensional problem. Instead of using a hard-coded phenomenological material model within the solver, the data-driven computing approach reformulates the boundary value problem such that the field solution is directly computed on the measurement data. The data-driven formulation results in a minimization problem with a Lagrange multiplier, where the sought solution must conform to Maxwell's equations while at the same time being closest to the available measurement data. The data-driven solver is applied to a three-dimensional model of an inductor excited by a DC-current. Numerical results for data sets of increasing cardinality verify that the data-driven solver recovers the conventional solution. Furthermore, this work concludes that the data-driven magnetostatic finite element solver is applicable to computationally demanding three-dimensional problems. Simulations with real world measurement data further show the practical usability of the solver.",
        "published": "2021-07-30T12:57:36Z",
        "link": "http://arxiv.org/abs/2107.14604v2",
        "categories": [
            "cs.CE",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Simulation-Based Optimization of High-Performance Wheel Loading",
        "authors": [
            "Koji Aoshima",
            "Martin Servin",
            "Eddie Wadbro"
        ],
        "summary": "Having smart and autonomous earthmoving in mind, we explore high-performance wheel loading in a simulated environment. This paper introduces a wheel loader simulator that combines contacting 3D multibody dynamics with a hybrid continuum-particle terrain model, supporting realistic digging forces and soil displacements at real-time performance. A total of 270,000 simulations are run with different loading actions, pile slopes, and soil to analyze how they affect the loading performance. The results suggest that the preferred digging actions should preserve and exploit a steep pile slope. High digging speed favors high productivity, while energy-efficient loading requires a lower dig speed.",
        "published": "2021-07-30T13:27:57Z",
        "link": "http://arxiv.org/abs/2107.14615v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "BoA-PTA, A Bayesian Optimization Accelerated Error-Free SPICE Solver",
        "authors": [
            "Wei W. Xing",
            "Xiang Jin",
            "Yi Liu",
            "Dan Niu",
            "Weishen Zhao",
            "Zhou Jin"
        ],
        "summary": "One of the greatest challenges in IC design is the repeated executions of computationally expensive SPICE simulations, particularly when highly complex chip testing/verification is involved. Recently, pseudo transient analysis (PTA) has shown to be one of the most promising continuation SPICE solver. However, the PTA efficiency is highly influenced by the inserted pseudo-parameters. In this work, we proposed BoA-PTA, a Bayesian optimization accelerated PTA that can substantially accelerate simulations and improve convergence performance without introducing extra errors. Furthermore, our method does not require any pre-computation data or offline training. The acceleration framework can either be implemented to speed up ongoing repeated simulations immediately or to improve new simulations of completely different circuits. BoA-PTA is equipped with cutting-edge machine learning techniques, e.g., deep learning, Gaussian process, Bayesian optimization, non-stationary monotonic transformation, and variational inference via parameterization. We assess BoA-PTA in 43 benchmark circuits against other SOTA SPICE solvers and demonstrate an average 2.3x (maximum 3.5x) speed-up over the original CEPTA.",
        "published": "2021-07-31T14:58:22Z",
        "link": "http://arxiv.org/abs/2108.00257v1",
        "categories": [
            "cs.LG",
            "cs.CE",
            "I.6.5; I.6.6; J.2; J.6"
        ]
    },
    {
        "title": "Emerging Methods of Auction Design in Social Networks",
        "authors": [
            "Yuhang Guo",
            "Dong Hao"
        ],
        "summary": "In recent years, a new branch of auction models called diffusion auction has extended the traditional auction into social network scenarios. The diffusion auction models the auction as a networked market whose nodes are potential customers and whose edges are the relations between these customers. The diffusion auction mechanism can incentivize buyers to not only submit a truthful bid, but also further invite their surrounding neighbors to participate into the auction. It can convene more participants than traditional auction mechanisms, which leads to better optimizations of different key aspects, such as social welfare, seller's revenue, amount of redistributed money and so on. The diffusion auctions have recently attracted a discrete interest in the algorithmic game theory and market design communities. This survey summarizes the current progress of diffusion auctions.",
        "published": "2021-08-01T07:18:52Z",
        "link": "http://arxiv.org/abs/2108.00381v1",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.CE"
        ]
    },
    {
        "title": "Network Flow based approaches for the Pipelines Routing Problem in Naval   Design",
        "authors": [
            "Víctor Blanco",
            "Gabriel González",
            "Yolanda Hinojosa",
            "Diego Ponce",
            "Miguel A. Pozo",
            "Justo Puerto"
        ],
        "summary": "In this paper we propose a general methodology for the optimal automatic routing of spatial pipelines motivated by a recent collaboration with Ghenova, a leading Naval Engineering company. We provide a minimum cost multicommodity network flow based model for the problem incorporating all the technical requirements for a feasible pipeline routing. A branch-and-cut approach is designed and different matheuristic algorithms are derived for solving efficiently the problem. We report the results of a battery of computational experiments to assess the problem performance as well as a case study of a real-world naval instance provided by our partner company.",
        "published": "2021-08-01T10:03:53Z",
        "link": "http://arxiv.org/abs/2108.00416v1",
        "categories": [
            "math.OC",
            "cs.CE"
        ]
    },
    {
        "title": "Risk Adversarial Learning System for Connected and Autonomous Vehicle   Charging",
        "authors": [
            "Md. Shirajum Munir",
            "Ki Tae Kim",
            "Kyi Thar",
            "Dusit Niyato",
            "Choong Seon Hong"
        ],
        "summary": "In this paper, the design of a rational decision support system (RDSS) for a connected and autonomous vehicle charging infrastructure (CAV-CI) is studied. In the considered CAV-CI, the distribution system operator (DSO) deploys electric vehicle supply equipment (EVSE) to provide an EV charging facility for human-driven connected vehicles (CVs) and autonomous vehicles (AVs). The charging request by the human-driven EV becomes irrational when it demands more energy and charging period than its actual need. Therefore, the scheduling policy of each EVSE must be adaptively accumulated the irrational charging request to satisfy the charging demand of both CVs and AVs. To tackle this, we formulate an RDSS problem for the DSO, where the objective is to maximize the charging capacity utilization by satisfying the laxity risk of the DSO. Thus, we devise a rational reward maximization problem to adapt the irrational behavior by CVs in a data-informed manner. We propose a novel risk adversarial multi-agent learning system (RAMALS) for CAV-CI to solve the formulated RDSS problem. In RAMALS, the DSO acts as a centralized risk adversarial agent (RAA) for informing the laxity risk to each EVSE. Subsequently, each EVSE plays the role of a self-learner agent to adaptively schedule its own EV sessions by coping advice from RAA. Experiment results show that the proposed RAMALS affords around 46.6% improvement in charging rate, about 28.6% improvement in the EVSE's active charging time and at least 33.3% more energy utilization, as compared to a currently deployed ACN EVSE system, and other baselines.",
        "published": "2021-08-02T02:38:15Z",
        "link": "http://arxiv.org/abs/2108.01466v2",
        "categories": [
            "cs.AI",
            "cs.CE",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "The Electric Vehicle Routing Problem with Nonlinear Charging Functions",
        "authors": [
            "Yijing Liang",
            "Said Dabia",
            "Zhixing Luo"
        ],
        "summary": "This paper outlines an exact and a heuristic algorithm for the electric vehicle routing problem with a nonlinear charging function (E-VRP-NL) introduced by Montoya et al. (2017). The E-VRP-NL captures several realistic features of electric vehicles including the battery limited driving range and nonlinear charging process at the charging stations. We formulate this problem as a set-partitioning and solve it using a column generation based algorithm. The resulting pricing problem of the column generation is a complicated problem as, next to the usual operational constraints e.g. time windows and vehicle capacity, electric vehicle related features are also considered. In particular, the nonlinear nature of the battery charging process requires the incorporation of a set of sophisticated recursive functions in the pricing algorithm. We show how these recursive functions allow for the simultaneous evaluation of the routing and charging decisions. Moreover, we illustrate how they can efficiently be embedded in the pricing algorithm. The column generation algorithm is integrated in a branch and bound algorithm and cutting planes are added resulting in a branch-and-price-and-cut algorithm for the E-VRP-NL. Next to the exact algorithm, we also develop a tabu search based heuristic to solve the problem quickly. To prove the efficiency of the proposed algorithms, their performance is tested on benchmark instances from the literature. Our exact algorithm can optimally solve instances with up to 40 customers, including several instances previously unsolved to optimality. The tabu search heuristic proves to be superior to state-of-the-art heuristics in the literature both on solution quality and computation times.",
        "published": "2021-08-03T03:43:10Z",
        "link": "http://arxiv.org/abs/2108.01273v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "The Sod gasdynamics problem as a tool for benchmarking face flux   construction in the finite volume method",
        "authors": [
            "Osama A. Marzouk"
        ],
        "summary": "The Finite Volume Method in Computational Fluid Dynamics to numerically model a fluid flow problem involves the process of formulating the numerical flux at the faces of the control volume. This process is important in deciding the resolution of the numerical solution, thus its quality. In the current work, the performance of different flux construction methods when solving the one-dimensional Euler equations for an inviscid flow is analyzed through a test problem in the literature having an exact (analytical) solution, which is the Sod problem. The work considered twenty two flux methods, which are: exact Riemann solver (Godunov), Roe, Kurganov-Noelle-Petrova, Kurganov-Tadmor, Steger-Warming Flux Vector Splitting, van Leer Flux Vector Splitting, AUSM, AUSM+, AUSM+-up, AUFS, five variants of the Harten-Lax-van Leer (HLL) family, and their corresponding five variants of the Harten-Lax-van Leer-Contact (HLLC) family, Lax-Friedrichs (Lax), and Rusanov. The methods of exact Riemann solver and van Leer showed excellent performance. The Riemann exact method took the longest runtime, but there was no significant difference in the runtime among all methods.",
        "published": "2021-08-03T19:11:57Z",
        "link": "http://arxiv.org/abs/2108.01709v1",
        "categories": [
            "math.NA",
            "cs.CE",
            "cs.NA",
            "physics.flu-dyn",
            "76N15",
            "J.2"
        ]
    },
    {
        "title": "Eliminating unwanted patterns with minimal interference",
        "authors": [
            "Zehavit Leibovich",
            "Ilan Gronau"
        ],
        "summary": "Artificial synthesis of DNA molecules is an essential part of the study of biological mechanisms. The design of a synthetic DNA molecule usually involves many objectives. One of the important objectives is to eliminate short sequence patterns that correspond to binding sites of restriction enzymes or transcription factors. While many design tools address this problem, no adequate formal solution exists for the pattern elimination problem. In this work, we present a formal description of the elimination problem and suggest efficient algorithms that eliminate unwanted patterns and allow optimization of other objectives with minimal interference to the desired DNA functionality. Our approach is flexible, efficient, and straightforward, and therefore can be easily incorporated in existing DNA design tools, making them considerably more powerful.",
        "published": "2021-08-03T19:51:43Z",
        "link": "http://arxiv.org/abs/2108.05848v1",
        "categories": [
            "q-bio.BM",
            "cs.CE"
        ]
    },
    {
        "title": "Topology optimization of the support structure for heat dissipation in   additive manufacturing",
        "authors": [
            "Takao Miki",
            "Shinji Nishiwaki"
        ],
        "summary": "A support structure is required to successfully create structural parts in the powder bed fusion process for additive manufacturing. In this study, we present the topology optimization of a support structure that improves the heat dissipation in the building process. First, we construct a numerical method that obtains the temperature field in the building process, represented by the transient heat conduction phenomenon with the volume heat flux. Next, we formulate an optimization problem for maximizing heat dissipation and develop an optimization algorithm that incorporates a level-set-based topology optimization. A sensitivity of the objective function is derived using the adjoint variable method. Finally, several numerical examples are provided to demonstrate the effectiveness and validity of the proposed method.",
        "published": "2021-08-04T02:30:42Z",
        "link": "http://arxiv.org/abs/2108.01815v2",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Notes on Perfectly Matched Layers (PMLs)",
        "authors": [
            "Steven G. Johnson"
        ],
        "summary": "This note is intended as a brief introduction to the theory and practice of perfectly matched layer (PML) absorbing boundaries for wave equations, originally developed for MIT courses 18.369 and 18.336. It focuses on the complex stretched-coordinate viewpoint, and also discusses the limitations of PML.",
        "published": "2021-08-04T14:07:13Z",
        "link": "http://arxiv.org/abs/2108.05348v1",
        "categories": [
            "cs.CE",
            "physics.comp-ph"
        ]
    },
    {
        "title": "A momentum preserving frictional contact algorithm based on affine   particle-in-cell grid transfers",
        "authors": [
            "Michael Tupek",
            "Jacob Koester",
            "Matthew Mosby"
        ],
        "summary": "An efficient and momentum conserving algorithm for enforcing contact between solid bodies is proposed. Previous advances in the material point method (MPM) led to a fast and simple, but potentially momentum violating, strategy for enforcing contact. This was achieved through a combination of velocity transfers between background and foreground grids, and a background grid velocity field update. We propose a modified strategy which ensures conservation of both linear and angular momentum with a novel use of the affine particle-in-cell (APIC) method. Two issues common to particle-in-cell based algorithms for contact are also addressed: material bodies tend to stick at a gap which is proportional to the grid spacing; and material points tend to stick together permanently when located within the same grid cell, making material rebound and friction challenging. We show that the use of APIC, combined with a grid transfer and momentum update algorithm results in contact being enforced at essentially zero gap. For the second issue, we propose a novel iterative scheme which allows particles interacting through the background grid to naturally separate after contact and enforce friction, while still satisfying momentum conservation.",
        "published": "2021-08-04T19:46:13Z",
        "link": "http://arxiv.org/abs/2108.02259v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "A Fracture Multiscale Model for Peridynamic enrichment within the   Partition of Unity Method",
        "authors": [
            "Matthias Birner",
            "Patrick Diehl",
            "Robert Lipton",
            "Marc Alexander Schweitzer"
        ],
        "summary": "Partition of unity methods (PUM) are of domain decomposition type and provide the opportunity for multiscale and multiphysics numerical modeling. Different physical models can exist within a PUM scheme for handling problems with zones of linear elasticity and zones where fractures occur. Here, the peridynamic (PD) model is used in regions of fracture and smooth PUM is used in the surrounding linear elastic media. The method is a so-called global-local enrichment strategy. The elastic fields of the undamaged media provide appropriate boundary data for the localized PD simulations. The first steps for a combined PD/PUM simulator are presented. In part I of this series, we show that the local PD approximation can be utilized to enrich the global PUM approximation to capture the true material response with high accuracy efficiently. Test problems are provided demonstrating the validity and potential of this numerical approach.",
        "published": "2021-08-05T01:47:37Z",
        "link": "http://arxiv.org/abs/2108.02336v4",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Implementing the BBE Agent-Based Model of a Sports-Betting Exchange",
        "authors": [
            "Dave Cliff",
            "James Hawkins",
            "James Keen",
            "Roberto Lau-Soto"
        ],
        "summary": "We describe three independent implementations of a new agent-based model (ABM) that simulates a contemporary sports-betting exchange, such as those offered commercially by companies including Betfair, Smarkets, and Betdaq. The motivation for constructing this ABM, which is known as the Bristol Betting Exchange (BBE), is so that it can serve as a synthetic data generator, producing large volumes of data that can be used to develop and test new betting strategies via advanced data analytics and machine learning techniques. Betting exchanges act as online platforms on which bettors can find willing counterparties to a bet, and they do this in a way that is directly comparable to the manner in which electronic financial exchanges, such as major stock markets, act as platforms that allow traders to find willing counterparties to buy from or sell to: the platform aggregates and anonymises orders from multiple participants, showing a summary of the market that is updated in real-time. In the first instance, BBE is aimed primarily at producing synthetic data for in-play betting (also known as in-race or in-game betting) where bettors can place bets on the outcome of a track-race event, such as a horse race, after the race has started and for as long as the race is underway, with betting only ceasing when the race ends. The rationale for, and design of, BBE has been described in detail in a previous paper that we summarise here, before discussing our comparative results which contrast a single-threaded implementation in Python, a multi-threaded implementation in Python, and an implementation where Python header-code calls simulations of the track-racing events written in OpenCL that execute on a 640-core GPU -- this runs approximately 1000 times faster than the single-threaded Python. Our source-code for BBE is freely available on GitHub.",
        "published": "2021-08-05T07:29:24Z",
        "link": "http://arxiv.org/abs/2108.02419v1",
        "categories": [
            "cs.CE",
            "q-fin.TR"
        ]
    },
    {
        "title": "Variational approach to relaxed topological optimization: closed form   solutions for structural problems in a sequential pseudo-time framework",
        "authors": [
            "J. Oliver",
            "D. Yago",
            "J. Cante",
            "O. Lloberas-Valls"
        ],
        "summary": "The work explores a specific scenario for structural computational optimization based on the following elements: (a) a relaxed optimization setting considering the ersatz (bi-material) approximation, (b) a treatment based on a nonsmoothed characteristic function field as a topological design variable, (c) the consistent derivation of a relaxed topological derivative whose determination is simple, general and efficient, (d) formulation of the overall increasing cost function topological sensitivity as a suitable optimality criterion, and (e) consideration of a pseudo-time framework for the problem solution, ruled by the problem constraint evolution. In this setting, it is shown that the optimization problem can be analytically solved in a variational framework, leading to, nonlinear, closed-form algebraic solutions for the characteristic function, which are then solved, in every time-step, via fixed point methods based on a pseudo-energy cutting algorithm combined with the exact fulfillment of the constraint, at every iteration of the non-linear algorithm, via a bisection method. The issue of the ill-posedness (mesh dependency) of the topological solution, is then easily solved via a Laplacian smoothing of that pseudo-energy. In the aforementioned context, a number of (3D) topological structural optimization benchmarks are solved, and the solutions obtained with the explored closed-form solution method, are analyzed, and compared, with their solution through an alternative level set method. Although the obtained results, in terms of the cost function and topology designs, are very similar in both methods, the associated computational cost is about five times smaller in the closedform solution method this possibly being one of its advantages.",
        "published": "2021-08-05T11:47:01Z",
        "link": "http://arxiv.org/abs/2108.02535v1",
        "categories": [
            "cs.CE",
            "math-ph",
            "math.MP"
        ]
    },
    {
        "title": "Generation of High-Order Coarse Quad Meshes on CAD Models via Integer   Linear Programming",
        "authors": [
            "Mattéo Couplet",
            "Maxence Reberol",
            "Jean-François Remacle"
        ],
        "summary": "We propose an end-to-end pipeline to robustly generate high-quality, high-order and coarse quadrilateral meshes on CAD models. This kind of mesh enables the use of high-order analysis techniques such as high-order finite element methods or isogeometric analysis. An initial unstructured mesh is generated; this mesh contains a low number of irregular vertices but these are not necessarily aligned, causing a very dense quad layout. A T-mesh is built on the mesh which allows to modify its topology by assigning new integer lengths to the T-mesh arcs. The task of simplifying the quad layout can be formulated as an Integer Linear Program which is solved efficiently using an adequate solver. Finally, a high-order quad mesh is extracted from the optimized topology. Validation on several CAD models shows that our approach is fast, robust, strictly respects the CAD features, and achieves interesting results in terms of coarseness and quality.",
        "published": "2021-08-05T14:14:08Z",
        "link": "http://arxiv.org/abs/2108.02635v1",
        "categories": [
            "cs.CE",
            "cs.CG"
        ]
    },
    {
        "title": "Next-Gen Gas Network Simulation",
        "authors": [
            "Christian Himpe",
            "Sara Grundel",
            "Peter Benner"
        ],
        "summary": "To overcome many-query optimization, control, or uncertainty quantification work loads in reliable gas and energy network operations, model order reduction is the mathematical technology of choice. To this end, we enhance the model, solver and reductor components of the \"morgen\" platform, introduced in Himpe et al [J.~Math.~Ind. 11:13, 2021], and conclude with a mathematically, numerically and computationally favorable model-solver-reductor ensemble.",
        "published": "2021-08-05T14:37:09Z",
        "link": "http://arxiv.org/abs/2108.02651v1",
        "categories": [
            "math.OC",
            "cs.CE",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Topology Optimization for Manufacturing with Accessible Support   Structures",
        "authors": [
            "Amir M. Mirzendehdel",
            "Morad Behandish",
            "Saigopal Nelaturi"
        ],
        "summary": "Metal additive manufacturing (AM) processes often fabricate a near-net shape that includes the as-designed part as well as the sacrificial support structures that need to be machined away by subtractive manufacturing (SM), for instance multi-axis machining. Thus, although AM is capable of generating highly complex parts, the limitations of SM due to possible collision between the milling tool and the workpiece can render an optimized part non-manufacturable. We present a systematic approach to topology optimization (TO) of parts for AM followed by SM to ensure removability of support structures, while optimizing the part's performance. A central idea is to express the producibility of the part from the near-net shape in terms of accessibility of every support structure point using a given set of cutting tool assemblies and fixturing orientations. Our approach does not impose any artificial constraints on geometric complexity of the part, support structures, machining tools, and fixturing devices. We extend the notion of inaccessibility measure field (IMF) to support structures to identify the inaccessible points and capture their contributions to non-manufacturability by a continuous spatial field. IMF is then augmented to the sensitivity field to guide the TO towards a manufacturable design. The approach enables efficient and effective design space exploration by finding nontrivial complex designs whose near-net shape can be 3D printed and post-processed for support removal by machining with a custom set of tools and fixtures. We demonstrate the efficacy of our approach on nontrivial examples in 2D and 3D.",
        "published": "2021-08-05T19:38:03Z",
        "link": "http://arxiv.org/abs/2108.02829v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Molecule Generation Experience: An Open Platform of Material Design for   Public Users",
        "authors": [
            "Seiji Takeda",
            "Toshiyuki Hama",
            "Hsiang-Han Hsu",
            "Akihiro Kishimoto",
            "Makoto Kogoh",
            "Takumi Hongo",
            "Kumiko Fujieda",
            "Hideaki Nakashika",
            "Dmitry Zubarev",
            "Daniel P. Sanders",
            "Jed W. Pitera",
            "Junta Fuchiwaki",
            "Daiju Nakano"
        ],
        "summary": "Artificial Intelligence (AI)-driven material design has been attracting great attentions as a groundbreaking technology across a wide spectrum of industries. Molecular design is particularly important owing to its broad application domains and boundless creativity attributed to progresses in generative models. The recent maturity of molecular generative models has stimulated expectations for practical use among potential users, who are not necessarily familiar with coding or scripting, such as experimental engineers and students in chemical domains. However, most of the existing molecular generative models are Python libraries on GitHub, that are accessible for only IT-savvy users. To fill this gap, we newly developed a graphical user interface (GUI)-based web application of molecular generative models, Molecule Generation Experience, that is open to the general public. This is the first web application of molecular generative models enabling users to work with built-in datasets to carry out molecular design. In this paper, we describe the background technology extended from our previous work. Our new online evaluation and structural filtering algorithms significantly improved the generation speed by 30 to 1,000 times with a wider structural variety, satisfying chemical stability and synthetic reality. We also describe in detail our Kubernetes-based scalable cloud architecture and user-oriented GUI that are necessary components to achieve a public service. Finally, we present actual use cases in industrial research to design new photoacid generators (PAGs) as well as release cases in educational events.",
        "published": "2021-08-06T10:48:00Z",
        "link": "http://arxiv.org/abs/2108.03044v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Topology Optimization Methods for 3D Structural Problems: A Comparative   Study",
        "authors": [
            "Daniel Yago",
            "Juan Cante",
            "Oriol Lloberas-Valls",
            "Javier Oliver"
        ],
        "summary": "The work provides an exhaustive comparison of some representative families of topology optimization methods for 3D structural optimization, such as the Solid Isotropic Material with Penalization (SIMP), the Level-set, the Bidirectional Evolutionary Structural Optimization (BESO), and the Variational Topology Optimization (VARTOP) methods. The main differences and similarities of these approaches are then highlighted from an algorithmic standpoint. The comparison is carried out via the study of a set of numerical benchmark cases using industrial-like fine-discretization meshes (around 1 million finite elements), and Matlab as the common computational platform, to ensure fair comparisons. Then, the results obtained for every benchmark case with the different methods are compared in terms of computational cost, topology quality, achieved minimum value of the objective function, and robustness of the computations (convergence in objective function and topology). Finally, some quantitative and qualitative results are presented, from which, an attempt of qualification of the methods, in terms of their relative performance, is done.",
        "published": "2021-08-06T14:40:13Z",
        "link": "http://arxiv.org/abs/2108.03146v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Approximation schemes for stochastic compliance-based topology   optimization with many loading scenarios",
        "authors": [
            "Mohamed Tarek",
            "Tapabrata Ray"
        ],
        "summary": "In this paper, approximation schemes are proposed for handling load uncertainty in compliance-based topology optimization problems, where the uncertainty is described in the form of a set of finitely many loading scenarios. Efficient approximate methods are proposed to approximately evaluate and differentiate either 1) the mean compliance, or 2) a class of scalar-valued function of the individual load compliances such as the weighted sum of the mean and standard deviation. The computational time complexities of the proposed algorithms are analyzed, compared to the exact approaches and then experimentally verified. Finally, some mean compliance minimization problems and some risk-averse compliance minimization problems are solved for verification.",
        "published": "2021-08-08T14:39:24Z",
        "link": "http://arxiv.org/abs/2108.03654v1",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "Second-Order Defeaturing Estimator of Manufacturing-Induced Porosity on   Structural Elasticity",
        "authors": [
            "Shiguang Deng",
            "Carl Soderhjelm",
            "Diran Apelian",
            "Krishnan Suresh"
        ],
        "summary": "Manufactured metallic components often contain non-uniformly distributed pores of complex morphologies. Since such porosity defects have significant influence on material behaviors and affect the usage in high-performance applications, it is significant to understand the impact of porosity characteristics on the behaviors of components. In this work, a gradient-enhanced porosity defeaturing estimator, which allows for the modeling of pore geometry and spatial distribution, is proposed within a general elastostatic framework. In this approach, the first order shape sensitivity is implemented to account for the change in elastic quantity of interests with respect to variations of pore sizes and shapes, which is then supplemented by a second order shape sensitivity whose mixed partial derivative quantifies the interactions between pores in proximity. The efficacy of the proposed method comes from its posterior manner that it only relies on field solutions of reference models where pores are suppressed. In this context, meshing difficulty and solution convergence issue are avoided, which would otherwise arise in a direct finite element analysis on porous structures. The impact of porosity on structural elastic performance is approximated using a second order Taylor expansion where the topological difference between the porous and reference domains is estimated by topological sensitivity; the field variables on pore boundaries are approximated as explicit functions of design variables using exterior formulations. Numerical results show that the elastic performances of components are influenced by the existence of pores. The pore-to-pore interactions are significant when pores are close by.",
        "published": "2021-08-08T21:48:06Z",
        "link": "http://arxiv.org/abs/2108.03740v3",
        "categories": [
            "cs.CE"
        ]
    },
    {
        "title": "dame-flame: A Python Library Providing Fast Interpretable Matching for   Causal Inference",
        "authors": [
            "Neha R. Gupta",
            "Vittorio Orlandi",
            "Chia-Rui Chang",
            "Tianyu Wang",
            "Marco Morucci",
            "Pritam Dey",
            "Thomas J. Howell",
            "Xian Sun",
            "Angikar Ghosal",
            "Sudeepa Roy",
            "Cynthia Rudin",
            "Alexander Volfovsky"
        ],
        "summary": "dame-flame is a Python package for performing matching for observational causal inference on datasets containing discrete covariates. This package implements the Dynamic Almost Matching Exactly (DAME) and Fast Large-Scale Almost Matching Exactly (FLAME) algorithms, which match treatment and control units on subsets of the covariates. The resulting matched groups are interpretable, because the matches are made on covariates, and high-quality, because machine learning is used to determine which covariates are important to match on. DAME solves an optimization problem that matches units on as many covariates as possible, prioritizing matches on important covariates. FLAME approximates the solution found by DAME via a much faster backward feature selection procedure. The package provides several adjustable parameters to adapt the algorithms to specific applications, and can calculate treatment effect estimates after matching. Descriptions of these parameters, details on estimating treatment effects, and further examples, can be found in the documentation at https://almost-matching-exactly.github.io/DAME-FLAME-Python-Package/",
        "published": "2021-01-06T04:38:57Z",
        "link": "http://arxiv.org/abs/2101.01867v3",
        "categories": [
            "cs.LG",
            "cs.MS"
        ]
    },
    {
        "title": "A Julia implementation of Algorithm NCL for constrained optimization",
        "authors": [
            "Ding Ma",
            "Dominique Orban",
            "Michael A. Saunders"
        ],
        "summary": "Algorithm NCL is designed for general smooth optimization problems where first and second derivatives are available, including problems whose constraints may not be linearly independent at a solution (i.e., do not satisfy the LICQ). It is equivalent to the LANCELOT augmented Lagrangian method, reformulated as a short sequence of nonlinearly constrained subproblems that can be solved efficiently by IPOPT and KNITRO, with warm starts on each subproblem. We give numerical results from a Julia implementation of Algorithm NCL on tax policy models that do not satisfy the LICQ, and on nonlinear least-squares problems and general problems from the CUTEst test set.",
        "published": "2021-01-06T17:57:44Z",
        "link": "http://arxiv.org/abs/2101.02164v1",
        "categories": [
            "math.OC",
            "cs.MS",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Number Parsing at a Gigabyte per Second",
        "authors": [
            "Daniel Lemire"
        ],
        "summary": "With disks and networks providing gigabytes per second, parsing decimal numbers from strings becomes a bottleneck. We consider the problem of parsing decimal numbers to the nearest binary floating-point value. The general problem requires variable-precision arithmetic. However, we need at most 17 digits to represent 64-bit standard floating-point numbers (IEEE 754). Thus we can represent the decimal significand with a single 64-bit word. By combining the significand and precomputed tables, we can compute the nearest floating-point number using as few as one or two 64-bit multiplications. Our implementation can be several times faster than conventional functions present in standard C libraries on modern 64-bit systems (Intel, AMD, ARM and POWER9). Our work is available as open source software used by major systems such as Apache Arrow and Yandex ClickHouse. The Go standard library has adopted a version of our approach.",
        "published": "2021-01-11T20:31:27Z",
        "link": "http://arxiv.org/abs/2101.11408v9",
        "categories": [
            "cs.DS",
            "cs.MS"
        ]
    },
    {
        "title": "Robust level-3 BLAS Inverse Iteration from the Hessenberg Matrix",
        "authors": [
            "Angelika Schwarz"
        ],
        "summary": "Inverse iteration is known to be an effective method for computing eigenvectors corresponding to simple and well-separated eigenvalues. In the non-symmetric case, the solution of shifted Hessenberg systems is a central step. Existing inverse iteration solvers approach the solution of the shifted Hessenberg systems with either RQ or LU factorizations and, once factored, solve the corresponding systems. This approach has limited level-3 BLAS potential since distinct shifts have distinct factorizations. This paper rearranges the RQ approach such that data shared between distinct shifts is exposed. Thereby the backward substitution with the triangular R factor can be expressed mostly with matrix-matrix multiplications (level-3 BLAS). The resulting algorithm computes eigenvectors in a tiled, overflow-free, and task-parallel fashion. The numerical experiments show that the new algorithm outperforms existing inverse iteration solvers for the computation of both real and complex eigenvectors.",
        "published": "2021-01-13T13:49:38Z",
        "link": "http://arxiv.org/abs/2101.05063v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "UFL Dual Spaces, a proposal",
        "authors": [
            "David A. Ham"
        ],
        "summary": "This white paper highlights current limitations in the algebraic closure Unified Form Language (UFL). UFL currently represents forms over finite element spaces, however finite element problems naturally result in objects in the dual to a finite element space, and operators mapping between primal and dual finite element spaces. This document sketches the relevant mathematical areas and proposes changes to the UFL language to support dual spaces as first class types in UFL.",
        "published": "2021-01-13T15:55:51Z",
        "link": "http://arxiv.org/abs/2101.05158v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "GPU Methodologies for Numerical Partial Differential Equations",
        "authors": [
            "Andrew Gloster"
        ],
        "summary": "In this thesis we develop techniques to efficiently solve numerical Partial Differential Equations (PDEs) using Graphical Processing Units (GPUs). Focus is put on both performance and re--usability of the methods developed, to this end a library, cuSten, for applying finite--difference stencils to numerical grids is presented herein. On top of this various batched tridiagonal and pentadiagonal matrix solvers are discussed. These have been benchmarked against the current state of the art and shown to improve performance in the solution of numerical PDEs. A variety of other benchmarks and use cases for the GPU methodologies are presented using the Cahn--Hilliard equation as a core example, but it is emphasised the methods are completely general. Finally through the application of the GPU methodologies to the Cahn--Hilliard equation new results are presented on the growth rates of the coarsened domains. In particular a statistical model is built up using batches of simulations run on GPUs from which the growth rates are extracted, it is shown that in a finite domain that the traditionally presented results of 1/3 scaling is in fact a distribution around this value. This result is discussed in conjunction with modelling via a stochastic PDE and sheds new light on the behaviour of the Cahn--Hilliard equation in finite domains.",
        "published": "2021-01-16T23:24:40Z",
        "link": "http://arxiv.org/abs/2101.06550v1",
        "categories": [
            "math.NA",
            "cs.DC",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "Acceleration of multiple precision matrix multiplication based on   multi-component floating-point arithmetic using AVX2",
        "authors": [
            "Tomonori Kouya"
        ],
        "summary": "In this paper, we report the results obtained from the acceleration of multi-binary64-type multiple precision matrix multiplication with AVX2. We target double-double (DD), triple-double (TD), and quad-double (QD) precision arithmetic designed by certain types of error-free transformation (EFT) arithmetic. Furthermore, we implement SIMDized EFT functions, which simultaneously compute with four binary64 numbers on x86_64 computing environment, and by using help of them, we also develop SIMDized DD, TD, and QD additions and multiplications. In addition, AVX2 load/store functions were adopted to efficiently speed up reading and storing matrix elements from/to memory. Owing to these combined techniques, our implemented multiple precision matrix multiplications have been accelerated more than three times compared with non-accelerated ones. Our accelerated matrix multiplication modifies the performance of parallelization with OpenMP.",
        "published": "2021-01-17T04:05:13Z",
        "link": "http://arxiv.org/abs/2101.06584v1",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "cs.PF"
        ]
    },
    {
        "title": "A bi-directional extensible interface between Lean and Mathematica",
        "authors": [
            "Robert Y. Lewis",
            "Minchao Wu"
        ],
        "summary": "We implement a user-extensible ad hoc connection between the Lean proof assistant and the computer algebra system Mathematica. By reflecting the syntax of each system in the other and providing a flexible interface for extending translation, our connection allows for the exchange of arbitrary information between the two systems.   We show how to make use of the Lean metaprogramming framework to verify certain Mathematica computations, so that the rigor of the proof assistant is not compromised. We also use Mathematica as an untrusted oracle to guide proof search in the proof assistant and interact with a Mathematica notebook from within a Lean session. In the other direction, we import and process Lean declarations from within Mathematica. The proof assistant library serves as a database of mathematical knowledge that the CAS can display and explore.",
        "published": "2021-01-17T11:33:25Z",
        "link": "http://arxiv.org/abs/2101.07758v1",
        "categories": [
            "cs.LO",
            "cs.MS"
        ]
    },
    {
        "title": "Brightening the Optical Flow through Posit Arithmetic",
        "authors": [
            "Vinay Saxena",
            "Ankitha Reddy",
            "Jonathan Neudorfer",
            "John Gustafson",
            "Sangeeth Nambiar",
            "Rainer Leupers",
            "Farhad Merchant"
        ],
        "summary": "As new technologies are invented, their commercial viability needs to be carefully examined along with their technical merits and demerits. The posit data format, proposed as a drop-in replacement for IEEE 754 float format, is one such invention that requires extensive theoretical and experimental study to identify products that can benefit from the advantages of posits for specific market segments. In this paper, we present an extensive empirical study of posit-based arithmetic vis-\\`a-vis IEEE 754 compliant arithmetic for the optical flow estimation method called Lucas-Kanade (LuKa). First, we use SoftPosit and SoftFloat format emulators to perform an empirical error analysis of the LuKa method. Our study shows that the average error in LuKa with SoftPosit is an order of magnitude lower than LuKa with SoftFloat. We then present the integration of the hardware implementation of a posit adder and multiplier in a RISC-V open-source platform. We make several recommendations, along with the analysis of LuKa in the RISC-V context, for future generation platforms incorporating posit arithmetic units.",
        "published": "2021-01-17T13:19:10Z",
        "link": "http://arxiv.org/abs/2101.06665v1",
        "categories": [
            "cs.AR",
            "cs.MS"
        ]
    },
    {
        "title": "On the efficient parallel computing of long term reliable trajectories   for the Lorenz system",
        "authors": [
            "I. Hristov",
            "R. Hristova",
            "S. Dimova",
            "P. Armyanov",
            "N. Shegunov",
            "I. Puzynin",
            "T. Puzynina",
            "Z. Sharipov",
            "Z. Tukhliev"
        ],
        "summary": "In this work we propose an efficient parallelization of multiple-precision Taylor series method with variable stepsize and fixed order. For given level of accuracy the optimal variable stepsize determines higher order of the method than in the case of optimal fixed stepsize. Although the used order of the method is greater then that in the case of fixed stepsize, and hence the computational work per step is greater, the reduced number of steps gives less overall work. Also the greater order of the method is beneficial in the sense that it increases the parallel efficiency. As a model problem we use the paradigmatic Lorenz system. With 256 CPU cores in Nestum cluster, Sofia, Bulgaria, we succeed to obtain a correct reference solution in the rather long time interval - [0,11000]. To get this solution we performed two large computations: one computation with 4566 decimal digits of precision and 5240-th order method, and second computation for verification - with 4778 decimal digits of precision and 5490-th order method.",
        "published": "2021-01-17T14:42:42Z",
        "link": "http://arxiv.org/abs/2101.06682v1",
        "categories": [
            "math.NA",
            "cs.DC",
            "cs.MS",
            "cs.NA",
            "65L05, 65Y05",
            "G.1.7; G.1.0"
        ]
    },
    {
        "title": "Accelerated Polynomial Evaluation and Differentiation at Power Series in   Multiple Double Precision",
        "authors": [
            "Jan Verschelde"
        ],
        "summary": "The problem is to evaluate a polynomial in several variables and its gradient at a power series truncated to some finite degree with multiple double precision arithmetic. To compensate for the cost overhead of multiple double precision and power series arithmetic, data parallel algorithms for general purpose graphics processing units are presented. The reverse mode of algorithmic differentiation is organized into a massively parallel computation of many convolutions and additions of truncated power series. Experimental results demonstrate that teraflop performance is obtained in deca double precision with power series truncated at degree 152. The algorithms scale well for increasing precision and increasing degrees.",
        "published": "2021-01-22T19:42:43Z",
        "link": "http://arxiv.org/abs/2101.10881v3",
        "categories": [
            "cs.MS",
            "cs.DC",
            "cs.NA",
            "cs.SC",
            "math.AG",
            "math.NA"
        ]
    },
    {
        "title": "FDApy: a Python package for functional data",
        "authors": [
            "Steven Golovkine"
        ],
        "summary": "We introduce FDApy, an open-source Python package for the analysis of functional data. The package provides tools for the representation of (multivariate) functional data defined on different dimensional domains and for functional data that is irregularly sampled. Additionally, dimension reduction techniques are implemented for multivariate and/or multidimensional functional data that are regularly or irregularly sampled. A toolbox for generating functional datasets is also provided. The documentation includes installation and usage instructions, examples on simulated and real datasets and a complete description of the API. FDApy is released under the MIT license. The code and documentation are available at https://github.com/StevenGolovkine/FDApy.",
        "published": "2021-01-26T10:07:33Z",
        "link": "http://arxiv.org/abs/2101.11003v2",
        "categories": [
            "cs.MS",
            "cs.LG",
            "stat.CO",
            "stat.ML",
            "62R10 (Primary)"
        ]
    },
    {
        "title": "Bayesian Paired-Comparison with the bpcs Package",
        "authors": [
            "David Issa Mattos",
            "Érika Martins Silva Ramos"
        ],
        "summary": "This article introduces the bpcs R package (Bayesian Paired Comparison in Stan) and the statistical models implemented in the package. This package aims to facilitate the use of Bayesian models for paired comparison data in behavioral research. Bayesian analysis of paired comparison data allows parameter estimation even in conditions where the maximum likelihood does not exist, allows easy extension of paired comparison models, provide straightforward interpretation of the results with credible intervals, have better control of type I error, have more robust evidence towards the null hypothesis, allows propagation of uncertainties, includes prior information, and perform well when handling models with many parameters and latent variables. The bpcs package provides a consistent interface for R users and several functions to evaluate the posterior distribution of all parameters, to estimate the posterior distribution of any contest between items, and to obtain the posterior distribution of the ranks. Three reanalyses of recent studies that used the frequentist Bradley-Terry model are presented. These reanalyses are conducted with the Bayesian models of the bpcs package, and all the code used to fit the models, generate the figures, and the tables are available in the online appendix.",
        "published": "2021-01-27T07:13:46Z",
        "link": "http://arxiv.org/abs/2101.11227v4",
        "categories": [
            "stat.ME",
            "cs.MS"
        ]
    },
    {
        "title": "tf.data: A Machine Learning Data Processing Framework",
        "authors": [
            "Derek G. Murray",
            "Jiri Simsa",
            "Ana Klimovic",
            "Ihor Indyk"
        ],
        "summary": "Training machine learning models requires feeding input data for models to ingest. Input pipelines for machine learning jobs are often challenging to implement efficiently as they require reading large volumes of data, applying complex transformations, and transferring data to hardware accelerators while overlapping computation and communication to achieve optimal performance. We present tf.data, a framework for building and executing efficient input pipelines for machine learning jobs. The tf.data API provides operators which can be parameterized with user-defined computation, composed, and reused across different machine learning domains. These abstractions allow users to focus on the application logic of data processing, while tf.data's runtime ensures that pipelines run efficiently.   We demonstrate that input pipeline performance is critical to the end-to-end training time of state-of-the-art machine learning models. tf.data delivers the high performance required, while avoiding the need for manual tuning of performance knobs. We show that tf.data features, such as parallelism, caching, static optimizations, and non-deterministic execution are essential for high performance. Finally, we characterize machine learning input pipelines for millions of jobs that ran in Google's fleet, showing that input data processing is highly diverse and consumes a significant fraction of job resources. Our analysis motivates future research directions, such as sharing computation across jobs and pushing data projection to the storage layer.",
        "published": "2021-01-28T17:16:46Z",
        "link": "http://arxiv.org/abs/2101.12127v2",
        "categories": [
            "cs.LG",
            "cs.MS"
        ]
    },
    {
        "title": "lrsarith: a small fixed/hybrid arithmetic C library",
        "authors": [
            "David Avis",
            "Charles Jordan"
        ],
        "summary": "We describe lrsarith which is a small fixed precision and hybrid arithmetic C library for integers and rationals that we developed for use in the lrslib library for polyhedral computation. Using a generic set of operations, a program can be compiled with either 64-bit or 128-bit (if available) fixed precision, with an extended precision library such as GMP or the built-in MP routines. A simple scheme checks for overflow and either terminates the program or, in hybrid mode, changes to a higher precision arithmetic. Implementing these arithmetics in lrslib resulted in only minimal changes to the original code. We give computational results using lrs and mplrs, vertex/facet enumeration codes in lrslib, using 64 and 128 bit fixed integer arithmetic with and without overflow checking, GMP arithmetic, lrsarith hybrid arithmetic with both GMP and MP, and FLINT hybrid arithmetic. We give a small self-contained example C program using the lrsarith package in both fixed precision and hybrid mode.",
        "published": "2021-01-29T06:40:53Z",
        "link": "http://arxiv.org/abs/2101.12425v1",
        "categories": [
            "cs.MS",
            "68-04",
            "G.4; D.m"
        ]
    },
    {
        "title": "Performance of the low-rank tensor-train SVD (TT-SVD) for large dense   tensors on modern multi-core CPUs",
        "authors": [
            "Melven Röhrig-Zöllner",
            "Jonas Thies",
            "Achim Basermann"
        ],
        "summary": "There are several factorizations of multi-dimensional tensors into lower-dimensional components, known as `tensor networks'. We consider the popular `tensor-train' (TT) format and ask: How efficiently can we compute a low-rank approximation from a full tensor on current multi-core CPUs?   Compared to sparse and dense linear algebra, kernel libraries for multi-linear algebra are rare and typically not as well optimized. Linear algebra libraries like BLAS and LAPACK may provide the required operations in principle, but often at the cost of additional data movements for rearranging memory layouts. Furthermore, these libraries are typically optimized for the compute-bound case (e.g.\\ square matrix operations) whereas low-rank tensor decompositions lead to memory bandwidth limited operations.   We propose a `tensor-train singular value decomposition' (TT-SVD) algorithm based on two building blocks: a `Q-less tall-skinny QR' factorization, and a fused tall-skinny matrix-matrix multiplication and reshape operation. We analyze the performance of the resulting TT-SVD algorithm using the Roofline performance model. In addition, we present performance results for different algorithmic variants for shared-memory as well as distributed-memory architectures. Our experiments show that commonly used TT-SVD implementations suffer severe performance penalties. We conclude that a dedicated library for tensor factorization kernels would benefit the community: Computing a low-rank approximation can be as cheap as reading the data twice from main memory. As a consequence, an implementation that achieves realistic performance will move the limit at which one has to resort to randomized methods that only process part of the data.",
        "published": "2021-01-29T22:56:55Z",
        "link": "http://arxiv.org/abs/2102.00104v3",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "15A23, 15A69, 65F99, 65Y05, 65Y20",
            "G.4; G.1.3"
        ]
    },
    {
        "title": "FastAD: Expression Template-Based C++ Library for Fast and   Memory-Efficient Automatic Differentiation",
        "authors": [
            "James Yang"
        ],
        "summary": "Automatic differentiation is a set of techniques to efficiently and accurately compute the derivative of a function represented by a computer program. Existing C++ libraries for automatic differentiation (e.g. Adept, Stan Math Library), however, exhibit large memory consumptions and runtime performance issues. This paper introduces FastAD, a new C++ template library for automatic differentiation, that overcomes all of these challenges in existing libraries by using vectorization, simpler memory management using a fully expression-template-based design, and other compile-time optimizations to remove some run-time overhead. Benchmarks show that FastAD performs 2-10 times faster than Adept and 2-19 times faster than Stan across various test cases including a few real-world examples.",
        "published": "2021-02-06T23:17:10Z",
        "link": "http://arxiv.org/abs/2102.03681v1",
        "categories": [
            "cs.MS",
            "stat.CO"
        ]
    },
    {
        "title": "Core Imaging Library -- Part I: a versatile Python framework for   tomographic imaging",
        "authors": [
            "Jakob S. Jørgensen",
            "Evelina Ametova",
            "Genoveva Burca",
            "Gemma Fardell",
            "Evangelos Papoutsellis",
            "Edoardo Pasca",
            "Kris Thielemans",
            "Martin Turner",
            "Ryan Warr",
            "William R. B. Lionheart",
            "Philip J. Withers"
        ],
        "summary": "We present the Core Imaging Library (CIL), an open-source Python framework for tomographic imaging with particular emphasis on reconstruction of challenging datasets. Conventional filtered back-projection reconstruction tends to be insufficient for highly noisy, incomplete, non-standard or multi-channel data arising for example in dynamic, spectral and in situ tomography. CIL provides an extensive modular optimisation framework for prototyping reconstruction methods including sparsity and total variation regularisation, as well as tools for loading, preprocessing and visualising tomographic data. The capabilities of CIL are demonstrated on a synchrotron example dataset and three challenging cases spanning golden-ratio neutron tomography, cone-beam X-ray laminography and positron emission tomography.",
        "published": "2021-02-08T22:26:37Z",
        "link": "http://arxiv.org/abs/2102.04560v2",
        "categories": [
            "math.OC",
            "cs.MS",
            "65K10, 65R32, 65F10"
        ]
    },
    {
        "title": "On PyTorch Implementation of Density Estimators for von Mises-Fisher and   Its Mixture",
        "authors": [
            "Minyoung Kim"
        ],
        "summary": "The von Mises-Fisher (vMF) is a well-known density model for directional random variables. The recent surge of the deep embedding methodologies for high-dimensional structured data such as images or texts, aimed at extracting salient directional information, can make the vMF model even more popular. In this article, we will review the vMF model and its mixture, provide detailed recipes of how to train the models, focusing on the maximum likelihood estimators, in Python/PyTorch. In particular, implementation of vMF typically suffers from the notorious numerical issue of the Bessel function evaluation in the density normalizer, especially when the dimensionality is high, and we address the issue using the MPMath library that supports arbitrary precision. For the mixture learning, we provide both minibatch-based large-scale SGD learning, as well as the EM algorithm which is a full batch estimator. For each estimator/methodology, we test our implementation on some synthetic data, while we also demonstrate the use case in a more realistic scenario of image clustering. Our code is publicly available in https://github.com/minyoungkim21/vmf-lib.",
        "published": "2021-02-10T09:26:56Z",
        "link": "http://arxiv.org/abs/2102.05340v1",
        "categories": [
            "cs.LG",
            "cs.MS"
        ]
    },
    {
        "title": "Core Imaging Library -- Part II: Multichannel reconstruction for dynamic   and spectral tomography",
        "authors": [
            "Evangelos Papoutsellis",
            "Evelina Ametova",
            "Claire Delplancke",
            "Gemma Fardell",
            "Jakob S. Jørgensen",
            "Edoardo Pasca",
            "Martin Turner",
            "Ryan Warr",
            "William R. B. Lionheart",
            "Philip J. Withers"
        ],
        "summary": "The newly developed Core Imaging Library (CIL) is a flexible plug and play library for tomographic imaging with a specific focus on iterative reconstruction. CIL provides building blocks for tailored regularised reconstruction algorithms and explicitly supports multichannel tomographic data. In the first part of this two-part publication, we introduced the fundamentals of CIL. This paper focuses on applications of CIL for multichannel data, e.g., dynamic and spectral. We formalise different optimisation problems for colour processing, dynamic and hyperspectral tomography and demonstrate CIL's capabilities for designing state of the art reconstruction methods through case studies and code snapshots.",
        "published": "2021-02-10T12:21:34Z",
        "link": "http://arxiv.org/abs/2102.06126v2",
        "categories": [
            "physics.med-ph",
            "cs.MS",
            "math.OC",
            "65K10, 65R32, 65F10"
        ]
    },
    {
        "title": "User manual for bch, a program for the fast computation of the   Baker-Campbell-Hausdorff and similar series",
        "authors": [
            "Harald Hofstätter"
        ],
        "summary": "This manual describes bch, an efficient program written in the C programming language for the fast computation of the Baker-Campbell-Hausdorff (BCH) and similar Lie series. The Lie series can be represented in the Lyndon basis, in the classical Hall basis, or in the right-normed basis of E.S. Chibrikov. In the Lyndon basis, which proves to be particularly efficient for this purpose, the computation of 111013 coefficients for the BCH series up to terms of degree 20 takes less than half a second on an ordinary personal computer and requires negligible 11MB of memory. Up to terms of degree 30, which is the maximum degree the program can handle, the computation of 74248451 coefficients takes 55 hours but still requires only a modest 5.5GB of memory.",
        "published": "2021-02-12T15:10:39Z",
        "link": "http://arxiv.org/abs/2102.06570v3",
        "categories": [
            "cs.MS",
            "math.RA"
        ]
    },
    {
        "title": "Optimizing Inference Performance of Transformers on CPUs",
        "authors": [
            "Dave Dice",
            "Alex Kogan"
        ],
        "summary": "The Transformer architecture revolutionized the field of natural language processing (NLP). Transformers-based models (e.g., BERT) power many important Web services, such as search, translation, question-answering, etc. While enormous research attention is paid to the training of those models, relatively little efforts are made to improve their inference performance. This paper comes to address this gap by presenting an empirical analysis of scalability and performance of inferencing a Transformer-based model on CPUs. Focusing on the highly popular BERT model, we identify key components of the Transformer architecture where the bulk of the computation happens, and propose three optimizations to speed them up. The optimizations are evaluated using the inference benchmark from HuggingFace, and are shown to achieve the speedup of up to x2.37. The considered optimizations do not require any changes to the implementation of the models nor affect their accuracy.",
        "published": "2021-02-12T17:01:35Z",
        "link": "http://arxiv.org/abs/2102.06621v3",
        "categories": [
            "cs.CL",
            "cs.AI",
            "cs.DC",
            "cs.LG",
            "cs.MS",
            "I.2.0; D.4.8; G.4"
        ]
    },
    {
        "title": "COMET: A Domain-Specific Compilation of High-Performance Computational   Chemistry",
        "authors": [
            "Erdal Mutlu",
            "Ruiqin Tian",
            "Bin Ren",
            "Sriram Krishnamoorthy",
            "Roberto Gioiosa",
            "Jacques Pienaar",
            "Gokcen Kestor"
        ],
        "summary": "The computational power increases over the past decades havegreatly enhanced the ability to simulate chemical reactions andunderstand ever more complex transformations. Tensor contractions are the fundamental computational building block of these simulations. These simulations have often been tied to one platform and restricted in generality by the interface provided to the user. The expanding prevalence of accelerators and researcher demands necessitate a more general approach which is not tied to specific hardware or requires contortion of algorithms to specific hardware platforms. In this paper we present COMET, a domain-specific programming language and compiler infrastructure for tensor contractions targeting heterogeneous accelerators. We present a system of progressive lowering through multiple layers of abstraction and optimization that achieves up to 1.98X speedup for 30 tensor contractions commonly used in computational chemistry and beyond.",
        "published": "2021-02-13T00:25:13Z",
        "link": "http://arxiv.org/abs/2102.06827v1",
        "categories": [
            "cs.MS",
            "physics.chem-ph"
        ]
    },
    {
        "title": "A computer algebra system for the study of commutativity up-to-coherent   homotopies",
        "authors": [
            "Anibal M. Medina-Mardones"
        ],
        "summary": "The Python package ComCH is a lightweight specialized computer algebra system that provides models for well known objects, the surjection and Barratt-Eccles operads, parameterizing the product structure of algebras that are commutative in a derived sense. The primary examples of such algebras treated by ComCH are the cochain complexes of spaces, for which it provides effective constructions of Steenrod cohomology operations at all prime.",
        "published": "2021-02-15T16:58:19Z",
        "link": "http://arxiv.org/abs/2102.07670v1",
        "categories": [
            "math.AT",
            "cs.MS",
            "Primary 55-04, 18M60, Secondary 55S05, 18M70, 55N31"
        ]
    },
    {
        "title": "Quasi-Monte Carlo Software",
        "authors": [
            "Sou-Cheng T. Choi",
            "Fred J. Hickernell",
            "R. Jagadeeswaran",
            "Michael J. McCourt",
            "Aleksei G. Sorokin"
        ],
        "summary": "Practitioners wishing to experience the efficiency gains from using low discrepancy sequences need correct, robust, well-written software. This article, based on our MCQMC 2020 tutorial, describes some of the better quasi-Monte Carlo (QMC) software available. We highlight the key software components required by QMC to approximate multivariate integrals or expectations of functions of vector random variables. We have combined these components in QMCPy, a Python open-source library, which we hope will draw the support of the QMC community. Here we introduce QMCPy.",
        "published": "2021-02-15T20:21:05Z",
        "link": "http://arxiv.org/abs/2102.07833v3",
        "categories": [
            "cs.MS",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "cuFINUFFT: a load-balanced GPU library for general-purpose nonuniform   FFTs",
        "authors": [
            "Yu-hsuan Shih",
            "Garrett Wright",
            "Joakim Andén",
            "Johannes Blaschke",
            "Alex H. Barnett"
        ],
        "summary": "Nonuniform fast Fourier transforms dominate the computational cost in many applications including image reconstruction and signal processing. We thus present a general-purpose GPU-based CUDA library for type 1 (nonuniform to uniform) and type 2 (uniform to nonuniform) transforms in dimensions 2 and 3, in single or double precision. It achieves high performance for a given user-requested accuracy, regardless of the distribution of nonuniform points, via cache-aware point reordering, and load-balanced blocked spreading in shared memory. At low accuracies, this gives on-GPU throughputs around $10^9$ nonuniform points per second, and (even including host-device transfer) is typically 4-10$\\times$ faster than the latest parallel CPU code FINUFFT (at 28 threads). It is competitive with two established GPU codes, being up to 90$\\times$ faster at high accuracy and/or type 1 clustered point distributions. Finally we demonstrate a 5-12$\\times$ speedup versus CPU in an X-ray diffraction 3D iterative reconstruction task at $10^{-12}$ accuracy, observing excellent multi-GPU weak scaling up to one rank per GPU.",
        "published": "2021-02-16T21:57:23Z",
        "link": "http://arxiv.org/abs/2102.08463v2",
        "categories": [
            "cs.DC",
            "cs.MS",
            "cs.NA",
            "eess.SP",
            "math.NA"
        ]
    },
    {
        "title": "Automatic Generation of Interpolants for Lattice Samplings: Part I --   Theory and Analysis",
        "authors": [
            "Joshua Horacsek",
            "Usman Alim"
        ],
        "summary": "Interpolation is a fundamental technique in scientific computing and is at the heart of many scientific visualization techniques. There is usually a trade-off between the approximation capabilities of an interpolation scheme and its evaluation efficiency. For many applications, it is important for a user to be able to navigate their data in real time. In practice, the evaluation efficiency (or speed) outweighs any incremental improvements in reconstruction fidelity. In this two-part work, we first analyze from a general standpoint the use of compact piece-wise polynomial basis functions to efficiently interpolate data that is sampled on a lattice. In the sequel, we detail how we generate efficient implementations via automatic code generation on both CPU and GPU architectures. Specifically, in this paper, we propose a general framework that can produce a fast evaluation scheme by analyzing the algebro-geometric structure of the convolution sum for a given lattice and basis function combination. We demonstrate the utility and generality of our framework by providing fast implementations of various box splines on the Body Centered and Face Centered Cubic lattices, as well as some non-separable box splines on the Cartesian lattice. We also provide fast implementations for certain Voronoi splines that have not yet appeared in the literature. Finally, we demonstrate that this framework may also be used for non-Cartesian lattices in 4D.",
        "published": "2021-02-17T00:45:23Z",
        "link": "http://arxiv.org/abs/2102.08514v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "Automatic Generation of Interpolants for Lattice Samplings: Part II --   Implementation and Code Generation",
        "authors": [
            "Joshua Horacsek",
            "Usman Alim"
        ],
        "summary": "In the prequel to this paper, we presented a systematic framework for processing spline spaces. In this paper, we take the results of that framework and provide a code generation pipeline that automatically generates efficient implementations of spline spaces. We decompose the final algorithm from Part I and translate the resulting components into LLVM-IR (a low level language that can be compiled to various targets/architectures). Our design provides a handful of parameters for a practitioner to tune - this is one of the avenues that provides us with the flexibility to target many different computational architectures and tune performance on those architectures. We also provide an evaluation of the effect of the different parameters on performance.",
        "published": "2021-02-17T00:55:19Z",
        "link": "http://arxiv.org/abs/2102.08518v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "Fast Graph Learning with Unique Optimal Solutions",
        "authors": [
            "Sami Abu-El-Haija",
            "Valentino Crespi",
            "Greg Ver Steeg",
            "Aram Galstyan"
        ],
        "summary": "We consider two popular Graph Representation Learning (GRL) methods: message passing for node classification and network embedding for link prediction. For each, we pick a popular model that we: (i) linearize and (ii) and switch its training objective to Frobenius norm error minimization. These simplifications can cast the training into finding the optimal parameters in closed-form. We program in TensorFlow a functional form of Truncated Singular Value Decomposition (SVD), such that, we could decompose a dense matrix $\\mathbf{M}$, without explicitly computing $\\mathbf{M}$. We achieve competitive performance on popular GRL tasks while providing orders of magnitude speedup. We open-source our code at http://github.com/samihaija/tf-fsvd",
        "published": "2021-02-17T02:00:07Z",
        "link": "http://arxiv.org/abs/2102.08530v4",
        "categories": [
            "cs.LG",
            "cs.MS",
            "cs.SI"
        ]
    },
    {
        "title": "Using Jupyter for reproducible scientific workflows",
        "authors": [
            "Marijan Beg",
            "Juliette Taka",
            "Thomas Kluyver",
            "Alexander Konovalov",
            "Min Ragan-Kelley",
            "Nicolas M. Thiéry",
            "Hans Fangohr"
        ],
        "summary": "Literate computing has emerged as an important tool for computational studies and open science, with growing folklore of best practices. In this work, we report two case studies - one in computational magnetism and another in computational mathematics - where domain-specific software was exposed to the Jupyter environment. This enables high-level control of simulations and computation, interactive exploration of computational results, batch processing on HPC resources, and reproducible workflow documentation in Jupyter notebooks. In the first study, Ubermag drives existing computational micromagnetics software through a domain-specific language embedded in Python. In the second study, a dedicated Jupyter kernel interfaces with the GAP system for computational discrete algebra and its dedicated programming language. In light of these case studies, we discuss the benefits of this approach, including progress toward more reproducible and reusable research results and outputs, notably through the use of infrastructure such as JupyterHub and Binder.",
        "published": "2021-02-18T14:20:15Z",
        "link": "http://arxiv.org/abs/2102.09562v1",
        "categories": [
            "cs.MS",
            "cs.NA",
            "math.NA",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Semi-analytic integration for a parallel space-time boundary element   method modeling the heat equation",
        "authors": [
            "Jan Zapletal",
            "Raphael Watschinger",
            "Günther Of",
            "Michal Merta"
        ],
        "summary": "The presented paper concentrates on the boundary element method (BEM) for the heat equation in three spatial dimensions. In particular, we deal with tensor product space-time meshes allowing for quadrature schemes analytic in time and numerical in space. The spatial integrals can be treated by standard BEM techniques known from three dimensional stationary problems. The contribution of the paper is twofold. First, we provide temporal antiderivatives of the heat kernel necessary for the assembly of BEM matrices and the evaluation of the representation formula. Secondly, the presented approach has been implemented in a publicly available library besthea allowing researchers to reuse the formulae and BEM routines straightaway. The results are validated by numerical experiments in an HPC environment.",
        "published": "2021-02-19T08:54:43Z",
        "link": "http://arxiv.org/abs/2102.09811v2",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "65N38, 35K05, 65Y05"
        ]
    },
    {
        "title": "An Empirical Analysis of the R Package Ecosystem",
        "authors": [
            "Ethan Bommarito",
            "Michael J Bommarito II"
        ],
        "summary": "In this research, we present a comprehensive, longitudinal empirical summary of the R package ecosystem, including not just CRAN, but also Bioconductor and GitHub. We analyze more than 25,000 packages, 150,000 releases, and 15 million files across two decades, providing comprehensive counts and trends for common metrics across packages, releases, authors, licenses, and other important metadata. We find that the historical growth of the ecosystem has been robust under all measures, with a compound annual growth rate of 29% for active packages, 28% for new releases, and 26% for active maintainers. As with many similar social systems, we find a number of highly right-skewed distributions with practical implications, including the distribution of releases per package, packages and releases per author or maintainer, package and maintainer dependency in-degree, and size per package and release. For example, the top five packages are imported by nearly 25% of all packages, and the top ten maintainers support packages that are imported by over half of all packages. We also highlight the dynamic nature of the ecosystem, recording both dramatic acceleration and notable deceleration in the growth of R. From a licensing perspective, we find a notable majority of packages are distributed under copyleft licensing or omit licensing information entirely. The data, methods, and calculations herein provide an anchor for public discourse and industry decisions related to R and CRAN, serving as a foundation for future research on the R software ecosystem and \"data science\" more broadly.",
        "published": "2021-02-19T12:55:18Z",
        "link": "http://arxiv.org/abs/2102.09904v1",
        "categories": [
            "cs.MS",
            "cs.CY",
            "cs.SE",
            "physics.soc-ph"
        ]
    },
    {
        "title": "Event-Based Automatic Differentiation of OpenMP with OpDiLib",
        "authors": [
            "Johannes Blühdorn",
            "Max Sagebaum",
            "Nicolas R. Gauger"
        ],
        "summary": "We present the new software OpDiLib, a universal add-on for classical operator overloading AD tools that enables the automatic differentiation (AD) of OpenMP parallelized code. With it, we establish support for OpenMP features in a reverse mode operator overloading AD tool to an extent that was previously only reported on in source transformation tools. We achieve this with an event-based implementation ansatz that is unprecedented in AD. Combined with modern OpenMP features around OMPT, we demonstrate how it can be used to achieve differentiation without any additional modifications of the source code; neither do we impose a priori restrictions on the data access patterns, which makes OpDiLib highly applicable. For further performance optimizations, restrictions like atomic updates on adjoint variables can be lifted in a fine-grained manner. OpDiLib can also be applied in a semi-automatic fashion via a macro interface, which supports compilers that do not implement OMPT. We demonstrate the applicability of OpDiLib for a pure operator overloading approach in a hybrid parallel environment. We quantify the cost of atomic updates on adjoint variables and showcase the speedup and scaling that can be achieved with the different configurations of OpDiLib in both the forward and the reverse pass.",
        "published": "2021-02-23T09:22:04Z",
        "link": "http://arxiv.org/abs/2102.11572v3",
        "categories": [
            "cs.MS",
            "D.1.3; D.2.13; G.1.4; G.4"
        ]
    },
    {
        "title": "NonlinearSchrodinger: Higher-Order Algorithms and Darboux   Transformations for Nonlinear Schrödinger Equations",
        "authors": [
            "Omar A. Ashour"
        ],
        "summary": "NonlinearSchrodinger.jl is a Julia package with a simple interface for studying solutions of nonlinear Schr\\\"odinger equations (NLSEs). In approximately ten lines of code, one can perform a simulation of the cubic NLSE using one of 32 algorithms, including symplectic and Runge-Kutta-Nystr\\\"om integrators up to eighth order. Furthermore, it is possible to compute analytical solutions via a numerical implementation of the Darboux transformation for extended NLSEs up to fifth order, with an equally simple interface. In what follows, we review the fundamentals of solving this class of equations numerically and analytically, discuss the implementation, and provide several examples.",
        "published": "2021-02-27T22:21:36Z",
        "link": "http://arxiv.org/abs/2103.14469v1",
        "categories": [
            "physics.comp-ph",
            "cs.MS",
            "cs.NA",
            "math.NA",
            "nlin.SI"
        ]
    },
    {
        "title": "A Difference-of-Convex Cutting Plane Algorithm for Mixed-Binary Linear   Program",
        "authors": [
            "Yi-Shuai Niu",
            "Yu You"
        ],
        "summary": "In this paper, we propose a cutting plane algorithm based on DC (Difference-of-Convex) programming and DC cut for globally solving Mixed-Binary Linear Program (MBLP). We first use a classical DC programming formulation via the exact penalization to formulate MBLP as a DC program, which can be solved by DCA algorithm. Then, we focus on the construction of DC cuts, which serves either as a local cut (namely type-I DC cut) at feasible local minimizer of MBLP, or as a global cut (namely type-II DC cut) at infeasible local minimizer of MBLP if some particular assumptions are verified. Otherwise, the constructibility of DC cut is still unclear, and we propose to use classical global cuts (such as the Lift-and-Project cut) instead. Combining DC cut and classical global cuts, a cutting plane algorithm, namely DCCUT, is established for globally solving MBLP. The convergence theorem of DCCUT is proved. Restarting DCA in DCCUT helps to quickly update the upper bound solution and to introduce more DC cuts for lower bound improvement. A variant of DCCUT by introducing more classical global cuts in each iteration is proposed, and parallel versions of DCCUT and its variant are also designed which use the power of multiple processors for better performance. Numerical simulations of DCCUT type algorithms comparing with the classical cutting plane algorithm using Lift-and-Project cuts are reported. Tests on some specific samples and the MIPLIB 2017 benchmark dataset demonstrate the benefits of DC cut and good performance of DCCUT algorithms.",
        "published": "2021-03-01T03:08:45Z",
        "link": "http://arxiv.org/abs/2103.00717v1",
        "categories": [
            "math.OC",
            "cs.MS",
            "90C11, 90C09, 90C10, 90C26, 90C30"
        ]
    },
    {
        "title": "TSSOS: a Julia library to exploit sparsity for large-scale polynomial   optimization",
        "authors": [
            "Victor Magron",
            "Jie Wang"
        ],
        "summary": "The Julia library TSSOS aims at helping polynomial optimizers to solve large-scale problems with sparse input data. The underlying algorithmic framework is based on exploiting correlative and term sparsity to obtain a new moment-SOS hierarchy involving potentially much smaller positive semidefinite matrices. TSSOS can be applied to numerous problems ranging from power networks to eigenvalue and trace optimization of noncommutative polynomials, involving up to tens of thousands of variables and constraints.",
        "published": "2021-03-01T11:09:40Z",
        "link": "http://arxiv.org/abs/2103.00915v1",
        "categories": [
            "math.OC",
            "cs.MS"
        ]
    },
    {
        "title": "An open-source framework for ExpFinder integrating $N$-gram Vector Space   Model and $μ$CO-HITS",
        "authors": [
            "Hung Du",
            "Yong-Bin Kang"
        ],
        "summary": "Finding experts drives successful collaborations and high-quality product development in academic and research domains. To contribute to the expert finding research community, we have developed ExpFinder which is a novel ensemble model for expert finding by integrating an $N$-gram vector space model ($n$VSM) and a graph-based model ($\\mu$CO-HITS). This paper provides descriptions of ExpFinder's architecture, key components, functionalities, and illustrative examples. ExpFinder is an effective and competitive model for expert finding, significantly outperforming a number of expert finding models.",
        "published": "2021-03-01T11:14:01Z",
        "link": "http://arxiv.org/abs/2103.00917v2",
        "categories": [
            "cs.IR",
            "cs.MS",
            "cs.SE"
        ]
    },
    {
        "title": "Machine Learning using Stata/Python",
        "authors": [
            "Giovanni Cerulli"
        ],
        "summary": "We present two related Stata modules, r_ml_stata and c_ml_stata, for fitting popular Machine Learning (ML) methods both in regression and classification settings. Using the recent Stata/Python integration platform (sfi) of Stata 16, these commands provide hyper-parameters' optimal tuning via K-fold cross-validation using greed search. More specifically, they make use of the Python Scikit-learn API to carry out both cross-validation and outcome/label prediction.",
        "published": "2021-03-03T10:31:44Z",
        "link": "http://arxiv.org/abs/2103.03122v1",
        "categories": [
            "stat.CO",
            "cs.LG",
            "cs.MS"
        ]
    },
    {
        "title": "Puiseux Series and Algebraic Solutions of First Order Autonomous AODEs   -- A MAPLE Package",
        "authors": [
            "Francois Boulier",
            "Jose Cano",
            "Sebastian Falkensteiner",
            "Rafael Sendra"
        ],
        "summary": "There exist several methods for computing exact solutions of algebraic differential equations. Most of the methods, however, do not ensure existence and uniqueness of the solutions and might fail after several steps, or are restricted to linear equations. The authors have presented in previous works a method to overcome this problem for autonomous first order algebraic ordinary differential equations and formal Puiseux series solutions and algebraic solutions. In the first case, all solutions can uniquely be represented by a sufficiently large truncation and in the latter case by its minimal polynomial. The main contribution of this paper is the implementation, in a MAPLE-package named FirstOrderSolve, of the algorithmic ideas presented therein. More precisely, all formal Puiseux series and algebraic solutions, including the generic and singular solutions, are computed and described uniquely. The computation strategy is to reduce the given differential equation to a simpler one by using local parametrizations and the already known degree bounds.",
        "published": "2021-03-05T13:20:47Z",
        "link": "http://arxiv.org/abs/2103.03646v1",
        "categories": [
            "cs.MS",
            "cs.SC",
            "34-04"
        ]
    },
    {
        "title": "GraphMineSuite: Enabling High-Performance and Programmable Graph Mining   Algorithms with Set Algebra",
        "authors": [
            "Maciej Besta",
            "Zur Vonarburg-Shmaria",
            "Yannick Schaffner",
            "Leonardo Schwarz",
            "Grzegorz Kwasniewski",
            "Lukas Gianinazzi",
            "Jakub Beranek",
            "Kacper Janda",
            "Tobias Holenstein",
            "Sebastian Leisinger",
            "Peter Tatkowski",
            "Esref Ozdemir",
            "Adrian Balla",
            "Marcin Copik",
            "Philipp Lindenberger",
            "Pavel Kalvoda",
            "Marek Konieczny",
            "Onur Mutlu",
            "Torsten Hoefler"
        ],
        "summary": "We propose GraphMineSuite (GMS): the first benchmarking suite for graph mining that facilitates evaluating and constructing high-performance graph mining algorithms. First, GMS comes with a benchmark specification based on extensive literature review, prescribing representative problems, algorithms, and datasets. Second, GMS offers a carefully designed software platform for seamless testing of different fine-grained elements of graph mining algorithms, such as graph representations or algorithm subroutines. The platform includes parallel implementations of more than 40 considered baselines, and it facilitates developing complex and fast mining algorithms. High modularity is possible by harnessing set algebra operations such as set intersection and difference, which enables breaking complex graph mining algorithms into simple building blocks that can be separately experimented with. GMS is supported with a broad concurrency analysis for portability in performance insights, and a novel performance metric to assess the throughput of graph mining algorithms, enabling more insightful evaluation. As use cases, we harness GMS to rapidly redesign and accelerate state-of-the-art baselines of core graph mining problems: degeneracy reordering (by up to >2x), maximal clique listing (by up to >9x), k-clique listing (by 1.1x), and subgraph isomorphism (by up to 2.5x), also obtaining better theoretical performance bounds.",
        "published": "2021-03-05T13:26:18Z",
        "link": "http://arxiv.org/abs/2103.03653v1",
        "categories": [
            "cs.DC",
            "cs.CV",
            "cs.DS",
            "cs.MS",
            "cs.PF"
        ]
    },
    {
        "title": "Quasi-structured quadrilateral meshing in Gmsh -- a robust pipeline for   complex CAD models",
        "authors": [
            "Maxence Reberol",
            "Christos Georgiadis",
            "Jean-François Remacle"
        ],
        "summary": "We propose an end-to-end pipeline to robustly generate high-quality quadrilateral meshes for complex CAD models. An initial quad-dominant mesh is generated with frontal point insertion guided by a locally integrable cross field and a scalar size map adapted to the small CAD features. After triangle combination and midpoint-subdivision into an all-quadrilateral mesh, the topology of the mesh is modified to reduce the number of irregular vertices. The idea is to preserve the irregular vertices matching cross-field singularities and to eliminate the others. The topological modifications are either local and based on disk quadrangulations, or more global with the remeshing of patches of quads according to predefined patterns. Validity of the quad mesh is guaranteed by monitoring element quality during all operations and reverting the changes when necessary. Advantages of our approach include robustness, strict respect of the CAD features and support for user-prescribed size constraints. The quad mesher, which is available in Gmsh, is validated and illustrated on two datasets of CAD models.",
        "published": "2021-03-08T10:23:55Z",
        "link": "http://arxiv.org/abs/2103.04652v1",
        "categories": [
            "cs.CE",
            "cs.CG",
            "cs.MS"
        ]
    },
    {
        "title": "ModelingToolkit: A Composable Graph Transformation System For   Equation-Based Modeling",
        "authors": [
            "Yingbo Ma",
            "Shashi Gowda",
            "Ranjan Anantharaman",
            "Chris Laughman",
            "Viral Shah",
            "Chris Rackauckas"
        ],
        "summary": "Getting good performance out of numerical equation solvers requires that the user has provided stable and efficient functions representing their model. However, users should not be trusted to write good code. In this manuscript we describe ModelingToolkit (MTK), a symbolic equation-based modeling system which allows for composable transformations to generate stable, efficient, and parallelized model implementations. MTK blurs the lines of traditional symbolic computing by acting directly on a user's numerical code. We show the ability to apply graph algorithms for automatically parallelizing and performing index reduction on code written for differential-algebraic equation (DAE) solvers, \"fixing\" the performance and stability of the model without requiring any changes to on the user's part. We demonstrate how composable model transformations can be combined with automated data-driven surrogate generation techniques, allowing machine learning methods to generate accelerated approximate models within an acausal modeling framework. These reduced models are shown to outperform the Dymola Modelica compiler on an HVAC model by 590x at 3\\% error. Together, this demonstrates MTK as a system for bringing the latest research in graph transformations directly to modeling applications.",
        "published": "2021-03-09T06:31:24Z",
        "link": "http://arxiv.org/abs/2103.05244v3",
        "categories": [
            "cs.MS",
            "cs.SC",
            "cs.SE"
        ]
    },
    {
        "title": "Exploiting Asynchronous Priority Scheduling in Parallel Eikonal Solvers",
        "authors": [
            "Ian Henriksen",
            "Bozhi You",
            "Keshav Pingali"
        ],
        "summary": "Numerical solutions to the Eikonal equation are computed using variants of the fast marching method, the fast sweeping method, and the fast iterative method. In this paper, we provide a unified view of these algorithms that highlights their similarities and suggests a wider class of Eikonal solvers. We then use this framework to justify applying concurrent priority scheduling techniques to Eikonal solvers. We demonstrate that doing so results in good parallel performance for a problem from seismology. We explain why existing Eikonal solvers may produce different results despite using the same differencing scheme and demonstrate techniques to address these discrepancies. These techniques allow us to obtain deterministic output from our asynchronous fine-grained parallel Eikonal solver.",
        "published": "2021-03-09T19:58:10Z",
        "link": "http://arxiv.org/abs/2103.05694v1",
        "categories": [
            "cs.DC",
            "cs.MS",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "XAMG: A library for solving linear systems with multiple right-hand side   vectors",
        "authors": [
            "Boris Krasnopolsky",
            "Alexey Medvedev"
        ],
        "summary": "This paper presents the XAMG library for solving large sparse systems of linear algebraic equations with multiple right-hand side vectors. The library specializes but is not limited to the solution of linear systems obtained from the discretization of elliptic differential equations. A corresponding set of numerical methods includes Krylov subspace, algebraic multigrid, Jacobi, Gauss-Seidel, and Chebyshev iterative methods. The parallelization is implemented with MPI+POSIX shared memory hybrid programming model, which introduces a three-level hierarchical decomposition using the corresponding per-level synchronization and communication primitives. The code contains a number of optimizations, including the multilevel data segmentation, compression of indices, mixed-precision floating-point calculations, vector status flags, and others. The XAMG library uses the program code of the well-known hypre library to construct the multigrid matrix hierarchy. The XAMG's own implementation for the solve phase of the iterative methods provides up to a twofold speedup compared to hypre for the tests performed. Additionally, XAMG provides extended functionality to solve systems with multiple right-hand side vectors.",
        "published": "2021-03-12T14:54:09Z",
        "link": "http://arxiv.org/abs/2103.07329v1",
        "categories": [
            "cs.MS",
            "cs.DC",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "An open-source ABAQUS implementation of the scaled boundary finite   element method to study interfacial problems using polyhedral meshes",
        "authors": [
            "Shukai Ya",
            "Sascha Eisenträger",
            "Chongmin Song",
            "Jianbo Li"
        ],
        "summary": "The scaled boundary finite element method (SBFEM) is capable of generating polyhedral elements with an arbitrary number of surfaces. This salient feature significantly alleviates the meshing burden being a bottleneck in the analysis pipeline in the standard finite element method (FEM). In this paper, we implement polyhedral elements based on the SBFEM into the commercial finite element software ABAQUS. To this end, user elements are provided through the user subroutine UEL. Detailed explanations regarding the data structures and implementational aspects of the procedures are given. The focus of the current implementation is on interfacial problems and therefore, element-based surfaces are created on polyhedral user elements to establish interactions. This is achieved by an overlay of standard finite elements with negligible stiffness, provided in the ABAQUS element library, with polyhedral user elements. By means of several numerical examples, the advantages of polyhedral elements regarding the treatment of non-matching interfaces and automatic mesh generation are clearly demonstrated. Thus, the performance of ABAQUS for problems involving interfaces is augmented based on the availability of polyhedral meshes. Due to the implementation of polyhedral user elements, ABAQUS can directly handle complex geometries given in the form of digital images or stereolithography (STL) files. In order to facilitate the use of the proposed approach, the code of the UEL is published open-source and can be downloaded from https://github.com/ShukaiYa/SBFEM-UEL.",
        "published": "2021-03-16T03:19:41Z",
        "link": "http://arxiv.org/abs/2103.09663v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "SymPKF: a symbolic and computational toolbox for the design of   parametric Kalman filter dynamics",
        "authors": [
            "Olivier Pannekoucke",
            "Philippe Arbogast"
        ],
        "summary": "Recent researches in data assimilation lead to the introduction of the parametric Kalman filter (PKF): an implementation of the Kalman filter, where the covariance matrices are approximated by a parameterized covariance model. In the PKF, the dynamics of the covariance during the forecast step relies on the prediction of the covariance parameters. Hence, the design of the parameter dynamics is crucial while it can be tedious to do this by hand. This contribution introduces a python package, SymPKF, able to compute PKF dynamics for univariate statistics and when the covariance model is parameterized from the variance and the local anisotropy of the correlations. The ability of SymPKF to produce the PKF dynamics is shown on a non-linear diffusive advection (Burgers equation) over a 1D domain and the linear advection over a 2D domain. The computation of the PKF dynamics is performed at a symbolic level, but an automatic code generator is also introduced to perform numerical simulations. A final multivariate example illustrates the potential of SymPKF to go beyond the univariate case.",
        "published": "2021-03-16T17:56:13Z",
        "link": "http://arxiv.org/abs/2103.09226v2",
        "categories": [
            "physics.data-an",
            "cs.MS",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Hessian Chain Bracketing",
        "authors": [
            "Uwe Naumann",
            "Shubhaditya Burela"
        ],
        "summary": "Second derivatives of mathematical models for real-world phenomena are fundamental ingredients of a wide range of numerical simulation methods including parameter sensitivity analysis, uncertainty quantification, nonlinear optimization and model calibration. The evaluation of such Hessians often dominates the overall computational effort. The combinatorial {\\sc Hessian Accumulation} problem aiming to minimize the number of floating-point operations required for the computation of a Hessian turns out to be NP-complete. We propose a dynamic programming formulation for the solution of {\\sc Hessian Accumulation} over a sub-search space. This approach yields improvements by factors of ten and higher over the state of the art based on second-order tangent and adjoint algorithmic differentiation.",
        "published": "2021-03-17T07:25:24Z",
        "link": "http://arxiv.org/abs/2103.09480v2",
        "categories": [
            "cs.MS",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Porting a sparse linear algebra math library to Intel GPUs",
        "authors": [
            "Yuhsiang M. Tsai",
            "Terry Cojean",
            "Hartwig Anzt"
        ],
        "summary": "With the announcement that the Aurora Supercomputer will be composed of general purpose Intel CPUs complemented by discrete high performance Intel GPUs, and the deployment of the oneAPI ecosystem, Intel has committed to enter the arena of discrete high performance GPUs. A central requirement for the scientific computing community is the availability of production-ready software stacks and a glimpse of the performance they can expect to see on Intel high performance GPUs. In this paper, we present the first platform-portable open source math library supporting Intel GPUs via the DPC++ programming environment. We also benchmark some of the developed sparse linear algebra functionality on different Intel GPUs to assess the efficiency of the DPC++ programming ecosystem to translate raw performance into application performance. Aside from quantifying the efficiency within the hardware-specific roofline model, we also compare against routines providing the same functionality that ship with Intel's oneMKL vendor library.",
        "published": "2021-03-18T09:44:17Z",
        "link": "http://arxiv.org/abs/2103.10116v1",
        "categories": [
            "cs.DC",
            "cs.MS",
            "cs.PF"
        ]
    },
    {
        "title": "FEniCS-preCICE: Coupling FEniCS to other Simulation Software",
        "authors": [
            "Benjamin Rodenberg",
            "Ishaan Desai",
            "Richard Hertrich",
            "Alexander Jaust",
            "Benjamin Uekermann"
        ],
        "summary": "The new software FEniCS-preCICE is a middle software layer, sitting in between the existing finite-element library FEniCS and the coupling library preCICE. The middle layer simplifies coupling (existing) FEniCS application codes to other simulation software via preCICE. To this end, FEniCS-preCICE converts between FEniCS and preCICE mesh and data structures, provides easy-to-use coupling conditions, and manages data checkpointing for implicit coupling. The new software is a library itself and follows a FEniCS-native style. Only a few lines of additional code are necessary to prepare a FEniCS application code for coupling. We illustrate the functionality of FEniCS-preCICE by two examples: a FEniCS heat conduction code coupled to OpenFOAM and a FEniCS linear elasticity code coupled to SU2. The results of both scenarios are compared with other simulation software showing good agreement.",
        "published": "2021-03-20T14:51:46Z",
        "link": "http://arxiv.org/abs/2103.11191v2",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "Understanding performance variability in standard and pipelined parallel   Krylov solvers",
        "authors": [
            "Hannah Morgan",
            "Patrick Sanan",
            "Matthew G. Knepley",
            "Richard Tran Mills"
        ],
        "summary": "In this work, we collect data from runs of Krylov subspace methods and pipelined Krylov algorithms in an effort to understand and model the impact of machine noise and other sources of variability on performance. We find large variability of Krylov iterations between compute nodes for standard methods that is reduced in pipelined algorithms, directly supporting conjecture, as well as large variation between statistical distributions of runtimes across iterations. Based on these results, we improve upon a previously introduced nondeterministic performance model by allowing iterations to fluctuate over time. We present our data from runs of various Krylov algorithms across multiple platforms as well as our updated non-stationary model that provides good agreement with observations. We also suggest how it can be used as a predictive tool.",
        "published": "2021-03-21T16:27:51Z",
        "link": "http://arxiv.org/abs/2103.12067v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "A Succinct Multivariate Lazy Multivariate Tower AD for Weil Algebra   Computation",
        "authors": [
            "Hiromi Ishii"
        ],
        "summary": "We propose a functional implementation of \\emph{Multivariate Tower Automatic Differentiation}. Our implementation is intended to be used in implementing $C^\\infty$-structure computation of an arbitrary Weil algebra, which we discussed in the previous work.",
        "published": "2021-03-22T06:54:32Z",
        "link": "http://arxiv.org/abs/2103.11615v2",
        "categories": [
            "cs.SC",
            "cs.MS",
            "cs.NA",
            "math.DG",
            "math.NA"
        ]
    },
    {
        "title": "Non-invasive multigrid for semi-structured grids",
        "authors": [
            "Matthias Mayr",
            "Luc Berger-Vergiat",
            "Peter Ohm",
            "Raymond S. Tuminaro"
        ],
        "summary": "Multigrid solvers for hierarchical hybrid grids (HHG) have been proposed to promote the efficient utilization of high performance computer architectures. These HHG meshes are constructed by uniformly refining a relatively coarse fully unstructured mesh. While HHG meshes provide some flexibility for unstructured applications, most multigrid calculations can be accomplished using efficient structured grid ideas and kernels. This paper focuses on generalizing the HHG idea so that it is applicable to a broader community of computational scientists, and so that it is easier for existing applications to leverage structured multigrid components. Specifically, we adapt the structured multigrid methodology to significantly more complex semi-structured meshes. Further, we illustrate how mature applications might adopt a semi-structured solver in a relatively non-invasive fashion. To do this, we propose a formal mathematical framework for describing the semi-structured solver. This formalism allows us to precisely define the associated multigrid method and to show its relationship to a more traditional multigrid solver. Additionally, the mathematical framework clarifies the associated software design and implementation. Numerical experiments highlight the relationship of the new solver with classical multigrid. We also demonstrate the generality and potential performance gains associated with this type of semi-structured multigrid.",
        "published": "2021-03-22T16:06:32Z",
        "link": "http://arxiv.org/abs/2103.11962v1",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "Kokkos Kernels: Performance Portable Sparse/Dense Linear Algebra and   Graph Kernels",
        "authors": [
            "Sivasankaran Rajamanickam",
            "Seher Acer",
            "Luc Berger-Vergiat",
            "Vinh Dang",
            "Nathan Ellingwood",
            "Evan Harvey",
            "Brian Kelley",
            "Christian R. Trott",
            "Jeremiah Wilke",
            "Ichitaro Yamazaki"
        ],
        "summary": "As hardware architectures are evolving in the push towards exascale, developing Computational Science and Engineering (CSE) applications depend on performance portable approaches for sustainable software development. This paper describes one aspect of performance portability with respect to developing a portable library of kernels that serve the needs of several CSE applications and software frameworks. We describe Kokkos Kernels, a library of kernels for sparse linear algebra, dense linear algebra and graph kernels. We describe the design principles of such a library and demonstrate portable performance of the library using some selected kernels. Specifically, we demonstrate the performance of four sparse kernels, three dense batched kernels, two graph kernels and one team level algorithm.",
        "published": "2021-03-22T16:36:12Z",
        "link": "http://arxiv.org/abs/2103.11991v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "A Massively Parallel Time-Domain Coupled Electrodynamics-Micromagnetics   Solver",
        "authors": [
            "Zhi Yao",
            "Revathi Jambunathan",
            "Yadong Zeng",
            "Andrew Nonaka"
        ],
        "summary": "We present a new, high-performance coupled electrodynamics-micromagnetics solver for full physical modeling of signals in microelectronic circuitry. The overall strategy couples a finite-difference time-domain (FDTD) approach for Maxwell's equations to a magnetization model described by the Landau-Lifshitz-Gilbert (LLG) equation. The algorithm is implemented in the Exascale Computing Project software framework, AMReX, which provides effective scalability on manycore and GPU-based supercomputing architectures. Furthermore, the code leverages ongoing developments of the Exascale Application Code, WarpX, primarily developed for plasma wakefield accelerator modeling. Our novel temporal coupling scheme provides second-order accuracy in space and time by combining the integration steps for the magnetic field and magnetization into an iterative sub-step that includes a trapezoidal discretization for the magnetization. The performance of the algorithm is demonstrated by the excellent scaling results on NERSC multicore and GPU systems, with a significant (59x) speedup on the GPU using a node-by-node comparison. We demonstrate the utility of our code by performing simulations of an electromagnetic waveguide and a magnetically tunable filter.",
        "published": "2021-03-23T20:10:47Z",
        "link": "http://arxiv.org/abs/2103.12819v1",
        "categories": [
            "physics.comp-ph",
            "cs.MS",
            "physics.app-ph",
            "35-04, 35Q60, 35Q61, 78-04, 78-10, 78M20, 78A50"
        ]
    },
    {
        "title": "The landscape of software for tensor computations",
        "authors": [
            "Christos Psarras",
            "Lars Karlsson",
            "Jiajia Li",
            "Paolo Bientinesi"
        ],
        "summary": "Tensors (also commonly seen as multi-linear operators or as multi-dimensional arrays) are ubiquitous in scientific computing and in data science, and so are the software efforts for tensor operations. Particularly in recent years, we have observed an explosion in libraries, compilers, packages, and toolboxes; unfortunately these efforts are very much scattered among the different scientific domains, and inevitably suffer from replication, suboptimal implementations, and in many cases, limited visibility. As a first step towards countering these inefficiencies, here we survey and loosely classify software packages related to tensor computations. Our aim is to assemble a comprehensive and up-to-date snapshot of the tensor software landscape, with the intention of helping both users and developers. Aware of the difficulties inherent in any multi-discipline survey, we very much welcome the reader's help in amending and expanding our software list, which currently features 80 projects.",
        "published": "2021-03-25T11:13:27Z",
        "link": "http://arxiv.org/abs/2103.13756v3",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "Automatic differentiation for Riemannian optimization on low-rank matrix   and tensor-train manifolds",
        "authors": [
            "Alexander Novikov",
            "Maxim Rakhuba",
            "Ivan Oseledets"
        ],
        "summary": "In scientific computing and machine learning applications, matrices and more general multidimensional arrays (tensors) can often be approximated with the help of low-rank decompositions. Since matrices and tensors of fixed rank form smooth Riemannian manifolds, one of the popular tools for finding low-rank approximations is to use Riemannian optimization. Nevertheless, efficient implementation of Riemannian gradients and Hessians, required in Riemannian optimization algorithms, can be a nontrivial task in practice. Moreover, in some cases, analytic formulas are not even available. In this paper, we build upon automatic differentiation and propose a method that, given an implementation of the function to be minimized, efficiently computes Riemannian gradients and matrix-by-vector products between an approximate Riemannian Hessian and a given vector.",
        "published": "2021-03-27T19:56:00Z",
        "link": "http://arxiv.org/abs/2103.14974v2",
        "categories": [
            "math.OC",
            "cs.LG",
            "cs.MS",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Mathematics of Digital Hyperspace",
        "authors": [
            "Jeremy Kepner",
            "Timothy Davis",
            "Vijay Gadepally",
            "Hayden Jananthan",
            "Lauren Milechin"
        ],
        "summary": "Social media, e-commerce, streaming video, e-mail, cloud documents, web pages, traffic flows, and network packets fill vast digital lakes, rivers, and oceans that we each navigate daily. This digital hyperspace is an amorphous flow of data supported by continuous streams that stretch standard concepts of type and dimension. The unstructured data of digital hyperspace can be elegantly represented, traversed, and transformed via the mathematics of hypergraphs, hypersparse matrices, and associative array algebra. This paper explores a novel mathematical concept, the semilink, that combines pairs of semirings to provide the essential operations for graph analytics, database operations, and machine learning. The GraphBLAS standard currently supports hypergraphs, hypersparse matrices, the mathematics required for semilinks, and seamlessly performs graph, network, and matrix operations. With the addition of key based indices (such as pointers to strings) and semilinks, GraphBLAS can become a richer associative array algebra and be a plug-in replacement for spreadsheets, database tables, and data centric operating systems, enhancing the navigation of unstructured data found in digital hyperspace.",
        "published": "2021-03-28T19:11:28Z",
        "link": "http://arxiv.org/abs/2103.15203v1",
        "categories": [
            "cs.MS",
            "cs.DB",
            "cs.DM",
            "cs.NE",
            "math.RA"
        ]
    },
    {
        "title": "TensorDiffEq: Scalable Multi-GPU Forward and Inverse Solvers for Physics   Informed Neural Networks",
        "authors": [
            "Levi D. McClenny",
            "Mulugeta A. Haile",
            "Ulisses M. Braga-Neto"
        ],
        "summary": "Physics-Informed Neural Networks promise to revolutionize science and engineering practice, by introducing domain-aware deep machine learning models into scientific computation. Several software suites have emerged to make the implementation and usage of these architectures available to the research and industry communities. Here we introduce\\linebreak TensorDiffEq, built on Tensorflow 2.x, which presents an intuitive Keras-like interface for problem domain definition, model definition, and solution of forward and inverse problems using physics-aware deep learning methods. TensorDiffEq takes full advantage of Tensorflow 2.x infrastructure for deployment on multiple GPUs, allowing the implementation of large high-dimensional and complex models. Simultaneously, TensorDiffEq supports the Keras API for custom neural network architecture definitions. In the case of smaller or simpler models, the package allows for rapid deployment on smaller-scale CPU platforms with negligible changes to the implementation scripts. We demonstrate the basic usage and capabilities of TensorDiffEq in solving forward, inverse, and data assimilation problems of varying sizes and levels of complexity. The source code is available at https://github.com/tensordiffeq.",
        "published": "2021-03-30T02:41:40Z",
        "link": "http://arxiv.org/abs/2103.16034v1",
        "categories": [
            "cs.MS",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Optimizer Fusion: Efficient Training with Better Locality and   Parallelism",
        "authors": [
            "Zixuan Jiang",
            "Jiaqi Gu",
            "Mingjie Liu",
            "Keren Zhu",
            "David Z. Pan"
        ],
        "summary": "Machine learning frameworks adopt iterative optimizers to train neural networks. Conventional eager execution separates the updating of trainable parameters from forward and backward computations. However, this approach introduces nontrivial training time overhead due to the lack of data locality and computation parallelism. In this work, we propose to fuse the optimizer with forward or backward computation to better leverage locality and parallelism during training. By reordering the forward computation, gradient calculation, and parameter updating, our proposed method improves the efficiency of iterative optimizers. Experimental results demonstrate that we can achieve an up to 20% training time reduction on various configurations. Since our methods do not alter the optimizer algorithm, they can be used as a general \"plug-in\" technique to the training process.",
        "published": "2021-04-01T03:44:13Z",
        "link": "http://arxiv.org/abs/2104.00237v1",
        "categories": [
            "cs.LG",
            "cs.MS"
        ]
    },
    {
        "title": "fairmodels: A Flexible Tool For Bias Detection, Visualization, And   Mitigation",
        "authors": [
            "Jakub Wiśniewski",
            "Przemysław Biecek"
        ],
        "summary": "Machine learning decision systems are getting omnipresent in our lives. From dating apps to rating loan seekers, algorithms affect both our well-being and future. Typically, however, these systems are not infallible. Moreover, complex predictive models are really eager to learn social biases present in historical data that can lead to increasing discrimination. If we want to create models responsibly then we need tools for in-depth validation of models also from the perspective of potential discrimination. This article introduces an R package fairmodels that helps to validate fairness and eliminate bias in classification models in an easy and flexible fashion. The fairmodels package offers a model-agnostic approach to bias detection, visualization and mitigation. The implemented set of functions and fairness metrics enables model fairness validation from different perspectives. The package includes a series of methods for bias mitigation that aim to diminish the discrimination in the model. The package is designed not only to examine a single model, but also to facilitate comparisons between multiple models.",
        "published": "2021-04-01T15:06:13Z",
        "link": "http://arxiv.org/abs/2104.00507v2",
        "categories": [
            "stat.ML",
            "cs.LG",
            "cs.MS",
            "stat.AP"
        ]
    },
    {
        "title": "The Two-Dimensional Swept Rule Applied on Heterogeneous Architectures",
        "authors": [
            "Anthony S. Walker",
            "Kyle E. Niemeyer"
        ],
        "summary": "The partial differential equations describing compressible fluid flows can be notoriously difficult to resolve on a pragmatic scale and often require the use of high performance computing systems and/or accelerators. However, these systems face scaling issues such as latency, the fixed cost of communicating information between devices in the system. The swept rule is a technique designed to minimize these costs by obtaining a solution to unsteady equations at as many possible spatial locations and times prior to communicating. In this study, we implemented and tested the swept rule for solving two-dimensional problems on heterogeneous computing systems across two distinct systems. Our solver showed a speedup range of 0.22-2.71 for the heat diffusion equation and 0.52-1.46 for the compressible Euler equations. We can conclude from this study that the swept rule offers both potential for speedups and slowdowns and that care should be taken when designing such a solver to maximize benefits. These results can help make decisions to maximize these benefits and inform designs.",
        "published": "2021-04-01T20:06:09Z",
        "link": "http://arxiv.org/abs/2105.10332v1",
        "categories": [
            "cs.DC",
            "cs.MS",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Two-Stage Gauss--Seidel Preconditioners and Smoothers for Krylov Solvers   on a GPU cluster",
        "authors": [
            "Luc Berger-Vergiat",
            "Brian Kelley",
            "Sivasankaran Rajamanickam",
            "Jonathan Hu",
            "Katarzyna Swirydowicz",
            "Paul Mullowney",
            "Stephen Thomas",
            "Ichitaro Yamazaki"
        ],
        "summary": "Gauss-Seidel (GS) relaxation is often employed as a preconditioner for a Krylov solver or as a smoother for Algebraic Multigrid (AMG). However, the requisite sparse triangular solve is difficult to parallelize on many-core architectures such as graphics processing units (GPUs). In the present study, the performance of the traditional GS relaxation based on a triangular solve is compared with two-stage variants, replacing the direct triangular solve with a fixed number of inner Jacobi-Richardson (JR) iterations. When a small number of inner iterations is sufficient to maintain the Krylov convergence rate, the two-stage GS (GS2) often outperforms the traditional algorithm on many-core architectures. We also compare GS2 with JR. When they perform the same number of flops for SpMV (e.g. three JR sweeps compared to two GS sweeps with one inner JR sweep), the GS2 iterations, and the Krylov solver preconditioned with GS2, may converge faster than the JR iterations. Moreover, for some problems (e.g. elasticity), it was found that JR may diverge with a damping factor of one, whereas two-stage GS may improve the convergence with more inner iterations. Finally, to study the performance of the two-stage smoother and preconditioner for a practical problem, %(e.g. using tuned damping factors), these were applied to incompressible fluid flow simulations on GPUs.",
        "published": "2021-04-02T18:49:32Z",
        "link": "http://arxiv.org/abs/2104.01196v2",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "Fitting Splines to Axonal Arbors Quantifies Relationship between Branch   Order and Geometry",
        "authors": [
            "Thomas L. Athey",
            "Jacopo Teneggi",
            "Joshua T. Vogelstein",
            "Daniel Tward",
            "Ulrich Mueller",
            "Michael I. Miller"
        ],
        "summary": "Neuromorphology is crucial to identifying neuronal subtypes and understanding learning. It is also implicated in neurological disease. However, standard morphological analysis focuses on macroscopic features such as branching frequency and connectivity between regions, and often neglects the internal geometry of neurons. In this work, we treat neuron trace points as a sampling of differentiable curves and fit them with a set of branching B-splines. We designed our representation with the Frenet-Serret formulas from differential geometry in mind. The Frenet-Serret formulas completely characterize smooth curves, and involve two parameters, curvature and torsion. Our representation makes it possible to compute these parameters from neuron traces in closed form. These parameters are defined continuously along the curve, in contrast to other parameters like tortuosity which depend on start and end points. We applied our method to a dataset of cortical projection neurons traced in two mouse brains, and found that the parameters are distributed differently between primary, collateral, and terminal axon branches, thus quantifying geometric differences between different components of an axonal arbor. The results agreed in both brains, further validating our representation. The code used in this work can be readily applied to neuron traces in SWC format and is available in our open-source Python package brainlit: http://brainlit.neurodata.io/.",
        "published": "2021-04-04T03:38:42Z",
        "link": "http://arxiv.org/abs/2104.01532v3",
        "categories": [
            "q-bio.NC",
            "cs.MS",
            "math.DG"
        ]
    },
    {
        "title": "LAGraph: Linear Algebra, Network Analysis Libraries, and the Study of   Graph Algorithms",
        "authors": [
            "Gábor Szárnyas",
            "David A. Bader",
            "Timothy A. Davis",
            "James Kitchen",
            "Timothy G. Mattson",
            "Scott McMillan",
            "Erik Welch"
        ],
        "summary": "Graph algorithms can be expressed in terms of linear algebra. GraphBLAS is a library of low-level building blocks for such algorithms that targets algorithm developers. LAGraph builds on top of the GraphBLAS to target users of graph algorithms with high-level algorithms common in network analysis. In this paper, we describe the first release of the LAGraph library, the design decisions behind the library, and performance using the GAP benchmark suite. LAGraph, however, is much more than a library. It is also a project to document and analyze the full range of algorithms enabled by the GraphBLAS. To that end, we have developed a compact and intuitive notation for describing these algorithms. In this paper, we present that notation with examples from the GAP benchmark suite.",
        "published": "2021-04-04T18:49:58Z",
        "link": "http://arxiv.org/abs/2104.01661v1",
        "categories": [
            "cs.MS",
            "cs.DS"
        ]
    },
    {
        "title": "AuTO: A Framework for Automatic differentiation in Topology Optimization",
        "authors": [
            "Aaditya Chandrasekhar",
            "Saketh Sridhara",
            "Krishnan Suresh"
        ],
        "summary": "A critical step in topology optimization (TO) is finding sensitivities. Manual derivation and implementation of the sensitivities can be quite laborious and error-prone, especially for non-trivial objectives, constraints and material models. An alternate approach is to utilize automatic differentiation (AD). While AD has been around for decades, and has also been applied in TO, wider adoption has largely been absent.   In this educational paper, we aim to reintroduce AD for TO, and make it easily accessible through illustrative codes. In particular, we employ JAX, a high-performance Python library for automatically computing sensitivities from a user defined TO problem. The resulting framework, referred to here as AuTO, is illustrated through several examples in compliance minimization, compliant mechanism design and microstructural design.",
        "published": "2021-04-05T15:36:17Z",
        "link": "http://arxiv.org/abs/2104.01965v1",
        "categories": [
            "cs.MS",
            "cs.CE",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Hardware-Oriented Krylov Methods for High-Performance Computing",
        "authors": [
            "Nils-Arne Dreier"
        ],
        "summary": "Krylov subspace methods are an essential building block in numerical simulation software. The efficient utilization of modern hardware is a challenging problem in the development of these methods. In this work, we develop Krylov subspace methods to solve linear systems with multiple right-hand sides, tailored to modern hardware in high-performance computing. To this end, we analyze an innovative block Krylov subspace framework that allows to balance the computational and data-transfer costs to the hardware. Based on the framework, we formulate commonly used Krylov methods. For the CG and BiCGStab methods, we introduce a novel stabilization approach as an alternative to a deflation strategy. This helps us to retain the block size, thus leading to a simpler and more efficient implementation. In addition, we optimize the methods further for distributed memory systems and the communication overhead. For the CG method, we analyze approaches to overlap the communication and computation and present multiple variants of the CG method, which differ in their communication properties. Furthermore, we present optimizations of the orthogonalization procedure in the GMRes method. Beside introducing a pipelined Gram-Schmidt variant that overlaps the global communication with the computation of inner products, we present a novel orthonormalization method based on the TSQR algorithm, which is communication-optimal and stable. For all optimized method, we present tests that show their superiority in a distributed setting.",
        "published": "2021-04-06T13:25:22Z",
        "link": "http://arxiv.org/abs/2104.02494v1",
        "categories": [
            "math.NA",
            "cs.DC",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "RLIBM-32: High Performance Correctly Rounded Math Libraries for 32-bit   Floating Point Representations",
        "authors": [
            "Jay P. Lim",
            "Santosh Nagarakatte"
        ],
        "summary": "This paper proposes a set of techniques to develop correctly rounded math libraries for 32-bit float and posit types. It enhances our RLibm approach that frames the problem of generating correctly rounded libraries as a linear programming problem in the context of 16-bit types to scale to 32-bit types. Specifically, this paper proposes new algorithms to (1) generate polynomials that produce correctly rounded outputs for all inputs using counterexample guided polynomial generation, (2) generate efficient piecewise polynomials with bit-pattern based domain splitting, and (3) deduce the amount of freedom available to produce correct results when range reduction involves multiple elementary functions. The resultant math library for the 32-bit float type is faster than state-of-the-art math libraries while producing the correct output for all inputs. We have also developed a set of correctly rounded elementary functions for 32-bit posits.",
        "published": "2021-04-08T20:37:17Z",
        "link": "http://arxiv.org/abs/2104.04043v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "MIPROT: A Medical Image Processing Toolbox for MATLAB",
        "authors": [
            "Alberto Gomez"
        ],
        "summary": "This paper presents a Matlab toolbox to perform basic image processing and visualization tasks, particularly designed for medical image processing. The functionalities available are similar to basic functions found in other non-Matlab widely used libraries such as the Insight Toolkit (ITK). The toolbox is entirely written in native Matlab code, but is fast and flexible.   Main use cases for the toolbox are illustrated here, including image input/output, pre-processing, filtering, image registration and visualisation. Both the code and sample data are made publicly available and open source.",
        "published": "2021-04-10T13:56:39Z",
        "link": "http://arxiv.org/abs/2104.04771v1",
        "categories": [
            "cs.MS",
            "65-04"
        ]
    },
    {
        "title": "Efficient algorithms for computing a rank-revealing UTV factorization on   parallel computing architectures",
        "authors": [
            "N. Heavner",
            "F. D. Igual",
            "G. Quintana-Ortí",
            "P. G. Martinsson"
        ],
        "summary": "The randomized singular value decomposition (RSVD) is by now a well established technique for efficiently computing an approximate singular value decomposition of a matrix. Building on the ideas that underpin the RSVD, the recently proposed algorithm \"randUTV\" computes a FULL factorization of a given matrix that provides low-rank approximations with near-optimal error. Because the bulk of randUTV is cast in terms of communication-efficient operations like matrix-matrix multiplication and unpivoted QR factorizations, it is faster than competing rank-revealing factorization methods like column pivoted QR in most high performance computational settings. In this article, optimized randUTV implementations are presented for both shared memory and distributed memory computing environments. For shared memory, randUTV is redesigned in terms of an \"algorithm-by-blocks\" that, together with a runtime task scheduler, eliminates bottlenecks from data synchronization points to achieve acceleration over the standard \"blocked algorithm\", based on a purely fork-join approach. The distributed memory implementation is based on the ScaLAPACK library. The performances of our new codes compare favorably with competing factorizations available on both shared memory and distributed memory architectures.",
        "published": "2021-04-12T19:15:36Z",
        "link": "http://arxiv.org/abs/2104.05782v1",
        "categories": [
            "cs.MS",
            "G.1.3; G.4; C.4; D.1.3; F.2.1"
        ]
    },
    {
        "title": "Parallelized Discrete Exterior Calculus for Three-Dimensional Elliptic   Problems",
        "authors": [
            "Pieter D. Boom",
            "Ashley Seepujak",
            "Odysseas Kosmas",
            "Lee Margetts",
            "Andrey Jivkov"
        ],
        "summary": "A formulation of elliptic boundary value problems is used to develop the first discrete exterior calculus (DEC) library for massively parallel computations with 3D domains. This can be used for steady-state analysis of any physical process driven by the gradient of a scalar quantity, e.g. temperature, concentration, pressure or electric potential, and is easily extendable to transient analysis. In addition to offering this library to the community, we demonstrate one important benefit from the DEC formulation: effortless introduction of strong heterogeneities and discontinuities. These are typical for real materials, but challenging for widely used domain discretization schemes, such as finite elements. Specifically, we demonstrate the efficiency of the method for calculating the evolution of thermal conductivity of a solid with a growing crack population. Future development of the library will deal with transient problems, and more importantly with processes driven by gradients of vector quantities.",
        "published": "2021-04-13T08:06:48Z",
        "link": "http://arxiv.org/abs/2104.05999v1",
        "categories": [
            "cs.MS",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Novel Matrix Hit and Run for Sampling Polytopes and Its GPU   Implementation",
        "authors": [
            "Mario Vazquez Corte",
            "Luis V. Montiel"
        ],
        "summary": "We propose and analyze a new Markov Chain Monte Carlo algorithm that generates a uniform sample over full and non-full dimensional polytopes. This algorithm, termed \"Matrix Hit and Run\" (MHAR), is a modification of the Hit and Run framework. For the regime $n^{1+\\frac{1}{3}} \\ll m$, MHAR has a lower asymptotic cost per sample in terms of soft-O notation ($\\SO$) than do existing sampling algorithms after a \\textit{warm start}. MHAR is designed to take advantage of matrix multiplication routines that require less computational and memory resources. Our tests show this implementation to be substantially faster than the \\textit{hitandrun} R package, especially for higher dimensions. Finally, we provide a python library based on Pytorch and a Colab notebook with the implementation ready for deployment in architectures with GPU or just CPU.",
        "published": "2021-04-14T19:55:04Z",
        "link": "http://arxiv.org/abs/2104.07097v1",
        "categories": [
            "cs.CG",
            "cs.MS",
            "cs.PF"
        ]
    },
    {
        "title": "A systematic review of Python packages for time series analysis",
        "authors": [
            "Julien Siebert",
            "Janek Groß",
            "Christof Schroth"
        ],
        "summary": "This paper presents a systematic review of Python packages with a focus on time series analysis. The objective is to provide (1) an overview of the different time series analysis tasks and preprocessing methods implemented, and (2) an overview of the development characteristics of the packages (e.g., documentation, dependencies, and community size). This review is based on a search of literature databases as well as GitHub repositories. Following the filtering process, 40 packages were analyzed. We classified the packages according to the analysis tasks implemented, the methods related to data preparation, and the means for evaluating the results produced (methods and access to evaluation data). We also reviewed documentation aspects, the licenses, the size of the packages' community, and the dependencies used. Among other things, our results show that forecasting is by far the most frequently implemented task, that half of the packages provide access to real datasets or allow generating synthetic data, and that many packages depend on a few libraries (the most used ones being numpy, scipy and pandas). We hope that this review can help practitioners and researchers navigate the space of Python packages dedicated to time series analysis. We will provide an updated list of the reviewed packages online at https://siebert-julien.github.io/time-series-analysis-python/.",
        "published": "2021-04-15T12:09:54Z",
        "link": "http://arxiv.org/abs/2104.07406v2",
        "categories": [
            "cs.MS",
            "68-04",
            "I.5.5"
        ]
    },
    {
        "title": "mlf-core: a framework for deterministic machine learning",
        "authors": [
            "Lukas Heumos",
            "Philipp Ehmele",
            "Luis Kuhn Cuellar",
            "Kevin Menden",
            "Edmund Miller",
            "Steffen Lemke",
            "Gisela Gabernet",
            "Sven Nahnsen"
        ],
        "summary": "Machine learning has shown extensive growth in recent years and is now routinely applied to sensitive areas. To allow appropriate verification of predictive models before deployment, models must be deterministic. However, major machine learning libraries default to the usage of non-deterministic algorithms based on atomic operations. Solely fixing all random seeds is not sufficient for deterministic machine learning. To overcome this shortcoming, various machine learning libraries released deterministic counterparts to the non-deterministic algorithms. We evaluated the effect of these algorithms on determinism and runtime. Based on these results, we formulated a set of requirements for deterministic machine learning and developed a new software solution, the mlf-core ecosystem, which aids machine learning projects to meet and keep these requirements. We applied mlf-core to develop deterministic models in various biomedical fields including a single cell autoencoder with TensorFlow, a PyTorch-based U-Net model for liver-tumor segmentation in CT scans, and a liver cancer classifier based on gene expression profiles with XGBoost.",
        "published": "2021-04-15T17:58:03Z",
        "link": "http://arxiv.org/abs/2104.07651v2",
        "categories": [
            "cs.MS",
            "cs.LG",
            "q-bio.QM",
            "stat.ML"
        ]
    },
    {
        "title": "Code generation for productive portable scalable finite element   simulation in Firedrake",
        "authors": [
            "Jack D. Betteridge",
            "Patrick E. Farrell",
            "David A. Ham"
        ],
        "summary": "Creating scalable, high performance PDE-based simulations requires a suitable combination of discretizations, differential operators, preconditioners and solvers. The required combination changes with the application and with the available hardware, yet software development time is a severely limited resource for most scientists and engineers. Here we demonstrate that generating simulation code from a high-level Python interface provides an effective mechanism for creating high performance simulations from very few lines of user code. We demonstrate that moving from one supercomputer to another can require significant algorithmic changes to achieve scalable performance, but that the code generation approach enables these algorithmic changes to be achieved with minimal development effort.",
        "published": "2021-04-16T10:14:54Z",
        "link": "http://arxiv.org/abs/2104.08012v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "Boosting Memory Access Locality of the Spectral Element Method with   Hilbert Space-Filling Curves",
        "authors": [
            "Roger R. F. Araújo",
            "Lutz Gross",
            "Samuel Xavier-de-Souza"
        ],
        "summary": "We propose an algorithm based on Hilbert space-filling curves to reorder mesh elements in memory for use with the Spectral Element Method, aiming to attain fewer cache misses, better locality of data reference and faster execution. We present a technique to numerically simulate acoustic wave propagation in 2D domains using the Spectral Element Method, and discuss computational performance aspects of this procedure. We reorder mesh-related data via Hilbert curves to achieve sizable reductions in execution time under several mesh configurations in shared-memory systems. Our experiments show that the Hilbert curve approach works well with meshes of several granularities and also with small and large variations in element sizes, achieving reductions between 9% and 25% in execution time when compared to three other ordering schemes.",
        "published": "2021-04-17T01:27:38Z",
        "link": "http://arxiv.org/abs/2104.08416v1",
        "categories": [
            "cs.MS",
            "cs.DC",
            "cs.PF",
            "86-08 (Primary), 35Q68, 35Q86 (Secondary)",
            "G.4; D.1.3"
        ]
    },
    {
        "title": "PyArmadillo: a streamlined linear algebra library for Python",
        "authors": [
            "Jason Rumengan",
            "Terry Yue Zhuo",
            "Conrad Sanderson"
        ],
        "summary": "PyArmadillo is a linear algebra library for the Python language, with the aim of closely mirroring the programming interface of the widely used Armadillo C++ library, which in turn is deliberately similar to Matlab. PyArmadillo hence facilitates algorithm prototyping with Matlab-like syntax directly in Python, and relatively straightforward conversion of PyArmadillo-based Python code into performant Armadillo-based C++ code. The converted code can be used for purposes such as speeding up Python-based programs in conjunction with pybind11, or the integration of algorithms originally prototyped in Python into larger C++ codebases. PyArmadillo provides objects for matrices and cubes, as well as over 200 associated functions for manipulating data stored in the objects. Integer, floating point and complex numbers are supported. Various matrix factorisations are provided through integration with LAPACK, or one of its high performance drop-in replacements such as Intel MKL or OpenBLAS. PyArmadillo is open-source software, distributed under the Apache 2.0 license; it can be obtained at https://pyarma.sourceforge.io or via the Python Package Index in precompiled form.",
        "published": "2021-04-22T15:13:33Z",
        "link": "http://arxiv.org/abs/2104.11120v4",
        "categories": [
            "cs.MS",
            "15-04, 62-04, 65-04, 68-04",
            "G.4; D.3; D.2.3"
        ]
    },
    {
        "title": "NOMAD version 4: Nonlinear optimization with the MADS algorithm",
        "authors": [
            "Charles Audet",
            "Sébastien Le Digabel",
            "Viviane Rochon Montplaisir",
            "Christophe Tribes"
        ],
        "summary": "NOMAD is software for optimizing blackbox problems. In continuous development since 2001, it constantly evolved with the integration of new algorithmic features published in scientific publications. These features are motivated by real applications encountered by industrial partners. The latest major release of NOMAD, version 3, dates from 2008. Minor releases are produced as new features are incorporated. The present work describes NOMAD 4, a complete redesign of the previous version, with a new architecture providing more flexible code, added functionalities and reusable code. We introduce algorithmic components, which are building blocks for more complex algorithms, and can initiate other components, launch nested algorithms, or perform specialized tasks. They facilitate the implementation of new ideas, including the MegaSearchPoll component, warm and hot restarts, and a revised version of the PSD-MADS algorithm. Another main improvement of NOMAD 4 is the usage of parallelism, to simultaneously compute multiple blackbox evaluations, and to maximize usage of available cores. Running different algorithms, tuning their parameters, and comparing their performance for optimization is simpler than before, while overall optimization performance is maintained between versions 3 and 4. NOMAD is freely available at www.gerad.ca/nomad and the whole project is visible at github.com/bbopt/nomad.",
        "published": "2021-04-23T14:28:57Z",
        "link": "http://arxiv.org/abs/2104.11627v2",
        "categories": [
            "math.OC",
            "cs.MS"
        ]
    },
    {
        "title": "tsrobprep - an R package for robust preprocessing of time series data",
        "authors": [
            "Michał Narajewski",
            "Jens Kley-Holsteg",
            "Florian Ziel"
        ],
        "summary": "Data cleaning is a crucial part of every data analysis exercise. Yet, the currently available R packages do not provide fast and robust methods for cleaning and preparation of time series data. The open source package tsrobprep introduces efficient methods for handling missing values and outliers using model based approaches. For data imputation a probabilistic replacement model is proposed, which may consist of autoregressive components and external inputs. For outlier detection a clustering algorithm based on finite mixture modelling is introduced, which considers time series properties in terms of the gradient and the underlying seasonality as features. The procedure allows to return a probability for each observation being outlying data as well as a specific cause for an outlier assignment in terms of the provided feature space. The methods work robust and are fully tunable. Moreover, by providing the auto_data_cleaning function the data preprocessing can be carried out in one cast, without comprehensive tuning and providing suitable results. The primary motivation of the package is the preprocessing of energy system data. We present application for electricity load, wind and solar power data.",
        "published": "2021-04-26T15:35:11Z",
        "link": "http://arxiv.org/abs/2104.12657v2",
        "categories": [
            "stat.ML",
            "cs.LG",
            "cs.MS",
            "stat.CO"
        ]
    },
    {
        "title": "Bringing Trimmed Serendipity Methods to Computational Practice in   Firedrake",
        "authors": [
            "Justin Crum",
            "Cyrus Cheng",
            "David A. Ham",
            "Lawrence Mitchell",
            "Robert C. Kirby",
            "Joshua A. Levine",
            "Andrew Gillette"
        ],
        "summary": "We present an implementation of the trimmed serendipity finite element family, using the open source finite element package Firedrake. The new elements can be used seamlessly within the software suite for problems requiring $H^1$, \\hcurl, or \\hdiv-conforming elements on meshes of squares or cubes. To test how well trimmed serendipity elements perform in comparison to traditional tensor product elements, we perform a sequence of numerical experiments including the primal Poisson, mixed Poisson, and Maxwell cavity eigenvalue problems. Overall, we find that the trimmed serendipity elements converge, as expected, at the same rate as the respective tensor product elements while being able to offer significant savings in the time or memory required to solve certain problems.",
        "published": "2021-04-27T05:25:02Z",
        "link": "http://arxiv.org/abs/2104.12986v2",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "math.AP"
        ]
    },
    {
        "title": "High-Performance Partial Spectrum Computation for Symmetric eigenvalue   problems and the SVD",
        "authors": [
            "D. Keyes",
            "H. Ltaief",
            "Y. Nakatsukasa",
            "D. Sukkari"
        ],
        "summary": "Current dense symmetric eigenvalue (EIG) and singular value decomposition (SVD) implementations may suffer from the lack of concurrency during the tridiagonal and bidiagonal reductions, respectively. This performance bottleneck is typical for the two-sided transformations due to the Level-2 BLAS memory-bound calls. Therefore, the current state-of-the-art EIG and SVD implementations may achieve only a small fraction of the system's sustained peak performance. The QR-based Dynamically Weighted Halley (QDWH) algorithm may be used as a pre-processing step toward the EIG and SVD solvers, while mitigating the aforementioned bottleneck. QDWH-EIG and QDWH-SVD expose more parallelism, while relying on compute-bound matrix operations. Both run closer to the sustained peak performance of the system, but at the expense of performing more FLOPS than the standard EIG and SVD algorithms. In this paper, we introduce a new QDWH-based solver for computing the partial spectrum for EIG (QDWHpartial-EIG) and SVD (QDWHpartial-SVD) problems. By optimizing the rational function underlying the algorithms only in the desired part of the spectrum, QDWHpartial-EIG and QDWHpartial-SVD algorithms efficiently compute a fraction (say 1-20%) of the corresponding spectrum. We develop high-performance implementations of QDWHpartial-EIG and QDWHpartial-SVD on distributed-memory anymore systems and demonstrate their numerical robustness. Experimental results using up to 36K MPI processes show performance speedups for QDWHpartial-SVD up to 6X and 2X against PDGESVD from ScaLAPACK and KSVD, respectively. QDWHpartial-EIG outperforms PDSYEVD from ScaLAPACK up to 3.5X but remains slower compared to ELPA. QDWHpartial-EIG achieves, however, a better occupancy of the underlying hardware by extracting higher sustained peak performance than ELPA, which is critical moving forward with accelerator-based supercomputers.",
        "published": "2021-04-29T08:04:23Z",
        "link": "http://arxiv.org/abs/2104.14186v1",
        "categories": [
            "math.NA",
            "cs.DC",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "Parallel implementation of a compatible high-order meshless method for   the Stokes' equations",
        "authors": [
            "Quang-Thinh Ha",
            "Paul A. Kuberry",
            "Nathaniel A. Trask",
            "Emily M. Ryan"
        ],
        "summary": "A parallel implementation of a compatible discretization scheme for steady-state Stokes problems is presented in this work. The scheme uses generalized moving least squares to generate differential operators and apply boundary conditions. This meshless scheme allows a high-order convergence for both the velocity and pressure, while also incorporates finite-difference-like sparse discretization. Additionally, the method is inherently scalable: the stencil generation process requires local inversion of matrices amenable to GPU acceleration, and the divergence-free treatment of velocity replaces the traditional saddle point structure of the global system with elliptic diagonal blocks amenable to algebraic multigrid. The implementation in this work uses a variety of Trilinos packages to exploit this local and global parallelism, and benchmarks demonstrating high-order convergence and weak scalability are provided.",
        "published": "2021-04-29T16:06:13Z",
        "link": "http://arxiv.org/abs/2104.14447v1",
        "categories": [
            "math.NA",
            "cs.DC",
            "cs.MS",
            "cs.NA",
            "cs.PF",
            "math.AP"
        ]
    },
    {
        "title": "QDOT: Quantized Dot Product Kernel for Approximate High-Performance   Computing",
        "authors": [
            "James Diffenderfer",
            "Daniel Osei-Kuffuor",
            "Harshitha Menon"
        ],
        "summary": "Approximate computing techniques have been successful in reducing computation and power costs in several domains. However, error sensitive applications in high-performance computing are unable to benefit from existing approximate computing strategies that are not developed with guaranteed error bounds. While approximate computing techniques can be developed for individual high-performance computing applications by domain specialists, this often requires additional theoretical analysis and potentially extensive software modification. Hence, the development of low-level error-bounded approximate computing strategies that can be introduced into any high-performance computing application without requiring additional analysis or significant software alterations is desirable. In this paper, we provide a contribution in this direction by proposing a general framework for designing error-bounded approximate computing strategies and apply it to the dot product kernel to develop qdot -- an error-bounded approximate dot product kernel. Following the introduction of qdot, we perform a theoretical analysis that yields a deterministic bound on the relative approximation error introduced by qdot. Empirical tests are performed to illustrate the tightness of the derived error bound and to demonstrate the effectiveness of qdot on a synthetic dataset, as well as two scientific benchmarks -- Conjugate Gradient (CG) and the Power method. In particular, using qdot for the dot products in CG can result in a majority of components being perforated or quantized to half precision without increasing the iteration count required for convergence to the same solution as CG using a double precision dot product.",
        "published": "2021-04-30T22:41:17Z",
        "link": "http://arxiv.org/abs/2105.00115v1",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "pyBKT: An Accessible Python Library of Bayesian Knowledge Tracing Models",
        "authors": [
            "Anirudhan Badrinath",
            "Frederic Wang",
            "Zachary Pardos"
        ],
        "summary": "Bayesian Knowledge Tracing, a model used for cognitive mastery estimation, has been a hallmark of adaptive learning research and an integral component of deployed intelligent tutoring systems (ITS). In this paper, we provide a brief history of knowledge tracing model research and introduce pyBKT, an accessible and computationally efficient library of model extensions from the literature. The library provides data generation, fitting, prediction, and cross-validation routines, as well as a simple to use data helper interface to ingest typical tutor log dataset formats. We evaluate the runtime with various dataset sizes and compare to past implementations. Additionally, we conduct sanity checks of the model using experiments with simulated data to evaluate the accuracy of its EM parameter learning and use real-world data to validate its predictions, comparing pyBKT's supported model variants with results from the papers in which they were originally introduced. The library is open source and open license for the purpose of making knowledge tracing more accessible to communities of research and practice and to facilitate progress in the field through easier replication of past approaches.",
        "published": "2021-05-02T03:08:53Z",
        "link": "http://arxiv.org/abs/2105.00385v2",
        "categories": [
            "cs.MS",
            "cs.AI",
            "cs.CY",
            "cs.LG"
        ]
    },
    {
        "title": "Paradiseo: From a Modular Framework for Evolutionary Computation to the   Automated Design of Metaheuristics ---22 Years of Paradiseo---",
        "authors": [
            "Johann Dreo",
            "Arnaud Liefooghe",
            "Sébastien Verel",
            "Marc Schoenauer",
            "Juan J. Merelo",
            "Alexandre Quemy",
            "Benjamin Bouvier",
            "Jan Gmys"
        ],
        "summary": "The success of metaheuristic optimization methods has led to the development of a large variety of algorithm paradigms. However, no algorithm clearly dominates all its competitors on all problems. Instead, the underlying variety of landscapes of optimization problems calls for a variety of algorithms to solve them efficiently. It is thus of prior importance to have access to mature and flexible software frameworks which allow for an efficient exploration of the algorithm design space. Such frameworks should be flexible enough to accommodate any kind of metaheuristics, and open enough to connect with higher-level optimization, monitoring and evaluation softwares. This article summarizes the features of the ParadisEO framework, a comprehensive C++ free software which targets the development of modular metaheuristics. ParadisEO provides a highly modular architecture, a large set of components, speed of execution and automated algorithm design features, which are key to modern approaches to metaheuristics development.",
        "published": "2021-05-02T08:45:33Z",
        "link": "http://arxiv.org/abs/2105.00420v1",
        "categories": [
            "cs.NE",
            "cs.MS"
        ]
    },
    {
        "title": "Sphynx: a parallel multi-GPU graph partitioner for distributed-memory   systems",
        "authors": [
            "Seher Acer",
            "Erik G Boman",
            "Christian A Glusa",
            "Sivasankaran Rajamanickam"
        ],
        "summary": "Graph partitioning has been an important tool to partition the work among several processors to minimize the communication cost and balance the workload. While accelerator-based supercomputers are emerging to be the standard, the use of graph partitioning becomes even more important as applications are rapidly moving to these architectures. However, there is no distributed-memory parallel, multi-GPU graph partitioner available for applications. We developed a spectral graph partitioner, Sphynx, using the portable, accelerator-friendly stack of the Trilinos framework. In Sphynx, we allow using different preconditioners and exploit their unique advantages. We use Sphynx to systematically evaluate the various algorithmic choices in spectral partitioning with a focus on the GPU performance. We perform those evaluations on two distinct classes of graphs: regular (such as meshes, matrices from finite element methods) and irregular (such as social networks and web graphs), and show that different settings and preconditioners are needed for these graph classes. The experimental results on the Summit supercomputer show that Sphynx is the fastest alternative on irregular graphs in an application-friendly setting and obtains a partitioning quality close to ParMETIS on regular graphs. When compared to nvGRAPH on a single GPU, Sphynx is faster and obtains better balance and better quality partitions. Sphynx provides a good and robust partitioning method across a wide range of graphs for applications looking for a GPU-based partitioner.",
        "published": "2021-05-02T23:47:28Z",
        "link": "http://arxiv.org/abs/2105.00578v1",
        "categories": [
            "cs.DC",
            "cs.DM",
            "cs.MS",
            "68W10"
        ]
    },
    {
        "title": "Exact Acceleration of K-Means++ and K-Means$\\|$",
        "authors": [
            "Edward Raff"
        ],
        "summary": "K-Means++ and its distributed variant K-Means$\\|$ have become de facto tools for selecting the initial seeds of K-means. While alternatives have been developed, the effectiveness, ease of implementation, and theoretical grounding of the K-means++ and $\\|$ methods have made them difficult to \"best\" from a holistic perspective. By considering the limited opportunities within seed selection to perform pruning, we develop specialized triangle inequality pruning strategies and a dynamic priority queue to show the first acceleration of K-Means++ and K-Means$\\|$ that is faster in run-time while being algorithmicly equivalent. For both algorithms we are able to reduce distance computations by over $500\\times$. For K-means++ this results in up to a 17$\\times$ speedup in run-time and a $551\\times$ speedup for K-means$\\|$. We achieve this with simple, but carefully chosen, modifications to known techniques which makes it easy to integrate our approach into existing implementations of these algorithms.",
        "published": "2021-05-06T20:22:55Z",
        "link": "http://arxiv.org/abs/2105.02936v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MS",
            "stat.ML"
        ]
    },
    {
        "title": "Similarity Downselection: A Python implementation of a heuristic search   algorithm for finding the set of the n most dissimilar items with an   application in conformer sampling",
        "authors": [
            "Felicity F. Nielson",
            "Sean M. Colby",
            "Ryan S. Renslow",
            "Thomas O. Metz"
        ],
        "summary": "Finding the set of the n items most dissimilar from each other out of a larger population becomes increasingly difficult and computationally expensive as either n or the population size grows large. Finding the set of the n most dissimilar items is different than simply sorting an array of numbers because there exists a pairwise relationship between each item and all other items in the population. For instance, if you have a set of the most dissimilar n=4 items, one or more of the items from n=4 might not be in the set n=5. An exact solution would have to search all possible combinations of size n in the population, exhaustively. We present an open-source software called similarity downselection (SDS), written in Python and freely available on GitHub. SDS implements a heuristic algorithm for quickly finding the approximate set(s) of the n most dissimilar items. We benchmark SDS against a Monte Carlo method, which attempts to find the exact solution through repeated random sampling. We show that for SDS to find the set of n most dissimilar conformers, our method is not only orders of magnitude faster, but is also more accurate than running the Monte Carlo for 1,000,000 iterations, each searching for set sizes n=3-7 out of a population of 50,000. We also benchmark SDS against the exact solution for example small populations, showing SDS produces a solution close to the exact solution in these instances.",
        "published": "2021-05-06T22:02:38Z",
        "link": "http://arxiv.org/abs/2105.02991v1",
        "categories": [
            "q-bio.BM",
            "cs.MS"
        ]
    },
    {
        "title": "ReLie: a Reduce program for Lie group analysis of differential equations",
        "authors": [
            "Francesco Oliveri"
        ],
        "summary": "Lie symmetry analysis provides a general theoretical framework for investigating ordinary and partial differential equations. The theory is completely algorithmic even if it usually involves lengthy computations. For this reason, many computer algebra packages have been developed along the years to automate the computation. In this paper, we describe the program ReLie, written in the Computer Algebra System Reduce, which since 2008 is an open source program (http://www.reduce-algebra.com) and is available for all platforms. \\relie is able to perform almost automatically the needed computations for Lie symmetry analysis of differential equations. Its source code is freely available at the url http://mat521.unime.it/oliveri. The use of the program is illustrated by means of some simple examples; nevertheless, it is to be underlined that it provides effective also for more complex computations where one has to deal with very large expressions.",
        "published": "2021-05-07T11:22:13Z",
        "link": "http://arxiv.org/abs/2105.11534v1",
        "categories": [
            "cs.MS",
            "cs.NA",
            "math-ph",
            "math.MP",
            "math.NA",
            "34-04, 34A05, 35-04, 58J70, 58J72"
        ]
    },
    {
        "title": "High-performance symbolic-numerics via multiple dispatch",
        "authors": [
            "Shashi Gowda",
            "Yingbo Ma",
            "Alessandro Cheli",
            "Maja Gwozdz",
            "Viral B. Shah",
            "Alan Edelman",
            "Christopher Rackauckas"
        ],
        "summary": "As mathematical computing becomes more democratized in high-level languages, high-performance symbolic-numeric systems are necessary for domain scientists and engineers to get the best performance out of their machine without deep knowledge of code optimization. Naturally, users need different term types either to have different algebraic properties for them, or to use efficient data structures. To this end, we developed Symbolics.jl, an extendable symbolic system which uses dynamic multiple dispatch to change behavior depending on the domain needs. In this work we detail an underlying abstract term interface which allows for speed without sacrificing generality. We show that by formalizing a generic API on actions independent of implementation, we can retroactively add optimized data structures to our system without changing the pre-existing term rewriters. We showcase how this can be used to optimize term construction and give a 113x acceleration on general symbolic transformations. Further, we show that such a generic API allows for complementary term-rewriting implementations. We demonstrate the ability to swap between classical term-rewriting simplifiers and e-graph-based term-rewriting simplifiers. We showcase an e-graph ruleset which minimizes the number of CPU cycles during expression evaluation, and demonstrate how it simplifies a real-world reaction-network simulation to halve the runtime. Additionally, we show a reaction-diffusion partial differential equation solver which is able to be automatically converted into symbolic expressions via multiple dispatch tracing, which is subsequently accelerated and parallelized to give a 157x simulation speedup. Together, this presents Symbolics.jl as a next-generation symbolic-numeric computing environment geared towards modeling and simulation.",
        "published": "2021-05-09T14:22:43Z",
        "link": "http://arxiv.org/abs/2105.03949v3",
        "categories": [
            "cs.CL",
            "cs.MS",
            "cs.PL",
            "cs.SC",
            "D.3.3; I.1.1; I.1.3"
        ]
    },
    {
        "title": "SIRNN: A Math Library for Secure RNN Inference",
        "authors": [
            "Deevashwer Rathee",
            "Mayank Rathee",
            "Rahul Kranti Kiran Goli",
            "Divya Gupta",
            "Rahul Sharma",
            "Nishanth Chandran",
            "Aseem Rastogi"
        ],
        "summary": "Complex machine learning (ML) inference algorithms like recurrent neural networks (RNNs) use standard functions from math libraries like exponentiation, sigmoid, tanh, and reciprocal of square root. Although prior work on secure 2-party inference provides specialized protocols for convolutional neural networks (CNNs), existing secure implementations of these math operators rely on generic 2-party computation (2PC) protocols that suffer from high communication. We provide new specialized 2PC protocols for math functions that crucially rely on lookup-tables and mixed-bitwidths to address this performance overhead; our protocols for math functions communicate up to 423x less data than prior work. Some of the mixed bitwidth operations used by our math implementations are (zero and signed) extensions, different forms of truncations, multiplication of operands of mixed-bitwidths, and digit decomposition (a generalization of bit decomposition to larger digits). For each of these primitive operations, we construct specialized 2PC protocols that are more communication efficient than generic 2PC, and can be of independent interest. Furthermore, our math implementations are numerically precise, which ensures that the secure implementations preserve model accuracy of cleartext. We build on top of our novel protocols to build SIRNN, a library for end-to-end secure 2-party DNN inference, that provides the first secure implementations of an RNN operating on time series sensor data, an RNN operating on speech data, and a state-of-the-art ML architecture that combines CNNs and RNNs for identifying all heads present in images. Our evaluation shows that SIRNN achieves up to three orders of magnitude of performance improvement when compared to inference of these models using an existing state-of-the-art 2PC framework.",
        "published": "2021-05-10T10:04:46Z",
        "link": "http://arxiv.org/abs/2105.04236v1",
        "categories": [
            "cs.CR",
            "cs.LG",
            "cs.MS"
        ]
    },
    {
        "title": "Accelerating the SpMV kernel on standard CPUs by exploiting the   partially diagonal structures",
        "authors": [
            "Takeshi Fukaya",
            "Koki Ishida",
            "Akie Miura",
            "Takeshi Iwashita",
            "Hiroshi Nakashima"
        ],
        "summary": "Sparse Matrix Vector multiplication (SpMV) is one of basic building blocks in scientific computing, and acceleration of SpMV has been continuously required. In this research, we aim for accelerating SpMV on recent CPUs for sparse matrices that have a specific sparsity structure, namely a diagonally structured sparsity pattern. We focus a hybrid storage format that combines the DIA and CSR formats, so-called the HDC format. First, we recall the importance of introducing cache blocking techniques into HDC-based SpMV kernels. Next, based on the observation of the cache blocked kernel, we present a modified version of the HDC formats, which we call the M-HDC format, in which partial diagonal structures are expected to be more efficiently picked up. For these SpMV kernels, we theoretically analyze the expected performance improvement based on performance models. Then, we conduct comprehensive experiments on state-of-the-art multi-core CPUs. By the experiments using typical matrices, we clarify the detailed performance characteristics of each SpMV kernel. We also evaluate the performance for matrices appearing in practical applications and demonstrate that our approach can accelerate SpMV for some of them. Through the present paper, we demonstrate the effectiveness of exploiting partial diagonal structures by the M-HDC format as a promising approach to accelerating SpMV on CPUs for a certain kind of practical sparse matrices.",
        "published": "2021-05-11T11:04:01Z",
        "link": "http://arxiv.org/abs/2105.04937v1",
        "categories": [
            "cs.DC",
            "cs.MS",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "SPUX Framework: a Scalable Package for Bayesian Uncertainty   Quantification and Propagation",
        "authors": [
            "Jonas Šukys",
            "Marco Bacci"
        ],
        "summary": "We present SPUX - a modular framework for Bayesian inference enabling uncertainty quantification and propagation in linear and nonlinear, deterministic and stochastic models, and supporting Bayesian model selection. SPUX can be coupled to any serial or parallel application written in any programming language, (e.g. including Python, R, Julia, C/C++, Fortran, Java, or a binary executable), scales effortlessly from serial runs on a personal computer to parallel high performance computing clusters, and aims to provide a platform particularly suited to support and foster reproducibility in computational science. We illustrate SPUX capabilities for a simple yet representative random walk model, describe how to couple different types of user applications, and showcase several readily available examples from environmental sciences. In addition to available state-of-the-art numerical inference algorithms including EMCEE, PMCMC (PF) and SABC, the open source nature of the SPUX framework and the explicit description of the hierarchical parallel SPUX executors should also greatly simplify the implementation and usage of other inference and optimization techniques.",
        "published": "2021-05-12T21:16:24Z",
        "link": "http://arxiv.org/abs/2105.05969v1",
        "categories": [
            "stat.CO",
            "cs.CE",
            "cs.MS"
        ]
    },
    {
        "title": "Experimental Evaluation of Multiprecision Strategies for GMRES on GPUs",
        "authors": [
            "Jennifer A. Loe",
            "Christian A. Glusa",
            "Ichitaro Yamazaki",
            "Erik G. Boman",
            "Sivasankaran Rajamanickam"
        ],
        "summary": "Support for lower precision computation is becoming more common in accelerator hardware due to lower power usage, reduced data movement and increased computational performance. However, computational science and engineering (CSE) problems require double precision accuracy in several domains. This conflict between hardware trends and application needs has resulted in a need for multiprecision strategies at the linear algebra algorithms level if we want to exploit the hardware to its full potential while meeting the accuracy requirements. In this paper, we focus on preconditioned sparse iterative linear solvers, a key kernel in several CSE applications. We present a study of multiprecision strategies for accelerating this kernel on GPUs. We seek the best methods for incorporating multiple precisions into the GMRES linear solver; these include iterative refinement and parallelizable preconditioners. Our work presents strategies to determine when multiprecision GMRES will be effective and to choose parameters for a multiprecision iterative refinement solver to achieve better performance. We use an implementation that is based on the Trilinos library and employs Kokkos Kernels for performance portability of linear algebra kernels. Performance results demonstrate the promise of multiprecision approaches and demonstrate even further improvements are possible by optimizing low-level kernels.",
        "published": "2021-05-16T23:22:02Z",
        "link": "http://arxiv.org/abs/2105.07544v1",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "FRaGenLP: A Generator of Random Linear Programming Problems for Cluster   Computing Systems",
        "authors": [
            "Leonid B. Sokolinsky",
            "Irina M. Sokolinskaya"
        ],
        "summary": "The article presents and evaluates a scalable FRaGenLP algorithm for generating random linear programming problems of large dimension $n$ on cluster computing systems. To ensure the consistency of the problem and the boundedness of the feasible region, the constraint system includes $2n+1$ standard inequalities, called support inequalities. New random inequalities are generated and added to the system in a manner that ensures the consistency of the constraints. Furthermore, the algorithm uses two likeness metrics to prevent the addition of a new random inequality that is similar to one already present in the constraint system. The algorithm also rejects random inequalities that cannot affect the solution of the linear programming problem bounded by the support inequalities. The parallel implementation of the FRaGenLP algorithm is performed in C++ through the parallel BSF-skeleton, which encapsulates all aspects related to the MPI-based parallelization of the program. We provide the results of large-scale computational experiments on a cluster computing system to study the scalability of the FRaGenLP algorithm.",
        "published": "2021-05-18T14:55:24Z",
        "link": "http://arxiv.org/abs/2105.10384v1",
        "categories": [
            "cs.DC",
            "cs.MS",
            "math.OC"
        ]
    },
    {
        "title": "Mill.jl and JsonGrinder.jl: automated differentiable feature extraction   for learning from raw JSON data",
        "authors": [
            "Simon Mandlik",
            "Matej Racinsky",
            "Viliam Lisy",
            "Tomas Pevny"
        ],
        "summary": "Learning from raw data input, thus limiting the need for manual feature engineering, is one of the key components of many successful applications of machine learning methods. While machine learning problems are often formulated on data that naturally translate into a vector representation suitable for classifiers, there are data sources, for example in cybersecurity, that are naturally represented in diverse files with a unifying hierarchical structure, such as XML, JSON, and Protocol Buffers. Converting this data to vector (tensor) representation is generally done by manual feature engineering, which is laborious, lossy, and prone to human bias about the importance of particular features.   Mill and JsonGrinder is a tandem of libraries, which fully automates the conversion. Starting with an arbitrary set of JSON samples, they create a differentiable machine learning model capable of infer from further JSON samples in their raw form.",
        "published": "2021-05-19T13:02:10Z",
        "link": "http://arxiv.org/abs/2105.09107v1",
        "categories": [
            "stat.ML",
            "cs.LG",
            "cs.MS"
        ]
    },
    {
        "title": "Uncertainty quantification through Monte Carlo method in a cloud   computing setting",
        "authors": [
            "A. Cunha Jr",
            "R. Nasser",
            "R. Sampaio",
            "H. Lopes",
            "K. Breitman"
        ],
        "summary": "The Monte Carlo (MC) method is the most common technique used for uncertainty quantification, due to its simplicity and good statistical results. However, its computational cost is extremely high, and, in many cases, prohibitive. Fortunately, the MC algorithm is easily parallelizable, which allows its use in simulations where the computation of a single realization is very costly. This work presents a methodology for the parallelization of the MC method, in the context of cloud computing. This strategy is based on the MapReduce paradigm, and allows an efficient distribution of tasks in the cloud. This methodology is illustrated on a problem of structural dynamics that is subject to uncertainties. The results show that the technique is capable of producing good results concerning statistical moments of low order. It is shown that even a simple problem may require many realizations for convergence of histograms, which makes the cloud computing strategy very attractive (due to its high scalability capacity and low-cost). Additionally, the results regarding the time of processing and storage space usage allow one to qualify this new methodology as a solution for simulations that require a number of MC realizations beyond the standard.",
        "published": "2021-05-20T04:52:40Z",
        "link": "http://arxiv.org/abs/2105.09512v1",
        "categories": [
            "stat.CO",
            "cs.MS",
            "math.PR",
            "stat.AP",
            "62D05",
            "G.3"
        ]
    },
    {
        "title": "On the Complexity and Parallel Implementation of Hensel's Lemma and   Weierstrass Preparation",
        "authors": [
            "Alexander Brandt",
            "Marc Moreno Maza"
        ],
        "summary": "Hensel's lemma, combined with repeated applications of Weierstrass preparation theorem, allows for the factorization of polynomials with multivariate power series coefficients. We present a complexity analysis for this method and leverage those results to guide the load-balancing of a parallel implementation to concurrently update all factors. In particular, the factorization creates a pipeline where the terms of degree k of the first factor are computed simultaneously with the terms of degree k-1 of the second factor, etc. An implementation challenge is the inherent irregularity of computational work between factors, as our complexity analysis reveals. Additional resource utilization and load-balancing is achieved through the parallelization of Weierstrass preparation. Experimental results show the efficacy of this mixed parallel scheme, achieving up to 9x parallel speedup on 12 cores.",
        "published": "2021-05-22T19:26:52Z",
        "link": "http://arxiv.org/abs/2105.10798v2",
        "categories": [
            "cs.SC",
            "cs.DC",
            "cs.MS"
        ]
    },
    {
        "title": "kEDM: A Performance-portable Implementation of Empirical Dynamic   Modeling using Kokkos",
        "authors": [
            "Keichi Takahashi",
            "Wassapon Watanakeesuntorn",
            "Kohei Ichikawa",
            "Joseph Park",
            "Ryousei Takano",
            "Jason Haga",
            "George Sugihara",
            "Gerald M. Pao"
        ],
        "summary": "Empirical Dynamic Modeling (EDM) is a state-of-the-art non-linear time-series analysis framework. Despite its wide applicability, EDM was not scalable to large datasets due to its expensive computational cost. To overcome this obstacle, researchers have attempted and succeeded in accelerating EDM from both algorithmic and implementational aspects. In previous work, we developed a massively parallel implementation of EDM targeting HPC systems (mpEDM). However, mpEDM maintains different backends for different architectures. This design becomes a burden in the increasingly diversifying HPC systems, when porting to new hardware. In this paper, we design and develop a performance-portable implementation of EDM based on the Kokkos performance portability framework (kEDM), which runs on both CPUs and GPUs while based on a single codebase. Furthermore, we optimize individual kernels specifically for EDM computation, and use real-world datasets to demonstrate up to $5.5\\times$ speedup compared to mpEDM in convergent cross mapping computation.",
        "published": "2021-05-26T02:21:55Z",
        "link": "http://arxiv.org/abs/2105.12301v1",
        "categories": [
            "cs.DC",
            "cs.MS",
            "cs.PF"
        ]
    },
    {
        "title": "A multiresolution Discrete Element Method for triangulated objects with   implicit timestepping",
        "authors": [
            "Peter J. Noble",
            "Tobias Weinzierl"
        ],
        "summary": "Simulations of many rigid bodies colliding with each other sometimes yield particularly interesting results if the colliding objects differ significantly in size and are non-spherical. The most expensive part within such a simulation code is the collision detection. We propose a family of novel multiscale collision detection algorithms that can be applied to triangulated objects within explicit and implicit time stepping methods. They are well-suited to handle objects that cannot be represented by analytical shapes or assemblies of analytical objects. Inspired by multigrid methods and adaptive mesh refinement, we determine collision points iteratively over a resolution hierarchy, and combine a functional minimisation plus penalty parameters with the actual comparision-based geometric distance calculation. Coarse surrogate geometry representations identify \"no collision\" scenarios early on and otherwise yield an educated guess which triangle subsets of the next finer level potentially yield collisions. They prune the search tree, and furthermore feed conservative contact force estimates into the iterative solve behind an implicit time stepping. Implicit time stepping and non-analytical shapes often yield prohibitive high compute cost for rigid body simulations. Our approach reduces these cost algorithmically by one to two orders of magnitude. It also exhibits high vectorisation efficiency due to its iterative nature.",
        "published": "2021-05-26T09:11:33Z",
        "link": "http://arxiv.org/abs/2105.12415v2",
        "categories": [
            "cs.CG",
            "cs.MS",
            "70E55, 70F35, 68U05, 51P05, 37N15"
        ]
    },
    {
        "title": "Task inefficiency patterns for a wave equation solver",
        "authors": [
            "Holger Schulz",
            "Gonzalo Brito Gadeschi",
            "Oleksandr Rudyy",
            "Tobias Weinzierl"
        ],
        "summary": "The orchestration of complex algorithms demands high levels of automation to use modern hardware efficiently. Task-based programming with OpenMP 5.0 is a prominent candidate to accomplish this goal. We study OpenMP 5.0's tasking in the context of a wave equation solver (ExaHyPE) using three different architectures and runtimes. We describe several task-scheduling flaws present in currently available runtimes, demonstrate how they impact performance and show how to work around them. Finally, we propose extensions to the OpenMP standard.",
        "published": "2021-05-26T18:00:01Z",
        "link": "http://arxiv.org/abs/2105.12739v2",
        "categories": [
            "cs.DC",
            "cs.MS"
        ]
    },
    {
        "title": "TensorFlow RiemOpt: a library for optimization on Riemannian manifolds",
        "authors": [
            "Oleg Smirnov"
        ],
        "summary": "The adoption of neural networks and deep learning in non-Euclidean domains has been hindered until recently by the lack of scalable and efficient learning frameworks. Existing toolboxes in this space were mainly motivated by research and education use cases, whereas practical aspects, such as deploying and maintaining machine learning models, were often overlooked.   We attempt to bridge this gap by proposing TensorFlow RiemOpt, a Python library for optimization on Riemannian manifolds in TensorFlow. The library is designed with the aim for a seamless integration with the TensorFlow ecosystem, targeting not only research, but also streamlining production machine learning pipelines.",
        "published": "2021-05-27T10:42:09Z",
        "link": "http://arxiv.org/abs/2105.13921v2",
        "categories": [
            "cs.MS",
            "cs.CG",
            "cs.LG"
        ]
    },
    {
        "title": "semopy 2: A Structural Equation Modeling Package with Random Effects in   Python",
        "authors": [
            "Georgy Meshcheryakov",
            "Anna A. Igolkina",
            "Maria G. Samsonova"
        ],
        "summary": "Structural Equation Modeling (SEM) is an umbrella term that includes numerous multivariate statistical techniques that are employed throughout a plethora of research areas, ranging from social to natural sciences. Until recently, SEM software was either commercial or restricted to niche languages, and the lack of SEM packages compatible with more mainstream programming languages was dire. To combat that, we introduced a Python package semopy 1 that surpassed other state-of-the-art software in terms of performance and estimation accuracy. Yet, it was lacking in functionality and its usage was burdened with unnecessary boilerplate code. Here, we introduce a complete overhaul of semopy that improves upon the previous results and comes with lots of new capabilities. Furthermore, we propose a novel SEM model that combines in itself a notion of random effects from linear mixed models (LMMs) to model numerous phenomena, such as spatial data, time series or population stratification in genetics.",
        "published": "2021-06-02T13:18:03Z",
        "link": "http://arxiv.org/abs/2106.01140v3",
        "categories": [
            "stat.AP",
            "cs.MS"
        ]
    },
    {
        "title": "Momentum-inspired Low-Rank Coordinate Descent for Diagonally Constrained   SDPs",
        "authors": [
            "Junhyung Lyle Kim",
            "JA Lara Benitez",
            "Mohammad Taha Toghani",
            "Cameron Wolfe",
            "Zhiwei Zhang",
            "Anastasios Kyrillidis"
        ],
        "summary": "We present a novel, practical, and provable approach for solving diagonally constrained semi-definite programming (SDP) problems at scale using accelerated non-convex programming. Our algorithm non-trivially combines acceleration motions from convex optimization with coordinate power iteration and matrix factorization techniques. The algorithm is extremely simple to implement, and adds only a single extra hyperparameter -- momentum. We prove that our method admits local linear convergence in the neighborhood of the optimum and always converges to a first-order critical point. Experimentally, we showcase the merits of our method on three major application domains: MaxCut, MaxSAT, and MIMO signal detection. In all cases, our methodology provides significant speedups over non-convex and convex SDP solvers -- 5X faster than state-of-the-art non-convex solvers, and 9 to 10^3 X faster than convex SDP solvers -- with comparable or improved solution quality.",
        "published": "2021-06-16T13:35:40Z",
        "link": "http://arxiv.org/abs/2106.08775v2",
        "categories": [
            "math.OC",
            "cs.IT",
            "cs.LG",
            "cs.MS",
            "math.IT",
            "stat.ML",
            "49-02",
            "F.2.1; G.4"
        ]
    },
    {
        "title": "Manifolds.jl: An Extensible Julia Framework for Data Analysis on   Manifolds",
        "authors": [
            "Seth D. Axen",
            "Mateusz Baran",
            "Ronny Bergmann",
            "Krzysztof Rzecki"
        ],
        "summary": "We present the Julia package Manifolds.jl, providing a fast and easy-to-use library of Riemannian manifolds and Lie groups. This package enables working with data defined on a Riemannian manifold, such as the circle, the sphere, symmetric positive definite matrices, or one of the models for hyperbolic spaces. We introduce a common interface, available in ManifoldsBase.jl, with which new manifolds, applications, and algorithms can be implemented. We demonstrate the utility of Manifolds.jl using B\\'ezier splines, an optimization task on manifolds, and principal component analysis on nonlinear data. In a benchmark, Manifolds.jl outperforms all comparable packages for low-dimensional manifolds in speed; over Python and Matlab packages, the improvement is often several orders of magnitude, while over C/C++ packages, the improvement is two-fold. For high-dimensional manifolds, it outperforms all packages except for Tensorflow-Riemopt, which is specifically tailored for high-dimensional manifolds.",
        "published": "2021-06-16T13:36:17Z",
        "link": "http://arxiv.org/abs/2106.08777v3",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "HIFIR: Hybrid Incomplete Factorization with Iterative Refinement for   Preconditioning Ill-conditioned and Singular Systems",
        "authors": [
            "Qiao Chen",
            "Xiangmin Jiao"
        ],
        "summary": "We introduce a software package called HIFIR for preconditioning sparse, unsymmetric, ill-conditioned, and potentially singular systems. HIFIR computes a hybrid incomplete factorization, which combines multilevel incomplete LU factorization with a truncated, rank-revealing QR factorization on the final Schur complement. This novel hybridization is based on the new theory of approximate generalized inverse and $\\epsilon$-accuracy. It enables near-optimal preconditioners for consistent systems and enables flexible GMRES to solve inconsistent systems when coupled with iterative refinement. In this paper, we focus on some practical algorithmic and software issues of HIFIR. In particular, we introduce a new inverse-based rook pivoting into ILU, which improves the robustness and the overall efficiency for some ill-conditioned systems by significantly reducing the size of the final Schur complement for some systems. We also describe the software design of HIFIR in terms of its efficient data structures for supporting rook pivoting in a multilevel setting, its template-based generic programming interfaces for mixed-precision real and complex values in C++, and its user-friendly high-level interfaces in MATLAB and Python. We demonstrate the effectiveness of HIFIR for ill-conditioned or singular systems arising from several applications, including the Helmholtz equation, linear elasticity, stationary incompressible Navier--Stokes equations, and time-dependent advection-diffusion equation.",
        "published": "2021-06-18T02:30:39Z",
        "link": "http://arxiv.org/abs/2106.09877v2",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "Efficient recursive least squares solver for rank-deficient matrices",
        "authors": [
            "Ruben Staub",
            "Stephan N. Steinmann"
        ],
        "summary": "Updating a linear least squares solution can be critical for near real-time signalprocessing applications. The Greville algorithm proposes a simple formula for updating the pseudoinverse of a matrix A $\\in$ R nxm with rank r. In this paper, we explicitly derive a similar formula by maintaining a general rank factorization, which we call rank-Greville. Based on this formula, we implemented a recursive least squares algorithm exploiting the rank-deficiency of A, achieving the update of the minimum-norm least-squares solution in O(mr) operations and, therefore, solving the linear least-squares problem from scratch in O(nmr) operations. We empirically confirmed that this algorithm displays a better asymptotic time complexity than LAPACK solvers for rank-deficient matrices. The numerical stability of rank-Greville was found to be comparable to Cholesky-based solvers. Nonetheless, our implementation supports exact numerical representations of rationals, due to its remarkable algebraic simplicity.",
        "published": "2021-06-22T07:59:35Z",
        "link": "http://arxiv.org/abs/2106.11594v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "Efficient algorithms for computing rank-revealing factorizations on a   GPU",
        "authors": [
            "Nathan Heavner",
            "Chao Chen",
            "Abinand Gopal",
            "Per-Gunnar Martinsson"
        ],
        "summary": "Standard rank-revealing factorizations such as the singular value decomposition and column pivoted QR factorization are challenging to implement efficiently on a GPU. A major difficulty in this regard is the inability of standard algorithms to cast most operations in terms of the Level-3 BLAS. This paper presents two alternative algorithms for computing a rank-revealing factorization of the form $A = U T V^*$, where $U$ and $V$ are orthogonal and $T$ is triangular. Both algorithms use randomized projection techniques to cast most of the flops in terms of matrix-matrix multiplication, which is exceptionally efficient on the GPU. Numerical experiments illustrate that these algorithms achieve an order of magnitude acceleration over finely tuned GPU implementations of the SVD while providing low-rank approximation errors close to that of the SVD.",
        "published": "2021-06-25T03:19:58Z",
        "link": "http://arxiv.org/abs/2106.13402v2",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "Optimal Checkpointing for Adjoint Multistage Time-Stepping Schemes",
        "authors": [
            "Hong Zhang",
            "Emil Constantinescu"
        ],
        "summary": "We consider checkpointing strategies that minimize the number of recomputations needed when performing discrete adjoint computations using multistage time-stepping schemes, which requires computing several substeps within one complete time step. In this case we propose two algorithms that can generate optimal checkpointing schedules under weak assumptions. The first is an extension of the seminal Revolve algorithm adapted to multistage schemes. The second algorithm, named CAMS, is developed based on dynamic programming, and it requires the least number of recomputations when compared with other algorithms. The CAMS algorithm is made publicly available in a library with bindings to C and Python. Numerical results illustrate that the proposed algorithms can deliver up to two times the speedup compared with that of classical Revolve. Moreover, we discuss a tailored implementation of an adjoint computation that is arguably better suited for mature scientific computing libraries by avoiding the central control assumed by the original checkpointing strategy. The proposed algorithms have been adopted by the PETSc TSAdjoint library. Their performance has been demonstrated with a large-scale PDE-constrained optimization problem on a leadership-class supercomputer.",
        "published": "2021-06-25T20:41:50Z",
        "link": "http://arxiv.org/abs/2106.13879v2",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "Linear solvers for power grid optimization problems: a review of   GPU-accelerated linear solvers",
        "authors": [
            "Kasia Swirydowicz",
            "Eric Darve",
            "Wesley Jones",
            "Jonathan Maack",
            "Shaked Regev",
            "Michael A. Saunders",
            "Stephen J. Thomas",
            "Slaven Peles"
        ],
        "summary": "The linear equations that arise in interior methods for constrained optimization are sparse symmetric indefinite and become extremely ill-conditioned as the interior method converges. These linear systems present a challenge for existing solver frameworks based on sparse LU or LDL^T decompositions. We benchmark five well known direct linear solver packages using matrices extracted from power grid optimization problems. The achieved solution accuracy varies greatly among the packages. None of the tested packages delivers significant GPU acceleration for our test cases.",
        "published": "2021-06-25T23:12:06Z",
        "link": "http://arxiv.org/abs/2106.13909v2",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "The mbsts package: Multivariate Bayesian Structural Time Series Models   in R",
        "authors": [
            "Ning Ning",
            "Jinwen Qiu"
        ],
        "summary": "The multivariate Bayesian structural time series (MBSTS) model is a general machine learning model that deals with inference and prediction for multiple correlated time series, where one also has the choice of using a different candidate pool of contemporaneous predictors for each target series. The MBSTS model has wide applications and is ideal for feature selection, time series forecasting, nowcasting, inferring causal impact, and others. This paper demonstrates how to use the R package mbsts for MBSTS modeling, establishing a bridge between user-friendly and developer-friendly functions in the package and the corresponding methodology. Object-oriented functions in the package are explained in the way that enables users to flexibly add or deduct some components, as well as to simplify or complicate some settings.",
        "published": "2021-06-26T15:28:38Z",
        "link": "http://arxiv.org/abs/2106.14045v3",
        "categories": [
            "stat.ME",
            "cs.LG",
            "cs.MS",
            "stat.AP",
            "stat.CO"
        ]
    },
    {
        "title": "Automatic Differentiation With Higher Infinitesimals, or Computational   Smooth Infinitesimal Analysis in Weil Algebra",
        "authors": [
            "Hiromi Ishii"
        ],
        "summary": "We propose an algorithm to compute the $C^\\infty$-ring structure of arbitrary Weil algebra. It allows us to do some analysis with higher infinitesimals numerically and symbolically. To that end, we first give a brief description of the (Forward-mode) automatic differentiation (AD) in terms of $C^\\infty$-rings. The notion of a $C^\\infty$-ring was introduced by Lawvere and used as the fundamental building block of smooth infinitesimal analysis and synthetic differential geometry. We argue that interpreting AD in terms of $C^\\infty$-rings gives us a unifying theoretical framework and modular ways to express multivariate partial derivatives. In particular, we can \"package\" higher-order Forward-mode AD as a Weil algebra, and take tensor products to compose them to achieve multivariate higher-order AD. The algorithms in the present paper can also be used for a pedagogical purpose in learning and studying smooth infinitesimal analysis as well.",
        "published": "2021-06-27T06:17:26Z",
        "link": "http://arxiv.org/abs/2106.14153v2",
        "categories": [
            "cs.SC",
            "cs.MS",
            "cs.NA",
            "math.CT",
            "math.DG",
            "math.NA"
        ]
    },
    {
        "title": "Leveraging GPU batching for scalable nonlinear programming through   massive Lagrangian decomposition",
        "authors": [
            "Youngdae Kim",
            "François Pacaud",
            "Kibaek Kim",
            "Mihai Anitescu"
        ],
        "summary": "We present the implementation of a trust-region Newton algorithm ExaTron for bound-constrained nonlinear programming problems, fully running on multiple GPUs. Without data transfers between CPU and GPU, our implementation has achieved the elimination of a major performance bottleneck under a memory-bound situation, particularly when solving many small problems in batch. We discuss the design principles and implementation details for our kernel function and core operations. Different design choices are justified by numerical experiments. By using the application of distributed control of alternating current optimal power flow, where a large problem is decomposed into many smaller nonlinear programs using a Lagrangian approach, we demonstrate computational performance of ExaTron on the Summit supercomputer at Oak RidgeNational Laboratory. Our numerical results show the linear scaling with respect to the batch size and the number of GPUs and more than 35 times speedup on 6 GPUs than on 40 CPUs available on a single node.",
        "published": "2021-06-28T21:39:38Z",
        "link": "http://arxiv.org/abs/2106.14995v1",
        "categories": [
            "math.OC",
            "cs.DC",
            "cs.MS",
            "65K05, 90C06, 90C30, 90-04, 90-08"
        ]
    },
    {
        "title": "Web-based Structural Identifiability Analyzer",
        "authors": [
            "Ilia Ilmer",
            "Alexey Ovchinnikov",
            "Gleb Pogudin"
        ],
        "summary": "Parameter identifiability describes whether, for a given differential model, one can determine parameter values from model equations. Knowing global or local identifiability properties allows construction of better practical experiments to identify parameters from experimental data. In this work, we present a web-based software tool that allows to answer specific identifiability queries. Concretely, our toolbox can determine identifiability of individual parameters of the model and also provide all functions of parameters that are identifiable (also called identifiable combinations) from single or multiple experiments. The program is freely available at https://maple.cloud/app/6509768948056064.",
        "published": "2021-06-29T02:57:34Z",
        "link": "http://arxiv.org/abs/2106.15066v1",
        "categories": [
            "cs.MS",
            "cs.SC",
            "cs.SY",
            "eess.SY",
            "q-bio.QM"
        ]
    },
    {
        "title": "Neko: A Modern, Portable, and Scalable Framework for High-Fidelity   Computational Fluid Dynamics",
        "authors": [
            "Niclas Jansson",
            "Martin Karp",
            "Artur Podobas",
            "Stefano Markidis",
            "Philipp Schlatter"
        ],
        "summary": "Recent trends and advancement in including more diverse and heterogeneous hardware in High-Performance Computing is challenging software developers in their pursuit for good performance and numerical stability. The well-known maxim \"software outlives hardware\" may no longer necessarily hold true, and developers are today forced to re-factor their codebases to leverage these powerful new systems. CFD is one of the many application domains affected. In this paper, we present Neko, a portable framework for high-order spectral element flow simulations. Unlike prior works, Neko adopts a modern object-oriented approach, allowing multi-tier abstractions of the solver stack and facilitating hardware backends ranging from general-purpose processors down to exotic vector processors and FPGAs. We show that Neko's performance and accuracy are comparable to NekRS, and thus on-par with Nek5000's successor on modern CPU machines. Furthermore, we develop a performance model, which we use to discuss challenges and opportunities for high-order solvers on emerging hardware.",
        "published": "2021-07-02T19:28:27Z",
        "link": "http://arxiv.org/abs/2107.01243v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "ATC: an Advanced Tucker Compression library for multidimensional data",
        "authors": [
            "Wouter Baert",
            "Nick Vannieuwenhoven"
        ],
        "summary": "We present ATC, a C++ library for advanced Tucker-based lossy compression of dense multidimensional numerical data in a shared-memory parallel setting, based on the sequentially truncated higher-order singular value decomposition (ST-HOSVD) and bit plane truncation. Several techniques are proposed to improve speed, memory usage, error control and compression rate. First, a hybrid truncation scheme is described which combines Tucker rank truncation and TTHRESH quantization [Ballester-Ripoll et al., IEEE Trans. Visual. Comput. Graph., 2020]. We derive a novel expression to approximate the error of truncated Tucker decompositions in the case of core and factor perturbations. Furthermore, we parallelize the quantization and encoding scheme and adjust this phase to improve error control. Moreover, implementation aspects are described, such as an ST-HOSVD procedure using only a single transposition. We also discuss several usability features of ATC, including the presence of multiple interfaces, extensive data type support and integrated downsampling of the decompressed data. Numerical results show that ATC maintains state-of-the-art Tucker compression rates, while providing average speed-up factors of 2.2-3.5 and halving memory usage. Furthermore, our compressor provides precise error control, only deviating 1.4% from the requested error on average. Finally, ATC often achieves higher compression than non-Tucker-based compressors in the high-error domain.",
        "published": "2021-07-03T08:58:42Z",
        "link": "http://arxiv.org/abs/2107.01384v4",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "DIRECTGO: A new DIRECT-type MATLAB toolbox for derivative-free global   optimization",
        "authors": [
            "Linas Stripinis",
            "Remigijus Paulavičius"
        ],
        "summary": "In this work, we introduce DIRECTGO, a new MATLAB toolbox for derivative-free global optimization. DIRECTGO collects various deterministic derivative-free DIRECT-type algorithms for box-constrained, generally-constrained, and problems with hidden constraints. Each sequential algorithm is implemented in two ways: using static and dynamic data structures for more efficient information storage and organization. Furthermore, parallel schemes are applied to some promising algorithms within DIRECTGO. The toolbox is equipped with a graphical user interface (GUI), ensuring the user-friendly use of all functionalities available in DIRECTGO. Available features are demonstrated in detailed computational studies using a comprehensive DIRECTGOLib v1.0 library of global optimization test problems. Additionally, eleven classical engineering design problems illustrate the potential of DIRECTGO to solve challenging real-world problems. Finally, the appendix gives examples of accompanying MATLAB programs and provides a synopsis of its use on the test problems with box and general constraints.",
        "published": "2021-07-05T18:13:21Z",
        "link": "http://arxiv.org/abs/2107.02205v2",
        "categories": [
            "math.OC",
            "cs.DS",
            "cs.MS",
            "68U99, 90C26 (Primary) 68W10 (Secondary)",
            "C.1.4; D.2; G.1.6; G.4"
        ]
    },
    {
        "title": "Fast Evaluation of Finite Element Weak Forms Using Python Tensor   Contraction Packages",
        "authors": [
            "Robert Cimrman"
        ],
        "summary": "In finite element calculations, the integral forms are usually evaluated using nested loops over elements, and over quadrature points. Many such forms (e.g. linear or multi-linear) can be expressed in a compact way, without the explicit loops, using a single tensor contraction expression by employing the Einstein summation convention. To automate this process and leverage existing high performance codes, we first introduce a notation allowing trivial differentiation of multi-linear finite element forms. Based on that we propose and describe a new transpiler from Einstein summation based expressions, augmented to allow defining multi-linear finite element weak forms, to regular tensor contraction expressions. The resulting expressions are compatible with a number of Python scientific computing packages, that implement, optimize and in some cases parallelize the general tensor contractions. We assess the performance of those packages, as well as the influence of operand memory layouts and tensor contraction paths optimizations on the elapsed time and memory requirements of the finite element form evaluations. We also compare the efficiency of the transpiled weak form implementations to the C-based functions available in the finite element package SfePy.",
        "published": "2021-07-07T15:08:24Z",
        "link": "http://arxiv.org/abs/2107.04121v1",
        "categories": [
            "cs.MS",
            "cs.NA",
            "math.NA",
            "65-04",
            "F.2.1; G.1.8; G.4"
        ]
    },
    {
        "title": "A Batched GPU Methodology for Numerical Solutions of Partial   Differential Equations",
        "authors": [
            "Enda Carroll",
            "Andrew Gloster",
            "Miguel D. Bustamante",
            "Lennon Ó' Náraigh"
        ],
        "summary": "In this paper we present a methodology for data accesses when solving batches of Tridiagonal and Pentadiagonal matrices that all share the same left-hand-side (LHS) matrix. The intended application is to the numerical solution of Partial Differential Equations via the finite-difference method, although the methodology is applicable more broadly. By only storing one copy of this matrix, a significant reduction in storage overheads is obtained, together with a corresponding decrease in compute time. Taken together, these two performance enhancements lead to an overall more efficient implementation over the current state of the art algorithms cuThomasBatch and cuPentBatch, allowing for a greater number of systems to be solved on a single GPU. We demonstrate the methodology in the case of the Diffusion Equation, Hyperdiffusion Equation, and the Cahn--Hilliard Equation, all in one spatial dimension. In this last example, we demonstrate how the method can be used to perform $2^{20}$ independent simulations of phase separation in one dimension. In this way, we build up a robust statistical description of the coarsening phenomenon which is the defining behavior of phase separation. We anticipate that the method will be of further use in other similar contexts requiring statistical simulation of physical systems.",
        "published": "2021-07-08T14:41:05Z",
        "link": "http://arxiv.org/abs/2107.05395v1",
        "categories": [
            "physics.comp-ph",
            "cs.DC",
            "cs.MS"
        ]
    },
    {
        "title": "Decomposition algorithms for tensors and polynomials",
        "authors": [
            "Antonio Laface",
            "Alex Massarenti",
            "Rick Rischter"
        ],
        "summary": "We give algorithms to compute decompositions of a given polynomial, or more generally mixed tensor, as sum of rank one tensors, and to establish whether such a decomposition is unique. In particular, we present methods to compute the decomposition of a general plane quintic in seven powers, and of a general space cubic in five powers; the two decompositions of a general plane sextic of rank nine, and the five decompositions of a general plane septic. Furthermore, we give Magma implementations of all our algorithms.",
        "published": "2021-07-08T20:31:05Z",
        "link": "http://arxiv.org/abs/2107.04097v1",
        "categories": [
            "math.AG",
            "cs.MS",
            "cs.SC",
            "Primary 14N07, Secondary 14N05, 51N35, 14Q15, 14N15"
        ]
    },
    {
        "title": "Algorithmic Causal Effect Identification with causaleffect",
        "authors": [
            "Martí Pedemonte",
            "Jordi Vitrià",
            "Álvaro Parafita"
        ],
        "summary": "Our evolution as a species made a huge step forward when we understood the relationships between causes and effects. These associations may be trivial for some events, but they are not in complex scenarios. To rigorously prove that some occurrences are caused by others, causal theory and causal inference were formalized, introducing the $do$-operator and its associated rules. The main goal of this report is to review and implement in Python some algorithms to compute conditional and non-conditional causal queries from observational data. To this end, we first present some basic background knowledge on probability and graph theory, before introducing important results on causal theory, used in the construction of the algorithms. We then thoroughly study the identification algorithms presented by Shpitser and Pearl in 2006, explaining our implementation in Python alongside. The main identification algorithm can be seen as a repeated application of the rules of $do$-calculus, and it eventually either returns an expression for the causal query from experimental probabilities or fails to identify the causal effect, in which case the effect is non-identifiable. We introduce our newly developed Python library and give some usage examples.",
        "published": "2021-07-09T19:00:33Z",
        "link": "http://arxiv.org/abs/2107.04632v1",
        "categories": [
            "cs.MS",
            "cs.AI",
            "math.ST",
            "stat.TH",
            "62D20 (Primary), 62H22 (Secondary)",
            "G.3; G.4"
        ]
    },
    {
        "title": "giotto-ph: A Python Library for High-Performance Computation of   Persistent Homology of Vietoris-Rips Filtrations",
        "authors": [
            "Julián Burella Pérez",
            "Sydney Hauke",
            "Umberto Lupo",
            "Matteo Caorsi",
            "Alberto Dassatti"
        ],
        "summary": "We introduce giotto-ph, a high-performance, open-source software package for the computation of Vietoris-Rips barcodes. giotto-ph is based on Morozov and Nigmetov's lockfree (multicore) implementation of Ulrich Bauer's Ripser package. It also contains a re-working of the GUDHI library's implementation of Boissonnat and Pritam's Edge Collapser, which can be used as a pre-processing step to dramatically reduce overall run-times in certain scenarios. Our contribution is twofold: on the one hand, we integrate existing state-of-the-art ideas coherently in a single library and provide Python bindings to the C++ code. On the other hand, we increase parallelization opportunities and improve overall performance by adopting more efficient data structures. Our persistent homology backend establishes a new state of the art, surpassing even GPU-accelerated implementations such as Ripser++ when using as few as 5-10 CPU cores. Furthermore, our implementation of Edge Collapser has fewer software dependencies and improved run-times relative to GUDHI's original implementation.",
        "published": "2021-07-12T13:30:45Z",
        "link": "http://arxiv.org/abs/2107.05412v2",
        "categories": [
            "cs.CG",
            "cs.MS",
            "68R99",
            "G.4; G.2.2"
        ]
    },
    {
        "title": "Parallel Element-based Algebraic Multigrid for H(curl) and H(div)   Problems Using the ParELAG Library",
        "authors": [
            "Delyan Z. Kalchev",
            "Panayot S. Vassilevski",
            "Umberto Villa"
        ],
        "summary": "This paper presents the use of element-based algebraic multigrid (AMGe) hierarchies, implemented in the ParELAG (Parallel Element Agglomeration Algebraic Multigrid Upscaling and Solvers) library, to produce multilevel preconditioners and solvers for H(curl) and H(div) formulations. ParELAG constructs hierarchies of compatible nested spaces, forming an exact de Rham sequence on each level. This allows the application of hybrid smoothers on all levels and AMS (Auxiliary-space Maxwell Solver) or ADS (Auxiliary-space Divergence Solver) on the coarsest levels, obtaining complete multigrid cycles. Numerical results are presented, showing the parallel performance of the proposed methods. As a part of the exposition, this paper demonstrates some of the capabilities of ParELAG and outlines some of the components and procedures within the library.",
        "published": "2021-07-12T17:48:29Z",
        "link": "http://arxiv.org/abs/2107.05613v2",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "Faster Math Functions, Soundly",
        "authors": [
            "Ian Briggs",
            "Pavel Panchekha"
        ],
        "summary": "Standard library implementations of functions like sin and exp optimize for accuracy, not speed, because they are intended for general-purpose use. But applications tolerate inaccuracy from cancellation, rounding error, and singularities-sometimes even very high error-and many application could tolerate error in function implementations as well. This raises an intriguing possibility: speeding up numerical code by tuning standard function implementations. This paper thus introduces OpTuner, an automatic method for selecting the best implementation of mathematical functions at each use site. OpTuner assembles dozens of implementations for the standard mathematical functions from across the speed-accuracy spectrum. OpTuner then uses error Taylor series and integer linear programming to compute optimal assignments of function implementation to use site and presents the user with a speed-accuracy Pareto curve they can use to speed up their code. In a case study on the POV-Ray ray tracer, OpTuner speeds up a critical computation, leading to a whole program speedup of 9% with no change in the program output (whereas human efforts result in slower code and lower-quality output). On a broader study of 37 standard benchmarks, OpTuner matches 216 implementations to 89 use sites and demonstrates speed-ups of 107% for negligible decreases in accuracy and of up to 438% for error-tolerant applications.",
        "published": "2021-07-12T22:12:33Z",
        "link": "http://arxiv.org/abs/2107.05761v1",
        "categories": [
            "cs.MS",
            "cs.SE"
        ]
    },
    {
        "title": "3D Acoustic-Elastic Coupling with Gravity: The Dynamics of the 2018   Palu, Sulawesi Earthquake and Tsunami",
        "authors": [
            "Lukas Krenz",
            "Carsten Uphoff",
            "Thomas Ulrich",
            "Alice-Agnes Gabriel",
            "Lauren S. Abrahams",
            "Eric M. Dunham",
            "Michael Bader"
        ],
        "summary": "We present a highly scalable 3D fully-coupled Earth & ocean model of earthquake rupture and tsunami generation. We model seismic, acoustic and surface gravity wave propagation in elastic (Earth) and acoustic (ocean) materials sourced by physics-based non-linear earthquake dynamic rupture. Complicated geometries, including high-resolution bathymetry, coastlines and segmented earthquake faults are discretized by adaptive unstructured tetrahedral meshes. A Discontinuous Galerkin discretization with ADER local time-stepping (ADER-DG) yields petascale computational efficiency and high-order accuracy in time and space.   We compare the 3D fully-coupled approach to a benchmark problem for 3D-2D linked models that use 2D shallow-water modeling. We present a large-scale fully-coupled model of the 2018 Sulawesi events that links the dynamics from supershear earthquake faulting to elastic and acoustic waves in Earth and ocean to tsunami gravity wave propagation in the narrow Palu Bay. And we demonstrate scalability and performance of the MPI+OpenMP parallelization on three petascale supercomputers.",
        "published": "2021-07-13T11:09:04Z",
        "link": "http://arxiv.org/abs/2107.06640v3",
        "categories": [
            "physics.comp-ph",
            "cs.DC",
            "cs.MS",
            "physics.geo-ph"
        ]
    },
    {
        "title": "Using a template engine as a computer algebra tool",
        "authors": [
            "Migran N. Gevorkyan",
            "Anna V. Korolkova",
            "Dmitry S. Kulyabov"
        ],
        "summary": "In research problems that involve the use of numerical methods for solving systems of ordinary differential equations (ODEs), it is often required to select the most efficient method for a particular problem. To solve a Cauchy problem for a system of ODEs, Runge-Kutta methods (explicit or implicit ones, with or without step-size control, etc.) are employed. In that case, it is required to search through many implementations of the numerical method and select coefficients or other parameters of its numerical scheme. This paper proposes a library and scripts for automated generation of routine functions in the Julia programming language for a set of numerical schemes of Runge-Kutta methods. For symbolic manipulations, we use a template substitution tool. The proposed approach to automated generation of program code allows us to use a single template for editing, instead of modifying each individual function to be compared. On the one hand, this provides universality in the implementation of a numerical scheme and, on the other hand, makes it possible to minimize the number of errors in the process of modifying the compared implementations of the numerical method. We consider Runge-Kutta methods without step-size control, embedded methods with step-size control, and Rosenbrock methods with step-size control. The program codes for the numerical schemes, which are generated automatically using the proposed library, are tested by numerical solution of several well-known problems.",
        "published": "2021-07-15T17:04:02Z",
        "link": "http://arxiv.org/abs/2107.07461v1",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "cs.SC"
        ]
    },
    {
        "title": "Topology optimization using the unsmooth variational topology   optimization (UNVARTOP) method. An educational implementation in Matlab",
        "authors": [
            "Daniel Yago",
            "Juan Cante",
            "Oriol Lloberas-Valls",
            "Javier Oliver"
        ],
        "summary": "This paper presents an efficient and comprehensive MATLAB code to solve two-dimensional structural topology optimization problems, including minimum mean compliance, compliant mechanism synthesis and multi-load compliance problems. The Unsmooth Variational Topology Optimization (UNVARTOP) method, developed by the authors in a previous work, is used in the topology optimization code, based on the finite element method (FEM), to compute the sensitivity and update the topology. The paper also includes instructions to improve the bisection algorithm, modify the computation of the Lagrangian multiplier by using an Augmented Lagrangian to impose the constraint, implement heat conduction problems and extend the code to three-dimensional topology optimization problems. The code, intended for students and newcomers in topology optimization, is included as an appendix (Appendix A) and it can be downloaded from https://github.com/DanielYago together with supplementary material.",
        "published": "2021-07-16T08:39:47Z",
        "link": "http://arxiv.org/abs/2107.07763v1",
        "categories": [
            "cs.CE",
            "cs.MS"
        ]
    },
    {
        "title": "Refactoring the MPS/University of Chicago Radiative MHD(MURaM) Model for   GPU/CPU Performance Portability Using OpenACC Directives",
        "authors": [
            "Eric Wright",
            "Damien Przybylski",
            "Matthias Rempel",
            "Cena Miller",
            "Supreeth Suresh",
            "Shiquan Su",
            "Richard Loft",
            "Sunita Chandrasekaran"
        ],
        "summary": "The MURaM (Max Planck University of Chicago Radiative MHD) code is a solar atmosphere radiative MHD model that has been broadly applied to solar phenomena ranging from quiet to active sun, including eruptive events such as flares and coronal mass ejections. The treatment of physics is sufficiently realistic to allow for the synthesis of emission from visible light to extreme UV and X-rays, which is critical for a detailed comparison with available and future multi-wavelength observations. This component relies critically on the radiation transport solver (RTS) of MURaM; the most computationally intensive component of the code. The benefits of accelerating RTS are multiple fold: A faster RTS allows for the regular use of the more expensive multi-band radiation transport needed for comparison with observations, and this will pave the way for the acceleration of ongoing improvements in RTS that are critical for simulations of the solar chromosphere. We present challenges and strategies to accelerate a multi-physics, multi-band MURaM using a directive-based programming model, OpenACC in order to maintain a single source code across CPUs and GPUs. Results for a $288^3$ test problem show that MURaM with the optimized RTS routine achieves 1.73x speedup using a single NVIDIA V100 GPU over a fully subscribed 40-core Intel Skylake CPU node and with respect to the number of simulation points (in millions) per second, a single NVIDIA V100 GPU is equivalent to 69 Skylake cores. We also measure parallel performance on up to 96 GPUs and present weak and strong scaling results.",
        "published": "2021-07-16T23:35:14Z",
        "link": "http://arxiv.org/abs/2107.08145v1",
        "categories": [
            "physics.space-ph",
            "cs.CE",
            "cs.MS"
        ]
    },
    {
        "title": "NeuralPDE: Automating Physics-Informed Neural Networks (PINNs) with   Error Approximations",
        "authors": [
            "Kirill Zubov",
            "Zoe McCarthy",
            "Yingbo Ma",
            "Francesco Calisto",
            "Valerio Pagliarino",
            "Simone Azeglio",
            "Luca Bottero",
            "Emmanuel Luján",
            "Valentin Sulzer",
            "Ashutosh Bharambe",
            "Nand Vinchhi",
            "Kaushik Balakrishnan",
            "Devesh Upadhyay",
            "Chris Rackauckas"
        ],
        "summary": "Physics-informed neural networks (PINNs) are an increasingly powerful way to solve partial differential equations, generate digital twins, and create neural surrogates of physical models. In this manuscript we detail the inner workings of NeuralPDE.jl and show how a formulation structured around numerical quadrature gives rise to new loss functions which allow for adaptivity towards bounded error tolerances. We describe the various ways one can use the tool, detailing mathematical techniques like using extended loss functions for parameter estimation and operator discovery, to help potential users adopt these PINN-based techniques into their workflow. We showcase how NeuralPDE uses a purely symbolic formulation so that all of the underlying training code is generated from an abstract formulation, and show how to make use of GPUs and solve systems of PDEs. Afterwards we give a detailed performance analysis which showcases the trade-off between training techniques on a large set of PDEs. We end by focusing on a complex multiphysics example, the Doyle-Fuller-Newman (DFN) Model, and showcase how this PDE can be formulated and solved with NeuralPDE. Together this manuscript is meant to be a detailed and approachable technical report to help potential users of the technique quickly get a sense of the real-world performance trade-offs and use cases of the PINN techniques.",
        "published": "2021-07-19T12:38:31Z",
        "link": "http://arxiv.org/abs/2107.09443v1",
        "categories": [
            "cs.MS",
            "cs.SC"
        ]
    },
    {
        "title": "Comparing OpenMP Implementations With Applications Across A64FX   Platforms",
        "authors": [
            "Benjamin Michalowicz",
            "Eric Raut",
            "Yan Kang",
            "Tony Curtis",
            "Barbara Chapman",
            "Dossay Oryspayev"
        ],
        "summary": "The development of the A64FX processor by Fujitsu has created a massive innovation in High-Performance Computing and the birth of Fugaku: the current world's fastest supercomputer. A variety of tools are used to analyze the run-times and performances of several applications, and in particular, how these applications scale on the A64FX processor. We examine the performance and behavior of applications through OpenMP scaling and how their performance differs across different compilers on the new Ookami cluster at Stony Brook University as well as the Fugaku supercomputer at RIKEN in Japan.",
        "published": "2021-07-21T20:28:38Z",
        "link": "http://arxiv.org/abs/2107.10346v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "Hyperbolic Diffusion in Flux Reconstruction: Optimisation through Kernel   Fusion within Tensor-Product Elements",
        "authors": [
            "Will Trojak",
            "Rob Watson",
            "Freddie Witherden"
        ],
        "summary": "Novel methods are presented in this initial study for the fusion of GPU kernels in the artificial compressibility method (ACM), using tensor product elements with constant Jacobians and flux reconstruction. This is made possible through the hyperbolisation of the diffusion terms, which eliminates the expensive algorithmic steps needed to form the viscous stresses. Two fusion approaches are presented, which offer differing levels of parallelism. This is found to be necessary for the change in workload as the order of accuracy of the elements is increased. Several further optimisations of these approaches are demonstrated, including a generation time memory manager which maximises resource usage. The fused kernels are able to achieve 3-4 times speedup, which compares favourably with a theoretical maximum speedup of 4. In three dimensional test cases, the generated fused kernels are found to reduce total runtime by ${\\sim}25\\%$, and, when compared to the standard ACM formulation, simulations demonstrate that a speedup of $2.3$ times can be achieved.",
        "published": "2021-07-22T18:22:27Z",
        "link": "http://arxiv.org/abs/2107.14027v2",
        "categories": [
            "cs.MS",
            "physics.comp-ph"
        ]
    },
    {
        "title": "MLDev: Data Science Experiment Automation and Reproducibility Software",
        "authors": [
            "Anton Khritankov",
            "Nikita Pershin",
            "Nikita Ukhov",
            "Artem Ukhov"
        ],
        "summary": "In this paper we explore the challenges of automating experiments in data science. We propose an extensible experiment model as a foundation for integration of different open source tools for running research experiments. We implement our approach in a prototype open source MLDev software package and evaluate it in a series of experiments yielding promising results. Comparison with other state-of-the-art tools signifies novelty of our approach.",
        "published": "2021-07-26T16:51:44Z",
        "link": "http://arxiv.org/abs/2107.12322v1",
        "categories": [
            "cs.LG",
            "cs.MS",
            "cs.SE",
            "I.2.m"
        ]
    },
    {
        "title": "Accelerated Multiple Precision Direct Method and Mixed Precision   Iterative Refinement on Python Programming Environment",
        "authors": [
            "Tomonori Kouya"
        ],
        "summary": "Current Python programming environment does not have any reliable and efficient multiple precision floating-point (MPF) arithmetic except ``mpmath\" and ``gmpy2\" packages based on GNU MP(GMP) and MPFR libraries. Although it is well known that multi-component-type MPF library can be utilized for middle length precision arithmetic under 200 bits, they are not widely used on Python environment. In this paper, we describe our accelerated MPF direct method with AVX2 techniques and its application to mixed precision iterative refinement combined with mpmath, and demonstrate their efficiency on x86\\_64 computational environments.",
        "published": "2021-07-27T01:57:03Z",
        "link": "http://arxiv.org/abs/2107.12550v1",
        "categories": [
            "cs.MS",
            "cs.NA",
            "cs.PF",
            "math.NA"
        ]
    },
    {
        "title": "Optimisation of an FPGA Credit Default Swap engine by embracing dataflow   techniques",
        "authors": [
            "Nick Brown",
            "Mark Klaisoongnoen",
            "Oliver Thomson Brown"
        ],
        "summary": "Quantitative finance is the use of mathematical models to analyse financial markets and securities. Typically requiring significant amounts of computation, an important question is the role that novel architectures can play in accelerating these models in the future on HPC machines. In this paper we explore the optimisation of an existing, open source, FPGA based Credit Default Swap (CDS) engine using High Level Synthesis (HLS). Developed by Xilinx, and part of their open source Vitis libraries, the implementation of this engine currently favours flexibility and ease of integration over performance.   We explore redesigning the engine to fully embrace the dataflow approach, ultimately resulting in an engine which is around eight times faster on an Alveo U280 FPGA than the original Xilinx library version. We then compare five of our engines on the U280 against a 24-core Xeon Platinum Cascade Lake CPU, outperforming the CPU by around 1.55 times, with the FPGA consuming 4.7 times less power and delivering around seven times the power efficiency of the CPU.",
        "published": "2021-07-28T17:10:50Z",
        "link": "http://arxiv.org/abs/2108.03982v1",
        "categories": [
            "cs.DC",
            "cs.MS"
        ]
    },
    {
        "title": "Accelerating advection for atmospheric modelling on Xilinx and Intel   FPGAs",
        "authors": [
            "Nick Brown"
        ],
        "summary": "Reconfigurable architectures, such as FPGAs, enable the execution of code at the electronics level, avoiding the assumptions imposed by the general purpose black-box micro-architectures of CPUs and GPUs. Such tailored execution can result in increased performance and power efficiency, and as the HPC community moves towards exascale an important question is the role such hardware technologies can play in future supercomputers.   In this paper we explore the porting of the PW advection kernel, an important code component used in a variety of atmospheric simulations and accounting for around 40\\% of the runtime of the popular Met Office NERC Cloud model (MONC). Building upon previous work which ported this kernel to an older generation of Xilinx FPGA, we target latest generation Xilinx Alveo U280 and Intel Stratix 10 FPGAs. Exploring the development of a dataflow design which is performance portable between vendors, we then describe implementation differences between the tool chains and compare kernel performance between FPGA hardware. This is followed by a more general performance comparison, scaling up the number of kernels on the Xilinx Alveo and Intel Stratix 10, against a 24 core Xeon Platinum Cascade Lake CPU and NVIDIA Tesla V100 GPU. When overlapping the transfer of data to and from the boards with compute, the FPGA solutions considerably outperform the CPU and, whilst falling short of the GPU in terms of performance, demonstrate power usage benefits, with the Alveo being especially power efficient. The result of this work is a comparison and set of design techniques that apply both to this specific atmospheric advection kernel on Xilinx and Intel FPGAs, and that are also of interest more widely when looking to accelerate HPC codes on a variety of reconfigurable architectures.",
        "published": "2021-07-28T17:14:01Z",
        "link": "http://arxiv.org/abs/2107.13500v1",
        "categories": [
            "cs.DC",
            "cs.MS"
        ]
    },
    {
        "title": "High Performance Uncertainty Quantification with Parallelized Multilevel   Markov Chain Monte Carlo",
        "authors": [
            "Linus Seelinger",
            "Anne Reinarz",
            "Leonhard Rannabauer",
            "Michael Bader",
            "Peter Bastian",
            "Robert Scheichl"
        ],
        "summary": "Numerical models of complex real-world phenomena often necessitate High Performance Computing (HPC). Uncertainties increase problem dimensionality further and pose even greater challenges.   We present a parallelization strategy for multilevel Markov chain Monte Carlo, a state-of-the-art, algorithmically scalable Uncertainty Quantification (UQ) algorithm for Bayesian inverse problems, and a new software framework allowing for large-scale parallelism across forward model evaluations and the UQ algorithms themselves. The main scalability challenge presents itself in the form of strong data dependencies introduced by the MLMCMC method, prohibiting trivial parallelization.   Our software is released as part of the modular and open-source MIT UQ Library (MUQ), and can easily be coupled with arbitrary user codes. We demonstrate it using the DUNE and the ExaHyPE Engine. The latter provides a realistic, large-scale tsunami model in which identify the source of a tsunami from buoy-elevation data.",
        "published": "2021-07-30T11:09:23Z",
        "link": "http://arxiv.org/abs/2107.14552v1",
        "categories": [
            "cs.MS",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "High-Performance Level-1 and Level-2 BLAS",
        "authors": [
            "Amit Singh",
            "Cem Bassoy"
        ],
        "summary": "The introduction of the Basic Linear Algebra Subroutine (BLAS) in the 1970s paved the way for different libraries to solve the same problem with an improved approach and hardware. The new BLAS implementation led to High-Performance Computing (HPC) innovation. All the love went to the level 3 BLAS due to its humongous application in different fields, not bounded by computer science. However, level 1 and level 2 got neglected; we tried to solve the problem by introducing the new algorithm for the Vector-Vector dot product, Vector-Vector outer product and Matrix-Vector product, which improves the performance of these operations in a significant way. We are not introducing any library but algorithms, which improves upon the current state of art algorithms. Also, we rely on the FMA instruction, OpenMP, and the compiler to optimize the code rather than implementing the algorithm in assembly. Therefore, our current implementation is machine oblivious and depends on the compilers ability to optimize the code.",
        "published": "2021-08-04T12:51:12Z",
        "link": "http://arxiv.org/abs/2108.02025v1",
        "categories": [
            "cs.MS",
            "cs.CC",
            "68Q17(Primary), 15A99(Secondary)"
        ]
    },
    {
        "title": "Partial Reuse AMG Setup Cost Amortization Strategy for the Solution of   Non-Steady State Problems",
        "authors": [
            "D. E. Demidov"
        ],
        "summary": "The partial reuse algebraic multigrid (AMG) setup cost amortization strategy is presented for the solution of non-steady state problems. The transfer operators are reused from the previous time steps, and the system matrices and the smoother operators are rebuilt on each of the AMG hierarchy levels. It is shown on the example of modelling a two-fluid dam break scenario that the strategy may decrease the AMG preconditioner setup cost by 40% to 200%. The total compute time is decreased by up to 20%, but the specific outcome depends on the fraction of time that the setup step initially takes.",
        "published": "2021-08-04T13:32:17Z",
        "link": "http://arxiv.org/abs/2108.02054v1",
        "categories": [
            "cs.MS",
            "35-04, 65-04, 65Y05, 65Y10, 65Y15, 97N80"
        ]
    },
    {
        "title": "Improving MATLAB's isprime performance without arbitrary-precision   arithmetic",
        "authors": [
            "Travis Near"
        ],
        "summary": "MATLAB is a numerical computing platform used by scientists, engineers, mathematicians, and students which contains many mathematical functions, including isprime. MATLAB's isprime function determines which elements of an input array are prime. This research details modular arithmetic techniques, the Miller-Rabin primality test, vectorized operations, and division-minimizing strategies which harness the power of MATLAB's capabilities to improve isprime's performance. The results are typically 5 to 10 times faster for small integers and many hundreds of times faster for large integers and long arrays.",
        "published": "2021-08-08T17:26:14Z",
        "link": "http://arxiv.org/abs/2108.04791v1",
        "categories": [
            "cs.MS",
            "cs.CR",
            "cs.PF"
        ]
    },
    {
        "title": "Parallel Sub-Structuring Methods for solving Sparse Linear Systems on a   cluster of GPU",
        "authors": [
            "Abal-Kassim Cheik Ahamed",
            "Frédéric Magoulès"
        ],
        "summary": "The main objective of this work consists in analyzing sub-structuring method for the parallel solution of sparse linear systems with matrices arising from the discretization of partial differential equations such as finite element, finite volume and finite difference. With the success encountered by the general-purpose processing on graphics processing units (GPGPU), we develop an hybrid multiGPUs and CPUs sub-structuring algorithm. GPU computing, with CUDA, is used to accelerate the operations performed on each processor. Numerical experiments have been performed on a set of matrices arising from engineering problems. We compare C+MPI implementation on classical CPU cluster with C+MPI+CUDA on a cluster of GPU. The performance comparison shows a speed-up for the sub-structuring method up to 19 times in double precision by using CUDA.",
        "published": "2021-08-08T19:41:11Z",
        "link": "http://arxiv.org/abs/2108.13162v1",
        "categories": [
            "math.NA",
            "cs.DC",
            "cs.MS",
            "cs.NA",
            "14Q65, 15A60, 65E10, 65F10, 68W10, 65Y05",
            "G.1.3; G.1.6; I.3.1; D.3.4"
        ]
    },
    {
        "title": "Grassland: A Rapid Algebraic Modeling System for Million-variable   Optimization",
        "authors": [
            "Xihan Li",
            "Xiongwei Han",
            "Zhishuo Zhou",
            "Mingxuan Yuan",
            "Jia Zeng",
            "Jun Wang"
        ],
        "summary": "An algebraic modeling system (AMS) is a type of mathematical software for optimization problems, which allows users to define symbolic mathematical models in a specific language, instantiate them with given source of data, and solve them with the aid of external solver engines. With the bursting scale of business models and increasing need for timeliness, traditional AMSs are not sufficient to meet the following industry needs: 1) million-variable models need to be instantiated from raw data very efficiently; 2) Strictly feasible solution of million-variable models need to be delivered in a rapid manner to make up-to-date decisions against highly dynamic environments. Grassland is a rapid AMS that provides an end-to-end solution to tackle these emerged new challenges. It integrates a parallelized instantiation scheme for large-scale linear constraints, and a sequential decomposition method that accelerates model solving exponentially with an acceptable loss of optimality. Extensive benchmarks on both classical models and real enterprise scenario demonstrate 6 ~ 10x speedup of Grassland over state-of-the-art solutions on model instantiation. Our proposed system has been deployed in the large-scale real production planning scenario of Huawei. With the aid of our decomposition method, Grassland successfully accelerated Huawei's million-variable production planning simulation pipeline from hours to 3 ~ 5 minutes, supporting near-real-time production plan decision making against highly dynamic supply-demand environment.",
        "published": "2021-08-10T11:02:54Z",
        "link": "http://arxiv.org/abs/2108.04586v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "Adaptive numerical simulations with Trixi.jl: A case study of Julia for   scientific computing",
        "authors": [
            "Hendrik Ranocha",
            "Michael Schlottke-Lakemper",
            "Andrew R. Winters",
            "Erik Faulhaber",
            "Jesse Chan",
            "Gregor J. Gassner"
        ],
        "summary": "We present Trixi.jl, a Julia package for adaptive high-order numerical simulations of hyperbolic partial differential equations. Utilizing Julia's strengths, Trixi.jl is extensible, easy to use, and fast. We describe the main design choices that enable these features and compare Trixi.jl with a mature open source Fortran code that uses the same numerical methods. We conclude with an assessment of Julia for simulation-focused scientific computing, an area that is still dominated by traditional high-performance computing languages such as C, C++, and Fortran.",
        "published": "2021-08-14T06:20:32Z",
        "link": "http://arxiv.org/abs/2108.06476v2",
        "categories": [
            "cs.MS",
            "cs.NA",
            "math.NA",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Vertical, Temporal, and Horizontal Scaling of Hierarchical Hypersparse   GraphBLAS Matrices",
        "authors": [
            "Jeremy Kepner",
            "Tim Davis",
            "Chansup Byun",
            "William Arcand",
            "David Bestor",
            "William Bergeron",
            "Vijay Gadepally",
            "Matthew Hubbell",
            "Michael Houle",
            "Michael Jones",
            "Anna Klein",
            "Lauren Milechin",
            "Julie Mullen",
            "Andrew Prout",
            "Albert Reuther",
            "Antonio Rosa",
            "Siddharth Samsi",
            "Charles Yee",
            "Peter Michaleas"
        ],
        "summary": "Hypersparse matrices are a powerful enabler for a variety of network, health, finance, and social applications. Hierarchical hypersparse GraphBLAS matrices enable rapid streaming updates while preserving algebraic analytic power and convenience. In many contexts, the rate of these updates sets the bounds on performance. This paper explores hierarchical hypersparse update performance on a variety of hardware with identical software configurations. The high-level language bindings of the GraphBLAS readily enable performance experiments on simultaneous diverse hardware. The best single process performance measured was 4,000,000 updates per second. The best single node performance measured was 170,000,000 updates per second. The hardware used spans nearly a decade and allows a direct comparison of hardware improvements for this computation over this time range; showing a 2x increase in single-core performance, a 3x increase in single process performance, and a 5x increase in single node performance. Running on nearly 2,000 MIT SuperCloud nodes simultaneously achieved a sustained update rate of over 200,000,000,000 updates per second. Hierarchical hypersparse GraphBLAS allows the MIT SuperCloud to analyze extremely large streaming network data sets.",
        "published": "2021-08-15T03:02:21Z",
        "link": "http://arxiv.org/abs/2108.06650v1",
        "categories": [
            "cs.DC",
            "cs.DM",
            "cs.MS",
            "cs.NI",
            "cs.PF"
        ]
    },
    {
        "title": "RLIBM-ALL: A Novel Polynomial Approximation Method to Produce Correctly   Rounded Results for Multiple Representations and Rounding Modes",
        "authors": [
            "Jay P. Lim",
            "Santosh Nagarakatte"
        ],
        "summary": "Mainstream math libraries for floating point (FP) do not produce correctly rounded results for all inputs. In contrast, CR-LIBM and RLIBM provide correctly rounded implementations for a specific FP representation with one rounding mode. Using such libraries for a representation with a new rounding mode or with different precision will result in wrong results due to double rounding. This paper proposes a novel method to generate a single polynomial approximation that produces correctly rounded results for all inputs for multiple rounding modes and multiple precision configurations. To generate a correctly rounded library for $n$-bits, our key idea is to generate such a polynomial approximation for a representation with $n+2$-bits using the \\emph{round-to-odd} mode. We prove that the resulting polynomial approximation will produce correctly rounded results for all five rounding modes in the standard and for multiple representations with $k$-bits such that $|E| +1 < k \\leq n$, where $|E|$ is the number of exponent bits in the representation. Building on our prior work in the RLIBM project, we also approximate the correctly rounded result when we generate the library with $n+2$-bits using the round-to-odd mode. We also generate polynomial approximations by structuring it as a linear programming problem but propose enhancements to polynomial generation to handle the round-to-odd mode. Our prototype is the first 32-bit float library that produces correctly rounded results with all rounding modes in the IEEE standard for all inputs with a single polynomial approximation. It also produces correctly rounded results for any FP configuration ranging from 10-bits to 32-bits while also being faster than mainstream libraries.",
        "published": "2021-08-15T14:44:50Z",
        "link": "http://arxiv.org/abs/2108.06756v2",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "Parallel time integration using Batched BLAS (Basic Linear Algebra   Subprograms) routines",
        "authors": [
            "Konstantin Herb",
            "Pol Welter"
        ],
        "summary": "We present an approach for integrating the time evolution of quantum systems. We leverage the computation power of graphics processing units (GPUs) to perform the integration of all time steps in parallel. The performance boost is especially prominent for small to medium-sized quantum systems. The devised algorithm can largely be implemented using the recently-specified batched versions of the BLAS routines, and can therefore be easily ported to a variety of platforms. Our PARAllelized Matrix Exponentiation for Numerical Time evolution (PARAMENT) implementation runs on CUDA-enabled graphics processing units.",
        "published": "2021-08-16T14:49:04Z",
        "link": "http://arxiv.org/abs/2108.07126v1",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "physics.comp-ph",
            "quant-ph"
        ]
    },
    {
        "title": "PyParSVD: A streaming, distributed and randomized   singular-value-decomposition library",
        "authors": [
            "Romit Maulik",
            "Gianmarco Mengaldo"
        ],
        "summary": "We introduce PyParSVD\\footnote{https://github.com/Romit-Maulik/PyParSVD}, a Python library that implements a streaming, distributed and randomized algorithm for the singular value decomposition. To demonstrate its effectiveness, we extract coherent structures from scientific data. Futhermore, we show weak scaling assessments on up to 256 nodes of the Theta machine at Argonne Leadership Computing Facility, demonstrating potential for large-scale data analyses of practical data sets.",
        "published": "2021-08-19T05:25:47Z",
        "link": "http://arxiv.org/abs/2108.08845v1",
        "categories": [
            "cs.MS",
            "cs.DC",
            "physics.ao-ph",
            "physics.flu-dyn"
        ]
    },
    {
        "title": "Fast MATLAB evaluation of nonlinear energies using FEM in 2D and 3D:   nodal elements",
        "authors": [
            "Alexej Moskovka",
            "Jan Valdman"
        ],
        "summary": "Nonlinear energy functionals appearing in the calculus of variations can be discretized by the finite element (FE) method and formulated as a sum of energy contributions from local elements. A fast evaluation of energy functionals containing the first order gradient terms is a central part of this contribution. We describe a vectorized implementation using the simplest linear nodal (P1) elements in which all energy contributions are evaluated all at once without the loop over triangular or tetrahedral elements. Furthermore, in connection to the first-order optimization methods, the discrete gradient of energy functional is assembled in a way that the gradient components are evaluated over all degrees of freedom all at once. The key ingredient is the vectorization of exact or approximate energy gradients over nodal patches. It leads to a time-efficient implementation at higher memory-cost. Provided codes in MATLAB related to 2D/3D hyperelasticity and 2D p-Laplacian problem are available for download and structured in a way it can be easily extended to other types of vector or scalar forms of energies.",
        "published": "2021-08-22T21:00:21Z",
        "link": "http://arxiv.org/abs/2109.01158v2",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "Reachability of weakly nonlinear systems using Carleman linearization",
        "authors": [
            "Marcelo Forets",
            "Christian Schilling"
        ],
        "summary": "In this article we introduce a solution method for a special class of nonlinear initial-value problems using set-based propagation techniques. The novelty of the approach is that we employ a particular embedding (Carleman linearization) to leverage recent advances of high-dimensional reachability solvers for linear ordinary differential equations based on the support function. Using a global error bound for the Carleman linearization abstraction, we are able to describe the full set of behaviors of the system for sets of initial conditions and in dense time.",
        "published": "2021-08-23T20:19:43Z",
        "link": "http://arxiv.org/abs/2108.10390v2",
        "categories": [
            "math.OC",
            "cs.MS",
            "cs.SY",
            "eess.SY",
            "math.DS"
        ]
    },
    {
        "title": "An Efficient ADER-DG Local Time Stepping Scheme for 3D HPC Simulation of   Seismic Waves in Poroelastic Media",
        "authors": [
            "Sebastian Wolf",
            "Martin Galis",
            "Carsten Uphoff",
            "Alice-Agnes Gabriel",
            "Peter Moczo",
            "David Gregor",
            "Michael Bader"
        ],
        "summary": "Many applications from geosciences require simulations of seismic waves in porous media. Biot's theory of poroelasticity describes the coupling between solid and fluid phases and introduces a stiff source term, thereby increasing computational cost and motivating efficient methods utilising High-Performance Computing. We present a novel realisation of the discontinuous Galerkin scheme with Arbitrary DERivative time stepping (ADER-DG) that copes with stiff source terms.   To integrate this source term with a reasonable time step size, we use an element-local space-time predictor, which needs to solve medium-sized linear systems - with 1000 to 10000 unknowns - in each element update (i.e., billions of times). We present a novel block-wise back-substitution algorithm for solving these systems efficiently. In comparison to LU decomposition, we reduce the number of floating-point operations by a factor of up to 25. The block-wise back-substitution is mapped to a sequence of small matrix-matrix multiplications, for which code generators are available to generate highly optimised code.   We verify the new solver thoroughly in problems of increasing complexity. We demonstrate high-order convergence for 3D problems. We verify the correct treatment of point sources, material interfaces and traction-free boundary conditions. In addition, we compare against a finite difference code for a newly defined layer over half-space problem. We find that extremely high accuracy is required to resolve the slow P-wave at a free surface, while solid particle velocities are not affected by coarser resolutions. By using a clustered local time stepping scheme, we reduce time to solution by a factor of 6 to 10 compared to global time stepping. We conclude our study with a scaling and performance analysis, demonstrating our implementation's efficiency and its potential for extreme-scale simulations.",
        "published": "2021-08-24T08:04:13Z",
        "link": "http://arxiv.org/abs/2108.10565v3",
        "categories": [
            "cs.DC",
            "cs.MS",
            "physics.comp-ph",
            "physics.geo-ph"
        ]
    },
    {
        "title": "Communication-hiding pipelined BiCGSafe methods for solving large linear   systems",
        "authors": [
            "Viet Q. H. Huynh",
            "Hiroshi Suito"
        ],
        "summary": "Recently, a new variant of the BiCGStab method, known as the pipeline BiCGStab, has been proposed. This method can achieve a higher degree of scalability and speed-up rates through a mechanism in which the communication phase for the computation of the inner product can be overlapped with the computation of the matrix-vector product. On the other hand, there exist several generalized iteration methods with better convergence behavior than BiCGStab such as ssBiCGSafe, BiCGSafe, GPBi-CG. Of these methods, ssBiCGSafe, which requires a single phase of computing inner products per one iteration, is best suited for high-performance computing systems. In this paper, inspired by the success of the pipelined BiCGStab method, we propose variations of the ssBiCGSafe method, in which only one phase of inner product computation per iteration is required and this inner product computation phase can be overlapped with the matrix-vector computation. Through numerical experiments, we show that the proposed methods lead to improvements in convergence behavior and execution time compared to the pipelined BiCGStab and ssBiCGSafe methods.",
        "published": "2021-08-24T09:16:15Z",
        "link": "http://arxiv.org/abs/2108.10591v2",
        "categories": [
            "cs.DC",
            "cs.MS"
        ]
    },
    {
        "title": "H2OPUS-TLR: High Performance Tile Low Rank Symmetric Factorizations   using Adaptive Randomized Approximation",
        "authors": [
            "Wajih Boukaram",
            "Stefano Zampini",
            "George Turkiyyah",
            "David Keyes"
        ],
        "summary": "Tile low rank representations of dense matrices partition them into blocks of roughly uniform size, where each off-diagonal tile is compressed and stored as its own low rank factorization. They offer an attractive representation for many data-sparse dense operators that appear in practical applications, where substantial compression and a much smaller memory footprint can be achieved. TLR matrices are a compromise between the simplicity of a regular perfectly-strided data structure and the optimal complexity of the unbalanced trees of hierarchically low rank matrices, and provide a convenient performance-tuning parameter through their tile size that can be proportioned to take into account the cache size where the tiles reside in the memory hierarchy.   There are currently no high-performance algorithms that can generate Cholesky and $LDL^T$ factorizations, particularly on GPUs. The difficulties in achieving high performance when factoring TLR matrices come from the expensive compression operations that must be performed during the factorization process and the adaptive rank distribution of the tiles that causes an irregular work pattern for the processing cores. In this work, we develop a dynamic batching operation and combine it with batched adaptive randomized approximations to achieve high performance both on GPUs and CPUs.   Our implementation attains over 1.2 TFLOP/s in double precision on the V100 GPU, and is limited by the performance of batched GEMM operations. The Cholesky factorization of covariance matrix of size $N = 131K$ arising in spatial statistics can be factored to an accuracy $\\epsilon=10^{-2}$ in just a few seconds. We believe the proposed GEMM-centric algorithm allows it to be readily ported to newer hardware such as the tensor cores that are optimized for small GEMM operations.",
        "published": "2021-08-26T17:43:37Z",
        "link": "http://arxiv.org/abs/2108.11932v1",
        "categories": [
            "cs.DC",
            "cs.MS",
            "65F05, 65F08, 65F55",
            "G.4"
        ]
    },
    {
        "title": "The ensmallen library for flexible numerical optimization",
        "authors": [
            "Ryan R. Curtin",
            "Marcus Edel",
            "Rahul Ganesh Prabhu",
            "Suryoday Basak",
            "Zhihao Lou",
            "Conrad Sanderson"
        ],
        "summary": "We overview the ensmallen numerical optimization library, which provides a flexible C++ framework for mathematical optimization of user-supplied objective functions. Many types of objective functions are supported, including general, differentiable, separable, constrained, and categorical. A diverse set of pre-built optimizers is provided, including Quasi-Newton optimizers and many variants of Stochastic Gradient Descent. The underlying framework facilitates the implementation of new optimizers. Optimization of an objective function typically requires supplying only one or two C++ functions. Custom behavior can be easily specified via callback functions. Empirical comparisons show that ensmallen outperforms other frameworks while providing more functionality. The library is available at https://ensmallen.org and is distributed under the permissive BSD license.",
        "published": "2021-08-30T03:49:21Z",
        "link": "http://arxiv.org/abs/2108.12981v2",
        "categories": [
            "cs.MS",
            "cs.SE",
            "math.OC",
            "65K10, 68N99",
            "G.4; G.1.3; G.1.6"
        ]
    },
    {
        "title": "A New Test for Hamming-Weight Dependencies",
        "authors": [
            "David Blackman",
            "Sebastiano Vigna"
        ],
        "summary": "We describe a new statistical test for pseudorandom number generators (PRNGs). Our test can find bias induced by dependencies among the Hamming weights of the outputs of a PRNG, even for PRNGs that pass state-of-the-art tests of the same kind from the literature, and in particular for generators based on $\\mathbf F_2$-linear transformations such as the dSFMT, xoroshiro1024+, and WELL512.",
        "published": "2021-08-30T08:43:23Z",
        "link": "http://arxiv.org/abs/2108.13061v2",
        "categories": [
            "cs.DS",
            "cs.MS"
        ]
    },
    {
        "title": "Accelerating an Iterative Eigensolver for Nuclear Structure   Configuration Interaction Calculations on GPUs using OpenACC",
        "authors": [
            "Pieter Maris",
            "Chao Yang",
            "Dossay Oryspayev",
            "Brandon Cook"
        ],
        "summary": "To accelerate the solution of large eigenvalue problems arising from many-body calculations in nuclear physics on distributed-memory parallel systems equipped with general-purpose Graphic Processing Units (GPUs), we modified a previously developed hybrid MPI/OpenMP implementation of an eigensolver written in FORTRAN 90 by using an OpenACC directives based programming model. Such an approach requires making minimal changes to the original code and enables a smooth migration of large-scale nuclear structure simulations from a distributed-memory many-core CPU system to a distributed GPU system. However, in order to make the OpenACC based eigensolver run efficiently on GPUs, we need to take into account the architectural differences between a many-core CPU and a GPU device. Consequently, the optimal way to insert OpenACC directives may be different from the original way of inserting OpenMP directives. We point out these differences in the implementation of sparse matrix-matrix multiplications (SpMM), which constitutes the main cost of the eigensolver, as well as other differences in the preconditioning step and dense linear algebra operations. We compare the performance of the OpenACC based implementation executed on multiple GPUs with the performance on distributed-memory many-core CPUs, and demonstrate significant speedup achieved on GPUs compared to the on-node performance of a many-core CPU. We also show that the overall performance improvement of the eigensolver on multiple GPUs is more modest due to the communication overhead among different MPI ranks.",
        "published": "2021-09-01T16:55:31Z",
        "link": "http://arxiv.org/abs/2109.00485v1",
        "categories": [
            "cs.DC",
            "cs.MS",
            "cs.NA",
            "math.NA",
            "nucl-th"
        ]
    },
    {
        "title": "RIFLE: Imputation and Robust Inference from Low Order Marginals",
        "authors": [
            "Sina Baharlouei",
            "Kelechi Ogudu",
            "Sze-chuan Suen",
            "Meisam Razaviyayn"
        ],
        "summary": "The ubiquity of missing values in real-world datasets poses a challenge for statistical inference and can prevent similar datasets from being analyzed in the same study, precluding many existing datasets from being used for new analyses. While an extensive collection of packages and algorithms have been developed for data imputation, the overwhelming majority perform poorly if there are many missing values and low sample sizes, which are unfortunately common characteristics in empirical data. Such low-accuracy estimations adversely affect the performance of downstream statistical models. We develop a statistical inference framework for regression and classification in the presence of missing data without imputation. Our framework, RIFLE (Robust InFerence via Low-order moment Estimations), estimates low-order moments of the underlying data distribution with corresponding confidence intervals to learn a distributionally robust model. We specialize our framework to linear regression and normal discriminant analysis, and we provide convergence and performance guarantees. This framework can also be adapted to impute missing data. In numerical experiments, we compare RIFLE to several state-of-the-art approaches (including MICE, Amelia, MissForest, KNN-imputer, MIDA, and Mean Imputer) for imputation and inference in the presence of missing values. Our experiments demonstrate that RIFLE outperforms other benchmark algorithms when the percentage of missing values is high and/or when the number of data points is relatively small. RIFLE is publicly available at https://github.com/optimization-for-data-driven-science/RIFLE.",
        "published": "2021-09-01T23:17:30Z",
        "link": "http://arxiv.org/abs/2109.00644v3",
        "categories": [
            "cs.LG",
            "cs.MS"
        ]
    },
    {
        "title": "dbcsp: User-friendly R package for Distance-Based Common Spacial   Patterns",
        "authors": [
            "Itsaso Rodriguez",
            "Itziar Irigoien",
            "Basilio Sierra",
            "Concepcion Arenas"
        ],
        "summary": "Common Spacial Patterns (CSP) is a widely used method to analyse electroencephalography (EEG) data, concerning the supervised classification of brain's activity. More generally, it can be useful to distinguish between multivariate signals recorded during a time span for two different classes. CSP is based on the simultaneous diagonalization of the average covariance matrices of signals from both classes and it allows to project the data into a low-dimensional subspace. Once data are represented in a low-dimensional subspace, a classification step must be carried out. The original CSP method is based on the Euclidean distance between signals and here, we extend it so that it can be applied on any appropriate distance for data at hand. Both, the classical CSP and the new Distance-Based CSP (DB-CSP) are implemented in an R package, called dbcsp.",
        "published": "2021-09-02T06:42:56Z",
        "link": "http://arxiv.org/abs/2109.00740v1",
        "categories": [
            "cs.MS",
            "eess.SP"
        ]
    },
    {
        "title": "A Study of Mixed Precision Strategies for GMRES on GPUs",
        "authors": [
            "Jennifer A. Loe",
            "Christian A. Glusa",
            "Ichitaro Yamazaki",
            "Erik G. Boman",
            "Sivasankaran Rajamanickam"
        ],
        "summary": "Support for lower precision computation is becoming more common in accelerator hardware due to lower power usage, reduced data movement and increased computational performance. However, computational science and engineering (CSE) problems require double precision accuracy in several domains. This conflict between hardware trends and application needs has resulted in a need for mixed precision strategies at the linear algebra algorithms level if we want to exploit the hardware to its full potential while meeting the accuracy requirements. In this paper, we focus on preconditioned sparse iterative linear solvers, a key kernel in several CSE applications. We present a study of mixed precision strategies for accelerating this kernel on an NVIDIA V$100$ GPU with a Power 9 CPU. We seek the best methods for incorporating multiple precisions into the GMRES linear solver; these include iterative refinement and parallelizable preconditioners. Our work presents strategies to determine when mixed precision GMRES will be effective and to choose parameters for a mixed precision iterative refinement solver to achieve better performance. We use an implementation that is based on the Trilinos library and employs Kokkos Kernels for performance portability of linear algebra kernels. Performance results demonstrate the promise of mixed precision approaches and demonstrate even further improvements are possible by optimizing low-level kernels.",
        "published": "2021-09-02T22:27:18Z",
        "link": "http://arxiv.org/abs/2109.01232v1",
        "categories": [
            "cs.DC",
            "cs.MS",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Achieving near native runtime performance and cross-platform performance   portability for random number generation through SYCL interoperability",
        "authors": [
            "Vincent R. Pascuzzi",
            "Mehdi Goli"
        ],
        "summary": "High-performance computing (HPC) is a major driver accelerating scientific research and discovery, from quantum simulations to medical therapeutics. While the increasing availability of HPC resources is in many cases pivotal to successful science, even the largest collaborations lack the computational expertise required for maximal exploitation of current hardware capabilities. The need to maintain multiple platform-specific codebases further complicates matters, potentially adding constraints on machines that can be utilized. Fortunately, numerous programming models are under development that aim to facilitate portable codes for heterogeneous computing. One in particular is SYCL, an open standard, C++-based single-source programming paradigm. Among SYCL's features is interoperability, a mechanism through which applications and third-party libraries coordinate sharing data and execute collaboratively. In this paper, we leverage the SYCL programming model to demonstrate cross-platform performance portability across heterogeneous resources. We detail our NVIDIA and AMD random number generator extensions to the oneMKL open-source interfaces library. Performance portability is measured relative to platform-specific baseline applications executed on four major hardware platforms using two different compilers supporting SYCL. The utility of our extensions are exemplified in a real-world setting via a high-energy physics simulation application. We show the performance of implementations that capitalize on SYCL interoperability are at par with native implementations, attesting to the cross-platform performance portability of a SYCL-based approach to scientific codes.",
        "published": "2021-09-03T06:14:30Z",
        "link": "http://arxiv.org/abs/2109.01329v2",
        "categories": [
            "cs.DC",
            "cs.MS",
            "hep-ex"
        ]
    },
    {
        "title": "The full Low-carbon Expansion Generation Optimization (LEGO) model",
        "authors": [
            "Sonja Wogrin",
            "Diego A. Tejada-Arango",
            "Udo Bachhiesl",
            "Benjamin F. Hobbs"
        ],
        "summary": "This paper introduces the full Low-carbon Expansion Generation Optimization (LEGO) model available on Github (https://github.com/wogrin/LEGO). LEGO is a mixed-integer quadratically constrained optimization problem and has been designed to be a multi-purpose tool, like a Swiss army knife, that can be employed to study many different aspects of the energy sector. Ranging from short-term unit commitment to long-term generation and transmission expansion planning. The underlying modeling philosophies are: modularity and flexibility. Its unique temporal structure allows LEGO to function with either chronological hourly data, or all kinds of representative periods. LEGO is also composed of thematic modules that can be added or removed from the model easily via data options depending on the scope of the study. Those modules include: unit commitment constraints; DC- or AC-OPF formulations; battery degradation; rate of change of frequency inertia constraints; demand-side management; or the hydrogen sector. LEGO also provides a plethora of model outputs (both primal and dual), which is the basis for both technical but also economic analyses. To our knowledge, there is no model that combines all of these capabilities, which we hereby make freely available to the scientific community.",
        "published": "2021-09-03T08:32:58Z",
        "link": "http://arxiv.org/abs/2109.01368v2",
        "categories": [
            "math.OC",
            "cs.CE",
            "cs.MS",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "OGRe: An Object-Oriented General Relativity Package for Mathematica",
        "authors": [
            "Barak Shoshany"
        ],
        "summary": "We present OGRe, a modern Mathematica package for tensor calculus, designed to be both powerful and user-friendly. The package can be used in a variety of contexts where tensor calculations are needed, in both mathematics and physics, but it is especially suitable for general relativity. By implementing an object-oriented design paradigm, OGRe allows calculating arbitrarily complicated tensor formulas easily, and automatically transforms between index configurations and coordinate systems behind the scenes as needed, eliminating user errors by making it impossible for the user to combine tensors in inconsistent ways. Other features include displaying tensors in various forms, automatic calculation of curvature tensors and geodesic equations, easy importing and exporting of tensors between sessions, optimized algorithms and parallelization for improved performance, and more.",
        "published": "2021-09-06T00:31:23Z",
        "link": "http://arxiv.org/abs/2109.04193v1",
        "categories": [
            "cs.MS",
            "cs.SC",
            "gr-qc",
            "math.DG"
        ]
    },
    {
        "title": "Efficient Exascale Discretizations: High-Order Finite Element Methods",
        "authors": [
            "Tzanio Kolev",
            "Paul Fischer",
            "Misun Min",
            "Jack Dongarra",
            "Jed Brown",
            "Veselin Dobrev",
            "Tim Warburton",
            "Stanimire Tomov",
            "Mark S. Shephard",
            "Ahmad Abdelfattah",
            "Valeria Barra",
            "Natalie Beams",
            "Jean-Sylvain Camier",
            "Noel Chalmers",
            "Yohann Dudouit",
            "Ali Karakus",
            "Ian Karlin",
            "Stefan Kerkemeier",
            "Yu-Hsiang Lan",
            "David Medina",
            "Elia Merzari",
            "Aleksandr Obabko",
            "Will Pazner",
            "Thilina Rathnayake",
            "Cameron W. Smith",
            "Lukas Spies",
            "Kasia Swirydowicz",
            "Jeremy Thompson",
            "Ananias Tomboulides",
            "Vladimir Tomov"
        ],
        "summary": "Efficient exploitation of exascale architectures requires rethinking of the numerical algorithms used in many large-scale applications. These architectures favor algorithms that expose ultra fine-grain parallelism and maximize the ratio of floating point operations to energy intensive data movement. One of the few viable approaches to achieve high efficiency in the area of PDE discretizations on unstructured grids is to use matrix-free/partially-assembled high-order finite element methods, since these methods can increase the accuracy and/or lower the computational time due to reduced data motion. In this paper we provide an overview of the research and development activities in the Center for Efficient Exascale Discretizations (CEED), a co-design center in the Exascale Computing Project that is focused on the development of next-generation discretization software and algorithms to enable a wide range of finite element applications to run efficiently on future hardware. CEED is a research partnership involving more than 30 computational scientists from two US national labs and five universities, including members of the Nek5000, MFEM, MAGMA and PETSc projects. We discuss the CEED co-design activities based on targeted benchmarks, miniapps and discretization libraries and our work on performance optimizations for large-scale GPU architectures. We also provide a broad overview of research and development activities in areas such as unstructured adaptive mesh refinement algorithms, matrix-free linear solvers, high-order data visualization, and list examples of collaborations with several ECP and external applications.",
        "published": "2021-09-10T17:07:48Z",
        "link": "http://arxiv.org/abs/2109.04996v1",
        "categories": [
            "cs.DC",
            "cs.MS",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "GPU Algorithms for Efficient Exascale Discretizations",
        "authors": [
            "Ahmad Abdelfattah",
            "Valeria Barra",
            "Natalie Beams",
            "Ryan Bleile",
            "Jed Brown",
            "Jean-Sylvain Camier",
            "Robert Carson",
            "Noel Chalmers",
            "Veselin Dobrev",
            "Yohann Dudouit",
            "Paul Fischer",
            "Ali Karakus",
            "Stefan Kerkemeier",
            "Tzanio Kolev",
            "Yu-Hsiang Lan",
            "Elia Merzari",
            "Misun Min",
            "Malachi Phillips",
            "Thilina Rathnayake",
            "Robert Rieben",
            "Thomas Stitt",
            "Ananias Tomboulides",
            "Stanimire Tomov",
            "Vladimir Tomov",
            "Arturo Vargas",
            "Tim Warburton",
            "Kenneth Weiss"
        ],
        "summary": "In this paper we describe the research and development activities in the Center for Efficient Exascale Discretization within the US Exascale Computing Project, targeting state-of-the-art high-order finite-element algorithms for high-order applications on GPU-accelerated platforms. We discuss the GPU developments in several components of the CEED software stack, including the libCEED, MAGMA, MFEM, libParanumal, and Nek projects. We report performance and capability improvements in several CEED-enabled applications on both NVIDIA and AMD GPU systems.",
        "published": "2021-09-10T19:17:02Z",
        "link": "http://arxiv.org/abs/2109.05072v1",
        "categories": [
            "cs.DC",
            "cs.MS",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "H2Opus: A distributed-memory multi-GPU software package for non-local   operators",
        "authors": [
            "Stefano Zampini",
            "Wajih Boukaram",
            "George Turkiyyah",
            "Omar Knio",
            "David E. Keyes"
        ],
        "summary": "Hierarchical $\\mathcal{H}^2$-matrices are asymptotically optimal representations for the discretizations of non-local operators such as those arising in integral equations or from kernel functions. Their $O(N)$ complexity in both memory and operator application makes them particularly suited for large-scale problems. As a result, there is a need for software that provides support for distributed operations on these matrices to allow large-scale problems to be represented. In this paper, we present high-performance, distributed-memory GPU-accelerated algorithms and implementations for matrix-vector multiplication and matrix recompression of hierarchical matrices in the $\\mathcal{H}^2$ format.   The algorithms are a new module of H2Opus, a performance-oriented package that supports a broad variety of $\\mathcal{H}^2$-matrix operations on CPUs and GPUs. Performance in the distributed GPU setting is achieved by marshaling the tree data of the hierarchical matrix representation to allow batched kernels to be executed on the individual GPUs. MPI is used for inter-process communication. We optimize the communication data volume and hide much of the communication cost with local compute phases of the algorithms. Results show near-ideal scalability up to 1024 NVIDIA V100 GPUs on Summit, with performance exceeding 2.3 Tflop/s/GPU for the matrix-vector multiplication, and 670 Gflops/s/GPU for matrix compression, which involves batched QR and SVD operations.   We illustrate the flexibility and efficiency of the library by solving a 2D variable diffusivity integral fractional diffusion problem with an algebraic multigrid-preconditioned Krylov solver and demonstrate scalability up to 16M degrees of freedom problems on 64 GPUs.",
        "published": "2021-09-12T07:32:41Z",
        "link": "http://arxiv.org/abs/2109.05451v1",
        "categories": [
            "cs.DC",
            "cs.MS",
            "65Y05, 65F55, 65R20, 65-04",
            "G.4; G.1.9"
        ]
    },
    {
        "title": "Arbitrary-precision computation of the gamma function",
        "authors": [
            "Fredrik Johansson"
        ],
        "summary": "We discuss the best methods available for computing the gamma function $\\Gamma(z)$ in arbitrary-precision arithmetic with rigorous error bounds. We address different cases: rational, algebraic, real or complex arguments; large or small arguments; low or high precision; with or without precomputation. The methods also cover the log-gamma function $\\log \\Gamma(z)$, the digamma function $\\psi(z)$, and derivatives $\\Gamma^{(n)}(z)$ and $\\psi^{(n)}(z)$. Besides attempting to summarize the existing state of the art, we present some new formulas, estimates, bounds and algorithmic improvements and discuss implementation results.",
        "published": "2021-09-17T07:58:43Z",
        "link": "http://arxiv.org/abs/2109.08392v1",
        "categories": [
            "cs.MS",
            "math.CA"
        ]
    },
    {
        "title": "Merlion: A Machine Learning Library for Time Series",
        "authors": [
            "Aadyot Bhatnagar",
            "Paul Kassianik",
            "Chenghao Liu",
            "Tian Lan",
            "Wenzhuo Yang",
            "Rowan Cassius",
            "Doyen Sahoo",
            "Devansh Arpit",
            "Sri Subramanian",
            "Gerald Woo",
            "Amrita Saha",
            "Arun Kumar Jagota",
            "Gokulakrishnan Gopalakrishnan",
            "Manpreet Singh",
            "K C Krithika",
            "Sukumar Maddineni",
            "Daeki Cho",
            "Bo Zong",
            "Yingbo Zhou",
            "Caiming Xiong",
            "Silvio Savarese",
            "Steven Hoi",
            "Huan Wang"
        ],
        "summary": "We introduce Merlion, an open-source machine learning library for time series. It features a unified interface for many commonly used models and datasets for anomaly detection and forecasting on both univariate and multivariate time series, along with standard pre/post-processing layers. It has several modules to improve ease-of-use, including visualization, anomaly score calibration to improve interpetability, AutoML for hyperparameter tuning and model selection, and model ensembling. Merlion also provides a unique evaluation framework that simulates the live deployment and re-training of a model in production. This library aims to provide engineers and researchers a one-stop solution to rapidly develop models for their specific time series needs and benchmark them across multiple time series datasets. In this technical report, we highlight Merlion's architecture and major functionalities, and we report benchmark numbers across different baseline models and ensembles.",
        "published": "2021-09-20T02:03:43Z",
        "link": "http://arxiv.org/abs/2109.09265v1",
        "categories": [
            "cs.LG",
            "cs.MS",
            "stat.ML"
        ]
    },
    {
        "title": "AbstractDifferentiation.jl: Backend-Agnostic Differentiable Programming   in Julia",
        "authors": [
            "Frank Schäfer",
            "Mohamed Tarek",
            "Lyndon White",
            "Chris Rackauckas"
        ],
        "summary": "No single Automatic Differentiation (AD) system is the optimal choice for all problems. This means informed selection of an AD system and combinations can be a problem-specific variable that can greatly impact performance. In the Julia programming language, the major AD systems target the same input and thus in theory can compose. Hitherto, switching between AD packages in the Julia Language required end-users to familiarize themselves with the user-facing API of the respective packages. Furthermore, implementing a new, usable AD package required AD package developers to write boilerplate code to define convenience API functions for end-users. As a response to these issues, we present AbstractDifferentiation.jl for the automatized generation of an extensive, unified, user-facing API for any AD package. By splitting the complexity between AD users and AD developers, AD package developers only need to implement one or two primitive definitions to support various utilities for AD users like Jacobians, Hessians and lazy product operators from native primitives such as pullbacks or pushforwards, thus removing tedious -- but so far inevitable -- boilerplate code, and enabling the easy switching and composing between AD implementations for end-users.",
        "published": "2021-09-25T22:19:12Z",
        "link": "http://arxiv.org/abs/2109.12449v2",
        "categories": [
            "cs.MS",
            "cs.LG",
            "cs.SE"
        ]
    },
    {
        "title": "The software design of Gridap: a Finite Element package based on the   Julia JIT compiler",
        "authors": [
            "Francesc Verdugo",
            "Santiago Badia"
        ],
        "summary": "We present the software design of Gridap, a novel finite element library written exclusively in the Julia programming language, which is being used by several research groups world-wide to simulate complex physical phenomena such as magnetohydrodynamics, photonics, weather modeling, non-linear solid mechanics, and fluid-structure interaction problems. The library provides a feature-rich set of discretization techniques for the numerical approximation of a wide range of PDEs, including linear, nonlinear, single-field, and multi-field equations. An expressive API allows users to define PDEs in weak form by a syntax close to the mathematical notation. While this is also available in previous codes, the main novelty of Gridap is that it implements this API without introducing a DSL plus a compiler of variational forms. Instead, it leverages the Julia just-in-time compiler to build efficient code, specialized for the concrete problem at hand. As a result, there is no need to use different languages for the computational back-end and the user front-end anymore, thus eliminating the so-called two-language problem. Gridap also provides a low-level API that is modular and extensible via the multiple-dispatch paradigm of Julia and provides easy access to the main building blocks of the library. The main contribution of this paper is the detailed presentation of the novel software abstractions behind the Gridap design that leverages the new software possibilities provided by the Julia language. The second main contribution of the article is a performance comparison against FEniCS. We measure CPU times needed to assemble discrete systems of linear equations for different problem types and show that the performance of Gridap is comparable to FEniCS, demonstrating that the new software design does not compromise performance. Gridap is freely available at Github and distributed under an MIT license.",
        "published": "2021-09-27T06:27:37Z",
        "link": "http://arxiv.org/abs/2109.12818v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "MPLAPACK version 2.0.1 user manual",
        "authors": [
            "Maho Nakata"
        ],
        "summary": "The MPLAPACK (formerly MPACK) is a multiple-precision version of LAPACK (https://www.netlib.org/lapack/). MPLAPACK version 2.0.1 is based on LAPACK version 3.9.1 and translated from Fortran 90 to C++ using FABLE, a Fortran to C++ source-to-source conversion tool (https://github.com/cctbx/cctbx_project/tree/master/fable/). MPLAPACK version 2.0.1 provides the real and complex version of MPBLAS, and the real and complex versions of MPLAPACK support all LAPACK features: solvers for systems of simultaneous linear equations, least-squares solutions of linear systems of equations, eigenvalue problems, and singular value problems, and related matrix factorizations except for mixed-precision routines. The MPLAPACK defines an API for numerical linear algebra, similar to LAPACK. It is easy to port legacy C/C++ numerical codes using MPLAPACK. MPLAPACK supports binary64, binary128, FP80 (extended double), MPFR, GMP, and QD libraries (double-double and quad-double). Users can choose MPFR or GMP for arbitrary accurate calculations, double-double or quad-double for fast 32 or 64-decimal calculations. We can consider the binary64 version as the C++ version of LAPACK. Moreover, it comes with an OpenMP accelerated version of MPBLAS for some routines and CUDA (A100 and V100 support) for double-double versions of Rgemm and Rsyrk. The peak performances of the OpenMP version are almost proportional to the number of cores, and the performances of the CUDA version are impressive, and approximately 400-600 GFlops. MPLAPACK is available at GitHub (https://github.com/nakatamaho/mplapack/) under the 2-clause BSD license.",
        "published": "2021-09-28T00:10:44Z",
        "link": "http://arxiv.org/abs/2109.13406v2",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "Power Consumption Analysis of Parallel Algorithms on GPUs",
        "authors": [
            "Frédéric Magoulès",
            "Abal-Kassim Cheik Ahamed",
            "Alban Desmaison",
            "Jean-Christophe Léchenet",
            "François Mayer",
            "Haifa Ben Salem",
            "Thomas Zhu"
        ],
        "summary": "Due to their highly parallel multi-cores architecture, GPUs are being increasingly used in a wide range of computationally intensive applications. Compared to CPUs, GPUs can achieve higher performances at accelerating the programs' execution in an energy-efficient way. Therefore GPGPU computing is useful for high performance computing applications and in many scientific research fields. In order to bring further performance improvements, GPU clusters are increasingly adopted. The energy consumed by GPUs cannot be neglected. Therefore, an energy-efficient time scheduling of the programs that are going to be executed by the parallel GPUs based on their deadline as well as the assigned priorities could be deployed to face their energetic avidity. For this reason, we present in this paper a model enabling the measure of the power consumption and the time execution of some elementary operations running on a single GPU using a new developed energy measurement protocol. Consequently, using our methodology, energy needs of a program could be predicted, allowing a better task scheduling.",
        "published": "2021-09-28T14:17:39Z",
        "link": "http://arxiv.org/abs/2110.01414v1",
        "categories": [
            "cs.DC",
            "cs.MS",
            "cs.NA",
            "cs.PF",
            "math.NA",
            "14Q65, 15A60, 65E10, 65F10, 68W10, 65Y05, 68M20",
            "G.1.3; G.1.6; I.3.1; D.3.4"
        ]
    },
    {
        "title": "preCICE v2: A Sustainable and User-Friendly Coupling Library",
        "authors": [
            "Gerasimos Chourdakis",
            "Kyle Davis",
            "Benjamin Rodenberg",
            "Miriam Schulte",
            "Frédéric Simonis",
            "Benjamin Uekermann",
            "Georg Abrams",
            "Hans-Joachim Bungartz",
            "Lucia Cheung Yau",
            "Ishaan Desai",
            "Konrad Eder",
            "Richard Hertrich",
            "Florian Lindner",
            "Alexander Rusch",
            "Dmytro Sashko",
            "David Schneider",
            "Amin Totounferoush",
            "Dominik Volland",
            "Peter Vollmer",
            "Oguz Ziya Koseomur"
        ],
        "summary": "preCICE is a free/open-source coupling library. It enables creating partitioned multi-physics simulations by gluing together separate software packages. This paper summarizes the development efforts in preCICE of the past five years. During this time span, we have turned the software from a working prototype -- sophisticated numerical coupling methods and scalability on ten thousands of compute cores -- to a sustainable and user-friendly software project with a steadily-growing community. Today, we know through forum discussions, conferences, workshops, and publications of more than 100 research groups using preCICE. We cover the fundamentals of the software alongside a performance and accuracy analysis of different data mapping methods. Afterwards, we describe ready-to-use integration with widely-used external simulation software packages, tests and continuous integration from unit to system level, and community building measures, drawing an overview of the current preCICE ecosystem.",
        "published": "2021-09-29T15:01:34Z",
        "link": "http://arxiv.org/abs/2109.14470v2",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "Learning the Markov Decision Process in the Sparse Gaussian Elimination",
        "authors": [
            "Yingshi Chen"
        ],
        "summary": "We propose a learning-based approach for the sparse Gaussian Elimination. There are many hard combinatorial optimization problems in modern sparse solver. These NP-hard problems could be handled in the framework of Markov Decision Process, especially the Q-Learning technique. We proposed some Q-Learning algorithms for the main modules of sparse solver: minimum degree ordering, task scheduling and adaptive pivoting. Finally, we recast the sparse solver into the framework of Q-Learning.   Our study is the first step to connect these two classical mathematical models: Gaussian Elimination and Markov Decision Process. Our learning-based algorithm could help improve the performance of sparse solver, which has been verified in some numerical experiments.",
        "published": "2021-09-30T08:56:39Z",
        "link": "http://arxiv.org/abs/2109.14929v1",
        "categories": [
            "math.NA",
            "cs.LG",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "An Attempt to Generate Code for Symmetric Tensor Computations",
        "authors": [
            "Jessica Shi",
            "Stephen Chou",
            "Fredrik Kjolstad",
            "Saman Amarasinghe"
        ],
        "summary": "This document describes an attempt to develop a compiler-based approach for computations with symmetric tensors. Given a computation and the symmetries of its input tensors, we derive formulas for random access under a storage scheme that eliminates redundancies; construct intermediate representations to describe the loop structure; and translate this information, using the taco tensor algebra compiler, into code. While we achieve a framework for reasoning about a fairly general class of symmetric computations, the resulting code is not performant when the symmetries are misaligned.",
        "published": "2021-10-01T03:07:26Z",
        "link": "http://arxiv.org/abs/2110.00186v1",
        "categories": [
            "cs.MS",
            "cs.PL"
        ]
    },
    {
        "title": "pyFFS: A Python Library for Fast Fourier Series Computation and   Interpolation with GPU Acceleration",
        "authors": [
            "Eric Bezzam",
            "Sepand Kashani",
            "Paul Hurley",
            "Martin Vetterli",
            "Matthieu Simeoni"
        ],
        "summary": "Fourier transforms are an often necessary component in many computational tasks, and can be computed efficiently through the fast Fourier transform (FFT) algorithm. However, many applications involve an underlying continuous signal, and a more natural choice would be to work with e.g. the Fourier series (FS) coefficients in order to avoid the additional overhead of translating between the analog and discrete domains. Unfortunately, there exists very little literature and tools for the manipulation of FS coefficients from discrete samples. This paper introduces a Python library called pyFFS for efficient FS coefficient computation, convolution, and interpolation. While the libraries SciPy and NumPy provide efficient functionality for discrete Fourier transform coefficients via the FFT algorithm, pyFFS addresses the computation of FS coefficients through what we call the fast Fourier series (FFS). Moreover, pyFFS includes an FS interpolation method based on the chirp Z-transform that can make it more than an order of magnitude faster than the SciPy equivalent when one wishes to perform interpolation. GPU support through the CuPy library allows for further acceleration, e.g. an order of magnitude faster for computing the 2-D FS coefficients of 1000 x 1000 samples and nearly two orders of magnitude faster for 2-D interpolation. As an application, we discuss the use of pyFFS in Fourier optics. pyFFS is available as an open source package at https://github.com/imagingofthings/pyFFS, with documentation at https://pyffs.readthedocs.io.",
        "published": "2021-10-01T08:38:17Z",
        "link": "http://arxiv.org/abs/2110.00262v3",
        "categories": [
            "cs.MS",
            "eess.SP"
        ]
    },
    {
        "title": "LazySets.jl: Scalable Symbolic-Numeric Set Computations",
        "authors": [
            "Marcelo Forets",
            "Christian Schilling"
        ],
        "summary": "LazySets.jl is a Julia library that provides ways to symbolically represent sets of points as geometric shapes, with a special focus on convex sets and polyhedral approximations. LazySets provides methods to apply common set operations, convert between different set representations, and efficiently compute with sets in high dimensions using specialized algorithms based on the set types. LazySets is the core library of JuliaReach, a cutting-edge software addressing the fundamental problem of reachability analysis: computing the set of states that are reachable by a dynamical system from all initial states and for all admissible inputs and parameters. While the library was originally designed for reachability and formal verification, its scope goes beyond such topics. LazySets is an easy-to-use, general-purpose and scalable library for computations that mix symbolics and numerics. In this article we showcase the basic functionality, highlighting some of the key design choices.",
        "published": "2021-10-04T20:50:47Z",
        "link": "http://arxiv.org/abs/2110.01711v2",
        "categories": [
            "cs.MS",
            "cs.CG",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "A Brief Introduction to Automatic Differentiation for Machine Learning",
        "authors": [
            "Davan Harrison"
        ],
        "summary": "Machine learning and neural network models in particular have been improving the state of the art performance on many artificial intelligence related tasks. Neural network models are typically implemented using frameworks that perform gradient based optimization methods to fit a model to a dataset. These frameworks use a technique of calculating derivatives called automatic differentiation (AD) which removes the burden of performing derivative calculations from the model designer. In this report we describe AD, its motivations, and different implementation approaches. We briefly describe dataflow programming as it relates to AD. Lastly, we present example programs that are implemented with Tensorflow and PyTorch, which are two commonly used AD frameworks.",
        "published": "2021-10-12T00:10:28Z",
        "link": "http://arxiv.org/abs/2110.06209v2",
        "categories": [
            "cs.LG",
            "cs.CL",
            "cs.MS",
            "cs.PL"
        ]
    },
    {
        "title": "LightSeq2: Accelerated Training for Transformer-based Models on GPUs",
        "authors": [
            "Xiaohui Wang",
            "Yang Wei",
            "Ying Xiong",
            "Guyue Huang",
            "Xian Qian",
            "Yufei Ding",
            "Mingxuan Wang",
            "Lei Li"
        ],
        "summary": "Transformer-based neural models are used in many AI applications. Training these models is expensive, as it takes huge GPU resources and long duration. It is challenging because typical data like sentences have variable lengths, and Transformer's computation patterns are more complex than convolutional neural networks. Existing systems either only focus on model inference or optimization for only BERT-like encoder models. In this paper, we present LightSeq2, a system to accelerate training for a general family of Transformer models on GPUs. We propose a series of GPU optimization techniques tailored to the specific computation flow and memory access patterns of Transformer models. LightSeq2 supports many model architectures, including BERT (encoder-only), GPT (decoder-only), Transformer (encoder-decoder), and vision Transformer. Our experiments for a variety of models and benchmarks show that LightSeq2 is consistently faster (1.4-3.5x) than previous systems on different GPUs. In particular, it gains 308% training speedup compared with existing systems on a large public machine translation benchmark (WMT14 English-German).",
        "published": "2021-10-12T03:17:03Z",
        "link": "http://arxiv.org/abs/2110.05722v3",
        "categories": [
            "cs.CL",
            "cs.MS"
        ]
    },
    {
        "title": "Fast Block Linear System Solver Using Q-Learning Schduling for Unified   Dynamic Power System Simulations",
        "authors": [
            "Yingshi Chen",
            "Xinli Song",
            "HanYang Dai",
            "Tao Liu",
            "Wuzhi Zhong",
            "Guoyang Wu"
        ],
        "summary": "We present a fast block direct solver for the unified dynamic simulations of power systems. This solver uses a novel Q-learning based method for task scheduling. Unified dynamic simulations of power systems represent a method in which the electric-mechanical transient, medium-term and long-term dynamic phenomena are organically united. Due to the high rank and large numbers in solving, fast solution of these equations is the key to speeding up the simulation. The sparse systems of simulation contain complex nested block structure, which could be used by the solver to speed up. For the scheduling of blocks and frontals in the solver, we use a learning based task-tree scheduling technique in the framework of Markov Decision Process. That is, we could learn optimal scheduling strategies by offline training on many sample matrices. Then for any systems, the solver would get optimal task partition and scheduling on the learned model. Our learning-based algorithm could help improve the performance of sparse solver, which has been verified in some numerical experiments. The simulation on some large power systems shows that our solver is 2-6 times faster than KLU, which is the state-of-the-art sparse solver for circuit simulation problems.",
        "published": "2021-10-12T09:10:27Z",
        "link": "http://arxiv.org/abs/2110.05843v1",
        "categories": [
            "cs.LG",
            "cs.MS",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "A Cross-Platform Benchmark for Interval Computation Libraries",
        "authors": [
            "Xuan Tang",
            "Zachary Ferguson",
            "Teseo Schneider",
            "Denis Zorin",
            "Shoaib Kamil",
            "Daniele Panozzo"
        ],
        "summary": "Interval computation is widely used to certify computations that use floating point operations to avoid pitfalls related to rounding error introduced by inaccurate operations. Despite its popularity and practical benefits, support for interval arithmetic is not standardized nor available in mainstream programming languages. We propose the first benchmark for interval computations, coupled with reference solutions computed with exact arithmetic, and compare popular C and C++ libraries over different architectures, operating systems, and compilers. The benchmark allows identifying limitations in existing implementations, and provides a reliable guide on which library to use on each system. We believe that our benchmark will be useful for developers of future interval libraries, as a way to test the correctness and performance of their algorithms.",
        "published": "2021-10-12T16:24:39Z",
        "link": "http://arxiv.org/abs/2110.06215v1",
        "categories": [
            "cs.MS",
            "cs.CG"
        ]
    },
    {
        "title": "libdlr: Efficient imaginary time calculations using the discrete Lehmann   representation",
        "authors": [
            "Jason Kaye",
            "Kun Chen",
            "Hugo U. R. Strand"
        ],
        "summary": "We introduce libdlr, a library implementing the recently introduced discrete Lehmann representation (DLR) of imaginary time Green's functions. The DLR basis consists of a collection of exponentials chosen by the interpolative decomposition to ensure stable and efficient recovery of Green's functions from imaginary time or Matsbuara frequency samples. The library provides subroutines to build the DLR basis and grids, and to carry out various standard operations. The simplicity of the DLR makes it straightforward to incorporate into existing codes as a replacement for less efficient representations of imaginary time Green's functions, and libdlr is intended to facilitate this process. libdlr is written in Fortran, provides a C header interface, and contains a Python module pydlr. We also introduce a stand-alone Julia implementation, Lehmann.jl.",
        "published": "2021-10-13T15:02:27Z",
        "link": "http://arxiv.org/abs/2110.06765v3",
        "categories": [
            "physics.comp-ph",
            "cond-mat.str-el",
            "cs.MS",
            "cs.NA",
            "math.NA",
            "81-04, 65D15",
            "G.4; J.2; G.1.2"
        ]
    },
    {
        "title": "Least Squares on GPUs in Multiple Double Precision",
        "authors": [
            "Jan Verschelde"
        ],
        "summary": "This paper describes the application of the code generated by the CAMPARY software to accelerate the solving of linear systems in the least squares sense on Graphics Processing Units (GPUs), in double double, quad double, and octo double precision. The goal is to use accelerators to offset the cost overhead caused by multiple double precision arithmetic. For the blocked Householder QR and the back substitution, of interest are those dimensions at which teraflop performance is attained. The other interesting question is the cost overhead factor that appears each time the precision is doubled.   Experimental results are reported on five different NVIDIA GPUs, with a particular focus on the P100 and the V100, both capable of teraflop performance. Thanks to the high Compute to Global Memory Access (CGMA) ratios of multiple double arithmetic, teraflop performance is already attained running the double double QR on 1,024-by-1,024 matrices, both on the P100 and the V100. For the back substitution, the dimension of the upper triangular system must be as high as 17,920 to reach one teraflops on the V100, in quad double precision, and then taking only the times spent by the kernels into account. The lower performance of the back substitution in small dimensions does not prevent teraflop performance of the solver at dimension 1,024, as the time for the QR decomposition dominates.   In doubling the precision from double double to quad double and from quad double to octo double, the observed cost overhead factors are lower than the factors predicted by the arithmetical operation counts. This observation correlates with the increased performance for increased precision, which can again be explained by the high CGMA ratios.",
        "published": "2021-10-15T21:25:14Z",
        "link": "http://arxiv.org/abs/2110.08375v2",
        "categories": [
            "cs.MS",
            "cs.DC",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Two-dimensional mesh generator in generalized coordinates implemented in   Python",
        "authors": [
            "Gustavo Taiji Naozuka",
            "Saulo Martiello Mastelini",
            "Eliandro Rodrigues Cirilo",
            "Neyva Maria Lopes Romeiro",
            "Paulo Laerte Natti"
        ],
        "summary": "Through mathematical models, it is possible to turn a problem of the physical domain into the computational domain. In this context, the paper presents a two-dimensional mesh generator in generalized coordinates, which uses the Parametric Linear Spline method and partial differential equations. The generator is automated and able to treat real complex domains. The code was implemented in Python, applying the Numpy and Matplotlib libraries to matrix manipulations and graphical plots, respectively. Applications are made for monoblock meshes (two-dimensional shape of a bottle) and multi-block meshes (geometry of Igap\\'o I lake, Londrina, Paran\\'a, Brazil).",
        "published": "2021-10-17T20:42:18Z",
        "link": "http://arxiv.org/abs/2110.12875v1",
        "categories": [
            "cs.MS",
            "cs.CY"
        ]
    },
    {
        "title": "The search of Type I codes",
        "authors": [
            "Carolin Hannusch",
            "Roland S. Major"
        ],
        "summary": "A self-dual binary linear code is called Type I code if it has singly-even codewords, i.e.~it has codewords with weight divisible by $2.$ The purpose of this paper is to investigate interesting properties of Type I codes of different lengths. Further, we build up a computer-based code-searching program based on our knowledge about Type I codes. Some computation results achieved by this program are given.",
        "published": "2021-10-18T12:45:02Z",
        "link": "http://arxiv.org/abs/2110.09244v1",
        "categories": [
            "cs.IT",
            "cs.MS",
            "math.IT",
            "94B05"
        ]
    },
    {
        "title": "Doubt and Redundancy Kill Soft Errors -- Towards Detection and   Correction of Silent Data Corruption in Task-based Numerical Software",
        "authors": [
            "Philipp Samfass",
            "Tobias Weinzierl",
            "Anne Reinarz",
            "Michael Bader"
        ],
        "summary": "Resilient algorithms in high-performance computing are subject to rigorous non-functional constraints. Resiliency must not increase the runtime, memory footprint or I/O demands too significantly. We propose a task-based soft error detection scheme that relies on error criteria per task outcome. They formalise how ``dubious'' an outcome is, i.e. how likely it contains an error. Our whole simulation is replicated once, forming two teams of MPI ranks that share their task results. Thus, ideally each team handles only around half of the workload. If a task yields large error criteria values, i.e.~is dubious, we compute the task redundantly and compare the outcomes. Whenever they disagree, the task result with a lower error likeliness is accepted. We obtain a self-healing, resilient algorithm which can compensate silent floating-point errors without a significant performance, I/O or memory footprint penalty. Case studies however suggest that a careful, domain-specific tailoring of the error criteria remains essential.",
        "published": "2021-10-18T12:51:20Z",
        "link": "http://arxiv.org/abs/2110.15804v1",
        "categories": [
            "cs.SE",
            "cs.AR",
            "cs.MS"
        ]
    },
    {
        "title": "Can Fortran's 'do concurrent' replace directives for accelerated   computing?",
        "authors": [
            "Miko M. Stulajter",
            "Ronald M. Caplan",
            "Jon A. Linker"
        ],
        "summary": "Recently, there has been growing interest in using standard language constructs (e.g. C++'s Parallel Algorithms and Fortran's do concurrent) for accelerated computing as an alternative to directive-based APIs (e.g. OpenMP and OpenACC). These constructs have the potential to be more portable, and some compilers already (or have plans to) support such standards. Here, we look at the current capabilities, portability, and performance of replacing directives with Fortran's do concurrent using a mini-app that currently implements OpenACC for GPU-acceleration and OpenMP for multi-core CPU parallelism. We replace as many directives as possible with do concurrent, testing various configurations and compiler options within three major compilers: GNU's gfortran, NVIDIA's nvfortran, and Intel's ifort. We find that with the right compiler versions and flags, many directives can be replaced without loss of performance or portability, and, in the case of nvfortran, they can all be replaced. We discuss limitations that may apply to more complicated codes and future language additions that may mitigate them. The software and Singularity containers are publicly provided to allow the results to be reproduced.",
        "published": "2021-10-18T23:01:07Z",
        "link": "http://arxiv.org/abs/2110.10151v1",
        "categories": [
            "cs.MS",
            "cs.PL",
            "68U99",
            "D.1.3; D.3.3"
        ]
    },
    {
        "title": "The Creation of Puffin, the Automatic Uncertainty Compiler",
        "authors": [
            "Nicholas Gray",
            "Marco De Angelis",
            "Scott Ferson"
        ],
        "summary": "An uncertainty compiler is a tool that automatically translates original computer source code lacking explicit uncertainty analysis into code containing appropriate uncertainty representations and uncertainty propagation algorithms. We have developed an prototype uncertainty compiler along with an associated object-oriented uncertainty language in the form of a stand-alone Python library. It handles the specifications of input uncertainties and inserts calls to intrusive uncertainty quantification algorithms in the library. The uncertainty compiler can apply intrusive uncertainty propagation methods to codes or parts of codes and therefore more comprehensively and flexibly address both epistemic and aleatory uncertainties.",
        "published": "2021-10-19T10:28:35Z",
        "link": "http://arxiv.org/abs/2110.10153v2",
        "categories": [
            "cs.MS",
            "stat.CO"
        ]
    },
    {
        "title": "Accelerating quantum many-body configuration interaction with directives",
        "authors": [
            "Brandon Cook",
            "Patrick J. Fasano",
            "Pieter Maris",
            "Chao Yang",
            "Dossay Oryspayev"
        ],
        "summary": "Many-Fermion Dynamics-nuclear, or MFDn, is a configuration interaction (CI) code for nuclear structure calculations. It is a platform-independent Fortran 90 code using a hybrid MPI+X programming model. For CPU platforms the application has a robust and optimized OpenMP implementation for shared memory parallelism. As part of the NESAP application readiness program for NERSC's latest Perlmutter system, MFDn has been updated to take advantage of accelerators. The current mainline GPU port is based on OpenACC. In this work we describe some of the key challenges of creating an efficient GPU implementation. Additionally, we compare the support of OpenMP and OpenACC on AMD and NVIDIA GPUs.",
        "published": "2021-10-20T20:17:18Z",
        "link": "http://arxiv.org/abs/2110.10765v1",
        "categories": [
            "cs.DC",
            "cs.CE",
            "cs.MS",
            "cs.PF",
            "nucl-th"
        ]
    },
    {
        "title": "Streaming Generalized Canonical Polyadic Tensor Decompositions",
        "authors": [
            "Eric Phipps",
            "Nick Johnson",
            "Tamara G. Kolda"
        ],
        "summary": "In this paper, we develop a method which we call OnlineGCP for computing the Generalized Canonical Polyadic (GCP) tensor decomposition of streaming data. GCP differs from traditional canonical polyadic (CP) tensor decompositions as it allows for arbitrary objective functions which the CP model attempts to minimize. This approach can provide better fits and more interpretable models when the observed tensor data is strongly non-Gaussian. In the streaming case, tensor data is gradually observed over time and the algorithm must incrementally update a GCP factorization with limited access to prior data. In this work, we extend the GCP formalism to the streaming context by deriving a GCP optimization problem to be solved as new tensor data is observed, formulate a tunable history term to balance reconstruction of recently observed data with data observed in the past, develop a scalable solution strategy based on segregated solves using stochastic gradient descent methods, describe a software implementation that provides performance and portability to contemporary CPU and GPU architectures and integrates with Matlab for enhanced useability, and demonstrate the utility and performance of the approach and software on several synthetic and real tensor data sets.",
        "published": "2021-10-27T15:26:24Z",
        "link": "http://arxiv.org/abs/2110.14514v1",
        "categories": [
            "math.NA",
            "cs.LG",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "Escaping the abstraction: a foreign function interface for the Unified   Form Language [UFL]",
        "authors": [
            "Nacime Bouziani",
            "David A. Ham"
        ],
        "summary": "High level domain specific languages for the finite element method underpin high productivity programming environments for simulations based on partial differential equations (PDE) while employing automatic code generation to achieve high performance. However, a limitation of this approach is that it does not support operators that are not directly expressible in the vector calculus. This is critical in applications where PDEs are not enough to accurately describe the physical problem of interest. The use of deep learning techniques have become increasingly popular in filling this knowledge gap, for example to include features not represented in the differential equations, or closures for unresolved spatiotemporal scales. We introduce an interface within the Firedrake finite element system that enables a seamless interface with deep learning models. This new feature composes with the automatic differentiation capabilities of Firedrake, enabling the automated solution of inverse problems. Our implementation interfaces with PyTorch and can be extended to other machine learning libraries. The resulting framework supports complex models coupling PDEs and deep learning whilst maintaining separation of concerns between application scientists and software experts.",
        "published": "2021-11-01T13:38:38Z",
        "link": "http://arxiv.org/abs/2111.00945v1",
        "categories": [
            "cs.MS",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Source-to-Source Automatic Differentiation of OpenMP Parallel Loops",
        "authors": [
            "Jan Hückelheim",
            "Laurent Hascoët"
        ],
        "summary": "This paper presents our work toward correct and efficient automatic differentiation of OpenMP parallel worksharing loops in forward and reverse mode. Automatic differentiation is a method to obtain gradients of numerical programs, which are crucial in optimization, uncertainty quantification, and machine learning. The computational cost to compute gradients is a common bottleneck in practice. For applications that are parallelized for multicore CPUs or GPUs using OpenMP, one also wishes to compute the gradients in parallel. We propose a framework to reason about the correctness of the generated derivative code, from which we justify our OpenMP extension to the differentiation model. We implement this model in the automatic differentiation tool Tapenade and present test cases that are differentiated following our extended differentiation procedure. Performance of the generated derivative programs in forward and reverse mode is better than sequential, although our reverse mode often scales worse than the input programs.",
        "published": "2021-11-02T19:40:59Z",
        "link": "http://arxiv.org/abs/2111.01861v1",
        "categories": [
            "cs.MS",
            "cs.LG",
            "cs.PF"
        ]
    },
    {
        "title": "Symbolic spectral decomposition of 3x3 matrices",
        "authors": [
            "Michal Habera",
            "Andreas Zilian"
        ],
        "summary": "Spectral decomposition of matrices is a recurring and important task in applied mathematics, physics and engineering. Many application problems require the consideration of matrices of size three with spectral decomposition over the real numbers. If the functional dependence of the spectral decomposition on the matrix elements has to be preserved, then closed-form solution approaches must be considered. Existing closed-form expressions are based on the use of principal matrix invariants which suffer from a number of deficiencies when evaluated in the framework of finite precision arithmetic. This paper introduces an alternative form for the computation of the involved matrix invariants (in particular the discriminant) in terms of sum-of-products expressions as function of the matrix elements. We prove and demonstrate by numerical examples that this alternative approach leads to increased floating point accuracy, especially in all important limit cases (e.g. eigenvalue multiplicity). It is believed that the combination of symbolic algorithms with the accuracy improvements presented in this paper can serve as a powerful building block for many engineering tasks.",
        "published": "2021-11-03T10:24:22Z",
        "link": "http://arxiv.org/abs/2111.02117v1",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "A set of R packages to estimate population counts from mobile phone data",
        "authors": [
            "Bogdan Oancea",
            "David Salgado",
            "Luis Sanguiao Sande",
            "Sandra Barragan"
        ],
        "summary": "In this paper, we describe the software implementation of the methodological framework designed to incorporate mobile phone data into the current production chain of official statistics during the ESSnet Big Data II project. We present an overview of the architecture of the software stack, its components, the interfaces between them, and show how they can be used. Our software implementation consists in four R packages: destim for estimation of the spatial distribution of the mobile devices, deduplication for classification of the devices as being in 1:1 or 2:1 correspondence with its owner, aggregation for estimation of the number of individuals detected by the network starting from the geolocation probabilities and the duplicity probabilities and inference which combines the number of individuals provided by the previous package with other information like the population counts from an official register and the mobile operator penetration rates to provide an estimation of the target population counts.",
        "published": "2021-11-04T04:02:44Z",
        "link": "http://arxiv.org/abs/2111.05269v1",
        "categories": [
            "cs.MS",
            "cs.SI",
            "stat.AP"
        ]
    },
    {
        "title": "Locally Feasibly Projected Sequential Quadratic Programming for   Nonlinear Programming on Arbitrary Smooth Constraint Manifolds",
        "authors": [
            "Kevin S. Silmore",
            "James W. Swan"
        ],
        "summary": "High-dimensional nonlinear optimization problems subject to nonlinear constraints can appear in several contexts including constrained physical and dynamical systems, statistical estimation, and other numerical models. Feasible optimization routines can sometimes be valuable if the objective function is only defined on the feasible set or if numerical difficulties associated with merit functions or infeasible termination arise during the use of infeasible optimization routines. Drawing on the Riemannian optimization and sequential quadratic programming literature, a practical algorithm is constructed to conduct feasible optimization on arbitrary implicitly defined constraint manifolds. Specifically, with $n$ (potentially bound-constrained) variables and $m < n$ nonlinear constraints, each outer optimization loop iteration involves a single $O(nm^2)$-flop factorization, and computationally efficient retractions are constructed that involve $O(nm)$-flop inner loop iterations. A package, LFPSQP.jl, is created using the Julia language that takes advantage of automatic differentiation and projected conjugate gradient methods for use in inexact/truncated Newton steps.",
        "published": "2021-11-05T03:10:24Z",
        "link": "http://arxiv.org/abs/2111.03236v1",
        "categories": [
            "math.OC",
            "cs.MS"
        ]
    },
    {
        "title": "MetaFEM: A Generic FEM Solver By Meta-expressions",
        "authors": [
            "Jiaxi Xie",
            "Kornel Ehmann",
            "Jian Cao"
        ],
        "summary": "Current multi-physics Finite Element Method (FEM) solvers are complex systems in terms of both their mathematical complexity and lines of code. This paper proposes a skeleton generic FEM solver, named MetaFEM, in total about 5,000 lines of Julia code, which translates generic input Partial Differential Equation (PDE) weak forms into corresponding GPU-accelerated simulations with a grammar similar to FEniCS or FreeFEM. Two novel approaches differentiate MetaFEM from the common solvers: (1) the FEM kernel is based on an original theory/algorithm which explicitly processes meta-expressions, as the name suggests, and (2) the symbolic engine is a rule-based Computer Algebra System (CAS), i.e., the equations are rewritten/derived according to a set of rewriting rules instead of going through completely fixed routines, supporting easy customization by developers. Example cases in thermal conduction, linear elasticity and incompressible flow are presented to demonstrate utility.",
        "published": "2021-11-05T15:01:56Z",
        "link": "http://arxiv.org/abs/2111.03541v2",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "Computing Sparse Jacobians and Hessians Using Algorithmic   Differentiation",
        "authors": [
            "Bradley M. Bell",
            "Kasper Kristensen"
        ],
        "summary": "Stochastic scientific models and machine learning optimization estimators have a large number of variables; hence computing large sparse Jacobians and Hessians is important. Algorithmic differentiation (AD) greatly reduces the programming effort required to obtain the sparsity patterns and values for these matrices. We present forward, reverse, and subgraph methods for computing sparse Jacobians and Hessians. Special attention is given the the subgraph method because it is new. The coloring and compression steps are not necessary when computing sparse Jacobians and Hessians using subgraphs. Complexity analysis shows that for some problems the subgraph method is expected to be much faster. We compare C++ operator overloading implementations of the methods in the ADOL-C and CppAD software packages using some of the MINPACK-2 test problems. The experiments are set up in a way that makes them easy to run on different hardware, different systems, different compilers, other test problem and other AD packages. The setup time is the time to record the graph, compute sparsity, coloring, compression, and optimization of the graph. If the setup is necessary for each evaluation, the subgraph implementation has similar run times for sparse Jacobians and faster run times for sparse Hessians.",
        "published": "2021-11-09T15:33:30Z",
        "link": "http://arxiv.org/abs/2111.05207v1",
        "categories": [
            "cs.MS",
            "cs.DS",
            "05C15, 65F50, 90C30",
            "F.2.2; G.2.2"
        ]
    },
    {
        "title": "Implicit SVD for Graph Representation Learning",
        "authors": [
            "Sami Abu-El-Haija",
            "Hesham Mostafa",
            "Marcel Nassar",
            "Valentino Crespi",
            "Greg Ver Steeg",
            "Aram Galstyan"
        ],
        "summary": "Recent improvements in the performance of state-of-the-art (SOTA) methods for Graph Representational Learning (GRL) have come at the cost of significant computational resource requirements for training, e.g., for calculating gradients via backprop over many data epochs. Meanwhile, Singular Value Decomposition (SVD) can find closed-form solutions to convex problems, using merely a handful of epochs. In this paper, we make GRL more computationally tractable for those with modest hardware. We design a framework that computes SVD of \\textit{implicitly} defined matrices, and apply this framework to several GRL tasks. For each task, we derive linear approximation of a SOTA model, where we design (expensive-to-store) matrix $\\mathbf{M}$ and train the model, in closed-form, via SVD of $\\mathbf{M}$, without calculating entries of $\\mathbf{M}$. By converging to a unique point in one step, and without calculating gradients, our models show competitive empirical test performance over various graphs such as article citation and biological interaction networks. More importantly, SVD can initialize a deeper model, that is architected to be non-linear almost everywhere, though behaves linearly when its parameters reside on a hyperplane, onto which SVD initializes. The deeper model can then be fine-tuned within only a few epochs. Overall, our procedure trains hundreds of times faster than state-of-the-art methods, while competing on empirical test performance. We open-source our implementation at: https://github.com/samihaija/isvd",
        "published": "2021-11-11T16:58:17Z",
        "link": "http://arxiv.org/abs/2111.06312v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MS",
            "cs.SI"
        ]
    },
    {
        "title": "Enhanced Formulation for Guillotine 2D Cutting Problems",
        "authors": [
            "Henrique Becker",
            "Olinto Araujo",
            "Luciana S. Buriol"
        ],
        "summary": "We advance the state of the art in Mixed-Integer Linear Programming (MILP) formulations for Guillotine 2D Cutting Problems by (i) adapting a previously known reduction to our preprocessing phase and by (ii) enhancing a previous formulation by cutting down its size and symmetries. Our focus is the Guillotine 2D Knapsack Problem with orthogonal and unrestricted cuts, constrained demand, unlimited stages, and no rotation -- however, the formulation may be adapted to many related problems. The code is available. Concerning the set of 59 instances used to benchmark the original formulation, and summing the statistics for all models generated, the enhanced formulation has only a small fraction of the variables and constraints of the original model (respectively, 3.07% and 8.35%). The enhanced formulation also takes about 4 hours to solve all instances while the original formulation takes 12 hours to solve 53 of them (the other six runs hit a three-hour time limit each). We integrate, to both formulations, a pricing framework proposed for the original formulation; the enhanced formulation keeps a significant advantage in this situation. Finally, in a recently proposed set of 80 harder instances, the enhanced formulation (with and without the pricing framework) found: 22 optimal solutions for the unrestricted problem (5 already known, 17 new); 22 optimal solutions for the restricted problem (all are new and they are not the same 22 of the optimal unrestricted solutions); better lower bounds for 25 instances; better upper bounds for 58 instances.",
        "published": "2021-11-11T17:59:35Z",
        "link": "http://arxiv.org/abs/2111.06348v1",
        "categories": [
            "math.OC",
            "cs.DM",
            "cs.DS",
            "cs.MS",
            "68R05 (Primary), 68U99, 05D99, 52B99"
        ]
    },
    {
        "title": "SimpleTensor -- a user-friendly Mathematica package for elementary   tensor and differential-geometric calculations",
        "authors": [
            "D. O. Rybalka"
        ],
        "summary": "In this paper we present a short overview of the new Wolfram Mathematica package intended for elementary \"in-basis\" tensor and differential-geometric calculations. In contrast to alternatives our package is designed to be easy-to-use, short, all-purpose, and hackable. It supports tensor contractions using Einstein notation, transformations between different bases, tensor derivative operator, expansion in basis vectors and forms, exterior derivative, and interior product.",
        "published": "2021-11-12T13:37:49Z",
        "link": "http://arxiv.org/abs/2111.06718v1",
        "categories": [
            "nucl-th",
            "cs.MS",
            "cs.SC",
            "hep-th",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Verified Optimization",
        "authors": [
            "Alexander Bentkamp",
            "Jeremy Avigad"
        ],
        "summary": "Optimization is used extensively in engineering, industry, and finance, and various methods are used to transform problems to the point where they are amenable to solution by numerical methods. We describe progress towards developing a framework, based on the Lean interactive proof assistant, for designing and applying such reductions in reliable and flexible ways.",
        "published": "2021-11-12T16:38:49Z",
        "link": "http://arxiv.org/abs/2111.06807v1",
        "categories": [
            "math.OC",
            "cs.LO",
            "cs.MS"
        ]
    },
    {
        "title": "ILU Smoothers for Low Mach Navier-Stokes Pressure Solvers",
        "authors": [
            "Stephen Thomas",
            "Arielle Carr",
            "Paul Mullowney",
            "Kasia Świrydowicz",
            "Marc Day"
        ],
        "summary": "Incomplete LU (ILU) smoothers are effective in the algebraic multigrid (AMG) $V$-cycle for reducing high-frequency components of the error. However, the requisite direct triangular solves are comparatively slow on GPUs. Previous work has demonstrated the advantages of Jacobi iteration as an alternative to direct solution of these systems. Depending on the threshold and fill-level parameters chosen, the factors can be highly non-normal and Jacobi is unlikely to converge in a low number of iterations. We demonstrate that row scaling can reduce the departure from normality, allowing us to replace the inherently sequential solve with a rapidly converging Richardson iteration. There are several advantages beyond the lower compute time. Scaling is performed locally for a diagonal block of the global matrix because it is applied directly to the factor. Further, an ILUT Schur complement smoother maintains a constant GMRES iteration count as the number of MPI ranks increases, and thus parallel strong-scaling is improved. Our algorithms have been incorporated into hypre, and we demonstrate improved time to solution for linear systems arising in the Nalu-Wind and PeleLM pressure solvers. For large problem sizes, GMRES$+$AMG executes at least five times faster when using iterative triangular solves compared with direct solves on massively-parallel GPUs.",
        "published": "2021-11-18T04:12:23Z",
        "link": "http://arxiv.org/abs/2111.09512v7",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "Method for representing an exponent in a fifth-dimensional hypercomplex   number systems using a hypercomplex computing software",
        "authors": [
            "Y. Boiarinova",
            "Y. Kalinovskiy"
        ],
        "summary": "The structure of method for constructing a representation of an exponential function in hypercomplex number systems(HNS) by the method of solving an associated system of linear differential equations is considered. Brief information about the hypercomplex computing software (HCS) is given. With the use of HCS, the necessary cumbersome operations on symbolic expressions were performed when constructing the representation of the exponent in the fifth-dimensional HNS. Fragments of programs in the environment of HCS and results of symbolic calculations are resulted",
        "published": "2021-11-18T18:07:32Z",
        "link": "http://arxiv.org/abs/2111.09841v1",
        "categories": [
            "cs.SE",
            "cs.MS"
        ]
    },
    {
        "title": "Parallel Algorithms for Masked Sparse Matrix-Matrix Products",
        "authors": [
            "Srđan Milaković",
            "Oguz Selvitopi",
            "Israt Nisa",
            "Zoran Budimlić",
            "Aydin Buluc"
        ],
        "summary": "Computing the product of two sparse matrices (SpGEMM) is a fundamental operation in various combinatorial and graph algorithms as well as various bioinformatics and data analytics applications for computing inner-product similarities. For an important class of algorithms, only a subset of the output entries are needed, and the resulting operation is known as Masked SpGEMM since a subset of the output entries is considered to be \"masked out\". Existing algorithms for Masked SpGEMM usually do not consider mask as part of multiplication and either first compute a regular SpGEMM followed by masking, or perform a sparse inner product only for output elements that are not masked out. In this work, we investigate various novel algorithms and data structures for this rather challenging and important computation, and provide guidelines on how to design a fast Masked-SpGEMM for shared-memory architectures. Our evaluations show that factors such as matrix and mask density, mask structure and cache behavior play a vital role in attaining high performance for Masked SpGEMM. We evaluate our algorithms on a large number of matrices using several real-world benchmarks and show that our algorithms in most cases significantly outperform the state of the art for Masked SpGEMM implementations.",
        "published": "2021-11-18T21:03:00Z",
        "link": "http://arxiv.org/abs/2111.09947v1",
        "categories": [
            "cs.DC",
            "cs.DS",
            "cs.MS"
        ]
    },
    {
        "title": "Computing with B-series",
        "authors": [
            "David I. Ketcheson",
            "Hendrik Ranocha"
        ],
        "summary": "We present BSeries.jl, a Julia package for the computation and manipulation of B-series, which are a versatile theoretical tool for understanding and designing discretizations of differential equations. We give a short introduction to the theory of B-series and associated concepts and provide examples of their use, including method composition and backward error analysis. The associated software is highly performant and makes it possible to work with B-series of high order.",
        "published": "2021-11-23T06:55:29Z",
        "link": "http://arxiv.org/abs/2111.11680v2",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "cs.SC"
        ]
    },
    {
        "title": "Polynomial spline collocation method for solving weakly regular Volterra   integral equations of the first kind",
        "authors": [
            "A. Tynda",
            "S. Noeiaghdam",
            "D. Sidorov"
        ],
        "summary": "The polynomial spline collocation method is proposed for solution of Volterra integral equations of the first kind with special piecewise continuous kernels. The Gauss-type quadrature formula is used to approximate integrals during the discretisation of the proposed projection method. The estimate of accuracy of approximate solution is obtained. Stochastic arithmetics is also used based on the Contr\\^{o}le et Estimation Stochastique des Arrondis de Calculs (CESTAC) method and the Control of Accuracy and Debugging for Numerical Applications (CADNA) library. Applying this approach it is possible to find optimal parameters of the projective method. The numerical examples are included to illustrate the efficiency of proposed novel collocation method.",
        "published": "2021-11-23T07:58:14Z",
        "link": "http://arxiv.org/abs/2111.11706v1",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "math.DS",
            "45H05, 65R20"
        ]
    },
    {
        "title": "A Massively Parallel Implementation of Multilevel Monte Carlo for Finite   Element Models",
        "authors": [
            "Santiago Badia",
            "Jerrad Hampton",
            "Javier Principe"
        ],
        "summary": "The Multilevel Monte Carlo (MLMC) method has proven to be an effective variance-reduction statistical method for Uncertainty Quantification (UQ) in Partial Differential Equation (PDE) models, combining model computations at different levels to create an accurate estimate. Still, the computational complexity of the resulting method is extremely high, particularly for 3D models, which requires advanced algorithms for the efficient exploitation of High Performance Computing (HPC). In this article we present a new implementation of the MLMC in massively parallel computer architectures, exploiting parallelism within and between each level of the hierarchy. The numerical approximation of the PDE is performed using the finite element method but the algorithm is quite general and could be applied to other discretization methods as well, although the focus is on parallel sampling. The two key ingredients of an efficient parallel implementation are a good processor partition scheme together with a good scheduling algorithm to assign work to different processors. We introduce a multiple partition of the set of processors that permits the simultaneous execution of different levels and we develop a dynamic scheduling algorithm to exploit it. The problem of finding the optimal scheduling of distributed tasks in a parallel computer is an NP-complete problem. We propose and analyze a new greedy scheduling algorithm to assign samples and we show that it is a 2-approximation, which is the best that may be expected under general assumptions. On top of this result we design a distributed memory implementation using the Message Passing Interface (MPI) standard. Finally we present a set of numerical experiments illustrating its scalability properties.",
        "published": "2021-11-23T11:04:12Z",
        "link": "http://arxiv.org/abs/2111.11788v2",
        "categories": [
            "cs.MS",
            "cs.CE"
        ]
    },
    {
        "title": "FCMpy: A Python Module for Constructing and Analyzing Fuzzy Cognitive   Maps",
        "authors": [
            "Samvel Mkhitaryan",
            "Philippe J. Giabbanelli",
            "Maciej K. Wozniak",
            "Gonzalo Napoles",
            "Nanne K. de Vries",
            "Rik Crutzen"
        ],
        "summary": "FCMpy is an open source package in Python for building and analyzing Fuzzy Cognitive Maps. More specifically, the package allows 1) deriving fuzzy causal weights from qualitative data, 2) simulating the system behavior, 3) applying machine learning algorithms (e.g., Nonlinear Hebbian Learning, Active Hebbian Learning, Genetic Algorithms and Deterministic Learning) to adjust the FCM causal weight matrix and to solve classification problems, and 4) implementing scenario analysis by simulating hypothetical interventions (i.e., analyzing what-if scenarios).",
        "published": "2021-11-24T19:21:14Z",
        "link": "http://arxiv.org/abs/2111.12749v1",
        "categories": [
            "cs.MS",
            "cs.LG"
        ]
    },
    {
        "title": "RLIBM-PROG: Progressive Polynomial Approximations for Fast Correctly   Rounded Math Libraries",
        "authors": [
            "Mridul Aanjaneya",
            "Jay P. Lim",
            "Santosh Nagarakatte"
        ],
        "summary": "This paper presents a novel method for generating a single polynomial approximation that produces correctly rounded results for all inputs of an elementary function for multiple representations. The generated polynomial approximation has the nice property that the first few lower degree terms produce correctly rounded results for specific representations of smaller bitwidths, which we call progressive performance. To generate such progressive polynomial approximations, we approximate the correctly rounded result and formulate the computation of correctly rounded polynomial approximations as a linear program similar to our prior work on the RLibm project. To enable the use of resulting polynomial approximations in mainstream libraries, we want to avoid piecewise polynomials with large lookup tables. We observe that the problem of computing polynomial approximations for elementary functions is a linear programming problem in low dimensions, i.e., with a small number of unknowns. We design a fast randomized algorithm for computing polynomial approximations with progressive performance. Our method produces correct and fast polynomials that require a small amount of storage. A few polynomial approximations from our prototype have already been incorporated into LLVM's math library.",
        "published": "2021-11-25T00:19:27Z",
        "link": "http://arxiv.org/abs/2111.12852v2",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "NCVX: A User-Friendly and Scalable Package for Nonconvex Optimization in   Machine Learning",
        "authors": [
            "Buyun Liang",
            "Tim Mitchell",
            "Ju Sun"
        ],
        "summary": "Optimizing nonconvex (NCVX) problems, especially nonsmooth and constrained ones, is an essential part of machine learning. However, it can be hard to reliably solve such problems without optimization expertise. Existing general-purpose NCVX optimization packages are powerful but typically cannot handle nonsmoothness. GRANSO is among the first optimization solvers targeting general nonsmooth NCVX problems with nonsmooth constraints, but, as it is implemented in MATLAB and requires the user to provide analytical gradients, GRANSO is often not a convenient choice in machine learning (especially deep learning) applications. To greatly lower the technical barrier, we introduce a new software package called NCVX, whose initial release contains the solver PyGRANSO, a PyTorch-enabled port of GRANSO incorporating auto-differentiation, GPU acceleration, tensor input, and support for new QP solvers. NCVX is built on freely available and widely used open-source frameworks, and as a highlight, can solve general constrained deep learning problems, the first of its kind. NCVX is available at https://ncvx.org, with detailed documentation and numerous examples from machine learning and other fields.",
        "published": "2021-11-27T21:02:20Z",
        "link": "http://arxiv.org/abs/2111.13984v2",
        "categories": [
            "cs.LG",
            "cs.CV",
            "cs.MS",
            "eess.SP",
            "math.OC"
        ]
    },
    {
        "title": "An Asymptotic Cost Model for Autoscheduling Sparse Tensor Programs",
        "authors": [
            "Willow Ahrens",
            "Fredrik Kjolstad",
            "Saman Amarasinghe"
        ],
        "summary": "While loop reordering and fusion can make big impacts on the constant-factor performance of dense tensor programs, the effects on sparse tensor programs are asymptotic, often leading to orders of magnitude performance differences in practice. Sparse tensors also introduce a choice of compressed storage formats that can have asymptotic effects. Research into sparse tensor compilers has led to simplified languages that express these tradeoffs, but the user is expected to provide a schedule that makes the decisions. This is challenging because schedulers must anticipate the interaction between sparse formats, loop structure, potential sparsity patterns, and the compiler itself. Automating this decision making process stands to finally make sparse tensor compilers accessible to end users.   We present, to the best of our knowledge, the first automatic asymptotic scheduler for sparse tensor programs. We provide an approach to abstractly represent the asymptotic cost of schedules and to choose between them. We narrow down the search space to a manageably small \"Pareto frontier\" of asymptotically undominated kernels. We test our approach by compiling these kernels with the TACO sparse tensor compiler and comparing them with those generated with the default TACO schedules. Our results show that our approach reduces the scheduling space by orders of magnitude and that the generated kernels perform asymptotically better than those generated using the default schedules.",
        "published": "2021-11-29T20:50:33Z",
        "link": "http://arxiv.org/abs/2111.14947v1",
        "categories": [
            "cs.MS",
            "cs.PL"
        ]
    },
    {
        "title": "On the very accurate evaluation of the Voigt/complex error function with   small imaginary argument",
        "authors": [
            "Yihong Wang"
        ],
        "summary": "A rapidly convergent series, based on Taylor expansion of the imaginary part of the complex error function, is presented for highly accurate approximation of the Voigt/complex error function with small imaginary argument (Y less than 0.1). Error analysis and run-time tests in double-precision computing platform reveals that in the real and imaginary parts the proposed algorithm provides average accuracy exceeding 10^-15 and 10^-16, respectively, and the calculation speed is as fast as that of reported in recent publications. An optimized MATLAB code providing rapid computation with high accuracy is presented.",
        "published": "2021-11-30T02:18:03Z",
        "link": "http://arxiv.org/abs/2112.02078v1",
        "categories": [
            "cs.MS",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "RawArray: A Simple, Fast, and Extensible Archival Format for Numeric   Data",
        "authors": [
            "David S. Smith"
        ],
        "summary": "Raw data sizes are growing and proliferating in scientific research, driven by the success of data-hungry computational methods, such as machine learning. The preponderance of proprietary and shoehorned data formats make computations slower and make it harder to reproduce research and to port methods to new platforms. Here we present the RawArray format: a simple, fast, and extensible format for archival storage of multidimensional numeric arrays on disk.   The RawArray file format is a simple concatenation of a header array and a data array. The header comprises seven or more 64-bit unsigned integers. The array data can be anything. Arbitrary user metadata can be appended to an RawArray file if desired, for example to store measurement details, color palettes, or geolocation data.   We present benchmarks showing a factor of 2--3$\\times$ speedup over HDF5 for a range of array sizes and a speedup of up to 20$\\times$ in reading the common deep learning datasets MNIST and CIFAR10.",
        "published": "2021-11-30T03:51:24Z",
        "link": "http://arxiv.org/abs/2112.01273v1",
        "categories": [
            "cs.DB",
            "cs.LG",
            "cs.MS"
        ]
    },
    {
        "title": "cliquematch: Finding correspondence via cliques in large graphs",
        "authors": [
            "Gautham Venkatasubramanian"
        ],
        "summary": "The maximum clique problem finds applications in computer vision, bioinformatics, and network analysis, many of which involve the construction of correspondence graphs to find similarities between two given objects. cliquematch is a Python package designed for this purpose: it provides a simple framework to construct correspondence graphs, and implements an algorithm to find and enumerate maximum cliques in C++, that can process graphs of a few million edges on consumer hardware, with comparable performance to publicly available methods.",
        "published": "2021-11-30T06:15:26Z",
        "link": "http://arxiv.org/abs/2112.00004v1",
        "categories": [
            "cs.MS",
            "cs.DS",
            "F.2.2; G.2.2; G.2.4; G.4; I.4.7"
        ]
    },
    {
        "title": "HOTTBOX: Higher Order Tensor ToolBOX",
        "authors": [
            "Ilya Kisil",
            "Giuseppe G. Calvi",
            "Bruno S. Dees",
            "Danilo P. Mandic"
        ],
        "summary": "HOTTBOX is a Python library for exploratory analysis and visualisation of multi-dimensional arrays of data, also known as tensors. The library includes methods ranging from standard multi-way operations and data manipulation through to multi-linear algebra based tensor decompositions. HOTTBOX also comprises sophisticated algorithms for generalised multi-linear classification and data fusion, such as Support Tensor Machine (STM) and Tensor Ensemble Learning (TEL). For user convenience, HOTTBOX offers a unifying API which establishes a self-sufficient ecosystem for various forms of efficient representation of multi-way data and the corresponding decomposition and association algorithms. Particular emphasis is placed on scalability and interactive visualisation, to support multidisciplinary data analysis communities working on big data and tensors. HOTTBOX also provides means for integration with other popular data science libraries for visualisation and data manipulation. The source code, examples and documentation ca be found at https://github.com/hottbox/hottbox.",
        "published": "2021-11-30T18:53:54Z",
        "link": "http://arxiv.org/abs/2111.15662v1",
        "categories": [
            "cs.MS",
            "eess.SP"
        ]
    },
    {
        "title": "hIPPYlib-MUQ: A Bayesian Inference Software Framework for Integration of   Data with Complex Predictive Models under Uncertainty",
        "authors": [
            "Ki-Tae Kim",
            "Umberto Villa",
            "Matthew Parno",
            "Youssef Marzouk",
            "Omar Ghattas",
            "Noemi Petra"
        ],
        "summary": "Bayesian inference provides a systematic framework for integration of data with mathematical models to quantify the uncertainty in the solution of the inverse problem. However, the solution of Bayesian inverse problems governed by complex forward models described by partial differential equations (PDEs) remains prohibitive with black-box Markov chain Monte Carlo (MCMC) methods. We present hIPPYlib-MUQ, an extensible and scalable software framework that contains implementations of state-of-the art algorithms aimed to overcome the challenges of high-dimensional, PDE-constrained Bayesian inverse problems. These algorithms accelerate MCMC sampling by exploiting the geometry and intrinsic low-dimensionality of parameter space via derivative information and low rank approximation. The software integrates two complementary open-source software packages, hIPPYlib and MUQ. hIPPYlib solves PDE-constrained inverse problems using automatically-generated adjoint-based derivatives, but it lacks full Bayesian capabilities. MUQ provides a spectrum of powerful Bayesian inversion models and algorithms, but expects forward models to come equipped with gradients and Hessians to permit large-scale solution. By combining these two libraries, we created a robust, scalable, and efficient software framework that realizes the benefits of each and allows us to tackle complex large-scale Bayesian inverse problems. To illustrate the capabilities of hIPPYlib-MUQ, we present a comparison of a number of MCMC methods on several inverse problems. These include problems with linear and nonlinear PDEs, various noise models, and different parameter dimensions. The results demonstrate that large ($\\sim 50\\times$) speedups over conventional black box and gradient-based MCMC algorithms can be obtained by exploiting Hessian information (from the log posterior), underscoring the power of the integrated hIPPYlib-MUQ framework.",
        "published": "2021-12-01T18:44:20Z",
        "link": "http://arxiv.org/abs/2112.00713v2",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "math.OC",
            "stat.CO",
            "35Q62, 62F15, 35R30, 35Q93, 65C99, 65K10, 49M15, 68N99"
        ]
    },
    {
        "title": "Dynamic Sparse Tensor Algebra Compilation",
        "authors": [
            "Stephen Chou",
            "Saman Amarasinghe"
        ],
        "summary": "This paper shows how to generate efficient tensor algebra code that compute on dynamic sparse tensors, which have sparsity structures that evolve over time. We propose a language for precisely specifying recursive, pointer-based data structures, and we show how this language can express a wide range of dynamic data structures that support efficient modification, such as linked lists, binary search trees, and B-trees. We then describe how, given high-level specifications of such data structures, a compiler can generate code to efficiently iterate over and compute with dynamic sparse tensors that are stored in the aforementioned data structures. Furthermore, we define an abstract interface that captures how nonzeros can be inserted into dynamic data structures, and we show how this abstraction guides a compiler to emit efficient code that store the results of sparse tensor algebra computations in dynamic data structures.   We evaluate our technique and find that it generates efficient dynamic sparse tensor algebra kernels. Code that our technique emits to compute the main kernel of the PageRank algorithm is 1.05$\\times$ as fast as Aspen, a state-of-the-art dynamic graph processing framework. Furthermore, our technique outperforms PAM, a parallel ordered (key-value) maps library, by 7.40$\\times$ when used to implement element-wise addition of a dynamic sparse matrix to a static sparse matrix.",
        "published": "2021-12-02T16:28:34Z",
        "link": "http://arxiv.org/abs/2112.01394v1",
        "categories": [
            "cs.MS",
            "cs.PL"
        ]
    },
    {
        "title": "Bayesian supervised predictive classification and hypothesis testing   toolkit for partition exchangeability",
        "authors": [
            "Ville Kinnula",
            "Jing Tang",
            "Ali Amiryousefi"
        ],
        "summary": "Bayesian supervised predictive classifiers, hypothesis testing, and parametric estimation under Partition Exchangeability are implemented. The two classifiers presented are the marginal classifier (that assumes test data is i.i.d.) next to a more computationally costly but accurate simultaneous classifier (that finds a labelling for the entire test dataset at once based on simultanous use of all the test data to predict each label). We also provide the Maximum Likelihood Estimation (MLE) of the only underlying parameter of the partition exchangeability generative model as well as hypothesis testing statistics for equality of this parameter with a single value, alternative, or multiple samples. We present functions to simulate the sequences from Ewens Sampling Formula as the realisation of the Poisson-Dirichlet distribution and their respective probabilities.",
        "published": "2021-12-02T21:50:42Z",
        "link": "http://arxiv.org/abs/2112.01618v1",
        "categories": [
            "stat.CO",
            "cs.MS"
        ]
    },
    {
        "title": "ProbNum: Probabilistic Numerics in Python",
        "authors": [
            "Jonathan Wenger",
            "Nicholas Krämer",
            "Marvin Pförtner",
            "Jonathan Schmidt",
            "Nathanael Bosch",
            "Nina Effenberger",
            "Johannes Zenn",
            "Alexandra Gessner",
            "Toni Karvonen",
            "François-Xavier Briol",
            "Maren Mahsereci",
            "Philipp Hennig"
        ],
        "summary": "Probabilistic numerical methods (PNMs) solve numerical problems via probabilistic inference. They have been developed for linear algebra, optimization, integration and differential equation simulation. PNMs naturally incorporate prior information about a problem and quantify uncertainty due to finite computational resources as well as stochastic input. In this paper, we present ProbNum: a Python library providing state-of-the-art probabilistic numerical solvers. ProbNum enables custom composition of PNMs for specific problem classes via a modular design as well as wrappers for off-the-shelf use. Tutorials, documentation, developer guides and benchmarks are available online at www.probnum.org.",
        "published": "2021-12-03T07:20:50Z",
        "link": "http://arxiv.org/abs/2112.02100v1",
        "categories": [
            "cs.MS",
            "cs.LG",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Differentiable Scripting",
        "authors": [
            "Uwe Naumann"
        ],
        "summary": "In Computational Science, Engineering and Finance (CSEF) scripts typically serve as the \"glue\" between potentially highly complex and computationally expensive external subprograms. Differentiability of the resulting programs turns out to be essential in the context of derivative-based methods for error analysis, uncertainty quantification, optimization or training of surrogates. We argue that it should be enforced by the scripting language itself through exclusive support of differentiable (smoothed) external subprograms and differentiable intrinsics combined with prohibition of nondifferentiable branches in the data flow. Illustration is provided by a prototype adjoint code compiler for a simple Python-like scripting language.",
        "published": "2021-12-03T12:33:56Z",
        "link": "http://arxiv.org/abs/2112.03036v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "AIMpy: A Python code to solve Schrödinger-like equations with the   asymptotic iteration method",
        "authors": [
            "Mesut Karakoç"
        ],
        "summary": "This paper is dedicated to present an open-source program so-called \\emph{AIMpy} built on Python language. \\emph{AIMpy} is a solver for Schr\\\"{o}dinger-like differential equations using Asymptotic Iteration Method (AIM). To confirm the code works seamlessly, it has been shown through the paper with recalculation of some previously studied eigenvalue examples that the code can reproduce their results very well.",
        "published": "2021-12-06T11:13:47Z",
        "link": "http://arxiv.org/abs/2112.02934v1",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "quant-ph"
        ]
    },
    {
        "title": "Simulation Intelligence: Towards a New Generation of Scientific Methods",
        "authors": [
            "Alexander Lavin",
            "David Krakauer",
            "Hector Zenil",
            "Justin Gottschlich",
            "Tim Mattson",
            "Johann Brehmer",
            "Anima Anandkumar",
            "Sanjay Choudry",
            "Kamil Rocki",
            "Atılım Güneş Baydin",
            "Carina Prunkl",
            "Brooks Paige",
            "Olexandr Isayev",
            "Erik Peterson",
            "Peter L. McMahon",
            "Jakob Macke",
            "Kyle Cranmer",
            "Jiaxin Zhang",
            "Haruko Wainwright",
            "Adi Hanuka",
            "Manuela Veloso",
            "Samuel Assefa",
            "Stephan Zheng",
            "Avi Pfeffer"
        ],
        "summary": "The original \"Seven Motifs\" set forth a roadmap of essential methods for the field of scientific computing, where a motif is an algorithmic method that captures a pattern of computation and data movement. We present the \"Nine Motifs of Simulation Intelligence\", a roadmap for the development and integration of the essential algorithms necessary for a merger of scientific computing, scientific simulation, and artificial intelligence. We call this merger simulation intelligence (SI), for short. We argue the motifs of simulation intelligence are interconnected and interdependent, much like the components within the layers of an operating system. Using this metaphor, we explore the nature of each layer of the simulation intelligence operating system stack (SI-stack) and the motifs therein: (1) Multi-physics and multi-scale modeling; (2) Surrogate modeling and emulation; (3) Simulation-based inference; (4) Causal modeling and inference; (5) Agent-based modeling; (6) Probabilistic programming; (7) Differentiable programming; (8) Open-ended optimization; (9) Machine programming. We believe coordinated efforts between motifs offers immense opportunity to accelerate scientific discovery, from solving inverse problems in synthetic biology and climate science, to directing nuclear energy experiments and predicting emergent behavior in socioeconomic settings. We elaborate on each layer of the SI-stack, detailing the state-of-art methods, presenting examples to highlight challenges and opportunities, and advocating for specific ways to advance the motifs and the synergies from their combinations. Advancing and integrating these technologies can enable a robust and efficient hypothesis-simulation-analysis type of scientific method, which we introduce with several use-cases for human-machine teaming and automated science.",
        "published": "2021-12-06T18:45:31Z",
        "link": "http://arxiv.org/abs/2112.03235v2",
        "categories": [
            "cs.AI",
            "cs.CE",
            "cs.LG",
            "cs.MS"
        ]
    },
    {
        "title": "Accelerating jackknife resampling for the Canonical Polyadic   Decomposition",
        "authors": [
            "Christos Psarras",
            "Lars Karlsson",
            "Rasmus Bro",
            "Paolo Bientinesi"
        ],
        "summary": "The Canonical Polyadic (CP) tensor decomposition is frequently used as a model in applications in a variety of different fields. Using jackknife resampling to estimate parameter uncertainties is often desirable but results in an increase of the already high computational cost. Upon observation that the resampled tensors, though different, are nearly identical, we show that it is possible to extend the recently proposed Concurrent ALS (CALS) technique to a jackknife resampling scenario. This extension gives access to the computational efficiency advantage of CALS for the price of a modest increase (typically a few percent) in the number of floating point operations. Numerical experiments on both synthetic and real-world datasets demonstrate that the new workflow based on a CALS extension can be several times faster than a straightforward workflow where the jackknife submodels are processed individually.",
        "published": "2021-12-07T20:58:30Z",
        "link": "http://arxiv.org/abs/2112.03985v1",
        "categories": [
            "cs.MS",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "(R)SE challenges in HPC",
        "authors": [
            "Jonas Thies",
            "Melven Röhrig-Zöllner",
            "Achim Basermann"
        ],
        "summary": "We discuss some specific software engineering challenges in the field of high-performance computing, and argue that the slow adoption of SE tools and techniques is at least in part caused by the fact that these do not address the HPC challenges `out-of-the-box'. By giving some examples of solutions for designing, testing and benchmarking HPC software, we intend to bring software engineering and HPC closer together.",
        "published": "2021-12-10T14:24:28Z",
        "link": "http://arxiv.org/abs/2112.06617v1",
        "categories": [
            "cs.SE",
            "cs.DC",
            "cs.MS",
            "cs.PF",
            "65Y05",
            "G.4; D.2.2"
        ]
    },
    {
        "title": "Matrix-free approaches for GPU acceleration of a high-order finite   element hydrodynamics application using MFEM, Umpire, and RAJA",
        "authors": [
            "Arturo Vargas",
            "Thomas M. Stitt",
            "Kenneth Weiss",
            "Vladimir Z. Tomov",
            "Jean-Sylvain Camier",
            "Tzanio Kolev",
            "Robert N. Rieben"
        ],
        "summary": "With the introduction of advanced heterogeneous computing architectures based on GPU accelerators, large-scale production codes have had to rethink their numerical algorithms and incorporate new programming models and memory management strategies in order to run efficiently on the latest supercomputers. In this work we discuss our co-design strategy to address these challenges and achieve performance and portability with MARBL, a next-generation multi-physics code in development at Lawrence Livermore National Laboratory. We present a two-fold approach, wherein new hardware is used to motivate both new algorithms and new abstraction layers, resulting in a single source application code suitable for a variety of platforms. Focusing on MARBL's ALE hydrodynamics package, we demonstrate scalability on different platforms and highlight that many of our innovations have been contributed back to open-source software libraries, such as MFEM (finite element algorithms) and RAJA (kernel abstractions).",
        "published": "2021-12-14T00:25:12Z",
        "link": "http://arxiv.org/abs/2112.07075v1",
        "categories": [
            "cs.MS",
            "35-04",
            "D.0; F.2; G.4; I.6"
        ]
    },
    {
        "title": "An eXtended Finite Element Method Implementation in COMSOL Multiphysics:   Thermo-Hydro-Mechanical Modeling of Fluid Flow in Discontinuous Porous Media",
        "authors": [
            "Ahmad Jafari",
            "Mohammad Vahab",
            "Pooyan Broumand",
            "Nasser Khalili"
        ],
        "summary": "This paper presents the implementation of the eXtended Finite Element Method (XFEM) in the general-purpose commercial software package COMSOL Multiphysics for multi-field thermo-hydro-mechanical problems in discontinuous porous media. To this end, an exclusive enrichment strategy is proposed in compliance with the COMSOL modeling structure. COMSOL modules and physics interfaces are adopted to take account of the relevant physical processes involved in thermo-hydro-mechanical coupling analysis, namely: the mechanical deformation, fluid flow in porous media and heat transfer. Essential changes are made to the internal variables of the physics interfaces to ensure consistency in the evaluation of enriched solution fields. The model preprocessing, level-set updates, coupling of the relevant physics and postprocessing procedures are performed adopting a coherent utilization of the COMSOL built-in features along with the COMSOL LiveLink for MATLAB functions. The implementation process, remedies for the treatment of the enriched zones, XFEM framework setup, multiphysics coupling, numerical integration and numerical solution strategy are described in detail. The capabilities and performance of the proposed approach are investigated by examining several multi-field thermo-hydro-mechanical simulations involving single/multiple discontinuities in 2D/3D porous rock settings.",
        "published": "2021-12-17T06:36:58Z",
        "link": "http://arxiv.org/abs/2112.11918v1",
        "categories": [
            "cs.MS",
            "cs.CE"
        ]
    },
    {
        "title": "Efficient implementation of modern entropy stable and kinetic energy   preserving discontinuous Galerkin methods for conservation laws",
        "authors": [
            "Hendrik Ranocha",
            "Michael Schlottke-Lakemper",
            "Jesse Chan",
            "Andrés M. Rueda-Ramírez",
            "Andrew R. Winters",
            "Florian Hindenlang",
            "Gregor J. Gassner"
        ],
        "summary": "Many modern discontinuous Galerkin (DG) methods for conservation laws make use of summation by parts operators and flux differencing to achieve kinetic energy preservation or entropy stability. While these techniques increase the robustness of DG methods significantly, they are also computationally more demanding than standard weak form nodal DG methods. We present several implementation techniques to improve the efficiency of flux differencing DG methods that use tensor product quadrilateral or hexahedral elements, in 2D or 3D respectively. Focus is mostly given to CPUs and DG methods for the compressible Euler equations, although these techniques are generally also useful for other physical systems including the compressible Navier-Stokes and magnetohydrodynamics equations. We present results using two open source codes, Trixi.jl written in Julia and FLUXO written in Fortran, to demonstrate that our proposed implementation techniques are applicable to different code bases and programming languages.",
        "published": "2021-12-20T13:25:37Z",
        "link": "http://arxiv.org/abs/2112.10517v2",
        "categories": [
            "cs.MS",
            "cs.NA",
            "math.NA",
            "physics.comp-ph"
        ]
    },
    {
        "title": "NetKet 3: Machine Learning Toolbox for Many-Body Quantum Systems",
        "authors": [
            "Filippo Vicentini",
            "Damian Hofmann",
            "Attila Szabó",
            "Dian Wu",
            "Christopher Roth",
            "Clemens Giuliani",
            "Gabriel Pescia",
            "Jannes Nys",
            "Vladimir Vargas-Calderon",
            "Nikita Astrakhantsev",
            "Giuseppe Carleo"
        ],
        "summary": "We introduce version 3 of NetKet, the machine learning toolbox for many-body quantum physics. NetKet is built around neural-network quantum states and provides efficient algorithms for their evaluation and optimization. This new version is built on top of JAX, a differentiable programming and accelerated linear algebra framework for the Python programming language. The most significant new feature is the possibility to define arbitrary neural network ans\\\"atze in pure Python code using the concise notation of machine-learning frameworks, which allows for just-in-time compilation as well as the implicit generation of gradients thanks to automatic differentiation. NetKet 3 also comes with support for GPU and TPU accelerators, advanced support for discrete symmetry groups, chunking to scale up to thousands of degrees of freedom, drivers for quantum dynamics applications, and improved modularity, allowing users to use only parts of the toolbox as a foundation for their own code.",
        "published": "2021-12-20T13:41:46Z",
        "link": "http://arxiv.org/abs/2112.10526v2",
        "categories": [
            "quant-ph",
            "cs.LG",
            "cs.MS",
            "physics.comp-ph"
        ]
    },
    {
        "title": "PyChEst: a Python package for the consistent retrospective estimation of   distributional changes in piece-wise stationary time series",
        "authors": [
            "Azadeh Khaleghi",
            "Lukas Zierahn"
        ],
        "summary": "We introduce PyChEst, a Python package which provides tools for the simultaneous estimation of multiple changepoints in the distribution of piece-wise stationary time series. The nonparametric algorithms implemented are provably consistent in a general framework: when the samples are generated by unknown piece-wise stationary processes. In this setting, samples may have long-range dependencies of arbitrary form and the finite-dimensional marginals of any (unknown) fixed size before and after the changepoints may be the same. The strength of the algorithms included in the package is in their ability to consistently detect the changes without imposing any assumptions beyond stationarity on the underlying process distributions. We illustrate this distinguishing feature by comparing the performance of the package against state-of-the-art models designed for a setting where the samples are independently and identically distributed.",
        "published": "2021-12-20T14:39:39Z",
        "link": "http://arxiv.org/abs/2112.10565v1",
        "categories": [
            "stat.CO",
            "cs.MS",
            "stat.AP",
            "stat.ML"
        ]
    },
    {
        "title": "Latte: Cross-framework Python Package for Evaluation of Latent-Based   Generative Models",
        "authors": [
            "Karn N. Watcharasupat",
            "Junyoung Lee",
            "Alexander Lerch"
        ],
        "summary": "Latte (for LATent Tensor Evaluation) is a Python library for evaluation of latent-based generative models in the fields of disentanglement learning and controllable generation. Latte is compatible with both PyTorch and TensorFlow/Keras, and provides both functional and modular APIs that can be easily extended to support other deep learning frameworks. Using NumPy-based and framework-agnostic implementation, Latte ensures reproducible, consistent, and deterministic metric calculations regardless of the deep learning framework of choice.",
        "published": "2021-12-20T16:00:28Z",
        "link": "http://arxiv.org/abs/2112.10638v3",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.IR",
            "cs.MS"
        ]
    },
    {
        "title": "PyTracer: Automatically profiling numerical instabilities in Python",
        "authors": [
            "Yohan Chatelain",
            "Nigel Yong",
            "Gregory Kiar",
            "Tristan Glatard"
        ],
        "summary": "Numerical stability is a crucial requirement of reliable scientific computing. However, despite the pervasiveness of Python in data science, analyzing large Python programs remains challenging due to the lack of scalable numerical analysis tools available for this language. To fill this gap, we developed PyTracer, a profiler to quantify numerical instability in Python applications. PyTracer transparently instruments Python code to produce numerical traces and visualize them interactively in a Plotly dashboard. We designed PyTracer to be agnostic to numerical noise model, allowing for tool evaluation through Monte-Carlo Arithmetic, random rounding, random data perturbation, or structured noise for a particular application. We illustrate PyTracer's capabilities by testing the numerical stability of key functions in both SciPy and Scikit-learn, two dominant Python libraries for mathematical modeling. Through these evaluations, we demonstrate PyTracer as a scalable, automatic, and generic framework for numerical profiling in Python.",
        "published": "2021-12-21T20:22:34Z",
        "link": "http://arxiv.org/abs/2112.11508v2",
        "categories": [
            "cs.MS",
            "cs.NA",
            "cs.SE",
            "math.NA"
        ]
    },
    {
        "title": "Iterative Krylov Methods for Acoustic Problems on Graphics Processing   Unit",
        "authors": [
            "Abal-Kassim Cheik Ahamed",
            "Frederic Magoules"
        ],
        "summary": "This paper deals with linear algebra operations on Graphics Processing Unit (GPU) with complex number arithmetic using double precision. An analysis of their uses within iterative Krylov methods is presented to solve acoustic problems. Numerical experiments performed on a set of acoustic matrices arising from the modelisation of acoustic phenomena inside a car compartment are collected, and outline the performance, robustness and effectiveness of our algorithms, with a speed-up up to 28x for dot product, 9.8x for sparse matrix-vector product and solvers.",
        "published": "2021-12-22T14:04:53Z",
        "link": "http://arxiv.org/abs/2112.11880v1",
        "categories": [
            "math.NA",
            "cs.DC",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "Variational symplectic diagonally implicit Runge-Kutta methods for   isospectral systems",
        "authors": [
            "Clauson Carvalho da Silva",
            "Christian Lessig"
        ],
        "summary": "Isospectral flows appear in a variety of applications, e.g. the Toda lattice in solid state physics or in discrete models for two-dimensional hydrodynamics, with the isospectral property often corresponding to mathematically or physically important conservation laws. Their most prominent feature, i.e. the conservation of the eigenvalues of the matrix state variable, should therefore be retained when discretizing these systems. Recently, it was shown how isospectral Runge-Kutta methods can, in the Lie-Poisson case also considered in our work, be obtained through Hamiltonian reduction of symplectic Runge-Kutta methods on the cotangent bundle of a Lie group. We provide the Lagrangian analogue and, in the case of symplectic diagonal implicit Runge-Kutta methods, derive the methods through a discrete Euler-Poincare reduction. Our derivation relies on a formulation of diagonally implicit isospectral Runge-Kutta methods in terms of the Cayley transform, generalizing earlier work that showed this for the implicit midpoint rule. Our work is also a generalization of earlier variational Lie group integrators that, interestingly, appear when these are interpreted as update equations for intermediate time points. From a practical point of view, our results allow for a simple implementation of higher order isospectral methods and we demonstrate this with numerical experiments where both the isospectral property and energy are conserved to high accuracy.",
        "published": "2021-12-27T15:04:55Z",
        "link": "http://arxiv.org/abs/2112.13721v1",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "65L06, 65P10"
        ]
    },
    {
        "title": "Proceedings of the 13th International Conference on Automated Deduction   in Geometry",
        "authors": [
            "Predrag Janičić",
            "Zoltán Kovács"
        ],
        "summary": "Automated Deduction in Geometry (ADG) is a forum to exchange ideas and views, to present research results and progress, and to demonstrate software tools at the intersection between geometry and automated deduction. Relevant topics include (but are not limited to): polynomial algebra, invariant and coordinate-free methods; probabilistic, synthetic, and logic approaches, techniques for automated geometric reasoning from discrete mathematics, combinatorics, and numerics; interactive theorem proving in geometry; symbolic and numeric methods for geometric computation, geometric constraint solving, automated generation/reasoning and manipulation with diagrams; design and implementation of geometry software, automated theorem provers, special-purpose tools, experimental studies; applications of ADG in mechanics, geometric modelling, CAGD/CAD, computer vision, robotics and education.   Traditionally, the ADG conference is held every two years. The previous editions of ADG were held in Nanning in 2018, Strasbourg in 2016, Coimbra in 2014, Edinburgh in 2012, Munich in 2010, Shanghai in 2008, Pontevedra in 2006, Gainesville in 2004, Hagenberg in 2002, Zurich in 2000, Beijing in 1998, and Toulouse in 1996. The 13th edition of ADG was supposed to be held in 2020 in Hagenberg, Austria, but due to the COVID-19 pandemic, it was postponed for 2021, and held online (still hosted by RISC Institute, Hagenberg, Austria), September 15-17, 2021 (https://www.risc.jku.at/conferences/adg2021).",
        "published": "2021-12-28T21:56:13Z",
        "link": "http://arxiv.org/abs/2112.14770v1",
        "categories": [
            "cs.AI",
            "cs.LO",
            "cs.MS",
            "cs.SC"
        ]
    },
    {
        "title": "Neumann Series in GMRES and Algebraic Multigrid Smoothers",
        "authors": [
            "Stephen Thomas",
            "Arielle Carr",
            "Paul Mullowney",
            "Ruipeng Li",
            "Kasia Świrydowicz"
        ],
        "summary": "Neumann series underlie both Krylov methods and algebraic multigrid smoothers. A low-synch modified Gram-Schmidt (MGS)-GMRES algorithm is described that employs a Neumann series to accelerate the projection step. A corollary to the backward stability result of Paige et al. (2006) demonstrates that the truncated Neumann series approximation is sufficient for convergence of GMRES. The lower triangular solver associated with the correction matrix $T_m = (\\: I + L_m \\:)^{-1}$ may then be replaced by a matrix-vector product with $T_m = I - L_m$. Next, Neumann series are applied to accelerate the classical R\\\"uge-Stuben algebraic multigrid preconditioner using both a polynomial Gauss-Seidel or incomplete ILU smoother. The sparse triangular solver employed in these smoothers is replaced by an inner iteration based upon matrix-vector products. Henrici's departure from normality of the associated iteration matrices leads to a better understanding of these series. Connections are made between the (non)normality of the $L$ and $U$ factors and nonlinear stability analysis, as well as the pseudospectra of the coefficient matrix. Furthermore, re-orderings that preserve structural symmetry also reduce the departure from normality of the upper triangular factor and improve the relative residual of the triangular solves. To demonstrate the effectiveness of this approach on many-core architectures, the proposed solver and preconditioner are applied to the pressure continuity equation for the incompressible Navier-Stokes equations of fluid motion. The pressure solve time is reduced considerably with no change in the convergence rate and the polynomial Gauss-Seidel smoother is compared with a Jacobi smoother. Numerical and timing results are presented for Nalu-Wind and the PeleLM combustion codes, where ILU with iterative triangular solvers is shown to be much more effective than polynomial Gauss-Seidel.",
        "published": "2021-12-29T17:57:07Z",
        "link": "http://arxiv.org/abs/2112.14681v1",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "Olsson.wl : a Mathematica package for the computation of linear   transformations of multivariable hypergeometric functions",
        "authors": [
            "B. Ananthanarayan",
            "Souvik Bera",
            "S. Friot",
            "Tanay Pathak"
        ],
        "summary": "We present the Olsson.wl Mathematica package which aims to find linear transformations for some classes of multivariable hypergeometric functions. It is based on a well-known method developed by P. O. M. Olsson in J. Math. Phys. 5, 420 (1964) in order to derive the analytic continuations of the Appell $F_1$ double hypergeometric series from the linear transformations of the Gauss $_2F_1$ hypergeometric function. We provide a brief description of Olsson's method and demonstrate the commands of the package, along with examples. We also provide a companion package, called ROC2.wl and dedicated to the derivation of the regions of convergence of double hypergeometric series. This package can be used independently of Olsson.wl.",
        "published": "2021-12-31T17:08:08Z",
        "link": "http://arxiv.org/abs/2201.01189v1",
        "categories": [
            "cs.MS",
            "cs.NA",
            "hep-ph",
            "hep-th",
            "math.NA"
        ]
    },
    {
        "title": "Proceedings 6th International Workshop on Symbolic-Numeric methods for   Reasoning about CPS and IoT",
        "authors": [
            "Thao Dang",
            "Stefan Ratschan"
        ],
        "summary": "The proceedings of the 6th International Workshop on Symbolic-Numeric Methods for Reasoning about CPS and IoT (SNR 2020) contains papers underlying talks presented at the workshop. SNR focuses on the combination of symbolic and numeric methods for reasoning about Cyber-Physical Systems and the Internet of Things to facilitate model identification, specification, verification, and control synthesis for these systems.",
        "published": "2021-01-01T06:32:01Z",
        "link": "http://arxiv.org/abs/2101.05256v1",
        "categories": [
            "cs.LO",
            "cs.SC"
        ]
    },
    {
        "title": "Monomial-agnostic computation of vanishing ideals",
        "authors": [
            "Hiroshi Kera",
            "Yoshihiko Hasegawa"
        ],
        "summary": "In the last decade, the approximate basis computation of vanishing ideals has been studied extensively in computational algebra and data-driven applications such as machine learning. However, symbolic computation and the dependency on term order remain essential gaps between the two fields. In this study, we present the first $\\textit{monomial-agnostic}$ basis computation, which works fully numerically with proper normalization and without term order. This is realized by gradient normalization, a newly proposed data-dependent normalization that normalizes a polynomial with the magnitude of gradients at given points. The data-dependent nature of gradient normalization brings various significant advantages: i) efficient resolution of the spurious vanishing problem, the scale-variance issue of approximately vanishing polynomials, without accessing coefficients of terms, ii) scaling-consistent basis computation, ensuring that input scaling does not lead to an essential change in the output, and iii) robustness against input perturbations, where the upper bound of error is determined only by the magnitude of the perturbations. Existing studies did not achieve any of these. As further applications of gradient information, we propose a monomial-agnostic basis reduction method and a regularization method to manage positive-dimensional ideals.",
        "published": "2021-01-01T14:27:45Z",
        "link": "http://arxiv.org/abs/2101.00243v6",
        "categories": [
            "cs.SC",
            "math.AC"
        ]
    },
    {
        "title": "Border basis computation with gradient-weighted normalization",
        "authors": [
            "Hiroshi Kera"
        ],
        "summary": "Normalization of polynomials plays a vital role in the approximate basis computation of vanishing ideals. Coefficient normalization, which normalizes a polynomial with its coefficient norm, is the most common method in computer algebra. This study proposes the gradient-weighted normalization method for the approximate border basis computation of vanishing ideals, inspired by recent developments in machine learning. The data-dependent nature of gradient-weighted normalization leads to better stability against perturbation and consistency in the scaling of input points, which cannot be attained by coefficient normalization. Only a subtle change is needed to introduce gradient normalization in the existing algorithms with coefficient normalization. The analysis of algorithms still works with a small modification, and the order of magnitude of time complexity of algorithms remains unchanged. We also prove that, with coefficient normalization, which does not provide the scaling consistency property, scaling of points (e.g., as a preprocessing) can cause an approximate basis computation to fail. This study is the first to theoretically highlight the crucial effect of scaling in approximate basis computation and presents the utility of data-dependent normalization.",
        "published": "2021-01-02T08:29:51Z",
        "link": "http://arxiv.org/abs/2101.00401v4",
        "categories": [
            "cs.SC",
            "cs.LG",
            "math.AC"
        ]
    },
    {
        "title": "Some fast algorithms multiplying a matrix by its adjoint",
        "authors": [
            "Jean-Guillaume Dumas",
            "Clément Pernet",
            "Alexandre Sedoglavic"
        ],
        "summary": "We present a non-commutative algorithm for the multiplication of a 2 x 2 block-matrix by its adjoint, defined by a matrix ring anti-homomorphism. This algorithm uses 5 block products (3 recursive calls and 2 general products)over C or in positive characteristic. The resulting algorithm for arbitrary dimensions is a reduction of multiplication of a matrix by its adjoint to general matrix product, improving by a constant factor previously known reductions. We prove also that there is no algorithm derived from bilinear forms using only four products and the adjoint of one of them. Second we give novel dedicated algorithms for the complex field and the quaternions to alternatively compute the multiplication taking advantage of the structure of the matrix-polynomial arithmetic involved. We then analyze the respective ranges of predominance of the two strategies. Finally we propose schedules with low memory footprint that support a fast and memory efficient practical implementation over a prime field.",
        "published": "2021-01-04T15:24:25Z",
        "link": "http://arxiv.org/abs/2101.01025v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Methods for computing $b$-functions associated with $μ$-constant   deformations -- Case of inner modality 2 --",
        "authors": [
            "Katsusuke Nabeshima",
            "Shinichi Tajima"
        ],
        "summary": "New methods for computing parametric local $b$-functions are introduced for $\\mu$-constant deformations of semi-weighted homogeneous singularities. The keys of the methods are comprehensive Gr\\\"obner systems in Poincar\\'e-Birkhoff-Witt algebra and holonomic ${\\mathcal D}$-modules. It is shown that the use of semi-weighted homogeneity reduces the computational complexity of $b$-functions associated with $\\mu$-constant deformations. In the case of inner modality 2, local $b$-functions associated with $\\mu$-constant deformations are obtained by the resulting method and given the list of parametric local $b$-functions.",
        "published": "2021-01-05T07:15:40Z",
        "link": "http://arxiv.org/abs/2101.01384v2",
        "categories": [
            "math.AG",
            "cs.SC",
            "13P10, 14H20"
        ]
    },
    {
        "title": "PTOPO: Computing the Geometry and the Topology of Parametric Curves",
        "authors": [
            "Christina Katsamaki",
            "Fabrice Rouillier",
            "Elias Tsigaridas"
        ],
        "summary": "We consider the problem of computing the topology and describing the geometry of a parametric curve in $\\mathbb{R}^n$. We present an algorithm, PTOPO, that constructs an abstract graph that is isotopic to the curve in the embedding space. Our method exploits the benefits of the parametric representation and does not resort to implicitization.   Most importantly, we perform all computations in the parameter space and not in the implicit space. When the parametrization involves polynomials of degree at most $d$ and maximum bitsize of coefficients $\\tau$, then the worst case bit complexity of PTOPO is $ \\tilde{\\mathcal{O}}_B(nd^6+nd^5\\tau+d^4(n^2+n\\tau)+d^3(n^2\\tau+ n^3)+n^3d^2\\tau)$. This bound matches the current record bound $\\tilde{\\mathcal{O}}_B(d^6+d^5\\tau)$ for the problem of computing the topology of a plane algebraic curve given in implicit form. For plane and space curves, if $N = \\max\\{d, \\tau \\}$, the complexity of PTOPO becomes $\\tilde{\\mathcal{O}}_B(N^6)$, which improves the state-of-the-art result, due to Alc\\'azar and D\\'iaz-Toca [CAGD'10], by a factor of $N^{10}$. In the same time complexity, we obtain a graph whose straight-line embedding is isotopic to the curve. However, visualizing the curve on top of the abstract graph construction, increases the bound to $\\tilde{\\mathcal{O}}_B(N^7)$. For curves of general dimension, we can also distinguish between ordinary and non-ordinary real singularities and determine their multiplicities in the same expected complexity of PTOPO by employing the algorithm of Blasco and P\\'erez-D\\'iaz [CAGD'19]. We have implemented PTOPO in Maple for the case of plane and space curves. Our experiments illustrate its practical nature.",
        "published": "2021-01-06T08:48:25Z",
        "link": "http://arxiv.org/abs/2101.01925v2",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Polynomial modular product verification and its implications",
        "authors": [
            "Pascal Giorgi",
            "Bruno Grenet",
            "Armelle Perret du Cray"
        ],
        "summary": "Polynomial multiplication is known to have quasi-linear complexity in both the dense and the sparse cases. Yet no truly linear algorithm has been given in any case for the problem, and it is not clear whether it is even possible. This leaves room for a better algorithm for the simpler problem of verifying a polynomial product. While finding deterministic methods seems out of reach, there exist probabilistic algorithms for the problem that are optimal in number of algebraic operations.   We study the generalization of the problem to the verification of a polynomial product modulo a sparse divisor. We investigate its bit complexity for both dense and sparse multiplicands. In particular, we are able to show the primacy of the verification over modular multiplication when the divisor has a constant sparsity and a second highest-degree monomial that is not too large. We use these results to obtain new bounds on the bit complexity of the standard polynomial multiplication verification. In particular, we provide optimal algorithms in the bit complexity model in the dense case by improving a result of Kaminski and develop the first quasi-optimal algorithm for verifying sparse polynomial product.",
        "published": "2021-01-06T17:19:14Z",
        "link": "http://arxiv.org/abs/2101.02142v1",
        "categories": [
            "cs.SC",
            "cs.CC"
        ]
    },
    {
        "title": "Theorem Proving and Algebra",
        "authors": [
            "Joseph A. Goguen"
        ],
        "summary": "This book can be seen either as a text on theorem proving that uses techniques from general algebra, or else as a text on general algebra illustrated and made concrete by practical exercises in theorem proving. The book considers several different logical systems, including first-order logic, Horn clause logic, equational logic, and first-order logic with equality. Similarly, several different proof paradigms are considered. However, we do emphasize equational logic, and for simplicity we use only the OBJ3 software system, though it is used in a rather flexible manner. We do not pursue the lofty goal of mechanizing proofs like those of which mathematicians are justly so proud; instead, we seek to take steps towards providing mechanical assistance for proofs that are useful for computer scientists in developing software and hardware. This more modest goal has the advantage of both being achievable and having practical benefits.   The following topics are covered: many-sorted signature, algebra and homomorphism; term algebra and substitution; equation and satisfaction; conditional equations; equational deduction and its completeness; deduction for conditional equations; the theorem of constants; interpretation and equivalence of theories; term rewriting, termination, confluence and normal form; abstract rewrite systems; standard models, abstract data types, initiality, and induction; rewriting and deduction modulo equations; first-order logic, models, and proof planning; second-order algebra; order-sorted algebra and rewriting; modules; unification and completion; and hidden algebra. In parallel with these are a gradual introduction to OBJ3, applications to group theory, various abstract data types (such as number systems, lists, and stacks), propositional calculus, hardware verification, the {\\lambda}-calculus, correctness of functional programs, and other topics.",
        "published": "2021-01-07T18:52:08Z",
        "link": "http://arxiv.org/abs/2101.02690v2",
        "categories": [
            "cs.LO",
            "cs.PL",
            "cs.SC",
            "68Q65, 03B70 (Primary)",
            "F.3.1; F.3.2; F.4.1; F.1.1; I.1.3"
        ]
    },
    {
        "title": "The Proper Basis for a Zero-dimensional Polynomial Ideal",
        "authors": [
            "Sheng-Ming Ma"
        ],
        "summary": "The proper basis formulated herein constitutes an improvement on the Gr\\\"obner basis for a zero-dimensional polynomial ideal. Let $K[\\mathbf{x}]$ be a polynomial ring over a field $K$ with $\\mathbf{x}:=(x_1,\\dotsc,x_n)$. With $x_1$ being the least variable, a zero-dimensional polynomial ideal $I\\subset K[\\mathbf{x}]$ always has an eliminant $\\chi\\in K[x_1]\\setminus K$ such that $I\\cap K[x_1]=(\\chi)$ after eliminating the other variables $\\tilde{\\mathbf{x}}:=(x_2,\\dotsc,x_n)$. Hence it is excessive computation for the elimination process involving the variable $x_1$ in Buchberger's algorithm for the Gr\\\"obner basis. It is natural to treat $K[\\mathbf{x}]$ as the algebra $K[x_1][\\tilde{\\mathbf{x}}]$ and define a new type of basis over $K[x_1]$ for $I$ called the proper basis. The proper basis is based on a new type of polynomial division called the proper division, which improves the division mechanism in M\\\"oller's algorithm over $K[x_1]$ for the Gr\\\"obner basis. We develop a modular algorithm over a principal ideal ring with zero divisors. The convincing efficiency of the proper basis over both Buchberger's Gr\\\"obner basis over $K$ and M\\\"oller's one over $K[x_1]$ is corroborated by a series of benchmark testings with respect to the typical \\textnormal{\\textsc{lex}} ordering.",
        "published": "2021-01-10T06:29:49Z",
        "link": "http://arxiv.org/abs/2101.03482v2",
        "categories": [
            "math.AC",
            "cs.SC",
            "math.AG",
            "13P10, 13B25"
        ]
    },
    {
        "title": "Object-Level Reasoning with Logics Encoded in HOL Light",
        "authors": [
            "Petros Papapanagiotou",
            "Jacques Fleuriot"
        ],
        "summary": "We present a generic framework that facilitates object level reasoning with logics that are encoded within the Higher Order Logic theorem proving environment of HOL Light. This involves proving statements in any logic using intuitive forward and backward chaining in a sequent calculus style. It is made possible by automated machinery that take care of the necessary structural reasoning and term matching automatically. Our framework can also handle type theoretic correspondences of proofs, effectively allowing the type checking and construction of computational processes via proof. We demonstrate our implementation using a simple propositional logic and its Curry-Howard correspondence to the lambda-calculus, and argue its use with linear logic and its various correspondences to session types.",
        "published": "2021-01-11T10:51:36Z",
        "link": "http://arxiv.org/abs/2101.03808v1",
        "categories": [
            "cs.LO",
            "cs.SC"
        ]
    },
    {
        "title": "Multi-Source Anomaly Detection in Distributed IT Systems",
        "authors": [
            "Jasmin Bogatinovski",
            "Sasho Nedelkoski"
        ],
        "summary": "The multi-source data generated by distributed systems, provide a holistic description of the system. Harnessing the joint distribution of the different modalities by a learning model can be beneficial for critical applications for maintenance of the distributed systems. One such important task is the task of anomaly detection where we are interested in detecting the deviation of the current behaviour of the system from the theoretically expected. In this work, we utilize the joint representation from the distributed traces and system log data for the task of anomaly detection in distributed systems. We demonstrate that the joint utilization of traces and logs produced better results compared to the single modality anomaly detection methods. Furthermore, we formalize a learning task - next template prediction NTP, that is used as a generalization for anomaly detection for both logs and distributed trace. Finally, we demonstrate that this formalization allows for the learning of template embedding for both the traces and logs. The joint embeddings can be reused in other applications as good initialization for spans and logs.",
        "published": "2021-01-13T10:11:32Z",
        "link": "http://arxiv.org/abs/2101.04977v1",
        "categories": [
            "cs.LG",
            "cs.DC",
            "cs.SC",
            "cs.SE"
        ]
    },
    {
        "title": "Weakly nonlocal Poisson brackets: tools, examples, computations",
        "authors": [
            "Matteo Casati",
            "Paolo Lorenzoni",
            "Daniele Valeri",
            "Raffaele Vitolo"
        ],
        "summary": "We implement an algorithm for the computation of Schouten bracket of weakly nonlocal Hamiltonian operators in three different computer algebra systems: Maple, Reduce and Mathematica. This class of Hamiltonian operators encompass almost all the examples coming from the theory of (1+1)-integrable evolutionary PDEs",
        "published": "2021-01-16T15:55:50Z",
        "link": "http://arxiv.org/abs/2101.06467v2",
        "categories": [
            "math-ph",
            "cs.SC",
            "math.MP",
            "nlin.SI"
        ]
    },
    {
        "title": "Telescopers for differential forms with one parameter",
        "authors": [
            "Shaoshi Chen",
            "Ruyong Feng",
            "Ziming Li",
            "Michael F. Singer",
            "Stephen Watt"
        ],
        "summary": "Telescopers for a function are linear differential (resp. difference) operators annihilated by the definite integral (resp. definite sum) of this function. They play a key role in Wilf-Zeilberger theory and algorithms for computing them have been extensively studied in the past thirty years. In this paper, we introduce the notion of telescopers for differential forms with $D$-finite function coefficients. These telescopers appear in several areas of mathematics, for instance parametrized differential Galois theory and mirror symmetry. We give a sufficient and necessary condition for the existence of telescopers for a differential form and describe a method to compute them if they exist. Algorithms for verifying this condition are also given.",
        "published": "2021-01-17T02:53:04Z",
        "link": "http://arxiv.org/abs/2101.06576v2",
        "categories": [
            "cs.SC",
            "68W30"
        ]
    },
    {
        "title": "Covering rational surfaces with rational parametrization images",
        "authors": [
            "Jorge Caravantes",
            "J. Rafael Sendra",
            "David Sevilla",
            "Carlos Villarino"
        ],
        "summary": "Let $S$ be a rational projective surface given by means of a projective rational parametrization whose base locus satisfies a mild assumption. In this paper we present an algorithm that provides three rational maps $f,g,h:\\mathbb{A}^2 --\\to S\\subset \\mathbb{P}^n$ such that the union of the three images covers $S$. As a consequence, we present a second algorithm that generates two rational maps $f,\\tilde{g}:\\mathbb{A}^2 --\\to S$, such that the union of their images covers the affine surface $S\\cap \\mathbb{A}^n$. In the affine case, the number of rational maps involved in the cover is in general optimal.",
        "published": "2021-01-18T11:25:48Z",
        "link": "http://arxiv.org/abs/2101.07011v1",
        "categories": [
            "math.AG",
            "cs.SC",
            "14Q10 (Primary) 68W30 (Secondary)"
        ]
    },
    {
        "title": "MultivariateApart: Generalized Partial Fractions",
        "authors": [
            "Matthias Heller",
            "Andreas von Manteuffel"
        ],
        "summary": "We present a package to perform partial fraction decompositions of multivariate rational functions. The algorithm allows to systematically avoid spurious denominator factors and is capable of producing unique results also when being applied to terms of a sum separately. The package is designed to work in Mathematica, but also provides interfaces to the Form and Singular computer algebra systems.",
        "published": "2021-01-20T19:00:20Z",
        "link": "http://arxiv.org/abs/2101.08283v1",
        "categories": [
            "cs.SC",
            "hep-ph",
            "hep-th"
        ]
    },
    {
        "title": "Accelerated Polynomial Evaluation and Differentiation at Power Series in   Multiple Double Precision",
        "authors": [
            "Jan Verschelde"
        ],
        "summary": "The problem is to evaluate a polynomial in several variables and its gradient at a power series truncated to some finite degree with multiple double precision arithmetic. To compensate for the cost overhead of multiple double precision and power series arithmetic, data parallel algorithms for general purpose graphics processing units are presented. The reverse mode of algorithmic differentiation is organized into a massively parallel computation of many convolutions and additions of truncated power series. Experimental results demonstrate that teraflop performance is obtained in deca double precision with power series truncated at degree 152. The algorithms scale well for increasing precision and increasing degrees.",
        "published": "2021-01-22T19:42:43Z",
        "link": "http://arxiv.org/abs/2101.10881v3",
        "categories": [
            "cs.MS",
            "cs.DC",
            "cs.NA",
            "cs.SC",
            "math.AG",
            "math.NA"
        ]
    },
    {
        "title": "There are EXACTLY 1493804444499093354916284290188948031229880469556 Ways   to Derange a Standard Deck of Cards (ignoring suits) [and many other such   useful facts]",
        "authors": [
            "Shalosh B. Ekhad",
            "Christoph Koutschan",
            "Doron Zeilberger"
        ],
        "summary": "In this memorial tribute to Joe Gillis, who taught us that Special Functions count, we show how the seminal Even-Gillis integral formula for the number of derangements of a multiset, in terms of Laguerre polynomials, can be used to efficiently compute not only the number of the title, but much harder ones, when it is interfaced with Wilf-Zeilberger algorithmic proof theory.",
        "published": "2021-01-25T14:53:38Z",
        "link": "http://arxiv.org/abs/2101.10147v1",
        "categories": [
            "math.CO",
            "cs.SC",
            "33F10, 05A15, 33D45, 68W30"
        ]
    },
    {
        "title": "Extensions of the AZ-algorithm and the Package MultiIntegrate",
        "authors": [
            "Jakob Ablinger"
        ],
        "summary": "We extend the (continuous) multivariate Almkvist-Zeilberger algorithm in order to apply it for instance to special Feynman integrals emerging in renormalizable Quantum field Theories. We will consider multidimensional integrals over hyperexponential integrands and try to find closed form representations in terms of nested sums and products or iterated integrals. In addition, if we fail to compute a closed form solution in full generality, we may succeed in computing the first coefficients of the Laurent series expansions of such integrals in terms of indefinite nested sums and products or iterated integrals. In this article we present the corresponding methods and algorithms. Our Mathematica package MultiIntegrate, can be considered as an enhanced implementation of the (continuous) multivariate Almkvist Zeilberger algorithm to compute recurrences or differential equations for hyperexponential integrands and integrals. Together with the summation package Sigma and the package HarmonicSums our package provides methods to compute closed form representations (or coefficients of the Laurent series expansions) of multidimensional integrals over hyperexponential integrands in terms of nested sums or iterated integrals.",
        "published": "2021-01-27T13:29:53Z",
        "link": "http://arxiv.org/abs/2101.11385v1",
        "categories": [
            "cs.SC",
            "hep-ph",
            "math.CO",
            "33F10",
            "G.2.1; F.2.2"
        ]
    },
    {
        "title": "A Companion Curve Tracing Method for Rank-deficient Polynomial Systems",
        "authors": [
            "Wenyuan Wu",
            "Changbo Chen"
        ],
        "summary": "We propose a method for tracing implicit real algebraic curves defined by polynomials with rank-deficient Jacobians.   For a given curve $f^{-1}(0)$, it first utilizes a regularization technique to compute at least one witness point per connected component of the curve.   We improve this step by establishing a sufficient condition for testing the emptiness of $f^{-1}(0)$.   We also analyze the convergence rate and carry out an error analysis for refining the witness points.   The witness points are obtained by computing the minimum distance of a random point to a smooth manifold embedding the curve while at the same time penalizing the residual of $f$ at the local minima.   To trace the curve starting from these witness points, we prove that if one drags the random point along a trajectory inside a tubular neighborhood of the embedded manifold of the curve, the projection of the trajectory on the manifold is unique and can be computed by numerical continuation.   We then show how to choose such a trajectory to approximate the curve by computing eigenvectors of certain matrices.   Effectiveness of the method is illustrated by examples.",
        "published": "2021-01-29T07:53:40Z",
        "link": "http://arxiv.org/abs/2101.12453v1",
        "categories": [
            "math.NA",
            "cs.NA",
            "cs.SC"
        ]
    },
    {
        "title": "Certified evaluations of Hölder continuous functions at roots of   polynomials",
        "authors": [
            "Parker B. Edwards",
            "Jonathan D. Hauenstein",
            "Clifford D. Smyth"
        ],
        "summary": "Various methods can obtain certified estimates for roots of polynomials. Many applications in science and engineering additionally utilize the value of functions evaluated at roots. For example, critical values are obtained by evaluating an objective function at critical points. For analytic evaluation functions, Newton's method naturally applies to yield certified estimates. These estimates no longer apply, however, for H\\\"older continuous functions, which are a generalization of Lipschitz continuous functions where continuous derivatives need not exist. This work develops and analyzes an alternative approach for certified estimates of evaluating locally H\\\"older continuous functions at roots of polynomials. An implementation of the method in Maple demonstrates efficacy and efficiency.",
        "published": "2021-01-30T00:14:39Z",
        "link": "http://arxiv.org/abs/2102.00115v1",
        "categories": [
            "cs.SC",
            "cs.NA",
            "math.NA",
            "65H14 (Primary) 65H04, 14-04 (Secondary)",
            "I.1.2"
        ]
    },
    {
        "title": "Choosing the Variable Ordering for Cylindrical Algebraic Decomposition   via Exploiting Chordal Structure",
        "authors": [
            "Haokun Li",
            "Bican Xia",
            "Huiying Zhang",
            "Tao Zheng"
        ],
        "summary": "Cylindrical algebraic decomposition (CAD) plays an important role in the field of real algebraic geometry and many other areas. As is well-known, the choice of variable ordering while computing CAD has a great effect on the time and memory use of the computation as well as the number of sample points computed. In this paper, we indicate that typical CAD algorithms, if executed with respect to a special kind of variable orderings (called \"the perfect elimination orderings\"), naturally preserve chordality, which is an important property on sparsity of variables. Experimentation suggests that if the associated graph of the polynomial system in question is chordal (\\emph{resp.}, is nearly chordal), then a perfect elimination ordering of the associated graph (\\emph{resp.}, of a minimal chordal completion of the associated graph) can be a good variable ordering for the CAD computation. That is, by using the perfect elimination orderings, the CAD computation may produce a much smaller full set of projection polynomials than by using other naive variable orderings. More importantly, for the complexity analysis of the CAD computation via a perfect elimination ordering, a so-called $(m,d)$-property of the full set of projection polynomials obtained via such an ordering is given, through which the \"size\" of this set is characterized. This property indicates that when the corresponding perfect elimination tree has a lower height, the full set of projection polynomials also tends to have a smaller \"size\". This is well consistent with the experimental results, hence the perfect elimination orderings with lower elimination tree height are further recommended to be used in the CAD projection.",
        "published": "2021-02-01T13:29:17Z",
        "link": "http://arxiv.org/abs/2102.00823v2",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Computing Limits of Quotients of Multivariate Real Analytic Functions",
        "authors": [
            "Adam Strzebonski"
        ],
        "summary": "We present an algorithm for computing limits of quotients of real analytic functions. The algorithm is based on computation of a bound on the Lojasiewicz exponent and requires the denominator to have an isolated zero at the limit point.",
        "published": "2021-02-02T00:57:48Z",
        "link": "http://arxiv.org/abs/2102.01242v1",
        "categories": [
            "cs.SC",
            "I.1.2; G.4"
        ]
    },
    {
        "title": "Term Algebras, Canonical Representations and Difference Ring Theory for   Symbolic Summation",
        "authors": [
            "Carsten Schneider"
        ],
        "summary": "A general overview of the existing difference ring theory for symbolic summation is given. Special emphasis is put on the user interface: the translation and back translation of the corresponding representations within the term algebra and the formal difference ring setting. In particular, canonical (unique) representations and their refinements in the introduced term algebra are explored by utilizing the available difference ring theory. Based on that, precise input-output specifications of the available tools of the summation package Sigma are provided.",
        "published": "2021-02-02T12:44:01Z",
        "link": "http://arxiv.org/abs/2102.01471v3",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Proceedings 11th International Workshop on Computing with Terms and   Graphs",
        "authors": [
            "Patrick Bahr"
        ],
        "summary": "Graphs, and graph transformation systems, are used in many areas within Computer Science: to represent data structures and algorithms, to define computation models, as a general modelling tool to study complex systems, etc. Research in term and graph rewriting ranges from theoretical questions to practical implementation issues. Relevant research areas include: the modelling of first- and higher-order term rewriting by graph rewriting, graphical frameworks such as interaction nets and sharing graphs (optimal reduction), rewrite calculi for the analysis of functional programs, graph reduction implementations of programming languages, graphical calculi modelling concurrent and mobile computations, object-oriented systems, graphs as a model of biological or chemical systems, and automated reasoning and symbolic computation systems working on shared structures. The aim of the TERMGRAPH workshop is to bring together researchers working in these different domains and to foster their interaction, to provide a forum for presenting new ideas and work in progress, and to enable newcomers to learn about current activities in this area.",
        "published": "2021-02-02T23:58:54Z",
        "link": "http://arxiv.org/abs/2102.01804v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Combinatorial Differential Algebra of $x^p$",
        "authors": [
            "Rida Ait El Manssour",
            "Anna-Laura Sattelberger"
        ],
        "summary": "We link $n$-jets of the affine monomial scheme defined by $x^p$ to the stable set polytope of some perfect graph. We prove that, as $p$ varies, the dimension of the coordinate ring of a certain subscheme of the scheme of $n$-jets as a $\\mathbb{C}$-vector space is a polynomial of degree $n+1$, namely the Ehrhart polynomial of the stable set polytope of that graph. One main ingredient for our proof is a result of Zobnin who determined a differential Gr\\\"{o}bner basis of the differential ideal generated by $x^p$. We generalize Zobnin's result to the bivariate case. We study $(m,n)$-jets, a higher-dimensional analog of jets, and relate them to regular unimodular triangulations.",
        "published": "2021-02-05T14:02:07Z",
        "link": "http://arxiv.org/abs/2102.03182v3",
        "categories": [
            "math.AG",
            "cs.SC",
            "math.CO",
            "05E40, 13P10, 12H05 (primary), 52B20 (secondary)"
        ]
    },
    {
        "title": "Solving linear difference equations with coefficients in rings with   idempotent representations",
        "authors": [
            "Jakob Ablinger",
            "Carsten Schneider"
        ],
        "summary": "We introduce a general reduction strategy that enables one to search for solutions of parameterized linear difference equations in difference rings. Here we assume that the ring itself can be decomposed by a direct sum of integral domains (using idempotent elements) that enjoys certain technical features and that the coefficients of the difference equation are not degenerated. Using this mechanism we can reduce the problem to find solutions in a ring (with zero-divisors) to search solutions in several copies of integral domains. Utilizing existing solvers in this integral domain setting, we obtain a general solver where the components of the linear difference equations and the solutions can be taken from difference rings that are built e.g., by $R\\Pi\\Sigma$-extensions over $\\Pi\\Sigma$-fields. This class of difference rings contains, e.g., nested sums and products, products over roots of unity and nested sums defined over such objects.",
        "published": "2021-02-05T17:28:04Z",
        "link": "http://arxiv.org/abs/2102.03307v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "On Two Signature Variants Of Buchberger's Algorithm Over Principal Ideal   Domains",
        "authors": [
            "Maria Francis",
            "Thibaut Verron"
        ],
        "summary": "Signature-based algorithms have brought large improvements in the performances of Gr\\\"obner bases algorithms for polynomial systems over fields. Furthermore, they yield additional data which can be used, for example, to compute the module of syzygies of an ideal or to compute coefficients in terms of the input generators.   In this paper, we examine two variants of Buchberger's algorithm to compute Gr\\\"obner bases over principal ideal domains, with the addition of signatures. The first one is adapted from Kandri-Rody and Kapur's algorithm, whereas the second one uses the ideas developed in the algorithms by L. Pan (1989) and D. Lichtblau (2012). The differences in constructions between the algorithms entail differences in the operations which are compatible with the signatures, and in the criteria which can be used to discard elements.   We prove that both algorithms are correct and discuss their relative performances in a prototype implementation in Magma.",
        "published": "2021-02-05T18:40:51Z",
        "link": "http://arxiv.org/abs/2102.03339v2",
        "categories": [
            "cs.SC",
            "math.AC"
        ]
    },
    {
        "title": "Algorithms for Linearly Recurrent Sequences of Truncated Polynomials",
        "authors": [
            "Seung Gyu Hyun",
            "Vincent Neiger",
            "Éric Schost"
        ],
        "summary": "Linear recurrent sequences are those whose elements are defined as linear combinations of preceding elements, and finding recurrence relations is a fundamental problem in computer algebra. In this paper, we focus on sequences whose elements are vectors over the ring $\\mathbb{A} = \\mathbb{K}[x]/(x^d)$ of truncated polynomials. Finding the ideal of their recurrence relations has applications such as the computation of minimal polynomials and determinants of sparse matrices over $\\mathbb{A}$. We present three methods for finding this ideal: a Berlekamp-Massey-like approach due to Kurakin, one which computes the kernel of some block-Hankel matrix over $\\mathbb{A}$ via a minimal approximant basis, and one based on bivariate Pad\\'e approximation. We propose complexity improvements for the first two methods, respectively by avoiding the computation of redundant relations and by exploiting the Hankel structure to compress the approximation problem. Then we confirm these improvements empirically through a C++ implementation, and we discuss the above-mentioned applications.",
        "published": "2021-02-06T13:21:03Z",
        "link": "http://arxiv.org/abs/2102.03583v2",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Separability Problems in Creative Telescoping",
        "authors": [
            "Shaoshi Chen",
            "Ruyong Feng",
            "Pingchuan Ma",
            "Michael F. Singer"
        ],
        "summary": "For given multivariate functions specified by algebraic, differential or difference equations, the separability problem is to decide whether they satisfy linear differential or difference equations in one variable. In this paper, we will explain how separability problems arise naturally in creative telescoping and present some criteria for testing the separability for several classes of special functions, including rational functions, hyperexponential functions, hypergeometric terms, and algebraic functions.",
        "published": "2021-02-07T01:34:36Z",
        "link": "http://arxiv.org/abs/2102.03693v1",
        "categories": [
            "cs.SC",
            "math.CA",
            "68W30, 12H05, 12H10",
            "I.1.2"
        ]
    },
    {
        "title": "Symbolic computation of hypergeometric type and non-holonomic power   series",
        "authors": [
            "Bertrand Teguia Tabuguia",
            "Wolfram Koepf"
        ],
        "summary": "A term $a_n$ is $m$-fold hypergeometric, for a given positive integer $m$, if the ratio $a_{n+m}/a_n$ is a rational function over a field $K$ of characteristic zero. We establish the structure of holonomic recurrence equation, i.e. linear and homogeneous recurrence equations having polynomial coefficients, that have $m$-fold hypergeometric term solutions over $K$, for any positive integer $m$. Consequently, we describe an algorithm, say $mfoldHyper$, that extends van Hoeij's algorithm (1998) which computes a basis of the subspace of hypergeometric $(m=1)$ term solutions of holonomic recurrence equations to the more general case of $m$-fold hypergeometric terms.   We generalize the concept of hypergeometric type power series introduced by Koepf (1992), by considering linear combinations of Laurent-Puiseux series whose coefficients are $m$-fold hypergeometric terms. Thus thanks to $mfoldHyper$, we deduce a complete procedure to compute these power series; indeed, it turns out that every linear combination of power series with $m$-fold hypergeometric term coefficients, for finitely many values of $m$, is detected.   On the other hand, we investigate an algorithm to represent power series of non-holonomic functions. The algorithm follows the same steps of Koepf's algorithm, but instead of seeking holonomic differential equations, quadratic differential equations are computed and the Cauchy product rule is used to deduce recurrence equations for the power series coefficients. This algorithm defines a normal function that yields together with enough initial values normal forms for many power series of non-holonomic functions. Therefore, non-trivial identities are automatically proved using this approach.   This paper is accompanied by implementations in the Computer Algebra Systems (CAS) Maxima 5.44.0 and Maple 2019.",
        "published": "2021-02-08T12:19:39Z",
        "link": "http://arxiv.org/abs/2102.04157v1",
        "categories": [
            "cs.SC",
            "Primary: 33F10, 30B60, Secondary: 33C20, 39A99"
        ]
    },
    {
        "title": "Fast real and complex root-finding methods for well-conditioned   polynomials",
        "authors": [
            "Guillaume Moroz"
        ],
        "summary": "Given a polynomial $p$ of degree $d$ and a bound $\\kappa$ on a condition number of $p$, we present the first root-finding algorithms that return all its real and complex roots with a number of bit operations quasi-linear in $d \\log^2(\\kappa)$. More precisely, several condition numbers can be defined depending on the norm chosen on the coefficients of the polynomial. Let $p(x) = \\sum\\_{k=0}^d a\\_k x^k = \\sum\\_{k=0}^d \\sqrt{\\binom d k} b\\_k x^k$. We call the condition number associated with a perturbation of the $a\\_k$ the hyperbolic condition number $\\kappa\\_h$, and the one associated with a perturbation of the $b\\_k$ the elliptic condition number $\\kappa\\_e$. For each of these condition numbers, we present algorithms that find the real and the complex roots of $p$ in $O\\left(d\\log^2(d\\kappa)\\ \\text{polylog}(\\log(d\\kappa))\\right)$ bit operations.Our algorithms are well suited for random polynomials since $\\kappa\\_h$ (resp. $\\kappa\\_e$) is bounded by a polynomial in $d$ with high probability if the $a\\_k$ (resp. the $b\\_k$) are independent, centered Gaussian variables of variance $1$.",
        "published": "2021-02-08T13:24:08Z",
        "link": "http://arxiv.org/abs/2102.04180v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Polynomial Linear System Solving with Random Errors: new bounds and   early termination technique",
        "authors": [
            "Guerrini Eleonora",
            "Lebreton Romain",
            "Zappatore Ilaria"
        ],
        "summary": "This paper deals with the polynomial linear system solving with errors (PLSwE) problem. Specifically, we focus on the evaluation-interpolation technique for solving polynomial linear systems and we assume that errors can occur in the evaluation step. In this framework, the number of evaluations needed to recover the solution of the linear system is crucial since it affects the number of computations. It depends on the parameters of the linear system (degrees, size) and on a bound on the number of errors.   Our work is part of a series of papers about PLSwE aiming to reduce this number of evaluations. We proved in [Guerrini et al., Proc. ISIT'19] that if errors are randomly distributed, the bound of the number of evaluations can be lowered for large error rate.   In this paper, following the approach of [Kaltofen et al., Proc. ISSAC'17], we improve the results of [Guerrini et al., Proc. ISIT'19] in two directions. First, we propose a new bound of the number of evaluations, lowering the dependency on the parameters of the linear system, based on work of [Cabay, Proc. SYMSAC'71]. Second, we introduce an early termination strategy in order to handle the unnecessary increase of the number of evaluations due to overestimation of the parameters of the system and on the bound on the number of errors.",
        "published": "2021-02-08T13:27:46Z",
        "link": "http://arxiv.org/abs/2102.04182v1",
        "categories": [
            "cs.SC",
            "cs.IT",
            "math.IT"
        ]
    },
    {
        "title": "On exact division and divisibility testing for sparse polynomials",
        "authors": [
            "Pascal Giorgi",
            "Bruno Grenet",
            "Armelle Perret du Cray"
        ],
        "summary": "No polynomial-time algorithm is known to test whether a sparse polynomial G divides another sparse polynomial $F$. While computing the quotient Q=F quo G can be done in polynomial time with respect to the sparsities of F, G and Q, this is not yet sufficient to get a polynomial-time divisibility test in general. Indeed, the sparsity of the quotient Q can be exponentially larger than the ones of F and G. In the favorable case where the sparsity #Q of the quotient is polynomial, the best known algorithm to compute Q has a non-linear factor #G#Q in the complexity, which is not optimal.   In this work, we are interested in the two aspects of this problem. First, we propose a new randomized algorithm that computes the quotient of two sparse polynomials when the division is exact. Its complexity is quasi-linear in the sparsities of F, G and Q. Our approach relies on sparse interpolation and it works over any finite field or the ring of integers. Then, as a step toward faster divisibility testing, we provide a new polynomial-time algorithm when the divisor has a specific shape. More precisely, we reduce the problem to finding a polynomial S such that QS is sparse and testing divisibility by S can be done in polynomial time. We identify some structure patterns in the divisor G for which we can efficiently compute such a polynomial~S.",
        "published": "2021-02-09T13:54:38Z",
        "link": "http://arxiv.org/abs/2102.04826v2",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "On FGLM Algorithms with Tate Algebras",
        "authors": [
            "Xavier Caruso",
            "Tristan Vaccon",
            "Thibaut Verron"
        ],
        "summary": "Tate introduced in [Ta71] the notion of Tate algebras to serve, in the context of analytic geometry over the-adics, as a counterpart of polynomial algebras in classical algebraic geometry. In [CVV19, CVV20] the formalism of Gr{\\\"o}bner bases over Tate algebras has been introduced and advanced signature-based algorithms have been proposed. In the present article, we extend the FGLM algorithm of [FGLM93] to Tate algebras. Beyond allowing for fast change of ordering, this strategy has two other important benefits. First, it provides an efficient algorithm for changing the radii of convergence which, in particular, makes effective the bridge between the polynomial setting and the Tate setting and may help in speeding up the computation of Gr{\\\"o}bner basis over Tate algebras. Second, it gives the foundations for designing a fast algorithm for interreduction, which could serve as basic primitive in our previous algorithms and accelerate them significantly.",
        "published": "2021-02-10T08:53:55Z",
        "link": "http://arxiv.org/abs/2102.05324v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Lazy Hermite Reduction and Creative Telescoping for Algebraic Functions",
        "authors": [
            "Shaoshi Chen",
            "Lixin Du",
            "Manuel Kauers"
        ],
        "summary": "Bronstein's lazy Hermite reduction is a symbolic integration technique that reduces algebraic functions to integrands with only simple poles without the prior computation of an integral basis. We sharpen the lazy Hermite reduction by combining it with the polynomial reduction to solve the decomposition problem of algebraic functions. The sharpened reduction is then used to design a reduction-based telescoping algorithm for algebraic functions in two variables.",
        "published": "2021-02-12T14:04:15Z",
        "link": "http://arxiv.org/abs/2102.06538v2",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Metatheory.jl: Fast and Elegant Algebraic Computation in Julia with   Extensible Equality Saturation",
        "authors": [
            "Alessandro Cheli"
        ],
        "summary": "We introduce Metatheory.jl: a lightweight and performant general purpose symbolics and metaprogramming framework meant to simplify the act of writing complex Julia metaprograms and to significantly enhance Julia with a native term rewriting system, based on state-of-the-art equality saturation techniques, and a dynamic first class Abstract Syntax Tree (AST) pattern matching system that is dynamically composable in an algebraic fashion, taking full advantage of the language's powerful reflection capabilities. Our contribution allows to perform general purpose symbolic mathematics, manipulation, optimization, synthesis or analysis of syntactically valid Julia expressions with a clean and concise programming interface, both during compilation or execution of programs.",
        "published": "2021-02-15T22:58:18Z",
        "link": "http://arxiv.org/abs/2102.07888v1",
        "categories": [
            "cs.PL",
            "cs.SC",
            "I.1.0; I.1.2; I.1.3; D.3.2; D.3.3; D.3.4"
        ]
    },
    {
        "title": "Root Radii and Subdivision for Polynomial Root-Finding",
        "authors": [
            "Rémi Imbach",
            "Victor Y. Pan"
        ],
        "summary": "We depart from our approximation of 2000 of all root radii of a polynomial, which has readily extended Sch{\\\"o}nhage's efficient algorithm of 1982 for a single root radius. We revisit this extension, advance it, based on our simple but novel idea, and yield significant practical acceleration of the known near optimal subdivision algorithms for complex and real root-finding of user's choice. We achieve this by means of significant saving of exclusion tests and Taylor's shifts, which are the bottleneck of subdivision root-finders. This saving relies on our novel recipes for the initialization of root-finding iterations of independent interest. We demonstrate our practical progress with numerical tests, provide extensive analysis of the resulting algorithms, and show that, like the preceding subdivision root-finders, they support near optimal Boolean complexity bounds.",
        "published": "2021-02-22T08:17:13Z",
        "link": "http://arxiv.org/abs/2102.10821v2",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "An algorithm to recognize regular singular Mahler systems",
        "authors": [
            "Colin Faverjon",
            "Marina Poulet"
        ],
        "summary": "This paper is devoted to the study of the analytic properties of Mahler systems at 0. We give an effective characterisation of Mahler systems that are regular singular at 0, that is, systems which are equivalent to constant ones. Similar characterisations already exist for differential and (q-)difference systems but they do not apply in the Mahler case. This work fills in the gap by giving an algorithm which decides whether or not a Mahler system is regular singular at 0. In particular, it gives an effective characterisation of Mahler systems to which an analog of Schlesinger's density theorem applies.",
        "published": "2021-02-22T09:13:11Z",
        "link": "http://arxiv.org/abs/2102.10842v2",
        "categories": [
            "cs.SC",
            "math.NT"
        ]
    },
    {
        "title": "Affine equivalences of surfaces of translation and minimal surfaces, and   applications to symmetry detection and design",
        "authors": [
            "Juan Gerardo Alcázar",
            "Georg Muntingh"
        ],
        "summary": "We introduce a characterization for affine equivalence of two surfaces of translation defined by either rational or meromorphic generators. In turn, this induces a similar characterization for minimal surfaces. In the rational case, our results provide algorithms for detecting affine equivalence of these surfaces, and therefore, in particular, the symmetries of a surface of translation or a minimal surface of the considered types. Additionally, we apply our results to designing surfaces of translation and minimal surfaces with symmetries, and to computing the symmetries of the higher-order Enneper surfaces.",
        "published": "2021-02-27T07:36:21Z",
        "link": "http://arxiv.org/abs/2103.00151v3",
        "categories": [
            "math.AG",
            "cs.CG",
            "cs.SC",
            "14Q10, 68W30",
            "F.2.2; I.1.2"
        ]
    },
    {
        "title": "Frobenius Groups with Perfect Order Classes",
        "authors": [
            "James McCarron"
        ],
        "summary": "The purpose of this paper is to investigate the finite Frobenius groups with \"perfect order classes\"; that is, those for which the number of elements of each order is a divisor of the order of the group. If a finite Frobenius group has perfect order classes then so too does its Frobenius complement, the Frobenius kernel is a homocyclic group of odd prime power order, and the Frobenius complement acts regularly on the elements of prime order in the Frobenius kernel. The converse is also true.   Combined with elementary number-theoretic arguments, we use this to provide characterisations of several important classes of Frobenius groups. The insoluble Frobenius groups with perfect order classes are fully characterised. These turn out to be the perfect Frobenius groups whose Frobenius kernel is a homocyclic $11$-group of rank $2$.   We also determine precisely which nilpotent Frobenius complements have perfect order classes, from which it follows that a Frobenius group with nilpotent complement has perfect order classes only if the Frobenius complement is a cyclic $\\{2,3\\}$-group of even order.   Those Frobenius groups for which the Frobenius complement is a biprimary group are also described fully, and we show that no soluble Frobenius group whose Frobenius complement is a $\\{2,3,5\\}$-group with order divisible by $30$ has perfect order classes.",
        "published": "2021-02-28T08:28:14Z",
        "link": "http://arxiv.org/abs/2103.00425v2",
        "categories": [
            "math.GR",
            "cs.SC",
            "math.NT",
            "20D60 (Primary), 20D99, 20E45, 20E99, 11A05, 11A07, 11D99\n  (Secondary)"
        ]
    },
    {
        "title": "Bayesian filtering for nonlinear stochastic systems using holonomic   gradient method with integral transform",
        "authors": [
            "Tomoyuki Iori",
            "Toshiyuki Ohtsuka"
        ],
        "summary": "This paper proposes a symbolic-numeric Bayesian filtering method for a class of discrete-time nonlinear stochastic systems to achieve high accuracy with a relatively small online computational cost. The proposed method is based on the holonomic gradient method (HGM), which is a symbolic-numeric method to evaluate integrals efficiently depending on several parameters. By approximating the posterior probability density function (PDF) of the state as a Gaussian PDF, the update process of its mean and variance can be formulated as evaluations of several integrals that exactly take into account the nonlinearity of the system dynamics. An integral transform is used to evaluate these integrals more efficiently using the HGM than our previous method. Further, a numerical example is provided to demonstrate the efficiency of the proposed method compared to other existing methods.",
        "published": "2021-03-01T00:59:30Z",
        "link": "http://arxiv.org/abs/2103.00675v4",
        "categories": [
            "math.NA",
            "cs.NA",
            "cs.SC",
            "cs.SY",
            "eess.SP",
            "eess.SY"
        ]
    },
    {
        "title": "Provability in BI's Sequent Calculus is Decidable",
        "authors": [
            "Alexander Gheorghiu",
            "Simon Docherty",
            "David Pym"
        ],
        "summary": "Warning: This paper contains a mistake, rendering the proof of the main theorem invalid. The logic of Bunched Implications (BI) combines both additive and multiplicative connectives, which include two primitive intuitionistic implications. As a consequence, contexts in the sequent presentation are not lists, nor multisets, but rather tree-like structures called bunches. This additional complexity notwithstanding, the logic has a well-behaved metatheory admitting all the familiar forms of semantics and proof systems. However, the presentation of an effective proof-search procedure has been elusive since the logic's debut. We show that one can reduce the proof-search space for any given sequent to a primitive recursive set, the argument generalizing Gentzen's decidability argument for classical propositional logic and combining key features of Dyckhoff's contraction-elimination argument for intuitionistic logic. An effective proof-search procedure, and hence decidability of provability, follows as a corollary.",
        "published": "2021-03-03T11:48:10Z",
        "link": "http://arxiv.org/abs/2103.02343v7",
        "categories": [
            "cs.LO",
            "cs.SC",
            "math.LO",
            "03B25 (Primary) 03D99, 68W68, 68Q68 (Secondary)",
            "F.0; I.1; F.3"
        ]
    },
    {
        "title": "Puiseux Series and Algebraic Solutions of First Order Autonomous AODEs   -- A MAPLE Package",
        "authors": [
            "Francois Boulier",
            "Jose Cano",
            "Sebastian Falkensteiner",
            "Rafael Sendra"
        ],
        "summary": "There exist several methods for computing exact solutions of algebraic differential equations. Most of the methods, however, do not ensure existence and uniqueness of the solutions and might fail after several steps, or are restricted to linear equations. The authors have presented in previous works a method to overcome this problem for autonomous first order algebraic ordinary differential equations and formal Puiseux series solutions and algebraic solutions. In the first case, all solutions can uniquely be represented by a sufficiently large truncation and in the latter case by its minimal polynomial. The main contribution of this paper is the implementation, in a MAPLE-package named FirstOrderSolve, of the algorithmic ideas presented therein. More precisely, all formal Puiseux series and algebraic solutions, including the generic and singular solutions, are computed and described uniquely. The computation strategy is to reduce the given differential equation to a simpler one by using local parametrizations and the already known degree bounds.",
        "published": "2021-03-05T13:20:47Z",
        "link": "http://arxiv.org/abs/2103.03646v1",
        "categories": [
            "cs.MS",
            "cs.SC",
            "34-04"
        ]
    },
    {
        "title": "DI2: prior-free and multi-item discretization ofbiomedical data and its   applications",
        "authors": [
            "Leonardo Alexandre",
            "Rafael S. Costa",
            "Rui Henriques"
        ],
        "summary": "Motivation: A considerable number of data mining approaches for biomedical data analysis, including state-of-the-art associative models, require a form of data discretization. Although diverse discretization approaches have been proposed, they generally work under a strict set of statistical assumptions which are arguably insufficient to handle the diversity and heterogeneity of clinical and molecular variables within a given dataset. In addition, although an increasing number of symbolic approaches in bioinformatics are able to assign multiple items to values occurring near discretization boundaries for superior robustness, there are no reference principles on how to perform multi-item discretizations.   Results: In this study, an unsupervised discretization method, DI2, for variables with arbitrarily skewed distributions is proposed. DI2 provides robust guarantees of generalization by placing data corrections using the Kolmogorov-Smirnov test before statistically fitting distribution candidates. DI2 further supports multi-item assignments. Results gathered from biomedical data show its relevance to improve classic discretization choices.   Software: available at https://github.com/JupitersMight/DI2",
        "published": "2021-03-07T13:45:30Z",
        "link": "http://arxiv.org/abs/2103.04356v1",
        "categories": [
            "q-bio.QM",
            "cs.SC"
        ]
    },
    {
        "title": "Classification of higher Mobility closed-loop Linkages",
        "authors": [
            "Tiago Duarte Guerreiro",
            "Zijia Li",
            "Josef Schicho"
        ],
        "summary": "We provide a complete classification of paradoxical closed-loop $n$-linkages, where $n\\geq6$, of mobility $n-4$ or higher, containing revolute, prismatic or helical joints. We also explicitly write down strong necessary conditions for $nR$-linkages of mobility $n-5$. Our main new tool is a geometric relation between a linkage $L$ and another linkage $L'$ resulting from adding equations to the configuration space of $L$. We then lift known classification results for $L'$ to $L$ using this relation.",
        "published": "2021-03-08T14:49:03Z",
        "link": "http://arxiv.org/abs/2103.04799v2",
        "categories": [
            "cs.CG",
            "cs.RO",
            "cs.SC",
            "math.AG",
            "math.RA"
        ]
    },
    {
        "title": "ModelingToolkit: A Composable Graph Transformation System For   Equation-Based Modeling",
        "authors": [
            "Yingbo Ma",
            "Shashi Gowda",
            "Ranjan Anantharaman",
            "Chris Laughman",
            "Viral Shah",
            "Chris Rackauckas"
        ],
        "summary": "Getting good performance out of numerical equation solvers requires that the user has provided stable and efficient functions representing their model. However, users should not be trusted to write good code. In this manuscript we describe ModelingToolkit (MTK), a symbolic equation-based modeling system which allows for composable transformations to generate stable, efficient, and parallelized model implementations. MTK blurs the lines of traditional symbolic computing by acting directly on a user's numerical code. We show the ability to apply graph algorithms for automatically parallelizing and performing index reduction on code written for differential-algebraic equation (DAE) solvers, \"fixing\" the performance and stability of the model without requiring any changes to on the user's part. We demonstrate how composable model transformations can be combined with automated data-driven surrogate generation techniques, allowing machine learning methods to generate accelerated approximate models within an acausal modeling framework. These reduced models are shown to outperform the Dymola Modelica compiler on an HVAC model by 590x at 3\\% error. Together, this demonstrates MTK as a system for bringing the latest research in graph transformations directly to modeling applications.",
        "published": "2021-03-09T06:31:24Z",
        "link": "http://arxiv.org/abs/2103.05244v3",
        "categories": [
            "cs.MS",
            "cs.SC",
            "cs.SE"
        ]
    },
    {
        "title": "Symbolic integration by integrating learning models with different   strengths and weaknesses",
        "authors": [
            "Hazumi Kubota",
            "Yuta Tokuoka",
            "Takahiro G. Yamada",
            "Akira Funahashi"
        ],
        "summary": "Integration is indispensable, not only in mathematics, but also in a wide range of other fields. A deep learning method has recently been developed and shown to be capable of integrating mathematical functions that could not previously be integrated on a computer. However, that method treats integration as equivalent to natural language translation and does not reflect mathematical information. In this study, we adjusted the learning model to take mathematical information into account and developed a wide range of learning models that learn the order of numerical operations more robustly. In this way, we achieved a 98.80% correct answer rate with symbolic integration, a higher rate than that of any existing method. We judged the correctness of the integration based on whether the derivative of the primitive function was consistent with the integrand. By building an integrated model based on this strategy, we achieved a 99.79% rate of correct answers with symbolic integration.",
        "published": "2021-03-09T15:46:36Z",
        "link": "http://arxiv.org/abs/2103.05497v1",
        "categories": [
            "cs.LG",
            "cs.SC"
        ]
    },
    {
        "title": "Optimal monomial quadratization for ODE systems",
        "authors": [
            "Andrey Bychkov",
            "Gleb Pogudin"
        ],
        "summary": "Quadratization problem is, given a system of ODEs with polynomial right-hand side, transform the system to a system with quadratic right-hand side by introducing new variables. Such transformations have been used, for example, as a preprocessing step by model order reduction methods and for transforming chemical reaction networks.   We present an algorithm that, given a system of polynomial ODEs, finds a transformation into a quadratic ODE system by introducing new variables which are monomials in the original variables. The algorithm is guaranteed to produce an optimal transformation of this form (that is, the number of new variables is as small as possible), and it is the first algorithm with such a guarantee we are aware of. Its performance compares favorably with the existing software, and it is capable to tackle problems that were out of reach before.",
        "published": "2021-03-14T19:49:05Z",
        "link": "http://arxiv.org/abs/2103.08013v3",
        "categories": [
            "cs.SC",
            "cs.DM",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Iterated integrals over letters induced by quadratic forms",
        "authors": [
            "J. Ablinger",
            "J. Blümlein",
            "C. Schneider"
        ],
        "summary": "An automated treatment of iterated integrals based on letters induced by real-valued quadratic forms and Kummer--Poincar\\'e letters is presented. These quantities emerge in analytic single and multi--scale Feynman diagram calculations. To compactify representations, one wishes to apply general properties of these quantities in computer-algebraic implementations. We provide the reduction to basis representations, expansions, analytic continuation and numerical evaluation of these quantities.",
        "published": "2021-03-15T12:20:31Z",
        "link": "http://arxiv.org/abs/2103.08330v1",
        "categories": [
            "hep-th",
            "cs.SC",
            "hep-ph",
            "math-ph",
            "math.MP"
        ]
    },
    {
        "title": "ChronoR: Rotation Based Temporal Knowledge Graph Embedding",
        "authors": [
            "Ali Sadeghian",
            "Mohammadreza Armandpour",
            "Anthony Colas",
            "Daisy Zhe Wang"
        ],
        "summary": "Despite the importance and abundance of temporal knowledge graphs, most of the current research has been focused on reasoning on static graphs. In this paper, we study the challenging problem of inference over temporal knowledge graphs. In particular, the task of temporal link prediction. In general, this is a difficult task due to data non-stationarity, data heterogeneity, and its complex temporal dependencies. We propose Chronological Rotation embedding (ChronoR), a novel model for learning representations for entities, relations, and time. Learning dense representations is frequently used as an efficient and versatile method to perform reasoning on knowledge graphs. The proposed model learns a k-dimensional rotation transformation parametrized by relation and time, such that after each fact's head entity is transformed using the rotation, it falls near its corresponding tail entity. By using high dimensional rotation as its transformation operator, ChronoR captures rich interaction between the temporal and multi-relational characteristics of a Temporal Knowledge Graph. Experimentally, we show that ChronoR is able to outperform many of the state-of-the-art methods on the benchmark datasets for temporal knowledge graph link prediction.",
        "published": "2021-03-18T17:08:33Z",
        "link": "http://arxiv.org/abs/2103.10379v1",
        "categories": [
            "cs.LG",
            "cs.SC"
        ]
    },
    {
        "title": "A Succinct Multivariate Lazy Multivariate Tower AD for Weil Algebra   Computation",
        "authors": [
            "Hiromi Ishii"
        ],
        "summary": "We propose a functional implementation of \\emph{Multivariate Tower Automatic Differentiation}. Our implementation is intended to be used in implementing $C^\\infty$-structure computation of an arbitrary Weil algebra, which we discussed in the previous work.",
        "published": "2021-03-22T06:54:32Z",
        "link": "http://arxiv.org/abs/2103.11615v2",
        "categories": [
            "cs.SC",
            "cs.MS",
            "cs.NA",
            "math.DG",
            "math.NA"
        ]
    },
    {
        "title": "Faster One Block Quantifier Elimination for Regular Polynomial Systems   of Equations",
        "authors": [
            "Huu Phuoc Le",
            "Mohab Safey El Din"
        ],
        "summary": "Quantifier elimination over the reals is a central problem in computational real algebraic geometry, polynomial system solving and symbolic computation. Given a semi-algebraic formula (whose atoms are polynomial constraints) with quantifiers on some variables, it consists in computing a logically equivalent formula involving only unquantified variables. When there is no alternation of quantifiers, one has a one block quantifier elimination problem.   This paper studies a variant of the one block quantifier elimination in which we compute an almost equivalent formula of the input. We design a new probabilistic efficient algorithm for solving this variant when the input is a system of polynomial equations satisfying some regularity assumptions. When the input is generic, involves $s$ polynomials of degree bounded by $D$ with $n$ quantified variables and $t$ unquantified ones, we prove that this algorithm outputs semi-algebraic formulas of degree bounded by $\\mathcal{D}$ using $O\\ {\\widetilde{~}}\\left ((n-s+1)\\ 8^{t}\\ \\mathcal{D}^{3t+2} \\binom{t+\\mathcal{D}}{t} \\right )$ arithmetic operations in the ground field where $\\mathcal{D} = 2(n+s)\\ D^s(D-1)^{n-s+1}\\ \\binom{n}{s}$. In practice, it allows us to solve quantifier elimination problems which are out of reach of the state-of-the-art (up to $8$ variables).",
        "published": "2021-03-25T10:26:51Z",
        "link": "http://arxiv.org/abs/2103.13735v3",
        "categories": [
            "cs.SC",
            "cs.CG",
            "I.1.2"
        ]
    },
    {
        "title": "Interpolation by decomposable univariate polynomials",
        "authors": [
            "Joachim von zur Gathen",
            "Guillermo Matera"
        ],
        "summary": "The usual univariate interpolation problem of finding a monic polynomial f of degree n that interpolates n given values is well understood. This paper studies a variant where f is required to be composite, say, a composition of two polynomials of degrees d and e, respectively, with de=n, and therefore d+e-1 given values. Some special cases are easy to solve, and for the general case, we construct a homotopy between it and a special case. We compute a geometric solution of the algebraic curve presenting this homotopy, and this also provides an answer to the interpolation task. The computing time is polynomial in the geometric data, like the degree, of this curve. A consequence is that for almost all inputs, a decomposable interpolation polynomial exists.",
        "published": "2021-03-29T19:57:59Z",
        "link": "http://arxiv.org/abs/2103.15926v1",
        "categories": [
            "math.AG",
            "cs.SC",
            "12E05 (Primary) 68W30, 14Q05, 14Q20 (Secondary)"
        ]
    },
    {
        "title": "Grounding Physical Concepts of Objects and Events Through Dynamic Visual   Reasoning",
        "authors": [
            "Zhenfang Chen",
            "Jiayuan Mao",
            "Jiajun Wu",
            "Kwan-Yee Kenneth Wong",
            "Joshua B. Tenenbaum",
            "Chuang Gan"
        ],
        "summary": "We study the problem of dynamic visual reasoning on raw videos. This is a challenging problem; currently, state-of-the-art models often require dense supervision on physical object properties and events from simulation, which are impractical to obtain in real life. In this paper, we present the Dynamic Concept Learner (DCL), a unified framework that grounds physical objects and events from video and language. DCL first adopts a trajectory extractor to track each object over time and to represent it as a latent, object-centric feature vector. Building upon this object-centric representation, DCL learns to approximate the dynamic interaction among objects using graph networks. DCL further incorporates a semantic parser to parse questions into semantic programs and, finally, a program executor to run the program to answer the question, levering the learned dynamics model. After training, DCL can detect and associate objects across the frames, ground visual properties, and physical events, understand the causal relationship between events, make future and counterfactual predictions, and leverage these extracted presentations for answering queries. DCL achieves state-of-the-art performance on CLEVRER, a challenging causal video reasoning dataset, even without using ground-truth attributes and collision labels from simulations for training. We further test DCL on a newly proposed video-retrieval and event localization dataset derived from CLEVRER, showing its strong generalization capacity.",
        "published": "2021-03-30T17:59:48Z",
        "link": "http://arxiv.org/abs/2103.16564v1",
        "categories": [
            "cs.CV",
            "cs.AI",
            "cs.CL",
            "cs.LG",
            "cs.SC"
        ]
    },
    {
        "title": "How to hunt wild constants",
        "authors": [
            "David R. Stoutemyer"
        ],
        "summary": "There are now several comprehensive web applications, stand-alone computer programs and computer algebra functions that, given a floating point number such as 6.518670730718491, can return concise nonfloat constants such as 3 arctan 2 + ln 9 + 1, that closely approximate the float. Examples include AskConstants, Inverse Symbolic Calculator, the Maple identify function, MESearch, OEIS, RIES, and WolframAlpha. Usefully often such a result is the exact limit as the float is computed with increasing precision. Therefore these program results are candidates for proving an exact result that you could not otherwise compute or conjecture without the program. Moreover, candidates that are not the exact limit can be provable bounds, or convey qualitative insight, or suggest series that they truncate, or provide sufficiently close efficient approximations for subsequent computation. This article describes some of these programs, how they work, and how best to use each of them. Almost everyone who uses or should use mathematical software can benefit from acquaintance with several such programs, because these programs differ in the sets of constants that they can return.",
        "published": "2021-03-30T23:19:16Z",
        "link": "http://arxiv.org/abs/2103.16720v3",
        "categories": [
            "cs.SC",
            "cs.NA",
            "math.NA",
            "65-04",
            "G.4"
        ]
    },
    {
        "title": "On the computation of asymptotic critical values of polynomial maps and   applications",
        "authors": [
            "Jérémy Berthomieu",
            "Andrew Ferguson",
            "Mohab Safey El Din"
        ],
        "summary": "Let $\\mathbf{f} = \\left(f_1, \\dots, f_p\\right) $ be a polynomial tuple in $\\mathbb{Q}[z_1, \\dots, z_n]$ and let $d = \\max_{1 \\leq i \\leq p} \\deg f_i$. We consider the problem of computing the set of asymptotic critical values of the polynomial mapping, with the assumption that this mapping is dominant, $\\mathbf{f}: z \\in \\mathbb{K}^n \\to (f\\_1(z), \\dots, f\\_p(z)) \\in \\mathbb{K}^p$ where $\\mathbb{K}$ is either $\\mathbb{R}$ or $\\mathbb{C}$. This is the set of values $c$ in the target space of $\\mathbf{f}$ such that there exists a sequence of points $(\\mathbf{x}_i)_{i\\in \\mathbb{N}}$ for which $\\mathbf{f}(\\mathbf{x}_i)$ tends to $c$ and $\\|\\mathbf{x}_i\\| \\kappa {\\rm d} \\mathbf{f}(\\mathbf{x}_i))$ tends to $0$ when $i$ tends to infinity where ${\\rm d} \\mathbf{f}$ is the differential of $\\mathbf{f}$ and $\\kappa$ is a function measuring the distance of a linear operator to the set of singular linear operators from $\\mathbb{K}^n$ to $\\mathbb{K}^p$. Computing the union of the classical and asymptotic critical values allows one to put into practice generalisations of Ehresmann's fibration theorem. This leads to natural and efficient applications in polynomial optimisation and computational real algebraic geometry. Going back to previous works by Kurdyka, Orro and Simon, we design new algorithms to compute asymptotic critical values. Through randomisation, we introduce new geometric characterisations of asymptotic critical values. This allows us to dramatically reduce the complexity of computing such values to a cost that is essentially $O(d^{2n(p+1)})$ arithmetic operations in $\\mathbb{Q}$. We also obtain tighter degree bounds on a hypersurface containing the asymptotic critical values, showing that the degree is at most $p^{n-p+1}(d-1)^{n-p}(d+1)^{p}$. Next, we show how to apply these algorithms to unconstrained polynomial optimisation problems and the problem of computing sample points per connected component of a semi-algebraic set defined by a single inequality/inequation. We report on the practical capabilities of our implementation of this algorithm. It shows how the practical efficiency surpasses the current state-of-the-art algorithms for computing asymptotic critical values by tackling examples that were previously out of reach.",
        "published": "2021-04-02T07:05:35Z",
        "link": "http://arxiv.org/abs/2104.00913v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "A Logical Programming Language as an Instrument for Specifying and   Verifying Dynamic Memory",
        "authors": [
            "René Haberland"
        ],
        "summary": "This work proposes a Prolog-dialect for the found and prioritised problems on expressibility and automation. Given some given C-like program, if dynamic memory is allocated, altered and freed on runtime, then a description of desired dynamic memory is a heap specification. The check of calculated memory state against a given specification is dynamic memory verification. This contribution only considers formal specification and verification in a Hoare calculus. Issues found include: invalid assignment, (temporary) unavailable data in memory cells, excessive memory allocation, (accidental) heap alteration in unexpected regions and others. Excessive memory allocation is nowadays successfully resolved by memory analysers like Valgrind. Essentially, papers in those areas did not bring any big breakthrough. Possible reasons may also include the decrease of tension due to more available memory and parallel threads. However, starting with Apt, problems related to variable modes have not yet been resolved -- neither entirely nor in an acceptable way. Research contributions over the last decades show again and again that heap issues remain and remain complex and still important. A significant contribution was reached in 2016 by Peter O'Hearn, who accepted the G\\\"{o}del prize for his parallel approach on a spatial heap operation.",
        "published": "2021-04-04T19:18:07Z",
        "link": "http://arxiv.org/abs/2104.01667v1",
        "categories": [
            "cs.LO",
            "cs.FL",
            "cs.PL",
            "cs.SC",
            "cs.SE"
        ]
    },
    {
        "title": "Computing the Characteristic Polynomial of Generic Toeplitz-like and   Hankel-like Matrices",
        "authors": [
            "Clément Pernet",
            "Hippolyte Signargout",
            "Pierre Karpman",
            "Gilles Villard"
        ],
        "summary": "New algorithms are presented for computing annihilating polynomials of Toeplitz, Hankel, and more generally Toeplitz+ Hankel-like matrices over a field. Our approach follows works on Coppersmith's block Wiedemann method with structured projections, which have been recently successfully applied for computing the bivariate resultant. A first baby-step/giant step approach -- directly derived using known techniques on structured matrices -- gives a randomized Monte Carlo algorithm for the minimal polynomial of an $n\\times n$ Toeplitz or Hankel-like matrix of displacement rank $\\alpha$ using $\\tilde O(n^{\\omega - c(\\omega)} \\alpha^{c(\\omega)})$ arithmetic operations, where $\\omega$ is the exponent of matrix multiplication and $c(2.373)\\approx 0.523$ for the best known value of $\\omega$. For generic Toeplitz+Hankel-like matrices a second algorithm computes the characteristic polynomial in $\\tilde O(n^{2-1/\\omega})$ operations when the displacement rank is considered constant. Previous algorithms required $O(n^2)$ operations while the exponents presented here are respectively less than $1.86$ and $1.58$ with the best known estimate for $\\omega$.",
        "published": "2021-04-06T13:29:36Z",
        "link": "http://arxiv.org/abs/2104.02497v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Polynomial Circuit Verification using BDDs",
        "authors": [
            "Rolf Drechsler"
        ],
        "summary": "Verification is one of the central tasks during circuit design. While most of the approaches have exponential worst-case behaviour, in the following techniques are discussed for proving polynomial circuit verification based on Binary Decision Diagrams (BDDs). It is shown that for circuits with specific structural properties, like e.g. tree-like circuits, and circuits based on multiplexers derived from BDDs complete formal verification can be carried out in polynomial time and space.",
        "published": "2021-04-07T09:56:42Z",
        "link": "http://arxiv.org/abs/2104.03024v1",
        "categories": [
            "cs.AR",
            "cs.DS",
            "cs.SC",
            "68W30, 68M07, 68W35",
            "B.6.3; B.2.1; F.2.2"
        ]
    },
    {
        "title": "msolve: A Library for Solving Polynomial Systems",
        "authors": [
            "Jérémy Berthomieu",
            "Christian Eder",
            "Mohab Safey El Din"
        ],
        "summary": "We present a new open source C library \\texttt{msolve} dedicated to solving multivariate polynomial systems of dimension zero through computer algebra methods. The core algorithmic framework of \\texttt{msolve} relies on Gr\\''obner bases and linear algebra based algorithms for polynomial system solving. It relies on Gr\\''obner basis computation w.r.t.\\ the degree reverse lexicographical order, Gr\\''obner conversion to a lexicographical Gr\\''obner basis and real solving of univariate polynomials. We explain in detail how these three main steps of the solving process are implemented, how we exploit \\texttt{AVX2} instruction processors and the more general implementation ideas we put into practice to better exploit the computational capabilities of this algorithmic framework. We compare the practical performances of \\texttt{msolve} with leading computer algebra systems such as \\textsc{Magma}, \\textsc{Maple}, \\textsc{Singular} on a wide range of systems with finitely many complex solutions, showing that \\texttt{msolve} can tackle systems which were out of reach by the computer algebra software state-of-the-art.",
        "published": "2021-04-08T07:37:02Z",
        "link": "http://arxiv.org/abs/2104.03572v2",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Multigraded Sylvester forms, Duality and Elimination Matrices",
        "authors": [
            "Laurent Busé",
            "Marc Chardin",
            "Navid Nemati"
        ],
        "summary": "In this paper we study the equations of the elimination ideal associated with $n+1$ generic multihomogeneous polynomials defined over a product of projective spaces of dimension $n$. We first prove a duality property and then make this duality explicit by introducing multigraded Sylvester forms. These results provide a partial generalization of similar properties that are known in the setting of homogeneous polynomial systems defined over a single projective space. As an important consequence, we derive a new family of elimination matrices that can be used for solving zero-dimensional multiprojective polynomial systems by means of linear algebra methods.",
        "published": "2021-04-18T19:40:08Z",
        "link": "http://arxiv.org/abs/2104.08941v2",
        "categories": [
            "math.AC",
            "cs.SC",
            "math.AG"
        ]
    },
    {
        "title": "Linear PDE with Constant Coefficients",
        "authors": [
            "Rida Ait El Manssour",
            "Marc Härkönen",
            "Bernd Sturmfels"
        ],
        "summary": "We discuss practical methods for computing the space of solutions to an arbitrary homogeneous linear system of partial differential equations with constant coefficients. These rest on the Fundamental Principle of Ehrenpreis-Palamodov from the 1960s. We develop this further using recent advances in computational commutative algebra.",
        "published": "2021-04-20T17:38:56Z",
        "link": "http://arxiv.org/abs/2104.10146v3",
        "categories": [
            "math.AC",
            "cs.SC",
            "math.AP",
            "13N10, 14-04, 14Q15, 35G35, 35C15"
        ]
    },
    {
        "title": "Exceptional points and domains of unitarity for a class of strongly   non-Hermitian real-matrix Hamiltonians",
        "authors": [
            "Miloslav Znojil"
        ],
        "summary": "A phenomenological Hamiltonian of a closed (i.e., unitary) quantum system is assumed to have an $N$ by $N$ real-matrix form composed of a unperturbed diagonal-matrix part $H^{(N)}_0$ and of a tridiagonal-matrix perturbation $\\lambda\\,W^{(N)}(\\lambda)$. The requirement of the unitarity of the evolution of the system (i.e., of the diagonalizability and of the reality of the spectrum) restricts, naturally, the variability of the matrix elements to a \"physical\" domain ${\\cal D}^{[N]} \\subset \\mathbb{R}^d$. We fix the unperturbed matrix (simulating a non-equidistant, square-well-type unperturbed spectrum) and we only admit the maximally non-Hermitian antisymmetric-matrix perturbations. This yields the hiddenly Hermitian model with the measure of perturbation $\\lambda$ and with the $d=N$ matrix elements which are, inside ${\\cal D}^{[N]}$, freely variable. Our aim is to describe the quantum phase-transition boundary $\\partial {\\cal D}^{[N]}$ (alias exceptional-point boundary) at which the unitarity of the system is lost. Our main attention is paid to the strong-coupling extremes of stability, i.e., to the Kato's exceptional points of order $N$ (EPN) and to the (sharply spiked) shape of the boundary $\\partial {\\cal D}^{[N]}$ in their vicinity. The feasibility of our constructions is based on the use of the high-precision arithmetics in combination with the computer-assisted symbolic manipulations (including, in particular, the Gr\\\"{o}bner basis elimination technique).",
        "published": "2021-04-22T12:27:09Z",
        "link": "http://arxiv.org/abs/2104.11016v1",
        "categories": [
            "math-ph",
            "cs.NA",
            "cs.SC",
            "math.MP",
            "math.NA",
            "quant-ph"
        ]
    },
    {
        "title": "EXplainable Neural-Symbolic Learning (X-NeSyL) methodology to fuse deep   learning representations with expert knowledge graphs: the MonuMAI cultural   heritage use case",
        "authors": [
            "Natalia Díaz-Rodríguez",
            "Alberto Lamas",
            "Jules Sanchez",
            "Gianni Franchi",
            "Ivan Donadello",
            "Siham Tabik",
            "David Filliat",
            "Policarpo Cruz",
            "Rosana Montes",
            "Francisco Herrera"
        ],
        "summary": "The latest Deep Learning (DL) models for detection and classification have achieved an unprecedented performance over classical machine learning algorithms. However, DL models are black-box methods hard to debug, interpret, and certify. DL alone cannot provide explanations that can be validated by a non technical audience. In contrast, symbolic AI systems that convert concepts into rules or symbols -- such as knowledge graphs -- are easier to explain. However, they present lower generalisation and scaling capabilities. A very important challenge is to fuse DL representations with expert knowledge. One way to address this challenge, as well as the performance-explainability trade-off is by leveraging the best of both streams without obviating domain expert knowledge. We tackle such problem by considering the symbolic knowledge is expressed in form of a domain expert knowledge graph. We present the eXplainable Neural-symbolic learning (X-NeSyL) methodology, designed to learn both symbolic and deep representations, together with an explainability metric to assess the level of alignment of machine and human expert explanations. The ultimate objective is to fuse DL representations with expert domain knowledge during the learning process to serve as a sound basis for explainability. X-NeSyL methodology involves the concrete use of two notions of explanation at inference and training time respectively: 1) EXPLANet: Expert-aligned eXplainable Part-based cLAssifier NETwork Architecture, a compositional CNN that makes use of symbolic representations, and 2) SHAP-Backprop, an explainable AI-informed training procedure that guides the DL process to align with such symbolic representations in form of knowledge graphs. We showcase X-NeSyL methodology using MonuMAI dataset for monument facade image classification, and demonstrate that our approach improves explainability and performance.",
        "published": "2021-04-24T09:06:08Z",
        "link": "http://arxiv.org/abs/2104.11914v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.CV",
            "cs.SC"
        ]
    },
    {
        "title": "Decomposition of a Quantum System Into Subsystems in Finite Quantum   Mechanics",
        "authors": [
            "Vladimir V. Kornyak"
        ],
        "summary": "Any Hilbert space with composite dimension can be factorized into a tensor product of smaller Hilbert spaces. This allows to decompose a quantum system into subsystems. We propose a simple tractable model for a constructive study of decompositions of quantum systems.",
        "published": "2021-04-24T17:55:23Z",
        "link": "http://arxiv.org/abs/2104.11992v1",
        "categories": [
            "quant-ph",
            "cs.SC",
            "hep-th"
        ]
    },
    {
        "title": "CPS Engineering: Gap Analysis and Perspectives",
        "authors": [
            "Emmanuel Ledinot"
        ],
        "summary": "Virtualization of computing and networking, IT-OT convergence, cybersecurity and AI-based enhancement of autonomy are significantly increasing the complexity of CPS and CPSoS. New challenges have emerged to demonstrate that these systems are safe and secure. We emphasize the role of control and emerging fields therein, like symbolic control or set-based fault-tolerant and decentralized control, to address safety. We have chosen three open verification problems we deem central in cost-effective development and certification of safety critical CPSoS. We review some promising threads of research that could lead in the long term to a scalable and powerful verification strategy. Its main components are set-based and invariant-based design, contracts, adversarial testing, algorithmic geometry of dynamics, and probabilistic estimation derived from compositional massive testing. To explore these orientations in collaborative projects, and to promote them in certification arenas, we propose to continue and upgrade an open innovation drone-based use case that originated from a collaborative research project in aeronautic certification reformation",
        "published": "2021-04-26T13:45:26Z",
        "link": "http://arxiv.org/abs/2104.13210v1",
        "categories": [
            "eess.SY",
            "cs.SC",
            "cs.SY"
        ]
    },
    {
        "title": "Tuple Interpretations for Higher-Order Rewriting",
        "authors": [
            "Deivid Vale",
            "Cynthia Kop"
        ],
        "summary": "We develop a class of algebraic interpretations for many-sorted and higher-order term rewriting systems that takes type information into account. Specifically, base-type terms are mapped to \\emph{tuples} of natural numbers and higher-order terms to functions between those tuples. Tuples may carry information relevant to the type; for instance, a term of type $\\mathsf{nat}$ may be associated to a pair $(\\mathsf{cost}, \\mathsf{size})$ representing its evaluation cost and size. This class of interpretations results in a more fine-grained notion of complexity than runtime or derivational complexity, which makes it particularly useful to obtain complexity bounds for higher-order rewriting systems. We show that rewriting systems compatible with tuple interpretations admit finite bounds on derivation height. Furthermore, we demonstrate how to mechanically construct tuple interpretations and how to orient $\\beta$ and $\\eta$ reductions within our technique. Finally, we relate our method to runtime complexity and prove that specific interpretation shapes imply certain runtime complexity bounds.",
        "published": "2021-05-03T18:34:37Z",
        "link": "http://arxiv.org/abs/2105.01112v1",
        "categories": [
            "cs.SC",
            "cs.LO"
        ]
    },
    {
        "title": "The D-plus Discriminant and Complexity of Root Clustering",
        "authors": [
            "Jing Yang",
            "Chee K. Yap"
        ],
        "summary": "Let $p(x)$ be an integer polynomial with $m\\ge 2$ distinct roots $\\rho_1,\\ldots,\\rho_m$ whose multiplicities are $\\boldsymbol{\\mu}=(\\mu_1,\\ldots,\\mu_m)$. We define the D-plus discriminant of $p(x)$ to be $D^+(p):= \\prod_{1\\le i<j\\le m}(\\rho_i-\\rho_j)^{\\mu_i+\\mu_j}$. We first prove a conjecture that $D^+(p)$ is a $\\boldsymbol{\\mu}$-symmetric function of its roots $\\rho_1,\\ldots,\\rho_m$. Our main result gives an explicit formula for $D^+(p)$, as a rational function of its coefficients. Our proof is ideal-theoretic, based on re-casting the classic Poisson resultant as the \"symbolic Poisson formula\". The D-plus discriminant first arose in the complexity analysis of a root clustering algorithm from Becker et al. (ISSAC 2016). The bit-complexity of this algorithm is proportional to a quantity $\\log(|D^+(p)|^{-1})$. As an application of our main result, we give an explicit upper bound on this quantity in terms of the degree of $p$ and its leading coefficient.",
        "published": "2021-05-09T07:13:21Z",
        "link": "http://arxiv.org/abs/2105.03856v2",
        "categories": [
            "cs.SC",
            "68W30, 11R29, 68Q25"
        ]
    },
    {
        "title": "High-performance symbolic-numerics via multiple dispatch",
        "authors": [
            "Shashi Gowda",
            "Yingbo Ma",
            "Alessandro Cheli",
            "Maja Gwozdz",
            "Viral B. Shah",
            "Alan Edelman",
            "Christopher Rackauckas"
        ],
        "summary": "As mathematical computing becomes more democratized in high-level languages, high-performance symbolic-numeric systems are necessary for domain scientists and engineers to get the best performance out of their machine without deep knowledge of code optimization. Naturally, users need different term types either to have different algebraic properties for them, or to use efficient data structures. To this end, we developed Symbolics.jl, an extendable symbolic system which uses dynamic multiple dispatch to change behavior depending on the domain needs. In this work we detail an underlying abstract term interface which allows for speed without sacrificing generality. We show that by formalizing a generic API on actions independent of implementation, we can retroactively add optimized data structures to our system without changing the pre-existing term rewriters. We showcase how this can be used to optimize term construction and give a 113x acceleration on general symbolic transformations. Further, we show that such a generic API allows for complementary term-rewriting implementations. We demonstrate the ability to swap between classical term-rewriting simplifiers and e-graph-based term-rewriting simplifiers. We showcase an e-graph ruleset which minimizes the number of CPU cycles during expression evaluation, and demonstrate how it simplifies a real-world reaction-network simulation to halve the runtime. Additionally, we show a reaction-diffusion partial differential equation solver which is able to be automatically converted into symbolic expressions via multiple dispatch tracing, which is subsequently accelerated and parallelized to give a 157x simulation speedup. Together, this presents Symbolics.jl as a next-generation symbolic-numeric computing environment geared towards modeling and simulation.",
        "published": "2021-05-09T14:22:43Z",
        "link": "http://arxiv.org/abs/2105.03949v3",
        "categories": [
            "cs.CL",
            "cs.MS",
            "cs.PL",
            "cs.SC",
            "D.3.3; I.1.1; I.1.3"
        ]
    },
    {
        "title": "Complexity Analysis of Root Clustering for a Complex Polynomial",
        "authors": [
            "Ruben Becker",
            "Michael Sagraloff",
            "Vikram Sharma",
            "Juan Xu",
            "Chee Yap"
        ],
        "summary": "Let $F(z)$ be an arbitrary complex polynomial. We introduce the local root clustering problem, to compute a set of natural $\\varepsilon$-clusters of roots of $F(z)$ in some box region $B_0$ in the complex plane. This may be viewed as an extension of the classical root isolation problem. Our contribution is two-fold: we provide an efficient certified subdivision algorithm for this problem, and we provide a bit-complexity analysis based on the local geometry of the root clusters.   Our computational model assumes that arbitrarily good approximations of the coefficients of $F$ are provided by means of an oracle at the cost of reading the coefficients. Our algorithmic techniques come from a companion paper (Becker et al., 2018) and are based on the Pellet test, Graeffe and Newton iterations, and are independent of Sch\\\"onhage's splitting circle method. Our algorithm is relatively simple and promises to be efficient in practice.",
        "published": "2021-05-11T16:36:19Z",
        "link": "http://arxiv.org/abs/2105.05183v1",
        "categories": [
            "cs.SC",
            "cs.CG"
        ]
    },
    {
        "title": "On the probability of generating a primitive matrix",
        "authors": [
            "Jingwei Chen",
            "Yong Feng",
            "Yang Liu",
            "Wenyuan Wu"
        ],
        "summary": "Given a $k\\times n$ integer primitive matrix $\\bf{A}$ (i.e., a matrix can be extended to an $n\\times n$ unimodular matrix over the integers) with the maximal absolute value of entries $\\|\\bf{A}\\|$ bounded by {an integer} $\\lambda$ from above, we study the probability that the $m\\times n$ matrix extended from $\\bf{A}$ by appending other $m-k$ row vectors of dimension $n$ with entries chosen randomly and independently from the uniform distribution over $\\{0, 1,\\ldots, \\lambda-1\\}$ is still primitive. We present a complete and rigorous proof of a lower bound on the probability, which is at least a constant for fixed $m$ in the range $[k+1, n-4]$. As an application, we prove that there exists a fast Las Vegas algorithm that completes a $k\\times n$ primitive matrix $\\bf{A}$ to an $n\\times n$ unimodular matrix within expected $\\tilde{O}(n^{\\omega}\\log \\|\\bf{A}\\|)$ bit operations, where $\\tilde{O}$ is big-$O$ but without log factors, $\\omega$ is the exponent on the arithmetic operations of matrix multiplication.",
        "published": "2021-05-12T01:03:20Z",
        "link": "http://arxiv.org/abs/2105.05383v2",
        "categories": [
            "cs.SC",
            "cs.DS",
            "15B36, 15A83",
            "F.2.1; I.1.2"
        ]
    },
    {
        "title": "Implementation and Evaluation of a Multivariate Abstraction-Based,   Interval-Based Dynamic Time-Warping Method as a Similarity Measure for   Longitudinal Medical Records",
        "authors": [
            "Yuval Shahar",
            "Matan Lion"
        ],
        "summary": "We extended dynamic time warping (DTW) into interval-based dynamic time warping (iDTW), including (A) interval-based representation (iRep): [1] abstracting raw, time-stamped data into interval-based abstractions, [2] comparison-period scoping, [3] partitioning abstract intervals into a given temporal granularity; (B) interval-based matching (iMatch): matching partitioned, abstract-concepts records, using a modified DTW. Using domain knowledge, we abstracted the raw data of medical records, for up to three concepts out of four or five relevant concepts, into two interval types: State abstractions (e.g. LOW, HIGH) and Gradient abstractions (e.g. INCREASING, DECREASING). We created all uni-dimensional (State or Gradient) or multi-dimensional (State and Gradient) abstraction combinations. Tasks: Classifying 161 oncology patients records as autologous or allogenic bone-marrow transplantation; classifying 125 hepatitis patients records as B or C hepatitis; predicting micro- or macro-albuminuria in the next year for 151 Type 2 diabetes patients. We used a k-Nearest-Neighbors majority, k = an odd number from 1 to SQRT(N), N = set size. 75,936 10-fold cross-validation experiments were performed: 33,600 (Oncology), 28,800 (Hepatitis), 13,536 (Diabetes). Measures: Area Under the Curve (AUC), optimal Youden's Index. Paired t-tests compared result vectors for equivalent configurations other than a tested variable, to determine a significant mean accuracy difference (P<0.05). Mean classification and prediction using abstractions was significantly better than using only raw time-stamped data. In each domain, at least one abstraction combination led to a significantly better mean performance than raw data. Increasing feature number and using Multi-dimensional abstractions enhanced performance. Unlike when using raw data, optimal mean performance was often reached with k=5, using abstractions.",
        "published": "2021-05-18T11:41:42Z",
        "link": "http://arxiv.org/abs/2105.08450v2",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.SC",
            "I.2.6"
        ]
    },
    {
        "title": "Yet another eigenvalue algorithm for solving polynomial systems",
        "authors": [
            "Matías R. Bender",
            "Simon Telen"
        ],
        "summary": "In latest years, several advancements have been made in symbolic-numerical eigenvalue techniques for solving polynomial systems. In this article, we add to this list. We design an algorithm which solves systems with isolated solutions reliably and efficiently. In overdetermined cases, it reduces the task to an eigenvalue problem in a simpler and considerably faster way than in previous methods, and it can outperform the homotopy continuation approach. We provide many examples and an implementation in the proof-of-concept Julia package EigenvalueSolver.jl.",
        "published": "2021-05-18T12:29:11Z",
        "link": "http://arxiv.org/abs/2105.08472v2",
        "categories": [
            "math.NA",
            "cs.NA",
            "cs.SC",
            "math.AG",
            "65H04 (Primary), 65H10"
        ]
    },
    {
        "title": "SANM: A Symbolic Asymptotic Numerical Solver with Applications in Mesh   Deformation",
        "authors": [
            "Kai Jia"
        ],
        "summary": "Solving nonlinear systems is an important problem. Numerical continuation methods efficiently solve certain nonlinear systems. The Asymptotic Numerical Method (ANM) is a powerful continuation method that usually converges faster than Newtonian methods. ANM explores the landscape of the function by following a parameterized solution curve approximated with a high-order power series. Although ANM has successfully solved a few graphics and engineering problems, prior to our work, applying ANM to new problems required significant effort because the standard ANM assumes quadratic functions, while manually deriving the power series expansion for nonquadratic systems is a tedious and challenging task.   This paper presents a novel solver, SANM, that applies ANM to solve symbolically represented nonlinear systems. SANM solves such systems in a fully automated manner. SANM also extends ANM to support many nonquadratic operators, including intricate ones such as singular value decomposition. Furthermore, SANM generalizes ANM to support the implicit homotopy form. Moreover, SANM achieves high computing performance via optimized system design and implementation.   We deploy SANM to solve forward and inverse elastic force equilibrium problems and controlled mesh deformation problems with a few constitutive models. Our results show that SANM converges faster than Newtonian solvers, requires little programming effort for new problems, and delivers comparable or better performance than a hand-coded, specialized ANM solver. While we demonstrate on mesh deformation problems, SANM is generic and potentially applicable to many tasks.",
        "published": "2021-05-18T14:04:06Z",
        "link": "http://arxiv.org/abs/2105.08535v1",
        "categories": [
            "math.NA",
            "cs.GR",
            "cs.NA",
            "cs.SC"
        ]
    },
    {
        "title": "Binomial Determinants for Tiling Problems Yield to the Holonomic Ansatz",
        "authors": [
            "Hao Du",
            "Christoph Koutschan",
            "Thotsaporn Thanatipanonda",
            "Elaine Wong"
        ],
        "summary": "We present and prove closed form expressions for some families of binomial determinants with signed Kronecker deltas that are located along an arbitrary diagonal in the corresponding matrix. They count cyclically symmetric rhombus tilings of hexagonal regions with triangular holes. We extend a previous systematic study of these families, where the locations of the Kronecker deltas depended on an additional parameter, to families with negative Kronecker deltas. By adapting Zeilberger's holonomic ansatz to make it work for our problems, we can take full advantage of computer algebra tools for symbolic summation. This, together with the combinatorial interpretation, allows us to realize some new determinantal relationships. From there, we are able to resolve all remaining open conjectures related to these determinants, including one from 2005 due to Lascoux and Krattenthaler.",
        "published": "2021-05-18T14:14:56Z",
        "link": "http://arxiv.org/abs/2105.08539v2",
        "categories": [
            "math.CO",
            "cs.SC"
        ]
    },
    {
        "title": "Wilf classes of non-symmetric operads",
        "authors": [
            "Andrey T. Cherkasov",
            "Dmitri Piontkovski"
        ],
        "summary": "Two operads are said to belong to the same Wilf class if they have the same generating series. We discuss possible Wilf classifications of non-symmetric operads with monomial relations. As a corollary, this would give the same classification for the operads with a finite Groebner basis.   Generally, there is no algorithm to decide whether two finitely presented operads belong to the same Wilf class. Still, we show that if an operad has a finite Groebner basis, then the monomial basis of the operad forms an unambiguous context-free language. Moreover, we discuss the deterministic grammar which defines the language. The generating series of the operad can be obtained as a result of an algorithmic elimination of variables from the algebraic system of equations defined by the Chomsky--Schutzenberger enumeration theorem. We then focus on the case of binary operads with a single relation. The approach is based on the results by Rowland on pattern avoidance in binary trees. We improve and refine Rowland's calculations and empirically confirm his conjecture. Here we use both the algebraic elimination and the direct calculation of formal power series from algebraic systems of equations. Finally, we discuss the connection of Wilf classes with algorithms for the Quillen homology of operads calculation.",
        "published": "2021-05-19T01:57:12Z",
        "link": "http://arxiv.org/abs/2105.08880v1",
        "categories": [
            "math.CO",
            "cs.FL",
            "cs.SC",
            "math.AT",
            "math.RA",
            "18M65 (Primary) 68Q45, 05A15, 05C30 (Secondary)"
        ]
    },
    {
        "title": "Recursion formulas for integrated products of Jacobi polynomials",
        "authors": [
            "Sven Beuchler",
            "Tim Haubold",
            "Veronika Pillwein"
        ],
        "summary": "From the literature it is known that orthogonal polynomials as the Jacobi polynomials can be expressed by hypergeometric series. In this paper, the authors derive several contiguous relations for terminating multivariate hypergeometric series. With these contiguous relations one can prove several recursion formulas of those series. This theoretical result allows to compute integrals over products of Jacobi polynomials in a very efficient recursive way. Moreover, the authors present an application to numerical analysis where it can be used in algorithms which compute the approximate solution of boundary value problem of partial differential equations by means of the finite elements method (FEM). With the aid of the contiguous relations, the approximate solution can be computed much faster than using numerical integration. A numerical example illustrates this effect.",
        "published": "2021-05-19T08:34:57Z",
        "link": "http://arxiv.org/abs/2105.08989v1",
        "categories": [
            "math.NA",
            "cs.NA",
            "cs.SC",
            "33C45, 33C70, 65N30"
        ]
    },
    {
        "title": "Computing the dimension of real algebraic sets",
        "authors": [
            "Piere Lairez",
            "Mohab Safey El Din"
        ],
        "summary": "Let $V$ be the set of real common solutions to $F = (f_1, \\ldots, f_s)$ in $\\mathbb{R}[x_1, \\ldots, x_n]$ and $D$ be the maximum total degree of the $f_i$'s. We design an algorithm which on input $F$ computes the dimension of $V$. Letting $L$ be the evaluation complexity of $F$ and $s=1$, it runs using $O^\\sim \\big (L D^{n(d+3)+1}\\big )$ arithmetic operations in $\\mathbb{Q}$ and at most $D^{n(d+1)}$ isolations of real roots of polynomials of degree at most $D^n$. Our algorithm depends on the real geometry of $V$; its practical behavior is more governed by the number of topology changes in the fibers of some well-chosen maps. Hence, the above worst-case bounds are rarely reached in practice, the factor $D^{nd}$ being in general much lower on practical examples. We report on an implementation showing its ability to solve problems which were out of reach of the state-of-the-art implementations.",
        "published": "2021-05-21T10:12:39Z",
        "link": "http://arxiv.org/abs/2105.10255v2",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "On the Complexity and Parallel Implementation of Hensel's Lemma and   Weierstrass Preparation",
        "authors": [
            "Alexander Brandt",
            "Marc Moreno Maza"
        ],
        "summary": "Hensel's lemma, combined with repeated applications of Weierstrass preparation theorem, allows for the factorization of polynomials with multivariate power series coefficients. We present a complexity analysis for this method and leverage those results to guide the load-balancing of a parallel implementation to concurrently update all factors. In particular, the factorization creates a pipeline where the terms of degree k of the first factor are computed simultaneously with the terms of degree k-1 of the second factor, etc. An implementation challenge is the inherent irregularity of computational work between factors, as our complexity analysis reveals. Additional resource utilization and load-balancing is achieved through the parallelization of Weierstrass preparation. Experimental results show the efficacy of this mixed parallel scheme, achieving up to 9x parallel speedup on 12 cores.",
        "published": "2021-05-22T19:26:52Z",
        "link": "http://arxiv.org/abs/2105.10798v2",
        "categories": [
            "cs.SC",
            "cs.DC",
            "cs.MS"
        ]
    },
    {
        "title": "Parametric Toricity of Steady State Varieties of Reaction Networks",
        "authors": [
            "Hamid Rahkooy",
            "Thomas Sturm"
        ],
        "summary": "We study real steady state varieties of the dynamics of chemical reaction networks. The dynamics are derived using mass action kinetics with parametric reaction rates. The models studied are not inherently parametric in nature. Rather, our interest in parameters is motivated by parameter uncertainty, as reaction rates are typically either measured with limited precision or estimated. We aim at detecting toricity and shifted toricity, using a framework that has been recently introduced and studied for the non-parametric case over both the real and the complex numbers. While toricity requires that the variety specifies a subgroup of the direct power of the multiplicative group of the underlying field, shifted toricity requires only a coset. In the non-parametric case these requirements establish real decision problems. In the presence of parameters we must go further and derive necessary and sufficient conditions in the parameters for toricity or shifted toricity to hold. Technically, we use real quantifier elimination methods. Our computations on biological networks here once more confirm shifted toricity as a relevant concept, while toricity holds only for degenerate parameter choices.",
        "published": "2021-05-23T04:09:21Z",
        "link": "http://arxiv.org/abs/2105.10853v2",
        "categories": [
            "q-bio.MN",
            "cs.LO",
            "cs.SC",
            "92C42 (Primary), 68W30, 14P05 (Secondary)"
        ]
    },
    {
        "title": "A Flawed Dataset for Symbolic Equation Verification",
        "authors": [
            "Ernest Davis"
        ],
        "summary": "Arabshahi, Singh, and Anandkumar (2018) propose a method for creating a dataset of symbolic mathematical equations for the tasks of symbolic equation verification and equation completion. Unfortunately, a dataset constructed using the method they propose will suffer from two serious flaws. First, the class of true equations that the procedure can generate will be very limited. Second, because true and false equations are generated in completely different ways, there are likely to be artifactual features that allow easy discrimination.   Moreover, over the class of equations they consider, there is an extremely simple probabilistic procedure that solves the problem of equation verification with extremely high reliability. The usefulness of this problem in general as a testbed for AI systems is therefore doubtful.",
        "published": "2021-05-24T18:05:38Z",
        "link": "http://arxiv.org/abs/2105.11479v4",
        "categories": [
            "cs.AI",
            "cs.SC"
        ]
    },
    {
        "title": "Koszul-type determinantal formulas for families of mixed multilinear   systems",
        "authors": [
            "Matías R. Bender",
            "Jean-Charles Faugère",
            "Angelos Mantzaflaris",
            "Elias Tsigaridas"
        ],
        "summary": "Effective computation of resultants is a central problem in elimination theory and polynomial system solving. Commonly, we compute the resultant as a quotient of determinants of matrices and we say that there exists a determinantal formula when we can express it as a determinant of a matrix whose elements are the coefficients of the input polynomials. We study the resultant in the context of mixed multilinear polynomial systems, that is multilinear systems with polynomials having different supports, on which determinantal formulas were not known. We construct determinantal formulas for two kind of multilinear systems related to the Multiparameter Eigenvalue Problem (MEP): first, when the polynomials agree in all but one block of variables; second, when the polynomials are bilinear with different supports, related to a bipartite graph. We use the Weyman complex to construct Koszul-type determinantal formulas that generalize Sylvester-type formulas. We can use the matrices associated to these formulas to solve square systems without computing the resultant. The combination of the resultant matrices with the eigenvalue and eigenvector criterion for polynomial systems leads to a new approach for solving MEP.",
        "published": "2021-05-26T08:54:14Z",
        "link": "http://arxiv.org/abs/2105.13188v1",
        "categories": [
            "math.AC",
            "cs.NA",
            "cs.SC",
            "math.NA",
            "13P15 (Primary) 14Q20 15A18"
        ]
    },
    {
        "title": "Resultant-based Elimination in Ore Algebra",
        "authors": [
            "Raqeeb Rasheed"
        ],
        "summary": "We consider resultant-based methods for elimination of indeterminates of Ore polynomial systems in Ore algebra. We start with defining the concept of resultant for bivariate Ore polynomials then compute it by the Dieudonne determinant of the polynomial coefficients. Additionally, we apply noncommutative versions of evaluation and interpolation techniques to the computation process to improve the efficiency of the method. The implementation of the algorithms will be performed in Maple to evaluate the performance of the approaches.",
        "published": "2021-05-31T08:49:42Z",
        "link": "http://arxiv.org/abs/2105.14799v3",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "A Computer Program for the Numerical Analysis of Economic Cycles Within   the Framework of the Dubovsky Generalized Model",
        "authors": [
            "Danil Makarov",
            "Roman Parovik"
        ],
        "summary": "The article proposes a computer program for calculating economic crises according to the generalized mathematical model of S.V. Dubovsky. This model is represented by a system of ordinary nonlinear differential equations with fractional derivatives in the sense of Gerasimov-Caputo with initial conditions. Furthermore, according to a numerical algorithm based on an explicit nonlocal finite-difference scheme, oscillograms and phase trajectories were constructed. It is shown that changing the orders of fractional derivatives in the model can give rise to various modes, for example, damped modes with a steady-state amplitude. It is concluded that the orders of fractional derivatives are responsible for the intensity of the process.",
        "published": "2021-06-03T13:23:50Z",
        "link": "http://arxiv.org/abs/2106.01827v1",
        "categories": [
            "math.NA",
            "cs.NA",
            "cs.SC",
            "37N30",
            "G.1.7"
        ]
    },
    {
        "title": "New data structure for univariate polynomial approximation and   applications to root isolation, numerical multipoint evaluation, and other   problems",
        "authors": [
            "Guillaume Moroz"
        ],
        "summary": "We present a new data structure to approximate accurately and efficiently a polynomial $f$ of degree $d$ given as a list of coefficients. Its properties allow us to improve the state-of-the-art bounds on the bit complexity for the problems of root isolation and approximate multipoint evaluation. This data structure also leads to a new geometric criterion to detect ill-conditioned polynomials, implying notably that the standard condition number of the zeros of a polynomial is at least exponential in the number of roots of modulus less than $1/2$ or greater than $2$.Given a polynomial $f$ of degree $d$ with $\\|f\\|_1 \\leq 2^\\tau$ for $\\tau \\geq 1$, isolating all its complex roots or evaluating it at $d$ points can be done with a quasi-linear number of arithmetic operations. However, considering the bit complexity, the state-of-the-art algorithms require at least $d^{3/2}$ bit operations even for well-conditioned polynomials and when the accuracy required is low. Given a positive integer $m$, we can compute our new data structure and evaluate $f$ at $d$ points in the unit disk with an absolute error less than $2^{-m}$ in $\\widetilde O(d(\\tau+m))$ bit operations, where $\\widetilde O(\\cdot)$ means that we omit logarithmic factors. We also show that if $\\kappa$ is the absolute condition number of the zeros of $f$, then we can isolate all the roots of $f$ in $\\widetilde O(d(\\tau + \\log \\kappa))$ bit operations. Moreover, our algorithms are simple to implement. For approximating the complex roots of a polynomial, we implemented a small prototype in \\verb|Python/NumPy| that is an order of magnitude faster than the state-of-the-art solver \\verb/MPSolve/ for high degree polynomials with random coefficients.",
        "published": "2021-06-04T14:20:05Z",
        "link": "http://arxiv.org/abs/2106.02505v4",
        "categories": [
            "cs.SC",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Learning a performance metric of Buchberger's algorithm",
        "authors": [
            "Jelena Mojsilović",
            "Dylan Peifer",
            "Sonja Petrović"
        ],
        "summary": "What can be (machine) learned about the complexity of Buchberger's algorithm?   Given a system of polynomials, Buchberger's algorithm computes a Gr\\\"obner basis of the ideal these polynomials generate using an iterative procedure based on multivariate long division. The runtime of each step of the algorithm is typically dominated by a series of polynomial additions, and the total number of these additions is a hardware independent performance metric that is often used to evaluate and optimize various implementation choices. In this work we attempt to predict, using just the starting input, the number of polynomial additions that take place during one run of Buchberger's algorithm. Good predictions are useful for quickly estimating difficulty and understanding what features make Gr\\\"obner basis computation hard. Our features and methods could also be used for value models in the reinforcement learning approach to optimize Buchberger's algorithm introduced in [Peifer, Stillman, and Halpern-Leistner, 2020].   We show that a multiple linear regression model built from a set of easy-to-compute ideal generator statistics can predict the number of polynomial additions somewhat well, better than an uninformed model, and better than regression models built on some intuitive commutative algebra invariants that are more difficult to compute. We also train a simple recursive neural network that outperforms these linear models. Our work serves as a proof of concept, demonstrating that predicting the number of polynomial additions in Buchberger's algorithm is a feasible problem from the point of view of machine learning.",
        "published": "2021-06-07T14:57:57Z",
        "link": "http://arxiv.org/abs/2106.03676v2",
        "categories": [
            "math.AC",
            "cs.LG",
            "cs.SC",
            "math.AG",
            "stat.ML"
        ]
    },
    {
        "title": "Design of Low-Artifact Interpolation Kernels by Means of Computer   Algebra",
        "authors": [
            "Peter Karpov"
        ],
        "summary": "We present a number of new piecewise-polynomial kernels for image interpolation. The kernels are constructed by optimizing a measure of interpolation quality based on the magnitude of anisotropic artifacts. The kernel design process is performed symbolically using Mathematica computer algebra system. Experimental evaluation involving 14 image quality assessment methods demonstrates that our results compare favorably with the existing linear interpolators.",
        "published": "2021-06-08T05:06:51Z",
        "link": "http://arxiv.org/abs/2106.04104v1",
        "categories": [
            "cs.CV",
            "cs.SC",
            "eess.IV"
        ]
    },
    {
        "title": "Interpolation and Model Checking for Nonlinear Arithmetic",
        "authors": [
            "Dejan Jovanović",
            "Bruno Dutertre"
        ],
        "summary": "We present a new model-based interpolation procedure for satisfiability modulo theories (SMT). The procedure uses a new mode of interaction with the SMT solver that we call solving modulo a model. This either extends a given partial model into a full model for a set of assertions or returns an explanation (a model interpolant) when no solution exists. This mode of interaction fits well into the model-constructing satisfiability (MCSAT) framework of SMT. We use it to develop an interpolation procedure for any MCSAT-supported theory. In particular, this method leads to an effective interpolation procedure for nonlinear real arithmetic. We evaluate the new procedure by integrating it into a model checker and comparing it with state-of-art model-checking tools for nonlinear arithmetic.",
        "published": "2021-06-08T13:56:56Z",
        "link": "http://arxiv.org/abs/2106.04340v1",
        "categories": [
            "cs.LO",
            "cs.PL",
            "cs.SC"
        ]
    },
    {
        "title": "Verifying Quantized Neural Networks using SMT-Based Model Checking",
        "authors": [
            "Luiz Sena",
            "Xidan Song",
            "Erickson Alves",
            "Iury Bessa",
            "Edoardo Manino",
            "Lucas Cordeiro",
            "Eddie de Lima Filho"
        ],
        "summary": "Artificial Neural Networks (ANNs) are being deployed for an increasing number of safety-critical applications, including autonomous cars and medical diagnosis. However, concerns about their reliability have been raised due to their black-box nature and apparent fragility to adversarial attacks. These concerns are amplified when ANNs are deployed on restricted system, which limit the precision of mathematical operations and thus introduce additional quantization errors. Here, we develop and evaluate a novel symbolic verification framework using software model checking (SMC) and satisfiability modulo theories (SMT) to check for vulnerabilities in ANNs. More specifically, we propose several ANN-related optimizations for SMC, including invariant inference via interval analysis, slicing, expression simplifications, and discretization of non-linear activation functions. With this verification framework, we can provide formal guarantees on the safe behavior of ANNs implemented both in floating- and fixed-point arithmetic. In this regard, our verification approach was able to verify and produce adversarial examples for $52$ test cases spanning image classification and general machine learning applications. Furthermore, for small- to medium-sized ANN, our approach completes most of its verification runs in minutes. Moreover, in contrast to most state-of-the-art methods, our approach is not restricted to specific choices regarding activation functions and non-quantized representations. Our experiments show that our approach can analyze larger ANN implementations and substantially reduce the verification time compared to state-of-the-art techniques that use SMT solving.",
        "published": "2021-06-10T18:27:45Z",
        "link": "http://arxiv.org/abs/2106.05997v2",
        "categories": [
            "cs.LG",
            "cs.CR",
            "cs.LO",
            "cs.SC"
        ]
    },
    {
        "title": "The DEWCAD Project: Pushing Back the Doubly Exponential Wall of   Cylindrical Algebraic Decomposition",
        "authors": [
            "R. Bradford",
            "J. H. Davenport",
            "M. England",
            "A. Sadeghimanesh",
            "A. Uncu"
        ],
        "summary": "This abstract seeks to introduce the ISSAC community to the DEWCAD project, which is based at Coventry University and the University of Bath, in the United Kingdom. The project seeks to push back the Doubly Exponential Wall of Cylindrical Algebraic Decomposition, through the integration of SAT/SMT technology, the extension of Lazard projection theory, and the development of new algorithms based on CAD technology but without producing CADs themselves. The project also seeks to develop applications of CAD and will focus on applications in the domains of economics and bio-network analysis.",
        "published": "2021-06-16T12:33:09Z",
        "link": "http://arxiv.org/abs/2106.08740v1",
        "categories": [
            "cs.SC",
            "68W30, 03C10",
            "I.1.2; I.1.4; G.4; J.3; J.4"
        ]
    },
    {
        "title": "Fast evaluation of some p-adic transcendental functions",
        "authors": [
            "Xavier Caruso",
            "Marc Mezzarobba",
            "Nobuki Takayama",
            "Tristan Vaccon"
        ],
        "summary": "We design algorithms for computing values of many p-adic elementary and special functions, including logarithms, exponentials, polylogarithms, and hypergeometric functions. All our algorithms feature a quasi-linear complexity with respect to the target precision and most of them are based on an adaptation to the-adic setting of the binary splitting and bit-burst strategies.",
        "published": "2021-06-17T08:30:29Z",
        "link": "http://arxiv.org/abs/2106.09315v1",
        "categories": [
            "cs.SC",
            "math.NT"
        ]
    },
    {
        "title": "LNN-EL: A Neuro-Symbolic Approach to Short-text Entity Linking",
        "authors": [
            "Hang Jiang",
            "Sairam Gurajada",
            "Qiuhao Lu",
            "Sumit Neelam",
            "Lucian Popa",
            "Prithviraj Sen",
            "Yunyao Li",
            "Alexander Gray"
        ],
        "summary": "Entity linking (EL), the task of disambiguating mentions in text by linking them to entities in a knowledge graph, is crucial for text understanding, question answering or conversational systems. Entity linking on short text (e.g., single sentence or question) poses particular challenges due to limited context. While prior approaches use either heuristics or black-box neural methods, here we propose LNN-EL, a neuro-symbolic approach that combines the advantages of using interpretable rules based on first-order logic with the performance of neural learning. Even though constrained to using rules, LNN-EL performs competitively against SotA black-box neural approaches, with the added benefits of extensibility and transferability. In particular, we show that we can easily blend existing rule templates given by a human expert, with multiple types of features (priors, BERT encodings, box embeddings, etc), and even scores resulting from previous EL methods, thus improving on such methods. For instance, on the LC-QuAD-1.0 dataset, we show more than $4$\\% increase in F1 score over previous SotA. Finally, we show that the inductive bias offered by using logic results in learned rules that transfer well across datasets, even without fine tuning, while maintaining high accuracy.",
        "published": "2021-06-17T20:22:45Z",
        "link": "http://arxiv.org/abs/2106.09795v1",
        "categories": [
            "cs.CL",
            "cs.AI",
            "cs.SC"
        ]
    },
    {
        "title": "Faster Sparse Matrix Inversion and Rank Computation in Finite Fields",
        "authors": [
            "Sílvia Casacuberta",
            "Rasmus Kyng"
        ],
        "summary": "We improve the current best running time value to invert sparse matrices over finite fields, lowering it to an expected $O\\big(n^{2.2131}\\big)$ time for the current values of fast rectangular matrix multiplication. We achieve the same running time for the computation of the rank and nullspace of a sparse matrix over a finite field. This improvement relies on two key techniques. First, we adopt the decomposition of an arbitrary matrix into block Krylov and Hankel matrices from Eberly et al. (ISSAC 2007). Second, we show how to recover the explicit inverse of a block Hankel matrix using low displacement rank techniques for structured matrices and fast rectangular matrix multiplication algorithms. We generalize our inversion method to block structured matrices with other displacement operators and strengthen the best known upper bounds for explicit inversion of block Toeplitz-like and block Hankel-like matrices, as well as for explicit inversion of block Vandermonde-like matrices with structured blocks. As a further application, we improve the complexity of several algorithms in topological data analysis and in finite group theory.",
        "published": "2021-06-17T22:01:46Z",
        "link": "http://arxiv.org/abs/2106.09830v2",
        "categories": [
            "cs.DS",
            "cs.NA",
            "cs.SC",
            "math.NA"
        ]
    },
    {
        "title": "Certifying a probabilistic parallel modular algorithm for rational   univariate representation",
        "authors": [
            "Bernard Parisse"
        ],
        "summary": "This paper is about solving polynomial systems. It first recalls how to do that efficiently with a very high probability of correctness by reconstructing a rational univariate representation (rur) using Groebner revlex computation, Berlekamp-Massey algorithm and Hankel linear system solving modulo several primes in parallel. Then it introduces a new method (theorem \\ref{prop:check}) for rur certification that is effective for most polynomial systems.These algorithms are implemented in https://www-fourier.univ-grenoble-alpes.fr/~parisse/giac.html since version 1.7.0-13 or 1.7.0-17 for certification, it has (July 2021) leading performances on multiple CPU, at least for an open-source software.",
        "published": "2021-06-21T08:24:22Z",
        "link": "http://arxiv.org/abs/2106.10912v3",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Multivariate Power Series in Maple",
        "authors": [
            "Mohammadali Asadi",
            "Alexander Brandt",
            "Mahsa Kazemi",
            "Marc Moreno Maza",
            "Erik Postma"
        ],
        "summary": "We present MultivariatePowerSeries, a Maple library introduced in Maple 2021, providing a variety of methods to study formal multivariate power series and univariate polynomials over such series. This library offers a simple and easy-to-use user interface. Its implementation relies on lazy evaluation techniques and takes advantage of Maple's features for object-oriented programming. The exposed methods include Weierstrass Preparation Theorem and factorization via Hensel's lemma. The computational performance is demonstrated by means of an experimental comparison with software counterparts.",
        "published": "2021-06-21T16:54:04Z",
        "link": "http://arxiv.org/abs/2106.15519v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Recovery from Power Sums",
        "authors": [
            "Hana Melánová",
            "Bernd Sturmfels",
            "Rosa Winter"
        ],
        "summary": "We study the problem of recovering a collection of $n$ numbers from the evaluation of $m$ power sums. This yields a system of polynomial equations, which can be underconstrained ($m < n$), square ($m = n$), or overconstrained ($m > n$). Fibers and images of power sum maps are explored in all three regimes, and in settings that range from complex and projective to real and positive. This involves surprising deviations from the B\\'ezout bound, and the recovery of vectors from length measurements by $p$-norms.",
        "published": "2021-06-26T09:31:22Z",
        "link": "http://arxiv.org/abs/2106.13981v1",
        "categories": [
            "math.AG",
            "cs.SC",
            "math.CO"
        ]
    },
    {
        "title": "SymbolicGPT: A Generative Transformer Model for Symbolic Regression",
        "authors": [
            "Mojtaba Valipour",
            "Bowen You",
            "Maysum Panju",
            "Ali Ghodsi"
        ],
        "summary": "Symbolic regression is the task of identifying a mathematical expression that best fits a provided dataset of input and output values. Due to the richness of the space of mathematical expressions, symbolic regression is generally a challenging problem. While conventional approaches based on genetic evolution algorithms have been used for decades, deep learning-based methods are relatively new and an active research area. In this work, we present SymbolicGPT, a novel transformer-based language model for symbolic regression. This model exploits the advantages of probabilistic language models like GPT, including strength in performance and flexibility. Through comprehensive experiments, we show that our model performs strongly compared to competing models with respect to the accuracy, running time, and data efficiency.",
        "published": "2021-06-27T03:26:35Z",
        "link": "http://arxiv.org/abs/2106.14131v1",
        "categories": [
            "cs.LG",
            "cs.CL",
            "cs.SC"
        ]
    },
    {
        "title": "Automatic Differentiation With Higher Infinitesimals, or Computational   Smooth Infinitesimal Analysis in Weil Algebra",
        "authors": [
            "Hiromi Ishii"
        ],
        "summary": "We propose an algorithm to compute the $C^\\infty$-ring structure of arbitrary Weil algebra. It allows us to do some analysis with higher infinitesimals numerically and symbolically. To that end, we first give a brief description of the (Forward-mode) automatic differentiation (AD) in terms of $C^\\infty$-rings. The notion of a $C^\\infty$-ring was introduced by Lawvere and used as the fundamental building block of smooth infinitesimal analysis and synthetic differential geometry. We argue that interpreting AD in terms of $C^\\infty$-rings gives us a unifying theoretical framework and modular ways to express multivariate partial derivatives. In particular, we can \"package\" higher-order Forward-mode AD as a Weil algebra, and take tensor products to compose them to achieve multivariate higher-order AD. The algorithms in the present paper can also be used for a pedagogical purpose in learning and studying smooth infinitesimal analysis as well.",
        "published": "2021-06-27T06:17:26Z",
        "link": "http://arxiv.org/abs/2106.14153v2",
        "categories": [
            "cs.SC",
            "cs.MS",
            "cs.NA",
            "math.CT",
            "math.DG",
            "math.NA"
        ]
    },
    {
        "title": "Conormal Spaces and Whitney Stratifications",
        "authors": [
            "Martin Helmer",
            "Vidit Nanda"
        ],
        "summary": "We describe a new algorithm for computing Whitney stratifications of complex projective varieties. The main ingredients are (a) an algebraic criterion, due to L\\^e and Teissier, which reformulates Whitney regularity in terms of conormal spaces and maps, and (b) a new interpretation of this conormal criterion via primary decomposition, which can be practically implemented on a computer. We show that this algorithm improves upon the existing state of the art by several orders of magnitude, even for relatively small input varieties. En route, we introduce related algorithms for efficiently stratifying affine varieties, flags on a given variety, and algebraic maps.",
        "published": "2021-06-28T10:23:15Z",
        "link": "http://arxiv.org/abs/2106.14555v4",
        "categories": [
            "math.AG",
            "cs.SC",
            "math.AC",
            "math.AT",
            "14B05, 14Q20, 32S60, 32S15"
        ]
    },
    {
        "title": "Computing Characteristic Polynomials of p-Curvatures in Average   Polynomial Time",
        "authors": [
            "Raphaël Pagès"
        ],
        "summary": "We design a fast algorithm that computes, for a given linear differential operator with coefficients in $Z[x ]$, all the characteristic polynomials of its p-curvatures, for all primes $p < N$ , in asymptotically quasi-linear bit complexity in N. We discuss implementations and applications of our algorithm. We shall see in particular that the good performances of our algorithm are quickly visible.",
        "published": "2021-06-28T12:40:27Z",
        "link": "http://arxiv.org/abs/2106.14637v2",
        "categories": [
            "cs.SC",
            "math.FA"
        ]
    },
    {
        "title": "Web-based Structural Identifiability Analyzer",
        "authors": [
            "Ilia Ilmer",
            "Alexey Ovchinnikov",
            "Gleb Pogudin"
        ],
        "summary": "Parameter identifiability describes whether, for a given differential model, one can determine parameter values from model equations. Knowing global or local identifiability properties allows construction of better practical experiments to identify parameters from experimental data. In this work, we present a web-based software tool that allows to answer specific identifiability queries. Concretely, our toolbox can determine identifiability of individual parameters of the model and also provide all functions of parameters that are identifiable (also called identifiable combinations) from single or multiple experiments. The program is freely available at https://maple.cloud/app/6509768948056064.",
        "published": "2021-06-29T02:57:34Z",
        "link": "http://arxiv.org/abs/2106.15066v1",
        "categories": [
            "cs.MS",
            "cs.SC",
            "cs.SY",
            "eess.SY",
            "q-bio.QM"
        ]
    },
    {
        "title": "Testing Binomiality of Chemical Reaction Networks Using Comprehensive   Gröbner Systems",
        "authors": [
            "Hamid Rahkooy",
            "Thomas Sturm"
        ],
        "summary": "We consider the problem of binomiality of the steady state ideals of biochemical reaction networks. We are interested in finding polynomial conditions on the parameters such that the steady state ideal of a chemical reaction network is binomial under every specialisation of the parameters if the conditions on the parameters hold. We approach the binomiality problem using Comprehensive Gr\\\"obner systems. Considering rate constants as parameters, we compute comprehensive Gr\\\"obner systems for various reactions. In particular, we make automatic computations on n-site phosphorylations and biomodels from the Biomodels repository using the grobcov library of the computer algebra system Singular.",
        "published": "2021-07-04T18:44:07Z",
        "link": "http://arxiv.org/abs/2107.01706v2",
        "categories": [
            "q-bio.MN",
            "cs.SC"
        ]
    },
    {
        "title": "Polynomial-Division-Based Algorithms for Computing Linear Recurrence   Relations",
        "authors": [
            "Jérémy Berthomieu",
            "Jean-Charles Faugère"
        ],
        "summary": "Sparse polynomial interpolation, sparse linear system solving or modular rational reconstruction are fundamental problems in Computer Algebra. They come down to computing linear recurrence relations of a sequence with the Berlekamp-Massey algorithm. Likewise, sparse multivariate polynomial interpolation and multidimensional cyclic code decoding require guessing linear recurrence relations of a multivariate sequence.Several algorithms solve this problem. The so-called Berlekamp-Massey-Sakata algorithm (1988) uses polynomial additions and shifts by a monomial. The Scalar-FGLM algorithm (2015) relies on linear algebra operations on a multi-Hankel matrix, a multivariate generalization of a Hankel matrix. The Artinian Gorenstein border basis algorithm (2017) uses a Gram-Schmidt process.We propose a new algorithm for computing the Gr{\\\"o}bner basis of the ideal of relations of a sequence based solely on multivariate polynomial arithmetic. This algorithm allows us to both revisit the Berlekamp-Massey-Sakata algorithm through the use of polynomial divisions and to completely revise the Scalar-FGLM algorithm without linear algebra operations.A key observation in the design of this algorithm is to work on the mirror of the truncated generating series allowing us to use polynomial arithmetic modulo a monomial ideal. It appears to have some similarities with Pad{\\'e} approximants of this mirror polynomial.As an addition from the paper published at the ISSAC conferance, we give an adaptive variant of this algorithm taking into account the shape of the final Gr{\\\"o}bner basis gradually as it is discovered. The main advantage of this algorithm is that its complexity in terms of operations and sequence queries only depends on the output Gr{\\\"o}bner basis.All these algorithms have been implemented in Maple and we report on our comparisons.",
        "published": "2021-07-06T12:50:57Z",
        "link": "http://arxiv.org/abs/2107.02582v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Decomposition algorithms for tensors and polynomials",
        "authors": [
            "Antonio Laface",
            "Alex Massarenti",
            "Rick Rischter"
        ],
        "summary": "We give algorithms to compute decompositions of a given polynomial, or more generally mixed tensor, as sum of rank one tensors, and to establish whether such a decomposition is unique. In particular, we present methods to compute the decomposition of a general plane quintic in seven powers, and of a general space cubic in five powers; the two decompositions of a general plane sextic of rank nine, and the five decompositions of a general plane septic. Furthermore, we give Magma implementations of all our algorithms.",
        "published": "2021-07-08T20:31:05Z",
        "link": "http://arxiv.org/abs/2107.04097v1",
        "categories": [
            "math.AG",
            "cs.MS",
            "cs.SC",
            "Primary 14N07, Secondary 14N05, 51N35, 14Q15, 14N15"
        ]
    },
    {
        "title": "Sensitivity analysis in differentially private machine learning using   hybrid automatic differentiation",
        "authors": [
            "Alexander Ziller",
            "Dmitrii Usynin",
            "Moritz Knolle",
            "Kritika Prakash",
            "Andrew Trask",
            "Rickmer Braren",
            "Marcus Makowski",
            "Daniel Rueckert",
            "Georgios Kaissis"
        ],
        "summary": "In recent years, formal methods of privacy protection such as differential privacy (DP), capable of deployment to data-driven tasks such as machine learning (ML), have emerged. Reconciling large-scale ML with the closed-form reasoning required for the principled analysis of individual privacy loss requires the introduction of new tools for automatic sensitivity analysis and for tracking an individual's data and their features through the flow of computation. For this purpose, we introduce a novel \\textit{hybrid} automatic differentiation (AD) system which combines the efficiency of reverse-mode AD with an ability to obtain a closed-form expression for any given quantity in the computational graph. This enables modelling the sensitivity of arbitrary differentiable function compositions, such as the training of neural networks on private data. We demonstrate our approach by analysing the individual DP guarantees of statistical database queries. Moreover, we investigate the application of our technique to the training of DP neural networks. Our approach can enable the principled reasoning about privacy loss in the setting of data processing, and further the development of automatic sensitivity analysis and privacy budgeting systems.",
        "published": "2021-07-09T07:19:23Z",
        "link": "http://arxiv.org/abs/2107.04265v2",
        "categories": [
            "cs.LG",
            "cs.CR",
            "cs.SC"
        ]
    },
    {
        "title": "Systematic human learning and generalization from a brief tutorial with   explanatory feedback",
        "authors": [
            "Andrew J. Nam",
            "James L. McClelland"
        ],
        "summary": "Neural networks have long been used to model human intelligence, capturing elements of behavior and cognition, and their neural basis. Recent advancements in deep learning have enabled neural network models to reach and even surpass human levels of intelligence in many respects, yet unlike humans, their ability to learn new tasks quickly remains a challenge. People can reason not only in familiar domains, but can also rapidly learn to reason through novel problems and situations, raising the question of how well modern neural network models capture human intelligence and in which ways they diverge. In this work, we explore this gap by investigating human adults' ability to learn an abstract reasoning task based on Sudoku from a brief instructional tutorial with explanatory feedback for incorrect responses using a narrow range of training examples. We find that participants who master the task do so within a small number of trials and generalize well to puzzles outside of the training range. We also find that most of those who master the task can describe a valid solution strategy, and such participants perform better on transfer puzzles than those whose strategy descriptions are vague or incomplete. Interestingly, fewer than half of our human participants were successful in acquiring a valid solution strategy, and this ability is associated with high school mathematics education. We consider the challenges these findings pose for building computational models that capture all aspects of our findings and point toward a possible role for learning to engage in explanation-based reasoning to support rapid learning and generalization.",
        "published": "2021-07-10T00:14:41Z",
        "link": "http://arxiv.org/abs/2107.06994v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.SC"
        ]
    },
    {
        "title": "Using a template engine as a computer algebra tool",
        "authors": [
            "Migran N. Gevorkyan",
            "Anna V. Korolkova",
            "Dmitry S. Kulyabov"
        ],
        "summary": "In research problems that involve the use of numerical methods for solving systems of ordinary differential equations (ODEs), it is often required to select the most efficient method for a particular problem. To solve a Cauchy problem for a system of ODEs, Runge-Kutta methods (explicit or implicit ones, with or without step-size control, etc.) are employed. In that case, it is required to search through many implementations of the numerical method and select coefficients or other parameters of its numerical scheme. This paper proposes a library and scripts for automated generation of routine functions in the Julia programming language for a set of numerical schemes of Runge-Kutta methods. For symbolic manipulations, we use a template substitution tool. The proposed approach to automated generation of program code allows us to use a single template for editing, instead of modifying each individual function to be compared. On the one hand, this provides universality in the implementation of a numerical scheme and, on the other hand, makes it possible to minimize the number of errors in the process of modifying the compared implementations of the numerical method. We consider Runge-Kutta methods without step-size control, embedded methods with step-size control, and Rosenbrock methods with step-size control. The program codes for the numerical schemes, which are generated automatically using the proposed library, are tested by numerical solution of several well-known problems.",
        "published": "2021-07-15T17:04:02Z",
        "link": "http://arxiv.org/abs/2107.07461v1",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "cs.SC"
        ]
    },
    {
        "title": "NeuralPDE: Automating Physics-Informed Neural Networks (PINNs) with   Error Approximations",
        "authors": [
            "Kirill Zubov",
            "Zoe McCarthy",
            "Yingbo Ma",
            "Francesco Calisto",
            "Valerio Pagliarino",
            "Simone Azeglio",
            "Luca Bottero",
            "Emmanuel Luján",
            "Valentin Sulzer",
            "Ashutosh Bharambe",
            "Nand Vinchhi",
            "Kaushik Balakrishnan",
            "Devesh Upadhyay",
            "Chris Rackauckas"
        ],
        "summary": "Physics-informed neural networks (PINNs) are an increasingly powerful way to solve partial differential equations, generate digital twins, and create neural surrogates of physical models. In this manuscript we detail the inner workings of NeuralPDE.jl and show how a formulation structured around numerical quadrature gives rise to new loss functions which allow for adaptivity towards bounded error tolerances. We describe the various ways one can use the tool, detailing mathematical techniques like using extended loss functions for parameter estimation and operator discovery, to help potential users adopt these PINN-based techniques into their workflow. We showcase how NeuralPDE uses a purely symbolic formulation so that all of the underlying training code is generated from an abstract formulation, and show how to make use of GPUs and solve systems of PDEs. Afterwards we give a detailed performance analysis which showcases the trade-off between training techniques on a large set of PDEs. We end by focusing on a complex multiphysics example, the Doyle-Fuller-Newman (DFN) Model, and showcase how this PDE can be formulated and solved with NeuralPDE. Together this manuscript is meant to be a detailed and approachable technical report to help potential users of the technique quickly get a sense of the real-world performance trade-offs and use cases of the PINN techniques.",
        "published": "2021-07-19T12:38:31Z",
        "link": "http://arxiv.org/abs/2107.09443v1",
        "categories": [
            "cs.MS",
            "cs.SC"
        ]
    },
    {
        "title": "Semantic Reasoning with Differentiable Graph Transformations",
        "authors": [
            "Alberto Cetoli"
        ],
        "summary": "This paper introduces a differentiable semantic reasoner, where rules are presented as a relevant set of graph transformations. These rules can be written manually or inferred by a set of facts and goals presented as a training set. While the internal representation uses embeddings in a latent space, each rule can be expressed as a set of predicates conforming to a subset of Description Logic.",
        "published": "2021-07-20T15:48:54Z",
        "link": "http://arxiv.org/abs/2107.09579v1",
        "categories": [
            "cs.AI",
            "cs.SC"
        ]
    },
    {
        "title": "On generalizing Descartes' rule of signs to hypersurfaces",
        "authors": [
            "Elisenda Feliu",
            "Máté L. Telek"
        ],
        "summary": "We give partial generalizations of the classical Descartes' rule of signs to multivariate polynomials (with real exponents), in the sense that we provide upper bounds on the number of connected components of the complement of a hypersurface in the positive orthant. In particular, we give conditions based on the geometrical configuration of the exponents and the sign of the coefficients that guarantee that the number of connected components where the polynomial attains a negative value is at most one or two. Our results fully cover the cases where such an upper bound provided by the univariate Descartes' rule of signs is one. This approach opens a new route to generalize Descartes' rule of signs to the multivariate case, differing from previous works that aim at counting the number of positive solutions of a system of multivariate polynomial equations.",
        "published": "2021-07-21T10:46:42Z",
        "link": "http://arxiv.org/abs/2107.10002v2",
        "categories": [
            "math.AG",
            "cs.SC"
        ]
    },
    {
        "title": "Learning Theorem Proving Components",
        "authors": [
            "Karel Chvalovský",
            "Jan Jakubův",
            "Miroslav Olšák",
            "Josef Urban"
        ],
        "summary": "Saturation-style automated theorem provers (ATPs) based on the given clause procedure are today the strongest general reasoners for classical first-order logic. The clause selection heuristics in such systems are, however, often evaluating clauses in isolation, ignoring other clauses. This has changed recently by equipping the E/ENIGMA system with a graph neural network (GNN) that chooses the next given clause based on its evaluation in the context of previously selected clauses. In this work, we describe several algorithms and experiments with ENIGMA, advancing the idea of contextual evaluation based on learning important components of the graph of clauses.",
        "published": "2021-07-21T12:00:05Z",
        "link": "http://arxiv.org/abs/2107.10034v1",
        "categories": [
            "cs.LO",
            "cs.AI",
            "cs.LG",
            "cs.NE",
            "cs.SC"
        ]
    },
    {
        "title": "Compression for 2-Parameter Persistent Homology",
        "authors": [
            "Ulderico Fugacci",
            "Michael Kerber",
            "Alexander Rolle"
        ],
        "summary": "Compression aims to reduce the size of an input, while maintaining its relevant properties. For multi-parameter persistent homology, compression is a necessary step in any computational pipeline, since standard constructions lead to large inputs, and computational tasks in this area tend to be expensive. We propose two compression methods for chain complexes of free 2-parameter persistence modules. The first method extends the multi-chunk algorithm for one-parameter persistent homology, returning the smallest chain complex among all the ones quasi-isomorphic to the input. The second method produces minimal presentations of the homology of the input; it is based on an algorithm of Lesnick and Wright, but incorporates several improvements that lead to substantial performance gains. The two methods are complementary, and can be combined to compute minimal presentations for complexes with millions of generators in a few seconds. The methods have been implemented, and the software is publicly available. We report on experimental evaluations, which demonstrate substantial improvements in performance compared to previously available compression strategies.",
        "published": "2021-07-22T20:58:08Z",
        "link": "http://arxiv.org/abs/2107.10924v2",
        "categories": [
            "math.AT",
            "cs.SC",
            "math.AC",
            "55N99, 13D02"
        ]
    },
    {
        "title": "Sum of Squares Decompositions of Polynomials over their Gradient Ideals   with Rational Coefficients",
        "authors": [
            "Victor Magron",
            "Mohab Safey El Din",
            "Trung-Hieu Vu"
        ],
        "summary": "Assessing non-negativity of multivariate polynomials over the reals, through the computation of {\\em certificates of non-negativity}, is a topical issue in polynomial optimization. This is usually tackled through the computation of {\\em sums-of-squares decompositions} which rely on efficient numerical solvers for semi-definite programming. This method faces two difficulties. The first one is that the certificates obtained this way are {\\em approximate} and then non-exact. The second one is due to the fact that not all non-negative polynomials are sums-of-squares. In this paper, we build on previous works by Parrilo, Nie, Demmel and Sturmfels who introduced certificates of non-negativity modulo {\\em gradient ideals}. We prove that, actually, such certificates can be obtained {\\em exactly}, over the rationals if the polynomial under consideration has rational coefficients and we provide {\\em exact} algorithms to compute them. We analyze the bit complexity of these algorithms and deduce bit size bounds of such certificates.",
        "published": "2021-07-25T15:13:43Z",
        "link": "http://arxiv.org/abs/2107.11825v1",
        "categories": [
            "cs.SC",
            "math.OC"
        ]
    },
    {
        "title": "Digital Collections of Examples in Mathematical Sciences",
        "authors": [
            "James Harold Davenport"
        ],
        "summary": "Some aspects of Computer Algebra (notably Computation Group Theory and Computational Number Theory) have some good databases of examples, typically of the form \"all the X up to size n\". But most of the others, especially on the polynomial side, are lacking such, despite the utility they have demonstrated in the related fields of SAT and SMT solving. We claim that the field would be enhanced by such community-maintained databases, rather than each author hand-selecting a few, which are often too large or error-prone to print, and therefore difficult for subsequent authors to reproduce.",
        "published": "2021-07-27T16:05:36Z",
        "link": "http://arxiv.org/abs/2107.12908v2",
        "categories": [
            "cs.SC",
            "00A35, 12-04, 20-04"
        ]
    },
    {
        "title": "ATLAS: Interactive and Educational Linear Algebra System Containing   Non-Standard Methods",
        "authors": [
            "Akhilesh Pai",
            "James Harold Davenport"
        ],
        "summary": "While there are numerous linear algebra teaching tools, they tend to be focused on the basics, and not handle the more advanced aspects. This project aims to fill that gap, focusing specifically on methods like Strassen's fast matrix multiplication.",
        "published": "2021-07-29T13:03:34Z",
        "link": "http://arxiv.org/abs/2107.13942v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Signature Gröbner bases, bases of syzygies and cofactor reconstruction   in the free algebra",
        "authors": [
            "Clemens Hofstadler",
            "Thibaut Verron"
        ],
        "summary": "Signature-based algorithms have become a standard approach for computing Gr\\\"obner bases in commutative polynomial rings. However, so far, it was not clear how to extend this concept to the setting of noncommutative polynomials in the free algebra. In this paper, we present a signature-based algorithm for computing Gr\\\"obner bases in precisely this setting. The algorithm is an adaptation of Buchberger's algorithm including signatures. We prove that our algorithm correctly enumerates a signature Gr\\\"obner basis as well as a Gr\\\"obner basis of the module generated by the leading terms of the generators' syzygies, and that it terminates whenever the ideal admits a finite signature Gr\\\"obner basis. Additionally, we adapt well-known signature-based criteria eliminating redundant reductions, such as the syzygy criterion, the F5 criterion and the singular criterion, to the case of noncommutative polynomials. We also generalize reconstruction methods from the commutative setting that allow to recover, from partial information about signatures, the coordinates of elements of a Gr\\\"obner basis in terms of the input polynomials, as well as a basis of the syzygy module of the generators. We have written a toy implementation of all the algorithms in the Mathematica package OperatorGB and we compare our signature-based algorithm to the classical Buchberger algorithm for noncommutative polynomials.",
        "published": "2021-07-30T14:52:12Z",
        "link": "http://arxiv.org/abs/2107.14675v3",
        "categories": [
            "cs.SC",
            "math.RA"
        ]
    },
    {
        "title": "Computing the Newton-step faster than Hessian accumulation",
        "authors": [
            "Akshay Srinivasan",
            "Emanuel Todorov"
        ],
        "summary": "Computing the Newton-step of a generic function with $N$ decision variables takes $O(N^3)$ flops. In this paper, we show that given the computational graph of the function, this bound can be reduced to $O(m\\tau^3)$, where $\\tau, m$ are the width and size of a tree-decomposition of the graph. The proposed algorithm generalizes nonlinear optimal-control methods based on LQR to general optimization problems and provides non-trivial gains in iteration-complexity even in cases where the Hessian is dense.",
        "published": "2021-08-02T11:22:08Z",
        "link": "http://arxiv.org/abs/2108.01219v1",
        "categories": [
            "math.OC",
            "cs.LG",
            "cs.SC",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Macaulay bases of modules",
        "authors": [
            "Sujit Rao"
        ],
        "summary": "We define Macaulay bases of modules, which are a common generalization of Groebner bases and Macaulay $H$-bases to suitably graded modules over a commutative graded $\\mathbf{k}$-algebra, where the index sets of the two gradings may differ. This includes Groebner bases of modules as a special case, in contrast to previous work on Macaulay bases of modules. We show that the standard results on Groebner bases and Macaulay $H$-bases generalize in fields of arbitrary characteristic to Macaulay bases, including the reduction algorithm and Buchberger's criterion and algorithm. A key result is that Macaulay bases, in contrast to Groebner bases, respect symmetries when there is a group $G$ acting homogeneously on a graded module, in which case the reduction algorithm is $G$-equivariant and the $\\mathbf{k}$-span of a Macaulay basis is $G$-invariant. We also show that some of the standard applications of Groebner bases can be generalized to Macaulay bases, including elimination and computation of syzygy modules, which require the generalization to modules that was not present in previous work.",
        "published": "2021-08-08T18:34:01Z",
        "link": "http://arxiv.org/abs/2108.03707v1",
        "categories": [
            "math.AC",
            "cs.SC",
            "math.RA"
        ]
    },
    {
        "title": "Linear equations for unordered data vectors in $[D]^k\\to{}Z^d$",
        "authors": [
            "Piotr Hofman",
            "Jakub Różycki"
        ],
        "summary": "Following a recently considered generalisation of linear equations to unordered-data vectors and to ordered-data vectors, we perform a further generalisation to data vectors that are functions from k-element subsets of the unordered-data set to vectors of integer numbers. These generalised equations naturally appear in the analysis of vector addition systems (or Petri nets) extended so that each token carries a set of unordered data. We show that nonnegative-integer solvability of linear equations is in nondeterministic exponential time while integer solvability is in polynomial time.",
        "published": "2021-08-09T16:27:52Z",
        "link": "http://arxiv.org/abs/2109.03025v5",
        "categories": [
            "cs.CC",
            "cs.FL",
            "cs.SC",
            "68Q85",
            "F.4.2; G.2.2; F.3.1"
        ]
    },
    {
        "title": "Renormalized Wolfram model exhibiting non-relativistic quantum behavior",
        "authors": [
            "José Manuel Rodríguez Caballero"
        ],
        "summary": "We show a Wolfram model whose renormalization generates a sequence of approximations of a wave function having the Pauli-x matrix as Hamiltonian.",
        "published": "2021-08-18T02:19:40Z",
        "link": "http://arxiv.org/abs/2108.08300v1",
        "categories": [
            "quant-ph",
            "cs.SC",
            "math.DS"
        ]
    },
    {
        "title": "Beyond Linear Algebra",
        "authors": [
            "Bernd Sturmfels"
        ],
        "summary": "Our title challenges the reader to venture beyond linear algebra in designing models and in thinking about numerical algorithms for identifying solutions. This article accompanies the author's lecture at the International Congress of Mathematicians 2022. It covers recent advances in the study of critical point equations in optimization and statistics, and it explores the role of nonlinear algebra in the study of linear PDE with constant coefficients.",
        "published": "2021-08-21T11:41:45Z",
        "link": "http://arxiv.org/abs/2108.09494v1",
        "categories": [
            "math.AG",
            "cs.SC",
            "math.OC",
            "math.ST",
            "stat.TH"
        ]
    },
    {
        "title": "Computer algebra in Julia",
        "authors": [
            "Dmitry S. Kulyabov",
            "Anna V. Korolkova"
        ],
        "summary": "Recently, the place of the main programming language for scientific and engineering computations has been little by little taken by Julia. Some users want to work completely within the Julia framework as they work within the Python framework. There are libraries for Julia that cover the majority of scientific and engineering computations demands. The aim of this paper is to combine the usage of the Julia framework for numerical computations and for symbolic computations in mathematical modeling problems. The main functional domains determining various variants of the application of computer algebra systems are described. In each of these domains, generic representatives of computer algebra systems in Julia are distinguished. The conclusion is that it is possible (and even convenient) to use computer algebra systems within the Julia framework.",
        "published": "2021-08-27T14:24:51Z",
        "link": "http://arxiv.org/abs/2108.12301v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Vivienne: Relational Verification of Cryptographic Implementations in   WebAssembly",
        "authors": [
            "Rodothea Myrsini Tsoupidi",
            "Musard Balliu",
            "Benoit Baudry"
        ],
        "summary": "This paper explores the use of relational symbolic execution to counter timing side channels in WebAssembly programs. We design and implement Vivienne, an open-source tool to automatically analyze WebAssembly cryptographic libraries for constant-time violations. Our approach features various optimizations that leverage the structure of WebAssembly and automated theorem provers, including support for loops via relational invariants. We evaluate Vivienne on 57 real-world cryptographic implementations, including a previously unverified implementation of the HACL* library in WebAssembly. The results indicate that Vivienne is a practical solution for constant-time analysis of cryptographic libraries in WebAssembly.",
        "published": "2021-09-03T09:11:08Z",
        "link": "http://arxiv.org/abs/2109.01386v1",
        "categories": [
            "cs.CR",
            "cs.PL",
            "cs.SC"
        ]
    },
    {
        "title": "Proceedings of the 9th International Workshop on Verification and   Program Transformation",
        "authors": [
            "Alexei Lisitsa",
            "Andrei P. Nemytykh"
        ],
        "summary": "The previous VPT 2020 workshop was organized in honour of Professor Alberto Pettorossi on the occasion of his academic retirement from Universit\\`a di Roma Tor Vergata. Due to the pandemic the VPT 2020 meeting was cancelled but its proceeding have already appeared in the EPTCS 320 volume. The joint VPT-20-21 event has subsumed the original programme of VPT 2020 and provided an opportunity to meet and celebrate the achievements of Professor Alberto Pettorossi; its programme was further expanded with the newly submitted presentations for VPT 2021. The aim of the VPT workshop series is to provide a forum where people from the areas of program transformation and program verification can fruitfully exchange ideas and gain a deeper understanding of the interactions between those two fields.",
        "published": "2021-09-05T05:42:21Z",
        "link": "http://arxiv.org/abs/2109.02001v1",
        "categories": [
            "cs.SC",
            "cs.PL",
            "cs.SE"
        ]
    },
    {
        "title": "OGRe: An Object-Oriented General Relativity Package for Mathematica",
        "authors": [
            "Barak Shoshany"
        ],
        "summary": "We present OGRe, a modern Mathematica package for tensor calculus, designed to be both powerful and user-friendly. The package can be used in a variety of contexts where tensor calculations are needed, in both mathematics and physics, but it is especially suitable for general relativity. By implementing an object-oriented design paradigm, OGRe allows calculating arbitrarily complicated tensor formulas easily, and automatically transforms between index configurations and coordinate systems behind the scenes as needed, eliminating user errors by making it impossible for the user to combine tensors in inconsistent ways. Other features include displaying tensors in various forms, automatic calculation of curvature tensors and geodesic equations, easy importing and exporting of tensors between sessions, optimized algorithms and parallelization for improved performance, and more.",
        "published": "2021-09-06T00:31:23Z",
        "link": "http://arxiv.org/abs/2109.04193v1",
        "categories": [
            "cs.MS",
            "cs.SC",
            "gr-qc",
            "math.DG"
        ]
    },
    {
        "title": "Proceedings of the 9th International Symposium on Symbolic Computation   in Software Science",
        "authors": [
            "Temur Kutsia"
        ],
        "summary": "This volume contains papers presented at the Ninth International Symposium on Symbolic Computation in Software Science, SCSS 2021.   Symbolic Computation is the science of computing with symbolic objects (terms, formulae, programs, representations of algebraic objects, etc.). Powerful algorithms have been developed during the past decades for the major subareas of symbolic computation: computer algebra and computational logic. These algorithms and methods are successfully applied in various fields, including software science, which covers a broad range of topics about software construction and analysis.   Meanwhile, artificial intelligence methods and machine learning algorithms are widely used nowadays in various domains and, in particular, combined with symbolic computation. Several approaches mix artificial intelligence and symbolic methods and tools deployed over large corpora to create what is known as cognitive systems. Cognitive computing focuses on building systems that interact with humans naturally by reasoning, aiming at learning at scale.   The purpose of SCSS is to promote research on theoretical and practical aspects of symbolic computation in software science, combined with modern artificial intelligence techniques. These proceedings contain the keynote paper by Bruno Buchberger and ten contributed papers. Besides, the conference program included three invited talks, nine short and work-in-progress papers, and a special session on computer algebra and computational logic. Due to the COVID-19 pandemic, the symposium was held completely online. It was organized by the Research Institute for Symbolic Computation (RISC) of the Johannes Kepler University Linz on September 8--10, 2021.",
        "published": "2021-09-06T14:22:11Z",
        "link": "http://arxiv.org/abs/2109.02501v1",
        "categories": [
            "cs.SC",
            "cs.AI",
            "cs.LO",
            "cs.SE"
        ]
    },
    {
        "title": "Efficient diagonalization of symmetric matrices associated with graphs   of small treewidth",
        "authors": [
            "Martin Fürer",
            "Carlos Hoppen",
            "Vilmar Trevisan"
        ],
        "summary": "Let $M=(m_{ij})$ be a symmetric matrix of order $n$ whose elements lie in an arbitrary field $\\mathbb{F}$, and let $G$ be the graph with vertex set $\\{1,\\ldots,n\\}$ such that distinct vertices $i$ and $j$ are adjacent if and only if $m_{ij} \\neq 0$. We introduce a dynamic programming algorithm that finds a diagonal matrix that is congruent to $M$. If $G$ is given with a tree decomposition $\\mathcal{T}$ of width $k$, then this can be done in time $O(k|\\mathcal{T}| + k^2 n)$, where $|\\mathcal{T}|$ denotes the number of nodes in $\\mathcal{T}$. Among other things, this allows one to compute the determinant, the rank and the inertia of a symmetric matrix in time $O(k|\\mathcal{T}| + k^2 n)$.",
        "published": "2021-09-06T14:48:46Z",
        "link": "http://arxiv.org/abs/2109.02515v2",
        "categories": [
            "cs.DS",
            "cs.SC",
            "math.CO",
            "15A18",
            "F.2.2; G.2.2"
        ]
    },
    {
        "title": "Symbolic Computation in Software Science: My Personal View",
        "authors": [
            "Bruno Buchberger"
        ],
        "summary": "In this note, I develop my personal view on the scope and relevance of symbolic computation in software science. For this, I discuss the interaction and differences between symbolic computation, software science, automatic programming, mathematical knowledge management, artificial intelligence, algorithmic intelligence, numerical computation, and machine learning. In the discussion of these notions, I allow myself to refer also to papers (1982, 1985, 2001, 2003, 2013) of mine in which I expressed my views on these areas at early stages of some of these fields.",
        "published": "2021-09-07T01:41:41Z",
        "link": "http://arxiv.org/abs/2109.02806v1",
        "categories": [
            "cs.SC",
            "cs.AI",
            "cs.SE"
        ]
    },
    {
        "title": "Jacobi's Bound. Jacobi's results translated in K{Ö}nig's,   Egerv{á}ry's and Ritt's mathematical languages",
        "authors": [
            "François Ollivier"
        ],
        "summary": "Jacobi's results on the computation of the order and of the normal forms of a differential system are translated in the formalism of differential algebra. In the quasi-regular case, we give complete proofs according to Jacobi's arguments. The main result is {\\it Jacobi's bound}, still conjectural in the general case: the order of a differential system $P_{1}, \\ldots, P_{n}$ is not greater than the maximum $\\cal O$ of the sums $\\sum_{i=1}^{n} a_{i,\\sigma(i)}$, for all permutations $\\sigma$ of the indices, where $a_{i,j}:={\\rm ord}_{x_{j}}P_{i}$, \\emph{viz.}\\ the \\emph{tropical determinant of the matrix $(a_{i,j})$}. The order is precisely equal to $\\cal O$ iff Jacobi's \\emph{truncated determinant} does not vanish.   Jacobi also gave a polynomial time algorithm to compute $\\cal O$, similar to Kuhn's \"Hungarian method\" and some variants of shortest path algorithms, related to the computation of integers $\\ell_{i}$ such that a normal form may be obtained, in the generic case, by differentiating $\\ell_{i}$ times equation $P_{i}$.   Fundamental results about changes of orderings and the various normal forms a system may have, including differential resolvents, are also provided.",
        "published": "2021-09-07T16:03:38Z",
        "link": "http://arxiv.org/abs/2109.03620v3",
        "categories": [
            "math.HO",
            "cs.SC",
            "12H05 (primary), 90C27 (secondary)",
            "I.1.2"
        ]
    },
    {
        "title": "The VLSAT-2 Benchmark Suite",
        "authors": [
            "Pierre Bouvier",
            "Hubert Garavel"
        ],
        "summary": "This report presents VLSAT-2 (an acronym for \"Very Large Boolean SATisfiability problems),the second part of a benchmark suite to be used in scientific experiments and softwarecompetitions addressing SAT-solving issues.VLSAT-2 contains 100 benchmarks (50 satisfiable and 50 unsatisfiable formulas)of increasing complexity, proposed in DIMACS CNF format undera permissive Creative Commons license.25% of these benchmarks have been used during the 2020 and 2021 editionsof the International SAT Competition.",
        "published": "2021-09-08T06:46:18Z",
        "link": "http://arxiv.org/abs/2110.06336v1",
        "categories": [
            "cs.DS",
            "cs.SC"
        ]
    },
    {
        "title": "Knowledge-Assisted Reasoning of Model-Augmented System Requirements with   Event Calculus and Goal-Directed Answer Set Programming",
        "authors": [
            "Brendan Hall",
            "Sarat Chandra Varanasi",
            "Jan Fiedor",
            "Joaquín Arias",
            "Kinjal Basu",
            "Fang Li",
            "Devesh Bhatt",
            "Kevin Driscoll",
            "Elmer Salazar",
            "Gopal Gupta"
        ],
        "summary": "We consider requirements for cyber-physical systems represented in constrained natural language. We present novel automated techniques for aiding in the development of these requirements so that they are consistent and can withstand perceived failures. We show how cyber-physical systems' requirements can be modeled using the event calculus (EC), a formalism used in AI for representing actions and change. We also show how answer set programming (ASP) and its query-driven implementation s(CASP) can be used to directly realize the event calculus model of the requirements. This event calculus model can be used to automatically validate the requirements. Since ASP is an expressive knowledge representation language, it can also be used to represent contextual knowledge about cyber-physical systems, which, in turn, can be used to find gaps in their requirements specifications. We illustrate our approach through an altitude alerting system from the avionics domain.",
        "published": "2021-09-10T02:43:08Z",
        "link": "http://arxiv.org/abs/2109.04634v1",
        "categories": [
            "cs.LO",
            "cs.AI",
            "cs.SC"
        ]
    },
    {
        "title": "Competition Report: CHC-COMP-21",
        "authors": [
            "Grigory Fedyukovich",
            "Philipp Rümmer"
        ],
        "summary": "CHC-COMP-21 is the fourth competition of solvers for Constrained Horn Clauses. In this year, 7 solvers participated at the competition, and were evaluated in 7 separate tracks on problems in linear integer arithmetic, linear real arithmetic, arrays, and algebraic data-types. The competition was run in March 2021 using the StarExec computing cluster. This report gives an overview of the competition design, explains the organisation of the competition, and presents the competition results.",
        "published": "2021-09-10T02:43:28Z",
        "link": "http://arxiv.org/abs/2109.04635v1",
        "categories": [
            "cs.LO",
            "cs.SC",
            "F.3.1"
        ]
    },
    {
        "title": "Adjoint Differentiation for generic matrix functions",
        "authors": [
            "Andrei Goloubentsev",
            "Dmitri Goloubentsev",
            "Evgeny Lakshtanov"
        ],
        "summary": "We derive a formula for the adjoint $\\overline{A}$ of a square-matrix operation of the form $C=f(A)$, where $f$ is holomorphic in the neighborhood of each eigenvalue. We then apply the formula to derive closed-form expressions in particular cases of interest such as the case when we have a spectral decomposition $A=UDU^{-1}$, the spectrum cut-off $C=A_+$ and the Nearest Correlation Matrix routine. Finally, we explain how to simplify the computation of adjoints for regularized linear regression coefficients.",
        "published": "2021-09-10T14:52:40Z",
        "link": "http://arxiv.org/abs/2109.04913v1",
        "categories": [
            "q-fin.CP",
            "cs.SC",
            "q-fin.RM"
        ]
    },
    {
        "title": "Conversational Multi-Hop Reasoning with Neural Commonsense Knowledge and   Symbolic Logic Rules",
        "authors": [
            "Forough Arabshahi",
            "Jennifer Lee",
            "Antoine Bosselut",
            "Yejin Choi",
            "Tom Mitchell"
        ],
        "summary": "One of the challenges faced by conversational agents is their inability to identify unstated presumptions of their users' commands, a task trivial for humans due to their common sense. In this paper, we propose a zero-shot commonsense reasoning system for conversational agents in an attempt to achieve this. Our reasoner uncovers unstated presumptions from user commands satisfying a general template of if-(state), then-(action), because-(goal). Our reasoner uses a state-of-the-art transformer-based generative commonsense knowledge base (KB) as its source of background knowledge for reasoning. We propose a novel and iterative knowledge query mechanism to extract multi-hop reasoning chains from the neural KB which uses symbolic logic rules to significantly reduce the search space. Similar to any KBs gathered to date, our commonsense KB is prone to missing knowledge. Therefore, we propose to conversationally elicit the missing knowledge from human users with our novel dynamic question generation strategy, which generates and presents contextualized queries to human users. We evaluate the model with a user study with human users that achieves a 35% higher success rate compared to SOTA.",
        "published": "2021-09-17T13:40:07Z",
        "link": "http://arxiv.org/abs/2109.08544v1",
        "categories": [
            "cs.AI",
            "cs.CL",
            "cs.LG",
            "cs.SC"
        ]
    },
    {
        "title": "On the representation of non-holonomic univariate power series",
        "authors": [
            "Bertrand Teguia Tabuguia",
            "Wolfram Koepf"
        ],
        "summary": "Holonomic functions play an essential role in Computer Algebra since they allow the application of many symbolic algorithms. Among all algorithmic attempts to find formulas for power series, the holonomic property remains the most important requirement to be satisfied by the function under consideration. The targeted functions mainly summarize that of meromorphic functions. However, expressions like $\\tan(z)$, $z/(\\exp(z)-1)$, $\\sec(z)$, etc., particularly, reciprocals, quotients and compositions of holonomic functions, are generally not holonomic. Therefore their power series are inaccessible by the holonomic framework. From the mathematical dictionaries, one can observe that most of the known closed-form formulas of non-holonomic power series involve another sequence whose evaluation depends on some finite summations. In the case of $\\tan(z)$ and $\\sec(z)$ the corresponding sequences are the Bernoulli and Euler numbers, respectively. Thus providing a symbolic approach that yields complete representations when linear summations for power series coefficients of non-holonomic functions appear, might be seen as a step forward towards the representation of non-holonomic power series.   By adapting the method of ansatz with undetermined coefficients, we build an algorithm that computes least-order quadratic differential equations with polynomial coefficients for a large class of non-holonomic functions. A differential equation resulting from this procedure is converted into a recurrence equation by applying the Cauchy product formula and rewriting powers into polynomials and derivatives into shifts. Finally, using enough initial values we are able to give normal form representations to characterize several non-holonomic power series and prove non-trivial identities. We discuss this algorithm and its implementation for Maple 2022.",
        "published": "2021-09-20T14:29:02Z",
        "link": "http://arxiv.org/abs/2109.09574v3",
        "categories": [
            "cs.SC",
            "Primary: 30B99, 34K17, Secondary: 34A09, 11B68"
        ]
    },
    {
        "title": "Not another computer algebra system: Highlighting wxMaxima in calculus",
        "authors": [
            "N. Karjanto",
            "H. S. Husain"
        ],
        "summary": "This article introduces and explains a computer algebra system (CAS) wxMaxima for Calculus teaching and learning at the tertiary level. The didactic reasoning behind this approach is the need to implement an element of technology into classrooms to enhance students' understanding of Calculus concepts. For many mathematics educators who have been using CAS, this material is of great interest, particularly for secondary teachers and university instructors who plan to introduce an alternative CAS into their classrooms. By highlighting both the strengths and limitations of the software, we hope that it will stimulate further debate not only among mathematics educators and software users but also also among symbolic computation and software developers.",
        "published": "2021-09-28T05:41:56Z",
        "link": "http://arxiv.org/abs/2109.13500v1",
        "categories": [
            "math.HO",
            "cs.SC",
            "physics.ed-ph",
            "68W30, 94-04, 97I40, 97I50, 97D40, 97D80, 97U50, 97U70"
        ]
    },
    {
        "title": "Bit Complexity of Jordan Normal Form and Spectral Factorization",
        "authors": [
            "Papri Dey",
            "Ravi Kannan",
            "Nick Ryder",
            "Nikhil Srivastava"
        ],
        "summary": "We study the bit complexity of two related fundamental computational problems in linear algebra and control theory. Our results are: (1) An $\\tilde{O}(n^{\\omega+3}a+n^4a^2+n^\\omega\\log(1/\\epsilon))$ time algorithm for finding an $\\epsilon-$approximation to the Jordan Normal form of an integer matrix with $a-$bit entries, where $\\omega$ is the exponent of matrix multiplication. (2) An $\\tilde{O}(n^6d^6a+n^4d^4a^2+n^3d^3\\log(1/\\epsilon))$ time algorithm for $\\epsilon$-approximately computing the spectral factorization $P(x)=Q^*(x)Q(x)$ of a given monic $n\\times n$ rational matrix polynomial of degree $2d$ with rational $a-$bit coefficients having $a-$bit common denominators, which satisfies $P(x)\\succeq 0$ for all real $x$. The first algorithm is used as a subroutine in the second one.   Despite its being of central importance, polynomial complexity bounds were not previously known for spectral factorization, and for Jordan form the best previous best running time was an unspecified polynomial in $n$ of degree at least twelve \\cite{cai1994computing}. Our algorithms are simple and judiciously combine techniques from numerical and symbolic computation, yielding significant advantages over either approach by itself.",
        "published": "2021-09-28T18:01:01Z",
        "link": "http://arxiv.org/abs/2109.13956v2",
        "categories": [
            "cs.DS",
            "cs.NA",
            "cs.SC",
            "math.NA",
            "math.OC"
        ]
    },
    {
        "title": "Segre-Driven Radicality Testing",
        "authors": [
            "Martin Helmer",
            "Elias Tsigaridas"
        ],
        "summary": "We present a probabilistic algorithm to test if a homogeneous polynomial ideal $I$ defining a scheme $X$ in $\\mathbb{P}^n$ is radical using Segre classes and other geometric notions from intersection theory. Its worst case complexity depends on the geometry of $X$. If the scheme $X$ has reduced isolated primary components and no embedded components supported the singular locus of $X_{\\rm red}=V(\\sqrt{I})$, then the worst case complexity is doubly exponential in $n$; in all the other cases the complexity is singly exponential. The realm of the ideals for which our radical testing procedure requires only single exponential time includes examples which are often considered pathological, such as the ones drawn from the famous Mayr-Meyer set of ideals which exhibit doubly exponential complexity for the ideal membership problem.",
        "published": "2021-10-05T10:06:06Z",
        "link": "http://arxiv.org/abs/2110.01913v1",
        "categories": [
            "math.AG",
            "cs.CC",
            "cs.SC",
            "math.AC",
            "14Qxx, 13Pxx, 13H15, 14C17, 14C20, 68W30, 65H10"
        ]
    },
    {
        "title": "VESPo: Verified Evaluation of Secret Polynomials",
        "authors": [
            "Jean-Guillaume Dumas",
            "Aude Maignan",
            "Clément Pernet",
            "Daniel S. Roche"
        ],
        "summary": "Proofs of Retrievability are protocols which allow a Client to store data remotely and to efficiently ensure, via audits, that the entirety of that data is still intact. Dynamic Proofs of Retrievability (DPoR) also support efficient retrieval and update of any small portion of the data.We propose a novel protocol for arbitrary outsourced data storage that achieves both low remote storage size and audit complexity.A key ingredient, that can be also of intrinsic interest, reduces to efficiently evaluating a secret polynomial at given public points, when the (encrypted) polynomial is stored on an untrusted Server.The Server performs the evaluations and also returns associated certificates. A Client can check that the evaluations are correct using the certificates and some pre-computed keys, more efficiently than re-evaluating the polynomial.Our protocols support two important features: the polynomial itself can be encrypted on the Server, and it can be dynamically updated by changing individual coefficients cheaply without redoing the entire setup.Our methods rely on linearly homomorphic encryption and pairings, and our implementation shows good performance for polynomial evaluations with millions of coefficients, and efficient DPoR with terabytes of data.For instance, for a 1TB database, compared to the state of art, we can reduce the Client storage by 5000x, communication size by 20x, and client-side audit time by 2x, at the cost of one order of magnitude increase in server-side audit time.",
        "published": "2021-10-05T13:11:04Z",
        "link": "http://arxiv.org/abs/2110.02022v5",
        "categories": [
            "cs.CR",
            "cs.SC"
        ]
    },
    {
        "title": "Computational aspects of finding a solution asymptotics for a singularly   perturbed system of differential equations",
        "authors": [
            "Vitaly A. Krasikov",
            "Andrey V. Nesterov"
        ],
        "summary": "We analyze the spatial structure of asymptotics of a solution to a singularly perturbed system of mass transfer equations. The leading term of the asymptotics is described by a parabolic equation with possibly degenerate spatial part. We prove a theorem that establishes a relationship between the degree of degeneracy and the numbers of equations in the system and spatial variables in some particular cases. The work hardly depends on the calculation of the eigenvalues of matrices that determine the spatial structure of the asymptotics by the means of computer algebra system Wolfram Mathematica. We put forward a hypothesis on the existence of the found connection for an arbitrary number of equations and spatial variables.",
        "published": "2021-10-11T08:37:52Z",
        "link": "http://arxiv.org/abs/2110.05082v1",
        "categories": [
            "math.AP",
            "cs.SC"
        ]
    },
    {
        "title": "Algebraic and Puiseux series solutions of systems of autonomous   algebraic ODEs of dimension one in several variables",
        "authors": [
            "Jose Cano",
            "Sebastian Falkensteiner",
            "Daniel Robertz",
            "Rafael Sendra"
        ],
        "summary": "In this paper we study systems of autonomous algebraic ODEs in several differential indeterminates. We develop a notion of algebraic dimension of such systems by considering them as algebraic systems. Afterwards we apply differential elimination and analyze the behavior of the dimension in the resulting Thomas decomposition. For such systems of algebraic dimension one, we show that all formal Puiseux series solutions can be approximated up to an arbitrary order by convergent solutions. We show that the existence of Puiseux series and algebraic solutions can be decided algorithmically. Moreover, we present a symbolic algorithm to compute all algebraic solutions. The output can either be represented by triangular systems or by their minimal polynomials.",
        "published": "2021-10-11T18:57:32Z",
        "link": "http://arxiv.org/abs/2110.05558v2",
        "categories": [
            "math.AG",
            "cs.SC",
            "12H05 Differential algebra, 68W30 Symbolic computation and algebraic\n  computation, 34A25 Analytical theory of ordinary differential equations"
        ]
    },
    {
        "title": "An Overview of Ontologies and Tool Support for COVID-19 Analytics",
        "authors": [
            "Aakash Ahmad",
            "Madhushi Bandara",
            "Mahdi Fahmideh",
            "Henderik A. Proper",
            "Giancarlo Guizzardi",
            "Jeffrey Soar"
        ],
        "summary": "The outbreak of the SARS-CoV-2 pandemic of the new COVID-19 disease (COVID-19 for short) demands empowering existing medical, economic, and social emergency backend systems with data analytics capabilities. An impediment in taking advantages of data analytics in these systems is the lack of a unified framework or reference model. Ontologies are highlighted as a promising solution to bridge this gap by providing a formal representation of COVID-19 concepts such as symptoms, infections rate, contact tracing, and drug modelling. Ontology-based solutions enable the integration of diverse data sources that leads to a better understanding of pandemic data, management of smart lockdowns by identifying pandemic hotspots, and knowledge-driven inference, reasoning, and recommendations to tackle surrounding issues.",
        "published": "2021-10-12T23:20:37Z",
        "link": "http://arxiv.org/abs/2110.06397v1",
        "categories": [
            "cs.SE",
            "cs.CL",
            "cs.SC"
        ]
    },
    {
        "title": "Faster Modular Composition",
        "authors": [
            "Vincent Neiger",
            "Bruno Salvy",
            "Éric Schost",
            "Gilles Villard"
        ],
        "summary": "A new Las Vegas algorithm is presented for the composition of two polynomials modulo a third one, over an arbitrary field. When the degrees of these polynomials are bounded by $n$, the algorithm uses $O(n^{1.43})$ field operations, breaking through the $3/2$ barrier in the exponent for the first time. The previous fastest algebraic algorithms, due to Brent and Kung in 1978, require $O(n^{1.63})$ field operations in general, and ${n^{3/2+o(1)}}$ field operations in the special case of power series over a field of large enough characteristic. If cubic-time matrix multiplication is used, the new algorithm runs in ${n^{5/3+o(1)}}$ operations, while previous ones run in $O(n^2)$ operations.   Our approach relies on the computation of a matrix of algebraic relations that is typically of small size. Randomization is used to reduce arbitrary input to this favorable situation.",
        "published": "2021-10-15T20:33:37Z",
        "link": "http://arxiv.org/abs/2110.08354v2",
        "categories": [
            "cs.SC",
            "cs.CC"
        ]
    },
    {
        "title": "Fast and Reliable Formal Verification of Smart Contracts with the Move   Prover",
        "authors": [
            "David Dill",
            "Wolfgang Grieskamp",
            "Junkil Park",
            "Shaz Qadeer",
            "Meng Xu",
            "Emma Zhong"
        ],
        "summary": "The Move Prover (MVP) is a formal verifier for smart contracts written in the Move programming language. MVP has an expressive specification language, and is fast and reliable enough that it can be run routinely by developers and in integration testing in a few minutes. Besides the simplicity of smart contracts and the Move language, three transformations are responsible for the practicality of MVP: (1) an alias-free memory model, (2) fine-grained invariant checking, and (3) monomorphization. The entirety of the Move code for the Diem blockchain has been extensively specified and can be completely verified by MVP in a few minutes. Changes in the Diem framework must be successfully verified before being integrated into the open source repository on GitHub.",
        "published": "2021-10-15T20:49:30Z",
        "link": "http://arxiv.org/abs/2110.08362v3",
        "categories": [
            "cs.PL",
            "cs.SC",
            "cs.SE"
        ]
    },
    {
        "title": "Arjun: An Efficient Independent Support Computation Technique and its   Applications to Counting and Sampling",
        "authors": [
            "Mate Soos",
            "Kuldeep S. Meel"
        ],
        "summary": "Given a Boolean formula $\\varphi$ over the set of variables $X$ and a projection set $\\mathcal{P} \\subseteq X$, a subset of variables $\\mathcal{I}$ is independent support of $\\mathcal{P}$ if two solutions agree on $\\mathcal{I}$, then they also agree on $\\mathcal{P}$. The notion of independent support is related to the classical notion of definability dating back to 1901, and have been studied over the decades. Recently, the computational problem of determining independent support for a given formula has attained importance owing to the crucial importance of independent support for hashing-based counting and sampling techniques.   In this paper, we design an efficient and scalable independent support computation technique that can handle formulas arising from real-world benchmarks. Our algorithmic framework, called Arjun, employs implicit and explicit definability notions, and is based on a tight integration of gate-identification techniques and assumption-based framework. We demonstrate that augmenting the state of the art model counter ApproxMC4 and sampler UniGen3 with Arjun leads to significant performance improvements. In particular, ApproxMC4 augmented with Arjun counts 387 more benchmarks out of 1896 while UniGen3 augmented with Arjun samples 319 more benchmarks within the same time limit.",
        "published": "2021-10-18T05:54:42Z",
        "link": "http://arxiv.org/abs/2110.09026v1",
        "categories": [
            "cs.AI",
            "cs.LO",
            "cs.SC"
        ]
    },
    {
        "title": "Ranking Facts for Explaining Answers to Elementary Science Questions",
        "authors": [
            "Jennifer D'Souza",
            "Isaiah Onando Mulang'",
            "Soeren Auer"
        ],
        "summary": "In multiple-choice exams, students select one answer from among typically four choices and can explain why they made that particular choice. Students are good at understanding natural language questions and based on their domain knowledge can easily infer the question's answer by 'connecting the dots' across various pertinent facts.   Considering automated reasoning for elementary science question answering, we address the novel task of generating explanations for answers from human-authored facts. For this, we examine the practically scalable framework of feature-rich support vector machines leveraging domain-targeted, hand-crafted features. Explanations are created from a human-annotated set of nearly 5,000 candidate facts in the WorldTree corpus. Our aim is to obtain better matches for valid facts of an explanation for the correct answer of a question over the available fact candidates. To this end, our features offer a comprehensive linguistic and semantic unification paradigm. The machine learning problem is the preference ordering of facts, for which we test pointwise regression versus pairwise learning-to-rank.   Our contributions are: (1) a case study in which two preference ordering approaches are systematically compared; (2) it is a practically competent approach that can outperform some variants of BERT-based reranking models; and (3) the human-engineered features make it an interpretable machine learning model for the task.",
        "published": "2021-10-18T06:15:11Z",
        "link": "http://arxiv.org/abs/2110.09036v1",
        "categories": [
            "cs.CL",
            "cs.AI",
            "cs.IR",
            "cs.SC"
        ]
    },
    {
        "title": "Pattern Division Random Access (PDRA) for M2M Communications with   Massive MIMO Systems",
        "authors": [
            "Xiaoming Dai",
            "Tiantian Yan",
            "Qianqian Li",
            "Hua Li",
            "Xiyuan Wang"
        ],
        "summary": "In this work, we introduce the pattern-domain pilot design paradigm based on a \"superposition of orthogonal-building-blocks\" with significantly larger contention space to enhance the massive machine-type communications (mMTC) random access (RA) performance in massive multiple-input multiple-output (MIMO) systems.Specifically, the pattern-domain pilot is constructed based on the superposition of $L$ cyclically-shifted Zadoff-Chu (ZC) sequences. The pattern-domain pilots exhibit zero correlation values between non-colliding patterns from the same root and low correlation values between patterns from different roots. The increased contention space, i.e., from N to $\\binom{N}{L}$, where $\\binom{N}{L}$ denotes the number of all L-combinations of a set N, and low correlation valueslead to a significantly lower pilot collision probability without compromising excessively on channel estimation performance for mMTC RA in massive MIMO systems.We present the framework and analysis of the RA success probability of the pattern-domain based scheme with massive MIMO systems.Numerical results demonstrate that the proposed pattern division random access (PDRA) scheme achieves an appreciable performance gain over the conventional one,while preserving the existing physical layer virtually unchanged. The extension of the \"superposition of orthogonal-building-blocks\" scheme to \"superposition of quasi-orthogonal-building-blocks\" is straightforward.",
        "published": "2021-10-20T14:28:53Z",
        "link": "http://arxiv.org/abs/2110.10586v2",
        "categories": [
            "cs.IT",
            "cs.SC",
            "math.IT"
        ]
    },
    {
        "title": "An echelon form of weakly infeasible semidefinite programs and bad   projections of the psd cone",
        "authors": [
            "Gábor Pataki",
            "Aleksandr Touzov"
        ],
        "summary": "A weakly infeasible semidefinite program (SDP) has no feasible solution, but it has approximate solutions whose constraint violation is arbitrarily small. These SDPs are ill-posed and numerically often unsolvable. They are also closely related to \"bad\" linear projections that map the cone of positive semidefinite matrices to a nonclosed set. We describe a simple echelon form of weakly infeasible SDPs with the following properties: (i) it is obtained by elementary row operations and congruence transformations, (ii) it makes weak infeasibility evident, and (iii) it permits us to construct any weakly infeasible SDP or bad linear projection by an elementary combinatorial algorithm. Based on our echelon form we generate a challenging library of weakly infeasible SDPs. Finally, we show that some SDPs in the literature are in our echelon form, for example, the SDP from the sum-of-squares relaxation of minimizing the famous Motzkin polynomial.",
        "published": "2021-10-21T19:11:16Z",
        "link": "http://arxiv.org/abs/2110.11437v3",
        "categories": [
            "math.OC",
            "cs.SC",
            "math.AG",
            "Primary: 90C22, 49N15, 15A21 Secondary: 47A52"
        ]
    },
    {
        "title": "Computing elements of certain form in ideals to prove properties of   operators",
        "authors": [
            "Clemens Hofstadler",
            "Clemens G. Raab",
            "Georg Regensburger"
        ],
        "summary": "Proving statements about linear operators expressed in terms of identities often leads to finding elements of certain form in noncommutative polynomial ideals. We illustrate this by examples coming from actual operator statements and discuss relevant algorithmic methods for finding such polynomials based on noncommutative Gr\\\"obner bases. In particular, we present algorithms for computing the intersection of a two-sided ideal with a one-sided ideal as well as for computing homogeneous polynomials in two-sided ideals and monomials in one-sided ideals. All methods presented in this work are implemented in the Mathematica package OperatorGB.",
        "published": "2021-10-25T13:09:27Z",
        "link": "http://arxiv.org/abs/2110.12933v2",
        "categories": [
            "cs.SC",
            "16Z10 (Primary), 03B35 (Secondary)"
        ]
    },
    {
        "title": "Towards a Theory of Domains for Harmonic Functions and its Symbolic   Counterpart",
        "authors": [
            "van Chiên Bui",
            "Gérard Duchamp",
            "Quoc Hoàn Ngo",
            "Vincel Hoang Ngoc Minh",
            "Vu Nguyen Dinh"
        ],
        "summary": "In this paper, we begin by reviewing the calculus induced by the framework of [10]. In there, we extended Polylogarithm functions over a subalgebra of noncommutative rational power series, recognizable by finite state (multiplicity) automata over the alphabet X = {x 0 , x 1 }. The stability of this calculus under shuffle products relies on the nuclearity of the target space [31]. We also concentrated on algebraic and analytic aspects of this extension allowing to index polylogarithms, at non positive multi-indices, by rational series and also allowing to regularize divergent polyzetas, at non positive multi-indices [10]. As a continuation of works in [10] and in order to understand the bridge between the extension of this \"polylogarithmic calculus\" and the world of harmonic sums, we propose a local theory, adapted to a full calculus on indices of Harmonic Sums based on the Taylor expansions, around zero, of polylogarithms with index x 1 on the rightmost end. This theory is not only compatible with Stuffle products but also with the Analytic Model. In this respect, it provides a stable and fully algorithmic model for Harmonic calculus. Examples by computer are also provided 6 .",
        "published": "2021-10-26T14:48:57Z",
        "link": "http://arxiv.org/abs/2110.13743v1",
        "categories": [
            "cs.SC",
            "math.CO"
        ]
    },
    {
        "title": "On some combinatorial sequences associated to invariant theory",
        "authors": [
            "Alin Bostan",
            "Jordan Tirrell",
            "Bruce W. Westbury",
            "Yi Zhang"
        ],
        "summary": "We study the enumerative and analytic properties of some sequences constructed using tensor invariant theory. The octant sequences are constructed from the exceptional Lie group $G_2$ and the quadrant sequences from the special linear group $SL(3)$. In each case we show that the corresponding sequences are related by binomial transforms. The first three octant sequences and the first four quadrant sequences are listed in the On-Line Encyclopedia of Integer Sequences (OEIS). These sequences all have interpretations as enumerating two-dimensional lattice walks but for the octant sequences the boundary conditions are unconventional. These sequences are all P-recursive and we give the corresponding recurrence relations. In all cases the associated differential operators are of third order and have the remarkable property that they can be solved to give closed formulae for the ordinary generating functions in terms of classical Gaussian hypergeometric functions. Moreover, we show that the octant sequences and the quadrant sequences are related by the branching rules for the inclusion of $SL(3)$ in $G_2$.",
        "published": "2021-10-26T15:04:50Z",
        "link": "http://arxiv.org/abs/2110.13753v2",
        "categories": [
            "math.CO",
            "cs.SC"
        ]
    },
    {
        "title": "A Design and an Implementation of an Inverse Kinematics Computation in   Robotics Using Real Quantifier Elimination based on Comprehensive Gröbner   Systems",
        "authors": [
            "Shuto Otaki",
            "Akira Terui",
            "Masahiko Mikawa"
        ],
        "summary": "The solution and implementation of the inverse kinematics computation of a three degree-of-freedom (DOF) robot manipulator using an algorithm for real quantifier elimination with Comprehensive Gr\\\"obner Systems (CGS) are presented. The method enables us to verify if the given parameters are feasible before solving the inverse kinematics problem. Furthermore, pre-computation of CGS and substituting parameters in the CGS with the given values avoids the repetitive computation of Gr\\\"obner basis. Experimental results compared with our previous implementation are shown.",
        "published": "2021-10-31T02:36:52Z",
        "link": "http://arxiv.org/abs/2111.00384v2",
        "categories": [
            "cs.RO",
            "cs.SC",
            "math.AC",
            "68W30, 13P10, 13P25"
        ]
    },
    {
        "title": "Differential elimination for dynamical models via projections with   applications to structural identifiability",
        "authors": [
            "Ruiwen Dong",
            "Christian Goodbrake",
            "Heather A Harrington",
            "Gleb Pogudin"
        ],
        "summary": "Elimination of unknowns in a system of differential equations is often required when analysing (possibly nonlinear) dynamical systems models, where only a subset of variables are observable. One such analysis, identifiability, often relies on computing input-output relations via differential algebraic elimination. Determining identifiability, a natural prerequisite for meaningful parameter estimation, is often prohibitively expensive for medium to large systems due to the computationally expensive task of elimination.   We propose an algorithm that computes a description of the set of differential-algebraic relations between the input and output variables of a dynamical system model. The resulting algorithm outperforms general-purpose software for differential elimination on a set of benchmark models from literature.   We use the designed elimination algorithm to build a new randomized algorithm for assessing structural identifiability of a parameter in a parametric model. A parameter is said to be identifiable if its value can be uniquely determined from input-output data assuming the absence of noise and sufficiently exciting inputs. Our new algorithm allows the identification of models that could not be tackled before.   Our implementation is publicly available as a Julia package at https://github.com/SciML/StructuralIdentifiability.jl.",
        "published": "2021-11-01T14:56:52Z",
        "link": "http://arxiv.org/abs/2111.00991v3",
        "categories": [
            "math.AG",
            "cs.CG",
            "cs.SC",
            "cs.SY",
            "eess.SY",
            "q-bio.QM"
        ]
    },
    {
        "title": "MultiplexNet: Towards Fully Satisfied Logical Constraints in Neural   Networks",
        "authors": [
            "Nicholas Hoernle",
            "Rafael Michael Karampatsis",
            "Vaishak Belle",
            "Kobi Gal"
        ],
        "summary": "We propose a novel way to incorporate expert knowledge into the training of deep neural networks. Many approaches encode domain constraints directly into the network architecture, requiring non-trivial or domain-specific engineering. In contrast, our approach, called MultiplexNet, represents domain knowledge as a logical formula in disjunctive normal form (DNF) which is easy to encode and to elicit from human experts. It introduces a Categorical latent variable that learns to choose which constraint term optimizes the error function of the network and it compiles the constraints directly into the output of existing learning algorithms. We demonstrate the efficacy of this approach empirically on several classical deep learning tasks, such as density estimation and classification in both supervised and unsupervised settings where prior knowledge about the domains was expressed as logical constraints. Our results show that the MultiplexNet approach learned to approximate unknown distributions well, often requiring fewer data samples than the alternative approaches. In some cases, MultiplexNet finds better solutions than the baselines; or solutions that could not be achieved with the alternative approaches. Our contribution is in encoding domain knowledge in a way that facilitates inference that is shown to be both efficient and general; and critically, our approach guarantees 100% constraint satisfaction in a network's output.",
        "published": "2021-11-02T12:39:21Z",
        "link": "http://arxiv.org/abs/2111.01564v1",
        "categories": [
            "cs.LG",
            "cs.SC"
        ]
    },
    {
        "title": "A Symbolic Approach to Detecting Hardware Trojans Triggered by Don't   Care Transitions",
        "authors": [
            "Ruochen Dai",
            "Tuba Yavuz"
        ],
        "summary": "Due to the globalization of Integrated Circuit (IC) supply chain, hardware trojans and the attacks that can trigger them have become an important security issue. One type of hardware Trojans leverages the don't care transitions in Finite State Machines (FSMs) of hardware designs. In this paper, we present a symbolic approach to detecting don't care transitions and the hidden Trojans. Our detection approach works at both RTL and gate-level, does not require a golden design, and works in three stages. In the first stage, it explores the reachable states. In the second stage, it performs an approximate analysis to find the don't care transitions. In the third stage, it performs a state-space exploration from reachable states that have incoming don't care transitions to find behavioral discrepancies with respect to what has been observed in the first stage. We also present a pruning technique based on the reachability of FSM states. We present a methodology that leverages both RTL and gate-level for soundness and efficiency. Specifically, we show that don't care transitions must be detected at the gate-level, i.e., after synthesis has been performed, for soundness. However, under specific conditions, Trojan detection can be performed more efficiently at RTL. Evaluation of our approach on a set of benchmarks from OpenCores and TrustHub and using gate-level representation generated by two synthesis tools, Yosys and Synopsis Design Compiler (SDC), shows that our approach is both efficient (up to 10X speedup w.r.t. no pruning) and precise (0% false positives) in detecting don't care transitions and the Trojans that leverage them. Additionally, the total analysis time can achieve up to 3.40X (using Yosys) and 2.52X (SDC) speedup when synthesis preserves the FSM structure and the Trojan detection is performed at RTL.",
        "published": "2021-11-07T03:08:02Z",
        "link": "http://arxiv.org/abs/2111.03989v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "NRPyLaTeX: A LaTeX interface to computer algebra systems for general   relativity",
        "authors": [
            "Kenneth J. Sible",
            "Zachariah B. Etienne"
        ],
        "summary": "While each computer algebra system (CAS) contains its own unique syntax for inputting mathematical expressions, LaTeX is perhaps the most widespread language for typesetting mathematics. NRPyLaTeX (NL) enables direct LaTeX input of complex tensorial expressions (written in Einstein notation) relevant to general relativity and differential geometry into the SymPy CAS. As SymPy also supports output compatible with the Mathematica and Maple CASs, NL lowers the learning curve for inputting and manipulating tensorial expressions in three widely used CASs. LaTeX however is a typesetting language, and as such is not designed to resolve ambiguities in mathematical expressions. To address this, NL implements a convenient configuration interface that, e.g., defines variables with certain attributes. Configuration commands appear as LaTeX comments, so that entire NL workflows can fit seamlessly into the LaTeX source code of scientific papers without interfering with the rendered mathematical expressions. Further, NL adopts NRPy+'s rigid syntax for indexed symbols (e.g., tensors), which enables NL output to be directly converted into highly optimized C/C++-code kernels using NRPy+. Finally NL has robust and user-friendly error-handling, which catches common tensor indexing errors and reports unresolved ambiguities, further expediting the input and validation of LaTeX expressions into a CAS.",
        "published": "2021-11-10T19:00:00Z",
        "link": "http://arxiv.org/abs/2111.05861v2",
        "categories": [
            "gr-qc",
            "astro-ph.HE",
            "cs.SC"
        ]
    },
    {
        "title": "SimpleTensor -- a user-friendly Mathematica package for elementary   tensor and differential-geometric calculations",
        "authors": [
            "D. O. Rybalka"
        ],
        "summary": "In this paper we present a short overview of the new Wolfram Mathematica package intended for elementary \"in-basis\" tensor and differential-geometric calculations. In contrast to alternatives our package is designed to be easy-to-use, short, all-purpose, and hackable. It supports tensor contractions using Einstein notation, transformations between different bases, tensor derivative operator, expansion in basis vectors and forms, exterior derivative, and interior product.",
        "published": "2021-11-12T13:37:49Z",
        "link": "http://arxiv.org/abs/2111.06718v1",
        "categories": [
            "nucl-th",
            "cs.MS",
            "cs.SC",
            "hep-th",
            "physics.comp-ph"
        ]
    },
    {
        "title": "A Maude Implementation of Rewritable Petri Nets: a Feasible Model for   Dynamically Reconfigurable Systems",
        "authors": [
            "Lorenzo Capra"
        ],
        "summary": "Petri Nets (PN) are a central, theoretically sound model for concurrent or distributed systems but, at least in their classical definition, not expressive enough to represent dynamic reconfiguration capabilities. On the other side, Rewriting Logic has proved to be a natural semantic framework for several formal models of concurrent/distributed systems. We propose a compact, efficient Maude formalization of dynamically reconfigurable PT nets (with inhibitor arcs), using as a running example the specification of a simple, fault-tolerant manufacturing system. We discuss the advantages of such a combined approach, as well as some concerns that it raises.",
        "published": "2021-11-16T03:10:10Z",
        "link": "http://arxiv.org/abs/2111.08205v1",
        "categories": [
            "cs.LO",
            "cs.SC",
            "cs.SE"
        ]
    },
    {
        "title": "Solving sums of squares in global fields",
        "authors": [
            "Przemysław Koprowski"
        ],
        "summary": "The problem of writing a totally positive element as a sum of squares has a long history in mathematics, going back to Bachet and Lagrange. While for some specific rings (like integers or polynomials over the rationals), there are known methods for decomposing an element into a sum of squares, in general, for many other important rings and fields, the problem is still widely open. In this paper, we present an explicit algorithm for decomposing an element of an arbitrary global field (either a number field or a global function field) into a sum of squares of minimal length.",
        "published": "2021-11-16T15:38:10Z",
        "link": "http://arxiv.org/abs/2111.08558v1",
        "categories": [
            "math.NT",
            "cs.SC",
            "11E25, 11Y40, 11E12"
        ]
    },
    {
        "title": "Isotropic vectors over global fields",
        "authors": [
            "Przemysław Koprowski"
        ],
        "summary": "We present a complete suite of algorithms for finding isotropic vectors of quadratic forms (of any dimension) over an arbitrary global field of characteristic different from 2.",
        "published": "2021-11-16T15:43:17Z",
        "link": "http://arxiv.org/abs/2111.08569v1",
        "categories": [
            "math.NT",
            "cs.SC",
            "11E12, 11E20, 11Y40, 11Y50"
        ]
    },
    {
        "title": "A fast algorithm for computing the Smith normal form with multipliers   for a nonsingular integer matrix",
        "authors": [
            "Stavros Birmpilis",
            "George Labahn",
            "Arne Storjohann"
        ],
        "summary": "A Las Vegas randomized algorithm is given to compute the Smith multipliers for a nonsingular integer matrix $A$, that is, unimodular matrices $U$ and $V$ such that $AV=US$, with $S$ the Smith normal form of $A$. The expected running time of the algorithm is about the same as required to multiply together two matrices of the same dimension and size of entries as $A$. Explicit bounds are given for the size of the entries in both unimodular multipliers. The main tool used by the algorithm is the Smith massager, a relaxed version of $V$, the unimodular matrix specifying the column operations of the Smith computation. From the perspective of efficiency, the main tools used are fast linear solving and partial linearization of integer matrices. As an application of the Smith with multipliers algorithm, a fast algorithm is given to find the fractional part of the inverse of the input matrix.",
        "published": "2021-11-18T21:26:47Z",
        "link": "http://arxiv.org/abs/2111.09949v2",
        "categories": [
            "cs.SC",
            "68W30"
        ]
    },
    {
        "title": "Multiplicity structure of the arc space of a fat point",
        "authors": [
            "Rida Ait El Manssour",
            "Gleb Pogudin"
        ],
        "summary": "The equation $x^m = 0$ defines a fat point on a line. The algebra of regular functions on the arc space of this scheme is the quotient of $k[x, x', x^{(2)}, \\ldots]$ by all differential consequences of $x^m = 0$. This infinite-dimensional algebra admits a natural filtration by finite dimensional algebras corresponding to the truncations of arcs. We show that the generating series for their dimensions equals $\\frac{m}{1 - mt}$. We also determine the lexicographic initial ideal of the defining ideal of the arc space. These results are motivated by nonreduced version of the geometric motivic Poincar\\'e series, multiplicities in differential algebra, and connections between arc spaces and the Rogers-Ramanujan identities. We also prove a recent conjecture put forth by Afsharijoo in the latter context.",
        "published": "2021-11-19T21:42:24Z",
        "link": "http://arxiv.org/abs/2111.10446v4",
        "categories": [
            "math.AG",
            "cs.SC",
            "math.AC",
            "math.CO",
            "12H05, 13D40, 05A17"
        ]
    },
    {
        "title": "Computing with B-series",
        "authors": [
            "David I. Ketcheson",
            "Hendrik Ranocha"
        ],
        "summary": "We present BSeries.jl, a Julia package for the computation and manipulation of B-series, which are a versatile theoretical tool for understanding and designing discretizations of differential equations. We give a short introduction to the theory of B-series and associated concepts and provide examples of their use, including method composition and backward error analysis. The associated software is highly performant and makes it possible to work with B-series of high order.",
        "published": "2021-11-23T06:55:29Z",
        "link": "http://arxiv.org/abs/2111.11680v2",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "cs.SC"
        ]
    },
    {
        "title": "From Kepler to Newton: Explainable AI for Science",
        "authors": [
            "Zelong Li",
            "Jianchao Ji",
            "Yongfeng Zhang"
        ],
        "summary": "The Observation--Hypothesis--Prediction--Experimentation loop paradigm for scientific research has been practiced by researchers for years towards scientific discoveries. However, with data explosion in both mega-scale and milli-scale scientific research, it has been sometimes very difficult to manually analyze the data and propose new hypotheses to drive the cycle for scientific discovery. In this paper, we discuss the role of Explainable AI in scientific discovery process by demonstrating an Explainable AI-based paradigm for science discovery. The key is to use Explainable AI to help derive data or model interpretations, hypotheses, as well as scientific discoveries or insights. We show how computational and data-intensive methodology -- together with experimental and theoretical methodology -- can be seamlessly integrated for scientific research. To demonstrate the AI-based science discovery process, and to pay our respect to some of the greatest minds in human history, we show how Kepler's laws of planetary motion and Newton's law of universal gravitation can be rediscovered by (Explainable) AI based on Tycho Brahe's astronomical observation data, whose works were leading the scientific revolution in the 16-17th century. This work also highlights the important role of Explainable AI (as compared to Blackbox AI) in science discovery to help humans prevent or better prepare for the possible technological singularity that may happen in the future, since science is not only about the know how, but also the know why. Presentation of the work is available at https://slideslive.com/38986142/from-kepler-to-newton-explainable-ai-for-science-discovery.",
        "published": "2021-11-24T00:45:27Z",
        "link": "http://arxiv.org/abs/2111.12210v7",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.SC"
        ]
    },
    {
        "title": "Quasi-equivalence of heights in algebraic function fields of one   variable",
        "authors": [
            "Ruyong Feng",
            "Shuang Feng",
            "Li-Yong Shen"
        ],
        "summary": "For points $(a,b)$ on an algebraic curve over a field $K$ with height $\\mathfrak{h}$, the asymptotic relation between $\\mathfrak{h}(a)$ and $\\mathfrak{h}(b)$ has been extensively studied in diophantine geometry. When $K=\\overline{k(t)}$ is the field of algebraic functions in $t$ over a field $k$ of characteristic zero, Eremenko in 1998 proved the following quasi-equivalence for an absolute logarithmic height $\\mathfrak{h}$ in $K$: Given $P\\in K[X,Y]$ irreducible over $K$ and $\\epsilon>0$, there is a constant $C$ only depending on $P$ and $\\epsilon$ such that for each $(a,b)\\in K^2$ with $P(a,b)=0$, $$   (1-\\epsilon) \\deg(P,Y) \\mathfrak{h}(b)-C \\leq \\deg(P,X) \\mathfrak{h}(a) \\leq (1+\\epsilon) \\deg(P,Y) \\mathfrak{h}(b)+C. $$ In this article, we shall give an explicit bound for the constant $C$ in terms of the total degree of $P$, the height of $P$ and $\\epsilon$. This result is expected to have applications in some other areas such as symbolic computation of differential and difference equations.",
        "published": "2021-11-25T11:09:39Z",
        "link": "http://arxiv.org/abs/2111.13025v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Hypergeometric Structures in Feynman Integrals",
        "authors": [
            "J. Blümlein",
            "M. Saragnese",
            "C. Schneider"
        ],
        "summary": "Hypergeometric structures in single and multiscale Feynman integrals emerge in a wide class of topologies. Using integration-by-parts relations, associated master or scalar integrals have to be calculated. For this purpose it appears useful to devise an automated method which recognizes the respective (partial) differential equations related to the corresponding higher transcendental functions. We solve these equations through associated recursions of the expansion coefficient of the multivalued formal Taylor series. The expansion coefficients can be determined using either the package {\\tt Sigma} in the case of linear difference equations or by applying heuristic methods in the case of partial linear difference equations. In the present context a new type of sums occurs, the Hurwitz harmonic sums, and generalized versions of them. The code {\\tt HypSeries} transforming classes of differential equations into analytic series expansions is described. Also partial difference equations having rational solutions and rational function solutions of Pochhammer symbols are considered, for which the code {\\tt solvePartialLDE} is designed. Generalized hypergeometric functions, Appell-,~Kamp\\'e de F\\'eriet-, Horn-, Lauricella-Saran-, Srivasta-, and Exton--type functions are considered. We illustrate the algorithms by examples.",
        "published": "2021-11-30T15:37:55Z",
        "link": "http://arxiv.org/abs/2111.15501v1",
        "categories": [
            "math-ph",
            "cs.SC",
            "hep-ph",
            "hep-th",
            "math.MP"
        ]
    },
    {
        "title": "Lecture notes on complexity of quantifier elimination over the reals",
        "authors": [
            "Nicolai Vorobjov"
        ],
        "summary": "These are lecture notes for a course I gave in mid-1990s for MSc students at the University of Bath. It presents an algorithm with singly exponential complexity for the existential theory of the reals, in the spirit of J. Renegar. The aim was to convey the main underlying ideas, so many of the proofs and finer details of algorithms are either missing or just sketched. I changed nothing in the original notes except adding references, bibliography, and correcting obvious typos.",
        "published": "2021-12-01T12:30:21Z",
        "link": "http://arxiv.org/abs/2112.00456v1",
        "categories": [
            "math.HO",
            "cs.SC",
            "math.LO"
        ]
    },
    {
        "title": "Combining Sub-Symbolic and Symbolic Methods for Explainability",
        "authors": [
            "Anna Himmelhuber",
            "Stephan Grimm",
            "Sonja Zillner",
            "Mitchell Joblin",
            "Martin Ringsquandl",
            "Thomas Runkler"
        ],
        "summary": "Similarly to other connectionist models, Graph Neural Networks (GNNs) lack transparency in their decision-making. A number of sub-symbolic approaches have been developed to provide insights into the GNN decision making process. These are first important steps on the way to explainability, but the generated explanations are often hard to understand for users that are not AI experts. To overcome this problem, we introduce a conceptual approach combining sub-symbolic and symbolic methods for human-centric explanations, that incorporate domain knowledge and causality. We furthermore introduce the notion of fidelity as a metric for evaluating how close the explanation is to the GNN's internal decision making process. The evaluation with a chemical dataset and ontology shows the explanatory value and reliability of our method.",
        "published": "2021-12-03T10:57:00Z",
        "link": "http://arxiv.org/abs/2112.01844v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.SC"
        ]
    },
    {
        "title": "Neuro-Symbolic Inductive Logic Programming with Logical Neural Networks",
        "authors": [
            "Prithviraj Sen",
            "Breno W. S. R. de Carvalho",
            "Ryan Riegel",
            "Alexander Gray"
        ],
        "summary": "Recent work on neuro-symbolic inductive logic programming has led to promising approaches that can learn explanatory rules from noisy, real-world data. While some proposals approximate logical operators with differentiable operators from fuzzy or real-valued logic that are parameter-free thus diminishing their capacity to fit the data, other approaches are only loosely based on logic making it difficult to interpret the learned \"rules\". In this paper, we propose learning rules with the recently proposed logical neural networks (LNN). Compared to others, LNNs offer strong connection to classical Boolean logic thus allowing for precise interpretation of learned rules while harboring parameters that can be trained with gradient-based optimization to effectively fit the data. We extend LNNs to induce rules in first-order logic. Our experiments on standard benchmarking tasks confirm that LNN rules are highly interpretable and can achieve comparable or higher accuracy due to their flexible parameterization.",
        "published": "2021-12-06T19:38:30Z",
        "link": "http://arxiv.org/abs/2112.03324v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.LO",
            "cs.SC"
        ]
    },
    {
        "title": "The VLSAT-3 Benchmark Suite",
        "authors": [
            "Pierre Bouvier"
        ],
        "summary": "This report presents VLSAT-3 (an acronym for \"Very Large Boolean SATisfiability problems\"),the third part of a benchmark suite to be used in scientific experimentsand software competitions addressing SAT and SMT (Satisfiability Modulo Theories) solving issues.VLSAT-3 contains 1200 (600~satisfiable and 600~unsatisfiable) quantifier-free first-order logic formulasof increasing complexity, proposed in SMT-LIB format under a permissive Creative Commons license.More than 90% of these benchmarks have been used during the 16th International Satisfiability Modulo TheoriesCompetition (SMT-COMP~2021).",
        "published": "2021-12-07T13:23:51Z",
        "link": "http://arxiv.org/abs/2112.03675v1",
        "categories": [
            "cs.DS",
            "cs.FL",
            "cs.SC"
        ]
    },
    {
        "title": "Explicit Bounds for Linear Forms in the Exponentials of Algebraic   Numbers",
        "authors": [
            "Cheng-Chao Huang"
        ],
        "summary": "In this paper, we study linear forms \\[\\lambda = \\beta_1\\mathrm{e}^{\\alpha_1}+\\cdots+\\beta_m\\mathrm{e}^{\\alpha_m},\\] where $\\alpha_i$ and $\\beta_i$ are algebraic numbers. An explicit lower bound for the absolute value of $\\lambda$ is proved, which is derived from \"th\\'eor\\`eme de Lindemann--Weierstrass effectif\" via constructive methods in algebraic computation. Besides, the existence of $\\lambda$ with an explicit upper bound is established on the result of counting algebraic numbers.",
        "published": "2021-12-09T15:58:04Z",
        "link": "http://arxiv.org/abs/2112.05004v2",
        "categories": [
            "math.NT",
            "cs.CC",
            "cs.SC"
        ]
    },
    {
        "title": "Polynomial XL: A Variant of the XL Algorithm Using Macaulay Matrices   over Polynomial Rings",
        "authors": [
            "Hiroki Furue",
            "Momonari Kudo"
        ],
        "summary": "Solving a system of $m$ multivariate quadratic equations in $n$ variables over finite fields (the MQ problem) is one of the important problems in the theory of computer science. The XL algorithm (XL for short) is a major approach for solving the MQ problem with linearization over a coefficient field. Furthermore, the hybrid approach with XL (h-XL) is a variant of XL guessing some variables beforehand. In this paper, we present a variant of h-XL, which we call the \\textit{polynomial XL (PXL)}. In PXL, the whole $n$ variables are divided into $k$ variables to be fixed and the remaining $n-k$ variables as ``main variables'', and we generate a Macaulay matrix with respect to the $n-k$ main variables over a polynomial ring of the $k$ (sub-)variables. By eliminating some columns of the Macaulay matrix over the polynomial ring before guessing $k$ variables, the amount of operations required for each guessed value can be reduced compared with h-XL. Our complexity analysis of PXL (under some practical assumptions and heuristics) gives a new theoretical bound, and it indicates that PXL could be more efficient than other algorithms in theory on the random system with $n=m$, which is the case of general multivariate signatures. For example, on systems over the finite field with ${2^8}$ elements with $n=m=80$, the numbers of operations deduced from the theoretical bounds of the hybrid approaches with XL and Wiedemann XL, Crossbred, and PXL with optimal $k$ are estimated as $2^{252}$, $2^{234}$, $2^{237}$, and $2^{220}$, respectively.",
        "published": "2021-12-09T16:30:48Z",
        "link": "http://arxiv.org/abs/2112.05023v2",
        "categories": [
            "cs.SC",
            "cs.CR",
            "math.AC"
        ]
    },
    {
        "title": "Solving degree, last fall degree, and related invariants",
        "authors": [
            "Alessio Caminata",
            "Elisa Gorla"
        ],
        "summary": "In this paper we study and relate several invariants connected to the solving degree of a polynomial system. This provides a rigorous framework for estimating the complexity of solving a system of polynomial equations via Groebner bases methods. Our main results include a connection between the solving degree and the last fall degree and one between the degree of regularity and the Castelnuovo-Mumford regularity.",
        "published": "2021-12-10T14:46:11Z",
        "link": "http://arxiv.org/abs/2112.05579v2",
        "categories": [
            "cs.CR",
            "cs.SC",
            "math.AC"
        ]
    },
    {
        "title": "Stability of Cournot duopoly games with isoelastic demands and quadratic   costs",
        "authors": [
            "Xiaoliang Li",
            "Li Su"
        ],
        "summary": "In this discussion draft, we explore different duopoly games of players with quadratic costs, where the market is supposed to have the isoelastic demand. Different from the usual approaches based on numerical computations, the methods used in the present work are built on symbolic computations, which can produce analytical and rigorous results. Our investigations show that the stability regions are enlarged for the games considered in this work compared to their counterparts with linear costs, which generalizes the classical results of \"F. M. Fisher. The stability of the Cournot oligopoly solution: The effects of speeds of adjustment and increasing marginal costs. The Review of Economic Studies, 28(2):125--135, 1961.\".",
        "published": "2021-12-11T10:52:07Z",
        "link": "http://arxiv.org/abs/2112.05948v2",
        "categories": [
            "cs.SC",
            "econ.TH",
            "math.DS"
        ]
    },
    {
        "title": "Analysis of stability and bifurcation for two heterogeneous triopoly   games with the isoelastic demand",
        "authors": [
            "Xiaoliang Li"
        ],
        "summary": "In this paper, we investigate two heterogeneous triopoly games where the demand function of the market is isoelastic. The local stability and the bifurcation of these games are systematically analyzed using the symbolic approach proposed by the author. The novelty of the present work is twofold. On one hand, the results of this paper are analytical, which are different from the existing results in the literature based on observations through numerical simulations. In particular, we rigorously prove the existence of double routes to chaos through the period-doubling bifurcation and through the Neimark-Sacker bifurcation. On the other hand, for the special case of the involved firms having identical marginal costs, we acquire the necessary and sufficient conditions of the local stability for both models. By further analyzing these conditions, it seems that that the presence of the local monopolistic approximation (LMA) mechanism might have a stabilizing effect for heterogeneous triopoly games with the isoelastic demand.",
        "published": "2021-12-11T11:01:20Z",
        "link": "http://arxiv.org/abs/2112.05950v1",
        "categories": [
            "math.DS",
            "cs.SC",
            "econ.TH"
        ]
    },
    {
        "title": "Proceedings Twelfth International Workshop on Graph Computational Models",
        "authors": [
            "Berthold Hoffmann",
            "Mark Minas"
        ],
        "summary": "This volume contains the post-proceedings of the Twelfth International Workshop on Graph Computation Models (GCM 2021). The workshop was part of STAF 2021 (Software Technologies: Applications and Foundations) as an online-workshop on 22nd June 2021.   Graphs are common mathematical structures that are visual and intuitive. They constitute a natural and seamless way for system modelling in science, engineering and beyond, including computer science, biology, business process modelling, etc. Graph computation models constitute a class of very high-level models where graphs are first-class citizens. The aim of the International GCM Workshop series is to bring together researchers interested in all aspects of computation models based on graphs and graph transformation. It promotes the cross-fertilizing exchange of ideas and experiences among senior and young researchers from the different communities interested in the foundations, applications, and implementations of graph computation models and related areas.",
        "published": "2021-12-19T18:24:10Z",
        "link": "http://arxiv.org/abs/2112.10217v1",
        "categories": [
            "cs.FL",
            "cs.SC"
        ]
    },
    {
        "title": "Marginal Independence Models",
        "authors": [
            "Tobias Boege",
            "Sonja Petrović",
            "Bernd Sturmfels"
        ],
        "summary": "We impose rank one constraints on marginalizations of a tensor, given by a simplicial complex. Following work of Kirkup and Sullivant, such marginal independence models can be made toric by a linear change of coordinates. We study their toric ideals, with emphasis on random graph models and independent set polytopes of matroids. We develop the numerical algebra of parameter estimation, using both Euclidean distance and maximum likelihood, and we present a comprehensive database of small models.",
        "published": "2021-12-19T23:58:17Z",
        "link": "http://arxiv.org/abs/2112.10287v2",
        "categories": [
            "math.ST",
            "cs.SC",
            "math.AG",
            "math.OC",
            "stat.TH",
            "62R01"
        ]
    },
    {
        "title": "The complexity of solving Weil restriction systems",
        "authors": [
            "Alessio Caminata",
            "Michela Ceria",
            "Elisa Gorla"
        ],
        "summary": "The solving degree of a system of multivariate polynomial equations provides an upper bound for the complexity of computing the solutions of the system via Groebner bases methods. In this paper, we consider polynomial systems that are obtained via Weil restriction of scalars. The latter is an arithmetic construction which, given a finite Galois field extension $k\\hookrightarrow K$, associates to a system $\\mathcal{F}$ defined over $K$ a system $\\mathrm{Weil}(\\mathcal{F})$ defined over $k$, in such a way that the solutions of $\\mathcal{F}$ over $K$ and those of $\\mathrm{Weil}(\\mathcal{F})$ over $k$ are in natural bijection. In this paper, we find upper bounds for the complexity of solving a polynomial system $\\mathrm{Weil}(\\mathcal{F})$ obtained via Weil restriction in terms of algebraic invariants of the system $\\mathcal{F}$.",
        "published": "2021-12-20T12:59:50Z",
        "link": "http://arxiv.org/abs/2112.10506v2",
        "categories": [
            "cs.CR",
            "cs.SC",
            "math.AC"
        ]
    },
    {
        "title": "FuSeBMC v.4: Smart Seed Generation for Hybrid Fuzzing",
        "authors": [
            "Kaled M. Alshmrany",
            "Mohannad Aldughaim",
            "Ahmed Bhayat",
            "Lucas C. Cordeiro"
        ],
        "summary": "FuSeBMC is a test generator for finding security vulnerabilities in C programs. In earlier work [4], we described a previous version that incrementally injected labels to guide Bounded Model Checking (BMC) and Evolutionary Fuzzing engines to produce test cases for code coverage and bug finding. This paper introduces a new version of FuSeBMC that utilizes both engines to produce smart seeds. First, the engines are run with a short time limit on a lightly instrumented version of the program to produce the seeds. The BMC engine is particularly useful in producing seeds that can pass through complex mathematical guards. Then, FuSeBMC runs its engines with more extended time limits using the smart seeds created in the previous round. FuSeBMC manages this process in two main ways using its Tracer subsystem. Firstly, it uses shared memory to record the labels covered by each test case. Secondly, it evaluates test cases, and those of high impact are turned into seeds for subsequent test fuzzing. As a result, we significantly increased our code coverage score from last year, outperforming all tools that participated in this year's competition in every single category.",
        "published": "2021-12-20T15:41:57Z",
        "link": "http://arxiv.org/abs/2112.10627v1",
        "categories": [
            "cs.CR",
            "cs.CY",
            "cs.SC",
            "cs.SE"
        ]
    },
    {
        "title": "An ASP-based Approach to Answering Natural Language Questions for Texts",
        "authors": [
            "Dhruva Pendharkar",
            "Kinjal Basu",
            "Farhad Shakerin",
            "Gopal Gupta"
        ],
        "summary": "An approach based on answer set programming (ASP) is proposed in this paper for representing knowledge generated from natural language texts. Knowledge in a text is modeled using a Neo Davidsonian-like formalism, which is then represented as an answer set program. Relevant commonsense knowledge is additionally imported from resources such as WordNet and represented in ASP. The resulting knowledge-base can then be used to perform reasoning with the help of an ASP system. This approach can facilitate many natural language tasks such as automated question answering, text summarization, and automated question generation. ASP-based representation of techniques such as default reasoning, hierarchical knowledge organization, preferences over defaults, etc., are used to model commonsense reasoning methods required to accomplish these tasks. In this paper, we describe the CASPR system that we have developed to automate the task of answering natural language questions given English text. CASPR can be regarded as a system that answers questions by \"understanding\" the text and has been tested on the SQuAD data set, with promising results.",
        "published": "2021-12-21T14:13:06Z",
        "link": "http://arxiv.org/abs/2112.11241v1",
        "categories": [
            "cs.CL",
            "cs.LO",
            "cs.SC"
        ]
    },
    {
        "title": "Analytical Modelling of Exoplanet Transit Specroscopy with Dimensional   Analysis and Symbolic Regression",
        "authors": [
            "Konstantin T. Matchev",
            "Katia Matcheva",
            "Alexander Roman"
        ],
        "summary": "The physical characteristics and atmospheric chemical composition of newly discovered exoplanets are often inferred from their transit spectra which are obtained from complex numerical models of radiative transfer. Alternatively, simple analytical expressions provide insightful physical intuition into the relevant atmospheric processes. The deep learning revolution has opened the door for deriving such analytical results directly with a computer algorithm fitting to the data. As a proof of concept, we successfully demonstrate the use of symbolic regression on synthetic data for the transit radii of generic hot Jupiter exoplanets to derive a corresponding analytical formula. As a preprocessing step, we use dimensional analysis to identify the relevant dimensionless combinations of variables and reduce the number of independent inputs, which improves the performance of the symbolic regression. The dimensional analysis also allowed us to mathematically derive and properly parametrize the most general family of degeneracies among the input atmospheric parameters which affect the characterization of an exoplanet atmosphere through transit spectroscopy.",
        "published": "2021-12-22T00:52:56Z",
        "link": "http://arxiv.org/abs/2112.11600v1",
        "categories": [
            "astro-ph.EP",
            "cs.LG",
            "cs.SC",
            "physics.data-an"
        ]
    },
    {
        "title": "An algebraic attack on stream ciphers with application to nonlinear   filter generators and WG-PRNG",
        "authors": [
            "Carla Mascia",
            "Enrico Piccione",
            "Massimiliano Sala"
        ],
        "summary": "In this paper, we propose a new algebraic attack on stream ciphers. Starting from the well-known attack due to Courtois and Meier, we design an attack especially effective against nonlinear filter generators. We test it on two toy stream ciphers and we show that the level of security of one of stream ciphers submitted to the NIST competition on Lightweight Cryptography, WG-PRNG, is less than that stated before now.",
        "published": "2021-12-22T23:13:45Z",
        "link": "http://arxiv.org/abs/2112.12268v3",
        "categories": [
            "cs.CR",
            "cs.SC",
            "94A60, 13P10, 11T71, 06E30",
            "E.3"
        ]
    },
    {
        "title": "Stability analysis of heterogeneous oligopoly games of increasing   players with quadratic costs",
        "authors": [
            "Xiaoliang Li"
        ],
        "summary": "In this discussion draft, we explore heterogeneous oligopoly games of increasing players with quadratic costs, where the market is supposed to have the isoelastic demand. For each of the models considered in this draft, we analytically investigate the necessary and sufficient condition of the local stability of its positive equilibrium. Furthermore, we rigorously prove that the stability regions are enlarged as the number of involved firms is increasing.",
        "published": "2021-12-24T03:52:20Z",
        "link": "http://arxiv.org/abs/2112.13844v1",
        "categories": [
            "econ.TH",
            "cs.SC",
            "math.DS"
        ]
    },
    {
        "title": "Automated Code Optimization with E-Graphs",
        "authors": [
            "Alessandro Cheli"
        ],
        "summary": "This thesis proposes an advanced, generic and high-level code rewriting and analysis system in the Julia programming language, providing applied equality saturation in the presence of multiple dispatch and metaprogramming. We show how our system can practically solve some challenging problems: Can programmers implement their own high-level compiler optimizations for their domain-specific scientific programs, without the requirement of them being compiler experts at all? Can these optimizers be implemented by users in the same language and inside the same programs they want to optimize, solving the two-language problem? Can these compiler optimizers be written in a high-level fashion, as equations, without the need to worry about the rewriting ordering? Thus, can symbolic mathematics do high-level compiler optimizations or vice-versa?",
        "published": "2021-12-26T12:49:18Z",
        "link": "http://arxiv.org/abs/2112.14714v2",
        "categories": [
            "cs.PL",
            "cs.SC",
            "I.1.0; I.1.2; I.1.3; D.3.2; D.3.3; D.3.4"
        ]
    },
    {
        "title": "Proceedings of the 13th International Conference on Automated Deduction   in Geometry",
        "authors": [
            "Predrag Janičić",
            "Zoltán Kovács"
        ],
        "summary": "Automated Deduction in Geometry (ADG) is a forum to exchange ideas and views, to present research results and progress, and to demonstrate software tools at the intersection between geometry and automated deduction. Relevant topics include (but are not limited to): polynomial algebra, invariant and coordinate-free methods; probabilistic, synthetic, and logic approaches, techniques for automated geometric reasoning from discrete mathematics, combinatorics, and numerics; interactive theorem proving in geometry; symbolic and numeric methods for geometric computation, geometric constraint solving, automated generation/reasoning and manipulation with diagrams; design and implementation of geometry software, automated theorem provers, special-purpose tools, experimental studies; applications of ADG in mechanics, geometric modelling, CAGD/CAD, computer vision, robotics and education.   Traditionally, the ADG conference is held every two years. The previous editions of ADG were held in Nanning in 2018, Strasbourg in 2016, Coimbra in 2014, Edinburgh in 2012, Munich in 2010, Shanghai in 2008, Pontevedra in 2006, Gainesville in 2004, Hagenberg in 2002, Zurich in 2000, Beijing in 1998, and Toulouse in 1996. The 13th edition of ADG was supposed to be held in 2020 in Hagenberg, Austria, but due to the COVID-19 pandemic, it was postponed for 2021, and held online (still hosted by RISC Institute, Hagenberg, Austria), September 15-17, 2021 (https://www.risc.jku.at/conferences/adg2021).",
        "published": "2021-12-28T21:56:13Z",
        "link": "http://arxiv.org/abs/2112.14770v1",
        "categories": [
            "cs.AI",
            "cs.LO",
            "cs.MS",
            "cs.SC"
        ]
    },
    {
        "title": "Subresultant of several univariate polynomials",
        "authors": [
            "Hoon Hong",
            "Jing Yang"
        ],
        "summary": "Subresultant of two univariate polynomials is a fundamental object in computational algebra and geometry with many applications (for instance, parametric GCD and parametric multiplicity of roots). In this paper, we generalize the theory of subresultants of two polynomials to arbitrary number of polynomials, resulting in multi-polynomial subresultants. Specifically,   1. we propose a definition of multi-polynomial subresultants, which is an expression in terms of roots;   2. we illustrate the usefulness of the proposed definition via the following two fundamental applications:   - parametric GCD of multi-polynomials, and   - parametric multiplicity of roots of a polynomial;   3. we provide several expressions for the multi-polynomials subresultants in terms of coefficients, for computation.",
        "published": "2021-12-31T10:20:52Z",
        "link": "http://arxiv.org/abs/2112.15370v4",
        "categories": [
            "cs.SC",
            "math.AC",
            "math.AG"
        ]
    }
]