[
    {
        "title": "Modelling Cournot Games as Multi-agent Multi-armed Bandits",
        "authors": [
            "Kshitija Taywade",
            "Brent Harrison",
            "Adib Bagh"
        ],
        "summary": "We investigate the use of a multi-agent multi-armed bandit (MA-MAB) setting for modeling repeated Cournot oligopoly games, where the firms acting as agents choose from the set of arms representing production quantity (a discrete value). Agents interact with separate and independent bandit problems. In this formulation, each agent makes sequential choices among arms to maximize its own reward. Agents do not have any information about the environment; they can only see their own rewards after taking an action. However, the market demand is a stationary function of total industry output, and random entry or exit from the market is not allowed. Given these assumptions, we found that an $\\epsilon$-greedy approach offers a more viable learning mechanism than other traditional MAB approaches, as it does not require any additional knowledge of the system to operate. We also propose two novel approaches that take advantage of the ordered action space: $\\epsilon$-greedy+HL and $\\epsilon$-greedy+EL. These new approaches help firms to focus on more profitable actions by eliminating less profitable choices and hence are designed to optimize the exploration. We use computer simulations to study the emergence of various equilibria in the outcomes and do the empirical analysis of joint cumulative regrets.",
        "published": "2022-01-01T22:02:47Z",
        "link": "http://arxiv.org/abs/2201.01182v1",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "econ.EM"
        ]
    },
    {
        "title": "Algorithm-Level Confidentiality for Average Consensus on Time-Varying   Directed Graphs",
        "authors": [
            "Huan Gao",
            "Yongqiang Wang"
        ],
        "summary": "Average consensus plays a key role in distributed networks, with applications ranging from time synchronization, information fusion, load balancing, to decentralized control. Existing average consensus algorithms require individual agents to exchange explicit state values with their neighbors, which leads to the undesirable disclosure of sensitive information in the state. In this paper, we propose a novel average consensus algorithm for time-varying directed graphs that can protect the confidentiality of a participating agent against other participating agents. The algorithm injects randomness in interaction to obfuscate information on the algorithm-level and can ensure information-theoretic privacy without the assistance of any trusted third party or data aggregator. By leveraging the inherent robustness of consensus dynamics against random variations in interaction, our proposed algorithm can also guarantee the accuracy of average consensus. The algorithm is distinctly different from differential-privacy based average consensus approaches which enable confidentiality through compromising accuracy in obtained consensus value. Numerical simulations confirm the effectiveness and efficiency of our proposed approach.",
        "published": "2022-01-02T05:07:08Z",
        "link": "http://arxiv.org/abs/2201.00293v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Primal-Dual Method for Optimization Problems with Changing Constraints",
        "authors": [
            "Igor Konnov"
        ],
        "summary": "We propose a modified primal-dual method for general convex optimization problems with changing constraints. We obtain properties of Lagrangian saddle points for these problems which enable us to establish convergence of the proposed method. We describe specializations of the proposed approach to multi-agent optimization problems under changing communication topology and to feasibility problems.",
        "published": "2022-01-02T11:09:37Z",
        "link": "http://arxiv.org/abs/2201.00334v1",
        "categories": [
            "math.OC",
            "cs.DC",
            "cs.MA",
            "65K05, 90C06, 90C25, 68M14, 68W15, 93A14"
        ]
    },
    {
        "title": "Using Non-Stationary Bandits for Learning in Repeated Cournot Games with   Non-Stationary Demand",
        "authors": [
            "Kshitija Taywade",
            "Brent Harrison",
            "Judy Goldsmith"
        ],
        "summary": "Many past attempts at modeling repeated Cournot games assume that demand is stationary. This does not align with real-world scenarios in which market demands can evolve over a product's lifetime for a myriad of reasons. In this paper, we model repeated Cournot games with non-stationary demand such that firms/agents face separate instances of non-stationary multi-armed bandit problem. The set of arms/actions that an agent can choose from represents discrete production quantities; here, the action space is ordered. Agents are independent and autonomous, and cannot observe anything from the environment; they can only see their own rewards after taking an action, and only work towards maximizing these rewards. We propose a novel algorithm 'Adaptive with Weighted Exploration (AWE) $\\epsilon$-greedy' which is remotely based on the well-known $\\epsilon$-greedy approach. This algorithm detects and quantifies changes in rewards due to varying market demand and varies learning rate and exploration rate in proportion to the degree of changes in demand, thus enabling agents to better identify new optimal actions. For efficient exploration, it also deploys a mechanism for weighing actions that takes advantage of the ordered action space. We use simulations to study the emergence of various equilibria in the market. In addition, we study the scalability of our approach in terms number of total agents in the system and the size of action space. We consider both symmetric and asymmetric firms in our models. We found that using our proposed method, agents are able to swiftly change their course of action according to the changes in demand, and they also engage in collusive behavior in many simulations.",
        "published": "2022-01-03T05:51:47Z",
        "link": "http://arxiv.org/abs/2201.00486v1",
        "categories": [
            "cs.LG",
            "cs.GT",
            "cs.MA",
            "econ.GN",
            "q-fin.EC"
        ]
    },
    {
        "title": "3DPG: Distributed Deep Deterministic Policy Gradient Algorithms for   Networked Multi-Agent Systems",
        "authors": [
            "Adrian Redder",
            "Arunselvan Ramaswamy",
            "Holger Karl"
        ],
        "summary": "We present Distributed Deep Deterministic Policy Gradient (3DPG), a multi-agent actor-critic (MAAC) algorithm for Markov games. Unlike previous MAAC algorithms, 3DPG is fully distributed during both training and deployment. 3DPG agents calculate local policy gradients based on the most recently available local data (states, actions) and local policies of other agents. During training, this information is exchanged using a potentially lossy and delaying communication network. The network therefore induces Age of Information (AoI) for data and policies. We prove the asymptotic convergence of 3DPG even in the presence of potentially unbounded Age of Information (AoI). This provides an important step towards practical online and distributed multi-agent learning since 3DPG does not assume information to be available deterministically. We analyze 3DPG in the presence of policy and data transfer under mild practical assumptions. Our analysis shows that 3DPG agents converge to a local Nash equilibrium of Markov games in terms of utility functions expressed as the expected value of the agents local approximate action-value functions (Q-functions). The expectations of the local Q-functions are with respect to limiting distributions over the global state-action space shaped by the agents' accumulated local experiences. Our results also shed light on the policies obtained by general MAAC algorithms. We show through a heuristic argument and numerical experiments that 3DPG improves convergence over previous MAAC algorithms that use old actions instead of old policies during training. Further, we show that 3DPG is robust to AoI; it learns competitive policies even with large AoI and low data availability.",
        "published": "2022-01-03T10:33:52Z",
        "link": "http://arxiv.org/abs/2201.00570v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "A Deeper Understanding of State-Based Critics in Multi-Agent   Reinforcement Learning",
        "authors": [
            "Xueguang Lyu",
            "Andrea Baisero",
            "Yuchen Xiao",
            "Christopher Amato"
        ],
        "summary": "Centralized Training for Decentralized Execution, where training is done in a centralized offline fashion, has become a popular solution paradigm in Multi-Agent Reinforcement Learning. Many such methods take the form of actor-critic with state-based critics, since centralized training allows access to the true system state, which can be useful during training despite not being available at execution time. State-based critics have become a common empirical choice, albeit one which has had limited theoretical justification or analysis. In this paper, we show that state-based critics can introduce bias in the policy gradient estimates, potentially undermining the asymptotic guarantees of the algorithm. We also show that, even if the state-based critics do not introduce any bias, they can still result in a larger gradient variance, contrary to the common intuition. Finally, we show the effects of the theories in practice by comparing different forms of centralized critics on a wide range of common benchmarks, and detail how various environmental properties are related to the effectiveness of different types of critics.",
        "published": "2022-01-03T14:51:30Z",
        "link": "http://arxiv.org/abs/2201.01221v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Modeling Human Driver Interactions Using an Infinite Policy Space   Through Gaussian Processes",
        "authors": [
            "Cem Okan Yaldiz",
            "Yildiray Yildiz"
        ],
        "summary": "This paper proposes a method for modeling human driver interactions that relies on multi-output gaussian processes. The proposed method is developed as a refinement of the game theoretical hierarchical reasoning approach called \"level-k reasoning\" which conventionally assigns discrete levels of behaviors to agents. Although it is shown to be an effective modeling tool, the level-k reasoning approach may pose undesired constraints for predicting human decision making due to a limited number (usually 2 or 3) of driver policies it extracts. The proposed approach is put forward to fill this gap in the literature by introducing a continuous domain framework that enables an infinite policy space. By using the approach presented in this paper, more accurate driver models can be obtained, which can then be employed for creating high fidelity simulation platforms for the validation of autonomous vehicle control algorithms. The proposed method is validated on a real traffic dataset and compared with the conventional level-k approach to demonstrate its contributions and implications.",
        "published": "2022-01-03T17:45:58Z",
        "link": "http://arxiv.org/abs/2201.01733v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Learning Complex Spatial Behaviours in ABM: An Experimental   Observational Study",
        "authors": [
            "Sedar Olmez",
            "Dan Birks",
            "Alison Heppenstall"
        ],
        "summary": "Capturing and simulating intelligent adaptive behaviours within spatially explicit individual-based models remains an ongoing challenge for researchers. While an ever-increasing abundance of real-world behavioural data are collected, few approaches exist that can quantify and formalise key individual behaviours and how they change over space and time. Consequently, commonly used agent decision-making frameworks, such as event-condition-action rules, are often required to focus only on a narrow range of behaviours. We argue that these behavioural frameworks often do not reflect real-world scenarios and fail to capture how behaviours can develop in response to stimuli. There has been an increased interest in Machine Learning methods and their potential to simulate intelligent adaptive behaviours in recent years. One method that is beginning to gain traction in this area is Reinforcement Learning (RL). This paper explores how RL can be applied to create emergent agent behaviours using a simple predator-prey Agent-Based Model (ABM). Running a series of simulations, we demonstrate that agents trained using the novel Proximal Policy Optimisation (PPO) algorithm behave in ways that exhibit properties of real-world intelligent adaptive behaviours, such as hiding, evading and foraging.",
        "published": "2022-01-04T11:56:11Z",
        "link": "http://arxiv.org/abs/2201.01099v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Value Functions Factorization with Latent State Information Sharing in   Decentralized Multi-Agent Policy Gradients",
        "authors": [
            "Hanhan Zhou",
            "Tian Lan",
            "Vaneet Aggarwal"
        ],
        "summary": "Value function factorization via centralized training and decentralized execution is promising for solving cooperative multi-agent reinforcement tasks. One of the approaches in this area, QMIX, has become state-of-the-art and achieved the best performance on the StarCraft II micromanagement benchmark. However, the monotonic-mixing of per agent estimates in QMIX is known to restrict the joint action Q-values it can represent, as well as the insufficient global state information for single agent value function estimation, often resulting in suboptimality. To this end, we present LSF-SAC, a novel framework that features a variational inference-based information-sharing mechanism as extra state information to assist individual agents in the value function factorization. We demonstrate that such latent individual state information sharing can significantly expand the power of value function factorization, while fully decentralized execution can still be maintained in LSF-SAC through a soft-actor-critic design. We evaluate LSF-SAC on the StarCraft II micromanagement challenge and demonstrate that it outperforms several state-of-the-art methods in challenging collaborative tasks. We further set extensive ablation studies for locating the key factors accounting for its performance improvements. We believe that this new insight can lead to new local value estimation methods and variational deep learning algorithms. A demo video and code of implementation can be found at https://sites.google.com/view/sacmm.",
        "published": "2022-01-04T17:05:07Z",
        "link": "http://arxiv.org/abs/2201.01247v3",
        "categories": [
            "cs.MA",
            "cs.LG"
        ]
    },
    {
        "title": "Conditional Imitation Learning for Multi-Agent Games",
        "authors": [
            "Andy Shih",
            "Stefano Ermon",
            "Dorsa Sadigh"
        ],
        "summary": "While advances in multi-agent learning have enabled the training of increasingly complex agents, most existing techniques produce a final policy that is not designed to adapt to a new partner's strategy. However, we would like our AI agents to adjust their strategy based on the strategies of those around them. In this work, we study the problem of conditional multi-agent imitation learning, where we have access to joint trajectory demonstrations at training time, and we must interact with and adapt to new partners at test time. This setting is challenging because we must infer a new partner's strategy and adapt our policy to that strategy, all without knowledge of the environment reward or dynamics. We formalize this problem of conditional multi-agent imitation learning, and propose a novel approach to address the difficulties of scalability and data scarcity. Our key insight is that variations across partners in multi-agent games are often highly structured, and can be represented via a low-rank subspace. Leveraging tools from tensor decomposition, our model learns a low-rank subspace over ego and partner agent strategies, then infers and adapts to a new partner strategy by interpolating in the subspace. We experiments with a mix of collaborative tasks, including bandits, particle, and Hanabi environments. Additionally, we test our conditional policies against real human partners in a user study on the Overcooked game. Our model adapts better to new partners compared to baselines, and robustly handles diverse settings ranging from discrete/continuous actions and static/online evaluation with AI/human partners.",
        "published": "2022-01-05T04:40:13Z",
        "link": "http://arxiv.org/abs/2201.01448v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Offsetting Unequal Competition through RL-assisted Incentive Schemes",
        "authors": [
            "Paramita Koley",
            "Aurghya Maiti",
            "Sourangshu Bhattacharya",
            "Niloy Ganguly"
        ],
        "summary": "This paper investigates the dynamics of competition among organizations with unequal expertise. Multi-agent reinforcement learning has been used to simulate and understand the impact of various incentive schemes designed to offset such inequality. We design Touch-Mark, a game based on well-known multi-agent-particle-environment, where two teams (weak, strong) with unequal but changing skill levels compete against each other. For training such a game, we propose a novel controller assisted multi-agent reinforcement learning algorithm \\our\\, which empowers each agent with an ensemble of policies along with a supervised controller that by selectively partitioning the sample space, triggers intelligent role division among the teammates. Using C-MADDPG as an underlying framework, we propose an incentive scheme for the weak team such that the final rewards of both teams become the same. We find that in spite of the incentive, the final reward of the weak team falls short of the strong team. On inspecting, we realize that an overall incentive scheme for the weak team does not incentivize the weaker agents within that team to learn and improve. To offset this, we now specially incentivize the weaker player to learn and as a result, observe that the weak team beyond an initial phase performs at par with the stronger team. The final goal of the paper has been to formulate a dynamic incentive scheme that continuously balances the reward of the two teams. This is achieved by devising an incentive scheme enriched with an RL agent which takes minimum information from the environment.",
        "published": "2022-01-05T04:47:22Z",
        "link": "http://arxiv.org/abs/2201.01450v1",
        "categories": [
            "cs.GT",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Handling Trust in A Cloud Based Multi Agent System",
        "authors": [
            "Imen Bouabdallah",
            "Hakima Mellah"
        ],
        "summary": "Cloud computing is an opened and distributed network that guarantees access to a large amount of data and IT infrastructure at several levels (software, hardware...). With the increase demand, handling clients' needs is getting increasingly challenging. Responding to all requesting clients could lead to security breaches, and since it is the provider's responsibility to secure not only the offered cloud services but also the data, it is important to ensure clients reliability. Although filtering clients in the cloud is not so common, it is required to assure cloud safety.   In this paper, by implementing multi agent systems in the cloud to handle interactions for the providers, trust is introduced at agent level to filtrate the clients asking for services by using Particle Swarm Optimization and acquaintance knowledge to determine malicious and untrustworthy clients. The selection depends on previous knowledge and overall rating of trusted peers. The conducted experiments show that the model outputs relevant results, and even with a small number of peers, the framework is able to converge to the best solution. The model presented in this paper is a part of ongoing work to adapt interactions in the cloud.",
        "published": "2022-01-05T20:25:16Z",
        "link": "http://arxiv.org/abs/2201.01807v2",
        "categories": [
            "cs.MA",
            "cs.DB",
            "cs.SI"
        ]
    },
    {
        "title": "Privacy-Friendly Peer-to-Peer Energy Trading: A Game Theoretical   Approach",
        "authors": [
            "Kamil Erdayandi",
            "Amrit Paudel",
            "Lucas Cordeiro",
            "Mustafa A. Mustafa"
        ],
        "summary": "In this paper, we propose a decentralized, privacy-friendly energy trading platform (PFET) based on game theoretical approach - specifically Stackelberg competition. Unlike existing trading schemes, PFET provides a competitive market in which prices and demands are determined based on competition, and computations are performed in a decentralized manner which does not rely on trusted third parties. It uses homomorphic encryption cryptosystem to encrypt sensitive information of buyers and sellers such as sellers$'$ prices and buyers$'$ demands. Buyers calculate total demand on particular seller using an encrypted data and sensitive buyer profile data is hidden from sellers. Hence, privacy of both sellers and buyers is preserved. Through privacy analysis and performance evaluation, we show that PFET preserves users$'$ privacy in an efficient manner.",
        "published": "2022-01-05T20:41:32Z",
        "link": "http://arxiv.org/abs/2201.01810v2",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.CR",
            "cs.MA",
            "E.3; I.2.11"
        ]
    },
    {
        "title": "Hidden Agenda: a Social Deduction Game with Diverse Learned Equilibria",
        "authors": [
            "Kavya Kopparapu",
            "Edgar A. Duéñez-Guzmán",
            "Jayd Matyas",
            "Alexander Sasha Vezhnevets",
            "John P. Agapiou",
            "Kevin R. McKee",
            "Richard Everett",
            "Janusz Marecki",
            "Joel Z. Leibo",
            "Thore Graepel"
        ],
        "summary": "A key challenge in the study of multiagent cooperation is the need for individual agents not only to cooperate effectively, but to decide with whom to cooperate. This is particularly critical in situations when other agents have hidden, possibly misaligned motivations and goals. Social deduction games offer an avenue to study how individuals might learn to synthesize potentially unreliable information about others, and elucidate their true motivations. In this work, we present Hidden Agenda, a two-team social deduction game that provides a 2D environment for studying learning agents in scenarios of unknown team alignment. The environment admits a rich set of strategies for both teams. Reinforcement learning agents trained in Hidden Agenda show that agents can learn a variety of behaviors, including partnering and voting without need for communication in natural language.",
        "published": "2022-01-05T20:54:10Z",
        "link": "http://arxiv.org/abs/2201.01816v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Auction-Based Ex-Post-Payment Incentive Mechanism Design for Horizontal   Federated Learning with Reputation and Contribution Measurement",
        "authors": [
            "Jingwen Zhang",
            "Yuezhou Wu",
            "Rong Pan"
        ],
        "summary": "Federated learning trains models across devices with distributed data, while protecting the privacy and obtaining a model similar to that of centralized ML. A large number of workers with data and computing power are the foundation of federal learning. However, the inevitable costs prevent self-interested workers from serving for free. Moreover, due to data isolation, task publishers lack effective methods to select, evaluate and pay reliable workers with high-quality data. Therefore, we design an auction-based incentive mechanism for horizontal federated learning with reputation and contribution measurement. By designing a reasonable method of measuring contribution, we establish the reputation of workers, which is easy to decline and difficult to improve. Through reverse auctions, workers bid for tasks, and the task publisher selects workers combining reputation and bid price. With the budget constraint, winning workers are paid based on performance. We proved that our mechanism satisfies the individual rationality of the honest worker, budget feasibility, truthfulness, and computational efficiency.",
        "published": "2022-01-07T11:44:20Z",
        "link": "http://arxiv.org/abs/2201.02410v2",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Deep Learnable Strategy Templates for Multi-Issue Bilateral Negotiation",
        "authors": [
            "Pallavi Bagga",
            "Nicola Paoletti",
            "Kostas Stathis"
        ],
        "summary": "We study how to exploit the notion of strategy templates to learn strategies for multi-issue bilateral negotiation. Each strategy template consists of a set of interpretable parameterized tactics that are used to decide an optimal action at any time. We use deep reinforcement learning throughout an actor-critic architecture to estimate the tactic parameter values for a threshold utility, when to accept an offer and how to generate a new bid. This contrasts with existing work that only estimates the threshold utility for those tactics. We pre-train the strategy by supervision from the dataset collected using \"teacher strategies\", thereby decreasing the exploration time required for learning during negotiation. As a result, we build automated agents for multi-issue negotiations that can adapt to different negotiation domains without the need to be pre-programmed. We empirically show that our work outperforms the state-of-the-art in terms of the individual as well as social efficiency.",
        "published": "2022-01-07T14:00:42Z",
        "link": "http://arxiv.org/abs/2201.02455v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Distributed Cooperative Multi-Agent Reinforcement Learning with Directed   Coordination Graph",
        "authors": [
            "Gangshan Jing",
            "He Bai",
            "Jemin George",
            "Aranya Chakrabortty",
            "Piyush. K. Sharma"
        ],
        "summary": "Existing distributed cooperative multi-agent reinforcement learning (MARL) frameworks usually assume undirected coordination graphs and communication graphs while estimating a global reward via consensus algorithms for policy evaluation. Such a framework may induce expensive communication costs and exhibit poor scalability due to requirement of global consensus. In this work, we study MARLs with directed coordination graphs, and propose a distributed RL algorithm where the local policy evaluations are based on local value functions. The local value function of each agent is obtained by local communication with its neighbors through a directed learning-induced communication graph, without using any consensus algorithm. A zeroth-order optimization (ZOO) approach based on parameter perturbation is employed to achieve gradient estimation. By comparing with existing ZOO-based RL algorithms, we show that our proposed distributed RL algorithm guarantees high scalability. A distributed resource allocation example is shown to illustrate the effectiveness of our algorithm.",
        "published": "2022-01-10T04:14:46Z",
        "link": "http://arxiv.org/abs/2201.04962v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG",
            "cs.SY",
            "eess.SY",
            "math.OC"
        ]
    },
    {
        "title": "Resilient Consensus with Multi-hop Communication",
        "authors": [
            "Liwei Yuan",
            "Hideaki Ishii"
        ],
        "summary": "In this paper, we study the problem of resilient consensus for a multi-agent network where some of the nodes might be adversarial, attempting to prevent consensus by transmitting faulty values. Our approach is based on that of the so-called weighted mean subsequence reduced (W-MSR) algorithm with a special emphasis on its use in agents capable to communicate with multi-hop neighbors. The MSR algorithm is a powerful tool for achieving resilient consensus under minimal requirements for network structures, characterized by the class of robust graphs. Our analysis highlights that through multi-hop communication, the network connectivity can be reduced especially in comparison with the common one-hop communication case. Moreover, we analyze the multi-hop W-MSR algorithm with delays in communication since the values from different multi-hop neighbors may arrive at the agents at different time steps.",
        "published": "2022-01-10T08:46:37Z",
        "link": "http://arxiv.org/abs/2201.03214v1",
        "categories": [
            "cs.MA",
            "cs.DC",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Macroprogramming: Concepts, State of the Art, and Opportunities of   Macroscopic Behaviour Modelling",
        "authors": [
            "Roberto Casadei"
        ],
        "summary": "Macroprogramming refers to the theory and practice of conveniently expressing the macro(scopic) behaviour of a system using a single program. Macroprogramming approaches are motivated by the need of effectively capturing global/system-level aspects and the collective behaviour of a set of interacting components, while abstracting over low-level details. In the past, this style of programming has been primarily adopted to describe the data-processing logic in wireless sensor networks; recently, research forums on spatial computing, collective adaptive systems, and Internet-of-Things have provided renewed interest in macro-approaches. However, related contributions are still fragmented and lacking conceptual consistency. Therefore, to foster principled research, an integrated view of the field is provided, together with opportunities and challenges.",
        "published": "2022-01-10T17:17:54Z",
        "link": "http://arxiv.org/abs/2201.03473v1",
        "categories": [
            "cs.PL",
            "cs.DC",
            "cs.MA",
            "cs.SE",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Assisting Unknown Teammates in Unknown Tasks: Ad Hoc Teamwork under   Partial Observability",
        "authors": [
            "João G. Ribeiro",
            "Cassandro Martinho",
            "Alberto Sardinha",
            "Francisco S. Melo"
        ],
        "summary": "In this paper, we present a novel Bayesian online prediction algorithm for the problem setting of ad hoc teamwork under partial observability (ATPO), which enables on-the-fly collaboration with unknown teammates performing an unknown task without needing a pre-coordination protocol. Unlike previous works that assume a fully observable state of the environment, ATPO accommodates partial observability, using the agent's observations to identify which task is being performed by the teammates. Our approach assumes neither that the teammate's actions are visible nor an environment reward signal. We evaluate ATPO in three domains -- two modified versions of the Pursuit domain with partial observability and the overcooked domain. Our results show that ATPO is effective and robust in identifying the teammate's task from a large library of possible tasks, efficient at solving it in near-optimal time, and scalable in adapting to increasingly larger problem sizes.",
        "published": "2022-01-10T18:53:34Z",
        "link": "http://arxiv.org/abs/2201.03538v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Pavlovian Signalling with General Value Functions in Agent-Agent   Temporal Decision Making",
        "authors": [
            "Andrew Butcher",
            "Michael Bradley Johanson",
            "Elnaz Davoodi",
            "Dylan J. A. Brenneis",
            "Leslie Acker",
            "Adam S. R. Parker",
            "Adam White",
            "Joseph Modayil",
            "Patrick M. Pilarski"
        ],
        "summary": "In this paper, we contribute a multi-faceted study into Pavlovian signalling -- a process by which learned, temporally extended predictions made by one agent inform decision-making by another agent. Signalling is intimately connected to time and timing. In service of generating and receiving signals, humans and other animals are known to represent time, determine time since past events, predict the time until a future stimulus, and both recognize and generate patterns that unfold in time. We investigate how different temporal processes impact coordination and signalling between learning agents by introducing a partially observable decision-making domain we call the Frost Hollow. In this domain, a prediction learning agent and a reinforcement learning agent are coupled into a two-part decision-making system that works to acquire sparse reward while avoiding time-conditional hazards. We evaluate two domain variations: machine agents interacting in a seven-state linear walk, and human-machine interaction in a virtual-reality environment. Our results showcase the speed of learning for Pavlovian signalling, the impact that different temporal representations do (and do not) have on agent-agent coordination, and how temporal aliasing impacts agent-agent and human-agent interactions differently. As a main contribution, we establish Pavlovian signalling as a natural bridge between fixed signalling paradigms and fully adaptive communication learning between two agents. We further show how to computationally build this adaptive signalling process out of a fixed signalling process, characterized by fast continual prediction learning and minimal constraints on the nature of the agent receiving signals. Our results therefore suggest an actionable, constructivist path towards communication learning between reinforcement learning agents.",
        "published": "2022-01-11T00:14:04Z",
        "link": "http://arxiv.org/abs/2201.03709v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "A Negotiating Strategy for a Hybrid Goal Function in Multilateral   Negotiation",
        "authors": [
            "Alon Stern",
            "Sarit Kraus",
            "David Sarne"
        ],
        "summary": "In various multi-agent negotiation settings, a negotiator's utility depends, either partially or fully, on the sum of negotiators' utilities (i.e., social welfare). While the need for effective negotiating-agent designs that take into account social welfare has been acknowledged in recent work, and even established as a category in automated negotiating agent competitions, very few designs have been proposed to date. In this paper, we present the design principles and results of an extensive evaluation of agent HerbT+, a negotiating agent aiming to maximize a linear tradeoff between individual and social welfare. Our evaluation framework relies on the automated negotiating agents competition (ANAC) and includes a thorough comparison of performance with the top 15 agents submitted between 2015-2018 based on negotiations involving 63 agents submitted to these competitions. We find that, except for a few minor exceptions, when social-welfare plays a substantial role in the agent's goal function, our agent outperforms all other tested designs.",
        "published": "2022-01-11T18:50:58Z",
        "link": "http://arxiv.org/abs/2201.04126v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Equilibration Analysis and Control of Coordinating Decision-Making   Populations",
        "authors": [
            "Negar Sakhaei",
            "Zeinab Maleki",
            "Pouria Ramazi"
        ],
        "summary": "Whether a population of decision-making individuals will reach a state of satisfactory decisions is a fundamental problem in studying collective behaviors. In the framework of evolutionary game theory and by means of potential functions, researchers have established equilibrium convergence under different update rules, including best-response and imitation, by imposing certain conditions on agents' utility functions. Then by using the proposed potential functions, they have been able to control these populations towards some desired equilibrium. Nevertheless, finding a potential function is often daunting, if not near impossible. We introduce the so-called coordinating agent who tends to switch to a decision only if at least another agent has done so. We prove that any population of coordinating agents, a coordinating population, almost surely equilibrates. Apparently, some binary network games that were proven to equilibrate using potential functions are coordinating, and some coloring problems can be solved using this notion. We additionally show that any mixed network of agents following best-response, imitation, or rational imitation, and associated with coordination payoff matrices is coordinating, and hence, equilibrates. As a second contribution, we provide an incentive-based control algorithm that leads coordinating populations to a desired equilibrium. The algorithm iteratively maximizes the ratio of the number of agents choosing the desired decision to the provided incentive. It performs near optimal and as well as specialized algorithms proposed for best-response and imitation; however, it does not require a potential function. Therefore, this control algorithm can be readily applied in general situations where no potential function is yet found for a given decision-making population.",
        "published": "2022-01-11T20:23:10Z",
        "link": "http://arxiv.org/abs/2201.04185v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Phragmén Rules for Degressive and Regressive Proportionality",
        "authors": [
            "Michal Jaworski",
            "Piotr Skowron"
        ],
        "summary": "We study two concepts of proportionality in the model of approval-based committee elections. In degressive proportionality small minorities of voters are favored in comparison with the standard linear proportionality. Regressive proportionality, on the other hand, requires that larger subdivisions of voters are privileged. We introduce a new family of rules that broadly generalize Phragm\\'en's Sequential Rule spanning the spectrum between degressive and regressive proportionality. We analyze and compare the two principles of proportionality assuming the voters and the candidates can be represented as points in an Euclidean issue space.",
        "published": "2022-01-12T00:14:44Z",
        "link": "http://arxiv.org/abs/2201.04248v1",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Safe Equilibrium",
        "authors": [
            "Sam Ganzfried"
        ],
        "summary": "The standard game-theoretic solution concept, Nash equilibrium, assumes that all players behave rationally. If we follow a Nash equilibrium and opponents are irrational (or follow strategies from a different Nash equilibrium), then we may obtain an extremely low payoff. On the other hand, a maximin strategy assumes that all opposing agents are playing to minimize our payoff (even if it is not in their best interest), and ensures the maximal possible worst-case payoff, but results in exceedingly conservative play. We propose a new solution concept called safe equilibrium that models opponents as behaving rationally with a specified probability and behaving potentially arbitrarily with the remaining probability. We prove that a safe equilibrium exists in all strategic-form games (for all possible values of the rationality parameters), and prove that its computation is PPAD-hard. We present exact algorithms for computing a safe equilibrium in both 2 and $n$-player games, as well as scalable approximation algorithms.",
        "published": "2022-01-12T01:45:51Z",
        "link": "http://arxiv.org/abs/2201.04266v10",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.CR",
            "cs.MA",
            "econ.TH"
        ]
    },
    {
        "title": "DPCL: a Language Template for Normative Specifications",
        "authors": [
            "Giovanni Sileno",
            "Thomas van Binsbergen",
            "Matteo Pascucci",
            "Tom van Engers"
        ],
        "summary": "Several solutions for specifying normative artefacts (norms, contracts, policies) in a computational processable way have been presented in the literature. Legal core ontologies have been proposed to systematize concepts and relationships relevant to normative reasoning. However, no solution amongst those has achieved general acceptance, and no common ground (representational, computational) has been identified enabling us to easily compare them. Yet, all these efforts share the same motivation of representing normative directives, therefore it is plausible that there may be a representational model encompassing all of them. This presentation will introduce DPCL, a domain-specific language (DSL) for specifying higher-level policies (including norms, contracts, etc.), centred on Hohfeld's framework of fundamental legal concepts. DPCL has to be seen primarily as a \"template\", i.e. as an informational model for architectural reference, rather than a fully-fledged formal language; it aims to make explicit the general requirements that should be expected in a language for norm specification. In this respect, it goes rather in the direction of legal core ontologies, but differently from those, our proposal aims to keep the character of a DSL, rather than a set of axioms in a logical framework: it is meant to be cross-compiled to underlying languages/tools adequate to the type of target application. We provide here an overview of some of the language features.",
        "published": "2022-01-12T13:51:11Z",
        "link": "http://arxiv.org/abs/2201.04477v1",
        "categories": [
            "cs.AI",
            "cs.FL",
            "cs.MA",
            "cs.PL",
            "cs.SC"
        ]
    },
    {
        "title": "Learning to Identify Top Elo Ratings: A Dueling Bandits Approach",
        "authors": [
            "Xue Yan",
            "Yali Du",
            "Binxin Ru",
            "Jun Wang",
            "Haifeng Zhang",
            "Xu Chen"
        ],
        "summary": "The Elo rating system is widely adopted to evaluate the skills of (chess) game and sports players. Recently it has been also integrated into machine learning algorithms in evaluating the performance of computerised AI agents. However, an accurate estimation of the Elo rating (for the top players) often requires many rounds of competitions, which can be expensive to carry out. In this paper, to improve the sample efficiency of the Elo evaluation (for top players), we propose an efficient online match scheduling algorithm. Specifically, we identify and match the top players through a dueling bandits framework and tailor the bandit algorithm to the gradient-based update of Elo. We show that it reduces the per-step memory and time complexity to constant, compared to the traditional likelihood maximization approaches requiring $O(t)$ time. Our algorithm has a regret guarantee of $\\tilde{O}(\\sqrt{T})$, sublinear in the number of competition rounds and has been extended to the multidimensional Elo ratings for handling intransitive games. We empirically demonstrate that our method achieves superior convergence speed and time efficiency on a variety of gaming tasks.",
        "published": "2022-01-12T13:57:29Z",
        "link": "http://arxiv.org/abs/2201.04480v2",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Agent-Temporal Attention for Reward Redistribution in Episodic   Multi-Agent Reinforcement Learning",
        "authors": [
            "Baicen Xiao",
            "Bhaskar Ramasubramanian",
            "Radha Poovendran"
        ],
        "summary": "This paper considers multi-agent reinforcement learning (MARL) tasks where agents receive a shared global reward at the end of an episode. The delayed nature of this reward affects the ability of the agents to assess the quality of their actions at intermediate time-steps. This paper focuses on developing methods to learn a temporal redistribution of the episodic reward to obtain a dense reward signal. Solving such MARL problems requires addressing two challenges: identifying (1) relative importance of states along the length of an episode (along time), and (2) relative importance of individual agents' states at any single time-step (among agents). In this paper, we introduce Agent-Temporal Attention for Reward Redistribution in Episodic Multi-Agent Reinforcement Learning (AREL) to address these two challenges. AREL uses attention mechanisms to characterize the influence of actions on state transitions along trajectories (temporal attention), and how each agent is affected by other agents at each time-step (agent attention). The redistributed rewards predicted by AREL are dense, and can be integrated with any given MARL algorithm. We evaluate AREL on challenging tasks from the Particle World environment and the StarCraft Multi-Agent Challenge. AREL results in higher rewards in Particle World, and improved win rates in StarCraft compared to three state-of-the-art reward redistribution methods. Our code is available at https://github.com/baicenxiao/AREL.",
        "published": "2022-01-12T18:35:46Z",
        "link": "http://arxiv.org/abs/2201.04612v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Decomposition of admissible functions in weighted coupled cell networks",
        "authors": [
            "Pedro Sequeira",
            "João P. Hespanha",
            "A. Pedro Aguiar"
        ],
        "summary": "This work makes explicit the degrees of freedom involved in modeling the dynamics of a network, or some other first-order property of a network, such as a measurement function. In previous work, an admissible function in a network was constructed through the evaluation of what we called oracle components. These oracle components are defined through some minimal properties that they are expected to obey. This is a high-level description in the sense that it is not clear how one could design such an object. The goal is to obtain a low-level representation of these objects by unwrapping them into their degrees of freedom. To achieve this, we introduce two decompositions. The first one is the more intuitive one and allows us to define the important concept of coupling order. The second decomposition is built on top of the first one and is valid for the class of coupling components that have finite coupling order. Despite this requirement, we show that this is still a very useful tool for designing coupling components with infinite coupling orders, through a limit approach.",
        "published": "2022-01-12T18:40:58Z",
        "link": "http://arxiv.org/abs/2201.04972v3",
        "categories": [
            "math.OC",
            "cs.MA",
            "math.DS",
            "34A34, 41A63, 11B73"
        ]
    },
    {
        "title": "Multi-agent Motion Planning from Signal Temporal Logic Specifications",
        "authors": [
            "Dawei Sun",
            "Jingkai Chen",
            "Sayan Mitra",
            "Chuchu Fan"
        ],
        "summary": "We tackle the challenging problem of multi-agent cooperative motion planning for complex tasks described using signal temporal logic (STL), where robots can have nonlinear and nonholonomic dynamics. Existing methods in multi-agent motion planning, especially those based on discrete abstractions and model predictive control (MPC), suffer from limited scalability with respect to the complexity of the task, the size of the workspace, and the planning horizon. We present a method based on {\\em timed waypoints\\/} to address this issue. We show that timed waypoints can help abstract nonlinear behaviors of the system as safety envelopes around the reference path defined by those waypoints. Then the search for waypoints satisfying the STL specifications can be inductively encoded as a mixed-integer linear program. The agents following the synthesized timed waypoints have their tasks automatically allocated, and are guaranteed to satisfy the STL specifications while avoiding collisions. We evaluate the algorithm on a wide variety of benchmarks. Results show that it supports multi-agent planning from complex specification over long planning horizons, and significantly outperforms state-of-the-art abstraction-based and MPC-based motion planning methods. The implementation is available at https://github.com/sundw2014/STLPlanning.",
        "published": "2022-01-13T23:49:36Z",
        "link": "http://arxiv.org/abs/2201.05247v1",
        "categories": [
            "cs.RO",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Standby-Based Deadlock Avoidance Method for Multi-Agent Pickup and   Delivery Tasks",
        "authors": [
            "Tomoki Yamauchi",
            "Yuki Miyashita",
            "Toshiharu Sugawara"
        ],
        "summary": "The multi-agent pickup and delivery (MAPD) problem, in which multiple agents iteratively carry materials without collisions, has received significant attention. However, many conventional MAPD algorithms assume a specifically designed grid-like environment, such as an automated warehouse. Therefore, they have many pickup and delivery locations where agents can stay for a lengthy period, as well as plentiful detours to avoid collisions owing to the freedom of movement in a grid. By contrast, because a maze-like environment such as a search-and-rescue or construction site has fewer pickup/delivery locations and their numbers may be unbalanced, many agents concentrate on such locations resulting in inefficient operations, often becoming stuck or deadlocked. Thus, to improve the transportation efficiency even in a maze-like restricted environment, we propose a deadlock avoidance method, called standby-based deadlock avoidance (SBDA). SBDA uses standby nodes determined in real-time using the articulation-point-finding algorithm, and the agent is guaranteed to stay there for a finite amount of time. We demonstrated that our proposed method outperforms a conventional approach. We also analyzed how the parameters used for selecting standby nodes affect the performance.",
        "published": "2022-01-16T10:28:52Z",
        "link": "http://arxiv.org/abs/2201.06014v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.RO"
        ]
    },
    {
        "title": "GCS: Graph-based Coordination Strategy for Multi-Agent Reinforcement   Learning",
        "authors": [
            "Jingqing Ruan",
            "Yali Du",
            "Xuantang Xiong",
            "Dengpeng Xing",
            "Xiyun Li",
            "Linghui Meng",
            "Haifeng Zhang",
            "Jun Wang",
            "Bo Xu"
        ],
        "summary": "Many real-world scenarios involve a team of agents that have to coordinate their policies to achieve a shared goal. Previous studies mainly focus on decentralized control to maximize a common reward and barely consider the coordination among control policies, which is critical in dynamic and complicated environments. In this work, we propose factorizing the joint team policy into a graph generator and graph-based coordinated policy to enable coordinated behaviours among agents. The graph generator adopts an encoder-decoder framework that outputs directed acyclic graphs (DAGs) to capture the underlying dynamic decision structure. We also apply the DAGness-constrained and DAG depth-constrained optimization in the graph generator to balance efficiency and performance. The graph-based coordinated policy exploits the generated decision structure. The graph generator and coordinated policy are trained simultaneously to maximize the discounted return. Empirical evaluations on Collaborative Gaussian Squeeze, Cooperative Navigation, and Google Research Football demonstrate the superiority of the proposed method.",
        "published": "2022-01-17T07:47:21Z",
        "link": "http://arxiv.org/abs/2201.06257v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Detecting danger in gridworlds using Gromov's Link Condition",
        "authors": [
            "Thomas F Burns",
            "Robert Tang"
        ],
        "summary": "Gridworlds have been long-utilised in AI research, particularly in reinforcement learning, as they provide simple yet scalable models for many real-world applications such as robot navigation, emergent behaviour, and operations research. We initiate a study of gridworlds using the mathematical framework of reconfigurable systems and state complexes due to Abrams, Ghrist & Peterson. State complexes represent all possible configurations of a system as a single geometric space, thus making them conducive to study using geometric, topological, or combinatorial methods. The main contribution of this work is a modification to the original Abrams, Ghrist & Peterson setup which we introduce to capture agent braiding and thereby more naturally represent the topology of gridworlds. With this modification, the state complexes may exhibit geometric defects (failure of Gromov's Link Condition). Serendipitously, we discover these failures occur exactly where undesirable or dangerous states appear in the gridworld. Our results therefore provide a novel method for seeking guaranteed safety limitations in discrete task environments with single or multiple agents, and offer useful safety information (in geometric and topological forms) for incorporation in or analysis of machine learning systems. More broadly, our work introduces tools from geometric group theory and combinatorics to the AI community and demonstrates a proof-of-concept for this geometric viewpoint of the task domain through the example of simple gridworld environments.",
        "published": "2022-01-17T08:33:28Z",
        "link": "http://arxiv.org/abs/2201.06274v2",
        "categories": [
            "cs.AI",
            "cs.MA",
            "math.CO",
            "math.GT",
            "math.MG",
            "57Z25 (Primary) 68R01, 51F99 (Secondary)",
            "I.2.0; G.2.0"
        ]
    },
    {
        "title": "NSGZero: Efficiently Learning Non-Exploitable Policy in Large-Scale   Network Security Games with Neural Monte Carlo Tree Search",
        "authors": [
            "Wanqi Xue",
            "Bo An",
            "Chai Kiat Yeo"
        ],
        "summary": "How resources are deployed to secure critical targets in networks can be modelled by Network Security Games (NSGs). While recent advances in deep learning (DL) provide a powerful approach to dealing with large-scale NSGs, DL methods such as NSG-NFSP suffer from the problem of data inefficiency. Furthermore, due to centralized control, they cannot scale to scenarios with a large number of resources. In this paper, we propose a novel DL-based method, NSGZero, to learn a non-exploitable policy in NSGs. NSGZero improves data efficiency by performing planning with neural Monte Carlo Tree Search (MCTS). Our main contributions are threefold. First, we design deep neural networks (DNNs) to perform neural MCTS in NSGs. Second, we enable neural MCTS with decentralized control, making NSGZero applicable to NSGs with many resources. Third, we provide an efficient learning paradigm, to achieve joint training of the DNNs in NSGZero. Compared to state-of-the-art algorithms, our method achieves significantly better data efficiency and scalability.",
        "published": "2022-01-17T13:27:16Z",
        "link": "http://arxiv.org/abs/2201.07224v1",
        "categories": [
            "cs.CR",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Cooperative constrained motion coordination of networked heterogeneous   vehicles",
        "authors": [
            "Zhiyong Sun",
            "Marcus Greiff",
            "Anders Robertsson",
            "Rolf Johansson",
            "Brian D. O. Anderson"
        ],
        "summary": "We consider the problem of cooperative motion coordination for multiple heterogeneous mobile vehicles subject to various constraints. These include nonholonomic motion constraints, constant speed constraints, holonomic coordination constraints, and equality/inequality geometric constraints. We develop a general framework involving differential-algebraic equations and viability theory to determine coordination feasibility for a coordinated motion control under heterogeneous vehicle dynamics and different types of coordination task constraints. If a coordinated motion solution exists for the derived differential-algebraic equations and/or inequalities, a constructive algorithm is proposed to derive an equivalent dynamical system that generates a set of feasible coordinated motions for each individual vehicle. In case studies on coordinating two vehicles, we derive analytical solutions to motion generation for two-vehicle groups consisting of car-like vehicles, unicycle vehicles, or vehicles with constant speeds, which serve as benchmark coordination tasks for more complex vehicle groups. The motion generation algorithm is well-backed by simulation data for a wide variety of coordination situations involving heterogeneous vehicles. We then extend the vehicle control framework to deal with the cooperative coordination problem with time-varying coordination tasks and leader-follower structure. We show several simulation experiments on multi-vehicle coordination under various constraints to validate the theory and the effectiveness of the proposed schemes.",
        "published": "2022-01-17T13:31:49Z",
        "link": "http://arxiv.org/abs/2201.06399v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.RO",
            "cs.SY",
            "math.DS",
            "math.OC"
        ]
    },
    {
        "title": "Consensus from group interactions: An adaptive voter model on   hypergraphs",
        "authors": [
            "Nikos Papanikolaou",
            "Giacomo Vaccario",
            "Erik Hormann",
            "Renaud Lambiotte",
            "Frank Schweitzer"
        ],
        "summary": "We study the effect of group interactions on the emergence of consensus in a spin system. Agents with discrete opinions $\\{0,1\\}$ form groups. They can change their opinion based on their group's influence (voter dynamics), but groups can also split and merge (adaptation). In a hypergraph, these groups are represented by hyperedges of different sizes. The heterogeneity of group sizes is controlled by a parameter $\\beta$. To study the impact of $\\beta$ on reaching consensus, we provide extensive computer simulations and compare them with an analytic approach for the dynamics of the average magnetization. We find that group interactions amplify small initial opinion biases, accelerate the formation of consensus and lead to a drift of the average magnetization. The conservation of the initial magnetization, known for basic voter models, is no longer obtained.",
        "published": "2022-01-17T14:18:39Z",
        "link": "http://arxiv.org/abs/2201.06421v1",
        "categories": [
            "physics.soc-ph",
            "cond-mat.stat-mech",
            "cs.MA",
            "nlin.AO"
        ]
    },
    {
        "title": "Planning Not to Talk: Multiagent Systems that are Robust to   Communication Loss",
        "authors": [
            "Mustafa O. Karabag",
            "Cyrus Neary",
            "Ufuk Topcu"
        ],
        "summary": "In a cooperative multiagent system, a collection of agents executes a joint policy in order to achieve some common objective. The successful deployment of such systems hinges on the availability of reliable inter-agent communication. However, many sources of potential disruption to communication exist in practice, such as radio interference, hardware failure, and adversarial attacks. In this work, we develop joint policies for cooperative multiagent systems that are robust to potential losses in communication. More specifically, we develop joint policies for cooperative Markov games with reach-avoid objectives. First, we propose an algorithm for the decentralized execution of joint policies during periods of communication loss. Next, we use the total correlation of the state-action process induced by a joint policy as a measure of the intrinsic dependencies between the agents. We then use this measure to lower-bound the performance of a joint policy when communication is lost. Finally, we present an algorithm that maximizes a proxy to this lower bound in order to synthesize minimum-dependency joint policies that are robust to communication loss. Numerical experiments show that the proposed minimum-dependency policies require minimal coordination between the agents while incurring little to no loss in performance; the total correlation value of the synthesized policy is one fifth of the total correlation value of the baseline policy which does not take potential communication losses into account. As a result, the performance of the minimum-dependency policies remains consistently high regardless of whether or not communication is available. By contrast, the performance of the baseline policy decreases by twenty percent when communication is lost.",
        "published": "2022-01-17T20:29:22Z",
        "link": "http://arxiv.org/abs/2201.06619v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Structural Consensus in Networks with Directed Topologies and Its   Cryptographic Implementation",
        "authors": [
            "Wentuo Fang",
            "Zhiyong Chen",
            "Mohsen Zamani"
        ],
        "summary": "The existing cryptosystem based approaches for privacy-preserving consensus of networked systems are usually limited to those with undirected topologies. This paper proposes a new privacy-preserving algorithm for networked systems with directed topologies to reach confidential consensus. As a prerequisite for applying the algorithm, a structural consensus problem is formulated and the solvability conditions are discussed for an explicitly constructed controller. The controller is then implemented with encryption to achieve consensus while avoiding individual's information leakage to external eavesdroppers and/or malicious internal neighbors.",
        "published": "2022-01-18T05:13:28Z",
        "link": "http://arxiv.org/abs/2201.06747v1",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "K-nearest Multi-agent Deep Reinforcement Learning for Collaborative   Tasks with a Variable Number of Agents",
        "authors": [
            "Hamed Khorasgani",
            "Haiyan Wang",
            "Hsiu-Khuern Tang",
            "Chetan Gupta"
        ],
        "summary": "Traditionally, the performance of multi-agent deep reinforcement learning algorithms are demonstrated and validated in gaming environments where we often have a fixed number of agents. In many industrial applications, the number of available agents can change at any given day and even when the number of agents is known ahead of time, it is common for an agent to break during the operation and become unavailable for a period of time. In this paper, we propose a new deep reinforcement learning algorithm for multi-agent collaborative tasks with a variable number of agents. We demonstrate the application of our algorithm using a fleet management simulator developed by Hitachi to generate realistic scenarios in a production site.",
        "published": "2022-01-18T16:14:24Z",
        "link": "http://arxiv.org/abs/2201.07092v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Speed-vs-Accuracy Tradeoff in Collective Estimation: An Adaptive   Exploration-Exploitation Case",
        "authors": [
            "Mohsen Raoufi",
            "Heiko Hamann",
            "Pawel Romanczuk"
        ],
        "summary": "The tradeoff between accuracy and speed is considered fundamental to individual and collective decision-making. In this paper, we focus on collective estimation as an example of collective decision-making. The task is to estimate the average scalar intensity of a desired feature in the environment. The solution we propose consists of exploration and exploitation phases, where the switching time is a factor dictating the balance between the two phases. By decomposing the total accuracy into bias and variance, we explain that diversity and social interactions could promote the accuracy of the collective decision. We also show how the exploration-vs-exploitation tradeoff relates to the speed-vs-accuracy tradeoff. One significant finding of our work is that there is an optimal duration for exploration to compromise between speed and accuracy. This duration cannot be determined offline for an unknown environment. Hence, we propose an adaptive, distributed mechanism enabling individual agents to decide in a decentralized manner when to switch. Moreover, the spatial consequence of the exploitation phase is an emergent collective movement, leading to the aggregation of the collective at the iso-contours of the mean intensity of the environmental field in the spatial domain. Examples of potential applications for such a fully distributed collective estimation model are spillage capturing and source localization.",
        "published": "2022-01-18T16:54:01Z",
        "link": "http://arxiv.org/abs/2201.07123v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Proportional Ranking in Primary Elections: A Case Study",
        "authors": [
            "Ariel Rosenfeld",
            "Ehud Shapiro",
            "Nimrod Talmon"
        ],
        "summary": "Many democratic political parties hold primary elections, which nicely reflects their democratic nature and promote, among other things, the democratic value of inclusiveness. However, the methods currently used for holding such primary elections may not be the most suitable, especially if some form of proportional ranking is desired. In this paper, we compare different algorithmic methods for holding primaries (i.e., different aggregation methods for voters' ballots), by evaluating the degree of proportional ranking that is achieved by each of them using real-world data. In particular, we compare six different algorithms by analyzing real-world data from a recent primary election conducted by the Israeli Democratit party. Technically, we analyze unique voter data and evaluate the proportionality achieved by means of cluster analysis, aiming at pinpointing the representation that is granted to different voter groups under each of the algorithmic methods considered. Our finding suggest that, contrary to the most-prominent primaries algorithm used (i.e., Approval), other methods such as Sequential Proportional Approval or Phragmen can bring about better proportional ranking and thus may be better suited for primary elections in practice.",
        "published": "2022-01-18T20:47:04Z",
        "link": "http://arxiv.org/abs/2201.07305v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Solving Dynamic Principal-Agent Problems with a Rationally Inattentive   Principal",
        "authors": [
            "Tong Mu",
            "Stephan Zheng",
            "Alexander Trott"
        ],
        "summary": "Principal-Agent (PA) problems describe a broad class of economic relationships characterized by misaligned incentives and asymmetric information. The Principal's problem is to find optimal incentives given the available information, e.g., a manager setting optimal wages for its employees. Whereas the Principal is often assumed rational, comparatively little is known about solutions when the Principal is boundedly rational, especially in the sequential setting, with multiple Agents, and with multiple information channels. Here, we develop RIRL, a deep reinforcement learning framework that solves such complex PA problems with a rationally inattentive Principal. Such a Principal incurs a cost for paying attention to information, which can model forms of bounded rationality. We use RIRL to analyze rich economic phenomena in manager-employee relationships. In the single-step setting, 1) RIRL yields wages that are consistent with theoretical predictions; and 2) non-zero attention costs lead to simpler but less profitable wage structures, and increased Agent welfare. In a sequential setting with multiple Agents, RIRL shows opposing consequences of the Principal's inattention to different information channels: 1) inattention to Agents' outputs closes wage gaps based on ability differences; and 2) inattention to Agents' efforts induces a social dilemma dynamic in which Agents work harder, but essentially for free. Moreover, RIRL reveals non-trivial relationships between the Principal's inattention and Agent types, e.g., if Agents are prone to sub-optimal effort choices, payment schedules are more sensitive to the Principal's attention cost. As such, RIRL can reveal novel economic relationships and enables progress towards understanding the effects of bounded rationality in dynamic settings.",
        "published": "2022-01-18T20:54:00Z",
        "link": "http://arxiv.org/abs/2202.01691v2",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Interpretable Learned Emergent Communication for Human-Agent Teams",
        "authors": [
            "Seth Karten",
            "Mycal Tucker",
            "Huao Li",
            "Siva Kailas",
            "Michael Lewis",
            "Katia Sycara"
        ],
        "summary": "Learning interpretable communication is essential for multi-agent and human-agent teams (HATs). In multi-agent reinforcement learning for partially-observable environments, agents may convey information to others via learned communication, allowing the team to complete its task. Inspired by human languages, recent works study discrete (using only a finite set of tokens) and sparse (communicating only at some time-steps) communication. However, the utility of such communication in human-agent team experiments has not yet been investigated. In this work, we analyze the efficacy of sparse-discrete methods for producing emergent communication that enables high agent-only and human-agent team performance. We develop agent-only teams that communicate sparsely via our scheme of Enforcers that sufficiently constrain communication to any budget. Our results show no loss or minimal loss of performance in benchmark environments and tasks. In human-agent teams tested in benchmark environments, where agents have been modeled using the Enforcers, we find that a prototype-based method produces meaningful discrete tokens that enable human partners to learn agent communication faster and better than a one-hot baseline. Additional HAT experiments show that an appropriate sparsity level lowers the cognitive load of humans when communicating with teams of agents and leads to superior team performance.",
        "published": "2022-01-19T07:31:06Z",
        "link": "http://arxiv.org/abs/2201.07452v2",
        "categories": [
            "cs.LG",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Effect of intervention policies in an agent based spatial epidemic model   of Gwalior",
        "authors": [
            "W. Wilfred Godfrey"
        ],
        "summary": "Covid-19 has ravaged the entire world and it may not be the last such to ravage the world. COMOKIT [3] is an agent based spatial modeling tool to study the effect of covid -19 in a geographical area by creating heterogenous synthetic agents and their behaviours. This paper presents comokit based case study on Gwalior region with respect to various intervention policies to curb the spread of the disease.",
        "published": "2022-01-19T11:51:50Z",
        "link": "http://arxiv.org/abs/2201.07545v1",
        "categories": [
            "cs.MA",
            "J.4"
        ]
    },
    {
        "title": "Anytime PSRO for Two-Player Zero-Sum Games",
        "authors": [
            "Stephen McAleer",
            "Kevin Wang",
            "John Lanier",
            "Marc Lanctot",
            "Pierre Baldi",
            "Tuomas Sandholm",
            "Roy Fox"
        ],
        "summary": "Policy space response oracles (PSRO) is a multi-agent reinforcement learning algorithm that has achieved state-of-the-art performance in very large two-player zero-sum games. PSRO is based on the tabular double oracle (DO) method, an algorithm that is guaranteed to converge to a Nash equilibrium, but may increase exploitability from one iteration to the next. We propose anytime double oracle (ADO), a tabular double oracle algorithm for 2-player zero-sum games that is guaranteed to converge to a Nash equilibrium while decreasing exploitability from one iteration to the next. Unlike DO, in which the restricted distribution is based on the restricted game formed by each player's strategy sets, ADO finds the restricted distribution for each player that minimizes its exploitability against any policy in the full, unrestricted game. We also propose a method of finding this restricted distribution via a no-regret algorithm updated against best responses, called RM-BR DO. Finally, we propose anytime PSRO (APSRO), a version of ADO that calculates best responses via reinforcement learning. In experiments on Leduc poker and random normal form games, we show that our methods achieve far lower exploitability than DO and PSRO and decrease exploitability monotonically.",
        "published": "2022-01-19T16:34:11Z",
        "link": "http://arxiv.org/abs/2201.07700v2",
        "categories": [
            "cs.GT",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Learning Multi-agent Skills for Tabular Reinforcement Learning using   Factor Graphs",
        "authors": [
            "Jiayu Chen",
            "Jingdi Chen",
            "Tian Lan",
            "Vaneet Aggarwal"
        ],
        "summary": "Covering skill (a.k.a., option) discovery has been developed to improve the exploration of reinforcement learning in single-agent scenarios with sparse reward signals, through connecting the most distant states in the embedding space provided by the Fiedler vector of the state transition graph. However, these option discovery methods cannot be directly extended to multi-agent scenarios, since the joint state space grows exponentially with the number of agents in the system. Thus, existing researches on adopting options in multi-agent scenarios still rely on single-agent option discovery and fail to directly discover the joint options that can improve the connectivity of the joint state space of agents. In this paper, we show that it is indeed possible to directly compute multi-agent options with collaborative exploratory behaviors among the agents, while still enjoying the ease of decomposition. Our key idea is to approximate the joint state space as a Kronecker graph -- the Kronecker product of individual agents' state transition graphs, based on which we can directly estimate the Fiedler vector of the joint state space using the Laplacian spectrum of individual agents' transition graphs. This decomposition enables us to efficiently construct multi-agent joint options by encouraging agents to connect the sub-goal joint states which are corresponding to the minimum or maximum values of the estimated joint Fiedler vector. The evaluation based on multi-agent collaborative tasks shows that the proposed algorithm can successfully identify multi-agent options, and significantly outperforms prior works using single-agent options or no options, in terms of both faster exploration and higher cumulative rewards.",
        "published": "2022-01-20T15:33:08Z",
        "link": "http://arxiv.org/abs/2201.08227v3",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Iterated Reasoning with Mutual Information in Cooperative and Byzantine   Decentralized Teaming",
        "authors": [
            "Sachin Konan",
            "Esmaeil Seraj",
            "Matthew Gombolay"
        ],
        "summary": "Information sharing is key in building team cognition and enables coordination and cooperation. High-performing human teams also benefit from acting strategically with hierarchical levels of iterated communication and rationalizability, meaning a human agent can reason about the actions of their teammates in their decision-making. Yet, the majority of prior work in Multi-Agent Reinforcement Learning (MARL) does not support iterated rationalizability and only encourage inter-agent communication, resulting in a suboptimal equilibrium cooperation strategy. In this work, we show that reformulating an agent's policy to be conditional on the policies of its neighboring teammates inherently maximizes Mutual Information (MI) lower-bound when optimizing under Policy Gradient (PG). Building on the idea of decision-making under bounded rationality and cognitive hierarchy theory, we show that our modified PG approach not only maximizes local agent rewards but also implicitly reasons about MI between agents without the need for any explicit ad-hoc regularization terms. Our approach, InfoPG, outperforms baselines in learning emergent collaborative behaviors and sets the state-of-the-art in decentralized cooperative MARL tasks. Our experiments validate the utility of InfoPG by achieving higher sample efficiency and significantly larger cumulative reward in several complex cooperative multi-agent domains.",
        "published": "2022-01-20T22:54:32Z",
        "link": "http://arxiv.org/abs/2201.08484v4",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG",
            "cs.RO"
        ]
    },
    {
        "title": "Multi-Agent Adversarial Attacks for Multi-Channel Communications",
        "authors": [
            "Juncheng Dong",
            "Suya Wu",
            "Mohammadreza Sultani",
            "Vahid Tarokh"
        ],
        "summary": "Recently Reinforcement Learning (RL) has been applied as an anti-adversarial remedy in wireless communication networks. However, studying the RL-based approaches from the adversary's perspective has received little attention. Additionally, RL-based approaches in an anti-adversary or adversarial paradigm mostly consider single-channel communication (either channel selection or single channel power control), while multi-channel communication is more common in practice. In this paper, we propose a multi-agent adversary system (MAAS) for modeling and analyzing adversaries in a wireless communication scenario by careful design of the reward function under realistic communication scenarios. In particular, by modeling the adversaries as learning agents, we show that the proposed MAAS is able to successfully choose the transmitted channel(s) and their respective allocated power(s) without any prior knowledge of the sender strategy. Compared to the single-agent adversary (SAA), multi-agents in MAAS can achieve significant reduction in signal-to-noise ratio (SINR) under the same power constraints and partial observability, while providing improved stability and a more efficient learning process. Moreover, through empirical studies we show that the results in simulation are close to the ones in communication in reality, a conclusion that is pivotal to the validity of performance of agents evaluated in simulations.",
        "published": "2022-01-22T23:57:00Z",
        "link": "http://arxiv.org/abs/2201.09149v2",
        "categories": [
            "cs.MA",
            "cs.IT",
            "cs.LG",
            "math.IT"
        ]
    },
    {
        "title": "On the throughput of the common target area for robotic swarm strategies   -- extended version",
        "authors": [
            "Yuri Tavares dos Passos",
            "Xavier Duquesne",
            "Leandro Soriano Marcolino"
        ],
        "summary": "A robotic swarm may encounter traffic congestion when many robots simultaneously attempt to reach the same area. For solving that efficiently, robots must execute decentralised traffic control algorithms. In this work, we propose a measure for evaluating the access efficiency of a common target area as the number of robots in the swarm rises: the common target area throughput. We also employ here the target area asymptotic throughput -- that is, the throughput of a target region with a limited area as the time tends to infinity -- because it is always finite as the number of robots grows, opposed to the relation arrival time at the target per number of robots that tends to infinity. Using this measure, we can analytically compare the effectiveness of different algorithms. In particular, we propose and formally evaluate three different theoretical strategies for getting to a circular target area: (i) forming parallel queues towards the target area, (ii) forming a hexagonal packing through a corridor going to the target, and (iii) making multiple curved trajectories towards the boundary of the target area. We calculate the throughput for a fixed time and the asymptotic throughput for these strategies. Additionally, we corroborate these results by simulations, showing that when a strategy has higher throughput, its arrival time per number of robots is lower. Thus, we conclude that using throughput is well suited for comparing congestion algorithms for a common target area in robotic swarms even if we do not have their closed asymptotic equation.",
        "published": "2022-01-23T18:16:12Z",
        "link": "http://arxiv.org/abs/2201.09335v3",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Congestion control algorithms for robotic swarms with a common target   based on the throughput of the target area",
        "authors": [
            "Yuri Tavares dos Passos",
            "Xavier Duquesne",
            "Leandro Soriano Marcolino"
        ],
        "summary": "When a large number of robots try to reach a common area, congestions happen, causing severe delays. To minimise congestion in a robotic swarm system, traffic control algorithms must be employed in a decentralised manner. Based on strategies aimed to maximise the throughput of the common target area, we developed two novel algorithms for robots using artificial potential fields for obstacle avoidance and navigation. One algorithm is inspired by creating a queue to get to the target area (Single Queue Former -- SQF), while the other makes the robots touch the boundary of the circular area by using vector fields (Touch and Run Vector Fields -- TRVF). We performed simulation experiments to show that the proposed algorithms are bounded by the throughput of their inspired theoretical strategies and compare the two novel algorithms with state-of-art algorithms for the same problem (PCC, EE and PCC-EE). The SQF algorithm significantly outperforms all other algorithms for a large number of robots or when the circular target region radius is small. TRVF, on the other hand, is better than SQF only for a limited number of robots and outperforms only PCC for numerous robots. However, it allows us to analyse the potential impacts on the throughput when transferring an idea from a theoretical strategy to a concrete algorithm that considers changing linear speeds and distances between robots.",
        "published": "2022-01-23T18:25:46Z",
        "link": "http://arxiv.org/abs/2201.09337v3",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "CTRMs: Learning to Construct Cooperative Timed Roadmaps for Multi-agent   Path Planning in Continuous Spaces",
        "authors": [
            "Keisuke Okumura",
            "Ryo Yonetani",
            "Mai Nishimura",
            "Asako Kanezaki"
        ],
        "summary": "Multi-agent path planning (MAPP) in continuous spaces is a challenging problem with significant practical importance. One promising approach is to first construct graphs approximating the spaces, called roadmaps, and then apply multi-agent pathfinding (MAPF) algorithms to derive a set of conflict-free paths. While conventional studies have utilized roadmap construction methods developed for single-agent planning, it remains largely unexplored how we can construct roadmaps that work effectively for multiple agents. To this end, we propose a novel concept of roadmaps called cooperative timed roadmaps (CTRMs). CTRMs enable each agent to focus on its important locations around potential solution paths in a way that considers the behavior of other agents to avoid inter-agent collisions (i.e., \"cooperative\"), while being augmented in the time direction to make it easy to derive a \"timed\" solution path. To construct CTRMs, we developed a machine-learning approach that learns a generative model from a collection of relevant problem instances and plausible solutions and then uses the learned model to sample the vertices of CTRMs for new, previously unseen problem instances. Our empirical evaluation revealed that the use of CTRMs significantly reduced the planning effort with acceptable overheads while maintaining a success rate and solution quality comparable to conventional roadmap construction approaches.",
        "published": "2022-01-24T05:43:59Z",
        "link": "http://arxiv.org/abs/2201.09467v1",
        "categories": [
            "cs.MA",
            "cs.LG",
            "cs.RO"
        ]
    },
    {
        "title": "Multidimensional Manhattan Preferences",
        "authors": [
            "Jiehua Chen",
            "Martin Nöllenburg",
            "Sofia Simola",
            "Anaïs Villedieu",
            "Markus Wallinger"
        ],
        "summary": "A preference profile with $m$ alternatives and $n$ voters is $d$-Manhattan (resp. $d$-Euclidean) if both the alternatives and the voters can be placed into the $d$-dimensional space such that between each pair of alternatives, every voter prefers the one which has a shorter Manhattan (resp. Euclidean) distance to the voter. Following Bogomolnaia and Laslier [Journal of Mathematical Economics, 2007] and Chen and Grottke [Social Choice and Welfare, 2021] who look at $d$-Euclidean preference profiles, we study which preference profiles are $d$-Manhattan depending on the values $m$ and $n$.   First, we show that each preference profile with $m$ alternatives and $n$ voters is $d$-Manhattan whenever $d$ $\\geq$ min($n$, $m$-$1$). Second, for $d = 2$, we show that the smallest non $d$-Manhattan preference profile has either three voters and six alternatives, or four voters and five alternatives, or five voters and four alternatives. This is more complex than the case with $d$-Euclidean preferences (see [Bogomolnaia and Laslier, 2007] and [Bulteau and Chen, 2020].",
        "published": "2022-01-24T13:52:38Z",
        "link": "http://arxiv.org/abs/2201.09691v1",
        "categories": [
            "cs.MA",
            "econ.TH",
            "math.CO"
        ]
    },
    {
        "title": "Multi-UAV Coverage Planning with Limited Endurance in Disaster   Environment",
        "authors": [
            "Hongyu Song",
            "Jincheng Yu",
            "Jiantao Qiu",
            "Zhixiao Sun",
            "Kuijun Lang",
            "Qing Luo",
            "Yuan Shen",
            "Yu Wang"
        ],
        "summary": "For scenes such as floods and earthquakes, the disaster area is large, and rescue time is tight. Multi-UAV exploration is more efficient than a single UAV. Existing UAV exploration work is modeled as a Coverage Path Planning (CPP) task to achieve full coverage of the area in the presence of obstacles. However, the endurance capability of UAV is limited, and the rescue time is urgent. Thus, even using multiple UAVs cannot achieve complete disaster area coverage in time. Therefore, in this paper we propose a multi-Agent Endurance-limited CPP (MAEl-CPP) problem based on a priori heatmap of the disaster area, which requires the exploration of more valuable areas under limited energy. Furthermore, we propose a path planning algorithm for the MAEl-CPP problem, by ranking the possible disaster areas according to their importance through satellite or remote aerial images and completing path planning according to the importance level. Experimental results show that our proposed algorithm is at least twice as effective as the existing method in terms of search efficiency.",
        "published": "2022-01-25T07:48:06Z",
        "link": "http://arxiv.org/abs/2201.10150v2",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Hacking the Colony: On the Disruptive Effect of Misleading Pheromone and   How to Defend Against It",
        "authors": [
            "Ashay Aswale",
            "Antonio Lopez",
            "Aukkawut Ammartayakun",
            "Carlo Pinciroli"
        ],
        "summary": "Ants have evolved to seek and retrieve food by leaving trails of pheromones. This mechanism has inspired several approaches to decentralized multi-robot coordination. However, in this paper, we show that pheromone trails are a fragile mechanism for coordination, and can be sabotaged to starve the colony. We introduce detractors: malicious agents that leave a misleading, but indistinguishable, trail of food pheromone to distract and trap cooperator ants in the nest. We analyze the effectiveness of detractors with respect to parameters such as evaporation rate of misleading pheromone and fraction of detractors in the colony. In addition, we propose a countermeasure to this attack by introducing a new type of pheromone: the cautionary pheromone. Cooperator ants secrete this type of pheromone atop existing food trails as a warning. When the cautionary pheromone intensity exceeds the food pheromone intensity, cooperator ants ignore overlapping food pheromone. We show that, despite its simplicity, this defense mechanism can limit, but not nullify, the effect of detractors. Ultimately, our work shows that pheromone-based coordination, while effective, is also fragile.",
        "published": "2022-01-25T07:57:19Z",
        "link": "http://arxiv.org/abs/2202.01808v2",
        "categories": [
            "cs.MA",
            "I.2.11"
        ]
    },
    {
        "title": "Public Information Representation for Adversarial Team Games",
        "authors": [
            "Luca Carminati",
            "Federico Cacciamani",
            "Marco Ciccone",
            "Nicola Gatti"
        ],
        "summary": "The peculiarity of adversarial team games resides in the asymmetric information available to the team members during the play, which makes the equilibrium computation problem hard even with zero-sum payoffs. The algorithms available in the literature work with implicit representations of the strategy space and mainly resort to Linear Programming and column generation techniques to enlarge incrementally the strategy space. Such representations prevent the adoption of standard tools such as abstraction generation, game solving, and subgame solving, which demonstrated to be crucial when solving huge, real-world two-player zero-sum games. Differently from these works, we answer the question of whether there is any suitable game representation enabling the adoption of those tools. In particular, our algorithms convert a sequential team game with adversaries to a classical two-player zero-sum game. In this converted game, the team is transformed into a single coordinator player who only knows information common to the whole team and prescribes to the players an action for any possible private state. Interestingly, we show that our game is more expressive than the original extensive-form game as any state/action abstraction of the extensive-form game can be captured by our representation, while the reverse does not hold. Due to the NP-hard nature of the problem, the resulting Public Team game may be exponentially larger than the original one. To limit this explosion, we provide three algorithms, each returning an information-lossless abstraction that dramatically reduces the size of the tree. These abstractions can be produced without generating the original game tree. Finally, we show the effectiveness of the proposed approach by presenting experimental results on Kuhn and Leduc Poker games, obtained by applying state-of-art algorithms for two-player zero-sum games on the converted games",
        "published": "2022-01-25T15:07:12Z",
        "link": "http://arxiv.org/abs/2201.10377v1",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Parameterized Analysis of Reconfigurable Broadcast Networks (Long   Version)",
        "authors": [
            "A. R. Balasubramanian",
            "Lucie Guillou",
            "Chana Weil-Kennedy"
        ],
        "summary": "Reconfigurable broadcast networks (RBN) are a model of distributed computation in which agents can broadcast messages to other agents using some underlying communication topology which can change arbitrarily over the course of executions. In this paper, we conduct parameterized analysis of RBN. We consider cubes,(infinite) sets of configurations in the form of lower and upper bounds on the number of agents in each state, and we show that we can evaluate boolean combinations over cubes and reachability sets of cubes in PSPACE. In particular, reachability from a cube to another cube is a PSPACE-complete problem.   To prove the upper bound for this parameterized analysis, we prove some structural properties about the reachability sets and the symbolic graph abstraction of RBN, which might be of independent interest. We justify this claim by providing two applications of these results. First, we show that the almost-sure coverability problem is PSPACE-complete for RBN, thereby closing a complexity gap from a previous paper. Second, we define a computation model using RBN, \\`a la population protocols, called RBN protocols. We characterize precisely the set of predicates that can be computed by such protocols.",
        "published": "2022-01-25T16:26:27Z",
        "link": "http://arxiv.org/abs/2201.10432v2",
        "categories": [
            "cs.LO",
            "cs.MA"
        ]
    },
    {
        "title": "Optimal Data Selection: An Online Distributed View",
        "authors": [
            "Mariel Werner",
            "Anastasios Angelopoulos",
            "Stephen Bates",
            "Michael I. Jordan"
        ],
        "summary": "The blessing of ubiquitous data also comes with a curse: the communication, storage, and labeling of massive, mostly redundant datasets. We seek to solve this problem at its core, collecting only valuable data and throwing out the rest via submodular maximization. Specifically, we develop algorithms for the online and distributed version of the problem, where data selection occurs in an uncoordinated fashion across multiple data streams. We design a general and flexible core selection routine for our algorithms which, given any stream of data, any assessment of its value, and any formulation of its selection cost, extracts the most valuable subset of the stream up to a constant factor while using minimal memory. Notably, our methods have the same theoretical guarantees as their offline counterparts, and, as far as we know, provide the first guarantees for online distributed submodular optimization in the literature. Finally, in learning tasks on ImageNet and MNIST, we show that our selection methods outperform random selection by $5-20\\%$.",
        "published": "2022-01-25T18:56:16Z",
        "link": "http://arxiv.org/abs/2201.10547v3",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Simultaneous Human-robot Matching and Routing for Multi-robot Tour   Guiding under Time Uncertainty",
        "authors": [
            "Bo Fu",
            "Tribhi Kathuria",
            "Denise Rizzo",
            "Matthew Castanier",
            "X. Jessie Yang",
            "Maani Ghaffari",
            "Kira Barton"
        ],
        "summary": "This work presents a framework for multi-robot tour guidance in a partially known environment with uncertainty, such as a museum. In the proposed centralized multi-robot planner, a simultaneous matching and routing problem (SMRP) is formulated to match the humans with robot guides according to their selected places of interest (POIs) and generate the routes and schedules for the robots according to uncertain spatial and time estimation. A large neighborhood search algorithm is developed to efficiently find sub-optimal low-cost solutions for the SMRP. The scalability and optimality of the multi-robot planner are evaluated computationally under different numbers of humans, robots, and POIs. The largest case tested involves 50 robots, 250 humans, and 50 POIs. Then, a photo-realistic multi-robot simulation platform was developed based on Habitat-AI to verify the tour guiding performance in an uncertain indoor environment. Results demonstrate that the proposed centralized tour planner is scalable, makes a smooth trade-off in the plans under different environmental constraints, and can lead to robust performance with inaccurate uncertainty estimations (within a certain margin).",
        "published": "2022-01-25T21:25:43Z",
        "link": "http://arxiv.org/abs/2201.10635v1",
        "categories": [
            "cs.RO",
            "cs.MA",
            "93A16"
        ]
    },
    {
        "title": "Sampling Equilibria: Fast No-Regret Learning in Structured Games",
        "authors": [
            "Daniel Beaglehole",
            "Max Hopkins",
            "Daniel Kane",
            "Sihan Liu",
            "Shachar Lovett"
        ],
        "summary": "Learning and equilibrium computation in games are fundamental problems across computer science and economics, with applications ranging from politics to machine learning. Much of the work in this area revolves around a simple algorithm termed \\emph{randomized weighted majority} (RWM), also known as \"Hedge\" or \"Multiplicative Weights Update,\" which is well known to achieve statistically optimal rates in adversarial settings (Littlestone and Warmuth '94, Freund and Schapire '99). Unfortunately, RWM comes with an inherent computational barrier: it requires maintaining and sampling from a distribution over all possible actions. In typical settings of interest the action space is exponentially large, seemingly rendering RWM useless in practice.   In this work, we refute this notion for a broad variety of \\emph{structured} games, showing it is possible to efficiently (approximately) sample the action space in RWM in \\emph{polylogarithmic} time. This gives the first efficient no-regret algorithms for problems such as the \\emph{(discrete) Colonel Blotto game}, \\emph{matroid congestion}, \\emph{matroid security}, and basic \\emph{dueling games}. As an immediate corollary, we give a polylogarithmic time meta-algorithm to compute approximate Nash Equilibria for these games that is exponentially faster than prior methods in several important settings. Further, our algorithm is the first to efficiently compute equilibria for more involved variants of these games with general sums, more than two players, and, for Colonel Blotto, multiple resource types.",
        "published": "2022-01-26T05:42:59Z",
        "link": "http://arxiv.org/abs/2201.10758v7",
        "categories": [
            "cs.GT",
            "cs.DM",
            "cs.DS",
            "cs.MA"
        ]
    },
    {
        "title": "Exploiting Semantic Epsilon Greedy Exploration Strategy in Multi-Agent   Reinforcement Learning",
        "authors": [
            "Hon Tik Tse",
            "Ho-fung Leung"
        ],
        "summary": "Multi-agent reinforcement learning (MARL) can model many real world applications. However, many MARL approaches rely on epsilon greedy for exploration, which may discourage visiting advantageous states in hard scenarios. In this paper, we propose a new approach QMIX(SEG) for tackling MARL. It makes use of the value function factorization method QMIX to train per-agent policies and a novel Semantic Epsilon Greedy (SEG) exploration strategy. SEG is a simple extension to the conventional epsilon greedy exploration strategy, yet it is experimentally shown to greatly improve the performance of MARL. We first cluster actions into groups of actions with similar effects and then use the groups in a bi-level epsilon greedy exploration hierarchy for action selection. We argue that SEG facilitates semantic exploration by exploring in the space of groups of actions, which have richer semantic meanings than atomic actions. Experiments show that QMIX(SEG) largely outperforms QMIX and leads to strong performance competitive with current state-of-the-art MARL approaches on the StarCraft Multi-Agent Challenge (SMAC) benchmark.",
        "published": "2022-01-26T08:21:11Z",
        "link": "http://arxiv.org/abs/2201.10803v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Constructing games on networks for controlling the inequalities in the   capital distribution",
        "authors": [
            "Jarosław Adam Miszczak"
        ],
        "summary": "The inequality in capital or resource distribution is among the important phenomena observed in populations. The sources of inequality and methods for controlling it are of practical interest. To study this phenomenon, we introduce a model of interaction between agents in the network designed for reducing the inequality in the distribution of capital. To achieve the effect of inequality reduction, we interpret the outcome of the elementary game played in the network such that the wining of the game is translated into the reduction of the inequality. We study different interpretations of the introduced scheme and their impact on the behaviour of agents in the terms of the capital distribution, and we provide examples based on the capital dependent Parrondo's paradox. The results presented in this study provide insight into the mechanics of the inequality formation in the society.",
        "published": "2022-01-26T13:02:45Z",
        "link": "http://arxiv.org/abs/2201.10913v1",
        "categories": [
            "physics.soc-ph",
            "cond-mat.stat-mech",
            "cs.GT",
            "cs.MA",
            "05C57, 62C86"
        ]
    },
    {
        "title": "Behavior Tree-Based Task Planning for Multiple Mobile Robots using a   Data Distribution Service",
        "authors": [
            "Seungwoo Jeong",
            "Taekwon Ga",
            "Inhwan Jeong",
            "Jongeun Choi"
        ],
        "summary": "In this study, we propose task planning framework for multiple robots that builds on a behavior tree (BT). BTs communicate with a data distribution service (DDS) to send and receive data. Since the standard BT derived from one root node with a single tick is unsuitable for multiple robots, a novel type of BT action and improved nodes are proposed to control multiple robots through a DDS asynchronously. To plan tasks for robots efficiently, a single task planning unit is implemented with the proposed task types. The task planning unit assigns tasks to each robot simultaneously through a single coalesced BT. If any robot falls into a fault while performing its assigned task, another BT embedded in the robot is executed; the robot enters the recovery mode in order to overcome the fault. To perform this function, the action in the BT corresponding to the task is defined as a variable, which is shared with the DDS so that any action can be exchanged between the task planning unit and robots. To show the feasibility of our framework in a real-world application, three mobile robots were experimentally coordinated for them to travel alternately to four goal positions by the proposed single task planning unit via a DDS.",
        "published": "2022-01-26T13:16:02Z",
        "link": "http://arxiv.org/abs/2201.10918v2",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA",
            "cs.NI"
        ]
    },
    {
        "title": "Social Learning under Randomized Collaborations",
        "authors": [
            "Yunus Inan",
            "Mert Kayaalp",
            "Emre Telatar",
            "Ali H. Sayed"
        ],
        "summary": "We study a social learning scheme where at every time instant, each agent chooses to receive information from one of its neighbors at random. We show that under this sparser communication scheme, the agents learn the truth eventually and the asymptotic convergence rate remains the same as the standard algorithms which use more communication resources. We also derive large deviation estimates of the log-belief ratios for a special case where each agent replaces its belief with that of the chosen neighbor.",
        "published": "2022-01-26T14:19:45Z",
        "link": "http://arxiv.org/abs/2201.10957v2",
        "categories": [
            "cs.MA",
            "cs.SI",
            "eess.SP"
        ]
    },
    {
        "title": "Distributed gradient-based optimization in the presence of dependent   aperiodic communication",
        "authors": [
            "Adrian Redder",
            "Arunselvan Ramaswamy",
            "Holger Karl"
        ],
        "summary": "Iterative distributed optimization algorithms involve multiple agents that communicate with each other, over time, in order to minimize/maximize a global objective. In the presence of unreliable communication networks, the Age-of-Information (AoI), which measures the freshness of data received, may be large and hence hinder algorithmic convergence. In this paper, we study the convergence of general distributed gradient-based optimization algorithms in the presence of communication that neither happens periodically nor at stochastically independent points in time. We show that convergence is guaranteed provided the random variables associated with the AoI processes are stochastically dominated by a random variable with finite first moment. This improves on previous requirements of boundedness of more than the first moment. We then introduce stochastically strongly connected (SSC) networks, a new stochastic form of strong connectedness for time-varying networks. We show: If for any $p \\ge0$ the processes that describe the success of communication between agents in a SSC network are $\\alpha$-mixing with $n^{p-1}\\alpha(n)$ summable, then the associated AoI processes are stochastically dominated by a random variable with finite $p$-th moment. In combination with our first contribution, this implies that distributed stochastic gradient descend converges in the presence of AoI, if $\\alpha(n)$ is summable.",
        "published": "2022-01-27T06:44:04Z",
        "link": "http://arxiv.org/abs/2201.11343v1",
        "categories": [
            "math.OC",
            "cs.LG",
            "cs.MA",
            "math.PR"
        ]
    },
    {
        "title": "Human-centered mechanism design with Democratic AI",
        "authors": [
            "Raphael Koster",
            "Jan Balaguer",
            "Andrea Tacchetti",
            "Ari Weinstein",
            "Tina Zhu",
            "Oliver Hauser",
            "Duncan Williams",
            "Lucy Campbell-Gillingham",
            "Phoebe Thacker",
            "Matthew Botvinick",
            "Christopher Summerfield"
        ],
        "summary": "Building artificial intelligence (AI) that aligns with human values is an unsolved problem. Here, we developed a human-in-the-loop research pipeline called Democratic AI, in which reinforcement learning is used to design a social mechanism that humans prefer by majority. A large group of humans played an online investment game that involved deciding whether to keep a monetary endowment or to share it with others for collective benefit. Shared revenue was returned to players under two different redistribution mechanisms, one designed by the AI and the other by humans. The AI discovered a mechanism that redressed initial wealth imbalance, sanctioned free riders, and successfully won the majority vote. By optimizing for human preferences, Democratic AI may be a promising method for value-aligned policy innovation.",
        "published": "2022-01-27T10:56:33Z",
        "link": "http://arxiv.org/abs/2201.11441v1",
        "categories": [
            "cs.AI",
            "cs.HC",
            "cs.MA",
            "econ.GN",
            "q-fin.EC"
        ]
    },
    {
        "title": "FCMNet: Full Communication Memory Net for Team-Level Cooperation in   Multi-Agent Systems",
        "authors": [
            "Yutong Wang",
            "Guillaume Sartoretti"
        ],
        "summary": "Decentralized cooperation in partially-observable multi-agent systems requires effective communications among agents. To support this effort, this work focuses on the class of problems where global communications are available but may be unreliable, thus precluding differentiable communication learning methods. We introduce FCMNet, a reinforcement learning based approach that allows agents to simultaneously learn a) an effective multi-hop communications protocol and b) a common, decentralized policy that enables team-level decision-making. Specifically, our proposed method utilizes the hidden states of multiple directional recurrent neural networks as communication messages among agents. Using a simple multi-hop topology, we endow each agent with the ability to receive information sequentially encoded by every other agent at each time step, leading to improved global cooperation. We demonstrate FCMNet on a challenging set of StarCraft II micromanagement tasks with shared rewards, as well as a collaborative multi-agent pathfinding task with individual rewards. There, our comparison results show that FCMNet outperforms state-of-the-art communication-based reinforcement learning methods in all StarCraft II micromanagement tasks, and value decomposition methods in certain tasks. We further investigate the robustness of FCMNet under realistic communication disturbances, such as random message loss or binarized messages (i.e., non-differentiable communication channels), to showcase FMCNet's potential applicability to robotic tasks under a variety of real-world conditions.",
        "published": "2022-01-28T09:12:01Z",
        "link": "http://arxiv.org/abs/2201.11994v2",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Backdoors Stuck At The Frontdoor: Multi-Agent Backdoor Attacks That   Backfire",
        "authors": [
            "Siddhartha Datta",
            "Nigel Shadbolt"
        ],
        "summary": "Malicious agents in collaborative learning and outsourced data collection threaten the training of clean models. Backdoor attacks, where an attacker poisons a model during training to successfully achieve targeted misclassification, are a major concern to train-time robustness. In this paper, we investigate a multi-agent backdoor attack scenario, where multiple attackers attempt to backdoor a victim model simultaneously. A consistent backfiring phenomenon is observed across a wide range of games, where agents suffer from a low collective attack success rate. We examine different modes of backdoor attack configurations, non-cooperation / cooperation, joint distribution shifts, and game setups to return an equilibrium attack success rate at the lower bound. The results motivate the re-evaluation of backdoor defense research for practical environments.",
        "published": "2022-01-28T16:11:40Z",
        "link": "http://arxiv.org/abs/2201.12211v1",
        "categories": [
            "cs.LG",
            "cs.CR",
            "cs.MA"
        ]
    },
    {
        "title": "Learning Stationary Nash Equilibrium Policies in $n$-Player Stochastic   Games with Independent Chains",
        "authors": [
            "S. Rasoul Etesami"
        ],
        "summary": "We consider a subclass of $n$-player stochastic games, in which players have their own internal state/action spaces while they are coupled through their payoff functions. It is assumed that players' internal chains are driven by independent transition probabilities. Moreover, players can receive only realizations of their payoffs, not the actual functions, and cannot observe each other's states/actions. For this class of games, we first show that finding a stationary Nash equilibrium (NE) policy without any assumption on the reward functions is interactable. However, for general reward functions, we develop polynomial-time learning algorithms based on dual averaging and dual mirror descent, which converge in terms of the averaged Nikaido-Isoda distance to the set of $\\epsilon$-NE policies almost surely or in expectation. In particular, under extra assumptions on the reward functions such as social concavity, we derive polynomial upper bounds on the number of iterates to achieve an $\\epsilon$-NE policy with high probability. Finally, we evaluate the effectiveness of the proposed algorithms in learning $\\epsilon$-NE policies using numerical experiments for energy management in smart grids.",
        "published": "2022-01-28T16:27:21Z",
        "link": "http://arxiv.org/abs/2201.12224v4",
        "categories": [
            "cs.LG",
            "cs.GT",
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "math.OC"
        ]
    },
    {
        "title": "Efficient Policy Space Response Oracles",
        "authors": [
            "Ming Zhou",
            "Jingxiao Chen",
            "Ying Wen",
            "Weinan Zhang",
            "Yaodong Yang",
            "Yong Yu",
            "Jun Wang"
        ],
        "summary": "Policy Space Response Oracle methods (PSRO) provide a general solution to learn Nash equilibrium in two-player zero-sum games but suffer from two drawbacks: (1) the computation inefficiency due to the need for consistent meta-game evaluation via simulations, and (2) the exploration inefficiency due to finding the best response against a fixed meta-strategy at every epoch. In this work, we propose Efficient PSRO (EPSRO) that largely improves the efficiency of the above two steps. Central to our development is the newly-introduced subroutine of no-regret optimization on the unrestricted-restricted (URR) game. By solving URR at each epoch, one can evaluate the current game and compute the best response in one forward pass without the need for meta-game simulations. Theoretically, we prove that the solution procedures of EPSRO offer a monotonic improvement on the exploitability, which none of existing PSRO methods possess. Furthermore, we prove that the no-regret optimization has a regret bound of $\\mathcal{O}(\\sqrt{T\\log{[(k^2+k)/2]}})$, where $k$ is the size of restricted policy set. Most importantly, a desirable property of EPSRO is that it is parallelizable, this allows for highly efficient exploration in the policy space that induces behavioral diversity. We test EPSRO on three classes of games, and report a 50x speedup in wall-time and 10x data efficiency while maintaining similar exploitability as existing PSRO methods on Kuhn and Leduc Poker games.",
        "published": "2022-01-28T17:54:45Z",
        "link": "http://arxiv.org/abs/2202.00633v4",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "The Price of Majority Support",
        "authors": [
            "Robin Fritsch",
            "Roger Wattenhofer"
        ],
        "summary": "We consider the problem of finding a compromise between the opinions of a group of individuals on a number of mutually independent, binary topics. In this paper, we quantify the loss in representativeness that results from requiring the outcome to have majority support, in other words, the \"price of majority support\". Each individual is assumed to support an outcome if they agree with the outcome on at least as many topics as they disagree on. Our results can also be seen as quantifying Anscombes paradox which states that topic-wise majority outcome may not be supported by a majority. To measure the representativeness of an outcome, we consider two metrics. First, we look for an outcome that agrees with a majority on as many topics as possible. We prove that the maximum number such that there is guaranteed to exist an outcome that agrees with a majority on this number of topics and has majority support, equals $\\ceil{(t+1)/2}$ where $t$ is the total number of topics. Second, we count the number of times a voter opinion on a topic matches the outcome on that topic. The goal is to find the outcome with majority support with the largest number of matches. We consider the ratio between this number and the number of matches of the overall best outcome which may not have majority support. We try to find the maximum ratio such that an outcome with majority support and this ratio of matches compared to the overall best is guaranteed to exist. For 3 topics, we show this ratio to be $5/6\\approx 0.83$. In general, we prove an upper bound that comes arbitrarily close to $2\\sqrt{6}-4\\approx 0.90$ as $t$ tends to infinity. Furthermore, we numerically compute a better upper and a non-matching lower bound in the relevant range for $t$.",
        "published": "2022-01-28T18:09:16Z",
        "link": "http://arxiv.org/abs/2201.12303v1",
        "categories": [
            "cs.LG",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Machine Learning Based Relative Orbit Transfer for Swarm Spacecraft   Motion Planning",
        "authors": [
            "Alex Sabol",
            "Kyongsik Yun",
            "Muhammad Adil",
            "Changrak Choi",
            "Ramtin Madani"
        ],
        "summary": "In this paper we describe a machine learning based framework for spacecraft swarm trajectory planning. In particular, we focus on coordinating motions of multi-spacecraft in formation flying through passive relative orbit(PRO) transfers. Accounting for spacecraft dynamics while avoiding collisions between the agents makes spacecraft swarm trajectory planning difficult. Centralized approaches can be used to solve this problem, but are computationally demanding and scale poorly with the number of agents in the swarm. As a result, centralized algorithms are ill-suited for real time trajectory planning on board small spacecraft (e.g. CubeSats) comprising the swarm. In our approach a neural network is used to approximate solutions of a centralized method. The necessary training data is generated using a centralized convex optimization framework through which several instances of the n=10 spacecraft swarm trajectory planning problem are solved. We are interested in answering the following questions which will give insight on the potential utility of deep learning-based approaches to the multi-spacecraft motion planning problem: 1) Can neural networks produce feasible trajectories that satisfy safety constraints (e.g. collision avoidance) and low in fuel cost? 2) Can a neural network trained using n spacecraft data be used to solve problems for spacecraft swarms of differing size?",
        "published": "2022-01-28T18:59:58Z",
        "link": "http://arxiv.org/abs/2201.12338v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Any-Play: An Intrinsic Augmentation for Zero-Shot Coordination",
        "authors": [
            "Keane Lucas",
            "Ross E. Allen"
        ],
        "summary": "Cooperative artificial intelligence with human or superhuman proficiency in collaborative tasks stands at the frontier of machine learning research. Prior work has tended to evaluate cooperative AI performance under the restrictive paradigms of self-play (teams composed of agents trained together) and cross-play (teams of agents trained independently but using the same algorithm). Recent work has indicated that AI optimized for these narrow settings may make for undesirable collaborators in the real-world. We formalize an alternative criteria for evaluating cooperative AI, referred to as inter-algorithm cross-play, where agents are evaluated on teaming performance with all other agents within an experiment pool with no assumption of algorithmic similarities between agents. We show that existing state-of-the-art cooperative AI algorithms, such as Other-Play and Off-Belief Learning, under-perform in this paradigm. We propose the Any-Play learning augmentation -- a multi-agent extension of diversity-based intrinsic rewards for zero-shot coordination (ZSC) -- for generalizing self-play-based algorithms to the inter-algorithm cross-play setting. We apply the Any-Play learning augmentation to the Simplified Action Decoder (SAD) and demonstrate state-of-the-art performance in the collaborative card game Hanabi.",
        "published": "2022-01-28T21:43:58Z",
        "link": "http://arxiv.org/abs/2201.12436v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "I.2.11"
        ]
    },
    {
        "title": "Fair Stable Matching Meets Correlated Preferences",
        "authors": [
            "Angelina Brilliantova",
            "Hadi Hosseini"
        ],
        "summary": "The stable matching problem sets the economic foundation of several practical applications ranging from school choice and medical residency to ridesharing and refugee placement. It is concerned with finding a matching between two disjoint sets of agents wherein no pair of agents prefer each other to their matched partners. The Deferred Acceptance (DA) algorithm is an elegant procedure that guarantees a stable matching for any input; however, its outcome may be unfair as it always favors one side by returning a matching that is optimal for one side (say men) and pessimal for the other side (say women). A desirable fairness notion is minimizing the sex-equality cost, i.e. the difference between the total rankings of both sides. Computing such stable matchings is a strongly NP-hard problem, which raises the question of what tractable algorithms to adopt in practice. We conduct a series of empirical evaluations on the properties of sex-equal stable matchings when preferences of agents on both sides are correlated. Our empirical results suggest that under correlated preferences, the DA algorithm returns stable matchings with low sex-equality cost, which further confirms its broad use in many practical applications.",
        "published": "2022-01-29T03:14:01Z",
        "link": "http://arxiv.org/abs/2201.12484v1",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "A Context-Integrated Transformer-Based Neural Network for Auction Design",
        "authors": [
            "Zhijian Duan",
            "Jingwu Tang",
            "Yutong Yin",
            "Zhe Feng",
            "Xiang Yan",
            "Manzil Zaheer",
            "Xiaotie Deng"
        ],
        "summary": "One of the central problems in auction design is developing an incentive-compatible mechanism that maximizes the auctioneer's expected revenue. While theoretical approaches have encountered bottlenecks in multi-item auctions, recently, there has been much progress on finding the optimal mechanism through deep learning. However, these works either focus on a fixed set of bidders and items, or restrict the auction to be symmetric. In this work, we overcome such limitations by factoring \\emph{public} contextual information of bidders and items into the auction learning framework. We propose $\\mathtt{CITransNet}$, a context-integrated transformer-based neural network for optimal auction design, which maintains permutation-equivariance over bids and contexts while being able to find asymmetric solutions. We show by extensive experiments that $\\mathtt{CITransNet}$ can recover the known optimal solutions in single-item settings, outperform strong baselines in multi-item auctions, and generalize well to cases other than those in training.",
        "published": "2022-01-29T03:47:00Z",
        "link": "http://arxiv.org/abs/2201.12489v3",
        "categories": [
            "cs.GT",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Transport Capacity Optimization for Resource Allocation in Tera-IoT   Networks",
        "authors": [
            "Cheol Jeong",
            "Chang-Jae Chun",
            "Won-Yong Shin",
            "Il-Min Kim"
        ],
        "summary": "We present a new adaptive resource optimization strategy that jointly allocates the subwindow and transmit power in multi-device terahertz (THz) band Internet of Things (Tera-IoT) networks. Unlike the prior studies focusing mostly on maximizing the sum distance, we incorporate both rate and transmission distance into the objective function of our problem formulation with key features of THz bands, including the spreading and molecular absorption losses. More specifically, as a performance metric of Tera-IoT networks, we adopt the transport capacity (TC), which is defined as the sum of the rate-distance products over all users. This metric has been widely adopted in large-scale ad hoc networks, and would also be appropriate for evaluating the performance of various Tera-IoT applications. We then formulate an optimization problem that aims at maximizing the TC. Moreover, motivated by the importance of the transmission distance that is very limited due to the high path loss in THz bands, our optimization problem is extended to the case of allocating the subwindow, transmit power, and transmission distance. We show how to solve our problems via an effective two-stage resource allocation strategy. We demonstrate the superiority of our adaptive solution over benchmark methods via intensive numerical evaluations for various environmental setups of large-scale Tera-IoT networks.",
        "published": "2022-01-29T10:17:12Z",
        "link": "http://arxiv.org/abs/2201.12548v1",
        "categories": [
            "cs.IT",
            "cs.DC",
            "cs.MA",
            "cs.NI",
            "math.IT"
        ]
    },
    {
        "title": "On Optimizing Shared-ride Mobility Services with Walking Legs",
        "authors": [
            "Zifan Wang",
            "Michael F Hyland",
            "Younghun Bahk",
            "Navjyoth JS Sarma"
        ],
        "summary": "Shared-ride mobility services that incorporate traveler walking legs aim to reduce vehicle-kilometers-travelled (VKT), vehicle-hours-travelled (VHT), request rejections, fleet size, or some combination of these factors, compared to door-to-door (D2D) shared-ride services. This paper provides a review of shared-ride services with walking legs (SRSWL), particularly the studies in the literature that model the operational problem(s) associated with SRSWL. The paper describes the operational and societal benefits of SRSWL as well as compares the SRSWL to circuitous D2D shared-ride services, ride-hailing services, and fixed-route transit services, in terms of VKT and traveler walking distance. The paper then delineates the operational subproblems associated with the SRSWL and discusses their computational complexity. Additionally, the review classifies configurations of SRSWL based on flexibility in assigning travelers to pickup and drop-off locations. The paper also discusses four modelling challenge: short-distance person trips, drop-off location choice for a vehicle's last remaining passenger, allowing vehicles to wait for travelers at pickup locations, and simultaneously reducing VHT/VKT and improving customer service quality relative to D2D shared-ride services. The review paper concludes by discussing the most critical areas of future research related to SRSWL.",
        "published": "2022-01-29T19:28:18Z",
        "link": "http://arxiv.org/abs/2201.12639v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Learning Intuitive Policies Using Action Features",
        "authors": [
            "Mingwei Ma",
            "Jizhou Liu",
            "Samuel Sokota",
            "Max Kleiman-Weiner",
            "Jakob Foerster"
        ],
        "summary": "An unaddressed challenge in multi-agent coordination is to enable AI agents to exploit the semantic relationships between the features of actions and the features of observations. Humans take advantage of these relationships in highly intuitive ways. For instance, in the absence of a shared language, we might point to the object we desire or hold up our fingers to indicate how many objects we want. To address this challenge, we investigate the effect of network architecture on the propensity of learning algorithms to exploit these semantic relationships. Across a procedurally generated coordination task, we find that attention-based architectures that jointly process a featurized representation of observations and actions have a better inductive bias for learning intuitive policies. Through fine-grained evaluation and scenario analysis, we show that the resulting policies are human-interpretable. Moreover, such agents coordinate with people without training on any human data.",
        "published": "2022-01-29T20:54:52Z",
        "link": "http://arxiv.org/abs/2201.12658v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Communication-Efficient Consensus Mechanism for Federated Reinforcement   Learning",
        "authors": [
            "Xing Xu",
            "Rongpeng Li",
            "Zhifeng Zhao",
            "Honggang Zhang"
        ],
        "summary": "The paper considers independent reinforcement learning (IRL) for multi-agent decision-making process in the paradigm of federated learning (FL). We show that FL can clearly improve the policy performance of IRL in terms of training efficiency and stability. However, since the policy parameters are trained locally and aggregated iteratively through a central server in FL, frequent information exchange incurs a large amount of communication overheads. To reach a good balance between improving the model's convergence performance and reducing the required communication and computation overheads, this paper proposes a system utility function and develops a consensus-based optimization scheme on top of the periodic averaging method, which introduces the consensus algorithm into FL for the exchange of a model's local gradients. This paper also provides novel convergence guarantees for the developed method, and demonstrates its superior effectiveness and efficiency in improving the system utility value through theoretical analyses and numerical simulation results.",
        "published": "2022-01-30T04:04:24Z",
        "link": "http://arxiv.org/abs/2201.12718v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Learning Collective Action under Risk Diversity",
        "authors": [
            "Ramona Merhej",
            "Fernando P. Santos",
            "Francisco S. Melo",
            "Mohamed Chetouani",
            "Francisco C. Santos"
        ],
        "summary": "Collective risk dilemmas (CRDs) are a class of n-player games that represent societal challenges where groups need to coordinate to avoid the risk of a disastrous outcome. Multi-agent systems incurring such dilemmas face difficulties achieving cooperation and often converge to sub-optimal, risk-dominant solutions where everyone defects. In this paper we investigate the consequences of risk diversity in groups of agents learning to play CRDs. We find that risk diversity places new challenges to cooperation that are not observed in homogeneous groups. We show that increasing risk diversity significantly reduces overall cooperation and hinders collective target achievement. It leads to asymmetrical changes in agents' policies -- i.e. the increase in contributions from individuals at high risk is unable to compensate for the decrease in contributions from individuals at low risk -- which overall reduces the total contributions in a population. When comparing RL behaviors to rational individualistic and social behaviors, we find that RL populations converge to fairer contributions among agents. Our results highlight the need for aligning risk perceptions among agents or develop new learning techniques that explicitly account for risk diversity.",
        "published": "2022-01-30T18:21:21Z",
        "link": "http://arxiv.org/abs/2201.12891v1",
        "categories": [
            "cs.MA",
            "cs.GT",
            "cs.LG"
        ]
    },
    {
        "title": "Generalization in Cooperative Multi-Agent Systems",
        "authors": [
            "Anuj Mahajan",
            "Mikayel Samvelyan",
            "Tarun Gupta",
            "Benjamin Ellis",
            "Mingfei Sun",
            "Tim Rocktäschel",
            "Shimon Whiteson"
        ],
        "summary": "Collective intelligence is a fundamental trait shared by several species of living organisms. It has allowed them to thrive in the diverse environmental conditions that exist on our planet. From simple organisations in an ant colony to complex systems in human groups, collective intelligence is vital for solving complex survival tasks. As is commonly observed, such natural systems are flexible to changes in their structure. Specifically, they exhibit a high degree of generalization when the abilities or the total number of agents changes within a system. We term this phenomenon as Combinatorial Generalization (CG). CG is a highly desirable trait for autonomous systems as it can increase their utility and deployability across a wide range of applications. While recent works addressing specific aspects of CG have shown impressive results on complex domains, they provide no performance guarantees when generalizing towards novel situations. In this work, we shed light on the theoretical underpinnings of CG for cooperative multi-agent systems (MAS). Specifically, we study generalization bounds under a linear dependence of the underlying dynamics on the agent capabilities, which can be seen as a generalization of Successor Features to MAS. We then extend the results first for Lipschitz and then arbitrary dependence of rewards on team capabilities. Finally, empirical analysis on various domains using the framework of multi-agent reinforcement learning highlights important desiderata for multi-agent algorithms towards ensuring CG.",
        "published": "2022-01-31T21:39:56Z",
        "link": "http://arxiv.org/abs/2202.00104v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Learning to Speak on Behalf of a Group: Medium Access Control for   Sending a Shared Message",
        "authors": [
            "Shaan ul Haque",
            "Siddharth Chandak",
            "Federico Chiariotti",
            "Deniz Gunduz",
            "Petar Popovski"
        ],
        "summary": "The rapid development of Industrial Internet of Things (IIoT) technologies has not only enabled new applications, but also presented new challenges for reliable communication with limited resources. In this work, we define a deceptively simple novel problem that can arise in these scenarios, in which a set of sensors need to communicate a joint observation. This observation is shared by a random subset of the nodes, which need to propagate it to the rest of the network, but coordination is complex: as signaling constraints require the use of random access schemes over shared channels, each sensor needs to implicitly coordinate with others with the same observation, so that at least one of the transmissions gets through without collisions. Unlike existing medium access control schemes, the goal here is not to maximize total goodput, but rather to make sure that the shared message gets through, regardless of the sender. The lack of any signaling, aside from an acknowledgment or lack thereof from the rest of the network, makes determining the optimal collective transmission strategy a significant challenge. We analyze this coordination problem theoretically, prove its hardness, and provide low-complexity solutions. While a low-complexity clustering-based approach is shown to provide near-optimal performance in certain special cases, for the general scenarios, we model each sensor as a multi-armed bandit (MAB), and provide a learning-based solution. Numerical results show the effectiveness of this approach in a variety of cases.",
        "published": "2022-02-01T13:29:25Z",
        "link": "http://arxiv.org/abs/2202.00401v1",
        "categories": [
            "cs.NI",
            "cs.MA"
        ]
    },
    {
        "title": "Black-box Bayesian inference for economic agent-based models",
        "authors": [
            "Joel Dyer",
            "Patrick Cannon",
            "J. Doyne Farmer",
            "Sebastian Schmon"
        ],
        "summary": "Simulation models, in particular agent-based models, are gaining popularity in economics. The considerable flexibility they offer, as well as their capacity to reproduce a variety of empirically observed behaviours of complex systems, give them broad appeal, and the increasing availability of cheap computing power has made their use feasible. Yet a widespread adoption in real-world modelling and decision-making scenarios has been hindered by the difficulty of performing parameter estimation for such models. In general, simulation models lack a tractable likelihood function, which precludes a straightforward application of standard statistical inference techniques. Several recent works have sought to address this problem through the application of likelihood-free inference techniques, in which parameter estimates are determined by performing some form of comparison between the observed data and simulation output. However, these approaches are (a) founded on restrictive assumptions, and/or (b) typically require many hundreds of thousands of simulations. These qualities make them unsuitable for large-scale simulations in economics and can cast doubt on the validity of these inference methods in such scenarios. In this paper, we investigate the efficacy of two classes of black-box approximate Bayesian inference methods that have recently drawn significant attention within the probabilistic machine learning community: neural posterior estimation and neural density ratio estimation. We present benchmarking experiments in which we demonstrate that neural network based black-box methods provide state of the art parameter inference for economic simulation models, and crucially are compatible with generic multivariate time-series data. In addition, we suggest appropriate assessment criteria for future benchmarking of approximate Bayesian inference procedures for economic simulation models.",
        "published": "2022-02-01T18:16:12Z",
        "link": "http://arxiv.org/abs/2202.00625v1",
        "categories": [
            "econ.EM",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Ranging-Based Localizability Optimization for Mobile Robotic Networks",
        "authors": [
            "Justin Cano",
            "Jerome Le Ny"
        ],
        "summary": "In robotic networks relying on noisy range measurements between agents for cooperative localization, the achievable positioning accuracy strongly strongly depends on the network geometry. This motivates the problem of planning robot trajectories in such multi-robot systems in a way that maintains high localization accuracy. We present potential-based planning methods, where localizability potentials are introduced to characterize the quality of the network geometry for cooperative position estimation. These potentials are based on Cramer Rao Lower Bounds (CRLB) and provide a theoretical lower bound on the error covariance achievable by any unbiased position estimator. In the process, we establish connections between CRLBs and the theory of graph rigidity, which has been previously used to plan the motion of robotic networks. We develop decentralized deployment algorithms appropriate for large networks, and we use equality-constrained CRLBs to extend the concept of localizability to scenarios where additional information about the relative positions of the ranging sensors is known. We illustrate the resulting robot deployment methodology through simulated examples and an experiment.",
        "published": "2022-02-01T21:03:10Z",
        "link": "http://arxiv.org/abs/2202.00756v2",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "On the Global Convergence Rates of Decentralized Softmax Gradient Play   in Markov Potential Games",
        "authors": [
            "Runyu Zhang",
            "Jincheng Mei",
            "Bo Dai",
            "Dale Schuurmans",
            "Na Li"
        ],
        "summary": "Softmax policy gradient is a popular algorithm for policy optimization in single-agent reinforcement learning, particularly since projection is not needed for each gradient update. However, in multi-agent systems, the lack of central coordination introduces significant additional difficulties in the convergence analysis. Even for a stochastic game with identical interest, there can be multiple Nash Equilibria (NEs), which disables proof techniques that rely on the existence of a unique global optimum. Moreover, the softmax parameterization introduces non-NE policies with zero gradient, making it difficult for gradient-based algorithms in seeking NEs. In this paper, we study the finite time convergence of decentralized softmax gradient play in a special form of game, Markov Potential Games (MPGs), which includes the identical interest game as a special case. We investigate both gradient play and natural gradient play, with and without $\\log$-barrier regularization. The established convergence rates for the unregularized cases contain a trajectory-dependent constant that can be arbitrarily large, whereas the $\\log$-barrier regularization overcomes this drawback, with the cost of slightly worse dependence on other factors such as the action set size. An empirical study on an identical interest matrix game confirms the theoretical findings.",
        "published": "2022-02-02T04:32:11Z",
        "link": "http://arxiv.org/abs/2202.00872v2",
        "categories": [
            "math.OC",
            "cs.MA"
        ]
    },
    {
        "title": "Dynamic Time Slot Allocation Algorithm for Quadcopter Swarms",
        "authors": [
            "Sharif Azem",
            "Anam Tahir",
            "Heinz Koeppl"
        ],
        "summary": "A swarm of quadcopters can perform cooperative tasks, such as monitoring of a large area, more efficiently than a single one. However, to be able to successfully work together, the quadcopters must be aware of the position of the other swarm members, especially to avoid collisions. A quadcopter can share its own position by transmitting it via radio waves and in order to allow multiple quadcopters to communicate effectively, a decentralized channel access protocol is essential. We propose a new dynamic channel access protocol, called Dynamic time slot allocation (DTSA), where the quadcopters share the total channel access time in a non-periodic and decentralized manner. Quadcopters with higher communication demands occupy more time slots than less active ones. Our dynamic approach allows the agents to adapt to changing swarm situations and therefore to act efficiently, as compared to the state-of-the-art periodic channel access protocol, time division multiple access (TDMA). Along with simulations, we also do experiments using real Crazyflie quadcopters to show the improved performance of DTSA as compared to TDMA.",
        "published": "2022-02-02T09:02:16Z",
        "link": "http://arxiv.org/abs/2202.00919v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "CTMSTOU driven markets: simulated environment for regime-awareness in   trading policies",
        "authors": [
            "Selim Amrouni",
            "Aymeric Moulin",
            "Tucker Balch"
        ],
        "summary": "Market regimes is a popular topic in quantitative finance even though there is little consensus on the details of how they should be defined. They arise as a feature both in financial market prediction problems and financial market task performing problems.   In this work we use discrete event time multi-agent market simulation to freely experiment in a reproducible and understandable environment where regimes can be explicitly switched and enforced.   We introduce a novel stochastic process to model the fundamental value perceived by market participants: Continuous-Time Markov Switching Trending Ornstein-Uhlenbeck (CTMSTOU), which facilitates the study of trading policies in regime switching markets.   We define the notion of regime-awareness for a trading agent as well and illustrate its importance through the study of different order placement strategies in the context of order execution problems.",
        "published": "2022-02-02T10:27:12Z",
        "link": "http://arxiv.org/abs/2202.00941v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "econ.GN",
            "q-fin.EC",
            "q-fin.MF"
        ]
    },
    {
        "title": "Minimizing Expected Intrusion Detection Time in Adversarial Patrolling",
        "authors": [
            "David Klaška",
            "Antonín Kučera",
            "Vít Musil",
            "Vojtěch Řehák"
        ],
        "summary": "In adversarial patrolling games, a mobile Defender strives to discover intrusions at vulnerable targets initiated by an Attacker. The Attacker's utility is traditionally defined as the probability of completing an attack, possibly weighted by target costs. However, in many real-world scenarios, the actual damage caused by the Attacker depends on the \\emph{time} elapsed since the attack's initiation to its detection. We introduce a formal model for such scenarios, and we show that the Defender always has an \\emph{optimal} strategy achieving maximal protection. We also prove that \\emph{finite-memory} Defender's strategies are sufficient for achieving protection arbitrarily close to the optimum. Then, we design an efficient \\emph{strategy synthesis} algorithm based on differentiable programming and gradient descent.",
        "published": "2022-02-02T15:50:12Z",
        "link": "http://arxiv.org/abs/2202.01095v1",
        "categories": [
            "cs.MA",
            "68T42",
            "I.2.9"
        ]
    },
    {
        "title": "Transfer in Reinforcement Learning via Regret Bounds for Learning Agents",
        "authors": [
            "Adrienne Tuynman",
            "Ronald Ortner"
        ],
        "summary": "We present an approach for the quantification of the usefulness of transfer in reinforcement learning via regret bounds for a multi-agent setting. Considering a number of $\\aleph$ agents operating in the same Markov decision process, however possibly with different reward functions, we consider the regret each agent suffers with respect to an optimal policy maximizing her average reward. We show that when the agents share their observations the total regret of all agents is smaller by a factor of $\\sqrt{\\aleph}$ compared to the case when each agent has to rely on the information collected by herself. This result demonstrates how considering the regret in multi-agent settings can provide theoretical bounds on the benefit of sharing observations in transfer learning.",
        "published": "2022-02-02T18:10:21Z",
        "link": "http://arxiv.org/abs/2202.01182v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Data-Driven Behaviour Estimation in Parametric Games",
        "authors": [
            "Anna M. Maddux",
            "Nicolò Pagan",
            "Giuseppe Belgioioso",
            "Florian Dörfler"
        ],
        "summary": "A central question in multi-agent strategic games deals with learning the underlying utilities driving the agents' behaviour. Motivated by the increasing availability of large data-sets, we develop an unifying data-driven technique to estimate agents' utility functions from their observed behaviour, irrespective of whether the observations correspond to equilibrium configurations or to temporal sequences of action profiles. Under standard assumptions on the parametrization of the utilities, the proposed inference method is computationally efficient and finds all the parameters that rationalize the observed behaviour best. We numerically validate our theoretical findings on the market share estimation problem under advertising competition, using historical data from the Coca-Cola Company and Pepsi Inc. duopoly.",
        "published": "2022-02-02T19:00:02Z",
        "link": "http://arxiv.org/abs/2202.01229v4",
        "categories": [
            "math.OC",
            "cs.GT",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Learning from a Learning User for Optimal Recommendations",
        "authors": [
            "Fan Yao",
            "Chuanhao Li",
            "Denis Nekipelov",
            "Hongning Wang",
            "Haifeng Xu"
        ],
        "summary": "In real-world recommendation problems, especially those with a formidably large item space, users have to gradually learn to estimate the utility of any fresh recommendations from their experience about previously consumed items. This in turn affects their interaction dynamics with the system and can invalidate previous algorithms built on the omniscient user assumption. In this paper, we formalize a model to capture such \"learning users\" and design an efficient system-side learning solution, coined Noise-Robust Active Ellipsoid Search (RAES), to confront the challenges brought by the non-stationary feedback from such a learning user. Interestingly, we prove that the regret of RAES deteriorates gracefully as the convergence rate of user learning becomes worse, until reaching linear regret when the user's learning fails to converge. Experiments on synthetic datasets demonstrate the strength of RAES for such a contemporaneous system-user learning problem. Our study provides a novel perspective on modeling the feedback loop in recommendation problems.",
        "published": "2022-02-03T22:45:12Z",
        "link": "http://arxiv.org/abs/2202.01879v1",
        "categories": [
            "cs.LG",
            "cs.IR",
            "cs.MA"
        ]
    },
    {
        "title": "HENRI: High Efficiency Negotiation-based Robust Interface for   Multi-party Multi-issue Negotiation over the Internet",
        "authors": [
            "Saurabh Deochake",
            "Shashank Kanth",
            "Subhadip Chakraborty",
            "Suresh Sarode",
            "Vidyasagar Potdar",
            "Debajyoti Mukhopadhyay"
        ],
        "summary": "This paper proposes a framework for a full fledged negotiation system that allows multi party multi issue negotiation. It focuses on the negotiation protocol to be observed and provides a platform for concurrent and independent negotiation on individual issues using the concept of multi threading. It depicts the architecture of an agent detailing its components. The paper sets forth a hierarchical pattern for the multiple issues concerning every party. The system also provides enhancements such as the time-to-live counters for every advertisement, refinement of utility considering non-functional attributes, prioritization of issues, by assigning weights to issues.",
        "published": "2022-02-04T23:18:49Z",
        "link": "http://arxiv.org/abs/2202.02430v1",
        "categories": [
            "cs.AI",
            "cs.MA",
            "cs.NI",
            "I.2.11"
        ]
    },
    {
        "title": "Governance of Autonomous Agents on the Web: Challenges and Opportunities",
        "authors": [
            "Timotheus Kampik",
            "Adnane Mansour",
            "Olivier Boissier",
            "Sabrina Kirrane",
            "Julian Padget",
            "Terry R. Payne",
            "Munindar P. Singh",
            "Valentina Tamma",
            "Antoine Zimmermann"
        ],
        "summary": "The study of autonomous agents has a long tradition in the Multiagent Systems and the Semantic Web communities, with applications ranging from automating business processes to personal assistants. More recently, the Web of Things (WoT), which is an extension of the Internet of Things (IoT) with metadata expressed in Web standards, and its community provide further motivation for pushing the autonomous agents research agenda forward. Although representing and reasoning about norms, policies and preferences is crucial to ensuring that autonomous agents act in a manner that satisfies stakeholder requirements, normative concepts, policies and preferences have yet to be considered as first-class abstractions in Web-based multiagent systems. Towards this end, this paper motivates the need for alignment and joint research across the Multiagent Systems, Semantic Web, and WoT communities, introduces a conceptual framework for governance of autonomous agents on the Web, and identifies several research challenges and opportunities.",
        "published": "2022-02-05T15:15:36Z",
        "link": "http://arxiv.org/abs/2202.02574v1",
        "categories": [
            "cs.MA",
            "cs.SE"
        ]
    },
    {
        "title": "EDCHO: High Order Exact Dynamic Consensus",
        "authors": [
            "Rodrigo Aldana-López",
            "Rosario Aragüés",
            "Carlos Sagüés"
        ],
        "summary": "This article addresses the problem of average consensus in a multi-agent system when the desired consensus quantity is a time varying signal. Although this problem has been addressed in existing literature by linear schemes, only bounded steady-state errors have been achieved. Other approaches have used first order sliding modes to achieve zero steady-state error, but suffer from the chattering effect. In this work, we propose a new exact dynamic consensus algorithm which leverages high order sliding modes, in the form of a distributed differentiator to achieve zero steady-state error of the average of time varying reference signals in a group of agents. Moreover, our proposal is also able to achieve consensus to high order derivatives of the average signal, if desired. An in depth formal study on the stability and convergence for EDCHO is provided for undirected connected graphs. Finally, the effectiveness and advantages of our proposal are shown with concrete simulation scenarios.",
        "published": "2022-02-07T09:09:42Z",
        "link": "http://arxiv.org/abs/2202.03012v2",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY",
            "math.OC"
        ]
    },
    {
        "title": "Asynchronous Parallel Incremental Block-Coordinate Descent for   Decentralized Machine Learning",
        "authors": [
            "Hao Chen",
            "Yu Ye",
            "Ming Xiao",
            "Mikael Skoglund"
        ],
        "summary": "Machine learning (ML) is a key technique for big-data-driven modelling and analysis of massive Internet of Things (IoT) based intelligent and ubiquitous computing. For fast-increasing applications and data amounts, distributed learning is a promising emerging paradigm since it is often impractical or inefficient to share/aggregate data to a centralized location from distinct ones. This paper studies the problem of training an ML model over decentralized systems, where data are distributed over many user devices and the learning algorithm run on-device, with the aim of relaxing the burden at a central entity/server. Although gossip-based approaches have been used for this purpose in different use cases, they suffer from high communication costs, especially when the number of devices is large. To mitigate this, incremental-based methods are proposed. We first introduce incremental block-coordinate descent (I-BCD) for the decentralized ML, which can reduce communication costs at the expense of running time. To accelerate the convergence speed, an asynchronous parallel incremental BCD (API-BCD) method is proposed, where multiple devices/agents are active in an asynchronous fashion. We derive convergence properties for the proposed methods. Simulation results also show that our API-BCD method outperforms state of the art in terms of running time and communication costs.",
        "published": "2022-02-07T15:04:15Z",
        "link": "http://arxiv.org/abs/2202.03263v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "A Robot Web for Distributed Many-Device Localisation",
        "authors": [
            "Riku Murai",
            "Joseph Ortiz",
            "Sajad Saeedi",
            "Paul H. J. Kelly",
            "Andrew J. Davison"
        ],
        "summary": "We show that a distributed network of robots or other devices which make measurements of each other can collaborate to globally localise via efficient ad-hoc peer to peer communication. Our Robot Web solution is based on Gaussian Belief Propagation on the fundamental non-linear factor graph describing the probabilistic structure of all of the observations robots make internally or of each other, and is flexible for any type of robot, motion or sensor. We define a simple and efficient communication protocol which can be implemented by the publishing and reading of web pages or other asynchronous communication technologies. We show in simulations with up to 1000 robots interacting in arbitrary patterns that our solution convergently achieves global accuracy as accurate as a centralised non-linear factor graph solver while operating with high distributed efficiency of computation and communication. Via the use of robust factors in GBP, our method is tolerant to a high percentage of faults in sensor measurements or dropped communication packets.",
        "published": "2022-02-07T16:00:25Z",
        "link": "http://arxiv.org/abs/2202.03314v2",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Probabilistic Consensus on Feature Distribution for Multi-robot Systems   with Markovian Exploration Dynamics",
        "authors": [
            "Aniket Shirsat",
            "Shatadal Mishra",
            "Wenlong Zhang",
            "Spring Berman"
        ],
        "summary": "In this paper, we present a consensus-based decentralized multi-robot approach to reconstruct a discrete distribution of features, modeled as an occupancy grid map, that represent information contained in a bounded planar 2D environment, such as visual cues used for navigation or semantic labels associated with object detection. The robots explore the environment according to a random walk modeled by a discrete-time discrete-state (DTDS) Markov chain and estimate the feature distribution from their own measurements and the estimates communicated by neighboring robots, using a distributed Chernoff fusion protocol. We prove that under this decentralized fusion protocol, each robot's feature distribution converges to the ground truth distribution in an almost sure sense. We verify this result in numerical simulations that show that the Hellinger distance between the estimated and ground truth feature distributions converges to zero over time for each robot. We also validate our strategy through Software-In-The-Loop (SITL) simulations of quadrotors that search a bounded square grid for a set of visual features distributed on a discretized circle.",
        "published": "2022-02-07T16:18:56Z",
        "link": "http://arxiv.org/abs/2202.03327v2",
        "categories": [
            "cs.RO",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Variance reduced stochastic optimization over directed graphs with row   and column stochastic weights",
        "authors": [
            "Muhammad I. Qureshi",
            "Ran Xin",
            "Soummya Kar",
            "Usman A. Khan"
        ],
        "summary": "This paper proposes AB-SAGA, a first-order distributed stochastic optimization method to minimize a finite-sum of smooth and strongly convex functions distributed over an arbitrary directed graph. AB-SAGA removes the uncertainty caused by the stochastic gradients using a node-level variance reduction and subsequently employs network-level gradient tracking to address the data dissimilarity across the nodes. Unlike existing methods that use the nonlinear push-sum correction to cancel the imbalance caused by the directed communication, the consensus updates in AB-SAGA are linear and uses both row and column stochastic weights. We show that for a constant step-size, AB-SAGA converges linearly to the global optimal. We quantify the directed nature of the underlying graph using an explicit directivity constant and characterize the regimes in which AB-SAGA achieves a linear speed-up over its centralized counterpart. Numerical experiments illustrate the convergence of AB-SAGA for strongly convex and nonconvex problems.",
        "published": "2022-02-07T16:44:48Z",
        "link": "http://arxiv.org/abs/2202.03346v1",
        "categories": [
            "math.OC",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Multi-Agent Path Finding with Prioritized Communication Learning",
        "authors": [
            "Wenhao Li",
            "Hongjun Chen",
            "Bo Jin",
            "Wenzhe Tan",
            "Hongyuan Zha",
            "Xiangfeng Wang"
        ],
        "summary": "Multi-agent pathfinding (MAPF) has been widely used to solve large-scale real-world problems, e.g., automation warehouses. The learning-based, fully decentralized framework has been introduced to alleviate real-time problems and simultaneously pursue optimal planning policy. However, existing methods might generate significantly more vertex conflicts (or collisions), which lead to a low success rate or more makespan. In this paper, we propose a PrIoritized COmmunication learning method (PICO), which incorporates the \\textit{implicit} planning priorities into the communication topology within the decentralized multi-agent reinforcement learning framework. Assembling with the classic coupled planners, the implicit priority learning module can be utilized to form the dynamic communication topology, which also builds an effective collision-avoiding mechanism. PICO performs significantly better in large-scale MAPF tasks in success rates and collision rates than state-of-the-art learning-based planners.",
        "published": "2022-02-08T04:04:19Z",
        "link": "http://arxiv.org/abs/2202.03634v2",
        "categories": [
            "cs.RO",
            "cs.GT",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Optimal Multi-Agent Path Finding for Precedence Constrained Planning   Tasks",
        "authors": [
            "Kushal Kedia",
            "Rajat Kumar Jenamani",
            "Aritra Hazra",
            "Partha Pratim Chakrabarti"
        ],
        "summary": "Multi-Agent Path Finding (MAPF) is the problem of finding collision-free paths for multiple agents from their start locations to end locations. We consider an extension to this problem, Precedence Constrained Multi-Agent Path Finding (PC-MAPF), wherein agents are assigned a sequence of planning tasks that contain precedence constraints between them. PC-MAPF has various applications, for example in multi-agent pickup and delivery problems where some objects might require multiple agents to collaboratively pickup and move them in unison. Precedence constraints also arise in warehouse assembly problems where before a manufacturing task can begin, its input resources must be manufactured and delivered. We propose a novel algorithm, Precedence Constrained Conflict Based Search (PC-CBS), which finds makespan-optimal solutions for this class of problems. PC-CBS utilizes a Precedence-Constrained Task-Graph to define valid intervals for each planning task and updates them when precedence conflicts are encountered. We benchmark the performance of this algorithm over various warehouse assembly, and multi-agent pickup and delivery tasks, and use it to evaluate the sub-optimality of a recently proposed efficient baseline.",
        "published": "2022-02-08T07:26:45Z",
        "link": "http://arxiv.org/abs/2202.10449v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Budgeted Combinatorial Multi-Armed Bandits",
        "authors": [
            "Debojit Das",
            "Shweta Jain",
            "Sujit Gujar"
        ],
        "summary": "We consider a budgeted combinatorial multi-armed bandit setting where, in every round, the algorithm selects a super-arm consisting of one or more arms. The goal is to minimize the total expected regret after all rounds within a limited budget. Existing techniques in this literature either fix the budget per round or fix the number of arms pulled in each round. Our setting is more general where based on the remaining budget and remaining number of rounds, the algorithm can decide how many arms to be pulled in each round. First, we propose CBwK-Greedy-UCB algorithm, which uses a greedy technique, CBwK-Greedy, to allocate the arms to the rounds. Next, we propose a reduction of this problem to Bandits with Knapsacks (BwK) with a single pull. With this reduction, we propose CBwK-LPUCB that uses PrimalDualBwK ingeniously. We rigorously prove regret bounds for CBwK-LP-UCB. We experimentally compare the two algorithms and observe that CBwK-Greedy-UCB performs incrementally better than CBwK-LP-UCB. We also show that for very high budgets, the regret goes to zero.",
        "published": "2022-02-08T07:58:25Z",
        "link": "http://arxiv.org/abs/2202.03704v2",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Predicting Voting Outcomes in the Presence of Communities, Echo Chambers   and Multiple Parties",
        "authors": [
            "Jacques Bara",
            "Omer Lev",
            "Paolo Turrini"
        ],
        "summary": "A recently proposed graph-theoretic metric, the influence gap, has shown to be a reliable predictor of the effect of social influence in two-party elections, albeit only tested on regular and scale-free graphs. Here, we investigate whether the influence gap is able to predict the outcome of multi-party elections on networks exhibiting community structure, i.e., made of highly interconnected components, and therefore more resembling of real-world interaction. To encode communities we build on the classical model of caveman graphs, which we extend to a richer graph family that displays different levels of homophily, i.e., how much connections and opinions are intertwined. First, we study the predictive power of the influence gap in the presence of communities. We show that when there is no clear initial majority the influence gap is not a good predictor of the election outcome. When we instead allow for varying majorities, although the influence gap improves as a predictor, counting the initial partisan majority does consistently better, across all levels of homophily. Second, we study the combined effect of the more predictive metrics, as function of the homophily levels. Using regression models, we demonstrate that the influence gap combined with the initial votes count does increase the overall predictive power for some levels of homophily. Third, we study elections with more than two parties. Specifically, we extend the definition of the influence gap to any number of parties, considering various generalisations, and show that the initial votes count has an even higher predictive power when compared to influence gap than it did in the two-party case.",
        "published": "2022-02-08T16:12:56Z",
        "link": "http://arxiv.org/abs/2202.03961v1",
        "categories": [
            "cs.SI",
            "cs.MA",
            "physics.soc-ph",
            "I.2.1; I.2.11; J.4"
        ]
    },
    {
        "title": "Enabling Imitation-Based Cooperation in Dynamic Social Networks",
        "authors": [
            "Jacques Bara",
            "Paolo Turrini",
            "Giulia Andrighetto"
        ],
        "summary": "The emergence of cooperation among self-interested agents has been a key concern of the multi-agent systems community for decades. With the increased importance of network-mediated interaction, researchers have shifted the attention on the impact of social networks and their dynamics in promoting or hindering cooperation, drawing various context-dependent conclusions. For example, some lines of research, theoretical and experimental, suggest the existence of a threshold effect in the ratio of timescales of network evolution, after which cooperation will emerge, whereas other lines dispute this, suggesting instead a Goldilocks zone. In this paper we provide an evolutionary game theory framework to understand coevolutionary processes from a bottom up perspective - in particular the emergence of a cooperator-core and defector-periphery - clarifying the impact of partner selection and imitation strategies in promoting cooperative behaviour, without assuming underlying communication or reputation mechanisms. In doing so we provide a unifying framework to study imitation-based cooperation in dynamic social networks and show that disputes in the literature can in fact coexist in so far as the results stem from different equally valid assumptions.",
        "published": "2022-02-08T16:27:33Z",
        "link": "http://arxiv.org/abs/2202.03972v1",
        "categories": [
            "physics.soc-ph",
            "cs.GT",
            "cs.MA",
            "math.DS",
            "I.2.11; I.2.1"
        ]
    },
    {
        "title": "Independent Policy Gradient for Large-Scale Markov Potential Games:   Sharper Rates, Function Approximation, and Game-Agnostic Convergence",
        "authors": [
            "Dongsheng Ding",
            "Chen-Yu Wei",
            "Kaiqing Zhang",
            "Mihailo R. Jovanović"
        ],
        "summary": "We examine global non-asymptotic convergence properties of policy gradient methods for multi-agent reinforcement learning (RL) problems in Markov potential games (MPG). To learn a Nash equilibrium of an MPG in which the size of state space and/or the number of players can be very large, we propose new independent policy gradient algorithms that are run by all players in tandem. When there is no uncertainty in the gradient evaluation, we show that our algorithm finds an $\\epsilon$-Nash equilibrium with $O(1/\\epsilon^2)$ iteration complexity which does not explicitly depend on the state space size. When the exact gradient is not available, we establish $O(1/\\epsilon^5)$ sample complexity bound in a potentially infinitely large state space for a sample-based algorithm that utilizes function approximation. Moreover, we identify a class of independent policy gradient algorithms that enjoys convergence for both zero-sum Markov games and Markov cooperative games with the players that are oblivious to the types of games being played. Finally, we provide computational experiments to corroborate the merits and the effectiveness of our theoretical developments.",
        "published": "2022-02-08T20:09:47Z",
        "link": "http://arxiv.org/abs/2202.04129v3",
        "categories": [
            "cs.LG",
            "cs.GT",
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "Intelligent Autonomous Intersection Management",
        "authors": [
            "Udesh Gunarathna",
            "Shanika Karunasekara",
            "Renata Borovica-Gajic",
            "Egemen Tanin"
        ],
        "summary": "Connected Autonomous Vehicles will make autonomous intersection management a reality replacing traditional traffic signal control. Autonomous intersection management requires time and speed adjustment of vehicles arriving at an intersection for collision-free passing through the intersection. Due to its computational complexity, this problem has been studied only when vehicle arrival times towards the vicinity of the intersection are known beforehand, which limits the applicability of these solutions for real-time deployment. To solve the real-time autonomous traffic intersection management problem, we propose a reinforcement learning (RL) based multiagent architecture and a novel RL algorithm coined multi-discount Q-learning. In multi-discount Q-learning, we introduce a simple yet effective way to solve a Markov Decision Process by preserving both short-term and long-term goals, which is crucial for collision-free speed control. Our empirical results show that our RL-based multiagent solution can achieve near-optimal performance efficiently when minimizing the travel time through an intersection.",
        "published": "2022-02-09T01:45:12Z",
        "link": "http://arxiv.org/abs/2202.04224v1",
        "categories": [
            "cs.MA",
            "cs.LG"
        ]
    },
    {
        "title": "Leveraging Experience in Lifelong Multi-Agent Pathfinding",
        "authors": [
            "Nitzan Madar",
            "Kiril Solovey",
            "Oren Salzman"
        ],
        "summary": "In Lifelong Multi-Agent Path Finding (L-MAPF) a team of agents performs a stream of tasks consisting of multiple locations to be visited by the agents on a shared graph while avoiding collisions with one another. L-MAPF is typically tackled by partitioning it into multiple consecutive, and hence similar, \"one-shot\" MAPF queries, as in the Rolling-Horizon Collision Resolution (RHCR) algorithm. Therefore, a solution to one query informs the next query, which leads to similarity with respect to the agents' start and goal positions, and how collisions need to be resolved from one query to the next. Thus, experience from solving one MAPF query can potentially be used to speedup solving the next one. Despite this intuition, current L-MAPF planners solve consecutive MAPF queries from scratch. In this paper, we introduce a new RHCR-inspired approach called exRHCR, which exploits experience in its constituent MAPF queries. In particular, exRHCR employs an extension of Priority-Based Search (PBS), a state-of-the-art MAPF solver. The extension, which we call exPBS, allows to warm-start the search with the priorities between agents used by PBS in the previous MAPF instances. We demonstrate empirically that exRHCR solves L-MAPF instances up to 39% faster than RHCR, and has the potential to increase system throughput for given task streams by increasing the number of agents a planner can cope with for a given time budget.",
        "published": "2022-02-09T10:41:35Z",
        "link": "http://arxiv.org/abs/2202.04382v3",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.RO"
        ]
    },
    {
        "title": "Allocation of Indivisible Items with Individual Preference Graphs",
        "authors": [
            "Nina Chiarelli",
            "Clément Dallard",
            "Andreas Darmann",
            "Stefan Lendl",
            "Martin Milanič",
            "Peter Muršič",
            "Ulrich Pferschy",
            "Nevena Pivač"
        ],
        "summary": "This paper studies the allocation of indivisible items to agents, when each agent's preferences are expressed by means of a directed acyclic graph. The vertices of each preference graph represent the subset of items approved of by the respective agent. An arc $(a,b)$ in such a graph means that the respective agent prefers item $a$ over item $b$. We introduce a new measure of dissatisfaction of an agent by counting the number of non-assigned items which are approved of by the agent and for which no more preferred item is allocated to the agent. Considering two problem variants, we seek an allocation of the items to the agents in a way that minimizes (i) the total dissatisfaction over all agents or (ii) the maximum dissatisfaction among the agents. For both optimization problems we study the status of computational complexity and obtain NP-hardness results as well as polynomial algorithms with respect to natural underlying graph structures, such as stars, trees, paths, and matchings. We also analyze the parameterized complexity of the two problems with respect to various parameters related to the number of agents, the dissatisfaction threshold, the vertex degrees of the preference graphs, and the treewidth.",
        "published": "2022-02-09T13:50:16Z",
        "link": "http://arxiv.org/abs/2202.04465v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Deploying Vaccine Distribution Sites for Improved Accessibility and   Equity to Support Pandemic Response",
        "authors": [
            "George Li",
            "Ann Li",
            "Madhav Marathe",
            "Aravind Srinivasan",
            "Leonidas Tsepenekas",
            "Anil Vullikanti"
        ],
        "summary": "In response to COVID-19, many countries have mandated social distancing and banned large group gatherings in order to slow down the spread of SARS-CoV-2. These social interventions along with vaccines remain the best way forward to reduce the spread of SARS CoV-2. In order to increase vaccine accessibility, states such as Virginia have deployed mobile vaccination centers to distribute vaccines across the state. When choosing where to place these sites, there are two important factors to take into account: accessibility and equity. We formulate a combinatorial problem that captures these factors and then develop efficient algorithms with theoretical guarantees on both of these aspects. Furthermore, we study the inherent hardness of the problem, and demonstrate strong impossibility results. Finally, we run computational experiments on real-world data to show the efficacy of our methods.",
        "published": "2022-02-09T19:57:55Z",
        "link": "http://arxiv.org/abs/2202.04705v1",
        "categories": [
            "cs.AI",
            "cs.DS",
            "cs.MA",
            "cs.SI"
        ]
    },
    {
        "title": "Reinforcement Learning in the Wild: Scalable RL Dispatching Algorithm   Deployed in Ridehailing Marketplace",
        "authors": [
            "Soheil Sadeghi Eshkevari",
            "Xiaocheng Tang",
            "Zhiwei Qin",
            "Jinhan Mei",
            "Cheng Zhang",
            "Qianying Meng",
            "Jia Xu"
        ],
        "summary": "In this study, a real-time dispatching algorithm based on reinforcement learning is proposed and for the first time, is deployed in large scale. Current dispatching methods in ridehailing platforms are dominantly based on myopic or rule-based non-myopic approaches. Reinforcement learning enables dispatching policies that are informed of historical data and able to employ the learned information to optimize returns of expected future trajectories. Previous studies in this field yielded promising results, yet have left room for further improvements in terms of performance gain, self-dependency, transferability, and scalable deployment mechanisms. The present study proposes a standalone RL-based dispatching solution that is equipped with multiple mechanisms to ensure robust and efficient on-policy learning and inference while being adaptable for full-scale deployment. A new form of value updating based on temporal difference is proposed that is more adapted to the inherent uncertainty of the problem. For the driver-order assignment, a customized utility function is proposed that when tuned based on the statistics of the market, results in remarkable performance improvement and interpretability. In addition, for reducing the risk of cancellation after drivers' assignment, an adaptive graph pruning strategy based on the multi-arm bandit problem is introduced. The method is evaluated using offline simulation with real data and yields notable performance improvement. In addition, the algorithm is deployed online in multiple cities under DiDi's operation for A/B testing and is launched in one of the major international markets as the primary mode of dispatch. The deployed algorithm shows over 1.3% improvement in total driver income from A/B testing. In addition, by causal inference analysis, as much as 5.3% improvement in major performance metrics is detected after full-scale deployment.",
        "published": "2022-02-10T16:07:17Z",
        "link": "http://arxiv.org/abs/2202.05118v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Grassroots Currencies: Foundations for Grassroots Digital Economies",
        "authors": [
            "Ehud Shapiro"
        ],
        "summary": "Grassroots currencies are means for turning mutual trust into liquidity, with the goal of providing foundations for grassroots digital economies. Grassroots coins are units of debt that can be issued by anyone -- people, corporations, cooperatives, banks, municipalities and governments -- and traded by anyone. They are more similar to `inside money' (a medium of exchange backed by private credit) and to fiat currencies (for which the issuer controls scarcity) than to global cryptocurrencies such as Bitcoin or Ethereum, which are unbacked and for which scarcity is controlled by the protocol.   In this paper we introduce the principles that underlie grassroots currencies; show that they naturally admit basic fiat currency measures regarding foreign trade such as foreign debt, trade balance, and velocity, and basic accounting measures such as cash ratio, quick ratio, and current ratio; elaborate economic scenarios enabled by these principles for grassroots currencies issued by natural and legal persons; relate grassroots currencies to extant work, including notions of personal currencies, community currencies, cryptocurrencies, and inside money; formally specify grassroots currencies as digital entities, governed by the Grassroots Currencies Protocol; discuss the security (safety, liveness, and privacy) of the protocol; and prove that the protocol is grassroots. An implementation of grassroots currencies via a blocklace-based payment system is described elsewhere.",
        "published": "2022-02-11T14:00:06Z",
        "link": "http://arxiv.org/abs/2202.05619v17",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Visualising Multiplayer Game Spaces",
        "authors": [
            "James Goodman",
            "Diego Perez-Liebana",
            "Simon Lucas"
        ],
        "summary": "We compare four different `game-spaces' in terms of their usefulness in characterising multi-player tabletop games, with a particular interest in any underlying change to a game's characteristics as the number of players changes. In each case we take a 16-dimensional feature space, and reduce it to a 2-dimensional visualizable landscape.   We find that a space obtained from optimization of parameters in Monte Carlo Tree Search (MCTS) is the most directly interpretable to characterise our set of games in terms of the relative importance of imperfect information, adversarial opponents and reward sparsity. These results do not correlate with a space defined using attributes of the game-tree.   This dimensionality reduction does not show any general effect as the number of players. We therefore consider the question using the original features to classify the games into two sets; those for which the characteristics of the game changes significantly as the number of players changes, and those for which there is no such effect.",
        "published": "2022-02-11T17:09:32Z",
        "link": "http://arxiv.org/abs/2202.05773v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Distributed saddle point problems for strongly concave-convex functions",
        "authors": [
            "Muhammad I. Qureshi",
            "Usman A. Khan"
        ],
        "summary": "In this paper, we propose GT-GDA, a distributed optimization method to solve saddle point problems of the form: $\\min_{\\mathbf{x}} \\max_{\\mathbf{y}} \\{F(\\mathbf{x},\\mathbf{y}) :=G(\\mathbf{x}) + \\langle \\mathbf{y}, \\overline{P} \\mathbf{x} \\rangle - H(\\mathbf{y})\\}$, where the functions $G(\\cdot)$, $H(\\cdot)$, and the the coupling matrix $\\overline{P}$ are distributed over a strongly connected network of nodes. GT-GDA is a first-order method that uses gradient tracking to eliminate the dissimilarity caused by heterogeneous data distribution among the nodes. In the most general form, GT-GDA includes a consensus over the local coupling matrices to achieve the optimal (unique) saddle point, however, at the expense of increased communication. To avoid this, we propose a more efficient variant GT-GDA-Lite that does not incur the additional communication and analyze its convergence in various scenarios. We show that GT-GDA converges linearly to the unique saddle point solution when $G(\\cdot)$ is smooth and convex, $H(\\cdot)$ is smooth and strongly convex, and the global coupling matrix $\\overline{P}$ has full column rank. We further characterize the regime under which GT-GDA exhibits a network topology-independent convergence behavior. We next show the linear convergence of GT-GDA to an error around the unique saddle point, which goes to zero when the coupling cost ${\\langle \\mathbf y, \\overline{P} \\mathbf x \\rangle}$ is common to all nodes, or when $G(\\cdot)$ and $H(\\cdot)$ are quadratic. Numerical experiments illustrate the convergence properties and importance of GT-GDA and GT-GDA-Lite for several applications.",
        "published": "2022-02-11T18:21:23Z",
        "link": "http://arxiv.org/abs/2202.05812v2",
        "categories": [
            "math.OC",
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Cooperative Solutions to Exploration Tasks Under Speed and Budget   Constraints",
        "authors": [
            "Karishma",
            "Shrisha Rao"
        ],
        "summary": "We present a multi-agent system where agents can cooperate to solve a system of dependent tasks, with agents having the capability to explore a solution space, make inferences, as well as query for information under a limited budget. Re-exploration of the solution space takes place by an agent when an older solution expires and is thus able to adapt to dynamic changes in the environment. We investigate the effects of task dependencies, with highly-dependent graph $G_{40}$ (a well-known program graph that contains $40$ highly interlinked nodes, each representing a task) and less-dependent graphs $G_{18}$ (a program graph that contains $18$ tasks with fewer links), increasing the speed of the agents and the complexity of the problem space and the query budgets available to agents. Specifically, we evaluate trade-offs between the agent's speed and query budget. During the experiments, we observed that increasing the speed of a single agent improves the system performance to a certain point only, and increasing the number of faster agents may not improve the system performance due to task dependencies. Favoring faster agents during budget allocation enhances the system performance, in line with the \"Matthew effect.\" We also observe that allocating more budget to a faster agent gives better performance for a less-dependent system, but increasing the number of faster agents gives a better performance for a highly-dependent system.",
        "published": "2022-02-11T20:17:15Z",
        "link": "http://arxiv.org/abs/2202.05891v1",
        "categories": [
            "cs.MA",
            "cs.DC"
        ]
    },
    {
        "title": "Deadlock Resolution and Recursive Feasibility in MPC-based Multi-robot   Trajectory Generation",
        "authors": [
            "Yuda Chen",
            "Meng Guo",
            "Zhongkui Li"
        ],
        "summary": "Online collision-free trajectory generation within a shared workspace is fundamental for most multi-robot applications. However, many widely-used methods based on model predictive control (MPC) lack theoretical guarantees on the feasibility of underlying optimization. Furthermore, when applied in a distributed manner without a central coordinator, deadlocks often occur where several robots block each other indefinitely. Whereas heuristic methods such as introducing random perturbations exist, no profound analyses are given to validate these measures. Towards this end, we propose a systematic method called infinite-horizon model predictive control with deadlock resolution. The MPC is formulated as a convex optimization over the proposed modified buffered Voronoi with warning band. Based on this formulation, the condition of deadlocks is formally analyzed and proven to be analogous to a force equilibrium. A detection-resolution scheme is proposed, which can effectively detect deadlocks online before they even happen. Once detected, it utilizes an adaptive resolution scheme to resolve deadlocks, under which no stable deadlocks can exist under minor conditions. In addition, the proposed planning algorithm ensures recursive feasibility of the underlying optimization at each time step under both input and model constraints, is concurrent for all robots and requires only local communication. Comprehensive simulation and experiment studies are conducted over large-scale multi-robot systems. Significant improvements on success rate are reported, in comparison with other state-of-the-art methods and especially in crowded and high-speed scenarios.",
        "published": "2022-02-12T14:04:44Z",
        "link": "http://arxiv.org/abs/2202.06071v4",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Individual-Level Inverse Reinforcement Learning for Mean Field Games",
        "authors": [
            "Yang Chen",
            "Libo Zhang",
            "Jiamou Liu",
            "Shuyue Hu"
        ],
        "summary": "The recent mean field game (MFG) formalism has enabled the application of inverse reinforcement learning (IRL) methods in large-scale multi-agent systems, with the goal of inferring reward signals that can explain demonstrated behaviours of large populations. The existing IRL methods for MFGs are built upon reducing an MFG to a Markov decision process (MDP) defined on the collective behaviours and average rewards of the population. However, this paper reveals that the reduction from MFG to MDP holds only for the fully cooperative setting. This limitation invalidates existing IRL methods on MFGs with non-cooperative environments. To measure more general behaviours in large populations, we study the use of individual behaviours to infer ground-truth reward functions for MFGs. We propose Mean Field IRL (MFIRL), the first dedicated IRL framework for MFGs that can handle both cooperative and non-cooperative environments. Based on this theoretically justified framework, we develop a practical algorithm effective for MFGs with unknown dynamics. We evaluate MFIRL on both cooperative and mixed cooperative-competitive scenarios with many agents. Results demonstrate that MFIRL excels in reward recovery, sample efficiency and robustness in the face of changing dynamics.",
        "published": "2022-02-13T20:35:01Z",
        "link": "http://arxiv.org/abs/2202.06401v1",
        "categories": [
            "cs.LG",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Motivating Physical Activity via Competitive Human-Robot Interaction",
        "authors": [
            "Boling Yang",
            "Golnaz Habibi",
            "Patrick E. Lancaster",
            "Byron Boots",
            "Joshua R. Smith"
        ],
        "summary": "This project aims to motivate research in competitive human-robot interaction by creating a robot competitor that can challenge human users in certain scenarios such as physical exercise and games. With this goal in mind, we introduce the Fencing Game, a human-robot competition used to evaluate both the capabilities of the robot competitor and user experience. We develop the robot competitor through iterative multi-agent reinforcement learning and show that it can perform well against human competitors. Our user study additionally found that our system was able to continuously create challenging and enjoyable interactions that significantly increased human subjects' heart rates. The majority of human subjects considered the system to be entertaining and desirable for improving the quality of their exercise.",
        "published": "2022-02-14T22:19:58Z",
        "link": "http://arxiv.org/abs/2202.07068v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.HC",
            "cs.MA"
        ]
    },
    {
        "title": "Price Cycles in Ridesharing Platforms",
        "authors": [
            "Chenkai Yu",
            "Hongyao Ma",
            "Adam Wierman"
        ],
        "summary": "In ridesharing platforms such as Uber and Lyft, it is observed that drivers sometimes collaboratively go offline when the price is low, and then return after the price has risen due to the perceived lack of supply. This collective strategy leads to cyclic fluctuations in prices and available drivers, resulting in poor reliability and social welfare. We study a continuous time, non-atomic model and prove that such online/offline strategies may form a Nash equilibrium among drivers, but lead to a lower total driver payoff if the market is sufficiently dense. Further, we show how to set price floors that effectively mitigate the emergence and impact of price cycles.",
        "published": "2022-02-14T23:15:19Z",
        "link": "http://arxiv.org/abs/2202.07086v1",
        "categories": [
            "cs.GT",
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "A Reliability-aware Distributed Framework to Schedule Residential   Charging of Electric Vehicles",
        "authors": [
            "Rounak Meyur",
            "Swapna Thorve",
            "Madhav Marathe",
            "Anil Vullikanti",
            "Samarth Swarup",
            "Henning Mortveit"
        ],
        "summary": "Residential consumers have become active participants in the power distribution network after being equipped with residential EV charging provisions. This creates a challenge for the network operator tasked with dispatching electric power to the residential consumers through the existing distribution network infrastructure in a reliable manner. In this paper, we address the problem of scheduling residential EV charging for multiple consumers while maintaining network reliability. An additional challenge is the restricted exchange of information: where the consumers do not have access to network information and the network operator does not have access to consumer load parameters. We propose a distributed framework which generates an optimal EV charging schedule for individual residential consumers based on their preferences and iteratively updates it until the network reliability constraints set by the operator are satisfied. We validate the proposed approach for different EV adoption levels in a synthetically created digital twin of an actual power distribution network. The results demonstrate that the new approach can achieve a higher level of network reliability compared to the case where residential consumers charge EVs based solely on their individual preferences, thus providing a solution for the existing grid to keep up with increased adoption rates without significant investments in increasing grid capacity.",
        "published": "2022-02-14T23:31:37Z",
        "link": "http://arxiv.org/abs/2202.07092v1",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Learning to Mitigate AI Collusion on Economic Platforms",
        "authors": [
            "Gianluca Brero",
            "Nicolas Lepore",
            "Eric Mibuari",
            "David C. Parkes"
        ],
        "summary": "Algorithmic pricing on online e-commerce platforms raises the concern of tacit collusion, where reinforcement learning algorithms learn to set collusive prices in a decentralized manner and through nothing more than profit feedback. This raises the question as to whether collusive pricing can be prevented through the design of suitable \"buy boxes,\" i.e., through the design of the rules that govern the elements of e-commerce sites that promote particular products and prices to consumers. In this paper, we demonstrate that reinforcement learning (RL) can also be used by platforms to learn buy box rules that are effective in preventing collusion by RL sellers. For this, we adopt the methodology of Stackelberg POMDPs, and demonstrate success in learning robust rules that continue to provide high consumer welfare together with sellers employing different behavior models or having out-of-distribution costs for goods.",
        "published": "2022-02-15T00:26:59Z",
        "link": "http://arxiv.org/abs/2202.07106v2",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Zero-Shot Assistance in Sequential Decision Problems",
        "authors": [
            "Sebastiaan De Peuter",
            "Samuel Kaski"
        ],
        "summary": "We consider the problem of creating assistants that can help agents solve new sequential decision problems, assuming the agent is not able to specify the reward function explicitly to the assistant. Instead of acting in place of the agent as in current automation-based approaches, we give the assistant an advisory role and keep the agent in the loop as the main decision maker. The difficulty is that we must account for potential biases of the agent which may cause it to seemingly irrationally reject advice. To do this we introduce a novel formalization of assistance that models these biases, allowing the assistant to infer and adapt to them. We then introduce a new method for planning the assistant's actions which can scale to large decision making problems. We show experimentally that our approach adapts to these agent biases, and results in higher cumulative reward for the agent than automation-based alternatives. Lastly, we show that an approach combining advice and automation outperforms advice alone at the cost of losing some safety guarantees.",
        "published": "2022-02-15T12:45:42Z",
        "link": "http://arxiv.org/abs/2202.07364v3",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Disentangling Successor Features for Coordination in Multi-agent   Reinforcement Learning",
        "authors": [
            "Seung Hyun Kim",
            "Neale Van Stralen",
            "Girish Chowdhary",
            "Huy T. Tran"
        ],
        "summary": "Multi-agent reinforcement learning (MARL) is a promising framework for solving complex tasks with many agents. However, a key challenge in MARL is defining private utility functions that ensure coordination when training decentralized agents. This challenge is especially prevalent in unstructured tasks with sparse rewards and many agents. We show that successor features can help address this challenge by disentangling an individual agent's impact on the global value function from that of all other agents. We use this disentanglement to compactly represent private utilities that support stable training of decentralized agents in unstructured tasks. We implement our approach using a centralized training, decentralized execution architecture and test it in a variety of multi-agent environments. Our results show improved performance and training time relative to existing methods and suggest that disentanglement of successor features offers a promising approach to coordination in MARL.",
        "published": "2022-02-15T21:48:26Z",
        "link": "http://arxiv.org/abs/2202.07741v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "A Survey of Ad Hoc Teamwork Research",
        "authors": [
            "Reuth Mirsky",
            "Ignacio Carlucho",
            "Arrasy Rahman",
            "Elliot Fosong",
            "William Macke",
            "Mohan Sridharan",
            "Peter Stone",
            "Stefano V. Albrecht"
        ],
        "summary": "Ad hoc teamwork is the research problem of designing agents that can collaborate with new teammates without prior coordination. This survey makes a two-fold contribution: First, it provides a structured description of the different facets of the ad hoc teamwork problem. Second, it discusses the progress that has been made in the field so far, and identifies the immediate and long-term open problems that need to be addressed in ad hoc teamwork.",
        "published": "2022-02-16T18:16:27Z",
        "link": "http://arxiv.org/abs/2202.10450v3",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "DARL1N: Distributed multi-Agent Reinforcement Learning with One-hop   Neighbors",
        "authors": [
            "Baoqian Wang",
            "Junfei Xie",
            "Nikolay Atanasov"
        ],
        "summary": "Most existing multi-agent reinforcement learning (MARL) methods are limited in the scale of problems they can handle. Particularly, with the increase of the number of agents, their training costs grow exponentially. In this paper, we address this limitation by introducing a scalable MARL method called Distributed multi-Agent Reinforcement Learning with One-hop Neighbors (DARL1N). DARL1N is an off-policy actor-critic method that breaks the curse of dimensionality by decoupling the global interactions among agents and restricting information exchanges to one-hop neighbors. Each agent optimizes its action value and policy functions over a one-hop neighborhood, significantly reducing the learning complexity, yet maintaining expressiveness by training with varying numbers and states of neighbors. This structure allows us to formulate a distributed learning framework to further speed up the training procedure. Comparisons with state-of-the-art MARL methods show that DARL1N significantly reduces training time without sacrificing policy quality and is scalable as the number of agents increases.",
        "published": "2022-02-18T04:55:09Z",
        "link": "http://arxiv.org/abs/2202.09019v2",
        "categories": [
            "cs.MA",
            "cs.LG"
        ]
    },
    {
        "title": "How to Manage Tiny Machine Learning at Scale: An Industrial Perspective",
        "authors": [
            "Haoyu Ren",
            "Darko Anicic",
            "Thomas Runkler"
        ],
        "summary": "Tiny machine learning (TinyML) has gained widespread popularity where machine learning (ML) is democratized on ubiquitous microcontrollers, processing sensor data everywhere in real-time. To manage TinyML in the industry, where mass deployment happens, we consider the hardware and software constraints, ranging from available onboard sensors and memory size to ML-model architectures and runtime platforms. However, Internet of Things (IoT) devices are typically tailored to specific tasks and are subject to heterogeneity and limited resources. Moreover, TinyML models have been developed with different structures and are often distributed without a clear understanding of their working principles, leading to a fragmented ecosystem. Considering these challenges, we propose a framework using Semantic Web technologies to enable the joint management of TinyML models and IoT devices at scale, from modeling information to discovering possible combinations and benchmarking, and eventually facilitate TinyML component exchange and reuse. We present an ontology (semantic schema) for neural network models aligned with the World Wide Web Consortium (W3C) Thing Description, which semantically describes IoT devices. Furthermore, a Knowledge Graph of 23 publicly available ML models and six IoT devices were used to demonstrate our concept in three case studies, and we shared the code and examples to enhance reproducibility: https://github.com/Haoyu-R/How-to-Manage-TinyML-at-Scale",
        "published": "2022-02-18T10:36:11Z",
        "link": "http://arxiv.org/abs/2202.09113v1",
        "categories": [
            "cs.AI",
            "cs.DB",
            "cs.DC",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Towards the Combination of Model Checking and Runtime Verification on   Multi-Agent Systems",
        "authors": [
            "Angelo Ferrando",
            "Vadim Malvone"
        ],
        "summary": "Multi-Agent Systems (MAS) are notoriously complex and hard to verify. In fact, it is not trivial to model a MAS, and even when a model is built, it is not always possible to verify, in a formal way, that it is actually behaving as we expect. Usually, it is relevant to know whether an agent is capable of fulfilling its own goals. One possible way to check this is through Model Checking. Specifically, by verifying Alternating-time Temporal Logic (ATL) properties, where the notion of strategies for achieving goals can be described. Unfortunately, the resulting model checking problem is not decidable in general. In this paper, we present a verification procedure based on combining Model Checking and Runtime Verification, where sub-models of the MAS model belonging to decidable fragments are verified by a model checker, and runtime monitors are used to verify the rest. Furthermore, we implement our technique and show experimental results.",
        "published": "2022-02-18T18:25:04Z",
        "link": "http://arxiv.org/abs/2202.09344v2",
        "categories": [
            "cs.LO",
            "cs.MA"
        ]
    },
    {
        "title": "Provably Private Distributed Averaging Consensus: An   Information-Theoretic Approach",
        "authors": [
            "Mohammad Fereydounian",
            "Aryan Mokhtari",
            "Ramtin Pedarsani",
            "Hamed Hassani"
        ],
        "summary": "In this work, we focus on solving a decentralized consensus problem in a private manner. Specifically, we consider a setting in which a group of nodes, connected through a network, aim at computing the mean of their local values without revealing those values to each other. The distributed consensus problem is a classic problem that has been extensively studied and its convergence characteristics are well-known. Alas, state-of-the-art consensus methods build on the idea of exchanging local information with neighboring nodes which leaks information about the users' local values. We propose an algorithmic framework that is capable of achieving the convergence limit and rate of classic consensus algorithms while keeping the users' local values private. The key idea of our proposed method is to carefully design noisy messages that are passed from each node to its neighbors such that the consensus algorithm still converges precisely to the average of local values, while a minimum amount of information about local values is leaked. We formalize this by precisely characterizing the mutual information between the private message of a node and all the messages that another adversary collects over time. We prove that our method is capable of preserving users' privacy for any network without a so-called \"generalized leaf\", and formalize the trade-off between privacy and convergence time. Unlike many private algorithms, any desired accuracy is achievable by our method, and the required level of privacy only affects the convergence time.",
        "published": "2022-02-18T19:35:09Z",
        "link": "http://arxiv.org/abs/2202.09398v1",
        "categories": [
            "cs.MA",
            "cs.IT",
            "math.IT"
        ]
    },
    {
        "title": "Communication-Efficient Actor-Critic Methods for Homogeneous Markov   Games",
        "authors": [
            "Dingyang Chen",
            "Yile Li",
            "Qi Zhang"
        ],
        "summary": "Recent success in cooperative multi-agent reinforcement learning (MARL) relies on centralized training and policy sharing. Centralized training eliminates the issue of non-stationarity MARL yet induces large communication costs, and policy sharing is empirically crucial to efficient learning in certain tasks yet lacks theoretical justification. In this paper, we formally characterize a subclass of cooperative Markov games where agents exhibit a certain form of homogeneity such that policy sharing provably incurs no suboptimality. This enables us to develop the first consensus-based decentralized actor-critic method where the consensus update is applied to both the actors and the critics while ensuring convergence. We also develop practical algorithms based on our decentralized actor-critic method to reduce the communication cost during training, while still yielding policies comparable with centralized training.",
        "published": "2022-02-18T20:35:00Z",
        "link": "http://arxiv.org/abs/2202.09422v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.GT",
            "cs.LG"
        ]
    },
    {
        "title": "Shaping Advice in Deep Reinforcement Learning",
        "authors": [
            "Baicen Xiao",
            "Bhaskar Ramasubramanian",
            "Radha Poovendran"
        ],
        "summary": "Reinforcement learning involves agents interacting with an environment to complete tasks. When rewards provided by the environment are sparse, agents may not receive immediate feedback on the quality of actions that they take, thereby affecting learning of policies. In this paper, we propose to methods to augment the reward signal from the environment with an additional reward termed shaping advice in both single and multi-agent reinforcement learning. The shaping advice is specified as a difference of potential functions at consecutive time-steps. Each potential function is a function of observations and actions of the agents. The use of potential functions is underpinned by an insight that the total potential when starting from any state and returning to the same state is always equal to zero. We show through theoretical analyses and experimental validation that the shaping advice does not distract agents from completing tasks specified by the environment reward. Theoretically, we prove that the convergence of policy gradients and value functions when using shaping advice implies the convergence of these quantities in the absence of shaping advice. We design two algorithms- Shaping Advice in Single-agent reinforcement learning (SAS) and Shaping Advice in Multi-agent reinforcement learning (SAM). Shaping advice in SAS and SAM needs to be specified only once at the start of training, and can easily be provided by non-experts. Experimentally, we evaluate SAS and SAM on two tasks in single-agent environments and three tasks in multi-agent environments that have sparse rewards. We observe that using shaping advice results in agents learning policies to complete tasks faster, and obtain higher rewards than algorithms that do not use shaping advice.",
        "published": "2022-02-19T01:42:04Z",
        "link": "http://arxiv.org/abs/2202.09489v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "The Pareto Frontier of Instance-Dependent Guarantees in Multi-Player   Multi-Armed Bandits with no Communication",
        "authors": [
            "Allen Liu",
            "Mark Sellke"
        ],
        "summary": "We study the stochastic multi-player multi-armed bandit problem. In this problem, $m$ players cooperate to maximize their total reward from $K > m$ arms. However the players cannot communicate and are penalized (e.g. receive no reward) if they pull the same arm at the same time. We ask whether it is possible to obtain optimal instance-dependent regret $\\tilde{O}(1/\\Delta)$ where $\\Delta$ is the gap between the $m$-th and $m+1$-st best arms. Such guarantees were recently achieved in a model allowing the players to implicitly communicate through intentional collisions.   Surprisingly, we show that with no communication at all, such guarantees are not achievable. In fact, obtaining the optimal $\\tilde{O}(1/\\Delta)$ regret for some values of $\\Delta$ necessarily implies strictly sub-optimal regret in other regimes. Our main result is a complete characterization of the Pareto optimal instance-dependent trade-offs that are possible with no communication. Our algorithm generalizes that of Bubeck, Budzinski, and the second author. As there, our algorithm succeeds even when feedback upon collision can be corrupted by an adaptive adversary, thanks to a strong no-collision property. Our lower bound is based on topological obstructions at multiple scales and is completely new.",
        "published": "2022-02-19T18:19:36Z",
        "link": "http://arxiv.org/abs/2202.09653v2",
        "categories": [
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "PooL: Pheromone-inspired Communication Framework forLarge Scale   Multi-Agent Reinforcement Learning",
        "authors": [
            "Zixuan Cao",
            "Mengzhi Shi",
            "Zhanbo Zhao",
            "Xiujun Ma"
        ],
        "summary": "Being difficult to scale poses great problems in multi-agent coordination. Multi-agent Reinforcement Learning (MARL) algorithms applied in small-scale multi-agent systems are hard to extend to large-scale ones because the latter is far more dynamic and the number of interactions increases exponentially with the growing number of agents. Some swarm intelligence algorithms simulate the release and utilization mechanism of pheromones to control large-scale agent coordination. Inspired by such algorithms, \\textbf{PooL}, an \\textbf{p}her\\textbf{o}m\\textbf{o}ne-based indirect communication framework applied to large scale multi-agent reinforcement \\textbf{l}earning is proposed in order to solve the large-scale multi-agent coordination problem. Pheromones released by agents of PooL are defined as outputs of most reinforcement learning algorithms, which reflect agents' views of the current environment. The pheromone update mechanism can efficiently organize the information of all agents and simplify the complex interactions among agents into low-dimensional representations. Pheromones perceived by agents can be regarded as a summary of the views of nearby agents which can better reflect the real situation of the environment. Q-Learning is taken as our base model to implement PooL and PooL is evaluated in various large-scale cooperative environments. Experiments show agents can capture effective information through PooL and achieve higher rewards than other state-of-arts methods with lower communication costs.",
        "published": "2022-02-20T03:09:53Z",
        "link": "http://arxiv.org/abs/2202.09722v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Velocity Obstacle Based Risk-Bounded Motion Planning for Stochastic   Multi-Agent Systems",
        "authors": [
            "Xiaoxue Zhang",
            "Jun Ma",
            "Zilong Cheng",
            "Masayoshi Tomizuka",
            "Tong Heng Lee"
        ],
        "summary": "In this paper, we present an innovative risk-bounded motion planning methodology for stochastic multi-agent systems. For this methodology, the disturbance, noise, and model uncertainty are considered; and a velocity obstacle method is utilized to formulate the collision-avoidance constraints in the velocity space. With the exploitation of geometric information of static obstacles and velocity obstacles, a distributed optimization problem with probabilistic chance constraints is formulated for the stochastic multi-agent system. Consequently, collision-free trajectories are generated under a prescribed collision risk bound. Due to the existence of probabilistic and disjunctive constraints, the distributed chance-constrained optimization problem is reformulated as a mixed-integer program by introducing the binary variable to improve computational efficiency. This approach thus renders it possible to execute the motion planning task in the velocity space instead of the position space, which leads to smoother collision-free trajectories for multi-agent systems and higher computational efficiency. Moreover, the risk of potential collisions is bounded with this robust motion planning methodology. To validate the effectiveness of the methodology, different scenarios for multiple agents are investigated, and the simulation results clearly show that the proposed approach can generate high-quality trajectories under a predefined collision risk bound and avoid potential collisions effectively in the velocity space.",
        "published": "2022-02-20T07:28:24Z",
        "link": "http://arxiv.org/abs/2202.09748v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Cooperative Artificial Intelligence",
        "authors": [
            "Tobias Baumann"
        ],
        "summary": "In the future, artificial learning agents are likely to become increasingly widespread in our society. They will interact with both other learning agents and humans in a variety of complex settings including social dilemmas. We argue that there is a need for research on the intersection between game theory and artificial intelligence, with the goal of achieving cooperative artificial intelligence that can navigate social dilemmas well. We consider the problem of how an external agent can promote cooperation between artificial learners by distributing additional rewards and punishments based on observing the actions of the learners. We propose a rule for automatically learning how to create the right incentives by considering the anticipated parameter updates of each agent. Using this learning rule leads to cooperation with high social welfare in matrix games in which the agents would otherwise learn to defect with high probability. We show that the resulting cooperative outcome is stable in certain games even if the planning agent is turned off after a given number of episodes, while other games require ongoing intervention to maintain mutual cooperation. Finally, we reflect on what the goals of multi-agent reinforcement learning should be in the first place, and discuss the necessary building blocks towards the goal of building cooperative AI.",
        "published": "2022-02-20T16:50:37Z",
        "link": "http://arxiv.org/abs/2202.09859v1",
        "categories": [
            "cs.AI",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Collusion Resistant Federated Learning with Oblivious Distributed   Differential Privacy",
        "authors": [
            "David Byrd",
            "Vaikkunth Mugunthan",
            "Antigoni Polychroniadou",
            "Tucker Hybinette Balch"
        ],
        "summary": "Privacy-preserving federated learning enables a population of distributed clients to jointly learn a shared model while keeping client training data private, even from an untrusted server. Prior works do not provide efficient solutions that protect against collusion attacks in which parties collaborate to expose an honest client's model parameters. We present an efficient mechanism based on oblivious distributed differential privacy that is the first to protect against such client collusion, including the \"Sybil\" attack in which a server preferentially selects compromised devices or simulates fake devices. We leverage the novel privacy mechanism to construct a secure federated learning protocol and prove the security of that protocol. We conclude with empirical analysis of the protocol's execution speed, learning accuracy, and privacy performance on two data sets within a realistic simulation of 5,000 distributed network clients.",
        "published": "2022-02-20T19:52:53Z",
        "link": "http://arxiv.org/abs/2202.09897v1",
        "categories": [
            "cs.CR",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Conflict-Based Search for Explainable Multi-Agent Path Finding",
        "authors": [
            "Justin Kottinger",
            "Shaull Almagor",
            "Morteza Lahijanian"
        ],
        "summary": "In the Multi-Agent Path Finding (MAPF) problem, the goal is to find non-colliding paths for agents in an environment, such that each agent reaches its goal from its initial location. In safety-critical applications, a human supervisor may want to verify that the plan is indeed collision-free. To this end, a recent work introduces a notion of explainability for MAPF based on a visualization of the plan as a short sequence of images representing time segments, where in each time segment the trajectories of the agents are disjoint. Then, the explainable MAPF problem asks for a set of non-colliding paths that admits a short-enough explanation. Explainable MAPF adds a new difficulty to MAPF, in that it is NP-hard with respect to the size of the environment, and not just the number of agents. Thus, traditional MAPF algorithms are not equipped to directly handle explainable-MAPF. In this work, we adapt Conflict Based Search (CBS), a well-studied algorithm for MAPF, to handle explainable MAPF. We show how to add explainability constraints on top of the standard CBS tree and its underlying A* search. We examine the usefulness of this approach and, in particular, the tradeoff between planning time and explainability.",
        "published": "2022-02-20T23:13:14Z",
        "link": "http://arxiv.org/abs/2202.09930v2",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Towards technological adaptation of advanced farming through AI, IoT,   and Robotics: A Comprehensive overview",
        "authors": [
            "Md. Mahadi Hasan",
            "Muhammad Usama Islam",
            "Muhammad Jafar Sadeq"
        ],
        "summary": "The population explosion of the 21st century has adversely affected the natural resources with restricted availability of cultivable land, increased average temperatures due to global warming, and carbon footprint resulting in a drastic increase in floods as well as droughts thus making food security significant anxiety for most countries. The traditional methods were no longer sufficient which paved the way for technological ascents such as a substantial rise in Artificial Intelligence (AI), Internet of Things (IoT), as well as Robotics that provides high productivity, functional efficiency, flexibility, cost-effectiveness in the domain of agriculture. AI, IoT, and Robotics-based devices and methods have produced new paradigms and opportunities in agriculture. AI's existing approaches are soil management, crop diseases identification, weed identification, and management in collaboration with IoT devices. IoT has utilized automatic agricultural operations and real-time monitoring with few personnel employed in real-time. The major existing applications of agricultural robotics are for the function of soil preparation, planting, monitoring, harvesting, and storage. In this paper, researchers have explored a comprehensive overview of recent implementation, scopes, opportunities, challenges, limitations, and future research instructions of AI, IoT, and Robotics based methodology in the agriculture sector.",
        "published": "2022-02-21T07:47:43Z",
        "link": "http://arxiv.org/abs/2202.10459v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "HCMD-zero: Learning Value Aligned Mechanisms from Data",
        "authors": [
            "Jan Balaguer",
            "Raphael Koster",
            "Ari Weinstein",
            "Lucy Campbell-Gillingham",
            "Christopher Summerfield",
            "Matthew Botvinick",
            "Andrea Tacchetti"
        ],
        "summary": "Artificial learning agents are mediating a larger and larger number of interactions among humans, firms, and organizations, and the intersection between mechanism design and machine learning has been heavily investigated in recent years. However, mechanism design methods often make strong assumptions on how participants behave (e.g. rationality), on the kind of knowledge designers have access to a priori (e.g. access to strong baseline mechanisms), or on what the goal of the mechanism should be (e.g. total welfare). Here we introduce HCMD-zero, a general purpose method to construct mechanisms making none of these three assumptions. HCMD-zero learns to mediate interactions among participants and adjusts the mechanism parameters to make itself more likely to be preferred by participants. It does so by remaining engaged in an electoral contest with copies of itself, thereby accessing direct feedback from participants. We test our method on a stylized resource allocation game that highlights the tension between productivity, equality and the temptation to free ride. HCMD-zero produces a mechanism that is preferred by human participants over a strong baseline, it does so automatically, without requiring prior knowledge, and using human behavioral trajectories sparingly and effectively. Our analysis shows HCMD-zero consistently makes the mechanism policy more and more likely to be preferred by human participants over the course of training, and that it results in a mechanism with an interpretable and intuitive policy.",
        "published": "2022-02-21T11:13:53Z",
        "link": "http://arxiv.org/abs/2202.10122v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG",
            "econ.GN",
            "q-fin.EC"
        ]
    },
    {
        "title": "The Good Shepherd: An Oracle Agent for Mechanism Design",
        "authors": [
            "Jan Balaguer",
            "Raphael Koster",
            "Christopher Summerfield",
            "Andrea Tacchetti"
        ],
        "summary": "From social networks to traffic routing, artificial learning agents are playing a central role in modern institutions. We must therefore understand how to leverage these systems to foster outcomes and behaviors that align with our own values and aspirations. While multiagent learning has received considerable attention in recent years, artificial agents have been primarily evaluated when interacting with fixed, non-learning co-players. While this evaluation scheme has merit, it fails to capture the dynamics faced by institutions that must deal with adaptive and continually learning constituents. Here we address this limitation, and construct agents (\"mechanisms\") that perform well when evaluated over the learning trajectory of their adaptive co-players (\"participants\"). The algorithm we propose consists of two nested learning loops: an inner loop where participants learn to best respond to fixed mechanisms; and an outer loop where the mechanism agent updates its policy based on experience. We report the performance of our mechanism agents when paired with both artificial learning agents and humans as co-players. Our results show that our mechanisms are able to shepherd the participants strategies towards favorable outcomes, indicating a path for modern institutions to effectively and automatically influence the strategies and behaviors of their constituents.",
        "published": "2022-02-21T11:28:09Z",
        "link": "http://arxiv.org/abs/2202.10135v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG",
            "econ.GN",
            "q-fin.EC"
        ]
    },
    {
        "title": "Multi-Agent Reinforcement Learning for Network Selection and Resource   Allocation in Heterogeneous multi-RAT Networks",
        "authors": [
            "Mhd Saria Allahham",
            "Alaa Awad Abdellatif",
            "Naram Mhaisen",
            "Amr Mohamed",
            "Aiman Erbad",
            "Mohsen Guizani"
        ],
        "summary": "The rapid production of mobile devices along with the wireless applications boom is continuing to evolve daily. This motivates the exploitation of wireless spectrum using multiple Radio Access Technologies (multi-RAT) and developing innovative network selection techniques to cope with such intensive demand while improving Quality of Service (QoS). Thus, we propose a distributed framework for dynamic network selection at the edge level, and resource allocation at the Radio Access Network (RAN) level, while taking into consideration diverse applications' characteristics. In particular, our framework employs a deep Multi-Agent Reinforcement Learning (DMARL) algorithm, that aims to maximize the edge nodes' quality of experience while extending the battery lifetime of the nodes and leveraging adaptive compression schemes. Indeed, our framework enables data transfer from the network's edge nodes, with multi-RAT capabilities, to the cloud in a cost and energy-efficient manner, while maintaining QoS requirements of different supported applications. Our results depict that our solution outperforms state-of-the-art techniques of network selection in terms of energy consumption, latency, and cost.",
        "published": "2022-02-21T15:33:08Z",
        "link": "http://arxiv.org/abs/2202.10308v1",
        "categories": [
            "cs.MA",
            "cs.NI"
        ]
    },
    {
        "title": "The Role of Heterogeneity in Autonomous Perimeter Defense Problems",
        "authors": [
            "Aviv Adler",
            "Oscar Mickelin",
            "Ragesh K. Ramachandran",
            "Gaurav S. Sukhatme",
            "Sertac Karaman"
        ],
        "summary": "When is heterogeneity in the composition of an autonomous robotic team beneficial and when is it detrimental? We investigate and answer this question in the context of a minimally viable model that examines the role of heterogeneous speeds in perimeter defense problems, where defenders share a total allocated speed budget. We consider two distinct problem settings and develop strategies based on dynamic programming and on local interaction rules. We present a theoretical analysis of both approaches and our results are extensively validated using simulations. Interestingly, our results demonstrate that the viability of heterogeneous teams depends on the amount of information available to the defenders. Moreover, our results suggest a universality property: across a wide range of problem parameters the optimal ratio of the speeds of the defenders remains nearly constant.",
        "published": "2022-02-21T18:46:11Z",
        "link": "http://arxiv.org/abs/2202.10433v1",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "It Takes Four to Tango: Multiagent Selfplay for Automatic Curriculum   Generation",
        "authors": [
            "Yuqing Du",
            "Pieter Abbeel",
            "Aditya Grover"
        ],
        "summary": "We are interested in training general-purpose reinforcement learning agents that can solve a wide variety of goals. Training such agents efficiently requires automatic generation of a goal curriculum. This is challenging as it requires (a) exploring goals of increasing difficulty, while ensuring that the agent (b) is exposed to a diverse set of goals in a sample efficient manner and (c) does not catastrophically forget previously solved goals. We propose Curriculum Self Play (CuSP), an automated goal generation framework that seeks to satisfy these desiderata by virtue of a multi-player game with four agents. We extend the asymmetric curricula learning in PAIRED (Dennis et al., 2020) to a symmetrized game that carefully balances cooperation and competition between two off-policy student learners and two regret-maximizing teachers. CuSP additionally introduces entropic goal coverage and accounts for the non-stationary nature of the students, allowing us to automatically induce a curriculum that balances progressive exploration with anti-catastrophic exploitation. We demonstrate that our method succeeds at generating an effective curricula of goals for a range of control tasks, outperforming other methods at zero-shot test-time generalization to novel out-of-distribution goals.",
        "published": "2022-02-22T01:23:23Z",
        "link": "http://arxiv.org/abs/2202.10608v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "A Decentralized Communication Framework based on Dual-Level Recurrence   for Multi-Agent Reinforcement Learning",
        "authors": [
            "Jingchen Li",
            "Haobin Shi",
            "Kao-Shing Hwang"
        ],
        "summary": "We propose a model enabling decentralized multiple agents to share their perception of environment in a fair and adaptive way. In our model, both the current message and historical observation are taken into account, and they are handled in the same recurrent model but in different forms. We present a dual-level recurrent communication framework for multi-agent systems, in which the first recurrence occurs in the communication sequence and is used to transmit communication data among agents, while the second recurrence is based on the time sequence and combines the historical observations for each agent. The developed communication flow separates communication messages from memories but allows agents to share their historical observations by the dual-level recurrence. This design makes agents adapt to changeable communication objects, while the communication results are fair to these agents. We provide a sufficient discussion about our method in both partially observable and fully observable environments. The results of several experiments suggest our method outperforms the existing decentralized communication frameworks and the corresponding centralized training method.",
        "published": "2022-02-22T01:36:59Z",
        "link": "http://arxiv.org/abs/2202.10612v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Decentralized Safe Multi-agent Stochastic Optimal Control using Deep   FBSDEs and ADMM",
        "authors": [
            "Marcus A. Pereira",
            "Augustinos D. Saravanos",
            "Oswin So",
            "Evangelos A. Theodorou"
        ],
        "summary": "In this work, we propose a novel safe and scalable decentralized solution for multi-agent control in the presence of stochastic disturbances. Safety is mathematically encoded using stochastic control barrier functions and safe controls are computed by solving quadratic programs. Decentralization is achieved by augmenting to each agent's optimization variables, copy variables, for its neighbors. This allows us to decouple the centralized multi-agent optimization problem. However, to ensure safety, neighboring agents must agree on \"what is safe for both of us\" and this creates a need for consensus. To enable safe consensus solutions, we incorporate an ADMM-based approach. Specifically, we propose a Merged CADMM-OSQP implicit neural network layer, that solves a mini-batch of both, local quadratic programs as well as the overall consensus problem, as a single optimization problem. This layer is embedded within a Deep FBSDEs network architecture at every time step, to facilitate end-to-end differentiable, safe and decentralized stochastic optimal control. The efficacy of the proposed approach is demonstrated on several challenging multi-robot tasks in simulation. By imposing requirements on safety specified by collision avoidance constraints, the safe operation of all agents is ensured during the entire training process. We also demonstrate superior scalability in terms of computational and memory savings as compared to a centralized approach.",
        "published": "2022-02-22T03:57:23Z",
        "link": "http://arxiv.org/abs/2202.10658v2",
        "categories": [
            "cs.MA",
            "cs.LG",
            "cs.RO",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Acceleration of Gossip Algorithms through the Euler-Poisson-Darboux   Equation",
        "authors": [
            "Raphaël Berthier",
            "Mufan Li"
        ],
        "summary": "Gossip algorithms and their accelerated versions have been studied exclusively in discrete time on graphs. In this work, we take a different approach, and consider the scaling limit of gossip algorithms in both large graphs and large number of iterations. These limits lead to well-known partial differential equations (PDEs) with insightful properties. On lattices, we prove that the non-accelerated gossip algorithm of Boyd et al. [2006] converges to the heat equation, and the accelerated Jacobi polynomial iteration of Berthier et al. [2020] converges to the Euler-Poisson-Darboux (EPD) equation - a damped wave equation. Remarkably, with appropriate parameters, the fundamental solution of the EPD equation has the ideal gossip behaviour: a uniform density over an ellipsoid, whose radius increases at a rate proportional to t - the fastest possible rate for locally communicating gossip algorithms. This is in contrast with the heat equation where the density spreads on a typical scale of $\\sqrt{t}$. Additionally, we provide simulations demonstrating that the gossip algorithms are accurately approximated by their limiting PDEs.",
        "published": "2022-02-22T09:02:21Z",
        "link": "http://arxiv.org/abs/2202.10742v1",
        "categories": [
            "cs.DC",
            "cs.MA"
        ]
    },
    {
        "title": "Event-Triggered Tracking Control of Networked Multi-Agent Systems",
        "authors": [
            "Wei Ren",
            "Dimos V. Dimarogonas"
        ],
        "summary": "This paper studies the tracking control problem of networked multi-agent systems under both multiple networks and event-triggered mechanisms. Multiple networks are to connect multiple agents and reference systems with decentralized controllers to guarantee their information transmission, whereas the event-triggered mechanisms are to reduce the information transmission via the networks. In this paper, each agent has a network to communicate with its controller and reference system, and all networks are independent and asynchronous and have local event-triggered mechanisms, which are based on local measurements and determine whether the local measurements need to be transmitted via the corresponding network. To address this scenario, we first implement the emulation-based approach to develop a novel hybrid model for the tracking control of networked multi-agent systems. Next, sufficient conditions are derived and decentralized event-triggered mechanisms are designed to guarantee the desired tracking performance. Furthermore, the proposed approach is applied to derive novel results for the event-triggered observer design problem of networked multi-agent systems. Finally, two numerical examples are presented to illustrate the validity of the developed results.",
        "published": "2022-02-22T09:12:37Z",
        "link": "http://arxiv.org/abs/2202.10752v4",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "On the Rate of Convergence of Payoff-based Algorithms to Nash   Equilibrium in Strongly Monotone Games",
        "authors": [
            "Tatiana Tatarenko",
            "Maryam Kamgarpour"
        ],
        "summary": "We derive the rate of convergence to Nash equilibria for the payoff-based algorithm proposed in \\cite{tat_kam_TAC}. These rates are achieved under the standard assumption of convexity of the game, strong monotonicity and differentiability of the pseudo-gradient. In particular, we show the algorithm achieves $O(\\frac{1}{T})$ in the two-point function evaluating setting and $O(\\frac{1}{\\sqrt{T}})$ in the one-point function evaluation under additional requirement of Lipschitz continuity of the pseudo-gradient. These rates are to our knowledge the best known rates for the corresponding problem classes.",
        "published": "2022-02-22T19:45:48Z",
        "link": "http://arxiv.org/abs/2202.11147v1",
        "categories": [
            "math.OC",
            "cs.MA"
        ]
    },
    {
        "title": "Incorporating social norms into a configurable agent-based model of the   decision to perform commuting behaviour",
        "authors": [
            "Robert Greener",
            "Daniel Lewis",
            "Jon Reades",
            "Simon Miles",
            "Steven Cummins"
        ],
        "summary": "Interventions to increase active commuting have been recommended as a method to increase population physical activity, but evidence is mixed. Social norms related to travel behaviour may influence the uptake of active commuting interventions but are rarely considered in their design and evaluation. In this study we develop an agent-based model that incorporates social norms related to travel behaviour and demonstrate the utility of this through implementing car-free Wednesdays. A synthetic population of Waltham Forest, London, UK was generated using a microsimulation approach with data from the UK Census 2011 and UK HLS datasets. An agent-based model was created using this synthetic population which modelled how the actions of peers and neighbours, subculture, habit, weather, bicycle ownership, car ownership, environmental supportiveness, and congestion affect the decision to trave. The developed model (MOTIVATE) is a configurable agent-based model where social norms related to travel behaviour are used to provide a more realistic representation of the socio-ecological systems in which active commuting interventions may be deployed. The utility of this model is demonstrated using car-free days as a hypothetical intervention. In the control scenario, the odds of active travel were plausible at 0.091 (89% HPDI: [0.091, 0.091]). Compared to the control scenario, the odds of active travel were increased by 70.3% (89% HPDI: [70.3%, 70.3%]), in the intervention scenario, on non-car-free days; the effect is sustained to non-car-free days. The model is a useful tool for investigating the effect of how social networks and social norms influence the effectiveness of various interventions. If configured using real-world built environment data, it may be useful for investigating how social norms interact with the built environment to cause the emergence of commuting conventions.",
        "published": "2022-02-22T20:03:20Z",
        "link": "http://arxiv.org/abs/2202.11149v3",
        "categories": [
            "cs.MA",
            "stat.AP",
            "J.3; J.4"
        ]
    },
    {
        "title": "SIPOMDPLite-Net: Lightweight, Self-Interested Learning and Planning in   POSGs with Sparse Interactions",
        "authors": [
            "Gengyu Zhang",
            "Prashant Doshi"
        ],
        "summary": "This work introduces sIPOMDPLite-net, a deep neural network (DNN) architecture for decentralized, self-interested agent control in partially observable stochastic games (POSGs) with sparse interactions between agents. The network learns to plan in contexts modeled by the interactive partially observable Markov decision process (I-POMDP) Lite framework and uses hierarchical value iteration networks to simulate the solution of nested MDPs, which I-POMDP Lite attributes to the other agent to model its behavior and predict its intention. We train sIPOMDPLite-net with expert demonstrations on small two-agent Tiger-grid tasks, for which it accurately learns the underlying I-POMDP Lite model and near-optimal policy, and the policy continues to perform well on larger grids and real-world maps. As such, sIPOMDPLite-net shows good transfer capabilities and offers a lighter learning and planning approach for individual, self-interested agents in multiagent settings.",
        "published": "2022-02-22T21:47:48Z",
        "link": "http://arxiv.org/abs/2202.11188v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Blockchain Framework for Artificial Intelligence Computation",
        "authors": [
            "Jie You"
        ],
        "summary": "Blockchain is an essentially distributed database recording all transactions or digital events among participating parties. Each transaction in the records is approved and verified by consensus of the participants in the system that requires solving a hard mathematical puzzle, which is known as proof-of-work. To make the approved records immutable, the mathematical puzzle is not trivial to solve and therefore consumes substantial computing resources. However, it is energy-wasteful to have many computational nodes installed in the blockchain competing to approve the records by just solving a meaningless puzzle. Here, we pose proof-of-work as a reinforcement-learning problem by modeling the blockchain growing as a Markov decision process, in which a learning agent makes an optimal decision over the environment's state, whereas a new block is added and verified. Specifically, we design the block verification and consensus mechanism as a deep reinforcement-learning iteration process. As a result, our method utilizes the determination of state transition and the randomness of action selection of a Markov decision process, as well as the computational complexity of a deep neural network, collectively to make the blocks not easy to recompute and to preserve the order of transactions, while the blockchain nodes are exploited to train the same deep neural network with different data samples (state-action pairs) in parallel, allowing the model to experience multiple episodes across computing nodes but at one time. Our method is used to design the next generation of public blockchain networks, which has the potential not only to spare computational resources for industrial applications but also to encourage data sharing and AI model design for common problems.",
        "published": "2022-02-23T01:44:27Z",
        "link": "http://arxiv.org/abs/2202.11264v1",
        "categories": [
            "cs.DC",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Evacuation trials from a double-deck electric train unit: Experimental   data and sensitivity analysis",
        "authors": [
            "Hana Najmanová",
            "Veronika Pešková",
            "Lukáš Kuklík",
            "Marek Bukáček",
            "Pavel Hrabák",
            "Daniel Vašata"
        ],
        "summary": "Passenger trains represent a challenging environment in emergencies, with specific evacuation conditions resulting from the typical layout and interior design inherent to public transportation vehicles. This paper describes a dataset obtained in a full-scale controlled experiment emulating the emergency evacuation of a double-deck electric unit railcar carried out in Prague in 2018. 15 evacuation trials involving 91 participants were conducted under various evacuation scenarios considering different compositions of passenger crowd, exit widths, and exit types (e.g. egress to a high platform, to an open rail line using stairs, and a 750 mm jump without any supporting equipment). The study's main goals were to collect experimental data on the movement conditions in the railcar and to study the impact of various boundary conditions on evacuation process and total evacuation time. Movement characteristics (exit flows, speeds) and human behaviour (pre-movement activities, exiting behaviours) were also analysed.   The data obtained was used to validate and adjust a Pathfinder model to capture important aspects of evacuation from the railcar. Furthermore, a series of simulations using this model was performed to provide sensitivity analysis of the influence of crowd composition, exit width, and exit type on total evacuation time. As a key finding, we can conclude that for the case of a standard exit path (platform or stairs) the width of the main exit had the greatest impact on total evacuation time, however, crowd composition played the prevailing role in evacuation scenarios involving a jump.",
        "published": "2022-02-23T12:25:06Z",
        "link": "http://arxiv.org/abs/2202.11460v1",
        "categories": [
            "cs.MA",
            "physics.soc-ph"
        ]
    },
    {
        "title": "Robust Federated Learning with Connectivity Failures: A   Semi-Decentralized Framework with Collaborative Relaying",
        "authors": [
            "Michal Yemini",
            "Rajarshi Saha",
            "Emre Ozfatura",
            "Deniz Gündüz",
            "Andrea J. Goldsmith"
        ],
        "summary": "Intermittent connectivity of clients to the parameter server (PS) is a major bottleneck in federated edge learning frameworks. The lack of constant connectivity induces a large generalization gap, especially when the local data distribution amongst clients exhibits heterogeneity. To overcome intermittent communication outages between clients and the central PS, we introduce the concept of collaborative relaying wherein the participating clients relay their neighbors' local updates to the PS in order to boost the participation of clients with poor connectivity to the PS. We propose a semi-decentralized federated learning framework in which at every communication round, each client initially computes a local consensus of a subset of its neighboring clients' updates, and eventually transmits to the PS a weighted average of its own update and those of its neighbors'. We appropriately optimize these local consensus weights to ensure that the global update at the PS is unbiased with minimal variance - consequently improving the convergence rate. Numerical evaluations on the CIFAR-10 dataset demonstrate that our collaborative relaying approach outperforms federated averaging-based benchmarks for learning over intermittently-connected networks such as when the clients communicate over millimeter wave channels with intermittent blockages.",
        "published": "2022-02-24T01:06:42Z",
        "link": "http://arxiv.org/abs/2202.11850v2",
        "categories": [
            "cs.DC",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Parameterized Intractability for Multi-Winner Election under the   Chamberlin-Courant Rule and the Monroe Rule",
        "authors": [
            "Jiehua Chen",
            "Sanjukta Roy"
        ],
        "summary": "Answering an open question by Betzler et al. [Betzler et al., JAIR'13], we resolve the parameterized complexity of the multi-winner determination problem under two famous representation voting rules: the Chamberlin-Courant (in short CC) rule [Chamberlin and Courant, APSR'83] and the Monroe rule [Monroe, APSR'95]. We show that under both rules, the problem is W[1]-hard with respect to the sum $\\beta$ of misrepresentations, thereby precluding the existence of any $f(\\beta) \\cdot |I|^{O(1)}$ -time algorithm, where $|I|$ denotes the size of the input instance.",
        "published": "2022-02-24T10:34:46Z",
        "link": "http://arxiv.org/abs/2202.12006v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.GT"
        ]
    },
    {
        "title": "Practical Abstraction for Model Checking of Multi-Agent Systems",
        "authors": [
            "Wojciech Jamroga",
            "Yan Kim"
        ],
        "summary": "Model checking of multi-agent systems (MAS) is known to be hard, both theoretically and in practice. A smart abstraction of the state space may significantly reduce the model, and facilitate the verification. In this paper, we propose and study an intuitive agent-based abstraction scheme, based on the removal of variables in the representation of a MAS. This allows to do the reduction without generating the global model of the system. Moreover, the process is easy to understand and control even for domain experts with little knowledge of computer science. We formally prove the correctness of the approach, and evaluate the gains experimentally on models of a postal voting procedure.",
        "published": "2022-02-24T10:57:06Z",
        "link": "http://arxiv.org/abs/2202.12016v4",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "HeRo 2.0: A Low-Cost Robot for Swarm Robotics Research",
        "authors": [
            "Paulo Rezeck",
            "Hector Azpurua",
            "Mauricio FS Correa",
            "Luiz Chaimowicz"
        ],
        "summary": "The current state of electronic component miniaturization coupled with the increasing efficiency in hardware and software allow the development of smaller and compact robotic systems. The convenience of using these small, simple, yet capable robots has gathered the research community's attention towards practical applications of swarm robotics. This paper presents the design of a novel platform for swarm robotics applications that is low cost, easy to assemble using off-the-shelf components, and deeply integrated with the most used robotic framework available today: ROS (Robot Operating System). The robotic platform is entirely open, composed of a 3D printed body and open-source software. We describe its architecture, present its main features, and evaluate its functionalities executing experiments using a couple of robots. Results demonstrate that the proposed mobile robot is very effective given its small size and reduced cost, being suitable for swarm robotics research and education.",
        "published": "2022-02-24T22:23:14Z",
        "link": "http://arxiv.org/abs/2202.12391v2",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Can autonomy make bicycle-sharing systems more sustainable?   Environmental impact analysis of an emerging mobility technology",
        "authors": [
            "Naroa Coretti Sanchez",
            "Luis Alonso Pastor",
            "Kent Larson"
        ],
        "summary": "Autonomous bicycles have recently been proposed as a new and more efficient approach to bicycle-sharing systems (BSS), but the corresponding environmental implications remain unresearched. Conducting environmental impact assessments at an early technological stage is critical to influencing the design and, ultimately, environmental impacts of a system. Consequently, this paper aims to assess the environmental impact of autonomous shared bikes compared with current station-based and dockless systems under different sets of modeling hypotheses and mode-shift scenarios. The results indicate that autonomy could reduce the environmental impact per passenger kilometer traveled of current station-based and dockless BSS by 33.1 % and 58.0 %. The sensitivity analysis shows that the environmental impact of autonomous shared bicycles will mainly depend on vehicle usage rates and the need for infrastructure. Finally, this study highlights the importance of targeting the mode replacement from more polluting modes, especially as traditional mobility modes decarbonize and become more efficient.",
        "published": "2022-02-24T22:57:18Z",
        "link": "http://arxiv.org/abs/2202.12405v1",
        "categories": [
            "econ.GN",
            "cs.MA",
            "q-fin.EC"
        ]
    },
    {
        "title": "Complexity of Deliberative Coalition Formation",
        "authors": [
            "Edith Elkind",
            "Abheek Ghosh",
            "Paul Goldberg"
        ],
        "summary": "Elkind et al. (AAAI, 2021) introduced a model for deliberative coalition formation, where a community wishes to identify a strongly supported proposal from a space of alternatives, in order to change the status quo. In their model, agents and proposals are points in a metric space, agents' preferences are determined by distances, and agents deliberate by dynamically forming coalitions around proposals that they prefer over the status quo. The deliberation process operates via k-compromise transitions, where agents from k (current) coalitions come together to form a larger coalition in order to support a (perhaps new) proposal, possibly leaving behind some of the dissenting agents from their old coalitions. A deliberation succeeds if it terminates by identifying a proposal with the largest possible support. For deliberation in d dimensions, Elkind et al. consider two variants of their model: in the Euclidean model, proposals and agent locations are points in R^d and the distance is measured according to ||...||_2; and in the hypercube model, proposals and agent locations are vertices of the d-dimensional hypercube and the metric is the Hamming distance. They show that in the continuous model 2-compromises are guaranteed to succeed, but in the discrete model for deliberation to succeed it may be necessary to use k-compromises with k >= d. We complement their analysis by (1) proving that in both models it is hard to find a proposal with a high degree of support, and even a 2-compromise transition may be hard to compute; (2) showing that a sequence of 2-compromise transitions may be exponentially long; (3) strengthening the lower bound on the size of the compromise for the d-hypercube model from d to 2^{\\Omega(d)}.",
        "published": "2022-02-25T10:18:22Z",
        "link": "http://arxiv.org/abs/2202.12594v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Inter-Cell Slicing Resource Partitioning via Coordinated Multi-Agent   Deep Reinforcement Learning",
        "authors": [
            "Tianlun Hu",
            "Qi Liao",
            "Qiang Liu",
            "Dan Wellington",
            "Georg Carle"
        ],
        "summary": "Network slicing enables the operator to configure virtual network instances for diverse services with specific requirements. To achieve the slice-aware radio resource scheduling, dynamic slicing resource partitioning is needed to orchestrate multi-cell slice resources and mitigate inter-cell interference. It is, however, challenging to derive the analytical solutions due to the complex inter-cell interdependencies, interslice resource constraints, and service-specific requirements. In this paper, we propose a multi-agent deep reinforcement learning (DRL) approach that improves the max-min slice performance while maintaining the constraints of resource capacity. We design two coordination schemes to allow distributed agents to coordinate and mitigate inter-cell interference. The proposed approach is extensively evaluated in a system-level simulator. The numerical results show that the proposed approach with inter-agent coordination outperforms the centralized approach in terms of delay and convergence. The proposed approach improves more than two-fold increase in resource efficiency as compared to the baseline approach.",
        "published": "2022-02-25T17:23:09Z",
        "link": "http://arxiv.org/abs/2202.12833v1",
        "categories": [
            "cs.NI",
            "cs.MA"
        ]
    },
    {
        "title": "Exploring Fairness in District-based Multi-party Elections under   different Voting Rules using Stochastic Simulations",
        "authors": [
            "Adway Mitra"
        ],
        "summary": "Many democratic societies use district-based elections, where the region under consideration is geographically divided into districts and a representative is chosen for each district based on the preferences of the electors who reside there. These representatives belong to political parties, and the executive powers are acquired by that party which has a majority of the elected district representatives. In most systems, each elector can express preference for one candidate, though they may have a complete or partial ranking of the candidates/parties. We show that this can lead to situations where many electors are dissatisfied with the election results, which is not desirable in a democracy. The results may be biased towards the supporters of a particular party, and against others. Inspired by current literature on fairness of Machine Learning algorithms, we define measures of fairness to quantify the satisfaction of electors, irrespective of their political choices. We also consider alternative election policies using concepts of voting rules and rank aggregation, to enable voters to express their detailed preferences without making the electoral process cumbersome or opaque. We then evaluate these policies using the aforementioned fairness measures with the help of Monte Carlo simulations. Such simulations are obtained using a proposed stochastic model for election simulation, that takes into account community identities of electors and its role in influencing their residence and political preferences. We show that this model can simulate actual multi-party elections in India. Through extensive simulations, we find that allowing voters to provide 2 preferences reduces the disparity between supporters of different parties in terms of the election result.",
        "published": "2022-02-25T18:03:03Z",
        "link": "http://arxiv.org/abs/2203.03720v1",
        "categories": [
            "cs.CY",
            "cs.MA",
            "cs.SI"
        ]
    },
    {
        "title": "Hierarchical Control for Head-to-Head Autonomous Racing",
        "authors": [
            "Rishabh Saumil Thakkar",
            "Aryaman Singh Samyal",
            "David Fridovich-Keil",
            "Zhe Xu",
            "Ufuk Topcu"
        ],
        "summary": "We develop a hierarchical controller for head-to-head autonomous racing. We first introduce a formulation of a racing game with realistic safety and fairness rules. A high-level planner approximates the original formulation as a discrete game with simplified state, control, and dynamics to easily encode the complex safety and fairness rules and calculates a series of target waypoints. The low-level controller takes the resulting waypoints as a reference trajectory and computes high-resolution control inputs by solving an alternative formulation approximation with simplified objectives and constraints. We consider two approaches for the low-level planner, constructing two hierarchical controllers. One approach uses multi-agent reinforcement learning (MARL), and the other solves a linear-quadratic Nash game (LQNG) to produce control inputs. The controllers are compared against three baselines: an end-to-end MARL controller, a MARL controller tracking a fixed racing line, and an LQNG controller tracking a fixed racing line. Quantitative results show that the proposed hierarchical methods outperform their respective baseline methods in terms of head-to-head race wins and abiding by the rules. The hierarchical controller using MARL for low-level control consistently outperformed all other methods by winning over 90% of head-to-head races and more consistently adhered to the complex racing rules. Qualitatively, we observe the proposed controllers mimicking actions performed by expert human drivers such as shielding/blocking, overtaking, and long-term planning for delayed advantages. We show that hierarchical planning for game-theoretic reasoning produces competitive behavior even when challenged with complex rules and constraints.",
        "published": "2022-02-25T18:11:52Z",
        "link": "http://arxiv.org/abs/2202.12861v6",
        "categories": [
            "cs.MA",
            "cs.RO",
            "math.OC"
        ]
    },
    {
        "title": "Distributed Multi-Agent Reinforcement Learning Based on Graph-Induced   Local Value Functions",
        "authors": [
            "Gangshan Jing",
            "He Bai",
            "Jemin George",
            "Aranya Chakrabortty",
            "Piyush K. Sharma"
        ],
        "summary": "Achieving distributed reinforcement learning (RL) for large-scale cooperative multi-agent systems (MASs) is challenging because: (i) each agent has access to only limited information; (ii) issues on convergence or computational complexity emerge due to the curse of dimensionality. In this paper, we propose a general computationally efficient distributed framework for cooperative multi-agent reinforcement learning (MARL) by utilizing the structures of graphs involved in this problem. We introduce three coupling graphs describing three types of inter-agent couplings in MARL, namely, the state graph, the observation graph and the reward graph. By further considering a communication graph, we propose two distributed RL approaches based on local value-functions derived from the coupling graphs. The first approach is able to reduce sample complexity significantly under specific conditions on the aforementioned four graphs. The second approach provides an approximate solution and can be efficient even for problems with dense coupling graphs. Here there is a trade-off between minimizing the approximation error and reducing the computational complexity. Simulations show that our RL algorithms have a significantly improved scalability to large-scale MASs compared with centralized and consensus-based distributed RL algorithms.",
        "published": "2022-02-26T03:01:51Z",
        "link": "http://arxiv.org/abs/2202.13046v5",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Orientation-Discriminative Feature Representation for Decentralized   Pedestrian Tracking",
        "authors": [
            "Vikram Shree",
            "Carlos Diaz-Ruiz",
            "Chang Liu",
            "Bharath Hariharan",
            "Mark Campbell"
        ],
        "summary": "This paper focuses on the problem of decentralized pedestrian tracking using a sensor network. Traditional works on pedestrian tracking usually use a centralized framework, which becomes less practical for robotic applications due to limited communication bandwidth. Our paper proposes a communication-efficient, orientation-discriminative feature representation to characterize pedestrian appearance information, that can be shared among sensors. Building upon that representation, our work develops a cross-sensor track association approach to achieve decentralized tracking. Extensive evaluations are conducted on publicly available datasets and results show that our proposed approach leads to improved performance in multi-sensor tracking.",
        "published": "2022-02-26T22:03:58Z",
        "link": "http://arxiv.org/abs/2202.13237v1",
        "categories": [
            "cs.CV",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Investigating the Role of Pedestrian Groups in Shared Spaces through   Simulation Modeling",
        "authors": [
            "Suhair Ahmed",
            "Fatema T. Johora",
            "Jörg P. Müller"
        ],
        "summary": "In shared space environments, urban space is shared among different types of road users, who frequently interact with each other to negotiate priority and coordinate their trajectories. Instead of traffic rules, interactions among them are conducted by informal rules like speed limitations and by social protocols e.g., courtesy behavior. Social groups (socially related road users who walk together) are an essential phenomenon in shared spaces and affect the safety and efficiency of such environments. To replicate group phenomena and systematically study their influence in shared spaces; realistic models of social groups and the integration of these models into shared space simulations are required. In this work, we focus on pedestrian groups and adopt an extended version of the social force model in conjunction with a game-theoretic model to simulate their movements. The novelty of our paper is in the modeling of interactions between social groups and vehicles. We validate our model by simulating scenarios involving interaction between social groups and also group-to-vehicle interaction.",
        "published": "2022-02-27T18:02:24Z",
        "link": "http://arxiv.org/abs/2202.13410v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "On Intercultural Transferability and Calibration of Heterogeneous Shared   Space Motion Models",
        "authors": [
            "Fatema T. Johora",
            "Jörg P. Müller"
        ],
        "summary": "Modelling and simulation of mixed-traffic zones is an important tool for transportation planners to assess safety, efficiency, and human-friendliness of future urban areas. This paper addresses problems of calibration and transferability of existing shared space models when applied to scenarios that differ in terms of cultural aspects, traffic conditions, and spatial layout. In particular, the first contribution of this work is an enhancement of the Game-Theoretic Social Force Model (GSFM) by a generic methodology for largely automated model calibration; we illustrate the use of the calibration method for a shared space environment in Germany. The second contribution is an investigation into transferability of shared space models. We define criteria for model transferability and present a case study, in which we analyse and evaluate transferability of the model we constructed based on the ``German dataset'' to a different shared space environment from China. Our results indicate that although -- as to be expected -- the model faces difficulties to replicate the movement behaviours of road users from a new environment, by adding social norms (derived through analysis) of that environment to our model, satisfactory improvement of model accuracy can be obtained with limited effort.",
        "published": "2022-02-27T18:24:10Z",
        "link": "http://arxiv.org/abs/2202.13419v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "PheroCom: Decentralised and asynchronous swarm robotics coordination   based on virtual pheromone and vibroacoustic communication",
        "authors": [
            "Claudiney R. Tinoco",
            "Gina M. B. Oliveira"
        ],
        "summary": "Representation and control of the dynamics of stigmergic substances used by bio-inspired approaches is a challenge when applied to robotics. In order to overcome this challenge, this work proposes a model to coordinate swarms of robots based on the virtualisation and control of these substances in a local scope. The model presents a new pheromone modelling, which enables the decentralisation and asynchronicity of navigation decisions. Each robot maintains an independent virtual pheromone map, which is continuously updated with the robot's deposits and pheromone evaporation. Moreover, the individual pheromone map is also updated by aggregating information from other robots that are exploring nearby areas. Thus, individual and independent maps replace the need of a centralising agent that controls and distributes the pheromone information, which is not always practicable. Pheromone information propagation is inspired by ants' vibroacoustic communication, which, in turn, is characterised as an indirect communication through a type of gossip protocol. The proposed model was evaluated through an agent simulation software, implemented by the authors, and in the Webots platform. Experiments were carried out to validate the model in different environments, with different shapes and sizes, as well as varying the number of robots. The analysis of the results has shown that the model was able to perform the coordination of the swarm, and the robots have exhibited an expressive performance executing the surveillance task.",
        "published": "2022-02-27T21:22:14Z",
        "link": "http://arxiv.org/abs/2202.13456v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA",
            "cs.NE",
            "I.2.9; I.2.8; I.2.1; I.2.11"
        ]
    },
    {
        "title": "Computational Experiments: Past, Present and Future",
        "authors": [
            "Xiao Xue",
            "Xiang-Ning Yu",
            "De-Yu Zhou",
            "Xiao Wang",
            "Zhang-Bin Zhou",
            "Fei-Yue Wang"
        ],
        "summary": "Powered by advanced information technology, more and more complex systems are exhibiting characteristics of the Cyber-Physical-Social Systems (CPSS). Understanding the mechanism of CPSS is essential to our ability to control their actions, reap their benefits and minimize their harms. In consideration of the cost, legal and institutional constraints on the study of CPSS in real world, computational experiments have emerged as a new method for quantitative analysis of CPSS. This paper outlines computational experiments from several key aspects, including origin, characteristics, methodological framework, key technologies, and some typical applications. Finally, this paper highlights some challenges of computational experiments to provide a roadmap for its rapid development and widespread application.",
        "published": "2022-02-28T11:18:17Z",
        "link": "http://arxiv.org/abs/2202.13690v1",
        "categories": [
            "cs.MA",
            "cs.CY",
            "cs.SI"
        ]
    },
    {
        "title": "\"If you could see me through my eyes\": Predicting Pedestrian Perception",
        "authors": [
            "Julian Petzold",
            "Mostafa Wahby",
            "Franek Stark",
            "Ulrich Behrje",
            "Heiko Hamann"
        ],
        "summary": "Pedestrians are particularly vulnerable road users in urban traffic. With the arrival of autonomous driving, novel technologies can be developed specifically to protect pedestrians. We propose a machine learning toolchain to train artificial neural networks as models of pedestrian behavior. In a preliminary study, we use synthetic data from simulations of a specific pedestrian crossing scenario to train a variational autoencoder and a long short-term memory network to predict a pedestrian's future visual perception. We can accurately predict a pedestrian's future perceptions within relevant time horizons. By iteratively feeding these predicted frames into these networks, they can be used as simulations of pedestrians as indicated by our results. Such trained networks can later be used to predict pedestrian behaviors even from the perspective of the autonomous car. Another future extension will be to re-train these networks with real-world video data.",
        "published": "2022-02-28T17:36:12Z",
        "link": "http://arxiv.org/abs/2202.13981v2",
        "categories": [
            "cs.CV",
            "cs.MA"
        ]
    },
    {
        "title": "Can Mean Field Control (MFC) Approximate Cooperative Multi Agent   Reinforcement Learning (MARL) with Non-Uniform Interaction?",
        "authors": [
            "Washim Uddin Mondal",
            "Vaneet Aggarwal",
            "Satish V. Ukkusuri"
        ],
        "summary": "Mean-Field Control (MFC) is a powerful tool to solve Multi-Agent Reinforcement Learning (MARL) problems. Recent studies have shown that MFC can well-approximate MARL when the population size is large and the agents are exchangeable. Unfortunately, the presumption of exchangeability implies that all agents uniformly interact with one another which is not true in many practical scenarios. In this article, we relax the assumption of exchangeability and model the interaction between agents via an arbitrary doubly stochastic matrix. As a result, in our framework, the mean-field `seen' by different agents are different. We prove that, if the reward of each agent is an affine function of the mean-field seen by that agent, then one can approximate such a non-uniform MARL problem via its associated MFC problem within an error of $e=\\mathcal{O}(\\frac{1}{\\sqrt{N}}[\\sqrt{|\\mathcal{X}|} + \\sqrt{|\\mathcal{U}|}])$ where $N$ is the population size and $|\\mathcal{X}|$, $|\\mathcal{U}|$ are the sizes of state and action spaces respectively. Finally, we develop a Natural Policy Gradient (NPG) algorithm that can provide a solution to the non-uniform MARL with an error $\\mathcal{O}(\\max\\{e,\\epsilon\\})$ and a sample complexity of $\\mathcal{O}(\\epsilon^{-3})$ for any $\\epsilon >0$.",
        "published": "2022-02-28T19:03:09Z",
        "link": "http://arxiv.org/abs/2203.00035v2",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Robust Multi-Agent Bandits Over Undirected Graphs",
        "authors": [
            "Daniel Vial",
            "Sanjay Shakkottai",
            "R. Srikant"
        ],
        "summary": "We consider a multi-agent multi-armed bandit setting in which $n$ honest agents collaborate over a network to minimize regret but $m$ malicious agents can disrupt learning arbitrarily. Assuming the network is the complete graph, existing algorithms incur $O( (m + K/n) \\log (T) / \\Delta )$ regret in this setting, where $K$ is the number of arms and $\\Delta$ is the arm gap. For $m \\ll K$, this improves over the single-agent baseline regret of $O(K\\log(T)/\\Delta)$.   In this work, we show the situation is murkier beyond the case of a complete graph. In particular, we prove that if the state-of-the-art algorithm is used on the undirected line graph, honest agents can suffer (nearly) linear regret until time is doubly exponential in $K$ and $n$. In light of this negative result, we propose a new algorithm for which the $i$-th agent has regret $O( ( d_{\\text{mal}}(i) + K/n) \\log(T)/\\Delta)$ on any connected and undirected graph, where $d_{\\text{mal}}(i)$ is the number of $i$'s neighbors who are malicious. Thus, we generalize existing regret bounds beyond the complete graph (where $d_{\\text{mal}}(i) = m$), and show the effect of malicious agents is entirely local (in the sense that only the $d_{\\text{mal}}(i)$ malicious agents directly connected to $i$ affect its long-term regret).",
        "published": "2022-02-28T20:21:55Z",
        "link": "http://arxiv.org/abs/2203.00076v2",
        "categories": [
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Pippi: Practical Protocol Instantiation",
        "authors": [
            "Samuel H. Christie V",
            "Amit K. Chopra",
            "Munindar P. Singh"
        ],
        "summary": "A protocol specifies interactions between roles, which together constitute a multiagent system (MAS). Enacting a protocol presupposes that agents are bound to the its roles. Existing protocol-based approaches, however, do not adequately treat the practical aspects of how roles bindings come about.   Pippi addresses this problem of MAS instantiation. It proposes the notion of a metaprotocol, enacting which instantiates a MAS suitable for enacting a given protocol. Pippi demonstrates the subtleties involved in instantiating MAS arising from protocol composition, correlation, and decentralization. To address these subtleties and further support practical application patterns, we introduce an enhanced protocol language, with support for parameter types (including role and protocol typed parameters, for metaprotocols), interface flexibility, and binding constraints. We discuss the realization of our approach through an extended agent architecture, including the novel concept of a MAS adapter for contact management. We evaluate Pippi's expressiveness by demonstrating common patterns for agent discovery.",
        "published": "2022-02-28T20:44:23Z",
        "link": "http://arxiv.org/abs/2203.00086v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Setting Fair Incentives to Maximize Improvement",
        "authors": [
            "Saba Ahmadi",
            "Hedyeh Beyhaghi",
            "Avrim Blum",
            "Keziah Naggita"
        ],
        "summary": "We consider the problem of helping agents improve by setting short-term goals. Given a set of target skill levels, we assume each agent will try to improve from their initial skill level to the closest target level within reach or do nothing if no target level is within reach. We consider two models: the common improvement capacity model, where agents have the same limit on how much they can improve, and the individualized improvement capacity model, where agents have individualized limits. Our goal is to optimize the target levels for social welfare and fairness objectives, where social welfare is defined as the total amount of improvement, and fairness objectives are considered where the agents belong to different underlying populations. A key technical challenge of this problem is the non-monotonicity of social welfare in the set of target levels, i.e., adding a new target level may decrease the total amount of improvement as it may get easier for some agents to improve. This is especially challenging when considering multiple groups because optimizing target levels in isolation for each group and outputting the union may result in arbitrarily low improvement for a group, failing the fairness objective. Considering these properties, we provide algorithms for optimal and near-optimal improvement for both social welfare and fairness objectives. These algorithmic results work for both the common and individualized improvement capacity models. Furthermore, we show a placement of target levels exists that is approximately optimal for the social welfare of each group. Unlike the algorithmic results, this structural statement only holds in the common improvement capacity model, and we show counterexamples in the individualized improvement capacity model. Finally, we extend our algorithms to learning settings where we have only sample access to the initial skill levels of agents.",
        "published": "2022-02-28T23:09:40Z",
        "link": "http://arxiv.org/abs/2203.00134v1",
        "categories": [
            "cs.GT",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Collaborative Robot Mapping using Spectral Graph Analysis",
        "authors": [
            "Lukas Bernreiter",
            "Shehryar Khattak",
            "Lionel Ott",
            "Roland Siegwart",
            "Marco Hutter",
            "Cesar Cadena"
        ],
        "summary": "In this paper, we deal with the problem of creating globally consistent pose graphs in a centralized multi-robot SLAM framework. For each robot to act autonomously, individual onboard pose estimates and maps are maintained, which are then communicated to a central server to build an optimized global map. However, inconsistencies between onboard and server estimates can occur due to onboard odometry drift or failure. Furthermore, robots do not benefit from the collaborative map if the server provides no feedback in a computationally tractable and bandwidth-efficient manner. Motivated by this challenge, this paper proposes a novel collaborative mapping framework to enable accurate global mapping among robots and server. In particular, structural differences between robot and server graphs are exploited at different spatial scales using graph spectral analysis to generate necessary constraints for the individual robot pose graphs. The proposed approach is thoroughly analyzed and validated using several real-world multi-robot field deployments where we show improvements of the onboard system up to 90%.",
        "published": "2022-03-01T09:34:08Z",
        "link": "http://arxiv.org/abs/2203.00308v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Quick Multi-Robot Motion Planning by Combining Sampling and Search",
        "authors": [
            "Keisuke Okumura",
            "Xavier Défago"
        ],
        "summary": "We propose a novel algorithm to solve multi-robot motion planning (MRMP) rapidly, called Simultaneous Sampling-and-Search Planning (SSSP). Conventional MRMP studies mostly take the form of two-phase planning that constructs roadmaps and then finds inter-robot collision-free paths on those roadmaps. In contrast, SSSP simultaneously performs roadmap construction and collision-free pathfinding. This is realized by uniting techniques of single-robot sampling-based motion planning and search techniques of multi-agent pathfinding on discretized spaces. Doing so builds the small search space, leading to quick MRMP. SSSP ensures finding a solution eventually if exists. Our empirical evaluations in various scenarios demonstrate that SSSP significantly outperforms standard approaches to MRMP, i.e., solving more problem instances much faster. We also applied SSSP to planning for 32 ground robots in a dense situation.",
        "published": "2022-03-01T09:43:20Z",
        "link": "http://arxiv.org/abs/2203.00315v3",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Learning Robust Real-Time Cultural Transmission without Human Data",
        "authors": [
            "Cultural General Intelligence Team",
            "Avishkar Bhoopchand",
            "Bethanie Brownfield",
            "Adrian Collister",
            "Agustin Dal Lago",
            "Ashley Edwards",
            "Richard Everett",
            "Alexandre Frechette",
            "Yanko Gitahy Oliveira",
            "Edward Hughes",
            "Kory W. Mathewson",
            "Piermaria Mendolicchio",
            "Julia Pawar",
            "Miruna Pislar",
            "Alex Platonov",
            "Evan Senter",
            "Sukhdeep Singh",
            "Alexander Zacherl",
            "Lei M. Zhang"
        ],
        "summary": "Cultural transmission is the domain-general social skill that allows agents to acquire and use information from each other in real-time with high fidelity and recall. In humans, it is the inheritance process that powers cumulative cultural evolution, expanding our skills, tools and knowledge across generations. We provide a method for generating zero-shot, high recall cultural transmission in artificially intelligent agents. Our agents succeed at real-time cultural transmission from humans in novel contexts without using any pre-collected human data. We identify a surprisingly simple set of ingredients sufficient for generating cultural transmission and develop an evaluation methodology for rigorously assessing it. This paves the way for cultural evolution as an algorithm for developing artificial general intelligence.",
        "published": "2022-03-01T19:32:27Z",
        "link": "http://arxiv.org/abs/2203.00715v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Hierarchical team structure and multidimensional localization (or   siloing) on networks",
        "authors": [
            "Laurent Hébert-Dufresne",
            "Guillaume St-Onge",
            "John Meluso",
            "James Bagrow",
            "Antoine Allard"
        ],
        "summary": "Knowledge silos emerge when structural properties of organizational interaction networks limit the diffusion of information. These structural barriers are known to take many forms at different scales - hubs in otherwise sparse organisations, large dense teams, or global core-periphery structure - but we lack an understanding of how these different structures interact. Here we bridge the gap between the mathematical literature on localization of spreading dynamics and the more applied literature on knowledge silos in organizational interaction networks. To do so, we introduce a new model that considers a layered structure of teams to unveil a new form of hierarchical localization (i.e., the localization of information at the top or center of an organization) and study its interplay with known phenomena of mesoscopic localization (i.e., the localization of information in large groups), $k$-core localization (i.e., around denser $k$-cores) and hub localization (i.e., around high degree stars). We also include a complex contagion mechanism by considering a general infection kernel which can depend on hierarchical level (influence), degree (popularity), infectious neighbors (social reinforcement) or team size (importance). This general model allows us to study the multifaceted phenomenon of information siloing in complex organizational interaction networks and opens the door to new optimization problems to promote or hinder the emergence of different localization regimes.",
        "published": "2022-03-01T21:07:29Z",
        "link": "http://arxiv.org/abs/2203.00745v1",
        "categories": [
            "physics.soc-ph",
            "cs.MA",
            "cs.SI",
            "nlin.AO"
        ]
    },
    {
        "title": "Modeling and Control of Smart Standalone Microgrids within Cyber   Physical System Frameworks",
        "authors": [
            "Meher Preetam Korukonda"
        ],
        "summary": "The ability of grid-connected microgrids (MG) to operate in islanded mode makes them an efficient solution for improving power quality and reliability. This property of MG is very much beneficial for remote and undeveloped areas in progressing countries. Moreover, ICT technology has led to the development of Smart Standalone Microgrids (SSMG), which are inundated with a plethora of sensors. This allows multiple microgrids to be controlled in a coordinated way to achieve self-sufficiency in power. In such systems, there is much interdependency between various power, control and communication parameters. Owing to these developments, the control of physical variables like voltage get affected by cyber parameters like, communication structure, delay and link loss. Moreover, due to isolation from main grid and abundance of renewable power generation units like solar PV, the inertia of these standalone grids is reduced greatly and calls for advanced control algorithms which use an abundance of sensors. Hence, the stability of these systems is greatly affected by sensor failures apart from many physical parameters like load and environmental conditions. In this thesis, a generic structure of an AC-DC hybrid microgrid is considered which is subdivided into various AC and DC counterparts. The AC and DC SSMGs are separately modeled and control solutions are proposed to improve their stability. The first two contributions propose adaptive control schemes on the primary level of control in the hybrid microgrid. Their function is to provide fast and stable parameters regulation in the DCSSMG when subjected to atmospheric changes along with faults in sensor readings. The third and fourth contributions cater to development of coordinated control cyber physical frameworks in the ACSSMG to handle the presence of simultaneous disturbances from both cyber/physical domains.",
        "published": "2022-03-02T09:22:55Z",
        "link": "http://arxiv.org/abs/2203.00970v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.NI",
            "cs.SY"
        ]
    },
    {
        "title": "STV+AGR: Towards Practical Verification of Strategic Ability Using   Assume-Guarantee Reasoning",
        "authors": [
            "Damian Kurpiewski",
            "Łukasz Mikulski",
            "Wojciech Jamroga"
        ],
        "summary": "We present a substantially expanded version of our tool STV for strategy synthesis and verification of strategic abilities. The new version provides a web interface and support for assume-guarantee verification of multi-agent systems.",
        "published": "2022-03-02T11:19:09Z",
        "link": "http://arxiv.org/abs/2203.01033v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Foundations for Grassroots Democratic Metaverse",
        "authors": [
            "Ehud Shapiro",
            "Nimrod Talmon"
        ],
        "summary": "While the physical lives of many of us are in democracies (one person, one vote - e.g., the EU and the US), our digital lives are mostly in autocracies (one person, all votes - e.g., Facebook). Cryptocurrencies promise liberation but stop short, at plutocracy (one coin, one vote). What would it take for us to live our digital lives in a digital democracy? This paper offers a vision, a theoretical framework, and an architecture for a grassroots network of autonomous, people-owned, people-operated, and people-governed digital communities, namely a grassroots democratic metaverse. It also charts a roadmap towards realizing it, and identifies unexplored territory for further research.",
        "published": "2022-03-02T12:16:09Z",
        "link": "http://arxiv.org/abs/2203.04090v3",
        "categories": [
            "cs.CY",
            "cs.AI",
            "cs.DC",
            "cs.MA",
            "cs.SI"
        ]
    },
    {
        "title": "The Dynamics of Q-learning in Population Games: a Physics-Inspired   Continuity Equation Model",
        "authors": [
            "Shuyue Hu",
            "Chin-Wing Leung",
            "Ho-fung Leung",
            "Harold Soh"
        ],
        "summary": "Although learning has found wide application in multi-agent systems, its effects on the temporal evolution of a system are far from understood. This paper focuses on the dynamics of Q-learning in large-scale multi-agent systems modeled as population games. We revisit the replicator equation model for Q-learning dynamics and observe that this model is inappropriate for our concerned setting. Motivated by this, we develop a new formal model, which bears a formal connection with the continuity equation in physics. We show that our model always accurately describes the Q-learning dynamics in population games across different initial settings of MASs and game configurations. We also show that our model can be applied to different exploration mechanisms, describe the mean dynamics, and be extended to Q-learning in 2-player and n-player games. Last but not least, we show that our model can provide insights into algorithm parameters and facilitate parameter tuning.",
        "published": "2022-03-03T03:22:38Z",
        "link": "http://arxiv.org/abs/2203.01500v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "SMA-NBO: A Sequential Multi-Agent Planning with Nominal Belief-State   Optimization in Target Tracking",
        "authors": [
            "Tianqi Li",
            "Lucas W. Krakow",
            "Swaminathan Gopalswamy"
        ],
        "summary": "In target tracking with mobile multi-sensor systems, sensor deployment impacts the observation capabilities and the resulting state estimation quality. Based on a partially observable Markov decision process (POMDP) formulation comprised of the observable sensor dynamics, unobservable target states, and accompanying observation laws, we present a distributed information-driven solution approach to the multi-agent target tracking problem, namely, sequential multi-agent nominal belief-state optimization (SMA-NBO). SMA-NBO seeks to minimize the expected tracking error via receding horizon control including a heuristic expected cost-to-go (HECTG). SMA-NBO incorporates a computationally efficient approximation of the target belief-state over the horizon. The agent-by-agent decision-making is capable of leveraging on-board (edge) compute for selecting (sub-optimal) target-tracking maneuvers exhibiting non-myopic cooperative fleet behavior. The optimization problem explicitly incorporates semantic information defining target occlusions from a world model. To illustrate the efficacy of our approach, a random occlusion forest environment is simulated. SMA-NBO is compared to other baseline approaches. The simulation results show SMA-NBO 1) maintains tracking performance and reduces the computational cost by replacing the calculation of the expected target trajectory with a single sample trajectory based on maximum a posteriori estimation; 2) generates cooperative fleet decision by sequentially optimizing single-agent policy with efficient usage of other agents' policy of intent; 3) aptly incorporates the multiple weighted trace penalty (MWTP) HECTG, which improves tracking performance with a computationally efficient heuristic.",
        "published": "2022-03-03T03:48:47Z",
        "link": "http://arxiv.org/abs/2203.01507v1",
        "categories": [
            "cs.MA",
            "cs.RO",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Fail-Safe Adversarial Generative Imitation Learning",
        "authors": [
            "Philipp Geiger",
            "Christoph-Nikolas Straehle"
        ],
        "summary": "For flexible yet safe imitation learning (IL), we propose theory and a modular method, with a safety layer that enables a closed-form probability density/gradient of the safe generative continuous policy, end-to-end generative adversarial training, and worst-case safety guarantees. The safety layer maps all actions into a set of safe actions, and uses the change-of-variables formula plus additivity of measures for the density. The set of safe actions is inferred by first checking safety of a finite sample of actions via adversarial reachability analysis of fallback maneuvers, and then concluding on the safety of these actions' neighborhoods using, e.g., Lipschitz continuity. We provide theoretical analysis showing the robustness advantage of using the safety layer already during training (imitation error linear in the horizon) compared to only using it at test time (up to quadratic error). In an experiment on real-world driver interaction data, we empirically demonstrate tractability, safety and imitation performance of our approach.",
        "published": "2022-03-03T13:03:06Z",
        "link": "http://arxiv.org/abs/2203.01696v2",
        "categories": [
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Social Opinion Formation and Decision Making Under Communication Trends",
        "authors": [
            "Mert Kayaalp",
            "Virginia Bordignon",
            "Ali H. Sayed"
        ],
        "summary": "This work studies the learning process over social networks under partial and random information sharing. In traditional social learning models, agents exchange full belief information with each other while trying to infer the true state of nature. We study the case where agents share information about only one hypothesis, namely, the trending topic, which can be randomly changing at every iteration. We show that agents can learn the true hypothesis even if they do not discuss it, at rates comparable to traditional social learning. We also show that using one's own belief as a prior for estimating the neighbors' non-transmitted beliefs might create opinion clusters that prevent learning with full confidence. This phenomenon occurs when a single hypothesis corresponding to the truth is exchanged exclusively during all times. Such a practice, however, avoids the complete rejection of the truth under any information exchange procedure -- something that could happen if priors were uniform.",
        "published": "2022-03-04T17:52:14Z",
        "link": "http://arxiv.org/abs/2203.02466v3",
        "categories": [
            "eess.SP",
            "cs.MA",
            "cs.SI"
        ]
    },
    {
        "title": "AutoDIME: Automatic Design of Interesting Multi-Agent Environments",
        "authors": [
            "Ingmar Kanitscheider",
            "Harri Edwards"
        ],
        "summary": "Designing a distribution of environments in which RL agents can learn interesting and useful skills is a challenging and poorly understood task, for multi-agent environments the difficulties are only exacerbated. One approach is to train a second RL agent, called a teacher, who samples environments that are conducive for the learning of student agents. However, most previous proposals for teacher rewards do not generalize straightforwardly to the multi-agent setting. We examine a set of intrinsic teacher rewards derived from prediction problems that can be applied in multi-agent settings and evaluate them in Mujoco tasks such as multi-agent Hide and Seek as well as a diagnostic single-agent maze task. Of the intrinsic rewards considered we found value disagreement to be most consistent across tasks, leading to faster and more reliable emergence of advanced skills in Hide and Seek and the maze task. Another candidate intrinsic reward considered, value prediction error, also worked well in Hide and Seek but was susceptible to noisy-TV style distractions in stochastic environments. Policy disagreement performed well in the maze task but did not speed up learning in Hide and Seek. Our results suggest that intrinsic teacher rewards, and in particular value disagreement, are a promising approach for automating both single and multi-agent environment design.",
        "published": "2022-03-04T18:25:33Z",
        "link": "http://arxiv.org/abs/2203.02481v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Machine Learning Simulates Agent-Based Model Towards Policy",
        "authors": [
            "Bernardo Alves Furtado",
            "Gustavo Onofre Andreão"
        ],
        "summary": "Public Policies are not intrinsically positive or negative. Rather, policies provide varying levels of effects across different recipients. Methodologically, computational modeling enables the application of multiple influences on empirical data, thus allowing for heterogeneous response to policies. We use a random forest machine learning algorithm to emulate an agent-based model (ABM) and evaluate competing policies across 46 Metropolitan Regions (MRs) in Brazil. In doing so, we use input parameters and output indicators of 11,076 actual simulation runs and one million emulated runs. As a result, we obtain the optimal (and non-optimal) performance of each region over the policies. Optimum is defined as a combination of GDP production and the Gini coefficient inequality indicator for the full ensemble of Metropolitan Regions. Results suggest that MRs already have embedded structures that favor optimal or non-optimal results, but they also illustrate which policy is more beneficial to each place. In addition to providing MR-specific policies' results, the use of machine learning to simulate an ABM reduces the computational burden, whereas allowing for a much larger variation among model parameters. The coherence of results within the context of larger uncertainty--vis-\\`a-vis those of the original ABM--reinforces robustness of the model. At the same time the exercise indicates which parameters should policymakers intervene on, in order to work towards precise policy optimal instruments.",
        "published": "2022-03-04T21:19:11Z",
        "link": "http://arxiv.org/abs/2203.02576v2",
        "categories": [
            "cs.MA",
            "cs.LG",
            "econ.GN",
            "q-fin.EC"
        ]
    },
    {
        "title": "SwarmUS: An open hardware and software on-board platform for swarm   robotics development",
        "authors": [
            "Étienne Villemure",
            "Philippe Arsenault",
            "Gabriel Lessard",
            "Thierry Constantin",
            "Hubert Dubé",
            "Louis-Daniel Gaulin",
            "Xavier Groleau",
            "Samuel Laperrière",
            "Charles Quesnel",
            "François Ferland"
        ],
        "summary": "Real life implementations of distributed swarm robotics are rare. The standardization of a general purpose swarm robotics platform could greatly accelerate swarm robotics towards real life implementations. The SwarmUS platform is an open-source hardware and software on-board embedded system designed to be added onto existing robots while providing them with swarm features, thus proposing a new take on the platform standardization problem. These features include a distributed relative localization system based on Ultra-Wideband, a local communication system based on Wi-Fi and a distributed coordination system based on the Buzz programming language between robots connected within a SwarmUS platform. Additionally, a human-swarm interaction mobile application and an emulation of the platform in the Robot Operating System (ROS) is presented. Finally, an implementation of the system was realized and tested on two types of robots : a TurtleBot3 Burger and two Pioneer 2DX.",
        "published": "2022-03-05T02:20:18Z",
        "link": "http://arxiv.org/abs/2203.02643v1",
        "categories": [
            "cs.RO",
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "C.3; J.7; I.2.9; C.2.4; B.1.5"
        ]
    },
    {
        "title": "Recursive Reasoning Graph for Multi-Agent Reinforcement Learning",
        "authors": [
            "Xiaobai Ma",
            "David Isele",
            "Jayesh K. Gupta",
            "Kikuo Fujimura",
            "Mykel J. Kochenderfer"
        ],
        "summary": "Multi-agent reinforcement learning (MARL) provides an efficient way for simultaneously learning policies for multiple agents interacting with each other. However, in scenarios requiring complex interactions, existing algorithms can suffer from an inability to accurately anticipate the influence of self-actions on other agents. Incorporating an ability to reason about other agents' potential responses can allow an agent to formulate more effective strategies. This paper adopts a recursive reasoning model in a centralized-training-decentralized-execution framework to help learning agents better cooperate with or compete against others. The proposed algorithm, referred to as the Recursive Reasoning Graph (R2G), shows state-of-the-art performance on multiple multi-agent particle and robotics games.",
        "published": "2022-03-06T00:57:50Z",
        "link": "http://arxiv.org/abs/2203.02844v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Fully Decentralized, Scalable Gaussian Processes for Multi-Agent   Federated Learning",
        "authors": [
            "George P. Kontoudis",
            "Daniel J. Stilwell"
        ],
        "summary": "In this paper, we propose decentralized and scalable algorithms for Gaussian process (GP) training and prediction in multi-agent systems. To decentralize the implementation of GP training optimization algorithms, we employ the alternating direction method of multipliers (ADMM). A closed-form solution of the decentralized proximal ADMM is provided for the case of GP hyper-parameter training with maximum likelihood estimation. Multiple aggregation techniques for GP prediction are decentralized with the use of iterative and consensus methods. In addition, we propose a covariance-based nearest neighbor selection strategy that enables a subset of agents to perform predictions. The efficacy of the proposed methods is illustrated with numerical experiments on synthetic and real data.",
        "published": "2022-03-06T02:54:13Z",
        "link": "http://arxiv.org/abs/2203.02865v1",
        "categories": [
            "stat.ML",
            "cs.LG",
            "cs.MA",
            "cs.RO",
            "math.OC"
        ]
    },
    {
        "title": "Watch from sky: machine-learning-based multi-UAV network for predictive   police surveillance",
        "authors": [
            "Ryusei Sugano",
            "Ryoichi Shinkuma",
            "Takayuki Nishio",
            "Sohei Itahara",
            "Narayan B. Mandayam"
        ],
        "summary": "This paper presents the watch-from-sky framework, where multiple unmanned aerial vehicles (UAVs) play four roles, i.e., sensing, data forwarding, computing, and patrolling, for predictive police surveillance. Our framework is promising for crime deterrence because UAVs are useful for collecting and distributing data and have high mobility. Our framework relies on machine learning (ML) technology for controlling and dispatching UAVs and predicting crimes. This paper compares the conceptual model of our framework against the literature. It also reports a simulation of UAV dispatching using reinforcement learning and distributed ML inference over a lossy UAV network.",
        "published": "2022-03-06T07:21:05Z",
        "link": "http://arxiv.org/abs/2203.02892v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "cs.NI"
        ]
    },
    {
        "title": "Depthwise Convolution for Multi-Agent Communication with Enhanced   Mean-Field Approximation",
        "authors": [
            "Donghan Xie",
            "Zhi Wang",
            "Chunlin Chen",
            "Daoyi Dong"
        ],
        "summary": "Multi-agent settings remain a fundamental challenge in the reinforcement learning (RL) domain due to the partial observability and the lack of accurate real-time interactions across agents. In this paper, we propose a new method based on local communication learning to tackle the multi-agent RL (MARL) challenge within a large number of agents coexisting. First, we design a new communication protocol that exploits the ability of depthwise convolution to efficiently extract local relations and learn local communication between neighboring agents. To facilitate multi-agent coordination, we explicitly learn the effect of joint actions by taking the policies of neighboring agents as inputs. Second, we introduce the mean-field approximation into our method to reduce the scale of agent interactions. To more effectively coordinate behaviors of neighboring agents, we enhance the mean-field approximation by a supervised policy rectification network (PRN) for rectifying real-time agent interactions and by a learnable compensation term for correcting the approximation bias. The proposed method enables efficient coordination as well as outperforms several baseline approaches on the adaptive traffic signal control (ATSC) task and the StarCraft II multi-agent challenge (SMAC).",
        "published": "2022-03-06T07:42:43Z",
        "link": "http://arxiv.org/abs/2203.02896v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Hierarchically Structured Scheduling and Execution of Tasks in a   Multi-Agent Environment",
        "authors": [
            "Diogo S. Carvalho",
            "Biswa Sengupta"
        ],
        "summary": "In a warehouse environment, tasks appear dynamically. Consequently, a task management system that matches them with the workforce too early (e.g., weeks in advance) is necessarily sub-optimal. Also, the rapidly increasing size of the action space of such a system consists of a significant problem for traditional schedulers. Reinforcement learning, however, is suited to deal with issues requiring making sequential decisions towards a long-term, often remote, goal. In this work, we set ourselves on a problem that presents itself with a hierarchical structure: the task-scheduling, by a centralised agent, in a dynamic warehouse multi-agent environment and the execution of one such schedule, by decentralised agents with only partial observability thereof. We propose to use deep reinforcement learning to solve both the high-level scheduling problem and the low-level multi-agent problem of schedule execution. Finally, we also conceive the case where centralisation is impossible at test time and workers must learn how to cooperate in executing the tasks in an environment with no schedule and only partial observability.",
        "published": "2022-03-06T18:11:34Z",
        "link": "http://arxiv.org/abs/2203.03021v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Diversifying Agent's Behaviors in Interactive Decision Models",
        "authors": [
            "Yinghui Pan",
            "Hanyi Zhang",
            "Yifeng Zeng",
            "Biyang Ma",
            "Jing Tang",
            "Zhong Ming"
        ],
        "summary": "Modelling other agents' behaviors plays an important role in decision models for interactions among multiple agents. To optimise its own decisions, a subject agent needs to model what other agents act simultaneously in an uncertain environment. However, modelling insufficiency occurs when the agents are competitive and the subject agent can not get full knowledge about other agents. Even when the agents are collaborative, they may not share their true behaviors due to their privacy concerns. In this article, we investigate into diversifying behaviors of other agents in the subject agent's decision model prior to their interactions. Starting with prior knowledge about other agents' behaviors, we use a linear reduction technique to extract representative behavioral features from the known behaviors. We subsequently generate their new behaviors by expanding the features and propose two diversity measurements to select top-K behaviors. We demonstrate the performance of the new techniques in two well-studied problem domains. This research will contribute to intelligent systems dealing with unknown unknowns in an open artificial intelligence world.",
        "published": "2022-03-06T23:05:00Z",
        "link": "http://arxiv.org/abs/2203.03068v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Automatic Calibration Framework of Agent-Based Models for Dynamic and   Heterogeneous Parameters",
        "authors": [
            "Dongjun Kim",
            "Tae-Sub Yun",
            "Il-Chul Moon",
            "Jang Won Bae"
        ],
        "summary": "Agent-based models (ABMs) highlight the importance of simulation validation, such as qualitative face validation and quantitative empirical validation. In particular, we focused on quantitative validation by adjusting simulation input parameters of the ABM. This study introduces an automatic calibration framework that combines the suggested dynamic and heterogeneous calibration methods. Specifically, the dynamic calibration fits the simulation results to the real-world data by automatically capturing suitable simulation time to adjust the simulation parameters. Meanwhile, the heterogeneous calibration reduces the distributional discrepancy between individuals in the simulation and the real world by adjusting agent related parameters cluster-wisely.",
        "published": "2022-03-07T05:45:16Z",
        "link": "http://arxiv.org/abs/2203.03147v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Efficient Policy Generation in Multi-Agent Systems via Hypergraph Neural   Network",
        "authors": [
            "Bin Zhang",
            "Yunpeng Bai",
            "Zhiwei Xu",
            "Dapeng Li",
            "Guoliang Fan"
        ],
        "summary": "The application of deep reinforcement learning in multi-agent systems introduces extra challenges. In a scenario with numerous agents, one of the most important concerns currently being addressed is how to develop sufficient collaboration between diverse agents. To address this problem, we consider the form of agent interaction based on neighborhood and propose a multi-agent reinforcement learning (MARL) algorithm based on the actor-critic method, which can adaptively construct the hypergraph structure representing the agent interaction and further implement effective information extraction and representation learning through hypergraph convolution networks, leading to effective cooperation. Based on different hypergraph generation methods, we present two variants: Actor Hypergraph Convolutional Critic Network (HGAC) and Actor Attention Hypergraph Critic Network (ATT-HGAC). Experiments with different settings demonstrate the advantages of our approach over other existing methods.",
        "published": "2022-03-07T10:34:40Z",
        "link": "http://arxiv.org/abs/2203.03265v2",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Reliably Re-Acting to Partner's Actions with the Social Intrinsic   Motivation of Transfer Empowerment",
        "authors": [
            "Tessa van der Heiden",
            "Herke van Hoof",
            "Efstratios Gavves",
            "Christoph Salge"
        ],
        "summary": "We consider multi-agent reinforcement learning (MARL) for cooperative communication and coordination tasks. MARL agents can be brittle because they can overfit their training partners' policies. This overfitting can produce agents that adopt policies that act under the expectation that other agents will act in a certain way rather than react to their actions. Our objective is to bias the learning process towards finding reactive strategies towards other agents' behaviors. Our method, transfer empowerment, measures the potential influence between agents' actions. Results from three simulated cooperation scenarios support our hypothesis that transfer empowerment improves MARL performance. We discuss how transfer empowerment could be a useful principle to guide multi-agent coordination by ensuring reactiveness to one's partner.",
        "published": "2022-03-07T13:03:35Z",
        "link": "http://arxiv.org/abs/2203.03355v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Reinforcement Learning for Location-Aware Scheduling",
        "authors": [
            "Stelios Stavroulakis",
            "Biswa Sengupta"
        ],
        "summary": "Recent techniques in dynamical scheduling and resource management have found applications in warehouse environments due to their ability to organize and prioritize tasks in a higher temporal resolution. The rise of deep reinforcement learning, as a learning paradigm, has enabled decentralized agent populations to discover complex coordination strategies. However, training multiple agents simultaneously introduce many obstacles in training as observation and action spaces become exponentially large. In our work, we experimentally quantify how various aspects of the warehouse environment (e.g., floor plan complexity, information about agents' live location, level of task parallelizability) affect performance and execution priority. To achieve efficiency, we propose a compact representation of the state and action space for location-aware multi-agent systems, wherein each agent has knowledge of only self and task coordinates, hence only partial observability of the underlying Markov Decision Process. Finally, we show how agents trained in certain environments maintain performance in completely unseen settings and also correlate performance degradation with floor plan geometry.",
        "published": "2022-03-07T15:51:00Z",
        "link": "http://arxiv.org/abs/2203.03480v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Influencing Long-Term Behavior in Multiagent Reinforcement Learning",
        "authors": [
            "Dong-Ki Kim",
            "Matthew Riemer",
            "Miao Liu",
            "Jakob N. Foerster",
            "Michael Everett",
            "Chuangchuang Sun",
            "Gerald Tesauro",
            "Jonathan P. How"
        ],
        "summary": "The main challenge of multiagent reinforcement learning is the difficulty of learning useful policies in the presence of other simultaneously learning agents whose changing behaviors jointly affect the environment's transition and reward dynamics. An effective approach that has recently emerged for addressing this non-stationarity is for each agent to anticipate the learning of other agents and influence the evolution of future policies towards desirable behavior for its own benefit. Unfortunately, previous approaches for achieving this suffer from myopic evaluation, considering only a finite number of policy updates. As such, these methods can only influence transient future policies rather than achieving the promise of scalable equilibrium selection approaches that influence the behavior at convergence. In this paper, we propose a principled framework for considering the limiting policies of other agents as time approaches infinity. Specifically, we develop a new optimization objective that maximizes each agent's average reward by directly accounting for the impact of its behavior on the limiting set of policies that other agents will converge to. Our paper characterizes desirable solution concepts within this problem setting and provides practical approaches for optimizing over possible outcomes. As a result of our farsighted objective, we demonstrate better long-term performance than state-of-the-art baselines across a suite of diverse multiagent benchmark domains.",
        "published": "2022-03-07T17:32:35Z",
        "link": "http://arxiv.org/abs/2203.03535v4",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Low-Loss Subspace Compression for Clean Gains against Multi-Agent   Backdoor Attacks",
        "authors": [
            "Siddhartha Datta",
            "Nigel Shadbolt"
        ],
        "summary": "Recent exploration of the multi-agent backdoor attack demonstrated the backfiring effect, a natural defense against backdoor attacks where backdoored inputs are randomly classified. This yields a side-effect of low accuracy w.r.t. clean labels, which motivates this paper's work on the construction of multi-agent backdoor defenses that maximize accuracy w.r.t. clean labels and minimize that of poison labels. Founded upon agent dynamics and low-loss subspace construction, we contribute three defenses that yield improved multi-agent backdoor robustness.",
        "published": "2022-03-07T20:30:44Z",
        "link": "http://arxiv.org/abs/2203.03692v2",
        "categories": [
            "cs.LG",
            "cs.CR",
            "cs.MA"
        ]
    },
    {
        "title": "Class Fairness in Online Matching",
        "authors": [
            "Hadi Hosseini",
            "Zhiyi Huang",
            "Ayumi Igarashi",
            "Nisarg Shah"
        ],
        "summary": "In the classical version of online bipartite matching, there is a given set of offline vertices (aka agents) and another set of vertices (aka items) that arrive online. When each item arrives, its incident edges -- the agents who like the item -- are revealed and the algorithm must irrevocably match the item to such agents. We initiate the study of class fairness in this setting, where agents are partitioned into a set of classes and the matching is required to be fair with respect to the classes. We adopt popular fairness notions from the fair division literature such as envy-freeness (up to one item), proportionality, and maximin share fairness to our setting. Our class versions of these notions demand that all classes, regardless of their sizes, receive a fair treatment. We study deterministic and randomized algorithms for matching indivisible items (leading to integral matchings) and for matching divisible items (leading to fractional matchings). We design and analyze three novel algorithms. For matching indivisible items, we propose an adaptive-priority-based algorithm, MATCH-AND-SHIFT, prove that it achieves 1/2-approximation of both class envy-freeness up to one item and class maximin share fairness, and show that each guarantee is tight. For matching divisible items, we design a water-filling-based algorithm, EQUAL-FILLING, that achieves (1-1/e)-approximation of class envy-freeness and class proportionality; we prove (1-1/e) to be tight for class proportionality and establish a 3/4 upper bound on class envy-freeness. Finally, we build upon EQUAL-FILLING to design a randomized algorithm for matching indivisible items, EQAUL-FILLING-OCS, which achieves 0.593-approximation of class proportionality. The algorithm and its analysis crucially leverage the recently introduced technique of online correlated selection (OCS) [Fahrbach et al., 2020].",
        "published": "2022-03-07T22:26:11Z",
        "link": "http://arxiv.org/abs/2203.03751v1",
        "categories": [
            "cs.GT",
            "cs.MA",
            "econ.TH",
            "I.2.11"
        ]
    },
    {
        "title": "Mini-batch stochastic three-operator splitting for distributed   optimization",
        "authors": [
            "Barbara Franci",
            "Mathias Staudigl"
        ],
        "summary": "We consider a network of agents, each with its own private cost consisting of a sum of two possibly nonsmooth convex functions, one of which is composed with a linear operator. At every iteration each agent performs local calculations and can only communicate with its neighbors. The challenging aspect of our study is that the smooth part of the private cost function is given as an expected value and agents only have access to this part of the problem formulation via a heavy-tailed stochastic oracle. To tackle such sampling-based optimization problems, we propose a stochastic extension of the triangular pre-conditioned primal-dual algorithm. We demonstrate almost sure convergence of the scheme and validate the performance of the method via numerical experiments.",
        "published": "2022-03-08T11:25:37Z",
        "link": "http://arxiv.org/abs/2203.04020v1",
        "categories": [
            "math.OC",
            "cs.MA"
        ]
    },
    {
        "title": "Towards Safe and Efficient Swarm-Human Collaboration: A Hierarchical   Multi-Agent Pickup and Delivery framework",
        "authors": [
            "Xin Gong",
            "Tieniu Wang",
            "Yukang Cui",
            "Tingwen Huang"
        ],
        "summary": "The multi-Agent Pickup and Delivery (MAPD) problem is crucial in the realm of Intelligent Storage Systems (ISSs), where multiple robots are assigned with time-varying, heterogeneous, and potentially uncertain tasks. When it comes to Human-Swarm Hybrid System ((HS)$_2$), robots and human workers will accomplish the MAPD tasks in collaboration. Herein, we propose a Human-Swarm Hybrid System Pickup and Delivery ((HS)$_2$PD) framework, which is predominant in future ISSs. A two-layer decision framework based on the prediction horizon window is established in light of the unpredictability of human behavior and the dynamic changes of tasks. The first layer is a two-level programming problem to solve the problems of mode assignment and TA. The second layer is devoted to the exact path of each agent via solving mixed-integer programming (MIP) problems. An integrated algorithm for the (HS)$_2$PD problem is summarized. The practicality and validity of the above algorithm are illustrated via a numerical simulation example towards (HS)$_2$PD tasks.",
        "published": "2022-03-08T12:44:45Z",
        "link": "http://arxiv.org/abs/2203.04052v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Multi-Agent Broad Reinforcement Learning for Intelligent Traffic Light   Control",
        "authors": [
            "Ruijie Zhu",
            "Lulu Li",
            "Shuning Wu",
            "Pei Lv",
            "Yafai Li",
            "Mingliang Xu"
        ],
        "summary": "Intelligent Traffic Light Control System (ITLCS) is a typical Multi-Agent System (MAS), which comprises multiple roads and traffic lights.Constructing a model of MAS for ITLCS is the basis to alleviate traffic congestion. Existing approaches of MAS are largely based on Multi-Agent Deep Reinforcement Learning (MADRL). Although the Deep Neural Network (DNN) of MABRL is effective, the training time is long, and the parameters are difficult to trace. Recently, Broad Learning Systems (BLS) provided a selective way for learning in the deep neural networks by a flat network. Moreover, Broad Reinforcement Learning (BRL) extends BLS in Single Agent Deep Reinforcement Learning (SADRL) problem with promising results. However, BRL does not focus on the intricate structures and interaction of agents. Motivated by the feature of MADRL and the issue of BRL, we propose a Multi-Agent Broad Reinforcement Learning (MABRL) framework to explore the function of BLS in MAS. Firstly, unlike most existing MADRL approaches, which use a series of deep neural networks structures, we model each agent with broad networks. Then, we introduce a dynamic self-cycling interaction mechanism to confirm the \"3W\" information: When to interact, Which agents need to consider, What information to transmit. Finally, we do the experiments based on the intelligent traffic light control scenario. We compare the MABRL approach with six different approaches, and experimental results on three datasets verify the effectiveness of MABRL.",
        "published": "2022-03-08T14:04:09Z",
        "link": "http://arxiv.org/abs/2203.04310v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Cooperative Trajectory Planning in Uncertain Environments with Monte   Carlo Tree Search and Risk Metrics",
        "authors": [
            "Philipp Stegmaier",
            "Karl Kurzer",
            "J. Marius Zöllner"
        ],
        "summary": "Automated vehicles require the ability to cooperate with humans for smooth integration into today's traffic. While the concept of cooperation is well known, developing a robust and efficient cooperative trajectory planning method is still a challenge. One aspect of this challenge is the uncertainty surrounding the state of the environment due to limited sensor accuracy. This uncertainty can be represented by a Partially Observable Markov Decision Process. Our work addresses this problem by extending an existing cooperative trajectory planning approach based on Monte Carlo Tree Search for continuous action spaces. It does so by explicitly modeling uncertainties in the form of a root belief state, from which start states for trees are sampled. After the trees have been constructed with Monte Carlo Tree Search, their results are aggregated into return distributions using kernel regression. We apply two risk metrics for the final selection, namely a Lower Confidence Bound and a Conditional Value at Risk. It can be demonstrated that the integration of risk metrics in the final selection policy consistently outperforms a baseline in uncertain environments, generating considerably safer trajectories.",
        "published": "2022-03-09T00:14:41Z",
        "link": "http://arxiv.org/abs/2203.04452v3",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.RO"
        ]
    },
    {
        "title": "Multi-Agent Active Search using Detection and Location Uncertainty",
        "authors": [
            "Arundhati Banerjee",
            "Ramina Ghods",
            "Jeff Schneider"
        ],
        "summary": "Active search, in applications like environment monitoring or disaster response missions, involves autonomous agents detecting targets in a search space using decision making algorithms that adapt to the history of their observations. Active search algorithms must contend with two types of uncertainty: detection uncertainty and location uncertainty. The more common approach in robotics is to focus on location uncertainty and remove detection uncertainty by thresholding the detection probability to zero or one. In contrast, it is common in the sparse signal processing literature to assume the target location is accurate and instead focus on the uncertainty of its detection. In this work, we first propose an inference method to jointly handle both target detection and location uncertainty. We then build a decision making algorithm on this inference method that uses Thompson sampling to enable decentralized multi-agent active search. We perform simulation experiments to show that our algorithms outperform competing baselines that only account for either target detection or location uncertainty. We finally demonstrate the real world transferability of our algorithms using a realistic simulation environment we created on the Unreal Engine 4 platform with an AirSim plugin.",
        "published": "2022-03-09T04:53:37Z",
        "link": "http://arxiv.org/abs/2203.04524v2",
        "categories": [
            "cs.RO",
            "cs.LG",
            "cs.MA",
            "I.2.9; I.2.11"
        ]
    },
    {
        "title": "Multi-Objective Multi-Agent Planning for Discovering and Tracking   Multiple Mobile Objects",
        "authors": [
            "Hoa Van Nguyen",
            "Ba-Ngu Vo",
            "Ba-Tuong Vo",
            "Hamid Rezatofighi",
            "Damith C. Ranasinghe"
        ],
        "summary": "We consider the online planning problem for a team of agents to discover and track an unknown and time-varying number of moving objects from onboard sensor measurements with uncertain measurement-object origins. Since the onboard sensors have limited field-of-views, the usual planning strategy based solely on either tracking detected objects or discovering unseen objects is inadequate. To address this, we formulate a new information-based multi-objective multi-agent control problem, cast as a partially observable Markov decision process (POMDP). The resulting multi-agent planning problem is exponentially complex due to the unknown data association between objects and multi-sensor measurements; hence, computing an optimal control action is intractable. We prove that the proposed multi-objective value function is a monotone submodular set function, which admits low-cost suboptimal solutions via greedy search with a tight optimality bound. The resulting planning algorithm has a linear complexity in the number of objects and measurements across the sensors, and quadratic in the number of agents. We demonstrate the proposed solution via a series of numerical experiments with a real-world dataset.",
        "published": "2022-03-09T07:02:27Z",
        "link": "http://arxiv.org/abs/2203.04551v4",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Multi-robot Cooperative Pursuit via Potential Field-Enhanced   Reinforcement Learning",
        "authors": [
            "Zheng Zhang",
            "Xiaohan Wang",
            "Qingrui Zhang",
            "Tianjiang Hu"
        ],
        "summary": "It is of great challenge, though promising, to coordinate collective robots for hunting an evader in a decentralized manner purely in light of local observations. In this paper, this challenge is addressed by a novel hybrid cooperative pursuit algorithm that combines reinforcement learning with the artificial potential field method. In the proposed algorithm, decentralized deep reinforcement learning is employed to learn cooperative pursuit policies that are adaptive to dynamic environments. The artificial potential field method is integrated into the learning process as predefined rules to improve the data efficiency and generalization ability. It is shown by numerical simulations that the proposed hybrid design outperforms the pursuit policies either learned from vanilla reinforcement learning or designed by the potential field method. Furthermore, experiments are conducted by transferring the learned pursuit policies into real-world mobile robots. Experimental results demonstrate the feasibility and potential of the proposed algorithm in learning multiple cooperative pursuit strategies.",
        "published": "2022-03-09T13:22:23Z",
        "link": "http://arxiv.org/abs/2203.04700v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Organisations (de-)centralised to a greater or lesser degree for   allocating cities in two Multiple Travelling Salesmen Problems",
        "authors": [
            "Thierry Moyaux"
        ],
        "summary": "Decisions in organisations may be made either by a Central Authority (CA), e.g., in a hierarchy, or by the agents in a decentralised way, e.g., in a heterarchy. Since both kinds of organisations have their advantages (e.g., optimality for centralised organisations and reactivity for decentralised ones), our goal is ultimately to understand when and how to use each of them. Our previous work proposed a variant of the Multiple Travelling Salesmen Problem, which we now call MTSPs . We use the subscript \"s\" to refer to salesmen's selfishness when they minimise their individual route length. If, on the contrary, they are assumed to be benevolent, we add subscript \"b\" and thus the term MTSPb to refer to the traditional MTSP in which the salesmen minimise the total route length. This article shows how to obtain such benevolent agents by slightly modifying selfish agents. We can then compare organisations which are (de-)centralised to a greater or lesser degree, which enables us to carry out the allocation of cities in the MTSPb . The first experiment shows that the relative efficiency (ranking) of the organisations differs between MTSPb and MTSPs . Since reactivity fosters decentralisation, the second experiment gradually reduces the time taken for it to impact this ranking. Both experiments show that pure centralisation is either the best or the worst option, and that the zone between the two situations is very narrow.",
        "published": "2022-03-10T07:53:37Z",
        "link": "http://arxiv.org/abs/2203.05219v1",
        "categories": [
            "cs.GT",
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "Breaking the Curse of Dimensionality in Multiagent State Space: A   Unified Agent Permutation Framework",
        "authors": [
            "Xiaotian Hao",
            "Hangyu Mao",
            "Weixun Wang",
            "Yaodong Yang",
            "Dong Li",
            "Yan Zheng",
            "Zhen Wang",
            "Jianye Hao"
        ],
        "summary": "The state space in Multiagent Reinforcement Learning (MARL) grows exponentially with the agent number. Such a curse of dimensionality results in poor scalability and low sample efficiency, inhibiting MARL for decades. To break this curse, we propose a unified agent permutation framework that exploits the permutation invariance (PI) and permutation equivariance (PE) inductive biases to reduce the multiagent state space. Our insight is that permuting the order of entities in the factored multiagent state space does not change the information. Specifically, we propose two novel implementations: a Dynamic Permutation Network (DPN) and a Hyper Policy Network (HPN). The core idea is to build separate entity-wise PI input and PE output network modules to connect the entity-factored state space and action space in an end-to-end way. DPN achieves such connections by two separate module selection networks, which consistently assign the same input module to the same input entity (guarantee PI) and assign the same output module to the same entity-related output (guarantee PE). To enhance the representation capability, HPN replaces the module selection networks of DPN with hypernetworks to directly generate the corresponding module weights. Extensive experiments in SMAC, Google Research Football and MPE validate that the proposed methods significantly boost the performance and the learning efficiency of existing MARL algorithms. Remarkably, in SMAC, we achieve 100% win rates in almost all hard and super-hard scenarios (never achieved before).",
        "published": "2022-03-10T11:00:53Z",
        "link": "http://arxiv.org/abs/2203.05285v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Linear Quadratic Mean-Field Games with Communication Constraints",
        "authors": [
            "Shubham Aggarwal",
            "Muhammad Aneeq uz Zaman",
            "Tamer Başar"
        ],
        "summary": "In this paper, we study a large population game with heterogeneous dynamics and cost functions solving a consensus problem. Moreover, the agents have communication constraints which appear as: (1) an Additive-White Gaussian Noise (AWGN) channel, and (2) asynchronous data transmission via a fixed scheduling policy. Since the complexity of solving the game increases with the number of agents, we use the Mean-Field Game paradigm to solve it. Under standard assumptions on the information structure of the agents, we prove that the control of the agent in the MFG setting is free of the dual effect. This allows us to obtain an equilibrium control policy for the generic agent, which is a function of only the local observation of the agent. Furthermore, the equilibrium mean-field trajectory is shown to follow linear dynamics, hence making it computable. We show that in the finite population game, the equilibrium control policy prescribed by the MFG analysis constitutes an $\\epsilon$-Nash equilibrium, where $\\epsilon$ tends to zero as the number of agents goes to infinity. The paper is concluded with simulations demonstrating the performance of the equilibrium control policy.",
        "published": "2022-03-11T00:15:26Z",
        "link": "http://arxiv.org/abs/2203.05686v2",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY",
            "math.OC"
        ]
    },
    {
        "title": "Automatic Performance Estimation for Decentralized Optimization",
        "authors": [
            "Sebastien Colla",
            "Julien M. Hendrickx"
        ],
        "summary": "We present a methodology to automatically compute worst-case performance bounds for a large class of first-order decentralized optimization algorithms. These algorithms aim at minimizing the average of local functions that are distributed across a network of agents. They typically combine local computations and consensus steps. Our methodology is based on the approach of Performance Estimation Problem (PEP), which allows computing the worst-case performance and a worst-case instance of first-order optimization algorithms by solving an SDP. We propose two ways of representing consensus steps in PEPs, which allow writing and solving PEPs for decentralized optimization. The first formulation is exact but specific to a given averaging matrix. The second formulation is a relaxation but provides guarantees valid over an entire class of averaging matrices, characterized by their spectral range. This formulation often allows recovering a posteriori the worst possible averaging matrix for the given algorithm. We apply our methodology to three different decentralized methods. For each of them, we obtain numerically tight worst-case performance bounds that significantly improve on the existing ones, as well as insights about the parameters tuning and the worst communication networks.",
        "published": "2022-03-11T14:47:17Z",
        "link": "http://arxiv.org/abs/2203.05963v3",
        "categories": [
            "math.OC",
            "cs.MA"
        ]
    },
    {
        "title": "Online Graph Learning from Social Interactions",
        "authors": [
            "Valentina Shumovskaia",
            "Konstantinos Ntemos",
            "Stefan Vlaski",
            "Ali H. Sayed"
        ],
        "summary": "Social learning algorithms provide models for the formation of opinions over social networks resulting from local reasoning and peer-to-peer exchanges. Interactions occur over an underlying graph topology, which describes the flow of information and relative influence between pairs of agents. For a given graph topology, these algorithms allow for the prediction of formed opinions. In this work, we study the inverse problem. Given a social learning model and observations of the evolution of beliefs over time, we aim at identifying the underlying graph topology. The learned graph allows for the inference of pairwise influence between agents, the overall influence agents have over the behavior of the network, as well as the flow of information through the social network. The proposed algorithm is online in nature and can adapt dynamically to changes in the graph topology or the true hypothesis.",
        "published": "2022-03-11T15:26:33Z",
        "link": "http://arxiv.org/abs/2203.06007v1",
        "categories": [
            "eess.SP",
            "cs.MA"
        ]
    },
    {
        "title": "Concentration Network for Reinforcement Learning of Large-Scale   Multi-Agent Systems",
        "authors": [
            "Qingxu Fu",
            "Tenghai Qiu",
            "Jianqiang Yi",
            "Zhiqiang Pu",
            "Shiguang Wu"
        ],
        "summary": "When dealing with a series of imminent issues, humans can naturally concentrate on a subset of these concerning issues by prioritizing them according to their contributions to motivational indices, e.g., the probability of winning a game. This idea of concentration offers insights into reinforcement learning of sophisticated Large-scale Multi-Agent Systems (LMAS) participated by hundreds of agents. In such an LMAS, each agent receives a long series of entity observations at each step, which can overwhelm existing aggregation networks such as graph attention networks and cause inefficiency. In this paper, we propose a concentration network called ConcNet. First, ConcNet scores the observed entities considering several motivational indices, e.g., expected survival time and state value of the agents, and then ranks, prunes, and aggregates the encodings of observed entities to extract features. Second, distinct from the well-known attention mechanism, ConcNet has a unique motivational subnetwork to explicitly consider the motivational indices when scoring the observed entities. Furthermore, we present a concentration policy gradient architecture that can learn effective policies in LMAS from scratch. Extensive experiments demonstrate that the presented architecture has excellent scalability and flexibility, and significantly outperforms existing methods on LMAS benchmarks.",
        "published": "2022-03-12T11:45:11Z",
        "link": "http://arxiv.org/abs/2203.06416v2",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "A ROS Architecture for Personalised HRI with a Bartender Social Robot",
        "authors": [
            "Alessandra Rossi",
            "Maria Di Maro",
            "Antonio Origlia",
            "Agostino Palmiero",
            "Silvia Rossi"
        ],
        "summary": "BRILLO (Bartending Robot for Interactive Long-Lasting Operations) project has the overall goal of creating an autonomous robotic bartender that can interact with customers while accomplishing its bartending tasks. In such a scenario, people's novelty effect connected to the use of an attractive technology is destined to wear off and, consequently, it negatively affects the success of the service robotics application. For this reason, providing personalised natural interaction while accessing its services is of paramount importance for increasing users' engagement and, consequently, their loyalty. In this paper, we present the developed three-layers ROS architecture integrating a perception layer managing the processing of different social signals, a decision-making layer for handling multi-party interactions, and an execution layer controlling the behaviour of a complex robot composed of arms and a face. Finally, user modelling through a beliefs layer allows for personalised interaction.",
        "published": "2022-03-13T11:33:06Z",
        "link": "http://arxiv.org/abs/2203.06631v2",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Cluster Assignment in Multi-Agent Systems",
        "authors": [
            "Miel Sharf",
            "Daniel Zelazo"
        ],
        "summary": "We study cluster assignment in multi-agent networks. We consider homogeneous diffusive networks, and focus on design of the graph that ensures the system will converge to a prescribed cluster configuration, i.e., specifying the number of clusters and agents within each cluster. Leveraging recent results from cluster synthesis, we show that it is possible to design an oriented graph such that the action of the automorphism group of the graph has orbits of predetermined sizes, guaranteeing that the network will converge to the prescribed cluster configuration. We provide upper and lower bounds on the number of edges that are needed to construct these graphs along with a constructive approach for generating these graphs. We support our analysis with some numerical examples.",
        "published": "2022-03-13T12:10:46Z",
        "link": "http://arxiv.org/abs/2203.06642v1",
        "categories": [
            "eess.SY",
            "cs.DM",
            "cs.MA",
            "cs.SY",
            "math.CO",
            "math.OC"
        ]
    },
    {
        "title": "A smart electric bike for smart cities",
        "authors": [
            "Shaun Sweeney",
            "Robert Shorten",
            "David Timoney",
            "Giovanni Russo",
            "Francesco Pilla"
        ],
        "summary": "This is a Masters Thesis completed at University College Dublin, Ireland in 2017 which involved augmenting an off-the-shelf electric bike with sensors to enable new services to be delivered to cyclists in cities. The application of primary interest was to control the cyclist's ventilation rate based on the concentration of local air pollutants. Detailed modelling and system design is presented for our Cyberphysical system which consisted of a modified BTwin e-bike, Cycle Analyst sensors, the cyclist themselves, a Bluetooth connected smartphone and our algorithms. Control algorithms to regulate the proportion of power the cyclist provided as a proxy for their ventilation rate were proposed and validated in a basic way, which were later proven significantly further in Further Work (see IEEE Transactions on Intelligent Transportation Systems paper: https://ieeexplore.ieee.org/abstract/document/8357977). The basic idea was to provide more electrical assistance to cyclists in areas of high air pollution to reduce the cyclist ventilation rate and thereby the amount of air pollutants inhaled. This presents an interesting control challenge due to the human-in-the-loop characteristics and the potential for impactful real life applications. A background literature review is provided on energy as it relates to cycling and some other applications are also discussed. A link to a video which demonstrates the system is provided, and also to a blog published by IBM Research about the system.",
        "published": "2022-03-13T15:28:12Z",
        "link": "http://arxiv.org/abs/2203.06679v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "DIAS: A Domain-Independent Alife-Based Problem-Solving System",
        "authors": [
            "Babak Hodjat",
            "Hormoz Shahrzad",
            "Risto Miikkulainen"
        ],
        "summary": "A domain-independent problem-solving system based on principles of Artificial Life is introduced. In this system, DIAS, the input and output dimensions of the domain are laid out in a spatial medium. A population of actors, each seeing only part of this medium, solves problems collectively in it. The process is independent of the domain and can be implemented through different kinds of actors. Through a set of experiments on various problem domains, DIAS is shown able to solve problems with different dimensionality and complexity, to require no hyperparameter tuning for new problems, and to exhibit lifelong learning, i.e. adapt rapidly to run-time changes in the problem domain, and do it better than a standard non-collective approach. DIAS therefore demonstrates a role for Alife in building scalable, general, and adaptive problem-solving systems.",
        "published": "2022-03-14T04:53:26Z",
        "link": "http://arxiv.org/abs/2203.06855v2",
        "categories": [
            "cs.NE",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Optimal Aggregation Strategies for Social Learning over Graphs",
        "authors": [
            "Ping Hu",
            "Virginia Bordignon",
            "Stefan Vlaski",
            "Ali H. Sayed"
        ],
        "summary": "Adaptive social learning is a useful tool for studying distributed decision-making problems over graphs. This paper investigates the effect of combination policies on the performance of adaptive social learning strategies. Using large-deviation analysis, it first derives a bound on the steady-state error probability and characterizes the optimal selection for the Perron eigenvectors of the combination policies. It subsequently studies the effect of the combination policy on the transient behavior of the learning strategy by estimating the adaptation time in the low signal-to-noise ratio regime. In the process, it is discovered that, interestingly, the influence of the combination policy on the transient behavior is insignificant, and thus it is more critical to employ policies that enhance the steady-state performance. The theoretical conclusions are illustrated by means of computer simulations.",
        "published": "2022-03-14T13:01:54Z",
        "link": "http://arxiv.org/abs/2203.07065v2",
        "categories": [
            "eess.SP",
            "cs.IT",
            "cs.MA",
            "math.IT"
        ]
    },
    {
        "title": "The Multi-Agent Pickup and Delivery Problem: MAPF, MARL and Its   Warehouse Applications",
        "authors": [
            "Tim Tsz-Kit Lau",
            "Biswa Sengupta"
        ],
        "summary": "We study two state-of-the-art solutions to the multi-agent pickup and delivery (MAPD) problem based on different principles -- multi-agent path-finding (MAPF) and multi-agent reinforcement learning (MARL). Specifically, a recent MAPF algorithm called conflict-based search (CBS) and a current MARL algorithm called shared experience actor-critic (SEAC) are studied. While the performance of these algorithms is measured using quite different metrics in their separate lines of work, we aim to benchmark these two methods comprehensively in a simulated warehouse automation environment.",
        "published": "2022-03-14T13:23:35Z",
        "link": "http://arxiv.org/abs/2203.07092v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Conservative Filtering for Heterogeneous Decentralized Data Fusion in   Dynamic Robotic Systems",
        "authors": [
            "Ofer Dagan",
            "Nisar R. Ahmed"
        ],
        "summary": "This paper presents a method for Bayesian multi-robot peer-to-peer data fusion where any pair of autonomous robots hold non-identical, but overlapping parts of a global joint probability distribution, representing real world inference tasks (e.g., mapping, tracking). It is shown that in dynamic stochastic systems, filtering, which corresponds to marginalization of past variables, results in direct and hidden dependencies between variables not mutually monitored by the robots, which might lead to an overconfident fused estimate. The paper makes both theoretical and practical contributions by providing (i) a rigorous analysis of the origin of the dependencies and and (ii) a conservative filtering algorithm for heterogeneous data fusion in dynamic systems that can be integrated with existing fusion algorithms. This work uses factor graphs as an analysis tool and an inference engine. Each robot in the network maintains a local factor graph and communicates only relevant parts of it (a sub-graph) to its neighboring robot. We discuss the applicability to various multi-robot robotic applications and demonstrate the performance using a multi-robot multi-target tracking simulation, showing that the proposed algorithm produces conservative estimates at each robot.",
        "published": "2022-03-14T14:38:51Z",
        "link": "http://arxiv.org/abs/2203.07142v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Efficient Model-based Multi-agent Reinforcement Learning via Optimistic   Equilibrium Computation",
        "authors": [
            "Pier Giuseppe Sessa",
            "Maryam Kamgarpour",
            "Andreas Krause"
        ],
        "summary": "We consider model-based multi-agent reinforcement learning, where the environment transition model is unknown and can only be learned via expensive interactions with the environment. We propose H-MARL (Hallucinated Multi-Agent Reinforcement Learning), a novel sample-efficient algorithm that can efficiently balance exploration, i.e., learning about the environment, and exploitation, i.e., achieve good equilibrium performance in the underlying general-sum Markov game. H-MARL builds high-probability confidence intervals around the unknown transition model and sequentially updates them based on newly observed data. Using these, it constructs an optimistic hallucinated game for the agents for which equilibrium policies are computed at each round. We consider general statistical models (e.g., Gaussian processes, deep ensembles, etc.) and policy classes (e.g., deep neural networks), and theoretically analyze our approach by bounding the agents' dynamic regret. Moreover, we provide a convergence rate to the equilibria of the underlying Markov game. We demonstrate our approach experimentally on an autonomous driving simulation benchmark. H-MARL learns successful equilibrium policies after a few interactions with the environment and can significantly improve the performance compared to non-optimistic exploration methods.",
        "published": "2022-03-14T17:24:03Z",
        "link": "http://arxiv.org/abs/2203.07322v2",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Refined Hardness of Distance-Optimal Multi-Agent Path Finding",
        "authors": [
            "Tzvika Geft",
            "Dan Halperin"
        ],
        "summary": "We study the computational complexity of multi-agent path finding (MAPF). Given a graph $G$ and a set of agents, each having a start and target vertex, the goal is to find collision-free paths minimizing the total distance traveled. To better understand the source of difficulty of the problem, we aim to study the simplest and least constrained graph class for which it remains hard. To this end, we restrict $G$ to be a 2D grid, which is a ubiquitous abstraction, as it conveniently allows for modeling well-structured environments (e.g., warehouses). Previous hardness results considered highly constrained 2D grids having only one vertex unoccupied by an agent, while the most restricted hardness result that allowed multiple empty vertices was for (non-grid) planar graphs. We therefore refine previous results by simultaneously considering both 2D grids and multiple empty vertices. We show that even in this case distance-optimal MAPF remains NP-hard, which settles an open problem posed by Banfi et al. (2017). We present a reduction directly from 3-SAT using simple gadgets, making our proof arguably more informative than previous work in terms of potential progress towards positive results. Furthermore, our reduction is the first linear one for the case where $G$ is planar, appearing nearly four decades after the first related result. This allows us to go a step further and exploit the Exponential Time Hypothesis (ETH) to obtain an exponential lower bound for the running time of the problem. Finally, as a stepping stone towards our main results, we prove the NP-hardness of the monotone case, in which agents move one by one with no intermediate stops.",
        "published": "2022-03-14T18:23:22Z",
        "link": "http://arxiv.org/abs/2203.07416v1",
        "categories": [
            "cs.MA",
            "cs.CG",
            "cs.RO"
        ]
    },
    {
        "title": "Safe adaptation in multiagent competition",
        "authors": [
            "Macheng Shen",
            "Jonathan P. How"
        ],
        "summary": "Achieving the capability of adapting to ever-changing environments is a critical step towards building fully autonomous robots that operate safely in complicated scenarios. In multiagent competitive scenarios, agents may have to adapt to new opponents with previously unseen behaviors by learning from the interaction experiences between the ego-agent and the opponent. However, this adaptation is susceptible to opponent exploitation. As the ego-agent updates its own behavior to exploit the opponent, its own behavior could become more exploitable as a result of overfitting to this specific opponent's behavior. To overcome this difficulty, we developed a safe adaptation approach in which the ego-agent is trained against a regularized opponent model, which effectively avoids overfitting and consequently improves the robustness of the ego-agent's policy. We evaluated our approach in the Mujoco domain with two competing agents. The experiment results suggest that our approach effectively achieves both adaptation to the specific opponent that the ego-agent is interacting with and maintaining low exploitability to other possible opponent exploitation.",
        "published": "2022-03-14T23:53:59Z",
        "link": "http://arxiv.org/abs/2203.07562v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "An Introduction to Multi-Agent Reinforcement Learning and Review of its   Application to Autonomous Mobility",
        "authors": [
            "Lukas M. Schmidt",
            "Johanna Brosig",
            "Axel Plinge",
            "Bjoern M. Eskofier",
            "Christopher Mutschler"
        ],
        "summary": "Many scenarios in mobility and traffic involve multiple different agents that need to cooperate to find a joint solution. Recent advances in behavioral planning use Reinforcement Learning to find effective and performant behavior strategies. However, as autonomous vehicles and vehicle-to-X communications become more mature, solutions that only utilize single, independent agents leave potential performance gains on the road. Multi-Agent Reinforcement Learning (MARL) is a research field that aims to find optimal solutions for multiple agents that interact with each other. This work aims to give an overview of the field to researchers in autonomous mobility. We first explain MARL and introduce important concepts. Then, we discuss the central paradigms that underlie MARL algorithms, and give an overview of state-of-the-art methods and ideas in each paradigm. With this background, we survey applications of MARL in autonomous mobility scenarios and give an overview of existing scenarios and implementations.",
        "published": "2022-03-15T06:40:28Z",
        "link": "http://arxiv.org/abs/2203.07676v2",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Learning to Infer Belief Embedded Communication",
        "authors": [
            "Guo Ye",
            "Han Liu",
            "Biswa Sengupta"
        ],
        "summary": "In multi-agent collaboration problems with communication, an agent's ability to encode their intention and interpret other agents' strategies is critical for planning their future actions. This paper introduces a novel algorithm called Intention Embedded Communication (IEC) to mimic an agent's language learning ability. IEC contains a perception module for decoding other agents' intentions in response to their past actions. It also includes a language generation module for learning implicit grammar during communication with two or more agents. Such grammar, by construction, should be compact for efficient communication. Both modules undergo conjoint evolution - similar to an infant's babbling that enables it to learn a language of choice by trial and error. We utilised three multi-agent environments, namely predator/prey, traffic junction and level-based foraging and illustrate that such a co-evolution enables us to learn much quicker (50%) than state-of-the-art algorithms like MADDPG. Ablation studies further show that disabling the inferring belief module, communication module, and the hidden states reduces the model performance by 38%, 60% and 30%, respectively. Hence, we suggest that modelling other agents' behaviour accelerates another agent to learn grammar and develop a language to communicate efficiently. We evaluate our method on a set of cooperative scenarios and show its superior performance to other multi-agent baselines. We also demonstrate that it is essential for agents to reason about others' states and learn this ability by continuous communication.",
        "published": "2022-03-15T12:42:10Z",
        "link": "http://arxiv.org/abs/2203.07832v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "CTDS: Centralized Teacher with Decentralized Student for Multi-Agent   Reinforcement Learning",
        "authors": [
            "Jian Zhao",
            "Xunhan Hu",
            "Mingyu Yang",
            "Wengang Zhou",
            "Jiangcheng Zhu",
            "Houqiang Li"
        ],
        "summary": "Due to the partial observability and communication constraints in many multi-agent reinforcement learning (MARL) tasks, centralized training with decentralized execution (CTDE) has become one of the most widely used MARL paradigms. In CTDE, centralized information is dedicated to learning the allocation of the team reward with a mixing network, while the learning of individual Q-values is usually based on local observations. The insufficient utility of global observation will degrade performance in challenging environments. To this end, this work proposes a novel Centralized Teacher with Decentralized Student (CTDS) framework, which consists of a teacher model and a student model. Specifically, the teacher model allocates the team reward by learning individual Q-values conditioned on global observation, while the student model utilizes the partial observations to approximate the Q-values estimated by the teacher model. In this way, CTDS balances the full utilization of global observation during training and the feasibility of decentralized execution for online inference. Our CTDS framework is generic which is ready to be applied upon existing CTDE methods to boost their performance. We conduct experiments on a challenging set of StarCraft II micromanagement tasks to test the effectiveness of our method and the results show that CTDS outperforms the existing value-based MARL methods.",
        "published": "2022-03-16T06:03:14Z",
        "link": "http://arxiv.org/abs/2203.08412v1",
        "categories": [
            "cs.MA",
            "cs.LG"
        ]
    },
    {
        "title": "Coach-assisted Multi-Agent Reinforcement Learning Framework for   Unexpected Crashed Agents",
        "authors": [
            "Jian Zhao",
            "Youpeng Zhao",
            "Weixun Wang",
            "Mingyu Yang",
            "Xunhan Hu",
            "Wengang Zhou",
            "Jianye Hao",
            "Houqiang Li"
        ],
        "summary": "Multi-agent reinforcement learning is difficult to be applied in practice, which is partially due to the gap between the simulated and real-world scenarios. One reason for the gap is that the simulated systems always assume that the agents can work normally all the time, while in practice, one or more agents may unexpectedly \"crash\" during the coordination process due to inevitable hardware or software failures. Such crashes will destroy the cooperation among agents, leading to performance degradation. In this work, we present a formal formulation of a cooperative multi-agent reinforcement learning system with unexpected crashes. To enhance the robustness of the system to crashes, we propose a coach-assisted multi-agent reinforcement learning framework, which introduces a virtual coach agent to adjust the crash rate during training. We design three coaching strategies and the re-sampling strategy for our coach agent. To the best of our knowledge, this work is the first to study the unexpected crashes in the multi-agent system. Extensive experiments on grid-world and StarCraft II micromanagement tasks demonstrate the efficacy of adaptive strategy compared with the fixed crash rate strategy and curriculum learning strategy. The ablation study further illustrates the effectiveness of our re-sampling strategy.",
        "published": "2022-03-16T08:22:45Z",
        "link": "http://arxiv.org/abs/2203.08454v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "PMIC: Improving Multi-Agent Reinforcement Learning with Progressive   Mutual Information Collaboration",
        "authors": [
            "Pengyi Li",
            "Hongyao Tang",
            "Tianpei Yang",
            "Xiaotian Hao",
            "Tong Sang",
            "Yan Zheng",
            "Jianye Hao",
            "Matthew E. Taylor",
            "Wenyuan Tao",
            "Zhen Wang",
            "Fazl Barez"
        ],
        "summary": "Learning to collaborate is critical in Multi-Agent Reinforcement Learning (MARL). Previous works promote collaboration by maximizing the correlation of agents' behaviors, which is typically characterized by Mutual Information (MI) in different forms. However, we reveal sub-optimal collaborative behaviors also emerge with strong correlations, and simply maximizing the MI can, surprisingly, hinder the learning towards better collaboration. To address this issue, we propose a novel MARL framework, called Progressive Mutual Information Collaboration (PMIC), for more effective MI-driven collaboration. PMIC uses a new collaboration criterion measured by the MI between global states and joint actions. Based on this criterion, the key idea of PMIC is maximizing the MI associated with superior collaborative behaviors and minimizing the MI associated with inferior ones. The two MI objectives play complementary roles by facilitating better collaborations while avoiding falling into sub-optimal ones. Experiments on a wide range of MARL benchmarks show the superior performance of PMIC compared with other algorithms.",
        "published": "2022-03-16T11:28:23Z",
        "link": "http://arxiv.org/abs/2203.08553v4",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Incorporating Multi-Agent Systems Technology in Power and Energy Systems   of Bangladesh: A Feasibility Study",
        "authors": [
            "Syed Redwan Md Hassan",
            "Nazmul Hasan",
            "Mohammad Ali Siddique",
            "K. M Solaiman Fahim",
            "Rummana Rahman",
            "Lamia Iftekhar"
        ],
        "summary": "The power sector of Bangladesh is presently experiencing essential changes as demand for power services is increasing with rising population and economic development. With a gradual shift from a rigidly centralized structure to a more decentralized and fluid setup, fundamentally because of the enormous advancement of distributed renewable energy sources, the future power system of the nation requires new control strategies to work efficiently and sustainably in the face of evolving conditions and constraints. Multi-Agent Systems (MAS) technology has attributes that meet these prerequisites of modern power systems and has been shown to be effective in dealing with its distributed and complex nature. This is a literature-based feasibility study to explore whether MAS technology is suited to be applied in the context of Bangladesh. For this preliminary paper, we look at the topic from a holistic perspective and conduct a meta-review to curate common applications of Multi-Agent System-based concepts, tools and algorithms on the power and energy sector. We also identify the top challenges of this domain in Bangladesh and connect the potential MAS-based solutions to address each challenge. Our qualitative assessment is motivated to provide a starting point for local researchers eager to experiment with MAS technology for application in Bangladesh.",
        "published": "2022-03-16T17:17:11Z",
        "link": "http://arxiv.org/abs/2203.08760v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "FairFoody: Bringing in Fairness in Food Delivery",
        "authors": [
            "Anjali Gupta",
            "Rahul Yadav",
            "Ashish Nair",
            "Abhijnan Chakraborty",
            "Sayan Ranu",
            "Amitabha Bagchi"
        ],
        "summary": "Along with the rapid growth and rise to prominence of food delivery platforms, concerns have also risen about the terms of employment of the gig workers underpinning this growth. Our analysis on data derived from a real-world food delivery platform across three large cities from India show that there is significant inequality in the money delivery agents earn. In this paper, we formulate the problem of fair income distribution among agents while also ensuring timely food delivery. We establish that the problem is not only NP-hard but also inapproximable in polynomial time. We overcome this computational bottleneck through a novel matching algorithm called FairFoody. Extensive experiments over real-world food delivery datasets show FairFoody imparts up to 10 times improvement in equitable income distribution when compared to baseline strategies, while also ensuring minimal impact on customer experience.",
        "published": "2022-03-16T18:07:39Z",
        "link": "http://arxiv.org/abs/2203.08849v3",
        "categories": [
            "cs.SI",
            "cs.MA"
        ]
    },
    {
        "title": "Backpropagation through Time and Space: Learning Numerical Methods with   Multi-Agent Reinforcement Learning",
        "authors": [
            "Elliot Way",
            "Dheeraj S. K. Kapilavai",
            "Yiwei Fu",
            "Lei Yu"
        ],
        "summary": "We introduce Backpropagation Through Time and Space (BPTTS), a method for training a recurrent spatio-temporal neural network, that is used in a homogeneous multi-agent reinforcement learning (MARL) setting to learn numerical methods for hyperbolic conservation laws. We treat the numerical schemes underlying partial differential equations (PDEs) as a Partially Observable Markov Game (POMG) in Reinforcement Learning (RL). Similar to numerical solvers, our agent acts at each discrete location of a computational space for efficient and generalizable learning. To learn higher-order spatial methods by acting on local states, the agent must discern how its actions at a given spatiotemporal location affect the future evolution of the state. The manifestation of this non-stationarity is addressed by BPTTS, which allows for the flow of gradients across both space and time. The learned numerical policies are comparable to the SOTA numerics in two settings, the Burgers' Equation and the Euler Equations, and generalize well to other simulation set-ups.",
        "published": "2022-03-16T20:50:24Z",
        "link": "http://arxiv.org/abs/2203.08937v3",
        "categories": [
            "cs.LG",
            "cs.MA",
            "physics.comp-ph"
        ]
    },
    {
        "title": "A Survey of Multi-Agent Deep Reinforcement Learning with Communication",
        "authors": [
            "Changxi Zhu",
            "Mehdi Dastani",
            "Shihan Wang"
        ],
        "summary": "Communication is an effective mechanism for coordinating the behaviors of multiple agents, broadening their views of the environment, and to support their collaborations. In the field of multi-agent deep reinforcement learning (MADRL), agents can improve the overall learning performance and achieve their objectives by communication. Agents can communicate various types of messages, either to all agents or to specific agent groups, or conditioned on specific constraints. With the growing body of research work in MADRL with communication (Comm-MADRL), there is a lack of a systematic and structural approach to distinguish and classify existing Comm-MADRL approaches. In this paper, we survey recent works in the Comm-MADRL field and consider various aspects of communication that can play a role in designing and developing multi-agent reinforcement learning systems. With these aspects in mind, we propose 9 dimensions along which Comm-MADRL approaches can be analyzed, developed, and compared. By projecting existing works into the multi-dimensional space, we discover interesting trends. We also propose some novel directions for designing future Comm-MADRL systems through exploring possible combinations of the dimensions.",
        "published": "2022-03-16T22:39:46Z",
        "link": "http://arxiv.org/abs/2203.08975v2",
        "categories": [
            "cs.MA",
            "cs.LG"
        ]
    },
    {
        "title": "PreTR: Spatio-Temporal Non-Autoregressive Trajectory Prediction   Transformer",
        "authors": [
            "Lina Achaji",
            "Thierno Barry",
            "Thibault Fouqueray",
            "Julien Moreau",
            "Francois Aioun",
            "Francois Charpillet"
        ],
        "summary": "Nowadays, our mobility systems are evolving into the era of intelligent vehicles that aim to improve road safety. Due to their vulnerability, pedestrians are the users who will benefit the most from these developments. However, predicting their trajectory is one of the most challenging concerns. Indeed, accurate prediction requires a good understanding of multi-agent interactions that can be complex. Learning the underlying spatial and temporal patterns caused by these interactions is even more of a competitive and open problem that many researchers are tackling. In this paper, we introduce a model called PRediction Transformer (PReTR) that extracts features from the multi-agent scenes by employing a factorized spatio-temporal attention module. It shows less computational needs than previously studied models with empirically better results. Besides, previous works in motion prediction suffer from the exposure bias problem caused by generating future sequences conditioned on model prediction samples rather than ground-truth samples. In order to go beyond the proposed solutions, we leverage encoder-decoder Transformer networks for parallel decoding a set of learned object queries. This non-autoregressive solution avoids the need for iterative conditioning and arguably decreases training and testing computational time. We evaluate our model on the ETH/UCY datasets, a publicly available benchmark for pedestrian trajectory prediction. Finally, we justify our usage of the parallel decoding technique by showing that the trajectory prediction task can be better solved as a non-autoregressive task.",
        "published": "2022-03-17T12:52:23Z",
        "link": "http://arxiv.org/abs/2203.09293v1",
        "categories": [
            "cs.CV",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "The Frost Hollow Experiments: Pavlovian Signalling as a Path to   Coordination and Communication Between Agents",
        "authors": [
            "Patrick M. Pilarski",
            "Andrew Butcher",
            "Elnaz Davoodi",
            "Michael Bradley Johanson",
            "Dylan J. A. Brenneis",
            "Adam S. R. Parker",
            "Leslie Acker",
            "Matthew M. Botvinick",
            "Joseph Modayil",
            "Adam White"
        ],
        "summary": "Learned communication between agents is a powerful tool when approaching decision-making problems that are hard to overcome by any single agent in isolation. However, continual coordination and communication learning between machine agents or human-machine partnerships remains a challenging open problem. As a stepping stone toward solving the continual communication learning problem, in this paper we contribute a multi-faceted study into what we term Pavlovian signalling -- a process by which learned, temporally extended predictions made by one agent inform decision-making by another agent with different perceptual access to their shared environment. We seek to establish how different temporal processes and representational choices impact Pavlovian signalling between learning agents. To do so, we introduce a partially observable decision-making domain we call the Frost Hollow. In this domain a prediction learning agent and a reinforcement learning agent are coupled into a two-part decision-making system that seeks to acquire sparse reward while avoiding time-conditional hazards. We evaluate two domain variations: 1) machine prediction and control learning in a linear walk, and 2) a prediction learning machine interacting with a human participant in a virtual reality environment. Our results showcase the speed of learning for Pavlovian signalling, the impact that different temporal representations do (and do not) have on agent-agent coordination, and how temporal aliasing impacts agent-agent and human-agent interactions differently. As a main contribution, we establish Pavlovian signalling as a natural bridge between fixed signalling paradigms and fully adaptive communication learning. Our results therefore point to an actionable, constructivist path towards continual communication learning between reinforcement learning agents, with potential impact in a range of real-world settings.",
        "published": "2022-03-17T17:49:45Z",
        "link": "http://arxiv.org/abs/2203.09498v1",
        "categories": [
            "cs.AI",
            "cs.CL",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Strategic Maneuver and Disruption with Reinforcement Learning Approaches   for Multi-Agent Coordination",
        "authors": [
            "Derrik E. Asher",
            "Anjon Basak",
            "Rolando Fernandez",
            "Piyush K. Sharma",
            "Erin G. Zaroukian",
            "Christopher D. Hsu",
            "Michael R. Dorothy",
            "Thomas Mahre",
            "Gerardo Galindo",
            "Luke Frerichs",
            "John Rogers",
            "John Fossaceca"
        ],
        "summary": "Reinforcement learning (RL) approaches can illuminate emergent behaviors that facilitate coordination across teams of agents as part of a multi-agent system (MAS), which can provide windows of opportunity in various military tasks. Technologically advancing adversaries pose substantial risks to a friendly nation's interests and resources. Superior resources alone are not enough to defeat adversaries in modern complex environments because adversaries create standoff in multiple domains against predictable military doctrine-based maneuvers. Therefore, as part of a defense strategy, friendly forces must use strategic maneuvers and disruption to gain superiority in complex multi-faceted domains such as multi-domain operations (MDO). One promising avenue for implementing strategic maneuver and disruption to gain superiority over adversaries is through coordination of MAS in future military operations. In this paper, we present overviews of prominent works in the RL domain with their strengths and weaknesses for overcoming the challenges associated with performing autonomous strategic maneuver and disruption in military contexts.",
        "published": "2022-03-17T19:02:18Z",
        "link": "http://arxiv.org/abs/2203.09565v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Hedonic Games With Friends, Enemies, and Neutrals: Resolving Open   Questions and Fine-Grained Complexity",
        "authors": [
            "Jiehua Chen",
            "Gergely Csáji",
            "Sanjukta Roy",
            "Sofia Simola"
        ],
        "summary": "We investigate verification and existence problems for prominent stability concepts in hedonic games with friends, enemies, and optionally with neutrals [8, 16]. We resolve several (long-standing) open questions [4, 16, 20, 23] and show that for friend-oriented preferences, under the friends and enemies model, it is coNP-complete to verify whether a given agent partition is (strictly) core stable, while under the friends, enemies, and neutrals model, it is NP-complete to determine whether an individual stable partition exists. We further look into natural restricted cases from the literature, such as when the friends and enemies relationships are symmetric, when the initial coalitions have bounded size, when the vertex degree in the friendship graph (resp. the union of friendship and enemy graph) is bounded, or when such graph is acyclic or close to being acyclic. We obtain a complete (parameterized) complexity picture regarding these cases.",
        "published": "2022-03-17T23:31:48Z",
        "link": "http://arxiv.org/abs/2203.09655v2",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Decentralizing Permissioned Blockchain with Delay Towers",
        "authors": [
            "Shashank Motepalli",
            "Hans-Arno Jacobsen"
        ],
        "summary": "Growing excitement around permissionless blockchains is uncovering its latent scalability concerns. Permissioned blockchains offer high transactional throughput and low latencies while compromising decentralization. In the quest for a decentralized, scalable blockchain fabric, i.e., to offer the scalability of permissioned blockchain in a permissionless setting, we present L4L to encourage decentralization over the permissioned Libra network without compromising its sustainability. L4L employs delay towers, -- puzzle towers that leverage verifiable delay functions -- for establishing identity in a permissionless setting. Delay towers cannot be parallelized due to their sequential execution, making them an eco-friendly alternative. We also discuss methodologies to replace validators participating in consensus to promote compliant behavior. Our evaluations found that the cost of enabling decentralization over permissioned networks is almost negligible. Furthermore, delay towers offer an alternative to existing permissionless consensus mechanisms without requiring airdrops or pre-sale of tokens.",
        "published": "2022-03-18T03:23:24Z",
        "link": "http://arxiv.org/abs/2203.09714v1",
        "categories": [
            "cs.MA",
            "cs.DC"
        ]
    },
    {
        "title": "Dencentralized learning in the presence of low-rank noise",
        "authors": [
            "Roula Nassif",
            "Virginia Bordignon",
            "Stefan Vlaski",
            "Ali H. Sayed"
        ],
        "summary": "Observations collected by agents in a network may be unreliable due to observation noise or interference. This paper proposes a distributed algorithm that allows each node to improve the reliability of its own observation by relying solely on local computations and interactions with immediate neighbors, assuming that the field (graph signal) monitored by the network lies in a low-dimensional subspace and that a low-rank noise is present in addition to the usual full-rank noise. While oblique projections can be used to project measurements onto a low-rank subspace along a direction that is oblique to the subspace, the resulting solution is not distributed. Starting from the centralized solution, we propose an algorithm that performs the oblique projection of the overall set of observations onto the signal subspace in an iterative and distributed manner. We then show how the oblique projection framework can be extended to handle distributed learning and adaptation problems over networks.",
        "published": "2022-03-18T09:13:57Z",
        "link": "http://arxiv.org/abs/2203.09810v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "eess.SP"
        ]
    },
    {
        "title": "Risk-Sensitive Bayesian Games for Multi-Agent Reinforcement Learning   under Policy Uncertainty",
        "authors": [
            "Hannes Eriksson",
            "Debabrota Basu",
            "Mina Alibeigi",
            "Christos Dimitrakakis"
        ],
        "summary": "In stochastic games with incomplete information, the uncertainty is evoked by the lack of knowledge about a player's own and the other players' types, i.e. the utility function and the policy space, and also the inherent stochasticity of different players' interactions. In existing literature, the risk in stochastic games has been studied in terms of the inherent uncertainty evoked by the variability of transitions and actions. In this work, we instead focus on the risk associated with the \\textit{uncertainty over types}. We contrast this with the multi-agent reinforcement learning framework where the other agents have fixed stationary policies and investigate risk-sensitiveness due to the uncertainty about the other agents' adaptive policies. We propose risk-sensitive versions of existing algorithms proposed for risk-neutral stochastic games, such as Iterated Best Response (IBR), Fictitious Play (FP) and a general multi-objective gradient approach using dual ascent (DAPG). Our experimental analysis shows that risk-sensitive DAPG performs better than competing algorithms for both social welfare and general-sum stochastic games.",
        "published": "2022-03-18T16:40:30Z",
        "link": "http://arxiv.org/abs/2203.10045v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Model-based Multi-agent Reinforcement Learning: Recent Progress and   Prospects",
        "authors": [
            "Xihuai Wang",
            "Zhicheng Zhang",
            "Weinan Zhang"
        ],
        "summary": "Significant advances have recently been achieved in Multi-Agent Reinforcement Learning (MARL) which tackles sequential decision-making problems involving multiple participants. However, MARL requires a tremendous number of samples for effective training. On the other hand, model-based methods have been shown to achieve provable advantages of sample efficiency. However, the attempts of model-based methods to MARL have just started very recently. This paper presents a review of the existing research on model-based MARL, including theoretical analyses, algorithms, and applications, and analyzes the advantages and potential of model-based MARL. Specifically, we provide a detailed taxonomy of the algorithms and point out the pros and cons for each algorithm according to the challenges inherent to multi-agent scenarios. We also outline promising directions for future development of this field.",
        "published": "2022-03-20T17:24:47Z",
        "link": "http://arxiv.org/abs/2203.10603v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Fictitious Play with Maximin Initialization",
        "authors": [
            "Sam Ganzfried"
        ],
        "summary": "Fictitious play has recently emerged as the most accurate scalable algorithm for approximating Nash equilibrium strategies in multiplayer games. We show that the degree of equilibrium approximation error of fictitious play can be significantly reduced by carefully selecting the initial strategies. We present several new procedures for strategy initialization and compare them to the classic approach, which initializes all pure strategies to have equal probability. The best-performing approach, called maximin, solves a nonconvex quadratic program to compute initial strategies and results in a nearly 75% reduction in approximation error compared to the classic approach when 5 initializations are used.",
        "published": "2022-03-21T07:34:20Z",
        "link": "http://arxiv.org/abs/2203.10774v5",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.MA",
            "econ.TH"
        ]
    },
    {
        "title": "Long Short-Term Memory for Spatial Encoding in Multi-Agent Path Planning",
        "authors": [
            "Marc R. Schlichting",
            "Stefan Notter",
            "Walter Fichter"
        ],
        "summary": "Reinforcement learning-based path planning for multi-agent systems of varying size constitutes a research topic with increasing significance as progress in domains such as urban air mobility and autonomous aerial vehicles continues. Reinforcement learning with continuous state and action spaces is used to train a policy network that accommodates desirable path planning behaviors and can be used for time-critical applications. A Long Short-Term Memory module is proposed to encode an unspecified number of states for a varying, indefinite number of agents. The described training strategies and policy architecture lead to a guidance that scales to an infinite number of agents and unlimited physical dimensions, although training takes place at a smaller scale. The guidance is implemented on a low-cost, off-the-shelf onboard computer. The feasibility of the proposed approach is validated by presenting flight test results of up to four drones, autonomously navigating collision-free in a real-world environment.",
        "published": "2022-03-21T09:16:56Z",
        "link": "http://arxiv.org/abs/2203.10823v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "I.2.8; I.2.9; I.2.11; J.2"
        ]
    },
    {
        "title": "Dynamic Certification for Autonomous Systems",
        "authors": [
            "Georgios Bakirtzis",
            "Steven Carr",
            "David Danks",
            "Ufuk Topcu"
        ],
        "summary": "Autonomous systems are often deployed in complex sociotechnical environments, such as public roads, where they must behave safely and securely. Unlike many traditionally engineered systems, autonomous systems are expected to behave predictably in varying \"open world\" environmental contexts that cannot be fully specified formally. As a result, assurance about autonomous systems requires us to develop new certification methods and mathematical tools that can bound the uncertainty engendered by these diverse deployment scenarios, rather than relying on static tools.",
        "published": "2022-03-21T13:14:49Z",
        "link": "http://arxiv.org/abs/2203.10950v3",
        "categories": [
            "cs.RO",
            "cs.LO",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Multi-Agent Relative Pose Estimation with UWB and Constrained   Communications",
        "authors": [
            "Andrew Fishberg",
            "Jonathan P. How"
        ],
        "summary": "Inter-agent relative localization is critical for any multi-robot system operating in the absence of external positioning infrastructure or prior environmental knowledge. We propose a novel inter-agent relative 2D pose estimation system where each participating agent is equipped with several ultra-wideband (UWB) ranging tags. Prior work typically supplements noisy UWB range measurements with additional continuously transmitted data, such as odometry, making these approaches scale poorly with increased swarm size or decreased communication throughput. This approach addresses these concerns by using only locally collected UWB measurements with no additionally transmitted data. By modeling observed ranging biases and systematic antenna obstructions in our proposed optimization solution, our experimental results demonstrate an improved mean position error (while remaining competitive in other metrics) over a similar state-of-the-art approach that additionally relies on continuously transmitted odometry.",
        "published": "2022-03-21T14:20:45Z",
        "link": "http://arxiv.org/abs/2203.11004v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Continuous Flow Model of a Historical Battle: A Fresh Look at Pickett's   charge",
        "authors": [
            "Jonathan Poggie",
            "Sorin A. Matei",
            "Robert Kirchubel"
        ],
        "summary": "A continuous flow model of infantry behavior, based on conservation of individuals and tracking of subunit identity, has been developed in sufficient detail that it can now be applied to a realistic simulation of a historical battle. Pickett's charge during the 1863 Battle of Gettysburg, Pennsylvania in the U.S. Civil War was chosen as an initial application of the model. This scenario is a good test of the current mathematical model because many modern military tactics were employed, in a context where the action took place on foot or horseback, and the historical map and troop numbers are available. Compared to a discrete agent model, the flow model was found to better capture the interaction of the forces with the terrain and each other. A brigade-level simulation, faithful to the details of the historical events, was performed. The main source of asymmetry in the numbers of casualties was found to be the inability of the Confederate forces to use effective ranged fire while they were moving. Comparison of simulations with and without terrain effects showed that they slow the pace of battle and favor the defenders, exposing the attackers to heavy ranged fire for an extended period. A statistical analysis of possible outcomes for an ensemble of 1000 randomized perturbations of the baseline brigade-level scenario was carried out. Consistent with historical events, it was found that only 6 percent of the scenarios resulted in an outcome that could be considered a Confederate victory.",
        "published": "2022-03-21T14:55:15Z",
        "link": "http://arxiv.org/abs/2203.11035v1",
        "categories": [
            "cs.MA",
            "cs.CY",
            "91F10, 91-10",
            "I.6.0; I.2.11; J.4"
        ]
    },
    {
        "title": "BESSIE: A Behavior and Epidemic Simulator for Use With Synthetic   Populations",
        "authors": [
            "Henning S Mortveit",
            "Stephen Adams",
            "Faraz Dadgostari",
            "Samarth Swarup",
            "Peter Beling"
        ],
        "summary": "In this paper, we present BESSIE (Behavior and Epidemic Simulator for Synthetic Information Environments), an open source, agent-based simulator for COVID-type epidemics. BESSIE uses a synthetic population where each person has demographic attributes, belong to a household, and has a base activity- and visit schedule covering seven days. The simulated disease spreads through contacts that arise from joint visits to the locations where activities take place. The simulation model has a plugin-type programmable behavioral model where, based on the dynamics and observables tracked by the simulator, agents decide on actions such as wearing a mask, engaging in social distancing, or refraining from certain activity types by staying at home instead. The plugins are supplied as Python code. To the best of our knowledge, BESSIE is a unique simulator supporting this feature set, and most certainly as open software.   To illustrate the use of BESSIE, we provide a COVID-relevant example demonstrating some of its capabilities. The example uses a synthetic population for the City of Charlottesville, Virginia. Both this population and the Python plugin modules used in the example are made available. The Python implementation, which can run on anything from a laptop to a cluster, is made available under the Apache 2.0 license (https://www.apache.org/licenses/LICENSE-2.0.html). The example population accompanying this publication is made available under the CC BY 4.0 license (https://creativecommons.org/licenses/by/4.0/).",
        "published": "2022-03-22T01:52:51Z",
        "link": "http://arxiv.org/abs/2203.11414v1",
        "categories": [
            "cs.MA",
            "physics.soc-ph"
        ]
    },
    {
        "title": "Distributing Collaborative Multi-Robot Planning with Gaussian Belief   Propagation",
        "authors": [
            "Aalok Patwardhan",
            "Riku Murai",
            "Andrew J. Davison"
        ],
        "summary": "Precise coordinated planning over a forward time window enables safe and highly efficient motion when many robots must work together in tight spaces, but this would normally require centralised control of all devices which is difficult to scale. We demonstrate GBP Planning, a new purely distributed technique based on Gaussian Belief Propagation for multi-robot planning problems, formulated by a generic factor graph defining dynamics and collision constraints over a forward time window. In simulations, we show that our method allows high performance collaborative planning where robots are able to cross each other in busy, intricate scenarios. They maintain shorter, quicker and smoother trajectories than alternative distributed planning techniques even in cases of communication failure. We encourage the reader to view the accompanying video demonstration at https://youtu.be/8VSrEUjH610.",
        "published": "2022-03-22T11:13:36Z",
        "link": "http://arxiv.org/abs/2203.11618v3",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Is Vanilla Policy Gradient Overlooked? Analyzing Deep Reinforcement   Learning for Hanabi",
        "authors": [
            "Bram Grooten",
            "Jelle Wemmenhove",
            "Maurice Poot",
            "Jim Portegies"
        ],
        "summary": "In pursuit of enhanced multi-agent collaboration, we analyze several on-policy deep reinforcement learning algorithms in the recently published Hanabi benchmark. Our research suggests a perhaps counter-intuitive finding, where Proximal Policy Optimization (PPO) is outperformed by Vanilla Policy Gradient over multiple random seeds in a simplified environment of the multi-agent cooperative card game. In our analysis of this behavior we look into Hanabi-specific metrics and hypothesize a reason for PPO's plateau. In addition, we provide proofs for the maximum length of a perfect game (71 turns) and any game (89 turns). Our code can be found at: https://github.com/bramgrooten/DeepRL-for-Hanabi",
        "published": "2022-03-22T12:28:06Z",
        "link": "http://arxiv.org/abs/2203.11656v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "A Decentralised Multi-Agent Reinforcement Learning Approach for the   Same-Day Delivery Problem",
        "authors": [
            "Elvin Ngu",
            "Leandro Parada",
            "Jose Javier Escribano Macias",
            "Panagiotis Angeloudis"
        ],
        "summary": "Same-Day Delivery services are becoming increasingly popular in recent years. These have been usually modelled by previous studies as a certain class of Dynamic Vehicle Routing Problem (DVRP) where goods must be delivered from a depot to a set of customers in the same day that the orders were placed. Adaptive exact solution methods for DVRPs can become intractable even for small problem instances. In this paper, we formulate the SDDP as a Markov Decision Process (MDP) and solve it using a parameter-sharing Deep Q-Network, which corresponds to a decentralised Multi-Agent Reinforcement Learning (MARL) approach. For this, we create a multi-agent grid-based SDD environment, consisting of multiple vehicles, a central depot and dynamic order generation. In addition, we introduce zone-specific order generation and reward probabilities. We compare the performance of our proposed MARL approach against a Mixed Inter Programming (MIP) solution. Results show that our proposed MARL framework performs on par with MIP-based policy when the number of orders is relatively low. For problem instances with higher order arrival rates, computational results show that the MARL approach underperforms the MIP by up to 30%. The performance gap between both methods becomes smaller when zone-specific parameters are employed. The gap is reduced from 30% to 3% for a 5x5 grid scenario with 30 orders. Execution time results indicate that the MARL approach is, on average, 65 times faster than the MIP-based policy, and therefore may be more advantageous for real-time control, at least for small-sized instances.",
        "published": "2022-03-22T12:33:41Z",
        "link": "http://arxiv.org/abs/2203.11658v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Congestion-aware path coordination game with Markov decision process   dynamics",
        "authors": [
            "Sarah H. Q. Li",
            "Dan Calderone",
            "Behcet Acikmese"
        ],
        "summary": "Inspired by the path coordination problem arising from robo-taxis, warehouse management, and mixed-vehicle routing problems, we model a group of heterogeneous players responding to stochastic demands as a congestion game under Markov decision process dynamics. Players share a common state-action space but have unique transition dynamics, and each player's unique cost is a {function} of the joint state-action probability distribution. For a class of player cost functions, we formulate the player-specific optimization problem, prove the equivalence between the Nash equilibrium and the solution of a potential minimization problem, and derive dynamic programming approaches to solve the Nash equilibrium. We apply this game to model multi-agent path coordination and introduce congestion-based cost functions that enable players to complete individual tasks while avoiding congestion with their opponents. Finally, we present a learning algorithm for finding the Nash equilibrium that has linear complexity in the number of players. We demonstrate our game model on a multi-robot warehouse \\change{path coordination problem}, in which robots autonomously retrieve and deliver packages while avoiding congested paths.",
        "published": "2022-03-23T01:54:54Z",
        "link": "http://arxiv.org/abs/2203.12133v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Multi-agent Searching System for Medical Information",
        "authors": [
            "Mariya Evtimova-Gardair"
        ],
        "summary": "In the paper is proposed a model of multi-agent security system for searching a medical information in Internet. The advantages when using mobile agent are described, so that to perform searching in Internet. Nowadays, multi-agent systems found their application into distribution of decisions. For modeling the proposed multi-agent medical system is used JADE. Finally, the results when using mobile agent are generated that could reflect performance when working with BIG DATA. The proposed system is having also relatively high precision 96%.",
        "published": "2022-03-23T14:58:43Z",
        "link": "http://arxiv.org/abs/2203.12465v1",
        "categories": [
            "cs.IR",
            "cs.CY",
            "cs.MA"
        ]
    },
    {
        "title": "Heterogeneous Ground-Air Autonomous Vehicle Networking in Austere   Environments: Practical Implementation of a Mesh Network in the DARPA   Subterranean Challenge",
        "authors": [
            "Harel Biggie",
            "Steve McGuire"
        ],
        "summary": "Implementing a wireless mesh network in a real-life scenario requires a significant systems engineering effort to turn a network concept into a complete system. This paper presents an evaluation of a fielded system within the DARPA Subterranean (SubT) Challenge Final Event that contributed to a 3rd place finish. Our system included a team of air and ground robots, deployable mesh extender nodes, and a human operator base station. This paper presents a real-world evaluation of a stack optimized for air and ground robotic exploration in a RF-limited environment under practical system design limitations. Our highly customizable solution utilizes a minimum of non-free components with form factor options suited for UAV operations and provides insight into network operations at all levels. We present performance metrics based on our performance in the Final Event of the DARPA Subterranean Challenge, demonstrating the practical successes and limitations of our approach, as well as a set of lessons learned and suggestions for future improvements.",
        "published": "2022-03-24T03:32:41Z",
        "link": "http://arxiv.org/abs/2203.12832v1",
        "categories": [
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Information Preferences of Individual Agents in   Linear-Quadratic-Gaussian Network Games",
        "authors": [
            "Furkan Sezer",
            "Ceyhun Eksin"
        ],
        "summary": "We consider linear-quadratic-Gaussian (LQG) network games in which agents have quadratic payoffs that depend on their individual and neighbors' actions, and an unknown payoff-relevant state. An information designer determines the fidelity of information revealed to the agents about the payoff state to maximize the social welfare. Prior results show that full information disclosure is optimal under certain assumptions on the payoffs, i.e., it is beneficial for the average individual. In this paper, we provide conditions based on the strength of the dependence of payoffs on neighbors' actions, i.e., competition, under which a rational agent is expected to benefit, i.e., receive higher payoffs, from full information disclosure. We find that all agents benefit from information disclosure for the star network structure when the game is symmetric and submodular or supermodular. We also identify that the central agent benefits more than a peripheral agent from full information disclosure unless the competition is strong and the number of peripheral agents is small enough. Despite the fact that all agents expect to benefit from information disclosure ex-ante, a central agent can be worse-off from information disclosure in many realizations of the payoff state under strong competition, indicating that a risk-averse central agent can prefer uninformative signals ex-ante.",
        "published": "2022-03-24T13:07:47Z",
        "link": "http://arxiv.org/abs/2203.13056v1",
        "categories": [
            "cs.GT",
            "cs.MA",
            "cs.SY",
            "econ.GN",
            "eess.SY",
            "math.OC",
            "q-fin.EC"
        ]
    },
    {
        "title": "Platform Behavior under Market Shocks: A Simulation Framework and   Reinforcement-Learning Based Study",
        "authors": [
            "Xintong Wang",
            "Gary Qiurui Ma",
            "Alon Eden",
            "Clara Li",
            "Alexander Trott",
            "Stephan Zheng",
            "David C. Parkes"
        ],
        "summary": "We study the behavior of an economic platform (e.g., Amazon, Uber Eats, Instacart) under shocks, such as COVID-19 lockdowns, and the effect of different regulation considerations imposed on a platform. To this end, we develop a multi-agent Gym environment of a platform economy in a dynamic, multi-period setting, with the possible occurrence of economic shocks. Buyers and sellers are modeled as economically-motivated agents, choosing whether or not to pay corresponding fees to use the platform. We formulate the platform's problem as a partially observable Markov decision process, and use deep reinforcement learning to model its fee setting and matching behavior. We consider two major types of regulation frameworks: (1) taxation policies and (2) platform fee restrictions, and offer extensive simulated experiments to characterize regulatory tradeoffs under optimal platform responses. Our results show that while many interventions are ineffective with a sophisticated platform actor, we identify a particular kind of regulation -- fixing fees to optimal, pre-shock fees while still allowing a platform to choose how to match buyer demands to sellers -- as promoting the efficiency, seller diversity, and resilience of the overall economic system.",
        "published": "2022-03-25T00:21:41Z",
        "link": "http://arxiv.org/abs/2203.13395v2",
        "categories": [
            "cs.MA",
            "cs.GT"
        ]
    },
    {
        "title": "Bisimulations for Verifying Strategic Abilities with an Application to   the ThreeBallot Voting Protocol",
        "authors": [
            "Francesco Belardinelli",
            "Rodica Condurache",
            "Catalin Dima",
            "Wojciech Jamroga",
            "Michal Knapik"
        ],
        "summary": "We propose a notion of alternating bisimulation for strategic abilities under imperfect information. The bisimulation preserves formulas of ATL$^*$ for both the {\\em objective} and {\\em subjective} variants of the state-based semantics with imperfect information, which are commonly used in the modeling and verification of multi-agent systems. Furthermore, we apply the theoretical result to the verification of coercion-resistance in the ThreeBallot voting system, a voting protocol that does not use cryptography. In particular, we show that natural simplifications of an initial model of the protocol are in fact bisimulations of the original model, and therefore satisfy the same ATL$^*$ properties, including coercion-resistance. These simplifications allow the model-checking tool MCMAS to terminate on models with a larger number of voters and candidates, compared with the initial model.",
        "published": "2022-03-25T14:56:20Z",
        "link": "http://arxiv.org/abs/2203.13692v3",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Dynamic Noises of Multi-Agent Environments Can Improve Generalization:   Agent-based Models meets Reinforcement Learning",
        "authors": [
            "Mohamed Akrout",
            "Amal Feriani",
            "Bob McLeod"
        ],
        "summary": "We study the benefits of reinforcement learning (RL) environments based on agent-based models (ABM). While ABMs are known to offer microfoundational simulations at the cost of computational complexity, we empirically show in this work that their non-deterministic dynamics can improve the generalization of RL agents. To this end, we examine the control of an epidemic SIR environments based on either differential equations or ABMs. Numerical simulations demonstrate that the intrinsic noise in the ABM-based dynamics of the SIR model not only improve the average reward but also allow the RL agent to generalize on a wider ranges of epidemic parameters.",
        "published": "2022-03-26T09:56:30Z",
        "link": "http://arxiv.org/abs/2204.14076v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Competition-Based Resilience in Distributed Quadratic Optimization",
        "authors": [
            "Luca Ballotta",
            "Giacomo Como",
            "Jeff S. Shamma",
            "Luca Schenato"
        ],
        "summary": "This paper proposes a novel approach to resilient distributed optimization with quadratic costs in a networked control system (e.g., wireless sensor network, power grid, robotic team) prone to external attacks (e.g., hacking, power outage) that cause agents to misbehave. Departing from classical filtering strategies proposed in literature, we draw inspiration from a game-theoretic formulation of the consensus problem and argue that adding competition to the mix can enhance resilience in the presence of malicious agents. Our intuition is corroborated by analytical and numerical results showing that i) our strategy highlights the presence of a nontrivial tradeoff between blind collaboration and full competition, and ii) such competition-based approach can outperform state-of-the-art algorithms based on Mean Subsequence Reduced.",
        "published": "2022-03-26T15:32:49Z",
        "link": "http://arxiv.org/abs/2203.14099v4",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY",
            "math.OC",
            "93B70 (Primary) 68M18, 93D09, 93D50 (Secondary)",
            "I.2.11"
        ]
    },
    {
        "title": "Collaborative Intelligent Reflecting Surface Networks with Multi-Agent   Reinforcement Learning",
        "authors": [
            "Jie Zhang",
            "Jun Li",
            "Yijin Zhang",
            "Qingqing Wu",
            "Xiongwei Wu",
            "Feng Shu",
            "Shi Jin",
            "Wen Chen"
        ],
        "summary": "Intelligent reflecting surface (IRS) is envisioned to be widely applied in future wireless networks. In this paper, we investigate a multi-user communication system assisted by cooperative IRS devices with the capability of energy harvesting. Aiming to maximize the long-term average achievable system rate, an optimization problem is formulated by jointly designing the transmit beamforming at the base station (BS) and discrete phase shift beamforming at the IRSs, with the constraints on transmit power, user data rate requirement and IRS energy buffer size. Considering time-varying channels and stochastic arrivals of energy harvested by the IRSs, we first formulate the problem as a Markov decision process (MDP) and then develop a novel multi-agent Q-mix (MAQ) framework with two layers to decouple the optimization parameters. The higher layer is for optimizing phase shift resolutions, and the lower one is for phase shift beamforming and power allocation. Since the phase shift optimization is an integer programming problem with a large-scale action space, we improve MAQ by incorporating the Wolpertinger method, namely, MAQ-WP algorithm to achieve a sub-optimality with reduced dimensions of action space. In addition, as MAQ-WP is still of high complexity to achieve good performance, we propose a policy gradient-based MAQ algorithm, namely, MAQ-PG, by mapping the discrete phase shift actions into a continuous space at the cost of a slight performance loss. Simulation results demonstrate that the proposed MAQ-WP and MAQ-PG algorithms can converge faster and achieve data rate improvements of 10.7% and 8.8% over the conventional multi-agent DDPG, respectively.",
        "published": "2022-03-26T20:37:14Z",
        "link": "http://arxiv.org/abs/2203.14152v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "eess.SP"
        ]
    },
    {
        "title": "UNMAS: Multi-Agent Reinforcement Learning for Unshaped Cooperative   Scenarios",
        "authors": [
            "Jiajun Chai",
            "Weifan Li",
            "Yuanheng Zhu",
            "Dongbin Zhao",
            "Zhe Ma",
            "Kewu Sun",
            "Jishiyu Ding"
        ],
        "summary": "Multi-agent reinforcement learning methods such as VDN, QMIX, and QTRAN that adopt centralized training with decentralized execution (CTDE) framework have shown promising results in cooperation and competition. However, in some multi-agent scenarios, the number of agents and the size of action set actually vary over time. We call these unshaped scenarios, and the methods mentioned above fail in performing satisfyingly. In this paper, we propose a new method called Unshaped Networks for Multi-Agent Systems (UNMAS) that adapts to the number and size changes in multi-agent systems. We propose the self-weighting mixing network to factorize the joint action-value. Its adaption to the change in agent number is attributed to the nonlinear mapping from each-agent Q value to the joint action-value with individual weights. Besides, in order to address the change in action set, each agent constructs an individual action-value network that is composed of two streams to evaluate the constant environment-oriented subset and the varying unit-oriented subset. We evaluate UNMAS on various StarCraft II micro-management scenarios and compare the results with several state-of-the-art MARL algorithms. The superiority of UNMAS is demonstrated by its highest winning rates especially on the most difficult scenario 3s5z_vs_3s6z. The agents learn to perform effectively cooperative behaviors while other MARL algorithms fail in. Animated demonstrations and source code are provided in https://sites.google.com/view/unmas.",
        "published": "2022-03-28T03:30:26Z",
        "link": "http://arxiv.org/abs/2203.14477v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Distributed Task Management in Fog Computing: A Socially Concave Bandit   Game",
        "authors": [
            "Xiaotong Cheng",
            "Setareh Maghsudi"
        ],
        "summary": "Fog computing leverages the task offloading capabilities at the network's edge to improve efficiency and enable swift responses to application demands. However, the design of task allocation strategies in a fog computing network is still challenging because of the heterogeneity of fog nodes and uncertainties in system dynamics. We formulate the distributed task allocation problem as a social-concave game with bandit feedback and show that the game has a unique Nash equilibrium, which is implementable using no-regret learning strategies (regret with sublinear growth). We then develop two no-regret online decision-making strategies. One strategy, namely bandit gradient ascent with momentum, is an online convex optimization algorithm with bandit feedback. The other strategy, Lipschitz bandit with initialization, is an EXP3 multi-armed bandit algorithm. We establish regret bounds for both strategies and analyze their convergence characteristics. Moreover, we compare the proposed strategies with an allocation strategy named learning with linear rewards. Theoretical- and numerical analysis shows the superior performance of the proposed strategies for efficient task allocation compared to the state-of-the-art methods.",
        "published": "2022-03-28T08:26:14Z",
        "link": "http://arxiv.org/abs/2203.14572v2",
        "categories": [
            "cs.MA",
            "cs.GT",
            "cs.LG"
        ]
    },
    {
        "title": "Solving Disjunctive Temporal Networks with Uncertainty under Restricted   Time-Based Controllability using Tree Search and Graph Neural Networks",
        "authors": [
            "Kevin Osanlou",
            "Jeremy Frank",
            "Andrei Bursuc",
            "Tristan Cazenave",
            "Eric Jacopin",
            "Christophe Guettier",
            "J. Benton"
        ],
        "summary": "Planning under uncertainty is an area of interest in artificial intelligence. We present a novel approach based on tree search and graph machine learning for the scheduling problem known as Disjunctive Temporal Networks with Uncertainty (DTNU). Dynamic Controllability (DC) of DTNUs seeks a reactive scheduling strategy to satisfy temporal constraints in response to uncontrollable action durations. We introduce new semantics for reactive scheduling: Time-based Dynamic Controllability (TDC) and a restricted subset of TDC, R-TDC. We design a tree search algorithm to determine whether or not a DTNU is R-TDC. Moreover, we leverage a graph neural network as a heuristic for tree search guidance. Finally, we conduct experiments on a known benchmark on which we show R-TDC to retain significant completeness with regard to DC, while being faster to prove. This results in the tree search processing fifty percent more DTNU problems in R-TDC than the state-of-the-art DC solver does in DC with the same time budget. We also observe that graph neural network search guidance leads to substantial performance gains on benchmarks of more complex DTNUs, with up to eleven times more problems solved than the baseline tree search.",
        "published": "2022-03-28T18:51:22Z",
        "link": "http://arxiv.org/abs/2203.15030v2",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "cs.RO",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "An Online Approach to Solve the Dynamic Vehicle Routing Problem with   Stochastic Trip Requests for Paratransit Services",
        "authors": [
            "Michael Wilbur",
            "Salah Uddin Kadir",
            "Youngseo Kim",
            "Geoffrey Pettet",
            "Ayan Mukhopadhyay",
            "Philip Pugliese",
            "Samitha Samaranayake",
            "Aron Laszka",
            "Abhishek Dubey"
        ],
        "summary": "Many transit agencies operating paratransit and microtransit services have to respond to trip requests that arrive in real-time, which entails solving hard combinatorial and sequential decision-making problems under uncertainty. To avoid decisions that lead to significant inefficiency in the long term, vehicles should be allocated to requests by optimizing a non-myopic utility function or by batching requests together and optimizing a myopic utility function. While the former approach is typically offline, the latter can be performed online. We point out two major issues with such approaches when applied to paratransit services in practice. First, it is difficult to batch paratransit requests together as they are temporally sparse. Second, the environment in which transit agencies operate changes dynamically (e.g., traffic conditions), causing estimates that are learned offline to become stale. To address these challenges, we propose a fully online approach to solve the dynamic vehicle routing problem (DVRP) with time windows and stochastic trip requests that is robust to changing environmental dynamics by construction. We focus on scenarios where requests are relatively sparse - our problem is motivated by applications to paratransit services. We formulate DVRP as a Markov decision process and use Monte Carlo tree search to evaluate actions for any given state. Accounting for stochastic requests while optimizing a non-myopic utility function is computationally challenging; indeed, the action space for such a problem is intractably large in practice. To tackle the large action space, we leverage the structure of the problem to design heuristics that can sample promising actions for the tree search. Our experiments using real-world data from our partner agency show that the proposed approach outperforms existing state-of-the-art approaches both in terms of performance and robustness.",
        "published": "2022-03-28T22:15:52Z",
        "link": "http://arxiv.org/abs/2203.15127v2",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Proximal-like algorithms for equilibrium seeking in mixed-integer Nash   equilibrium problems",
        "authors": [
            "Filippo Fabiani",
            "Barbara Franci",
            "Simone Sagratella",
            "Martin Schmidt",
            "Mathias Staudigl"
        ],
        "summary": "We consider potential games with mixed-integer variables, for which we propose two distributed, proximal-like equilibrium seeking algorithms. Specifically, we focus on two scenarios: i) the underlying game is generalized ordinal and the agents update through iterations by choosing an exact optimal strategy; ii) the game admits an exact potential and the agents adopt approximated optimal responses. By exploiting the properties of integer-compatible regularization functions used as penalty terms, we show that both algorithms converge to either an exact or an $\\epsilon$-approximate equilibrium. We corroborate our findings on a numerical instance of a Cournot oligopoly model.",
        "published": "2022-03-29T10:13:35Z",
        "link": "http://arxiv.org/abs/2203.15410v2",
        "categories": [
            "math.OC",
            "cs.GT",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "A stochastic generalized Nash equilibrium model for platforms   competition in the ride-hail market",
        "authors": [
            "Filippo Fabiani",
            "Barbara Franci"
        ],
        "summary": "The presence of uncertainties in the ride-hailing market complicates the pricing strategies of on-demand platforms that compete each other to offer a mobility service while striving to maximize their profit. Looking at this problem as a stochastic generalized Nash equilibrium problem (SGNEP), we design a distributed, stochastic equilibrium seeking algorithm with Tikhonov regularization to find an optimal pricing strategy. Remarkably, the proposed iterative scheme does not require an increasing (possibly infinite) number of samples of the random variable to perform the stochastic approximation, thus making it appealing from a practical perspective. Moreover, we show that the algorithm returns a Nash equilibrium under mere monotonicity assumption and a careful choice of the step size sequence, obtained by exploiting the specific structure of the SGNEP at hand. We finally corroborate our results on a numerical instance of the on-demand ride-hailing market.",
        "published": "2022-03-29T10:16:47Z",
        "link": "http://arxiv.org/abs/2203.15412v1",
        "categories": [
            "math.OC",
            "cs.GT",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Efficiently Evolving Swarm Behaviors Using Grammatical Evolution With   PPA-style Behavior Trees",
        "authors": [
            "Aadesh Neupane",
            "Michael A. Goodrich"
        ],
        "summary": "Evolving swarm behaviors with artificial agents is computationally expensive and challenging. Because reward structures are often sparse in swarm problems, only a few simulations among hundreds evolve successful swarm behaviors. Additionally, swarm evolutionary algorithms typically rely on ad hoc fitness structures, and novel fitness functions need to be designed for each swarm task. This paper evolves swarm behaviors by systematically combining Postcondition-Precondition-Action (PPA) canonical Behavior Trees (BT) with a Grammatical Evolution. The PPA structure replaces ad hoc reward structures with systematic postcondition checks, which allows a common grammar to learn solutions to different tasks using only environmental cues and BT feedback. The static performance of learned behaviors is poor because no agent learns all necessary subtasks, but performance while evolving is excellent because agents can quickly change behaviors in new contexts. The evolving algorithm succeeded in 75\\% of learning trials for both foraging and nest maintenance tasks, an eight-fold improvement over prior work.",
        "published": "2022-03-29T17:36:50Z",
        "link": "http://arxiv.org/abs/2203.15776v1",
        "categories": [
            "cs.NE",
            "cs.MA"
        ]
    },
    {
        "title": "Asynchronous, Option-Based Multi-Agent Policy Gradient: A Conditional   Reasoning Approach",
        "authors": [
            "Xubo Lyu",
            "Amin Banitalebi-Dehkordi",
            "Mo Chen",
            "Yong Zhang"
        ],
        "summary": "Cooperative multi-agent problems often require coordination between agents, which can be achieved through a centralized policy that considers the global state. Multi-agent policy gradient (MAPG) methods are commonly used to learn such policies, but they are often limited to problems with low-level action spaces. In complex problems with large state and action spaces, it is advantageous to extend MAPG methods to use higher-level actions, also known as options, to improve the policy search efficiency. However, multi-robot option executions are often asynchronous, that is, agents may select and complete their options at different time steps. This makes it difficult for MAPG methods to derive a centralized policy and evaluate its gradient, as centralized policy always select new options at the same time. In this work, we propose a novel, conditional reasoning approach to address this problem and demonstrate its effectiveness on representative option-based multi-agent cooperative tasks through empirical validation. Find code and videos at: \\href{https://sites.google.com/view/mahrlsupp/}{https://sites.google.com/view/mahrlsupp/}",
        "published": "2022-03-29T22:02:28Z",
        "link": "http://arxiv.org/abs/2203.15925v3",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Continuous Integration of Data Histories into Consistent Namespaces",
        "authors": [
            "Mark Burgess",
            "Andras Gerlits"
        ],
        "summary": "We describe a policy-based approach to the scaling of shared data services, using a hierarchy of calibrated data pipelines to automate the continuous integration of data flows. While there is no unique solution to the problem of time order, we show how to use a fair interleaving to reproduce reliable `latest version' semantics in a controlled way, by trading locality for temporal resolution. We thus establish an invariant global ordering from a spanning tree over all shards, with controlled scalability. This forms a versioned coordinate system (or versioned namespace) with consistent semantics and self-protecting rate-limited versioning, analogous to publish-subscribe addressing schemes for Content Delivery Network (CDN) or Name Data Networking (NDN) schemes.",
        "published": "2022-03-30T09:17:31Z",
        "link": "http://arxiv.org/abs/2204.00470v1",
        "categories": [
            "cs.DC",
            "cs.MA",
            "C.3; E.1; H.2.1; H.2.5; H.1.0"
        ]
    },
    {
        "title": "Hypergraphon Mean Field Games",
        "authors": [
            "Kai Cui",
            "Wasiur R. KhudaBukhsh",
            "Heinz Koeppl"
        ],
        "summary": "We propose an approach to modelling large-scale multi-agent dynamical systems allowing interactions among more than just pairs of agents using the theory of mean field games and the notion of hypergraphons, which are obtained as limits of large hypergraphs. To the best of our knowledge, ours is the first work on mean field games on hypergraphs. Together with an extension to a multi-layer setup, we obtain limiting descriptions for large systems of non-linear, weakly-interacting dynamical agents. On the theoretical side, we prove the well-foundedness of the resulting hypergraphon mean field game, showing both existence and approximate Nash properties. On the applied side, we extend numerical and learning algorithms to compute the hypergraphon mean field equilibria. To verify our approach empirically, we consider a social rumor spreading model, where we give agents intrinsic motivation to spread rumors to unaware agents, and an epidemics control problem.",
        "published": "2022-03-30T11:57:16Z",
        "link": "http://arxiv.org/abs/2203.16223v3",
        "categories": [
            "cs.GT",
            "cs.LG",
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "Multi-Agent Spatial Predictive Control with Application to Drone   Flocking (Extended Version)",
        "authors": [
            "Andreas Brandstätter",
            "Scott A. Smolka",
            "Scott D. Stoller",
            "Ashish Tiwari",
            "Radu Grosu"
        ],
        "summary": "We introduce the novel concept of Spatial Predictive Control (SPC) to solve the following problem: given a collection of agents (e.g., drones) with positional low-level controllers (LLCs) and a mission-specific distributed cost function, how can a distributed controller achieve and maintain cost-function minimization without a plant model and only positional observations of the environment? Our fully distributed SPC controller is based strictly on the position of the agent itself and on those of its neighboring agents. This information is used in every time-step to compute the gradient of the cost function and to perform a spatial look-ahead to predict the best next target position for the LLC. Using a high-fidelity simulation environment, we show that SPC outperforms the most closely related class of controllers, Potential Field Controllers, on the drone flocking problem. We also show that SPC is able to cope with a potential sim-to-real transfer gap by demonstrating its performance on real hardware, namely our implementation of flocking using nine Crazyflie 2.1 drones.",
        "published": "2022-03-31T11:29:35Z",
        "link": "http://arxiv.org/abs/2203.16960v1",
        "categories": [
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Sequential Cooperative Energy and Time-Optimal Lane Change Maneuvers for   Highway Traffic",
        "authors": [
            "Andres S. Chavez Armijos",
            "Rui Chen",
            "Christos G. Cassandras",
            "Yasir K. Al-Nadawi",
            "Hossein Noukhiz Mahjoub",
            "Hidekazu Araki"
        ],
        "summary": "We derive optimal control policies for a Connected Automated Vehicle (CAV) and cooperating neighboring CAVs to carry out a lane change maneuver consisting of a longitudinal phase where the CAV properly positions itself relative to the cooperating neighbors and a lateral phase where it safely changes lanes. In contrast to prior work on this problem, where the CAV \"selfishly\" seeks to minimize its maneuver time, we seek to ensure that the fast-lane traffic flow is minimally disrupted (through a properly defined metric) and that highway throughput is improved by optimally selecting the cooperating vehicles. We show that analytical solutions for the optimal trajectories can be derived and are guaranteed to satisfy safety constraints for all vehicles involved in the maneuver. When feasible solutions do not exist, we include a time relaxation method trading off a longer maneuver time with reduced disruption. Our analysis is also extended to multiple sequential maneuvers. Simulation results where the controllers are implemented show their effectiveness in terms of safety guarantees and up to 35% throughput improvement compared to maneuvers with no vehicle cooperation.",
        "published": "2022-03-31T15:21:20Z",
        "link": "http://arxiv.org/abs/2203.17102v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Diffusion of Information on Networked Lattices by Gossip",
        "authors": [
            "Hans Riess",
            "Robert Ghrist"
        ],
        "summary": "We study time-dependent dynamics on a network of order lattices, where structure-preserving lattice maps are used to fuse lattice-valued data over vertices and edges. The principal contribution is a novel asynchronous Laplacian, generalizing the usual graph Laplacian, adapted to a network of heterogeneous lattices. The resulting gossip algorithm is shown to converge asymptotically to stable \"harmonic\" distributions of lattice data. This general theorem is applicable to several general problems, including lattice-valued consensus, Kripke semantics, and threat detection, all using asynchronous local update rules.",
        "published": "2022-04-01T02:27:20Z",
        "link": "http://arxiv.org/abs/2204.00167v2",
        "categories": [
            "cs.MA",
            "math.AT",
            "93C65, 93A16, 03B42, 03B42"
        ]
    },
    {
        "title": "Fusing Interpretable Knowledge of Neural Network Learning Agents For   Swarm-Guidance",
        "authors": [
            "Duy Tung Nguyen",
            "Kathryn Kasmarik",
            "Hussein Abbass"
        ],
        "summary": "Neural-based learning agents make decisions using internal artificial neural networks. In certain situations, it becomes pertinent that this knowledge is re-interpreted in a friendly form to both the human and the machine. These situations include: when agents are required to communicate the knowledge they learn to each other in a transparent way in the presence of an external human observer, in human-machine teaming settings where humans and machines need to collaborate on a task, or where there is a requirement to verify the knowledge exchanged between the agents. We propose an interpretable knowledge fusion framework suited for neural-based learning agents, and propose a Priority on Weak State Areas (PoWSA) retraining technique. We first test the proposed framework on a synthetic binary classification task before evaluating it on a shepherding-based multi-agent swarm guidance task. Results demonstrate that the proposed framework increases the success rate on the swarm-guidance environment by 11% and better stability in return for a modest increase in computational cost of 14.5% to achieve interpretability. Moreover, the framework presents the knowledge learnt by an agent in a human-friendly representation, leading to a better descriptive visual representation of an agent's knowledge.",
        "published": "2022-04-01T08:07:41Z",
        "link": "http://arxiv.org/abs/2204.00272v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Robust and Efficient Aggregation for Distributed Learning",
        "authors": [
            "Stefan Vlaski",
            "Christian Schroth",
            "Michael Muma",
            "Abdelhak M. Zoubir"
        ],
        "summary": "Distributed learning paradigms, such as federated and decentralized learning, allow for the coordination of models across a collection of agents, and without the need to exchange raw data. Instead, agents compute model updates locally based on their available data, and subsequently share the update model with a parameter server or their peers. This is followed by an aggregation step, which traditionally takes the form of a (weighted) average. Distributed learning schemes based on averaging are known to be susceptible to outliers. A single malicious agent is able to drive an averaging-based distributed learning algorithm to an arbitrarily poor model. This has motivated the development of robust aggregation schemes, which are based on variations of the median and trimmed mean. While such procedures ensure robustness to outliers and malicious behavior, they come at the cost of significantly reduced sample efficiency. This means that current robust aggregation schemes require significantly higher agent participation rates to achieve a given level of performance than their mean-based counterparts in non-contaminated settings. In this work we remedy this drawback by developing statistically efficient and robust aggregation schemes for distributed learning.",
        "published": "2022-04-01T17:17:41Z",
        "link": "http://arxiv.org/abs/2204.00586v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Byzantine-Robust Federated Linear Bandits",
        "authors": [
            "Ali Jadbabaie",
            "Haochuan Li",
            "Jian Qian",
            "Yi Tian"
        ],
        "summary": "In this paper, we study a linear bandit optimization problem in a federated setting where a large collection of distributed agents collaboratively learn a common linear bandit model. Standard federated learning algorithms applied to this setting are vulnerable to Byzantine attacks on even a small fraction of agents. We propose a novel algorithm with a robust aggregation oracle that utilizes the geometric median. We prove that our proposed algorithm is robust to Byzantine attacks on fewer than half of agents and achieves a sublinear $\\tilde{\\mathcal{O}}({T^{3/4}})$ regret with $\\mathcal{O}(\\sqrt{T})$ steps of communication in $T$ steps. Moreover, we make our algorithm differentially private via a tree-based mechanism. Finally, if the level of corruption is known to be small, we show that using the geometric median of mean oracle for robust aggregation further improves the regret bound.",
        "published": "2022-04-03T20:22:26Z",
        "link": "http://arxiv.org/abs/2204.01155v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Best-Response Bayesian Reinforcement Learning with Bayes-adaptive POMDPs   for Centaurs",
        "authors": [
            "Mustafa Mert Çelikok",
            "Frans A. Oliehoek",
            "Samuel Kaski"
        ],
        "summary": "Centaurs are half-human, half-AI decision-makers where the AI's goal is to complement the human. To do so, the AI must be able to recognize the goals and constraints of the human and have the means to help them. We present a novel formulation of the interaction between the human and the AI as a sequential game where the agents are modelled using Bayesian best-response models. We show that in this case the AI's problem of helping bounded-rational humans make better decisions reduces to a Bayes-adaptive POMDP. In our simulated experiments, we consider an instantiation of our framework for humans who are subjectively optimistic about the AI's future behaviour. Our results show that when equipped with a model of the human, the AI can infer the human's bounds and nudge them towards better decisions. We discuss ways in which the machine can learn to improve upon its own limitations as well with the help of the human. We identify a novel trade-off for centaurs in partially observable tasks: for the AI's actions to be acceptable to the human, the machine must make sure their beliefs are sufficiently aligned, but aligning beliefs might be costly. We present a preliminary theoretical analysis of this trade-off and its dependence on task structure.",
        "published": "2022-04-03T21:00:51Z",
        "link": "http://arxiv.org/abs/2204.01160v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Monte Carlo Physarum Machine: Characteristics of Pattern Formation in   Continuous Stochastic Transport Networks",
        "authors": [
            "Oskar Elek",
            "Joseph N. Burchett",
            "J. Xavier Prochaska",
            "Angus G. Forbes"
        ],
        "summary": "We present Monte Carlo Physarum Machine: a computational model suitable for reconstructing continuous transport networks from sparse 2D and 3D data. MCPM is a probabilistic generalization of Jones's 2010 agent-based model for simulating the growth of Physarum polycephalum slime mold. We compare MCPM to Jones's work on theoretical grounds, and describe a task-specific variant designed for reconstructing the large-scale distribution of gas and dark matter in the Universe known as the Cosmic web. To analyze the new model, we first explore MCPM's self-patterning behavior, showing a wide range of continuous network-like morphologies -- called \"polyphorms\" -- that the model produces from geometrically intuitive parameters. Applying MCPM to both simulated and observational cosmological datasets, we then evaluate its ability to produce consistent 3D density maps of the Cosmic web. Finally, we examine other possible tasks where MCPM could be useful, along with several examples of fitting to domain-specific data as proofs of concept.",
        "published": "2022-04-04T05:54:41Z",
        "link": "http://arxiv.org/abs/2204.01256v1",
        "categories": [
            "astro-ph.CO",
            "cs.AI",
            "cs.GR",
            "cs.MA",
            "I.2.11; I.6.8; I.3.8"
        ]
    },
    {
        "title": "The Parking Problem: A Game-Theoretic Solution",
        "authors": [
            "Giuseppe Calise",
            "Aniello Murano",
            "Silvia Stranieri"
        ],
        "summary": "In this paper, we propose a game-theoretic solution to the parking problem, by exploiting a strategic-reasoning approach for multi-agent systems. Precisely, cars are modeled by agents interacting among them in a multi-player game setting, whose aim is to get a free slot parking-place satisfying their own constraints. The overall assignment is then given as a Nash equilibrium solution. We come up with an algorithm (and its implementation in a tool) that works in quadratic time. We give evidence of the benefits of our approach by running our tool on a large hospital parking space.",
        "published": "2022-04-04T11:27:01Z",
        "link": "http://arxiv.org/abs/2204.01395v1",
        "categories": [
            "cs.MA",
            "cs.GT"
        ]
    },
    {
        "title": "Automated generalisation of buildings using CartAGen platform",
        "authors": [
            "Jagadish Boodala",
            "Onkar Dikshit",
            "Nagarajan Balasubramanian"
        ],
        "summary": "In this paper, we present a methodology to automatically derive the generalised representations of buildings at scales 1:25K, 1:50K, and to delineate the urban area for 1:250K scale representation. These generalised representations are derived from 1:10K scale. The automatic generalisation processes are realised using the specific algorithms and the generalisation models available in the CartAGen (CARTographic Agent GENeralisation) platform. The CartAGen is an open source map generalisation platform developed by IGN France. The proposed methodology in this paper is evaluated using the data products available from the Ordnance Survey, UK, and the Survey of India, India. This study investigates the applicability of the CartAGen platform for generalising the data products which have been excluded from the investigations by IGN France. This paper discusses the modifications required for such data products.",
        "published": "2022-04-04T14:51:29Z",
        "link": "http://arxiv.org/abs/2204.01544v1",
        "categories": [
            "cs.MA",
            "cs.DB"
        ]
    },
    {
        "title": "Distributed Anomaly Detection and Estimation over Sensor Networks:   Observational-Equivalence and Q-Redundant Observer Design",
        "authors": [
            "Mohammadreza Doostmohammadian",
            "Themistoklis Charalambous"
        ],
        "summary": "In this paper, we study stateless and stateful physics-based anomaly detection scenarios via distributed estimation over sensor networks. In the stateful case, the detector keeps track of the sensor residuals (i.e., the difference of estimated and true outputs) and reports an alarm if certain statistics of the recorded residuals deviate over a predefined threshold, e.g., \\chi^2 (Chi-square) detector. Instead, only instantaneous deviation of the residuals raises the alarm in the stateless case without considering the history of the sensor outputs and estimation data. Given (approximate) false-alarm rate for both cases, we propose a probabilistic threshold design based on the noise statistics. We show by simulation that increasing the window length in the stateful case may not necessarily reduce the false-alarm rate. On the other hand, it adds unwanted delay to raise the alarm. The distributed aspect of the proposed detection algorithm enables local isolation of the faulty sensors with possible recovery solutions by adding redundant observationally-equivalent sensors. We, then, offer a mechanism to design Q-redundant distributed observers, robust to failure (or removal) of up to Q sensors over the network.",
        "published": "2022-04-04T14:56:30Z",
        "link": "http://arxiv.org/abs/2204.01549v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY",
            "eess.SP",
            "math.OC"
        ]
    },
    {
        "title": "Multi-Agent Distributed Reinforcement Learning for Making Decentralized   Offloading Decisions",
        "authors": [
            "Jing Tan",
            "Ramin Khalili",
            "Holger Karl",
            "Artur Hecker"
        ],
        "summary": "We formulate computation offloading as a decentralized decision-making problem with autonomous agents. We design an interaction mechanism that incentivizes agents to align private and system goals by balancing between competition and cooperation. The mechanism provably has Nash equilibria with optimal resource allocation in the static case. For a dynamic environment, we propose a novel multi-agent online learning algorithm that learns with partial, delayed and noisy state information, and a reward signal that reduces information need to a great extent. Empirical results confirm that through learning, agents significantly improve both system and individual performance, e.g., 40% offloading failure rate reduction, 32% communication overhead reduction, up to 38% computation resource savings in low contention, 18% utilization increase with reduced load variation in high contention, and improvement in fairness. Results also confirm the algorithm's good convergence and generalization property in significantly different environments.",
        "published": "2022-04-05T15:01:48Z",
        "link": "http://arxiv.org/abs/2204.02267v1",
        "categories": [
            "cs.MA",
            "cs.GT",
            "cs.LG"
        ]
    },
    {
        "title": "Deep Interactive Motion Prediction and Planning: Playing Games with   Motion Prediction Models",
        "authors": [
            "Jose L. Vazquez",
            "Alexander Liniger",
            "Wilko Schwarting",
            "Daniela Rus",
            "Luc Van Gool"
        ],
        "summary": "In most classical Autonomous Vehicle (AV) stacks, the prediction and planning layers are separated, limiting the planner to react to predictions that are not informed by the planned trajectory of the AV. This work presents a module that tightly couples these layers via a game-theoretic Model Predictive Controller (MPC) that uses a novel interactive multi-agent neural network policy as part of its predictive model. In our setting, the MPC planner considers all the surrounding agents by informing the multi-agent policy with the planned state sequence. Fundamental to the success of our method is the design of a novel multi-agent policy network that can steer a vehicle given the state of the surrounding agents and the map information. The policy network is trained implicitly with ground-truth observation data using backpropagation through time and a differentiable dynamics model to roll out the trajectory forward in time. Finally, we show that our multi-agent policy network learns to drive while interacting with the environment, and, when combined with the game-theoretic MPC planner, can successfully generate interactive behaviors.",
        "published": "2022-04-05T17:58:18Z",
        "link": "http://arxiv.org/abs/2204.02392v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Deep Graphic FBSDEs for Opinion Dynamics Stochastic Control",
        "authors": [
            "Tianrong Chen",
            "Ziyi Wang",
            "Evangelos A. Theodorou"
        ],
        "summary": "In this paper, we present a scalable deep learning approach to solve opinion dynamics stochastic optimal control problems with mean field term coupling in the dynamics and cost function. Our approach relies on the probabilistic representation of the solution of the Hamilton-Jacobi-Bellman partial differential equation. Grounded on the nonlinear version of the Feynman-Kac lemma, the solutions of the Hamilton-Jacobi-Bellman partial differential equation are linked to the solution of Forward-Backward Stochastic Differential Equations. These equations can be solved numerically using a novel deep neural network with architecture tailored to the problem in consideration. The resulting algorithm is tested on a polarized opinion consensus experiment. The large-scale (10K) agents experiment validates the scalability and generalizability of our algorithm. The proposed framework opens up the possibility for future applications on extremely large-scale problems.",
        "published": "2022-04-05T22:07:32Z",
        "link": "http://arxiv.org/abs/2204.02506v3",
        "categories": [
            "cs.MA",
            "cs.LG"
        ]
    },
    {
        "title": "On the Impact of Social Media Recommendations on Opinion Consensus",
        "authors": [
            "Vincenzo Auletta",
            "Antonio Coppola",
            "Diodato Ferraioli"
        ],
        "summary": "We consider a discrete opinion formation problem in a setting where agents are influenced by both information diffused by their social relations and from recommendations received directly from the social media manager. We study how the \"strength\" of the influence of the social media and the homophily ratio affect the probability of the agents of reaching a consensus and how these factors can determine the type of consensus reached. In a simple 2-symmetric block model we prove that agents converge either to a consensus or to a persistent disagreement. In particular, we show that when the homophily ratio is large, the social media has a very low capacity of determining the outcome of the opinion dynamics. On the other hand, when the homophily ratio is low, the social media influence can have an important role on the dynamics, either by making harder to reach a consensus or inducing it on extreme opinions. Finally, in order to extend our analysis to more general and realistic settings we give some experimental evidences that our results still hold on general networks.",
        "published": "2022-04-07T09:01:42Z",
        "link": "http://arxiv.org/abs/2204.03299v2",
        "categories": [
            "cs.SI",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Robust Event-Driven Interactions in Cooperative Multi-Agent Learning",
        "authors": [
            "Daniel Jarne Ornia",
            "Manuel Mazo Jr"
        ],
        "summary": "We present an approach to reduce the communication required between agents in a Multi-Agent learning system by exploiting the inherent robustness of the underlying Markov Decision Process. We compute so-called robustness surrogate functions (off-line), that give agents a conservative indication of how far their state measurements can deviate before they need to update other agents in the system. This results in fully distributed decision functions, enabling agents to decide when it is necessary to update others. We derive bounds on the optimality of the resulting systems in terms of the discounted sum of rewards obtained, and show these bounds are a function of the design parameters. Additionally, we extend the results for the case where the robustness surrogate functions are learned from data, and present experimental results demonstrating a significant reduction in communication events between agents.",
        "published": "2022-04-07T11:00:39Z",
        "link": "http://arxiv.org/abs/2204.03361v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Distributed Reinforcement Learning for Robot Teams: A Review",
        "authors": [
            "Yutong Wang",
            "Mehul Damani",
            "Pamela Wang",
            "Yuhong Cao",
            "Guillaume Sartoretti"
        ],
        "summary": "Purpose of review: Recent advances in sensing, actuation, and computation have opened the door to multi-robot systems consisting of hundreds/thousands of robots, with promising applications to automated manufacturing, disaster relief, harvesting, last-mile delivery, port/airport operations, or search and rescue. The community has leveraged model-free multi-agent reinforcement learning (MARL) to devise efficient, scalable controllers for multi-robot systems (MRS). This review aims to provide an analysis of the state-of-the-art in distributed MARL for multi-robot cooperation.   Recent findings: Decentralized MRS face fundamental challenges, such as non-stationarity and partial observability. Building upon the \"centralized training, decentralized execution\" paradigm, recent MARL approaches include independent learning, centralized critic, value decomposition, and communication learning approaches. Cooperative behaviors are demonstrated through AI benchmarks and fundamental real-world robotic capabilities such as multi-robot motion/path planning.   Summary: This survey reports the challenges surrounding decentralized model-free MARL for multi-robot cooperation and existing classes of approaches. We present benchmarks and robotic applications along with a discussion on current open avenues for research.",
        "published": "2022-04-07T15:34:19Z",
        "link": "http://arxiv.org/abs/2204.03516v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Capacity Analysis of Intersections When CAVs Crossing in a Collaborative   and Lane-Free Order",
        "authors": [
            "Mahdi Amouzadi",
            "Mobolaji Olawumi Orisatoki",
            "Arash M. Dizqah"
        ],
        "summary": "Connected and autonomous vehicles (CAVs) improve the throughput of intersections by crossing in a lane-free order as compared to the signalised crossing of human drivers. However, it is challenging to quantify such an improvement because the available frameworks to analyse the capacity (i.e., the maximum throughput) of the conventional intersections does not apply to the lane-free ones. This paper proposes a novel theoretical framework to numerically simulate and compare the capacity of lane-free and conventional intersections. The results show that the maximum number of vehicles passing through a lane-free intersection is up to seven times more than a signalised intersection managed by the state-of-the-art max-pressure and Webster algorithms. A sensitivity analysis shows that, in contrast to the signalised intersections, the capacity of the lane-free intersections improves by an increase in initial speed, the maximum permissible speed and acceleration of vehicles.",
        "published": "2022-04-07T16:22:18Z",
        "link": "http://arxiv.org/abs/2204.03550v2",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY",
            "math.OC"
        ]
    },
    {
        "title": "MA-Dreamer: Coordination and communication through shared imagination",
        "authors": [
            "Kenzo Lobos-Tsunekawa",
            "Akshay Srinivasan",
            "Michael Spranger"
        ],
        "summary": "Multi-agent RL is rendered difficult due to the non-stationary nature of environment perceived by individual agents. Theoretically sound methods using the REINFORCE estimator are impeded by its high-variance, whereas value-function based methods are affected by issues stemming from their ad-hoc handling of situations like inter-agent communication. Methods like MADDPG are further constrained due to their requirement of centralized critics etc. In order to address these issues, we present MA-Dreamer, a model-based method that uses both agent-centric and global differentiable models of the environment in order to train decentralized agents' policies and critics using model-rollouts a.k.a `imagination'. Since only the model-training is done off-policy, inter-agent communication/coordination and `language emergence' can be handled in a straight-forward manner. We compare the performance of MA-Dreamer with other methods on two soccer-based games. Our experiments show that in long-term speaker-listener tasks and in cooperative games with strong partial-observability, MA-Dreamer finds a solution that makes effective use of coordination, whereas competing methods obtain marginal scores and fail outright, respectively. By effectively achieving coordination and communication under more relaxed and general conditions, out method opens the door to the study of more complex problems and population-based training.",
        "published": "2022-04-10T13:54:26Z",
        "link": "http://arxiv.org/abs/2204.04687v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "A-DRIVE: Autonomous Deadlock Detection and Recovery at Road   Intersections for Connected and Automated Vehicles",
        "authors": [
            "Shunsuke Aoki",
            "Ragunathan",
            "Rajkumar"
        ],
        "summary": "Connected and Automated Vehicles (CAVs) are highly expected to improve traffic throughput and safety at road intersections, single-track lanes, and construction zones. However, multiple CAVs can block each other and create a mutual deadlock around these road segments (i) when vehicle systems have a failure, such as a communication failure, control failure, or localization failure and/or (ii) when vehicles use a long shared road segment. In this paper, we present an Autonomous Deadlock Detection and Recovery Protocol at Intersections for Automated Vehicles named A-DRIVE that is a decentralized and time-sensitive technique to improve traffic throughput and shorten worst-case recovery time. To enable the deadlock recovery with automated vehicles and with human-driven vehicles, A-DRIVE includes two components: V2V communication-based A-DRIVE and Local perception-based A-DRIVE. V2V communication-based A-DRIVE is designed for homogeneous traffic environments in which all the vehicles are connected and automated. Local perception-based A-DRIVE is for mixed traffic, where CAVs, non-connected automated vehicles, and human-driven vehicles co-exist and cooperate with one another. Since these two components are not exclusive, CAVs inclusively and seamlessly use them in practice. Finally, our simulation results show that A-DRIVE improves traffic throughput compared to a baseline protocol.",
        "published": "2022-04-11T07:19:50Z",
        "link": "http://arxiv.org/abs/2204.04910v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "A Finite-State Fixed-Corridor Model for UAS Traffic Management",
        "authors": [
            "Hamid Emadi",
            "Ella Atkins",
            "Hossein Rastgoftar"
        ],
        "summary": "This paper proposes a physics-inspired solution for low altitude Unmanned Aircraft System (UAS) Traffic Management (UTM) in urban areas. We decompose UTM into spatial and temporal planning problems. For the spatial planning problem, we use the principles of Eulerian continuum mechanics to safely and optimally allocate finite airspace to a UAS. To this end, the finite airspace is partitioned into planned and unplanned subspaces with unplanned subspace(s) or zone(s) enclosing buildings and restricted no-fly regions. The planned subspace is divided into navigable channels that safely wrap unplanned zone(s). We model the airspace planning problem as a Markov Decision Process (MDP) with states defined based on spatial and temporal airspace features and actions authorizing transitions between safe navigable channels. We apply the proposed traffic management solution to plan safe coordination of small UAS in the airspace above downtown Tucson, Arizona.",
        "published": "2022-04-12T04:06:25Z",
        "link": "http://arxiv.org/abs/2204.05517v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "An Analysis of Discretization Methods for Communication Learning with   Multi-Agent Reinforcement Learning",
        "authors": [
            "Astrid Vanneste",
            "Simon Vanneste",
            "Kevin Mets",
            "Tom De Schepper",
            "Siegfried Mercelis",
            "Steven Latré",
            "Peter Hellinckx"
        ],
        "summary": "Communication is crucial in multi-agent reinforcement learning when agents are not able to observe the full state of the environment. The most common approach to allow learned communication between agents is the use of a differentiable communication channel that allows gradients to flow between agents as a form of feedback. However, this is challenging when we want to use discrete messages to reduce the message size since gradients cannot flow through a discrete communication channel. Previous work proposed methods to deal with this problem. However, these methods are tested in different communication learning architectures and environments, making it hard to compare them. In this paper, we compare several state-of-the-art discretization methods as well as two methods that have not been used for communication learning before. We do this comparison in the context of communication learning using gradients from other agents and perform tests on several environments. Our results show that none of the methods is best in all environments. The best choice in discretization method greatly depends on the environment. However, the discretize regularize unit (DRU), straight through DRU and the straight through gumbel softmax show the most consistent results across all the tested environments. Therefore, these methods prove to be the best choice for general use while the straight through estimator and the gumbel softmax may provide better results in specific environments but fail completely in others.",
        "published": "2022-04-12T09:54:58Z",
        "link": "http://arxiv.org/abs/2204.05669v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Improving generalization to new environments and removing catastrophic   forgetting in Reinforcement Learning by using an eco-system of agents",
        "authors": [
            "Olivier Moulin",
            "Vincent Francois-Lavet",
            "Paul Elbers",
            "Mark Hoogendoorn"
        ],
        "summary": "Adapting a Reinforcement Learning (RL) agent to an unseen environment is a difficult task due to typical over-fitting on the training environment. RL agents are often capable of solving environments very close to the trained environment, but when environments become substantially different, their performance quickly drops. When agents are retrained on new environments, a second issue arises: there is a risk of catastrophic forgetting, where the performance on previously seen environments is seriously hampered. This paper proposes a novel approach that exploits an eco-system of agents to address both concerns. Hereby, the (limited) adaptive power of individual agents is harvested to build a highly adaptive eco-system.",
        "published": "2022-04-13T17:52:54Z",
        "link": "http://arxiv.org/abs/2204.06550v2",
        "categories": [
            "cs.AI",
            "cs.MA",
            "I.2.11"
        ]
    },
    {
        "title": "Agent-based Constraint Solving for Resource Allocation in Manycore   Systems",
        "authors": [
            "Volker Wenzel",
            "Lars Bauer",
            "Wolfgang Schröder-Preikschat",
            "Jörg Henkel"
        ],
        "summary": "For efficiency reasons, manycore systems are increasingly heterogeneous, which makes the mapping of complex workloads a key problem with a high optimization potential. Constraints express the application requirements like which core type to choose, how many cores to choose, exclusively or non-exclusively, using a certain core, etc. In this work, we propose a decentralized solution for solving application resource constraints by means of an agent-based approach in order to obtain scalability. We translate the constraints into a Distributed Constraint Optimization Problem (DCOP) and propose a local search algorithm RESMGM to solve them. For the first time, we demonstrate the viability and efficiency of the DCOP approach for heterogeneous manycore systems. Our RESMGM algorithm supports a far wider range of constraints than state-of-the-art, leading to superior results, but still has comparable overheads w.r.t. computation and communication.",
        "published": "2022-04-13T18:49:12Z",
        "link": "http://arxiv.org/abs/2204.06603v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "On Scheduling Mechanisms Beyond the Worst Case",
        "authors": [
            "Yansong Gao",
            "Jie Zhang"
        ],
        "summary": "The problem of scheduling unrelated machines has been studied since the inception of algorithmic mechanism design \\cite{NR99}. It is a resource allocation problem that entails assigning $m$ tasks to $n$ machines for execution. Machines are regarded as strategic agents who may lie about their execution costs so as to minimize their allocated workload. To address the situation when monetary payment is not an option to compensate the machines' costs, \\citeauthor{DBLP:journals/mst/Koutsoupias14} [2014] devised two \\textit{truthful} mechanisms, K and P respectively, that achieve an approximation ratio of $\\frac{n+1}{2}$ and $n$, for social cost minimization. In addition, no truthful mechanism can achieve an approximation ratio better than $\\frac{n+1}{2}$. Hence, mechanism K is optimal. While approximation ratio provides a strong worst-case guarantee, it also limits us to a comprehensive understanding of mechanism performance on various inputs. This paper investigates these two scheduling mechanisms beyond the worst case. We first show that mechanism K achieves a smaller social cost than mechanism P on every input. That is, mechanism K is pointwise better than mechanism P. Next, for each task $j$, when machines' execution costs $t_i^j$ are independent and identically drawn from a task-specific distribution $F^j(t)$, we show that the average-case approximation ratio of mechanism K converges to a constant. This bound is tight for mechanism K. For a better understanding of this distribution dependent constant, on the one hand, we estimate its value by plugging in a few common distributions; on the other, we show that this converging bound improves a known bound \\cite{DBLP:conf/aaai/Zhang18} which only captures the single-task setting. Last, we find that the average-case approximation ratio of mechanism P converges to the same constant.",
        "published": "2022-04-14T20:57:50Z",
        "link": "http://arxiv.org/abs/2204.07223v2",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Methodical Advice Collection and Reuse in Deep Reinforcement Learning",
        "authors": [
            "Sahir",
            "Ercüment İlhan",
            "Srijita Das",
            "Matthew E. Taylor"
        ],
        "summary": "Reinforcement learning (RL) has shown great success in solving many challenging tasks via use of deep neural networks. Although using deep learning for RL brings immense representational power, it also causes a well-known sample-inefficiency problem. This means that the algorithms are data-hungry and require millions of training samples to converge to an adequate policy. One way to combat this issue is to use action advising in a teacher-student framework, where a knowledgeable teacher provides action advice to help the student. This work considers how to better leverage uncertainties about when a student should ask for advice and if the student can model the teacher to ask for less advice. The student could decide to ask for advice when it is uncertain or when both it and its model of the teacher are uncertain. In addition to this investigation, this paper introduces a new method to compute uncertainty for a deep RL agent using a secondary neural network. Our empirical results show that using dual uncertainties to drive advice collection and reuse may improve learning performance across several Atari games.",
        "published": "2022-04-14T22:24:55Z",
        "link": "http://arxiv.org/abs/2204.07254v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Machine Learning Approaches to Automated Mechanism Design for Public   Project Problem",
        "authors": [
            "Guanhua Wang"
        ],
        "summary": "Mechanism design is a central research branch in microeconomics. An effective mechanism can significantly improve performance and efficiency of social decisions under desired objectives, such as to maximize social welfare or to maximize revenue for agents. However, mechanism design is challenging for many common models including the public project problem model which we study in this thesis. A typical public project problem is a group of agents crowdfunding a public project (e.g., building a bridge). The mechanism will decide the payment and allocation for each agent (e.g., how much the agent pays, and whether the agent can use it) according to their valuations. The mechanism can be applied to various economic scenarios, including those related to cyber security. There are different constraints and optimized objectives for different public project scenarios (sub-problems), making it unrealistic to design a universal mechanism that fits all scenarios, and designing mechanisms for different settings manually is a taxing job. Therefore, we explore automated mechanism design (AMD) of public project problems under different constraints.   In this thesis, we focus on the public project problem, which includes many sub-problems (excludable/non-excludable, divisible/indivisible, binary/non-binary). We study the classical public project model and extend this model to other related areas such as the zero-day exploit markets. For different sub-problems of the public project problem, we adopt different novel machine learning techniques to design optimal or near-optimal mechanisms via automated mechanism design. We evaluate our mechanisms by theoretical analysis or experimentally comparing our mechanisms against existing mechanisms. The experiments and theoretical results show that our mechanisms are better than state-of-the-art automated or manual mechanisms.",
        "published": "2022-04-15T03:39:48Z",
        "link": "http://arxiv.org/abs/2204.07315v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Knowledge Equivalence in Digital Twins of Intelligent Systems",
        "authors": [
            "Nan Zhang",
            "Rami Bahsoon",
            "Nikos Tziritas",
            "Georgios Theodoropoulos"
        ],
        "summary": "A digital twin contains up-to-date data-driven models of the physical world being studied and can use simulation to optimise the physical world. However, the analysis made by the digital twin is valid and reliable only when the model is equivalent to the physical world. Maintaining such an equivalent model is challenging, especially when the physical systems being modelled are intelligent and autonomous. The paper focuses in particular on digital twin models of intelligent systems where the systems are knowledge-aware but with limited capability. The digital twin improves the acting of the physical system at a meta-level by accumulating more knowledge in the simulated environment. The modelling of such an intelligent physical system requires replicating the knowledge-awareness capability in the virtual space. Novel equivalence maintaining techniques are needed, especially in synchronising the knowledge between the model and the physical system. This paper proposes the notion of knowledge equivalence and an equivalence maintaining approach by knowledge comparison and updates. A quantitative analysis of the proposed approach confirms that compared to state equivalence, knowledge equivalence maintenance can tolerate deviation thus reducing unnecessary updates and achieve more Pareto efficient solutions for the trade-off between update overhead and simulation reliability.",
        "published": "2022-04-15T14:31:17Z",
        "link": "http://arxiv.org/abs/2204.07481v3",
        "categories": [
            "cs.AI",
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "I.6; D.2.11; I.2.4; I.2.11; I.2.6; C.3"
        ]
    },
    {
        "title": "Resource-Aware Distributed Submodular Maximization: A Paradigm for   Multi-Robot Decision-Making",
        "authors": [
            "Zirui Xu",
            "Vasileios Tzoumas"
        ],
        "summary": "Multi-robot decision-making is the process where multiple robots coordinate actions. In this paper, we aim for efficient and effective multi-robot decision-making despite the robots' limited on-board resources and the often resource-demanding complexity of their tasks. We introduce the first algorithm enabling the robots to choose with which few other robots to coordinate and provably balance the trade-off of centralized vs. decentralized coordination. Particularly, centralization favors globally near-optimal decision-making but at the cost of increased on-board resource requirements; whereas, decentralization favors minimal resource requirements but at a global suboptimality cost. All robots can thus afford our algorithm, irrespective of their resources. We are motivated by the future of autonomy that involves multiple robots coordinating actions to complete resource-demanding tasks, such as target tracking, area coverage, and monitoring. To provide closed-form guarantees, we focus on maximization problems involving monotone and \"doubly\" submodular functions. To capture the cost of decentralization, we introduce the notion of Centralization Of Information among non-Neighbors (COIN). We validate our algorithm in simulated scenarios of image covering.",
        "published": "2022-04-15T15:47:05Z",
        "link": "http://arxiv.org/abs/2204.07520v3",
        "categories": [
            "math.OC",
            "cs.AI",
            "cs.MA",
            "cs.RO",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Towards Comprehensive Testing on the Robustness of Cooperative   Multi-agent Reinforcement Learning",
        "authors": [
            "Jun Guo",
            "Yonghong Chen",
            "Yihang Hao",
            "Zixin Yin",
            "Yin Yu",
            "Simin Li"
        ],
        "summary": "While deep neural networks (DNNs) have strengthened the performance of cooperative multi-agent reinforcement learning (c-MARL), the agent policy can be easily perturbed by adversarial examples. Considering the safety critical applications of c-MARL, such as traffic management, power management and unmanned aerial vehicle control, it is crucial to test the robustness of c-MARL algorithm before it was deployed in reality. Existing adversarial attacks for MARL could be used for testing, but is limited to one robustness aspects (e.g., reward, state, action), while c-MARL model could be attacked from any aspect. To overcome the challenge, we propose MARLSafe, the first robustness testing framework for c-MARL algorithms. First, motivated by Markov Decision Process (MDP), MARLSafe consider the robustness of c-MARL algorithms comprehensively from three aspects, namely state robustness, action robustness and reward robustness. Any c-MARL algorithm must simultaneously satisfy these robustness aspects to be considered secure. Second, due to the scarceness of c-MARL attack, we propose c-MARL attacks as robustness testing algorithms from multiple aspects. Experiments on \\textit{SMAC} environment reveals that many state-of-the-art c-MARL algorithms are of low robustness in all aspect, pointing out the urgent need to test and enhance robustness of c-MARL algorithms.",
        "published": "2022-04-17T05:15:51Z",
        "link": "http://arxiv.org/abs/2204.07932v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "On Arbitrary Compression for Decentralized Consensus and Stochastic   Optimization over Directed Networks",
        "authors": [
            "Mohammad Taha Toghani",
            "César A. Uribe"
        ],
        "summary": "We study the decentralized consensus and stochastic optimization problems with compressed communications over static directed graphs. We propose an iterative gradient-based algorithm that compresses messages according to a desired compression ratio. The proposed method provably reduces the communication overhead on the network at every communication round. Contrary to existing literature, we allow for arbitrary compression ratios in the communicated messages. We show a linear convergence rate for the proposed method on the consensus problem. Moreover, we provide explicit convergence rates for decentralized stochastic optimization problems on smooth functions that are either (i) strongly convex, (ii) convex, or (iii) non-convex. Finally, we provide numerical experiments to illustrate convergence under arbitrary compression ratios and the communication efficiency of our algorithm.",
        "published": "2022-04-18T04:41:56Z",
        "link": "http://arxiv.org/abs/2204.08160v1",
        "categories": [
            "math.OC",
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Lane-Free Crossing of CAVs through Intersections as a Minimum-Time   Optimal Control Problem",
        "authors": [
            "Mahdi Amouzadi",
            "Mobolaji Olawumi Orisatoki",
            "Arash M. Dizqah"
        ],
        "summary": "Unlike conventional cars, connected and autonomous vehicles (CAVs) can cross intersections in a lane-free order and utilise the whole area of intersections. This paper presents a minimum-time optimal control problem to centrally control the CAVs to simultaneously cross an intersection in the shortest possible time. Dual problem theory is employed to convexify the constraints of CAVs to avoid collision with each other and with road boundaries. The developed formulation is smooth and solvable by gradient-based algorithms. Simulation results show that the proposed strategy reduces the crossing time of intersections by an average of 52% and 54% as compared to, respectively, the state-of-the-art reservation-based and lane-free methods. Furthermore, the crossing time by the proposed strategy is fixed to a constant value for an intersection regardless of the number of CAVs.",
        "published": "2022-04-18T12:04:57Z",
        "link": "http://arxiv.org/abs/2204.08270v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Multi-UAV Collision Avoidance using Multi-Agent Reinforcement Learning   with Counterfactual Credit Assignment",
        "authors": [
            "Shuangyao Huang",
            "Haibo Zhang",
            "Zhiyi Huang"
        ],
        "summary": "Multi-UAV collision avoidance is a challenging task for UAV swarm applications due to the need of tight cooperation among swarm members for collision-free path planning. Centralized Training with Decentralized Execution (CTDE) in Multi-Agent Reinforcement Learning is a promising method for multi-UAV collision avoidance, in which the key challenge is to effectively learn decentralized policies that can maximize a global reward cooperatively. We propose a new multi-agent critic-actor learning scheme called MACA for UAV swarm collision avoidance. MACA uses a centralized critic to maximize the discounted global reward that considers both safety and energy efficiency, and an actor per UAV to find decentralized policies to avoid collisions. To solve the credit assignment problem in CTDE, we design a counterfactual baseline that marginalizes both an agent's state and action, enabling to evaluate the importance of an agent in the joint observation-action space. To train and evaluate MACA, we design our own simulation environment MACAEnv to closely mimic the realistic behaviors of a UAV swarm. Simulation results show that MACA achieves more than 16% higher average reward than two state-of-the-art MARL algorithms and reduces failure rate by 90% and response time by over 99% compared to a conventional UAV swarm collision avoidance algorithm in all test scenarios.",
        "published": "2022-04-19T00:28:51Z",
        "link": "http://arxiv.org/abs/2204.08594v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Consensus of networked double integrator systems under sensor bias",
        "authors": [
            "Pallavi Sinha",
            "Srikant Sukumar",
            "Himani Sinhmar"
        ],
        "summary": "A novel distributed control law for consensus of networked double integrator systems with biased measurements is developed in this article. The agents measure relative positions over a time-varying, undirected graph with an unknown and constant sensor bias corrupting the measurements. An adaptive control law is derived using Lyapunov methods to estimate the individual sensor biases accurately. The proposed algorithm ensures that position consensus is achieved exponentially in addition to bias estimation. The results leverage recent advances in collective initial excitation based results in adaptive estimation. Conditions connecting bipartite graphs and collective initial excitation are also developed. The algorithms are illustrated via simulation studies on a network of double integrators with local communication and biased measurements.",
        "published": "2022-04-19T04:59:53Z",
        "link": "http://arxiv.org/abs/2204.08666v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Event-triggered Approximate Byzantine Consensus with Multi-hop   Communication",
        "authors": [
            "Liwei Yuan",
            "Hideaki Ishii"
        ],
        "summary": "In this paper, we consider a resilient consensus problem for the multi-agent network where some of the agents are subject to Byzantine attacks and may transmit erroneous state values to their neighbors. In particular, we develop an event-triggered update rule to tackle this problem as well as reduce the communication for each agent. Our approach is based on the mean subsequence reduced (MSR) algorithm with agents being capable to communicate with multi-hop neighbors. Since delays are critical in such an environment, we provide necessary graph conditions for the proposed algorithm to perform well with delays in the communication. We highlight that through multi-hop communication, the network connectivity can be reduced especially in comparison with the common onehop communication case. Lastly, we show the effectiveness of the proposed algorithm by a numerical example.",
        "published": "2022-04-19T13:29:02Z",
        "link": "http://arxiv.org/abs/2204.08883v1",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Massive Twinning to Enhance Emergent Intelligence",
        "authors": [
            "Siyu Yuan",
            "Bin Han",
            "Dennis Krummacker",
            "Hans D. Schotten"
        ],
        "summary": "As a complement to conventional AI solutions, emergent intelligence (EI) exhibits competitiveness in 6G IIoT scenario for its various outstanding features including robustness, protection to privacy, and scalability. However, despite the low computational complexity, EI is challenged by its high demand of data traffic in massive deployment. We propose to leverage massive twinning, which 6G is envisaged to support, to reduce the data traffic in EI and therewith enhance its performance.",
        "published": "2022-04-20T08:51:06Z",
        "link": "http://arxiv.org/abs/2204.09316v2",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Mingling Foresight with Imagination: Model-Based Cooperative Multi-Agent   Reinforcement Learning",
        "authors": [
            "Zhiwei Xu",
            "Dapeng Li",
            "Bin Zhang",
            "Yuan Zhan",
            "Yunpeng Bai",
            "Guoliang Fan"
        ],
        "summary": "Recently, model-based agents have achieved better performance than model-free ones using the same computational budget and training time in single-agent environments. However, due to the complexity of multi-agent systems, it is tough to learn the model of the environment. The significant compounding error may hinder the learning process when model-based methods are applied to multi-agent tasks. This paper proposes an implicit model-based multi-agent reinforcement learning method based on value decomposition methods. Under this method, agents can interact with the learned virtual environment and evaluate the current state value according to imagined future states in the latent space, making agents have the foresight. Our approach can be applied to any multi-agent value decomposition method. The experimental results show that our method improves the sample efficiency in different partially observable Markov decision process domains.",
        "published": "2022-04-20T12:16:27Z",
        "link": "http://arxiv.org/abs/2204.09418v3",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Dynamic Interlining in Bus Operations",
        "authors": [
            "Seyedmostafa Zahedi",
            "Haris N. Koutsopoulos",
            "Zhenliang Ma"
        ],
        "summary": "The paper introduces and evaluates the concept of the dynamic interlining of buses. Dynamic interlining is an operational strategy for routes that have a terminal station at a common hub, that allows a portion of (or all) the fleet to be shared among the routes belonging to the hub (shared fleet) as needed. The shared fleet is dispatched on an on-demand basis to serve scheduled trips on any route to avoid delays and regulate services. The paper examines systematically the impacts of dynamic interlining on service reliability. It formulates the dispatching problem as an optimization problem and uses simulation to evaluate the dynamic interlining strategy under a variety of operating conditions. Using bus routes in Boston Massachusetts Bay Transportation Authority (MBTA) as a case study, the feasibility of the strategy, as well as factors that affect its performance are investigated. Results show that dynamic interlining can improve service reliability (increases on-time departures and decreases departure headways variability at the hub). The fraction of the fleet that is shared has the most dominant impact on performance. In the case where all buses are dynamically interlined, the performance improves as route frequency increases and more routes participate in the strategy.",
        "published": "2022-04-21T08:49:13Z",
        "link": "http://arxiv.org/abs/2204.09971v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Multi-UAV trajectory planning for 3D visual inspection of complex   structures",
        "authors": [
            "Stefan Ivić",
            "Bojan Crnković",
            "Luka Grbčić",
            "Lea Matleković"
        ],
        "summary": "The application of autonomous UAVs to infrastructure inspection tasks provides benefits in terms of operation time reduction, safety, and cost-effectiveness. This paper presents trajectory planning for three-dimensional autonomous multi-UAV volume coverage and visual inspection of infrastructure based on the Heat Equation Driven Area Coverage (HEDAC) algorithm. The method generates trajectories using a potential field and implements distance fields to prevent collisions and to determine UAVs' camera orientation. It successfully achieves coverage during the visual inspection of complex structures such as a wind turbine and a bridge, outperforming a state-of-the-art method by allowing more surface area to be inspected under the same conditions. The presented trajectory planning method offers flexibility in various setup parameters and is applicable to real-world inspection tasks. Conclusively, the proposed methodology could potentially be applied to different autonomous UAV tasks, or even utilized as a UAV motion control method if its computational efficiency is improved.",
        "published": "2022-04-21T12:56:58Z",
        "link": "http://arxiv.org/abs/2204.10070v4",
        "categories": [
            "math.OC",
            "cs.MA",
            "cs.RO",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Distributed stochastic projection-free solver for constrained   optimization",
        "authors": [
            "Xia Jiang",
            "Xianlin Zeng",
            "Lihua Xie",
            "Jian Sun",
            "Jie Chen"
        ],
        "summary": "This paper proposes a distributed stochastic projection-free algorithm for large-scale constrained finite-sum optimization whose constraint set is complicated such that the projection onto the constraint set can be expensive. The global cost function is allocated to multiple agents, each of which computes its local stochastic gradients and communicates with its neighbors to solve the global problem. Stochastic gradient methods enable low computational cost, while they are hard and slow to converge due to the variance caused by random sampling. To construct a convergent distributed stochastic projection-free algorithm, this paper incorporates a variance reduction technique and gradient tracking technique in the Frank-Wolfe update. We develop a sampling rule for the variance reduction technique to reduce the variance introduced by stochastic gradients. Complete and rigorous proofs show that the proposed distributed projection-free algorithm converges with a sublinear convergence rate and enjoys superior complexity guarantees for both convex and non-convex objective functions. By comparative simulations, we demonstrate the convergence and computational efficiency of the proposed algorithm.",
        "published": "2022-04-22T09:48:39Z",
        "link": "http://arxiv.org/abs/2204.10605v1",
        "categories": [
            "math.OC",
            "cs.MA"
        ]
    },
    {
        "title": "Embracing AWKWARD! Real-time Adjustment of Reactive Plans Using Social   Norms",
        "authors": [
            "Leila Methnani",
            "Andreas Antoniades",
            "Andreas Theodorou"
        ],
        "summary": "This paper presents the AWKWARD architecture for the development of hybrid agents in Multi-Agent Systems. AWKWARD agents can have their plans re-configured in real time to align with social role requirements under changing environmental and social circumstances. The proposed hybrid architecture makes use of Behaviour Oriented Design (BOD) to develop agents with reactive planning and of the well-established OperA framework to provide organisational, social, and interaction definitions in order to validate and adjust agents' behaviours. Together, OperA and BOD can achieve real-time adjustment of agent plans for evolving social roles, while providing the additional benefit of transparency into the interactions that drive this behavioural change in individual agents. We present this architecture to motivate the bridging between traditional symbolic- and behaviour-based AI communities, where such combined solutions can help MAS researchers in their pursuit of building stronger, more robust intelligent agent teams. We use DOTA2, a game where success is heavily dependent on social interactions, as a medium to demonstrate a sample implementation of our proposed hybrid architecture.",
        "published": "2022-04-22T15:02:08Z",
        "link": "http://arxiv.org/abs/2204.10740v3",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "The Boltzmann Policy Distribution: Accounting for Systematic   Suboptimality in Human Models",
        "authors": [
            "Cassidy Laidlaw",
            "Anca Dragan"
        ],
        "summary": "Models of human behavior for prediction and collaboration tend to fall into two categories: ones that learn from large amounts of data via imitation learning, and ones that assume human behavior to be noisily-optimal for some reward function. The former are very useful, but only when it is possible to gather a lot of human data in the target environment and distribution. The advantage of the latter type, which includes Boltzmann rationality, is the ability to make accurate predictions in new environments without extensive data when humans are actually close to optimal. However, these models fail when humans exhibit systematic suboptimality, i.e. when their deviations from optimal behavior are not independent, but instead consistent over time. Our key insight is that systematic suboptimality can be modeled by predicting policies, which couple action choices over time, instead of trajectories. We introduce the Boltzmann policy distribution (BPD), which serves as a prior over human policies and adapts via Bayesian inference to capture systematic deviations by observing human actions during a single episode. The BPD is difficult to compute and represent because policies lie in a high-dimensional continuous space, but we leverage tools from generative and sequence models to enable efficient sampling and inference. We show that the BPD enables prediction of human behavior and human-AI collaboration equally as well as imitation learning-based human models while using far less data.",
        "published": "2022-04-22T15:26:25Z",
        "link": "http://arxiv.org/abs/2204.10759v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Competitive Physics Informed Networks",
        "authors": [
            "Qi Zeng",
            "Yash Kothari",
            "Spencer H. Bryngelson",
            "Florian Schäfer"
        ],
        "summary": "Neural networks can be trained to solve partial differential equations (PDEs) by using the PDE residual as the loss function. This strategy is called \"physics-informed neural networks\" (PINNs), but it currently cannot produce high-accuracy solutions, typically attaining about $0.1\\%$ relative error. We present an adversarial approach that overcomes this limitation, which we call competitive PINNs (CPINNs). CPINNs train a discriminator that is rewarded for predicting mistakes the PINN makes. The discriminator and PINN participate in a zero-sum game with the exact PDE solution as an optimal strategy. This approach avoids squaring the large condition numbers of PDE discretizations, which is the likely reason for failures of previous attempts to decrease PINN errors even on benign problems. Numerical experiments on a Poisson problem show that CPINNs achieve errors four orders of magnitude smaller than the best-performing PINN. We observe relative errors on the order of single-precision accuracy, consistently decreasing with each epoch. To the authors' knowledge, this is the first time this level of accuracy and convergence behavior has been achieved. Additional experiments on the nonlinear Schr\\\"odinger, Burgers', and Allen-Cahn equation show that the benefits of CPINNs are not limited to linear problems.",
        "published": "2022-04-23T22:01:37Z",
        "link": "http://arxiv.org/abs/2204.11144v2",
        "categories": [
            "cs.LG",
            "cs.MA",
            "cs.NA",
            "math.NA",
            "math.OC"
        ]
    },
    {
        "title": "Secure Distributed/Federated Learning: Prediction-Privacy Trade-Off for   Multi-Agent System",
        "authors": [
            "Mohamed Ridha Znaidi",
            "Gaurav Gupta",
            "Paul Bogdan"
        ],
        "summary": "Decentralized learning is an efficient emerging paradigm for boosting the computing capability of multiple bounded computing agents. In the big data era, performing inference within the distributed and federated learning (DL and FL) frameworks, the central server needs to process a large amount of data while relying on various agents to perform multiple distributed training tasks. Considering the decentralized computing topology, privacy has become a first-class concern. Moreover, assuming limited information processing capability for the agents calls for a sophisticated \\textit{privacy-preserving decentralization} that ensures efficient computation. Towards this end, we study the \\textit{privacy-aware server to multi-agent assignment} problem subject to information processing constraints associated with each agent, while maintaining the privacy and assuring learning informative messages received by agents about a global terminal through the distributed private federated learning (DPFL) approach. To find a decentralized scheme for a two-agent system, we formulate an optimization problem that balances privacy and accuracy, taking into account the quality of compression constraints associated with each agent. We propose an iterative converging algorithm by alternating over self-consistent equations. We also numerically evaluate the proposed solution to show the privacy-prediction trade-off and demonstrate the efficacy of the novel approach in ensuring privacy in DL and FL.",
        "published": "2022-04-24T19:19:20Z",
        "link": "http://arxiv.org/abs/2205.04855v1",
        "categories": [
            "cs.MA",
            "cs.CR",
            "cs.IT",
            "cs.LG",
            "math.IT"
        ]
    },
    {
        "title": "Collaborative Auto-Curricula Multi-Agent Reinforcement Learning with   Graph Neural Network Communication Layer for Open-ended Wildfire-Management   Resource Distribution",
        "authors": [
            "Philipp Dominic Siedler"
        ],
        "summary": "Most real-world domains can be formulated as multi-agent (MA) systems. Intentionality sharing agents can solve more complex tasks by collaborating, possibly in less time. True cooperative actions are beneficial for egoistic and collective reasons. However, teaching individual agents to sacrifice egoistic benefits for a better collective performance seems challenging. We build on a recently proposed Multi-Agent Reinforcement Learning (MARL) mechanism with a Graph Neural Network (GNN) communication layer. Rarely chosen communication actions were marginally beneficial. Here we propose a MARL system in which agents can help collaborators perform better while risking low individual performance. We conduct our study in the context of resource distribution for wildfire management. Communicating environmental features and partially observable fire occurrence help the agent collective to pre-emptively distribute resources. Furthermore, we introduce a procedural training environment accommodating auto-curricula and open-endedness towards better generalizability. Our MA communication proposal outperforms a Greedy Heuristic Baseline and a Single-Agent (SA) setup. We further demonstrate how auto-curricula and openendedness improves generalizability of our MA proposal.",
        "published": "2022-04-24T20:13:30Z",
        "link": "http://arxiv.org/abs/2204.11350v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Accelerated Multiplicative Weights Update Avoids Saddle Points almost   always",
        "authors": [
            "Yi Feng",
            "Ioannis Panageas",
            "Xiao Wang"
        ],
        "summary": "We consider non-convex optimization problems with constraint that is a product of simplices. A commonly used algorithm in solving this type of problem is the Multiplicative Weights Update (MWU), an algorithm that is widely used in game theory, machine learning and multi-agent systems. Despite it has been known that MWU avoids saddle points, there is a question that remains unaddressed:\"Is there an accelerated version of MWU that avoids saddle points provably?\" In this paper we provide a positive answer to above question. We provide an accelerated MWU based on Riemannian Accelerated Gradient Descent, and prove that the Riemannian Accelerated Gradient Descent, thus the accelerated MWU, almost always avoid saddle points.",
        "published": "2022-04-25T02:54:05Z",
        "link": "http://arxiv.org/abs/2204.11407v1",
        "categories": [
            "math.OC",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "A Time-Triggered Dimension Reduction Algorithm for the Task Assignment   Problem",
        "authors": [
            "Han Wang",
            "Kostas Margellos",
            "Antonis Papachristodoulou"
        ],
        "summary": "The task assignment problem is fundamental in combinatorial optimisation, aiming at allocating one or more tasks to a number of agents while minimizing the total cost or maximizing the overall assignment benefit. This problem is known to be computationally hard since it is usually formulated as a mixed-integer programming problem. In this paper, we consider a novel time-triggered dimension reduction algorithm (TTDRA). We propose convexification approaches to convexify both the constraints and the cost function for the general non-convex assignment problem. The computational speed is accelerated via our time-triggered dimension reduction scheme, where the triggering condition is designed based on the optimality tolerance and the convexity of the cost function. Optimality and computational efficiency are verified via numerical simulations on benchmark examples.",
        "published": "2022-04-25T07:35:27Z",
        "link": "http://arxiv.org/abs/2204.11476v1",
        "categories": [
            "math.OC",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Travel time optimization on multi-AGV routing by reverse annealing",
        "authors": [
            "Renichiro Haba",
            "Masayuki Ohzeki",
            "Kazuyuki Tanaka"
        ],
        "summary": "Quantum annealing has been actively researched since D-Wave Systems produced the first commercial machine in 2011. Controlling a large fleet of automated guided vehicles is one of the real-world applications utilizing quantum annealing. In this study, we propose a formulation to control the traveling routes to minimize the travel time. We validate our formulation through simulation in a virtual plant and authenticate the effectiveness for faster distribution compared to a greedy algorithm that does not consider the overall detour distance. Furthermore, we utilize reverse annealing to maximize the advantage of the D-Wave's quantum annealer. Starting from relatively good solutions obtained by a fast greedy algorithm, reverse annealing searches for better solutions around them. Our reverse annealing method improves the performance compared to standard quantum annealing alone and performs up to 10 times faster than the strong classical solver, Gurobi. This study extends a use of optimization with general problem solvers in the application of multi-AGV systems and reveals the potential of reverse annealing as an optimizer.",
        "published": "2022-04-25T17:01:56Z",
        "link": "http://arxiv.org/abs/2204.11789v1",
        "categories": [
            "quant-ph",
            "cs.MA",
            "cs.RO",
            "cs.SY",
            "eess.SY",
            "stat.CO"
        ]
    },
    {
        "title": "PP-MARL: Efficient Privacy-Preserving MARL for Cooperative Intelligence   in Communication",
        "authors": [
            "Tingting Yuan",
            "Hwei-Ming Chung",
            "Xiaoming Fu"
        ],
        "summary": "Artificial intelligence (AI) has been introduced in communication networks and services to improve efficiency via self-optimization. Cooperative intelligence (CI), also known as collective intelligence and collaborative intelligence, is expected to become an integral element in next-generation networks because it can aggregate the capabilities and intelligence of multiple devices. However, privacy issues may intimidate, obstruct, and hinder the deployment of CI in practice because collaboration heavily relies on data and information sharing. Additional practical constraints in communication (e.g., limited bandwidth) further limit the performance of CI. To overcome these challenges, we propose PP-MARL, an efficient privacy-preserving learning scheme based on multi-agent reinforcement learning (MARL). We apply and evaluate our scheme in two communication-related use cases: mobility management in drone-assisted communication and network control with edge intelligence. Simulation results reveal that the proposed scheme can achieve efficient and reliable collaboration with 1.1-6 times better privacy protection and lower overheads (e.g., 84-91% reduction in bandwidth) than state-of-the-art approaches.",
        "published": "2022-04-26T04:08:27Z",
        "link": "http://arxiv.org/abs/2204.12064v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.CR",
            "cs.NI"
        ]
    },
    {
        "title": "Know Thy Student: Interactive Learning with Gaussian Processes",
        "authors": [
            "Rose E. Wang",
            "Mike Wu",
            "Noah Goodman"
        ],
        "summary": "Learning often involves interaction between multiple agents. Human teacher-student settings best illustrate how interactions result in efficient knowledge passing where the teacher constructs a curriculum based on their students' abilities. Prior work in machine teaching studies how the teacher should construct optimal teaching datasets assuming the teacher knows everything about the student. However, in the real world, the teacher doesn't have complete information about the student. The teacher must interact and diagnose the student, before teaching. Our work proposes a simple diagnosis algorithm which uses Gaussian processes for inferring student-related information, before constructing a teaching dataset. We apply this to two settings. One is where the student learns from scratch and the teacher must figure out the student's learning algorithm parameters, eg. the regularization parameters in ridge regression or support vector machines. Two is where the student has partially explored the environment and the teacher must figure out the important areas the student has not explored; we study this in the offline reinforcement learning setting where the teacher must provide demonstrations to the student and avoid sending redundant trajectories. Our experiments highlight the importance of diagosing before teaching and demonstrate how students can learn more efficiently with the help of an interactive teacher. We conclude by outlining where diagnosing combined with teaching would be more desirable than passive learning.",
        "published": "2022-04-26T04:43:57Z",
        "link": "http://arxiv.org/abs/2204.12072v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Linear TDOA-based Measurements for Distributed Estimation and Localized   Tracking",
        "authors": [
            "Mohammadreza Doostmohammadian",
            "Themistoklis Charalambous"
        ],
        "summary": "We propose a linear time-difference-of-arrival (TDOA) measurement model to improve \\textit{distributed} estimation performance for localized target tracking. We design distributed filters over sparse (possibly large-scale) communication networks using consensus-based data-fusion techniques. The proposed distributed and localized tracking protocols considerably reduce the sensor network's required connectivity and communication rate. We, further, consider $\\kappa$-redundant observability and fault-tolerant design in case of losing communication links or sensor nodes. We present the minimal conditions on the remaining sensor network (after link/node removal) such that the distributed observability is still preserved and, thus, the sensor network can track the (single) maneuvering target. The motivation is to reduce the communication load versus the processing load, as the computational units are, in general, less costly than the communication devices. We evaluate the tracking performance via simulations in MATLAB.",
        "published": "2022-04-26T13:23:57Z",
        "link": "http://arxiv.org/abs/2204.12298v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.RO",
            "cs.SY",
            "eess.SP",
            "math.DS"
        ]
    },
    {
        "title": "REDCHO: Robust Exact Dynamic Consensus of High Order",
        "authors": [
            "Rodrigo Aldana-López",
            "Rosario Aragüés",
            "Carlos Sagüés"
        ],
        "summary": "This article addresses the problem of average consensus in a multi-agent system when the desired consensus quantity is a time varying signal. Recently, the EDCHO protocol leveraged high order sliding modes to achieve exact consensus under a constrained set of initial conditions, limiting its applicability to static networks. In this work, we propose REDCHO, an extension of the previous protocol which is robust to mismatch in the initial conditions, making it suitable to use cases in which connection and disconnection of agents is possible. The convergence properties of the protocol are formally explored. Finally, the effectiveness and advantages of our proposal are shown with concrete simulation examples showing the benefits of REDCHO against other methods in the literature.",
        "published": "2022-04-26T14:34:43Z",
        "link": "http://arxiv.org/abs/2204.12344v2",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY",
            "math.OC"
        ]
    },
    {
        "title": "Learning Eco-Driving Strategies at Signalized Intersections",
        "authors": [
            "Vindula Jayawardana",
            "Cathy Wu"
        ],
        "summary": "Signalized intersections in arterial roads result in persistent vehicle idling and excess accelerations, contributing to fuel consumption and CO2 emissions. There has thus been a line of work studying eco-driving control strategies to reduce fuel consumption and emission levels at intersections. However, methods to devise effective control strategies across a variety of traffic settings remain elusive. In this paper, we propose a reinforcement learning (RL) approach to learn effective eco-driving control strategies. We analyze the potential impact of a learned strategy on fuel consumption, CO2 emission, and travel time and compare with naturalistic driving and model-based baselines. We further demonstrate the generalizability of the learned policies under mixed traffic scenarios. Simulation results indicate that scenarios with 100% penetration of connected autonomous vehicles (CAV) may yield as high as 18% reduction in fuel consumption and 25% reduction in CO2 emission levels while even improving travel speed by 20%. Furthermore, results indicate that even 25% CAV penetration can bring at least 50% of the total fuel and emission reduction benefits.",
        "published": "2022-04-26T19:45:11Z",
        "link": "http://arxiv.org/abs/2204.12561v1",
        "categories": [
            "eess.SY",
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Evolutionary Multi-Armed Bandits with Genetic Thompson Sampling",
        "authors": [
            "Baihan Lin"
        ],
        "summary": "As two popular schools of machine learning, online learning and evolutionary computations have become two important driving forces behind real-world decision making engines for applications in biomedicine, economics, and engineering fields. Although there are prior work that utilizes bandits to improve evolutionary algorithms' optimization process, it remains a field of blank on how evolutionary approach can help improve the sequential decision making tasks of online learning agents such as the multi-armed bandits. In this work, we propose the Genetic Thompson Sampling, a bandit algorithm that keeps a population of agents and update them with genetic principles such as elite selection, crossover and mutations. Empirical results in multi-armed bandit simulation environments and a practical epidemic control problem suggest that by incorporating the genetic algorithm into the bandit algorithm, our method significantly outperforms the baselines in nonstationary settings. Lastly, we introduce EvoBandit, a web-based interactive visualization to guide the readers through the entire learning process and perform lightweight evaluations on the fly. We hope to engage researchers into this growing field of research with this investigation.",
        "published": "2022-04-26T22:41:17Z",
        "link": "http://arxiv.org/abs/2205.10113v1",
        "categories": [
            "cs.NE",
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Insight into Voting Problem Complexity Using Randomized Classes",
        "authors": [
            "Zack Fitzsimmons",
            "Edith Hemaspaandra"
        ],
        "summary": "The first step in classifying the complexity of an NP problem is typically showing the problem in P or NP-complete. This has been a successful first step for many problems, including voting problems. However, in this paper we show that this may not always be the best first step. We consider the problem of constructive control by replacing voters (CCRV) introduced by Loreggia et al. (2015) for the scoring rule First-Last, which is defined by $\\langle 1, 0, \\dots, 0, -1\\rangle$. We show that this problem is equivalent to Exact Perfect Bipartite Matching, and so CCRV for First-Last can be determined in random polynomial time. So on the one hand, if CCRV for First-Last is NP-complete then RP = NP, which is extremely unlikely. On the other hand, showing that CCRV for First-Last is in P would also show that Exact Perfect Bipartite Matching is in P, which would solve a well-studied 40-year-old open problem.   By considering RP as an option we also gain insight into the complexity of CCRV for 2-Approval, ultimately showing it in P, which settles the complexity of the sole open problem in the comprehensive table from Erd\\'{e}lyi et al. (2021).",
        "published": "2022-04-27T11:39:43Z",
        "link": "http://arxiv.org/abs/2204.12856v2",
        "categories": [
            "cs.GT",
            "cs.CC",
            "cs.MA"
        ]
    },
    {
        "title": "On the role of population heterogeneity in emergent communication",
        "authors": [
            "Mathieu Rita",
            "Florian Strub",
            "Jean-Bastien Grill",
            "Olivier Pietquin",
            "Emmanuel Dupoux"
        ],
        "summary": "Populations have often been perceived as a structuring component for language to emerge and evolve: the larger the population, the more structured the language. While this observation is widespread in the sociolinguistic literature, it has not been consistently reproduced in computer simulations with neural agents. In this paper, we thus aim to clarify this apparent contradiction. We explore emergent language properties by varying agent population size in the speaker-listener Lewis Game. After reproducing the experimental difference, we challenge the simulation assumption that the agent community is homogeneous. We first investigate how speaker-listener asymmetry alters language structure to examine two potential diversity factors: training speed and network capacity. We find out that emergent language properties are only altered by the relative difference of learning speeds between speaker and listener, and not by their absolute values. From then, we leverage this observation to control population heterogeneity without introducing confounding factors. We finally show that introducing such training speed heterogeneities naturally sort out the initial contradiction: larger simulated communities start developing more stable and structured languages.",
        "published": "2022-04-27T14:45:36Z",
        "link": "http://arxiv.org/abs/2204.12982v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Hierarchical Control for Cooperative Teams in Competitive Autonomous   Racing",
        "authors": [
            "Rishabh Saumil Thakkar",
            "Aryaman Singh Samyal",
            "David Fridovich-Keil",
            "Zhe Xu",
            "Ufuk Topcu"
        ],
        "summary": "We investigate the problem of autonomous racing among teams of cooperative agents that are subject to realistic racing rules. Our work extends previous research on hierarchical control in head-to-head autonomous racing by considering a generalized version of the problem while maintaining the two-level hierarchical control structure. A high-level tactical planner constructs a discrete game that encodes the complex rules using simplified dynamics to produce a sequence of target waypoints. The low-level path planner uses these waypoints as a reference trajectory and computes high-resolution control inputs by solving a simplified formulation of a racing game with a simplified representation of the realistic racing rules. We explore two approaches for the low-level path planner: training a multi-agent reinforcement learning (MARL) policy and solving a linear-quadratic Nash game (LQNG) approximation. We evaluate our controllers on simple and complex tracks against three baselines: an end-to-end MARL controller, a MARL controller tracking a fixed racing line, and an LQNG controller tracking a fixed racing line. Quantitative results show our hierarchical methods outperform the baselines in terms of race wins, overall team performance, and compliance with the rules. Qualitatively, we observe the hierarchical controllers mimic actions performed by expert human drivers such as coordinated overtaking, defending against multiple opponents, and long-term planning for delayed advantages.",
        "published": "2022-04-27T17:08:56Z",
        "link": "http://arxiv.org/abs/2204.13070v3",
        "categories": [
            "cs.MA",
            "cs.GT"
        ]
    },
    {
        "title": "AdaBest: Minimizing Client Drift in Federated Learning via Adaptive Bias   Estimation",
        "authors": [
            "Farshid Varno",
            "Marzie Saghayi",
            "Laya Rafiee Sevyeri",
            "Sharut Gupta",
            "Stan Matwin",
            "Mohammad Havaei"
        ],
        "summary": "In Federated Learning (FL), a number of clients or devices collaborate to train a model without sharing their data. Models are optimized locally at each client and further communicated to a central hub for aggregation. While FL is an appealing decentralized training paradigm, heterogeneity among data from different clients can cause the local optimization to drift away from the global objective. In order to estimate and therefore remove this drift, variance reduction techniques have been incorporated into FL optimization recently. However, these approaches inaccurately estimate the clients' drift and ultimately fail to remove it properly. In this work, we propose an adaptive algorithm that accurately estimates drift across clients. In comparison to previous works, our approach necessitates less storage and communication bandwidth, as well as lower compute costs. Additionally, our proposed methodology induces stability by constraining the norm of estimates for client drift, making it more practical for large scale FL. Experimental findings demonstrate that the proposed algorithm converges significantly faster and achieves higher accuracy than the baselines across various FL benchmarks.",
        "published": "2022-04-27T20:04:24Z",
        "link": "http://arxiv.org/abs/2204.13170v4",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.CV",
            "cs.DC",
            "cs.MA",
            "I.2; I.4; I.5"
        ]
    },
    {
        "title": "Adaptive Multi-Strategy Market-Making Agent For Volatile Markets",
        "authors": [
            "Ali Raheman",
            "Anton Kolonin",
            "Alexey Glushchenko",
            "Arseniy Fokin",
            "Ikram Ansari"
        ],
        "summary": "Crypto-currency market uncertainty drives the need to find adaptive solutions to maximise gain or at least to avoid loss throughout the periods of trading activity. Given the high dimensionality and complexity of the state-action space in this domain, it can be treated as a \"Narrow AGI\" problem with the scope of goals and environments bound to financial markets. Adaptive Multi-Strategy Agent approach for market-making introduces a new solution to maximise positive \"alpha\" in long-term handling limit order book (LOB) positions by using multiple sub-agents implementing different strategies with a dynamic selection of these agents based on changing market conditions. AMSA provides no specific strategy of its own while being responsible for segmenting the periods of market-making activity into smaller execution sub-periods, performing internal backtesting on historical data on each of the sub-periods, doing sub- agent performance evaluation and re-selection of them at the end of each sub- period, and collecting returns and losses incrementally. With this approach, the return becomes a function of hyper-parameters such as market data granularity (refresh rate), the execution sub-period duration, number of active sub-agents, and their individual strategies. Sub-agent selection for the next trading sub-period is made based on return/loss and alpha values obtained during internal backtesting as well as real trading. Experiments with the AMSA have been performed under different market conditions relying on historical data and proved a high probability of positive alpha throughout the periods of trading activity in the case of properly selected hyper-parameters.",
        "published": "2022-04-28T03:08:50Z",
        "link": "http://arxiv.org/abs/2204.13265v1",
        "categories": [
            "q-fin.TR",
            "cs.CE",
            "cs.MA"
        ]
    },
    {
        "title": "From prediction markets to interpretable collective intelligence",
        "authors": [
            "Alexey V. Osipov",
            "Nikolay N. Osipov"
        ],
        "summary": "We outline how to create a mechanism that provides an optimal way to elicit, from an arbitrary group of experts, the probability of the truth of an arbitrary logical proposition together with collective information that has an explicit form and interprets this probability. Namely, we provide strong arguments for the possibility of the development of a self-resolving prediction market with play money that incentivizes direct information exchange between experts. Such a system could, in particular, motivate simultaneously many experts to collectively solve scientific or medical problems in a very efficient manner. We also note that in our considerations, experts are not assumed to be Bayesian.",
        "published": "2022-04-28T11:44:29Z",
        "link": "http://arxiv.org/abs/2204.13424v3",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.IT",
            "cs.MA",
            "econ.EM",
            "math.IT"
        ]
    },
    {
        "title": "How social influence affects the wisdom of crowds in influence networks",
        "authors": [
            "Ye Tian",
            "Long Wang",
            "Francesco Bullo"
        ],
        "summary": "A long-standing debate is whether social influence improves the collective wisdom of a crowd or undermines it. This paper addresses this question based on a naive learning setting in influence systems theory: in our models individuals evolve their estimates of an unknown truth according to the weighted-average opinion dynamics. A formal mathematization is provided with rigorous theoretical analysis. We obtain various conditions for improving, optimizing and undermining the crowd accuracy, respectively. We prove that if the wisdom of finite-size group is improved, then the collective estimate converges to the truth as group size increases, provided individuals' variances are finite. We show that whether social influence improves or undermines the wisdom is determined by the social power allocation of the influence system: if the influence system allocates relatively larger social power to relatively more accurate individuals, it improves the wisdom; on the contrary, if the influence system assigns less social power to more accurate individuals, it undermines the wisdom. At a population level, individuals' susceptibilities to interpersonal influence and network centralities are both crucial. To improve the wisdom, more accurate individuals should be less susceptible and have larger network centralities. Particularly, in democratic influence networks, if relatively more accurate individuals are relatively less susceptible, the wisdom is improved; if more accurate individuals are more susceptible, the wisdom is undermined, which is consistent with the reported empirical evidence. Our investigation provides a theoretical framework for understanding the role social influence plays in the emergence of collective wisdom.",
        "published": "2022-04-28T16:12:17Z",
        "link": "http://arxiv.org/abs/2204.13610v2",
        "categories": [
            "cs.SI",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "On the Arithmetic and Geometric Fusion of Beliefs for Distributed   Inference",
        "authors": [
            "Mert Kayaalp",
            "Yunus Inan",
            "Emre Telatar",
            "Ali H. Sayed"
        ],
        "summary": "We study the asymptotic learning rates under linear and log-linear combination rules of belief vectors in a distributed hypothesis testing problem. We show that under both combination strategies, agents are able to learn the truth exponentially fast, with a faster rate under log-linear fusion. We examine the gap between the rates in terms of network connectivity and information diversity. We also provide closed-form expressions for special cases involving federated architectures and exchangeable networks.",
        "published": "2022-04-28T18:58:06Z",
        "link": "http://arxiv.org/abs/2204.13741v2",
        "categories": [
            "eess.SP",
            "cs.MA",
            "cs.SI"
        ]
    },
    {
        "title": "BILP-Q: Quantum Coalition Structure Generation",
        "authors": [
            "Supreeth Mysore Venkatesh",
            "Antonio Macaluso",
            "Matthias Klusch"
        ],
        "summary": "Quantum AI is an emerging field that uses quantum computing to solve typical complex problems in AI. In this work, we propose BILP-Q, the first-ever general quantum approach for solving the Coalition Structure Generation problem (CSGP), which is notably NP-hard. In particular, we reformulate the CSGP in terms of a Quadratic Binary Combinatorial Optimization (QUBO) problem to leverage existing quantum algorithms (e.g., QAOA) to obtain the best coalition structure. Thus, we perform a comparative analysis in terms of time complexity between the proposed quantum approach and the most popular classical baselines. Furthermore, we consider standard benchmark distributions for coalition values to test the BILP-Q on small-scale experiments using the IBM Qiskit environment. Finally, since QUBO problems can be solved operating with quantum annealing, we run BILP-Q on medium-size problems using a real quantum annealer (D-Wave).",
        "published": "2022-04-28T22:19:50Z",
        "link": "http://arxiv.org/abs/2204.13802v1",
        "categories": [
            "quant-ph",
            "cs.AI",
            "cs.MA",
            "I.2.11; F.1.0"
        ]
    },
    {
        "title": "Maxmin Participatory Budgeting",
        "authors": [
            "Gogulapati Sreedurga",
            "Mayank Ratan Bhardwaj",
            "Y. Narahari"
        ],
        "summary": "Participatory Budgeting (PB) is a popular voting method by which a limited budget is divided among a set of projects, based on the preferences of voters over the projects. PB is broadly categorised as divisible PB (if the projects are fractionally implementable) and indivisible PB (if the projects are atomic). Egalitarianism, an important objective in PB, has not received much attention in the context of indivisible PB. This paper addresses this gap through a detailed study of a natural egalitarian rule, Maxmin Participatory Budgeting (MPB), in the context of indivisible PB. Our study is in two parts: (1) computational (2) axiomatic. In the first part, we prove that MPB is computationally hard and give pseudo-polynomial time and polynomial-time algorithms when parameterized by certain well-motivated parameters. We propose an algorithm that achieves for MPB, additive approximation guarantees for restricted spaces of instances and empirically show that our algorithm in fact gives exact optimal solutions on real-world PB datasets. We also establish an upper bound on the approximation ratio achievable for MPB by the family of exhaustive strategy-proof PB algorithms. In the second part, we undertake an axiomatic study of the MPB rule by generalizing known axioms in the literature. Our study leads to the proposal of a new axiom, maximal coverage, which captures fairness aspects. We prove that MPB satisfies maximal coverage.",
        "published": "2022-04-29T07:45:44Z",
        "link": "http://arxiv.org/abs/2204.13923v1",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Cooperative Aerial-Ground Multi-Robot System for Automated Construction   Tasks",
        "authors": [
            "Marko Krizmancic",
            "Barbara Arbanas",
            "Tamara Petrovic",
            "Frano Petric",
            "Stjepan Bogdan"
        ],
        "summary": "In this paper, we study a cooperative aerial-ground robotic team and its application to the task of automated construction. We propose a solution for planning and coordinating the mission of constructing a wall with a predefined structure for a heterogeneous system consisting of one mobile robot and up to three unmanned aerial vehicles. The wall consists of bricks of various weights and sizes, some of which need to be transported using multiple robots simultaneously. To that end, we use hierarchical task representation to specify interrelationships between mission subtasks and employ effective scheduling and coordination mechanism, inspired by Generalized Partial Global Planning. We evaluate the performance of the method under different optimization criteria and validate the solution in the realistic Gazebo simulation environment.",
        "published": "2022-04-29T07:54:45Z",
        "link": "http://arxiv.org/abs/2204.13926v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Human-in-the-loop online multi-agent approach to increase   trustworthiness in ML models through trust scores and data augmentation",
        "authors": [
            "Gusseppe Bravo-Rocca",
            "Peini Liu",
            "Jordi Guitart",
            "Ajay Dholakia",
            "David Ellison",
            "Miroslav Hodak"
        ],
        "summary": "Increasing a ML model accuracy is not enough, we must also increase its trustworthiness. This is an important step for building resilient AI systems for safety-critical applications such as automotive, finance, and healthcare. For that purpose, we propose a multi-agent system that combines both machine and human agents. In this system, a checker agent calculates a trust score of each instance (which penalizes overconfidence and overcautiousness in predictions) using an agreement-based method and ranks it; then an improver agent filters the anomalous instances based on a human rule-based procedure (which is considered safe), gets the human labels, applies geometric data augmentation, and retrains with the augmented data using transfer learning. We evaluate the system on corrupted versions of the MNIST and FashionMNIST datasets. We get an improvement in accuracy and trust score with just few additional labels compared to a baseline approach.",
        "published": "2022-04-29T17:33:14Z",
        "link": "http://arxiv.org/abs/2204.14255v2",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Learning Mixed Strategies in Trajectory Games",
        "authors": [
            "Lasse Peters",
            "David Fridovich-Keil",
            "Laura Ferranti",
            "Cyrill Stachniss",
            "Javier Alonso-Mora",
            "Forrest Laine"
        ],
        "summary": "In multi-agent settings, game theory is a natural framework for describing the strategic interactions of agents whose objectives depend upon one another's behavior. Trajectory games capture these complex effects by design. In competitive settings, this makes them a more faithful interaction model than traditional \"predict then plan\" approaches. However, current game-theoretic planning methods have important limitations. In this work, we propose two main contributions. First, we introduce an offline training phase which reduces the online computational burden of solving trajectory games. Second, we formulate a lifted game which allows players to optimize multiple candidate trajectories in unison and thereby construct more competitive \"mixed\" strategies. We validate our approach on a number of experiments using the pursuit-evasion game \"tag.\"",
        "published": "2022-04-30T15:09:01Z",
        "link": "http://arxiv.org/abs/2205.00291v2",
        "categories": [
            "cs.GT",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Drone Flocking Optimization using NSGA-II and Principal Component   Analysis",
        "authors": [
            "Jagdish Chand Bansal",
            "Nikhil Sethi",
            "Ogbonnaya Anicho",
            "Atulya Nagar"
        ],
        "summary": "Individual agents in natural systems like flocks of birds or schools of fish display a remarkable ability to coordinate and communicate in local groups and execute a variety of tasks efficiently. Emulating such natural systems into drone swarms to solve problems in defence, agriculture, industry automation and humanitarian relief is an emerging technology. However, flocking of aerial robots while maintaining multiple objectives, like collision avoidance, high speed etc. is still a challenge. In this paper, optimized flocking of drones in a confined environment with multiple conflicting objectives is proposed. The considered objectives are collision avoidance (with each other and the wall), speed, correlation, and communication (connected and disconnected agents). Principal Component Analysis (PCA) is applied for dimensionality reduction, and understanding the collective dynamics of the swarm. The control model is characterised by 12 parameters which are then optimized using a multi-objective solver (NSGA-II). The obtained results are reported and compared with that of the CMA-ES algorithm. The study is particularly useful as the proposed optimizer outputs a Pareto Front representing different types of swarms which can applied to different scenarios in the real world.",
        "published": "2022-05-01T09:24:01Z",
        "link": "http://arxiv.org/abs/2205.00432v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Extracting Symbolic Models of Collective Behaviors with Graph Neural   Networks and Macro-Micro Evolution",
        "authors": [
            "Stephen Powers",
            "Carlo Pinciroli"
        ],
        "summary": "Collective behaviors are typically hard to model. The scale of the swarm, the large number of interactions, and the richness and complexity of the behaviors are factors that make it difficult to distill a collective behavior into simple symbolic expressions. In this paper, we propose a novel approach to symbolic regression designed to facilitate such modeling. Using raw and post-processed data as an input, our approach produces viable symbolic expressions that closely model the target behavior. Our approach is composed of two phases. In the first, a graph neural network (GNN) is trained to extract an approximation of the target behavior. In the second phase, the GNN is used to produce data for a nested evolutionary algorithm called macro-micro evolution (MME). The macro layer of this algorithm selects candidate symbolic expressions, while the micro layer tunes its parameters. Experimental evaluation shows that our approach outperforms competing solutions for symbolic regression, making it possible to extract compact expressions for complex swarm behaviors.",
        "published": "2022-05-02T01:45:50Z",
        "link": "http://arxiv.org/abs/2205.00614v1",
        "categories": [
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Optimal preference satisfaction for conflict-free joint decisions",
        "authors": [
            "Hiroaki Shinkawa",
            "Nicolas Chauvet",
            "Guillaume Bachelier",
            "André Röhm",
            "Ryoichi Horisaki",
            "Makoto Naruse"
        ],
        "summary": "We all have preferences when multiple choices are available. If we insist on satisfying our preferences only, we may suffer a loss due to conflicts with other people's identical selections. Such a case applies when the choice cannot be divided into multiple pieces due to the intrinsic nature of the resources. Former studies, such as the top trading cycle, examined how to conduct fair joint decision-making while avoiding decision conflicts from the perspective of game theory when multiple players have their own deterministic preference profiles. However, in reality, probabilistic preferences can naturally appear in relation to the stochastic decision-making of humans. Here, we theoretically derive conflict-free joint decision-making that can satisfy the probabilistic preferences of all individual players. More specifically, we mathematically prove the conditions wherein the deviation of the resultant chance of obtaining each choice from the individual preference profile, which we call the loss, becomes zero, meaning that all players' satisfaction is perfectly appreciated while avoiding decision conflicts. Furthermore, even in situations where zero-loss conflict-free joint decision-making is unachievable, we show how to derive joint decision-making that accomplishes the theoretical minimum loss while ensuring conflict-free choices. Numerical demonstrations are also shown with several benchmarks.",
        "published": "2022-05-02T10:31:32Z",
        "link": "http://arxiv.org/abs/2205.00799v1",
        "categories": [
            "econ.TH",
            "cs.MA",
            "math.PR",
            "physics.app-ph"
        ]
    },
    {
        "title": "Hierarchical Decompositions of Stochastic Pursuit-Evasion Games",
        "authors": [
            "Yue Guan",
            "Mohammad Afshari",
            "Qifan Zhang",
            "Panagiotis Tsiotras"
        ],
        "summary": "In this work we present a hierarchical framework for solving discrete stochastic pursuit-evasion games (PEGs) in large grid worlds. With a partition of the grid world into superstates (e.g., \"rooms\"), the proposed approach creates a two-resolution decision-making process, which consists of a set of local PEGs at the original state level and an aggregated PEG at the superstate level. Having much smaller cardinality, both the local games and the aggregated game can be easily solved to a Nash equilibrium. To connect the decision-making at the two resolutions, we use the Nash values of the local PEGs as the rewards for the aggregated game. Through numerical simulations, we show that the proposed hierarchical framework significantly reduces the computation overhead, while still maintaining a satisfactory level of performance when competing against the flat Nash policies.",
        "published": "2022-05-02T13:00:35Z",
        "link": "http://arxiv.org/abs/2205.00885v2",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Real-Time BDI Agents: a model and its implementation",
        "authors": [
            "Andrea Traldi",
            "Francesco Bruschetti",
            "Marco Robol",
            "Marco Roveri",
            "Paolo Giorgini"
        ],
        "summary": "The BDI model proved to be effective for developing applications requiring high-levels of autonomy and to deal with the complexity and unpredictability of real-world scenarios. The model, however, has significant limitations in reacting and handling contingencies within the given real-time constraints. Without an explicit representation of time, existing real-time BDI implementations overlook the temporal implications during the agent's decision process that may result in delays or unresponsiveness of the system when it gets overloaded. In this paper, we redefine the BDI agent control loop inspired by well established algorithms for real-time systems to ensure a proper reaction of agents and their effective application in typical real-time domains. Our model proposes an effective real-time management of goals, plans, and actions with respect to time constraints and resources availability. We propose an implementation of the model for a resource-collection video-game and we validate the approach against a set of significant scenarios.",
        "published": "2022-05-02T15:28:18Z",
        "link": "http://arxiv.org/abs/2205.00979v1",
        "categories": [
            "cs.MA",
            "cs.SE"
        ]
    },
    {
        "title": "Autonomy and Intelligence in the Computing Continuum: Challenges,   Enablers, and Future Directions for Orchestration",
        "authors": [
            "Henna Kokkonen",
            "Lauri Lovén",
            "Naser Hossein Motlagh",
            "Abhishek Kumar",
            "Juha Partala",
            "Tri Nguyen",
            "Víctor Casamayor Pujol",
            "Panos Kostakos",
            "Teemu Leppänen",
            "Alfonso González-Gil",
            "Ester Sola",
            "Iñigo Angulo",
            "Madhusanka Liyanage",
            "Mehdi Bennis",
            "Sasu Tarkoma",
            "Schahram Dustdar",
            "Susanna Pirttikangas",
            "Jukka Riekki"
        ],
        "summary": "Future AI applications require performance, reliability and privacy that the existing, cloud-dependant system architectures cannot provide. In this article, we study orchestration in the device-edge-cloud continuum, and focus on edge AI for resource orchestration. We claim that to support the constantly growing requirements of intelligent applications in the device-edge-cloud computing continuum, resource orchestration needs to embrace edge AI and emphasize local autonomy and intelligence. To justify the claim, we provide a general definition for continuum orchestration, and look at how current and emerging orchestration paradigms are suitable for the computing continuum. We describe certain major emerging research themes that may affect future orchestration, and provide an early vision of an orchestration paradigm that embraces those research themes. Finally, we survey current key edge AI methods and look at how they may contribute into fulfilling the vision of future continuum orchestration.",
        "published": "2022-05-03T11:26:36Z",
        "link": "http://arxiv.org/abs/2205.01423v3",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Model-Free Opponent Shaping",
        "authors": [
            "Chris Lu",
            "Timon Willi",
            "Christian Schroeder de Witt",
            "Jakob Foerster"
        ],
        "summary": "In general-sum games, the interaction of self-interested learning agents commonly leads to collectively worst-case outcomes, such as defect-defect in the iterated prisoner's dilemma (IPD). To overcome this, some methods, such as Learning with Opponent-Learning Awareness (LOLA), shape their opponents' learning process. However, these methods are myopic since only a small number of steps can be anticipated, are asymmetric since they treat other agents as naive learners, and require the use of higher-order derivatives, which are calculated through white-box access to an opponent's differentiable learning algorithm. To address these issues, we propose Model-Free Opponent Shaping (M-FOS). M-FOS learns in a meta-game in which each meta-step is an episode of the underlying inner game. The meta-state consists of the inner policies, and the meta-policy produces a new inner policy to be used in the next episode. M-FOS then uses generic model-free optimisation methods to learn meta-policies that accomplish long-horizon opponent shaping. Empirically, M-FOS near-optimally exploits naive learners and other, more sophisticated algorithms from the literature. For example, to the best of our knowledge, it is the first method to learn the well-known Zero-Determinant (ZD) extortion strategy in the IPD. In the same settings, M-FOS leads to socially optimal outcomes under meta-self-play. Finally, we show that M-FOS can be scaled to high-dimensional settings.",
        "published": "2022-05-03T12:20:14Z",
        "link": "http://arxiv.org/abs/2205.01447v2",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "On the Convergence of Fictitious Play: A Decomposition Approach",
        "authors": [
            "Yurong Chen",
            "Xiaotie Deng",
            "Chenchen Li",
            "David Mguni",
            "Jun Wang",
            "Xiang Yan",
            "Yaodong Yang"
        ],
        "summary": "Fictitious play (FP) is one of the most fundamental game-theoretical learning frameworks for computing Nash equilibrium in $n$-player games, which builds the foundation for modern multi-agent learning algorithms. Although FP has provable convergence guarantees on zero-sum games and potential games, many real-world problems are often a mixture of both and the convergence property of FP has not been fully studied yet. In this paper, we extend the convergence results of FP to the combinations of such games and beyond. Specifically, we derive new conditions for FP to converge by leveraging game decomposition techniques. We further develop a linear relationship unifying cooperation and competition in the sense that these two classes of games are mutually transferable. Finally, we analyze a non-convergent example of FP, the Shapley game, and develop sufficient conditions for FP to converge.",
        "published": "2022-05-03T13:04:09Z",
        "link": "http://arxiv.org/abs/2205.01469v1",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Data assimilation with agent-based models using Markov chain sampling",
        "authors": [
            "Daniel Tang",
            "Nick Malleson"
        ],
        "summary": "Every day, weather forecasting centres around the world make use of noisy, incomplete observations of the atmosphere to update their weather forecasts. This process is known as data assimilation, data fusion or state estimation and is best expressed as Bayesian inference: given a set of observations, some prior beliefs and a model of the target system, what is the probability distribution of some set of unobserved quantities or latent variables at some time, possibly in the future?   While data assimilation has developed rapidly in some areas, relatively little progress has been made in performing data assimilation with agent-based models. This has hampered the use of agent-based models to make quantitative claims about real-world systems.   Here we present an algorithm that uses Markov-Chain-Monte-Carlo methods to generate samples of the parameters and trajectories of an agent-based model over a window of time given a set of possibly noisy, aggregated and incomplete observations of the system. This can be used as-is, or as part of a data assimilation cycle or sequential-MCMC algorithm.   Our algorithm is applicable to time-stepping, agent-based models whose agents have a finite set of states and a finite number of ways of acting on the world. As presented the algorithm is only practical for agents with a few bytes of internal state although we discuss ways of removing this restriction. We demonstrate the algorithm by performing data assimilation with an agent-based, spatial predator-prey model.",
        "published": "2022-05-03T16:52:11Z",
        "link": "http://arxiv.org/abs/2205.01616v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Traversing Supervisor Problem: An Approximately Optimal Approach to   Multi-Robot Assistance",
        "authors": [
            "Tianchen Ji",
            "Roy Dong",
            "Katherine Driggs-Campbell"
        ],
        "summary": "The number of multi-robot systems deployed in field applications has increased dramatically over the years. Despite the recent advancement of navigation algorithms, autonomous robots often encounter challenging situations where the control policy fails and the human assistance is required to resume robot tasks. Human-robot collaboration can help achieve high-levels of autonomy, but monitoring and managing multiple robots at once by a single human supervisor remains a challenging problem. Our goal is to help a supervisor decide which robots to assist in which order such that the team performance can be maximized. We formulate the one-to-many supervision problem in uncertain environments as a dynamic graph traversal problem. An approximation algorithm based on the profitable tour problem on a static graph is developed to solve the original problem, and the approximation error is bounded and analyzed. Our case study on a simulated autonomous farm demonstrates superior team performance than baseline methods in task completion time and human working time, and that our method can be deployed in real-time for robot fleets with moderate size.",
        "published": "2022-05-03T20:35:17Z",
        "link": "http://arxiv.org/abs/2205.01768v1",
        "categories": [
            "cs.RO",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "On the Complexity of Majority Illusion in Social Networks",
        "authors": [
            "Umberto Grandi",
            "Grzegorz Lisowski",
            "M. S. Ramanujan",
            "Paolo Turrini"
        ],
        "summary": "Majority illusion occurs in a social network when the majority of the network nodes belong to a certain type but each node's neighbours mostly belong to a different type, therefore creating the wrong perception, i.e., the illusion, that the majority type is different from the actual one. From a system engineering point of view, we want to devise algorithms to detect and, crucially, correct this undesirable phenomenon. In this paper we initiate the computational study of majority illusion in social networks, providing complexity results for its occurrence and avoidance. Namely, we show that identifying whether a network can be labelled such that majority illusion is present, as well as the problem of removing an illusion by adding or deleting edges of the network, are NP-complete problems.",
        "published": "2022-05-04T13:30:37Z",
        "link": "http://arxiv.org/abs/2205.02056v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Creating Teams of Simple Agents for Specified Tasks: A Computational   Complexity Perspective",
        "authors": [
            "T. Wareham"
        ],
        "summary": "Teams of interacting and co-operating agents have been proposed as an efficient and robust alternative to monolithic centralized control for carrying out specified tasks in a variety of applications. A number of different team and agent architectures have been investigated, e.g., teams based on single vs multiple behaviorally-distinct types of agents (homogeneous vs heterogeneous teams), simple vs complex agents, direct vs indirect agent-to-agent communication. A consensus is emerging that (1) heterogeneous teams composed of simple agents that communicate indirectly are preferable and (2) automated methods for verifying and designing such teams are necessary. In this paper, we use computational complexity analysis to assess viable algorithmic options for such automated methods for various types of teams. Building on recent complexity analyses addressing related questions in swarm robotics, we prove that automated team verification and design are by large both exact and approximate polynomial-time intractable in general for the most basic types of homogeneous and heterogeneous teams consisting of simple agents that communicate indirectly. Our results suggest that tractability for these problems must be sought relative to additional restrictions on teams, agents, operating environments, and tasks.",
        "published": "2022-05-04T13:46:17Z",
        "link": "http://arxiv.org/abs/2205.02061v1",
        "categories": [
            "cs.MA",
            "cs.CC",
            "I.2.11; F.2.0"
        ]
    },
    {
        "title": "HARL: A Novel Hierachical Adversary Reinforcement Learning for   Automoumous Intersection Management",
        "authors": [
            "Guanzhou Li",
            "Jianping Wu",
            "Yujing He"
        ],
        "summary": "As an emerging technology, Connected Autonomous Vehicles (CAVs) are believed to have the ability to move through intersections in a faster and safer manner, through effective Vehicle-to-Everything (V2X) communication and global observation. Autonomous intersection management is a key path to efficient crossing at intersections, which reduces unnecessary slowdowns and stops through adaptive decision process of each CAV, enabling fuller utilization of the intersection space. Distributed reinforcement learning (DRL) offers a flexible, end-to-end model for AIM, adapting for many intersection scenarios. While DRL is prone to collisions as the actions of multiple sides in the complicated interactions are sampled from a generic policy, restricting the application of DRL in realistic scenario. To address this, we propose a hierarchical RL framework where models at different levels vary in receptive scope, action step length, and feedback period of reward. The upper layer model accelerate CAVs to prevent them from being clashed, while the lower layer model adjust the trends from upper layer model to avoid the change of mobile state causing new conflicts. And the real action of CAV at each step is co-determined by the trends from both levels, forming a real-time balance in the adversarial process. The proposed model is proven effective in the experiment undertaken in a complicated intersection with 4 branches and 4 lanes each branch, and show better performance compared with baselines.",
        "published": "2022-05-05T04:07:13Z",
        "link": "http://arxiv.org/abs/2205.02428v4",
        "categories": [
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Multi-Agent Deep Reinforcement Learning in Vehicular OCC",
        "authors": [
            "Amirul Islam",
            "Leila Musavian",
            "Nikolaos Thomos"
        ],
        "summary": "Optical camera communications (OCC) has emerged as a key enabling technology for the seamless operation of future autonomous vehicles. In this paper, we introduce a spectral efficiency optimization approach in vehicular OCC. Specifically, we aim at optimally adapting the modulation order and the relative speed while respecting bit error rate and latency constraints. As the optimization problem is NP-hard problem, we model the optimization problem as a Markov decision process (MDP) to enable the use of solutions that can be applied online. We then relaxed the constrained problem by employing Lagrange relaxation approach before solving it by multi-agent deep reinforcement learning (DRL). We verify the performance of our proposed scheme through extensive simulations and compare it with various variants of our approach and a random method. The evaluation shows that our system achieves significantly higher sum spectral efficiency compared to schemes under comparison.",
        "published": "2022-05-05T14:25:54Z",
        "link": "http://arxiv.org/abs/2205.02672v1",
        "categories": [
            "cs.LG",
            "cs.IT",
            "cs.MA",
            "cs.NI",
            "math.IT"
        ]
    },
    {
        "title": "Utility-Based Context-Aware Multi-Agent Recommendation System for Energy   Efficiency in Residential Buildings",
        "authors": [
            "Valentyna Riabchuk",
            "Leon Hagel",
            "Felix Germaine",
            "Alona Zharova"
        ],
        "summary": "A significant part of CO2 emissions is due to high electricity consumption in residential buildings. Using load shifting can help to improve the households' energy efficiency. To nudge changes in energy consumption behavior, simple but powerful architectures are vital. This paper presents a novel algorithm of a recommendation system generating device usage recommendations and suggests a framework for evaluating its performance by analyzing potential energy cost savings. As a utility-based recommender system, it models user preferences depending on habitual device usage patterns, user availability, and device usage costs. As a context-aware system, it requires an external hourly electricity price signal and appliance-level energy consumption data. Due to a multi-agent architecture, it provides flexibility and allows for adjustments and further enhancements. Empirical results show that the system can provide energy cost savings of 18% and more for most studied households.",
        "published": "2022-05-05T15:22:56Z",
        "link": "http://arxiv.org/abs/2205.02704v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Optimal Information Provision for Strategic Hybrid Workers",
        "authors": [
            "Sohil Shah",
            "Saurabh Amin",
            "Patrick Jaillet"
        ],
        "summary": "We study the problem of information provision by a strategic central planner who can publicly signal about an uncertain infectious risk parameter. Signalling leads to an updated public belief over the parameter, and agents then make equilibrium choices on whether to work remotely or in-person. The planner maintains a set of desirable outcomes for each realization of the uncertain parameter and seeks to maximize the probability that agents choose an acceptable outcome for the true parameter. We distinguish between stateless and stateful objectives. In the former, the set of desirable outcomes does not change as a function of the risk parameter, whereas in the latter it does. For stateless objectives, we reduce the problem to maximizing the probability of inducing mean beliefs that lie in intervals computable from the set of desirable outcomes. We derive the optimal signalling mechanism and show that it partitions the parameter domain into at most two intervals with the signals generated according to an interval-specific distribution. For the stateful case, we consider a practically relevant situation in which the planner can enforce in-person work capacity limits that progressively get more stringent as the risk parameter increases. We show that the optimal signalling mechanism for this case can be obtained by solving a linear program. We numerically verify the improvement in achieving desirable outcomes using our information design relative to no information and full information benchmarks.",
        "published": "2022-05-05T16:06:00Z",
        "link": "http://arxiv.org/abs/2205.02732v1",
        "categories": [
            "cs.MA",
            "cs.GT"
        ]
    },
    {
        "title": "Automating Reasoning with Standpoint Logic via Nested Sequents",
        "authors": [
            "Tim S. Lyon",
            "Lucía Gómez Álvarez"
        ],
        "summary": "Standpoint logic is a recently proposed formalism in the context of knowledge integration, which advocates a multi-perspective approach permitting reasoning with a selection of diverse and possibly conflicting standpoints rather than forcing their unification. In this paper, we introduce nested sequent calculi for propositional standpoint logics--proof systems that manipulate trees whose nodes are multisets of formulae--and show how to automate standpoint reasoning by means of non-deterministic proof-search algorithms. To obtain worst-case complexity-optimal proof-search, we introduce a novel technique in the context of nested sequents, referred to as \"coloring,\" which consists of taking a formula as input, guessing a certain coloring of its subformulae, and then running proof-search in a nested sequent calculus on the colored input. Our technique lets us decide the validity of standpoint formulae in CoNP since proof-search only produces a partial proof relative to each permitted coloring of the input. We show how all partial proofs can be fused together to construct a complete proof when the input is valid, and how certain partial proofs can be transformed into a counter-model when the input is invalid. These \"certificates\" (i.e. proofs and counter-models) serve as explanations of the (in)validity of the input.",
        "published": "2022-05-05T16:27:57Z",
        "link": "http://arxiv.org/abs/2205.02749v1",
        "categories": [
            "cs.LO",
            "cs.AI",
            "cs.DS",
            "cs.MA",
            "math.LO"
        ]
    },
    {
        "title": "A Realistic Cyclist Model for SUMO Based on the SimRa Dataset",
        "authors": [
            "Ahmet-Serdar Karakaya",
            "Konstantin Köhler",
            "Julian Heinovski",
            "Falko Dressler",
            "David Bermbach"
        ],
        "summary": "Increasing the modal share of bicycle traffic to reduce carbon emissions, reduce urban car traffic, and to improve the health of citizens, requires a shift away from car-centric city planning. For this, traffic planners often rely on simulation tools such as SUMO which allow them to study the effects of construction changes before implementing them. Similarly, studies of vulnerable road users, here cyclists, also use such models to assess the performance of communication-based road traffic safety systems. The cyclist model in SUMO, however, is very imprecise as SUMO cyclists behave either like slow cars or fast pedestrians, thus, casting doubt on simulation results for bicycle traffic. In this paper, we analyze acceleration, velocity, and intersection left-turn behavior of cyclists in a large dataset of real world cycle tracks. We use the results to derive an improved cyclist model and implement it in SUMO.",
        "published": "2022-05-05T19:32:08Z",
        "link": "http://arxiv.org/abs/2205.04538v1",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Semi-Supervised Imitation Learning of Team Policies from Suboptimal   Demonstrations",
        "authors": [
            "Sangwon Seo",
            "Vaibhav V. Unhelkar"
        ],
        "summary": "We present Bayesian Team Imitation Learner (BTIL), an imitation learning algorithm to model the behavior of teams performing sequential tasks in Markovian domains. In contrast to existing multi-agent imitation learning techniques, BTIL explicitly models and infers the time-varying mental states of team members, thereby enabling learning of decentralized team policies from demonstrations of suboptimal teamwork. Further, to allow for sample- and label-efficient policy learning from small datasets, BTIL employs a Bayesian perspective and is capable of learning from semi-supervised demonstrations. We demonstrate and benchmark the performance of BTIL on synthetic multi-agent tasks as well as a novel dataset of human-agent teamwork. Our experiments show that BTIL can successfully learn team policies from demonstrations despite the influence of team members' (time-varying and potentially misaligned) mental states on their behavior.",
        "published": "2022-05-05T23:18:32Z",
        "link": "http://arxiv.org/abs/2205.02959v6",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Transferable Cross-Chain Options",
        "authors": [
            "Daniel Engel",
            "Yingjie Xue"
        ],
        "summary": "An option is a financial agreement between two parties to trade two assets. One party is given the right, but not the obligation, to complete the swap before a specified termination time. In todays financial markets, an option is considered an asset which can itself be transferred: while an option is active, one party can sell its rights (or obligations) to another. Todays blockchains support simple options in the form of cross-chain atomic swap protocols where one party has the choice whether to complete the swap. The options implemented by these cross-chain protocols, are not, however, transferable. This paper proposes novel distributed protocols for transferable cross-chain options, where both option owners and providers can sell their positions to third parties. The protocol ensures that none of the parties can be cheated, that no unauthorized party can interfere, and that the transfer succeeds if the buyer and seller faithfully follow the protocol.",
        "published": "2022-05-06T01:01:09Z",
        "link": "http://arxiv.org/abs/2205.02971v1",
        "categories": [
            "cs.CR",
            "cs.DC",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Learning to Cooperate with Completely Unknown Teammates",
        "authors": [
            "Alexandre Neves",
            "Alberto Sardinha"
        ],
        "summary": "A key goal of ad hoc teamwork is to develop a learning agent that cooperates with unknown teams, without resorting to any pre-coordination protocol. Despite a vast number of ad hoc teamwork algorithms in the literature, most of them cannot address the problem of learning to cooperate with a completely unknown team, unless it learns from scratch. This article presents a novel approach that uses transfer learning alongside the state-of-the-art PLASTIC-Policy to adapt to completely unknown teammates quickly. We test our solution within the Half Field Offense simulator with five different teammates. The teammates were designed independently by developers from different countries and at different times. Our empirical evaluation shows that it is advantageous for an ad hoc agent to leverage its past knowledge when adapting to a new team instead of learning how to cooperate with it from scratch.",
        "published": "2022-05-06T15:14:42Z",
        "link": "http://arxiv.org/abs/2205.03289v1",
        "categories": [
            "cs.MA",
            "I.2.6"
        ]
    },
    {
        "title": "Learning Scalable Policies over Graphs for Multi-Robot Task Allocation   using Capsule Attention Networks",
        "authors": [
            "Steve Paul",
            "Payam Ghassemi",
            "Souma Chowdhury"
        ],
        "summary": "This paper presents a novel graph reinforcement learning (RL) architecture to solve multi-robot task allocation (MRTA) problems that involve tasks with deadlines and workload, and robot constraints such as work capacity. While drawing motivation from recent graph learning methods that learn to solve combinatorial optimization (CO) problems such as multi-Traveling Salesman and Vehicle Routing Problems using RL, this paper seeks to provide better performance (compared to non-learning methods) and important scalability (compared to existing learning architectures) for the stated class of MRTA problems. The proposed neural architecture, called Capsule Attention-based Mechanism or CapAM acts as the policy network, and includes three main components: 1) an encoder: a Capsule Network based node embedding model to represent each task as a learnable feature vector; 2) a decoder: an attention-based model to facilitate a sequential output; and 3) context: that encodes the states of the mission and the robots. To train the CapAM model, the policy-gradient method based on REINFORCE is used. When evaluated over unseen scenarios, CapAM demonstrates better task completion performance and $>$10 times faster decision-making compared to standard non-learning based online MRTA methods. CapAM's advantage in generalizability, and scalability to test problems of size larger than those used in training, are also successfully demonstrated in comparison to a popular approach for learning to solve CO problems, namely the purely attention mechanism.",
        "published": "2022-05-06T15:56:40Z",
        "link": "http://arxiv.org/abs/2205.03321v1",
        "categories": [
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Concepts and Algorithms for Agent-based Decentralized and Integrated   Scheduling of Production and Auxiliary Processes",
        "authors": [
            "Felix Gehlhoff",
            "Alexander Fay"
        ],
        "summary": "Individualized products and shorter product life cycles have driven companies to rethink traditional mass production. New concepts like Industry 4.0 foster the advent of decentralized production control and distribution of information. A promising technology for realizing such scenarios are Multi-agent systems. This contribution analyses the requirements for an agent-based decentralized and integrated scheduling approach. Part of the requirements is to develop a linearly scaling communication architecture, as the communication between the agents is a major driver of the scheduling execution time. The approach schedules production, transportation, buffering and shared resource operations such as tools in an integrated manner to account for interdependencies between them. Part of the logistics requirements reflect constraints for large workpieces such as buffer scarcity. The approach aims at providing a general solution that is also applicable to large system sizes that, for example, can be found in production networks with multiple companies. Further, it is applicable for different kinds of factory organization (flow shop, job shop etc.). The approach is explained using an example based on industrial requirements. Experiments have been conducted to evaluate the scheduling execution time. The results show the approach's linear scaling behavior. Also, analyses of the concurrent negotiation ability are conducted.",
        "published": "2022-05-06T18:44:29Z",
        "link": "http://arxiv.org/abs/2205.04461v2",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "$λ$-domain VVC Rate Control Based on Game Theory",
        "authors": [
            "Jielian Lin",
            "Aiping Huang",
            "Keke Zhang",
            "Xu Wang",
            "Tiesong Zhao"
        ],
        "summary": "Versatile Video Coding (VVC) has set a new milestone in high-efficiency video coding. In the standard encoder, the $\\lambda$-domain rate control is incorporated for its high accuracy and good Rate-Distortion (RD) performance. In this paper, we formulate this task as a Nash equilibrium problem that effectively bargains between multiple agents, {\\it i.e.}, Coding Tree Units (CTUs) in the frame. After that, we calculate the optimal $\\lambda$ value with a two-step strategy: a Newton method to iteratively obtain an intermediate variable, and a solution of Nash equilibrium to obtain the optimal $\\lambda$. Finally, we propose an effective CTU-level rate allocation with the optimal $\\lambda$ value. To the best of our knowledge, we are the first to combine game theory with $\\lambda$-domain rate control. Experimental results with Common Test Conditions (CTC) demonstrate the efficiency of the proposed method, which outperforms the state-of-the-art CTU-level rate allocation algorithms.",
        "published": "2022-05-07T08:35:58Z",
        "link": "http://arxiv.org/abs/2205.03595v1",
        "categories": [
            "cs.MM",
            "cs.MA"
        ]
    },
    {
        "title": "Dynamic Matching Bandit For Two-Sided Online Markets",
        "authors": [
            "Yuantong Li",
            "Chi-hua Wang",
            "Guang Cheng",
            "Will Wei Sun"
        ],
        "summary": "Two-sided online matching platforms are employed in various markets. However, agents' preferences in the current market are usually implicit and unknown, thus needing to be learned from data. With the growing availability of dynamic side information involved in the decision process, modern online matching methodology demands the capability to track shifting preferences for agents based on contextual information. This motivates us to propose a novel framework for this dynamic online matching problem with contextual information, which allows for dynamic preferences in matching decisions. Existing works focus on online matching with static preferences, but this is insufficient: the two-sided preference changes as soon as one side's contextual information updates, resulting in non-static matching. In this paper, we propose a dynamic matching bandit algorithm to adapt to this problem. The key component of the proposed dynamic matching algorithm is an online estimation of the preference ranking with a statistical guarantee. Theoretically, we show that the proposed dynamic matching algorithm delivers an agent-optimal stable matching result with high probability. In particular, we prove a logarithmic regret upper bound $\\mathcal{O}(\\log(T))$ and construct a corresponding instance-dependent matching regret lower bound. In the experiments, we demonstrate that dynamic matching algorithm is robust to various preference schemes, dimensions of contexts, reward noise levels, and context variation levels, and its application to a job-seeking market further demonstrates the practical usage of the proposed method.",
        "published": "2022-05-07T18:28:20Z",
        "link": "http://arxiv.org/abs/2205.03699v3",
        "categories": [
            "cs.LG",
            "cs.GT",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "SSIM-Variation-Based Complexity Optimization for Versatile Video Coding",
        "authors": [
            "Jielian Lin",
            "Hongbin Lin",
            "Zhichen Zhang",
            "Yiwen Xu",
            "Tiesong Zhao"
        ],
        "summary": "To date, Versatile Video Coding (VVC) has a more magnificent overall performance than High Efficiency Video Coding (HEVC). The Quadtree with Nested Multi-Type Tree (QTMT) coding block structure can substantially enhance video coding quality in VVC. However, the coding gain also leads to a greater coding complexity. Therefore, this letter proposes a Fast Decision Scheme Based on Structural Similarity Index Metric Variation (FDS-SSIMV) to solve this problem. Firstly, the Structural Similarity Index Metric Variation (SSIMV) characteristic among the sub coding units of the spit mode is illustrated. Next, to evaluate the SSIMV value, SSIMV measure strategies are designed for different split modes in this letter. Then, the desired split modes are selected by the SSIMV values. Experimental results show that the proposed method achieves 64.74\\% average encoding Time Saving (TS) with a 2.79\\% Bj$\\varnothing$ntegaard Delta Bit Rate (BDBR), outperforming the benchmarks.",
        "published": "2022-05-08T05:12:40Z",
        "link": "http://arxiv.org/abs/2205.03782v1",
        "categories": [
            "cs.MM",
            "cs.MA"
        ]
    },
    {
        "title": "Dynamic Operads, Dynamic Categories: From Deep Learning to Prediction   Markets",
        "authors": [
            "Brandon T. Shapiro",
            "David I. Spivak"
        ],
        "summary": "Natural organized systems adapt to internal and external pressures and this happens at all levels of the abstraction hierarchy. Wanting to think clearly about this idea motivates our paper, and so the idea is elaborated extensively in the introduction, which should be broadly accessible to a philosophically-interested audience. In the remaining sections, we turn to more compressed category theory. We define the monoidal double category Org of dynamic organizations, we provide definitions of Org-enriched, or dynamic, categorical structures -- e.g. dynamic categories, operads, and monoidal categories -- and we show how they instantiate the motivating philosophical ideas. We give two examples of dynamic categorical structures: prediction markets as a dynamic operad and deep learning as a dynamic monoidal category.",
        "published": "2022-05-08T16:16:44Z",
        "link": "http://arxiv.org/abs/2205.03906v4",
        "categories": [
            "math.CT",
            "cs.LG",
            "cs.MA",
            "math.DS"
        ]
    },
    {
        "title": "Competition and Cooperation of Autonomous Ridepooling Services:   Game-Based Simulation of a Broker Concept",
        "authors": [
            "Roman Engelhardt",
            "Patrick Malcolm",
            "Florian Dandl",
            "Klaus Bogenberger"
        ],
        "summary": "Autonomous mobility on demand services have the potential to disrupt the future mobility system landscape. Ridepooling services in particular can decrease land consumption and increase transportation efficiency by increasing the average vehicle occupancy. Nevertheless, because ridepooling services require a sufficient user base for pooling to take effect, their performance can suffer if multiple operators offer such a service and must split the demand. This study presents a simulation framework for evaluating the impact of competition and cooperation among multiple ridepooling providers. Two different kinds of interaction via a broker platform are compared with the base cases of a single monopolistic operator and two independent operators with divided demand. In the first, the broker presents trip offers from all operators to customers (similar to a mobility-as-a-service platform), who can then freely choose an operator. In the second, a regulated broker platform can manipulate operator offers with the goal of shifting the customer-operator assignment from a user equilibrium towards a system optimum. To model adoptions of the service design depending on the different interaction scenario, a game setting is introduced. Within alternating turns between operators, operators can adapt parameters of their service (fleet size and objective function) to maximize profit. Results for a case study based on Manhattan taxi data, show that operators generate the highest profit in the broker setting while operating the largest fleet. Additionally, pooling efficiency can nearly be maintained compared to a single operator. With the resulting increased service rate, the regulated competition benefits not only operators (profit) and cities (increased pooling efficiency), but also customers. Contrarily, when users can decide freely, the lowest pooling efficiency and operator profit is observed.",
        "published": "2022-05-09T14:22:15Z",
        "link": "http://arxiv.org/abs/2205.04319v1",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Informed Steiner Trees: Sampling and Pruning for Multi-Goal Path Finding   in High Dimensions",
        "authors": [
            "Nikhil Chandak",
            "Kenny Chour",
            "Sivakumar Rathinam",
            "R. Ravi"
        ],
        "summary": "We interleave sampling based motion planning methods with pruning ideas from minimum spanning tree algorithms to develop a new approach for solving a Multi-Goal Path Finding (MGPF) problem in high dimensional spaces. The approach alternates between sampling points from selected regions in the search space and de-emphasizing regions that may not lead to good solutions for MGPF. Our approach provides an asymptotic, 2-approximation guarantee for MGPF. We also present extensive numerical results to illustrate the advantages of our proposed approach over uniform sampling in terms of the quality of the solutions found and computation speed.",
        "published": "2022-05-09T20:46:29Z",
        "link": "http://arxiv.org/abs/2205.04548v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.RO"
        ]
    },
    {
        "title": "Integrating Parcel Deliveries into a Ride-Pooling Service -- An   Agent-Based Simulation Study",
        "authors": [
            "Fabian Fehn",
            "Roman Engelhardt",
            "Florian Dandl",
            "Klaus Bogenberger",
            "Fritz Busch"
        ],
        "summary": "This paper examines the integration of freight delivery into the passenger transport of an on-demand ride-pooling service. The goal of this research is to use existing passenger trips for logistics services and thus reduce additional vehicle kilometers for freight delivery and the total number of vehicles on the road network. This is achieved by merging the need for two separate fleets into a single one by combining the services. To evaluate the potential of such a mobility-on-demand service, this paper uses an agent-based simulation framework and integrates three heuristic parcel assignment strategies into a ride-pooling fleet control algorithm. Two integration scenarios (moderate and full) are set up. While in both scenarios passengers and parcels share rides in one vehicle, in the moderate scenario no stops for parcel pick-up and delivery are allowed during a passenger ride to decrease customer inconvenience. Using real-world demand data for a case study of Munich, Germany, the two integration scenarios together with the three assignment strategies are compared to the status quo, which uses two separate vehicle fleets for passenger and logistics transport. The results indicate that the integration of logistics services into a ride-pooling service is possible and can exploit unused system capacities without deteriorating passenger transport. Depending on the assignment strategies nearly all parcels can be served until a parcel to passenger demand ratio of 1:10 while the overall fleet kilometers can be deceased compared to the status quo.",
        "published": "2022-05-10T07:37:50Z",
        "link": "http://arxiv.org/abs/2205.04718v1",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Environmental Sensing Options for Robot Teams: A Computational   Complexity Perspective",
        "authors": [
            "Todd Wareham",
            "Andrew Vardy"
        ],
        "summary": "Visual and scalar-field (e.g., chemical) sensing are two of the options robot teams can use to perceive their environments when performing tasks. We give the first comparison of the computational characteristic of visual and scalar-field sensing, phrased in terms of the computational complexities of verifying and designing teams of robots to efficiently and robustly perform distributed construction tasks. This is done relative a basic model in which teams of robots with deterministic finite-state controllers operate in a synchronous error-free manner in 2D grid-based environments. Our results show that for both types of sensing, all of our problems are polynomial-time intractable in general and remain intractable under a variety of restrictions on parameters characterizing robot controllers, teams, and environments. That being said, these results also include restricted situations for each of our problems in which those problems are effectively polynomial-time tractable. Though there are some differences, our results suggest that (at least in this stage of our investigation) verification and design problems relative to visual and scalar-field sensing have roughly the same patterns and types of tractability and intractability results.",
        "published": "2022-05-10T16:47:57Z",
        "link": "http://arxiv.org/abs/2205.05034v1",
        "categories": [
            "cs.MA",
            "cs.CC",
            "cs.RO",
            "I.2.11; F.2.0"
        ]
    },
    {
        "title": "Efficient Distributed Framework for Collaborative Multi-Agent   Reinforcement Learning",
        "authors": [
            "Shuhan Qi",
            "Shuhao Zhang",
            "Xiaohan Hou",
            "Jiajia Zhang",
            "Xuan Wang",
            "Jing Xiao"
        ],
        "summary": "Multi-agent reinforcement learning for incomplete information environments has attracted extensive attention from researchers. However, due to the slow sample collection and poor sample exploration, there are still some problems in multi-agent reinforcement learning, such as unstable model iteration and low training efficiency. Moreover, most of the existing distributed framework are proposed for single-agent reinforcement learning and not suitable for multi-agent. In this paper, we design an distributed MARL framework based on the actor-work-learner architecture. In this framework, multiple asynchronous environment interaction modules can be deployed simultaneously, which greatly improves the sample collection speed and sample diversity. Meanwhile, to make full use of computing resources, we decouple the model iteration from environment interaction, and thus accelerate the policy iteration. Finally, we verified the effectiveness of propose framework in MaCA military simulation environment and the SMAC 3D realtime strategy gaming environment with imcomplete information characteristics.",
        "published": "2022-05-11T03:12:49Z",
        "link": "http://arxiv.org/abs/2205.05248v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Hierarchical Collaborative Hyper-parameter Tuning",
        "authors": [
            "Ahmad Esmaeili",
            "Zahra Ghorrati",
            "Eric Matson"
        ],
        "summary": "Hyper-parameter Tuning is among the most critical stages in building machine learning solutions. This paper demonstrates how multi-agent systems can be utilized to develop a distributed technique for determining near-optimal values for any arbitrary set of hyper-parameters in a machine learning model. The proposed method employs a distributedly formed hierarchical agent-based architecture for the cooperative searching procedure of tuning hyper-parameter values. The presented generic model is used to develop a guided randomized agent-based tuning technique, and its behavior is investigated in both machine learning and global function optimization applications. According the empirical results, the proposed model outperformed both of its underlying randomized tuning strategies in terms of classification error and function evaluations, notably in higher number of dimensions.",
        "published": "2022-05-11T05:16:57Z",
        "link": "http://arxiv.org/abs/2205.05272v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Collaborative Multi-Radars Tracking by Distributed Auctions",
        "authors": [
            "Pierre Larrenie",
            "Cédric Buron",
            "Frédéric Barbaresco"
        ],
        "summary": "In this paper, we present an algorithm which lies in the domain of task allocation for a set of static autonomous radars with rotating antennas. It allows a set of radars to allocate in a fully decentralized way a set of active tracking tasks according to their location, considering that a target can be tracked by several radars, in order to improve accuracy with which the target is tracked. The allocation algorithm proceeds through a collaborative and fully decentralized auction protocol, using a collaborative auction protocol (Consensus Based Bundle Auction algorithm). Our algorithm is based on a double use of our allocation protocol among the radars. The latter begin by allocating targets, then launch a second round of allocation if theyhave resources left, in order to improve accuracy on targets already tracked. Our algorithm is also able to adapt to dynamism, i.e. to take into account the fact that the targets are moving and that the radar(s) most suitable for Tracking them changes as the mission progresses. To do this, the algorithm is restarted on a regular basis, to ensure that a bid made by a radar can decrease when the target moves away from it. Since our algorithm is based on collaborative auctions, it does not plan the following rounds, assuming that the targets are not predictable enough for this. Our algorithm is however based on radars capable of anticipating the positions of short-term targets, thanks to a Kalman filter. The algorithm will be illustrated based on a multi-radar tracking scenario where the radars, autonomous, must follow a set of targets in order to reduce the position uncertainty of the targets. Standby aspects will not be considered in this scenario. It is assumed that the radars can pick up targets in active pursuit, with an area ofuncertainty corresponding to their distance.",
        "published": "2022-05-11T08:22:28Z",
        "link": "http://arxiv.org/abs/2205.05334v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Learning to Retrieve Videos by Asking Questions",
        "authors": [
            "Avinash Madasu",
            "Junier Oliva",
            "Gedas Bertasius"
        ],
        "summary": "The majority of traditional text-to-video retrieval systems operate in static environments, i.e., there is no interaction between the user and the agent beyond the initial textual query provided by the user. This can be sub-optimal if the initial query has ambiguities, which would lead to many falsely retrieved videos. To overcome this limitation, we propose a novel framework for Video Retrieval using Dialog (ViReD), which enables the user to interact with an AI agent via multiple rounds of dialog, where the user refines retrieved results by answering questions generated by an AI agent. Our novel multimodal question generator learns to ask questions that maximize the subsequent video retrieval performance using (i) the video candidates retrieved during the last round of interaction with the user and (ii) the text-based dialog history documenting all previous interactions, to generate questions that incorporate both visual and linguistic cues relevant to video retrieval. Furthermore, to generate maximally informative questions, we propose an Information-Guided Supervision (IGS), which guides the question generator to ask questions that would boost subsequent video retrieval accuracy. We validate the effectiveness of our interactive ViReD framework on the AVSD dataset, showing that our interactive method performs significantly better than traditional non-interactive video retrieval systems. We also demonstrate that our proposed approach generalizes to the real-world settings that involve interactions with real humans, thus, demonstrating the robustness and generality of our framework",
        "published": "2022-05-11T19:14:39Z",
        "link": "http://arxiv.org/abs/2205.05739v3",
        "categories": [
            "cs.CV",
            "cs.AI",
            "cs.CL",
            "cs.HC",
            "cs.MA"
        ]
    },
    {
        "title": "Learning to Guide Multiple Heterogeneous Actors from a Single Human   Demonstration via Automatic Curriculum Learning in StarCraft II",
        "authors": [
            "Nicholas Waytowich",
            "James Hare",
            "Vinicius G. Goecks",
            "Mark Mittrick",
            "John Richardson",
            "Anjon Basak",
            "Derrik E. Asher"
        ],
        "summary": "Traditionally, learning from human demonstrations via direct behavior cloning can lead to high-performance policies given that the algorithm has access to large amounts of high-quality data covering the most likely scenarios to be encountered when the agent is operating. However, in real-world scenarios, expert data is limited and it is desired to train an agent that learns a behavior policy general enough to handle situations that were not demonstrated by the human expert. Another alternative is to learn these policies with no supervision via deep reinforcement learning, however, these algorithms require a large amount of computing time to perform well on complex tasks with high-dimensional state and action spaces, such as those found in StarCraft II. Automatic curriculum learning is a recent mechanism comprised of techniques designed to speed up deep reinforcement learning by adjusting the difficulty of the current task to be solved according to the agent's current capabilities. Designing a proper curriculum, however, can be challenging for sufficiently complex tasks, and thus we leverage human demonstrations as a way to guide agent exploration during training. In this work, we aim to train deep reinforcement learning agents that can command multiple heterogeneous actors where starting positions and overall difficulty of the task are controlled by an automatically-generated curriculum from a single human demonstration. Our results show that an agent trained via automated curriculum learning can outperform state-of-the-art deep reinforcement learning baselines and match the performance of the human expert in a simulated command and control task in StarCraft II modeled over a real military scenario.",
        "published": "2022-05-11T21:53:11Z",
        "link": "http://arxiv.org/abs/2205.05784v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "I.2.6; I.2.11"
        ]
    },
    {
        "title": "Aphorisms on Epidemiological Modelling",
        "authors": [
            "Juan Afanador"
        ],
        "summary": "Epidemiological modelling is critiqued towards a scientific practice of negativity in the context of Scotland's Centre of Expertise on Animal Disease Outbreaks (EPIC). The paratactical approach to the melancholy science is invoked to problematise One Health, the intra-pandemic modelling culture, and to delineate an inkling of the negative in EPIC's work.",
        "published": "2022-05-12T15:08:22Z",
        "link": "http://arxiv.org/abs/2205.07632v1",
        "categories": [
            "physics.soc-ph",
            "cs.MA"
        ]
    },
    {
        "title": "Collaborative Multi-agent Stochastic Linear Bandits",
        "authors": [
            "Ahmadreza Moradipari",
            "Mohammad Ghavamzadeh",
            "Mahnoosh Alizadeh"
        ],
        "summary": "We study a collaborative multi-agent stochastic linear bandit setting, where $N$ agents that form a network communicate locally to minimize their overall regret. In this setting, each agent has its own linear bandit problem (its own reward parameter) and the goal is to select the best global action w.r.t. the average of their reward parameters. At each round, each agent proposes an action, and one action is randomly selected and played as the network action. All the agents observe the corresponding rewards of the played actions and use an accelerated consensus procedure to compute an estimate of the average of the rewards obtained by all the agents. We propose a distributed upper confidence bound (UCB) algorithm and prove a high probability bound on its $T$-round regret in which we include a linear growth of regret associated with each communication round. Our regret bound is of order $\\mathcal{O}\\Big(\\sqrt{\\frac{T}{N \\log(1/|\\lambda_2|)}}\\cdot (\\log T)^2\\Big)$, where $\\lambda_2$ is the second largest (in absolute value) eigenvalue of the communication matrix.",
        "published": "2022-05-12T19:46:35Z",
        "link": "http://arxiv.org/abs/2205.06331v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "MOPaC: The Multiple Offers Protocol for Multilateral Negotiations with   Partial Consensus",
        "authors": [
            "Pradeep K. Murukannaiah",
            "Catholijn M. Jonker"
        ],
        "summary": "Existing protocols for multilateral negotiation require a full consensus among the negotiating parties. In contrast, we propose a protocol for multilateral negotiation that allows partial consensus, wherein only a subset of the negotiating parties can reach an agreement. We motivate problems that require such a protocol and describe the protocol formally.",
        "published": "2022-05-13T14:27:11Z",
        "link": "http://arxiv.org/abs/2205.06678v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Emergent Bartering Behaviour in Multi-Agent Reinforcement Learning",
        "authors": [
            "Michael Bradley Johanson",
            "Edward Hughes",
            "Finbarr Timbers",
            "Joel Z. Leibo"
        ],
        "summary": "Advances in artificial intelligence often stem from the development of new environments that abstract real-world situations into a form where research can be done conveniently. This paper contributes such an environment based on ideas inspired by elementary Microeconomics. Agents learn to produce resources in a spatially complex world, trade them with one another, and consume those that they prefer. We show that the emergent production, consumption, and pricing behaviors respond to environmental conditions in the directions predicted by supply and demand shifts in Microeconomics. We also demonstrate settings where the agents' emergent prices for goods vary over space, reflecting the local abundance of goods. After the price disparities emerge, some agents then discover a niche of transporting goods between regions with different prevailing prices -- a profitable strategy because they can buy goods where they are cheap and sell them where they are expensive. Finally, in a series of ablation experiments, we investigate how choices in the environmental rewards, bartering actions, agent architecture, and ability to consume tradable goods can either aid or inhibit the emergence of this economic behavior. This work is part of the environment development branch of a research program that aims to build human-like artificial general intelligence through multi-agent interactions in simulated societies. By exploring which environment features are needed for the basic phenomena of elementary microeconomics to emerge automatically from learning, we arrive at an environment that differs from those studied in prior multi-agent reinforcement learning work along several dimensions. For example, the model incorporates heterogeneous tastes and physical abilities, and agents negotiate with one another as a grounded form of communication.",
        "published": "2022-05-13T16:44:51Z",
        "link": "http://arxiv.org/abs/2205.06760v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Principal-Agent Hypothesis Testing",
        "authors": [
            "Stephen Bates",
            "Michael I. Jordan",
            "Michael Sklar",
            "Jake A. Soloff"
        ],
        "summary": "Consider the relationship between a regulator (the principal) and an experimenter (the agent) such as a pharmaceutical company. The pharmaceutical company wishes to sell a drug for profit, whereas the regulator wishes to allow only efficacious drugs to be marketed. The efficacy of the drug is not known to the regulator, so the pharmaceutical company must run a costly trial to prove efficacy to the regulator. Critically, the statistical protocol used to establish efficacy affects the behavior of a strategic, self-interested agent; a lower standard of statistical evidence incentivizes the agent to run more trials that are less likely to be effective. The interaction between the statistical protocol and the incentives of the pharmaceutical company is crucial for understanding this system and designing protocols with high social utility. In this work, we discuss how the regulator can set up a protocol with payoffs based on statistical evidence. We show how to design protocols that are robust to an agent's strategic actions, and derive the optimal protocol in the presence of strategic entrants.",
        "published": "2022-05-13T17:59:23Z",
        "link": "http://arxiv.org/abs/2205.06812v3",
        "categories": [
            "cs.GT",
            "cs.LG",
            "cs.MA",
            "math.ST",
            "stat.ME",
            "stat.TH"
        ]
    },
    {
        "title": "LB-OPAR: Load Balanced Optimized Predictive and Adaptive Routing for   Cooperative UAV Networks",
        "authors": [
            "Mohammed Gharib",
            "Fatemeh Afghah",
            "Elizabeth Serena Bentley"
        ],
        "summary": "Cooperative ad-hoc UAV networks have been turning into the primary solution set for situations where establishing a communication infrastructure is not feasible. Search-and-rescue after a disaster and intelligence, surveillance, and reconnaissance (ISR) are two examples where the UAV nodes need to send their collected data cooperatively into a central decision maker unit. Recently proposed SDN-based solutions show incredible performance in managing different aspects of such networks. Alas, the routing problem for the highly dynamic UAV networks has not been addressed adequately. An optimal, reliable, and adaptive routing algorithm compatible with the SDN design and highly dynamic nature of such networks is required to improve the network performance. This paper proposes a load-balanced optimized predictive and adaptive routing (LB-OPAR), an SDN-based routing solution for cooperative UAV networks. LB-OPAR is the extension of our recently published routing algorithm (OPAR) that balances the network load and optimizes the network performance in terms of throughput, success rate, and flow completion time (FCT). We analytically model the routing problem in highly dynamic UAV network and propose a lightweight algorithmic solution to find the optimal solution with $O(|E|^2)$ time complexity where $|E|$ is the total number of network links. We exhaustively evaluate the proposed algorithm's performance using ns-3 network simulator. Results show that LB-OPAR outperforms the benchmark algorithms by $20\\%$ in FCT, by $30\\%$ in flow success rate on average, and up to $400\\%$ in throughput.",
        "published": "2022-05-14T20:28:41Z",
        "link": "http://arxiv.org/abs/2205.07126v1",
        "categories": [
            "cs.NI",
            "cs.MA",
            "cs.PF"
        ]
    },
    {
        "title": "Understanding Emergent Behaviours in Multi-Agent Systems with   Evolutionary Game Theory",
        "authors": [
            "The Anh Han"
        ],
        "summary": "The mechanisms of emergence and evolution of collective behaviours in dynamical Multi-Agent Systems (MAS) of multiple interacting agents, with diverse behavioral strategies in co-presence, have been undergoing mathematical study via Evolutionary Game Theory (EGT). Their systematic study also resorts to agent-based modelling and simulation (ABM) techniques, thus enabling the study of aforesaid mechanisms under a variety of conditions, parameters, and alternative virtual games. This paper summarises some main research directions and challenges tackled in our group, using methods from EGT and ABM. These range from the introduction of cognitive and emotional mechanisms into agents' implementation in an evolving MAS, to the cost-efficient interference for promoting prosocial behaviours in complex networks, to the regulation and governance of AI safety development ecology, and to the equilibrium analysis of random evolutionary multi-player games. This brief aims to sensitize the reader to EGT based issues, results and prospects, which are accruing in importance for the modeling of minds with machines and the engineering of prosocial behaviours in dynamical MAS, with impact on our understanding of the emergence and stability of collective behaviours. In all cases, important open problems in MAS research as viewed or prioritised by the group are described.",
        "published": "2022-05-15T20:01:48Z",
        "link": "http://arxiv.org/abs/2205.07369v1",
        "categories": [
            "cs.AI",
            "cs.MA",
            "math.DS",
            "nlin.AO"
        ]
    },
    {
        "title": "Behaviour Explanation via Causal Analysis of Mental States: A   Preliminary Report",
        "authors": [
            "Shakil M. Khan"
        ],
        "summary": "Inspired by a novel action-theoretic formalization of actual cause, Khan and Lesp\\'erance (2021) recently proposed a first account of causal knowledge that supports epistemic effects, models causal knowledge dynamics, and allows sensing actions to be causes of observed effects. To date, no other study has looked specifically at these issues. But their formalization is not sufficiently expressive enough to model explanations via causal analysis of mental states as it ignores a crucial aspect of theory of mind, namely motivations. In this paper, we build on their work to support causal reasoning about conative effects. In our framework, one can reason about causes of motivational states, and we allow motivation-altering actions to be causes of observed effects. We illustrate that this formalization along with a model of goal recognition can be utilized to explain agent behaviour in communicative multiagent contexts.",
        "published": "2022-05-16T04:46:50Z",
        "link": "http://arxiv.org/abs/2205.07443v1",
        "categories": [
            "cs.AI",
            "cs.LO",
            "cs.MA",
            "I.2.11; I.2.4"
        ]
    },
    {
        "title": "Communication-Free Shepherding Navigation with Multiple Steering Agents",
        "authors": [
            "Aiyi Li",
            "Masaki Ogura",
            "Naoki Wakamiya"
        ],
        "summary": "Swarm guidance addresses a challenging problem considering the navigation and control of a group of passive agents. To solve this problem, shepherding offers a bio-inspired technique of navigating such group of agents by using external steering agents with appropriately designed movement law. Although most shepherding researches are mainly based on the availability of centralized instructions, these assumptions are not realistic enough to solve some emerging application problems. Therefore, this paper presents a decentralized shepherding method where each steering agent makes movements based on its own observation without any inter-agent communication. Our numerical simulations confirm the effectiveness of the proposed method by showing its high success rate and low costs in various placement patterns. These advantages particularly improve with the increase in the number of steering agents.",
        "published": "2022-05-17T07:47:47Z",
        "link": "http://arxiv.org/abs/2205.08155v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Moving Smart Contracts -- A Privacy Preserving Method for Off-Chain Data   Trust",
        "authors": [
            "Simon Tschirner",
            "Shashank Shekher Tripathi",
            "Mathias Roeper",
            "Markus M. Becker",
            "Volker Skwarek"
        ],
        "summary": "Blockchains provide environments where parties can interact transparently and securely peer-to-peer without needing a trusted third party. Parties can trust the integrity and correctness of transactions and the verifiable execution of binary code on the blockchain (smart contracts) inside the system. Including information from outside of the blockchain remains challenging. A challenge is data privacy. In a public system, shared data becomes public and, coming from a single source, often lacks credibility. A private system gives the parties control over their data and sources but trades in positive aspects as transparency. Often, not the data itself is the most critical information but the result of a computation performed on it.   An example is research data certification. To keep data private but still prove data provenance, researchers can store a hash value of that data on the blockchain. This hash value is either calculated locally on private data without the chance for validation or is calculated on the blockchain, meaning that data must be published and stored on the blockchain -- a problem of the overall data amount stored on and distributed with the ledger. A system we called moving smart contracts bypasses this problem: Data remain local, but trusted nodes can access them and execute trusted smart contract code stored on the blockchain. This method avoids the system-wide distribution of research data and makes it accessible and verifiable with trusted software.",
        "published": "2022-05-17T15:32:33Z",
        "link": "http://arxiv.org/abs/2205.08440v2",
        "categories": [
            "cs.CR",
            "cs.DC",
            "cs.MA",
            "cs.SE",
            "C.2.4; E.2; E.3"
        ]
    },
    {
        "title": "A general framework for optimising cost-effectiveness of pandemic   response under partial intervention measures",
        "authors": [
            "Quang Dang Nguyen",
            "Mikhail Prokopenko"
        ],
        "summary": "The COVID-19 pandemic created enormous public health and socioeconomic challenges. The health effects of vaccination and non-pharmaceutical interventions (NPIs) were often contrasted with significant social and economic costs. We describe a general framework aimed to derive adaptive cost-effective interventions, adequate for both recent and emerging pandemic threats. We also quantify the net health benefits and propose a reinforcement learning approach to optimise adaptive NPIs. The approach utilises an agent-based model simulating pandemic responses in Australia, and accounts for a heterogeneous population with variable levels of compliance fluctuating over time and across individuals. Our analysis shows that a significant net health benefit may be attained by adaptive NPIs formed by partial social distancing measures, coupled with moderate levels of the society's willingness to pay for health gains (health losses averted). We demonstrate that a socially acceptable balance between health effects and incurred economic costs is achievable over a long term, despite possible early setbacks.",
        "published": "2022-05-18T15:29:46Z",
        "link": "http://arxiv.org/abs/2205.08996v2",
        "categories": [
            "cs.MA",
            "econ.GN",
            "physics.soc-ph",
            "q-bio.PE",
            "q-fin.EC"
        ]
    },
    {
        "title": "Cordial Miners: Fast and Efficient Consensus for Every Eventuality",
        "authors": [
            "Idit Keidar",
            "Oded Naor",
            "Ouri Poupko",
            "Ehud Shapiro"
        ],
        "summary": "Cordial Miners are a family of efficient Byzantine Atomic Broadcast protocols, with instances for asynchrony and eventual synchrony.   They improve the latency of state-of-the-art DAG-based protocols by almost 2X and achieve optimal good-case complexity of O(n) by forgoing Reliable Broadcast as a building block.   Rather, Cordial Miners use the blocklace -- a partially-ordered counterpart of the totally-ordered blockchain data structure -- to implement the three algorithmic components of consensus: Dissemination, equivocation-exclusion, and ordering.",
        "published": "2022-05-18T18:45:20Z",
        "link": "http://arxiv.org/abs/2205.09174v6",
        "categories": [
            "cs.DC",
            "cs.MA",
            "cs.NI"
        ]
    },
    {
        "title": "Centralized Model-Predictive Control with Human-Driver Interaction for   Platooning",
        "authors": [
            "Justin M. Kennedy",
            "Julian Heinovski",
            "Daniel E. Quevedo",
            "Falko Dressler"
        ],
        "summary": "Cooperative adaptive cruise control presents an opportunity to improve road transportation through increase in road capacity and reduction in energy use and accidents. Clever design of control algorithms and communication systems is required to ensure that the vehicle platoon is stable and meets desired safety requirements. In this paper, we propose a centralized model predictive controller for a heterogeneous platoon of vehicles to reach a desired platoon velocity and individual inter-vehicle distances with driver-selected headway time. As a novel concept, we allow for interruption from a human driver in the platoon that temporarily takes control of their vehicle with the assumption that the driver will, at minimum, obey legal velocity limits and the physical performance constraints of their vehicle. The finite horizon cost function of our proposed platoon controller is inspired from the infinite horizon design. To the best of our knowledge, this is the first platoon controller that integrates human-driven vehicles. We illustrate the performance of our proposed design with a numerical study, demonstrating that the safety distance, velocity, and actuation constraints are obeyed. Additionally, in simulation we illustrate a key property of string stability where the impact of a disturbance is reduced through the platoon.",
        "published": "2022-05-19T00:46:30Z",
        "link": "http://arxiv.org/abs/2205.09259v5",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Learning Progress Driven Multi-Agent Curriculum",
        "authors": [
            "Wenshuai Zhao",
            "Zhiyuan Li",
            "Joni Pajarinen"
        ],
        "summary": "Curriculum reinforcement learning (CRL) aims to speed up learning by gradually increasing the difficulty of a task, usually quantified by the achievable expected return. Inspired by the success of CRL in single-agent settings, a few works have attempted to apply CRL to multi-agent reinforcement learning (MARL) using the number of agents to control task difficulty. However, existing works typically use manually defined curricula such as a linear scheme. In this paper, we first apply state-of-the-art single-agent self-paced CRL to sparse reward MARL. Although with satisfying performance, we identify two potential flaws of the curriculum generated by existing reward-based CRL methods: (1) tasks with high returns may not provide informative learning signals and (2) the exacerbated credit assignment difficulty in tasks where more agents yield higher returns. Thereby, we further propose self-paced MARL (SPMARL) to prioritize tasks based on \\textit{learning progress} instead of the episode return. Our method not only outperforms baselines in three challenging sparse-reward benchmarks but also converges faster than self-paced CRL.",
        "published": "2022-05-20T08:16:30Z",
        "link": "http://arxiv.org/abs/2205.10016v2",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Correct by Design Coordination of Autonomous Driving Systems",
        "authors": [
            "Marius Bozga",
            "Joseph Sifakis"
        ],
        "summary": "The paper proposes a method for the correct by design coordination of autonomous driving systems (ADS). It builds on previous results on collision avoidance policies and the modeling of ADS by combining descriptions of their static environment in the form of maps, and the dynamic behavior of their vehicles. An ADS is modeled as a dynamic system involving a set of vehicles coordinated by a Runtime that based on vehicle positions on a map and their kinetic attributes, computes free spaces for each vehicle. Vehicles are bounded to move within the corresponding allocated free spaces. We provide a correct by design safe control policy for an ADS if its vehicles and the Runtime respect corresponding assume-guarantee contracts. The result is established by showing that the composition of assume-guarantee contracts is an inductive invariant that entails ADS safety. We show that it is practically possible to define speed control policies for vehicles that comply with their contracts. Furthermore, we show that traffic rules can be specified in a linear-time temporal logic, as a class of formulas that constrain vehicle speeds. The main result is that, given a set of traffic rules, it is possible to derive free space policies of the Runtime such that the resulting system behavior is safe by design with respect to the rules.",
        "published": "2022-05-20T09:17:42Z",
        "link": "http://arxiv.org/abs/2205.10037v1",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Decentralized Autonomous Organizations for Tax Credit's Tracking",
        "authors": [
            "Giovanni De Gasperis",
            "Sante Dino Facchini",
            "Alessio Susco"
        ],
        "summary": "Tax credit stimulus and fiscal bonuses had a very important impact on Italian economy in the last decade. Along with a huge expansion in constructions a relevant increase in scams and frauds has come too. The aim of this article is to design a possible system to track and control the whole tax credit process from its generation to its redeem through a Decentralized Autonomous Organization architecture enriched with a Multi Agent Systems to implement controllers.",
        "published": "2022-05-20T10:43:39Z",
        "link": "http://arxiv.org/abs/2205.10075v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Kernel Estimates as General Concept for the Measuring of Pedestrian   Density",
        "authors": [
            "Jana Vacková",
            "Marek Bukáček"
        ],
        "summary": "The standard definition of pedestrian density produces scattered values, hence, many approaches have been developed to improve the features of the estimated density. This paper provides a review of generally applied methods and presents a general framework based on various kernels that bring desired properties of density estimates (e.g., continuity) and incorporate ordinarily used methods. The developed kernel concept considers each pedestrian as a source of density distribution, parametrized by the kernel type (e.g., Gauss, cone) and kernel size. The quantitative parametric study performed on experimental data illustrates that parametrization brings desired features, for instance, a conic kernel with a base radius in (0.7, 1.2) m produces smooth values that retain trend features. The correspondence between kernel and non-kernel methods (namely Voronoi diagram and customized inverse distance to the nearest pedestrian) is achievable for a wide range of kernel parameter. Thereby the generality of the concept is supported.",
        "published": "2022-05-20T12:39:27Z",
        "link": "http://arxiv.org/abs/2205.10145v2",
        "categories": [
            "physics.soc-ph",
            "cs.MA",
            "nlin.AO",
            "stat.AP"
        ]
    },
    {
        "title": "Random Coordinate Descent for Resource Allocation in Open Multi-Agent   Systems",
        "authors": [
            "Charles Monnoyer de Galland",
            "Renato Vizuete",
            "Julien M. Hendrickx",
            "Elena Panteley",
            "Paolo Frasca"
        ],
        "summary": "We propose a method for analyzing the distributed random coordinate descent algorithm for solving separable resource allocation problems in the context of an open multiagent system, where agents can be replaced during the process. In particular, we characterize the evolution of the distance to the minimizer in expectation by following a time-varying optimization approach which builds on two components. First, we establish the linear convergence of the algorithm in closed systems, in terms of the estimate towards the minimizer, for general graphs and appropriate step-size. Second, we estimate the change of the optimal solution after a replacement, in order to evaluate its effect on the distance between the current estimate and the minimizer. From these two elements, we derive stability conditions in open systems and establish the linear convergence of the algorithm towards a steady-state expected error. Our results enable to characterize the trade-off between speed of convergence and robustness to agent replacements, under the assumptions that local functions are smooth, strongly convex, and have their minimizers located in a given ball. The approach proposed in this paper can moreover be extended to other algorithms guaranteeing linear convergence in closed system.",
        "published": "2022-05-20T15:42:08Z",
        "link": "http://arxiv.org/abs/2205.10259v2",
        "categories": [
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "Multi-stage Resilience Management of Smart Power Distribution Systems: A   Stochastic Robust Optimization Model",
        "authors": [
            "Nariman L. Dehghani",
            "Abdollah Shafieezadeh"
        ],
        "summary": "Significant outages from weather and climate extremes have highlighted the critical need for resilience-centered risk management of the grid. This paper proposes a multi-stage stochastic robust optimization (SRO) model that advances the existing planning frameworks on two main fronts. First, it captures interactions of operational measures with hardening decisions. Second, it properly treats the multitude of uncertainties in planning. The SRO model coordinates hardening and system operational measures for smart power distribution systems equipped with distributed generation units and switches. To capture the uncertainty in the incurred damage by extreme events, an uncertainty set is developed by integrating probabilistic information of hurricanes with the performance of overhead structures. A novel probabilistic model for the repair time of damaged lines is derived to account for the uncertainty in the recovery process. A solution strategy based on the integration of a differential evolution algorithm and a mixed-integer solver is designed to solve the resilience maximization model. The proposed approach is applied to a modified IEEE 33-bus system with 485 utility poles and a 118-bus system with 1841 poles. The systems are mapped on the Harris County, TX, U.S. Results reveal that optimal hardening decisions can be significantly influenced by resilience operational measures.",
        "published": "2022-05-20T23:22:21Z",
        "link": "http://arxiv.org/abs/2205.10459v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Multi-Agent Feedback Enabled Neural Networks for Intelligent   Communications",
        "authors": [
            "Fanglei Sun",
            "Yang Li",
            "Ying Wen",
            "Jingchen Hu",
            "Jun Wang",
            "Yang Yang",
            "Kai Li"
        ],
        "summary": "In the intelligent communication field, deep learning (DL) has attracted much attention due to its strong fitting ability and data-driven learning capability. Compared with the typical DL feedforward network structures, an enhancement structure with direct data feedback have been studied and proved to have better performance than the feedfoward networks. However, due to the above simple feedback methods lack sufficient analysis and learning ability on the feedback data, it is inadequate to deal with more complicated nonlinear systems and therefore the performance is limited for further improvement. In this paper, a novel multi-agent feedback enabled neural network (MAFENN) framework is proposed, which make the framework have stronger feedback learning capabilities and more intelligence on feature abstraction, denoising or generation, etc. Furthermore, the MAFENN framework is theoretically formulated into a three-player Feedback Stackelberg game, and the game is proved to converge to the Feedback Stackelberg equilibrium. The design of MAFENN framework and algorithm are dedicated to enhance the learning capability of the feedfoward DL networks or their variations with the simple data feedback. To verify the MAFENN framework's feasibility in wireless communications, a multi-agent MAFENN based equalizer (MAFENN-E) is developed for wireless fading channels with inter-symbol interference (ISI). Experimental results show that when the quadrature phase-shift keying (QPSK) modulation scheme is adopted, the SER performance of our proposed method outperforms that of the traditional equalizers by about 2 dB in linear channels. When in nonlinear channels, the SER performance of our proposed method outperforms that of either traditional or DL based equalizers more significantly, which shows the effectiveness and robustness of our proposal in the complex channel environment.",
        "published": "2022-05-22T05:28:43Z",
        "link": "http://arxiv.org/abs/2205.10750v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "eess.SP"
        ]
    },
    {
        "title": "Social Practices: a Complete Formalization",
        "authors": [
            "Frank Dignum"
        ],
        "summary": "Multi-agent models are a suitable starting point to model complex social interactions. However, as the complexity of the systems increase, we argue that novel modeling approaches are needed that can deal with inter-dependencies at different levels of society, where many heterogeneous parties (software agents, robots, humans) are interacting and reacting to each other. In this paper, we present a formalization of a social framework for agents based on the concept of Social Practices as high level specifications of normal (expected) behavior in a given social context. We argue that social practices facilitate the practical reasoning of agents in standard social interactions. Thus they can support deliberations for complex situations just like conventions and norms. However, they also come with a social context that gives handles for social planning and deliberation in top of the normal functional deliberation. The main goal of this paper is to give a formalization of social practices that can be used as a basis for implementations and defining precise structures within which social learning can take place.",
        "published": "2022-05-22T09:58:42Z",
        "link": "http://arxiv.org/abs/2206.06088v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Semi-Decentralized Federated Learning with Collaborative Relaying",
        "authors": [
            "Michal Yemini",
            "Rajarshi Saha",
            "Emre Ozfatura",
            "Deniz Gündüz",
            "Andrea J. Goldsmith"
        ],
        "summary": "We present a semi-decentralized federated learning algorithm wherein clients collaborate by relaying their neighbors' local updates to a central parameter server (PS). At every communication round to the PS, each client computes a local consensus of the updates from its neighboring clients and eventually transmits a weighted average of its own update and those of its neighbors to the PS. We appropriately optimize these averaging weights to ensure that the global update at the PS is unbiased and to reduce the variance of the global update at the PS, consequently improving the rate of convergence. Numerical simulations substantiate our theoretical claims and demonstrate settings with intermittent connectivity between the clients and the PS, where our proposed algorithm shows an improved convergence rate and accuracy in comparison with the federated averaging algorithm.",
        "published": "2022-05-23T02:16:53Z",
        "link": "http://arxiv.org/abs/2205.10998v1",
        "categories": [
            "cs.LG",
            "cs.DC",
            "cs.MA"
        ]
    },
    {
        "title": "Learning to Advise and Learning from Advice in Cooperative Multi-Agent   Reinforcement Learning",
        "authors": [
            "Yue Jin",
            "Shuangqing Wei",
            "Jian Yuan",
            "Xudong Zhang"
        ],
        "summary": "Learning to coordinate is a daunting problem in multi-agent reinforcement learning (MARL). Previous works have explored it from many facets, including cognition between agents, credit assignment, communication, expert demonstration, etc. However, less attention were paid to agents' decision structure and the hierarchy of coordination. In this paper, we explore the spatiotemporal structure of agents' decisions and consider the hierarchy of coordination from the perspective of multilevel emergence dynamics, based on which a novel approach, Learning to Advise and Learning from Advice (LALA), is proposed to improve MARL. Specifically, by distinguishing the hierarchy of coordination, we propose to enhance decision coordination at meso level with an advisor and leverage a policy discriminator to advise agents' learning at micro level. The advisor learns to aggregate decision information in both spatial and temporal domains and generates coordinated decisions by employing a spatiotemporal dual graph convolutional neural network with a task-oriented objective function. Each agent learns from the advice via a policy generative adversarial learning method where a discriminator distinguishes between the policies of the agent and the advisor and boosts both of them based on its judgement. Experimental results indicate the advantage of LALA over baseline approaches in terms of both learning efficiency and coordination capability. Coordination mechanism is investigated from the perspective of multilevel emergence dynamics and mutual information point of view, which provides a novel perspective and method to analyze and improve MARL algorithms.",
        "published": "2022-05-23T09:56:12Z",
        "link": "http://arxiv.org/abs/2205.11163v1",
        "categories": [
            "cs.MA",
            "cs.LG"
        ]
    },
    {
        "title": "Effective Integration of Weighted Cost-to-go and Conflict Heuristic   within Suboptimal CBS",
        "authors": [
            "Rishi Veerapaneni",
            "Tushar Kusnur",
            "Maxim Likhachev"
        ],
        "summary": "Conflict-Based Search (CBS) is a popular multi-agent path finding (MAPF) solver that employs a low-level single agent planner and a high-level constraint tree to resolve conflicts. The vast majority of modern MAPF solvers focus on improving CBS by reducing the size of this tree through various strategies with few methods modifying the low level planner. Typically low level planners in existing CBS methods use an unweighted cost-to-go heuristic, with suboptimal CBS methods also using a conflict heuristic to help the high level search. In this paper, we show that, contrary to prevailing CBS beliefs, a weighted cost-to-go heuristic can be used effectively alongside the conflict heuristic in two possible variants. In particular, one of these variants can obtain large speedups, 2-100x, across several scenarios and suboptimal CBS methods. Importantly, we discover that performance is related not to the weighted cost-to-go heuristic but rather to the relative conflict heuristic weight's ability to effectively balance low-level and high-level work. Additionally, to the best of our knowledge, we show the first theoretical relation of prioritized planning and bounded suboptimal CBS and demonstrate that our methods are their natural generalization. Update March 2024: We found that the relative speedup decreases to around 1.2-10x depending on how the conflict heuristic is computed (see appendix for more details).",
        "published": "2022-05-23T20:49:40Z",
        "link": "http://arxiv.org/abs/2205.11624v5",
        "categories": [
            "cs.AI",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "A Mechanized Proof of Bounded Convergence Time for the Distributed   Perimeter Surveillance System (DPSS) Algorithm A",
        "authors": [
            "David Greve",
            "Jennifer Davis",
            "Laura Humphrey"
        ],
        "summary": "The decentralized perimeter surveillance system (DPSS) seeks to provide a decentralized protocol for evenly distributing surveillance of a perimeter over time across an ensemble of unmanned aerial vehicles (UAVs) whose members may communicate only when in close proximity to each other. The protocol must also converge to an even distribution of the perimeter in bounded time. Two versions of the DPSS protocol presented in the original paper seem to converge in bounded time but only informal proofs and arguments are given. A later application of model checking to these protocols found an error in one of the key lemmas, invalidating the informal proof for one and casting doubt on the other. Therefore, a new hand proof of the convergence time for the simpler version of the DPSS protocol or algorithm, Algorithm A or DPSS-A, was developed by Jeremy Avigad and Floris van Doorn. This paper describes a mechanization of that hand proof in the logic of ACL2 and discusses three specific ACL2 utilities that proved useful for expressing and reasoning about the DPSS model.",
        "published": "2022-05-24T01:15:41Z",
        "link": "http://arxiv.org/abs/2205.11697v1",
        "categories": [
            "cs.LO",
            "cs.MA"
        ]
    },
    {
        "title": "Justifying Social-Choice Mechanism Outcome for Improving Participant   Satisfaction",
        "authors": [
            "Sharadhi Alape Suryanarayana",
            "David Sarne",
            "Sarit Kraus"
        ],
        "summary": "In many social-choice mechanisms the resulting choice is not the most preferred one for some of the participants, thus the need for methods to justify the choice made in a way that improves the acceptance and satisfaction of said participants. One natural method for providing such explanations is to ask people to provide them, e.g., through crowdsourcing, and choosing the most convincing arguments among those received. In this paper we propose the use of an alternative approach, one that automatically generates explanations based on desirable mechanism features found in theoretical mechanism design literature. We test the effectiveness of both of the methods through a series of extensive experiments conducted with over 600 participants in ranked voting, a classic social choice mechanism. The analysis of the results reveals that explanations indeed affect both average satisfaction from and acceptance of the outcome in such settings. In particular, explanations are shown to have a positive effect on satisfaction and acceptance when the outcome (the winning candidate in our case) is the least desirable choice for the participant. A comparative analysis reveals that the automatically generated explanations result in similar levels of satisfaction from and acceptance of an outcome as with the more costly alternative of crowdsourced explanations, hence eliminating the need to keep humans in the loop. Furthermore, the automatically generated explanations significantly reduce participants' belief that a different winner should have been elected compared to crowdsourced explanations.",
        "published": "2022-05-24T19:15:26Z",
        "link": "http://arxiv.org/abs/2205.15863v1",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.MA",
            "I.2.11"
        ]
    },
    {
        "title": "MAVIPER: Learning Decision Tree Policies for Interpretable Multi-Agent   Reinforcement Learning",
        "authors": [
            "Stephanie Milani",
            "Zhicheng Zhang",
            "Nicholay Topin",
            "Zheyuan Ryan Shi",
            "Charles Kamhoua",
            "Evangelos E. Papalexakis",
            "Fei Fang"
        ],
        "summary": "Many recent breakthroughs in multi-agent reinforcement learning (MARL) require the use of deep neural networks, which are challenging for human experts to interpret and understand. On the other hand, existing work on interpretable reinforcement learning (RL) has shown promise in extracting more interpretable decision tree-based policies from neural networks, but only in the single-agent setting. To fill this gap, we propose the first set of algorithms that extract interpretable decision-tree policies from neural networks trained with MARL. The first algorithm, IVIPER, extends VIPER, a recent method for single-agent interpretable RL, to the multi-agent setting. We demonstrate that IVIPER learns high-quality decision-tree policies for each agent. To better capture coordination between agents, we propose a novel centralized decision-tree training algorithm, MAVIPER. MAVIPER jointly grows the trees of each agent by predicting the behavior of the other agents using their anticipated trees, and uses resampling to focus on states that are critical for its interactions with other agents. We show that both algorithms generally outperform the baselines and that MAVIPER-trained agents achieve better-coordinated performance than IVIPER-trained agents on three different multi-agent particle-world environments.",
        "published": "2022-05-25T02:38:10Z",
        "link": "http://arxiv.org/abs/2205.12449v2",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "A Survey of Graph-Theoretic Approaches for Analyzing the Resilience of   Networked Control Systems",
        "authors": [
            "Mohammad Pirani",
            "Aritra Mitra",
            "Shreyas Sundaram"
        ],
        "summary": "As the scale of networked control systems increases and interactions between different subsystems become more sophisticated, questions of the resilience of such networks increase in importance. The need to redefine classical system and control-theoretic notions using the language of graphs has recently started to gain attention as a fertile and important area of research. This paper presents an overview of graph-theoretic methods for analyzing the resilience of networked control systems. We discuss various distributed algorithms operating on networked systems and investigate their resilience against adversarial actions by looking at the structural properties of their underlying networks. We present graph-theoretic methods to quantify the attack impact, and reinterpret some system-theoretic notions of robustness from a graph-theoretic standpoint to mitigate the impact of the attacks. Moreover, we discuss miscellaneous problems in the security of networked control systems which use graph-theory as a tool in their analyses. We conclude by introducing some avenues for further research in this field.",
        "published": "2022-05-25T05:16:19Z",
        "link": "http://arxiv.org/abs/2205.12498v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY",
            "math.OC"
        ]
    },
    {
        "title": "Maximising the Influence of Temporary Participants in Opinion Formation",
        "authors": [
            "Zhiqiang Zhuang",
            "Kewen Wang",
            "Zhe Wang",
            "Junhu Wang",
            "Yinong Yang"
        ],
        "summary": "DeGroot-style opinion formation presumes a continuous interaction among agents of a social network. Hence, it cannot handle agents external to the social network that interact only temporarily with the permanent ones. Many real-world organisations and individuals fall into such a category. For instance, a company tries to persuade as many as possible to buy its products and, due to various constraints, can only exert its influence for a limited amount of time. We propose a variant of the DeGroot model that allows an external agent to interact with the permanent ones for a preset period of time. We obtain several insights on maximising an external agent's influence in opinion formation by analysing and simulating the variant.",
        "published": "2022-05-25T05:40:34Z",
        "link": "http://arxiv.org/abs/2205.12503v2",
        "categories": [
            "cs.MA",
            "cs.SI"
        ]
    },
    {
        "title": "Deadlock-Free Method for Multi-Agent Pickup and Delivery Problem Using   Priority Inheritance with Temporary Priority",
        "authors": [
            "Yukita Fujitani",
            "Tomoki Yamauchi",
            "Yuki Miyashita",
            "Toshiharu Sugawara"
        ],
        "summary": "This paper proposes a control method for the multi-agent pickup and delivery problem (MAPD problem) by extending the priority inheritance with backtracking (PIBT) method to make it applicable to more general environments. PIBT is an effective algorithm that introduces a priority to each agent, and at each timestep, the agents, in descending order of priority, decide their next neighboring locations in the next timestep through communications only with the local agents. Unfortunately, PIBT is only applicable to environments that are modeled as a bi-connected area, and if it contains dead-ends, such as tree-shaped paths, PIBT may cause deadlocks. However, in the real-world environment, there are many dead-end paths to locations such as the shelves where materials are stored as well as loading/unloading locations to transportation trucks. Our proposed method enables MAPD tasks to be performed in environments with some tree-shaped paths without deadlock while preserving the PIBT feature; it does this by allowing the agents to have temporary priorities and restricting agents' movements in the trees. First, we demonstrate that agents can always reach their delivery without deadlock. Our experiments indicate that the proposed method is very efficient, even in environments where PIBT is not applicable, by comparing them with those obtained using the well-known token passing method as a baseline.",
        "published": "2022-05-25T05:45:22Z",
        "link": "http://arxiv.org/abs/2205.12504v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Trust-based Consensus in Multi-Agent Reinforcement Learning Systems",
        "authors": [
            "Ho Long Fung",
            "Victor-Alexandru Darvariu",
            "Stephen Hailes",
            "Mirco Musolesi"
        ],
        "summary": "An often neglected issue in multi-agent reinforcement learning (MARL) is the potential presence of unreliable agents in the environment whose deviations from expected behavior can prevent a system from accomplishing its intended tasks. In particular, consensus is a fundamental underpinning problem of cooperative distributed multi-agent systems. Consensus requires different agents, situated in a decentralized communication network, to reach an agreement out of a set of initial proposals that they put forward. Learning-based agents should adopt a protocol that allows them to reach consensus despite having one or more unreliable agents in the system. This paper investigates the problem of unreliable agents in MARL, considering consensus as a case study. Echoing established results in the distributed systems literature, our experiments show that even a moderate fraction of such agents can greatly impact the ability of reaching consensus in a networked environment. We propose Reinforcement Learning-based Trusted Consensus (RLTC), a decentralized trust mechanism, in which agents can independently decide which neighbors to communicate with. We empirically demonstrate that our trust mechanism is able to handle unreliable agents effectively, as evidenced by higher consensus success rates.",
        "published": "2022-05-25T15:58:34Z",
        "link": "http://arxiv.org/abs/2205.12880v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "QGNN: Value Function Factorisation with Graph Neural Networks",
        "authors": [
            "Ryan Kortvelesy",
            "Amanda Prorok"
        ],
        "summary": "In multi-agent reinforcement learning, the use of a global objective is a powerful tool for incentivising cooperation. Unfortunately, it is not sample-efficient to train individual agents with a global reward, because it does not necessarily correlate with an agent's individual actions. This problem can be solved by factorising the global value function into local value functions. Early work in this domain performed factorisation by conditioning local value functions purely on local information. Recently, it has been shown that providing both local information and an encoding of the global state can promote cooperative behaviour. In this paper we propose QGNN, the first value factorisation method to use a graph neural network (GNN) based model. The multi-layer message passing architecture of QGNN provides more representational complexity than models in prior work, allowing it to produce a more effective factorisation. QGNN also introduces a permutation invariant mixer which is able to match the performance of other methods, even with significantly fewer parameters. We evaluate our method against several baselines, including QMIX-Att, GraphMIX, QMIX, VDN, and hybrid architectures. Our experiments include Starcraft, the standard benchmark for credit assignment; Estimate Game, a custom environment that explicitly models inter-agent dependencies; and Coalition Structure Generation, a foundational problem with real-world applications. The results show that QGNN outperforms state-of-the-art value factorisation baselines consistently.",
        "published": "2022-05-25T18:35:11Z",
        "link": "http://arxiv.org/abs/2205.13005v2",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "LAMP 2.0: A Robust Multi-Robot SLAM System for Operation in Challenging   Large-Scale Underground Environments",
        "authors": [
            "Yun Chang",
            "Kamak Ebadi",
            "Christopher E. Denniston",
            "Muhammad Fadhil Ginting",
            "Antoni Rosinol",
            "Andrzej Reinke",
            "Matteo Palieri",
            "Jingnan Shi",
            "Arghya Chatterjee",
            "Benjamin Morrell",
            "Ali-akbar Agha-mohammadi",
            "Luca Carlone"
        ],
        "summary": "Search and rescue with a team of heterogeneous mobile robots in unknown and large-scale underground environments requires high-precision localization and mapping. This crucial requirement is faced with many challenges in complex and perceptually-degraded subterranean environments, as the onboard perception system is required to operate in off-nominal conditions (poor visibility due to darkness and dust, rugged and muddy terrain, and the presence of self-similar and ambiguous scenes). In a disaster response scenario and in the absence of prior information about the environment, robots must rely on noisy sensor data and perform Simultaneous Localization and Mapping (SLAM) to build a 3D map of the environment and localize themselves and potential survivors. To that end, this paper reports on a multi-robot SLAM system developed by team CoSTAR in the context of the DARPA Subterranean Challenge. We extend our previous work, LAMP, by incorporating a single-robot front-end interface that is adaptable to different odometry sources and lidar configurations, a scalable multi-robot front-end to support inter- and intra-robot loop closure detection for large scale environments and multi-robot teams, and a robust back-end equipped with an outlier-resilient pose graph optimization based on Graduated Non-Convexity. We provide a detailed ablation study on the multi-robot front-end and back-end, and assess the overall system performance in challenging real-world datasets collected across mines, power plants, and caves in the United States. We also release our multi-robot back-end datasets (and the corresponding ground truth), which can serve as challenging benchmarks for large-scale underground SLAM.",
        "published": "2022-05-26T03:52:56Z",
        "link": "http://arxiv.org/abs/2205.13135v3",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "FedFormer: Contextual Federation with Attention in Reinforcement   Learning",
        "authors": [
            "Liam Hebert",
            "Lukasz Golab",
            "Pascal Poupart",
            "Robin Cohen"
        ],
        "summary": "A core issue in multi-agent federated reinforcement learning is defining how to aggregate insights from multiple agents. This is commonly done by taking the average of each participating agent's model weights into one common model (FedAvg). We instead propose FedFormer, a novel federation strategy that utilizes Transformer Attention to contextually aggregate embeddings from models originating from different learner agents. In so doing, we attentively weigh the contributions of other agents with respect to the current agent's environment and learned relationships, thus providing a more effective and efficient federation. We evaluate our methods on the Meta-World environment and find that our approach yields significant improvements over FedAvg and non-federated Soft Actor-Critic single-agent methods. Our results compared to Soft Actor-Critic show that FedFormer achieves higher episodic return while still abiding by the privacy constraints of federated learning. Finally, we also demonstrate improvements in effectiveness with increased agent pools across all methods in certain tasks. This is contrasted by FedAvg, which fails to make noticeable improvements when scaled.",
        "published": "2022-05-27T01:19:22Z",
        "link": "http://arxiv.org/abs/2205.13697v3",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Agent-based model using GPS analysis for infection spread and inhibition   mechanism of SARS-CoV-2 in Tokyo",
        "authors": [
            "Taishu Murakami",
            "Shunsuke Sakuragi",
            "Hiroshi Deguchi",
            "Masaru Nakata"
        ],
        "summary": "Analyzing the SARS-CoV-2 pandemic outbreak based on actual data while reflecting the characteristics of the real city provides beneficial information for taking reasonable infection control measures in the future. We demonstrate agent-based modeling for Tokyo based on GPS information and official national statistics and perform a spatiotemporal analysis of the infection situation in Tokyo. As a result of the simulation during the first wave of SARS-CoV-2 in Tokyo using real GPS data, the infection occurred in the service industry, such as restaurants, in the city center, and then the infected people brought back the virus to the residential area; the infection spread in each area in Tokyo. This phenomenon clarifies that the spread of infection can be curbed by suppressing going out or strengthening infection prevention measures in service facilities. It was shown that pandemic measures in Tokyo could be achieved not only by strong control, such as the lockdown of cities, but also by thorough infection prevention measures in service facilities, which explains the curb phenomena in real Tokyo.",
        "published": "2022-05-27T01:31:04Z",
        "link": "http://arxiv.org/abs/2206.02538v1",
        "categories": [
            "physics.soc-ph",
            "cs.MA",
            "q-bio.PE"
        ]
    },
    {
        "title": "Off-Beat Multi-Agent Reinforcement Learning",
        "authors": [
            "Wei Qiu",
            "Weixun Wang",
            "Rundong Wang",
            "Bo An",
            "Yujing Hu",
            "Svetlana Obraztsova",
            "Zinovi Rabinovich",
            "Jianye Hao",
            "Yingfeng Chen",
            "Changjie Fan"
        ],
        "summary": "We investigate model-free multi-agent reinforcement learning (MARL) in environments where off-beat actions are prevalent, i.e., all actions have pre-set execution durations. During execution durations, the environment changes are influenced by, but not synchronised with, action execution. Such a setting is ubiquitous in many real-world problems. However, most MARL methods assume actions are executed immediately after inference, which is often unrealistic and can lead to catastrophic failure for multi-agent coordination with off-beat actions. In order to fill this gap, we develop an algorithmic framework for MARL with off-beat actions. We then propose a novel episodic memory, LeGEM, for model-free MARL algorithms. LeGEM builds agents' episodic memories by utilizing agents' individual experiences. It boosts multi-agent learning by addressing the challenging temporal credit assignment problem raised by the off-beat actions via our novel reward redistribution scheme, alleviating the issue of non-Markovian reward. We evaluate LeGEM on various multi-agent scenarios with off-beat actions, including Stag-Hunter Game, Quarry Game, Afforestation Game, and StarCraft II micromanagement tasks. Empirical results show that LeGEM significantly boosts multi-agent coordination and achieves leading performance and improved sample efficiency.",
        "published": "2022-05-27T02:21:04Z",
        "link": "http://arxiv.org/abs/2205.13718v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Feudal Multi-Agent Reinforcement Learning with Adaptive Network   Partition for Traffic Signal Control",
        "authors": [
            "Jinming Ma",
            "Feng Wu"
        ],
        "summary": "Multi-agent reinforcement learning (MARL) has been applied and shown great potential in multi-intersections traffic signal control, where multiple agents, one for each intersection, must cooperate together to optimize traffic flow. To encourage global cooperation, previous work partitions the traffic network into several regions and learns policies for agents in a feudal structure. However, static network partition fails to adapt to dynamic traffic flow, which will changes frequently over time. To address this, we propose a novel feudal MARL approach with adaptive network partition. Specifically, we first partition the network into several regions according to the traffic flow. To do this, we propose two approaches: one is directly to use graph neural network (GNN) to generate the network partition, and the other is to use Monte-Carlo tree search (MCTS) to find the best partition with criteria computed by GNN. Then, we design a variant of Qmix using GNN to handle various dimensions of input, given by the dynamic network partition. Finally, we use a feudal hierarchy to manage agents in each partition and promote global cooperation. By doing so, agents are able to adapt to the traffic flow as required in practice. We empirically evaluate our method both in a synthetic traffic grid and real-world traffic networks of three cities, widely used in the literature. Our experimental results confirm that our method can achieve better performance, in terms of average travel time and queue length, than several leading methods for traffic signal control.",
        "published": "2022-05-27T09:02:10Z",
        "link": "http://arxiv.org/abs/2205.13836v1",
        "categories": [
            "cs.MA",
            "cs.LG"
        ]
    },
    {
        "title": "Private and Byzantine-Proof Cooperative Decision-Making",
        "authors": [
            "Abhimanyu Dubey",
            "Alex Pentland"
        ],
        "summary": "The cooperative bandit problem is a multi-agent decision problem involving a group of agents that interact simultaneously with a multi-armed bandit, while communicating over a network with delays. The central idea in this problem is to design algorithms that can efficiently leverage communication to obtain improvements over acting in isolation. In this paper, we investigate the stochastic bandit problem under two settings - (a) when the agents wish to make their communication private with respect to the action sequence, and (b) when the agents can be byzantine, i.e., they provide (stochastically) incorrect information. For both these problem settings, we provide upper-confidence bound algorithms that obtain optimal regret while being (a) differentially-private and (b) tolerant to byzantine agents. Our decentralized algorithms require no information about the network of connectivity between agents, making them scalable to large dynamic systems. We test our algorithms on a competitive benchmark of random graphs and demonstrate their superior performance with respect to existing robust algorithms. We hope that our work serves as an important step towards creating distributed decision-making systems that maintain privacy.",
        "published": "2022-05-27T18:03:54Z",
        "link": "http://arxiv.org/abs/2205.14174v1",
        "categories": [
            "stat.ML",
            "cs.CR",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Modelleme ve Simulasyon",
        "authors": [
            "Serdar Abut"
        ],
        "summary": "Computer modeling and simulation is used to analyze system behavior and evaluate strategies for operating in descriptive or predictive modes. In this part of the book, modeling and simulation approaches that have been proposed since the 1970s have been tried to be presented. Simulation models used in social sciences, risk management and cloud-based information systems are tried to be summarized, and information about agent-based modeling and simulation approach is given.",
        "published": "2022-05-27T19:15:27Z",
        "link": "http://arxiv.org/abs/2208.06344v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Deep Learning-based Spatially Explicit Emulation of an Agent-Based   Simulator for Pandemic in a City",
        "authors": [
            "Varun Madhavan",
            "Adway Mitra",
            "Partha Pratim Chakrabarti"
        ],
        "summary": "Agent-Based Models are very useful for simulation of physical or social processes, such as the spreading of a pandemic in a city. Such models proceed by specifying the behavior of individuals (agents) and their interactions, and parameterizing the process of infection based on such interactions based on the geography and demography of the city. However, such models are computationally very expensive, and the complexity is often linear in the total number of agents. This seriously limits the usage of such models for simulations, which often have to be run hundreds of times for policy planning and even model parameter estimation. An alternative is to develop an emulator, a surrogate model that can predict the Agent-Based Simulator's output based on its initial conditions and parameters. In this paper, we discuss a Deep Learning model based on Dilated Convolutional Neural Network that can emulate such an agent based model with high accuracy. We show that use of this model instead of the original Agent-Based Model provides us major gains in the speed of simulations, allowing much quicker calibration to observations, and more extensive scenario analysis. The models we consider are spatially explicit, as the locations of the infected individuals are simulated instead of the gross counts. Another aspect of our emulation framework is its divide-and-conquer approach that divides the city into several small overlapping blocks and carries out the emulation in them parallelly, after which these results are merged together. This ensures that the same emulator can work for a city of any size, and also provides significant improvement of time complexity of the emulator, compared to the original simulator.",
        "published": "2022-05-28T10:56:37Z",
        "link": "http://arxiv.org/abs/2205.14396v2",
        "categories": [
            "cs.MA",
            "cs.CY",
            "cs.LG"
        ]
    },
    {
        "title": "Agent-based Simulation of District-based Elections",
        "authors": [
            "Adway Mitra"
        ],
        "summary": "In district-based elections, electors cast votes in their respective districts. In each district, the party with maximum votes wins the corresponding seat in the governing body. The election result is based on the number of seats won by different parties. In this system, locations of electors across the districts may severely affect the election result even if the total number of votes obtained by different parties remains unchanged. A less popular party may end up winning more seats if their supporters are suitably distributed spatially. This happens due to various regional and social influences on individual voters which modulate their voting choice. In this paper, we explore agent-based models for district-based elections, where we consider each elector as an agent, and try to represent their social and geographical attributes and political inclinations using probability distributions. This model can be used to simulate election results by Monte Carlo sampling. The models allow us to explore the full space of possible outcomes of an electoral setting, though they can also be calibrated to actual election results for suitable values of parameters. We use Approximate Bayesian Computation (ABC) framework to estimate model parameters. We show that our model can reproduce the results of elections held in India and USA, and can also produce counterfactual scenarios.",
        "published": "2022-05-28T11:19:04Z",
        "link": "http://arxiv.org/abs/2205.14400v2",
        "categories": [
            "cs.MA",
            "cs.CY"
        ]
    },
    {
        "title": "Independent and Decentralized Learning in Markov Potential Games",
        "authors": [
            "Chinmay Maheshwari",
            "Manxi Wu",
            "Druv Pai",
            "Shankar Sastry"
        ],
        "summary": "We propose a multi-agent reinforcement learning dynamics, and analyze its convergence in infinite-horizon discounted Markov potential games. We focus on the independent and decentralized setting, where players do not have knowledge of the game model and cannot coordinate. In each stage, players update their estimate of Q-function that evaluates their total contingent payoff based on the realized one-stage reward in an asynchronous manner. Then, players independently update their policies by incorporating an optimal one-stage deviation strategy based on the estimated Q-function. A key feature of the learning dynamics is that the Q-function estimates are updated at a faster timescale than the policies. We prove that the policies induced by our learning dynamics converge to the set of stationary Nash equilibria in Markov potential games with probability 1. Our results highlight the efficacy of simple learning dynamics in reaching to the set of stationary Nash equilibrium even in environments with minimal information available.",
        "published": "2022-05-29T07:39:09Z",
        "link": "http://arxiv.org/abs/2205.14590v6",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.GT",
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "91A06, 91A10, 91A14, 91A25, 91A26, 91A50,"
        ]
    },
    {
        "title": "2-Dimensional Euclidean Preferences",
        "authors": [
            "Laurent Bulteau",
            "Jiehua Chen"
        ],
        "summary": "A preference profile with m alternatives and n voters is 2-dimensional Euclidean if both the alternatives and the voters can be placed into a 2-dimensional space such that for each pair of alternatives, every voter prefers the one which has a shorter Euclidean distance to the voter. We study how 2-dimensional Euclidean preference profiles depend on the values m and n. We find that any profile with at most two voters or at most three alternatives is 2-dimensional Euclidean while for three voters, we can show this property for up to seven alternatives. The results are tight in terms of Bogomolnaia and Laslier [2, Proposition 15(1)].",
        "published": "2022-05-29T15:06:14Z",
        "link": "http://arxiv.org/abs/2205.14687v1",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Random Rank: The One and Only Strategyproof and Proportionally Fair   Randomized Facility Location Mechanism",
        "authors": [
            "Haris Aziz",
            "Alexander Lam",
            "Mashbat Suzuki",
            "Toby Walsh"
        ],
        "summary": "Proportionality is an attractive fairness concept that has been applied to a range of problems including the facility location problem, a classic problem in social choice. In our work, we propose a concept called Strong Proportionality, which ensures that when there are two groups of agents at different locations, both groups incur the same total cost. We show that although Strong Proportionality is a well-motivated and basic axiom, there is no deterministic strategyproof mechanism satisfying the property. We then identify a randomized mechanism called Random Rank (which uniformly selects a number $k$ between $1$ to $n$ and locates the facility at the $k$'th highest agent location) which satisfies Strong Proportionality in expectation. Our main theorem characterizes Random Rank as the unique mechanism that achieves universal truthfulness, universal anonymity, and Strong Proportionality in expectation among all randomized mechanisms. Finally, we show via the AverageOrRandomRank mechanism that even stronger ex-post fairness guarantees can be achieved by weakening universal truthfulness to strategyproofness in expectation.",
        "published": "2022-05-30T00:51:57Z",
        "link": "http://arxiv.org/abs/2205.14798v2",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.MA",
            "econ.TH"
        ]
    },
    {
        "title": "Multi-Agent Reinforcement Learning is a Sequence Modeling Problem",
        "authors": [
            "Muning Wen",
            "Jakub Grudzien Kuba",
            "Runji Lin",
            "Weinan Zhang",
            "Ying Wen",
            "Jun Wang",
            "Yaodong Yang"
        ],
        "summary": "Large sequence model (SM) such as GPT series and BERT has displayed outstanding performance and generalization capabilities on vision, language, and recently reinforcement learning tasks. A natural follow-up question is how to abstract multi-agent decision making into an SM problem and benefit from the prosperous development of SMs. In this paper, we introduce a novel architecture named Multi-Agent Transformer (MAT) that effectively casts cooperative multi-agent reinforcement learning (MARL) into SM problems wherein the task is to map agents' observation sequence to agents' optimal action sequence. Our goal is to build the bridge between MARL and SMs so that the modeling power of modern sequence models can be unleashed for MARL. Central to our MAT is an encoder-decoder architecture which leverages the multi-agent advantage decomposition theorem to transform the joint policy search problem into a sequential decision making process; this renders only linear time complexity for multi-agent problems and, most importantly, endows MAT with monotonic performance improvement guarantee. Unlike prior arts such as Decision Transformer fit only pre-collected offline data, MAT is trained by online trials and errors from the environment in an on-policy fashion. To validate MAT, we conduct extensive experiments on StarCraftII, Multi-Agent MuJoCo, Dexterous Hands Manipulation, and Google Research Football benchmarks. Results demonstrate that MAT achieves superior performance and data efficiency compared to strong baselines including MAPPO and HAPPO. Furthermore, we demonstrate that MAT is an excellent few-short learner on unseen tasks regardless of changes in the number of agents. See our project page at https://sites.google.com/view/multi-agent-transformer.",
        "published": "2022-05-30T09:39:45Z",
        "link": "http://arxiv.org/abs/2205.14953v3",
        "categories": [
            "cs.MA",
            "cs.LG"
        ]
    },
    {
        "title": "Residual Q-Networks for Value Function Factorizing in Multi-Agent   Reinforcement Learning",
        "authors": [
            "Rafael Pina",
            "Varuna De Silva",
            "Joosep Hook",
            "Ahmet Kondoz"
        ],
        "summary": "Multi-Agent Reinforcement Learning (MARL) is useful in many problems that require the cooperation and coordination of multiple agents. Learning optimal policies using reinforcement learning in a multi-agent setting can be very difficult as the number of agents increases. Recent solutions such as Value Decomposition Networks (VDN), QMIX, QTRAN and QPLEX adhere to the centralized training and decentralized execution scheme and perform factorization of the joint action-value functions. However, these methods still suffer from increased environmental complexity, and at times fail to converge in a stable manner. We propose a novel concept of Residual Q-Networks (RQNs) for MARL, which learns to transform the individual Q-value trajectories in a way that preserves the Individual-Global-Max criteria (IGM), but is more robust in factorizing action-value functions. The RQN acts as an auxiliary network that accelerates convergence and will become obsolete as the agents reach the training objectives. The performance of the proposed method is compared against several state-of-the-art techniques such as QPLEX, QMIX, QTRAN and VDN, in a range of multi-agent cooperative tasks. The results illustrate that the proposed method, in general, converges faster, with increased stability and shows robust performance in a wider family of environments. The improvements in results are more prominent in environments with severe punishments for non-cooperative behaviours and especially in the absence of complete state information during training time.",
        "published": "2022-05-30T16:56:06Z",
        "link": "http://arxiv.org/abs/2205.15245v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Asynchronous Deterministic Leader Election in Three-Dimensional   Programmable Matter",
        "authors": [
            "Joseph L. Briones",
            "Tishya Chhabra",
            "Joshua J. Daymude",
            "Andréa W. Richa"
        ],
        "summary": "Over three decades of scientific endeavors to realize programmable matter, a substance that can change its physical properties based on user input or responses to its environment, there have been many advances in both the engineering of modular robotic systems and the corresponding algorithmic theory of collective behavior. However, while the design of modular robots routinely addresses the challenges of realistic three-dimensional (3D) space, algorithmic theory remains largely focused on 2D abstractions such as planes and planar graphs. In this work, we formalize the 3D geometric space variant for the canonical amoebot model of programmable matter, using the face-centered cubic (FCC) lattice to represent space and define local spatial orientations. We then give a distributed algorithm for leader election in connected, contractible 2D or 3D geometric amoebot systems that deterministically elects exactly one leader in $\\mathcal{O}(n)$ rounds under an unfair sequential adversary, where $n$ is the number of amoebots in the system. We then demonstrate how this algorithm can be transformed using the concurrency control framework for amoebot algorithms (DISC 2021) to obtain the first known amoebot algorithm, both in 2D and 3D space, to solve leader election under an unfair asynchronous adversary.",
        "published": "2022-05-30T20:18:28Z",
        "link": "http://arxiv.org/abs/2205.15412v2",
        "categories": [
            "cs.DC",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "A Game-Theoretic Framework for Managing Risk in Multi-Agent Systems",
        "authors": [
            "Oliver Slumbers",
            "David Henry Mguni",
            "Stephen Marcus McAleer",
            "Stefano B. Blumberg",
            "Jun Wang",
            "Yaodong Yang"
        ],
        "summary": "In order for agents in multi-agent systems (MAS) to be safe, they need to take into account the risks posed by the actions of other agents. However, the dominant paradigm in game theory (GT) assumes that agents are not affected by risk from other agents and only strive to maximise their expected utility. For example, in hybrid human-AI driving systems, it is necessary to limit large deviations in reward resulting from car crashes. Although there are equilibrium concepts in game theory that take into account risk aversion, they either assume that agents are risk-neutral with respect to the uncertainty caused by the actions of other agents, or they are not guaranteed to exist. We introduce a new GT-based Risk-Averse Equilibrium (RAE) that always produces a solution that minimises the potential variance in reward accounting for the strategy of other agents. Theoretically and empirically, we show RAE shares many properties with a Nash Equilibrium (NE), establishing convergence properties and generalising to risk-dominant NE in certain cases. To tackle large-scale problems, we extend RAE to the PSRO multi-agent reinforcement learning (MARL) framework. We empirically demonstrate the minimum reward variance benefits of RAE in matrix games with high-risk outcomes. Results on MARL experiments show RAE generalises to risk-dominant NE in a trust dilemma game and that it reduces instances of crashing by 7x in an autonomous driving setting versus the best performing baseline.",
        "published": "2022-05-30T21:20:30Z",
        "link": "http://arxiv.org/abs/2205.15434v4",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Causal Explanations for Sequential Decision Making Under Uncertainty",
        "authors": [
            "Samer B. Nashed",
            "Saaduddin Mahmud",
            "Claudia V. Goldman",
            "Shlomo Zilberstein"
        ],
        "summary": "We introduce a novel framework for causal explanations of stochastic, sequential decision-making systems built on the well-studied structural causal model paradigm for causal reasoning. This single framework can identify multiple, semantically distinct explanations for agent actions -- something not previously possible. In this paper, we establish exact methods and several approximation techniques for causal inference on Markov decision processes using this framework, followed by results on the applicability of the exact methods and some run time bounds. We discuss several scenarios that illustrate the framework's flexibility and the results of experiments with human subjects that confirm the benefits of this approach.",
        "published": "2022-05-30T23:17:58Z",
        "link": "http://arxiv.org/abs/2205.15462v2",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Zero-Emission Delivery for Logistics and Transportation: Challenges,   Research Issues, and Opportunities",
        "authors": [
            "J. Bukhari",
            "A. G. Somanagoudar",
            "L. Hou",
            "O. Herrera",
            "W. Merida"
        ],
        "summary": "Greenhouse gas, produced from various industries such as Power, Manufacturing, Transport, Chemical, or Agriculture, is the major source of global warming. While the transport industry is among the top three major contributors, accounting for 16.2% of global emissions. To counter this, many countries are responding actively to achieve net or absolute zero-emission goals by replacing fossil fuel with renewable energy sources. In response to this initiative, this chapter provides a systematic review of the use of zero-emission vehicles for a specific use case of package delivery. It first compares different green delivery systems that use unmanned aerial vehicles, electric vehicles, and fuel-cell trucks for certain weight categories. Specifically, a coordination of unmanned aerial vehicle and ground-based electric truck envisions a new paradigm of ground-based zero-emission vehicles where unmanned aerial vehicles can fly in the air beyond the visual line of sight empowered by future-generation wireless technologies. The integration of zero-emission vehicles for package delivery will encounter many challenges in analyzing, modelling, planning, and designing a green logistics system. This chapter investigates these challenges in the adoption of zero-emission vehicles with the existing research issues from a technical, environmental, economic, and political point of view. In addition, this study also sheds a new research perspective on artificial intelligence and integrated solutions for zero-emission deliveries.",
        "published": "2022-05-31T08:36:47Z",
        "link": "http://arxiv.org/abs/2205.15606v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Multi-Agent Learning of Numerical Methods for Hyperbolic PDEs with   Factored Dec-MDP",
        "authors": [
            "Yiwei Fu",
            "Dheeraj S. K. Kapilavai",
            "Elliot Way"
        ],
        "summary": "Factored decentralized Markov decision process (Dec-MDP) is a framework for modeling sequential decision making problems in multi-agent systems. In this paper, we formalize the learning of numerical methods for hyperbolic partial differential equations (PDEs), specifically the Weighted Essentially Non-Oscillatory (WENO) scheme, as a factored Dec-MDP problem. We show that different reward formulations lead to either reinforcement learning (RL) or behavior cloning, and a homogeneous policy could be learned for all agents under the RL formulation with a policy gradient algorithm. Because the trained agents only act on their local observations, the multi-agent system can be used as a general numerical method for hyperbolic PDEs and generalize to different spatial discretizations, episode lengths, dimensions, and even equation types.",
        "published": "2022-05-31T12:02:18Z",
        "link": "http://arxiv.org/abs/2205.15716v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Learning Generalizable Risk-Sensitive Policies to Coordinate in   Decentralized Multi-Agent General-Sum Games",
        "authors": [
            "Ziyi Liu",
            "Xian Guo",
            "Yongchun Fang"
        ],
        "summary": "While various multi-agent reinforcement learning methods have been proposed in cooperative settings, few works investigate how self-interested learning agents achieve mutual coordination in decentralized general-sum games and generalize pre-trained policies to non-cooperative opponents during execution. In this paper, we present Generalizable Risk-Sensitive Policy (GRSP). GRSP learns the distributions over agent's return and estimate a dynamic risk-seeking bonus to discover risky coordination strategies. Furthermore, to avoid overfitting to training opponents, GRSP learns an auxiliary opponent modeling task to infer opponents' types and dynamically alter corresponding strategies during execution. Empirically, agents trained via GRSP can achieve mutual coordination during training stably and avoid being exploited by non-cooperative opponents during execution. To the best of our knowledge, it is the first method to learn coordination strategies between agents both in iterated prisoner's dilemma (IPD) and iterated stag hunt (ISH) without shaping opponents or rewards, and firstly consider generalization during execution. Furthermore, we show that GRSP can be scaled to high-dimensional settings.",
        "published": "2022-05-31T15:09:50Z",
        "link": "http://arxiv.org/abs/2205.15859v3",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "CBS-Budget (CBSB): A Complete and Bounded Suboptimal Search for   Multi-Agent Path Finding",
        "authors": [
            "Jaein Lim",
            "Panagiotis Tsiotras"
        ],
        "summary": "Multi-Agent Path Finding (MAPF) is the problem of finding a collection of collision-free paths for a team of multiple agents while minimizing some global cost, such as the sum of the time travelled by all agents, or the time travelled by the last agent. Conflict Based Search (CBS) is a leading complete and optimal MAPF solver which lazily explores the joint agent state space, using an admissible heuristic joint plan. Such an admissible heuristic joint plan is computed by combining individual shortest paths found without considering inter-agent conflicts, and which becomes gradually more informed as constraints are added to individual agents' path planning problems to avoid discovered conflicts. In this paper, we seek to speedup CBS by finding a more informed heuristic joint plan which is bounded from above. We first propose the budgeted Class-Ordered A* (bCOA*), a novel algorithm that finds the shortest path with minimal number of conflicts that is upper bounded in terms of length. Then, we propose a novel bounded-cost variant of CBS, called CBS-Budget (CBSB) by using a bCOA* search at the low-level search of the CBS and by using a modified focal search at the high-level search of the CBS. We prove that CBSB is complete and bounded-suboptimal. In our numerical experiments, CBSB finds a near optimal solution for hundreds of agents within a fraction of a second. CBSB shows state-of-the-art performance, comparable to Explicit Estimation CBS (EECBS), an enhanced recent version of CBS. On the other hand, CBSB is easier to implement than EECBS, since only two priority queues at the high-level search are needed as in Enhanced CBS (ECBS).",
        "published": "2022-05-31T22:22:33Z",
        "link": "http://arxiv.org/abs/2206.00130v1",
        "categories": [
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Provably Efficient Offline Multi-agent Reinforcement Learning via   Strategy-wise Bonus",
        "authors": [
            "Qiwen Cui",
            "Simon S. Du"
        ],
        "summary": "This paper considers offline multi-agent reinforcement learning. We propose the strategy-wise concentration principle which directly builds a confidence interval for the joint strategy, in contrast to the point-wise concentration principle that builds a confidence interval for each point in the joint action space. For two-player zero-sum Markov games, by exploiting the convexity of the strategy-wise bonus, we propose a computationally efficient algorithm whose sample complexity enjoys a better dependency on the number of actions than the prior methods based on the point-wise bonus. Furthermore, for offline multi-agent general-sum Markov games, based on the strategy-wise bonus and a novel surrogate function, we give the first algorithm whose sample complexity only scales $\\sum_{i=1}^mA_i$ where $A_i$ is the action size of the $i$-th player and $m$ is the number of players. In sharp contrast, the sample complexity of methods based on the point-wise bonus would scale with the size of the joint action space $\\Pi_{i=1}^m A_i$ due to the curse of multiagents. Lastly, all of our algorithms can naturally take a pre-specified strategy class $\\Pi$ as input and output a strategy that is close to the best strategy in $\\Pi$. In this setting, the sample complexity only scales with $\\log |\\Pi|$ instead of $\\sum_{i=1}^mA_i$.",
        "published": "2022-06-01T00:18:15Z",
        "link": "http://arxiv.org/abs/2206.00159v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "DM$^2$: Decentralized Multi-Agent Reinforcement Learning for   Distribution Matching",
        "authors": [
            "Caroline Wang",
            "Ishan Durugkar",
            "Elad Liebman",
            "Peter Stone"
        ],
        "summary": "Current approaches to multi-agent cooperation rely heavily on centralized mechanisms or explicit communication protocols to ensure convergence. This paper studies the problem of distributed multi-agent learning without resorting to centralized components or explicit communication. It examines the use of distribution matching to facilitate the coordination of independent agents. In the proposed scheme, each agent independently minimizes the distribution mismatch to the corresponding component of a target visitation distribution. The theoretical analysis shows that under certain conditions, each agent minimizing its individual distribution mismatch allows the convergence to the joint policy that generated the target distribution. Further, if the target distribution is from a joint policy that optimizes a cooperative task, the optimal policy for a combination of this task reward and the distribution matching reward is the same joint policy. This insight is used to formulate a practical algorithm (DM$^2$), in which each individual agent matches a target distribution derived from concurrently sampled trajectories from a joint expert policy. Experimental validation on the StarCraft domain shows that combining (1) a task reward, and (2) a distribution matching reward for expert demonstrations for the same task, allows agents to outperform a naive distributed baseline. Additional experiments probe the conditions under which expert demonstrations need to be sampled to obtain the learning benefits.",
        "published": "2022-06-01T04:57:50Z",
        "link": "http://arxiv.org/abs/2206.00233v3",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG",
            "cs.RO",
            "I.2.0; I.2.8; I.2.9; I.2.11"
        ]
    },
    {
        "title": "Policy Diagnosis via Measuring Role Diversity in Cooperative Multi-agent   RL",
        "authors": [
            "Siyi Hu",
            "Chuanlong Xie",
            "Xiaodan Liang",
            "Xiaojun Chang"
        ],
        "summary": "Cooperative multi-agent reinforcement learning (MARL) is making rapid progress for solving tasks in a grid world and real-world scenarios, in which agents are given different attributes and goals, resulting in different behavior through the whole multi-agent task. In this study, we quantify the agent's behavior difference and build its relationship with the policy performance via {\\bf Role Diversity}, a metric to measure the characteristics of MARL tasks. We define role diversity from three perspectives: action-based, trajectory-based, and contribution-based to fully measure a multi-agent task. Through theoretical analysis, we find that the error bound in MARL can be decomposed into three parts that have a strong relation to the role diversity. The decomposed factors can significantly impact policy optimization on three popular directions including parameter sharing, communication mechanism, and credit assignment. The main experimental platforms are based on {\\bf Multiagent Particle Environment (MPE)} and {\\bf The StarCraft Multi-Agent Challenge (SMAC). Extensive experiments} clearly show that role diversity can serve as a robust measurement for the characteristics of a multi-agent cooperation task and help diagnose whether the policy fits the current multi-agent system for a better policy performance.",
        "published": "2022-06-01T04:58:52Z",
        "link": "http://arxiv.org/abs/2207.05683v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Propagation of epidemics in a polarized society: impact of clustering   among unvaccinated individuals",
        "authors": [
            "Ixandra Achitouv"
        ],
        "summary": "Polarization of opinions about vaccination can have a negative impact on pandemic control. In this work we quantify this negative impact for the transmission of COVID-19, using an agent based simulation in an heterogeneous population with multi-type networks, representing different types of social interactions. We show that the clustering of unvaccinated individuals, associated with polarization of opinion, can lead to significant differences in the evolution of the pandemic compared to deterministic model predictions. Under our realistic baseline scenario these differences are a 33pc increase of the effective reproduction number, a 157pc increase of infections at the peak and a 30pc increase in the final cumulative attack rate.",
        "published": "2022-06-01T09:44:49Z",
        "link": "http://arxiv.org/abs/2206.00357v1",
        "categories": [
            "physics.soc-ph",
            "cs.MA",
            "cs.SI"
        ]
    },
    {
        "title": "A kinetic description of the body size distributions of species",
        "authors": [
            "Stefano Gualandi",
            "Giuseppe Toscani",
            "Eleonora Vercesi"
        ],
        "summary": "In this paper, by resorting to classical methods of statistical mechanics, we build a kinetic model able to reproduce the observed statistical weight distribution of many diverse species. The kinetic description of the time variations of the weight distribution is based on elementary interactions that describe in a qualitative and quantitative way successive evolutionary updates, and determine explicit equilibrium distributions. Numerical fittings on mammalian eutherians of the order Chiroptera population illustrates the effectiveness of the approach.",
        "published": "2022-06-01T13:49:58Z",
        "link": "http://arxiv.org/abs/2206.00495v1",
        "categories": [
            "q-bio.PE",
            "cs.MA"
        ]
    },
    {
        "title": "helyOS: A customized off-the-shelf solution for autonomous driving   applications in delimited areas",
        "authors": [
            "Carlos Viol Barbosa",
            "Nikolay Belov",
            "Felix Keppler",
            "Julius Kolb",
            "Gunter Nitzsche",
            "Sebastian Wagner"
        ],
        "summary": "Microservice Architectures (MSA), known to successfully handle complex software systems, are emerging as the new paradigm for automotive software. The design of an MSA requires correct subdivision of the software system and implementation of the communication between components. These tasks demand both software expertise and domain knowledge. In this context, we developed an MSA framework pre-tailored to meet the requirements of autonomous driving applications in delimited areas - the helyOS framework. The framework decomposes complex applications in predefined microservice domains and provides a communication backbone for event messages and data. This paper demonstrates how such a tailored MSA framework can accelerate the development by prompting a quick start for the integration of motion planning algorithms, device controllers, vehicles simulators and web-browser interfaces.",
        "published": "2022-06-01T14:03:11Z",
        "link": "http://arxiv.org/abs/2206.00504v1",
        "categories": [
            "cs.SE",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "A Geometry-Sensitive Quorum Sensing Algorithm for the Best-of-N Site   Selection Problem",
        "authors": [
            "Grace Cai",
            "Nancy Lynch"
        ],
        "summary": "The house hunting behavior of the Temnothorax albipennis ant allows the colony to explore several nest choices and agree on the best one. Their behavior serves as the basis for many bio-inspired swarm models to solve the same problem. However, many of the existing site selection models in both insect colony and swarm literature test the model's accuracy and decision time only on setups where all potential site choices are equidistant from the swarm's starting location. These models do not account for the geographic challenges that result from site choices with different geometry. For example, although actual ant colonies are capable of consistently choosing a higher quality, further site instead of a lower quality, closer site, existing models are much less accurate in this scenario. Existing models are also more prone to committing to a low quality site if it is on the path between the agents' starting site and a higher quality site. We present a new model for the site selection problem and verify via simulation that is able to better handle these geographic challenges. Our results provide insight into the types of challenges site selection models face when distance is taken into account. Our work will allow swarms to be robust to more realistic situations where sites could be distributed in the environment in many different ways.",
        "published": "2022-06-01T15:57:49Z",
        "link": "http://arxiv.org/abs/2206.00587v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Post-Disaster Repair Crew Assignment Optimization Using Minimum Latency",
        "authors": [
            "Anakin Dey",
            "Melkior Ornik"
        ],
        "summary": "Across infrastructure domains, physical damage caused by storms and other weather events often requires costly and time-sensitive repairs to restore services as quickly as possible. While recent studies have used agent-based models to estimate the cost of repairs, the implemented strategies for assignment of repair crews to different locations are generally human-driven or based on simple rules. In order to find performant strategies, we continue with an agent-based model, but approach this problem as a combinational optimization problem known as the Minimum Weighted Latency Problem for multiple repair crews. We apply a partitioning algorithm that balances the assignment of targets amongst all the crews using two different heuristics that optimize either the importance of repair locations or the travel time between them. We benchmark our algorithm on both randomly generated graphs as well as data derived from a real-world urban environment, and show that our algorithm delivers significantly better assignments than existing methods.",
        "published": "2022-06-01T16:10:37Z",
        "link": "http://arxiv.org/abs/2206.00597v3",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Innovations in Integrating Machine Learning and Agent-Based Modeling of   Biomedical Systems",
        "authors": [
            "Nikita Sivakumar",
            "Cameron Mura",
            "Shayn M. Peirce"
        ],
        "summary": "Agent-based modeling (ABM) is a well-established paradigm for simulating complex systems via interactions between constituent entities. Machine learning (ML) refers to approaches whereby statistical algorithms 'learn' from data on their own, without imposing a priori theories of system behavior. Biological systems -- from molecules, to cells, to entire organisms -- consist of vast numbers of entities, governed by complex webs of interactions that span many spatiotemporal scales and exhibit nonlinearity, stochasticity and intricate coupling between entities. The macroscopic properties and collective dynamics of such systems are difficult to capture via continuum modelling and mean-field formalisms. ABM takes a 'bottom-up' approach that obviates these difficulties by enabling one to easily propose and test a set of well-defined 'rules' to be applied to the individual entities (agents) in a system. Evaluating a system and propagating its state over discrete time-steps effectively simulates the system, allowing observables to be computed and system properties to be analyzed. Because the rules that govern an ABM can be difficult to abstract and formulate from experimental data, there is an opportunity to use ML to help infer optimal, system-specific ABM rules. Once such rule-sets are devised, ABM calculations can generate a wealth of data, and ML can be applied there too -- e.g., to probe statistical measures that meaningfully describe a system's stochastic properties. As an example of synergy in the other direction (from ABM to ML), ABM simulations can generate realistic datasets for training ML algorithms (e.g., for regularization, to mitigate overfitting). In these ways, one can envision various synergistic ABM$\\rightleftharpoons$ML loops. This review summarizes how ABM and ML have been integrated in contexts that span spatiotemporal scales, from cellular to population-level epidemiology.",
        "published": "2022-06-02T15:19:09Z",
        "link": "http://arxiv.org/abs/2206.01092v2",
        "categories": [
            "q-bio.QM",
            "cs.LG",
            "cs.MA",
            "q-bio.CB"
        ]
    },
    {
        "title": "Game-theoretic Utility Tree for Multi-Robot Cooperative Pursuit Strategy",
        "authors": [
            "Qin Yang",
            "Ramviyas Parasuraman"
        ],
        "summary": "Underlying relationships among multiagent systems (MAS) in hazardous scenarios can be represented as game-theoretic models. In adversarial environments, the adversaries can be intentional or unintentional based on their needs and motivations. Agents will adopt suitable decision-making strategies to maximize their current needs and minimize their expected costs. This paper proposes and extends the new hierarchical network-based model, termed Game-theoretic Utility Tree (GUT), to arrive at a cooperative pursuit strategy to catch an evader in the Pursuit-Evasion game domain. We verify and demonstrate the performance of the proposed method using the Robotarium platform compared to the conventional constant bearing (CB) and pure pursuit (PP) strategies. The experiments demonstrated the effectiveness of the GUT, and the performances validated that the GUT could effectively organize cooperation strategies, helping the group with fewer advantages achieve higher performance.",
        "published": "2022-06-02T15:50:25Z",
        "link": "http://arxiv.org/abs/2206.01109v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Two Ways of Understanding Social Dynamics: Analyzing the Predictability   of Emergence of Objects in Reddit r/place Dependent on Locality in Space and   Time",
        "authors": [
            "Alyssa M Adams",
            "Javier Fernandez",
            "Olaf Witkowski"
        ],
        "summary": "Lately, studying social dynamics in interacting agents has been boosted by the power of computer models, which bring the richness of qualitative work, while offering the precision, transparency, extensiveness, and replicability of statistical and mathematical approaches. A particular set of phenomena for the study of social dynamics is Web collaborative platforms. A dataset of interest is r/place, a collaborative social experiment held in 2017 on Reddit, which consisted of a shared online canvas of 1000 pixels by 1000 pixels co-edited by over a million recorded users over 72 hours. In this paper, we designed and compared two methods to analyze the dynamics of this experiment. Our first method consisted in approximating the set of 2D cellular-automata-like rules used to generate the canvas images and how these rules change over time. The second method consisted in a convolutional neural network (CNN) that learned an approximation to the generative rules in order to generate the complex outcomes of the canvas. Our results indicate varying context-size dependencies for the predictability of different objects in r/place in time and space. They also indicate a surprising peak in difficulty to statistically infer behavioral rules towards the middle of the social experiment, while user interactions did not drop until before the end. The combination of our two approaches, one rule-based and the other statistical CNN-based, shows the ability to highlight diverse aspects of analyzing social dynamics.",
        "published": "2022-06-02T20:17:14Z",
        "link": "http://arxiv.org/abs/2206.03563v2",
        "categories": [
            "physics.soc-ph",
            "cs.HC",
            "cs.LG",
            "cs.MA",
            "cs.SI",
            "nlin.CG"
        ]
    },
    {
        "title": "Towards Group Learning: Distributed Weighting of Experts",
        "authors": [
            "Ben Abramowitz",
            "Nicholas Mattei"
        ],
        "summary": "Aggregating signals from a collection of noisy sources is a fundamental problem in many domains including crowd-sourcing, multi-agent planning, sensor networks, signal processing, voting, ensemble learning, and federated learning. The core question is how to aggregate signals from multiple sources (e.g. experts) in order to reveal an underlying ground truth. While a full answer depends on the type of signal, correlation of signals, and desired output, a problem common to all of these applications is that of differentiating sources based on their quality and weighting them accordingly. It is often assumed that this differentiation and aggregation is done by a single, accurate central mechanism or agent (e.g. judge). We complicate this model in two ways. First, we investigate the setting with both a single judge, and one with multiple judges. Second, given this multi-agent interaction of judges, we investigate various constraints on the judges' reporting space. We build on known results for the optimal weighting of experts and prove that an ensemble of sub-optimal mechanisms can perform optimally under certain conditions. We then show empirically that the ensemble approximates the performance of the optimal mechanism under a broader range of conditions.",
        "published": "2022-06-03T00:29:31Z",
        "link": "http://arxiv.org/abs/2206.02566v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "econ.TH"
        ]
    },
    {
        "title": "Simulation of Crowd Egress with Environmental Stressors",
        "authors": [
            "Peng Wang",
            "Xiaoda Wang",
            "Peter Luh",
            "Christian Wilkie",
            "Timo Korhonen",
            "Neal Olderman"
        ],
        "summary": "This article introduces a modeling framework to characterize evacuee response to environmental stimuli during emergency egress. The model is developed in consistency with stress theory, which explains how an organism reacts to environmental stressors. We integrate the theory into the well-known social-force model, and develop a framework to simulate crowd evacuation behavior in multi-compartment buildings. Our method serves as a theoretical basis to study crowd movement at bottlenecks, and simulate their herding and way-finding behavior in normal and hazardous conditions. The pre-movement behavior is also briefly investigated by using opinion dynamics with social group model. The algorithms have been partly tested in FDS+EVAC as well as our simulation platform crowdEgress.",
        "published": "2022-06-03T05:06:23Z",
        "link": "http://arxiv.org/abs/2206.01393v6",
        "categories": [
            "physics.soc-ph",
            "cs.MA",
            "nlin.AO"
        ]
    },
    {
        "title": "The Before, During, and After of Multi-Robot Deadlock",
        "authors": [
            "Jaskaran Grover",
            "Changliu Liu",
            "Katia Sycara"
        ],
        "summary": "Collision avoidance for multirobot systems is a well-studied problem. Recently, control barrier functions (CBFs) have been proposed for synthesizing controllers that guarantee collision avoidance and goal stabilization for multiple robots. However, it has been noted that reactive control synthesis methods (such as CBFs) are prone to \\textit{deadlock}, an equilibrium of system dynamics that causes the robots to stall before reaching their goals. In this paper, we analyze the closed-loop dynamics of robots using CBFs, to characterize controller parameters, initial conditions, and goal locations that invariably lead the system to deadlock. Using tools from duality theory, we derive geometric properties of robot configurations of an $N$ robot system once it is in deadlock and we justify them using the mechanics interpretation of KKT conditions. Our key deductions are that 1) system deadlock is characterized by a force-equilibrium on robots and 2) deadlock occurs to ensure safety when safety is on the brink of being violated. These deductions allow us to interpret deadlock as a subset of the state space, and we show that this set is non-empty and located on the boundary of the safe set. By exploiting these properties, we analyze the number of admissible robot configurations in deadlock and develop a provably-correct decentralized algorithm for deadlock resolution to safely deliver the robots to their goals. This algorithm is validated in simulations as well as experimentally on Khepera-IV robots.",
        "published": "2022-06-03T18:48:55Z",
        "link": "http://arxiv.org/abs/2206.01781v1",
        "categories": [
            "cs.RO",
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "A particle system with mean-field interaction: Large-scale limit of   stationary distributions",
        "authors": [
            "Alexander Stolyar"
        ],
        "summary": "We consider a system consisting of $n$ particles, moving forward in jumps on the real line. System state is the empirical distribution of particle locations. Each particle ``jumps forward'' at some time points, with the instantaneous rate of jumps given by a decreasing function of the particle's location quantile within the current state (empirical distribution). Previous work on this model established, under certain conditions, the convergence, as $n\\to\\infty$, of the system random dynamics to that of a deterministic mean-field model (MFM), which is a solution to an integro-differential equation. Another line of previous work established the existence of MFMs that are traveling waves, as well as the attraction of MFM trajectories to traveling waves. The main results of this paper are: (a) We prove that, as $n\\to\\infty$, the stationary distributions of (re-centered) states concentrate on a (re-centered) traveling wave; (b) We obtain a uniform across $n$ moment bound on the stationary distributions of (re-centered) states; (c) We prove a convergence-to-MFM result, which is substantially more general than that in previous work. Results (b) and (c) serve as ``ingredients'' of the proof of (a), but also are of independent interest.",
        "published": "2022-06-03T21:39:15Z",
        "link": "http://arxiv.org/abs/2206.01827v3",
        "categories": [
            "math.PR",
            "cs.MA",
            "90B15, 60K25"
        ]
    },
    {
        "title": "Leveraging Heterogeneous Capabilities in Multi-Agent Systems for   Environmental Conflict Resolution",
        "authors": [
            "Michael Enqi Cao",
            "Jonas Warnke",
            "Yunhai Han",
            "Xinpei Ni",
            "Ye Zhao",
            "Samuel Coogan"
        ],
        "summary": "In this paper, we introduce a high-level controller synthesis framework that enables teams of heterogeneous agents to assist each other in resolving environmental conflicts that appear at runtime. This conflict resolution method is built upon temporal-logic-based reactive synthesis to guarantee safety and task completion under specific environment assumptions. In heterogeneous multi-agent systems, every agent is expected to complete its own tasks in service of a global team objective. However, at runtime, an agent may encounter un-modeled obstacles (e.g., doors or walls) that prevent it from achieving its own task. To address this problem, we employ the capabilities of other heterogeneous agents to resolve the obstacle. A controller framework is proposed to redirect agents with the capability of resolving the appropriate obstacles to the required target when such a situation is detected. Three case studies involving a bipedal robot Digit and a quadcopter are used to evaluate the controller performance in action. Additionally, we implement the proposed framework on a physical multi-agent robotic system to demonstrate its viability for real world applications.",
        "published": "2022-06-03T21:47:41Z",
        "link": "http://arxiv.org/abs/2206.01833v3",
        "categories": [
            "cs.RO",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Learning in Congestion Games with Bandit Feedback",
        "authors": [
            "Qiwen Cui",
            "Zhihan Xiong",
            "Maryam Fazel",
            "Simon S. Du"
        ],
        "summary": "In this paper, we investigate Nash-regret minimization in congestion games, a class of games with benign theoretical structure and broad real-world applications. We first propose a centralized algorithm based on the optimism in the face of uncertainty principle for congestion games with (semi-)bandit feedback, and obtain finite-sample guarantees. Then we propose a decentralized algorithm via a novel combination of the Frank-Wolfe method and G-optimal design. By exploiting the structure of the congestion game, we show the sample complexity of both algorithms depends only polynomially on the number of players and the number of facilities, but not the size of the action set, which can be exponentially large in terms of the number of facilities. We further define a new problem class, Markov congestion games, which allows us to model the non-stationarity in congestion games. We propose a centralized algorithm for Markov congestion games, whose sample complexity again has only polynomial dependence on all relevant problem parameters, but not the size of the action set.",
        "published": "2022-06-04T02:32:26Z",
        "link": "http://arxiv.org/abs/2206.01880v3",
        "categories": [
            "cs.GT",
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Evaluation of creating scoring opportunities for teammates in soccer via   trajectory prediction",
        "authors": [
            "Masakiyo Teranishi",
            "Kazushi Tsutsui",
            "Kazuya Takeda",
            "Keisuke Fujii"
        ],
        "summary": "Evaluating the individual movements for teammates in soccer players is crucial for assessing teamwork, scouting, and fan engagement. It has been said that players in a 90-min game do not have the ball for about 87 minutes on average. However, it has remained difficult to evaluate an attacking player without receiving the ball, and to reveal how movement contributes to the creation of scoring opportunities for teammates. In this paper, we evaluate players who create off-ball scoring opportunities by comparing actual movements with the reference movements generated via trajectory prediction. First, we predict the trajectories of players using a graph variational recurrent neural network that can accurately model the relationship between players and predict the long-term trajectory. Next, based on the difference in the modified off-ball evaluation index between the actual and the predicted trajectory as a reference, we evaluate how the actual movement contributes to scoring opportunity compared to the predicted movement. For verification, we examined the relationship with the annual salary, the goals, and the rating in the game by experts for all games of a team in a professional soccer league in a year. The results show that the annual salary and the proposed indicator correlated significantly, which could not be explained by the existing indicators and goals. Our results suggest the effectiveness of the proposed method as an indicator for a player without the ball to create a scoring chance for teammates.",
        "published": "2022-06-04T03:58:37Z",
        "link": "http://arxiv.org/abs/2206.01899v3",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Estimating counterfactual treatment outcomes over time in complex   multiagent scenarios",
        "authors": [
            "Keisuke Fujii",
            "Koh Takeuchi",
            "Atsushi Kuribayashi",
            "Naoya Takeishi",
            "Yoshinobu Kawahara",
            "Kazuya Takeda"
        ],
        "summary": "Evaluation of intervention in a multiagent system, e.g., when humans should intervene in autonomous driving systems and when a player should pass to teammates for a good shot, is challenging in various engineering and scientific fields. Estimating the individual treatment effect (ITE) using counterfactual long-term prediction is practical to evaluate such interventions. However, most of the conventional frameworks did not consider the time-varying complex structure of multiagent relationships and covariate counterfactual prediction. This may lead to erroneous assessments of ITE and difficulty in interpretation. Here we propose an interpretable, counterfactual recurrent network in multiagent systems to estimate the effect of the intervention. Our model leverages graph variational recurrent neural networks and theory-based computation with domain knowledge for the ITE estimation framework based on long-term prediction of multiagent covariates and outcomes, which can confirm the circumstances under which the intervention is effective. On simulated models of an automated vehicle and biological agents with time-varying confounders, we show that our methods achieved lower estimation errors in counterfactual covariates and the most effective treatment timing than the baselines. Furthermore, using real basketball data, our methods performed realistic counterfactual predictions and evaluated the counterfactual passes in shot scenarios.",
        "published": "2022-06-04T04:04:25Z",
        "link": "http://arxiv.org/abs/2206.01900v4",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "stat.ME",
            "stat.ML"
        ]
    },
    {
        "title": "Optimizing Indoor Navigation Policies For Spatial Distancing",
        "authors": [
            "Xun Zhang",
            "Mathew Schwartz",
            "Muhammad Usman",
            "Petros Faloutsos",
            "Mubbasir Kapadia"
        ],
        "summary": "In this paper, we focus on the modification of policies that can lead to movement patterns and directional guidance of occupants, which are represented as agents in a 3D simulation engine. We demonstrate an optimization method that improves a spatial distancing metric by modifying the navigation graph by introducing a measure of spatial distancing of agents as a function of agent density (i.e., occupancy). Our optimization framework utilizes such metrics as the target function, using a hybrid approach of combining genetic algorithm and simulated annealing. We show that within our framework, the simulation-optimization process can help to improve spatial distancing between agents by optimizing the navigation policies for a given indoor environment.",
        "published": "2022-06-04T21:57:22Z",
        "link": "http://arxiv.org/abs/2207.08860v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.GR",
            "cs.RO"
        ]
    },
    {
        "title": "Collaborative search and autonomous task allocation in organizations of   learning agents",
        "authors": [
            "Stephan Leitner"
        ],
        "summary": "This paper introduces a model of multi-unit organizations with either static structures, i.e., they are designed top-down following classical approaches to organizational design, or dynamic structures, i.e., the structures emerge over time from micro-level decisions. In the latter case, the units are capable of learning about the technical interdependencies of the task they face, and they use their knowledge by adapting the task allocation from time to time. In both static and dynamic organizations, searching for actions to increase the performance can either be carried out individually or collaboratively. The results indicate that (i) collaborative search processes can help overcome the adverse effects of inefficient task allocations as long as there is an internal fit with other organizational design elements, and (ii) for dynamic organizations, the emergent task allocation does not necessarily mirror the technical interdependencies of the task the organizations face, even though the same (or even higher) performances are achieved.",
        "published": "2022-06-05T10:03:13Z",
        "link": "http://arxiv.org/abs/2206.02142v2",
        "categories": [
            "econ.GN",
            "cs.MA",
            "nlin.AO",
            "q-fin.EC",
            "37M05, 90-10, 90B70, 90B50",
            "J.4; I.6.3; I.6.6; I.2.6"
        ]
    },
    {
        "title": "Machine learning applications for electricity market agent-based models:   A systematic literature review",
        "authors": [
            "Alexander J. M. Kell",
            "Stephen McGough",
            "Matthew Forshaw"
        ],
        "summary": "The electricity market has a vital role to play in the decarbonisation of the energy system. However, the electricity market is made up of many different variables and data inputs. These variables and data inputs behave in sometimes unpredictable ways which can not be predicted a-priori. It has therefore been suggested that agent-based simulations are used to better understand the dynamics of the electricity market. Agent-based models provide the opportunity to integrate machine learning and artificial intelligence to add intelligence, make better forecasts and control the power market in better and more efficient ways. In this systematic literature review, we review 55 papers published between 2016 and 2021 which focus on machine learning applied to agent-based electricity market models. We find that research clusters around popular topics, such as bidding strategies. However, there exists a long-tail of different research applications that could benefit from the high intensity research from the more investigated applications.",
        "published": "2022-06-05T14:52:26Z",
        "link": "http://arxiv.org/abs/2206.02196v1",
        "categories": [
            "cs.MA",
            "cs.LG"
        ]
    },
    {
        "title": "How does a Rational Agent Act in an Epidemic?",
        "authors": [
            "S. Yagiz Olmez",
            "Shubham Aggarwal",
            "Jin Won Kim",
            "Erik Miehling",
            "Tamer Başar",
            "Matthew West",
            "Prashant G. Mehta"
        ],
        "summary": "Evolution of disease in a large population is a function of the top-down policy measures from a centralized planner, as well as the self-interested decisions (to be socially active) of individual agents in a large heterogeneous population. This paper is concerned with understanding the latter based on a mean-field type optimal control model. Specifically, the model is used to investigate the role of partial information on an agent's decision-making, and study the impact of such decisions by a large number of agents on the spread of the virus in the population. The motivation comes from the presymptomatic and asymptomatic spread of the COVID-19 virus where an agent unwittingly spreads the virus. We show that even in a setting with fully rational agents, limited information on the viral state can result in an epidemic growth.",
        "published": "2022-06-05T17:21:29Z",
        "link": "http://arxiv.org/abs/2206.02222v1",
        "categories": [
            "math.OC",
            "cs.GT",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "ACHORD: Communication-Aware Multi-Robot Coordination with Intermittent   Connectivity",
        "authors": [
            "Maira Saboia",
            "Lillian Clark",
            "Vivek Thangavelu",
            "Jeffrey A. Edlund",
            "Kyohei Otsu",
            "Gustavo J. Correa",
            "Vivek Shankar Varadharajan",
            "Angel Santamaria-Navarro",
            "Thomas Touma",
            "Amanda Bouman",
            "Hovhannes Melikyan",
            "Torkom Pailevanian",
            "Sung-Kyun Kim",
            "Avak Archanian",
            "Tiago Stegun Vaquero",
            "Giovanni Beltrame",
            "Nils Napp",
            "Gustavo Pessin",
            "Ali-akbar Agha-mohammadi"
        ],
        "summary": "Communication is an important capability for multi-robot exploration because (1) inter-robot communication (comms) improves coverage efficiency and (2) robot-to-base comms improves situational awareness. Exploring comms-restricted (e.g., subterranean) environments requires a multi-robot system to tolerate and anticipate intermittent connectivity, and to carefully consider comms requirements, otherwise mission-critical data may be lost. In this paper, we describe and analyze ACHORD (Autonomous & Collaborative High-Bandwidth Operations with Radio Droppables), a multi-layer networking solution which tightly co-designs the network architecture and high-level decision-making for improved comms. ACHORD provides bandwidth prioritization and timely and reliable data transfer despite intermittent connectivity. Furthermore, it exposes low-layer networking metrics to the application layer to enable robots to autonomously monitor, map, and extend the network via droppable radios, as well as restore connectivity to improve collaborative exploration. We evaluate our solution with respect to the comms performance in several challenging underground environments including the DARPA SubT Finals competition environment. Our findings support the use of data stratification and flow control to improve bandwidth-usage.",
        "published": "2022-06-05T19:35:54Z",
        "link": "http://arxiv.org/abs/2206.02245v1",
        "categories": [
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Decentralized, Communication- and Coordination-free Learning in   Structured Matching Markets",
        "authors": [
            "Chinmay Maheshwari",
            "Eric Mazumdar",
            "Shankar Sastry"
        ],
        "summary": "We study the problem of online learning in competitive settings in the context of two-sided matching markets. In particular, one side of the market, the agents, must learn about their preferences over the other side, the firms, through repeated interaction while competing with other agents for successful matches. We propose a class of decentralized, communication- and coordination-free algorithms that agents can use to reach to their stable match in structured matching markets. In contrast to prior works, the proposed algorithms make decisions based solely on an agent's own history of play and requires no foreknowledge of the firms' preferences. Our algorithms are constructed by splitting up the statistical problem of learning one's preferences, from noisy observations, from the problem of competing for firms. We show that under realistic structural assumptions on the underlying preferences of the agents and firms, the proposed algorithms incur a regret which grows at most logarithmically in the time horizon. Our results show that, in the case of matching markets, competition need not drastically affect the performance of decentralized, communication and coordination free online learning algorithms.",
        "published": "2022-06-06T04:08:04Z",
        "link": "http://arxiv.org/abs/2206.02344v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "econ.TH"
        ]
    },
    {
        "title": "Consensus Learning for Cooperative Multi-Agent Reinforcement Learning",
        "authors": [
            "Zhiwei Xu",
            "Bin Zhang",
            "Dapeng Li",
            "Zeren Zhang",
            "Guangchong Zhou",
            "Hao Chen",
            "Guoliang Fan"
        ],
        "summary": "Almost all multi-agent reinforcement learning algorithms without communication follow the principle of centralized training with decentralized execution. During centralized training, agents can be guided by the same signals, such as the global state. During decentralized execution, however, agents lack the shared signal. Inspired by viewpoint invariance and contrastive learning, we propose consensus learning for cooperative multi-agent reinforcement learning in this paper. Although based on local observations, different agents can infer the same consensus in discrete space. During decentralized execution, we feed the inferred consensus as an explicit input to the network of agents, thereby developing their spirit of cooperation. Our proposed method can be extended to various multi-agent reinforcement learning algorithms with small model changes. Moreover, we carry out them on some fully cooperative tasks and get convincing results.",
        "published": "2022-06-06T12:43:07Z",
        "link": "http://arxiv.org/abs/2206.02583v3",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Policy Optimization for Markov Games: Unified Framework and Faster   Convergence",
        "authors": [
            "Runyu Zhang",
            "Qinghua Liu",
            "Huan Wang",
            "Caiming Xiong",
            "Na Li",
            "Yu Bai"
        ],
        "summary": "This paper studies policy optimization algorithms for multi-agent reinforcement learning. We begin by proposing an algorithm framework for two-player zero-sum Markov Games in the full-information setting, where each iteration consists of a policy update step at each state using a certain matrix game algorithm, and a value update step with a certain learning rate. This framework unifies many existing and new policy optimization algorithms. We show that the state-wise average policy of this algorithm converges to an approximate Nash equilibrium (NE) of the game, as long as the matrix game algorithms achieve low weighted regret at each state, with respect to weights determined by the speed of the value updates. Next, we show that this framework instantiated with the Optimistic Follow-The-Regularized-Leader (OFTRL) algorithm at each state (and smooth value updates) can find an $\\mathcal{\\widetilde{O}}(T^{-5/6})$ approximate NE in $T$ iterations, and a similar algorithm with slightly modified value update rule achieves a faster $\\mathcal{\\widetilde{O}}(T^{-1})$ convergence rate. These improve over the current best $\\mathcal{\\widetilde{O}}(T^{-1/2})$ rate of symmetric policy optimization type algorithms. We also extend this algorithm to multi-player general-sum Markov Games and show an $\\mathcal{\\widetilde{O}}(T^{-3/4})$ convergence rate to Coarse Correlated Equilibria (CCE). Finally, we provide a numerical example to verify our theory and investigate the importance of smooth value updates, and find that using \"eager\" value updates instead (equivalent to the independent natural policy gradient algorithm) may significantly slow down the convergence, even on a simple game with $H=2$ layers.",
        "published": "2022-06-06T14:23:13Z",
        "link": "http://arxiv.org/abs/2206.02640v4",
        "categories": [
            "cs.LG",
            "cs.GT",
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "Predicting and Understanding Human Action Decisions during Skillful   Joint-Action via Machine Learning and Explainable-AI",
        "authors": [
            "Fabrizia Auletta",
            "Rachel W. Kallen",
            "Mario di Bernardo",
            "Micheal J. Richardson"
        ],
        "summary": "This study uses supervised machine learning (SML) and explainable artificial intelligence (AI) to model, predict and understand human decision-making during skillful joint-action. Long short-term memory networks were trained to predict the target selection decisions of expert and novice actors completing a dyadic herding task. Results revealed that the trained models were expertise specific and could not only accurately predict the target selection decisions of expert and novice herders but could do so at timescales that preceded an actor's conscious intent. To understand what differentiated the target selection decisions of expert and novice actors, we then employed the explainable-AI technique, SHapley Additive exPlanation, to identify the importance of informational features (variables) on model predictions. This analysis revealed that experts were more influenced by information about the state of their co-herders compared to novices. The utility of employing SML and explainable-AI techniques for investigating human decision-making is discussed.",
        "published": "2022-06-06T16:54:43Z",
        "link": "http://arxiv.org/abs/2206.02739v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Collaborative Linear Bandits with Adversarial Agents: Near-Optimal   Regret Bounds",
        "authors": [
            "Aritra Mitra",
            "Arman Adibi",
            "George J. Pappas",
            "Hamed Hassani"
        ],
        "summary": "We consider a linear stochastic bandit problem involving $M$ agents that can collaborate via a central server to minimize regret. A fraction $\\alpha$ of these agents are adversarial and can act arbitrarily, leading to the following tension: while collaboration can potentially reduce regret, it can also disrupt the process of learning due to adversaries. In this work, we provide a fundamental understanding of this tension by designing new algorithms that balance the exploration-exploitation trade-off via carefully constructed robust confidence intervals. We also complement our algorithms with tight analyses. First, we develop a robust collaborative phased elimination algorithm that achieves $\\tilde{O}\\left(\\alpha+ 1/\\sqrt{M}\\right) \\sqrt{dT}$ regret for each good agent; here, $d$ is the model-dimension and $T$ is the horizon. For small $\\alpha$, our result thus reveals a clear benefit of collaboration despite adversaries. Using an information-theoretic argument, we then prove a matching lower bound, thereby providing the first set of tight, near-optimal regret bounds for collaborative linear bandits with adversaries. Furthermore, by leveraging recent advances in high-dimensional robust statistics, we significantly extend our algorithmic ideas and results to (i) the generalized linear bandit model that allows for non-linear observation maps; and (ii) the contextual bandit setting that allows for time-varying feature vectors.",
        "published": "2022-06-06T18:16:34Z",
        "link": "http://arxiv.org/abs/2206.02834v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "math.OC",
            "stat.ML"
        ]
    },
    {
        "title": "Explainability in Mechanism Design: Recent Advances and the Road Ahead",
        "authors": [
            "Sharadhi Alape Suryanarayana",
            "David Sarne",
            "Sarit Kraus"
        ],
        "summary": "Designing and implementing explainable systems is seen as the next step towards increasing user trust in, acceptance of and reliance on Artificial Intelligence (AI) systems. While explaining choices made by black-box algorithms such as machine learning and deep learning has occupied most of the limelight, systems that attempt to explain decisions (even simple ones) in the context of social choice are steadily catching up. In this paper, we provide a comprehensive survey of explainability in mechanism design, a domain characterized by economically motivated agents and often having no single choice that maximizes all individual utility functions. We discuss the main properties and goals of explainability in mechanism design, distinguishing them from those of Explainable AI in general. This discussion is followed by a thorough review of the challenges one may face when working on Explainable Mechanism Design and propose a few solution concepts to those.",
        "published": "2022-06-07T06:08:53Z",
        "link": "http://arxiv.org/abs/2206.03031v2",
        "categories": [
            "cs.MA",
            "A.1; I.2.11"
        ]
    },
    {
        "title": "A Route Network Planning Method for Urban Air Delivery",
        "authors": [
            "Xinyu He",
            "Fang He",
            "Lishuai Li",
            "Lei Zhang",
            "Gang Xiao"
        ],
        "summary": "High-tech giants and start-ups are investing in drone technologies to provide urban air delivery service, which is expected to solve the last-mile problem and mitigate road traffic congestion. However, air delivery service will not scale up without proper traffic management for drones in dense urban environment. Currently, a range of Concepts of Operations (ConOps) for unmanned aircraft system traffic management (UTM) are being proposed and evaluated by researchers, operators, and regulators. Among these, the tube-based (or corridor-based) ConOps has emerged in operations in some regions of the world for drone deliveries and is expected to continue serving certain scenarios that with dense and complex airspace and requires centralized control in the future. Towards the tube-based ConOps, we develop a route network planning method to design routes (tubes) in a complex urban environment in this paper. In this method, we propose a priority structure to decouple the network planning problem, which is NP-hard, into single-path planning problems. We also introduce a novel space cost function to enable the design of dense and aligned routes in a network. The proposed method is tested on various scenarios and compared with other state-of-the-art methods. Results show that our method can generate near-optimal route networks with significant computational time-savings.",
        "published": "2022-06-07T08:09:48Z",
        "link": "http://arxiv.org/abs/2206.03085v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "About Digital Twins, agents, and multiagent systems: a   cross-fertilisation journey",
        "authors": [
            "Stefano Mariani",
            "Marco Picone",
            "Alessandro Ricci"
        ],
        "summary": "Digital Twins (DTs) are rapidly emerging as a fundamental brick of engineering cyber-physical systems, but their notion is still mostly bound to specific business domains (e.g. manufacturing), goals (e.g. product design), or application domains (e.g. the Internet of Things). As such, their value as general purpose engineering abstractions is yet to be fully revealed. In this paper, we relate DTs with agents and multiagent systems, as the latter are arguably the most rich abstractions available for the engineering of complex socio-technical and cyber-physical systems, and the former could both fill in some gaps in agent-oriented engineering and benefit from an agent-oriented interpretation -- in a cross-fertilisation journey.",
        "published": "2022-06-07T13:08:46Z",
        "link": "http://arxiv.org/abs/2206.03253v1",
        "categories": [
            "cs.MA",
            "I.2.11; D.2.10; D.2.11"
        ]
    },
    {
        "title": "Towards Explainable Social Agent Authoring tools: A case study on   FAtiMA-Toolkit",
        "authors": [
            "Manuel Guimarães",
            "Joana Campos",
            "Pedro A. Santos",
            "João Dias",
            "Rui Prada"
        ],
        "summary": "The deployment of Socially Intelligent Agents (SIAs) in learning environments has proven to have several advantages in different areas of application. Social Agent Authoring Tools allow scenario designers to create tailored experiences with high control over SIAs behaviour, however, on the flip side, this comes at a cost as the complexity of the scenarios and its authoring can become overbearing. In this paper we introduce the concept of Explainable Social Agent Authoring Tools with the goal of analysing if authoring tools for social agents are understandable and interpretable. To this end we examine whether an authoring tool, FAtiMA-Toolkit, is understandable and its authoring steps interpretable, from the point-of-view of the author. We conducted two user studies to quantitatively assess the Interpretability, Comprehensibility and Transparency of FAtiMA-Toolkit from the perspective of a scenario designer. One of the key findings is the fact that FAtiMA-Toolkit's conceptual model is, in general, understandable, however the emotional-based concepts were not as easily understood and used by the authors. Although there are some positive aspects regarding the explainability of FAtiMA-Toolkit, there is still progress to be made to achieve a fully explainable social agent authoring tool. We provide a set of key concepts and possible solutions that can guide developers to build such tools.",
        "published": "2022-06-07T14:55:06Z",
        "link": "http://arxiv.org/abs/2206.03360v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Multi-Robot Synergistic Localization in Dynamic Environments",
        "authors": [
            "Ehsan Latif",
            "Ramviyas Parasuraman"
        ],
        "summary": "A mobile robot's precise location information is critical for navigation and task processing, especially for a multi-robot system (MRS) to collaborate and collect valuable data from the field. However, a robot in situations where it does not have access to GPS signals, such as in an environmentally controlled, indoor, or underground environment, finds it difficult to locate using its sensor alone. As a result, robots sharing their local information to improve their localization estimates benefit the entire MRS team. There have been several attempts to model-based multi-robot localization using Radio Signal Strength Indicator (RSSI) as a source to calculate bearing information. We also utilize the RSSI for wireless networks generated through the communication of multiple robots in a system and aim to localize agents with high accuracy and efficiency in a dynamic environment for shared information fusion to refine the localization estimation. This estimator structure reduces one source of measurement correlation while appropriately incorporating others. This paper proposes a decentralized Multi-robot Synergistic Localization System (MRSL) for a dense and dynamic environment. Robots update their position estimation whenever new information receives from their neighbors. When the system senses the presence of other robots in the region, it exchanges position estimates and merges the received data to improve its localization accuracy. Our approach uses Bayesian rule-based integration, which has shown to be computationally efficient and applicable to asynchronous robotics communication. We have performed extensive simulation experiments with a varying number of robots to analyze the algorithm. MRSL's localization accuracy with RSSI outperformed other algorithms from the literature, showing a significant promise for future development.",
        "published": "2022-06-07T20:44:32Z",
        "link": "http://arxiv.org/abs/2206.03573v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Stabilizing Voltage in Power Distribution Networks via Multi-Agent   Reinforcement Learning with Transformer",
        "authors": [
            "Minrui Wang",
            "Mingxiao Feng",
            "Wengang Zhou",
            "Houqiang Li"
        ],
        "summary": "The increased integration of renewable energy poses a slew of technical challenges for the operation of power distribution networks. Among them, voltage fluctuations caused by the instability of renewable energy are receiving increasing attention. Utilizing MARL algorithms to coordinate multiple control units in the grid, which is able to handle rapid changes of power systems, has been widely studied in active voltage control task recently. However, existing approaches based on MARL ignore the unique nature of the grid and achieve limited performance. In this paper, we introduce the transformer architecture to extract representations adapting to power network problems and propose a Transformer-based Multi-Agent Actor-Critic framework (T-MAAC) to stabilize voltage in power distribution networks. In addition, we adopt a novel auxiliary-task training process tailored to the voltage control task, which improves the sample efficiency and facilitating the representation learning of the transformer-based model. We couple T-MAAC with different multi-agent actor-critic algorithms, and the consistent improvements on the active voltage control task demonstrate the effectiveness of the proposed method.",
        "published": "2022-06-08T07:48:42Z",
        "link": "http://arxiv.org/abs/2206.03721v1",
        "categories": [
            "cs.MA",
            "cs.LG",
            "I.2.11"
        ]
    },
    {
        "title": "Utilising the CLT Structure in Stochastic Gradient based Sampling :   Improved Analysis and Faster Algorithms",
        "authors": [
            "Aniket Das",
            "Dheeraj Nagaraj",
            "Anant Raj"
        ],
        "summary": "We consider stochastic approximations of sampling algorithms, such as Stochastic Gradient Langevin Dynamics (SGLD) and the Random Batch Method (RBM) for Interacting Particle Dynamcs (IPD). We observe that the noise introduced by the stochastic approximation is nearly Gaussian due to the Central Limit Theorem (CLT) while the driving Brownian motion is exactly Gaussian. We harness this structure to absorb the stochastic approximation error inside the diffusion process, and obtain improved convergence guarantees for these algorithms. For SGLD, we prove the first stable convergence rate in KL divergence without requiring uniform warm start, assuming the target density satisfies a Log-Sobolev Inequality. Our result implies superior first-order oracle complexity compared to prior works, under significantly milder assumptions. We also prove the first guarantees for SGLD under even weaker conditions such as H\\\"{o}lder smoothness and Poincare Inequality, thus bridging the gap between the state-of-the-art guarantees for LMC and SGLD. Our analysis motivates a new algorithm called covariance correction, which corrects for the additional noise introduced by the stochastic approximation by rescaling the strength of the diffusion. Finally, we apply our techniques to analyze RBM, and significantly improve upon the guarantees in prior works (such as removing exponential dependence on horizon), under minimal assumptions.",
        "published": "2022-06-08T10:17:40Z",
        "link": "http://arxiv.org/abs/2206.03792v6",
        "categories": [
            "math.PR",
            "cs.LG",
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "Scalable Joint Learning of Wireless Multiple-Access Policies and their   Signaling",
        "authors": [
            "Mateus P. Mota",
            "Alvaro Valcarce",
            "Jean-Marie Gorce"
        ],
        "summary": "In this paper, we apply an multi-agent reinforcement learning (MARL) framework allowing the base station (BS) and the user equipments (UEs) to jointly learn a channel access policy and its signaling in a wireless multiple access scenario. In this framework, the BS and UEs are reinforcement learning (RL) agents that need to cooperate in order to deliver data. The comparison with a contention-free and a contention-based baselines shows that our framework achieves a superior performance in terms of goodput even in high traffic situations while maintaining a low collision rate. The scalability of the proposed method is studied, since it is a major problem in MARL and this paper provides the first results in order to address it.",
        "published": "2022-06-08T12:38:04Z",
        "link": "http://arxiv.org/abs/2206.03844v1",
        "categories": [
            "cs.IT",
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "math.IT"
        ]
    },
    {
        "title": "Push--Pull with Device Sampling",
        "authors": [
            "Yu-Guan Hsieh",
            "Yassine Laguel",
            "Franck Iutzeler",
            "Jérôme Malick"
        ],
        "summary": "We consider decentralized optimization problems in which a number of agents collaborate to minimize the average of their local functions by exchanging over an underlying communication graph. Specifically, we place ourselves in an asynchronous model where only a random portion of nodes perform computation at each iteration, while the information exchange can be conducted between all the nodes and in an asymmetric fashion. For this setting, we propose an algorithm that combines gradient tracking with a network-level variance reduction (in contrast to variance reduction within each node). This enables each node to track the average of the gradients of the objective functions. Our theoretical analysis shows that the algorithm converges linearly, when the local objective functions are strongly convex, under mild connectivity conditions on the expected mixing matrices. In particular, our result does not require the mixing matrices to be doubly stochastic. In the experiments, we investigate a broadcast mechanism that transmits information from computing nodes to their neighbors, and confirm the linear convergence of our method on both synthetic and real-world datasets.",
        "published": "2022-06-08T18:18:18Z",
        "link": "http://arxiv.org/abs/2206.04113v2",
        "categories": [
            "math.OC",
            "cs.DC",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Linear Delta Arrays for Compliant Dexterous Distributed Manipulation",
        "authors": [
            "Sarvesh Patil",
            "Tony Tao",
            "Tess Hellebrekers",
            "Oliver Kroemer",
            "F. Zeynep Temel"
        ],
        "summary": "This paper presents a new type of distributed dexterous manipulator: delta arrays. Our delta array setup consists of 64 linearly-actuated delta robots with 3D-printed compliant linkages. Through the design of the individual delta robots, the modular array structure, and distributed communication and control, we study a wide range of in-plane and out-of-plane manipulations, as well as prehensile manipulations among subsets of neighboring delta robots. We also demonstrate dexterous manipulation capabilities of the delta array using reinforcement learning while leveraging the compliance to not break the end-effectors. Our evaluations show that the resulting 192 DoF compliant robot is capable of performing various coordinated distributed manipulations of a variety of objects, including translation, alignment, prehensile squeezing, lifting, and grasping.",
        "published": "2022-06-09T16:23:42Z",
        "link": "http://arxiv.org/abs/2206.04596v3",
        "categories": [
            "cs.RO",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Merak: An Efficient Distributed DNN Training Framework with Automated 3D   Parallelism for Giant Foundation Models",
        "authors": [
            "Zhiquan Lai",
            "Shengwei Li",
            "Xudong Tang",
            "Keshi Ge",
            "Weijie Liu",
            "Yabo Duan",
            "Linbo Qiao",
            "Dongsheng Li"
        ],
        "summary": "Foundation models are becoming the dominant deep learning technologies. Pretraining a foundation model is always time-consumed due to the large scale of both the model parameter and training dataset. Besides being computing-intensive, the training process is extremely memory-intensive and communication-intensive. These features make it necessary to apply 3D parallelism, which integrates data parallelism, pipeline model parallelism and tensor model parallelism, to achieve high training efficiency.   To achieve this goal, some custom software frameworks such as Megatron-LM and DeepSpeed are developed. However, current 3D parallelism frameworks still meet two issues: i) they are not transparent to model developers, which need to manually modify the model to parallelize training. ii) their utilization of computation, GPU memory and network bandwidth are not sufficient. We propose Merak, an automated 3D parallelism deep learning training framework with high resource utilization. Merak automatically deploys with an automatic model partitioner, which uses a graph sharding algorithm on a proxy representation of the model. Merak also presents the non-intrusive API for scaling out foundation model training with minimal code modification. In addition, we design a high-performance 3D parallel runtime engine in Merak. It uses several techniques to exploit available training resources, including shifted critical path pipeline schedule that brings a higher computation utilization, stage-aware recomputation that makes use of idle worker memory, and sub-pipelined tensor model parallelism that overlaps communication and computation. Experiments on 64 GPUs show Merak can speedup the training performance over the state-of-the-art 3D parallelism frameworks of models with 1.5, 2.5, 8.3, and 20 billion parameters by up to 1.42X, 1.39X, 1.43X, and 1.61X, respectively.",
        "published": "2022-06-10T09:15:48Z",
        "link": "http://arxiv.org/abs/2206.04959v4",
        "categories": [
            "cs.LG",
            "cs.DC",
            "cs.MA"
        ]
    },
    {
        "title": "Social Network Structure Shapes Innovation: Experience-sharing in RL   with SAPIENS",
        "authors": [
            "Eleni Nisioti",
            "Mateo Mahaut",
            "Pierre-Yves Oudeyer",
            "Ida Momennejad",
            "Clément Moulin-Frier"
        ],
        "summary": "Human culture relies on innovation: our ability to continuously explore how existing elements can be combined to create new ones. Innovation is not solitary, it relies on collective search and accumulation. Reinforcement learning (RL) approaches commonly assume that fully-connected groups are best suited for innovation. However, human laboratory and field studies have shown that hierarchical innovation is more robustly achieved by dynamic social network structures. In dynamic settings, humans oscillate between innovating individually or in small clusters, and then sharing outcomes with others. To our knowledge, the role of social network structure on innovation has not been systematically studied in RL. Here, we use a multi-level problem setting (WordCraft), with three different innovation tasks to test the hypothesis that the social network structure affects the performance of distributed RL algorithms. We systematically design networks of DQNs sharing experiences from their replay buffers in varying structures (fully-connected, small world, dynamic, ring) and introduce a set of behavioral and mnemonic metrics that extend the classical reward-focused evaluation framework of RL. Comparing the level of innovation achieved by different social network structures across different tasks shows that, first, consistent with human findings, experience sharing within a dynamic structure achieves the highest level of innovation in tasks with a deceptive nature and large search spaces. Second, experience sharing is not as helpful when there is a single clear path to innovation. Third, the metrics we propose, can help understand the success of different social network structures on different tasks, with the diversity of experiences on an individual and group level lending crucial insights.",
        "published": "2022-06-10T12:47:45Z",
        "link": "http://arxiv.org/abs/2206.05060v2",
        "categories": [
            "cs.AI",
            "cs.MA",
            "cs.SI"
        ]
    },
    {
        "title": "Characterizing Properties and Trade-offs of Centralized Delegation   Mechanisms in Liquid Democracy",
        "authors": [
            "Brian Brubach",
            "Audrey Ballarin",
            "Heeba Nazeer"
        ],
        "summary": "Liquid democracy is a form of transitive delegative democracy that has received a flurry of scholarly attention from the computer science community in recent years. In its simplest form, every agent starts with one vote and may have other votes assigned to them via delegation from other agents. They can choose to delegate all votes assigned to them to another agent or vote directly with all votes assigned to them. However, many proposed realizations of liquid democracy allow for agents to express their delegation/voting preferences in more complex ways (e.g., a ranked list of potential delegates) and employ a centralized delegation mechanism to compute the final vote tally. In doing so, centralized delegation mechanisms can make decisions that affect the outcome of a vote and where/whether agents are able to delegate their votes. Much of the analysis thus far has focused on the ability of these mechanisms to make a correct choice. We extend this analysis by introducing and formalizing other important properties of a centralized delegation mechanism in liquid democracy with respect to crucial features such as accountability, transparency, explainability, fairness, and user agency. In addition, we evaluate existing methods in terms of these properties, show how some prior work can be augmented to achieve desirable properties, prove impossibility results for achieving certain sets of properties simultaneously, and highlight directions for future work.",
        "published": "2022-06-10T20:11:35Z",
        "link": "http://arxiv.org/abs/2206.05339v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Islamic and capitalist economies: Comparison using econophysics models   of wealth exchange and redistribution",
        "authors": [
            "Takeshi Kato"
        ],
        "summary": "Islamic and capitalist economies have several differences, the most fundamental being that the Islamic economy is characterized by the prohibition of interest (riba) and speculation (gharar) and the enforcement of Shariah-compliant profit-loss sharing (mudaraba, murabaha, salam, etc.) and wealth redistribution (waqf, sadaqah, and zakat). In this study, I apply new econophysics models of wealth exchange and redistribution to quantitatively compare these characteristics to those of capitalism and evaluate wealth distribution and disparity using a simulation. Specifically, regarding exchange, I propose a loan interest model representing finance capitalism and riba and a joint venture model representing shareholder capitalism and mudaraba; regarding redistribution, I create a transfer model representing inheritance tax and waqf. As exchanges are repeated from an initial uniform distribution of wealth, wealth distribution approaches a power-law distribution more quickly for the loan interest than the joint venture model; and the Gini index, representing disparity, rapidly increases. The joint venture model's Gini index increases more slowly, but eventually, the wealth distribution in both models becomes a delta distribution, and the Gini index gradually approaches 1. Next, when both models are combined with the transfer model to redistribute wealth in every given period, the loan interest model has a larger Gini index than the joint venture model, but both converge to a Gini index of less than 1. These results quantitatively reveal that in the Islamic economy, disparity is restrained by prohibiting riba and promoting reciprocal exchange in mudaraba and redistribution through waqf. Comparing Islamic and capitalist economies provides insights into the benefits of economically embracing the ethical practice of mutual aid and suggests guidelines for an alternative to capitalism.",
        "published": "2022-06-11T06:47:40Z",
        "link": "http://arxiv.org/abs/2206.05443v2",
        "categories": [
            "econ.TH",
            "cs.MA",
            "physics.soc-ph",
            "91B43, 91B70, 62P20"
        ]
    },
    {
        "title": "An Algorithm for Exact Numerical Age-of-Information Evaluation in   Multi-Agent Systems",
        "authors": [
            "Richard Schoeffauer",
            "Gerhard Wunder"
        ],
        "summary": "We present an algorithm for the numerical evaluation of the state-space distribution of an Age-of-Information network. Given enough computational resources, the evaluation can be performed to an arbitrary high precision. An Age-of-Information network is described by a vector of natural numbers, that track how outdated status information from various agents is. Our algorithm yields the means to determine any moment of the corresponding stochastic process. This can be extremely valuable for cases in which the network consists of controllers that communicate with one another, as it potentially allows for less conservative control behavior. It also enables the comparison of different policies regarding their performance (minimizing the average Age-of-Information) to a much more accurate degree than was possible before. This is illustrated using the conventional MaxWeight policy and the optimal policy. We also validate and compare the algorithm with Monte-Carlo-Simulations.",
        "published": "2022-06-11T12:11:49Z",
        "link": "http://arxiv.org/abs/2206.05510v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Bounded strategic reasoning explains crisis emergence in multi-agent   market games",
        "authors": [
            "Benjamin Patrick Evans",
            "Mikhail Prokopenko"
        ],
        "summary": "The efficient market hypothesis (EMH), based on rational expectations and market equilibrium, is the dominant perspective for modelling economic markets. However, the most notable critique of the EMH is the inability to model periods of out-of-equilibrium behaviour in the absence of any significant external news. When such dynamics emerge endogenously, the traditional economic frameworks provide no explanation for such behaviour and the deviation from equilibrium. This work offers an alternate perspective explaining the endogenous emergence of punctuated out-of-equilibrium dynamics based on bounded rational agents. In a concise market entrance game, we show how boundedly rational strategic reasoning can lead to endogenously emerging crises, exhibiting fat tails in \"returns\". We also show how other common stylised facts of economic markets, such as clustered volatility, can be explained due to agent diversity (or lack thereof) and the varying learning updates across the agents. This work explains various stylised facts and crisis emergence in economic markets, in the absence of any external news, based purely on agent interactions and bounded rational reasoning.",
        "published": "2022-06-11T17:15:53Z",
        "link": "http://arxiv.org/abs/2206.05568v1",
        "categories": [
            "cs.MA",
            "cs.CE",
            "cs.GT",
            "econ.GN",
            "q-fin.CP",
            "q-fin.EC"
        ]
    },
    {
        "title": "Convergence and Stability of Coupled Belief--Strategy Learning Dynamics   in Continuous Games",
        "authors": [
            "Manxi Wu",
            "Saurabh Amin",
            "Asuman Ozdaglar"
        ],
        "summary": "We propose a learning dynamics to model how strategic agents repeatedly play a continuous game while relying on an information platform to learn an unknown payoff-relevant parameter. In each time step, the platform updates a belief estimate of the parameter based on players' strategies and realized payoffs using Bayes's rule. Then, players adopt a generic learning rule to adjust their strategies based on the updated belief. We present results on the convergence of beliefs and strategies and the properties of convergent fixed points of the dynamics. We obtain sufficient and necessary conditions for the existence of globally stable fixed points. We also provide sufficient conditions for the local stability of fixed points. These results provide an approach to analyzing the long-term outcomes that arise from the interplay between Bayesian belief learning and strategy learning in games, and enable us to characterize conditions under which learning leads to a complete information equilibrium.",
        "published": "2022-06-12T01:00:04Z",
        "link": "http://arxiv.org/abs/2206.05637v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Deep Reinforcement Learning for Optimal Investment and Saving Strategy   Selection in Heterogeneous Profiles: Intelligent Agents working towards   retirement",
        "authors": [
            "Fatih Ozhamaratli",
            "Paolo Barucca"
        ],
        "summary": "The transition from defined benefit to defined contribution pension plans shifts the responsibility for saving toward retirement from governments and institutions to the individuals. Determining optimal saving and investment strategy for individuals is paramount for stable financial stance and for avoiding poverty during work-life and retirement, and it is a particularly challenging task in a world where form of employment and income trajectory experienced by different occupation groups are highly diversified. We introduce a model in which agents learn optimal portfolio allocation and saving strategies that are suitable for their heterogeneous profiles. We use deep reinforcement learning to train agents. The environment is calibrated with occupation and age dependent income evolution dynamics. The research focuses on heterogeneous income trajectories dependent on agent profiles and incorporates the behavioural parameterisation of agents. The model provides a flexible methodology to estimate lifetime consumption and investment choices for heterogeneous profiles under varying scenarios.",
        "published": "2022-06-12T20:27:58Z",
        "link": "http://arxiv.org/abs/2206.05835v1",
        "categories": [
            "q-fin.PM",
            "cs.LG",
            "cs.MA",
            "econ.GN",
            "q-fin.EC"
        ]
    },
    {
        "title": "Coordinating Monetary Contributions in Participatory Budgeting",
        "authors": [
            "Haris Aziz",
            "Sujit Gujar",
            "Manisha Padala",
            "Mashbat Suzuki",
            "Jeremy Vollen"
        ],
        "summary": "We formalize a framework for coordinating funding and selecting projects, the costs of which are shared among agents with quasi-linear utility functions and individual budgets. Our model contains the classical discrete participatory budgeting model as a special case, while capturing other useful scenarios. We propose several important axioms and objectives and study how well they can be simultaneously satisfied. We show that whereas welfare maximization admits an FPTAS, welfare maximization subject to a natural and very weak participation requirement leads to a strong inapproximability. This result is bypassed if we consider some natural restricted valuations, namely laminar single-minded valuations and symmetric valuations. Our analysis for the former restriction leads to the discovery of a new class of tractable instances for the Set Union Knapsack problem, a classical problem in combinatorial optimization.",
        "published": "2022-06-13T08:27:16Z",
        "link": "http://arxiv.org/abs/2206.05966v3",
        "categories": [
            "cs.GT",
            "cs.CC",
            "cs.MA",
            "econ.TH"
        ]
    },
    {
        "title": "Multi-Agent Neural Rewriter for Vehicle Routing with Limited Disclosure   of Costs",
        "authors": [
            "Nathalie Paul",
            "Tim Wirtz",
            "Stefan Wrobel",
            "Alexander Kister"
        ],
        "summary": "We interpret solving the multi-vehicle routing problem as a team Markov game with partially observable costs. For a given set of customers to serve, the playing agents (vehicles) have the common goal to determine the team-optimal agent routes with minimal total cost. Each agent thereby observes only its own cost. Our multi-agent reinforcement learning approach, the so-called multi-agent Neural Rewriter, builds on the single-agent Neural Rewriter to solve the problem by iteratively rewriting solutions. Parallel agent action execution and partial observability require new rewriting rules for the game. We propose the introduction of a so-called pool in the system which serves as a collection point for unvisited nodes. It enables agents to act simultaneously and exchange nodes in a conflict-free manner. We realize limited disclosure of agent-specific costs by only sharing them during learning. During inference, each agents acts decentrally, solely based on its own cost. First empirical results on small problem sizes demonstrate that we reach a performance close to the employed OR-Tools benchmark which operates in the perfect cost information setting.",
        "published": "2022-06-13T09:17:40Z",
        "link": "http://arxiv.org/abs/2206.05990v1",
        "categories": [
            "cs.LG",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Stable Relationships",
        "authors": [
            "Sam Ganzfried"
        ],
        "summary": "We study a dynamic model of the relationship between two people where the states depend on the \"power\" in the relationship. We perform a comprehensive analysis of stability of the system, and determine a set of conditions under which stable relationships are possible. In particular, stable relationships can occur if both people are dominant, but the sum of dominances is below a bound determined by the model's parameters. Stable relationships can also occur if one person is dominant and the other is submissive, provided the level of dominance exceeds the level of submissiveness but not beyond a threshold. We also conclude that a stable relationship is not possible if both people are submissive. While our model is motivated by a social or romantic relationship, it can also be applied to professional or business relationships as well as diplomatic relationships between nations.",
        "published": "2022-06-13T21:01:37Z",
        "link": "http://arxiv.org/abs/2206.06468v9",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "math.DS"
        ]
    },
    {
        "title": "Universally Expressive Communication in Multi-Agent Reinforcement   Learning",
        "authors": [
            "Matthew Morris",
            "Thomas D. Barrett",
            "Arnu Pretorius"
        ],
        "summary": "Allowing agents to share information through communication is crucial for solving complex tasks in multi-agent reinforcement learning. In this work, we consider the question of whether a given communication protocol can express an arbitrary policy. By observing that many existing protocols can be viewed as instances of graph neural networks (GNNs), we demonstrate the equivalence of joint action selection to node labelling. With standard GNN approaches provably limited in their expressive capacity, we draw from existing GNN literature and consider augmenting agent observations with: (1) unique agent IDs and (2) random noise. We provide a theoretical analysis as to how these approaches yield universally expressive communication, and also prove them capable of targeting arbitrary sets of actions for identical agents. Empirically, these augmentations are found to improve performance on tasks where expressive communication is required, whilst, in general, the optimal communication protocol is found to be task-dependent.",
        "published": "2022-06-14T11:16:33Z",
        "link": "http://arxiv.org/abs/2206.06758v3",
        "categories": [
            "cs.MA",
            "cs.DM",
            "cs.LG",
            "68T07, 68T42, 68R10 (Primary) 68T20, 05C15 (Secondary)",
            "I.2.11; I.2.6; I.2.8"
        ]
    },
    {
        "title": "Resource-Mediated Consensus Formation",
        "authors": [
            "Omar Malik",
            "James Flamino",
            "Boleslaw K. Szymanski"
        ],
        "summary": "In social sciences, simulating opinion dynamics to study the interplay between homophily and influence, and the subsequent formation of echo chambers, is of great importance. As such, in this paper we investigate echo chambers by implementing a unique social game in which we spawn in a large number of agents, each assigned one of the two opinions on an issue and a finite amount of influence in the form of a game currency. Agents attempt to have an opinion that is a majority at the end of the game, to obtain a reward also paid in the game currency. At the beginning of each round, a randomly selected agent is selected, referred to as a speaker. The second agent is selected in the radius of speaker influence (which is a set subset of the speaker's neighbors) to interact with the speaker as a listener. In this interaction, the speaker proposes a payoff in the game currency from their personal influence budget to persuade the listener to hold the speaker's opinion in future rounds until chosen listener again. The listener can either choose to accept or reject this payoff to hold the speaker's opinion for future rounds. The listener's choice is informed only by their estimate of global majority opinion through a limited view of the opinions of their neighboring agents. We show that the influence game leads to the formation of \"echo chambers,\" or homogeneous clusters of opinions. We also investigate various scenarios to disrupt the creation of such echo chambers, including the introduction of resource disparity between agents with different opinions, initially preferentially assigning opinions to agents, and the introduction of committed agents, who never change their initial opinion.",
        "published": "2022-06-14T18:36:22Z",
        "link": "http://arxiv.org/abs/2206.07099v1",
        "categories": [
            "cs.MA",
            "cs.SI"
        ]
    },
    {
        "title": "Coevolutionary Dynamics of Actions and Opinions in Social Networks",
        "authors": [
            "Hassan Dehghani Aghbolagh",
            "Mengbin Ye",
            "Lorenzo Zino",
            "Ming Cao",
            "Zhiyong Chen"
        ],
        "summary": "Empirical studies suggest a deep intertwining between opinion formation and decision-making processes, but these have been treated as separate problems in the study of dynamical models for social networks. In this paper, we bridge the gap in the literature by proposing a novel coevolutionary model, in which each individual selects an action from a binary set and has an opinion on which action they prefer. Actions and opinions coevolve on a two-layer network. For homogeneous parameters, undirected networks, and under reasonable assumptions on the asynchronous updating mechanics, we prove that the coevolutionary dynamics is an ordinal potential game, enabling analysis via potential game theory. Specifically, we establish global convergence to the Nash equilibria of the game, proving that actions converge in a finite number of time steps, while opinions converge asymptotically. Next, we provide sufficient conditions for the existence of, and convergence to, polarized equilibria, whereby the population splits into two communities, each selecting and supporting one of the actions. Finally, we use simulations to examine the social psychological phenomenon of pluralistic ignorance.",
        "published": "2022-06-15T02:05:31Z",
        "link": "http://arxiv.org/abs/2206.07242v2",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SI",
            "cs.SY",
            "math.DS"
        ]
    },
    {
        "title": "Automating the resolution of flight conflicts: Deep reinforcement   learning in service of air traffic controllers",
        "authors": [
            "George Vouros",
            "George Papadopoulos",
            "Alevizos Bastas",
            "Jose Manuel Cordero",
            "Ruben Rodrigez Rodrigez"
        ],
        "summary": "Dense and complex air traffic scenarios require higher levels of automation than those exhibited by tactical conflict detection and resolution (CD\\&R) tools that air traffic controllers (ATCO) use today. However, the air traffic control (ATC) domain, being safety critical, requires AI systems to which operators are comfortable to relinquishing control, guaranteeing operational integrity and automation adoption. Two major factors towards this goal are quality of solutions, and transparency in decision making. This paper proposes using a graph convolutional reinforcement learning method operating in a multiagent setting where each agent (flight) performs a CD\\&R task, jointly with other agents. We show that this method can provide high-quality solutions with respect to stakeholders interests (air traffic controllers and airspace users), addressing operational transparency issues.",
        "published": "2022-06-15T09:06:58Z",
        "link": "http://arxiv.org/abs/2206.07403v1",
        "categories": [
            "cs.MA",
            "cs.LG",
            "I.2.1; I.2.11; I.2.6"
        ]
    },
    {
        "title": "Calibrating Agent-based Models to Microdata with Graph Neural Networks",
        "authors": [
            "Joel Dyer",
            "Patrick Cannon",
            "J. Doyne Farmer",
            "Sebastian M. Schmon"
        ],
        "summary": "Calibrating agent-based models (ABMs) to data is among the most fundamental requirements to ensure the model fulfils its desired purpose. In recent years, simulation-based inference methods have emerged as powerful tools for performing this task when the model likelihood function is intractable, as is often the case for ABMs. In some real-world use cases of ABMs, both the observed data and the ABM output consist of the agents' states and their interactions over time. In such cases, there is a tension between the desire to make full use of the rich information content of such granular data on the one hand, and the need to reduce the dimensionality of the data to prevent difficulties associated with high-dimensional learning tasks on the other. A possible resolution is to construct lower-dimensional time-series through the use of summary statistics describing the macrostate of the system at each time point. However, a poor choice of summary statistics can result in an unacceptable loss of information from the original dataset, dramatically reducing the quality of the resulting calibration. In this work, we instead propose to learn parameter posteriors associated with granular microdata directly using temporal graph neural networks. We will demonstrate that such an approach offers highly compelling inductive biases for Bayesian inference using the raw ABM microstates as output.",
        "published": "2022-06-15T14:41:43Z",
        "link": "http://arxiv.org/abs/2206.07570v1",
        "categories": [
            "cs.MA",
            "cs.LG",
            "cs.SI",
            "stat.ML"
        ]
    },
    {
        "title": "Convergence and Price of Anarchy Guarantees of the Softmax Policy   Gradient in Markov Potential Games",
        "authors": [
            "Dingyang Chen",
            "Qi Zhang",
            "Thinh T. Doan"
        ],
        "summary": "We study the performance of policy gradient methods for the subclass of Markov games known as Markov potential games (MPGs), which extends the notion of normal-form potential games to the stateful setting and includes the important special case of the fully cooperative setting where the agents share an identical reward function. Our focus in this paper is to study the convergence of the policy gradient method for solving MPGs under softmax policy parameterization, both tabular and parameterized with general function approximators such as neural networks. We first show the asymptotic convergence of this method to a Nash equilibrium of MPGs for tabular softmax policies. Second, we derive the finite-time performance of the policy gradient in two settings: 1) using the log-barrier regularization, and 2) using the natural policy gradient under the best-response dynamics (NPG-BR). Finally, extending the notion of price of anarchy (POA) and smoothness in normal-form games, we introduce the POA for MPGs and provide a POA bound for NPG-BR. To our knowledge, this is the first POA bound for solving MPGs. To support our theoretical results, we empirically compare the convergence rates and POA of policy gradient variants for both tabular and neural softmax policies.",
        "published": "2022-06-15T16:41:06Z",
        "link": "http://arxiv.org/abs/2206.07642v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.GT",
            "cs.LG"
        ]
    },
    {
        "title": "Reinforcement Learning for Economic Policy: A New Frontier?",
        "authors": [
            "Callum Rhys Tilbury"
        ],
        "summary": "Agent-based computational economics is a field with a rich academic history, yet one which has struggled to enter mainstream policy design toolboxes, plagued by the challenges associated with representing a complex and dynamic reality. The field of Reinforcement Learning (RL), too, has a rich history, and has recently been at the centre of several exponential developments. Modern RL implementations have been able to achieve unprecedented levels of sophistication, handling previously unthinkable degrees of complexity. This review surveys the historical barriers of classical agent-based techniques in economic modelling, and contemplates whether recent developments in RL can overcome any of them.",
        "published": "2022-06-16T10:35:26Z",
        "link": "http://arxiv.org/abs/2206.08781v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "econ.GN",
            "q-fin.EC"
        ]
    },
    {
        "title": "On-the-fly Adaptation of Patrolling Strategies in Changing Environments",
        "authors": [
            "Tomáš Brázdil",
            "David Klaška",
            "Antonín Kučera",
            "Vít Musil",
            "Petr Novotný",
            "Vojtěch Řehák"
        ],
        "summary": "We consider the problem of efficient patrolling strategy adaptation in a changing environment where the topology of Defender's moves and the importance of guarded targets change unpredictably. The Defender must instantly switch to a new strategy optimized for the new environment, not disrupting the ongoing patrolling task, and the new strategy must be computed promptly under all circumstances. Since strategy switching may cause unintended security risks compromising the achieved protection, our solution includes mechanisms for detecting and mitigating this problem. The efficiency of our framework is evaluated experimentally.",
        "published": "2022-06-16T11:32:24Z",
        "link": "http://arxiv.org/abs/2206.08096v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "UAVs Beneath the Surface: Cooperative Autonomy for Subterranean Search   and Rescue in DARPA SubT",
        "authors": [
            "Matej Petrlik",
            "Pavel Petracek",
            "Vit Kratky",
            "Tomas Musil",
            "Yurii Stasinchuk",
            "Matous Vrba",
            "Tomas Baca",
            "Daniel Hert",
            "Martin Pecka",
            "Tomas Svoboda",
            "Martin Saska"
        ],
        "summary": "This paper presents a novel approach for autonomous cooperating UAVs in search and rescue operations in subterranean domains with complex topology. The proposed system was ranked second in the Virtual Track of the DARPA SubT Finals as part of the team CTU-CRAS-NORLAB. In contrast to the winning solution that was developed specifically for the Virtual Track, the proposed solution also proved to be a robust system for deployment onboard physical UAVs flying in the extremely harsh and confined environment of the real-world competition. The proposed approach enables fully autonomous and decentralized deployment of a UAV team with seamless simulation-to-world transfer, and proves its advantage over less mobile UGV teams in the flyable space of diverse environments. The main contributions of the paper are present in the mapping and navigation pipelines. The mapping approach employs novel map representations -- SphereMap for efficient risk-aware long-distance planning, FacetMap for surface coverage, and the compressed topological-volumetric LTVMap for allowing multi-robot cooperation under low-bandwidth communication. These representations are used in navigation together with novel methods for visibility-constrained informed search in a general 3D environment with no assumptions about the environment structure, while balancing deep exploration with sensor-coverage exploitation. The proposed solution also includes a visual-perception pipeline for on-board detection and localization of objects of interest in four RGB stream at 5 Hz each without a dedicated GPU. Apart from participation in the DARPA SubT, the performance of the UAV system is supported by extensive experimental verification in diverse environments with both qualitative and quantitative evaluation.",
        "published": "2022-06-16T13:54:33Z",
        "link": "http://arxiv.org/abs/2206.08185v2",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "A Comprehensive Eco-Driving Strategy for Connected and Autonomous   Vehicles (CAVs) with Microscopic Traffic Simulation Testing Evaluation",
        "authors": [
            "Ozgenur Kavas-Torris",
            "Levent Guvenc"
        ],
        "summary": "In this paper, a comprehensive Eco-Driving strategy for CAVs is presented. In this setup, multiple driving modes calculate speed profiles ideal for their own set of constraints simultaneously to save fuel as much as possible, while a High Level (HL) controller ensures smooth transitions between the driving modes for Eco-Driving. This Eco-Driving deterministic controller for an ego CAV was equipped with Vehicle-to-Infrastructure (V2I) and Vehicle-to-Vehicle (V2V) algorithms. Simulation results are used to show that the HL controller ensures significant fuel economy improvement as compared to baseline driving modes with no collisions between the ego CAV and traffic vehicles while the driving mode of the ego CAV was set correctly under changing constraints.",
        "published": "2022-06-16T17:10:18Z",
        "link": "http://arxiv.org/abs/2206.08306v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.NA",
            "cs.SY",
            "math.NA"
        ]
    },
    {
        "title": "Belief-Desire-Intention (BDI) Multi-agent System for Cloud Marketplace   Negotiation",
        "authors": [
            "Saurabh Deochake"
        ],
        "summary": "With the evolution of cloud computing, there has been a rise of large enterprises extending their infrastructure and workloads into the public cloud. This paper proposes a full-fledged framework for a Belief-Desire-Intention (BDI) multi-agent-based cloud marketplace system for cloud resources. Each party in the cloud marketplace system supports a BDI agent for autonomous decision making and negotiation to facilitate automated buying and selling of resources. Additionally, multiple BDI agents from an enterprise competing for the same cloud resource can consult with each other via Master Negotiation Clearing House to minimize the overall cost function for the enterprise while negotiating for a cloud resource. The cloud marketplace system is further augmented with assignments of behavior norm and reputation index to the agents to facilitate trust among them.",
        "published": "2022-06-16T22:36:45Z",
        "link": "http://arxiv.org/abs/2206.08468v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.DC",
            "cs.NI"
        ]
    },
    {
        "title": "Towards Human-Level Bimanual Dexterous Manipulation with Reinforcement   Learning",
        "authors": [
            "Yuanpei Chen",
            "Tianhao Wu",
            "Shengjie Wang",
            "Xidong Feng",
            "Jiechuang Jiang",
            "Stephen Marcus McAleer",
            "Yiran Geng",
            "Hao Dong",
            "Zongqing Lu",
            "Song-Chun Zhu",
            "Yaodong Yang"
        ],
        "summary": "Achieving human-level dexterity is an important open problem in robotics. However, tasks of dexterous hand manipulation, even at the baby level, are challenging to solve through reinforcement learning (RL). The difficulty lies in the high degrees of freedom and the required cooperation among heterogeneous agents (e.g., joints of fingers). In this study, we propose the Bimanual Dexterous Hands Benchmark (Bi-DexHands), a simulator that involves two dexterous hands with tens of bimanual manipulation tasks and thousands of target objects. Specifically, tasks in Bi-DexHands are designed to match different levels of human motor skills according to cognitive science literature. We built Bi-DexHands in the Issac Gym; this enables highly efficient RL training, reaching 30,000+ FPS by only one single NVIDIA RTX 3090. We provide a comprehensive benchmark for popular RL algorithms under different settings; this includes Single-agent/Multi-agent RL, Offline RL, Multi-task RL, and Meta RL. Our results show that the PPO type of on-policy algorithms can master simple manipulation tasks that are equivalent up to 48-month human babies (e.g., catching a flying object, opening a bottle), while multi-agent RL can further help to master manipulations that require skilled bimanual cooperation (e.g., lifting a pot, stacking blocks). Despite the success on each single task, when it comes to acquiring multiple manipulation skills, existing RL algorithms fail to work in most of the multi-task and the few-shot learning settings, which calls for more substantial development from the RL community. Our project is open sourced at https://github.com/PKU-MARL/DexterousHands.",
        "published": "2022-06-17T11:09:06Z",
        "link": "http://arxiv.org/abs/2206.08686v2",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Logic-based Reward Shaping for Multi-Agent Reinforcement Learning",
        "authors": [
            "Ingy ElSayed-Aly",
            "Lu Feng"
        ],
        "summary": "Reinforcement learning (RL) relies heavily on exploration to learn from its environment and maximize observed rewards. Therefore, it is essential to design a reward function that guarantees optimal learning from the received experience. Previous work has combined automata and logic based reward shaping with environment assumptions to provide an automatic mechanism to synthesize the reward function based on the task. However, there is limited work on how to expand logic-based reward shaping to Multi-Agent Reinforcement Learning (MARL). The environment will need to consider the joint state in order to keep track of other agents if the task requires cooperation, thus suffering from the curse of dimensionality with respect to the number of agents. This project explores how logic-based reward shaping for MARL can be designed for different scenarios and tasks. We present a novel method for semi-centralized logic-based MARL reward shaping that is scalable in the number of agents and evaluate it in multiple scenarios.",
        "published": "2022-06-17T16:30:27Z",
        "link": "http://arxiv.org/abs/2206.08881v1",
        "categories": [
            "cs.AI",
            "cs.FL",
            "cs.MA",
            "I.2.6; I.2.4"
        ]
    },
    {
        "title": "Edge-Aided Sensor Data Sharing in Vehicular Communication Networks",
        "authors": [
            "Rui Song",
            "Anupama Hegde",
            "Numan Senel",
            "Alois Knoll",
            "Andreas Festag"
        ],
        "summary": "Sensor data sharing in vehicular networks can significantly improve the range and accuracy of environmental perception for connected automated vehicles. Different concepts and schemes for dissemination and fusion of sensor data have been developed. It is common to these schemes that measurement errors of the sensors impair the perception quality and can result in road traffic accidents. Specifically, when the measurement error from the sensors (also referred as measurement noise) is unknown and time varying, the performance of the data fusion process is restricted, which represents a major challenge in the calibration of sensors. In this paper, we consider sensor data sharing and fusion in a vehicular network with both, vehicle-to-infrastructure and vehicle-to-vehicle communication. We propose a method, named Bidirectional Feedback Noise Estimation (BiFNoE), in which an edge server collects and caches sensor measurement data from vehicles. The edge estimates the noise and the targets alternately in double dynamic sliding time windows and enhances the distributed cooperative environment sensing at each vehicle with low communication costs. We evaluate the proposed algorithm and data dissemination strategy in an application scenario by simulation and show that the perception accuracy is on average improved by around 80 % with only 12 kbps uplink and 28 kbps downlink bandwidth.",
        "published": "2022-06-17T16:30:56Z",
        "link": "http://arxiv.org/abs/2206.08882v1",
        "categories": [
            "cs.MA",
            "cs.CV",
            "eess.SP"
        ]
    },
    {
        "title": "Responsibility-associated Multi-agent Collision Avoidance with Social   Preferences",
        "authors": [
            "Yiwei Lyu",
            "Wenhao Luo",
            "John M. Dolan"
        ],
        "summary": "This paper introduces a novel social preference-aware decentralized safe control framework to address the responsibility allocation problem in multi-agent collision avoidance. Considering that agents do not necessarily cooperate in symmetric ways, this paper focuses on semi-cooperative behavior among heterogeneous agents with varying cooperation levels. Drawing upon the idea of Social Value Orientation (SVO) for quantifying the individual selfishness, we propose a novel concept of Responsibility-associated Social Value Orientation (R-SVO) to express the intended relative social implications between pairwise agents. This is used to redefine each agent's social preferences or personalities in terms of corresponding responsibility shares in contributing to the coordination scenario, such as semi-cooperative collision avoidance where all agents interact in an asymmetric way. By incorporating such relative social implications through proposed Local Pairwise Responsibility Weights, we develop a Responsibility-associated Control Barrier Function-based safe control framework for individual agents, and multi-agent collision avoidance is achieved with formally provable safety guarantees. Simulations are provided to demonstrate the effectiveness and efficiency of the proposed framework in several multi-agent navigation tasks, such as a position-swapping game, a self-driving car highway ramp merging scenario, and a circular position swapping game.",
        "published": "2022-06-17T22:17:11Z",
        "link": "http://arxiv.org/abs/2206.09030v1",
        "categories": [
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Beyond Rewards: a Hierarchical Perspective on Offline Multiagent   Behavioral Analysis",
        "authors": [
            "Shayegan Omidshafiei",
            "Andrei Kapishnikov",
            "Yannick Assogba",
            "Lucas Dixon",
            "Been Kim"
        ],
        "summary": "Each year, expert-level performance is attained in increasingly-complex multiagent domains, where notable examples include Go, Poker, and StarCraft II. This rapid progression is accompanied by a commensurate need to better understand how such agents attain this performance, to enable their safe deployment, identify limitations, and reveal potential means of improving them. In this paper we take a step back from performance-focused multiagent learning, and instead turn our attention towards agent behavior analysis. We introduce a model-agnostic method for discovery of behavior clusters in multiagent domains, using variational inference to learn a hierarchy of behaviors at the joint and local agent levels. Our framework makes no assumption about agents' underlying learning algorithms, does not require access to their latent states or policies, and is trained using only offline observational data. We illustrate the effectiveness of our method for enabling the coupled understanding of behaviors at the joint and local agent level, detection of behavior changepoints throughout training, discovery of core behavioral concepts, demonstrate the approach's scalability to a high-dimensional multiagent MuJoCo control domain, and also illustrate that the approach can disentangle previously-trained policies in OpenAI's hide-and-seek domain.",
        "published": "2022-06-17T23:07:33Z",
        "link": "http://arxiv.org/abs/2206.09046v3",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "A Marriage between Adversarial Team Games and 2-player Games: Enabling   Abstractions, No-regret Learning, and Subgame Solving",
        "authors": [
            "Luca Carminati",
            "Federico Cacciamani",
            "Marco Ciccone",
            "Nicola Gatti"
        ],
        "summary": "\\emph{Ex ante} correlation is becoming the mainstream approach for \\emph{sequential adversarial team games}, where a team of players faces another team in a zero-sum game. It is known that team members' asymmetric information makes both equilibrium computation \\textsf{APX}-hard and team's strategies not directly representable on the game tree. This latter issue prevents the adoption of successful tools for huge 2-player zero-sum games such as, \\emph{e.g.}, abstractions, no-regret learning, and subgame solving. This work shows that we can recover from this weakness by bridging the gap between sequential adversarial team games and 2-player games. In particular, we propose a new, suitable game representation that we call \\emph{team-public-information}, in which a team is represented as a single coordinator who only knows information common to the whole team and prescribes to each member an action for any possible private state. The resulting representation is highly \\emph{explainable}, being a 2-player tree in which the team's strategies are behavioral with a direct interpretation and more expressive than the original extensive form when designing abstractions. Furthermore, we prove payoff equivalence of our representation, and we provide techniques that, starting directly from the extensive form, generate dramatically more compact representations without information loss. Finally, we experimentally evaluate our techniques when applied to a standard testbed, comparing their performance with the current state of the art.",
        "published": "2022-06-18T10:02:08Z",
        "link": "http://arxiv.org/abs/2206.09161v1",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "A Critical Review of Communications in Multi-Robot Systems",
        "authors": [
            "Jennifer Gielis",
            "Ajay Shankar",
            "Amanda Prorok"
        ],
        "summary": "Purpose of Review. This review summarizes the broad roles that communication formats and technologies have played in enabling multi-robot systems. We approach this field from two perspectives: of robotic applications that need communication capabilities in order to accomplish tasks, and of networking technologies that have enabled newer and more advanced multi-robot systems.   Recent Findings. Through this review, we identify a dearth of work that holistically tackles the problem of co-design and co-optimization of robots and the networks they employ. We also highlight the role that data-driven and machine learning approaches play in evolving communication pipelines for multi-robot systems. In particular, we refer to recent work that diverges from hand-designed communication patterns, and also discuss the \"sim-to-real\" gap in this context.   Summary. We present a critical view of the way robotic algorithms and their networking systems have evolved, and make the case for a more synergistic approach. Finally, we also identify four broad Open Problems for research and development, while offering a data-driven perspective for solving some of them.",
        "published": "2022-06-19T20:26:50Z",
        "link": "http://arxiv.org/abs/2206.09484v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Cooperative Edge Caching via Multi Agent Reinforcement Learning in Fog   Radio Access Networks",
        "authors": [
            "Qi Chang",
            "Yanxiang Jiang",
            "Fu-Chun Zheng",
            "Mehdi Bennis",
            "Xiaohu You"
        ],
        "summary": "In this paper, the cooperative edge caching problem in fog radio access networks (F-RANs) is investigated. To minimize the content transmission delay, we formulate the cooperative caching optimization problem to find the globally optimal caching strategy.By considering the non-deterministic polynomial hard (NP-hard) property of this problem, a Multi Agent Reinforcement Learning (MARL)-based cooperative caching scheme is proposed.Our proposed scheme applies double deep Q-network (DDQN) in every fog access point (F-AP), and introduces the communication process in multi-agent system. Every F-AP records the historical caching strategies of its associated F-APs as the observations of communication procedure.By exchanging the observations, F-APs can leverage the cooperation and make the globally optimal caching strategy.Simulation results show that the proposed MARL-based cooperative caching scheme has remarkable performance compared with the benchmark schemes in minimizing the content transmission delay.",
        "published": "2022-06-20T03:16:17Z",
        "link": "http://arxiv.org/abs/2206.09549v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "From Multi-agent to Multi-robot: A Scalable Training and Evaluation   Platform for Multi-robot Reinforcement Learning",
        "authors": [
            "Zhiuxan Liang",
            "Jiannong Cao",
            "Shan Jiang",
            "Divya Saxena",
            "Jinlin Chen",
            "Huafeng Xu"
        ],
        "summary": "Multi-agent reinforcement learning (MARL) has been gaining extensive attention from academia and industries in the past few decades. One of the fundamental problems in MARL is how to evaluate different approaches comprehensively. Most existing MARL methods are evaluated in either video games or simplistic simulated scenarios. It remains unknown how these methods perform in real-world scenarios, especially multi-robot systems. This paper introduces a scalable emulation platform for multi-robot reinforcement learning (MRRL) called SMART to meet this need. Precisely, SMART consists of two components: 1) a simulation environment that provides a variety of complex interaction scenarios for training and 2) a real-world multi-robot system for realistic performance evaluation. Besides, SMART offers agent-environment APIs that are plug-and-play for algorithm implementation. To illustrate the practicality of our platform, we conduct a case study on the cooperative driving lane change scenario. Building off the case study, we summarize several unique challenges of MRRL, which are rarely considered previously. Finally, we open-source the simulation environments, associated benchmark tasks, and state-of-the-art baselines to encourage and empower MRRL research.",
        "published": "2022-06-20T06:36:45Z",
        "link": "http://arxiv.org/abs/2206.09590v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.RO",
            "I.2.9; I.2.11"
        ]
    },
    {
        "title": "MF-OMO: An Optimization Formulation of Mean-Field Games",
        "authors": [
            "Xin Guo",
            "Anran Hu",
            "Junzi Zhang"
        ],
        "summary": "This paper proposes a new mathematical paradigm to analyze discrete-time mean-field games. It is shown that finding Nash equilibrium solutions for a general class of discrete-time mean-field games is equivalent to solving an optimization problem with bounded variables and simple convex constraints, called MF-OMO. This equivalence framework enables finding multiple (and possibly all) Nash equilibrium solutions of mean-field games by standard algorithms. For instance, projected gradient descent is shown to be capable of retrieving all possible Nash equilibrium solutions when there are finitely many of them, with proper initializations. Moreover, analyzing mean-field games with linear rewards and mean-field independent dynamics is reduced to solving a finite number of linear programs, hence solvable in finite time. This framework does not rely on the contractive and the monotone assumptions and the uniqueness of the Nash equilibrium.",
        "published": "2022-06-20T07:35:12Z",
        "link": "http://arxiv.org/abs/2206.09608v3",
        "categories": [
            "math.OC",
            "cs.MA",
            "math.PR"
        ]
    },
    {
        "title": "Nocturne: a scalable driving benchmark for bringing multi-agent learning   one step closer to the real world",
        "authors": [
            "Eugene Vinitsky",
            "Nathan Lichtlé",
            "Xiaomeng Yang",
            "Brandon Amos",
            "Jakob Foerster"
        ],
        "summary": "We introduce Nocturne, a new 2D driving simulator for investigating multi-agent coordination under partial observability. The focus of Nocturne is to enable research into inference and theory of mind in real-world multi-agent settings without the computational overhead of computer vision and feature extraction from images. Agents in this simulator only observe an obstructed view of the scene, mimicking human visual sensing constraints. Unlike existing benchmarks that are bottlenecked by rendering human-like observations directly using a camera input, Nocturne uses efficient intersection methods to compute a vectorized set of visible features in a C++ back-end, allowing the simulator to run at over 2000 steps-per-second. Using open-source trajectory and map data, we construct a simulator to load and replay arbitrary trajectories and scenes from real-world driving data. Using this environment, we benchmark reinforcement-learning and imitation-learning agents and demonstrate that the agents are quite far from human-level coordination ability and deviate significantly from the expert trajectories.",
        "published": "2022-06-20T16:51:44Z",
        "link": "http://arxiv.org/abs/2206.09889v3",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG",
            "cs.RO"
        ]
    },
    {
        "title": "On the Impossibility of Learning to Cooperate with Adaptive Partner   Strategies in Repeated Games",
        "authors": [
            "Robert Loftin",
            "Frans A. Oliehoek"
        ],
        "summary": "Learning to cooperate with other agents is challenging when those agents also possess the ability to adapt to our own behavior. Practical and theoretical approaches to learning in cooperative settings typically assume that other agents' behaviors are stationary, or else make very specific assumptions about other agents' learning processes. The goal of this work is to understand whether we can reliably learn to cooperate with other agents without such restrictive assumptions, which are unlikely to hold in real-world applications. Our main contribution is a set of impossibility results, which show that no learning algorithm can reliably learn to cooperate with all possible adaptive partners in a repeated matrix game, even if that partner is guaranteed to cooperate with some stationary strategy. Motivated by these results, we then discuss potential alternative assumptions which capture the idea that an adaptive partner will only adapt rationally to our behavior.",
        "published": "2022-06-20T16:59:12Z",
        "link": "http://arxiv.org/abs/2206.10614v2",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "I.2.6"
        ]
    },
    {
        "title": "The fastest linearly converging discrete-time average consensus using   buffered information",
        "authors": [
            "Amir-Salar Esteki",
            "Hossein Moradian",
            "Solmaz S. Kia"
        ],
        "summary": "In this letter, we study the problem of accelerating reaching average consensus over connected graphs in a discrete-time communication setting. Literature has shown that consensus algorithms can be accelerated by increasing the graph connectivity or optimizing the weights agents place on the information received from their neighbors. In this letter instead of altering the communication graph, we investigate two methods that use buffered states to accelerate reaching average consensus over a given graph. In the first method, we study how convergence rate of the well-known first-order Laplacian average consensus algorithm changes with delayed feedback and obtain a sufficient condition on the ranges of delay that leads to faster convergence. In the second proposed method, we show how average consensus problem can be cast as a convex optimization problem and solved by first-order accelerated optimization algorithms for strongly-convex cost functions. We construct the fastest converging average consensus algorithm using the so-called Triple Momentum optimization algorithm. We demonstrate our results using an in-network linear regression problem, which is formulated as two average consensus problems.",
        "published": "2022-06-20T17:49:46Z",
        "link": "http://arxiv.org/abs/2206.09916v1",
        "categories": [
            "math.OC",
            "cs.MA"
        ]
    },
    {
        "title": "Certifiably Robust Policy Learning against Adversarial Communication in   Multi-agent Systems",
        "authors": [
            "Yanchao Sun",
            "Ruijie Zheng",
            "Parisa Hassanzadeh",
            "Yongyuan Liang",
            "Soheil Feizi",
            "Sumitra Ganesh",
            "Furong Huang"
        ],
        "summary": "Communication is important in many multi-agent reinforcement learning (MARL) problems for agents to share information and make good decisions. However, when deploying trained communicative agents in a real-world application where noise and potential attackers exist, the safety of communication-based policies becomes a severe issue that is underexplored. Specifically, if communication messages are manipulated by malicious attackers, agents relying on untrustworthy communication may take unsafe actions that lead to catastrophic consequences. Therefore, it is crucial to ensure that agents will not be misled by corrupted communication, while still benefiting from benign communication. In this work, we consider an environment with $N$ agents, where the attacker may arbitrarily change the communication from any $C<\\frac{N-1}{2}$ agents to a victim agent. For this strong threat model, we propose a certifiable defense by constructing a message-ensemble policy that aggregates multiple randomly ablated message sets. Theoretical analysis shows that this message-ensemble policy can utilize benign communication while being certifiably robust to adversarial communication, regardless of the attacking algorithm. Experiments in multiple environments verify that our defense significantly improves the robustness of trained policies against various types of attacks.",
        "published": "2022-06-21T07:32:18Z",
        "link": "http://arxiv.org/abs/2206.10158v2",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "World of Bugs: A Platform for Automated Bug Detection in 3D Video Games",
        "authors": [
            "Benedict Wilkins",
            "Kostas Stathis"
        ],
        "summary": "We present World of Bugs (WOB), an open platform that aims to support Automated Bug Detection (ABD) research in video games. We discuss some open problems in ABD and how they relate to the platform's design, arguing that learning-based solutions are required if further progress is to be made. The platform's key feature is a growing collection of common video game bugs that may be used for training and evaluating ABD approaches.",
        "published": "2022-06-21T10:52:03Z",
        "link": "http://arxiv.org/abs/2206.11037v1",
        "categories": [
            "cs.SE",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "POGEMA: Partially Observable Grid Environment for Multiple Agents",
        "authors": [
            "Alexey Skrynnik",
            "Anton Andreychuk",
            "Konstantin Yakovlev",
            "Aleksandr I. Panov"
        ],
        "summary": "We introduce POGEMA (https://github.com/AIRI-Institute/pogema) a sandbox for challenging partially observable multi-agent pathfinding (PO-MAPF) problems . This is a grid-based environment that was specifically designed to be a flexible, tunable and scalable benchmark. It can be tailored to a variety of PO-MAPF, which can serve as an excellent testing ground for planning and learning methods, and their combination, which will allow us to move towards filling the gap between AI planning and learning.",
        "published": "2022-06-22T09:39:50Z",
        "link": "http://arxiv.org/abs/2206.10944v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Modeling Emergent Lexicon Formation with a Self-Reinforcing Stochastic   Process",
        "authors": [
            "Brendon Boldt",
            "David Mortensen"
        ],
        "summary": "We introduce FiLex, a self-reinforcing stochastic process which models finite lexicons in emergent language experiments. The central property of FiLex is that it is a self-reinforcing process, parallel to the intuition that the more a word is used in a language, the more its use will continue. As a theoretical model, FiLex serves as a way to both explain and predict the behavior of the emergent language system. We empirically test FiLex's ability to capture the relationship between the emergent language's hyperparameters and the lexicon's Shannon entropy.",
        "published": "2022-06-22T14:47:24Z",
        "link": "http://arxiv.org/abs/2206.11146v1",
        "categories": [
            "cs.CL",
            "cs.MA",
            "I.2.11; I.2.7; I.6.m"
        ]
    },
    {
        "title": "Multi-Agent Car Parking using Reinforcement Learning",
        "authors": [
            "Omar Tanner"
        ],
        "summary": "As the industry of autonomous driving grows, so does the potential interaction of groups of autonomous cars. Combined with the advancement of Artificial Intelligence and simulation, such groups can be simulated, and safety-critical models can be learned controlling the cars within. This study applies reinforcement learning to the problem of multi-agent car parking, where groups of cars aim to efficiently park themselves, while remaining safe and rational. Utilising robust tools and machine learning frameworks, we design and implement a flexible car parking environment in the form of a Markov decision process with independent learners, exploiting multi-agent communication. We implement a suite of tools to perform experiments at scale, obtaining models parking up to 7 cars with over a 98.1% success rate, significantly beating existing single-agent models. We also obtain several results relating to competitive and collaborative behaviours exhibited by the cars in our environment, with varying densities and levels of communication. Notably, we discover a form of collaboration that cannot arise without competition, and a 'leaky' form of collaboration whereby agents collaborate without sufficient state. Such work has numerous potential applications in the autonomous driving and fleet management industries, and provides several useful techniques and benchmarks for the application of reinforcement learning to multi-agent car parking.",
        "published": "2022-06-22T16:50:04Z",
        "link": "http://arxiv.org/abs/2206.13338v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Recommendations for Systematic Research on Emergent Language",
        "authors": [
            "Brendon Boldt",
            "David Mortensen"
        ],
        "summary": "Emergent language is unique among fields within the discipline of machine learning for its open-endedness, not obviously presenting well-defined problems to be solved. As a result, the current research in the field has largely been exploratory: focusing on establishing new problems, techniques, and phenomena. Yet after these problems have been established, subsequent progress requires research which can measurably demonstrate how it improves on prior approaches. This type of research is what we call systematic research; in this paper, we illustrate this mode of research specifically for emergent language. We first identify the overarching goals of emergent language research, categorizing them as either science or engineering. Using this distinction, we present core methodological elements of science and engineering, analyze their role in current emergent language research, and recommend how to apply these elements.",
        "published": "2022-06-22T18:10:44Z",
        "link": "http://arxiv.org/abs/2206.11302v1",
        "categories": [
            "cs.MA",
            "cs.CL",
            "I.2.11; I.6.m; K.4.m"
        ]
    },
    {
        "title": "Graph-Based Multi-Robot Path Finding and Planning",
        "authors": [
            "Hang Ma"
        ],
        "summary": "Purpose of Review   Planning collision-free paths for multiple robots is important for real-world multi-robot systems and has been studied as an optimization problem on graphs, called Multi-Agent Path Finding (MAPF). This review surveys different categories of classic and state-of-the-art MAPF algorithms and different research attempts to tackle the challenges of generalizing MAPF techniques to real-world scenarios.   Recent Findings   Solving MAPF problems optimally is computationally challenging. Recent advances have resulted in MAPF algorithms that can compute collision-free paths for hundreds of robots and thousands of navigation tasks in seconds of runtime. Many variants of MAPF have been formalized to adapt MAPF techniques to different real-world requirements, such as considerations of robot kinematics, online optimization for real-time systems, and the integration of task assignment and path planning.   Summary   Algorithmic techniques for MAPF problems have addressed important aspects of several multi-robot applications, including automated warehouse fulfillment and sortation, automated train scheduling, and navigation of non-holonomic robots and quadcopters. This showcases their potential for real-world applications of large-scale multi-robot systems.",
        "published": "2022-06-22T18:47:00Z",
        "link": "http://arxiv.org/abs/2206.11319v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "PAC: Assisted Value Factorisation with Counterfactual Predictions in   Multi-Agent Reinforcement Learning",
        "authors": [
            "Hanhan Zhou",
            "Tian Lan",
            "Vaneet Aggarwal"
        ],
        "summary": "Multi-agent reinforcement learning (MARL) has witnessed significant progress with the development of value function factorization methods. It allows optimizing a joint action-value function through the maximization of factorized per-agent utilities due to monotonicity. In this paper, we show that in partially observable MARL problems, an agent's ordering over its own actions could impose concurrent constraints (across different states) on the representable function class, causing significant estimation error during training. We tackle this limitation and propose PAC, a new framework leveraging Assistive information generated from Counterfactual Predictions of optimal joint action selection, which enable explicit assistance to value function factorization through a novel counterfactual loss. A variational inference-based information encoding method is developed to collect and encode the counterfactual predictions from an estimated baseline. To enable decentralized execution, we also derive factorized per-agent policies inspired by a maximum-entropy MARL framework. We evaluate the proposed PAC on multi-agent predator-prey and a set of StarCraft II micromanagement tasks. Empirical results demonstrate improved results of PAC over state-of-the-art value-based and policy-based multi-agent reinforcement learning algorithms on all benchmarks.",
        "published": "2022-06-22T23:34:30Z",
        "link": "http://arxiv.org/abs/2206.11420v3",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Nash equilibrium seeking under partial decision information:   Monotonicity, smoothness and proximal-point algorithms",
        "authors": [
            "Mattia Bianchi",
            "Sergio Grammatico"
        ],
        "summary": "We address Nash equilibrium problems in a partial-decision information scenario, where each agent can only exchange information with some neighbors, while its cost function possibly depends on the strategies of all agents. We characterize the relation between several monotonicity and smoothness conditions postulated in the literature. Furthermore, we prove convergence of a preconditioned proximal point algorithm, under a restricted monotonicity property that allows for a non-Lipschitz, non-continuous game mapping.",
        "published": "2022-06-23T09:28:44Z",
        "link": "http://arxiv.org/abs/2206.11568v1",
        "categories": [
            "math.OC",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "A Novel Multi-Agent Scheduling Mechanism for Adaptation of Production   Plans in Case of Supply Chain Disruptions",
        "authors": [
            "Jing Tan",
            "Lars Braubach",
            "Kai Jander",
            "Rongjun Xu",
            "Kai Chen"
        ],
        "summary": "Manufacturing companies typically use sophisticated production planning systems optimizing production steps, often delivering near-optimal solutions. As a downside for delivering a near-optimal schedule, planning systems have high computational demands resulting in hours of computation. Under normal circumstances this is not issue if there is enough buffer time before implementation of the schedule (e.g. at night for the next day). However, in case of unexpected disruptions such as delayed part deliveries or defectively manufactured goods, the planned schedule may become invalid and swift replanning becomes necessary. Such immediate replanning is unsuited for existing optimal planners due to the computational requirements. This paper proposes a novel solution that can effectively and efficiently perform replanning in case of different types of disruptions using an existing plan. The approach is based on the idea to adhere to the existing schedule as much as possible, adapting it based on limited local changes. For that purpose an agent-based scheduling mechanism has been devised, in which agents represent materials and production sites and use local optimization techniques and negotiations to generate an adapted (sufficient, but non-optimal) schedule. The approach has been evaluated using real production data from Huawei, showing that efficient schedules are produced in short time. The system has been implemented as proof of concept and is currently reimplemented and transferred to a production system based on the Jadex agent platform.",
        "published": "2022-06-23T10:28:54Z",
        "link": "http://arxiv.org/abs/2206.12413v1",
        "categories": [
            "cs.AI",
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "Dynamic consensus with prescribed convergence time for multi-leader   formation tracking",
        "authors": [
            "Rodrigo Aldana-López",
            "David Gómez-Gutiérrez",
            "Rosario Aragüés",
            "Carlos Sagüés"
        ],
        "summary": "This work addresses the problem of distributed formation tracking for a group of follower holonomic mobile robots around a reference signal. The reference signal is comprised of the geometric center of the positions of multiple leaders. This work's main contribution is a novel Modulated Distributed Virtual Observer (MDVO) for the reference signal. Moreover, the proposed MDVO is based on an exact dynamic consensus algorithm with a prescribed convergence time. In addition, we provide simulation examples showcasing two different application scenarios for the proposal.",
        "published": "2022-06-23T10:35:26Z",
        "link": "http://arxiv.org/abs/2206.11608v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY",
            "math.OC"
        ]
    },
    {
        "title": "A Fast Algorithm for Robust Action Selection in Multi-Agent Systems",
        "authors": [
            "Jun Liu",
            "Ryan K. Williams"
        ],
        "summary": "In this paper, we consider a robust action selection problem in multi-agent systems where performance must be guaranteed when the system suffers a worst-case attack on its agents. Specifically, agents are tasked with selecting actions from a common ground set according to individualized objective functions, and we aim to protect the system against attacks. In our problem formulation, attackers attempt to disrupt the system by removing an agent's contribution after knowing the system solution and thus can attack perfectly. To protect the multi-agent system against such attacks, we aim to maximize the minimum performance of all agents' individual objective functions under attacks. Thus, we propose a fast algorithm with tunable parameters for balancing complexity and performance, yielding substantially improved time complexity and performance compared to recent methods. Finally, we provide Monte Carlo simulations to demonstrate the performance of the proposed algorithm.",
        "published": "2022-06-23T16:49:08Z",
        "link": "http://arxiv.org/abs/2206.11824v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Toward multi-target self-organizing pursuit in a partially observable   Markov game",
        "authors": [
            "Lijun Sun",
            "Yu-Cheng Chang",
            "Chao Lyu",
            "Ye Shi",
            "Yuhui Shi",
            "Chin-Teng Lin"
        ],
        "summary": "The multiple-target self-organizing pursuit (SOP) problem has wide applications and has been considered a challenging self-organization game for distributed systems, in which intelligent agents cooperatively pursue multiple dynamic targets with partial observations. This work proposes a framework for decentralized multi-agent systems to improve the implicit coordination capabilities in search and pursuit. We model a self-organizing system as a partially observable Markov game (POMG) featured by large-scale, decentralization, partial observation, and noncommunication. The proposed distributed algorithm: fuzzy self-organizing cooperative coevolution (FSC2) is then leveraged to resolve the three challenges in multi-target SOP: distributed self-organizing search (SOS), distributed task allocation, and distributed single-target pursuit. FSC2 includes a coordinated multi-agent deep reinforcement learning (MARL) method that enables homogeneous agents to learn natural SOS patterns. Additionally, we propose a fuzzy-based distributed task allocation method, which locally decomposes multi-target SOP into several single-target pursuit problems. The cooperative coevolution principle is employed to coordinate distributed pursuers for each single-target pursuit problem. Therefore, the uncertainties of inherent partial observation and distributed decision-making in the POMG can be alleviated. The experimental results demonstrate that by decomposing the SOP task, FSC2 achieves superior performance compared with other implicit coordination policies fully trained by general MARL algorithms. The scalability of FSC2 is proved that up to 2048 FSC2 agents perform efficient multi-target SOP with almost 100 percent capture rates. Empirical analyses and ablation studies verify the interpretability, rationality, and effectiveness of component algorithms in FSC2.",
        "published": "2022-06-24T14:59:56Z",
        "link": "http://arxiv.org/abs/2206.12330v3",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Diegetic Representation of Feedback in Open Games",
        "authors": [
            "Matteo Capucci"
        ],
        "summary": "We improve the framework of open games with agency by showing how the players' counterfactual analysis giving rise to Nash equilibria can be described in the dynamics of the game itself (hence diegetically), getting rid of devices such as equilibrium predicates. This new approach overlaps almost completely with the way gradient-based learners are specified and trained. Indeed, we show feedback propagation in games can be seen as a form of backpropagation, with a crucial difference explaining the distinctive character of the phenomenology of non-cooperative games. We outline a functorial construction of arena of games, show players form a subsystem over it, and prove that their 'fixpoint behaviours' are Nash equilibria.",
        "published": "2022-06-24T15:20:43Z",
        "link": "http://arxiv.org/abs/2206.12338v3",
        "categories": [
            "cs.GT",
            "cs.MA",
            "math.CT"
        ]
    },
    {
        "title": "Insect-inspired Visually-guided Decentralized Swarming",
        "authors": [
            "Mehdi Yadipour",
            "Imraan A. Faruque"
        ],
        "summary": "This paper addresses the need for fast, lightweight, vision-guided swarming under limited computation and no explicit communication network or position source. The study develops a multi-agent optic flow sensing framework, then integrates perfect information distributed feedback with optic flow sensing to create an analogous visually-guided feedback path for idealized inter-agent velocity and distance structures. The Cucker-Smale flocking example is used to develop vision-guided swarming with rigorous asymptotic convergence guarantees, including under ignorance of agent size.",
        "published": "2022-06-24T19:50:01Z",
        "link": "http://arxiv.org/abs/2206.12482v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "AGENT: An Adaptive Grouping Entrapping Method of Flocking Systems",
        "authors": [
            "Chen Wang",
            "Minqiang Gu",
            "Wenxi Kuang",
            "Dongliang Wang",
            "Weicheng Luo",
            "Zhaohui Shi",
            "Zhun Fan"
        ],
        "summary": "This study proposes a distributed algorithm that makes agents' adaptive grouping entrap multiple targets via automatic decision making, smooth flocking, and well-distributed entrapping. Agents make their own decisions about which targets to surround based on environmental information. An improved artificial potential field method is proposed to enable agents to smoothly and naturally change the formation to adapt to the environment. The proposed strategies guarantee that the coordination of swarm agents develops the phenomenon of multiple targets entrapping at the swarm level. We validate the performance of the proposed method using simulation experiments and design indicators for the analysis of these simulation and physical experiments.",
        "published": "2022-06-25T15:12:18Z",
        "link": "http://arxiv.org/abs/2206.14614v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Optimal Regulation of Prosumers and Consumers in Smart Energy   Communities",
        "authors": [
            "Syed Eqbal Alam",
            "Dhirendra Shukla"
        ],
        "summary": "In smart energy communities, households of a particular geographical location make a cooperative group to achieve the community's social welfare. Prosumers are the users that both consume and produce energy. In this paper, we develop stochastic and distributed algorithms to regulate the number of consumers and the number of prosumers with heterogeneous energy sources in the smart energy community. In the community, each prosumer has one of the heterogeneous energy sources such as solar photovoltaic panels or wind turbines installed in their household. The prosumers and consumers decide in a probabilistic way when to be active. They keep their information private and do not need to share it with other prosumers or consumers in the community. Moreover, we consider a central server that keeps track of the total number of active prosumers and consumers and sends feedback signals in the community at each time step; the prosumers and consumers use these signals to calculate their probabilistic intent. We present experimental results to check the efficacy of the algorithms. We observe that the average number of times prosumers and consumers are active reaches the optimal value over time, and the community asymptotically achieves the social optimum value.",
        "published": "2022-06-25T15:59:16Z",
        "link": "http://arxiv.org/abs/2206.12679v3",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY",
            "math.OC"
        ]
    },
    {
        "title": "Hierarchical Reinforcement Learning with Opponent Modeling for   Distributed Multi-agent Cooperation",
        "authors": [
            "Zhixuan Liang",
            "Jiannong Cao",
            "Shan Jiang",
            "Divya Saxena",
            "Huafeng Xu"
        ],
        "summary": "Many real-world applications can be formulated as multi-agent cooperation problems, such as network packet routing and coordination of autonomous vehicles. The emergence of deep reinforcement learning (DRL) provides a promising approach for multi-agent cooperation through the interaction of the agents and environments. However, traditional DRL solutions suffer from the high dimensions of multiple agents with continuous action space during policy search. Besides, the dynamicity of agents' policies makes the training non-stationary. To tackle the issues, we propose a hierarchical reinforcement learning approach with high-level decision-making and low-level individual control for efficient policy search. In particular, the cooperation of multiple agents can be learned in high-level discrete action space efficiently. At the same time, the low-level individual control can be reduced to single-agent reinforcement learning. In addition to hierarchical reinforcement learning, we propose an opponent modeling network to model other agents' policies during the learning process. In contrast to end-to-end DRL approaches, our approach reduces the learning complexity by decomposing the overall task into sub-tasks in a hierarchical way. To evaluate the efficiency of our approach, we conduct a real-world case study in the cooperative lane change scenario. Both simulation and real-world experiments show the superiority of our approach in the collision rate and convergence speed.",
        "published": "2022-06-25T19:09:29Z",
        "link": "http://arxiv.org/abs/2206.12718v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.RO",
            "I.2.9; I.2.11"
        ]
    },
    {
        "title": "Prescribed-Time Synchronization of Multiweighted and Directed Complex   Networks",
        "authors": [
            "Linlong Xu",
            "Xiwei Liu"
        ],
        "summary": "In this note, we study the prescribed-time (PT) synchronization of multiweighted and directed complex networks (MWDCNs) via pinning control. Unlike finite-time and fixed-time synchronization, the time for synchronization can be preset as needed, which is independent of initial values and parameters like coupling strength. First and foremost, we reveal the essence of PT stability by improper integral, L'Hospital rule and Taylor expansion theory. Many controllers established previously for PT stability can be included in our new model. Then, we apply this new result on MWDCNs as an application. The synchronization error at the prescribed time is discussed carefully, so, PT synchronization can be reached. The network topology can be directed and disconnected, which means that the outer coupling matrices (OCMs) can be asymmetric and not connected. The relationships between nodes are allowed to be cooperative or competitive, so elements in OCMs and inner coupling matrices (ICMs) can be positive or negative. We use the rearranging variables' order technique to combine ICMs and OCMs together to get the sum matrices, which can make a bridge between multiweighted and single-weighted networks. Finally, simulations are presented to illustrate the effectiveness of our theory.",
        "published": "2022-06-28T03:18:45Z",
        "link": "http://arxiv.org/abs/2206.13723v1",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "DistSPECTRL: Distributing Specifications in Multi-Agent Reinforcement   Learning Systems",
        "authors": [
            "Joe Eappen",
            "Suresh Jagannathan"
        ],
        "summary": "While notable progress has been made in specifying and learning objectives for general cyber-physical systems, applying these methods to distributed multi-agent systems still pose significant challenges. Among these are the need to (a) craft specification primitives that allow expression and interplay of both local and global objectives, (b) tame explosion in the state and action spaces to enable effective learning, and (c) minimize coordination frequency and the set of engaged participants for global objectives. To address these challenges, we propose a novel specification framework that allows natural composition of local and global objectives used to guide training of a multi-agent system. Our technique enables learning expressive policies that allow agents to operate in a coordination-free manner for local objectives, while using a decentralized communication protocol for enforcing global ones. Experimental results support our claim that sophisticated multi-agent distributed planning problems can be effectively realized using specification-guided learning.",
        "published": "2022-06-28T04:53:33Z",
        "link": "http://arxiv.org/abs/2206.13754v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Cooperative Multi-Agent Search on Endogenously-Changing Fitness   Landscapes",
        "authors": [
            "Chin Woei Lim",
            "Richard Allmendinger",
            "Joshua Knowles",
            "Ayesha Alhosani",
            "Mercedes Bleda"
        ],
        "summary": "We use a multi-agent system to model how agents (representing firms) may collaborate and adapt in a business 'landscape' where some, more influential, firms are given the power to shape the landscape of other firms. The landscapes we study are based on the well-known NK model of Kauffman, with the addition of 'shapers', firms that can change the landscape's features for themselves and all other players. Our work investigates how firms that are additionally endowed with cognitive and experiential search, and the ability to form collaborations with other firms, can use these capabilities to adapt more quickly and adeptly. We find that, in a collaborative group, firms must still have a mind of their own and resist direct mimicry of stronger partners to attain better heights collectively. Larger groups and groups with more influential members generally do better, so targeted intelligent cooperation is beneficial. These conclusions are tentative, and our results show a sensitivity to landscape ruggedness and \"malleability\" (i.e. the capacity of the landscape to be changed by the shaper firms). Overall, our work demonstrates the potential of computer science, evolution, and machine learning to contribute to business strategy in these complex environments.",
        "published": "2022-06-28T09:21:30Z",
        "link": "http://arxiv.org/abs/2206.13844v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.NE"
        ]
    },
    {
        "title": "A Contribution to the Defense of Liquid Democracy",
        "authors": [
            "Gregory Butterworth",
            "Richard Booth"
        ],
        "summary": "Liquid democracy is a hybrid direct-representative decision making process that provides each voter with the option of either voting directly or to delegate their vote to another voter, i.e., to a representative of their choice. One of the proposed advantages of liquid democracy is that, in general, it is assumed that voters will delegate their vote to others that are better informed, which leads to more informed and better decisions. Considering an audience from various knowledge domains, we provide an accessible high-level analysis of a prominent critique of liquid democracy by Caragiannis and Micha. Caragiannis and Micha's critique contains three central topics: 1. Analysis using their $\\alpha$-delegation model, which does not assume delegation to the more informed; 2. Novel delegation network structures where it is advantageous to delegate to the less informed rather than the more informed; and 3. Due to NP hardness, the implied impracticability of a social network obtaining an optimal delegation structure. We show that in the real world, Caragiannis and Micha's critique of liquid democracy has little or no relevance. Respectively, our critique is based on: 1. The identification of incorrect $\\alpha$-delegation model assumptions; 2. A lack of novel delegation structures and their effect in a real-world implementation of liquid democracy, which would be guaranteed with constraints that sensibly distribute voting power; and 3. The irrelevance of an optimal delegation structure if the correct result is guaranteed regardless. We conclude that Caragiannis and Micha's critique has no significant negative relevance to the proposition of liquid democracy.",
        "published": "2022-06-28T11:40:28Z",
        "link": "http://arxiv.org/abs/2206.13904v2",
        "categories": [
            "cs.MA",
            "cs.GT",
            "cs.SI"
        ]
    },
    {
        "title": "Reasoning about Moving Target Defense in Attack Modeling Formalisms",
        "authors": [
            "Gabriel Ballot",
            "Vadim Malvone",
            "Jean Leneutre",
            "Etienne Borde"
        ],
        "summary": "Since 2009, Moving Target Defense (MTD) has become a new paradigm of defensive mechanism that frequently changes the state of the target system to confuse the attacker. This frequent change is costly and leads to a trade-off between misleading the attacker and disrupting the quality of service. Optimizing the MTD activation frequency is necessary to develop this defense mechanism when facing realistic, multi-step attack scenarios. Attack modeling formalisms based on DAG are prominently used to specify these scenarios. Our contribution is a new DAG-based formalism for MTDs and its translation into a Price Timed Markov Decision Process to find the best activation frequencies against the attacker's time/cost-optimal strategies. For the first time, MTD activation frequencies are analyzed in a state-of-the-art DAG-based representation. Moreover, this is the first paper that considers the specificity of MTDs in the automatic analysis of attack modeling formalisms. Finally, we present some experimental results using Uppaal Stratego to demonstrate its applicability and relevance.",
        "published": "2022-06-28T15:18:12Z",
        "link": "http://arxiv.org/abs/2206.14076v1",
        "categories": [
            "cs.CR",
            "cs.MA"
        ]
    },
    {
        "title": "Breaking indecision in multi-agent, multi-option dynamics",
        "authors": [
            "Alessio Franci",
            "Martin Golubitsky",
            "Ian Stewart",
            "Anastasia Bizyaeva",
            "Naomi Ehrich Leonard"
        ],
        "summary": "How does a group of agents break indecision when deciding about options with qualities that are hard to distinguish? Biological and artificial multi-agent systems, from honeybees and bird flocks to bacteria, robots, and humans, often need to overcome indecision when choosing among options in situations in which the performance or even the survival of the group are at stake. Breaking indecision is also important because in a fully indecisive state agents are not biased toward any specific option and therefore the agent group is maximally sensitive and prone to adapt to inputs and changes in its environment. Here, we develop a mathematical theory to study how decisions arise from the breaking of indecision. Our approach is grounded in both equivariant and network bifurcation theory. We model decision from indecision as synchrony-breaking in influence networks in which each node is the value assigned by an agent to an option. First, we show that three universal decision behaviors, namely, deadlock, consensus, and dissensus, are the generic outcomes of synchrony-breaking bifurcations from a fully synchronous state of indecision in influence networks. Second, we show that all deadlock and consensus value patterns and some dissensus value patterns are predicted by the symmetry of the influence networks. Third, we show that there are also many `exotic' dissensus value patterns. These patterns are predicted by network architecture, but not by network symmetries, through a new synchrony-breaking branching lemma. This is the first example of exotic solutions in an application. Numerical simulations of a novel influence network model illustrate our theoretical results.",
        "published": "2022-06-29T20:22:57Z",
        "link": "http://arxiv.org/abs/2206.14893v1",
        "categories": [
            "math.DS",
            "cs.MA",
            "cs.SI",
            "math.OC"
        ]
    },
    {
        "title": "Bridging Mean-Field Games and Normalizing Flows with Trajectory   Regularization",
        "authors": [
            "Han Huang",
            "Jiajia Yu",
            "Jie Chen",
            "Rongjie Lai"
        ],
        "summary": "Mean-field games (MFGs) are a modeling framework for systems with a large number of interacting agents. They have applications in economics, finance, and game theory. Normalizing flows (NFs) are a family of deep generative models that compute data likelihoods by using an invertible mapping, which is typically parameterized by using neural networks. They are useful for density modeling and data generation. While active research has been conducted on both models, few noted the relationship between the two. In this work, we unravel the connections between MFGs and NFs by contextualizing the training of an NF as solving the MFG. This is achieved by reformulating the MFG problem in terms of agent trajectories and parameterizing a discretization of the resulting MFG with flow architectures. With this connection, we explore two research directions. First, we employ expressive NF architectures to accurately solve high-dimensional MFGs, sidestepping the curse of dimensionality in traditional numerical methods. Compared with other deep learning approaches, our trajectory-based formulation encodes the continuity equation in the neural network, resulting in a better approximation of the population dynamics. Second, we regularize the training of NFs with transport costs and show the effectiveness on controlling the model's Lipschitz bound, resulting in better generalization performance. We demonstrate numerical results through comprehensive experiments on a variety of synthetic and real-life datasets.",
        "published": "2022-06-30T02:44:39Z",
        "link": "http://arxiv.org/abs/2206.14990v1",
        "categories": [
            "math.OC",
            "cs.LG",
            "cs.MA",
            "49M41, 49M25"
        ]
    },
    {
        "title": "Mastering the Game of Stratego with Model-Free Multiagent Reinforcement   Learning",
        "authors": [
            "Julien Perolat",
            "Bart de Vylder",
            "Daniel Hennes",
            "Eugene Tarassov",
            "Florian Strub",
            "Vincent de Boer",
            "Paul Muller",
            "Jerome T. Connor",
            "Neil Burch",
            "Thomas Anthony",
            "Stephen McAleer",
            "Romuald Elie",
            "Sarah H. Cen",
            "Zhe Wang",
            "Audrunas Gruslys",
            "Aleksandra Malysheva",
            "Mina Khan",
            "Sherjil Ozair",
            "Finbarr Timbers",
            "Toby Pohlen",
            "Tom Eccles",
            "Mark Rowland",
            "Marc Lanctot",
            "Jean-Baptiste Lespiau",
            "Bilal Piot",
            "Shayegan Omidshafiei",
            "Edward Lockhart",
            "Laurent Sifre",
            "Nathalie Beauguerlange",
            "Remi Munos",
            "David Silver",
            "Satinder Singh",
            "Demis Hassabis",
            "Karl Tuyls"
        ],
        "summary": "We introduce DeepNash, an autonomous agent capable of learning to play the imperfect information game Stratego from scratch, up to a human expert level. Stratego is one of the few iconic board games that Artificial Intelligence (AI) has not yet mastered. This popular game has an enormous game tree on the order of $10^{535}$ nodes, i.e., $10^{175}$ times larger than that of Go. It has the additional complexity of requiring decision-making under imperfect information, similar to Texas hold'em poker, which has a significantly smaller game tree (on the order of $10^{164}$ nodes). Decisions in Stratego are made over a large number of discrete actions with no obvious link between action and outcome. Episodes are long, with often hundreds of moves before a player wins, and situations in Stratego can not easily be broken down into manageably-sized sub-problems as in poker. For these reasons, Stratego has been a grand challenge for the field of AI for decades, and existing AI methods barely reach an amateur level of play. DeepNash uses a game-theoretic, model-free deep reinforcement learning method, without search, that learns to master Stratego via self-play. The Regularised Nash Dynamics (R-NaD) algorithm, a key component of DeepNash, converges to an approximate Nash equilibrium, instead of 'cycling' around it, by directly modifying the underlying multi-agent learning dynamics. DeepNash beats existing state-of-the-art AI methods in Stratego and achieved a yearly (2022) and all-time top-3 rank on the Gravon games platform, competing with human expert players.",
        "published": "2022-06-30T15:53:19Z",
        "link": "http://arxiv.org/abs/2206.15378v1",
        "categories": [
            "cs.AI",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Multi-Agent Shape Control with Optimal Transport",
        "authors": [
            "Alex Tong Lin",
            "Stanley J. Osher"
        ],
        "summary": "We introduce a method called MASCOT (Multi-Agent Shape Control with Optimal Transport) to compute optimal control solutions of agents with shape/formation/density constraints. For example, we might want to apply shape constraints on the agents -- perhaps we desire the agents to hold a particular shape along the path, or we want agents to spread out in order to minimize collisions. We might also want a proportion of agents to move to one destination, while the other agents move to another, and to do this in the optimal way, i.e. the source-destination assignments should be optimal. In order to achieve this, we utilize the Earth Mover's Distance from Optimal Transport to distribute the agents into their proper positions so that certain shapes can be satisfied. This cost is both introduced in the terminal cost and in the running cost of the optimal control problem.",
        "published": "2022-06-30T23:49:51Z",
        "link": "http://arxiv.org/abs/2207.00129v2",
        "categories": [
            "cs.MA",
            "cs.CG",
            "cs.RO",
            "cs.SY",
            "eess.SY",
            "math.OC"
        ]
    },
    {
        "title": "COOR-PLT: A hierarchical control model for coordinating adaptive   platoons of connected and autonomous vehicles at signal-free intersections   based on deep reinforcement learning",
        "authors": [
            "Duowei Li",
            "Jianping Wu",
            "Feng Zhu",
            "Tianyi Chen",
            "Yiik Diew Wong"
        ],
        "summary": "Platooning and coordination are two implementation strategies that are frequently proposed for traffic control of connected and autonomous vehicles (CAVs) at signal-free intersections instead of using conventional traffic signals. However, few studies have attempted to integrate both strategies to better facilitate the CAV control at signal-free intersections. To this end, this study proposes a hierarchical control model, named COOR-PLT, to coordinate adaptive CAV platoons at a signal-free intersection based on deep reinforcement learning (DRL). COOR-PLT has a two-layer framework. The first layer uses a centralized control strategy to form adaptive platoons. The optimal size of each platoon is determined by considering multiple objectives (i.e., efficiency, fairness and energy saving). The second layer employs a decentralized control strategy to coordinate multiple platoons passing through the intersection. Each platoon is labeled with coordinated status or independent status, upon which its passing priority is determined. As an efficient DRL algorithm, Deep Q-network (DQN) is adopted to determine platoon sizes and passing priorities respectively in the two layers. The model is validated and examined on the simulator Simulation of Urban Mobility (SUMO). The simulation results demonstrate that the model is able to: (1) achieve satisfactory convergence performances; (2) adaptively determine platoon size in response to varying traffic conditions; and (3) completely avoid deadlocks at the intersection. By comparison with other control methods, the model manifests its superiority of adopting adaptive platooning and DRL-based coordination strategies. Also, the model outperforms several state-of-the-art methods on reducing travel time and fuel consumption in different traffic conditions.",
        "published": "2022-07-01T02:22:31Z",
        "link": "http://arxiv.org/abs/2207.07195v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Comprehensive Reactive Safety: No Need For A Trajectory If You Have A   Strategy",
        "authors": [
            "Fang Da"
        ],
        "summary": "Safety guarantees in motion planning for autonomous driving typically involve certifying the trajectory to be collision-free under any motion of the uncontrollable participants in the environment, such as the human-driven vehicles on the road. As a result they usually employ a conservative bound on the behavior of such participants, such as reachability analysis. We point out that planning trajectories to rigorously avoid the entirety of the reachable regions is unnecessary and too restrictive, because observing the environment in the future will allow us to prune away most of them; disregarding this ability to react to future updates could prohibit solutions to scenarios that are easily navigated by human drivers. We propose to account for the autonomous vehicle's reactions to future environment changes by a novel safety framework, Comprehensive Reactive Safety. Validated in simulations in several urban driving scenarios such as unprotected left turns and lane merging, the resulting planning algorithm called Reactive ILQR demonstrates strong negotiation capabilities and better safety at the same time.",
        "published": "2022-07-01T04:21:31Z",
        "link": "http://arxiv.org/abs/2207.00198v2",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Quick Relaxation in Collective Motion",
        "authors": [
            "Bernard Chazelle",
            "Kritkorn Karntikoon"
        ],
        "summary": "We establish sufficient conditions for the quick relaxation to kinetic equilibrium in the classic Vicsek-Cucker-Smale model of bird flocking. The convergence time is polynomial in the number of birds as long as the number of flocks remains bounded. This new result relies on two key ingredients: exploiting the convex geometry of embedded averaging systems; and deriving new bounds on the s-energy of disconnected agreement systems. We also apply our techniques to bound the relaxation time of certain pattern-formation robotic systems investigated by Sugihara and Suzuki.",
        "published": "2022-07-01T05:36:12Z",
        "link": "http://arxiv.org/abs/2207.00213v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Distributed Influence-Augmented Local Simulators for Parallel MARL in   Large Networked Systems",
        "authors": [
            "Miguel Suau",
            "Jinke He",
            "Mustafa Mert Çelikok",
            "Matthijs T. J. Spaan",
            "Frans A. Oliehoek"
        ],
        "summary": "Due to its high sample complexity, simulation is, as of today, critical for the successful application of reinforcement learning. Many real-world problems, however, exhibit overly complex dynamics, which makes their full-scale simulation computationally slow. In this paper, we show how to decompose large networked systems of many agents into multiple local components such that we can build separate simulators that run independently and in parallel. To monitor the influence that the different local components exert on one another, each of these simulators is equipped with a learned model that is periodically trained on real trajectories. Our empirical results reveal that distributing the simulation among different processes not only makes it possible to train large multi-agent systems in just a few hours but also helps mitigate the negative effects of simultaneous learning.",
        "published": "2022-07-01T09:33:33Z",
        "link": "http://arxiv.org/abs/2207.00288v2",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "HyperTensioN and Total-order Forward Decomposition optimizations",
        "authors": [
            "Maurício Cecílio Magnaguagno",
            "Felipe Meneguzzi",
            "Lavindra de Silva"
        ],
        "summary": "Hierarchical Task Networks (HTN) planners generate plans using a decomposition process with extra domain knowledge to guide search towards a planning task. While domain experts develop HTN descriptions, they may repeatedly describe the same preconditions, or methods that are rarely used or possible to be decomposed. By leveraging a three-stage compiler design we can easily support more language descriptions and preprocessing optimizations that when chained can greatly improve runtime efficiency in such domains. In this paper we evaluate such optimizations with the HyperTensioN HTN planner, used in the HTN IPC 2020.",
        "published": "2022-07-01T11:23:52Z",
        "link": "http://arxiv.org/abs/2207.00345v1",
        "categories": [
            "cs.AI",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Conflict-based Search for Multi-Robot Motion Planning with Kinodynamic   Constraints",
        "authors": [
            "Justin Kottinger",
            "Shaull Almagor",
            "Morteza Lahijanian"
        ],
        "summary": "Multi-robot motion planning (MRMP) is the fundamental problem of finding non-colliding trajectories for multiple robots acting in an environment, under kinodynamic constraints. Due to its complexity, existing algorithms either utilize simplifying assumptions or are incomplete. This work introduces kinodynamic conflict-based search (K-CBS), a decentralized (decoupled) MRMP algorithm that is general, scalable, and probabilistically complete. The algorithm takes inspiration from successful solutions to the discrete analogue of MRMP over finite graphs, known as multi-agent path finding (MAPF). Specifically, we adapt ideas from conflict-based search (CBS) - a popular decentralized MAPF algorithm - to the MRMP setting. The novelty in this adaptation is that we work directly in the continuous domain, without the need for discretization. In particular, the kinodynamic constraints are treated natively. K-CBS plans for each robot individually using a low-level planner and and grows a conflict tree to resolve collisions between robots by defining constraints for individual robots. The low-level planner can be any sampling-based, tree-search algorithm for kinodynamic robots, thus lifting existing planners for single robots to the multi-robot settings. We show that K-CBS inherits the (probabilistic) completeness of the low-level planner. We illustrate the generality and performance of K-CBS in several case studies and benchmarks.",
        "published": "2022-07-01T17:54:10Z",
        "link": "http://arxiv.org/abs/2207.00576v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Separating and Collapsing Electoral Control Types",
        "authors": [
            "Benjamin Carleton",
            "Michael C. Chavrimootoo",
            "Lane A. Hemaspaandra",
            "David E. Narváez",
            "Conor Taliancich",
            "Henry B. Welles"
        ],
        "summary": "[HHM20] discovered, for 7 pairs (C,D) of seemingly distinct standard electoral control types, that C and D are identical: For each input I and each election system, I is a Yes instance of both C and D, or of neither. Surprisingly this had gone undetected, even as the field was score-carding how many std. control types election systems were resistant to; various \"different\" cells on such score cards were, unknowingly, duplicate effort on the same issue. This naturally raises the worry that other pairs of control types are also identical, and so work still is being needlessly duplicated.   We determine, for all std. control types, which pairs are, for elections whose votes are linear orderings of the candidates, always identical. We show that no identical control pairs exist beyond the known 7. We for 3 central election systems determine which control pairs are identical (\"collapse\") with respect to those systems, and we explore containment/incomparability relationships between control pairs. For approval voting, which has a different \"type\" for its votes, [HHM20]'s 7 collapses still hold. But we find 14 additional collapses that hold for approval voting but not for some election systems whose votes are linear orderings. We find 1 additional collapse for veto and none for plurality. We prove that each of the 3 election systems mentioned have no collapses other than those inherited from [HHM20] or added here. But we show many new containment relationships that hold between some separating control pairs, and for each separating pair of std. control types classify its separation in terms of containment (always, and strict on some inputs) or incomparability.   Our work, for the general case and these 3 important election systems, clarifies the landscape of the 44 std. control types, for each pair collapsing or separating them, and also providing finer-grained information on the separations.",
        "published": "2022-07-02T01:46:23Z",
        "link": "http://arxiv.org/abs/2207.00710v7",
        "categories": [
            "cs.MA",
            "cs.GT",
            "I.2.11"
        ]
    },
    {
        "title": "Metacognitive Decision Making Framework for Multi-UAV Target Search   Without Communication",
        "authors": [
            "J. Senthilnath",
            "K. Harikumar",
            "S. Suresh"
        ],
        "summary": "This paper presents a new Metacognitive Decision Making (MDM) framework inspired by human-like metacognitive principles. The MDM framework is incorporated in unmanned aerial vehicles (UAVs) deployed for decentralized stochastic search without communication for detecting stationary targets (fixed/sudden pop-up) and dynamic targets. The UAVs are equipped with multiple sensors (varying sensing capability) and search for targets in a largely unknown area. The MDM framework consists of a metacognitive component and a self-cognitive component. The metacognitive component helps to self-regulate the search with multiple sensors addressing the issues of \"which-sensor-to-use\", \"when-to-switch-sensor\", and \"how-to-search\". Each sensor possesses inverse characteristics for the sensing attributes like sensing range and accuracy. Based on the information gathered by multiple sensors carried by each UAV, the self-cognitive component regulates different levels of stochastic search and switching levels for effective searching. The lower levels of search aim to localize the search space for the possible presence of a target (detection) with different sensors. The highest level of a search exploits the search space for target confirmation using the sensor with the highest accuracy among all sensors. The performance of the MDM framework with two sensors having low accuracy with wide range sensor for detection and increased accuracy with low range sensor for confirmation is evaluated through Monte-Carlo simulations and compared with six multi-UAV stochastic search algorithms (three self-cognitive searches and three self and social-cognitive based search). The results indicate that the MDM framework is efficient in detecting and confirming targets in an unknown environment.",
        "published": "2022-07-02T03:32:38Z",
        "link": "http://arxiv.org/abs/2207.00725v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Hierarchical Dynamic Routing in Complex Networks via   Topologically-decoupled and Cooperative Reinforcement Learning Agents",
        "authors": [
            "Shiyuan Hu",
            "Shihan Xiao"
        ],
        "summary": "The transport capacity of a communication network can be characterized by the transition from a free-flow state to a congested state. Here, we propose a dynamic routing strategy in complex networks based on hierarchical bypass selections. The routing decisions are made by the reinforcement learning agents implemented at selected nodes with high betweenness centrality. The learning processes of the agents are decoupled from each other due to the degeneracy of their bypasses. Through interactions mediated by the underlying traffic dynamics, the agents act cooperatively, and coherent actions arise spontaneously. With only a small number of agents, the transport capacities are significantly improved, including in real-world Internet networks at the router level and the autonomous system level. Our strategy is also resilient to link removals.",
        "published": "2022-07-02T07:31:15Z",
        "link": "http://arxiv.org/abs/2207.00763v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Communication Pattern Logic: Epistemic and Topological Views",
        "authors": [
            "Armando Castañeda",
            "Hans van Ditmarsch",
            "David A. Rosenblueth",
            "Diego A. Velázquez"
        ],
        "summary": "We propose communication pattern logic. A communication pattern describes how processes or agents inform each other, independently of the information content. The full-information protocol in distributed computing is the special case wherein all agents inform each other. We study this protocol in distributed computing models where communication might fail: an agent is certain about the messages it receives, but it may be uncertain about the messages other agents have received. In a dynamic epistemic logic with distributed knowledge and with modalities for communication patterns, the latter are interpreted by updating Kripke models. We propose an axiomatization of communication pattern logic, and we show that collective bisimilarity (comparing models on their distributed knowledge) is preserved when updating models with communication patterns. We can also interpret communication patterns by updating simplicial complexes, a well-known topological framework for distributed computing. We show that the different semantics correspond, and propose collective bisimulation between simplicial complexes.",
        "published": "2022-07-02T12:52:27Z",
        "link": "http://arxiv.org/abs/2207.00823v4",
        "categories": [
            "cs.DC",
            "cs.MA"
        ]
    },
    {
        "title": "NVIF: Neighboring Variational Information Flow for Large-Scale   Cooperative Multi-Agent Scenarios",
        "authors": [
            "Jiajun Chai",
            "Yuanheng Zhu",
            "Dongbin Zhao"
        ],
        "summary": "Communication-based multi-agent reinforcement learning (MARL) provides information exchange between agents, which promotes the cooperation. However, existing methods cannot perform well in the large-scale multi-agent system. In this paper, we adopt neighboring communication and propose a Neighboring Variational Information Flow (NVIF) to provide efficient communication for agents. It employs variational auto-encoder to compress the shared information into a latent state. This communication protocol does not rely dependently on a specific task, so that it can be pre-trained to stabilize the MARL training. Besides. we combine NVIF with Proximal Policy Optimization (NVIF-PPO) and Deep Q Network (NVIF-DQN), and present a theoretical analysis to illustrate NVIF-PPO can promote cooperation. We evaluate the NVIF-PPO and NVIF-DQN on MAgent, a widely used large-scale multi-agent environment, by two tasks with different map sizes. Experiments show that our method outperforms other compared methods, and can learn effective and scalable cooperation strategies in the large-scale multi-agent system.",
        "published": "2022-07-03T06:15:16Z",
        "link": "http://arxiv.org/abs/2207.00964v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Government Intervention in Catastrophe Insurance Markets: A   Reinforcement Learning Approach",
        "authors": [
            "Menna Hassan",
            "Nourhan Sakr",
            "Arthur Charpentier"
        ],
        "summary": "This paper designs a sequential repeated game of a micro-founded society with three types of agents: individuals, insurers, and a government. Nascent to economics literature, we use Reinforcement Learning (RL), closely related to multi-armed bandit problems, to learn the welfare impact of a set of proposed policy interventions per $1 spent on them. The paper rigorously discusses the desirability of the proposed interventions by comparing them against each other on a case-by-case basis. The paper provides a framework for algorithmic policy evaluation using calibrated theoretical models which can assist in feasibility studies.",
        "published": "2022-07-03T11:06:44Z",
        "link": "http://arxiv.org/abs/2207.01010v1",
        "categories": [
            "cs.MA",
            "cs.LG",
            "econ.GN",
            "q-fin.EC"
        ]
    },
    {
        "title": "\"Y'all are just too sensitive\": A computational ethics approach to   understanding how prejudice against marginalized communities becomes   epistemic belief",
        "authors": [
            "Johannah Sprinz"
        ],
        "summary": "Members of marginalized communities are often accused of being \"too sensitive\" when subjected to supposedly harmless acts of microaggression. This paper explores a simulated society consisting of marginalized and non-marginalized agents who interact and may, based on their individually held convictions, commit acts of microaggressions. Agents witnessing a microaggression might condone, ignore or condemn such microaggressions, thus potentially influencing a perpetrator's conviction. A prototype model has been implemented in NetLogo, and possible applications are briefly discussed.",
        "published": "2022-07-03T12:01:53Z",
        "link": "http://arxiv.org/abs/2207.01017v1",
        "categories": [
            "cs.MA",
            "cs.CY",
            "I.6.3"
        ]
    },
    {
        "title": "Can Competition Outperform Collaboration? The Role of Misbehaving Agents",
        "authors": [
            "Luca Ballotta",
            "Giacomo Como",
            "Jeff S. Shamma",
            "Luca Schenato"
        ],
        "summary": "We investigate a novel approach to resilient distributed optimization with quadratic costs in a multi-agent system prone to unexpected events that make some agents misbehave. In contrast to commonly adopted filtering strategies, we draw inspiration from phenomena modeled through the Friedkin-Johnsen dynamics and argue that adding competition to the mix can improve resilience in the presence of misbehaving agents. Our intuition is corroborated by analytical and numerical results showing that (i) there exists a nontrivial trade-off between full collaboration and full competition and (ii) our competition-based approach can outperform state-of-the-art algorithms based on Weighted Mean Subsequence Reduced. We also study impact of communication topology and connectivity on resilience, pointing out insights to robust network design.",
        "published": "2022-07-04T12:08:45Z",
        "link": "http://arxiv.org/abs/2207.01346v3",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.RO",
            "cs.SY",
            "93D50 (Primary) 93B70 (Secondary)",
            "I.2.8; I.2.9"
        ]
    },
    {
        "title": "How Routing Strategies Impact Urban Emissions",
        "authors": [
            "Giuliano Cornacchia",
            "Matteo Böhm",
            "Giovanni Mauro",
            "Mirco Nanni",
            "Dino Pedreschi",
            "Luca Pappalardo"
        ],
        "summary": "Navigation apps use routing algorithms to suggest the best path to reach a user's desired destination. Although undoubtedly useful, navigation apps' impact on the urban environment (e.g., carbon dioxide emissions and population exposure to pollution) is still largely unclear. In this work, we design a simulation framework to assess the impact of routing algorithms on carbon dioxide emissions within an urban environment. Using APIs from TomTom and OpenStreetMap, we find that settings in which either all vehicles or none of them follow a navigation app's suggestion lead to the worst impact in terms of CO2 emissions. In contrast, when just a portion (around half) of vehicles follow these suggestions, and some degree of randomness is added to the remaining vehicles' paths, we observe a reduction in the overall CO2 emissions over the road network. Our work is a first step towards designing next-generation routing principles that may increase urban well-being while satisfying individual needs.",
        "published": "2022-07-04T14:46:08Z",
        "link": "http://arxiv.org/abs/2207.01456v1",
        "categories": [
            "cs.CY",
            "cs.MA"
        ]
    },
    {
        "title": "Repeatedly Matching Items to Agents Fairly and Efficiently",
        "authors": [
            "Ioannis Caragiannis",
            "Shivika Narang"
        ],
        "summary": "We consider a novel setting where a set of items are matched to the same set of agents repeatedly over multiple rounds. Each agent gets exactly one item per round, which brings interesting challenges to finding efficient and/or fair {\\em repeated matchings}. A particular feature of our model is that the value of an agent for an item in some round depends on the number of rounds in which the item has been used by the agent in the past. We present a set of positive and negative results about the efficiency and fairness of repeated matchings. For example, when items are goods, a variation of the well-studied fairness notion of envy-freeness up to one good (EF1) can be satisfied under certain conditions. Furthermore, it is intractable to achieve fairness and (approximate) efficiency simultaneously, even though they are achievable separately. For mixed items, which can be goods for some agents and chores for others, we propose and study a new notion of fairness that we call {\\em swap envy-freeness} (swapEF).",
        "published": "2022-07-04T17:17:06Z",
        "link": "http://arxiv.org/abs/2207.01589v1",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "EasyABM: a lightweight and easy to use heterogeneous agent-based   modelling tool written in Julia",
        "authors": [
            "Renu Solanki",
            "Monisha Khanna",
            "Shailly Anand",
            "Anita Gulati",
            "Prateek Kumar",
            "Munendra Kumar",
            "Dushyant Kumar"
        ],
        "summary": "Agent based modelling is a computational approach that aims to understand the behaviour of complex systems through simplified interactions of programmable objects in computer memory called agents. Agent based models (ABMs) are predominantly used in fields of biology, ecology, social sciences and economics where the systems of interest often consist of several interacting entities. In this work, we present a Julia package EasyABM.jl for simplifying the process of studying agent based models. EasyABM.jl provides an intuitive and easy to understand functional approach for building and analysing agent based models.",
        "published": "2022-07-05T15:21:44Z",
        "link": "http://arxiv.org/abs/2207.02107v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Learning Task Embeddings for Teamwork Adaptation in Multi-Agent   Reinforcement Learning",
        "authors": [
            "Lukas Schäfer",
            "Filippos Christianos",
            "Amos Storkey",
            "Stefano V. Albrecht"
        ],
        "summary": "Successful deployment of multi-agent reinforcement learning often requires agents to adapt their behaviour. In this work, we discuss the problem of teamwork adaptation in which a team of agents needs to adapt their policies to solve novel tasks with limited fine-tuning. Motivated by the intuition that agents need to be able to identify and distinguish tasks in order to adapt their behaviour to the current task, we propose to learn multi-agent task embeddings (MATE). These task embeddings are trained using an encoder-decoder architecture optimised for reconstruction of the transition and reward functions which uniquely identify tasks. We show that a team of agents is able to adapt to novel tasks when provided with task embeddings. We propose three MATE training paradigms: independent MATE, centralised MATE, and mixed MATE which vary in the information used for the task encoding. We show that the embeddings learned by MATE identify tasks and provide useful information which agents leverage during adaptation to novel tasks.",
        "published": "2022-07-05T18:23:20Z",
        "link": "http://arxiv.org/abs/2207.02249v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Ramp Metering to Maximize Freeway Throughput under Vehicle Safety   Constraints",
        "authors": [
            "Milad Pooladsanj",
            "Ketan Savla",
            "Petros A. Ioannou"
        ],
        "summary": "We consider Ramp Metering (RM) at the microscopic level subject to vehicle following safety constraints for a freeway with arbitrary number of on- and off-ramps. The arrival times of vehicles to the on-ramps, as well as their destinations are modeled by exogenous stochastic processes. Once a vehicle is released from an on-ramp, it accelerates towards the free flow speed if it is not obstructed by another vehicle; once it gets close to another vehicle, it adopts a safe gap vehicle following behavior. The vehicle exits the freeway once it reaches its destination off-ramp. We design traffic-responsive RM policies that maximize the throughput. For a given routing matrix, the throughput of a RM policy is characterized by the set of on-ramp arrival rates for which the expected queue size at all the on-ramps remain bounded. The proposed RM policies work in synchronous cycles during which an on-ramp does not release more vehicles than its queue size at the beginning of the cycle. Moreover, all the policies operate under vehicle following safety constraints, where new vehicles are released only if there is sufficient gap between vehicles on the mainline at the moment of release. We provide three mechanisms under which each on-ramp: (i) pauses release for a time interval at the end of a cycle, or (ii) adjusts the release rate during a cycle, or (iii) adopts a conservative safe gap criterion for release during a cycle. All the proposed policies are reactive, meaning that they only require real-time traffic measurements without the need for demand prediction. The throughput of these policies is characterized by studying stochastic stability of the induced Markov chains, and is proven to be maximized when the merging speed at all the on-ramps equals the free flow speed. Simulations are provided to illustrate the performance of our policies and compare with a well-known RM policy from the literature.",
        "published": "2022-07-05T23:30:41Z",
        "link": "http://arxiv.org/abs/2207.02360v3",
        "categories": [
            "math.PR",
            "cs.MA",
            "cs.RO",
            "cs.SY",
            "eess.SY",
            "math.DS"
        ]
    },
    {
        "title": "On the Complexity of Rational Verification",
        "authors": [
            "Julian Gutierrez",
            "Muhammad Najib",
            "Giuseppe Perelli",
            "Michael Wooldridge"
        ],
        "summary": "Rational verification refers to the problem of checking which temporal logic properties hold of a concurrent multiagent system, under the assumption that agents in the system choose strategies that form a game-theoretic equilibrium. Rational verification can be understood as a counterpart to model checking for multiagent systems, but while classical model checking can be done in polynomial time for some temporal logic specification languages such as CTL, and polynomial space with LTL specifications, rational verification is much harder: the key decision problems for rational verification are 2EXPTIME-complete with LTL specifications, even when using explicit-state system representations. Against this background, our contributions in this paper are threefold. First, we show that the complexity of rational verification can be greatly reduced by restricting specifications to GR(1), a fragment of LTL that can represent a broad and practically useful class of response properties of reactive systems. In particular, we show that for a number of relevant settings, rational verification can be done in polynomial space and even in polynomial time. Second, we provide improved complexity results for rational verification when considering players' goals given by mean-payoff utility functions; arguably the most widely used approach for quantitative objectives in concurrent and multiagent systems. Finally, we consider the problem of computing outcomes that satisfy social welfare constraints. To this end, we consider both utilitarian and egalitarian social welfare and show that computing such outcomes is either PSPACE-complete or NP-complete.",
        "published": "2022-07-06T12:56:22Z",
        "link": "http://arxiv.org/abs/2207.02637v1",
        "categories": [
            "cs.LO",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "RoVaR: Robust Multi-agent Tracking through Dual-layer Diversity in   Visual and RF Sensor Fusion",
        "authors": [
            "Mallesham Dasari",
            "Ramanujan K Sheshadri",
            "Karthikeyan Sundaresan",
            "Samir R. Das"
        ],
        "summary": "The plethora of sensors in our commodity devices provides a rich substrate for sensor-fused tracking. Yet, today's solutions are unable to deliver robust and high tracking accuracies across multiple agents in practical, everyday environments - a feature central to the future of immersive and collaborative applications. This can be attributed to the limited scope of diversity leveraged by these fusion solutions, preventing them from catering to the multiple dimensions of accuracy, robustness (diverse environmental conditions) and scalability (multiple agents) simultaneously. In this work, we take an important step towards this goal by introducing the notion of dual-layer diversity to the problem of sensor fusion in multi-agent tracking. We demonstrate that the fusion of complementary tracking modalities, - passive/relative (e.g., visual odometry) and active/absolute tracking (e.g., infrastructure-assisted RF localization) offer a key first layer of diversity that brings scalability while the second layer of diversity lies in the methodology of fusion, where we bring together the complementary strengths of algorithmic (for robustness) and data-driven (for accuracy) approaches. RoVaR is an embodiment of such a dual-layer diversity approach that intelligently attends to cross-modal information using algorithmic and data-driven techniques that jointly share the burden of accurately tracking multiple agents in the wild. Extensive evaluations reveal RoVaR's multi-dimensional benefits in terms of tracking accuracy (median of 15cm), robustness (in unseen environments), light weight (runs in real-time on mobile platforms such as Jetson Nano/TX2), to enable practical multi-agent immersive applications in everyday environments.",
        "published": "2022-07-06T16:26:42Z",
        "link": "http://arxiv.org/abs/2207.02792v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Search versus Search for Collapsing Electoral Control Types",
        "authors": [
            "Benjamin Carleton",
            "Michael C. Chavrimootoo",
            "Lane A. Hemaspaandra",
            "David E. Narváez",
            "Conor Taliancich",
            "Henry B. Welles"
        ],
        "summary": "Electoral control types are ways of trying to change the outcome of elections by altering aspects of their composition and structure [BTT92]. We say two compatible (i.e., having the same input types) control types that are about the same election system E form a collapsing pair if for every possible input (which typically consists of a candidate set, a vote set, a focus candidate, and sometimes other parameters related to the nature of the attempted alteration), either both or neither of the attempted attacks can be successfully carried out. For each of the seven general (i.e., holding for all election systems) electoral control type collapsing pairs found by Hemaspaandra, Hemaspaandra, and Menton [HHM20] and for each of the additional electoral control type collapsing pairs of Carleton et al. [CCH+ 22] for veto and approval (and many other election systems in light of that paper's Theorems 3.6 and 3.9), both members of the collapsing pair have the same complexity since as sets they are the same set. However, having the same complexity (as sets) is not enough to guarantee that as search problems they have the same complexity. In this paper, we explore the relationships between the search versions of collapsing pairs. For each of the collapsing pairs of Hemaspaandra, Hemaspaandra, and Menton [HHM20] and Carleton et al. [CCH+ 22], we prove that the pair's members' search-version complexities are polynomially related (given access, for cases when the winner problem itself is not in polynomial time, to an oracle for the winner problem). Beyond that, we give efficient reductions that from a solution to one compute a solution to the other. For the concrete systems plurality, veto, and approval, we completely determine which of their (due to our results) polynomially-related collapsing search-problem pairs are polynomial-time computable and which are NP-hard.",
        "published": "2022-07-07T02:26:27Z",
        "link": "http://arxiv.org/abs/2207.03049v6",
        "categories": [
            "cs.GT",
            "cs.CC",
            "cs.MA",
            "I.2.11; F.2.2; F.1.3"
        ]
    },
    {
        "title": "A Distributed Diffusion Kalman Filter In Multitask Networks",
        "authors": [
            "Ijeoma Amuche Chikwendu",
            "Kulevome Delanyo Kwame Bensah",
            "Chiagoziem Chima Ukwuoma",
            "Chukwuebuka Joseph Ejiyi"
        ],
        "summary": "The Distributed Diffusion Kalman Filter (DDKF) algorithm in all its magnitude has earned great attention lately and has shown an elaborate way to address the issue of distributed optimization over networks. Estimation and tracking of a single state vector collectively by nodes have been the point of focus. In reality, however, there are several multi-task-oriented issues where the optimal state vector for each node may not be the same. Its objective is to know many related tasks simultaneously, rather than the typical single-task problems. This work considers sensor networks for distributed multi-task tracking in which individual nodes communicate with its immediate nodes. A diffusion-based distributed multi-task tracking algorithm is developed. This is done by implementing an unsupervised adaptive clustering process, which aids nodes in forming clusters and collaborating on tasks. For distributed target tracking, an adaptive clustering approach, which gives agents the ability to identify and select through adaptive adjustments of combination weights nodes who to collaborate with and who not to in order to estimate the common state vector. This gave rise to an effective level of cooperation for improving state vector estimation accuracy, especially in cases where a cluster's background experience is unknown. To demonstrate the efficiency of our algorithm, computer simulations were conducted. Comparison has been carried out for the Diffusion Kalman Filter multitask with respect to the Adapt then combine (ATC) diffusion schemes utilizing both static and adaptive combination weights. Results showed that the ATC diffusion schemes algorithm has great performance with the adaptive combiners as compared to static combiners.",
        "published": "2022-07-07T09:17:24Z",
        "link": "http://arxiv.org/abs/2207.03181v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "A Model-based Multi-agent Framework to Enable an Agile Response to   Supply Chain Disruptions",
        "authors": [
            "Mingjie Bi",
            "Gongyu Chen",
            "Dawn M. Tilbury",
            "Siqian Shen",
            "Kira Barton"
        ],
        "summary": "Due to the COVID-19 pandemic, the global supply chain is disrupted at an unprecedented scale under uncertain and unknown trends of labor shortage, high material prices, and changing travel or trade regulations. To stay competitive, enterprises desire agile and dynamic response strategies to quickly react to disruptions and recover supply-chain functions. Although both centralized and multi-agent approaches have been studied, their implementation requires prior knowledge of disruptions and agent-rule-based reasoning. In this paper, we introduce a model-based multi-agent framework that enables agent coordination and dynamic agent decision-making to respond to supply chain disruptions in an agile and effective manner. Through a small-scale simulated case study, we showcase the feasibility of the proposed approach under several disruption scenarios that affect a supply chain network differently, and analyze performance trade-offs between the proposed distributed and centralized methods.",
        "published": "2022-07-07T17:41:29Z",
        "link": "http://arxiv.org/abs/2207.03460v1",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "For Learning in Symmetric Teams, Local Optima are Global Nash Equilibria",
        "authors": [
            "Scott Emmons",
            "Caspar Oesterheld",
            "Andrew Critch",
            "Vincent Conitzer",
            "Stuart Russell"
        ],
        "summary": "Although it has been known since the 1970s that a globally optimal strategy profile in a common-payoff game is a Nash equilibrium, global optimality is a strict requirement that limits the result's applicability. In this work, we show that any locally optimal symmetric strategy profile is also a (global) Nash equilibrium. Furthermore, we show that this result is robust to perturbations to the common payoff and to the local optimum. Applied to machine learning, our result provides a global guarantee for any gradient method that finds a local optimum in symmetric strategy space. While this result indicates stability to unilateral deviation, we nevertheless identify broad classes of games where mixed local optima are unstable under joint, asymmetric deviations. We analyze the prevalence of instability by running learning algorithms in a suite of symmetric games, and we conclude by discussing the applicability of our results to multi-agent RL, cooperative inverse RL, and decentralized POMDPs.",
        "published": "2022-07-07T17:55:04Z",
        "link": "http://arxiv.org/abs/2207.03470v1",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "VMAS: A Vectorized Multi-Agent Simulator for Collective Robot Learning",
        "authors": [
            "Matteo Bettini",
            "Ryan Kortvelesy",
            "Jan Blumenkamp",
            "Amanda Prorok"
        ],
        "summary": "While many multi-robot coordination problems can be solved optimally by exact algorithms, solutions are often not scalable in the number of robots. Multi-Agent Reinforcement Learning (MARL) is gaining increasing attention in the robotics community as a promising solution to tackle such problems. Nevertheless, we still lack the tools that allow us to quickly and efficiently find solutions to large-scale collective learning tasks. In this work, we introduce the Vectorized Multi-Agent Simulator (VMAS). VMAS is an open-source framework designed for efficient MARL benchmarking. It is comprised of a vectorized 2D physics engine written in PyTorch and a set of twelve challenging multi-robot scenarios. Additional scenarios can be implemented through a simple and modular interface. We demonstrate how vectorization enables parallel simulation on accelerated hardware without added complexity. When comparing VMAS to OpenAI MPE, we show how MPE's execution time increases linearly in the number of simulations while VMAS is able to execute 30,000 parallel simulations in under 10s, proving more than 100x faster. Using VMAS's RLlib interface, we benchmark our multi-robot scenarios using various Proximal Policy Optimization (PPO)-based MARL algorithms. VMAS's scenarios prove challenging in orthogonal ways for state-of-the-art MARL algorithms. The VMAS framework is available at https://github.com/proroklab/VectorizedMultiAgentSimulator. A video of VMAS scenarios and experiments is available at https://youtu.be/aaDRYfiesAY.",
        "published": "2022-07-07T18:48:58Z",
        "link": "http://arxiv.org/abs/2207.03530v2",
        "categories": [
            "cs.RO",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Learning-based Autonomous Channel Access in the Presence of Hidden   Terminals",
        "authors": [
            "Yulin Shao",
            "Yucheng Cai",
            "Taotao Wang",
            "Ziyang Guo",
            "Peng Liu",
            "Jiajun Luo",
            "Deniz Gunduz"
        ],
        "summary": "We consider the problem of autonomous channel access (AutoCA), where a group of terminals tries to discover a communication strategy with an access point (AP) via a common wireless channel in a distributed fashion. Due to the irregular topology and the limited communication range of terminals, a practical challenge for AutoCA is the hidden terminal problem, which is notorious in wireless networks for deteriorating the throughput and delay performances. To meet the challenge, this paper presents a new multi-agent deep reinforcement learning paradigm, dubbed MADRL-HT, tailored for AutoCA in the presence of hidden terminals. MADRL-HT exploits topological insights and transforms the observation space of each terminal into a scalable form independent of the number of terminals. To compensate for the partial observability, we put forth a look-back mechanism such that the terminals can infer behaviors of their hidden terminals from the carrier sensed channel states as well as feedback from the AP. A window-based global reward function is proposed, whereby the terminals are instructed to maximize the system throughput while balancing the terminals' transmission opportunities over the course of learning. Extensive numerical experiments verified the superior performance of our solution benchmarked against the legacy carrier-sense multiple access with collision avoidance (CSMA/CA) protocol.",
        "published": "2022-07-07T22:30:31Z",
        "link": "http://arxiv.org/abs/2207.03605v2",
        "categories": [
            "cs.LG",
            "cs.IT",
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "math.IT"
        ]
    },
    {
        "title": "Interaction Pattern Disentangling for Multi-Agent Reinforcement Learning",
        "authors": [
            "Shunyu Liu",
            "Jie Song",
            "Yihe Zhou",
            "Na Yu",
            "Kaixuan Chen",
            "Zunlei Feng",
            "Mingli Song"
        ],
        "summary": "Deep cooperative multi-agent reinforcement learning has demonstrated its remarkable success over a wide spectrum of complex control tasks. However, recent advances in multi-agent learning mainly focus on value decomposition while leaving entity interactions still intertwined, which easily leads to over-fitting on noisy interactions between entities. In this work, we introduce a novel interactiOn Pattern disenTangling (OPT) method, to disentangle the entity interactions into interaction prototypes, each of which represents an underlying interaction pattern within a subgroup of the entities. OPT facilitates filtering the noisy interactions between irrelevant entities and thus significantly improves generalizability as well as interpretability. Specifically, OPT introduces a sparse disagreement mechanism to encourage sparsity and diversity among discovered interaction prototypes. Then the model selectively restructures these prototypes into a compact interaction pattern by an aggregator with learnable weights. To alleviate the training instability issue caused by partial observability, we propose to maximize the mutual information between the aggregation weights and the history behaviors of each agent. Experiments on single-task, multi-task and zero-shot benchmarks demonstrate that the proposed method yields results superior to the state-of-the-art counterparts. Our code is available at https://github.com/liushunyu/OPT.",
        "published": "2022-07-08T13:42:54Z",
        "link": "http://arxiv.org/abs/2207.03902v4",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "High Performance Simulation for Scalable Multi-Agent Reinforcement   Learning",
        "authors": [
            "Jordan Langham-Lopez",
            "Sebastian M. Schmon",
            "Patrick Cannon"
        ],
        "summary": "Multi-agent reinforcement learning experiments and open-source training environments are typically limited in scale, supporting tens or sometimes up to hundreds of interacting agents. In this paper we demonstrate the use of Vogue, a high performance agent based model (ABM) framework. Vogue serves as a multi-agent training environment, supporting thousands to tens of thousands of interacting agents while maintaining high training throughput by running both the environment and reinforcement learning (RL) agents on the GPU. High performance multi-agent environments at this scale have the potential to enable the learning of robust and flexible policies for use in ABMs and simulations of complex systems. We demonstrate training performance with two newly developed, large scale multi-agent training environments. Moreover, we show that these environments can train shared RL policies on time-scales of minutes and hours.",
        "published": "2022-07-08T14:54:06Z",
        "link": "http://arxiv.org/abs/2207.03945v1",
        "categories": [
            "cs.MA",
            "cs.LG",
            "cs.PF"
        ]
    },
    {
        "title": "On the properties of path additions for traffic routing",
        "authors": [
            "Matteo Bettini",
            "Amanda Prorok"
        ],
        "summary": "In this paper we investigate the impact of path additions to transport networks with optimised traffic routing. In particular, we study the behaviour of total travel time, and consider both self-interested routing paradigms, such as User Equilibrium (UE) routing, as well as cooperative paradigms, such as classic Multi-Commodity (MC) network flow and System Optimal (SO) routing. We provide a formal framework for designing transport networks through iterative path additions, introducing the concepts of trip spanning tree and trip path graph. Using this formalisation, we prove multiple properties of the objective function for transport network design. Since the underlying routing problem is NP-Hard, we investigate properties that provide guarantees in approximate algorithm design. Firstly, while Braess' paradox has shown that total travel time is not monotonic non-increasing with respect to path additions under self-interested routing (UE), we prove that, instead, monotonicity holds for cooperative routing (MC and SO). This result has the important implication that cooperative agents make the best use of redundant infrastructure. Secondly, we prove via a counterexample that the intuitive statement `adding a path to a transport network always grants greater or equal benefit to users than adding it to a superset of that network' is false. In other words we prove that, for all the routing formulations studied, total travel time is not supermodular with respect to path additions. While this counter-intuitive result yields a hardness property for algorithm design, we provide particular instances where, instead, the property of supermodularity holds. Our study on monotonicity and supermodularity of total travel time with respect to path additions provides formal proofs and scenarios that constitute important insights for transport network designers.",
        "published": "2022-07-10T17:13:33Z",
        "link": "http://arxiv.org/abs/2207.04505v1",
        "categories": [
            "cs.MA",
            "cs.RO",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Strategic Voting in the Context of Stable-Matching of Teams",
        "authors": [
            "Leora Schmerler",
            "Noam Hazon",
            "Sarit Kraus"
        ],
        "summary": "In the celebrated stable-matching problem, there are two sets of agents M and W, and the members of M only have preferences over the members of W and vice versa. It is usually assumed that each member of M and W is a single entity. However, there are many cases in which each member of M or W represents a team that consists of several individuals with common interests. For example, students may need to be matched to professors for their final projects, but each project is carried out by a team of students. Thus, the students first form teams, and the matching is between teams of students and professors.   When a team is considered as an agent from M or W, it needs to have a preference order that represents it. A voting rule is a natural mechanism for aggregating the preferences of the team members into a single preference order. In this paper, we investigate the problem of strategic voting in the context of stable-matching of teams. Specifically, we assume that members of each team use the Borda rule for generating the preference order of the team. Then, the Gale-Shapley algorithm is used for finding a stable-matching, where the set M is the proposing side. We show that the single-voter manipulation problem can be solved in polynomial time, both when the team is from M and when it is from W. We show that the coalitional manipulation problem is computationally hard, but it can be solved approximately both when the team is from M and when it is from W.",
        "published": "2022-07-11T14:40:35Z",
        "link": "http://arxiv.org/abs/2207.04912v2",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Parallel Bayesian Optimization of Agent-based Transportation Simulation",
        "authors": [
            "Kiran Chhatre",
            "Sidney Feygin",
            "Colin Sheppard",
            "Rashid Waraich"
        ],
        "summary": "MATSim (Multi-Agent Transport Simulation Toolkit) is an open source large-scale agent-based transportation planning project applied to various areas like road transport, public transport, freight transport, regional evacuation, etc. BEAM (Behavior, Energy, Autonomy, and Mobility) framework extends MATSim to enable powerful and scalable analysis of urban transportation systems. The agents from the BEAM simulation exhibit 'mode choice' behavior based on multinomial logit model. In our study, we consider eight mode choices viz. bike, car, walk, ride hail, driving to transit, walking to transit, ride hail to transit, and ride hail pooling. The 'alternative specific constants' for each mode choice are critical hyperparameters in a configuration file related to a particular scenario under experimentation. We use the 'Urbansim-10k' BEAM scenario (with 10,000 population size) for all our experiments. Since these hyperparameters affect the simulation in complex ways, manual calibration methods are time consuming. We present a parallel Bayesian optimization method with early stopping rule to achieve fast convergence for the given multi-in-multi-out problem to its optimal configurations. Our model is based on an open source HpBandSter package. This approach combines hierarchy of several 1D Kernel Density Estimators (KDE) with a cheap evaluator (Hyperband, a single multidimensional KDE). Our model has also incorporated extrapolation based early stopping rule. With our model, we could achieve a 25% L1 norm for a large-scale BEAM simulation in fully autonomous manner. To the best of our knowledge, our work is the first of its kind applied to large-scale multi-agent transportation simulations. This work can be useful for surrogate modeling of scenarios with very large populations.",
        "published": "2022-07-11T17:49:29Z",
        "link": "http://arxiv.org/abs/2207.05041v1",
        "categories": [
            "cs.LG",
            "cs.DC",
            "cs.MA"
        ]
    },
    {
        "title": "Cluster-Based Control of Transition-Independent MDPs",
        "authors": [
            "Carmel Fiscko",
            "Soummya Kar",
            "Bruno Sinopoli"
        ],
        "summary": "This work studies efficient solution methods for cluster-based control policies of transition-independent Markov decision processes (TI-MDPs). We focus on control of multi-agent systems, whereby a central planner (CP) influences agents to select desirable group behavior. The agents are partitioned into disjoint clusters whereby agents in the same cluster receive the same controls but agents in different clusters may receive different controls. Under mild assumptions, this process can be modeled as a TI-MDP where each factor describes the behavior of one cluster. The action space of the TI-MDP becomes exponential with respect to the number of clusters. To efficiently find a policy in this rapidly scaling space, we propose a clustered Bellman operator that optimizes over the action space for one cluster at any evaluation. We present Clustered Value Iteration (CVI), which uses this operator to iteratively perform \"round robin\" optimization across the clusters. CVI converges exponentially faster than standard value iteration (VI), and can find policies that closely approximate the MDP's true optimal value. A special class of TI-MDPs with separable reward functions are investigated, and it is shown that CVI will find optimal policies on this class of problems. Finally, the optimal clustering assignment problem is explored. The value functions TI-MDPs with submodular reward functions are shown to be submodular functions, so submodular set optimization may be used to find a near optimal clustering assignment. We propose an iterative greedy cluster splitting algorithm, which yields monotonic submodular improvement in value at each iteration. Finally, simulations offer empirical assessment of the proposed methods.",
        "published": "2022-07-11T23:33:22Z",
        "link": "http://arxiv.org/abs/2207.05224v3",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Herd Routes: A Preventative IoT-Based System for Improving Female   Pedestrian Safety on City Streets",
        "authors": [
            "Madeleine Woodburn",
            "Wynita M. Griggs",
            "Jakub Marecek",
            "Robert N. Shorten"
        ],
        "summary": "Over two thirds of women of all ages in the UK have experienced some form of sexual harassment in a public space. Recent tragic incidents involving female pedestrians have highlighted some of the personal safety issues that women still face in cities today. There exist many popular location-based safety applications as a result of this; however, these applications tend to take a reactive approach where action is taken only after an incident has occurred. This paper proposes a preventative approach to the problem by creating safer public environments through societal incentivisation. The proposed system, called \"Herd Routes\", improves the safety of female pedestrians by generating busier pedestrian routes as a result of route incentivisation. A novel application of distributed ledgers is proposed to provide security and trust, a record of system users' locations and IDs, and a platform for token exchange. A proof-of-concept was developed using the simulation package SUMO (Simulation of Urban Mobility), and a smartphone app. was built in Android Studio so that pedestrian Hardware-in-the-Loop testing could be carried out to validate the technical feasibility and desirability of the system. With positive results from the initial testing of the proof-of-concept, further development could significantly contribute towards creating safer pedestrian routes through cities, and tackle the societal change that is required to improve female pedestrian safety in the long term.",
        "published": "2022-07-12T03:18:19Z",
        "link": "http://arxiv.org/abs/2207.05279v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Towards Global Optimality in Cooperative MARL with the Transformation   And Distillation Framework",
        "authors": [
            "Jianing Ye",
            "Chenghao Li",
            "Jianhao Wang",
            "Chongjie Zhang"
        ],
        "summary": "Decentralized execution is one core demand in cooperative multi-agent reinforcement learning (MARL). Recently, most popular MARL algorithms have adopted decentralized policies to enable decentralized execution and use gradient descent as their optimizer. However, there is hardly any theoretical analysis of these algorithms taking the optimization method into consideration, and we find that various popular MARL algorithms with decentralized policies are suboptimal in toy tasks when gradient descent is chosen as their optimization method. In this paper, we theoretically analyze two common classes of algorithms with decentralized policies -- multi-agent policy gradient methods and value-decomposition methods to prove their suboptimality when gradient descent is used. In addition, we propose the Transformation And Distillation (TAD) framework, which reformulates a multi-agent MDP as a special single-agent MDP with a sequential structure and enables decentralized execution by distilling the learned policy on the derived ``single-agent\" MDP. This approach uses a two-stage learning paradigm to address the optimization problem in cooperative MARL, maintaining its performance guarantee. Empirically, we implement TAD-PPO based on PPO, which can theoretically perform optimal policy learning in the finite multi-agent MDPs and shows significant outperformance on a large set of cooperative multi-agent tasks.",
        "published": "2022-07-12T06:59:13Z",
        "link": "http://arxiv.org/abs/2207.11143v3",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Reward-Sharing Relational Networks in Multi-Agent Reinforcement Learning   as a Framework for Emergent Behavior",
        "authors": [
            "Hossein Haeri",
            "Reza Ahmadzadeh",
            "Kshitij Jerath"
        ],
        "summary": "In this work, we integrate `social' interactions into the MARL setup through a user-defined relational network and examine the effects of agent-agent relations on the rise of emergent behaviors. Leveraging insights from sociology and neuroscience, our proposed framework models agent relationships using the notion of Reward-Sharing Relational Networks (RSRN), where network edge weights act as a measure of how much one agent is invested in the success of (or `cares about') another. We construct relational rewards as a function of the RSRN interaction weights to collectively train the multi-agent system via a multi-agent reinforcement learning algorithm. The performance of the system is tested for a 3-agent scenario with different relational network structures (e.g., self-interested, communitarian, and authoritarian networks). Our results indicate that reward-sharing relational networks can significantly influence learned behaviors. We posit that RSRN can act as a framework where different relational networks produce distinct emergent behaviors, often analogous to the intuited sociological understanding of such networks.",
        "published": "2022-07-12T23:27:42Z",
        "link": "http://arxiv.org/abs/2207.05886v2",
        "categories": [
            "cs.AI",
            "cs.MA",
            "cs.SI"
        ]
    },
    {
        "title": "Relationship Design for Socially-Aware Behavior in Static Games",
        "authors": [
            "Shenghui Chen",
            "Yigit E. Bayiz",
            "David Fridovich-Keil",
            "Ufuk Topcu"
        ],
        "summary": "Autonomous agents can adopt socially-aware behaviors to reduce social costs, mimicking the way animals interact in nature and humans in society. We present a new approach to model socially-aware decision-making that includes two key elements: bounded rationality and inter-agent relationships. We capture the interagent relationships by introducing a novel model called a relationship game and encode agents' bounded rationality using quantal response equilibria. For each relationship game, we define a social cost function and formulate a mechanism design problem to optimize weights for relationships that minimize social cost at the equilibrium. We address the multiplicity of equilibria by presenting the problem in two forms: Min-Max and Min-Min, aimed respectively at minimization of the highest and lowest social costs in the equilibria. We compute the quantal response equilibrium by solving a least-squares problem defined with its Karush-Kuhn-Tucker conditions, and propose two projected gradient descent algorithms to solve the mechanism design problems. Numerical results, including two-lane congestion and congestion with an ambulance, confirm that these algorithms consistently reach the equilibrium with the intended social costs.",
        "published": "2022-07-13T17:50:34Z",
        "link": "http://arxiv.org/abs/2207.06392v2",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "A Coupling Approach to Analyzing Games with Dynamic Environments",
        "authors": [
            "Brandon C. Collins",
            "Shouhuai Xu",
            "Philip N. Brown"
        ],
        "summary": "The theory of learning in games has extensively studied situations where agents respond dynamically to each other by optimizing a fixed utility function. However, in real situations, the strategic environment varies as a result of past agent choices. Unfortunately, the analysis techniques that enabled a rich characterization of the emergent behavior in static environment games fail to cope with dynamic environment games. To address this, we develop a general framework using probabilistic couplings to extend the analysis of static environment games to dynamic ones. Using this approach, we obtain sufficient conditions under which traditional characterizations of Nash equilibria with best response dynamics and stochastic stability with log-linear learning can be extended to dynamic environment games. As a case study, we pose a model of cyber threat intelligence sharing between firms and a simple dynamic game-theoretic model of social precautions in an epidemic, both of which feature dynamic environments. For both examples, we obtain conditions under which the emergent behavior is characterized in the dynamic game by performing the traditional analysis on a reference static environment game.",
        "published": "2022-07-13T19:51:54Z",
        "link": "http://arxiv.org/abs/2207.06504v1",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Self-Play PSRO: Toward Optimal Populations in Two-Player Zero-Sum Games",
        "authors": [
            "Stephen McAleer",
            "JB Lanier",
            "Kevin Wang",
            "Pierre Baldi",
            "Roy Fox",
            "Tuomas Sandholm"
        ],
        "summary": "In competitive two-agent environments, deep reinforcement learning (RL) methods based on the \\emph{Double Oracle (DO)} algorithm, such as \\emph{Policy Space Response Oracles (PSRO)} and \\emph{Anytime PSRO (APSRO)}, iteratively add RL best response policies to a population. Eventually, an optimal mixture of these population policies will approximate a Nash equilibrium. However, these methods might need to add all deterministic policies before converging. In this work, we introduce \\emph{Self-Play PSRO (SP-PSRO)}, a method that adds an approximately optimal stochastic policy to the population in each iteration. Instead of adding only deterministic best responses to the opponent's least exploitable population mixture, SP-PSRO also learns an approximately optimal stochastic policy and adds it to the population as well. As a result, SP-PSRO empirically tends to converge much faster than APSRO and in many games converges in just a few iterations.",
        "published": "2022-07-13T22:55:51Z",
        "link": "http://arxiv.org/abs/2207.06541v1",
        "categories": [
            "cs.GT",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "A Simple Adaptive Procedure Converging to Forgiving Correlated   Equilibria",
        "authors": [
            "Hugh Zhang"
        ],
        "summary": "Simple adaptive procedures that converge to correlated equilibria are known to exist for normal form games (Hart and Mas-Colell 2000), but no such analogue exists for extensive-form games. Leveraging inspiration from Zinkevich et al. (2008), we show that any internal regret minimization procedure designed for normal-form games can be efficiently extended to finite extensive-form games of perfect recall. Our procedure converges to the set of forgiving correlated equilibria, a refinement of various other proposed extensions of the correlated equilibrium solution concept to extensive-form games (Forges 1986a; Forges 1986b; von Stengel and Forges 2008). In a forgiving correlated equilibrium, players receive move recommendations only upon reaching the relevant information set instead of all at once at the beginning of the game. Assuming all other players follow their recommendations, each player is incentivized to follow her recommendations regardless of whether she has done so at previous infosets. The resulting procedure is completely decentralized: players need neither knowledge of their opponents' actions nor even a complete understanding of the game itself beyond their own payoffs and strategies.",
        "published": "2022-07-13T23:10:00Z",
        "link": "http://arxiv.org/abs/2207.06548v1",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Scalable Model-based Policy Optimization for Decentralized Networked   Systems",
        "authors": [
            "Yali Du",
            "Chengdong Ma",
            "Yuchen Liu",
            "Runji Lin",
            "Hao Dong",
            "Jun Wang",
            "Yaodong Yang"
        ],
        "summary": "Reinforcement learning algorithms require a large amount of samples; this often limits their real-world applications on even simple tasks. Such a challenge is more outstanding in multi-agent tasks, as each step of operation is more costly requiring communications or shifting or resources. This work aims to improve data efficiency of multi-agent control by model-based learning. We consider networked systems where agents are cooperative and communicate only locally with their neighbors, and propose the decentralized model-based policy optimization framework (DMPO). In our method, each agent learns a dynamic model to predict future states and broadcast their predictions by communication, and then the policies are trained under the model rollouts. To alleviate the bias of model-generated data, we restrain the model usage for generating myopic rollouts, thus reducing the compounding error of model generation. To pertain the independence of policy update, we introduce extended value function and theoretically prove that the resulting policy gradient is a close approximation to true policy gradients. We evaluate our algorithm on several benchmarks for intelligent transportation systems, which are connected autonomous vehicle control tasks (Flow and CACC) and adaptive traffic signal control (ATSC). Empirically results show that our method achieves superior data efficiency and matches the performance of model-free methods using true models.",
        "published": "2022-07-13T23:52:14Z",
        "link": "http://arxiv.org/abs/2207.06559v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "math.OC",
            "stat.ML"
        ]
    },
    {
        "title": "Robot Swarms as Hybrid Systems: Modelling and Verification",
        "authors": [
            "Stefan Schupp",
            "Francesco Leofante",
            "Leander Behr",
            "Erika Ábrahám",
            "Armando Taccella"
        ],
        "summary": "A swarm robotic system consists of a team of robots performing cooperative tasks without any centralized coordination. In principle, swarms enable flexible and scalable solutions; however, designing individual control algorithms that can guarantee a required global behavior is difficult. Formal methods have been suggested by several researchers as a mean to increase confidence in the behavior of the swarm. In this work, we propose to model swarms as hybrid systems and use reachability analysis to verify their properties. We discuss challenges and report on the experience gained from applying hybrid formalisms to the verification of a swarm robotic system.",
        "published": "2022-07-14T09:10:00Z",
        "link": "http://arxiv.org/abs/2207.06758v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY",
            "C.1.m; D.2.4"
        ]
    },
    {
        "title": "Structure of Core-Periphery Communities",
        "authors": [
            "Junwei Su",
            "Peter Marbach"
        ],
        "summary": "It has been experimentally shown that communities in social networks tend to have a core-periphery topology. However, there is still a limited understanding of the precise structure of core-periphery communities in social networks including the connectivity structure and interaction rates between agents. In this paper, we use a game-theoretic approach to derive a more precise characterization of the structure of core-periphery communities.",
        "published": "2022-07-14T14:48:09Z",
        "link": "http://arxiv.org/abs/2207.06964v1",
        "categories": [
            "cs.SI",
            "cs.MA"
        ]
    },
    {
        "title": "Spin glass systems as collective active inference",
        "authors": [
            "Conor Heins",
            "Brennan Klein",
            "Daphne Demekas",
            "Miguel Aguilera",
            "Christopher Buckley"
        ],
        "summary": "An open question in the study of emergent behaviour in multi-agent Bayesian systems is the relationship, if any, between individual and collective inference. In this paper we explore the correspondence between generative models that exist at two distinct scales, using spin glass models as a sandbox system to investigate this question. We show that the collective dynamics of a specific type of active inference agent is equivalent to sampling from the stationary distribution of a spin glass system. A collective of specifically-designed active inference agents can thus be described as implementing a form of sampling-based inference (namely, from a Boltzmann machine) at the higher level. However, this equivalence is very fragile, breaking upon simple modifications to the generative models of the individual agents or the nature of their interactions. We discuss the implications of this correspondence and its fragility for the study of multiscale systems composed of Bayesian agents.",
        "published": "2022-07-14T14:54:12Z",
        "link": "http://arxiv.org/abs/2207.06970v1",
        "categories": [
            "cond-mat.dis-nn",
            "cs.MA",
            "physics.soc-ph"
        ]
    },
    {
        "title": "ASUMAN: Age Sense Updating Multiple Access in Networks",
        "authors": [
            "Purbesh Mitra",
            "Sennur Ulukus"
        ],
        "summary": "We consider a fully-connected wireless gossip network which consists of a source and $n$ receiver nodes. The source updates itself with a Poisson process and also sends updates to the nodes as Poisson arrivals. Upon receiving the updates, the nodes update their knowledge about the source. The nodes gossip the data among themselves in the form of Poisson arrivals to disperse their knowledge about the source. The total gossiping rate is bounded by a constraint. The goal of the network is to be as timely as possible with the source. In this work, we propose ASUMAN, a distributed opportunistic gossiping scheme, where after each time the source updates itself, each node waits for a time proportional to its current age and broadcasts a signal to the other nodes of the network. This allows the nodes in the network which have higher age to remain silent and only the low-age nodes to gossip, thus utilizing a significant portion of the constrained total gossip rate. We calculate the average age for a typical node in such a network with symmetric settings and show that the theoretical upper bound on the age scales as $O(1)$. ASUMAN, with an average age of $O(1)$, offers significant gains compared to a system where the nodes just gossip blindly with a fixed update rate in which case the age scales as $O(\\log n)$.",
        "published": "2022-07-14T17:45:47Z",
        "link": "http://arxiv.org/abs/2207.07094v1",
        "categories": [
            "cs.IT",
            "cs.MA",
            "cs.NI",
            "eess.SP",
            "math.IT"
        ]
    },
    {
        "title": "K-level Reasoning for Zero-Shot Coordination in Hanabi",
        "authors": [
            "Brandon Cui",
            "Hengyuan Hu",
            "Luis Pineda",
            "Jakob N. Foerster"
        ],
        "summary": "The standard problem setting in cooperative multi-agent settings is self-play (SP), where the goal is to train a team of agents that works well together. However, optimal SP policies commonly contain arbitrary conventions (\"handshakes\") and are not compatible with other, independently trained agents or humans. This latter desiderata was recently formalized by Hu et al. 2020 as the zero-shot coordination (ZSC) setting and partially addressed with their Other-Play (OP) algorithm, which showed improved ZSC and human-AI performance in the card game Hanabi. OP assumes access to the symmetries of the environment and prevents agents from breaking these in a mutually incompatible way during training. However, as the authors point out, discovering symmetries for a given environment is a computationally hard problem. Instead, we show that through a simple adaption of k-level reasoning (KLR) Costa Gomes et al. 2006, synchronously training all levels, we can obtain competitive ZSC and ad-hoc teamplay performance in Hanabi, including when paired with a human-like proxy bot. We also introduce a new method, synchronous-k-level reasoning with a best response (SyKLRBR), which further improves performance on our synchronous KLR by co-training a best response.",
        "published": "2022-07-14T18:53:34Z",
        "link": "http://arxiv.org/abs/2207.07166v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Stochastic Market Games",
        "authors": [
            "Kyrill Schmid",
            "Lenz Belzner",
            "Robert Müller",
            "Johannes Tochtermann",
            "Claudia Linnhoff-Popien"
        ],
        "summary": "Some of the most relevant future applications of multi-agent systems like autonomous driving or factories as a service display mixed-motive scenarios, where agents might have conflicting goals. In these settings agents are likely to learn undesirable outcomes in terms of cooperation under independent learning, such as overly greedy behavior. Motivated from real world societies, in this work we propose to utilize market forces to provide incentives for agents to become cooperative. As demonstrated in an iterated version of the Prisoner's Dilemma, the proposed market formulation can change the dynamics of the game to consistently learn cooperative policies. Further we evaluate our approach in spatially and temporally extended settings for varying numbers of agents. We empirically find that the presence of markets can improve both the overall result and agent individual returns via their trading activities.",
        "published": "2022-07-15T10:37:16Z",
        "link": "http://arxiv.org/abs/2207.07388v3",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Multi-AGV's Temporal Memory-based RRT Exploration in Unknown Environment",
        "authors": [
            "Billy Pik Lik Lau",
            "Brandon Jin Yang Ong",
            "Leonard Kin Yung Loh",
            "Ran Liu",
            "Chau Yuen",
            "Gim Song Soh",
            "U-Xuan Tan"
        ],
        "summary": "With the increasing need for multi-robot for exploring the unknown region in a challenging environment, efficient collaborative exploration strategies are needed for achieving such feat. A frontier-based Rapidly-Exploring Random Tree (RRT) exploration can be deployed to explore an unknown environment. However, its' greedy behavior causes multiple robots to explore the region with the highest revenue, which leads to massive overlapping in exploration process. To address this issue, we present a temporal memory-based RRT (TM-RRT) exploration strategy for multi-robot to perform robust exploration in an unknown environment. It computes adaptive duration for each frontier assigned and calculates the frontier's revenue based on the relative position of each robot. In addition, each robot is equipped with a memory consisting of frontier assigned and share among fleets to prevent repeating assignment of same frontier. Through both simulation and actual deployment, we have shown the robustness of TM-RRT exploration strategy by completing the exploration in a 25.0m x 54.0m (1350.0m2) area, while the conventional RRT exploration strategy falls short.",
        "published": "2022-07-15T14:09:25Z",
        "link": "http://arxiv.org/abs/2207.07484v1",
        "categories": [
            "cs.RO",
            "cs.MA",
            "68T40"
        ]
    },
    {
        "title": "Cooperative Marine Operations via Ad Hoc Teams",
        "authors": [
            "Ignacio Carlucho",
            "Arrasy Rahman",
            "William Ard",
            "Elliot Fosong",
            "Corina Barbalata",
            "Stefano V. Albrecht"
        ],
        "summary": "While research in ad hoc teamwork has great potential for solving real-world robotic applications, most developments so far have been focusing on environments with simple dynamics. In this article, we discuss how the problem of ad hoc teamwork can be of special interest for marine robotics and how it can aid marine operations. Particularly, we present a set of challenges that need to be addressed for achieving ad hoc teamwork in underwater environments and we discuss possible solutions based on current state-of-the-art developments in the ad hoc teamwork literature.",
        "published": "2022-07-15T14:34:57Z",
        "link": "http://arxiv.org/abs/2207.07498v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Proactive Distributed Constraint Optimization of Heterogeneous Incident   Vehicle Teams",
        "authors": [
            "Justice Darko",
            "Hyoshin Park"
        ],
        "summary": "Traditionally, traffic incident management (TIM) programs coordinate the deployment of emergency resources to immediate incident requests without accommodating the interdependencies on incident evolutions in the environment. However, ignoring inherent interdependencies on the evolution of incidents in the environment while making current deployment decisions is shortsighted, and the resulting naive deployment strategy can significantly worsen the overall incident delay impact on the network. The interdependencies on incident evolution in the environment, including those between incident occurrences, and those between resource availability in near-future requests and the anticipated duration of the immediate incident request, should be considered through a look-ahead model when making current-stage deployment decisions. This study develops a new proactive framework based on the distributed constraint optimization problem (DCOP) to address the above limitations, overcoming conventional TIM models that cannot accommodate the dependencies in the TIM problem. Furthermore, the optimization objective is formulated to incorporate Unmanned Aerial Vehicles (UAVs). The UAVs' role in TIM includes exploring uncertain traffic conditions, detecting unexpected events, and augmenting information from roadway traffic sensors. Robustness analysis of our model for multiple TIM scenarios shows satisfactory performance using local search exploration heuristics. Overall, our model reports a significant reduction in total incident delay compared to conventional TIM models. With UAV support, we demonstrate a further decrease in the overall incident delay through the shorter response time of emergency vehicles, and a reduction in uncertainties associated with the estimated incident delay impact.",
        "published": "2022-07-16T13:43:58Z",
        "link": "http://arxiv.org/abs/2207.11132v2",
        "categories": [
            "eess.SY",
            "cs.AI",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Indivisible Participatory Budgeting under Weak Rankings",
        "authors": [
            "Gogulapati Sreedurga",
            "Yadati Narahari"
        ],
        "summary": "Participatory budgeting (PB) has attracted much attention in recent times due to its wide applicability in social choice settings. In this paper, we consider indivisible PB which involves allocating an available, limited budget to a set of indivisible projects, each having a certain cost, based on the preferences of agents over projects. The specific, important, research gap that we address in this paper is to propose classes of rules for indivisible PB with weak rankings (i.e., weak ordinal preferences) and investigate their key algorithmic and axiomatic issues. We propose two classes of rules having distinct significance and motivation. The first is layered approval rules which enable weak rankings to be studied by carefully translating them into approval votes. The second is need-based rules which enable to capture fairness issues. Under layered approval rules, we study two natural families of rules: greedy-truncation rules and cost-worthy rules. The paper has two parts. In the first part, we investigate algorithmic and complexity related issues for the proposed rules. In the second part, we present a detailed axiomatic analysis of these rules, for which, we examine and generalize axioms in the literature and also introduce a new axiom, pro-affordability. The paper helps to highlight the trade-offs among practical appeal, computational complexity, and axiomatic compliance of these rules.",
        "published": "2022-07-16T16:46:12Z",
        "link": "http://arxiv.org/abs/2207.07981v1",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Characterization of Group-Fair Social Choice Rules under Single-Peaked   Preferences",
        "authors": [
            "Gogulapati Sreedurga",
            "Soumyarup Sadhukhan",
            "Souvik Roy",
            "Yadati Narahari"
        ],
        "summary": "We study fairness in social choice settings under single-peaked preferences. Construction and characterization of social choice rules in the single-peaked domain has been extensively studied in prior works. In fact, in the single-peaked domain, it is known that unanimous and strategy-proof deterministic rules have to be min-max rules and those that also satisfy anonymity have to be median rules. Further, random social choice rules satisfying these properties have been shown to be convex combinations of respective deterministic rules. We non-trivially add to this body of results by including fairness considerations in social choice. Our study directly addresses fairness for groups of agents. To study group-fairness, we consider an existing partition of the agents into logical groups, based on natural attributes such as gender, race, and location. To capture fairness within each group, we introduce the notion of group-wise anonymity. To capture fairness across the groups, we propose a weak notion as well as a strong notion of fairness. The proposed fairness notions turn out to be natural generalizations of existing individual-fairness notions and moreover provide non-trivial outcomes for strict ordinal preferences, unlike the existing group-fairness notions. We provide two separate characterizations of random social choice rules that satisfy group-fairness: (i) direct characterization (ii) extreme point characterization (as convex combinations of fair deterministic social choice rules). We also explore the special case where there are no groups and provide sharper characterizations of rules that achieve individual-fairness.",
        "published": "2022-07-16T17:12:54Z",
        "link": "http://arxiv.org/abs/2207.07984v1",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.MA",
            "econ.TH"
        ]
    },
    {
        "title": "Task Allocation with Load Management in Multi-Agent Teams",
        "authors": [
            "Haochen Wu",
            "Amin Ghadami",
            "Alparslan Emrah Bayrak",
            "Jonathon M. Smereka",
            "Bogdan I. Epureanu"
        ],
        "summary": "In operations of multi-agent teams ranging from homogeneous robot swarms to heterogeneous human-autonomy teams, unexpected events might occur. While efficiency of operation for multi-agent task allocation problems is the primary objective, it is essential that the decision-making framework is intelligent enough to manage unexpected task load with limited resources. Otherwise, operation effectiveness would drastically plummet with overloaded agents facing unforeseen risks. In this work, we present a decision-making framework for multi-agent teams to learn task allocation with the consideration of load management through decentralized reinforcement learning, where idling is encouraged and unnecessary resource usage is avoided. We illustrate the effect of load management on team performance and explore agent behaviors in example scenarios. Furthermore, a measure of agent importance in collaboration is developed to infer team resilience when facing handling potential overload situations.",
        "published": "2022-07-17T20:17:09Z",
        "link": "http://arxiv.org/abs/2207.08279v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.RO"
        ]
    },
    {
        "title": "Fast Convergence of Optimistic Gradient Ascent in Network Zero-Sum   Extensive Form Games",
        "authors": [
            "Georgios Piliouras",
            "Lillian Ratliff",
            "Ryann Sim",
            "Stratis Skoulakis"
        ],
        "summary": "The study of learning in games has thus far focused primarily on normal form games. In contrast, our understanding of learning in extensive form games (EFGs) and particularly in EFGs with many agents lags far behind, despite them being closer in nature to many real world applications. We consider the natural class of Network Zero-Sum Extensive Form Games, which combines the global zero-sum property of agent payoffs, the efficient representation of graphical games as well the expressive power of EFGs. We examine the convergence properties of Optimistic Gradient Ascent (OGA) in these games. We prove that the time-average behavior of such online learning dynamics exhibits $O(1/T)$ rate convergence to the set of Nash Equilibria. Moreover, we show that the day-to-day behavior also converges to Nash with rate $O(c^{-t})$ for some game-dependent constant $c>0$.",
        "published": "2022-07-18T08:21:39Z",
        "link": "http://arxiv.org/abs/2207.08426v1",
        "categories": [
            "cs.GT",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "RESAM: Requirements Elicitation and Specification for Deep-Learning   Anomaly Models with Applications to UAV Flight Controllers",
        "authors": [
            "Md Nafee Al Islam",
            "Yihong Ma",
            "Pedro Alarcon Granadeno",
            "Nitesh Chawla",
            "Jane Cleland-Huang"
        ],
        "summary": "CyberPhysical systems (CPS) must be closely monitored to identify and potentially mitigate emergent problems that arise during their routine operations. However, the multivariate time-series data which they typically produce can be complex to understand and analyze. While formal product documentation often provides example data plots with diagnostic suggestions, the sheer diversity of attributes, critical thresholds, and data interactions can be overwhelming to non-experts who subsequently seek help from discussion forums to interpret their data logs. Deep learning models, such as Long Short-term memory (LSTM) networks can be used to automate these tasks and to provide clear explanations of diverse anomalies detected in real-time multivariate data-streams. In this paper we present RESAM, a requirements process that integrates knowledge from domain experts, discussion forums, and formal product documentation, to discover and specify requirements and design definitions in the form of time-series attributes that contribute to the construction of effective deep learning anomaly detectors. We present a case-study based on a flight control system for small Uncrewed Aerial Systems and demonstrate that its use guides the construction of effective anomaly detection models whilst also providing underlying support for explainability. RESAM is relevant to domains in which open or closed online forums provide discussion support for log analysis.",
        "published": "2022-07-18T18:09:59Z",
        "link": "http://arxiv.org/abs/2207.08857v1",
        "categories": [
            "cs.SE",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Distributed Differentiable Dynamic Game for Multi-robot Coordination",
        "authors": [
            "Yizhi Zhou",
            "Wanxin Jin",
            "Xuan Wang"
        ],
        "summary": "This paper develops a Distributed Differentiable Dynamic Game (D3G) framework, which can efficiently solve the forward and inverse problems in multi-robot coordination. We formulate multi-robot coordination as a dynamic game, where the behavior of a robot is dictated by its own dynamics and objective that also depends on others' behavior. In the forward problem, D3G enables all robots collaboratively to seek the Nash equilibrium of the game in a distributed manner, by developing a distributed shooting-based Nash solver. In the inverse problem, where each robot aims to find (learn) its objective (and dynamics) parameters to mimic given coordination demonstrations, D3G proposes a differentiation solver based on Differential Pontryagin's Maximum Principle, which allows each robot to update its parameters in a distributed and coordinated manner. We test the D3G in simulation with two types of robots given different task configurations. The results demonstrate the effectiveness of D3G for solving both forward and inverse problems in comparison with existing methods.",
        "published": "2022-07-18T19:06:18Z",
        "link": "http://arxiv.org/abs/2207.08892v4",
        "categories": [
            "cs.RO",
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Layered Cost-Map-Based Traffic Management for Multiple Automated Mobile   Robots via a Data Distribution Service",
        "authors": [
            "Seungwoo Jeong",
            "Taekwon Ga",
            "Inhwan Jeong",
            "Jongkyu Oh",
            "Jongeun Choi"
        ],
        "summary": "This letter proposes traffic management for multiple automated mobile robots (AMRs) based on a layered cost map. Multiple AMRs communicate via a data distribution service (DDS), which is shared by topics in the same DDS domain. The cost of each layer is manipulated by topics. The traffic management server in the domain sends or receives topics to each of AMRs. Using the layered cost map, the new concept of prohibition filter, lane filter, fleet layer, and region filter are proposed and implemented. The prohibition filter can help a user set an area that would prohibit an AMR from trespassing. The lane filter can help set one-way directions based on an angle image. The fleet layer can help AMRs share their locations via the traffic management server. The region filter requests for or receives an exclusive area, which can be occupied by only one AMR, from the traffic management server. All the layers are experimentally validated with real-world AMRs. Each area can be configured with user-defined images or text-based parameter files.",
        "published": "2022-07-18T19:23:30Z",
        "link": "http://arxiv.org/abs/2207.08902v1",
        "categories": [
            "cs.RO",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Ballot Length in Instant Runoff Voting",
        "authors": [
            "Kiran Tomlinson",
            "Johan Ugander",
            "Jon Kleinberg"
        ],
        "summary": "Instant runoff voting (IRV) is an increasingly-popular alternative to traditional plurality voting in which voters submit rankings over the candidates rather than single votes. In practice, elections using IRV often restrict the ballot length, the number of candidates a voter is allowed to rank on their ballot. We theoretically and empirically analyze how ballot length can influence the outcome of an election, given fixed voter preferences. We show that there exist preference profiles over $k$ candidates such that up to $k-1$ different candidates win at different ballot lengths. We derive exact lower bounds on the number of voters required for such profiles and provide a construction matching the lower bound for unrestricted voter preferences. Additionally, we characterize which sequences of winners are possible over ballot lengths and provide explicit profile constructions achieving any feasible winner sequence. We also examine how classic preference restrictions influence our results--for instance, single-peakedness makes $k-1$ different winners impossible but still allows at least $\\Omega(\\sqrt k)$. Finally, we analyze a collection of 168 real-world elections, where we truncate rankings to simulate shorter ballots. We find that shorter ballots could have changed the outcome in one quarter of these elections. Our results highlight ballot length as a consequential degree of freedom in the design of IRV elections.",
        "published": "2022-07-18T22:01:13Z",
        "link": "http://arxiv.org/abs/2207.08958v3",
        "categories": [
            "cs.MA",
            "econ.TH"
        ]
    },
    {
        "title": "Proceedings of the Second Workshop on Agents and Robots for reliable   Engineered Autonomy",
        "authors": [
            "Rafael C. Cardoso",
            "Angelo Ferrando",
            "Fabio Papacchini",
            "Mehrnoosh Askarpour",
            "Louise A. Dennis"
        ],
        "summary": "This volume contains the proceedings of the Second Workshop on Agents and Robots for reliable Engineered Autonomy (AREA 2022), co-located with the 31st International Joint Conference on Artificial Intelligence and the 25th European Conference on Artificial Intelligence (IJCAI-ECAI 2022). The AREA workshop brings together researchers from autonomous agents, software engineering and robotic communities, as combining knowledge coming from these research areas may lead to innovative approaches that solve complex problems related with the verification and validation of autonomous robotic systems.",
        "published": "2022-07-19T04:12:36Z",
        "link": "http://arxiv.org/abs/2207.09058v1",
        "categories": [
            "cs.MA",
            "cs.RO",
            "cs.SE"
        ]
    },
    {
        "title": "Few-Shot Teamwork",
        "authors": [
            "Elliot Fosong",
            "Arrasy Rahman",
            "Ignacio Carlucho",
            "Stefano V. Albrecht"
        ],
        "summary": "We propose the novel few-shot teamwork (FST) problem, where skilled agents trained in a team to complete one task are combined with skilled agents from different tasks, and together must learn to adapt to an unseen but related task. We discuss how the FST problem can be seen as addressing two separate problems: one of reducing the experience required to train a team of agents to complete a complex task; and one of collaborating with unfamiliar teammates to complete a new task. Progress towards solving FST could lead to progress in both multi-agent reinforcement learning and ad hoc teamwork.",
        "published": "2022-07-19T14:34:41Z",
        "link": "http://arxiv.org/abs/2207.09300v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Resource allocation in open multi-agent systems: an online optimization   analysis",
        "authors": [
            "Renato Vizuete",
            "Charles Monnoyer de Galland",
            "Julien M. Hendrickx",
            "Paolo Frasca",
            "Elena Panteley"
        ],
        "summary": "The resource allocation problem consists of the optimal distribution of a budget between agents in a group. We consider such a problem in the context of open systems, where agents can be replaced at some time instances. These replacements lead to variations in both the budget and the total cost function that hinder the overall network's performance. For a simple setting, we analyze the performance of the Random Coordinate Descent algorithm (RCD) using tools similar to those commonly used in online optimization. In particular, we study the accumulated errors that compare solutions issued from the RCD algorithm and the optimal solution or the non-collaborating selfish strategy and we derive some bounds in expectation for these accumulated errors.",
        "published": "2022-07-19T15:04:55Z",
        "link": "http://arxiv.org/abs/2207.09316v1",
        "categories": [
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "Industry Led Use-Case Development for Human-Swarm Operations",
        "authors": [
            "Jediah R. Clark",
            "Mohammad Naiseh",
            "Joel Fischer",
            "Marise Galvez Trigo",
            "Katie Parnell",
            "Mario Brito",
            "Adrian Bodenmann",
            "Sarvapali D. Ramchurn",
            "Mohammad Divband Soorati"
        ],
        "summary": "In the domain of unmanned vehicles, autonomous robotic swarms promise to deliver increased efficiency and collective autonomy. How these swarms will operate in the future, and what communication requirements and operational boundaries will arise are yet to be sufficiently defined. A workshop was conducted with 11 professional unmanned-vehicle operators and designers with the objective of identifying use-cases for developing and testing robotic swarms. Three scenarios were defined by experts and were then compiled to produce a single use case outlining the scenario, objectives, agents, communication requirements and stages of operation when collaborating with highly autonomous swarms. Our compiled use case is intended for researchers, designers, and manufacturers alike to test and tailor their design pipeline to accommodate for some of the key issues in human-swarm ininteraction. Examples of application include informing simulation development, forming the basis of further design workshops, and identifying trust issues that may arise between human operators and the swarm.",
        "published": "2022-07-19T20:50:23Z",
        "link": "http://arxiv.org/abs/2207.09543v2",
        "categories": [
            "cs.RO",
            "cs.HC",
            "cs.MA"
        ]
    },
    {
        "title": "Collective Decision Making in Communication-Constrained Environments",
        "authors": [
            "Thomas G. Kelly",
            "Mohammad Divband Soorati",
            "Klaus-Peter Zauner",
            "Sarvapali D. Ramchurn",
            "Danesh Tarapore"
        ],
        "summary": "One of the main tasks for autonomous robot swarms is to collectively decide on the best available option. Achieving that requires a high quality communication between the agents that may not be always available in a real world environment. In this paper we introduce the communication-constrained collective decision-making problem where some areas of the environment limit the agents' ability to communicate, either by reducing success rate or blocking the communication channels. We propose a decentralised algorithm for mapping environmental features for robot swarms as well as improving collective decision making in communication-limited environments without prior knowledge of the communication landscape. Our results show that making a collective aware of the communication environment can improve the speed of convergence in the presence of communication limitations, at least 3 times faster, without sacrificing accuracy.",
        "published": "2022-07-19T21:48:15Z",
        "link": "http://arxiv.org/abs/2207.09564v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Task Allocation using a Team of Robots",
        "authors": [
            "Haris Aziz",
            "Arindam Pal",
            "Ali Pourmiri",
            "Fahimeh Ramezani",
            "Brendan Sims"
        ],
        "summary": "Task allocation using a team or coalition of robots is one of the most important problems in robotics, computer science, operational research, and artificial intelligence. In recent work, research has focused on handling complex objectives and feasibility constraints amongst other variations of the multi-robot task allocation problem. There are many examples of important research progress in these directions. We present a general formulation of the task allocation problem that generalizes several versions that are well-studied. Our formulation includes the states of robots, tasks, and the surrounding environment in which they operate. We describe how the problem can vary depending on the feasibility constraints, objective functions, and the level of dynamically changing information. In addition, we discuss existing solution approaches for the problem including optimization-based approaches, and market-based approaches.",
        "published": "2022-07-20T04:49:11Z",
        "link": "http://arxiv.org/abs/2207.09650v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.DM",
            "cs.MA"
        ]
    },
    {
        "title": "RV4JaCa -- Runtime Verification for Multi-Agent Systems",
        "authors": [
            "Debora C. Engelmann",
            "Angelo Ferrando",
            "Alison R. Panisson",
            "Davide Ancona",
            "Rafael H. Bordini",
            "Viviana Mascardi"
        ],
        "summary": "This paper presents a Runtime Verification (RV) approach for Multi-Agent Systems (MAS) using the JaCaMo framework. Our objective is to bring a layer of security to the MAS. This layer is capable of controlling events during the execution of the system without needing a specific implementation in the behaviour of each agent to recognise the events. MAS have been used in the context of hybrid intelligence. This use requires communication between software agents and human beings. In some cases, communication takes place via natural language dialogues. However, this kind of communication brings us to a concern related to controlling the flow of dialogue so that agents can prevent any change in the topic of discussion that could impair their reasoning. We demonstrate the implementation of a monitor that aims to control this dialogue flow in a MAS that communicates with the user through natural language to aid decision-making in hospital bed allocation.",
        "published": "2022-07-20T07:25:47Z",
        "link": "http://arxiv.org/abs/2207.09708v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.SE"
        ]
    },
    {
        "title": "Towards VEsNA, a Framework for Managing Virtual Environments via Natural   Language Agents",
        "authors": [
            "Andrea Gatti",
            "Viviana Mascardi"
        ],
        "summary": "Automating a factory where robots are involved is neither trivial nor cheap. Engineering the factory automation process in such a way that return of interest is maximized and risk for workers and equipment is minimized, is hence of paramount importance. Simulation can be a game changer in this scenario but requires advanced programming skills that domain experts and industrial designers might not have. In this paper we present the preliminary design and implementation of a general-purpose framework for creating and exploiting Virtual Environments via Natural language Agents (VEsNA). VEsNA takes advantage of agent-based technologies and natural language processing to enhance the design of virtual environments. The natural language input provided to VEsNA is understood by a chatbot and passed to a cognitive intelligent agent that implements the logic behind displacing objects in the virtual environment. In the VEsNA vision, the intelligent agent will be able to reason on this displacement and on its compliance to legal and normative constraints. It will also be able to implement what-if analysis and case-based reasoning. Objects populating the virtual environment will include active objects and will populate a dynamic simulation whose outcomes will be interpreted by the cognitive agent; explanations and suggestions will be passed back to the user by the chatbot.",
        "published": "2022-07-20T07:26:59Z",
        "link": "http://arxiv.org/abs/2207.09711v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Differentiable Agent-based Epidemiology",
        "authors": [
            "Ayush Chopra",
            "Alexander Rodríguez",
            "Jayakumar Subramanian",
            "Arnau Quera-Bofarull",
            "Balaji Krishnamurthy",
            "B. Aditya Prakash",
            "Ramesh Raskar"
        ],
        "summary": "Mechanistic simulators are an indispensable tool for epidemiology to explore the behavior of complex, dynamic infections under varying conditions and navigate uncertain environments. Agent-based models (ABMs) are an increasingly popular simulation paradigm that can represent the heterogeneity of contact interactions with granular detail and agency of individual behavior. However, conventional ABM frameworks are not differentiable and present challenges in scalability; due to which it is non-trivial to connect them to auxiliary data sources. In this paper, we introduce GradABM: a scalable, differentiable design for agent-based modeling that is amenable to gradient-based learning with automatic differentiation. GradABM can quickly simulate million-size populations in few seconds on commodity hardware, integrate with deep neural networks and ingest heterogeneous data sources. This provides an array of practical benefits for calibration, forecasting, and evaluating policy interventions. We demonstrate the efficacy of GradABM via extensive experiments with real COVID-19 and influenza datasets.",
        "published": "2022-07-20T07:32:02Z",
        "link": "http://arxiv.org/abs/2207.09714v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "q-bio.PE",
            "q-bio.QM"
        ]
    },
    {
        "title": "MABe22: A Multi-Species Multi-Task Benchmark for Learned Representations   of Behavior",
        "authors": [
            "Jennifer J. Sun",
            "Markus Marks",
            "Andrew Ulmer",
            "Dipam Chakraborty",
            "Brian Geuther",
            "Edward Hayes",
            "Heng Jia",
            "Vivek Kumar",
            "Sebastian Oleszko",
            "Zachary Partridge",
            "Milan Peelman",
            "Alice Robie",
            "Catherine E. Schretter",
            "Keith Sheppard",
            "Chao Sun",
            "Param Uttarwar",
            "Julian M. Wagner",
            "Eric Werner",
            "Joseph Parker",
            "Pietro Perona",
            "Yisong Yue",
            "Kristin Branson",
            "Ann Kennedy"
        ],
        "summary": "We introduce MABe22, a large-scale, multi-agent video and trajectory benchmark to assess the quality of learned behavior representations. This dataset is collected from a variety of biology experiments, and includes triplets of interacting mice (4.7 million frames video+pose tracking data, 10 million frames pose only), symbiotic beetle-ant interactions (10 million frames video data), and groups of interacting flies (4.4 million frames of pose tracking data). Accompanying these data, we introduce a panel of real-life downstream analysis tasks to assess the quality of learned representations by evaluating how well they preserve information about the experimental conditions (e.g. strain, time of day, optogenetic stimulation) and animal behavior. We test multiple state-of-the-art self-supervised video and trajectory representation learning methods to demonstrate the use of our benchmark, revealing that methods developed using human action datasets do not fully translate to animal datasets. We hope that our benchmark and dataset encourage a broader exploration of behavior representation learning methods across species and settings.",
        "published": "2022-07-21T15:51:30Z",
        "link": "http://arxiv.org/abs/2207.10553v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.CV",
            "cs.MA"
        ]
    },
    {
        "title": "A Dual Accelerated Method for Online Stochastic Distributed Averaging:   From Consensus to Decentralized Policy Evaluation",
        "authors": [
            "Sheng Zhang",
            "Ashwin Pananjady",
            "Justin Romberg"
        ],
        "summary": "Motivated by decentralized sensing and policy evaluation problems, we consider a particular type of distributed stochastic optimization problem over a network, called the online stochastic distributed averaging problem. We design a dual-based method for this distributed consensus problem with Polyak--Ruppert averaging and analyze its behavior. We show that the proposed algorithm attains an accelerated deterministic error depending optimally on the condition number of the network, and also that it has an order-optimal stochastic error. This improves on the guarantees of state-of-the-art distributed stochastic optimization algorithms when specialized to this setting, and yields -- among other things -- corollaries for decentralized policy evaluation. Our proofs rely on explicitly studying the evolution of several relevant linear systems, and may be of independent interest. Numerical experiments are provided, which validate our theoretical results and demonstrate that our approach outperforms existing methods in finite-sample scenarios on several natural network topologies.",
        "published": "2022-07-23T05:58:13Z",
        "link": "http://arxiv.org/abs/2207.11425v2",
        "categories": [
            "math.OC",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Distributed Projection-free Algorithm for Constrained Aggregative   Optimization",
        "authors": [
            "Tongyu Wang",
            "Peng Yi"
        ],
        "summary": "In this paper, we focus on solving a distributed convex aggregative optimization problem in a network, where each agent has its own cost function which depends not only on its own decision variables but also on the aggregated function of all agents' decision variables. The decision variable is constrained within a feasible set. In order to minimize the sum of the cost functions when each agent only knows its local cost function, we propose a distributed Frank-Wolfe algorithm based on gradient tracking for the aggregative optimization problem where each node maintains two estimates, namely an estimate of the sum of agents' decision variable and an estimate of the gradient of global function. The algorithm is projection-free, but only involves solving a linear optimization to get a search direction at each step. We show the convergence of the proposed algorithm for convex and smooth objective functions over a time-varying network. Finally, we demonstrate the convergence and computational efficiency of the proposed algorithm via numerical simulations.",
        "published": "2022-07-25T03:13:28Z",
        "link": "http://arxiv.org/abs/2207.11885v1",
        "categories": [
            "math.OC",
            "cs.MA"
        ]
    },
    {
        "title": "Multi-Scale Asset Distribution Model for Dynamic Environments",
        "authors": [
            "Payam Zahadat",
            "Ada Diaconescu"
        ],
        "summary": "In many self-organising systems the ability to extract necessary resources from the external environment is essential to the system's growth and survival. Examples include the extraction of sunlight and nutrients in organic plants, of monetary income in business organisations and of mobile robots in swarm intelligence actions. When operating within competitive, ever-changing environments, such systems must distribute their internal assets wisely so as to improve and adapt their ability to extract available resources. As the system size increases, the asset-distribution process often gets organised around a multi-scale control topology. This topology may be static (fixed) or dynamic (enabling growth and structural adaptation) depending on the system's internal constraints and adaptive mechanisms. In this paper, we expand on a plant-inspired asset-distribution model and introduce a more general multi-scale model applicable across a wider range of natural and artificial system domains. We study the impact that the topology of the multi-scale control process has upon the system's ability to self-adapt asset distribution when resource availability changes within the environment. Results show how different topological characteristics and different competition levels between system branches impact overall system profitability, adaptation delays and disturbances when environmental changes occur. These findings provide a basis for system designers to select the most suitable topology and configuration for their particular application and execution environment.",
        "published": "2022-07-25T11:14:49Z",
        "link": "http://arxiv.org/abs/2207.12063v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.SI",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Stable Parallel Training of Wasserstein Conditional Generative   Adversarial Neural Networks",
        "authors": [
            "Massimiliano Lupo Pasini",
            "Junqi Yin"
        ],
        "summary": "We propose a stable, parallel approach to train Wasserstein Conditional Generative Adversarial Neural Networks (W-CGANs) under the constraint of a fixed computational budget. Differently from previous distributed GANs training techniques, our approach avoids inter-process communications, reduces the risk of mode collapse and enhances scalability by using multiple generators, each one of them concurrently trained on a single data label. The use of the Wasserstein metric also reduces the risk of cycling by stabilizing the training of each generator. We illustrate the approach on the CIFAR10, CIFAR100, and ImageNet1k datasets, three standard benchmark image datasets, maintaining the original resolution of the images for each dataset. Performance is assessed in terms of scalability and final accuracy within a limited fixed computational time and computational resources. To measure accuracy, we use the inception score, the Frechet inception distance, and image quality. An improvement in inception score and Frechet inception distance is shown in comparison to previous results obtained by performing the parallel approach on deep convolutional conditional generative adversarial neural networks (DC-CGANs) as well as an improvement of image quality of the new images created by the GANs approach. Weak scaling is attained on both datasets using up to 2,000 NVIDIA V100 GPUs on the OLCF supercomputer Summit.",
        "published": "2022-07-25T16:30:40Z",
        "link": "http://arxiv.org/abs/2207.12315v1",
        "categories": [
            "cs.AI",
            "cs.CV",
            "cs.DC",
            "cs.LG",
            "cs.MA",
            "68T01, 68T10, 68M14, 65Y05, 65Y10",
            "I.2.0; I.2.11; C.1.4; C.2.4"
        ]
    },
    {
        "title": "Optimizing Empty Container Repositioning and Fleet Deployment via   Configurable Semi-POMDPs",
        "authors": [
            "Riccardo Poiani",
            "Ciprian Stirbu",
            "Alberto Maria Metelli",
            "Marcello Restelli"
        ],
        "summary": "With the continuous growth of the global economy and markets, resource imbalance has risen to be one of the central issues in real logistic scenarios. In marine transportation, this trade imbalance leads to Empty Container Repositioning (ECR) problems. Once the freight has been delivered from an exporting country to an importing one, the laden will turn into empty containers that need to be repositioned to satisfy new goods requests in exporting countries. In such problems, the performance that any cooperative repositioning policy can achieve strictly depends on the routes that vessels will follow (i.e., fleet deployment). Historically, Operation Research (OR) approaches were proposed to jointly optimize the repositioning policy along with the fleet of vessels. However, the stochasticity of future supply and demand of containers, together with black-box and non-linear constraints that are present within the environment, make these approaches unsuitable for these scenarios. In this paper, we introduce a novel framework, Configurable Semi-POMDPs, to model this type of problems. Furthermore, we provide a two-stage learning algorithm, \"Configure & Conquer\" (CC), that first configures the environment by finding an approximation of the optimal fleet deployment strategy, and then \"conquers\" it by learning an ECR policy in this tuned environmental setting. We validate our approach in large and real-world instances of the problem. Our experiments highlight that CC avoids the pitfalls of OR methods and that it is successful at optimizing both the ECR policy and the fleet of vessels, leading to superior performance in world trade environments.",
        "published": "2022-07-25T20:13:44Z",
        "link": "http://arxiv.org/abs/2207.12509v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "A Geometric Approach to Passive Localisation",
        "authors": [
            "Theofilos Triommatis",
            "Igor Potapov",
            "Gareth Rees",
            "Jason F. Ralph"
        ],
        "summary": "In this paper, we present a geometric framework for the passive localisation of static emitters. The objective is to localise the position of the emitters in a given area by centralised coordination of mobile passive sensors. This framework uses only the geometry of the problem to minimise the maximal bounds of the emitters' locations without using a belief or probability distribution. This geometric approach provides effective boundaries on the emitters' position. It can also be useful in evaluating different decision-making strategies for coordinating mobile passive sensors and complementing statistical methods during the initialisation process. The effectiveness of the geometric approach is shown by designing and evaluating a greedy decision-making strategy, where a sensor selects its future position by minimising the maximum uncertainty on its next measurement using one of the global objective functions. Finally, we analyse and discuss the emergent behaviour and robustness of the proposed algorithms.",
        "published": "2022-07-27T09:29:03Z",
        "link": "http://arxiv.org/abs/2207.13396v1",
        "categories": [
            "cs.MA",
            "cs.CG",
            "math.DS"
        ]
    },
    {
        "title": "Adapting the Exploration-Exploitation Balance in Heterogeneous Swarms:   Tracking Evasive Targets",
        "authors": [
            "Hian Lee Kwa",
            "Victor Babineau",
            "Julien Philippot",
            "Roland Bouffanais"
        ],
        "summary": "There has been growing interest in the use of multi-robot systems in various tasks and scenarios. The main attractiveness of such systems is their flexibility, robustness, and scalability. An often overlooked yet promising feature is system modularity, which offers the possibility to harness agent specialization, while also enabling system-level upgrades. However, altering the agents' capacities can change the exploration-exploitation balance required to maximize the system's performance. Here, we study the effect of a swarm's heterogeneity on its exploration-exploitation balance while tracking multiple fast-moving evasive targets under the Cooperative Multi-Robot Observation of Multiple Moving Targets framework. To this end, we use a decentralized search and tracking strategy with adjustable levels of exploration and exploitation. By indirectly tuning the balance, we first confirm the presence of an optimal balance between these two key competing actions. Next, by substituting slower moving agents with faster ones, we show that the system exhibits a performance improvement without any modifications to the original strategy. In addition, owing to the additional amount of exploitation carried out by the faster agents, we demonstrate that a heterogeneous system's performance can be further improved by reducing an agent's level of connectivity, to favor the conduct of exploratory actions. Furthermore, in studying the influence of the density of swarming agents, we show that the addition of faster agents can counterbalance a reduction in the overall number of agents while maintaining the level of tracking performance. Finally, we explore the challenges of using differentiated strategies to take advantage of the heterogeneous nature of the swarm.",
        "published": "2022-07-27T13:50:02Z",
        "link": "http://arxiv.org/abs/2207.13523v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "FleetPy: A Modular Open-Source Simulation Tool for Mobility On-Demand   Services",
        "authors": [
            "Roman Engelhardt",
            "Florian Dandl",
            "Arslan-Ali Syed",
            "Yunfei Zhang",
            "Fabian Fehn",
            "Fynn Wolf",
            "Klaus Bogenberger"
        ],
        "summary": "The market share of mobility on-demand (MoD) services strongly increased in recent years and is expected to rise even higher once vehicle automation is fully available. These services might reduce space consumption in cities as fewer parking spaces are required if private vehicle trips are replaced. If rides are shared additionally, occupancy related traffic efficiency is increased. Simulations help to identify the actual impact of MoD on a traffic system, evaluate new control algorithms for improved service efficiency and develop guidelines for regulatory measures. This paper presents the open-source agent-based simulation framework FleetPy. FleetPy (written in the programming language \"Python\") is explicitly developed to model MoD services in a high level of detail. It specially focuses on the modeling of interactions of users with operators while its flexibility allows the integration and embedding of multiple operators in the overall transportation system. Its modular structure ensures the transferabillity of previously developed elements and the selection of an appropriate level of modeling detail. This paper compares existing simulation frameworks for MoD services and highlights exclusive features of FleetPy. The upper level simulation flows are presented, followed by required input data for the simulation and the output data FleetPy produces. Additionally, the modules within FleetPy and high-level descriptions of current implementations are provided. Finally, an example showcase for Manhattan, NYC provides insights into the impacts of different modules for simulation flow, fleet optimization, traveler behavior and network representation.",
        "published": "2022-07-28T17:30:35Z",
        "link": "http://arxiv.org/abs/2207.14246v1",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Entangled Rendezvous: A Possible Application of Bell Non-Locality For   Mobile Agents on Networks",
        "authors": [
            "Piotr Mironowicz"
        ],
        "summary": "Rendezvous is an old problem of assuring that two or more parties, initially separated, not knowing the position of each other, and not allowed to communicate, meet without pre-agreement on the meeting point. This problem has been extensively studied in classical computer science and has vivid importance to modern applications like coordinating a fleet of drones in an enemy's territory. Quantum non-locality, like Bell inequality violation, has shown that in many cases quantum entanglement allows for improved coordination of two separated parties compared to classical sources. The non-signaling correlations in many cases even strengthened such phenomena. In this work, we analyze, how Bell non-locality can be used by asymmetric location-aware agents trying to rendezvous on a finite network with a limited number of steps. We provide the optimal solution to this problem for both agents using quantum resources, and agents with only ``classical'' computing power. Our results show that for cubic graphs and cycles it is possible to gain an advantage by allowing the agents to use assistance of entangled quantum states.",
        "published": "2022-07-28T23:04:48Z",
        "link": "http://arxiv.org/abs/2207.14404v1",
        "categories": [
            "quant-ph",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Distributed control for geometric pattern formation of large-scale   multirobot systems",
        "authors": [
            "Andrea Giusti",
            "Gian Carlo Maffettone",
            "Davide Fiore",
            "Marco Coraggio",
            "Mario di Bernardo"
        ],
        "summary": "Geometric pattern formation is crucial in many tasks involving large-scale multi-agent systems. Examples include mobile agents performing surveillance, swarm of drones or robots, or smart transportation systems. Currently, most control strategies proposed to achieve pattern formation in network systems either show good performance but require expensive sensors and communication devices, or have lesser sensor requirements but behave more poorly. Also, they often require certain prescribed structural interconnections between the agents (e.g., regular lattices, all-to-all networks etc). In this paper, we provide a distributed displacement-based control law that allows large group of agents to achieve triangular and square lattices, with low sensor requirements and without needing communication between the agents. Also, a simple, yet powerful, adaptation law is proposed to automatically tune the control gains in order to reduce the design effort, while improving robustness and flexibility. We show the validity and robustness of our approach via numerical simulations and experiments, comparing it with other approaches from the existing literature.",
        "published": "2022-07-29T09:28:40Z",
        "link": "http://arxiv.org/abs/2207.14567v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Multi-Agent Reinforcement Learning for Long-Term Network Resource   Allocation through Auction: a V2X Application",
        "authors": [
            "Jing Tan",
            "Ramin Khalili",
            "Holger Karl",
            "Artur Hecker"
        ],
        "summary": "We formulate offloading of computational tasks from a dynamic group of mobile agents (e.g., cars) as decentralized decision making among autonomous agents. We design an interaction mechanism that incentivizes such agents to align private and system goals by balancing between competition and cooperation. In the static case, the mechanism provably has Nash equilibria with optimal resource allocation. In a dynamic environment, this mechanism's requirement of complete information is impossible to achieve. For such environments, we propose a novel multi-agent online learning algorithm that learns with partial, delayed and noisy state information, thus greatly reducing information need. Our algorithm is also capable of learning from long-term and sparse reward signals with varying delay. Empirical results from the simulation of a V2X application confirm that through learning, agents with the learning algorithm significantly improve both system and individual performance, reducing up to 30% of offloading failure rate, communication overhead and load variation, increasing computation resource utilization and fairness. Results also confirm the algorithm's good convergence and generalization property in different environments.",
        "published": "2022-07-29T10:29:06Z",
        "link": "http://arxiv.org/abs/2208.04237v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Perspectives on the System-level Design of a Safe Autonomous Driving   Stack",
        "authors": [
            "Majd Hawasly",
            "Jonathan Sadeghi",
            "Morris Antonello",
            "Stefano V. Albrecht",
            "John Redford",
            "Subramanian Ramamoorthy"
        ],
        "summary": "Achieving safe and robust autonomy is the key bottleneck on the path towards broader adoption of autonomous vehicles technology. This motivates going beyond extrinsic metrics such as miles between disengagement, and calls for approaches that embody safety by design. In this paper, we address some aspects of this challenge, with emphasis on issues of motion planning and prediction. We do this through description of novel approaches taken to solving selected sub-problems within an autonomous driving stack, in the process introducing the design philosophy being adopted within Five. This includes safe-by-design planning, interpretable as well as verifiable prediction, and modelling of perception errors to enable effective sim-to-real and real-to-sim transfer within the testing pipeline of a realistic autonomous system.",
        "published": "2022-07-29T22:43:44Z",
        "link": "http://arxiv.org/abs/2208.00096v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Unified Automatic Control of Vehicular Systems with Reinforcement   Learning",
        "authors": [
            "Zhongxia Yan",
            "Abdul Rahman Kreidieh",
            "Eugene Vinitsky",
            "Alexandre M. Bayen",
            "Cathy Wu"
        ],
        "summary": "Emerging vehicular systems with increasing proportions of automated components present opportunities for optimal control to mitigate congestion and increase efficiency. There has been a recent interest in applying deep reinforcement learning (DRL) to these nonlinear dynamical systems for the automatic design of effective control strategies. Despite conceptual advantages of DRL being model-free, studies typically nonetheless rely on training setups that are painstakingly specialized to specific vehicular systems. This is a key challenge to efficient analysis of diverse vehicular and mobility systems. To this end, this article contributes a streamlined methodology for vehicular microsimulation and discovers high performance control strategies with minimal manual design. A variable-agent, multi-task approach is presented for optimization of vehicular Partially Observed Markov Decision Processes. The methodology is experimentally validated on mixed autonomy traffic systems, where fractions of vehicles are automated; empirical improvement, typically 15-60% over a human driving baseline, is observed in all configurations of six diverse open or closed traffic systems. The study reveals numerous emergent behaviors resembling wave mitigation, traffic signaling, and ramp metering. Finally, the emergent behaviors are analyzed to produce interpretable control strategies, which are validated against the learned control strategies.",
        "published": "2022-07-30T16:23:45Z",
        "link": "http://arxiv.org/abs/2208.00268v1",
        "categories": [
            "cs.AI",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "e-Genia3 An AgentSpeak extension for empathic agents",
        "authors": [
            "Joaquin Taverner",
            "Emilio Vivancos",
            "Vicente Botti"
        ],
        "summary": "In this paper, we present e-Genia3 an extension of AgentSpeak to provide support to the development of empathic agents. The new extension modifies the agent's reasoning processes to select plans according to the analyzed event and the affective state and personality of the agent. In addition, our proposal allows a software agent to simulate the distinction between self and other agents through two different event appraisal processes: the empathic appraisal process, for eliciting emotions as a response to other agents emotions, and the regular affective appraisal process for other non-empathic affective events. The empathic regulation process adapts the elicited empathic emotion based on intrapersonal factors (e.g., the agent's personality and affective memory) and interpersonal characteristics of the agent (e.g., the affective link between the agents). The use of a memory of past events and their corresponding elicited emotions allows the maintaining of an affective link to support long-term empathic interaction between agents.",
        "published": "2022-08-01T10:53:25Z",
        "link": "http://arxiv.org/abs/2208.00737v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.PL"
        ]
    },
    {
        "title": "See What the Robot Can't See: Learning Cooperative Perception for Visual   Navigation",
        "authors": [
            "Jan Blumenkamp",
            "Qingbiao Li",
            "Binyu Wang",
            "Zhe Liu",
            "Amanda Prorok"
        ],
        "summary": "We consider the problem of navigating a mobile robot towards a target in an unknown environment that is endowed with visual sensors, where neither the robot nor the sensors have access to global positioning information and only use first-person-view images. In order to overcome the need for positioning, we train the sensors to encode and communicate relevant viewpoint information to the mobile robot, whose objective it is to use this information to navigate to the target along the shortest path. We overcome the challenge of enabling all the sensors (even those that cannot directly see the target) to predict the direction along the shortest path to the target by implementing a neighborhood-based feature aggregation module using a Graph Neural Network (GNN) architecture. In our experiments, we first demonstrate generalizability to previously unseen environments with various sensor layouts. Our results show that by using communication between the sensors and the robot, we achieve up to 2.0x improvement in SPL (Success weighted by Path Length) when compared to a communication-free baseline. This is done without requiring a global map, positioning data, nor pre-calibration of the sensor network. Second, we perform a zero-shot transfer of our model from simulation to the real world. Laboratory experiments demonstrate the feasibility of our approach in various cluttered environments. Finally, we showcase examples of successful navigation to the target while both the sensor network layout as well as obstacles are dynamically reconfigured as the robot navigates. We provide a video demo, the dataset, trained models, and source code.   https://www.youtube.com/watch?v=kcmr6RUgucw https://github.com/proroklab/sensor-guided-visual-nav",
        "published": "2022-08-01T11:37:01Z",
        "link": "http://arxiv.org/abs/2208.00759v5",
        "categories": [
            "cs.RO",
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Short-term Load Forecasting with Distributed Long Short-Term Memory",
        "authors": [
            "Yi Dong",
            "Yang Chen",
            "Xingyu Zhao",
            "Xiaowei Huang"
        ],
        "summary": "With the employment of smart meters, massive data on consumer behaviour can be collected by retailers. From the collected data, the retailers may obtain the household profile information and implement demand response. While retailers prefer to acquire a model as accurate as possible among different customers, there are two major challenges. First, different retailers in the retail market do not share their consumer's electricity consumption data as these data are regarded as their assets, which has led to the problem of data island. Second, the electricity load data are highly heterogeneous since different retailers may serve various consumers. To this end, a fully distributed short-term load forecasting framework based on a consensus algorithm and Long Short-Term Memory (LSTM) is proposed, which may protect the customer's privacy and satisfy the accurate load forecasting requirement. Specifically, a fully distributed learning framework is exploited for distributed training, and a consensus technique is applied to meet confidential privacy. Case studies show that the proposed method has comparable performance with centralised methods regarding the accuracy, but the proposed method shows advantages in training speed and data privacy.",
        "published": "2022-08-01T21:40:16Z",
        "link": "http://arxiv.org/abs/2208.01147v2",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Optimal and Bounded-Suboptimal Multi-Goal Task Assignment and Path   Finding",
        "authors": [
            "Xinyi Zhong",
            "Jiaoyang Li",
            "Sven Koenig",
            "Hang Ma"
        ],
        "summary": "We formalize and study the multi-goal task assignment and path finding (MG-TAPF) problem from theoretical and algorithmic perspectives. The MG-TAPF problem is to compute an assignment of tasks to agents, where each task consists of a sequence of goal locations, and collision-free paths for the agents that visit all goal locations of their assigned tasks in sequence. Theoretically, we prove that the MG-TAPF problem is NP-hard to solve optimally. We present algorithms that build upon algorithmic techniques for the multi-agent path finding problem and solve the MG-TAPF problem optimally and bounded-suboptimally. We experimentally compare these algorithms on a variety of different benchmark domains.",
        "published": "2022-08-02T03:17:29Z",
        "link": "http://arxiv.org/abs/2208.01222v1",
        "categories": [
            "cs.AI",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Multi-Goal Multi-Agent Pickup and Delivery",
        "authors": [
            "Qinghong Xu",
            "Jiaoyang Li",
            "Sven Koenig",
            "Hang Ma"
        ],
        "summary": "In this work, we consider the Multi-Agent Pickup-and-Delivery (MAPD) problem, where agents constantly engage with new tasks and need to plan collision-free paths to execute them. To execute a task, an agent needs to visit a pair of goal locations, consisting of a pickup location and a delivery location. We propose two variants of an algorithm that assigns a sequence of tasks to each agent using the anytime algorithm Large Neighborhood Search (LNS) and plans paths using the Multi-Agent Path Finding (MAPF) algorithm Priority-Based Search (PBS). LNS-PBS is complete for well-formed MAPD instances, a realistic subclass of MAPD instances, and empirically more effective than the existing complete MAPD algorithm CENTRAL. LNS-wPBS provides no completeness guarantee but is empirically more efficient and stable than LNS-PBS. It scales to thousands of agents and thousands of tasks in a large warehouse and is empirically more effective than the existing scalable MAPD algorithm HBH+MLA*. LNS-PBS and LNS-wPBS also apply to a more general variant of MAPD, namely the Multi-Goal MAPD (MG-MAPD) problem, where tasks can have different numbers of goal locations.",
        "published": "2022-08-02T03:20:59Z",
        "link": "http://arxiv.org/abs/2208.01223v1",
        "categories": [
            "cs.AI",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Evaluating Inter-Operator Cooperation Scenarios to Save Radio Access   Network Energy",
        "authors": [
            "Xavier Marjou",
            "Tangui Le Gléau",
            "Vincent Messié",
            "Benoit Radier",
            "Tayeb Lemlouma",
            "Gaël Fromentoux"
        ],
        "summary": "Reducing energy consumption is crucial to reduce the human debt's with regard to our planet. Therefore most companies try to reduce their energetic consumption while taking care to preserve the service delivered to their customers. To do so, a service provider (SP) typically downscale or shutdown part of its infrastructure in periods of low-activity where only few customers need the service. However an SP still needs to maintain part of its infrastructure \"on\", which still requires significant energy. For example a mobile national operator (MNO) needs to maintain most of its radio access network (RAN) active. Could an SP do better by cooperating with other SPs who would temporarily support its users, thus allowing it to temporarily shut down its infrastructure, and then reciprocate during another low-activity period? To answer this question, we investigated a novel collaboration framework based on multi-agent reinforcement learning (MARL) allowing negotiations between SPs as well as trustful reports from a distributed ledger technology (DLT) to evaluate the amount of energy being saved. We leveraged it to experiment three different sets of rules (free, recommended, or imposed) regulating the negotiation between multiple SPs (3, 4, 8, or 10). With respect to four cooperation metrics (efficiency, safety, incentive-compatibility, and fairness), the simulations showed that the imposed set of rules proved to be the best mode.",
        "published": "2022-08-02T07:14:28Z",
        "link": "http://arxiv.org/abs/2208.01285v1",
        "categories": [
            "cs.MA",
            "cs.GT"
        ]
    },
    {
        "title": "A Model for Multi-Agent Heterogeneous Interaction Problems",
        "authors": [
            "Christopher D. Hsu",
            "Mulugeta A. Haile",
            "Pratik Chaudhari"
        ],
        "summary": "We introduce a model for multi-agent interaction problems to understand how a heterogeneous team of agents should organize its resources to tackle a heterogeneous team of attackers. This model is inspired by how the human immune system tackles a diverse set of pathogens. The key property of this model is a ``cross-reactivity'' kernel which enables a particular defender type to respond strongly to some attacker types but weakly to a few different types of attackers. We show how due to such cross-reactivity, the defender team can optimally counteract a heterogeneous attacker team using very few types of defender agents, and thereby minimize its resources. We study this model in different settings to characterize a set of guiding principles for control problems with heterogeneous teams of agents, e.g., sensitivity of the harm to sub-optimal defender distributions, and competition between defenders gives near-optimal behavior using decentralized computation of the control. We also compare this model with existing approaches including reinforcement-learned policies, perimeter defense, and coverage control.",
        "published": "2022-08-02T13:06:47Z",
        "link": "http://arxiv.org/abs/2208.01430v4",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Heterogeneous-Agent Mirror Learning: A Continuum of Solutions to   Cooperative MARL",
        "authors": [
            "Jakub Grudzien Kuba",
            "Xidong Feng",
            "Shiyao Ding",
            "Hao Dong",
            "Jun Wang",
            "Yaodong Yang"
        ],
        "summary": "The necessity for cooperation among intelligent machines has popularised cooperative multi-agent reinforcement learning (MARL) in the artificial intelligence (AI) research community. However, many research endeavors have been focused on developing practical MARL algorithms whose effectiveness has been studied only empirically, thereby lacking theoretical guarantees. As recent studies have revealed, MARL methods often achieve performance that is unstable in terms of reward monotonicity or suboptimal at convergence. To resolve these issues, in this paper, we introduce a novel framework named Heterogeneous-Agent Mirror Learning (HAML) that provides a general template for MARL algorithmic designs. We prove that algorithms derived from the HAML template satisfy the desired properties of the monotonic improvement of the joint reward and the convergence to Nash equilibrium. We verify the practicality of HAML by proving that the current state-of-the-art cooperative MARL algorithms, HATRPO and HAPPO, are in fact HAML instances. Next, as a natural outcome of our theory, we propose HAML extensions of two well-known RL algorithms, HAA2C (for A2C) and HADDPG (for DDPG), and demonstrate their effectiveness against strong baselines on StarCraftII and Multi-Agent MuJoCo tasks.",
        "published": "2022-08-02T18:16:42Z",
        "link": "http://arxiv.org/abs/2208.01682v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "CAPD: A Context-Aware, Policy-Driven Framework for Secure and Resilient   IoBT Operations",
        "authors": [
            "Sai Sree Laya Chukkapalli",
            "Anupam Joshi",
            "Tim Finin",
            "Robert F. Erbacher"
        ],
        "summary": "The Internet of Battlefield Things (IoBT) will advance the operational effectiveness of infantry units. However, this requires autonomous assets such as sensors, drones, combat equipment, and uncrewed vehicles to collaborate, securely share information, and be resilient to adversary attacks in contested multi-domain operations. CAPD addresses this problem by providing a context-aware, policy-driven framework supporting data and knowledge exchange among autonomous entities in a battlespace. We propose an IoBT ontology that facilitates controlled information sharing to enable semantic interoperability between systems. Its key contributions include providing a knowledge graph with a shared semantic schema, integration with background knowledge, efficient mechanisms for enforcing data consistency and drawing inferences, and supporting attribute-based access control. The sensors in the IoBT provide data that create populated knowledge graphs based on the ontology. This paper describes using CAPD to detect and mitigate adversary actions. CAPD enables situational awareness using reasoning over the sensed data and SPARQL queries. For example, adversaries can cause sensor failure or hijacking and disrupt the tactical networks to degrade video surveillance. In such instances, CAPD uses an ontology-based reasoner to see how alternative approaches can still support the mission. Depending on bandwidth availability, the reasoner initiates the creation of a reduced frame rate grayscale video by active transcoding or transmits only still images. This ability to reason over the mission sensed environment and attack context permits the autonomous IoBT system to exhibit resilience in contested conditions.",
        "published": "2022-08-02T19:27:51Z",
        "link": "http://arxiv.org/abs/2208.01703v1",
        "categories": [
            "cs.CR",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Deep Reinforcement Learning for Multi-Agent Interaction",
        "authors": [
            "Ibrahim H. Ahmed",
            "Cillian Brewitt",
            "Ignacio Carlucho",
            "Filippos Christianos",
            "Mhairi Dunion",
            "Elliot Fosong",
            "Samuel Garcin",
            "Shangmin Guo",
            "Balint Gyevnar",
            "Trevor McInroe",
            "Georgios Papoudakis",
            "Arrasy Rahman",
            "Lukas Schäfer",
            "Massimiliano Tamborski",
            "Giuseppe Vecchio",
            "Cheng Wang",
            "Stefano V. Albrecht"
        ],
        "summary": "The development of autonomous agents which can interact with other agents to accomplish a given task is a core area of research in artificial intelligence and machine learning. Towards this goal, the Autonomous Agents Research Group develops novel machine learning algorithms for autonomous systems control, with a specific focus on deep reinforcement learning and multi-agent reinforcement learning. Research problems include scalable learning of coordinated agent policies and inter-agent communication; reasoning about the behaviours, goals, and composition of other agents from limited observations; and sample-efficient learning based on intrinsic motivation, curriculum learning, causal inference, and representation learning. This article provides a broad overview of the ongoing research portfolio of the group and discusses open problems for future directions.",
        "published": "2022-08-02T21:55:56Z",
        "link": "http://arxiv.org/abs/2208.01769v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Decentralized Learning With Limited Communications for Multi-robot   Coverage of Unknown Spatial Fields",
        "authors": [
            "Kensuke Nakamura",
            "María Santos",
            "Naomi Ehrich Leonard"
        ],
        "summary": "This paper presents an algorithm for a team of mobile robots to simultaneously learn a spatial field over a domain and spatially distribute themselves to optimally cover it. Drawing from previous approaches that estimate the spatial field through a centralized Gaussian process, this work leverages the spatial structure of the coverage problem and presents a decentralized strategy where samples are aggregated locally by establishing communications through the boundaries of a Voronoi partition. We present an algorithm whereby each robot runs a local Gaussian process calculated from its own measurements and those provided by its Voronoi neighbors, which are incorporated into the individual robot's Gaussian process only if they provide sufficiently novel information. The performance of the algorithm is evaluated in simulation and compared with centralized approaches.",
        "published": "2022-08-03T00:59:22Z",
        "link": "http://arxiv.org/abs/2208.01800v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Finite-time Motion Planning of Multi-agent Systems with Collision   Avoidance",
        "authors": [
            "Yilei Jiang",
            "Dongkun Han"
        ],
        "summary": "Finite-time motion planning with collision avoidance is a challenging issue in multi-agent systems. This paper proposes a novel distributed controller based on a new Lyapunov barrier function which guarantees finite-time stability for multi-agent systems without collisions. First, the problem of finite-time motion planning of multi-agent systems is formulated. Then, a novel finite-time distributed controller is developed based on a Lyapunov barrier function. Finally, numerical simulations demonstrate the effectiveness of proposed method.",
        "published": "2022-08-03T12:43:24Z",
        "link": "http://arxiv.org/abs/2208.02020v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Efficiently Computing Nash Equilibria in Adversarial Team Markov Games",
        "authors": [
            "Fivos Kalogiannis",
            "Ioannis Anagnostides",
            "Ioannis Panageas",
            "Emmanouil-Vasileios Vlatakis-Gkaragkounis",
            "Vaggos Chatziafratis",
            "Stelios Stavroulakis"
        ],
        "summary": "Computing Nash equilibrium policies is a central problem in multi-agent reinforcement learning that has received extensive attention both in theory and in practice. However, provable guarantees have been thus far either limited to fully competitive or cooperative scenarios or impose strong assumptions that are difficult to meet in most practical applications. In this work, we depart from those prior results by investigating infinite-horizon \\emph{adversarial team Markov games}, a natural and well-motivated class of games in which a team of identically-interested players -- in the absence of any explicit coordination or communication -- is competing against an adversarial player. This setting allows for a unifying treatment of zero-sum Markov games and Markov potential games, and serves as a step to model more realistic strategic interactions that feature both competing and cooperative interests. Our main contribution is the first algorithm for computing stationary $\\epsilon$-approximate Nash equilibria in adversarial team Markov games with computational complexity that is polynomial in all the natural parameters of the game, as well as $1/\\epsilon$. The proposed algorithm is particularly natural and practical, and it is based on performing independent policy gradient steps for each player in the team, in tandem with best responses from the side of the adversary; in turn, the policy for the adversary is then obtained by solving a carefully constructed linear program. Our analysis leverages non-standard techniques to establish the KKT optimality conditions for a nonlinear program with nonconvex constraints, thereby leading to a natural interpretation of the induced Lagrange multipliers. Along the way, we significantly extend an important characterization of optimal policies in adversarial (normal-form) team games due to Von Stengel and Koller (GEB `97).",
        "published": "2022-08-03T16:41:01Z",
        "link": "http://arxiv.org/abs/2208.02204v1",
        "categories": [
            "cs.GT",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Distributed Event-triggered Control of Networked Strict-feedback Systems   Via Intermittent State Feedback",
        "authors": [
            "Libei Sun",
            "Xiucai Huang",
            "Yongduan Song"
        ],
        "summary": "It poses technical difficulty to achieve stable tracking even for single mismatched nonlinear strict-feedback systems when intermittent state feedback is utilized. The underlying problem becomes even more complicated if such systems are networked with directed communication and state-triggering setting. In this work, we present a fully distributed neuroadaptive tracking control scheme for multiple agent systems in strict-feedback form using triggered state from the agent itself and the triggered states from the neighbor agents. To circumvent the non-differentiability of virtual controllers stemming from state-triggering, we first develop a distributed continuous control scheme under regular state feedback, upon which we construct the distributed event-triggered control scheme by replacing the states in the preceding scheme with the triggered ones. Several useful lemmas are introduced to allow the stability condition to be established with such replacement, ensuring that all the closed-loop signals are semi-globally uniformly ultimately bounded (SGUUB), with the output tracking error converging to a residual set around zero. Besides, with proper choices of the design parameters, the tracking performance in the mean square sense can be improved. Numerical simulation verifies the benefits and efficiency of the proposed method.",
        "published": "2022-08-04T02:46:57Z",
        "link": "http://arxiv.org/abs/2208.02415v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Transferable Multi-Agent Reinforcement Learning with Dynamic   Participating Agents",
        "authors": [
            "Xuting Tang",
            "Jia Xu",
            "Shusen Wang"
        ],
        "summary": "We study multi-agent reinforcement learning (MARL) with centralized training and decentralized execution. During the training, new agents may join, and existing agents may unexpectedly leave the training. In such situations, a standard deep MARL model must be trained again from scratch, which is very time-consuming. To tackle this problem, we propose a special network architecture with a few-shot learning algorithm that allows the number of agents to vary during centralized training. In particular, when a new agent joins the centralized training, our few-shot learning algorithm trains its policy network and value network using a small number of samples; when an agent leaves the training, the training process of the remaining agents is not affected. Our experiments show that using the proposed network architecture and algorithm, model adaptation when new agents join can be 100+ times faster than the baseline. Our work is applicable to any setting, including cooperative, competitive, and mixed.",
        "published": "2022-08-04T03:16:42Z",
        "link": "http://arxiv.org/abs/2208.02424v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Modelling the Rise and Fall of Two-Sided Mobility Markets with   Microsimulation",
        "authors": [
            "Farnoud Ghasemi",
            "Rafał Kucharski"
        ],
        "summary": "In this paper, we propose a novel modelling framework to reproduce the market entry strategies for two-sided mobility platforms. In the MaaSSim agent-based simulator, we develop a co-evolutionary model to represent day-to-day dynamics of the two-sided mobility market with agents making rational decisions to maximize their perceived utility. Participation probability of agents depends on utility, composed of: experience, word of mouth and marketing components adjusted by agents every day with the novel S-shaped formulas - better suited (in our opinion) to reproduce market entry dynamics than previous approaches. With such a rich representation, we can realistically model a variety of market entry strategies and create significant network effects to reproduce the rise and fall of two-side mobility platforms. To illustrate model capabilities, we simulate a 400-day evolution of 200 drivers and 2000 travelers on a road-network of Amsterdam. We design a six-stage market entry strategy with consecutive: kick-off, discount, launch, growth, maturity and greed stages. After 25 days the platform offers discounts, yet it starts gaining market share only when the marketing campaign launches at day 50. Campaign finishes after 50 days, which does not stop the growth, now fueled mainly with a positive word of mouth effect and experiences. The platform ends discounts after 200 days and reaches the steady maturity period, after which its greedy strategy leads to collapse of its market share and profit. All above simulated with a single behavioral model, which well reproduces how agents of both sides adapts to platform actions.",
        "published": "2022-08-04T07:07:53Z",
        "link": "http://arxiv.org/abs/2208.02496v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Learning Interaction Variables and Kernels from Observations of   Agent-Based Systems",
        "authors": [
            "Jinchao Feng",
            "Mauro Maggioni",
            "Patrick Martin",
            "Ming Zhong"
        ],
        "summary": "Dynamical systems across many disciplines are modeled as interacting particles or agents, with interaction rules that depend on a very small number of variables (e.g. pairwise distances, pairwise differences of phases, etc...), functions of the state of pairs of agents. Yet, these interaction rules can generate self-organized dynamics, with complex emergent behaviors (clustering, flocking, swarming, etc.). We propose a learning technique that, given observations of states and velocities along trajectories of the agents, yields both the variables upon which the interaction kernel depends and the interaction kernel itself, in a nonparametric fashion. This yields an effective dimension reduction which avoids the curse of dimensionality from the high-dimensional observation data (states and velocities of all the agents). We demonstrate the learning capability of our method to a variety of first-order interacting systems.",
        "published": "2022-08-04T16:31:01Z",
        "link": "http://arxiv.org/abs/2208.02758v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "cs.NA",
            "math.DS",
            "math.NA"
        ]
    },
    {
        "title": "Nonstationary Continuum-Armed Bandit Strategies for Automated Trading in   a Simulated Financial Market",
        "authors": [
            "Bingde Liu",
            "John Cartlidge"
        ],
        "summary": "We approach the problem of designing an automated trading strategy that can consistently profit by adapting to changing market conditions. This challenge can be framed as a Nonstationary Continuum-Armed Bandit (NCAB) problem. To solve the NCAB problem, we propose PRBO, a novel trading algorithm that uses Bayesian optimization and a ``bandit-over-bandit'' framework to dynamically adjust strategy parameters in response to market conditions. We use Bristol Stock Exchange (BSE) to simulate financial markets containing heterogeneous populations of automated trading agents and compare PRBO with PRSH, a reference trading strategy that adapts strategy parameters through stochastic hill-climbing. Results show that PRBO generates significantly more profit than PRSH, despite having fewer hyperparameters to tune. The code for PRBO and performing experiments is available online open-source (https://github.com/HarmoniaLeo/PRZI-Bayesian-Optimisation).",
        "published": "2022-08-04T22:06:25Z",
        "link": "http://arxiv.org/abs/2208.02901v3",
        "categories": [
            "cs.MA",
            "cs.LG"
        ]
    },
    {
        "title": "Learning to Coordinate for a Worker-Station Multi-robot System in Planar   Coverage Tasks",
        "authors": [
            "Jingtao Tang",
            "Yuan Gao",
            "Tin Lun Lam"
        ],
        "summary": "For massive large-scale tasks, a multi-robot system (MRS) can effectively improve efficiency by utilizing each robot's different capabilities, mobility, and functionality. In this paper, we focus on the multi-robot coverage path planning (mCPP) problem in large-scale planar areas with random dynamic interferers in the environment, where the robots have limited resources. We introduce a worker-station MRS consisting of multiple workers with limited resources for actual work, and one station with enough resources for resource replenishment. We aim to solve the mCPP problem for the worker-station MRS by formulating it as a fully cooperative multi-agent reinforcement learning problem. Then we propose an end-to-end decentralized online planning method, which simultaneously solves coverage planning for workers and rendezvous planning for station. Our method manages to reduce the influence of random dynamic interferers on planning, while the robots can avoid collisions with them. We conduct simulation and real robot experiments, and the comparison results show that our method has competitive performance in solving the mCPP problem for worker-station MRS in metric of task finish time.",
        "published": "2022-08-05T05:36:42Z",
        "link": "http://arxiv.org/abs/2208.02993v2",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "A Cooperation Graph Approach for Multiagent Sparse Reward Reinforcement   Learning",
        "authors": [
            "Qingxu Fu",
            "Tenghai Qiu",
            "Zhiqiang Pu",
            "Jianqiang Yi",
            "Wanmai Yuan"
        ],
        "summary": "Multiagent reinforcement learning (MARL) can solve complex cooperative tasks. However, the efficiency of existing MARL methods relies heavily on well-defined reward functions. Multiagent tasks with sparse reward feedback are especially challenging not only because of the credit distribution problem, but also due to the low probability of obtaining positive reward feedback. In this paper, we design a graph network called Cooperation Graph (CG). The Cooperation Graph is the combination of two simple bipartite graphs, namely, the Agent Clustering subgraph (ACG) and the Cluster Designating subgraph (CDG). Next, based on this novel graph structure, we propose a Cooperation Graph Multiagent Reinforcement Learning (CG-MARL) algorithm, which can efficiently deal with the sparse reward problem in multiagent tasks. In CG-MARL, agents are directly controlled by the Cooperation Graph. And a policy neural network is trained to manipulate this Cooperation Graph, guiding agents to achieve cooperation in an implicit way. This hierarchical feature of CG-MARL provides space for customized cluster-actions, an extensible interface for introducing fundamental cooperation knowledge. In experiments, CG-MARL shows state-of-the-art performance in sparse reward multiagent benchmarks, including the anti-invasion interception task and the multi-cargo delivery task.",
        "published": "2022-08-05T06:32:16Z",
        "link": "http://arxiv.org/abs/2208.03002v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Agents Incorporating Identity and Dynamic Teams in Social Dilemmas",
        "authors": [
            "Kyle Tilbury",
            "Jesse Hoey"
        ],
        "summary": "We present our preliminary work on a multi-agent system involving the complex human phenomena of identity and dynamic teams. We outline our ongoing experimentation into understanding how these factors can eliminate some of the naive assumptions of current multi-agent approaches. These include a lack of complex heterogeneity between agents and unchanging team structures. We outline the human social psychological basis for identity, one's sense of self, and dynamic teams, the changing nature of human teams. We describe our application of these factors to a multi-agent system and our expectations for how they might improve the system's applicability to more complex problems, with specific relevance to ad hoc teamwork. We expect that the inclusion of more complex human processes, like identity and dynamic teams, will help with the eventual goal of having effective human-agent teams.",
        "published": "2022-08-05T17:30:37Z",
        "link": "http://arxiv.org/abs/2208.03293v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Maximum Correntropy Value Decomposition for Multi-agent Deep   Reinforcemen Learning",
        "authors": [
            "Kai Liu",
            "Tianxian Zhang",
            "Lingjiang Kong"
        ],
        "summary": "We explore value decomposition solutions for multi-agent deep reinforcement learning in the popular paradigm of centralized training with decentralized execution(CTDE). As the recognized best solution to CTDE, Weighted QMIX is cutting-edge on StarCraft Multi-agent Challenge (SMAC), with a weighting scheme implemented on QMIX to place more emphasis on the optimal joint actions. However, the fixed weight requires manual tuning according to the application scenarios, which painfully prevents Weighted QMIX from being used in broader engineering applications. In this paper, we first demonstrate the flaw of Weighted QMIX using an ordinary One-Step Matrix Game (OMG), that no matter how the weight is chosen, Weighted QMIX struggles to deal with non-monotonic value decomposition problems with a large variance of reward distributions. Then we characterize the problem of value decomposition as an Underfitting One-edged Robust Regression problem and make the first attempt to give a solution to the value decomposition problem from the perspective of information-theoretical learning. We introduce the Maximum Correntropy Criterion (MCC) as a cost function to dynamically adapt the weight to eliminate the effects of minimum in reward distributions. We simplify the implementation and propose a new algorithm called MCVD. A preliminary experiment conducted on OMG shows that MCVD could deal with non-monotonic value decomposition problems with a large tolerance of kernel bandwidth selection. Further experiments are carried out on Cooperative-Navigation and multiple SMAC scenarios, where MCVD exhibits unprecedented ease of implementation, broad applicability, and stability.",
        "published": "2022-08-07T08:06:21Z",
        "link": "http://arxiv.org/abs/2208.03663v1",
        "categories": [
            "cs.MA",
            "cs.LG"
        ]
    },
    {
        "title": "Emerging cooperation on the road by myopic local interactions",
        "authors": [
            "Dmitry Rabinovich",
            "Alfred M. Bruckstein"
        ],
        "summary": "We study a combinatorial problem inspired by the following scenario: fully autonomous vehicles drive on a multi-lane ($m \\geq 2$) road. Each vehicle heads to its own destination and is allowed to exit the road only through a single designated off-ramp lane. However, an individual vehicle has a severely limited memory and sensing capabilities, and, moreover, does not communicate with its peers. In this work we present a distributed algorithm that, nonetheless, allows vehicles to get to the desired lane without collisions and in timely manner.",
        "published": "2022-08-07T16:11:45Z",
        "link": "http://arxiv.org/abs/2208.03760v3",
        "categories": [
            "cs.MA",
            "cs.DC"
        ]
    },
    {
        "title": "Socially Intelligent Genetic Agents for the Emergence of Explicit Norms",
        "authors": [
            "Rishabh Agrawal",
            "Nirav Ajmeri",
            "Munindar P. Singh"
        ],
        "summary": "Norms help regulate a society. Norms may be explicit (represented in structured form) or implicit. We address the emergence of explicit norms by developing agents who provide and reason about explanations for norm violations in deciding sanctions and identifying alternative norms. These agents use a genetic algorithm to produce norms and reinforcement learning to learn the values of these norms. We find that applying explanations leads to norms that provide better cohesion and goal satisfaction for the agents. Our results are stable for societies with differing attitudes of generosity.",
        "published": "2022-08-07T18:48:48Z",
        "link": "http://arxiv.org/abs/2208.03789v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Recovering the Graph Underlying Networked Dynamical Systems under   Partial Observability: A Deep Learning Approach",
        "authors": [
            "Sérgio Machado",
            "Anirudh Sridhar",
            "Paulo Gil",
            "Jorge Henriques",
            "José M. F. Moura",
            "Augusto Santos"
        ],
        "summary": "We study the problem of graph structure identification, i.e., of recovering the graph of dependencies among time series. We model these time series data as components of the state of linear stochastic networked dynamical systems. We assume partial observability, where the state evolution of only a subset of nodes comprising the network is observed. We devise a new feature vector computed from the observed time series and prove that these features are linearly separable, i.e., there exists a hyperplane that separates the cluster of features associated with connected pairs of nodes from those associated with disconnected pairs. This renders the features amenable to train a variety of classifiers to perform causal inference. In particular, we use these features to train Convolutional Neural Networks (CNNs). The resulting causal inference mechanism outperforms state-of-the-art counterparts w.r.t. sample-complexity. The trained CNNs generalize well over structurally distinct networks (dense or sparse) and noise-level profiles. Remarkably, they also generalize well to real-world networks while trained over a synthetic network (realization of a random graph). Finally, the proposed method consistently reconstructs the graph in a pairwise manner, that is, by deciding if an edge or arrow is present or absent in each pair of nodes, from the corresponding time series of each pair. This fits the framework of large-scale systems, where observation or processing of all nodes in the network is prohibitive.",
        "published": "2022-08-08T20:32:28Z",
        "link": "http://arxiv.org/abs/2208.04405v3",
        "categories": [
            "cs.LG",
            "cs.MA",
            "stat.ME",
            "62D20, 93B30",
            "I.2.m; G.3"
        ]
    },
    {
        "title": "An Agent-Based Fleet Management Model for First- and Last-Mile Services",
        "authors": [
            "Saumya Bhatnagar",
            "Tarun Rambha",
            "Gitakrishnan Ramadurai"
        ],
        "summary": "With the growth of cars and car-sharing applications, commuters in many cities, particularly developing countries, are shifting away from public transport. These shifts have affected two key stakeholders: transit operators and first- and last-mile (FLM) services. Although most cities continue to invest heavily in bus and metro projects to make public transit attractive, ridership in these systems has often failed to reach targeted levels. FLM service providers also experience lower demand and revenues in the wake of shifts to other means of transport. Effective FLM options are required to prevent this phenomenon and make public transport attractive for commuters. One possible solution is to forge partnerships between public transport and FLM providers that offer competitive joint mobility options. Such solutions require prudent allocation of supply and optimised strategies for FLM operations and ride-sharing. To this end, we build an agent- and event-based simulation model which captures interactions between passengers and FLM services using statecharts, vehicle routing models, and other trip matching rules. An optimisation model for allocating FLM vehicles at different transit stations is proposed to reduce unserved requests. Using real-world metro transit demand data from Bengaluru, India, the effectiveness of our approach in improving FLM connectivity and quantifying the benefits of sharing trips is demonstrated.",
        "published": "2022-08-09T06:52:28Z",
        "link": "http://arxiv.org/abs/2208.04563v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Learning Mean-Field Control for Delayed Information Load Balancing in   Large Queuing Systems",
        "authors": [
            "Anam Tahir",
            "Kai Cui",
            "Heinz Koeppl"
        ],
        "summary": "Recent years have seen a great increase in the capacity and parallel processing power of data centers and cloud services. To fully utilize the said distributed systems, optimal load balancing for parallel queuing architectures must be realized. Existing state-of-the-art solutions fail to consider the effect of communication delays on the behaviour of very large systems with many clients. In this work, we consider a multi-agent load balancing system, with delayed information, consisting of many clients (load balancers) and many parallel queues. In order to obtain a tractable solution, we model this system as a mean-field control problem with enlarged state-action space in discrete time through exact discretization. Subsequently, we apply policy gradient reinforcement learning algorithms to find an optimal load balancing solution. Here, the discrete-time system model incorporates a synchronization delay under which the queue state information is synchronously broadcasted and updated at all clients. We then provide theoretical performance guarantees for our methodology in large systems. Finally, using experiments, we prove that our approach is not only scalable but also shows good performance when compared to the state-of-the-art power-of-d variant of the Join-the-Shortest-Queue (JSQ) and other policies in the presence of synchronization delays.",
        "published": "2022-08-09T13:47:19Z",
        "link": "http://arxiv.org/abs/2208.04777v1",
        "categories": [
            "cs.DC",
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Heterogeneous Multi-agent Zero-Shot Coordination by Coevolution",
        "authors": [
            "Ke Xue",
            "Yutong Wang",
            "Cong Guan",
            "Lei Yuan",
            "Haobo Fu",
            "Qiang Fu",
            "Chao Qian",
            "Yang Yu"
        ],
        "summary": "Generating agents that can achieve zero-shot coordination (ZSC) with unseen partners is a new challenge in cooperative multi-agent reinforcement learning (MARL). Recently, some studies have made progress in ZSC by exposing the agents to diverse partners during the training process. They usually involve self-play when training the partners, implicitly assuming that the tasks are homogeneous. However, many real-world tasks are heterogeneous, and hence previous methods may be inefficient. In this paper, we study the heterogeneous ZSC problem for the first time and propose a general method based on coevolution, which coevolves two populations of agents and partners through three sub-processes: pairing, updating and selection. Experimental results on various heterogeneous tasks highlight the necessity of considering the heterogeneous setting and demonstrate that our proposed method is a promising solution for heterogeneous ZSC tasks.",
        "published": "2022-08-09T16:16:28Z",
        "link": "http://arxiv.org/abs/2208.04957v2",
        "categories": [
            "cs.NE",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Ad Hoc Teamwork in the Presence of Adversaries",
        "authors": [
            "Ted Fujimoto",
            "Samrat Chatterjee",
            "Auroop Ganguly"
        ],
        "summary": "Advances in ad hoc teamwork have the potential to create agents that collaborate robustly in real-world applications. Agents deployed in the real world, however, are vulnerable to adversaries with the intent to subvert them. There has been little research in ad hoc teamwork that assumes the presence of adversaries. We explain the importance of extending ad hoc teamwork to include the presence of adversaries and clarify why this problem is difficult. We then propose some directions for new research opportunities in ad hoc teamwork that leads to more robust multi-agent cyber-physical infrastructure systems.",
        "published": "2022-08-09T23:21:11Z",
        "link": "http://arxiv.org/abs/2208.05071v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Inaccuracy rates for distributed inference over random networks with   applications to social learning",
        "authors": [
            "Dragana Bajovic"
        ],
        "summary": "This paper studies probabilistic rates of convergence for consensus+innovations type of algorithms in random, generic networks. For each node, we find a lower and also a family of upper bounds on the large deviations rate function, thus enabling the computation of the exponential convergence rates for the events of interest on the iterates. Relevant applications include error exponents in distributed hypothesis testing, rates of convergence of beliefs in social learning, and inaccuracy rates in distributed estimation. The bounds on the rate function have a very particular form at each node: they are constructed as the convex envelope between the rate function of the hypothetical fusion center and the rate function corresponding to a certain topological mode of the node's presence. We further show tightness of the discovered bounds for several cases, such as pendant nodes and regular networks, thus establishing the first proof of the large deviations principle for consensus+innovations and social learning in random networks.",
        "published": "2022-08-10T09:30:57Z",
        "link": "http://arxiv.org/abs/2208.05236v1",
        "categories": [
            "cs.IT",
            "cs.MA",
            "math.IT"
        ]
    },
    {
        "title": "Diversifying Message Aggregation in Multi-Agent Communication via   Normalized Tensor Nuclear Norm Regularization",
        "authors": [
            "Yuanzhao Zhai",
            "Kele Xu",
            "Bo Ding",
            "Dawei Feng",
            "Zijian Gao",
            "Huaimin Wang"
        ],
        "summary": "Aggregating messages is a key component for the communication of multi-agent reinforcement learning (Comm-MARL). Recently, it has witnessed the prevalence of graph attention networks (GAT) in Comm-MARL, where agents can be represented as nodes and messages can be aggregated via the weighted passing. While successful, GAT can lead to homogeneity in the strategies of message aggregation, and the ``core'' agent may excessively influence other agents' behaviors, which can severely limit the multi-agent coordination. To address this challenge, we first study the adjacency tensor of the communication graph and demonstrate that the homogeneity of message aggregation could be measured by the normalized tensor rank. Since the rank optimization problem is known to be NP-hard, we define a new nuclear norm, which is a convex surrogate of normalized tensor rank, to replace the rank. Leveraging the norm, we further propose a plug-and-play regularizer on the adjacency tensor, named Normalized Tensor Nuclear Norm Regularization (NTNNR), to actively enrich the diversity of message aggregation during the training stage. We extensively evaluate GAT with the proposed regularizer in both cooperative and mixed cooperative-competitive scenarios. The results demonstrate that aggregating messages using NTNNR-enhanced GAT can improve the efficiency of the training and achieve higher asymptotic performance than existing message aggregation methods. When NTNNR is applied to existing graph-attention Comm-MARL methods, we also observe significant performance improvements on the StarCraft II micromanagement benchmarks.",
        "published": "2022-08-10T16:04:49Z",
        "link": "http://arxiv.org/abs/2208.05414v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "EvolveHypergraph: Group-Aware Dynamic Relational Reasoning for   Trajectory Prediction",
        "authors": [
            "Jiachen Li",
            "Chuanbo Hua",
            "Jinkyoo Park",
            "Hengbo Ma",
            "Victoria Dax",
            "Mykel J. Kochenderfer"
        ],
        "summary": "While the modeling of pair-wise relations has been widely studied in multi-agent interacting systems, its ability to capture higher-level and larger-scale group-wise activities is limited. In this paper, we propose a group-aware relational reasoning approach (named EvolveHypergraph) with explicit inference of the underlying dynamically evolving relational structures, and we demonstrate its effectiveness for multi-agent trajectory prediction. In addition to the edges between a pair of nodes (i.e., agents), we propose to infer hyperedges that adaptively connect multiple nodes to enable group-aware relational reasoning in an unsupervised manner without fixing the number of hyperedges. The proposed approach infers the dynamically evolving relation graphs and hypergraphs over time to capture the evolution of relations, which are used by the trajectory predictor to obtain future states. Moreover, we propose to regularize the smoothness of the relation evolution and the sparsity of the inferred graphs or hypergraphs, which effectively improves training stability and enhances the explainability of inferred relations. The proposed approach is validated on both synthetic crowd simulations and multiple real-world benchmark datasets. Our approach infers explainable, reasonable group-aware relations and achieves state-of-the-art performance in long-term prediction.",
        "published": "2022-08-10T17:57:10Z",
        "link": "http://arxiv.org/abs/2208.05470v1",
        "categories": [
            "cs.CV",
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Augmented Driver Behavior Models for High-Fidelity Simulation Study of   Crash Detection Algorithms",
        "authors": [
            "Ahura Jami",
            "Mahdi Razzaghpour",
            "Hussein Alnuweiri",
            "Yaser P. Fallah"
        ],
        "summary": "Developing safety and efficiency applications for Connected and Automated Vehicles (CAVs) require a great deal of testing and evaluation. The need for the operation of these systems in critical and dangerous situations makes the burden of their evaluation very costly, possibly dangerous, and time-consuming. As an alternative, researchers attempt to study and evaluate their algorithms and designs using simulation platforms. Modeling the behavior of drivers or human operators in CAVs or other vehicles interacting with them is one of the main challenges of such simulations. While developing a perfect model for human behavior is a challenging task and an open problem, we present a significant augmentation of the current models used in simulators for driver behavior. In this paper, we present a simulation platform for a hybrid transportation system that includes both human-driven and automated vehicles. In addition, we decompose the human driving task and offer a modular approach to simulating a large-scale traffic scenario, allowing for a thorough investigation of automated and active safety systems. Such representation through Interconnected modules offers a human-interpretable system that can be tuned to represent different classes of drivers. Additionally, we analyze a large driving dataset to extract expressive parameters that would best describe different driving characteristics. Finally, we recreate a similarly dense traffic scenario within our simulator and conduct a thorough analysis of various human-specific and system-specific factors, studying their effect on traffic network performance and safety.",
        "published": "2022-08-10T19:59:16Z",
        "link": "http://arxiv.org/abs/2208.05540v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.RO"
        ]
    },
    {
        "title": "The emergence of division of labor through decentralized social   sanctioning",
        "authors": [
            "Anil Yaman",
            "Joel Z. Leibo",
            "Giovanni Iacca",
            "Sang Wan Lee"
        ],
        "summary": "Human ecological success relies on our characteristic ability to flexibly self-organize into cooperative social groups, the most successful of which employ substantial specialization and division of labor. Unlike most other animals, humans learn by trial and error during their lives what role to take on. However, when some critical roles are more attractive than others, and individuals are self-interested, then there is a social dilemma: each individual would prefer others take on the critical but unremunerative roles so they may remain free to take one that pays better. But disaster occurs if all act thusly and a critical role goes unfilled. In such situations learning an optimum role distribution may not be possible. Consequently, a fundamental question is: how can division of labor emerge in groups of self-interested lifetime-learning individuals? Here we show that by introducing a model of social norms, which we regard as emergent patterns of decentralized social sanctioning, it becomes possible for groups of self-interested individuals to learn a productive division of labor involving all critical roles. Such social norms work by redistributing rewards within the population to disincentivize antisocial roles while incentivizing prosocial roles that do not intrinsically pay as well as others.",
        "published": "2022-08-10T21:35:38Z",
        "link": "http://arxiv.org/abs/2208.05568v6",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.NE"
        ]
    },
    {
        "title": "Multi-Agent Reinforcement Learning with Graph Convolutional Neural   Networks for optimal Bidding Strategies of Generation Units in Electricity   Markets",
        "authors": [
            "Pegah Rokhforoz",
            "Olga Fink"
        ],
        "summary": "Finding optimal bidding strategies for generation units in electricity markets would result in higher profit. However, it is a challenging problem due to the system uncertainty which is due to the unknown other generation units' strategies. Distributed optimization, where each entity or agent decides on its bid individually, has become state of the art. However, it cannot overcome the challenges of system uncertainties. Deep reinforcement learning is a promising approach to learn the optimal strategy in uncertain environments. Nevertheless, it is not able to integrate the information on the spatial system topology in the learning process. This paper proposes a distributed learning algorithm based on deep reinforcement learning (DRL) combined with a graph convolutional neural network (GCN). In fact, the proposed framework helps the agents to update their decisions by getting feedback from the environment so that it can overcome the challenges of the uncertainties. In this proposed algorithm, the state and connection between nodes are the inputs of the GCN, which can make agents aware of the structure of the system. This information on the system topology helps the agents to improve their bidding strategies and increase the profit. We evaluate the proposed algorithm on the IEEE 30-bus system under different scenarios. Also, to investigate the generalization ability of the proposed approach, we test the trained model on IEEE 39-bus system. The results show that the proposed algorithm has more generalization abilities compare to the DRL and can result in higher profit when changing the topology of the system.",
        "published": "2022-08-11T09:29:31Z",
        "link": "http://arxiv.org/abs/2208.06242v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Enabling Long-term Fairness in Dynamic Resource Allocation",
        "authors": [
            "T. Si-Salem",
            "G. Iosifidis",
            "G. Neglia"
        ],
        "summary": "We study the fairness of dynamic resource allocation problem under the $\\alpha$-fairness criterion. We recognize two different fairness objectives that naturally arise in this problem: the well-understood slot-fairness objective that aims to ensure fairness at every timeslot, and the less explored horizon-fairness objective that aims to ensure fairness across utilities accumulated over a time horizon. We argue that horizon-fairness comes at a lower price in terms of social welfare. We study horizon-fairness with the regret as a performance metric and show that vanishing regret cannot be achieved in presence of an unrestricted adversary. We propose restrictions on the adversary's capabilities corresponding to realistic scenarios and an online policy that indeed guarantees vanishing regret under these restrictions. We demonstrate the applicability of the proposed fairness framework to a representative resource management problem considering a virtualized caching system where different caches cooperate to serve content requests.",
        "published": "2022-08-11T15:57:45Z",
        "link": "http://arxiv.org/abs/2208.05898v2",
        "categories": [
            "cs.GT",
            "cs.MA",
            "cs.PF"
        ]
    },
    {
        "title": "Macro Ethics Principles for Responsible AI Systems: Taxonomy and Future   Directions",
        "authors": [
            "Jessica Woodgate",
            "Nirav Ajmeri"
        ],
        "summary": "Responsible AI must be able to make or support decisions that consider human values and can be justified by human morals. Accommodating values and morals in responsible decision making is supported by adopting a perspective of macro ethics, which views ethics through a holistic lens incorporating social context. Normative ethical principles inferred from philosophy can be used to methodically reason about ethics and make ethical judgements in specific contexts. Operationalising normative ethical principles thus promotes responsible reasoning under the perspective of macro ethics. We survey AI and computer science literature and develop a taxonomy of 21 normative ethical principles which can be operationalised in AI. We describe how each principle has previously been operationalised, highlighting key themes that AI practitioners seeking to implement ethical principles should be aware of. We envision that this taxonomy will facilitate the development of methodologies to incorporate normative ethical principles in reasoning capacities of responsible AI systems.",
        "published": "2022-08-12T08:48:16Z",
        "link": "http://arxiv.org/abs/2208.12616v4",
        "categories": [
            "cs.CY",
            "cs.MA"
        ]
    },
    {
        "title": "AI for Global Climate Cooperation: Modeling Global Climate Negotiations,   Agreements, and Long-Term Cooperation in RICE-N",
        "authors": [
            "Tianyu Zhang",
            "Andrew Williams",
            "Soham Phade",
            "Sunil Srinivasa",
            "Yang Zhang",
            "Prateek Gupta",
            "Yoshua Bengio",
            "Stephan Zheng"
        ],
        "summary": "Comprehensive global cooperation is essential to limit global temperature increases while continuing economic development, e.g., reducing severe inequality or achieving long-term economic growth. Achieving long-term cooperation on climate change mitigation with n strategic agents poses a complex game-theoretic problem. For example, agents may negotiate and reach climate agreements, but there is no central authority to enforce adherence to those agreements. Hence, it is critical to design negotiation and agreement frameworks that foster cooperation, allow all agents to meet their individual policy objectives, and incentivize long-term adherence. This is an interdisciplinary challenge that calls for collaboration between researchers in machine learning, economics, climate science, law, policy, ethics, and other fields. In particular, we argue that machine learning is a critical tool to address the complexity of this domain. To facilitate this research, here we introduce RICE-N, a multi-region integrated assessment model that simulates the global climate and economy, and which can be used to design and evaluate the strategic outcomes for different negotiation and agreement frameworks. We also describe how to use multi-agent reinforcement learning to train rational agents using RICE-N. This framework underpinsAI for Global Climate Cooperation, a working group collaboration and competition on climate negotiation and agreement design. Here, we invite the scientific community to design and evaluate their solutions using RICE-N, machine learning, economic intuition, and other domain knowledge. More information can be found on www.ai4climatecoop.org.",
        "published": "2022-08-15T04:38:06Z",
        "link": "http://arxiv.org/abs/2208.07004v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "93A16, 91-10, 68T07",
            "I.2.11; J.2; J.4"
        ]
    },
    {
        "title": "Cooperative and uncooperative institution designs: Surprises and   problems in open-source game theory",
        "authors": [
            "Andrew Critch",
            "Michael Dennis",
            "Stuart Russell"
        ],
        "summary": "It is increasingly possible for real-world agents, such as software-based agents or human institutions, to view the internal programming of other such agents that they interact with. For instance, a company can read the bylaws of another company, or one software system can read the source code of another. Game-theoretic equilibria between the designers of such agents are called \\emph{program equilibria}, and we call this area \\emph{open-source game theory}.   In this work we demonstrate a series of counterintuitive results on open-source games, which are independent of the programming language in which agents are written. We show that certain formal institution designs that one might expect to defect against each other will instead turn out to cooperate, or conversely, cooperate when one might expect them to defect. The results hold in a setting where each institution has full visibility into the other institution's true operating procedures. We also exhibit examples and ten open problems for better understanding these phenomena. We argue that contemporary game theory remains ill-equipped to study program equilibria, given that even the outcomes of single games in open-source settings remain counterintuitive and poorly understood. Nonetheless, some of these open-source agents exhibit desirable characteristics -- e.g., they can unexploitably create incentives for cooperation and legibility from other agents -- such that analyzing them could yield considerable benefits.",
        "published": "2022-08-15T04:56:06Z",
        "link": "http://arxiv.org/abs/2208.07006v1",
        "categories": [
            "cs.GT",
            "cs.LO",
            "cs.MA",
            "93A14, 93A16, 91-08, 91A11, 91A35, 91A68, 91A44, 91B06, 91B41, 91B52",
            "F.3.1; F.4.1; I.2.3; J.4"
        ]
    },
    {
        "title": "Fair Division meets Vehicle Routing: Fairness for Drivers with Monotone   Profits",
        "authors": [
            "Martin Damyanov Aleksandrov"
        ],
        "summary": "We propose a new model for fair division and vehicle routing, where drivers have monotone profit preferences, and their vehicles have feasibility constraints, for customer requests. For this model, we design two new axiomatic notions for fairness for drivers: FEQ1 and FEF1. FEQ1 encodes driver pairwise bounded equitability. FEF1 encodes driver pairwise bounded envy freeness. We compare FEQ1 and FEF1 with popular fair division notions such as EQ1 and EF1. We also give algorithms for guaranteeing FEQ1 and FEF1, respectively.",
        "published": "2022-08-15T09:53:50Z",
        "link": "http://arxiv.org/abs/2208.07094v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Cooperative guidance of multiple missiles: a hybrid co-evolutionary   approach",
        "authors": [
            "Xuejing Lan",
            "Junda Chen",
            "Zhijia Zhao",
            "Tao Zou"
        ],
        "summary": "Cooperative guidance of multiple missiles is a challenging task with rigorous constraints of time and space consensus, especially when attacking dynamic targets. In this paper, the cooperative guidance task is described as a distributed multi-objective cooperative optimization problem. To address the issues of non-stationarity and continuous control faced by cooperative guidance, the natural evolutionary strategy (NES) is improved along with an elitist adaptive learning technique to develop a novel natural co-evolutionary strategy (NCES). The gradients of original evolutionary strategy are rescaled to reduce the estimation bias caused by the interaction between the multiple missiles. Then, a hybrid co-evolutionary cooperative guidance law (HCCGL) is proposed by integrating the highly scalable co-evolutionary mechanism and the traditional guidance strategy. Finally, three simulations under different conditions demonstrate the effectiveness and superiority of this guidance law in solving cooperative guidance tasks with high accuracy. The proposed co-evolutionary approach has great prospects not only in cooperative guidance, but also in other application scenarios of multi-objective optimization, dynamic optimization and distributed control.",
        "published": "2022-08-15T12:59:38Z",
        "link": "http://arxiv.org/abs/2208.07156v2",
        "categories": [
            "cs.NE",
            "cs.CE",
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "F.2.2; J.2"
        ]
    },
    {
        "title": "A Multi-Criteria Metaheuristic Algorithm for Distributed Optimization of   Electric Energy Storage",
        "authors": [
            "Rico Schrage",
            "Paul Hendrik Tiemann",
            "Astrid Nieße"
        ],
        "summary": "The distributed schedule optimization of energy storage constitutes a challenge. Such algorithms often expect an input set containing all feasible schedules or respectively require to efficiently search the schedule space. It is hardly possible to accomplish this with energy storage due to its high flexibility. In this paper, the problem is introduced in detail and addressed by a metaheuristic algorithm, which generates a preselection of schedules. Three contributions are presented to achieve this goal: First, an extension for a distributed schedule optimization allowing a simultaneous optimization is developed. Second, an evolutionary algorithm is designed to generate optimized schedules. Third, the algorithm is extended to include an arbitrary local criterion. It is shown that the presented approach is suitable to schedule electric energy storage in real households and industries with different generator and storage types.",
        "published": "2022-08-15T13:42:12Z",
        "link": "http://arxiv.org/abs/2208.07185v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Transformer-based Value Function Decomposition for Cooperative   Multi-agent Reinforcement Learning in StarCraft",
        "authors": [
            "Muhammad Junaid Khan",
            "Syed Hammad Ahmed",
            "Gita Sukthankar"
        ],
        "summary": "The StarCraft II Multi-Agent Challenge (SMAC) was created to be a challenging benchmark problem for cooperative multi-agent reinforcement learning (MARL). SMAC focuses exclusively on the problem of StarCraft micromanagement and assumes that each unit is controlled individually by a learning agent that acts independently and only possesses local information; centralized training is assumed to occur with decentralized execution (CTDE). To perform well in SMAC, MARL algorithms must handle the dual problems of multi-agent credit assignment and joint action evaluation.   This paper introduces a new architecture TransMix, a transformer-based joint action-value mixing network which we show to be efficient and scalable as compared to the other state-of-the-art cooperative MARL solutions. TransMix leverages the ability of transformers to learn a richer mixing function for combining the agents' individual value functions. It achieves comparable performance to previous work on easy SMAC scenarios and outperforms other techniques on hard scenarios, as well as scenarios that are corrupted with Gaussian noise to simulate fog of war.",
        "published": "2022-08-15T16:13:16Z",
        "link": "http://arxiv.org/abs/2208.07298v1",
        "categories": [
            "cs.MA",
            "cs.LG"
        ]
    },
    {
        "title": "Neural Payoff Machines: Predicting Fair and Stable Payoff Allocations   Among Team Members",
        "authors": [
            "Daphne Cornelisse",
            "Thomas Rood",
            "Mateusz Malinowski",
            "Yoram Bachrach",
            "Tal Kachman"
        ],
        "summary": "In many multi-agent settings, participants can form teams to achieve collective outcomes that may far surpass their individual capabilities. Measuring the relative contributions of agents and allocating them shares of the reward that promote long-lasting cooperation are difficult tasks. Cooperative game theory offers solution concepts identifying distribution schemes, such as the Shapley value, that fairly reflect the contribution of individuals to the performance of the team or the Core, which reduces the incentive of agents to abandon their team. Applications of such methods include identifying influential features and sharing the costs of joint ventures or team formation. Unfortunately, using these solutions requires tackling a computational barrier as they are hard to compute, even in restricted settings. In this work, we show how cooperative game-theoretic solutions can be distilled into a learned model by training neural networks to propose fair and stable payoff allocations. We show that our approach creates models that can generalize to games far from the training distribution and can predict solutions for more players than observed during training. An important application of our framework is Explainable AI: our approach can be used to speed-up Shapley value computations on many instances.",
        "published": "2022-08-18T12:33:09Z",
        "link": "http://arxiv.org/abs/2208.08798v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.GT",
            "cs.MA",
            "econ.TH"
        ]
    },
    {
        "title": "Scalable Multi-Agent Lab Framework for Lab Optimization",
        "authors": [
            "A. Gilad Kusne",
            "Austin McDannald"
        ],
        "summary": "Autonomous materials research systems allow scientists to fail smarter, learn faster, and spend less resources in their studies. As these systems grow in number, capability, and complexity, a new challenge arises - how will they work together across large facilities? We explore one solution to this question - a multi-agent laboratory control frame-work. We demonstrate this framework with an autonomous material science lab in mind - where information from diverse research campaigns can be combined to ad-dress the scientific question at hand. This framework can 1) account for realistic resource limits such as equipment use, 2) allow for machine learning agents with diverse learning capabilities and goals capable of running re-search campaigns, and 3) facilitate multi-agent collaborations and teams. The framework is dubbed the MULTI-agent auTonomous fAcilities - a Scalable frameworK aka MULTITASK. MULTITASK makes possible facility-wide simulations, including agent-instrument and agent-agent interactions. Through MULTITASK's modularity, real-world facilities can come on-line in phases, with simulated instruments gradually replaced by real-world instruments. We hope MULTITASK opens new areas of study in large-scale autonomous and semi-autonomous research campaigns and facilities.",
        "published": "2022-08-19T00:18:19Z",
        "link": "http://arxiv.org/abs/2208.09099v3",
        "categories": [
            "cs.MA",
            "cond-mat.mtrl-sci",
            "cs.LG"
        ]
    },
    {
        "title": "Blockchain-based traffic management for Advanced Air Mobility",
        "authors": [
            "I. Romani de Oliveira",
            "T. Matsumoto",
            "E. C. Pinto Neto"
        ],
        "summary": "The large public interest in Advanced Air Mobility (AAM) will soon lead to congested skies overhead cities, analogously to what happened with other transportation means, including commercial aviation. In the latter case, the combination of large distances and demanded number flights is such that a system with centralized control, with most of the decisions made by human operators, is safe. However, for AAM, it is expected a much higher demand, because it will be used for people's daily commutes. Thus, higher automation levels will become a requirement for coordinating this traffic, which might not be effectively managed by humans. The establishment of fixed air routes can abate complexity, however at the cost of limiting capacity and decreasing efficiency. Another alternative is the use of a powerful central system based on Artificial Intelligence (AI), which would allow flexible trajectories and higher efficiency. However, such system would require concentrated investment, could contain Single-Points-of-Failure (SPoFs), would be a highly sought target of malicious attacks, and would be subject to periods of unavailability.   This work proposes a new technology that solves the problem of managing the high complexity of the AAM traffic with a secure distributed approach, without the need for a proprietary centralized automation system. This technology enables distributed airspace allocation management and conflict resolution by means of trusted shared data structures and associated smart contracts running on a blockchain ecosystem. This way, it greatly reduces the risk of system outages due to SPoFs, by allowing peer-to-peer conflict resolution, and being more resilient to failures in the ground communication infrastructure. Furthermore, it provides priority-based balancing mechanisms that help to regulate fairness among participants in the utilization of the airspace.",
        "published": "2022-08-19T12:54:37Z",
        "link": "http://arxiv.org/abs/2208.09312v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Exploring Task-oriented Communication in Multi-agent System: A Deep   Reinforcement Learning Approach",
        "authors": [
            "Guojun He"
        ],
        "summary": "The multi-agent system (MAS) enables the sharing of capabilities among agents, such that collaborative tasks can be accomplished with high scalability and efficiency. MAS is increasingly widely applied in various fields. Meanwhile, the large-scale and time-sensitive data transmission between agents brings challenges to the communication system. The traditional wireless communication ignores the content of the data and its impact on the task execution at the receiver, which makes it difficult to guarantee the timeliness and relevance of the information. This limitation leads to that traditional wireless communication struggles to effectively support emerging multi-agent collaborative applications. Faced with this dilemma, task-oriented communication is a potential solution, which aims to transmit task-relevant information to improve task execution performance. However, multi-agent collaboration itself is a complex class of sequential decision problems. It is challenging to explore efficient information flow in this context. In this article, we use deep reinforcement learning (DRL) to explore task-oriented communication in MAS. We begin with a discussion on the application of DRL to task-oriented communication. We then envision a task-oriented communication architecture for MAS, and discuss the designs based on DRL. Finally, we discuss open problems for future research and conclude this article.",
        "published": "2022-08-22T09:21:54Z",
        "link": "http://arxiv.org/abs/2208.10165v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Elastic buildings: Calibrated district-scale simulation of   occupant-flexible campus operation for hybrid work optimization",
        "authors": [
            "Martín Mosteiro-Romero",
            "Clayton Miller",
            "Adrian Chong",
            "Rudi Stouffs"
        ],
        "summary": "Before 2020, the way occupants utilized the built environment had been changing slowly towards scenarios in which occupants have more choice and flexibility in where and how they work. The global COVID-19 pandemic accelerated this phenomenon rapidly through lockdowns and hybrid work arrangements. Many occupants and employers are considering keeping some of these flexibility-based strategies due to their benefits and cost impacts. This paper simulates various scenarios related to the operational technologies and policies of a real-world campus using a district-scale City Energy Analyst (CEA) model that is calibrated with measured energy and occupancy profiles extracted from WiFi data. These scenarios demonstrate the energy impact of ramping building operations up and down more rapidly and effectively to the flex-based work strategies that may solidify. The scenarios show a 4-12% decrease in space cooling demand due to occupant absenteeism if centralized building system operation is in place, but as high as 21-68% if occupancy-driven building controls are implemented. The paper discusses technologies and strategies that are important in this paradigm shift of operations.",
        "published": "2022-08-22T10:22:18Z",
        "link": "http://arxiv.org/abs/2210.06124v2",
        "categories": [
            "physics.soc-ph",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "An Entropy-based Measure of Intelligence Degree of System Structures",
        "authors": [
            "Wei Su"
        ],
        "summary": "In this paper, we investigate how to measure the intelligence of systems under specific structures. Two indicators are adopted to characterize the intelligence of a given structure, namely the function diversity of the structure, and the ability to generate order under specific environments. A measure of intelligence degree is proposed, with which the intelligence degree of several basic structures is calculated. It is shown that some structures are indeed \"smarter\" than the others under the proposed measure. The results add a possible way of revealing the evolution mechanism of natural life and constructing life-like structures with high intelligence degree.",
        "published": "2022-08-22T12:40:55Z",
        "link": "http://arxiv.org/abs/2208.10266v1",
        "categories": [
            "nlin.AO",
            "cs.AI",
            "cs.MA",
            "physics.bio-ph"
        ]
    },
    {
        "title": "A simple learning agent interacting with an agent-based market model",
        "authors": [
            "Matthew Dicks",
            "Andrew Paskaramoorthy",
            "Tim Gebbie"
        ],
        "summary": "We consider the learning dynamics of a single reinforcement learning optimal execution trading agent when it interacts with an event driven agent-based financial market model. Trading takes place asynchronously through a matching engine in event time. The optimal execution agent is considered at different levels of initial order-sizes and differently sized state spaces. The resulting impact on the agent-based model and market are considered using a calibration approach that explores changes in the empirical stylised facts and price impact curves. Convergence, volume trajectory and action trace plots are used to visualise the learning dynamics. Here the smaller state space agents had the number of states they visited converge much faster than the larger state space agents, and they were able to start learning to trade intuitively using the spread and volume states. We find that the moments of the model are robust to the impact of the learning agents except for the Hurst exponent, which was lowered by the introduction of strategic order-splitting. The introduction of the learning agent preserves the shape of the price impact curves but can reduce the trade-sign auto-correlations when their trading volumes increase.",
        "published": "2022-08-22T16:42:06Z",
        "link": "http://arxiv.org/abs/2208.10434v4",
        "categories": [
            "q-fin.TR",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Formal Contracts Mitigate Social Dilemmas in Multi-Agent RL",
        "authors": [
            "Andreas A. Haupt",
            "Phillip J. K. Christoffersen",
            "Mehul Damani",
            "Dylan Hadfield-Menell"
        ],
        "summary": "Multi-agent Reinforcement Learning (MARL) is a powerful tool for training autonomous agents acting independently in a common environment. However, it can lead to sub-optimal behavior when individual incentives and group incentives diverge. Humans are remarkably capable at solving these social dilemmas. It is an open problem in MARL to replicate such cooperative behaviors in selfish agents. In this work, we draw upon the idea of formal contracting from economics to overcome diverging incentives between agents in MARL. We propose an augmentation to a Markov game where agents voluntarily agree to binding transfers of reward, under pre-specified conditions. Our contributions are theoretical and empirical. First, we show that this augmentation makes all subgame-perfect equilibria of all Fully Observable Markov Games exhibit socially optimal behavior, given a sufficiently rich space of contracts. Next, we show that for general contract spaces, and even under partial observability, richer contract spaces lead to higher welfare. Hence, contract space design solves an exploration-exploitation tradeoff, sidestepping incentive issues. We complement our theoretical analysis with experiments. Issues of exploration in the contracting augmentation are mitigated using a training methodology inspired by multi-objective reinforcement learning: Multi-Objective Contract Augmentation Learning (MOCA). We test our methodology in static, single-move games, as well as dynamic domains that simulate traffic, pollution management and common pool resource management.",
        "published": "2022-08-22T17:42:03Z",
        "link": "http://arxiv.org/abs/2208.10469v4",
        "categories": [
            "cs.AI",
            "cs.GT",
            "cs.MA",
            "econ.TH"
        ]
    },
    {
        "title": "Quantum Multi-Agent Meta Reinforcement Learning",
        "authors": [
            "Won Joon Yun",
            "Jihong Park",
            "Joongheon Kim"
        ],
        "summary": "Although quantum supremacy is yet to come, there has recently been an increasing interest in identifying the potential of quantum machine learning (QML) in the looming era of practical quantum computing. Motivated by this, in this article we re-design multi-agent reinforcement learning (MARL) based on the unique characteristics of quantum neural networks (QNNs) having two separate dimensions of trainable parameters: angle parameters affecting the output qubit states, and pole parameters associated with the output measurement basis. Exploiting this dyadic trainability as meta-learning capability, we propose quantum meta MARL (QM2ARL) that first applies angle training for meta-QNN learning, followed by pole training for few-shot or local-QNN training. To avoid overfitting, we develop an angle-to-pole regularization technique injecting noise into the pole domain during angle training. Furthermore, by exploiting the pole as the memory address of each trained QNN, we introduce the concept of pole memory allowing one to save and load trained QNNs using only two-parameter pole values. We theoretically prove the convergence of angle training under the angle-to-pole regularization, and by simulation corroborate the effectiveness of QM2ARL in achieving high reward and fast convergence, as well as of the pole memory in fast adaptation to a time-varying environment.",
        "published": "2022-08-22T22:46:52Z",
        "link": "http://arxiv.org/abs/2208.11510v4",
        "categories": [
            "quant-ph",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "The Robustness of Tether Friction in Non-idealized Terrains",
        "authors": [
            "Justin J. Page",
            "Laura K. Treers",
            "Steven Jens Jorgensen",
            "Ronald S. Fearing",
            "Hannah S. Stuart"
        ],
        "summary": "Reduced traction limits the ability of mobile robotic systems to resist or apply large external loads, such as tugging a massive payload. One simple and versatile solution is to wrap a tether around naturally occurring objects to leverage the capstan effect and create exponentially-amplified holding forces. Experiments show that an idealized capstan model explains force amplification experienced on common irregular outdoor objects - trees, rocks, posts. Robust to variable environmental conditions, this exponential amplification method can harness single or multiple capstan objects, either in series or in parallel with a team of robots. This adaptability allows for a range of potential configurations especially useful for when objects cannot be fully encircled or gripped. These principles are demonstrated with mobile platforms to (1) control the lowering and arrest of a payload, (2) to achieve planar control of a payload, and (3) to act as an anchor point for a more massive platform to winch towards. We show the simple addition of a tether, wrapped around shallow stones in sand, amplifies holding force of a low-traction platform by up to 774x.",
        "published": "2022-08-22T23:14:19Z",
        "link": "http://arxiv.org/abs/2208.10646v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Entropy Enhanced Multi-Agent Coordination Based on Hierarchical Graph   Learning for Continuous Action Space",
        "authors": [
            "Yining Chen",
            "Ke Wang",
            "Guanghua Song",
            "Xiaohong Jiang"
        ],
        "summary": "In most existing studies on large-scale multi-agent coordination, the control methods aim to learn discrete policies for agents with finite choices. They rarely consider selecting actions directly from continuous action spaces to provide more accurate control, which makes them unsuitable for more complex tasks. To solve the control issue due to large-scale multi-agent systems with continuous action spaces, we propose a novel MARL coordination control method that derives stable continuous policies. By optimizing policies with maximum entropy learning, agents improve their exploration in execution and acquire an excellent performance after training. We also employ hierarchical graph attention networks (HGAT) and gated recurrent units (GRU) to improve the scalability and transferability of our method. The experiments show that our method consistently outperforms all baselines in large-scale multi-agent cooperative reconnaissance tasks.",
        "published": "2022-08-23T01:53:15Z",
        "link": "http://arxiv.org/abs/2208.10676v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Inferring Topology of Networked Dynamical Systems by Active Excitations",
        "authors": [
            "Yushan Li",
            "Jianping He",
            "Cailian Chen",
            "Xinping Guan"
        ],
        "summary": "Topology inference for networked dynamical systems (NDSs) has received considerable attention in recent years. The majority of pioneering works have dealt with inferring the topology from abundant observations of NDSs, so as to approximate the real one asymptotically. Leveraging the characteristic that NDSs will react to various disturbances and the disturbance's influence will consistently spread, this paper focuses on inferring the topology by a few active excitations. The key challenge is to distinguish different influences of system noises and excitations from the exhibited state deviations, where the influences will decay with time and the exciatation cannot be arbitrarily large. To practice, we propose a one-shot excitation based inference method to infer $h$-hop neighbors of a node. The excitation conditions for accurate one-hop neighbor inference are first derived with probability guarantees. Then, we extend the results to $h$-hop neighbor inference and multiple excitations cases, providing the explicit relationships between the inference accuracy and excitation magnitude. Specifically, the excitation based inference method is not only suitable for scenarios where abundant observations are unavailable, but also can be leveraged as auxiliary means to improve the accuracy of existing methods. Simulations are conducted to verify the analytical results.",
        "published": "2022-08-24T02:38:35Z",
        "link": "http://arxiv.org/abs/2208.11276v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Multi-AI Complex Systems in Humanitarian Response",
        "authors": [
            "Joseph Aylett-Bullock",
            "Miguel Luengo-Oroz"
        ],
        "summary": "AI is being increasingly used to aid response efforts to humanitarian emergencies at multiple levels of decision-making. Such AI systems are generally understood to be stand-alone tools for decision support, with ethical assessments, guidelines and frameworks applied to them through this lens. However, as the prevalence of AI increases in this domain, such systems will begin to encounter each other through information flow networks created by interacting decision-making entities, leading to multi-AI complex systems which are often ill understood. In this paper we describe how these multi-AI systems can arise, even in relatively simple real-world humanitarian response scenarios, and lead to potentially emergent and erratic erroneous behavior. We discuss how we can better work towards more trustworthy multi-AI systems by exploring some of the associated challenges and opportunities, and how we can design better mechanisms to understand and assess such systems. This paper is designed to be a first exposition on this topic in the field of humanitarian response, raising awareness, exploring the possible landscape of this domain, and providing a starting point for future work within the wider community.",
        "published": "2022-08-24T03:01:21Z",
        "link": "http://arxiv.org/abs/2208.11282v2",
        "categories": [
            "cs.CY",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Formation control with connectivity assurance for missile swarm: a   natural co-evolutionary strategy approach",
        "authors": [
            "Junda Chen"
        ],
        "summary": "Formation control problem is one of the most concerned topics within the realm of swarm intelligence, which is usually solved by conventional mathematical approaches. In this paper, however, we presents a metaheuristic approach that leverages a natural co-evolutionary strategy to solve the formation control problem for a swarm of missiles. The missile swarm is modeled by a second-order system with heterogeneous reference target, and exponential error function is made to be the objective function such that the swarm converge to optimal equilibrium states satisfying certain formation requirements. Focusing on the issue of local optimum and unstable evolution, we incorporate a novel model-based policy constraint and a population adaptation strategies that greatly alleviates the performance degradation. With application of the Molloy-Reed criterion in the field of network communication, we developed an adaptive topology method that assure the connectivity under node failure and its effectiveness are validated both theoretically and experimentally. Experimental results valid the effectiveness of the proposed formation control approach. More significantly, we showed that it is feasible to treat generic formation control problem as Markov Decision Process(MDP) and solve it through iterative learning.",
        "published": "2022-08-24T07:54:06Z",
        "link": "http://arxiv.org/abs/2208.11347v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.NE",
            "cs.SY"
        ]
    },
    {
        "title": "The END: Estimation Network Design for games under partial-decision   information",
        "authors": [
            "Mattia Bianchi",
            "Sergio Grammatico"
        ],
        "summary": "Multi-agent decision problems are typically solved via distributed iterative algorithms, where the agents only communicate between themselves on a peer-to-peer network. Each agent usually maintains a copy of each decision variable, while agreement among the local copies is enforced via consensus protocols. Yet, each agent is often directly influenced by a small portion of the decision variables only: neglecting this sparsity results in redundancy, poor scalability with the network size, communication and memory overhead. To address these challenges, we develop Estimation Network Design (END), a framework for the design and analysis of distributed algorithms, generalizing several recent approaches. END algorithms can be tuned to exploit problem-specific sparsity structures, by optimally allocating copies of each variable only to a subset of agents, to improve efficiency and minimize redundancy. We illustrate the END's potential by designing new algorithms for generalised Nash equilibrium (GNE) seeking under partial-decision information, that can leverage the sparsity in cost functions, constraints and aggregation values. Finally, we test numerically our methods on a unicast rate allocation problem, revealing greatly reduced communication and memory costs.",
        "published": "2022-08-24T08:54:37Z",
        "link": "http://arxiv.org/abs/2208.11377v2",
        "categories": [
            "math.OC",
            "cs.GT",
            "cs.MA",
            "cs.NI"
        ]
    },
    {
        "title": "A Consistency Constraint-Based Approach to Coupled State Constraints in   Distributed Model Predictive Control",
        "authors": [
            "Adrian Wiltz",
            "Fei Chen",
            "Dimos V. Dimarogonas"
        ],
        "summary": "In this paper, we present a distributed model predictive control (DMPC) scheme for dynamically decoupled systems which are subject to state constraints, coupling state constraints and input constraints. In the proposed control scheme, neighbor-to-neighbor communication suffices and all subsystems solve their local optimization problem in parallel. The approach relies on consistency constraints which define a neighborhood around each subsystem's reference trajectory where the state of the respective subsystem is guaranteed to stay in. Reference trajectories and consistency constraints are known to neighboring subsystems. Contrary to other relevant approaches, the reference trajectories are improved iteratively. Besides, the presented approach allows the formulation of convex optimization problems even in the presence of non-convex state constraints. The algorithm's effectiveness is demonstrated with a simulation.",
        "published": "2022-08-24T11:10:31Z",
        "link": "http://arxiv.org/abs/2208.11439v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Knowledge-based and Data-driven Reasoning and Learning for Ad Hoc   Teamwork",
        "authors": [
            "Hasra Dodampegama",
            "Mohan Sridharan"
        ],
        "summary": "We present an architecture for ad hoc teamwork, which refers to collaboration in a team of agents without prior coordination. State of the art methods for this problem often include a data-driven component that uses a long history of prior observations to model the behaviour of other agents (or agent types) and to determine the ad hoc agent's behaviour. In many practical domains, it is challenging to find large training datasets, and necessary to understand and incrementally extend the existing models to account for changes in team composition or domain attributes. Our architecture combines the principles of knowledge-based and data-driven reasoning and learning. Specifically, we enable an ad hoc agent to perform non-monotonic logical reasoning with prior commonsense domain knowledge and incrementally-updated simple predictive models of other agents' behaviour. We use the benchmark simulated multi-agent collaboration domain Fort Attack to demonstrate that our architecture supports adaptation to unforeseen changes, incremental learning and revision of models of other agents' behaviour from limited samples, transparency in the ad hoc agent's decision making, and better performance than a data-driven baseline.",
        "published": "2022-08-24T13:57:33Z",
        "link": "http://arxiv.org/abs/2208.11556v2",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Multidisciplinary learning through collective performance favors   decentralization",
        "authors": [
            "John Meluso",
            "Laurent Hébert-Dufresne"
        ],
        "summary": "Many models of learning in teams assume that team members can share solutions or learn concurrently. However, these assumptions break down in multidisciplinary teams where team members often complete distinct, interrelated pieces of larger tasks. Such contexts make it difficult for individuals to separate the performance effects of their own actions from the actions of interacting neighbors. In this work, we show that individuals can overcome this challenge by learning from network neighbors through mediating artifacts (like collective performance assessments). When neighbors' actions influence collective outcomes, teams with different networks perform relatively similarly to one another. However, varying a team's network can affect performance on tasks that weight individuals' contributions by network properties. Consequently, when individuals innovate (through ``exploring'' searches), dense networks hurt performance slightly by increasing uncertainty. In contrast, dense networks moderately help performance when individuals refine their work (through ``exploiting'' searches) by efficiently finding local optima. We also find that decentralization improves team performance across a battery of 34 tasks. Our results offer design principles for multidisciplinary teams within which other forms of learning prove more difficult.",
        "published": "2022-08-24T15:43:00Z",
        "link": "http://arxiv.org/abs/2208.11618v2",
        "categories": [
            "physics.soc-ph",
            "cs.MA",
            "cs.SI",
            "nlin.AO"
        ]
    },
    {
        "title": "Oracle-free Reinforcement Learning in Mean-Field Games along a Single   Sample Path",
        "authors": [
            "Muhammad Aneeq uz Zaman",
            "Alec Koppel",
            "Sujay Bhatt",
            "Tamer Başar"
        ],
        "summary": "We consider online reinforcement learning in Mean-Field Games (MFGs). Unlike traditional approaches, we alleviate the need for a mean-field oracle by developing an algorithm that approximates the Mean-Field Equilibrium (MFE) using the single sample path of the generic agent. We call this {\\it Sandbox Learning}, as it can be used as a warm-start for any agent learning in a multi-agent non-cooperative setting. We adopt a two time-scale approach in which an online fixed-point recursion for the mean-field operates on a slower time-scale, in tandem with a control policy update on a faster time-scale for the generic agent. Given that the underlying Markov Decision Process (MDP) of the agent is communicating, we provide finite sample convergence guarantees in terms of convergence of the mean-field and control policy to the mean-field equilibrium. The sample complexity of the Sandbox learning algorithm is $\\tilde{\\mathcal{O}}(\\epsilon^{-4})$ where $\\epsilon$ is the MFE approximation error. This is similar to works which assume access to oracle. Finally, we empirically demonstrate the effectiveness of the sandbox learning algorithm in diverse scenarios, including those where the MDP does not necessarily have a single communicating class.",
        "published": "2022-08-24T16:22:31Z",
        "link": "http://arxiv.org/abs/2208.11639v3",
        "categories": [
            "cs.LG",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Runtime reliability monitoring for complex fault-tolerance policies",
        "authors": [
            "Alessandro Fantechi",
            "Gloria Gori",
            "Marco Papini"
        ],
        "summary": "Reliability of complex Cyber-Physical Systems is necessary to guarantee availability and/or safety of the provided services. Diverse and complex fault tolerance policies are adopted to enhance reliability, that include a varied mix of redundancy and dynamic reconfiguration to address hardware reliability, as well as specific software reliability techniques like diversity or software rejuvenation. These complex policies call for flexible runtime health checks of system executions that go beyond conventional runtime monitoring of pre-programmed health conditions, also in order to minimize maintenance costs. Defining a suitable monitoring model in the application of this method in complex systems is still a challenge. In this paper we propose a novel approach, Reliability Based Monitoring (RBM), for a flexible runtime monitoring of reliability in complex systems, that exploits a hierarchical reliability model periodically applied to runtime diagnostics data: this allows to dynamically plan maintenance activities aimed at prevent failures. As a proof of concept, we show how to apply RBM to a 2oo3 software system implementing different fault-tolerant policies.",
        "published": "2022-08-25T14:17:29Z",
        "link": "http://arxiv.org/abs/2208.12111v1",
        "categories": [
            "cs.SE",
            "cs.MA"
        ]
    },
    {
        "title": "Emergence of group hierarchy",
        "authors": [
            "Guillaume Deffuant",
            "Thibaut Roubin"
        ],
        "summary": "We consider an opinion dynamics model where, during random pair interactions, each agent modifies her opinions about both agents of the random pair and also about some other agents, chosen randomly. Moreover, each agent belongs to a single group and the opinions within the group are attracted to their average. In simulations starting from neutral opinions, we observe the emergence of a group hierarchy. We derive a moment approximation that provides equations ruling the evolution of the average opinion of agents in a group about the agents of another group. This approximation explains how the group hierarchy emerges.",
        "published": "2022-08-25T15:08:49Z",
        "link": "http://arxiv.org/abs/2208.12149v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Towards A Complete Multi-Agent Pathfinding Algorithm For Large Agents",
        "authors": [
            "Stepan Dergachev",
            "Konstantin Yakovlev"
        ],
        "summary": "Multi-agent pathfinding (MAPF) is a challenging problem which is hard to solve optimally even when simplifying assumptions are adopted, e.g. planar graphs (typically -- grids), discretized time, uniform duration of move and wait actions etc. On the other hand, MAPF under such restrictive assumptions (also known as the Classical MAPF) is equivalent to the so-called pebble motion problem for which non-optimal polynomial time algorithms do exist. Recently, a body of works emerged that investigated MAPF beyond the basic setting and, in particular, considered agents of arbitrary size and shape. Still, to the best of our knowledge no complete algorithms for such MAPF variant exists. In this work we attempt to narrow this gap by considering MAPF for large agents and suggesting how this problem can be reduced to pebble motion on (general) graphs. The crux of this reduction is the procedure that moves away the agents away from the edge which is needed to perform a move action of the current agent. We consider different variants of how this procedure can be implemented and present a variant of the pebble motion algorithm which incorporates this procedure. Unfortunately, the algorithm is still incomplete, but empirically we show that it is able to solve much more MAPF instances (under the strict time limit) with large agents on arbitrary non-planar graphs (roadmaps) compared to the state-of-the-art MAPF solver -- Continous Conflict-Based Search (CCBS).",
        "published": "2022-08-25T17:37:31Z",
        "link": "http://arxiv.org/abs/2208.12236v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "CH-MARL: A Multimodal Benchmark for Cooperative, Heterogeneous   Multi-Agent Reinforcement Learning",
        "authors": [
            "Vasu Sharma",
            "Prasoon Goyal",
            "Kaixiang Lin",
            "Govind Thattai",
            "Qiaozi Gao",
            "Gaurav S. Sukhatme"
        ],
        "summary": "We propose a multimodal (vision-and-language) benchmark for cooperative and heterogeneous multi-agent learning. We introduce a benchmark multimodal dataset with tasks involving collaboration between multiple simulated heterogeneous robots in a rich multi-room home environment. We provide an integrated learning framework, multimodal implementations of state-of-the-art multi-agent reinforcement learning techniques, and a consistent evaluation protocol. Our experiments investigate the impact of different modalities on multi-agent learning performance. We also introduce a simple message passing method between agents. The results suggest that multimodality introduces unique challenges for cooperative multi-agent learning and there is significant room for advancing multi-agent reinforcement learning methods in such settings.",
        "published": "2022-08-26T02:21:31Z",
        "link": "http://arxiv.org/abs/2208.13626v1",
        "categories": [
            "cs.AI",
            "cs.CV",
            "cs.LG",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Socially Fair Reinforcement Learning",
        "authors": [
            "Debmalya Mandal",
            "Jiarui Gan"
        ],
        "summary": "We consider the problem of episodic reinforcement learning where there are multiple stakeholders with different reward functions. Our goal is to output a policy that is socially fair with respect to different reward functions. Prior works have proposed different objectives that a fair policy must optimize including minimum welfare, and generalized Gini welfare. We first take an axiomatic view of the problem, and propose four axioms that any such fair objective must satisfy. We show that the Nash social welfare is the unique objective that uniquely satisfies all four objectives, whereas prior objectives fail to satisfy all four axioms. We then consider the learning version of the problem where the underlying model i.e. Markov decision process is unknown. We consider the problem of minimizing regret with respect to the fair policies maximizing three different fair objectives -- minimum welfare, generalized Gini welfare, and Nash social welfare. Based on optimistic planning, we propose a generic learning algorithm and derive its regret bound with respect to the three different policies. For the objective of Nash social welfare, we also derive a lower bound in regret that grows exponentially with $n$, the number of agents. Finally, we show that for the objective of minimum welfare, one can improve regret by a factor of $O(H)$ for a weaker notion of regret.",
        "published": "2022-08-26T11:01:55Z",
        "link": "http://arxiv.org/abs/2208.12584v2",
        "categories": [
            "cs.LG",
            "cs.CY",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Battery and Hydrogen Energy Storage Control in a Smart Energy Network   with Flexible Energy Demand using Deep Reinforcement Learning",
        "authors": [
            "Cephas Samende",
            "Zhong Fan",
            "Jun Cao"
        ],
        "summary": "Smart energy networks provide for an effective means to accommodate high penetrations of variable renewable energy sources like solar and wind, which are key for deep decarbonisation of energy production. However, given the variability of the renewables as well as the energy demand, it is imperative to develop effective control and energy storage schemes to manage the variable energy generation and achieve desired system economics and environmental goals. In this paper, we introduce a hybrid energy storage system composed of battery and hydrogen energy storage to handle the uncertainties related to electricity prices, renewable energy production and consumption. We aim to improve renewable energy utilisation and minimise energy costs and carbon emissions while ensuring energy reliability and stability within the network. To achieve this, we propose a multi-agent deep deterministic policy gradient approach, which is a deep reinforcement learning-based control strategy to optimise the scheduling of the hybrid energy storage system and energy demand in real-time. The proposed approach is model-free and does not require explicit knowledge and rigorous mathematical models of the smart energy network environment. Simulation results based on real-world data show that: (i) integration and optimised operation of the hybrid energy storage system and energy demand reduces carbon emissions by 78.69%, improves cost savings by 23.5% and renewable energy utilisation by over 13.2% compared to other baseline models and (ii) the proposed algorithm outperforms the state-of-the-art self-learning algorithms like deep-Q network.",
        "published": "2022-08-26T16:47:48Z",
        "link": "http://arxiv.org/abs/2208.12779v1",
        "categories": [
            "eess.SY",
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Will you infect me with your opinion?",
        "authors": [
            "Krzysztof Domino",
            "Jarosław Adam Miszczak"
        ],
        "summary": "Opinion formation is one of the most fascinating phenomena observed in human communities, and the ability to predict and to control the dynamics of this process is interesting from the theoretical as well as practical point of view. Although there are many sophisticated models of opinion formation, they often lack the connection with real life data, and there are still sociological processes that need to be explained. To address this, we propose a model describing the dynamics of opinion formation which mimics the process of the virus or disease spreading in the population. The introduced model is motivated by the model of disease spread with three possible channels - direct contact, indirect contact, and contact with \"contaminated\" elements. We demonstrate that the presence of \"contaminated\" elements, which in the case of on-line communities can be represented as the content published on the Internet, has considerable impact on the process of opinion formation. We argue that by using a simple mechanism of opinion spreading via passive elements, the introduced model captures the meaningful elements of opinion formation in complex communities. The presented work provides a step towards formulating universal laws governing social as well as physical or technical systems.",
        "published": "2022-08-29T08:48:53Z",
        "link": "http://arxiv.org/abs/2208.13426v2",
        "categories": [
            "physics.soc-ph",
            "cs.MA",
            "cs.SI"
        ]
    },
    {
        "title": "Decentralized Coordination in Partially Observable Queueing Networks",
        "authors": [
            "Jiekai Jia",
            "Anam Tahir",
            "Heinz Koeppl"
        ],
        "summary": "We consider communication in a fully cooperative multi-agent system, where the agents have partial observation of the environment and must act jointly to maximize the overall reward. We have a discrete-time queueing network where agents route packets to queues based only on the partial information of the current queue lengths. The queues have limited buffer capacity, so packet drops happen when they are sent to a full queue. In this work, we implemented a communication channel for the agents to share their information in order to reduce the packet drop rate. For efficient information sharing we use an attention-based communication model, called ATVC, to select informative messages from other agents. The agents then infer the state of queues using a combination of the variational auto-encoder, VAE, and product-of-experts, PoE, model. Ultimately, the agents learn what they need to communicate and with whom, instead of communicating all the time with everyone. We also show empirically that ATVC is able to infer the true state of the queues and leads to a policy which outperforms existing baselines.",
        "published": "2022-08-29T14:12:45Z",
        "link": "http://arxiv.org/abs/2208.13621v1",
        "categories": [
            "cs.LG",
            "cs.DC",
            "cs.MA"
        ]
    },
    {
        "title": "A further exploration of deep Multi-Agent Reinforcement Learning with   Hybrid Action Space",
        "authors": [
            "Hongzhi Hua",
            "Guixuan Wen",
            "Kaigui Wu"
        ],
        "summary": "The research of extending deep reinforcement learning (drl) to multi-agent field has solved many complicated problems and made great achievements. However, almost all these studies only focus on discrete or continuous action space and there are few works having ever used multi-agent deep reinforcement learning to real-world environment problems which mostly have a hybrid action space. Therefore, in this paper, we propose two algorithms: deep multi-agent hybrid soft actor-critic (MAHSAC) and multi-agent hybrid deep deterministic policy gradients (MAHDDPG) to fill this gap. This two algorithms follow the centralized training and decentralized execution (CTDE) paradigm and could handle hybrid action space problems. Our experiences are running on multi-agent particle environment which is an easy multi-agent particle world, along with some basic simulated physics. The experimental results show that these algorithms have good performances.",
        "published": "2022-08-30T07:40:15Z",
        "link": "http://arxiv.org/abs/2208.14447v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Distributed Constraint-Coupled Optimization over Lossy Networks",
        "authors": [
            "Mohammadreza Doostmohammadian",
            "Usman A. Khan",
            "Alireza Aghasi",
            "Themistoklis Charalambous"
        ],
        "summary": "This paper considers distributed resource allocation and sum-preserving constrained optimization over lossy networks, where the links are unreliable and subject to packet drops. We define the conditions to ensure convergence under packet drops and link removal by focusing on two main properties of our allocation algorithm: (i) The weight-stochastic condition in typical consensus schemes is reduced to balanced weights, with no need for readjusting the weights to satisfy stochasticity. (ii) The algorithm does not require all-time connectivity but instead uniform connectivity over some non-overlapping finite time intervals. First, we prove that our algorithm provides primal-feasible allocation at every iteration step and converges under the conditions (i)-(ii) and some other mild conditions on the nonlinear iterative dynamics. These nonlinearities address possible practical constraints in real applications due to, for example, saturation or quantization among others. Then, using (i)-(ii) and the notion of bond-percolation theory, we relate the packet drop rate and the network percolation threshold to the (finite) number of iterations ensuring uniform connectivity and, thus, convergence towards the optimum value.",
        "published": "2022-08-30T10:02:17Z",
        "link": "http://arxiv.org/abs/2208.14116v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY",
            "math.OC"
        ]
    },
    {
        "title": "Bayesian Optimization-based Combinatorial Assignment",
        "authors": [
            "Jakob Weissteiner",
            "Jakob Heiss",
            "Julien Siems",
            "Sven Seuken"
        ],
        "summary": "We study the combinatorial assignment domain, which includes combinatorial auctions and course allocation. The main challenge in this domain is that the bundle space grows exponentially in the number of items. To address this, several papers have recently proposed machine learning-based preference elicitation algorithms that aim to elicit only the most important information from agents. However, the main shortcoming of this prior work is that it does not model a mechanism's uncertainty over values for not yet elicited bundles. In this paper, we address this shortcoming by presenting a Bayesian optimization-based combinatorial assignment (BOCA) mechanism. Our key technical contribution is to integrate a method for capturing model uncertainty into an iterative combinatorial auction mechanism. Concretely, we design a new method for estimating an upper uncertainty bound that can be used to define an acquisition function to determine the next query to the agents. This enables the mechanism to properly explore (and not just exploit) the bundle space during its preference elicitation phase. We run computational experiments in several spectrum auction domains to evaluate BOCA's performance. Our results show that BOCA achieves higher allocative efficiency than state-of-the-art approaches.",
        "published": "2022-08-31T08:47:02Z",
        "link": "http://arxiv.org/abs/2208.14698v5",
        "categories": [
            "cs.LG",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Innovation and informal knowledge exchanges between firms",
        "authors": [
            "Juste Raimbault"
        ],
        "summary": "Firm clusters are seen as having a positive effect on innovations, what can be interpreted as economies of scale or knowledge spillovers. The processes underlying the success of these clusters remain difficult to isolate. We propose in this paper a stylised agent-based model to test the role of geographical proximity and informal knowledge exchanges between firms on the emergence of innovations. The model is run on synthetic firm clusters. Sensitivity analysis and systematic model exploration unveil a strong impact of interaction distance on innovations, with a qualitative shift when spatial interactions are more intense. Model bi-objective optimisation shows a compromise between innovation and product diversity, suggesting trade-offs for clusters in practice. This model provides thus a first basis to systematically explore the interplay between firm cluster geography and innovation, from an evolutionary perspective.",
        "published": "2022-08-31T09:26:10Z",
        "link": "http://arxiv.org/abs/2208.14719v1",
        "categories": [
            "cs.MA",
            "cs.CY",
            "physics.soc-ph"
        ]
    },
    {
        "title": "Recent Advances in Modeling and Control of Epidemics using a Mean Field   Approach",
        "authors": [
            "Amal Roy",
            "Chandramani Singh",
            "Y. Narahari"
        ],
        "summary": "Modeling and control of epidemics such as the novel Corona virus have assumed paramount importance at a global level. A natural and powerful dynamical modeling framework to use in this context is a continuous time Markov decision process (CTMDP) that encompasses classical compartmental paradigms such as the Susceptible-Infected-Recovered (SIR) model. The challenges with CTMDP based models motivate the need for a more efficient approach and the mean field approach offers an effective alternative. The mean field approach computes the collective behavior of a dynamical system comprising numerous interacting nodes (where nodes represent individuals in the population). This paper (a) presents an overview of the mean field approach to epidemic modeling and control and (b) provides a state-of-the-art update on recent advances on this topic. Our discussion in this paper proceeds along two specific threads. The first thread assumes that the individual nodes faithfully follow a socially optimal control policy prescribed by a regulatory authority. The second thread allows the individual nodes to exhibit independent, strategic behavior. In this case, the strategic interaction is modeled as a mean field game and the control is based on the associated mean field Nash equilibria. In this paper, we start with a discussion of modeling of epidemics using an extended compartmental model - SIVR and provide an illustrative example. We next provide a review of relevant literature, using a mean field approach, on optimal control of epidemics, dealing with how a regulatory authority may optimally contain epidemic spread in a population. Following this, we provide an update on the literature on the use of the mean field game based approach in the study of epidemic spread and control. We conclude the paper with relevant future research directions.",
        "published": "2022-08-31T10:41:24Z",
        "link": "http://arxiv.org/abs/2208.14765v2",
        "categories": [
            "physics.soc-ph",
            "cs.GT",
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "q-bio.PE"
        ]
    },
    {
        "title": "Taming Multi-Agent Reinforcement Learning with Estimator Variance   Reduction",
        "authors": [
            "Taher Jafferjee",
            "Juliusz Ziomek",
            "Tianpei Yang",
            "Zipeng Dai",
            "Jianhong Wang",
            "Matthew Taylor",
            "Kun Shao",
            "Jun Wang",
            "David Mguni"
        ],
        "summary": "Centralised training with decentralised execution (CT-DE) serves as the foundation of many leading multi-agent reinforcement learning (MARL) algorithms. Despite its popularity, it suffers from a critical drawback due to its reliance on learning from a single sample of the joint-action at a given state. As agents explore and update their policies during training, these single samples may poorly represent the actual joint-policy of the system of agents leading to high variance gradient estimates that hinder learning. To address this problem, we propose an enhancement tool that accommodates any actor-critic MARL method. Our framework, Performance Enhancing Reinforcement Learning Apparatus (PERLA), introduces a sampling technique of the agents' joint-policy into the critics while the agents train. This leads to TD updates that closely approximate the true expected value under the current joint-policy rather than estimates from a single sample of the joint-action at a given state. This produces low variance and precise estimates of expected returns, minimising the variance in the critic estimators which typically hinders learning. Moreover, as we demonstrate, by eliminating much of the critic variance from the single sampling of the joint policy, PERLA enables CT-DE methods to scale more efficiently with the number of agents. Theoretically, we prove that PERLA reduces variance in value estimates similar to that of decentralised training while maintaining the benefits of centralised training. Empirically, we demonstrate PERLA's superior performance and ability to reduce estimator variance in a range of benchmarks including Multi-agent Mujoco, and StarCraft II Multi-agent Challenge.",
        "published": "2022-09-02T13:44:00Z",
        "link": "http://arxiv.org/abs/2209.01054v2",
        "categories": [
            "cs.MA",
            "cs.LG"
        ]
    },
    {
        "title": "Learning Practical Communication Strategies in Cooperative Multi-Agent   Reinforcement Learning",
        "authors": [
            "Diyi Hu",
            "Chi Zhang",
            "Viktor Prasanna",
            "Bhaskar Krishnamachari"
        ],
        "summary": "In Multi-Agent Reinforcement Learning, communication is critical to encourage cooperation among agents. Communication in realistic wireless networks can be highly unreliable due to network conditions varying with agents' mobility, and stochasticity in the transmission process. We propose a framework to learn practical communication strategies by addressing three fundamental questions: (1) When: Agents learn the timing of communication based on not only message importance but also wireless channel conditions. (2) What: Agents augment message contents with wireless network measurements to better select the game and communication actions. (3) How: Agents use a novel neural message encoder to preserve all information from received messages, regardless of the number and order of messages. Simulating standard benchmarks under realistic wireless network settings, we show significant improvements in game performance, convergence speed and communication efficiency compared with state-of-the-art.",
        "published": "2022-09-02T22:18:43Z",
        "link": "http://arxiv.org/abs/2209.01288v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "A repeated unknown game: Decentralized task offloading in vehicular fog   computing",
        "authors": [
            "Byungjin Cho",
            "Yu Xiao"
        ],
        "summary": "Offloading computation to nearby edge/fog computing nodes, including the ones carried by moving vehicles, e.g., vehicular fog nodes (VFN), has proved to be a promising approach for enabling low-latency and compute-intensive mobility applications, such as cooperative and autonomous driving. This work considers vehicular fog computing scenarios where the clients of computation offloading services try to minimize their own costs while deciding which VFNs to offload their tasks. We focus on decentralized multi-agent decision-making in a repeated unknown game where each agent, e.g., service client, can observe only its own action and realized cost. In other words, each agent is unaware of the game composition or even the existence of opponents. We apply a completely uncoupled learning rule to generalize the decentralized decision-making algorithm presented in \\cite{Cho2021} for the multi-agent case. The multi-agent solution proposed in this work can capture the unknown offloading cost variations susceptive to resource congestion under an adversarial framework where each agent may take implicit cost estimation and suitable resource choice adapting to the dynamics associated with volatile supply and demand. According to the evaluation via simulation, this work reveals that such individual perturbations for robustness to uncertainty and adaptation to dynamicity ensure a certain level of optimality in terms of social welfare, e.g., converging the actual sequence of play with unknown and asymmetric attributes and lowering the correspondent cost in social welfare due to the self-interested behaviors of agents.",
        "published": "2022-09-03T07:55:48Z",
        "link": "http://arxiv.org/abs/2209.01353v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Simulation-Assisted Optimization for Large-Scale Evacuation Planning   with Congestion-Dependent Delays",
        "authors": [
            "Kazi Ashik Islam",
            "Da Qi Chen",
            "Madhav Marathe",
            "Henning Mortveit",
            "Samarth Swarup",
            "Anil Vullikanti"
        ],
        "summary": "Evacuation planning is a crucial part of disaster management. However, joint optimization of its two essential components, routing and scheduling, with objectives such as minimizing average evacuation time or evacuation completion time, is a computationally hard problem. To approach it, we present MIP-LNS, a scalable optimization method that utilizes heuristic search with mathematical optimization and can optimize a variety of objective functions. We also present the method MIP-LNS-SIM, where we combine agent-based simulation with MIP-LNS to estimate delays due to congestion, as well as, find optimized plans considering such delays. We use Harris County in Houston, Texas, as our study area. We show that, within a given time limit, MIP-LNS finds better solutions than existing methods in terms of three different metrics. However, when congestion dependent delay is considered, MIP-LNS-SIM outperforms MIP-LNS in multiple performance metrics. In addition, MIP-LNS-SIM has a significantly lower percent error in estimated evacuation completion time compared to MIP-LNS.",
        "published": "2022-09-04T05:30:51Z",
        "link": "http://arxiv.org/abs/2209.01535v6",
        "categories": [
            "cs.AI",
            "cs.CY",
            "cs.MA"
        ]
    },
    {
        "title": "Learning to Deceive in Multi-Agent Hidden Role Games",
        "authors": [
            "Matthew Aitchison",
            "Lyndon Benke",
            "Penny Sweetser"
        ],
        "summary": "Deception is prevalent in human social settings. However, studies into the effect of deception on reinforcement learning algorithms have been limited to simplistic settings, restricting their applicability to complex real-world problems. This paper addresses this by introducing a new mixed competitive-cooperative multi-agent reinforcement learning (MARL) environment inspired by popular role-based deception games such as Werewolf, Avalon, and Among Us. The environment's unique challenge lies in the necessity to cooperate with other agents despite not knowing if they are friend or foe. Furthermore, we introduce a model of deception, which we call Bayesian belief manipulation (BBM) and demonstrate its effectiveness at deceiving other agents in this environment while also increasing the deceiving agent's performance.",
        "published": "2022-09-04T07:35:23Z",
        "link": "http://arxiv.org/abs/2209.01551v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Energy Management of Multi-mode Hybrid Electric Vehicles based on   Hand-shaking Multi-agent Learning",
        "authors": [
            "Min Hua",
            "Zhi Li",
            "Quan Zhou"
        ],
        "summary": "The future transportation system will be a multi-agent network where connected AI agents can work together to address the grand challenges in our age, e.g., mitigation of real-world driving energy consumption. Distinguished from the existing research on vehicle energy management, which decoupled multiple inputs and multiple outputs (MIMO) control into single-output(MISO) control, this paper studied a multi-agent deep reinforcement learning (MADRL) framework to deal with multiple control outputs simultaneously. A new hand-shaking strategy is proposed for the DRL agents by introducing an independence ratio, and a parametric study is conducted to obtain the best setting for the MADRL framework. The study suggested that the MADRL with an independence ratio of 0.2 is the best, and more than 2.4% of energy can be saved over the conventional DRL framework.",
        "published": "2022-09-06T16:40:55Z",
        "link": "http://arxiv.org/abs/2209.02633v3",
        "categories": [
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Bayesian Statistical Model Checking for Multi-agent Systems using   HyperPCTL*",
        "authors": [
            "Spandan Das",
            "Pavithra Prabhakar"
        ],
        "summary": "In this paper, we present a Bayesian method for statistical model checking (SMC) of probabilistic hyperproperties specified in the logic HyperPCTL* on discrete-time Markov chains (DTMCs). While SMC of HyperPCTL* using sequential probability ratio test (SPRT) has been explored before, we develop an alternative SMC algorithm based on Bayesian hypothesis testing. In comparison to PCTL*, verifying HyperPCTL* formulae is complex owing to their simultaneous interpretation on multiple paths of the DTMC. In addition, extending the bottom-up model-checking algorithm of the non-probabilistic setting is not straight forward due to the fact that SMC does not return exact answers to the satisfiability problems of subformulae, instead, it only returns correct answers with high-confidence. We propose a recursive algorithm for SMC of HyperPCTL* based on a modified Bayes' test that factors in the uncertainty in the recursive satisfiability results. We have implemented our algorithm in a Python toolbox, HyProVer, and compared our approach with the SPRT based SMC. Our experimental evaluation demonstrates that our Bayesian SMC algorithm performs better both in terms of the verification time and the number of samples required to deduce satisfiability of a given HyperPCTL* formula.",
        "published": "2022-09-06T17:36:28Z",
        "link": "http://arxiv.org/abs/2209.02672v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LO",
            "cs.RO",
            "I.2.9; G.3"
        ]
    },
    {
        "title": "DC-MRTA: Decentralized Multi-Robot Task Allocation and Navigation in   Complex Environments",
        "authors": [
            "Aakriti Agrawal",
            "Senthil Hariharan",
            "Amrit Singh Bedi",
            "Dinesh Manocha"
        ],
        "summary": "We present a novel reinforcement learning (RL) based task allocation and decentralized navigation algorithm for mobile robots in warehouse environments. Our approach is designed for scenarios in which multiple robots are used to perform various pick up and delivery tasks. We consider the problem of joint decentralized task allocation and navigation and present a two level approach to solve it. At the higher level, we solve the task allocation by formulating it in terms of Markov Decision Processes and choosing the appropriate rewards to minimize the Total Travel Delay (TTD). At the lower level, we use a decentralized navigation scheme based on ORCA that enables each robot to perform these tasks in an independent manner, and avoid collisions with other robots and dynamic obstacles. We combine these lower and upper levels by defining rewards for the higher level as the feedback from the lower level navigation algorithm. We perform extensive evaluation in complex warehouse layouts with large number of agents and highlight the benefits over state-of-the-art algorithms based on myopic pickup distance minimization and regret-based task selection. We observe improvement up to 14% in terms of task completion time and up-to 40% improvement in terms of computing collision-free trajectories for the robots.",
        "published": "2022-09-07T00:35:27Z",
        "link": "http://arxiv.org/abs/2209.02865v1",
        "categories": [
            "cs.RO",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "KT-BT: A Framework for Knowledge Transfer Through Behavior Trees in   Multi-Robot Systems",
        "authors": [
            "Sanjay Sarma Oruganti Venkata",
            "Ramviyas Parasuraman",
            "Ramana Pidaparti"
        ],
        "summary": "Multi-Robot and Multi-Agent Systems demonstrate collective (swarm) intelligence through systematic and distributed integration of local behaviors in a group. Agents sharing knowledge about the mission and environment can enhance performance at individual and mission levels. However, this is difficult to achieve, partly due to the lack of a generic framework for transferring part of the known knowledge (behaviors) between agents. This paper presents a new knowledge representation framework and a transfer strategy called KT-BT: Knowledge Transfer through Behavior Trees. The KT-BT framework follows a query-response-update mechanism through an online Behavior Tree framework, where agents broadcast queries for unknown conditions and respond with appropriate knowledge using a condition-action-control sub-flow. We embed a novel grammar structure called stringBT that encodes knowledge, enabling behavior sharing. We theoretically investigate the properties of the KT-BT framework in achieving homogeneity of high knowledge across the entire group compared to a heterogeneous system without the capability of sharing their knowledge. We extensively verify our framework in a simulated multi-robot search and rescue problem. The results show successful knowledge transfers and improved group performance in various scenarios. We further study the effects of opportunities and communication range on group performance, knowledge spread, and functional heterogeneity in a group of agents, presenting interesting insights.",
        "published": "2022-09-07T02:17:04Z",
        "link": "http://arxiv.org/abs/2209.02886v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Accurate Cooperative Sensor Fusion by Parameterized Covariance   Generation for Sensing and Localization Pipelines in CAVs",
        "authors": [
            "Edward Andert",
            "Aviral Shrivastava"
        ],
        "summary": "A major challenge in cooperative sensing is to weight the measurements taken from the various sources to get an accurate result. Ideally, the weights should be inversely proportional to the error in the sensing information. However, previous cooperative sensor fusion approaches for autonomous vehicles use a fixed error model, in which the covariance of a sensor and its recognizer pipeline is just the mean of the measured covariance for all sensing scenarios. The approach proposed in this paper estimates error using key predictor terms that have high correlation with sensing and localization accuracy for accurate covariance estimation of each sensor observation. We adopt a tiered fusion model consisting of local and global sensor fusion steps. At the local fusion level, we add in a covariance generation stage using the error model for each sensor and the measured distance to generate the expected covariance matrix for each observation. At the global sensor fusion stage we add an additional stage to generate the localization covariance matrix from the key predictor term velocity and combines that with the covariance generated from the local fusion for accurate cooperative sensing. To showcase our method, we built a set of 1/10 scale model autonomous vehicles with scale accurate sensing capabilities and classified the error characteristics against a motion capture system. Results show an average and max improvement in RMSE when detecting vehicle positions of 1.42x and 1.78x respectively in a four-vehicle cooperative fusion scenario when using our error model versus a typical fixed error model.",
        "published": "2022-09-07T17:12:28Z",
        "link": "http://arxiv.org/abs/2209.03306v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "On the Near-Optimality of Local Policies in Large Cooperative   Multi-Agent Reinforcement Learning",
        "authors": [
            "Washim Uddin Mondal",
            "Vaneet Aggarwal",
            "Satish V. Ukkusuri"
        ],
        "summary": "We show that in a cooperative $N$-agent network, one can design locally executable policies for the agents such that the resulting discounted sum of average rewards (value) well approximates the optimal value computed over all (including non-local) policies. Specifically, we prove that, if $|\\mathcal{X}|, |\\mathcal{U}|$ denote the size of state, and action spaces of individual agents, then for sufficiently small discount factor, the approximation error is given by $\\mathcal{O}(e)$ where $e\\triangleq \\frac{1}{\\sqrt{N}}\\left[\\sqrt{|\\mathcal{X}|}+\\sqrt{|\\mathcal{U}|}\\right]$. Moreover, in a special case where the reward and state transition functions are independent of the action distribution of the population, the error improves to $\\mathcal{O}(e)$ where $e\\triangleq \\frac{1}{\\sqrt{N}}\\sqrt{|\\mathcal{X}|}$. Finally, we also devise an algorithm to explicitly construct a local policy. With the help of our approximation results, we further establish that the constructed local policy is within $\\mathcal{O}(\\max\\{e,\\epsilon\\})$ distance of the optimal policy, and the sample complexity to achieve such a local policy is $\\mathcal{O}(\\epsilon^{-3})$, for any $\\epsilon>0$.",
        "published": "2022-09-07T23:15:08Z",
        "link": "http://arxiv.org/abs/2209.03491v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Adaptive Combination of a Genetic Algorithm and Novelty Search for Deep   Neuroevolution",
        "authors": [
            "Eyal Segal",
            "Moshe Sipper"
        ],
        "summary": "Evolutionary Computation (EC) has been shown to be able to quickly train Deep Artificial Neural Networks (DNNs) to solve Reinforcement Learning (RL) problems. While a Genetic Algorithm (GA) is well-suited for exploiting reward functions that are neither deceptive nor sparse, it struggles when the reward function is either of those. To that end, Novelty Search (NS) has been shown to be able to outperform gradient-following optimizers in some cases, while under-performing in others. We propose a new algorithm: Explore-Exploit $\\gamma$-Adaptive Learner ($E^2\\gamma AL$, or EyAL). By preserving a dynamically-sized niche of novelty-seeking agents, the algorithm manages to maintain population diversity, exploiting the reward signal when possible and exploring otherwise. The algorithm combines both the exploitation power of a GA and the exploration power of NS, while maintaining their simplicity and elegance. Our experiments show that EyAL outperforms NS in most scenarios, while being on par with a GA -- and in some scenarios it can outperform both. EyAL also allows the substitution of the exploiting component (GA) and the exploring component (NS) with other algorithms, e.g., Evolution Strategy and Surprise Search, thus opening the door for future research.",
        "published": "2022-09-08T07:50:44Z",
        "link": "http://arxiv.org/abs/2209.03618v1",
        "categories": [
            "cs.NE",
            "cs.MA"
        ]
    },
    {
        "title": "A Survey on Large-Population Systems and Scalable Multi-Agent   Reinforcement Learning",
        "authors": [
            "Kai Cui",
            "Anam Tahir",
            "Gizem Ekinci",
            "Ahmed Elshamanhory",
            "Yannick Eich",
            "Mengguang Li",
            "Heinz Koeppl"
        ],
        "summary": "The analysis and control of large-population systems is of great interest to diverse areas of research and engineering, ranging from epidemiology over robotic swarms to economics and finance. An increasingly popular and effective approach to realizing sequential decision-making in multi-agent systems is through multi-agent reinforcement learning, as it allows for an automatic and model-free analysis of highly complex systems. However, the key issue of scalability complicates the design of control and reinforcement learning algorithms particularly in systems with large populations of agents. While reinforcement learning has found resounding empirical success in many scenarios with few agents, problems with many agents quickly become intractable and necessitate special consideration. In this survey, we will shed light on current approaches to tractably understanding and analyzing large-population systems, both through multi-agent reinforcement learning and through adjacent areas of research such as mean-field games, collective intelligence, or complex network theory. These classically independent subject areas offer a variety of approaches to understanding or modeling large-population systems, which may be of great use for the formulation of tractable MARL algorithms in the future. Finally, we survey potential areas of application for large-scale control and identify fruitful future applications of learning algorithms in practical systems. We hope that our survey could provide insight and future directions to junior and senior researchers in theoretical and applied sciences alike.",
        "published": "2022-09-08T14:58:50Z",
        "link": "http://arxiv.org/abs/2209.03859v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Learning Sparse Graphon Mean Field Games",
        "authors": [
            "Christian Fabian",
            "Kai Cui",
            "Heinz Koeppl"
        ],
        "summary": "Although the field of multi-agent reinforcement learning (MARL) has made considerable progress in the last years, solving systems with a large number of agents remains a hard challenge. Graphon mean field games (GMFGs) enable the scalable analysis of MARL problems that are otherwise intractable. By the mathematical structure of graphons, this approach is limited to dense graphs which are insufficient to describe many real-world networks such as power law graphs. Our paper introduces a novel formulation of GMFGs, called LPGMFGs, which leverages the graph theoretical concept of $L^p$ graphons and provides a machine learning tool to efficiently and accurately approximate solutions for sparse network problems. This especially includes power law networks which are empirically observed in various application areas and cannot be captured by standard graphons. We derive theoretical existence and convergence guarantees and give empirical examples that demonstrate the accuracy of our learning approach for systems with many agents. Furthermore, we extend the Online Mirror Descent (OMD) learning algorithm to our setup to accelerate learning speed, empirically show its capabilities, and conduct a theoretical analysis using the novel concept of smoothed step graphons. In general, we provide a scalable, mathematically well-founded machine learning approach to a large class of otherwise intractable problems of great relevance in numerous research fields.",
        "published": "2022-09-08T15:35:42Z",
        "link": "http://arxiv.org/abs/2209.03880v3",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.GT",
            "cs.LG"
        ]
    },
    {
        "title": "Mean Field Games on Weighted and Directed Graphs via Colored Digraphons",
        "authors": [
            "Christian Fabian",
            "Kai Cui",
            "Heinz Koeppl"
        ],
        "summary": "The field of multi-agent reinforcement learning (MARL) has made considerable progress towards controlling challenging multi-agent systems by employing various learning methods. Numerous of these approaches focus on empirical and algorithmic aspects of the MARL problems and lack a rigorous theoretical foundation. Graphon mean field games (GMFGs) on the other hand provide a scalable and mathematically well-founded approach to learning problems that involve a large number of connected agents. In standard GMFGs, the connections between agents are undirected, unweighted and invariant over time. Our paper introduces colored digraphon mean field games (CDMFGs) which allow for weighted and directed links between agents that are also adaptive over time. Thus, CDMFGs are able to model more complex connections than standard GMFGs. Besides a rigorous theoretical analysis including both existence and convergence guarantees, we provide a learning scheme and illustrate our findings with an epidemics model and a model of the systemic risk in financial markets.",
        "published": "2022-09-08T15:45:20Z",
        "link": "http://arxiv.org/abs/2209.03887v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.GT",
            "cs.LG"
        ]
    },
    {
        "title": "Joint Caching and Transmission in the Mobile Edge Network: A Multi-Agent   Learning Approach",
        "authors": [
            "Qirui Mi",
            "Ning Yang",
            "Haifeng Zhang",
            "Haijun Zhang",
            "Jun Wang"
        ],
        "summary": "Joint caching and transmission optimization problem is challenging due to the deep coupling between decisions. This paper proposes an iterative distributed multi-agent learning approach to jointly optimize caching and transmission. The goal of this approach is to minimize the total transmission delay of all users. In this iterative approach, each iteration includes caching optimization and transmission optimization. A multi-agent reinforcement learning (MARL)-based caching network is developed to cache popular tasks, such as answering which files to evict from the cache and which files to storage. Based on the cached files of the caching network, the transmission network transmits cached files for users by single transmission (ST) or joint transmission (JT) with multi-agent Bayesian learning automaton (MABLA) method. And then users access the edge servers with the minimum transmission delay. The experimental results demonstrate the performance of the proposed multi-agent learning approach.",
        "published": "2022-09-09T07:51:10Z",
        "link": "http://arxiv.org/abs/2209.04164v1",
        "categories": [
            "cs.MA",
            "cs.NI"
        ]
    },
    {
        "title": "Multi-Agent Path Finding on Strongly Connected Digraphs: feasibility and   solution algorithms",
        "authors": [
            "Stefano Ardizzoni",
            "Irene Saccani",
            "Luca Consolini",
            "Marco Locatelli"
        ],
        "summary": "On an assigned graph, the problem of Multi-Agent Pathfinding (MAPF) consists in finding paths for multiple agents, avoiding collisions. Finding the minimum-length solution is known to be NP-hard, and computation times grows exponentially with the number of agents. However, in industrial applications, it is important to find feasible, suboptimal solutions, in a time that grows polynomially with the number of agents. Such algorithms exist for undirected and biconnected directed graphs. Our main contribution is to generalize these algorithms to the more general case of strongly connected directed graphs. In particular, given a MAPF problem with at least two holes, we present an algorithm that checks the problem feasibility in linear time with respect to the number of nodes, and provides a feasible solution in polynomial time.",
        "published": "2022-09-09T13:18:36Z",
        "link": "http://arxiv.org/abs/2209.04286v1",
        "categories": [
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Cooperation and Competition: Flocking with Evolutionary Multi-Agent   Reinforcement Learning",
        "authors": [
            "Yunxiao Guo",
            "Xinjia Xie",
            "Runhao Zhao",
            "Chenglan Zhu",
            "Jiangting Yin",
            "Han Long"
        ],
        "summary": "Flocking is a very challenging problem in a multi-agent system; traditional flocking methods also require complete knowledge of the environment and a precise model for control. In this paper, we propose Evolutionary Multi-Agent Reinforcement Learning (EMARL) in flocking tasks, a hybrid algorithm that combines cooperation and competition with little prior knowledge. As for cooperation, we design the agents' reward for flocking tasks according to the boids model. While for competition, agents with high fitness are designed as senior agents, and those with low fitness are designed as junior, letting junior agents inherit the parameters of senior agents stochastically. To intensify competition, we also design an evolutionary selection mechanism that shows effectiveness on credit assignment in flocking tasks. Experimental results in a range of challenging and self-contrast benchmarks demonstrate that EMARL significantly outperforms the full competition or cooperation methods.",
        "published": "2022-09-10T15:35:20Z",
        "link": "http://arxiv.org/abs/2209.04696v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.RO"
        ]
    },
    {
        "title": "Graphon Mean-Field Control for Cooperative Multi-Agent Reinforcement   Learning",
        "authors": [
            "Yuanquan Hu",
            "Xiaoli Wei",
            "Junji Yan",
            "Hengxi Zhang"
        ],
        "summary": "The marriage between mean-field theory and reinforcement learning has shown a great capacity to solve large-scale control problems with homogeneous agents. To break the homogeneity restriction of mean-field theory, a recent interest is to introduce graphon theory to the mean-field paradigm. In this paper, we propose a graphon mean-field control (GMFC) framework to approximate cooperative multi-agent reinforcement learning (MARL) with nonuniform interactions and show that the approximate order is of $\\mathcal{O}(\\frac{1}{\\sqrt{N}})$, with $N$ the number of agents. By discretizing the graphon index of GMFC, we further introduce a smaller class of GMFC called block GMFC, which is shown to well approximate cooperative MARL. Our empirical studies on several examples demonstrate that our GMFC approach is comparable with the state-of-art MARL algorithms while enjoying better scalability.",
        "published": "2022-09-11T08:00:39Z",
        "link": "http://arxiv.org/abs/2209.04808v1",
        "categories": [
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "Mean-Field Control Approach to Decentralized Stochastic Control with   Finite-Dimensional Memories",
        "authors": [
            "Takehiro Tottori",
            "Tetsuya J. Kobayashi"
        ],
        "summary": "Decentralized stochastic control (DSC) considers the optimal control problem of a multi-agent system. However, DSC cannot be solved except in the special cases because the estimation among the agents is generally intractable. In this work, we propose memory-limited DSC (ML-DSC), in which each agent compresses the observation history into the finite-dimensional memory. Because this compression simplifies the estimation among the agents, ML-DSC can be solved in more general cases based on the mean-field control theory. We demonstrate ML-DSC in the general LQG problem. Because estimation and control are not clearly separated in the general LQG problem, the Riccati equation is modified to the decentralized Riccati equation, which improves estimation as well as control. Our numerical experiment shows that the decentralized Riccati equation is superior to the conventional Riccati equation.",
        "published": "2022-09-12T07:52:27Z",
        "link": "http://arxiv.org/abs/2209.05067v1",
        "categories": [
            "math.OC",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Empirically grounded agent-based policy evaluation of the adoption of   sustainable lighting under the European Ecodesign Directive",
        "authors": [
            "Gido H. Schoenmacker",
            "Wander Jager",
            "Rineke Verbrugge"
        ],
        "summary": "Twelve years ago, the European Union began with the gradual phase-out of energy-inefficient incandescent light bulbs under the Ecodesign Directive. In this work, we implement an agent-based simulation to model the consumer behaviour in the EU lighting market with the goal to explain consumer behaviour and explore alternative policies. Agents are based on the Consumat II model, have individual preferences based on empirical market research, gather experience from past actions, and socially interact with each other in a dynamic environment. Our findings suggest that the adoption of energy-friendly lighting alternatives was hindered by a low level of consumer interest combined with high-enough levels of satisfaction about incandescent bulbs and that information campaigns can partially address this. These findings offer insight into both individual-level driving forces of behaviour and society-level outcomes in a niche market. With this, our work demonstrates the strengths of agent-based models for policy generation and evaluation.",
        "published": "2022-09-12T09:32:17Z",
        "link": "http://arxiv.org/abs/2209.05109v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Solving the Job Shop Scheduling Problem with Ant Colony Optimization",
        "authors": [
            "Alysson Ribeiro da Silva"
        ],
        "summary": "The Job Shop Schedule Problem (JSSP) refers to the ability of an agent to allocate tasks that should be executed in a specified time in a machine from a cluster. The task allocation can be achieved from several methods, however, this report it is explored the ability of the Ant Colony Optimization to generate feasible solutions for several JSSP instances. This proposal models the JSSP as a complete graph since disjunct models can prevent the ACO from exploring all the search space. Several instances of the JSSP were used to evaluate the proposal. Results suggest that the algorithm can reach optimum solutions for easy and harder instances with a selection of parameters.",
        "published": "2022-09-12T14:38:43Z",
        "link": "http://arxiv.org/abs/2209.05284v1",
        "categories": [
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Exploration and Coverage with Swarms of Settling Agents",
        "authors": [
            "Ori Rappel",
            "Joseph Ben-Asher",
            "Alfred Bruckstein"
        ],
        "summary": "We consider several algorithms for exploring and filling an unknown, connected region, by simple, airborne agents. The agents are assumed to be identical, autonomous, anonymous and to have a finite amount of memory. The region is modeled as a connected sub-set of a regular grid composed of square cells. The algorithms described herein are suited for Micro Air Vehicles (MAV) since these air vehicles enable unobstructed views of the ground below and can move freely in space at various heights. The agents explore the region by applying various action-rules based on locally acquired information Some of them may settle in unoccupied cells as the exploration progresses. Settled agents become virtual pheromones for the exploration and coverage process, beacons that subsequently aid the remaining, and still exploring, mobile agents. We introduce a backward propagating information diffusion process as a way to implement a deterministic indicator of process termination and guide the mobile agents. For the proposed algorithms, complete covering of the graph in finite time is guaranteed when the size of the region is fixed. Bounds on the coverage times are also derived. Extensive simulation results exhibit good agreement with the theoretical predictions.",
        "published": "2022-09-12T18:03:44Z",
        "link": "http://arxiv.org/abs/2209.05512v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "RTAW: An Attention Inspired Reinforcement Learning Method for   Multi-Robot Task Allocation in Warehouse Environments",
        "authors": [
            "Aakriti Agrawal",
            "Amrit Singh Bedi",
            "Dinesh Manocha"
        ],
        "summary": "We present a novel reinforcement learning based algorithm for multi-robot task allocation problem in warehouse environments. We formulate it as a Markov Decision Process and solve via a novel deep multi-agent reinforcement learning method (called RTAW) with attention inspired policy architecture. Hence, our proposed policy network uses global embeddings that are independent of the number of robots/tasks. We utilize proximal policy optimization algorithm for training and use a carefully designed reward to obtain a converged policy. The converged policy ensures cooperation among different robots to minimize total travel delay (TTD) which ultimately improves the makespan for a sufficiently large task-list. In our extensive experiments, we compare the performance of our RTAW algorithm to state of the art methods such as myopic pickup distance minimization (greedy) and regret based baselines on different navigation schemes. We show an improvement of upto 14% (25-1000 seconds) in TTD on scenarios with hundreds or thousands of tasks for different challenging warehouse layouts and task generation schemes. We also demonstrate the scalability of our approach by showing performance with up to $1000$ robots in simulations.",
        "published": "2022-09-13T05:21:53Z",
        "link": "http://arxiv.org/abs/2209.05738v2",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "D-Lite: Navigation-Oriented Compression of 3D Scene Graphs for   Multi-Robot Collaboration",
        "authors": [
            "Yun Chang",
            "Luca Ballotta",
            "Luca Carlone"
        ],
        "summary": "For a multi-robot team that collaboratively explores an unknown environment, it is of vital importance that collected information is efficiently shared among robots in order to support exploration and navigation tasks. Practical constraints of wireless channels, such as limited bandwidth, urge robots to carefully select information to be transmitted. In this paper, we consider the case where environmental information is modeled using a 3D Scene Graph, a hierarchical map representation that describes both geometric and semantic aspects of the environment. Then, we leverage graph-theoretic tools, namely graph spanners, to design greedy algorithms that efficiently compress 3D Scene Graphs with the aim of enabling communication between robots under bandwidth constraints. Our compression algorithms are navigation-oriented in that they are designed to approximately preserve shortest paths between locations of interest, while meeting a user-specified communication budget constraint. The effectiveness of the proposed algorithms is demonstrated in synthetic robot navigation experiments in a realistic simulator. A video abstract is available at https://youtu.be/nKYXU5VC6A8.",
        "published": "2022-09-13T16:05:31Z",
        "link": "http://arxiv.org/abs/2209.06111v6",
        "categories": [
            "cs.RO",
            "cs.DM",
            "cs.MA",
            "05C85 (Primary), 65D19, 91B32 (Secondary)",
            "I.2.9; I.2.10; I.2.11; G.2.2; C.2.4"
        ]
    },
    {
        "title": "Collective Adaptation in Multi-Agent Systems: How Predator Confusion   Shapes Swarm-Like Behaviors",
        "authors": [
            "Georgi Ivanov",
            "George Palamas"
        ],
        "summary": "Popular hypotheses about the origins of collective adaptation are related to two basic behaviours: protection from predators and a combined search for food resources. Among the anti-predator explanations, the predator confusion hypothesis suggests that groups of individuals moving in a swarm aim to overwhelm the predator while the dilution of risk hypothesis suggests that the probability of a single prey being targeted by a predator is lower in larger groups. In this paper, we explore how emergent behaviors arise from a predator-driven process as an adaptive response to external stimuli perceived as threatening. Moreover, we suggest a predator confusion process to provide a selective pressure for the prey to evolve group formations. We analyze the foraging and prey-predator dynamics evolved in terms of group density and formation, behavior consistency, predator evasion and success rate, and foraging rate. Two agents' perceptual models are compared. A local observation model, where agents can only see what's in their immediate vicinity, and a global observation model, where agents are able to see the predator at all times. Both models were evolved for predator avoidance, foraging and collision avoidance, using reinforcement learning in a simulated game environment. Our results suggest that the dilution of risk factor is sufficient to evolve group formations, and the predator confusion effect could play an important role in the evolution of collaborative behaviors. Finally, we show how variations in the information exchange of this social order can impact the global collective behaviors.",
        "published": "2022-09-13T22:53:23Z",
        "link": "http://arxiv.org/abs/2209.06338v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "An ensemble Multi-Agent System for non-linear classification",
        "authors": [
            "Thibault Fourez",
            "Nicolas Verstaevel",
            "Frédéric Migeon",
            "Frédéric Schettini",
            "Frederic Amblard"
        ],
        "summary": "Self-Adaptive Multi-Agent Systems (AMAS) transform machine learning problems into problems of local cooperation between agents. We present smapy, an ensemble based AMAS implementation for mobility prediction, whose agents are provided with machine learning models in addition to their cooperation rules. With a detailed methodology, we show that it is possible to use linear models for nonlinear classification on a benchmark transport mode detection dataset, if they are integrated in a cooperative multi-agent structure. The results obtained show a significant improvement of the performance of linear models in non-linear contexts thanks to the multi-agent approach.",
        "published": "2022-09-14T08:22:11Z",
        "link": "http://arxiv.org/abs/2209.06824v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Valid Utility Games with Information Sharing Constraints",
        "authors": [
            "David Grimsman",
            "Philip N. Brown",
            "Jason R. Marden"
        ],
        "summary": "The use of game theoretic methods for control in multiagent systems has been an important topic in recent research. Valid utility games in particular have been used to model real-world problems; such games have the convenient property that the value of any decision set which is a Nash equilibrium of the game is guaranteed to be within 1/2 of the value of the optimal decision set. However, an implicit assumption in this guarantee is that each agent is aware of the decisions of all other agents. In this work, we first describe how this guarantee degrades as agents are only aware of a subset of the decisions of other agents. We then show that this loss can be mitigated by restriction to a relevant subclass of games.",
        "published": "2022-09-15T05:24:15Z",
        "link": "http://arxiv.org/abs/2209.07055v1",
        "categories": [
            "cs.GT",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "On Generalization of Decentralized Learning with Separable Data",
        "authors": [
            "Hossein Taheri",
            "Christos Thrampoulidis"
        ],
        "summary": "Decentralized learning offers privacy and communication efficiency when data are naturally distributed among agents communicating over an underlying graph. Motivated by overparameterized learning settings, in which models are trained to zero training loss, we study algorithmic and generalization properties of decentralized learning with gradient descent on separable data. Specifically, for decentralized gradient descent (DGD) and a variety of loss functions that asymptote to zero at infinity (including exponential and logistic losses), we derive novel finite-time generalization bounds. This complements a long line of recent work that studies the generalization performance and the implicit bias of gradient descent over separable data, but has thus far been limited to centralized learning scenarios. Notably, our generalization bounds approximately match in order their centralized counterparts. Critical behind this, and of independent interest, is establishing novel bounds on the training loss and the rate-of-consensus of DGD for a class of self-bounded losses. Finally, on the algorithmic front, we design improved gradient-based routines for decentralized learning with separable data and empirically demonstrate orders-of-magnitude of speed-up in terms of both training and generalization performance.",
        "published": "2022-09-15T07:59:05Z",
        "link": "http://arxiv.org/abs/2209.07116v4",
        "categories": [
            "cs.LG",
            "cs.DC",
            "cs.MA",
            "eess.SP"
        ]
    },
    {
        "title": "How to solve a classification problem using a cooperative tiling   Multi-Agent System?",
        "authors": [
            "Thibault Fourez",
            "Nicolas Verstaevel",
            "Frédéric Migeon",
            "Frédéric Schettini",
            "Frédéric Amblard"
        ],
        "summary": "Adaptive Multi-Agent Systems (AMAS) transform dynamic problems into problems of local cooperation between agents. We present smapy, an ensemble based AMAS implementation for mobility prediction, whose agents are provided with machine learning models in addition to their cooperation rules. With a detailed methodology, we propose a framework to transform a classification problem into a cooperative tiling of the input variable space. We show that it is possible to use linear classifiers for online non-linear classification on three benchmark toy problems chosen for their different levels of linear separability, if they are integrated in a cooperative Multi-Agent structure. The results obtained show a significant improvement of the performance of linear classifiers in non-linear contexts in terms of classification accuracy and decision boundaries, thanks to the cooperative approach.",
        "published": "2022-09-15T09:35:33Z",
        "link": "http://arxiv.org/abs/2209.14239v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "MIXRTs: Toward Interpretable Multi-Agent Reinforcement Learning via   Mixing Recurrent Soft Decision Trees",
        "authors": [
            "Zichuan Liu",
            "Yuanyang Zhu",
            "Zhi Wang",
            "Yang Gao",
            "Chunlin Chen"
        ],
        "summary": "While achieving tremendous success in various fields, existing multi-agent reinforcement learning (MARL) with a black-box neural network architecture makes decisions in an opaque manner that hinders humans from understanding the learned knowledge and how input observations influence decisions. Instead, existing interpretable approaches, such as traditional linear models and decision trees, usually suffer from weak expressivity and low accuracy. To address this apparent dichotomy between performance and interpretability, our solution, MIXing Recurrent soft decision Trees (MIXRTs), is a novel interpretable architecture that can represent explicit decision processes via the root-to-leaf path and reflect each agent's contribution to the team. Specifically, we construct a novel soft decision tree to address partial observability by leveraging the advances in recurrent neural networks, and demonstrate which features influence the decision-making process through the tree-based model. Then, based on the value decomposition framework, we linearly assign credit to each agent by explicitly mixing individual action values to estimate the joint action value using only local observations, providing new insights into how agents cooperate to accomplish the task. Theoretical analysis shows that MIXRTs guarantees the structural constraint on additivity and monotonicity in the factorization of joint action values. Evaluations on the challenging Spread and StarCraft II tasks show that MIXRTs achieves competitive performance compared to widely investigated methods and delivers more straightforward explanations of the decision processes. We explore a promising path toward developing learning algorithms with both high performance and interpretability, potentially shedding light on new interpretable paradigms for MARL.",
        "published": "2022-09-15T11:39:59Z",
        "link": "http://arxiv.org/abs/2209.07225v3",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "The Controllability and Structural Controllability of Laplacian Dynamics",
        "authors": [
            "Jijun Qu",
            "Zhijian Ji",
            "Yungang Liu",
            "Chong Lin"
        ],
        "summary": "In this paper, classic controllability and structural controllability under two protocols are investigated. For classic controllability, the multiplicity of eigenvalue zero of general Laplacian matrix $L^*$ is shown to be determined by the sum of the numbers of zero circles, identical nodes and opposite pairs, while it is always simple for the Laplacian $L$ with diagonal entries in absolute form. For a fixed structurally balanced topology, the controllable subspace is proved to be invariant even if the antagonistic weights are selected differently under the corresponding protocol with $L$. For a graph expanded from a star graph rooted from a single leader, the dimension of controllable subspace is two under the protocol associated with $L^*$. In addition, the system is structurally controllable under both protocols if and only if the topology without unaccessible nodes is connected. As a reinforcing case of structural controllability, strong structural controllability requires the system to be controllable for any choice of weights. The connection between father nodes and child nodes affects strong structural controllability because it determines the linear relationship of the control information from father nodes. This discovery is a major factor in establishing the sufficient conditions on strong structural controllability for multi-agent systems under both protocols, rather than for complex networks, about latter results are already abundant.",
        "published": "2022-09-15T12:01:09Z",
        "link": "http://arxiv.org/abs/2209.07236v1",
        "categories": [
            "math.OC",
            "cs.MA"
        ]
    },
    {
        "title": "Mean-Field Approximation of Cooperative Constrained Multi-Agent   Reinforcement Learning (CMARL)",
        "authors": [
            "Washim Uddin Mondal",
            "Vaneet Aggarwal",
            "Satish V. Ukkusuri"
        ],
        "summary": "Mean-Field Control (MFC) has recently been proven to be a scalable tool to approximately solve large-scale multi-agent reinforcement learning (MARL) problems. However, these studies are typically limited to unconstrained cumulative reward maximization framework. In this paper, we show that one can use the MFC approach to approximate the MARL problem even in the presence of constraints. Specifically, we prove that, an $N$-agent constrained MARL problem, with state, and action spaces of each individual agents being of sizes $|\\mathcal{X}|$, and $|\\mathcal{U}|$ respectively, can be approximated by an associated constrained MFC problem with an error, $e\\triangleq \\mathcal{O}\\left([\\sqrt{|\\mathcal{X}|}+\\sqrt{|\\mathcal{U}|}]/\\sqrt{N}\\right)$. In a special case where the reward, cost, and state transition functions are independent of the action distribution of the population, we prove that the error can be improved to $e=\\mathcal{O}(\\sqrt{|\\mathcal{X}|}/\\sqrt{N})$. Also, we provide a Natural Policy Gradient based algorithm and prove that it can solve the constrained MARL problem within an error of $\\mathcal{O}(e)$ with a sample complexity of $\\mathcal{O}(e^{-6})$.",
        "published": "2022-09-15T16:33:38Z",
        "link": "http://arxiv.org/abs/2209.07437v2",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Differentiable Bilevel Programming for Stackelberg Congestion Games",
        "authors": [
            "Jiayang Li",
            "Jing Yu",
            "Qianni Wang",
            "Boyi Liu",
            "Zhaoran Wang",
            "Yu Marco Nie"
        ],
        "summary": "In a Stackelberg congestion game (SCG), a leader aims to maximize their own gain by anticipating and manipulating the equilibrium state at which the followers settle by playing a congestion game. Often formulated as bilevel programs, large-scale SCGs are well known for their intractability and complexity. Here, we attempt to tackle this computational challenge by marrying traditional methodologies with the latest differentiable programming techniques in machine learning. The core idea centers on replacing the lower-level equilibrium problem with a smooth evolution trajectory defined by the imitative logit dynamic (ILD), which we prove converges to the equilibrium of the congestion game under mild conditions. Building upon this theoretical foundation, we propose two new local search algorithms for SCGs. The first is a gradient descent algorithm that obtains the derivatives by unrolling ILD via differentiable programming. Thanks to the smoothness of ILD, the algorithm promises both efficiency and scalability. The second algorithm adds a heuristic twist by cutting short the followers' evolution trajectory. Behaviorally, this means that, instead of anticipating the followers' best response at equilibrium, the leader seeks to approximate that response by only looking ahead a limited number of steps. Our numerical experiments are carried out over various instances of classic SCG applications, ranging from toy benchmarks to large-scale real-world examples. The results show the proposed algorithms are reliable and scalable local solvers that deliver high-quality solutions with greater regularity and significantly less computational effort compared to the many incumbents included in our study.",
        "published": "2022-09-15T21:32:23Z",
        "link": "http://arxiv.org/abs/2209.07618v4",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Computing the optimal distributionally-robust strategy to commit to",
        "authors": [
            "Sai Mali Ananthanarayanan",
            "Christian Kroer"
        ],
        "summary": "The Stackelberg game model, where a leader commits to a strategy and the follower best responds, has found widespread application, particularly to security problems. In the security setting, the goal is for the leader to compute an optimal strategy to commit to, in order to protect some asset. In many of these applications, the parameters of the follower utility model are not known with certainty. Distributionally-robust optimization addresses this issue by allowing a distribution over possible model parameters, where this distribution comes from a set of possible distributions. The goal is to maximize the expected utility with respect to the worst-case distribution. We initiate the study of distributionally-robust models for computing the optimal strategy to commit to. We consider the case of normal-form games with uncertainty about the follower utility model. Our main theoretical result is to show that a distributionally-robust Stackelberg equilibrium always exists across a wide array of uncertainty models. For the case of a finite set of possible follower utility functions we present two algorithms to compute a distributionally-robust strong Stackelberg equilibrium (DRSSE) using mathematical programs. Next, in the general case where there is an infinite number of possible follower utility functions and the uncertainty is represented by a Wasserstein ball around a finitely-supported nominal distribution, we give an incremental mixed-integer-programming-based algorithm for computing the optimal distributionally-robust strategy. Experiments substantiate the tractability of our algorithm on a classical Stackelberg game, showing that our approach scales to medium-sized games.",
        "published": "2022-09-15T23:20:26Z",
        "link": "http://arxiv.org/abs/2209.07647v1",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Quantization for decentralized learning under subspace constraints",
        "authors": [
            "Roula Nassif",
            "Stefan Vlaski",
            "Marco Carpentiero",
            "Vincenzo Matta",
            "Marc Antonini",
            "Ali H. Sayed"
        ],
        "summary": "In this paper, we consider decentralized optimization problems where agents have individual cost functions to minimize subject to subspace constraints that require the minimizers across the network to lie in low-dimensional subspaces. This constrained formulation includes consensus or single-task optimization as special cases, and allows for more general task relatedness models such as multitask smoothness and coupled optimization. In order to cope with communication constraints, we propose and study an adaptive decentralized strategy where the agents employ differential randomized quantizers to compress their estimates before communicating with their neighbors. The analysis shows that, under some general conditions on the quantization noise, and for sufficiently small step-sizes $\\mu$, the strategy is stable both in terms of mean-square error and average bit rate: by reducing $\\mu$, it is possible to keep the estimation errors small (on the order of $\\mu$) without increasing indefinitely the bit rate as $\\mu\\rightarrow 0$. Simulations illustrate the theoretical findings and the effectiveness of the proposed approach, revealing that decentralized learning is achievable at the expense of only a few bits.",
        "published": "2022-09-16T09:38:38Z",
        "link": "http://arxiv.org/abs/2209.07821v2",
        "categories": [
            "math.OC",
            "cs.LG",
            "cs.MA",
            "eess.SP"
        ]
    },
    {
        "title": "Optimizing Industrial HVAC Systems with Hierarchical Reinforcement   Learning",
        "authors": [
            "William Wong",
            "Praneet Dutta",
            "Octavian Voicu",
            "Yuri Chervonyi",
            "Cosmin Paduraru",
            "Jerry Luo"
        ],
        "summary": "Reinforcement learning (RL) techniques have been developed to optimize industrial cooling systems, offering substantial energy savings compared to traditional heuristic policies. A major challenge in industrial control involves learning behaviors that are feasible in the real world due to machinery constraints. For example, certain actions can only be executed every few hours while other actions can be taken more frequently. Without extensive reward engineering and experimentation, an RL agent may not learn realistic operation of machinery. To address this, we use hierarchical reinforcement learning with multiple agents that control subsets of actions according to their operation time scales. Our hierarchical approach achieves energy savings over existing baselines while maintaining constraints such as operating chillers within safe bounds in a simulated HVAC control environment.",
        "published": "2022-09-16T18:00:46Z",
        "link": "http://arxiv.org/abs/2209.08112v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "cs.RO",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "ASIR: Robust Agent-based Representation Of SIR Model",
        "authors": [
            "Boyan Xu"
        ],
        "summary": "Compartmental models (written as $CM$) and agent-based models (written as $AM$) are dominant methods in the field of epidemic simulation. But in the literature there lacks discussion on how to build the \\textbf{quantitative relationship} between them. In this paper, we propose an agent-based $SIR$ model: $ASIR$. $ASIR$ can robustly reproduce the infection curve predicted by a given SIR model (the simplest $CM$.) Notably, one can deduce any parameter of $ASIR$ from parameters of $SIR$ without manual tuning. $ASIR$ offers epidemiologists a method to transform a calibrated $SIR$ model into an agent-based model that inherit $SIR$'s performance without another round of calibration. The design $ASIR$ is inspirational for building a general quantitative relationship between $CM$ and $AM$.",
        "published": "2022-09-17T02:01:30Z",
        "link": "http://arxiv.org/abs/2209.08214v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "A Robust and Constrained Multi-Agent Reinforcement Learning Electric   Vehicle Rebalancing Method in AMoD Systems",
        "authors": [
            "Sihong He",
            "Yue Wang",
            "Shuo Han",
            "Shaofeng Zou",
            "Fei Miao"
        ],
        "summary": "Electric vehicles (EVs) play critical roles in autonomous mobility-on-demand (AMoD) systems, but their unique charging patterns increase the model uncertainties in AMoD systems (e.g. state transition probability). Since there usually exists a mismatch between the training and test/true environments, incorporating model uncertainty into system design is of critical importance in real-world applications. However, model uncertainties have not been considered explicitly in EV AMoD system rebalancing by existing literature yet, and the coexistence of model uncertainties and constraints that the decision should satisfy makes the problem even more challenging. In this work, we design a robust and constrained multi-agent reinforcement learning (MARL) framework with state transition kernel uncertainty for EV AMoD systems. We then propose a robust and constrained MARL algorithm (ROCOMA) with robust natural policy gradients (RNPG) that trains a robust EV rebalancing policy to balance the supply-demand ratio and the charging utilization rate across the city under model uncertainty. Experiments show that the ROCOMA can learn an effective and robust rebalancing policy. It outperforms non-robust MARL methods in the presence of model uncertainties. It increases the system fairness by 19.6% and decreases the rebalancing costs by 75.8%.",
        "published": "2022-09-17T03:24:10Z",
        "link": "http://arxiv.org/abs/2209.08230v2",
        "categories": [
            "cs.MA",
            "cs.LG",
            "cs.RO",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "MA2QL: A Minimalist Approach to Fully Decentralized Multi-Agent   Reinforcement Learning",
        "authors": [
            "Kefan Su",
            "Siyuan Zhou",
            "Jiechuan Jiang",
            "Chuang Gan",
            "Xiangjun Wang",
            "Zongqing Lu"
        ],
        "summary": "Decentralized learning has shown great promise for cooperative multi-agent reinforcement learning (MARL). However, non-stationarity remains a significant challenge in fully decentralized learning. In the paper, we tackle the non-stationarity problem in the simplest and fundamental way and propose multi-agent alternate Q-learning (MA2QL), where agents take turns updating their Q-functions by Q-learning. MA2QL is a minimalist approach to fully decentralized cooperative MARL but is theoretically grounded. We prove that when each agent guarantees $\\varepsilon$-convergence at each turn, their joint policy converges to a Nash equilibrium. In practice, MA2QL only requires minimal changes to independent Q-learning (IQL). We empirically evaluate MA2QL on a variety of cooperative multi-agent tasks. Results show MA2QL consistently outperforms IQL, which verifies the effectiveness of MA2QL, despite such minimal changes.",
        "published": "2022-09-17T04:54:32Z",
        "link": "http://arxiv.org/abs/2209.08244v2",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Sub-optimal Policy Aided Multi-Agent Reinforcement Learning for Flocking   Control",
        "authors": [
            "Yunbo Qiu",
            "Yue Jin",
            "Jian Wang",
            "Xudong Zhang"
        ],
        "summary": "Flocking control is a challenging problem, where multiple agents, such as drones or vehicles, need to reach a target position while maintaining the flock and avoiding collisions with obstacles and collisions among agents in the environment. Multi-agent reinforcement learning has achieved promising performance in flocking control. However, methods based on traditional reinforcement learning require a considerable number of interactions between agents and the environment. This paper proposes a sub-optimal policy aided multi-agent reinforcement learning algorithm (SPA-MARL) to boost sample efficiency. SPA-MARL directly leverages a prior policy that can be manually designed or solved with a non-learning method to aid agents in learning, where the performance of the policy can be sub-optimal. SPA-MARL recognizes the difference in performance between the sub-optimal policy and itself, and then imitates the sub-optimal policy if the sub-optimal policy is better. We leverage SPA-MARL to solve the flocking control problem. A traditional control method based on artificial potential fields is used to generate a sub-optimal policy. Experiments demonstrate that SPA-MARL can speed up the training process and outperform both the MARL baseline and the used sub-optimal policy.",
        "published": "2022-09-17T15:10:49Z",
        "link": "http://arxiv.org/abs/2209.08347v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Sample-Efficient Multi-Agent Reinforcement Learning with Demonstrations   for Flocking Control",
        "authors": [
            "Yunbo Qiu",
            "Yuzhu Zhan",
            "Yue Jin",
            "Jian Wang",
            "Xudong Zhang"
        ],
        "summary": "Flocking control is a significant problem in multi-agent systems such as multi-agent unmanned aerial vehicles and multi-agent autonomous underwater vehicles, which enhances the cooperativity and safety of agents. In contrast to traditional methods, multi-agent reinforcement learning (MARL) solves the problem of flocking control more flexibly. However, methods based on MARL suffer from sample inefficiency, since they require a huge number of experiences to be collected from interactions between agents and the environment. We propose a novel method Pretraining with Demonstrations for MARL (PwD-MARL), which can utilize non-expert demonstrations collected in advance with traditional methods to pretrain agents. During the process of pretraining, agents learn policies from demonstrations by MARL and behavior cloning simultaneously, and are prevented from overfitting demonstrations. By pretraining with non-expert demonstrations, PwD-MARL improves sample efficiency in the process of online MARL with a warm start. Experiments show that PwD-MARL improves sample efficiency and policy performance in the problem of flocking control, even with bad or few demonstrations.",
        "published": "2022-09-17T15:24:37Z",
        "link": "http://arxiv.org/abs/2209.08351v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Robust Online and Distributed Mean Estimation Under Adversarial Data   Corruption",
        "authors": [
            "Tong Yao",
            "Shreyas Sundaram"
        ],
        "summary": "We study robust mean estimation in an online and distributed scenario in the presence of adversarial data attacks. At each time step, each agent in a network receives a potentially corrupted data point, where the data points were originally independent and identically distributed samples of a random variable. We propose online and distributed algorithms for all agents to asymptotically estimate the mean. We provide the error-bound and the convergence properties of the estimates to the true mean under our algorithms. Based on the network topology, we further evaluate each agent's trade-off in convergence rate between incorporating data from neighbors and learning with only local observations.",
        "published": "2022-09-17T16:36:21Z",
        "link": "http://arxiv.org/abs/2209.09624v1",
        "categories": [
            "cs.CR",
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Stigmergy-based, Dual-Layer Coverage of Unknown Indoor Regions",
        "authors": [
            "Ori Rappel",
            "Michael Amir",
            "Alfred M. Bruckstein"
        ],
        "summary": "We present algorithms for uniformly covering an unknown indoor region with a swarm of simple, anonymous and autonomous mobile agents. The exploration of such regions is made difficult by the lack of a common global reference frame, severe degradation of radio-frequency communication, and numerous ground obstacles. We propose addressing these challenges by using airborne agents, such as Micro Air Vehicles, in dual capacity, both as mobile explorers and (once they land) as beacons that help other agents navigate the region.   The algorithms we propose are designed for a swarm of simple, identical, ant-like agents with local sensing capabilities. The agents enter the region, which is discretized as a graph, over time from one or more entry points and are tasked with occupying all of its vertices. Unlike many works in this area, we consider the requirement of informing an outside operator with limited information that the coverage mission is complete. Even with this additional requirement we show, both through simulations and mathematical proofs, that the dual role concept results in linear-time termination, while also besting many well-known algorithms in the literature in terms of energy use.",
        "published": "2022-09-18T14:18:30Z",
        "link": "http://arxiv.org/abs/2209.08573v2",
        "categories": [
            "cs.MA",
            "cs.DM",
            "68W15"
        ]
    },
    {
        "title": "Too Global To Be Local: Swarm Consensus in Adversarial Settings",
        "authors": [
            "Lior Moshe",
            "Noa Agmon"
        ],
        "summary": "Reaching a consensus in a swarm of robots is one of the fundamental problems in swarm robotics, examining the possibility of reaching an agreement within the swarm members. The recently-introduced contamination problem offers a new perspective of the problem, in which swarm members should reach a consensus in spite of the existence of adversarial members that intentionally act to divert the swarm members towards a different consensus. In this paper, we search for a consensus-reaching algorithm under the contamination problem setting by taking a top-down approach: We transform the problem to a centralized two-player game in which each player controls the behavior of a subset of the swarm, trying to force the entire swarm to converge to an agreement on its own value. We define a performance metric for each players performance, proving a correlation between this metric and the chances of the player to win the game. We then present the globally optimal solution to the game and prove that unfortunately it is unattainable in a distributed setting, due to the challenging characteristics of the swarm members. We therefore examine the problem on a simplified swarm model, and compare the performance of the globally optimal strategy with locally optimal strategies, demonstrating its superiority in rigorous simulation experiments.",
        "published": "2022-09-18T15:55:58Z",
        "link": "http://arxiv.org/abs/2209.08587v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Synthesis of Cost-Optimal Multi-Agent Systems for Resource Allocation",
        "authors": [
            "Nils Timm",
            "Josua Botha"
        ],
        "summary": "Multi-agent systems for resource allocation (MRAs) have been introduced as a concept for modelling competitive resource allocation problems in distributed computing. An MRA is composed of a set of agents and a set of resources. Each agent has goals in terms of allocating certain resources. For MRAs it is typically of importance that they are designed in a way such that there exists a strategy that guarantees that all agents will achieve their goals. The corresponding model checking problem is to determine whether such a winning strategy exists or not, and the synthesis problem is to actually build the strategy. While winning strategies ensure that all goals will be achieved, following such strategies does not necessarily involve an optimal use of resources.   In this paper, we present a technique that allows to synthesise cost-optimal solutions to distributed resource allocation problems. We consider a scenario where system components such as agents and resources involve costs. A multi-agent system shall be designed that is cost-minimal but still capable of accomplishing a given set of goals. Our approach synthesises a winning strategy that minimises the cumulative costs of the components that are required for achieving the goals. The technique is based on a propositional logic encoding and a reduction of the synthesis problem to the maximum satisfiability problem (Max-SAT). Hence, a Max-SAT solver can be used to perform the synthesis. From a truth assignment that maximises the number of satisfied clauses of the encoding a cost-optimal winning strategy as well as a cost-optimal system can be immediately derived.",
        "published": "2022-09-20T05:09:50Z",
        "link": "http://arxiv.org/abs/2209.09473v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Analysis Of The Anytime MAPF Solvers Based On The Combination Of   Conflict-Based Search (CBS) and Focal Search (FS)",
        "authors": [
            "Ilya Ivanashev",
            "Anton Andreychuk",
            "Konstantin Yakovlev"
        ],
        "summary": "Conflict-Based Search (CBS) is a widely used algorithm for solving multi-agent pathfinding (MAPF) problems optimally. The core idea of CBS is to run hierarchical search, when, on the high level the tree of solutions candidates is explored, and on the low-level an individual planning for a specific agent (subject to certain constraints) is carried out. To trade-off optimality for running time different variants of bounded sub-optimal CBS were designed, which alter both high- and low-level search routines of CBS. Moreover, anytime variant of CBS does exist that applies Focal Search (FS) to the high-level of CBS - Anytime BCBS. However, no comprehensive analysis of how well this algorithm performs compared to the naive one, when we simply re-invoke CBS with the decreased sub-optimality bound, was present. This work aims at filling this gap. Moreover, we present and evaluate another anytime version of CBS that uses FS on both levels of CBS. Empirically, we show that its behavior is principally different from the one demonstrated by Anytime BCBS. Finally, we compare both algorithms head-to-head and show that using Focal Search on both levels of CBS can be beneficial in a wide range of setups.",
        "published": "2022-09-20T11:05:14Z",
        "link": "http://arxiv.org/abs/2209.09612v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Rethinking Individual Global Max in Cooperative Multi-Agent   Reinforcement Learning",
        "authors": [
            "Yitian Hong",
            "Yaochu Jin",
            "Yang Tang"
        ],
        "summary": "In cooperative multi-agent reinforcement learning, centralized training and decentralized execution (CTDE) has achieved remarkable success. Individual Global Max (IGM) decomposition, which is an important element of CTDE, measures the consistency between local and joint policies. The majority of IGM-based research focuses on how to establish this consistent relationship, but little attention has been paid to examining IGM's potential flaws. In this work, we reveal that the IGM condition is a lossy decomposition, and the error of lossy decomposition will accumulated in hypernetwork-based methods. To address the above issue, we propose to adopt an imitation learning strategy to separate the lossy decomposition from Bellman iterations, thereby avoiding error accumulation. The proposed strategy is theoretically proved and empirically verified on the StarCraft Multi-Agent Challenge benchmark problem with zero sight view. The results also confirm that the proposed method outperforms state-of-the-art IGM-based approaches.",
        "published": "2022-09-20T11:38:50Z",
        "link": "http://arxiv.org/abs/2209.09640v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Asynchronous Actor-Critic for Multi-Agent Reinforcement Learning",
        "authors": [
            "Yuchen Xiao",
            "Weihao Tan",
            "Christopher Amato"
        ],
        "summary": "Synchronizing decisions across multiple agents in realistic settings is problematic since it requires agents to wait for other agents to terminate and communicate about termination reliably. Ideally, agents should learn and execute asynchronously instead. Such asynchronous methods also allow temporally extended actions that can take different amounts of time based on the situation and action executed. Unfortunately, current policy gradient methods are not applicable in asynchronous settings, as they assume that agents synchronously reason about action selection at every time step. To allow asynchronous learning and decision-making, we formulate a set of asynchronous multi-agent actor-critic methods that allow agents to directly optimize asynchronous policies in three standard training paradigms: decentralized learning, centralized learning, and centralized training for decentralized execution. Empirical results (in simulation and hardware) in a variety of realistic domains demonstrate the superiority of our approaches in large multi-agent problems and validate the effectiveness of our algorithms for learning high-quality and asynchronous solutions.",
        "published": "2022-09-20T16:36:23Z",
        "link": "http://arxiv.org/abs/2209.10113v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Relational Reasoning via Set Transformers: Provable Efficiency and   Applications to MARL",
        "authors": [
            "Fengzhuo Zhang",
            "Boyi Liu",
            "Kaixin Wang",
            "Vincent Y. F. Tan",
            "Zhuoran Yang",
            "Zhaoran Wang"
        ],
        "summary": "The cooperative Multi-A gent R einforcement Learning (MARL) with permutation invariant agents framework has achieved tremendous empirical successes in real-world applications. Unfortunately, the theoretical understanding of this MARL problem is lacking due to the curse of many agents and the limited exploration of the relational reasoning in existing works. In this paper, we verify that the transformer implements complex relational reasoning, and we propose and analyze model-free and model-based offline MARL algorithms with the transformer approximators. We prove that the suboptimality gaps of the model-free and model-based algorithms are independent of and logarithmic in the number of agents respectively, which mitigates the curse of many agents. These results are consequences of a novel generalization error bound of the transformer and a novel analysis of the Maximum Likelihood Estimate (MLE) of the system dynamics with the transformer. Our model-based algorithm is the first provably efficient MARL algorithm that explicitly exploits the permutation invariance of the agents. Our improved generalization bound may be of independent interest and is applicable to other regression problems related to the transformer beyond MARL.",
        "published": "2022-09-20T16:42:59Z",
        "link": "http://arxiv.org/abs/2209.09845v3",
        "categories": [
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Macro-Action-Based Multi-Agent/Robot Deep Reinforcement Learning under   Partial Observability",
        "authors": [
            "Yuchen Xiao"
        ],
        "summary": "The state-of-the-art multi-agent reinforcement learning (MARL) methods have provided promising solutions to a variety of complex problems. Yet, these methods all assume that agents perform synchronized primitive-action executions so that they are not genuinely scalable to long-horizon real-world multi-agent/robot tasks that inherently require agents/robots to asynchronously reason about high-level action selection at varying time durations. The Macro-Action Decentralized Partially Observable Markov Decision Process (MacDec-POMDP) is a general formalization for asynchronous decision-making under uncertainty in fully cooperative multi-agent tasks. In this thesis, we first propose a group of value-based RL approaches for MacDec-POMDPs, where agents are allowed to perform asynchronous learning and decision-making with macro-action-value functions in three paradigms: decentralized learning and control, centralized learning and control, and centralized training for decentralized execution (CTDE). Building on the above work, we formulate a set of macro-action-based policy gradient algorithms under the three training paradigms, where agents are allowed to directly optimize their parameterized policies in an asynchronous manner. We evaluate our methods both in simulation and on real robots over a variety of realistic domains. Empirical results demonstrate the superiority of our approaches in large multi-agent problems and validate the effectiveness of our algorithms for learning high-quality and asynchronous solutions with macro-actions.",
        "published": "2022-09-20T21:13:51Z",
        "link": "http://arxiv.org/abs/2209.10003v2",
        "categories": [
            "cs.AI",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Introducing emotions in the reasoning cycle ofnormative aware agents",
        "authors": [
            "Daniel Perez",
            "Estefania Argente",
            "Elena Del Val",
            "Soledad Valero"
        ],
        "summary": "Human relationships are complex processes that often involve following certain rules that regulate interactions and/or expected outcomes. These rules may be imposed by an authority or established by society. In multi-agent systems, normative systems have extensively addressed aspects such as norm synthesis, norm conflict detection, as well as norm emergence. However, if human behaviour is to be adequately simulated, not only normative aspects but also emotional aspects have to be taken into account. In this paper, we propose a Jason agent architecture that incorporates norms and emotions in its reasoning process to determine which plan (actions) to execute. The proposal is evaluated through a scenario based on a social network, which allows us to analyse the benefits of using emotional normative agents to achieve simulations closer to real human world.",
        "published": "2022-09-21T00:08:22Z",
        "link": "http://arxiv.org/abs/2209.10049v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Towards a Standardised Performance Evaluation Protocol for Cooperative   MARL",
        "authors": [
            "Rihab Gorsane",
            "Omayma Mahjoub",
            "Ruan de Kock",
            "Roland Dubb",
            "Siddarth Singh",
            "Arnu Pretorius"
        ],
        "summary": "Multi-agent reinforcement learning (MARL) has emerged as a useful approach to solving decentralised decision-making problems at scale. Research in the field has been growing steadily with many breakthrough algorithms proposed in recent years. In this work, we take a closer look at this rapid development with a focus on evaluation methodologies employed across a large body of research in cooperative MARL. By conducting a detailed meta-analysis of prior work, spanning 75 papers accepted for publication from 2016 to 2022, we bring to light worrying trends that put into question the true rate of progress. We further consider these trends in a wider context and take inspiration from single-agent RL literature on similar issues with recommendations that remain applicable to MARL. Combining these recommendations, with novel insights from our analysis, we propose a standardised performance evaluation protocol for cooperative MARL. We argue that such a standard protocol, if widely adopted, would greatly improve the validity and credibility of future research, make replication and reproducibility easier, as well as improve the ability of the field to accurately gauge the rate of progress over time by being able to make sound comparisons across different works. Finally, we release our meta-analysis data publicly on our project website for future research on evaluation: https://sites.google.com/view/marl-standard-protocol",
        "published": "2022-09-21T16:40:03Z",
        "link": "http://arxiv.org/abs/2209.10485v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.GL",
            "cs.MA",
            "I.2.11; I.2.0; A.1"
        ]
    },
    {
        "title": "Developing, Evaluating and Scaling Learning Agents in Multi-Agent   Environments",
        "authors": [
            "Ian Gemp",
            "Thomas Anthony",
            "Yoram Bachrach",
            "Avishkar Bhoopchand",
            "Kalesha Bullard",
            "Jerome Connor",
            "Vibhavari Dasagi",
            "Bart De Vylder",
            "Edgar Duenez-Guzman",
            "Romuald Elie",
            "Richard Everett",
            "Daniel Hennes",
            "Edward Hughes",
            "Mina Khan",
            "Marc Lanctot",
            "Kate Larson",
            "Guy Lever",
            "Siqi Liu",
            "Luke Marris",
            "Kevin R. McKee",
            "Paul Muller",
            "Julien Perolat",
            "Florian Strub",
            "Andrea Tacchetti",
            "Eugene Tarassov",
            "Zhe Wang",
            "Karl Tuyls"
        ],
        "summary": "The Game Theory & Multi-Agent team at DeepMind studies several aspects of multi-agent learning ranging from computing approximations to fundamental concepts in game theory to simulating social dilemmas in rich spatial environments and training 3-d humanoids in difficult team coordination tasks. A signature aim of our group is to use the resources and expertise made available to us at DeepMind in deep reinforcement learning to explore multi-agent systems in complex environments and use these benchmarks to advance our understanding. Here, we summarise the recent work of our team and present a taxonomy that we feel highlights many important open challenges in multi-agent research.",
        "published": "2022-09-22T12:28:29Z",
        "link": "http://arxiv.org/abs/2209.10958v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Metamorphic Testing in Autonomous System Simulations",
        "authors": [
            "Jubril Gbolahan Adigun",
            "Linus Eisele",
            "Michael Felderer"
        ],
        "summary": "Metamorphic testing has proven to be effective for test case generation and fault detection in many domains. It is a software testing strategy that uses certain relations between input-output pairs of a program, referred to as metamorphic relations. This approach is relevant in the autonomous systems domain since it helps in cases where the outcome of a given test input may be difficult to determine. In this paper therefore, we provide an overview of metamorphic testing as well as an implementation in the autonomous systems domain. We implement an obstacle detection and avoidance task in autonomous drones utilising the GNC API alongside a simulation in Gazebo. Particularly, we describe properties and best practices that are crucial for the development of effective metamorphic relations. We also demonstrate two metamorphic relations for metamorphic testing of single and more than one drones, respectively. Our relations reveal several properties and some weak spots of both the implementation and the avoidance algorithm in the light of metamorphic testing. The results indicate that metamorphic testing has great potential in the autonomous systems domain and should be considered for quality assurance in this field.",
        "published": "2022-09-22T14:29:24Z",
        "link": "http://arxiv.org/abs/2209.11031v1",
        "categories": [
            "cs.SE",
            "cs.MA",
            "cs.RO",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Environment Optimization for Multi-Agent Navigation",
        "authors": [
            "Zhan Gao",
            "Amanda Prorok"
        ],
        "summary": "Traditional approaches to the design of multi-agent navigation algorithms consider the environment as a fixed constraint, despite the obvious influence of spatial constraints on agents' performance. Yet hand-designing improved environment layouts and structures is inefficient and potentially expensive. The goal of this paper is to consider the environment as a decision variable in a system-level optimization problem, where both agent performance and environment cost can be accounted for. We begin by proposing a novel environment optimization problem. We show, through formal proofs, under which conditions the environment can change while guaranteeing completeness (i.e., all agents reach their navigation goals). Our solution leverages a model-free reinforcement learning approach. In order to accommodate a broad range of implementation scenarios, we include both online and offline optimization, and both discrete and continuous environment representations. Numerical results corroborate our theoretical findings and validate our approach.",
        "published": "2022-09-22T19:22:16Z",
        "link": "http://arxiv.org/abs/2209.11279v1",
        "categories": [
            "cs.RO",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Equitable Marketplace Mechanism Design",
        "authors": [
            "Kshama Dwarakanath",
            "Svitlana S Vyetrenko",
            "Tucker Balch"
        ],
        "summary": "We consider a trading marketplace that is populated by traders with diverse trading strategies and objectives. The marketplace allows the suppliers to list their goods and facilitates matching between buyers and sellers. In return, such a marketplace typically charges fees for facilitating trade. The goal of this work is to design a dynamic fee schedule for the marketplace that is equitable and profitable to all traders while being profitable to the marketplace at the same time (from charging fees). Since the traders adapt their strategies to the fee schedule, we present a reinforcement learning framework for simultaneously learning a marketplace fee schedule and trading strategies that adapt to this fee schedule using a weighted optimization objective of profits and equitability. We illustrate the use of the proposed approach in detail on a simulated stock exchange with different types of investors, specifically market makers and consumer investors. As we vary the equitability weights across different investor classes, we see that the learnt exchange fee schedule starts favoring the class of investors with the highest weight. We further discuss the observed insights from the simulated stock exchange in light of the general framework of equitable marketplace mechanism design.",
        "published": "2022-09-22T20:03:34Z",
        "link": "http://arxiv.org/abs/2209.15418v1",
        "categories": [
            "cs.GT",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Stabilizability of multi-agent systems under event-triggered controllers",
        "authors": [
            "Yinshuang Sun",
            "Zhijian Ji",
            "Yungang Liu",
            "Chong Lin"
        ],
        "summary": "In view of the problems of large consumption of communication and computing resources in the control process, this note studies a fundamental property for a class of multi-agent systems under event-triggered strategy: the S-stabilizability of a group of multi-agent systems with general linear dynamics under weakly connected directed topology. The results indicate that the S-stabilizability can be described in some way that the stabilizability region and feedback gain can evaluate the performance of the protocol. Firstly, a new distributed event-triggered protocol is proposed. Under this protocol, a kind of hybrid static and dynamic event-triggered strategy are presented, respectively. In particular, by using Lyapunov stability theory and graph partition tool, it is proved that the proposed event-triggered control strategy can guarantee the closed-loop system achieve S-stabilizability effectively, if at least one vertex in each iSCC cell receives information from the leader, which reflects the ability of distributed control law. Further, we demonstrate that the stabilizability can be realized if the initial system matrix A is Hurwitz. Moreover, it is confirmed that the designed static event-triggered condition is a limit case of dynamic event condition and can guarantee Zeno-free behavior. Finally, the validity of the theoretical results is proved by numerical simulation.",
        "published": "2022-09-24T08:34:14Z",
        "link": "http://arxiv.org/abs/2209.11958v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Cooperative Tuning of Multi-Agent Optimal Control Systems",
        "authors": [
            "Zehui Lu",
            "Wanxin Jin",
            "Shaoshuai Mou",
            "Brian D. O. Anderson"
        ],
        "summary": "This paper investigates the problem of cooperative tuning of multi-agent optimal control systems, where a network of agents (i.e. multiple coupled optimal control systems) adjusts parameters in their dynamics, objective functions, or controllers in a coordinated way to minimize the sum of their loss functions. Different from classical techniques for tuning parameters in a controller, we allow tunable parameters appearing in both the system dynamics and the objective functions of each agent. A framework is developed to allow all agents to reach a consensus on the tunable parameter, which minimizes team loss. The key idea of the proposed algorithm rests on the integration of consensus-based distributed optimization for a multi-agent system and a gradient generator capturing the optimal performance as a function of the parameter in the feedback loop tuning the parameter for each agent. Both theoretical results and simulations for a synchronous multi-agent rendezvous problem are provided to validate the proposed method for cooperative tuning of multi-agent optimal control.",
        "published": "2022-09-24T14:28:42Z",
        "link": "http://arxiv.org/abs/2209.12017v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Graph Neural Networks for Multi-Robot Active Information Acquisition",
        "authors": [
            "Mariliza Tzes",
            "Nikolaos Bousias",
            "Evangelos Chatzipantazis",
            "George J. Pappas"
        ],
        "summary": "This paper addresses the Multi-Robot Active Information Acquisition (AIA) problem, where a team of mobile robots, communicating through an underlying graph, estimates a hidden state expressing a phenomenon of interest. Applications like target tracking, coverage and SLAM can be expressed in this framework. Existing approaches, though, are either not scalable, unable to handle dynamic phenomena or not robust to changes in the communication graph. To counter these shortcomings, we propose an Information-aware Graph Block Network (I-GBNet), an AIA adaptation of Graph Neural Networks, that aggregates information over the graph representation and provides sequential-decision making in a distributed manner. The I-GBNet, trained via imitation learning with a centralized sampling-based expert solver, exhibits permutation equivariance and time invariance, while harnessing the superior scalability, robustness and generalizability to previously unseen environments and robot configurations. Experiments on significantly larger graphs and dimensionality of the hidden state and more complex environments than those seen in training validate the properties of the proposed architecture and its efficacy in the application of localization and tracking of dynamic targets.",
        "published": "2022-09-24T21:45:06Z",
        "link": "http://arxiv.org/abs/2209.12091v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Learning Decentralized Strategies for a Perimeter Defense Game with   Graph Neural Networks",
        "authors": [
            "Elijah S. Lee",
            "Lifeng Zhou",
            "Alejandro Ribeiro",
            "Vijay Kumar"
        ],
        "summary": "We consider the problem of finding decentralized strategies for multi-agent perimeter defense games. In this work, we design a graph neural network-based learning framework to learn a mapping from defenders' local perceptions and the communication graph to defenders' actions such that the learned actions are close to that generated by a centralized expert algorithm. We demonstrate that our proposed networks stay closer to the expert policy and are superior to other baseline algorithms by capturing more intruders. Our GNN-based networks are trained at a small scale and can generalize to large scales. To validate our results, we run perimeter defense games in scenarios with different team sizes and initial configurations to evaluate the performance of the learned networks.",
        "published": "2022-09-24T22:48:51Z",
        "link": "http://arxiv.org/abs/2211.01757v1",
        "categories": [
            "cs.MA",
            "cs.LG"
        ]
    },
    {
        "title": "The topology in the game controllability of multiagent systems",
        "authors": [
            "Junhao Guo",
            "Zhijian Ji",
            "Yungang Liu"
        ],
        "summary": "In this paper, the graph based condition for the controllability of game based control system is presented when the control of regulator is not zero. A control framework which can describe realism well expressed as the game based control system (GBCS), was obtained in 2019, which, unfortunately, is not graph theoretically verifiable, and the regulator control input is assumed to be zero. However, based on a new established notion, strategy matrix, we propose a graph theory condition to judge the controllability of GBCS, instead of using algebraic conditions for complex mathematical calculations. More specifically, to tackle these issues, one needs to study the expression of Nash equilibrium actions when regulators control is not zero first. Based on this expression, the general formula of game controllability matrix is obtained, which provides theoretical support for studying the essential influence of topology on game based control system. The general formula is always affected by the specific matrix strategy matrix, composed of Nash equilibrium actions, and the matrix can not only be obtained by matrix calculation, but also can be directly written through the topology, which is the specific influence of the topology on the GBCS. Finally, we obtain the result of judging the controllability of the system directly according to the topological structure, and put forward the conjecture that there is no limitation of equivalent partition in GBCS. Arguably, this is a surprising conjecture on the equivalent partition of graphs, because only the limitation of equivalent partition in fivenode graphs has been solved so far",
        "published": "2022-09-25T04:33:56Z",
        "link": "http://arxiv.org/abs/2209.12142v1",
        "categories": [
            "math.OC",
            "cs.MA"
        ]
    },
    {
        "title": "Hierarchical Cyclic Pursuit: Algebraic Curves Containing the Laplacian   Spectra",
        "authors": [
            "Sergei E. Parsegov",
            "Pavel Yu. Chebotarev",
            "Pavel S. Shcherbakov",
            "Federico M. Ibáñez"
        ],
        "summary": "The paper addresses the problem of multi-agent communication in networks with regular directed ring structure. These can be viewed as hierarchical extensions of the classical cyclic pursuit topology. We show that the spectra of the corresponding Laplacian matrices allow exact localization on the complex plane. Furthermore, we derive a general form of the characteristic polynomial of such matrices, analyze the algebraic curves its roots belong to, and propose a way to obtain their closed-form equations. In combination with frequency domain consensus criteria for high-order SISO linear agents, these curves enable one to analyze the feasibility of consensus in networks with varying number of agents.",
        "published": "2022-09-25T08:31:52Z",
        "link": "http://arxiv.org/abs/2209.12178v1",
        "categories": [
            "cs.MA",
            "math.CO",
            "math.OC",
            "93B70 93C95 37N35"
        ]
    },
    {
        "title": "Online Submodular Coordination with Bounded Tracking Regret: Theory,   Algorithm, and Applications to Multi-Robot Coordination",
        "authors": [
            "Zirui Xu",
            "Hongyu Zhou",
            "Vasileios Tzoumas"
        ],
        "summary": "We enable efficient and effective coordination in unpredictable environments, i.e., in environments whose future evolution is unknown a priori and even adversarial. We are motivated by the future of autonomy that involves multiple robots coordinating in dynamic, unstructured, and adversarial environments to complete complex tasks such as target tracking, environmental mapping, and area monitoring. Such tasks are often modeled as submodular maximization coordination problems. We introduce the first submodular coordination algorithm with bounded tracking regret, i.e., with bounded suboptimality with respect to optimal time-varying actions that know the future a priori. The bound gracefully degrades with the environments' capacity to change adversarially. It also quantifies how often the robots must re-select actions to \"learn\" to coordinate as if they knew the future a priori. The algorithm requires the robots to select actions sequentially based on the actions selected by the previous robots in the sequence. Particularly, the algorithm generalizes the seminal Sequential Greedy algorithm by Fisher et al. to unpredictable environments, leveraging submodularity and algorithms for the problem of tracking the best expert. We validate our algorithm in simulated scenarios of target tracking.",
        "published": "2022-09-26T05:31:34Z",
        "link": "http://arxiv.org/abs/2209.12429v3",
        "categories": [
            "eess.SY",
            "cs.AI",
            "cs.MA",
            "cs.RO",
            "cs.SY",
            "math.OC"
        ]
    },
    {
        "title": "Constrained Multi-Agent Path Finding on Directed Graphs",
        "authors": [
            "Stefano Ardizzoni",
            "Luca Consolini",
            "Marco Locatelli",
            "Irene Saccani"
        ],
        "summary": "We discuss C-MP and C-MAPF, generalizations of the classical Motion Planning (MP) and Multi-Agent Path Finding (MAPF) problems on a directed graph G. Namely, we enforce an upper bound on the number of agents that occupy each member of a family of vertex subsets. For instance, this constraint allows maintaining a safety distance between agents. We prove that finding a feasible solution of C-MP and C-MAPF is NP-hard, and we propose a reduction method to convert them to standard MP and MAPF. This reduction method consists in finding a subset of nodes W and a reduced graph G/W, such that a solution of MAPF on G/W provides a solution of C-MAPF on G. Moreover, we study the problem of finding W of maximum cardinality, which is strongly NP-hard.",
        "published": "2022-09-26T08:31:10Z",
        "link": "http://arxiv.org/abs/2209.12506v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Coupling OMNeT++ and mosaik for integrated Co-Simulation of ICT-reliant   Smart Grids",
        "authors": [
            "Frauke Oest",
            "Emilie Frost",
            "Malin Radtke",
            "Sebastian Lehnhoff"
        ],
        "summary": "The increasing integration of renewable energy resources requires so-called smart grid services for monitoring, control and automation tasks. Simulation environments are vital for evaluating and developing innovative solutions and algorithms. Especially in smart energy systems, we face a variety of heterogeneous simulators representing, e.g., power grids, analysis or control components and markets. The co-simulation framework mosaik can be used to orchestrate the data exchange and time synchronization between individual simulators. So far, the underlying communication infrastructure has often been assumed to be optimal and therefore, the influence of e.g., communication delays has been neglected. This paper presents the first results of the project cosima, which aims at connecting the communication simulator OMNeT++ to the co-simulation framework mosaik to analyze the resilience and robustness of smart grid services, e.g., multi-agent-based services with respect to adaptivity, scalability, extensibility and usability. This facilitates simulations with realistic communication technologies (such as 5G) and the analysis of dynamic communication characteristics by simulating multiple messages. We show the functionality and benefits of cosima in experiments with 50 agents.",
        "published": "2022-09-26T10:12:15Z",
        "link": "http://arxiv.org/abs/2209.12550v3",
        "categories": [
            "cs.NI",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "More Centralized Training, Still Decentralized Execution: Multi-Agent   Conditional Policy Factorization",
        "authors": [
            "Jiangxing Wang",
            "Deheng Ye",
            "Zongqing Lu"
        ],
        "summary": "In cooperative multi-agent reinforcement learning (MARL), combining value decomposition with actor-critic enables agents to learn stochastic policies, which are more suitable for the partially observable environment. Given the goal of learning local policies that enable decentralized execution, agents are commonly assumed to be independent of each other, even in centralized training. However, such an assumption may prohibit agents from learning the optimal joint policy. To address this problem, we explicitly take the dependency among agents into centralized training. Although this leads to the optimal joint policy, it may not be factorized for decentralized execution. Nevertheless, we theoretically show that from such a joint policy, we can always derive another joint policy that achieves the same optimality but can be factorized for decentralized execution. To this end, we propose multi-agent conditional policy factorization (MACPF), which takes more centralized training but still enables decentralized execution. We empirically verify MACPF in various cooperative MARL tasks and demonstrate that MACPF achieves better performance or faster convergence than baselines. Our code is available at https://github.com/PKU-RL/FOP-DMAC-MACPF.",
        "published": "2022-09-26T13:29:22Z",
        "link": "http://arxiv.org/abs/2209.12681v2",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Multi-Agent Coordination via Multi-Level Communication",
        "authors": [
            "Ziluo Ding",
            "Zeyuan Liu",
            "Zhirui Fang",
            "Kefan Su",
            "Liwen Zhu",
            "Zongqing Lu"
        ],
        "summary": "The partial observability and stochasticity in multi-agent settings can be mitigated by accessing more information about others via communication. However, the coordination problem still exists since agents cannot communicate actual actions with each other at the same time due to the circular dependencies. In this paper, we propose a novel multi-level communication scheme, Sequential Communication (SeqComm). SeqComm treats agents asynchronously (the upper-level agents make decisions before the lower-level ones) and has two communication phases. In the negotiation phase, agents determine the priority of decision-making by communicating hidden states of observations and comparing the value of intention, obtained by modeling the environment dynamics. In the launching phase, the upper-level agents take the lead in making decisions and then communicate their actions with the lower-level agents. Theoretically, we prove the policies learned by SeqComm are guaranteed to improve monotonically and converge. Empirically, we show that SeqComm outperforms existing methods in various cooperative multi-agent tasks.",
        "published": "2022-09-26T14:08:03Z",
        "link": "http://arxiv.org/abs/2209.12713v2",
        "categories": [
            "cs.MA",
            "cs.LG"
        ]
    },
    {
        "title": "Exploration of the effects of epidemics on the regional socio-economics:   a modelling approach",
        "authors": [
            "Jan E. Snellman",
            "Rafael A. Barrio",
            "Kimmo K. Kaski",
            "Maarit J. Korpi--Lagg"
        ],
        "summary": "Pandemics, in addition to affecting the health of populations, can have huge impacts on their social and economic behavior. These factors, on the other hand, have the potential to feed back to and influence the disease spreading. It is important to systematically study these interrelations, to determine which ones have significant effects, and whether the effects are adverse or beneficial. Our recently developed epidemic model with agent-based and geographical elements is used in this study for such a purpose. We perform an extensive parameter space exploration of the socio-economic part of the model, including factors like the attitudes (called values) of the agents towards the disease spreading, health, economic situation, and regulations by government agents. We search for prominent patterns from the resulting simulated data using basic classification tools, namely self-organizing maps and principal component analysis. We seek to isolate the most important value parameters of the population and government agents influencing the disease spreading speed and patterns, and monitor different quantities of the model output, such as infection rates, the propagation speed of the epidemic, economic activity, government regulations, and the compliance of population. Out of these, the ones describing the epidemic spreading were resulting in the most distinctive clustering of the data, and they were selected as the basis of the remaining analysis. We relate the found clusters to three distinct types of disease spreading: wave-like, chaotic, and transitional spreading patterns. The most important value parameter contributing to phase changes between these phases was found to be the compliance of the population agents towards the government regulations.",
        "published": "2022-09-26T19:14:56Z",
        "link": "http://arxiv.org/abs/2209.12973v1",
        "categories": [
            "physics.soc-ph",
            "cs.MA",
            "I.2.11"
        ]
    },
    {
        "title": "D-ITAGS: A Dynamic Interleaved Approach to Resilient Task Allocation,   Scheduling, and Motion Planning",
        "authors": [
            "Glen Neville",
            "Sonia Chernova",
            "Harish Ravichandar"
        ],
        "summary": "Complex, multi-objective missions require the coordination of heterogeneous robots at multiple inter-connected levels, such as coalition formation, scheduling, and motion planning. This challenge is exacerbated by dynamic changes, such as sensor and actuator failures, communication loss, and unexpected delays.   We introduce Dynamic Iterative Task Allocation Graph Search (D-ITAGS) to \\textit{simultaneously} address coalition formation, scheduling, and motion planning in dynamic settings involving heterogeneous teams. D-ITAGS achieves resilience via two key characteristics: i) interleaved execution, and ii) targeted repair. \\textit{Interleaved execution} enables an effective search for solutions at each layer while avoiding incompatibility with other layers. \\textit{Targeted repair} identifies and repairs parts of the existing solution impacted by a given disruption, while conserving the rest. In addition to algorithmic contributions, we provide theoretical insights into the inherent trade-off between time and resource optimality in these settings and derive meaningful bounds on schedule suboptimality.   Our experiments reveal that i) D-ITAGS is significantly faster than recomputation from scratch in dynamic settings, with little to no loss in solution quality, and ii) the theoretical suboptimality bounds consistently hold in practice.",
        "published": "2022-09-27T00:59:04Z",
        "link": "http://arxiv.org/abs/2209.13092v2",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Robust MADER: Decentralized and Asynchronous Multiagent Trajectory   Planner Robust to Communication Delay",
        "authors": [
            "Kota Kondo",
            "Jesus Tordesillas",
            "Reinaldo Figueroa",
            "Juan Rached",
            "Joseph Merkel",
            "Parker C. Lusk",
            "Jonathan P. How"
        ],
        "summary": "Although communication delays can disrupt multiagent systems, most of the existing multiagent trajectory planners lack a strategy to address this issue. State-of-the-art approaches typically assume perfect communication environments, which is hardly realistic in real-world experiments. This paper presents Robust MADER (RMADER), a decentralized and asynchronous multiagent trajectory planner that can handle communication delays among agents. By broadcasting both the newly optimized trajectory and the committed trajectory, and by performing a delay check step, RMADER is able to guarantee safety even under communication delay. RMADER was validated through extensive simulation and hardware flight experiments and achieved a 100% success rate of collision-free trajectory generation, outperforming state-of-the-art approaches.",
        "published": "2022-09-27T20:13:06Z",
        "link": "http://arxiv.org/abs/2209.13667v3",
        "categories": [
            "cs.RO",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "OA-Bug: An Olfactory-Auditory Augmented Bug Algorithm for Swarm Robots   in a Denied Environment",
        "authors": [
            "Siqi Tan",
            "Xiaoya Zhang",
            "Jingyao Li",
            "Ruitao Jing",
            "Mufan Zhao",
            "Yang Liu",
            "Quan Quan"
        ],
        "summary": "Searching in a denied environment is challenging for swarm robots as no assistance from GNSS, mapping, data sharing, and central processing is allowed. However, using olfactory and auditory signals to cooperate like animals could be an important way to improve the collaboration of swarm robots. In this paper, an Olfactory-Auditory augmented Bug algorithm (OA-Bug) is proposed for a swarm of autonomous robots to explore a denied environment. A simulation environment is built to measure the performance of OA-Bug. The coverage of the search task can reach 96.93% using OA-Bug, which is significantly improved compared with a similar algorithm, SGBA. Furthermore, experiments are conducted on real swarm robots to prove the validity of OA-Bug. Results show that OA-Bug can improve the performance of swarm robots in a denied environment.",
        "published": "2022-09-28T11:29:28Z",
        "link": "http://arxiv.org/abs/2209.14007v4",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Advising Autonomous Cars about the Rules of the Road",
        "authors": [
            "Joe Collenette",
            "Louise A. Dennis",
            "Michael Fisher"
        ],
        "summary": "This paper describes (R)ules (o)f (T)he (R)oad (A)dvisor, an agent that provides recommended and possible actions to be generated from a set of human-level rules. We describe the architecture and design of RoTRA, both formally and with an example. Specifically, we use RoTRA to formalise and implement the UK \"Rules of the Road\", and describe how this can be incorporated into autonomous cars such that they can reason internally about obeying the rules of the road. In addition, the possible actions generated are annotated to indicate whether the rules state that the action must be taken or that they only recommend that the action should be taken, as per the UK Highway Code (Rules of The Road). The benefits of utilising this system include being able to adapt to different regulations in different jurisdictions; allowing clear traceability from rules to behaviour, and providing an external automated accountability mechanism that can check whether the rules were obeyed in some given situation. A simulation of an autonomous car shows, via a concrete example, how trust can be built by putting the autonomous vehicle through a number of scenarios which test the car's ability to obey the rules of the road. Autonomous cars that incorporate this system are able to ensure that they are obeying the rules of the road and external (legal or regulatory) bodies can verify that this is the case, without the vehicle or its manufacturer having to expose their source code or make their working transparent, thus allowing greater trust between car companies, jurisdictions, and the general public.",
        "published": "2022-09-28T12:22:59Z",
        "link": "http://arxiv.org/abs/2209.14035v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "A Doxastic Characterisation of Autonomous Decisive Systems",
        "authors": [
            "Astrid Rakow"
        ],
        "summary": "A highly autonomous system (HAS) has to assess the situation it is in and derive beliefs, based on which, it decides what to do next. The beliefs are not solely based on the observations the HAS has made so far, but also on general insights about the world, in which the HAS operates. These insights have either been built in the HAS during design or are provided by trusted sources during its mission. Although its beliefs may be imprecise and might bear flaws, the HAS will have to extrapolate the possible futures in order to evaluate the consequences of its actions and then take its decisions autonomously. In this paper, we formalize an autonomous decisive system as a system that always chooses actions that it currently believes are the best. We show that it can be checked whether an autonomous decisive system can be built given an application domain, the dynamically changing knowledge base and a list of LTL mission goals. We moreover can synthesize a belief formation for an autonomous decisive system. For the formal characterization, we use a doxastic framework for safety-critical HASs where the belief formation supports the HAS's extrapolation.",
        "published": "2022-09-28T12:24:00Z",
        "link": "http://arxiv.org/abs/2209.14038v1",
        "categories": [
            "cs.GT",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Scheduling of Missions with Constrained Tasks for Heterogeneous Robot   Systems",
        "authors": [
            "Gricel Vázquez",
            "Radu Calinescu",
            "Javier Cámara"
        ],
        "summary": "We present a formal tasK AllocatioN and scheduling apprOAch for multi-robot missions (KANOA). KANOA supports two important types of task constraints: task ordering, which requires the execution of several tasks in a specified order; and joint tasks, which indicates tasks that must be performed by more than one robot. To mitigate the complexity of robotic mission planning, KANOA handles the allocation of the mission tasks to robots, and the scheduling of the allocated tasks separately. To that end, the task allocation problem is formalised in first-order logic and resolved using the Alloy model analyzer, and the task scheduling problem is encoded as a Markov decision process and resolved using the PRISM probabilistic model checker. We illustrate the application of KANOA through a case study in which a heterogeneous robotic team is assigned a hospital maintenance mission.",
        "published": "2022-09-28T12:24:51Z",
        "link": "http://arxiv.org/abs/2209.14040v1",
        "categories": [
            "cs.LO",
            "cs.MA",
            "cs.RO",
            "I.2.11; D.4.1"
        ]
    },
    {
        "title": "Generating Safe Autonomous Decision-Making in ROS",
        "authors": [
            "Yi Yang",
            "Tom Holvoet"
        ],
        "summary": "The Robot Operating System (ROS) is a widely used framework for building robotic systems. It offers a wide variety of reusable packages and a pattern for new developments. It is up to developers how to combine these elements and integrate them with decision-making for autonomous behavior. The feature of such decision-making that is in general valued the most is safety assurance.   In this research preview, we present a formal approach for generating safe autonomous decision-making in ROS. We first describe how to improve our existing static verification approach to verify multi-goal multi-agent decision-making. After that, we describe how to transition from the improved static verification approach to the proposed runtime verification approach. An initial implementation of this research proposal yields promising results.",
        "published": "2022-09-28T12:25:42Z",
        "link": "http://arxiv.org/abs/2209.14042v1",
        "categories": [
            "cs.MA",
            "cs.LO",
            "cs.RO"
        ]
    },
    {
        "title": "Generalizing Liquid Democracy to multi-agent delegation: A Voting Power   Measure and Equilibrium Analysis",
        "authors": [
            "Francisco M. Bersetche"
        ],
        "summary": "In this study, we propose a generalization of the classic model of liquid democracy that allows fractional delegation of voting weight, while simultaneously allowing for the existence of equilibrium states. Our approach empowers agents to partition and delegate their votes to multiple representatives, all while retaining a fraction of the voting power for themselves. We introduce a penalty mechanism for the length of delegation chains. We discuss the desirable properties of a reasonable generalization of the classic model, and prove that smaller penalty factors bring the model closer to satisfying these properties. In the subsequent section, we explore the presence of equilibrium states in a general delegation game utilizing the proposed voting measure. In contrast to the classical model, we demonstrate that this game exhibits pure strategy Nash equilibria, contingent upon the imposition of a penalty on the length of delegation chains.",
        "published": "2022-09-28T14:25:36Z",
        "link": "http://arxiv.org/abs/2209.14128v3",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Pareto Actor-Critic for Equilibrium Selection in Multi-Agent   Reinforcement Learning",
        "authors": [
            "Filippos Christianos",
            "Georgios Papoudakis",
            "Stefano V. Albrecht"
        ],
        "summary": "This work focuses on equilibrium selection in no-conflict multi-agent games, where we specifically study the problem of selecting a Pareto-optimal Nash equilibrium among several existing equilibria. It has been shown that many state-of-the-art multi-agent reinforcement learning (MARL) algorithms are prone to converging to Pareto-dominated equilibria due to the uncertainty each agent has about the policy of the other agents during training. To address sub-optimal equilibrium selection, we propose Pareto Actor-Critic (Pareto-AC), which is an actor-critic algorithm that utilises a simple property of no-conflict games (a superset of cooperative games): the Pareto-optimal equilibrium in a no-conflict game maximises the returns of all agents and, therefore, is the preferred outcome for all agents. We evaluate Pareto-AC in a diverse set of multi-agent games and show that it converges to higher episodic returns compared to seven state-of-the-art MARL algorithms and that it successfully converges to a Pareto-optimal equilibrium in a range of matrix games. Finally, we propose PACDCG, a graph neural network extension of Pareto-AC, which is shown to efficiently scale in games with a large number of agents.",
        "published": "2022-09-28T18:14:34Z",
        "link": "http://arxiv.org/abs/2209.14344v3",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Neighborhood Gradient Clustering: An Efficient Decentralized Learning   Method for Non-IID Data Distributions",
        "authors": [
            "Sai Aparna Aketi",
            "Sangamesh Kodge",
            "Kaushik Roy"
        ],
        "summary": "Decentralized learning over distributed datasets can have significantly different data distributions across the agents. The current state-of-the-art decentralized algorithms mostly assume the data distributions to be Independent and Identically Distributed. This paper focuses on improving decentralized learning over non-IID data. We propose \\textit{Neighborhood Gradient Clustering (NGC)}, a novel decentralized learning algorithm that modifies the local gradients of each agent using self- and cross-gradient information. Cross-gradients for a pair of neighboring agents are the derivatives of the model parameters of an agent with respect to the dataset of the other agent. In particular, the proposed method replaces the local gradients of the model with the weighted mean of the self-gradients, model-variant cross-gradients (derivatives of the neighbors' parameters with respect to the local dataset), and data-variant cross-gradients (derivatives of the local model with respect to its neighbors' datasets). The data-variant cross-gradients are aggregated through an additional communication round without breaking the privacy constraints. Further, we present \\textit{CompNGC}, a compressed version of \\textit{NGC} that reduces the communication overhead by $32 \\times$. We theoretically analyze the convergence rate of the proposed algorithm and demonstrate its efficiency over non-IID data sampled from {various vision and language} datasets trained. Our experiments demonstrate that \\textit{NGC} and \\textit{CompNGC} outperform (by $0-6\\%$) the existing SoTA decentralized learning algorithm over non-IID data with significantly less compute and memory requirements. Further, our experiments show that the model-variant cross-gradient information available locally at each agent can improve the performance over non-IID data by $1-35\\%$ without additional communication cost.",
        "published": "2022-09-28T19:28:54Z",
        "link": "http://arxiv.org/abs/2209.14390v6",
        "categories": [
            "cs.LG",
            "cs.DC",
            "cs.MA"
        ]
    },
    {
        "title": "A Multiagent Framework for the Asynchronous and Collaborative Extension   of Multitask ML Systems",
        "authors": [
            "Andrea Gesmundo"
        ],
        "summary": "The traditional ML development methodology does not enable a large number of contributors, each with distinct objectives, to work collectively on the creation and extension of a shared intelligent system. Enabling such a collaborative methodology can accelerate the rate of innovation, increase ML technologies accessibility and enable the emergence of novel capabilities. We believe that this novel methodology for ML development can be demonstrated through a modularized representation of ML models and the definition of novel abstractions allowing to implement and execute diverse methods for the asynchronous use and extension of modular intelligent systems. We present a multiagent framework for the collaborative and asynchronous extension of dynamic large-scale multitask systems.",
        "published": "2022-09-29T13:02:58Z",
        "link": "http://arxiv.org/abs/2209.14745v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.CV",
            "cs.MA",
            "cs.NE"
        ]
    },
    {
        "title": "Combining Theory of Mind and Abduction for Cooperation under Imperfect   Information",
        "authors": [
            "Nieves Montes",
            "Nardine Osman",
            "Carles Sierra"
        ],
        "summary": "In this paper, we formalise and implement an agent model for cooperation under imperfect information. It is based on Theory of Mind (the cognitive ability to understand the mental state of others) and abductive reasoning (the inference paradigm that computes explanations from observations). The combination of these two techniques allows agents to derive the motives behind the actions of their peers, and incorporate this knowledge into their own decision-making. We have implemented this model in a totally domain-independent fashion and successfully tested it for the cooperative card game Hanabi.",
        "published": "2022-09-30T07:33:15Z",
        "link": "http://arxiv.org/abs/2209.15279v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Emergent Communication: Generalization and Overfitting in Lewis Games",
        "authors": [
            "Mathieu Rita",
            "Corentin Tallec",
            "Paul Michel",
            "Jean-Bastien Grill",
            "Olivier Pietquin",
            "Emmanuel Dupoux",
            "Florian Strub"
        ],
        "summary": "Lewis signaling games are a class of simple communication games for simulating the emergence of language. In these games, two agents must agree on a communication protocol in order to solve a cooperative task. Previous work has shown that agents trained to play this game with reinforcement learning tend to develop languages that display undesirable properties from a linguistic point of view (lack of generalization, lack of compositionality, etc). In this paper, we aim to provide better understanding of this phenomenon by analytically studying the learning problem in Lewis games. As a core contribution, we demonstrate that the standard objective in Lewis games can be decomposed in two components: a co-adaptation loss and an information loss. This decomposition enables us to surface two potential sources of overfitting, which we show may undermine the emergence of a structured communication protocol. In particular, when we control for overfitting on the co-adaptation loss, we recover desired properties in the emergent languages: they are more compositional and generalize better.",
        "published": "2022-09-30T09:50:46Z",
        "link": "http://arxiv.org/abs/2209.15342v2",
        "categories": [
            "cs.MA",
            "cs.CL",
            "cs.IT",
            "math.IT"
        ]
    },
    {
        "title": "Communication-Enabled Deep Reinforcement Learning to Optimise   Energy-Efficiency in UAV-Assisted Networks",
        "authors": [
            "Babatunji Omoniwa",
            "Boris Galkin",
            "Ivana Dusparic"
        ],
        "summary": "Unmanned aerial vehicles (UAVs) are increasingly deployed to provide wireless connectivity to static and mobile ground users in situations of increased network demand or points of failure in existing terrestrial cellular infrastructure. However, UAVs are energy-constrained and experience the challenge of interference from nearby UAV cells sharing the same frequency spectrum, thereby impacting the system's energy efficiency (EE). Recent approaches focus on optimising the system's EE by optimising the trajectory of UAVs serving only static ground users and neglecting mobile users. Several others neglect the impact of interference from nearby UAV cells, assuming an interference-free network environment. Despite growing research interest in decentralised control over centralised UAVs' control, direct collaboration among UAVs to improve coordination while optimising the systems' EE has not been adequately explored. To address this, we propose a direct collaborative communication-enabled multi-agent decentralised double deep Q-network (CMAD-DDQN) approach. The CMAD-DDQN is a collaborative algorithm that allows UAVs to explicitly share their telemetry via existing 3GPP guidelines by communicating with their nearest neighbours. This allows the agent-controlled UAVs to optimise their 3D flight trajectories by filling up knowledge gaps and converging to optimal policies. Simulation results show that the proposed approach outperforms existing baselines in terms of maximising the systems' EE without degrading coverage performance in the network. The CMAD-DDQN approach outperforms the MAD-DDQN that neglects direct collaboration among UAVs, the multi-agent deep deterministic policy gradient (MADDPG) and random policy approaches that consider a 2D UAV deployment design while neglecting interference from nearby UAV cells by about 15%, 65% and 85%, respectively.",
        "published": "2022-09-30T18:50:07Z",
        "link": "http://arxiv.org/abs/2210.00041v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Safety-Critical Adaptation in Self-Adaptive Systems",
        "authors": [
            "Simon Diemert",
            "Jens H. Weber"
        ],
        "summary": "Modern systems are designed to operate in increasingly variable and uncertain environments. Not only are these environments complex, in the sense that they contain a tremendous number of variables, but they also change over time. Systems must be able to adjust their behaviour at run-time to manage these uncertainties. These self-adaptive systems have been studied extensively. This paper proposes a definition of a safety-critical self-adaptive system and then describes a taxonomy for classifying adaptations into different types based on their impact on the system's safety and the system's safety case. The taxonomy expresses criteria for classification and then describes specific criteria that the safety case for a self-adaptive system must satisfy, depending on the type of adaptations performed. Each type in the taxonomy is illustrated using the example of a safety-critical self-adaptive water heating system.",
        "published": "2022-09-30T21:16:34Z",
        "link": "http://arxiv.org/abs/2210.00095v1",
        "categories": [
            "cs.SE",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Integrating Conventional Headway Control with Reinforcement Learning to   Avoid Bus Bunching",
        "authors": [
            "Xiheng Wang"
        ],
        "summary": "Bus bunching is a natural-occurring phenomenon that undermines the efficiency and stability of the public transportation system. The mainstream solutions control the bus to intentionally stay longer at certain stations. Existing control methods include conventional methods that provide a formula to calculate the control time and reinforcement learning (RL) methods that determine the control policy through repeated interactions with the system. In this paper, we propose an integrated proximal policy optimization model with dual-headway (IPPO-DH). IPPO-DH integrates the conventional headway control with reinforcement learning, so that it acquires the advantages of both algorithms -- it is more efficient in normal environments and more stable in harsh ones. To demonstrate such an advantage, we design a bus simulation environment and compare IPPO-DH with RL and several conventional methods. The results show that the proposed model maintains the application value of the conventional method by avoiding the instability of the RL method in certain environments, and improves the efficiency compared with the conventional control, shedding new light on real-world bus transit system optimization.",
        "published": "2022-10-01T06:11:11Z",
        "link": "http://arxiv.org/abs/2210.00201v1",
        "categories": [
            "cs.MA",
            "49Q22 (Primary), 93A16 (Secondary)",
            "I.2.8"
        ]
    },
    {
        "title": "Privacy-preserving Decentralized Federated Learning over Time-varying   Communication Graph",
        "authors": [
            "Yang Lu",
            "Zhengxin Yu",
            "Neeraj Suri"
        ],
        "summary": "Establishing how a set of learners can provide privacy-preserving federated learning in a fully decentralized (peer-to-peer, no coordinator) manner is an open problem. We propose the first privacy-preserving consensus-based algorithm for the distributed learners to achieve decentralized global model aggregation in an environment of high mobility, where the communication graph between the learners may vary between successive rounds of model aggregation. In particular, in each round of global model aggregation, the Metropolis-Hastings method is applied to update the weighted adjacency matrix based on the current communication topology. In addition, the Shamir's secret sharing scheme is integrated to facilitate privacy in reaching consensus of the global model. The paper establishes the correctness and privacy properties of the proposed algorithm. The computational efficiency is evaluated by a simulation built on a federated learning framework with a real-word dataset.",
        "published": "2022-10-01T17:17:22Z",
        "link": "http://arxiv.org/abs/2210.00325v1",
        "categories": [
            "cs.CR",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Sustained oscillations in multi-topic belief dynamics over signed   networks",
        "authors": [
            "Anastasia Bizyaeva",
            "Alessio Franci",
            "Naomi Ehrich Leonard"
        ],
        "summary": "We study the dynamics of belief formation on multiple interconnected topics in networks of agents with a shared belief system. We establish sufficient conditions and necessary conditions under which sustained oscillations of beliefs arise on the network in a Hopf bifurcation and characterize the role of the communication graph and the belief system graph in shaping the relative phase and amplitude patterns of the oscillations. Additionally, we distinguish broad classes of graphs that exhibit such oscillations from those that do not.",
        "published": "2022-10-01T20:00:49Z",
        "link": "http://arxiv.org/abs/2210.00353v2",
        "categories": [
            "math.OC",
            "cs.MA",
            "cs.SI",
            "math.DS",
            "physics.soc-ph"
        ]
    },
    {
        "title": "Incentive Mechanism and Path Planning for UAV Hitching over Traffic   Networks",
        "authors": [
            "Ziyi Lu",
            "Na Yu",
            "Xuehe Wang"
        ],
        "summary": "Package delivery via the UAVs is a promising transport mode to provide efficient and green logistic services, especially in urban areas or complicated topography. However, the energy storage limit of the UAV makes it difficult to perform long-distance delivery tasks. In this paper, we propose a novel multimodal logistics framework, in which the UAVs can call on ground vehicles to provide hitch services to save their own energy and extend their delivery distance. This multimodal logistics framework is formulated as a two-stage model to jointly consider the incentive mechanism design for ground vehicles and path planning for UAVs. In Stage I, to deal with the motivations for ground vehicles to assist UAV delivery, a dynamic pricing scheme is proposed to best balance the vehicle response time and payments to ground vehicles. It shows that a higher price should be decided if the vehicle response time is long to encourage more vehicles to offer a ride. In Stage II, the task allocation and path planning of the UAVs over traffic network is studied based on the vehicle response time obtained in Stage I. To address pathfinding with restrictions and the performance degradation of the pathfinding algorithm due to the rising number of conflicts in multi-agent pathfinding, we propose the suboptimal conflict avoidance-based path search (CABPS) algorithm, which has polynomial time complexity. Finally, we validate our results via simulations. It is shown that our approach is able to increase the success rate of UAV package delivery. Moreover, we estimate the delivery time of the UAV in a pessimistic case, it is still twice as fast as the delivery time of the ground vehicle only.",
        "published": "2022-10-02T11:32:38Z",
        "link": "http://arxiv.org/abs/2210.00490v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Agent-Cells with DNA Programming: A Dynamic Decentralized System",
        "authors": [
            "Arash Vaezi"
        ],
        "summary": "This paper introduces a new concept. We intend to give life to a software agent. A software agent is a computer program that acts on a user's behalf. We put a DNA inside the agent. DNA is a simple text, a whole roadmap of a network of agents or a system with details. A Dynamic Numerical Abstract of a multiagent system. It is also a reproductive part for an \\emph{agent} that makes the agent take actions and decide independently and reproduce coworkers. By defining different DNA structures, one can establish new agents and different nets for different usages. We initiate such thinking as \\emph{DNA programming}. This strategy leads to a new field of programming. This type of programming can help us manage large systems with various elements with an incredibly organized customizable structure. An agent can reproduce another agent. We put one or a few agents around a given network, and the agents will reproduce themselves till they can reach others and pervade the whole network. An agent's position or other environmental or geographical characteristics make it possible for an agent to know its active set of \\emph{genes} on its DNA. The active set of genes specifies its duties. There is a database that includes a list of functions s.t. each one is an implementation of what a \\emph{gene} represents. To utilize a decentralized database, we may use a blockchain-based structure.   This design can adapt to a system that manages many static and dynamic networks. This network could be a distributed system, a decentralized system, a telecommunication network such as a 5G monitoring system, an IoT management system, or even an energy management system. The final system is the combination of all the agents and the overlay net that connects the agents. We denote the final net as the \\emph{body} of the system.",
        "published": "2022-10-02T16:53:49Z",
        "link": "http://arxiv.org/abs/2211.17104v3",
        "categories": [
            "cs.MA",
            "cs.CR",
            "cs.DC"
        ]
    },
    {
        "title": "Establishing Meta-Decision-Making for AI: An Ontology of Relevance,   Representation and Reasoning",
        "authors": [
            "Cosmin Badea",
            "Leilani Gilpin"
        ],
        "summary": "We propose an ontology of building decision-making systems, with the aim of establishing Meta-Decision-Making for Artificial Intelligence (AI), improving autonomy, and creating a framework to build metrics and benchmarks upon. To this end, we propose the three parts of Relevance, Representation, and Reasoning, and discuss their value in ensuring safety and mitigating risk in the context of third wave cognitive systems. Our nomenclature reflects the literature on decision-making, and our ontology allows researchers that adopt it to frame their work in relation to one or more of these parts.",
        "published": "2022-10-02T19:49:55Z",
        "link": "http://arxiv.org/abs/2210.00608v1",
        "categories": [
            "cs.AI",
            "cs.CY",
            "cs.LO",
            "cs.MA"
        ]
    },
    {
        "title": "Economic-Driven Adaptive Traffic Signal Control",
        "authors": [
            "Shan Jiang",
            "Yufei Huang",
            "Mohsen Jafari",
            "Mohammad Jalayer"
        ],
        "summary": "With the emerging connected-vehicle technologies and smart roads, the need for intelligent adaptive traffic signal controls is more than ever before. This paper proposes a novel Economic-driven Adaptive Traffic Signal Control (eATSC) model with a hyper control variable - interest rate defined in economics for traffic signal control at signalized intersections. The eATSC uses a continuous compounding function that captures both the total number of vehicles and the accumulated waiting time of each vehicle to compute penalties for different directions. The computed penalties grow with waiting time and is used for signal control decisions. Each intersection is assigned two intelligent agents adjusting interest rate and signal length for different directions according to the traffic patterns, respectively. The problem is formulated as a Markov Decision Process (MDP) problem to reduce congestions, and a two-agent Double Dueling Deep Q Network (DDDQN) is utilized to solve the problem. Under the optimal policy, the agents can select the optimal interest rates and signal time to minimize the likelihood of traffic congestion. To evaluate the superiority of our method, a VISSIM simulation model with classic four-leg signalized intersections is developed. The results indicate that the proposed model is adequately able to maintain healthy traffic flow at the intersection.",
        "published": "2022-10-02T22:24:58Z",
        "link": "http://arxiv.org/abs/2210.00645v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Automated Performance Estimation for Decentralized Optimization via   Network Size Independent Problems",
        "authors": [
            "Sebastien Colla",
            "Julien M. Hendrickx"
        ],
        "summary": "We develop a novel formulation of the Performance Estimation Problem (PEP) for decentralized optimization whose size is independent of the number of agents in the network. The PEP approach allows computing automatically the worst-case performance and worst-case instance of first-order optimization methods by solving an SDP. Unlike previous work, the size of our new PEP formulation is independent of the network size. For this purpose, we take a global view of the decentralized problem and we also decouple the consensus subspace and its orthogonal complement. We apply our methodology to different decentralized methods such as DGD, DIGing and EXTRA and obtain numerically tight performance guarantees that are valid for any network size.",
        "published": "2022-10-03T03:06:10Z",
        "link": "http://arxiv.org/abs/2210.00695v1",
        "categories": [
            "math.OC",
            "cs.MA"
        ]
    },
    {
        "title": "Cooperative Multi-Agent Deep Reinforcement Learning for Reliable and   Energy-Efficient Mobile Access via Multi-UAV Control",
        "authors": [
            "Chanyoung Park",
            "Soohyun Park",
            "Soyi Jung",
            "Carlos Cordeiro",
            "Joongheon Kim"
        ],
        "summary": "This paper addresses a novel multi-agent deep reinforcement learning (MADRL)-based positioning algorithm for multiple unmanned aerial vehicles (UAVs) collaboration (i.e., UAVs work as mobile base stations). The primary objective of the proposed algorithm is to establish dependable mobile access networks for cellular vehicle-to-everything (C-V2X) communication, thereby facilitating the realization of high-quality intelligent transportation systems (ITS). The reliable mobile access services can be achieved in following two ways, i.e., i) energy-efficient UAV operation and ii) reliable wireless communication services. For energy-efficient UAV operation, the reward of our proposed MADRL algorithm contains the features for UAV energy consumption models in order to realize efficient operations. Furthermore, for reliable wireless communication services, the quality of service (QoS) requirements of individual users are considered as a part of rewards and 60GHz mmWave radio is used for mobile access. This paper considers the 60GHz mmWave access for utilizing the benefits of i) ultra-wide-bandwidth for multi-Gbps high-speed communications and ii) high-directional communications for spatial reuse that is obviously good for densely deployed users. Lastly, the comprehensive and data-intensive performance evaluation of the proposed MADRL-based algorithm for multi-UAV positioning is conducted in this paper. The results of these evaluations demonstrate that the proposed algorithm outperforms other existing algorithms.",
        "published": "2022-10-03T14:01:52Z",
        "link": "http://arxiv.org/abs/2210.00945v2",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Assuring Safety of Vision-Based Swarm Formation Control",
        "authors": [
            "Chiao Hsieh",
            "Yubin Koh",
            "Yangge Li",
            "Sayan Mitra"
        ],
        "summary": "Vision-based formation control systems are attractive because they can use inexpensive sensors and can work in GPS-denied environments. The safety assurance for such systems is challenging: the vision component's accuracy depends on the environment in complicated ways, these errors propagate through the system and lead to incorrect control actions, and there exists no formal specification for end-to-end reasoning. We address this problem and propose a technique for safety assurance of vision-based formation control: First, we propose a scheme for constructing quantizers that are consistent with vision-based perception. Next, we show how the convergence analysis of a standard quantized consensus algorithm can be adapted for the constructed quantizers. We use the recently defined notion of perception contracts to create error bounds on the actual vision-based perception pipeline using sampled data from different ground truth states, environments, and weather conditions. Specifically, we use a quantizer in logarithmic polar coordinates, and we show that this quantizer is suitable for the constructed perception contracts for the vision-based position estimation, where the error worsens with respect to the absolute distance between agents. We build our formation control algorithm with this nonuniform quantizer, and we prove its convergence employing an existing result for quantized consensus.",
        "published": "2022-10-03T14:47:32Z",
        "link": "http://arxiv.org/abs/2210.00982v2",
        "categories": [
            "cs.MA",
            "cs.RO",
            "cs.SE"
        ]
    },
    {
        "title": "Agent swarms: cooperation and coordination under stringent   communications constraint",
        "authors": [
            "Paul Kinsler",
            "Sean Holman",
            "Andrew Elliott",
            "Cathryn N. Mitchell",
            "R. Eddie Wilson"
        ],
        "summary": "Here we consider the communications tactics appropriate for a group of agents that need to \"swarm\" together in a highly adversarial environment. Specfically, whilst they need to cooperate by exchanging information with each other about their location and their plans; at the same time they also need to keep such communications to an absolute minimum. This might be due to a need for stealth, or otherwise be relevant to situations where communications are signficantly restricted. Complicating this process is that we assume each agent has (a) no means of passively locating others, (b) it must rely on being updated by reception of appropriate messages; and if no such update messages arrive, (c) then their own beliefs about other agents will gradually become out of date and increasingly inaccurate. Here we use a geometry-free multi-agent model that is capable of allowing for message-based information transfer between agents with different intrinsic connectivities, as would be present in a spatial arrangement of agents. We present agent-centric performance metrics that require only minimal assumptions, and show how simulated outcome distributions, risks, and connectivities depend on the ratio of information gain to loss. We also show that checking for too-long round-trip times can be an effective minimal-information filter for determining which agents to no longer target with messages.",
        "published": "2022-10-03T18:33:05Z",
        "link": "http://arxiv.org/abs/2210.01163v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Meta Navigation Functions: Adaptive Associations for Coordination of   Multi-Agent Systems",
        "authors": [
            "Matin Macktoobian",
            "Guillaume Ferdinand Duc"
        ],
        "summary": "In this paper, we introduce a new class of potential fields, i.e., meta navigation functions (MNFs) to coordinate multi-agent systems. Thanks to the MNF formulation, agents can contribute to each other's coordination via partial and/or total associations, contrary to traditional decentralized navigation functions (DNFs). In particular, agents may stimulate each other via their MNFs. Moreover, MNFs need to be confined which is a weaker condition compared to the Morse condition of DNFs. An MNF is composed of a confined function and an attraction kernel. The critical points of the former can be confined in a safe region around a target critical point. The collision-free trajectory of an agent and its associations to its peers are governed by a confined function before reaching its safe region. Then, the attraction kernel drives the agent to its target in the safe region. MNFs provide faster coordination compared to DNFs. We illustrate how MNFs may exhibit some social behaviors in the course of partial and total associations among agents. Our simulations verify the efficiency of MNFs to coordinate complex swarms of agents.",
        "published": "2022-10-04T02:15:15Z",
        "link": "http://arxiv.org/abs/2210.01314v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Federated Reinforcement Learning for Real-Time Electric Vehicle Charging   and Discharging Control",
        "authors": [
            "Zixuan Zhang",
            "Yuning Jiang",
            "Yuanming Shi",
            "Ye Shi",
            "Wei Chen"
        ],
        "summary": "With the recent advances in mobile energy storage technologies, electric vehicles (EVs) have become a crucial part of smart grids. When EVs participate in the demand response program, the charging cost can be significantly reduced by taking full advantage of the real-time pricing signals. However, many stochastic factors exist in the dynamic environment, bringing significant challenges to design an optimal charging/discharging control strategy. This paper develops an optimal EV charging/discharging control strategy for different EV users under dynamic environments to maximize EV users' benefits. We first formulate this problem as a Markov decision process (MDP). Then we consider EV users with different behaviors as agents in different environments. Furthermore, a horizontal federated reinforcement learning (HFRL)-based method is proposed to fit various users' behaviors and dynamic environments. This approach can learn an optimal charging/discharging control strategy without sharing users' profiles. Simulation results illustrate that the proposed real-time EV charging/discharging control strategy can perform well among various stochastic factors.",
        "published": "2022-10-04T08:22:46Z",
        "link": "http://arxiv.org/abs/2210.01452v1",
        "categories": [
            "eess.SY",
            "cs.LG",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Incentivising cooperation by rewarding the weakest member",
        "authors": [
            "Jory Schossau",
            "Bamshad Shirmohammadi",
            "Arend Hintze"
        ],
        "summary": "Autonomous agents that act with each other on behalf of humans are becoming more common in many social domains, such as customer service, transportation, and health care. In such social situations greedy strategies can reduce the positive outcome for all agents, such as leading to stop-and-go traffic on highways, or causing a denial of service on a communications channel. Instead, we desire autonomous decision-making for efficient performance while also considering equitability of the group to avoid these pitfalls. Unfortunately, in complex situations it is far easier to design machine learning objectives for selfish strategies than for equitable behaviors. Here we present a simple way to reward groups of agents in both evolution and reinforcement learning domains by the performance of their weakest member. We show how this yields ``fairer'' more equitable behavior, while also maximizing individual outcomes, and we show the relationship to biological selection mechanisms of group-level selection and inclusive fitness theory.",
        "published": "2022-10-04T14:03:37Z",
        "link": "http://arxiv.org/abs/2212.00119v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "DGORL: Distributed Graph Optimization based Relative Localization of   Multi-Robot Systems",
        "authors": [
            "Ehsan Latif",
            "Ramviyas Parasuraman"
        ],
        "summary": "An optimization problem is at the heart of many robotics estimating, planning, and optimum control problems. Several attempts have been made at model-based multi-robot localization, and few have formulated the multi-robot collaborative localization problem as a factor graph problem to solve through graph optimization. Here, the optimization objective is to minimize the errors of estimating the relative location estimates in a distributed manner. Our novel graph-theoretic approach to solving this problem consists of three major components; (connectivity) graph formation, expansion through transition model, and optimization of relative poses. First, we estimate the relative pose-connectivity graph using the received signal strength between the connected robots, indicating relative ranges between them. Then, we apply a motion model to formulate graph expansion and optimize them using g$^2$o graph optimization as a distributed solver over dynamic networks. Finally, we theoretically analyze the algorithm and numerically validate its optimality and performance through extensive simulations. The results demonstrate the practicality of the proposed solution compared to a state-of-the-art algorithm for collaborative localization in multi-robot systems.",
        "published": "2022-10-04T15:03:21Z",
        "link": "http://arxiv.org/abs/2210.01662v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "ISFL: Federated Learning for Non-i.i.d. Data with Local Importance   Sampling",
        "authors": [
            "Zheqi Zhu",
            "Yuchen Shi",
            "Pingyi Fan",
            "Chenghui Peng",
            "Khaled B. Letaief"
        ],
        "summary": "As a promising learning paradigm integrating computation and communication, federated learning (FL) proceeds the local training and the periodic sharing from distributed clients. Due to the non-i.i.d. data distribution on clients, FL model suffers from the gradient diversity, poor performance, bad convergence, etc. In this work, we aim to tackle this key issue by adopting importance sampling (IS) for local training. We propose importance sampling federated learning (ISFL), an explicit framework with theoretical guarantees. Firstly, we derive the convergence theorem of ISFL to involve the effects of local importance sampling. Then, we formulate the problem of selecting optimal IS weights and obtain the theoretical solutions. We also employ a water-filling method to calculate the IS weights and develop the ISFL algorithms. The experimental results on CIFAR-10 fit the proposed theorems well and verify that ISFL reaps better performance, sampling efficiency, as well as explainability on non-i.i.d. data. To the best of our knowledge, ISFL is the first non-i.i.d. FL solution from the local sampling aspect which exhibits theoretical compatibility with neural network models. Furthermore, as a local sampling approach, ISFL can be easily migrated into other emerging FL frameworks.",
        "published": "2022-10-05T09:43:58Z",
        "link": "http://arxiv.org/abs/2210.02119v3",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.DC",
            "cs.MA"
        ]
    },
    {
        "title": "Game Theoretic Rating in N-player general-sum games with Equilibria",
        "authors": [
            "Luke Marris",
            "Marc Lanctot",
            "Ian Gemp",
            "Shayegan Omidshafiei",
            "Stephen McAleer",
            "Jerome Connor",
            "Karl Tuyls",
            "Thore Graepel"
        ],
        "summary": "Rating strategies in a game is an important area of research in game theory and artificial intelligence, and can be applied to any real-world competitive or cooperative setting. Traditionally, only transitive dependencies between strategies have been used to rate strategies (e.g. Elo), however recent work has expanded ratings to utilize game theoretic solutions to better rate strategies in non-transitive games. This work generalizes these ideas and proposes novel algorithms suitable for N-player, general-sum rating of strategies in normal-form games according to the payoff rating system. This enables well-established solution concepts, such as equilibria, to be leveraged to efficiently rate strategies in games with complex strategic interactions, which arise in multiagent training and real-world interactions between many agents. We empirically validate our methods on real world normal-form data (Premier League) and multiagent reinforcement learning agent evaluation.",
        "published": "2022-10-05T12:33:03Z",
        "link": "http://arxiv.org/abs/2210.02205v1",
        "categories": [
            "cs.GT",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Cost Aware Asynchronous Multi-Agent Active Search",
        "authors": [
            "Arundhati Banerjee",
            "Ramina Ghods",
            "Jeff Schneider"
        ],
        "summary": "Multi-agent active search requires autonomous agents to choose sensing actions that efficiently locate targets. In a realistic setting, agents also must consider the costs that their decisions incur. Previously proposed active search algorithms simplify the problem by ignoring uncertainty in the agent's environment, using myopic decision making, and/or overlooking costs. In this paper, we introduce an online active search algorithm to detect targets in an unknown environment by making adaptive cost-aware decisions regarding the agent's actions. Our algorithm combines principles from Thompson Sampling (for search space exploration and decentralized multi-agent decision making), Monte Carlo Tree Search (for long horizon planning) and pareto-optimal confidence bounds (for multi-objective optimization in an unknown environment) to propose an online lookahead planner that removes all the simplifications. We analyze the algorithm's performance in simulation to show its efficacy in cost aware active search.",
        "published": "2022-10-05T13:38:30Z",
        "link": "http://arxiv.org/abs/2210.02259v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "From Intelligent Agents to Trustworthy Human-Centred Multiagent Systems",
        "authors": [
            "Mohammad Divband Soorati",
            "Enrico H. Gerding",
            "Enrico Marchioni",
            "Pavel Naumov",
            "Timothy J. Norman",
            "Sarvapali D. Ramchurn",
            "Bahar Rastegari",
            "Adam Sobey",
            "Sebastian Stein",
            "Danesh Tarpore",
            "Vahid Yazdanpanah",
            "Jie Zhang"
        ],
        "summary": "The Agents, Interaction and Complexity research group at the University of Southampton has a long track record of research in multiagent systems (MAS). We have made substantial scientific contributions across learning in MAS, game-theoretic techniques for coordinating agent systems, and formal methods for representation and reasoning. We highlight key results achieved by the group and elaborate on recent work and open research challenges in developing trustworthy autonomous systems and deploying human-centred AI systems that aim to support societal good.",
        "published": "2022-10-05T13:40:38Z",
        "link": "http://arxiv.org/abs/2210.02260v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Spatial-Temporal-Aware Safe Multi-Agent Reinforcement Learning of   Connected Autonomous Vehicles in Challenging Scenarios",
        "authors": [
            "Zhili Zhang",
            "Songyang Han",
            "Jiangwei Wang",
            "Fei Miao"
        ],
        "summary": "Communication technologies enable coordination among connected and autonomous vehicles (CAVs). However, it remains unclear how to utilize shared information to improve the safety and efficiency of the CAV system in dynamic and complicated driving scenarios. In this work, we propose a framework of constrained multi-agent reinforcement learning (MARL) with a parallel Safety Shield for CAVs in challenging driving scenarios that includes unconnected hazard vehicles. The coordination mechanisms of the proposed MARL include information sharing and cooperative policy learning, with Graph Convolutional Network (GCN)-Transformer as a spatial-temporal encoder that enhances the agent's environment awareness. The Safety Shield module with Control Barrier Functions (CBF)-based safety checking protects the agents from taking unsafe actions. We design a constrained multi-agent advantage actor-critic (CMAA2C) algorithm to train safe and cooperative policies for CAVs. With the experiment deployed in the CARLA simulator, we verify the performance of the safety checking, spatial-temporal encoder, and coordination mechanisms designed in our method by comparative experiments in several challenging scenarios with unconnected hazard vehicles. Results show that our proposed methodology significantly increases system safety and efficiency in challenging scenarios.",
        "published": "2022-10-05T14:39:07Z",
        "link": "http://arxiv.org/abs/2210.02300v3",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "A Liquid Democracy System for Human-Computer Societies",
        "authors": [
            "Anton Kolonin",
            "Ben Goertzel",
            "Cassio Pennachin",
            "Deborah Duong",
            "Marco Argentieri",
            "Matt Iklé",
            "Nejc Znidar"
        ],
        "summary": "Problem of reliable democratic governance is critical for survival of any community, and it will be critical for communities powered with Artificial Intelligence (AI) systems upon developments of the latter. Apparently, it will be getting more and more critical because of increasing speeds and scales of electronic communications and decreasing latencies in system responses. In order to address this need, we present design and implementation of a reputation system supporting \"liquid democracy\" principle. The system is based on \"weighted liquid rank\" algorithm employing different sorts of explicit and implicit ratings being exchanged by members of the society as well as implicit assessments of of the members based on measures of their activity in the society. The system is evaluated against live social network data with help of simulation modelling for an online marketplace case.",
        "published": "2022-10-05T15:57:49Z",
        "link": "http://arxiv.org/abs/2210.02356v1",
        "categories": [
            "cs.MA",
            "cs.CY",
            "cs.SI"
        ]
    },
    {
        "title": "A Reputation System for Market Security and Equity",
        "authors": [
            "Anton Kolonin",
            "Deborah Duong",
            "Ben Goertzel",
            "Cassio Pennachin",
            "Matt Iklé",
            "Nejc Znidar",
            "Marco Argentieri"
        ],
        "summary": "We simulate a reputation system in a market to optimise the balance between market security and market equity. We introduce a method of using a reputation system that will stabilise the distribution of wealth in a market in a fair manner. We also introduce metrics of a modified Gini that takes production quality into account, a way to use a weighted Pearson as a tool to optimise balance.",
        "published": "2022-10-05T16:06:14Z",
        "link": "http://arxiv.org/abs/2210.02362v1",
        "categories": [
            "cs.MA",
            "cs.CY",
            "cs.SI"
        ]
    },
    {
        "title": "Perception of Personality Traits in Crowds of Virtual Humans",
        "authors": [
            "Lucas Nardino",
            "Enzo Krzmienszki",
            "Vinícius Jurinic Cassol",
            "Diogo Schaffer",
            "Victor Flávio de Andrade Araujo",
            "Rodolfo Migon Favaretto",
            "Felipe Elsner",
            "Gabriel Fonseca Silva",
            "Soraia Raupp Musse"
        ],
        "summary": "This paper proposes a perceptual visual analysis regarding the personality of virtual humans. Many studies have presented findings regarding the way human beings perceive virtual humans with respect to their faces, body animation, motion in the virtual environment and etc. We are interested in investigating the way people perceive visual manifestations of virtual humans' personality traits when they are interactive and organized in groups. Many applications in games and movies can benefit from the findings regarding the perceptual analysis with the main goal to provide more realistic characters and improve the users' experience. We provide experiments with subjects and obtained results indicate that, although is very subtle, people perceive more the extraversion (the personality trait that we measured), into the crowds of virtual humans, when interacting with virtual humans behaviors, than when just observing as a spectator camera.",
        "published": "2022-10-06T16:48:16Z",
        "link": "http://arxiv.org/abs/2210.03042v1",
        "categories": [
            "cs.HC",
            "cs.MA"
        ]
    },
    {
        "title": "LODUS: A Multi-Level Framework for Simulating Environment and Population   -- A Contagion Experiment on a Pandemic World",
        "authors": [
            "Gabriel Fonseca Silva",
            "Vinícius Cassol",
            "Amyr Borges Fortes Neto",
            "Andre Antonitsch",
            "Diogo Schaffer",
            "Soraia Raupp Musse",
            "Rodrigo de Marsillac Linn"
        ],
        "summary": "Nowadays we are experiencing a way of life that never existed before. The pandemic has sharply changed our habits, customs, and behavior. In addition, a lot of work was suddenly requested for city managers challenging them to develop strategies to try stopping the pandemic progression. Urban environments must be dynamic and managers need fast decisions when working on crisis situations. In this paper we present LODUS, a framework able to simulate urban environments on a multi-level approach, combining macro and micro simulation information in order to provide accurate information about population dynamics. Furthermore, the framework LODUS is a powerful tool when performing an urban viability study, since the simulation results are able to highlight and predict attention points prior to an urban environment to be built.",
        "published": "2022-10-06T17:09:34Z",
        "link": "http://arxiv.org/abs/2210.03060v1",
        "categories": [
            "cs.MA",
            "cs.HC"
        ]
    },
    {
        "title": "Moving Virtual Agents Forward in Space and Time",
        "authors": [
            "Gabriel F. Silva",
            "Paulo Knob",
            "Carlos G. Johansson",
            "Douglas A. Schlatter",
            "Soraia R. Musse"
        ],
        "summary": "This article proposes an adaptation from the model of Bianco for fast-forwarding agents in crowd simulation, which enables us to accurately fast forward agents in time. Besides being able to jump from one position to another, agents are able to stay inside their track, it means, the new position is calculated taking into account the original global path the agent would follow, if not being fast-forwarded. Obstacles and other agents around are also taken into account when calculating the new position. In addition, we included a personality aspect on agents, which affect their behaviors and, also, be taken into account when jumping to a future time and space. We conducted some experiments to validate our model, which shows that it was able to indeed fast forward agents from a position to another, in a coherent time, sticking to a given global path while avoiding collisions. Finally, we present a use case, showing that our method can fit inside a \"Fog of War\" system.",
        "published": "2022-10-06T17:28:04Z",
        "link": "http://arxiv.org/abs/2210.03073v1",
        "categories": [
            "cs.MA",
            "cs.GR"
        ]
    },
    {
        "title": "Double Averaging and Gradient Projection: Convergence Guarantees for   Decentralized Constrained Optimization",
        "authors": [
            "Firooz Shahriari-Mehr",
            "Ashkan Panahi"
        ],
        "summary": "We consider a generic decentralized constrained optimization problem over static, directed communication networks, where each agent has exclusive access to only one convex, differentiable, local objective term and one convex constraint set. For this setup, we propose a novel decentralized algorithm, called DAGP (Double Averaging and Gradient Projection), based on local gradients, projection onto local constraints, and local averaging. We achieve global optimality through a novel distributed tracking technique we call distributed null projection. Further, we show that DAGP can be used to solve unconstrained problems with non-differentiable objective terms with a problem reduction scheme. Assuming only smoothness of the objective terms, we study the convergence of DAGP and establish sub-linear rates of convergence in terms of feasibility, consensus, and optimality, with no extra assumption (e.g. strong convexity). For the analysis, we forego the difficulties of selecting Lyapunov functions by proposing a new methodology of convergence analysis in optimization problems, which we refer to as aggregate lower-bounding. To demonstrate the generality of this method, we also provide an alternative convergence proof for the standard gradient descent algorithm with smooth functions. Finally, we present numerical results demonstrating the effectiveness of our proposed method in both constrained and unconstrained problems. In particular, we propose a distributed scheme by DAGP for the optimal transport problem with superior performance and speed.",
        "published": "2022-10-06T21:57:15Z",
        "link": "http://arxiv.org/abs/2210.03232v3",
        "categories": [
            "math.OC",
            "cs.DC",
            "cs.MA"
        ]
    },
    {
        "title": "Multi-agent Deep Covering Skill Discovery",
        "authors": [
            "Jiayu Chen",
            "Marina Haliem",
            "Tian Lan",
            "Vaneet Aggarwal"
        ],
        "summary": "The use of skills (a.k.a., options) can greatly accelerate exploration in reinforcement learning, especially when only sparse reward signals are available. While option discovery methods have been proposed for individual agents, in multi-agent reinforcement learning settings, discovering collaborative options that can coordinate the behavior of multiple agents and encourage them to visit the under-explored regions of their joint state space has not been considered. In this case, we propose Multi-agent Deep Covering Option Discovery, which constructs the multi-agent options through minimizing the expected cover time of the multiple agents' joint state space. Also, we propose a novel framework to adopt the multi-agent options in the MARL process. In practice, a multi-agent task can usually be divided into some sub-tasks, each of which can be completed by a sub-group of the agents. Therefore, our algorithm framework first leverages an attention mechanism to find collaborative agent sub-groups that would benefit most from coordinated actions. Then, a hierarchical algorithm, namely HA-MSAC, is developed to learn the multi-agent options for each sub-group to complete their sub-tasks first, and then to integrate them through a high-level policy as the solution of the whole task. This hierarchical option construction allows our framework to strike a balance between scalability and effective collaboration among the agents. The evaluation based on multi-agent collaborative tasks shows that the proposed algorithm can effectively capture the agent interactions with the attention mechanism, successfully identify multi-agent options, and significantly outperforms prior works using single-agent options or no options, in terms of both faster exploration and higher task rewards.",
        "published": "2022-10-07T00:40:59Z",
        "link": "http://arxiv.org/abs/2210.03269v3",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "A Novel Graph-based Motion Planner of Multi-Mobile Robot Systems with   Formation and Obstacle Constraints",
        "authors": [
            "Wenhang Liu",
            "Jiawei Hu",
            "Heng Zhang",
            "Michael Yu Wang",
            "Zhenhua Xiong"
        ],
        "summary": "Multi-mobile robot systems show great advantages over one single robot in many applications. However, the robots are required to form desired task-specified formations, making feasible motions decrease significantly. Thus, it is challenging to determine whether the robots can pass through an obstructed environment under formation constraints, especially in an obstacle-rich environment. Furthermore, is there an optimal path for the robots? To deal with the two problems, a novel graphbased motion planner is proposed in this paper. A mapping between workspace and configuration space of multi-mobile robot systems is first built, where valid configurations can be acquired to satisfy both formation constraints and collision avoidance. Then, an undirected graph is generated by verifying connectivity between valid configurations. The breadth-first search method is employed to answer the question of whether there is a feasible path on the graph. Finally, an optimal path will be planned on the updated graph, considering the cost of path length and formation preference. Simulation results show that the planner can be applied to get optimal motions of robots under formation constraints in obstacle-rich environments. Additionally, different constraints are considered.",
        "published": "2022-10-07T06:06:30Z",
        "link": "http://arxiv.org/abs/2210.03340v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "The Power of Small Coalitions under Two-Tier Majority on Regular Graphs",
        "authors": [
            "Pavel Chebotarev",
            "David Peleg"
        ],
        "summary": "In this paper, we study the following problem. Consider a setting where a proposal is offered to the vertices of a given network $G$, and the vertices must conduct a vote and decide whether to accept the proposal or reject it. Each vertex $v$ has its own valuation of the proposal; we say that $v$ is ``happy'' if its valuation is positive (i.e., it expects to gain from adopting the proposal) and ``sad'' if its valuation is negative. However, vertices do not base their vote merely on their own valuation. Rather, a vertex $v$ is a \\emph{proponent} of the proposal if the majority of its neighbors are happy with it and an \\emph{opponent} in the opposite case. At the end of the vote, the network collectively accepts the proposal whenever the majority of its vertices are proponents. We study this problem for regular graphs with loops. Specifically, we consider the class $\\mathcal{G}_{n|d|h}$ of $d$-regular graphs of odd order $n$ with all $n$ loops and $h$ happy vertices. We are interested in establishing necessary and sufficient conditions for the class $\\mathcal{G}_{n|d|h}$ to contain a labeled graph accepting the proposal, as well as conditions to contain a graph rejecting the proposal. We also discuss connections to the existing literature, including that on majority domination, and investigate the properties of the obtained conditions.",
        "published": "2022-10-07T08:59:41Z",
        "link": "http://arxiv.org/abs/2210.03410v4",
        "categories": [
            "math.CO",
            "cs.DM",
            "cs.MA",
            "cs.SI",
            "math.OC",
            "05C69, 05C22, 68R10, 91B14, 94C15"
        ]
    },
    {
        "title": "How to Enable Uncertainty Estimation in Proximal Policy Optimization",
        "authors": [
            "Eugene Bykovets",
            "Yannick Metz",
            "Mennatallah El-Assady",
            "Daniel A. Keim",
            "Joachim M. Buhmann"
        ],
        "summary": "While deep reinforcement learning (RL) agents have showcased strong results across many domains, a major concern is their inherent opaqueness and the safety of such systems in real-world use cases. To overcome these issues, we need agents that can quantify their uncertainty and detect out-of-distribution (OOD) states. Existing uncertainty estimation techniques, like Monte-Carlo Dropout or Deep Ensembles, have not seen widespread adoption in on-policy deep RL. We posit that this is due to two reasons: concepts like uncertainty and OOD states are not well defined compared to supervised learning, especially for on-policy RL methods. Secondly, available implementations and comparative studies for uncertainty estimation methods in RL have been limited. To overcome the first gap, we propose definitions of uncertainty and OOD for Actor-Critic RL algorithms, namely, proximal policy optimization (PPO), and present possible applicable measures. In particular, we discuss the concepts of value and policy uncertainty. The second point is addressed by implementing different uncertainty estimation methods and comparing them across a number of environments. The OOD detection performance is evaluated via a custom evaluation benchmark of in-distribution (ID) and OOD states for various RL environments. We identify a trade-off between reward and OOD detection performance. To overcome this, we formulate a Pareto optimization problem in which we simultaneously optimize for reward and OOD detection performance. We show experimentally that the recently proposed method of Masksembles strikes a favourable balance among the survey methods, enabling high-quality uncertainty estimation and OOD detection while matching the performance of original RL agents.",
        "published": "2022-10-07T15:56:59Z",
        "link": "http://arxiv.org/abs/2210.03649v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "cs.RO",
            "I.2; I.2.6; I.2.8; I.2.9; I.2.10"
        ]
    },
    {
        "title": "Reinforcement Learning Approach for Multi-Agent Flexible Scheduling   Problems",
        "authors": [
            "Hongjian Zhou",
            "Boyang Gu",
            "Chenghao Jin"
        ],
        "summary": "Scheduling plays an important role in automated production. Its impact can be found in various fields such as the manufacturing industry, the service industry and the technology industry. A scheduling problem (NP-hard) is a task of finding a sequence of job assignments on a given set of machines with the goal of optimizing the objective defined. Methods such as Operation Research, Dispatching Rules, and Combinatorial Optimization have been applied to scheduling problems but no solution guarantees to find the optimal solution. The recent development of Reinforcement Learning has shown success in sequential decision-making problems. This research presents a Reinforcement Learning approach for scheduling problems. In particular, this study delivers an OpenAI gym environment with search-space reduction for Job Shop Scheduling Problems and provides a heuristic-guided Q-Learning solution with state-of-the-art performance for Multi-agent Flexible Job Shop Problems.",
        "published": "2022-10-07T16:31:01Z",
        "link": "http://arxiv.org/abs/2210.03674v1",
        "categories": [
            "cs.AI",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Traffic-Aware Autonomous Driving with Differentiable Traffic Simulation",
        "authors": [
            "Laura Zheng",
            "Sanghyun Son",
            "Ming C. Lin"
        ],
        "summary": "While there have been advancements in autonomous driving control and traffic simulation, there have been little to no works exploring their unification with deep learning. Works in both areas seem to focus on entirely different exclusive problems, yet traffic and driving are inherently related in the real world. In this paper, we present Traffic-Aware Autonomous Driving (TrAAD), a generalizable distillation-style method for traffic-informed imitation learning that directly optimizes for faster traffic flow and lower energy consumption. TrAAD focuses on the supervision of speed control in imitation learning systems, as most driving research focuses on perception and steering. Moreover, our method addresses the lack of co-simulation between traffic and driving simulators and provides a basis for directly involving traffic simulation with autonomous driving in future work. Our results show that, with information from traffic simulation involved in the supervision of imitation learning methods, an autonomous vehicle can learn how to accelerate in a fashion that is beneficial for traffic flow and overall energy consumption for all nearby vehicles.",
        "published": "2022-10-07T18:41:40Z",
        "link": "http://arxiv.org/abs/2210.03772v5",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Stackelberg POMDP: A Reinforcement Learning Approach for Economic Design",
        "authors": [
            "Gianluca Brero",
            "Alon Eden",
            "Darshan Chakrabarti",
            "Matthias Gerstgrasser",
            "Amy Greenwald",
            "Vincent Li",
            "David C. Parkes"
        ],
        "summary": "We introduce a reinforcement learning framework for economic design where the interaction between the environment designer and the participants is modeled as a Stackelberg game. In this game, the designer (leader) sets up the rules of the economic system, while the participants (followers) respond strategically. We integrate algorithms for determining followers' response strategies into the leader's learning environment, providing a formulation of the leader's learning problem as a POMDP that we call the Stackelberg POMDP. We prove that the optimal leader's strategy in the Stackelberg game is the optimal policy in our Stackelberg POMDP under a limited set of possible policies, establishing a connection between solving POMDPs and Stackelberg games. We solve our POMDP under a limited set of policy options via the centralized training with decentralized execution framework. For the specific case of followers that are modeled as no-regret learners, we solve an array of increasingly complex settings, including problems of indirect mechanism design where there is turn-taking and limited communication by agents. We demonstrate the effectiveness of our training framework through ablation studies. We also give convergence results for no-regret learners to a Bayesian version of a coarse-correlated equilibrium, extending known results to correlated types.",
        "published": "2022-10-07T23:55:51Z",
        "link": "http://arxiv.org/abs/2210.03852v4",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Safety Embedded Stochastic Optimal Control of Networked Multi-Agent   Systems via Barrier States",
        "authors": [
            "Lin Song",
            "Pan Zhao",
            "Neng Wan",
            "Naira Hovakimyan"
        ],
        "summary": "This paper presents a novel approach for achieving safe stochastic optimal control in networked multi-agent systems (MASs). The proposed method incorporates barrier states (BaSs) into the system dynamics to embed safety constraints. To accomplish this, the networked MAS is factorized into multiple subsystems, and each one is augmented with BaSs for the central agent. The optimal control law is obtained by solving the joint Hamilton-Jacobi-Bellman (HJB) equation on the augmented subsystem, which guarantees safety via the boundedness of the BaSs. The BaS-based optimal control technique yields safe control actions while maintaining optimality. The safe optimal control solution is approximated using path integrals. To validate the effectiveness of the proposed approach, numerical simulations are conducted on a cooperative UAV team in two different scenarios.",
        "published": "2022-10-08T00:11:04Z",
        "link": "http://arxiv.org/abs/2210.03855v2",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY",
            "math.OC"
        ]
    },
    {
        "title": "Self-organizing nest migration dynamics synthesis for ant colony systems",
        "authors": [
            "Matin Macktoobian"
        ],
        "summary": "In this study, we synthesize a novel dynamical approach for ant colonies enabling them to migrate to new nest sites in a self-organizing fashion. In other words, we realize ant colony migration as a self-organizing phenotype-level collective behavior. For this purpose, we first segment the edges of the graph of ants' pathways. Then, each segment, attributed to its own pheromone profile, may host an ant. So, multiple ants may occupy an edge at the same time. Thanks to this segment-wise edge formulation, ants have more selection options in the course of their pathway determination, thereby increasing the diversity of their colony's emergent behaviors. In light of the continuous pheromone dynamics of segments, each edge owns a spatio-temporal piece-wise continuous pheromone profile in which both deposit and evaporation processes are unified. The passive dynamics of the proposed migration mechanism is sufficiently rich so that an ant colony can migrate to the vicinity of a new nest site in a self-organizing manner without any external supervision. In particular, we perform extensive simulations to test our migration dynamics applied to a colony including 500 ants traversing a pathway graph comprising 200 nodes and 4000 edges which are segmented based on various resolutions. The obtained results exhibit the effectiveness of our strategy.",
        "published": "2022-10-08T09:16:16Z",
        "link": "http://arxiv.org/abs/2210.03975v1",
        "categories": [
            "cs.RO",
            "cs.MA",
            "cs.NE"
        ]
    },
    {
        "title": "Cognitive Models as Simulators: The Case of Moral Decision-Making",
        "authors": [
            "Ardavan S. Nobandegani",
            "Thomas R. Shultz",
            "Irina Rish"
        ],
        "summary": "To achieve desirable performance, current AI systems often require huge amounts of training data. This is especially problematic in domains where collecting data is both expensive and time-consuming, e.g., where AI systems require having numerous interactions with humans, collecting feedback from them. In this work, we substantiate the idea of $\\textit{cognitive models as simulators}$, which is to have AI systems interact with, and collect feedback from, cognitive models instead of humans, thereby making their training process both less costly and faster. Here, we leverage this idea in the context of moral decision-making, by having reinforcement learning (RL) agents learn about fairness through interacting with a cognitive model of the Ultimatum Game (UG), a canonical task in behavioral and brain sciences for studying fairness. Interestingly, these RL agents learn to rationally adapt their behavior depending on the emotional state of their simulated UG responder. Our work suggests that using cognitive models as simulators of humans is an effective approach for training AI systems, presenting an important way for computational cognitive science to make contributions to AI.",
        "published": "2022-10-08T23:14:14Z",
        "link": "http://arxiv.org/abs/2210.04121v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "q-bio.NC"
        ]
    },
    {
        "title": "Hypergraph-based Multi-Robot Task and Motion Planning",
        "authors": [
            "James Motes",
            "Tan Chen",
            "Timothy Bretl",
            "Marco Morales",
            "Nancy M. Amato"
        ],
        "summary": "We present a multi-robot task and motion planning method that, when applied to the rearrangement of objects by manipulators, results in solution times up to three orders of magnitude faster than existing methods and successfully plans for problems with up to twenty objects, more than three times as many objects as comparable methods. We achieve this improvement by decomposing the planning space to consider manipulators alone, objects, and manipulators holding objects. We represent this decomposition with a hypergraph where vertices are decomposed elements of the planning spaces and hyperarcs are transitions between elements. Existing methods use graph-based representations where vertices are full composite spaces and edges are transitions between these. Using the hypergraph reduces the representation size of the planning space-for multi-manipulator object rearrangement, the number of hypergraph vertices scales linearly with the number of either robots or objects, while the number of hyperarcs scales quadratically with the number of robots and linearly with the number of objects. In contrast, the number of vertices and edges in graph-based representations scales exponentially in the number of robots and objects. We show that similar gains can be achieved for other multi-robot task and motion planning problems.",
        "published": "2022-10-09T19:43:21Z",
        "link": "http://arxiv.org/abs/2210.04333v2",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "ELIGN: Expectation Alignment as a Multi-Agent Intrinsic Reward",
        "authors": [
            "Zixian Ma",
            "Rose Wang",
            "Li Fei-Fei",
            "Michael Bernstein",
            "Ranjay Krishna"
        ],
        "summary": "Modern multi-agent reinforcement learning frameworks rely on centralized training and reward shaping to perform well. However, centralized training and dense rewards are not readily available in the real world. Current multi-agent algorithms struggle to learn in the alternative setup of decentralized training or sparse rewards. To address these issues, we propose a self-supervised intrinsic reward ELIGN - expectation alignment - inspired by the self-organization principle in Zoology. Similar to how animals collaborate in a decentralized manner with those in their vicinity, agents trained with expectation alignment learn behaviors that match their neighbors' expectations. This allows the agents to learn collaborative behaviors without any external reward or centralized training. We demonstrate the efficacy of our approach across 6 tasks in the multi-agent particle and the complex Google Research football environments, comparing ELIGN to sparse and curiosity-based intrinsic rewards. When the number of agents increases, ELIGN scales well in all multi-agent tasks except for one where agents have different capabilities. We show that agent coordination improves through expectation alignment because agents learn to divide tasks amongst themselves, break coordination symmetries, and confuse adversaries. These results identify tasks where expectation alignment is a more useful strategy than curiosity-driven exploration for multi-agent coordination, enabling agents to do zero-shot coordination.",
        "published": "2022-10-09T22:24:44Z",
        "link": "http://arxiv.org/abs/2210.04365v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Belief functions on ordered frames of discernment",
        "authors": [
            "Arnaud Martin"
        ],
        "summary": "Most questionnaires offer ordered responses whose order is poorly studied via belief functions. In this paper, we study the consequences of a frame of discernment consisting of ordered elements on belief functions. This leads us to redefine the power space and the union of ordered elements for the disjunctive combination. We also study distances on ordered elements and their use. In particular, from a membership function, we redefine the cardinality of the intersection of ordered elements, considering them fuzzy.",
        "published": "2022-10-10T10:09:32Z",
        "link": "http://arxiv.org/abs/2210.04535v2",
        "categories": [
            "cs.AI",
            "cs.MA",
            "cs.SI"
        ]
    },
    {
        "title": "The Small Solution Hypothesis for MAPF on Strongly Connected Directed   Graphs Is True",
        "authors": [
            "Bernhard Nebel"
        ],
        "summary": "The determination of the computational complexity of multi-agent pathfinding on directed graphs (diMAPF) has been an open research problem for many years. While diMAPF has been shown to be polynomial for some special cases, only recently, it has been established that the problem is NP-hard in general. Further, it has been proved that diMAPF will be in NP if the short solution hypothesis for strongly connected directed graphs is correct. In this paper, it is shown that this hypothesis is indeed true, even when one allows for synchronous rotations.",
        "published": "2022-10-10T11:51:16Z",
        "link": "http://arxiv.org/abs/2210.04590v4",
        "categories": [
            "cs.AI",
            "cs.MA",
            "I.2.8"
        ]
    },
    {
        "title": "Communication between agents in dynamic epistemic logic",
        "authors": [
            "Fernando R. Velázquez-Quesada"
        ],
        "summary": "This manuscript studies actions of communication between epistemic logic agents. It starts by looking into actions through which all/some agents share all their information, defining the model operation that transforms the model, discussing its properties, introducing a modality for describing it and providing an axiom system for the latter. The main part of the manuscript focuses on an action through which some agents share part of their information: they share all that they know about a topic defined by a given formula. Once again, the manuscript defines the model operation that transforms the model, discusses its properties, introduces a modality for describing it and provides an axiom system for the latter.",
        "published": "2022-10-10T12:57:32Z",
        "link": "http://arxiv.org/abs/2210.04656v1",
        "categories": [
            "cs.LO",
            "cs.MA",
            "03B42 (Primary), 03B45, 03B70, 68T27"
        ]
    },
    {
        "title": "MARLlib: A Scalable and Efficient Multi-agent Reinforcement Learning   Library",
        "authors": [
            "Siyi Hu",
            "Yifan Zhong",
            "Minquan Gao",
            "Weixun Wang",
            "Hao Dong",
            "Xiaodan Liang",
            "Zhihui Li",
            "Xiaojun Chang",
            "Yaodong Yang"
        ],
        "summary": "A significant challenge facing researchers in the area of multi-agent reinforcement learning (MARL) pertains to the identification of a library that can offer fast and compatible development for multi-agent tasks and algorithm combinations, while obviating the need to consider compatibility issues. In this paper, we present MARLlib, a library designed to address the aforementioned challenge by leveraging three key mechanisms: 1) a standardized multi-agent environment wrapper, 2) an agent-level algorithm implementation, and 3) a flexible policy mapping strategy. By utilizing these mechanisms, MARLlib can effectively disentangle the intertwined nature of the multi-agent task and the learning process of the algorithm, with the ability to automatically alter the training strategy based on the current task's attributes. The MARLlib library's source code is publicly accessible on GitHub: \\url{https://github.com/Replicable-MARL/MARLlib}.",
        "published": "2022-10-11T03:11:12Z",
        "link": "http://arxiv.org/abs/2210.13708v4",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Human-AI Coordination via Human-Regularized Search and Learning",
        "authors": [
            "Hengyuan Hu",
            "David J Wu",
            "Adam Lerer",
            "Jakob Foerster",
            "Noam Brown"
        ],
        "summary": "We consider the problem of making AI agents that collaborate well with humans in partially observable fully cooperative environments given datasets of human behavior. Inspired by piKL, a human-data-regularized search method that improves upon a behavioral cloning policy without diverging far away from it, we develop a three-step algorithm that achieve strong performance in coordinating with real humans in the Hanabi benchmark. We first use a regularized search algorithm and behavioral cloning to produce a better human model that captures diverse skill levels. Then, we integrate the policy regularization idea into reinforcement learning to train a human-like best response to the human model. Finally, we apply regularized search on top of the best response policy at test time to handle out-of-distribution challenges when playing with humans. We evaluate our method in two large scale experiments with humans. First, we show that our method outperforms experts when playing with a group of diverse human players in ad-hoc teams. Second, we show that our method beats a vanilla best response to behavioral cloning baseline by having experts play repeatedly with the two agents.",
        "published": "2022-10-11T03:46:12Z",
        "link": "http://arxiv.org/abs/2210.05125v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "A General Learning Framework for Open Ad Hoc Teamwork Using Graph-based   Policy Learning",
        "authors": [
            "Arrasy Rahman",
            "Ignacio Carlucho",
            "Niklas Höpner",
            "Stefano V. Albrecht"
        ],
        "summary": "Open ad hoc teamwork is the problem of training a single agent to efficiently collaborate with an unknown group of teammates whose composition may change over time. A variable team composition creates challenges for the agent, such as the requirement to adapt to new team dynamics and dealing with changing state vector sizes. These challenges are aggravated in real-world applications in which the controlled agent only has a partial view of the environment. In this work, we develop a class of solutions for open ad hoc teamwork under full and partial observability. We start by developing a solution for the fully observable case that leverages graph neural network architectures to obtain an optimal policy based on reinforcement learning. We then extend this solution to partially observable scenarios by proposing different methodologies that maintain belief estimates over the latent environment states and team composition. These belief estimates are combined with our solution for the fully observable case to compute an agent's optimal policy under partial observability in open ad hoc teamwork. Empirical results demonstrate that our solution can learn efficient policies in open ad hoc teamwork in fully and partially observable cases. Further analysis demonstrates that our methods' success is a result of effectively learning the effects of teammates' actions while also inferring the inherent state of the environment under partial observability.",
        "published": "2022-10-11T13:44:44Z",
        "link": "http://arxiv.org/abs/2210.05448v2",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Mastering the Game of No-Press Diplomacy via Human-Regularized   Reinforcement Learning and Planning",
        "authors": [
            "Anton Bakhtin",
            "David J Wu",
            "Adam Lerer",
            "Jonathan Gray",
            "Athul Paul Jacob",
            "Gabriele Farina",
            "Alexander H Miller",
            "Noam Brown"
        ],
        "summary": "No-press Diplomacy is a complex strategy game involving both cooperation and competition that has served as a benchmark for multi-agent AI research. While self-play reinforcement learning has resulted in numerous successes in purely adversarial games like chess, Go, and poker, self-play alone is insufficient for achieving optimal performance in domains involving cooperation with humans. We address this shortcoming by first introducing a planning algorithm we call DiL-piKL that regularizes a reward-maximizing policy toward a human imitation-learned policy. We prove that this is a no-regret learning algorithm under a modified utility function. We then show that DiL-piKL can be extended into a self-play reinforcement learning algorithm we call RL-DiL-piKL that provides a model of human play while simultaneously training an agent that responds well to this human model. We used RL-DiL-piKL to train an agent we name Diplodocus. In a 200-game no-press Diplomacy tournament involving 62 human participants spanning skill levels from beginner to expert, two Diplodocus agents both achieved a higher average score than all other participants who played more than two games, and ranked first and third according to an Elo ratings model.",
        "published": "2022-10-11T14:47:35Z",
        "link": "http://arxiv.org/abs/2210.05492v1",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Multi-Agent Distributed and Decentralized Geometric Task Allocation",
        "authors": [
            "Michael Amir",
            "Yigal Koifman",
            "Yakov Bloch",
            "Ariel Barel",
            "Alfred M. Bruckstein"
        ],
        "summary": "We consider the general problem of geometric task allocation, wherein a large, decentralised swarm of simple mobile agents must detect the locations of tasks in the plane and position themselves nearby. The tasks are represented by an a priori unknown demand profile $\\Phi(x,y)$ that determines how many agents are needed in each location. The agents are autonomous, oblivious and indistinguishable, and have finite sensing range. They must configure themselves according to $\\Phi$ using only local information about $\\Phi$ and about the positions of nearby agents. All agents act according to the same local sensing-based rule of motion, and cannot explicitly communicate nor share information.   We propose an optimization-based approach to the problem which results in attraction-repulsion dynamics. Repulsion encourages agents to spread out and explore the region so as to find the tasks, and attraction causes them to accumulate at task locations. We derive this approach via gradient descent over an appropriate ``error'' functional, and test it extensively through numerical simulations.   The figures in this work are snapshots of simulations that can be viewed online at https://youtu.be/kyUiGYSaaoQ.",
        "published": "2022-10-11T15:46:54Z",
        "link": "http://arxiv.org/abs/2210.05552v2",
        "categories": [
            "cs.MA",
            "math.DS",
            "68W15"
        ]
    },
    {
        "title": "Zero-Order One-Point Estimate with Distributed Stochastic   Gradient-Tracking Technique",
        "authors": [
            "Elissa Mhanna",
            "Mohamad Assaad"
        ],
        "summary": "In this work, we consider a distributed multi-agent stochastic optimization problem, where each agent holds a local objective function that is smooth and convex, and that is subject to a stochastic process. The goal is for all agents to collaborate to find a common solution that optimizes the sum of these local functions. With the practical assumption that agents can only obtain noisy numerical function queries at exactly one point at a time, we extend the distributed stochastic gradient-tracking method to the bandit setting where we don't have an estimate of the gradient, and we introduce a zero-order (ZO) one-point estimate (1P-DSGT). We analyze the convergence of this novel technique for smooth and convex objectives using stochastic approximation tools, and we prove that it converges almost surely to the optimum. We then study the convergence rate for when the objectives are additionally strongly convex. We obtain a rate of $O(\\frac{1}{\\sqrt{k}})$ after a sufficient number of iterations $k > K_2$ which is usually optimal for techniques utilizing one-point estimators. We also provide a regret bound of $O(\\sqrt{k})$, which is exceptionally good compared to the aforementioned techniques. We further illustrate the usefulness of the proposed technique using numerical experiments.",
        "published": "2022-10-11T17:04:45Z",
        "link": "http://arxiv.org/abs/2210.05618v1",
        "categories": [
            "math.OC",
            "cs.DC",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "REMS: Middleware for Robotics Education and Development",
        "authors": [
            "Yusuke Tanaka",
            "Ankur Mehta"
        ],
        "summary": "This paper introduces REMS, a robotics middleware and control framework that is designed to introduce the Zen of Python to robotics and to improve robotics education and development flow. Although existing middleware can serve hardware abstraction and modularity, setting up environments and learning middleware-specific syntax and procedures are less viable in education. They can curb opportunities to understand robotics concepts, theories, and algorithms. Robotics is a field of integration; students and developers from various backgrounds will be involved in programming. Establishing Pythonic and object-oriented robotic framework in a natural way can enhance modular and abstracted programming for better readability, reusability, and simplicity, but also supports useful and practical skills generally in coding. REMS is to be a valuable robot educational medium not just as a tool and to be a platform from one robot to multi-agent across hardware, simulation, and analytical model implementations.",
        "published": "2022-10-11T21:05:08Z",
        "link": "http://arxiv.org/abs/2210.05784v1",
        "categories": [
            "cs.RO",
            "cs.MA",
            "cs.SE"
        ]
    },
    {
        "title": "Effect of sociability and curiosity of senior developers in building   agile scrum team competency",
        "authors": [
            "Ravi Kalluri"
        ],
        "summary": "This paper aims to investigate the mechanisms that contribute to propagation of competence in an Agile Scrum team. This study seeks to challenge the traditional view of bounded rationality (BR). An Agile Scrum team (Team) is expected to build problem solving competence quickly as the expected ramp up time continues to shrink. But the team has a mixture of expertise, competence and sociability levels that affect out-of-the-box performance. The objective is to expand BR into the social realm and see how teams can self-organize and reconfigure to allow effective problem solving. Studies have shown that agent-based computational simulation is an appropriate technique to explore this point from a theoretical perspective. (Fioretti, 2013) (Secchi, 2015). The first step is to define the problem, discuss how senior team members exhibit high curiosity and apply sociability and cognitive resources to develop overall team competence. This dynamic is modeled and simulated in NetLogoR and the results are analyzed. Finally, some key findings are presented and discussed.",
        "published": "2022-10-12T07:14:50Z",
        "link": "http://arxiv.org/abs/2210.05967v1",
        "categories": [
            "cs.SI",
            "cs.MA",
            "cs.SE"
        ]
    },
    {
        "title": "Phantom -- A RL-driven multi-agent framework to model complex systems",
        "authors": [
            "Leo Ardon",
            "Jared Vann",
            "Deepeka Garg",
            "Tom Spooner",
            "Sumitra Ganesh"
        ],
        "summary": "Agent based modelling (ABM) is a computational approach to modelling complex systems by specifying the behaviour of autonomous decision-making components or agents in the system and allowing the system dynamics to emerge from their interactions. Recent advances in the field of Multi-agent reinforcement learning (MARL) have made it feasible to study the equilibrium of complex environments where multiple agents learn simultaneously. However, most ABM frameworks are not RL-native, in that they do not offer concepts and interfaces that are compatible with the use of MARL to learn agent behaviours. In this paper, we introduce a new open-source framework, Phantom, to bridge the gap between ABM and MARL. Phantom is an RL-driven framework for agent-based modelling of complex multi-agent systems including, but not limited to economic systems and markets. The framework aims to provide the tools to simplify the ABM specification in a MARL-compatible way - including features to encode dynamic partial observability, agent utility functions, heterogeneity in agent preferences or types, and constraints on the order in which agents can act (e.g. Stackelberg games, or more complex turn-taking environments). In this paper, we present these features, their design rationale and present two new environments leveraging the framework.",
        "published": "2022-10-12T08:37:38Z",
        "link": "http://arxiv.org/abs/2210.06012v3",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "A Cooperative Perception System Robust to Localization Errors",
        "authors": [
            "Zhiying Song",
            "Fuxi Wen",
            "Hailiang Zhang",
            "Jun Li"
        ],
        "summary": "Cooperative perception is challenging for safety-critical autonomous driving applications.The errors in the shared position and pose cause an inaccurate relative transform estimation and disrupt the robust mapping of the Ego vehicle. We propose a distributed object-level cooperative perception system called OptiMatch, in which the detected 3D bounding boxes and local state information are shared between the connected vehicles. To correct the noisy relative transform, the local measurements of both connected vehicles (bounding boxes) are utilized, and an optimal transport theory-based algorithm is developed to filter out those objects jointly detected by the vehicles along with their correspondence, constructing an associated co-visible set. A correction transform is estimated from the matched object pairs and further applied to the noisy relative transform, followed by global fusion and dynamic mapping. Experiment results show that robust performance is achieved for different levels of location and heading errors, and the proposed framework outperforms the state-of-the-art benchmark fusion schemes, including early, late, and intermediate fusion, on average precision by a large margin when location and/or heading errors occur.",
        "published": "2022-10-12T15:07:24Z",
        "link": "http://arxiv.org/abs/2210.06289v2",
        "categories": [
            "cs.MA",
            "cs.CV",
            "cs.RO"
        ]
    },
    {
        "title": "Near-Optimal Multi-Agent Learning for Safe Coverage Control",
        "authors": [
            "Manish Prajapat",
            "Matteo Turchetta",
            "Melanie N. Zeilinger",
            "Andreas Krause"
        ],
        "summary": "In multi-agent coverage control problems, agents navigate their environment to reach locations that maximize the coverage of some density. In practice, the density is rarely known $\\textit{a priori}$, further complicating the original NP-hard problem. Moreover, in many applications, agents cannot visit arbitrary locations due to $\\textit{a priori}$ unknown safety constraints. In this paper, we aim to efficiently learn the density to approximately solve the coverage problem while preserving the agents' safety. We first propose a conditionally linear submodular coverage function that facilitates theoretical analysis. Utilizing this structure, we develop MacOpt, a novel algorithm that efficiently trades off the exploration-exploitation dilemma due to partial observability, and show that it achieves sublinear regret. Next, we extend results on single-agent safe exploration to our multi-agent setting and propose SafeMac for safe coverage and exploration. We analyze SafeMac and give first of its kind results: near optimal coverage in finite time while provably guaranteeing safety. We extensively evaluate our algorithms on synthetic and real problems, including a bio-diversity monitoring task under safety constraints, where SafeMac outperforms competing methods.",
        "published": "2022-10-12T16:33:34Z",
        "link": "http://arxiv.org/abs/2210.06380v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "cs.RO",
            "math.OC"
        ]
    },
    {
        "title": "Multi-agent Dynamic Algorithm Configuration",
        "authors": [
            "Ke Xue",
            "Jiacheng Xu",
            "Lei Yuan",
            "Miqing Li",
            "Chao Qian",
            "Zongzhang Zhang",
            "Yang Yu"
        ],
        "summary": "Automated algorithm configuration relieves users from tedious, trial-and-error tuning tasks. A popular algorithm configuration tuning paradigm is dynamic algorithm configuration (DAC), in which an agent learns dynamic configuration policies across instances by reinforcement learning (RL). However, in many complex algorithms, there may exist different types of configuration hyperparameters, and such heterogeneity may bring difficulties for classic DAC which uses a single-agent RL policy. In this paper, we aim to address this issue and propose multi-agent DAC (MA-DAC), with one agent working for one type of configuration hyperparameter. MA-DAC formulates the dynamic configuration of a complex algorithm with multiple types of hyperparameters as a contextual multi-agent Markov decision process and solves it by a cooperative multi-agent RL (MARL) algorithm. To instantiate, we apply MA-DAC to a well-known optimization algorithm for multi-objective optimization problems. Experimental results show the effectiveness of MA-DAC in not only achieving superior performance compared with other configuration tuning approaches based on heuristic rules, multi-armed bandits, and single-agent RL, but also being capable of generalizing to different problem classes. Furthermore, we release the environments in this paper as a benchmark for testing MARL algorithms, with the hope of facilitating the application of MARL.",
        "published": "2022-10-13T08:39:32Z",
        "link": "http://arxiv.org/abs/2210.06835v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "cs.NE"
        ]
    },
    {
        "title": "Agent-Based Modelling for Urban Analytics: State of the Art and   Challenges",
        "authors": [
            "Nick Malleson",
            "Mark Birkin",
            "Daniel Birks",
            "Jiaqi Ge",
            "Alison Heppenstall",
            "Ed Manley",
            "Josie McCulloch",
            "Patricia Ternes"
        ],
        "summary": "Agent-based modelling (ABM) is a facet of wider Multi-Agent Systems (MAS) research that explores the collective behaviour of individual `agents', and the implications that their behaviour and interactions have for wider systemic behaviour. The method has been shown to hold considerable value in exploring and understanding human societies, but is still largely confined to use in academia. This is particularly evident in the field of Urban Analytics; one that is characterised by the use of new forms of data in combination with computational approaches to gain insight into urban processes. In Urban Analytics, ABM is gaining popularity as a valuable method for understanding the low-level interactions that ultimately drive cities, but as yet is rarely used by stakeholders (planners, governments, etc.) to address real policy problems. This paper presents the state-of-the-art in the application of ABM at the interface of MAS and Urban Analytics by a group of ABM researchers who are affiliated with the Urban Analytics programme of the Alan Turing Institute in London (UK). It addresses issues around modelling behaviour, the use of new forms of data, the calibration of models under high uncertainty, real-time modelling, the use of AI techniques, large-scale models, and the implications for modelling policy. The discussion also contextualises current research in wider debates around Data Science, Artificial Intelligence, and MAS more broadly.",
        "published": "2022-10-13T12:29:16Z",
        "link": "http://arxiv.org/abs/2210.06955v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Simulating Ride-Pooling Services with Pre-Booking and On-Demand   Customers",
        "authors": [
            "Roman Engelhardt",
            "Florian Dandl",
            "Klaus Bogenberger"
        ],
        "summary": "If private vehicle trips can be replaced, ride-pooling services can decrease parking space needed by higher vehicle utilization and increase traffic efficiency by increasing vehicle occupancy. Nevertheless, substantial benefits can only be achieved if a certain market penetration is passed to find enough shareable rides for pooling to take place. Additionally, because of their highly dynamic and stochastic nature on-demand ride-pooling services cannot always guarantee that a request is served. Allowing customers to pre-book their trip in advance could provide benefits for both aspects. Additional knowledge helps an operator to better plan vehicle schedules to improve service efficiency while an accepted trip or a rejection can be communicated early on to the customer. This study presents a simulation framework where a ride-pooling provider offers a service in mixed operation: Customers can either use the service on-demand or pre-book trips. A graph-based batch optimization formulation is proposed to create offline schedules for pre-booking customers. Using two rolling horizons, this offline solution is forwarded to an online optimization for on-demand and pre-booking customers simultaneously. The framework is tested in a case study for Manhattan, NYC. That the graph-based batch optimization is superior to a basic insertion method in terms of solution quality and run-time. Due to additional knowledge, the ride-pooling operator can improve the solution quality significantly by serving more customers while pooling efficiency can be increased. Additionally, customers have shorter waiting and detour times the more customers book a trip in advance.",
        "published": "2022-10-13T12:48:26Z",
        "link": "http://arxiv.org/abs/2210.06972v1",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Scalable Multi-robot Motion Planning for Congested Environments With   Topological Guidance",
        "authors": [
            "Courtney McBeth",
            "James Motes",
            "Diane Uwacu",
            "Marco Morales",
            "Nancy M. Amato"
        ],
        "summary": "Multi-robot motion planning (MRMP) is the problem of finding collision-free paths for a set of robots in a continuous state space. The difficulty of MRMP increases with the number of robots and is exacerbated in environments with narrow passages that robots must pass through, like warehouse aisles where coordination between robots is required. In single-robot settings, topology-guided motion planning methods have shown improved performance in these constricted environments. In this work, we extend an existing topology-guided single-robot motion planning method to the multi-robot domain to leverage the improved efficiency provided by topological guidance. We demonstrate our method's ability to efficiently plan paths in complex environments with many narrow passages, scaling to robot teams of size up to 25 times larger than existing methods in this class of problems. By leveraging knowledge of the topology of the environment, we also find higher-quality solutions than other methods.",
        "published": "2022-10-13T16:26:01Z",
        "link": "http://arxiv.org/abs/2210.07141v2",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Towards Multi-Agent Reinforcement Learning driven Over-The-Counter   Market Simulations",
        "authors": [
            "Nelson Vadori",
            "Leo Ardon",
            "Sumitra Ganesh",
            "Thomas Spooner",
            "Selim Amrouni",
            "Jared Vann",
            "Mengda Xu",
            "Zeyu Zheng",
            "Tucker Balch",
            "Manuela Veloso"
        ],
        "summary": "We study a game between liquidity provider and liquidity taker agents interacting in an over-the-counter market, for which the typical example is foreign exchange. We show how a suitable design of parameterized families of reward functions coupled with shared policy learning constitutes an efficient solution to this problem. By playing against each other, our deep-reinforcement-learning-driven agents learn emergent behaviors relative to a wide spectrum of objectives encompassing profit-and-loss, optimal execution and market share. In particular, we find that liquidity providers naturally learn to balance hedging and skewing, where skewing refers to setting their buy and sell prices asymmetrically as a function of their inventory. We further introduce a novel RL-based calibration algorithm which we found performed well at imposing constraints on the game equilibrium. On the theoretical side, we are able to show convergence rates for our multi-agent policy gradient algorithm under a transitivity assumption, closely related to generalized ordinal potential games.",
        "published": "2022-10-13T17:06:08Z",
        "link": "http://arxiv.org/abs/2210.07184v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.GT",
            "q-fin.CP"
        ]
    },
    {
        "title": "Distributed Computation for the Non-metric Data Placement Problem using   Glauber Dynamics and Auctions",
        "authors": [
            "S. Rasoul Etesami"
        ],
        "summary": "We consider the non-metric data placement problem and develop distributed algorithms for computing or approximating its optimal integral solution. We first show that the non-metric data placement problem is inapproximable up to a logarithmic factor. We then provide a game-theoretic decomposition of the objective function and show that natural Glauber dynamics in which players update their resources with probability proportional to the utility they receive from caching those resources will converge to an optimal global solution for a sufficiently large noise parameter. In particular, we establish the polynomial mixing time of the Glauber dynamics for a certain range of noise parameters. Finally, we provide another auction-based distributed algorithm, which allows us to approximate the optimal global solution with a performance guarantee that depends on the ratio of the revenue vs. social welfare obtained from the underlying auction. Our results provide the first distributed computation algorithms for the non-metric data placement problem.",
        "published": "2022-10-14T02:20:37Z",
        "link": "http://arxiv.org/abs/2210.07461v1",
        "categories": [
            "cs.GT",
            "cs.DC",
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "math.OC"
        ]
    },
    {
        "title": "Distributional Reward Estimation for Effective Multi-Agent Deep   Reinforcement Learning",
        "authors": [
            "Jifeng Hu",
            "Yanchao Sun",
            "Hechang Chen",
            "Sili Huang",
            "haiyin piao",
            "Yi Chang",
            "Lichao Sun"
        ],
        "summary": "Multi-agent reinforcement learning has drawn increasing attention in practice, e.g., robotics and automatic driving, as it can explore optimal policies using samples generated by interacting with the environment. However, high reward uncertainty still remains a problem when we want to train a satisfactory model, because obtaining high-quality reward feedback is usually expensive and even infeasible. To handle this issue, previous methods mainly focus on passive reward correction. At the same time, recent active reward estimation methods have proven to be a recipe for reducing the effect of reward uncertainty. In this paper, we propose a novel Distributional Reward Estimation framework for effective Multi-Agent Reinforcement Learning (DRE-MARL). Our main idea is to design the multi-action-branch reward estimation and policy-weighted reward aggregation for stabilized training. Specifically, we design the multi-action-branch reward estimation to model reward distributions on all action branches. Then we utilize reward aggregation to obtain stable updating signals during training. Our intuition is that consideration of all possible consequences of actions could be useful for learning policies. The superiority of the DRE-MARL is demonstrated using benchmark multi-agent scenarios, compared with the SOTA baselines in terms of both effectiveness and robustness.",
        "published": "2022-10-14T08:31:45Z",
        "link": "http://arxiv.org/abs/2210.07636v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "A situated agent-based model to reveal irrigators' options behind their   actions under institutional arrangements in Southern France",
        "authors": [
            "Bastien Richard",
            "Bruno Bonté",
            "Olivier Barreteau",
            "Isabelle Braud"
        ],
        "summary": "There has been little exploration of the explicit simulation of the set of options of actors in agent-based models and its evolution over time. This study proposes to use affordances as intermediate entities between agents' environment and agent actions. We illustrated the approach on a typical gravity-fed network in the South-East of France to explore how the abandonment of traditional sharing of water changes the irrigators' options to irrigate. We simulated a typical dry year irrigation season under two institutional arrangements (i.e. traditional coordination through daily slots and its abandonment). Simulation results are consistent with field surveys, and reveal an increase in the number of internal conflicts among irrigators as the counterpart of the abandonment of traditional sharing of water. They also highlight the consequences of the heterogeneity of the irrigators' interests within the collective institution. The sensitivity analysis of the model allowed identification of optimal modalities of coordination, and a potential compromise between past and current institutional arrangements. The key benefits of using affordances in ABM lie in the study of their population dynamics for characterizing the interaction situations between actors and their environment and for better understanding the model dynamics.",
        "published": "2022-10-14T08:59:54Z",
        "link": "http://arxiv.org/abs/2211.13115v1",
        "categories": [
            "physics.soc-ph",
            "cs.MA"
        ]
    },
    {
        "title": "Decentralized Policy Gradient for Nash Equilibria Learning of   General-sum Stochastic Games",
        "authors": [
            "Yan Chen",
            "Tao Li"
        ],
        "summary": "We study Nash equilibria learning of a general-sum stochastic game with an unknown transition probability density function. Agents take actions at the current environment state and their joint action influences the transition of the environment state and their immediate rewards. Each agent only observes the environment state and its own immediate reward and is unknown about the actions or immediate rewards of others. We introduce the concepts of weighted asymptotic Nash equilibrium with probability 1 and in probability. For the case with exact pseudo gradients, we design a two-loop algorithm by the equivalence of Nash equilibrium and variational inequality problems. In the outer loop, we sequentially update a constructed strongly monotone variational inequality by updating a proximal parameter while employing a single-call extra-gradient algorithm in the inner loop for solving the constructed variational inequality. We show that if the associated Minty variational inequality has a solution, then the designed algorithm converges to the k^{1/2}-weighted asymptotic Nash equilibrium. Further, for the case with unknown pseudo gradients, we propose a decentralized algorithm, where the G(PO)MDP gradient estimator of the pseudo gradient is provided by Monte-Carlo simulations. The convergence to the k^{1/4} -weighted asymptotic Nash equilibrium in probability is achieved.",
        "published": "2022-10-14T09:09:56Z",
        "link": "http://arxiv.org/abs/2210.07651v2",
        "categories": [
            "eess.SY",
            "cs.AI",
            "cs.GT",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "A Non-iterative Spatio-temporal Multi-task Assignments based   Collision-free Trajectories for Music Playing Robots",
        "authors": [
            "Shridhar Velhal",
            "Krishna Kishore VS",
            "Suresh Sundaram"
        ],
        "summary": "In this paper, a non-iterative spatio-temporal multi-task assignment approach is used for playing piano music by a team of robots. This paper considers the piano playing problem, in which an algorithm needs to compute the trajectories for a dynamically sized team of robots who will play the musical notes by traveling through the specific locations associated with musical notes at their respective specific times. A two-step dynamic resource allocation based on a spatio-temporal multi-task assignment problem (DREAM), has been implemented to assign robots for playing the musical tune. The algorithm computes the required number of robots to play the music in the first step. In the second step, optimal assignments are computed for the updated team of robots, which minimizes the total distance traveled by the team. Even for the individual feasible trajectories, the multi-robot execution may fail if robots encounter a collision. As some time will be utilized for this conflict resolution, robots may not be able to reach the desired location on time. This paper analyses and proves that, if robots are operating in a convex region, the solution of the DREAM approach provides collision-free trajectories. The working of the DREAM approach has been illustrated with the help of the high fidelity simulations in Gazebo operated using ROS2. The result clearly shows that the DREAM approach computes the required number of robots and assigns multiple tasks to robots in at most two steps. The simulation of the robots playing music, using computed assignments, is demonstrated in the attached video. video link: \\url{https://youtu.be/XToicNm-CO8}",
        "published": "2022-10-14T09:12:38Z",
        "link": "http://arxiv.org/abs/2210.07653v2",
        "categories": [
            "cs.RO",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Differentiable Hybrid Traffic Simulation",
        "authors": [
            "Sanghyun Son",
            "Yi-Ling Qiao",
            "Jason Sewall",
            "Ming C. Lin"
        ],
        "summary": "We introduce a novel differentiable hybrid traffic simulator, which simulates traffic using a hybrid model of both macroscopic and microscopic models and can be directly integrated into a neural network for traffic control and flow optimization. This is the first differentiable traffic simulator for macroscopic and hybrid models that can compute gradients for traffic states across time steps and inhomogeneous lanes. To compute the gradient flow between two types of traffic models in a hybrid framework, we present a novel intermediate conversion component that bridges the lanes in a differentiable manner as well. We also show that we can use analytical gradients to accelerate the overall process and enhance scalability. Thanks to these gradients, our simulator can provide more efficient and scalable solutions for complex learning and control problems posed in traffic engineering than other existing algorithms. Refer to https://sites.google.com/umd.edu/diff-hybrid-traffic-sim for our project.",
        "published": "2022-10-14T18:20:15Z",
        "link": "http://arxiv.org/abs/2210.08046v1",
        "categories": [
            "cs.GR",
            "cs.LG",
            "cs.MA",
            "I.6.1; I.6.3"
        ]
    },
    {
        "title": "On the Computation of Distributed Knowledge as the Greatest Lower Bound   of Knowledge",
        "authors": [
            "Santiago Quintero",
            "Carlos Pinzón",
            "Sergio Ramírez",
            "Frank Valencia"
        ],
        "summary": "Let $L$ be a finite lattice and $\\mathcal{E}(L)$ be the set of join endomorphisms of $L$. We consider the problem of given $L$ and $f,g \\in \\mathcal{E}(L)$, finding the greatest lower bound $f \\sqcap_{{\\scriptsize \\mathcal{E}(L)}} g$ in the lattice $\\mathcal{E}(L)$. (1) We show that if $L$ is distributive, the problem can be solved in time $O(n)$ where $n=| L |$. The previous upper bound was $O(n^2)$. (2) We provide new algorithms for arbitrary lattices and give experimental evidence that they are significantly faster than the existing algorithm. (3) We characterize the standard notion of distributed knowledge of a group as the greatest lower bound of the join-endomorphisms representing the knowledge of each member of the group. (4) We show that deciding whether an agent has the distributed knowledge of two other agents can be computed in time $O(n^2)$ where $n$ is the size of the underlying set of states. (5) For the special case of $S5$ knowledge, we show that it can be decided in time $O(n\\alpha_{n})$ where $\\alpha_{n}$ is the inverse of the Ackermann function.",
        "published": "2022-10-14T21:54:15Z",
        "link": "http://arxiv.org/abs/2210.08128v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "SOCIALMAPF: Optimal and Efficient Multi-Agent Path Finding with   Strategic Agents for Social Navigation",
        "authors": [
            "Rohan Chandra",
            "Rahul Maligi",
            "Arya Anantula",
            "Joydeep Biswas"
        ],
        "summary": "We propose an extension to the MAPF formulation, called SocialMAPF, to account for private incentives of agents in constrained environments such as doorways, narrow hallways, and corridor intersections. SocialMAPF is able to, for instance, accurately reason about the urgent incentive of an agent rushing to the hospital over another agent's less urgent incentive of going to a grocery store; MAPF ignores such agent-specific incentives. Our proposed formulation addresses the open problem of optimal and efficient path planning for agents with private incentives. To solve SocialMAPF, we propose a new class of algorithms that use mechanism design during conflict resolution to simultaneously optimize agents' private local utilities and the global system objective. We perform an extensive array of experiments that show that optimal search-based MAPF techniques lead to collisions and increased time-to-goal in SocialMAPF compared to our proposed method using mechanism design. Furthermore, we empirically demonstrate that mechanism design results in models that maximizes agent utility and minimizes the overall time-to-goal of the entire system. We further showcase the capabilities of mechanism design-based planning by successfully deploying it in environments with static obstacles. To conclude, we briefly list several research directions using the SocialMAPF formulation, such as exploring motion planning in the continuous domain for agents with private incentives.",
        "published": "2022-10-15T22:49:26Z",
        "link": "http://arxiv.org/abs/2210.08390v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.GT",
            "cs.RO"
        ]
    },
    {
        "title": "Limited or Biased: Modeling Sub-Rational Human Investors in Financial   Markets",
        "authors": [
            "Penghang Liu",
            "Kshama Dwarakanath",
            "Svitlana S Vyetrenko",
            "Tucker Balch"
        ],
        "summary": "Human decision-making in real-life deviates significantly from the optimal decisions made by fully rational agents, primarily due to computational limitations or psychological biases. While existing studies in behavioral finance have discovered various aspects of human sub-rationality, there lacks a comprehensive framework to transfer these findings into an adaptive human model applicable across diverse financial market scenarios. In this study, we introduce a flexible model that incorporates five different aspects of human sub-rationality using reinforcement learning. Our model is trained using a high-fidelity multi-agent market simulator, which overcomes limitations associated with the scarcity of labeled data of individual investors. We evaluate the behavior of sub-rational human investors using hand-crafted market scenarios and SHAP value analysis, showing that our model accurately reproduces the observations in the previous studies and reveals insights of the driving factors of human behavior. Finally, we explore the impact of sub-rationality on the investor's Profit and Loss (PnL) and market quality. Our experiments reveal that bounded-rational and prospect-biased human behaviors improve liquidity but diminish price efficiency, whereas human behavior influenced by myopia, optimism, and pessimism reduces market liquidity.",
        "published": "2022-10-16T15:50:26Z",
        "link": "http://arxiv.org/abs/2210.08569v2",
        "categories": [
            "cs.AI",
            "cs.MA",
            "q-fin.TR"
        ]
    },
    {
        "title": "Decision-Making Among Bounded Rational Agents",
        "authors": [
            "Junhong Xu",
            "Durgakant Pushp",
            "Kai Yin",
            "Lantao Liu"
        ],
        "summary": "When robots share the same workspace with other intelligent agents (e.g., other robots or humans), they must be able to reason about the behaviors of their neighboring agents while accomplishing the designated tasks. In practice, frequently, agents do not exhibit absolutely rational behavior due to their limited computational resources. Thus, predicting the optimal agent behaviors is undesirable (because it demands prohibitive computational resources) and undesirable (because the prediction may be wrong). Motivated by this observation, we remove the assumption of perfectly rational agents and propose incorporating the concept of bounded rationality from an information-theoretic view into the game-theoretic framework. This allows the robots to reason other agents' sub-optimal behaviors and act accordingly under their computational constraints. Specifically, bounded rationality directly models the agent's information processing ability, which is represented as the KL-divergence between nominal and optimized stochastic policies, and the solution to the bounded-optimal policy can be obtained by an efficient importance sampling approach. Using both simulated and real-world experiments in multi-robot navigation tasks, we demonstrate that the resulting framework allows the robots to reason about different levels of rational behaviors of other agents and compute a reasonable strategy under its computational constraint.",
        "published": "2022-10-17T00:29:24Z",
        "link": "http://arxiv.org/abs/2210.08672v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Rethinking Trajectory Prediction via \"Team Game\"",
        "authors": [
            "Zikai Wei",
            "Xinge Zhu",
            "Bo Dai",
            "Dahua Lin"
        ],
        "summary": "To accurately predict trajectories in multi-agent settings, e.g. team games, it is important to effectively model the interactions among agents. Whereas a number of methods have been developed for this purpose, existing methods implicitly model these interactions as part of the deep net architecture. However, in the real world, interactions often exist at multiple levels, e.g. individuals may form groups, where interactions among groups and those among the individuals in the same group often follow significantly different patterns. In this paper, we present a novel formulation for multi-agent trajectory prediction, which explicitly introduces the concept of interactive group consensus via an interactive hierarchical latent space. This formulation allows group-level and individual-level interactions to be captured jointly, thus substantially improving the capability of modeling complex dynamics. On two multi-agent settings, i.e. team sports and pedestrians, the proposed framework consistently achieves superior performance compared to existing methods.",
        "published": "2022-10-17T07:16:44Z",
        "link": "http://arxiv.org/abs/2210.08793v1",
        "categories": [
            "cs.CV",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "PTDE: Personalized Training with Distilled Execution for Multi-Agent   Reinforcement Learning",
        "authors": [
            "Yiqun Chen",
            "Hangyu Mao",
            "Jiaxin Mao",
            "Shiguang Wu",
            "Tianle Zhang",
            "Bin Zhang",
            "Wei Yang",
            "Hongxing Chang"
        ],
        "summary": "Centralized Training with Decentralized Execution (CTDE) has emerged as a widely adopted paradigm in multi-agent reinforcement learning, emphasizing the utilization of global information for learning an enhanced joint $Q$-function or centralized critic. In contrast, our investigation delves into harnessing global information to directly enhance individual $Q$-functions or individual actors. Notably, we discover that applying identical global information universally across all agents proves insufficient for optimal performance. Consequently, we advocate for the customization of global information tailored to each agent, creating agent-personalized global information to bolster overall performance. Furthermore, we introduce a novel paradigm named Personalized Training with Distilled Execution (PTDE), wherein agent-personalized global information is distilled into the agent's local information. This distilled information is then utilized during decentralized execution, resulting in minimal performance degradation. PTDE can be seamlessly integrated with state-of-the-art algorithms, leading to notable performance enhancements across diverse benchmarks, including the SMAC benchmark, Google Research Football (GRF) benchmark, and Learning to Rank (LTR) task.",
        "published": "2022-10-17T09:08:13Z",
        "link": "http://arxiv.org/abs/2210.08872v2",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Turbocharging Solution Concepts: Solving NEs, CEs and CCEs with Neural   Equilibrium Solvers",
        "authors": [
            "Luke Marris",
            "Ian Gemp",
            "Thomas Anthony",
            "Andrea Tacchetti",
            "Siqi Liu",
            "Karl Tuyls"
        ],
        "summary": "Solution concepts such as Nash Equilibria, Correlated Equilibria, and Coarse Correlated Equilibria are useful components for many multiagent machine learning algorithms. Unfortunately, solving a normal-form game could take prohibitive or non-deterministic time to converge, and could fail. We introduce the Neural Equilibrium Solver which utilizes a special equivariant neural network architecture to approximately solve the space of all games of fixed shape, buying speed and determinism. We define a flexible equilibrium selection framework, that is capable of uniquely selecting an equilibrium that minimizes relative entropy, or maximizes welfare. The network is trained without needing to generate any supervised training data. We show remarkable zero-shot generalization to larger games. We argue that such a network is a powerful component for many possible multiagent algorithms.",
        "published": "2022-10-17T17:00:31Z",
        "link": "http://arxiv.org/abs/2210.09257v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Learning Control Admissibility Models with Graph Neural Networks for   Multi-Agent Navigation",
        "authors": [
            "Chenning Yu",
            "Hongzhan Yu",
            "Sicun Gao"
        ],
        "summary": "Deep reinforcement learning in continuous domains focuses on learning control policies that map states to distributions over actions that ideally concentrate on the optimal choices in each step. In multi-agent navigation problems, the optimal actions depend heavily on the agents' density. Their interaction patterns grow exponentially with respect to such density, making it hard for learning-based methods to generalize. We propose to switch the learning objectives from predicting the optimal actions to predicting sets of admissible actions, which we call control admissibility models (CAMs), such that they can be easily composed and used for online inference for an arbitrary number of agents. We design CAMs using graph neural networks and develop training methods that optimize the CAMs in the standard model-free setting, with the additional benefit of eliminating the need for reward engineering typically required to balance collision avoidance and goal-reaching requirements. We evaluate the proposed approach in multi-agent navigation environments. We show that the CAM models can be trained in environments with only a few agents and be easily composed for deployment in dense environments with hundreds of agents, achieving better performance than state-of-the-art methods.",
        "published": "2022-10-17T19:20:58Z",
        "link": "http://arxiv.org/abs/2210.09378v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "RPM: Generalizable Behaviors for Multi-Agent Reinforcement Learning",
        "authors": [
            "Wei Qiu",
            "Xiao Ma",
            "Bo An",
            "Svetlana Obraztsova",
            "Shuicheng Yan",
            "Zhongwen Xu"
        ],
        "summary": "Despite the recent advancement in multi-agent reinforcement learning (MARL), the MARL agents easily overfit the training environment and perform poorly in the evaluation scenarios where other agents behave differently. Obtaining generalizable policies for MARL agents is thus necessary but challenging mainly due to complex multi-agent interactions. In this work, we model the problem with Markov Games and propose a simple yet effective method, ranked policy memory (RPM), to collect diverse multi-agent trajectories for training MARL policies with good generalizability. The main idea of RPM is to maintain a look-up memory of policies. In particular, we try to acquire various levels of behaviors by saving policies via ranking the training episode return, i.e., the episode return of agents in the training environment; when an episode starts, the learning agent can then choose a policy from the RPM as the behavior policy. This innovative self-play training framework leverages agents' past policies and guarantees the diversity of multi-agent interaction in the training data. We implement RPM on top of MARL algorithms and conduct extensive experiments on Melting Pot. It has been demonstrated that RPM enables MARL agents to interact with unseen agents in multi-agent generalization evaluation scenarios and complete given tasks, and it significantly boosts the performance up to 402% on average.",
        "published": "2022-10-18T07:32:43Z",
        "link": "http://arxiv.org/abs/2210.09646v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Proximal Learning With Opponent-Learning Awareness",
        "authors": [
            "Stephen Zhao",
            "Chris Lu",
            "Roger Baker Grosse",
            "Jakob Nicolaus Foerster"
        ],
        "summary": "Learning With Opponent-Learning Awareness (LOLA) (Foerster et al. [2018a]) is a multi-agent reinforcement learning algorithm that typically learns reciprocity-based cooperation in partially competitive environments. However, LOLA often fails to learn such behaviour on more complex policy spaces parameterized by neural networks, partly because the update rule is sensitive to the policy parameterization. This problem is especially pronounced in the opponent modeling setting, where the opponent's policy is unknown and must be inferred from observations; in such settings, LOLA is ill-specified because behaviorally equivalent opponent policies can result in non-equivalent updates. To address this shortcoming, we reinterpret LOLA as approximating a proximal operator, and then derive a new algorithm, proximal LOLA (POLA), which uses the proximal formulation directly. Unlike LOLA, the POLA updates are parameterization invariant, in the sense that when the proximal objective has a unique optimum, behaviorally equivalent policies result in behaviorally equivalent updates. We then present practical approximations to the ideal POLA update, which we evaluate in several partially competitive environments with function approximation and opponent modeling. This empirically demonstrates that POLA achieves reciprocity-based cooperation more reliably than LOLA.",
        "published": "2022-10-18T19:54:17Z",
        "link": "http://arxiv.org/abs/2210.10125v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Verification of the Socio-Technical Aspects of Voting: The Case of the   Polish Postal Vote 2020",
        "authors": [
            "Wojciech Jamroga",
            "Peter Y. A. Ryan",
            "Yan Kim"
        ],
        "summary": "Voting procedures are designed and implemented by people, for people, and with significant human involvement. Thus, one should take into account the human factors in order to comprehensively analyze properties of an election and detect threats. In particular, it is essential to assess how actions and strategies of the involved agents (voters, municipal office employees, mail clerks) can influence the outcome of other agents' actions as well as the overall outcome of the election. In this paper, we present our first attempt to capture those aspects in a formal multi-agent model of the Polish presidential election 2020. The election marked the first time when postal vote was universally available in Poland. Unfortunately, the voting scheme was prepared under time pressure and political pressure, and without the involvement of experts. This might have opened up possibilities for various kinds of ballot fraud, in-house coercion, etc. We propose a preliminary scalable model of the procedure in the form of a Multi-Agent Graph, and formalize selected integrity and security properties by formulas of agent logics. Then, we transform the models and formulas so that they can be input to the state-of-art model checker Uppaal. The first series of experiments demonstrates that verification scales rather badly due to the state-space explosion. However, we show that a recently developed technique of user-friendly model reduction by variable abstraction allows us to verify more complex scenarios.",
        "published": "2022-10-19T16:15:53Z",
        "link": "http://arxiv.org/abs/2210.10694v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Oracles & Followers: Stackelberg Equilibria in Deep Multi-Agent   Reinforcement Learning",
        "authors": [
            "Matthias Gerstgrasser",
            "David C. Parkes"
        ],
        "summary": "Stackelberg equilibria arise naturally in a range of popular learning problems, such as in security games or indirect mechanism design, and have received increasing attention in the reinforcement learning literature. We present a general framework for implementing Stackelberg equilibria search as a multi-agent RL problem, allowing a wide range of algorithmic design choices. We discuss how previous approaches can be seen as specific instantiations of this framework. As a key insight, we note that the design space allows for approaches not previously seen in the literature, for instance by leveraging multitask and meta-RL techniques for follower convergence. We propose one such approach using contextual policies, and evaluate it experimentally on both standard and novel benchmark domains, showing greatly improved sample efficiency compared to previous approaches. Finally, we explore the effect of adopting algorithm designs outside the borders of our framework.",
        "published": "2022-10-19T23:04:16Z",
        "link": "http://arxiv.org/abs/2210.11942v4",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Shepherding Heterogeneous Flock with Model-Based Discrimination",
        "authors": [
            "Anna Fujioka",
            "Masaki Ogura",
            "Naoki Wakamiya"
        ],
        "summary": "The problem of guiding a flock of agents to a destination by the repulsion forces exerted by a smaller number of external agents is called the shepherding problem. This problem has attracted attention due to its potential applications, including diverting birds away for preventing airplane accidents, recovering spilled oil in the ocean, and guiding a swarm of robots for mapping. Although there have been various studies on the shepherding problem, most of them place the uniformity assumption on the dynamics of agents to be guided. However, we can find various practical situations where this assumption does not necessarily hold. In this paper, we propose a shepherding method for a flock of agents consisting of normal agents to be guided and other variant agents. In this method, the shepherd discriminates normal and variant agents based on their behaviors' deviation from the one predicted by the potentially inaccurate model of the normal agents. As for the discrimination process, we propose two methods using static and dynamic thresholds. Our simulation results show that the proposed methods outperform a conventional method for various types of variant agents.",
        "published": "2022-10-20T07:22:19Z",
        "link": "http://arxiv.org/abs/2210.11055v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Voter Coalitions and democracy in Decentralized Finance: Evidence from   MakerDAO",
        "authors": [
            "Xiaotong Sun",
            "Xi Chen",
            "Charalampos Stasinakis",
            "Georgios Sermpinis"
        ],
        "summary": "Decentralized Autonomous Organization (DAO) provides a decentralized governance solution through blockchain, where decision-making process relies on on-chain voting and follows majority rule. This paper focuses on MakerDAO, and we find three voter coalitions after applying clustering algorithm to voting history. The emergence of a dominant voter coalition is a signal of governance centralization in DAO, and voter coalitions have complicated influence on Maker protocol, which is governed by MakerDAO. This paper presents empirical evidence of multicoalition democracy in DAO and further contributes to the contemporary debate on whether decentralized governance is possible.",
        "published": "2022-10-20T12:27:41Z",
        "link": "http://arxiv.org/abs/2210.11203v4",
        "categories": [
            "cs.SI",
            "cs.MA",
            "q-fin.GN",
            "q-fin.TR"
        ]
    },
    {
        "title": "Explainable Multi-Agent Recommendation System for Energy-Efficient   Decision Support in Smart Homes",
        "authors": [
            "Alona Zharova",
            "Annika Boer",
            "Julia Knoblauch",
            "Kai Ingo Schewina",
            "Jana Vihs"
        ],
        "summary": "Understandable and persuasive recommendations support the electricity consumers' behavioral change to tackle the energy efficiency problem. Generating load shifting recommendations for household appliances as explainable increases the transparency and trustworthiness of the system. This paper proposes an explainable multi-agent recommendation system for load shifting for household appliances. First, we provide agents with enhanced predictive capacity by including weather data, applying state-of-the-art models, and tuning the hyperparameters. Second, we suggest an Explainability Agent providing transparent recommendations. We also provide an overview of the predictive and explainability performance. Third, we discuss the impact and scaling potential of the suggested approach.",
        "published": "2022-10-20T12:51:18Z",
        "link": "http://arxiv.org/abs/2210.11218v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "ADOPT: A system for Alerting Drivers to Occluded Pedestrian Traffic",
        "authors": [
            "Abrar Alali",
            "Stephan Olariu",
            "Shubham Jain"
        ],
        "summary": "Recent statistics reveal an alarming increase in accidents involving pedestrians (especially children) crossing the street. A common philosophy of existing pedestrian detection approaches is that this task should be undertaken by the moving cars themselves. In sharp departure from this philosophy, we propose to enlist the help of cars parked along the sidewalk to detect and protect crossing pedestrians. In support of this goal, we propose ADOPT: a system for Alerting Drivers to Occluded Pedestrian Traffic. ADOPT lays the theoretical foundations of a system that uses parked cars to: (1) detect the presence of a group of crossing pedestrians - a crossing cohort; (2) predict the time the last member of the cohort takes to clear the street; (3) send alert messages to those approaching cars that may reach the crossing area while pedestrians are still in the street; and, (4) show how approaching cars can adjust their speed, given several simultaneous crossing locations. Importantly, in ADOPT all communications occur over very short distances and at very low power. Our extensive simulations using SUMO-generated pedestrian and car traffic have shown the effectiveness of ADOPT in detecting and protecting crossing pedestrians.",
        "published": "2022-10-20T13:34:43Z",
        "link": "http://arxiv.org/abs/2212.00137v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Towards Evology: a Market Ecology Agent-Based Model of US Equity Mutual   Funds",
        "authors": [
            "Aymeric Vie",
            "Maarten Scholl",
            "Alissa M. Kleinnijenhuis",
            "J. Doyne Farmer"
        ],
        "summary": "The profitability of various investment styles in investment funds depends on macroeconomic conditions. Market ecology, which views financial markets as ecosystems of diverse, interacting and evolving trading strategies, has shown that endogenous interactions between strategies determine market behaviour and styles' performance. We present Evology: a heterogeneous, empirically calibrated multi-agent market ecology agent-based model to quantify endogenous interactions between US equity mutual funds, particularly Value and Growth investment styles. We outline the model design, validation and calibration approach and its potential for optimising investment strategies using machine learning algorithms.",
        "published": "2022-10-20T15:30:38Z",
        "link": "http://arxiv.org/abs/2210.11344v2",
        "categories": [
            "cs.MA",
            "cs.CE"
        ]
    },
    {
        "title": "Competing Bandits in Time Varying Matching Markets",
        "authors": [
            "Deepan Muthirayan",
            "Chinmay Maheshwari",
            "Pramod P. Khargonekar",
            "Shankar Sastry"
        ],
        "summary": "We study the problem of online learning in two-sided non-stationary matching markets, where the objective is to converge to a stable match. In particular, we consider the setting where one side of the market, the arms, has fixed known set of preferences over the other side, the players. While this problem has been studied when the players have fixed but unknown preferences, in this work we study the problem of how to learn when the preferences of the players are time varying and unknown. Our contribution is a methodology that can handle any type of preference structure and variation scenario. We show that, with the proposed algorithm, each player receives a uniform sub-linear regret of {$\\widetilde{\\mathcal{O}}(L^{1/2}_TT^{1/2})$} up to the number of changes in the underlying preferences of the agents, $L_T$. Therefore, we show that the optimal rates for single-agent learning can be achieved in spite of the competition up to a difference of a constant factor. We also discuss extensions of this algorithm to the case where the number of changes need not be known a priori.",
        "published": "2022-10-21T02:36:57Z",
        "link": "http://arxiv.org/abs/2210.11692v2",
        "categories": [
            "cs.LG",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "An agent-based approach to procedural city generation incorporating Land   Use and Transport Interaction models",
        "authors": [
            "Luiz Fernando Silva Eugênio dos Santos",
            "Claus Aranha",
            "André Ponce de Leon F de Carvalho"
        ],
        "summary": "We apply the knowledge of urban settings established with the study of Land Use and Transport Interaction (LUTI) models to develop reward functions for an agent-based system capable of planning realistic artificial cities. The system aims to replicate in the micro scale the main components of real settlements, such as zoning and accessibility in a road network. Moreover, we propose a novel representation for the agent's environment that efficiently combines the road graph with a discrete model for the land. Our system starts from an empty map consisting only of the road network graph, and the agent incrementally expands it by building new sites while distinguishing land uses between residential, commercial, industrial, and recreational.",
        "published": "2022-10-21T13:49:16Z",
        "link": "http://arxiv.org/abs/2211.01959v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Explainability in autonomous pedagogically structured scenarios",
        "authors": [
            "Minal Suresh Patil"
        ],
        "summary": "We present the notion of explainability for decision-making processes in a pedagogically structured autonomous environment. Multi-agent systems that are structured pedagogically consist of pedagogical teachers and learners that operate in environments in which both are sometimes not fully aware of all the states in the environment and beliefs of other agents thus making it challenging to explain their decisions and actions with one another. This work emphasises the need for robust and iterative explanation-based communication between the pedagogical teacher and the learner. Explaining the rationale behind multi-agent decisions in an interactive, partially observable environment is necessary to build trustworthy and reliable communication between pedagogical teachers and learners. Ongoing research is primarily focused on explanations of the agents' behaviour towards humans, and there is a lack of research on inter-agent explainability.",
        "published": "2022-10-21T17:50:51Z",
        "link": "http://arxiv.org/abs/2210.12140v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "DeGroot-based opinion formation under a global steering mechanism",
        "authors": [
            "Ivan Conjeaud",
            "Philipp Lorenz-Spreen",
            "Argyris Kalogeratos"
        ],
        "summary": "This paper investigates how interacting agents arrive to a consensus or a polarized state. We study the opinion formation process under the effect of a global steering mechanism (GSM), which aggregates the opinion-driven stochastic agent states at the network level and feeds back to them a form of global information. We also propose a new two-layer agent-based opinion formation model, called GSM-DeGroot, that captures the coupled dynamics between agent-to-agent local interactions and the GSM's steering effect. This way, agents are subject to the effects of a DeGroot-like local opinion propagation, as well as to a wide variety of possible aggregated information that can affect their opinions, such as trending news feeds, press coverage, polls, elections, etc. Contrary to the standard DeGroot model, our model allows polarization to emerge by letting agents react to the global information in a stubborn differential way. Moreover, the introduced stochastic agent states produce event stream dynamics that can fit to real event data. We explore numerically the model dynamics to find regimes of qualitatively different behavior. We also challenge our model by fitting it to the dynamics of real topics that attracted the public attention and were recorded on Twitter. Our experiments show that the proposed model holds explanatory power, as it evidently captures real opinion formation dynamics via a relatively small set of interpretable parameters.",
        "published": "2022-10-21T22:02:47Z",
        "link": "http://arxiv.org/abs/2210.12274v2",
        "categories": [
            "cs.SI",
            "cs.CY",
            "cs.MA",
            "68U35, 91Cxx, 90-10",
            "I.6; H.4; J.4; K.4.2"
        ]
    },
    {
        "title": "An Axiomatic Characterization of Split Cycle",
        "authors": [
            "Yifeng Ding",
            "Wesley H. Holliday",
            "Eric Pacuit"
        ],
        "summary": "A number of rules for resolving majority cycles in elections have been proposed in the literature. Recently, Holliday and Pacuit (Journal of Theoretical Politics 33 (2021) 475-524) axiomatically characterized the class of rules refined by one such cycle-resolving rule, dubbed Split Cycle: in each majority cycle, discard the majority preferences with the smallest majority margin. They showed that any rule satisfying five standard axioms plus a weakening of Arrow's Independence of Irrelevant Alternatives (IIA), called Coherent IIA, is refined by Split Cycle. In this paper, we go further and show that Split Cycle is the only rule satisfying the axioms of Holliday and Pacuit together with two additional axioms, which characterize the class of rules that refine Split Cycle: Coherent Defeat and Positive Involvement in Defeat. Coherent Defeat states that any majority preference not occurring in a cycle is retained, while Positive Involvement in Defeat is closely related to the well-known axiom of Positive Involvement (as in J. Perez, Social Choice and Welfare 18 (2001) 601-616). We characterize Split Cycle not only as a collective choice rule but also as a social choice correspondence, over both profiles of linear ballots and profiles of ballots allowing ties.",
        "published": "2022-10-22T17:21:15Z",
        "link": "http://arxiv.org/abs/2210.12503v3",
        "categories": [
            "econ.TH",
            "cs.GT",
            "cs.MA",
            "91B12, 91B14, 91B10",
            "I.2.11"
        ]
    },
    {
        "title": "Symmetric (Optimistic) Natural Policy Gradient for Multi-agent Learning   with Parameter Convergence",
        "authors": [
            "Sarath Pattathil",
            "Kaiqing Zhang",
            "Asuman Ozdaglar"
        ],
        "summary": "Multi-agent interactions are increasingly important in the context of reinforcement learning, and the theoretical foundations of policy gradient methods have attracted surging research interest. We investigate the global convergence of natural policy gradient (NPG) algorithms in multi-agent learning. We first show that vanilla NPG may not have parameter convergence, i.e., the convergence of the vector that parameterizes the policy, even when the costs are regularized (which enabled strong convergence guarantees in the policy space in the literature). This non-convergence of parameters leads to stability issues in learning, which becomes especially relevant in the function approximation setting, where we can only operate on low-dimensional parameters, instead of the high-dimensional policy. We then propose variants of the NPG algorithm, for several standard multi-agent learning scenarios: two-player zero-sum matrix and Markov games, and multi-player monotone games, with global last-iterate parameter convergence guarantees. We also generalize the results to certain function approximation settings. Note that in our algorithms, the agents take symmetric roles. Our results might also be of independent interest for solving nonconvex-nonconcave minimax optimization problems with certain structures. Simulations are also provided to corroborate our theoretical findings.",
        "published": "2022-10-23T18:27:04Z",
        "link": "http://arxiv.org/abs/2210.12812v2",
        "categories": [
            "math.OC",
            "cs.LG",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "A Cooperative Reinforcement Learning Environment for Detecting and   Penalizing Betrayal",
        "authors": [
            "Nikiforos Pittaras"
        ],
        "summary": "In this paper we present a Reinforcement Learning environment that leverages agent cooperation and communication, aimed at detection, learning and ultimately penalizing betrayal patterns that emerge in the behavior of self-interested agents. We provide a description of game rules, along with interesting cases of betrayal and trade-offs that arise. Preliminary experimental investigations illustrate a) betrayal emergence, b) deceptive agents outperforming honest baselines and b) betrayal detection based on classification of behavioral features, which surpasses probabilistic detection baselines. Finally, we propose approaches for penalizing betrayal, list directions for future work and suggest interesting extensions of the environment towards capturing and exploring increasingly complex patterns of social interactions.",
        "published": "2022-10-23T20:08:47Z",
        "link": "http://arxiv.org/abs/2210.12841v1",
        "categories": [
            "cs.LG",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Multi-Agent Path Finding via Tree LSTM",
        "authors": [
            "Yuhao Jiang",
            "Kunjie Zhang",
            "Qimai Li",
            "Jiaxin Chen",
            "Xiaolong Zhu"
        ],
        "summary": "In recent years, Multi-Agent Path Finding (MAPF) has attracted attention from the fields of both Operations Research (OR) and Reinforcement Learning (RL). However, in the 2021 Flatland3 Challenge, a competition on MAPF, the best RL method scored only 27.9, far less than the best OR method. This paper proposes a new RL solution to Flatland3 Challenge, which scores 125.3, several times higher than the best RL solution before. We creatively apply a novel network architecture, TreeLSTM, to MAPF in our solution. Together with several other RL techniques, including reward shaping, multiple-phase training, and centralized control, our solution is comparable to the top 2-3 OR methods.",
        "published": "2022-10-24T03:22:20Z",
        "link": "http://arxiv.org/abs/2210.12933v2",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "An Opponent-Aware Reinforcement Learning Method for Team-to-Team   Multi-Vehicle Pursuit via Maximizing Mutual Information Indicator",
        "authors": [
            "Qinwen Wang",
            "Xinhang Li",
            "Zheng Yuan",
            "Yiying Yang",
            "Chen Xu",
            "Lin Zhang"
        ],
        "summary": "The pursuit-evasion game in Smart City brings a profound impact on the Multi-vehicle Pursuit (MVP) problem, when police cars cooperatively pursue suspected vehicles. Existing studies on the MVP problems tend to set evading vehicles to move randomly or in a fixed prescribed route. The opponent modeling method has proven considerable promise in tackling the non-stationary caused by the adversary agent. However, most of them focus on two-player competitive games and easy scenarios without the interference of environments. This paper considers a Team-to-Team Multi-vehicle Pursuit (T2TMVP) problem in the complicated urban traffic scene where the evading vehicles adopt the pre-trained dynamic strategies to execute decisions intelligently. To solve this problem, we propose an opponent-aware reinforcement learning via maximizing mutual information indicator (OARLM2I2) method to improve pursuit efficiency in the complicated environment. First, a sequential encoding-based opponents joint strategy modeling (SEOJSM) mechanism is proposed to generate evading vehicles' joint strategy model, which assists the multi-agent decision-making process based on deep Q-network (DQN). Then, we design a mutual information-united loss, simultaneously considering the reward fed back from the environment and the effectiveness of opponents' joint strategy model, to update pursuing vehicles' decision-making process. Extensive experiments based on SUMO demonstrate our method outperforms other baselines by 21.48% on average in reducing pursuit time. The code is available at \\url{https://github.com/ANT-ITS/OARLM2I2}.",
        "published": "2022-10-24T08:04:16Z",
        "link": "http://arxiv.org/abs/2210.13015v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "An agent-based epidemics simulation to compare and explain screening and   vaccination prioritisation strategies",
        "authors": [
            "Carole Adam",
            "Helene Arduin"
        ],
        "summary": "This paper describes an agent-based model of epidemics dynamics. This model is willingly simplified, as its goal is not to predict the evolution of the epidemics, but to explain the underlying mechanisms in an interactive way. This model allows to compare screening prioritisation strategies, as well as vaccination priority strategies, on a virtual population. The model is implemented in Netlogo in different simulators, published online to let people experiment with them. This paper reports on the model design, implementation, and experimentations. In particular we have compared screening strategies to evaluate the epidemics vs control it by quarantining infectious people; and we have compared vaccinating older people with more risk factors, vs younger people with more social contacts.",
        "published": "2022-10-24T10:15:07Z",
        "link": "http://arxiv.org/abs/2210.13089v1",
        "categories": [
            "cs.MA",
            "cs.CY"
        ]
    },
    {
        "title": "Interactive inference: a multi-agent model of cooperative joint actions",
        "authors": [
            "Domenico Maisto",
            "Francesco Donnarumma",
            "Giovanni Pezzulo"
        ],
        "summary": "We advance a novel computational model of multi-agent, cooperative joint actions that is grounded in the cognitive framework of active inference. The model assumes that to solve a joint task, such as pressing together a red or blue button, two (or more) agents engage in a process of interactive inference. Each agent maintains probabilistic beliefs about the goal of the joint task (e.g., should we press the red or blue button?) and updates them by observing the other agent's movements, while in turn selecting movements that make his own intentions legible and easy to infer by the other agent (i.e., sensorimotor communication). Over time, the interactive inference aligns both the beliefs and the behavioral strategies of the agents, hence ensuring the success of the joint action. We exemplify the functioning of the model in two simulations. The first simulation illustrates a ''leaderless'' joint action. It shows that when two agents lack a strong preference about their joint task goal, they jointly infer it by observing each other's movements. In turn, this helps the interactive alignment of their beliefs and behavioral strategies. The second simulation illustrates a \"leader-follower\" joint action. It shows that when one agent (\"leader\") knows the true joint goal, it uses sensorimotor communication to help the other agent (\"follower\") infer it, even if doing this requires selecting a more costly individual plan. These simulations illustrate that interactive inference supports successful multi-agent joint actions and reproduces key cognitive and behavioral dynamics of \"leaderless\" and \"leader-follower\" joint actions observed in human-human experiments. In sum, interactive inference provides a cognitively inspired, formal framework to realize cooperative joint actions and consensus in multi-agent systems.",
        "published": "2022-10-24T11:01:29Z",
        "link": "http://arxiv.org/abs/2210.13113v2",
        "categories": [
            "cs.AI",
            "cs.IT",
            "cs.MA",
            "math.IT",
            "q-bio.NC",
            "93A16",
            "I.2.11"
        ]
    },
    {
        "title": "Offline congestion games: How feedback type affects data coverage   requirement",
        "authors": [
            "Haozhe Jiang",
            "Qiwen Cui",
            "Zhihan Xiong",
            "Maryam Fazel",
            "Simon S. Du"
        ],
        "summary": "This paper investigates when one can efficiently recover an approximate Nash Equilibrium (NE) in offline congestion games. The existing dataset coverage assumption in offline general-sum games inevitably incurs a dependency on the number of actions, which can be exponentially large in congestion games. We consider three different types of feedback with decreasing revealed information. Starting from the facility-level (a.k.a., semi-bandit) feedback, we propose a novel one-unit deviation coverage condition and give a pessimism-type algorithm that can recover an approximate NE. For the agent-level (a.k.a., bandit) feedback setting, interestingly, we show the one-unit deviation coverage condition is not sufficient. On the other hand, we convert the game to multi-agent linear bandits and show that with a generalized data coverage assumption in offline linear bandits, we can efficiently recover the approximate NE. Lastly, we consider a novel type of feedback, the game-level feedback where only the total reward from all agents is revealed. Again, we show the coverage assumption for the agent-level feedback setting is insufficient in the game-level feedback setting, and with a stronger version of the data coverage assumption for linear bandits, we can recover an approximate NE. Together, our results constitute the first study of offline congestion games and imply formal separations between different types of feedback.",
        "published": "2022-10-24T16:49:16Z",
        "link": "http://arxiv.org/abs/2210.13396v2",
        "categories": [
            "cs.GT",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Networked Signal and Information Processing",
        "authors": [
            "Stefan Vlaski",
            "Soummya Kar",
            "Ali H. Sayed",
            "José M. F. Moura"
        ],
        "summary": "The article reviews significant advances in networked signal and information processing, which have enabled in the last 25 years extending decision making and inference, optimization, control, and learning to the increasingly ubiquitous environments of distributed agents. As these interacting agents cooperate, new collective behaviors emerge from local decisions and actions. Moreover, and significantly, theory and applications show that networked agents, through cooperation and sharing, are able to match the performance of cloud or federated solutions, while offering the potential for improved privacy, increasing resilience, and saving resources.",
        "published": "2022-10-25T04:57:34Z",
        "link": "http://arxiv.org/abs/2210.13767v2",
        "categories": [
            "eess.SP",
            "cs.DC",
            "cs.LG",
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "Entity Divider with Language Grounding in Multi-Agent Reinforcement   Learning",
        "authors": [
            "Ziluo Ding",
            "Wanpeng Zhang",
            "Junpeng Yue",
            "Xiangjun Wang",
            "Tiejun Huang",
            "Zongqing Lu"
        ],
        "summary": "We investigate the use of natural language to drive the generalization of policies in multi-agent settings. Unlike single-agent settings, the generalization of policies should also consider the influence of other agents. Besides, with the increasing number of entities in multi-agent settings, more agent-entity interactions are needed for language grounding, and the enormous search space could impede the learning process. Moreover, given a simple general instruction,e.g., beating all enemies, agents are required to decompose it into multiple subgoals and figure out the right one to focus on. Inspired by previous work, we try to address these issues at the entity level and propose a novel framework for language grounding in multi-agent reinforcement learning, entity divider (EnDi). EnDi enables agents to independently learn subgoal division at the entity level and act in the environment based on the associated entities. The subgoal division is regularized by opponent modeling to avoid subgoal conflicts and promote coordinated strategies. Empirically, EnDi demonstrates the strong generalization ability to unseen games with new dynamics and expresses the superiority over existing methods.",
        "published": "2022-10-25T11:53:52Z",
        "link": "http://arxiv.org/abs/2210.13942v1",
        "categories": [
            "cs.LG",
            "cs.CL",
            "cs.MA"
        ]
    },
    {
        "title": "Unknown area exploration for robots with energy constraints using a   modified Butterfly Optimization Algorithm",
        "authors": [
            "Amine Bendahmane",
            "Redouane Tlemsani"
        ],
        "summary": "Butterfly Optimization Algorithm (BOA) is a recent metaheuristic that has been used in several optimization problems. In this paper, we propose a new version of the algorithm (xBOA) based on the crossover operator and compare its results to the original BOA and 3 other variants recently introduced in the literature. We also proposed a framework for solving the unknown area exploration problem with energy constraints using metaheuristics in both single- and multi-robot scenarios. This framework allowed us to benchmark the performances of different metaheuristics for the robotics exploration problem. We conducted several experiments to validate this framework and used it to compare the effectiveness of xBOA with wellknown metaheuristics used in the literature through 5 evaluation criteria. Although BOA and xBOA are not optimal in all these criteria, we found that BOA can be a good alternative to many metaheuristics in terms of the exploration time, while xBOA is more robust to local optima; has better fitness convergence; and achieves better exploration rates than the original BOA and its other variants.",
        "published": "2022-10-26T15:15:19Z",
        "link": "http://arxiv.org/abs/2210.14774v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Non-Linear Coordination Graphs",
        "authors": [
            "Yipeng Kang",
            "Tonghan Wang",
            "Xiaoran Wu",
            "Qianlan Yang",
            "Chongjie Zhang"
        ],
        "summary": "Value decomposition multi-agent reinforcement learning methods learn the global value function as a mixing of each agent's individual utility functions. Coordination graphs (CGs) represent a higher-order decomposition by incorporating pairwise payoff functions and thus is supposed to have a more powerful representational capacity. However, CGs decompose the global value function linearly over local value functions, severely limiting the complexity of the value function class that can be represented. In this paper, we propose the first non-linear coordination graph by extending CG value decomposition beyond the linear case. One major challenge is to conduct greedy action selections in this new function class to which commonly adopted DCOP algorithms are no longer applicable. We study how to solve this problem when mixing networks with LeakyReLU activation are used. An enumeration method with a global optimality guarantee is proposed and motivates an efficient iterative optimization method with a local optimality guarantee. We find that our method can achieve superior performance on challenging multi-agent coordination tasks like MACO.",
        "published": "2022-10-26T18:11:31Z",
        "link": "http://arxiv.org/abs/2211.08404v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG"
        ]
    },
    {
        "title": "Trust-Awareness to Secure Swarm Intelligence from Data Injection Attack",
        "authors": [
            "Bin Han",
            "Dennis Krummacker",
            "Qiuheng Zhou",
            "Hans D. Schotten"
        ],
        "summary": "Enabled by the emerging industrial agent (IA) technology, swarm intelligence (SI) is envisaged to play an important role in future industrial Internet of Things (IIoT) that is shaped by Sixth Generation (6G) mobile communications and digital twin (DT). However, its fragility against data injection attack may halt it from practical deployment. In this paper we propose an efficient trust approach to address this security concern for SI.",
        "published": "2022-10-27T13:37:50Z",
        "link": "http://arxiv.org/abs/2211.08407v4",
        "categories": [
            "cs.NE",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Secure Distributed Optimization Under Gradient Attacks",
        "authors": [
            "Shuhua Yu",
            "Soummya Kar"
        ],
        "summary": "In this paper, we study secure distributed optimization against arbitrary gradient attack in multi-agent networks. In distributed optimization, there is no central server to coordinate local updates, and each agent can only communicate with its neighbors on a predefined network. We consider the scenario where out of $n$ networked agents, a fixed but unknown fraction $\\rho$ of the agents are under arbitrary gradient attack in that their stochastic gradient oracles return arbitrary information to derail the optimization process, and the goal is to minimize the sum of local objective functions on unattacked agents. We propose a distributed stochastic gradient method that combines local variance reduction and clipping (CLIP-VRG). We show that, in a connected network, when unattacked local objective functions are convex and smooth, share a common minimizer, and their sum is strongly convex, CLIP-VRG leads to almost sure convergence of the iterates to the exact sum cost minimizer at all agents. We quantify a tight upper bound of the fraction $\\rho$ of attacked agents in terms of problem parameters such as the condition number of the associated sum cost that guarantee exact convergence of CLIP-VRG, and characterize its asymptotic convergence rate. Finally, we empirically demonstrate the effectiveness of the proposed method under gradient attacks in both synthetic dataset and image classification datasets.",
        "published": "2022-10-28T01:23:34Z",
        "link": "http://arxiv.org/abs/2210.15821v1",
        "categories": [
            "math.OC",
            "cs.DC",
            "cs.MA"
        ]
    },
    {
        "title": "Credit-Based Congestion Pricing: Equilibrium Properties and Optimal   Scheme Design",
        "authors": [
            "Devansh Jalota",
            "Jessica Lazarus",
            "Alexandre Bayen",
            "Marco Pavone"
        ],
        "summary": "Credit-based congestion pricing (CBCP) has emerged as a mechanism to alleviate the social inequity concerns of road congestion pricing - a promising strategy for traffic congestion mitigation - by providing low-income users with travel credits to offset some of their toll payments. While CBCP offers immense potential for addressing inequity issues that hamper the practical viability of congestion pricing, the deployment of CBCP in practice is nascent, and the potential efficacy and optimal design of CBCP schemes have yet to be formalized. In this work, we study the design of CBCP schemes to achieve particular societal objectives and investigate their influence on traffic patterns when routing heterogeneous users with different values of time (VoTs) in a multi-lane highway with an express lane. We introduce a new non-atomic congestion game model of a mixed-economy, wherein eligible users receive travel credits while the remaining ineligible users pay out-of-pocket to use the express lane. In this setting, we investigate the effect of CBCP schemes on traffic patterns by characterizing the properties (i.e., existence, comparative statics) of the corresponding Nash equilibria and, in the setting when eligible users have time-invariant VoTs, develop a convex program to compute these equilibria. We further present a bi-level optimization framework to design optimal CBCP schemes to achieve a central planner's societal objectives. Finally, we conduct numerical experiments based on a case study of the San Mateo 101 Express Lanes Project, one of the first North American CBCP pilots. Our results demonstrate the potential of CBCP to enable low-income travelers to avail of the travel time savings provided by congestion pricing on express lanes while having comparatively low impacts on the travel costs of other road users.",
        "published": "2022-10-28T05:29:10Z",
        "link": "http://arxiv.org/abs/2210.15907v1",
        "categories": [
            "cs.GT",
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "Defense Against Smart Invaders with Swarms of Sweeping Agents",
        "authors": [
            "Roee M. Francos",
            "Alfred M. Bruckstein"
        ],
        "summary": "The goal of this research is to devise guaranteed defense policies that allow to protect a given region from the entrance of smart mobile invaders by detecting them using a team of defending agents equipped with identical line sensors. By designing cooperative defense strategies that ensure all invaders are detected, conditions on the defenders' speed are derived. Successful accomplishment of the defense task implies invaders with a known limit on their speed cannot slip past the defenders and enter the guarded region undetected. The desired outcome of the defense protocols is to defend the area and additionally to expand it as much as possible. Expansion becomes possible if the defenders' speed exceeds a critical speed that is necessary to only defend the initial region. We present results on the total search time, critical speeds and maximal expansion possible for two types of novel pincer-movement defense processes, circular and spiral, for any even number of defenders. The proposed spiral process allows to detect invaders at nearly the lowest theoretically optimal speed, and if this speed is exceeded, it also allows to expand the protected region almost to the maximal area.",
        "published": "2022-10-28T11:18:08Z",
        "link": "http://arxiv.org/abs/2210.16063v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Learning Modular Simulations for Homogeneous Systems",
        "authors": [
            "Jayesh K. Gupta",
            "Sai Vemprala",
            "Ashish Kapoor"
        ],
        "summary": "Complex systems are often decomposed into modular subsystems for engineering tractability. Although various equation based white-box modeling techniques make use of such structure, learning based methods have yet to incorporate these ideas broadly. We present a modular simulation framework for modeling homogeneous multibody dynamical systems, which combines ideas from graph neural networks and neural differential equations. We learn to model the individual dynamical subsystem as a neural ODE module. Full simulation of the composite system is orchestrated via spatio-temporal message passing between these modules. An arbitrary number of modules can be combined to simulate systems of a wide variety of coupling topologies. We evaluate our framework on a variety of systems and show that message passing allows coordination between multiple modules over time for accurate predictions and in certain cases, enables zero-shot generalization to new system configurations. Furthermore, we show that our models can be transferred to new system configurations with lower data requirement and training effort, compared to those trained from scratch.",
        "published": "2022-10-28T17:48:01Z",
        "link": "http://arxiv.org/abs/2210.16294v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Curiosity-Driven Multi-Agent Exploration with Mixed Objectives",
        "authors": [
            "Roben Delos Reyes",
            "Kyunghwan Son",
            "Jinhwan Jung",
            "Wan Ju Kang",
            "Yung Yi"
        ],
        "summary": "Intrinsic rewards have been increasingly used to mitigate the sparse reward problem in single-agent reinforcement learning. These intrinsic rewards encourage the agent to look for novel experiences, guiding the agent to explore the environment sufficiently despite the lack of extrinsic rewards. Curiosity-driven exploration is a simple yet efficient approach that quantifies this novelty as the prediction error of the agent's curiosity module, an internal neural network that is trained to predict the agent's next state given its current state and action. We show here, however, that naively using this curiosity-driven approach to guide exploration in sparse reward cooperative multi-agent environments does not consistently lead to improved results. Straightforward multi-agent extensions of curiosity-driven exploration take into consideration either individual or collective novelty only and thus, they do not provide a distinct but collaborative intrinsic reward signal that is essential for learning in cooperative multi-agent tasks. In this work, we propose a curiosity-driven multi-agent exploration method that has the mixed objective of motivating the agents to explore the environment in ways that are individually and collectively novel. First, we develop a two-headed curiosity module that is trained to predict the corresponding agent's next observation in the first head and the next joint observation in the second head. Second, we design the intrinsic reward formula to be the sum of the individual and joint prediction errors of this curiosity module. We empirically show that the combination of our curiosity module architecture and intrinsic reward formulation guides multi-agent exploration more efficiently than baseline approaches, thereby providing the best performance boost to MARL algorithms in cooperative navigation environments with sparse rewards.",
        "published": "2022-10-29T02:45:38Z",
        "link": "http://arxiv.org/abs/2210.16468v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Observable Perfect Equilibrium",
        "authors": [
            "Sam Ganzfried"
        ],
        "summary": "While Nash equilibrium has emerged as the central game-theoretic solution concept, many important games contain several Nash equilibria and we must determine how to select between them in order to create real strategic agents. Several Nash equilibrium refinement concepts have been proposed and studied for sequential imperfect-information games, the most prominent being trembling-hand perfect equilibrium, quasi-perfect equilibrium, and recently one-sided quasi-perfect equilibrium. These concepts are robust to certain arbitrarily small mistakes, and are guaranteed to always exist; however, we argue that neither of these is the correct concept for developing strong agents in sequential games of imperfect information. We define a new equilibrium refinement concept for extensive-form games called observable perfect equilibrium in which the solution is robust over trembles in publicly-observable action probabilities (not necessarily over all action probabilities that may not be observable by opposing players). Observable perfect equilibrium correctly captures the assumption that the opponent is playing as rationally as possible given mistakes that have been observed (while previous solution concepts do not). We prove that observable perfect equilibrium is always guaranteed to exist, and demonstrate that it leads to a different solution than the prior extensive-form refinements in no-limit poker. We expect observable perfect equilibrium to be a useful equilibrium refinement concept for modeling many important imperfect-information games of interest in artificial intelligence.",
        "published": "2022-10-29T06:07:29Z",
        "link": "http://arxiv.org/abs/2210.16506v9",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.MA",
            "econ.TH"
        ]
    },
    {
        "title": "Searching for Deviations in Trading Systems: Combining Control-Flow and   Data Perspectives",
        "authors": [
            "Julio C. Carrasquel",
            "Irina A. Lomazova"
        ],
        "summary": "Trading systems are software platforms that support the exchange of securities (e.g., company shares) between participants. In this paper, we present a method to search for deviations in trading systems by checking conformance between colored Petri nets and event logs. Colored Petri nets (CPNs) are an extension of Petri nets, a formalism for modeling of distributed systems. CPNs allow us to describe an expected causal ordering between system activities and how data attributes of domain-related objects (e.g., orders to trade) must be transformed. Event logs consist of traces corresponding to runs of a real system. By comparing CPNs and event logs, different types of deviations can be detected. Using this method, we report the validation of a real-life trading system.",
        "published": "2022-10-30T10:22:12Z",
        "link": "http://arxiv.org/abs/2210.16800v1",
        "categories": [
            "cs.SE",
            "cs.DM",
            "cs.MA"
        ]
    },
    {
        "title": "Unrolled Graph Learning for Multi-Agent Collaboration",
        "authors": [
            "Enpei Zhang",
            "Shuo Tang",
            "Xiaowen Dong",
            "Siheng Chen",
            "Yanfeng Wang"
        ],
        "summary": "Multi-agent learning has gained increasing attention to tackle distributed machine learning scenarios under constrictions of data exchanging. However, existing multi-agent learning models usually consider data fusion under fixed and compulsory collaborative relations among agents, which is not as flexible and autonomous as human collaboration. To fill this gap, we propose a distributed multi-agent learning model inspired by human collaboration, in which the agents can autonomously detect suitable collaborators and refer to collaborators' model for better performance. To implement such adaptive collaboration, we use a collaboration graph to indicate the pairwise collaborative relation. The collaboration graph can be obtained by graph learning techniques based on model similarity between different agents. Since model similarity can not be formulated by a fixed graphical optimization, we design a graph learning network by unrolling, which can learn underlying similar features among potential collaborators. By testing on both regression and classification tasks, we validate that our proposed collaboration model can figure out accurate collaborative relationship and greatly improve agents' learning performance.",
        "published": "2022-10-31T07:05:44Z",
        "link": "http://arxiv.org/abs/2210.17101v3",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Safe and Efficient Manoeuvring for Emergency Vehicles in Autonomous   Traffic using Multi-Agent Proximal Policy Optimisation",
        "authors": [
            "Leandro Parada",
            "Eduardo Candela",
            "Luis Marques",
            "Panagiotis Angeloudis"
        ],
        "summary": "Manoeuvring in the presence of emergency vehicles is still a major issue for vehicle autonomy systems. Most studies that address this topic are based on rule-based methods, which cannot cover all possible scenarios that can take place in autonomous traffic. Multi-Agent Proximal Policy Optimisation (MAPPO) has recently emerged as a powerful method for autonomous systems because it allows for training in thousands of different situations. In this study, we present an approach based on MAPPO to guarantee the safe and efficient manoeuvring of autonomous vehicles in the presence of an emergency vehicle. We introduce a risk metric that summarises the potential risk of collision in a single index. The proposed method generates cooperative policies allowing the emergency vehicle to go at $15 \\%$ higher average speed while maintaining high safety distances. Moreover, we explore the trade-off between safety and traffic efficiency and assess the performance in a competitive scenario.",
        "published": "2022-10-31T15:05:49Z",
        "link": "http://arxiv.org/abs/2210.17381v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Space-Fluid Adaptive Sampling by Self-Organisation",
        "authors": [
            "Roberto Casadei",
            "Stefano Mariani",
            "Danilo Pianini",
            "Mirko Viroli",
            "Franco Zambonelli"
        ],
        "summary": "A recurrent task in coordinated systems is managing (estimating, predicting, or controlling) signals that vary in space, such as distributed sensed data or computation outcomes. Especially in large-scale settings, the problem can be addressed through decentralised and situated computing systems: nodes can locally sense, process, and act upon signals, and coordinate with neighbours to implement collective strategies. Accordingly, in this work we devise distributed coordination strategies for the estimation of a spatial phenomenon through collaborative adaptive sampling. Our design is based on the idea of dynamically partitioning space into regions that compete and grow/shrink to provide accurate aggregate sampling. Such regions hence define a sort of virtualised space that is \"fluid\", since its structure adapts in response to pressure forces exerted by the underlying phenomenon. We provide an adaptive sampling algorithm in the field-based coordination framework, and prove it is self-stabilising and locally optimal. Finally, we verify by simulation that the proposed algorithm effectively carries out a spatially adaptive sampling while maintaining a tuneable trade-off between accuracy and efficiency.",
        "published": "2022-10-31T17:29:41Z",
        "link": "http://arxiv.org/abs/2210.17505v5",
        "categories": [
            "cs.DC",
            "cs.AI",
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "I.2.11; D.3.1; D.1.3"
        ]
    },
    {
        "title": "Agent-Time Attention for Sparse Rewards Multi-Agent Reinforcement   Learning",
        "authors": [
            "Jennifer She",
            "Jayesh K. Gupta",
            "Mykel J. Kochenderfer"
        ],
        "summary": "Sparse and delayed rewards pose a challenge to single agent reinforcement learning. This challenge is amplified in multi-agent reinforcement learning (MARL) where credit assignment of these rewards needs to happen not only across time, but also across agents. We propose Agent-Time Attention (ATA), a neural network model with auxiliary losses for redistributing sparse and delayed rewards in collaborative MARL. We provide a simple example that demonstrates how providing agents with their own local redistributed rewards and shared global redistributed rewards motivate different policies. We extend several MiniGrid environments, specifically MultiRoom and DoorKey, to the multi-agent sparse delayed rewards setting. We demonstrate that ATA outperforms various baselines on many instances of these environments. Source code of the experiments is available at https://github.com/jshe/agent-time-attention.",
        "published": "2022-10-31T17:54:51Z",
        "link": "http://arxiv.org/abs/2210.17540v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Indexability is Not Enough for Whittle: Improved, Near-Optimal   Algorithms for Restless Bandits",
        "authors": [
            "Abheek Ghosh",
            "Dheeraj Nagaraj",
            "Manish Jain",
            "Milind Tambe"
        ],
        "summary": "We study the problem of planning restless multi-armed bandits (RMABs) with multiple actions. This is a popular model for multi-agent systems with applications like multi-channel communication, monitoring and machine maintenance tasks, and healthcare. Whittle index policies, which are based on Lagrangian relaxations, are widely used in these settings due to their simplicity and near-optimality under certain conditions. In this work, we first show that Whittle index policies can fail in simple and practically relevant RMAB settings, even when the RMABs are indexable. We discuss why the optimality guarantees fail and why asymptotic optimality may not translate well to practically relevant planning horizons.   We then propose an alternate planning algorithm based on the mean-field method, which can provably and efficiently obtain near-optimal policies with a large number of arms, without the stringent structural assumptions required by the Whittle index policies. This borrows ideas from existing research with some improvements: our approach is hyper-parameter free, and we provide an improved non-asymptotic analysis which has: (a) no requirement for exogenous hyper-parameters and tighter polynomial dependence on known problem parameters; (b) high probability bounds which show that the reward of the policy is reliable; and (c) matching sub-optimality lower bounds for this algorithm with respect to the number of arms, thus demonstrating the tightness of our bounds. Our extensive experimental analysis shows that the mean-field approach matches or outperforms other baselines.",
        "published": "2022-10-31T19:35:15Z",
        "link": "http://arxiv.org/abs/2211.00112v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG",
            "math.OC"
        ]
    },
    {
        "title": "Differentiable Model Selection for Ensemble Learning",
        "authors": [
            "James Kotary",
            "Vincenzo Di Vito",
            "Ferdinando Fioretto"
        ],
        "summary": "Model selection is a strategy aimed at creating accurate and robust models. A key challenge in designing these algorithms is identifying the optimal model for classifying any particular input sample. This paper addresses this challenge and proposes a novel framework for differentiable model selection integrating machine learning and combinatorial optimization. The framework is tailored for ensemble learning, a strategy that combines the outputs of individually pre-trained models, and learns to select appropriate ensemble members for a particular input sample by transforming the ensemble learning task into a differentiable selection program trained end-to-end within the ensemble learning model. Tested on various tasks, the proposed framework demonstrates its versatility and effectiveness, outperforming conventional and advanced consensus rules across a variety of settings and learning tasks.",
        "published": "2022-11-01T03:37:49Z",
        "link": "http://arxiv.org/abs/2211.00251v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Can maker-taker fees prevent algorithmic cooperation in market making?",
        "authors": [
            "Bingyan Han"
        ],
        "summary": "In a semi-realistic market simulator, independent reinforcement learning algorithms may facilitate market makers to maintain wide spreads even without communication. This unexpected outcome challenges the current antitrust law framework. We study the effectiveness of maker-taker fee models in preventing cooperation via algorithms. After modeling market making as a repeated general-sum game, we experimentally show that the relation between net transaction costs and maker rebates is not necessarily monotone. Besides an upper bound on taker fees, we may also need a lower bound on maker rebates to destabilize the cooperation. We also consider the taker-maker model and the effects of mid-price volatility, inventory risk, and the number of agents.",
        "published": "2022-11-01T14:39:49Z",
        "link": "http://arxiv.org/abs/2211.00496v1",
        "categories": [
            "q-fin.TR",
            "cs.MA"
        ]
    },
    {
        "title": "Counting and Computing Join-Endomorphisms in Lattices (Revisited)",
        "authors": [
            "Carlos Pinzón",
            "Santiago Quintero",
            "Sergio Ramírez",
            "Camilo Rueda",
            "Frank Valencia"
        ],
        "summary": "Structures involving a lattice and join-endomorphisms on it are ubiquitous in computer science. We study the cardinality of the set $\\mathcal{E}(L)$ of all join-endomorphisms of a given finite lattice $L$. In particular, we show for $\\mathbf{M}_n$, the discrete order of $n$ elements extended with top and bottom, $| \\mathcal{E}(\\mathbf{M}_n) | =n!\\mathcal{L}_n(-1)+(n+1)^2$ where $\\mathcal{L}_n(x)$ is the Laguerre polynomial of degree $n$. We also study the following problem: Given a lattice $L$ of size $n$ and a set $S\\subseteq \\mathcal{E}(L)$ of size $m$, find the greatest lower bound ${\\large\\sqcap}_{\\mathcal{E}(L)} S$. The join-endomorphism ${\\large\\sqcap}_{\\mathcal{E}(L)} S$ has meaningful interpretations in epistemic logic, distributed systems, and Aumann structures. We show that this problem can be solved with worst-case time complexity in $O(mn)$ for distributive lattices and $O(mn + n^3)$ for arbitrary lattices. In the particular case of modular lattices, we present an adaptation of the latter algorithm that reduces its average time complexity. We provide theoretical and experimental results to support this enhancement. The complexity is expressed in terms of the basic binary lattice operations performed by the algorithm.",
        "published": "2022-11-01T22:56:47Z",
        "link": "http://arxiv.org/abs/2211.00781v1",
        "categories": [
            "cs.MA",
            "math.RA"
        ]
    },
    {
        "title": "An Information-Theoretic Approach for Estimating Scenario Generalization   in Crowd Motion Prediction",
        "authors": [
            "Gang Qiao",
            "Kaidong Hu",
            "Seonghyeon Moon",
            "Samuel S. Sohn",
            "Sejong Yoon",
            "Mubbasir Kapadia",
            "Vladimir Pavlovic"
        ],
        "summary": "Learning-based approaches to modeling crowd motion have become increasingly successful but require training and evaluation on large datasets, coupled with complex model selection and parameter tuning. To circumvent this tremendously time-consuming process, we propose a novel scoring method, which characterizes generalization of models trained on source crowd scenarios and applied to target crowd scenarios using a training-free, model-agnostic Interaction + Diversity Quantification score, ISDQ. The Interaction component aims to characterize the difficulty of scenario domains, while the diversity of a scenario domain is captured in the Diversity score. Both scores can be computed in a computation tractable manner. Our experimental results validate the efficacy of the proposed method on several simulated and real-world (source,target) generalization tasks, demonstrating its potential to select optimal domain pairs before training and testing a model.",
        "published": "2022-11-02T01:39:30Z",
        "link": "http://arxiv.org/abs/2211.00817v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Learning to Price Supply Chain Contracts against a Learning Retailer",
        "authors": [
            "Xuejun Zhao",
            "Ruihao Zhu",
            "William B. Haskell"
        ],
        "summary": "The rise of big data analytics has automated the decision-making of companies and increased supply chain agility. In this paper, we study the supply chain contract design problem faced by a data-driven supplier who needs to respond to the inventory decisions of the downstream retailer. Both the supplier and the retailer are uncertain about the market demand and need to learn about it sequentially. The goal for the supplier is to develop data-driven pricing policies with sublinear regret bounds under a wide range of possible retailer inventory policies for a fixed time horizon.   To capture the dynamics induced by the retailer's learning policy, we first make a connection to non-stationary online learning by following the notion of variation budget. The variation budget quantifies the impact of the retailer's learning strategy on the supplier's decision-making. We then propose dynamic pricing policies for the supplier for both discrete and continuous demand. We also note that our proposed pricing policy only requires access to the support of the demand distribution, but critically, does not require the supplier to have any prior knowledge about the retailer's learning policy or the demand realizations. We examine several well-known data-driven policies for the retailer, including sample average approximation, distributionally robust optimization, and parametric approaches, and show that our pricing policies lead to sublinear regret bounds in all these cases.   At the managerial level, we answer affirmatively that there is a pricing policy with a sublinear regret bound under a wide range of retailer's learning policies, even though she faces a learning retailer and an unknown demand distribution. Our work also provides a novel perspective in data-driven operations management where the principal has to learn to react to the learning policies employed by other agents in the system.",
        "published": "2022-11-02T04:00:47Z",
        "link": "http://arxiv.org/abs/2211.04586v1",
        "categories": [
            "cs.LG",
            "cs.GT",
            "cs.MA",
            "econ.TH",
            "stat.ML"
        ]
    },
    {
        "title": "Over-communicate no more: Situated RL agents learn concise communication   protocols",
        "authors": [
            "Aleksandra Kalinowska",
            "Elnaz Davoodi",
            "Florian Strub",
            "Kory W Mathewson",
            "Ivana Kajic",
            "Michael Bowling",
            "Todd D Murphey",
            "Patrick M Pilarski"
        ],
        "summary": "While it is known that communication facilitates cooperation in multi-agent settings, it is unclear how to design artificial agents that can learn to effectively and efficiently communicate with each other. Much research on communication emergence uses reinforcement learning (RL) and explores unsituated communication in one-step referential tasks -- the tasks are not temporally interactive and lack time pressures typically present in natural communication. In these settings, agents may successfully learn to communicate, but they do not learn to exchange information concisely -- they tend towards over-communication and an inefficient encoding. Here, we explore situated communication in a multi-step task, where the acting agent has to forgo an environmental action to communicate. Thus, we impose an opportunity cost on communication and mimic the real-world pressure of passing time. We compare communication emergence under this pressure against learning to communicate with a cost on articulation effort, implemented as a per-message penalty (fixed and progressively increasing). We find that while all tested pressures can disincentivise over-communication, situated communication does it most effectively and, unlike the cost on effort, does not negatively impact emergence. Implementing an opportunity cost on communication in a temporally extended environment is a step towards embodiment, and might be a pre-condition for incentivising efficient, human-like communication.",
        "published": "2022-11-02T21:08:14Z",
        "link": "http://arxiv.org/abs/2211.01480v1",
        "categories": [
            "cs.MA",
            "cs.CL",
            "cs.HC"
        ]
    },
    {
        "title": "Cooperative Maneuvers of Highly Automated Vehicles at Urban   Intersections: A Game-theoretic Approach",
        "authors": [
            "Björn Koopmann",
            "Stefan Puch",
            "Günter Ehmen",
            "Martin Fränzle"
        ],
        "summary": "In this paper, we propose an approach how connected and highly automated vehicles can perform cooperative maneuvers such as lane changes and left-turns at urban intersections where they have to deal with human-operated vehicles and vulnerable road users such as cyclists and pedestrians in so-called mixed traffic. In order to support cooperative maneuvers the urban intersection is equipped with an intelligent controller which has access to different sensors along the intersection to detect and predict the behavior of the traffic participants involved. Since the intersection controller cannot directly control all road users and - not least due to the legal situation - driving decisions must always be made by the vehicle controller itself, we focus on a decentralized control paradigm. In this context, connected and highly automated vehicles use some carefully selected game theory concepts to make the best possible and clear decisions about cooperative maneuvers. The aim is to improve traffic efficiency while maintaining road safety at the same time. Our first results obtained with a prototypical implementation of the approach in a traffic simulation are promising.",
        "published": "2022-11-03T07:49:51Z",
        "link": "http://arxiv.org/abs/2211.01633v1",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "An Efficient Approach with Dynamic Multi-Swarm of UAVs for Forest   Firefighting",
        "authors": [
            "Josy John",
            "K. Harikumar",
            "J. Senthilnath",
            "Suresh Sundaram"
        ],
        "summary": "In this paper, the Multi-Swarm Cooperative Information-driven search and Divide and Conquer mitigation control (MSCIDC) approach is proposed for faster detection and mitigation of forest fire by reducing the loss of biodiversity, nutrients, soil moisture, and other intangible benefits. A swarm is a cooperative group of Unmanned Aerial Vehicles (UAVs) that fly together to search and quench the fire effectively. The multi-swarm cooperative information-driven search uses a multi-level search comprising cooperative information-driven exploration and exploitation for quick/accurate detection of fire location. The search level is selected based on the thermal sensor information about the potential fire area. The dynamicity of swarms, aided by global regulative repulsion and merging between swarms, reduces the detection and mitigation time compared to the existing methods. The local attraction among the members of the swarm helps the non-detector members to reach the fire location faster, and divide-and-conquer mitigation control ensures a non-overlapping fire sector allocation for all members quenching the fire. The performance of MSCIDC has been compared with different multi-UAV methods using a simulated environment of pine forest. The performance clearly shows that MSCIDC mitigates fire much faster than the multi-UAV methods. The Monte-Carlo simulation results indicate that the proposed method reduces the average forest area burnt by $65\\%$ and mission time by $60\\%$ compared to the best result case of the multi-UAV approaches, guaranteeing a faster and successful mission.",
        "published": "2022-11-03T16:41:09Z",
        "link": "http://arxiv.org/abs/2211.01958v1",
        "categories": [
            "cs.MA",
            "cs.RO",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Group Cohesion in Multi-Agent Scenarios as an Emergent Behavior",
        "authors": [
            "Gianluca Georg Alois Volkmer",
            "Nabil Alsabah"
        ],
        "summary": "In this paper, we elaborate on the design and discuss the results of a multi-agent simulation that we have developed using the PSI cognitive architecture. We demonstrate that imbuing agents with intrinsic needs for group affiliation, certainty and competence will lead to the emergence of social behavior among agents. This behavior expresses itself in altruism toward in-group agents and adversarial tendencies toward out-group agents. Our simulation also shows how parameterization can have dramatic effects on agent behavior. Introducing an out-group bias, for example, not only made agents behave aggressively toward members of the other group, but it also increased in-group cohesion. Similarly, environmental and situational factors facilitated the emergence of outliers: agents from adversarial groups becoming close friends.   Overall, this simulation showcases the power of psychological frameworks, in general, and the PSI paradigm, in particular, to bring about human-like behavioral patterns in an emergent fashion.",
        "published": "2022-11-03T18:37:05Z",
        "link": "http://arxiv.org/abs/2211.02089v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Scalable Multi-Agent Reinforcement Learning through Intelligent   Information Aggregation",
        "authors": [
            "Siddharth Nayak",
            "Kenneth Choi",
            "Wenqi Ding",
            "Sydney Dolan",
            "Karthik Gopalakrishnan",
            "Hamsa Balakrishnan"
        ],
        "summary": "We consider the problem of multi-agent navigation and collision avoidance when observations are limited to the local neighborhood of each agent. We propose InforMARL, a novel architecture for multi-agent reinforcement learning (MARL) which uses local information intelligently to compute paths for all the agents in a decentralized manner. Specifically, InforMARL aggregates information about the local neighborhood of agents for both the actor and the critic using a graph neural network and can be used in conjunction with any standard MARL algorithm. We show that (1) in training, InforMARL has better sample efficiency and performance than baseline approaches, despite using less information, and (2) in testing, it scales well to environments with arbitrary numbers of agents and obstacles. We illustrate these results using four task environments, including one with predetermined goals for each agent, and one in which the agents collectively try to cover all goals. Code available at https://github.com/nsidn98/InforMARL.",
        "published": "2022-11-03T20:02:45Z",
        "link": "http://arxiv.org/abs/2211.02127v3",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.RO"
        ]
    },
    {
        "title": "Emergent Quantized Communication",
        "authors": [
            "Boaz Carmeli",
            "Ron Meir",
            "Yonatan Belinkov"
        ],
        "summary": "The field of emergent communication aims to understand the characteristics of communication as it emerges from artificial agents solving tasks that require information exchange. Communication with discrete messages is considered a desired characteristic, for both scientific and applied reasons. However, training a multi-agent system with discrete communication is not straightforward, requiring either reinforcement learning algorithms or relaxing the discreteness requirement via a continuous approximation such as the Gumbel-softmax. Both these solutions result in poor performance compared to fully continuous communication. In this work, we propose an alternative approach to achieve discrete communication -- quantization of communicated messages. Using message quantization allows us to train the model end-to-end, achieving superior performance in multiple setups. Moreover, quantization is a natural framework that runs the gamut from continuous to discrete communication. Thus, it sets the ground for a broader view of multi-agent communication in the deep learning era.",
        "published": "2022-11-04T12:39:45Z",
        "link": "http://arxiv.org/abs/2211.02412v2",
        "categories": [
            "cs.AI",
            "cs.MA",
            "68T07",
            "I.2.6"
        ]
    },
    {
        "title": "Multilingual Name Entity Recognition and Intent Classification Employing   Deep Learning Architectures",
        "authors": [
            "Sofia Rizou",
            "Antonia Paflioti",
            "Angelos Theofilatos",
            "Athena Vakali",
            "George Sarigiannidis",
            "Konstantinos Ch. Chatzisavvas"
        ],
        "summary": "Named Entity Recognition and Intent Classification are among the most important subfields of the field of Natural Language Processing. Recent research has lead to the development of faster, more sophisticated and efficient models to tackle the problems posed by those two tasks. In this work we explore the effectiveness of two separate families of Deep Learning networks for those tasks: Bidirectional Long Short-Term networks and Transformer-based networks. The models were trained and tested on the ATIS benchmark dataset for both English and Greek languages. The purpose of this paper is to present a comparative study of the two groups of networks for both languages and showcase the results of our experiments. The models, being the current state-of-the-art, yielded impressive results and achieved high performance.",
        "published": "2022-11-04T12:42:29Z",
        "link": "http://arxiv.org/abs/2211.02415v1",
        "categories": [
            "cs.CL",
            "cs.LG",
            "cs.MA",
            "I.2.7; I.2.1; I.2.11"
        ]
    },
    {
        "title": "Changing agents and ascribing beliefs in dynamic epistemic logic",
        "authors": [
            "Shikha Singh",
            "Kamal Lodaya",
            "Deepak Khemani"
        ],
        "summary": "In dynamic epistemic logic (Van Ditmarsch, Van Der Hoek, & Kooi, 2008) it is customary to use an action frame (Baltag & Moss, 2004; Baltag, Moss, & Solecki, 1998) to describe different views of a single action. In this article, action frames are extended to add or remove agents, we call these agent-update frames. This can be done selectively so that only some specified agents get information of the update, which can be used to model several interesting examples such as private update and deception, studied earlier by Baltag and Moss (2004); Sakama (2015); Van Ditmarsch, Van Eijck, Sietsma, and Wang (2012). The product update of a Kripke model by an action frame is an abbreviated way of describing the transformed Kripke model which is the result of performing the action. This is substantially extended to a sum-product update of a Kripke model by an agent-update frame in the new setting. These ideas are applied to an AI problem of modelling a story. We show that dynamic epistemic logics, with update modalities now based on agent-update frames, continue to have sound and complete proof systems. Decision procedures for model checking and satisfiability have expected complexity. For a sublanguage, there are polynomial space algorithms.",
        "published": "2022-11-04T13:37:53Z",
        "link": "http://arxiv.org/abs/2211.02452v4",
        "categories": [
            "cs.AI",
            "cs.LO",
            "cs.MA"
        ]
    },
    {
        "title": "GoRela: Go Relative for Viewpoint-Invariant Motion Forecasting",
        "authors": [
            "Alexander Cui",
            "Sergio Casas",
            "Kelvin Wong",
            "Simon Suo",
            "Raquel Urtasun"
        ],
        "summary": "The task of motion forecasting is critical for self-driving vehicles (SDVs) to be able to plan a safe maneuver. Towards this goal, modern approaches reason about the map, the agents' past trajectories and their interactions in order to produce accurate forecasts. The predominant approach has been to encode the map and other agents in the reference frame of each target agent. However, this approach is computationally expensive for multi-agent prediction as inference needs to be run for each agent. To tackle the scaling challenge, the solution thus far has been to encode all agents and the map in a shared coordinate frame (e.g., the SDV frame). However, this is sample inefficient and vulnerable to domain shift (e.g., when the SDV visits uncommon states). In contrast, in this paper, we propose an efficient shared encoding for all agents and the map without sacrificing accuracy or generalization. Towards this goal, we leverage pair-wise relative positional encodings to represent geometric relationships between the agents and the map elements in a heterogeneous spatial graph. This parameterization allows us to be invariant to scene viewpoint, and save online computation by re-using map embeddings computed offline. Our decoder is also viewpoint agnostic, predicting agent goals on the lane graph to enable diverse and context-aware multimodal prediction. We demonstrate the effectiveness of our approach on the urban Argoverse 2 benchmark as well as a novel highway dataset.",
        "published": "2022-11-04T16:10:50Z",
        "link": "http://arxiv.org/abs/2211.02545v2",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.CV",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Graph Reinforcement Learning Application to Co-operative Decision-Making   in Mixed Autonomy Traffic: Framework, Survey, and Challenges",
        "authors": [
            "Qi Liu",
            "Xueyuan Li",
            "Zirui Li",
            "Jingda Wu",
            "Guodong Du",
            "Xin Gao",
            "Fan Yang",
            "Shihua Yuan"
        ],
        "summary": "Proper functioning of connected and automated vehicles (CAVs) is crucial for the safety and efficiency of future intelligent transport systems. Meanwhile, transitioning to fully autonomous driving requires a long period of mixed autonomy traffic, including both CAVs and human-driven vehicles. Thus, collaboration decision-making for CAVs is essential to generate appropriate driving behaviors to enhance the safety and efficiency of mixed autonomy traffic. In recent years, deep reinforcement learning (DRL) has been widely used in solving decision-making problems. However, the existing DRL-based methods have been mainly focused on solving the decision-making of a single CAV. Using the existing DRL-based methods in mixed autonomy traffic cannot accurately represent the mutual effects of vehicles and model dynamic traffic environments. To address these shortcomings, this article proposes a graph reinforcement learning (GRL) approach for multi-agent decision-making of CAVs in mixed autonomy traffic. First, a generic and modular GRL framework is designed. Then, a systematic review of DRL and GRL methods is presented, focusing on the problems addressed in recent research. Moreover, a comparative study on different GRL methods is further proposed based on the designed framework to verify the effectiveness of GRL methods. Results show that the GRL methods can well optimize the performance of multi-agent decision-making for CAVs in mixed autonomy traffic compared to the DRL methods. Finally, challenges and future research directions are summarized. This study can provide a valuable research reference for solving the multi-agent decision-making problems of CAVs in mixed autonomy traffic and can promote the implementation of GRL-based methods into intelligent transportation systems. The source code of our work can be found at https://github.com/Jacklinkk/Graph_CAVs.",
        "published": "2022-11-06T01:50:13Z",
        "link": "http://arxiv.org/abs/2211.03005v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Developing Decentralised Resilience to Malicious Influence in Collective   Perception Problem",
        "authors": [
            "Chris Wise",
            "Aya Hussein",
            "Heba El-Fiqi"
        ],
        "summary": "In collective decision-making, designing algorithms that use only local information to effect swarm-level behaviour is a non-trivial problem. We used machine learning techniques to teach swarm members to map their local perceptions of the environment to an optimal action. A curriculum inspired by Machine Education approaches was designed to facilitate this learning process and teach the members the skills required for optimal performance in the collective perception problem. We extended upon previous approaches by creating a curriculum that taught agents resilience to malicious influence. The experimental results show that well-designed rules-based algorithms can produce effective agents. When performing opinion fusion, we implemented decentralised resilience by having agents dynamically weight received opinion. We found a non-significant difference between constant and dynamic weights, suggesting that momentum-based opinion fusion is perhaps already a resilience mechanism.",
        "published": "2022-11-06T08:53:33Z",
        "link": "http://arxiv.org/abs/2211.03063v1",
        "categories": [
            "cs.MA",
            "cs.LG"
        ]
    },
    {
        "title": "EdgeVision: Towards Collaborative Video Analytics on Distributed Edges   for Performance Maximization",
        "authors": [
            "Guanyu Gao",
            "Yuqi Dong",
            "Ran Wang",
            "Xin Zhou"
        ],
        "summary": "Deep Neural Network (DNN)-based video analytics significantly improves recognition accuracy in computer vision applications. Deploying DNN models at edge nodes, closer to end users, reduces inference delay and minimizes bandwidth costs. However, these resource-constrained edge nodes may experience substantial delays under heavy workloads, leading to imbalanced workload distribution. While previous efforts focused on optimizing hierarchical device-edge-cloud architectures or centralized clusters for video analytics, we propose addressing these challenges through collaborative distributed and autonomous edge nodes. Despite the intricate control involved, we introduce EdgeVision, a Multiagent Reinforcement Learning (MARL)- based framework for collaborative video analytics on distributed edges. EdgeVision enables edge nodes to autonomously learn policies for video preprocessing, model selection, and request dispatching. Our approach utilizes an actor-critic-based MARL algorithm enhanced with an attention mechanism to learn optimal policies. To validate EdgeVision, we construct a multi-edge testbed and conduct experiments with real-world datasets. Results demonstrate a performance enhancement of 33.6% to 86.4% compared to baseline methods.",
        "published": "2022-11-06T13:02:08Z",
        "link": "http://arxiv.org/abs/2211.03102v3",
        "categories": [
            "cs.DC",
            "cs.MA",
            "cs.MM"
        ]
    },
    {
        "title": "Learning Task Requirements and Agent Capabilities for Multi-agent Task   Allocation",
        "authors": [
            "Bo Fu",
            "William Smith",
            "Denise Rizzo",
            "Matthew Castanier",
            "Maani Ghaffari",
            "Kira Barton"
        ],
        "summary": "This paper presents a learning framework to estimate an agent capability and task requirement model for multi-agent task allocation. With a set of team configurations and the corresponding task performances as the training data, linear task constraints can be learned to be embedded in many existing optimization-based task allocation frameworks. Comprehensive computational evaluations are conducted to test the scalability and prediction accuracy of the learning framework with a limited number of team configurations and performance pairs. A ROS and Gazebo-based simulation environment is developed to validate the proposed requirements learning and task allocation framework in practical multi-agent exploration and manipulation tasks. Results show that the learning process for scenarios with 40 tasks and 6 types of agents uses around 12 seconds, ending up with prediction errors in the range of 0.5-2%.",
        "published": "2022-11-07T03:45:57Z",
        "link": "http://arxiv.org/abs/2211.03286v2",
        "categories": [
            "cs.RO",
            "cs.MA",
            "93A16"
        ]
    },
    {
        "title": "RITA: Boost Driving Simulators with Realistic Interactive Traffic Flow",
        "authors": [
            "Zhengbang Zhu",
            "Shenyu Zhang",
            "Yuzheng Zhuang",
            "Yuecheng Liu",
            "Minghuan Liu",
            "Liyuan Mao",
            "Ziqin Gong",
            "Shixiong Kai",
            "Qiang Gu",
            "Bin Wang",
            "Siyuan Cheng",
            "Xinyu Wang",
            "Jianye Hao",
            "Yong Yu"
        ],
        "summary": "High-quality traffic flow generation is the core module in building simulators for autonomous driving. However, the majority of available simulators are incapable of replicating traffic patterns that accurately reflect the various features of real-world data while also simulating human-like reactive responses to the tested autopilot driving strategies. Taking one step forward to addressing such a problem, we propose Realistic Interactive TrAffic flow (RITA) as an integrated component of existing driving simulators to provide high-quality traffic flow for the evaluation and optimization of the tested driving strategies. RITA is developed with consideration of three key features, i.e., fidelity, diversity, and controllability, and consists of two core modules called RITABackend and RITAKit. RITABackend is built to support vehicle-wise control and provide traffic generation models from real-world datasets, while RITAKit is developed with easy-to-use interfaces for controllable traffic generation via RITABackend. We demonstrate RITA's capacity to create diversified and high-fidelity traffic simulations in several highly interactive highway scenarios. The experimental findings demonstrate that our produced RITA traffic flows exhibit all three key features, hence enhancing the completeness of driving strategy evaluation. Moreover, we showcase the possibility for further improvement of baseline strategies through online fine-tuning with RITA traffic flows.",
        "published": "2022-11-07T10:13:33Z",
        "link": "http://arxiv.org/abs/2211.03408v5",
        "categories": [
            "cs.AI",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Satellite Navigation and Coordination with Limited Information Sharing",
        "authors": [
            "Sydney Dolan",
            "Siddharth Nayak",
            "Hamsa Balakrishnan"
        ],
        "summary": "We explore space traffic management as an application of collision-free navigation in multi-agent systems where vehicles have limited observation and communication ranges. We investigate the effectiveness of transferring a collision avoidance multi-agent reinforcement (MARL) model trained on a ground environment to a space one. We demonstrate that the transfer learning model outperforms a model that is trained directly on the space environment. Furthermore, we find that our approach works well even when we consider the perturbations to satellite dynamics caused by the Earth's oblateness. Finally, we show how our methods can be used to evaluate the benefits of information-sharing between satellite operators in order to improve coordination.",
        "published": "2022-11-07T16:14:31Z",
        "link": "http://arxiv.org/abs/2211.03658v3",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Federated Causal Discovery From Interventions",
        "authors": [
            "Amin Abyaneh",
            "Nino Scherrer",
            "Patrick Schwab",
            "Stefan Bauer",
            "Bernhard Schölkopf",
            "Arash Mehrjou"
        ],
        "summary": "Causal discovery serves a pivotal role in mitigating model uncertainty through recovering the underlying causal mechanisms among variables. In many practical domains, such as healthcare, access to the data gathered by individual entities is limited, primarily for privacy and regulatory constraints. However, the majority of existing causal discovery methods require the data to be available in a centralized location. In response, researchers have introduced federated causal discovery. While previous federated methods consider distributed observational data, the integration of interventional data remains largely unexplored. We propose FedCDI, a federated framework for inferring causal structures from distributed data containing interventional samples. In line with the federated learning framework, FedCDI improves privacy by exchanging belief updates rather than raw samples. Additionally, it introduces a novel intervention-aware method for aggregating individual updates. We analyze scenarios with shared or disjoint intervened covariates, and mitigate the adverse effects of interventional data heterogeneity. The performance and scalability of FedCDI is rigorously tested across a variety of synthetic and real-world graphs.",
        "published": "2022-11-07T20:25:48Z",
        "link": "http://arxiv.org/abs/2211.03846v4",
        "categories": [
            "cs.LG",
            "cs.MA",
            "stat.ME"
        ]
    },
    {
        "title": "Policy-Based Reinforcement Learning for Assortative Matching in Human   Behavior Modeling",
        "authors": [
            "Ou Deng",
            "Qun Jin"
        ],
        "summary": "This paper explores human behavior in virtual networked communities, specifically individuals or groups' potential and expressive capacity to respond to internal and external stimuli, with assortative matching as a typical example. A modeling approach based on Multi-Agent Reinforcement Learning (MARL) is proposed, adding a multi-head attention function to the A3C algorithm to enhance learning effectiveness. This approach simulates human behavior in certain scenarios through various environmental parameter settings and agent action strategies. In our experiment, reinforcement learning is employed to serve specific agents that learn from environment status and competitor behaviors, optimizing strategies to achieve better results. The simulation includes individual and group levels, displaying possible paths to forming competitive advantages. This modeling approach provides a means for further analysis of the evolutionary dynamics of human behavior, communities, and organizations in various socioeconomic issues.",
        "published": "2022-11-08T01:19:14Z",
        "link": "http://arxiv.org/abs/2211.03936v3",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "A study on the ephemeral nature of knowledge shared within multiagent   systems",
        "authors": [
            "Sanjay Sarma Oruganti Venkata",
            "Ramviyas Parasuraman",
            "Ramana Pidaparti"
        ],
        "summary": "Achieving knowledge sharing within an artificial swarm system could lead to significant development in autonomous multiagent and robotic systems research and realize collective intelligence. However, this is difficult to achieve since there is no generic framework to transfer skills between agents other than a query-response-based approach. Moreover, natural living systems have a \"forgetfulness\" property for everything they learn. Analyzing such ephemeral nature (temporal memory properties of new knowledge gained) in artificial systems has never been studied in the literature. We propose a behavior tree-based framework to realize a query-response mechanism for transferring skills encoded as the condition-action control sub-flow of that portion of the knowledge between agents to fill this gap. We simulate a multiagent group with different initial knowledge on a foraging mission. While performing basic operations, each robot queries other robots to respond to an unknown condition. The responding robot shares the control actions by sharing a portion of the behavior tree that addresses the queries. Specifically, we investigate the ephemeral nature of the new knowledge gained through such a framework, where the knowledge gained by the agent is either limited due to memory or is forgotten over time. Our investigations show that knowledge grows proportionally with the duration of remembrance, which is trivial. However, we found minimal impact on knowledge growth due to memory. We compare these cases against a baseline that involved full knowledge pre-coded on all agents. We found that knowledge-sharing strived to match the baseline condition by sharing and achieving knowledge growth as a collective system.",
        "published": "2022-11-08T18:19:27Z",
        "link": "http://arxiv.org/abs/2211.04433v1",
        "categories": [
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Solving Collaborative Dec-POMDPs with Deep Reinforcement Learning   Heuristics",
        "authors": [
            "Nitsan Soffair"
        ],
        "summary": "WQMIX, QMIX, QTRAN, and VDN are SOTA algorithms for Dec-POMDP. All of them cannot solve complex agents' cooperation domains. We give an algorithm to solve such problems. In the first stage, we solve a single-agent problem and get a policy. In the second stage, we solve the multi-agent problem with the single-agent policy. SA2MA has a clear advantage over all competitors in complex agents' cooperative domains.",
        "published": "2022-11-09T08:11:16Z",
        "link": "http://arxiv.org/abs/2211.15411v6",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Deterministic Random Walk Model in NetLogo and the Identification of   Asymmetric Saturation Time in Random Graph",
        "authors": [
            "Ayan Chatterjee",
            "Qingtao Cao",
            "Amirhossein Sajadi",
            "Babak Ravandi"
        ],
        "summary": "Interactive programming environments are powerful tools for promoting innovative network thinking, teaching science of complexity, and exploring emergent phenomena. This paper reports on our recent development of the deterministic random walk model in NetLogo, a leading platform for computational thinking, eco-system thinking, and multi-agent cross-platform programming environment. The deterministic random walk is foundational to modeling dynamical processes on complex networks. Inspired by the temporal visualizations offered in NetLogo, we investigated the relationship between network topology and diffusion saturation time for the deterministic random walk model. Our analysis uncovers that in Erd\\H{o}s-R\\'{e}nyi graphs, the saturation time exhibits an asymmetric pattern with a considerable probability of occurrence. This behavior occurs when the hubs, defined as nodes with relatively higher number of connections, emerge in Erd\\H{o}s-R\\'{e}nyi graphs. Yet, our analysis yields that the hubs in Barab\\'{a}si-Albert model stabilize the the convergence time of the deterministic random walk model. These findings strongly suggest that depending on the dynamical process running on complex networks, complementing characteristics other than the degree need to be taken into account for considering a node as a hub. We have made our development open-source, available to the public at no cost at https://github.com/bravandi/NetLogo-Dynamical-Processes.",
        "published": "2022-11-09T20:47:03Z",
        "link": "http://arxiv.org/abs/2211.05189v2",
        "categories": [
            "cs.MA",
            "stat.AP"
        ]
    },
    {
        "title": "A Reliable and Low Latency Synchronizing Middleware for Co-simulation of   a Heterogeneous Multi-Robot Systems",
        "authors": [
            "Emon Dey",
            "Mikolaj Walczak",
            "Mohammad Saeid Anwar",
            "Nirmalya Roy"
        ],
        "summary": "Search and rescue, wildfire monitoring, and flood/hurricane impact assessment are mission-critical services for recent IoT networks. Communication synchronization, dependability, and minimal communication jitter are major simulation and system issues for the time-based physics-based ROS simulator, event-based network-based wireless simulator, and complex dynamics of mobile and heterogeneous IoT devices deployed in actual environments. Simulating a heterogeneous multi-robot system before deployment is difficult due to synchronizing physics (robotics) and network simulators. Due to its master-based architecture, most TCP/IP-based synchronization middlewares use ROS1. A real-time ROS2 architecture with masterless packet discovery synchronizes robotics and wireless network simulations. A velocity-aware Transmission Control Protocol (TCP) technique for ground and aerial robots using Data Distribution Service (DDS) publish-subscribe transport minimizes packet loss, synchronization, transmission, and communication jitters. Gazebo and NS-3 simulate and test. Simulator-agnostic middleware. LOS/NLOS and TCP/UDP protocols tested our ROS2-based synchronization middleware for packet loss probability and average latency. A thorough ablation research replaced NS-3 with EMANE, a real-time wireless network simulator, and masterless ROS2 with master-based ROS1. Finally, we tested network synchronization and jitter using one aerial drone (Duckiedrone) and two ground vehicles (TurtleBot3 Burger) on different terrains in masterless (ROS2) and master-enabled (ROS1) clusters. Our middleware shows that a large-scale IoT infrastructure with a diverse set of stationary and robotic devices can achieve low-latency communications (12% and 11% reduction in simulation and real) while meeting mission-critical application reliability (10% and 15% packet loss reduction) and high-fidelity requirements.",
        "published": "2022-11-10T06:04:10Z",
        "link": "http://arxiv.org/abs/2211.05359v1",
        "categories": [
            "cs.RO",
            "cs.MA",
            "cs.NI"
        ]
    },
    {
        "title": "Efficient Domain Coverage for Vehicles with Second-Order Dynamics via   Multi-Agent Reinforcement Learning",
        "authors": [
            "Xinyu Zhao",
            "Razvan C. Fetecau",
            "Mo Chen"
        ],
        "summary": "Collaborative autonomous multi-agent systems covering a specified area have many potential applications, such as UAV search and rescue, forest fire fighting, and real-time high-resolution monitoring. Traditional approaches for such coverage problems involve designing a model-based control policy based on sensor data. However, designing model-based controllers is challenging, and the state-of-the-art classical control policy still exhibits a large degree of sub-optimality. In this paper, we present a reinforcement learning (RL) approach for the multi-agent efficient domain coverage problem involving agents with second-order dynamics. Our approach is based on the Multi-Agent Proximal Policy Optimization Algorithm (MAPPO). Our proposed network architecture includes the incorporation of LSTM and self-attention, which allows the trained policy to adapt to a variable number of agents. Our trained policy significantly outperforms the state-of-the-art classical control policy. We demonstrate our proposed method in a variety of simulated experiments.",
        "published": "2022-11-11T01:59:12Z",
        "link": "http://arxiv.org/abs/2211.05952v4",
        "categories": [
            "cs.RO",
            "cs.LG",
            "cs.MA",
            "I.2.9, I.2.11"
        ]
    },
    {
        "title": "Fast model averaging via buffered states and first-order accelerated   optimization algorithms",
        "authors": [
            "Amir-Salar Esteki",
            "Hossein Moradian",
            "Solmaz S. Kia"
        ],
        "summary": "In this letter, we study the problem of accelerating reaching average consensus over connected graphs in a discrete-time communication setting. Literature has shown that consensus algorithms can be accelerated by increasing the graph connectivity or optimizing the weights agents place on the information received from their neighbors. Here, instead of altering the communication graph, we investigate two methods that use buffered states to accelerate reaching average consensus over a given graph. In the first method, we study how convergence rate of the well-known first-order Laplacian average consensus algorithm changes when agreement feedback is generated from buffered states. For this study, we obtain a sufficient condition on the ranges of buffered state that leads to faster convergence. In the second proposed method, we show how the average consensus problem can be cast as a convex optimization problem and solved by first-order accelerated optimization algorithms for strongly-convex cost functions. We construct an accelerated average consensus algorithm using the so-called Triple Momentum optimization algorithm. The first approach requires less global knowledge for choosing the step size, whereas the second one converges faster in our numerical results by using extra information from the graph topology. We demonstrate our results by implementing the proposed algorithms in a Gaussian Mixture Model (GMM) estimation problem used in sensor networks.",
        "published": "2022-11-11T02:12:51Z",
        "link": "http://arxiv.org/abs/2211.05959v1",
        "categories": [
            "math.OC",
            "cs.MA"
        ]
    },
    {
        "title": "Autotelic Reinforcement Learning in Multi-Agent Environments",
        "authors": [
            "Eleni Nisioti",
            "Elías Masquil",
            "Gautier Hamon",
            "and Clément Moulin-Frier"
        ],
        "summary": "In the intrinsically motivated skills acquisition problem, the agent is set in an environment without any pre-defined goals and needs to acquire an open-ended repertoire of skills. To do so the agent needs to be autotelic (deriving from the Greek auto (self) and telos (end goal)): it needs to generate goals and learn to achieve them following its own intrinsic motivation rather than external supervision. Autotelic agents have so far been considered in isolation. But many applications of open-ended learning entail groups of agents. Multi-agent environments pose an additional challenge for autotelic agents: to discover and master goals that require cooperation agents must pursue them simultaneously, but they have low chances of doing so if they sample them independently. In this work, we propose a new learning paradigm for modeling such settings, the Decentralized Intrinsically Motivated Skills Acquisition Problem (Dec-IMSAP), and employ it to solve cooperative navigation tasks. First, we show that agents setting their goals independently fail to master the full diversity of goals. Then, we show that a sufficient condition for achieving this is to ensure that a group aligns its goals, i.e., the agents pursue the same cooperative goal. Our empirical analysis shows that alignment enables specialization, an efficient strategy for cooperation. Finally, we introduce the Goal-coordination game, a fully-decentralized emergent communication algorithm, where goal alignment emerges from the maximization of individual rewards in multi-goal cooperative environments and show that it is able to reach equal performance to a centralized training baseline that guarantees aligned goals. To our knowledge, this is the first contribution addressing the problem of intrinsically motivated multi-agent goal exploration in a decentralized training paradigm.",
        "published": "2022-11-11T09:30:07Z",
        "link": "http://arxiv.org/abs/2211.06082v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Emergency action termination for immediate reaction in hierarchical   reinforcement learning",
        "authors": [
            "Michał Bortkiewicz",
            "Jakub Łyskawa",
            "Paweł Wawrzyński",
            "Mateusz Ostaszewski",
            "Artur Grudkowski",
            "Tomasz Trzciński"
        ],
        "summary": "Hierarchical decomposition of control is unavoidable in large dynamical systems. In reinforcement learning (RL), it is usually solved with subgoals defined at higher policy levels and achieved at lower policy levels. Reaching these goals can take a substantial amount of time, during which it is not verified whether they are still worth pursuing. However, due to the randomness of the environment, these goals may become obsolete. In this paper, we address this gap in the state-of-the-art approaches and propose a method in which the validity of higher-level actions (thus lower-level goals) is constantly verified at the higher level. If the actions, i.e. lower level goals, become inadequate, they are replaced by more appropriate ones. This way we combine the advantages of hierarchical RL, which is fast training, and flat RL, which is immediate reactivity. We study our approach experimentally on seven benchmark environments.",
        "published": "2022-11-11T16:56:02Z",
        "link": "http://arxiv.org/abs/2211.06351v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Distributed Average Consensus Over Noisy Communication Links in Directed   Graphs",
        "authors": [
            "Vivek Khatana",
            "Murti V. Salapaka"
        ],
        "summary": "Motivated by the needs of resiliency, scalability, and plug-and-play operation, distributed decision-making is becoming increasingly prevalent. The problem of achieving consensus in a multi-agent system is at the core of distributed decision-making. In this article, we study the problem of achieving average consensus over a directed multi-agent network when the communication links are corrupted with noise. We propose an algorithm where each agent updates its estimates based on the local mixing of information and adds its weighted noise-free initial information to its updates during every iteration. We demonstrate that with appropriately designed weights the agents achieve consensus under additive communication noise. We establish that when the communication links are noiseless the proposed algorithm moves towards consensus at a geometric rate. Under communication noise, we prove that the agent estimates reach a consensus value almost surely. We present numerical experiments to corroborate the efficacy of the proposed algorithm under different noise realizations and various algorithm parameters.",
        "published": "2022-11-11T21:49:08Z",
        "link": "http://arxiv.org/abs/2211.10334v1",
        "categories": [
            "cs.DC",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Multi-Agent Deep Reinforcement Learning for Efficient Passenger Delivery   in Urban Air Mobility",
        "authors": [
            "Chanyoung Park",
            "Soohyun Park",
            "Gyu Seon Kim",
            "Soyi Jung",
            "Jae-Hyun Kim",
            "Joongheon Kim"
        ],
        "summary": "It has been considered that urban air mobility (UAM), also known as drone-taxi or electrical vertical takeoff and landing (eVTOL), will play a key role in future transportation. By putting UAM into practical future transportation, several benefits can be realized, i.e., (i) the total travel time of passengers can be reduced compared to traditional transportation and (ii) there is no environmental pollution and no special labor costs to operate the system because electric batteries will be used in UAM system. However, there are various dynamic and uncertain factors in the flight environment, i.e., passenger sudden service requests, battery discharge, and collision among UAMs. Therefore, this paper proposes a novel cooperative MADRL algorithm based on centralized training and distributed execution (CTDE) concepts for reliable and efficient passenger delivery in UAM networks. According to the performance evaluation results, we confirm that the proposed algorithm outperforms other existing algorithms in terms of the number of serviced passengers increase (30%) and the waiting time per serviced passenger decrease (26%).",
        "published": "2022-11-13T12:30:48Z",
        "link": "http://arxiv.org/abs/2211.06890v2",
        "categories": [
            "cs.MA",
            "cs.LG"
        ]
    },
    {
        "title": "Robust Collaborative 3D Object Detection in Presence of Pose Errors",
        "authors": [
            "Yifan Lu",
            "Quanhao Li",
            "Baoan Liu",
            "Mehrdad Dianati",
            "Chen Feng",
            "Siheng Chen",
            "Yanfeng Wang"
        ],
        "summary": "Collaborative 3D object detection exploits information exchange among multiple agents to enhance accuracy of object detection in presence of sensor impairments such as occlusion. However, in practice, pose estimation errors due to imperfect localization would cause spatial message misalignment and significantly reduce the performance of collaboration. To alleviate adverse impacts of pose errors, we propose CoAlign, a novel hybrid collaboration framework that is robust to unknown pose errors. The proposed solution relies on a novel agent-object pose graph modeling to enhance pose consistency among collaborating agents. Furthermore, we adopt a multi-scale data fusion strategy to aggregate intermediate features at multiple spatial resolutions. Comparing with previous works, which require ground-truth pose for training supervision, our proposed CoAlign is more practical since it doesn't require any ground-truth pose supervision in the training and makes no specific assumptions on pose errors. Extensive evaluation of the proposed method is carried out on multiple datasets, certifying that CoAlign significantly reduce relative localization error and achieving the state of art detection performance when pose errors exist. Code are made available for the use of the research community at https://github.com/yifanlu0227/CoAlign.",
        "published": "2022-11-14T09:11:14Z",
        "link": "http://arxiv.org/abs/2211.07214v3",
        "categories": [
            "cs.CV",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Dynamic Collaborative Multi-Agent Reinforcement Learning Communication   for Autonomous Drone Reforestation",
        "authors": [
            "Philipp Dominic Siedler"
        ],
        "summary": "We approach autonomous drone-based reforestation with a collaborative multi-agent reinforcement learning (MARL) setup. Agents can communicate as part of a dynamically changing network. We explore collaboration and communication on the back of a high-impact problem. Forests are the main resource to control rising CO2 conditions. Unfortunately, the global forest volume is decreasing at an unprecedented rate. Many areas are too large and hard to traverse to plant new trees. To efficiently cover as much area as possible, here we propose a Graph Neural Network (GNN) based communication mechanism that enables collaboration. Agents can share location information on areas needing reforestation, which increases viewed area and planted tree count. We compare our proposed communication mechanism with a multi-agent baseline without the ability to communicate. Results show how communication enables collaboration and increases collective performance, planting precision and the risk-taking propensity of individual agents.",
        "published": "2022-11-14T13:25:22Z",
        "link": "http://arxiv.org/abs/2211.15414v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "A Robust Dynamic Average Consensus Algorithm that Ensures both   Differential Privacy and Accurate Convergence",
        "authors": [
            "Yongqiang Wang"
        ],
        "summary": "We propose a new dynamic average consensus algorithm that is robust to information-sharing noise arising from differential-privacy design. Not only is dynamic average consensus widely used in cooperative control and distributed tracking, it is also a fundamental building block in numerous distributed computation algorithms such as multi-agent optimization and distributed Nash equilibrium seeking. We propose a new dynamic average consensus algorithm that is robust to persistent and independent information-sharing noise added for the purpose of differential-privacy protection. In fact, the algorithm can ensure both provable convergence to the exact average reference signal and rigorous epsilon-differential privacy (even when the number of iterations tends to infinity), which, to our knowledge, has not been achieved before in average consensus algorithms. Given that channel noise in communication can be viewed as a special case of differential-privacy noise, the algorithm can also be used to counteract communication imperfections. Numerical simulation results confirm the effectiveness of the proposed approach.",
        "published": "2022-11-14T22:52:23Z",
        "link": "http://arxiv.org/abs/2211.07791v6",
        "categories": [
            "cs.CR",
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "Linear Convergent Distributed Nash Equilibrium Seeking with Compression",
        "authors": [
            "Xiaomeng Chen",
            "Yuchi Wu",
            "Xinlei Yi",
            "Minyi Huang",
            "Ling Shi"
        ],
        "summary": "Information compression techniques are majorly employed to address the concern of reducing communication cost over peer-to-peer links. In this paper, we investigate distributed Nash equilibrium (NE) seeking problems in a class of non-cooperative games over directed graphs with information compression. To improve communication efficiency, a compressed distributed NE seeking (C-DNES) algorithm is proposed to obtain a NE for games, where the differences between decision vectors and their estimates are compressed. The proposed algorithm is compatible with a general class of compression operators, including both unbiased and biased compressors. Moreover, our approach only requires the adjacency matrix of the directed graph to be row-stochastic, in contrast to past works that relied on balancedness or specific global network parameters. It is shown that C-DNES not only inherits the advantages of conventional distributed NE algorithms, achieving linear convergence rate for games with restricted strongly monotone mappings, but also saves communication costs in terms of transmitted bits. Finally, numerical simulations illustrate the advantages of C-DNES in saving communication cost by an order of magnitude under different compressors.",
        "published": "2022-11-15T02:27:17Z",
        "link": "http://arxiv.org/abs/2211.07849v2",
        "categories": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Explainable Action Advising for Multi-Agent Reinforcement Learning",
        "authors": [
            "Yue Guo",
            "Joseph Campbell",
            "Simon Stepputtis",
            "Ruiyu Li",
            "Dana Hughes",
            "Fei Fang",
            "Katia Sycara"
        ],
        "summary": "Action advising is a knowledge transfer technique for reinforcement learning based on the teacher-student paradigm. An expert teacher provides advice to a student during training in order to improve the student's sample efficiency and policy performance. Such advice is commonly given in the form of state-action pairs. However, it makes it difficult for the student to reason with and apply to novel states. We introduce Explainable Action Advising, in which the teacher provides action advice as well as associated explanations indicating why the action was chosen. This allows the student to self-reflect on what it has learned, enabling advice generalization and leading to improved sample efficiency and learning performance - even in environments where the teacher is sub-optimal. We empirically show that our framework is effective in both single-agent and multi-agent scenarios, yielding improved policy returns and convergence rates when compared to state-of-the-art methods",
        "published": "2022-11-15T04:15:03Z",
        "link": "http://arxiv.org/abs/2211.07882v3",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Who Reviews The Reviewers? A Multi-Level Jury Problem",
        "authors": [
            "Ben Abramowitz",
            "Omer Lev",
            "Nicholas Mattei"
        ],
        "summary": "We consider the problem of determining a binary ground truth using advice from a group of independent reviewers (experts) who express their guess about a ground truth correctly with some independent probability (competence). In this setting, when all reviewers are competent (competence greater than one-half), the Condorcet Jury Theorem tells us that adding more reviewers increases the overall accuracy, and if all competences are known, then there exists an optimal weighting of the reviewers. However, in practical settings, reviewers may be noisy or incompetent, i.e., competence below half, and the number of experts may be small, so the asymptotic Condorcet Jury Theorem is not practically relevant. In such cases we explore appointing one or more chairs (judges) who determine the weight of each reviewer for aggregation, creating multiple levels. However, these chairs may be unable to correctly identify the competence of the reviewers they oversee, and therefore unable to compute the optimal weighting. We give conditions when a set of chairs is able to weight the reviewers optimally, and depending on the competence distribution of the agents, give results about when it is better to have more chairs or more reviewers. Through numerical simulations we show that in some cases it is better to have more chairs, but in many cases it is better to have more reviewers.",
        "published": "2022-11-15T20:47:14Z",
        "link": "http://arxiv.org/abs/2211.08494v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "cs.SI",
            "econ.TH"
        ]
    },
    {
        "title": "Social Mechanism Design: Making Maximally Acceptable Decisions",
        "authors": [
            "Ben Abramowitz",
            "Nicholas Mattei"
        ],
        "summary": "Agents care not only about the outcomes of collective decisions but also about how decisions are made. In many cases, both the outcome and the procedure affect whether agents see a decision as legitimate, justifiable, or acceptable. We propose a novel model for collective decisions that takes into account both the preferences of the agents and their higher order concerns about the process of preference aggregation. To this end we (1) propose natural, plausible preference structures and establish key properties thereof, (2) develop mechanisms for aggregating these preferences to maximize the acceptability of decisions, and (3) characterize the performance of our acceptance-maximizing mechanisms. We apply our general approach to the specific setting of dichotomous choice, and compare the worst-case rates of acceptance achievable among populations of agents of different types. We also show in the special case of rule selection, i.e., amendment procedures, the method proposed by Abramowitz, Shapiro, and Talmon (2021) achieves universal acceptance with certain agent types.",
        "published": "2022-11-15T20:59:34Z",
        "link": "http://arxiv.org/abs/2211.08501v2",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "The scaling of goals via homeostasis: an evolutionary simulation,   experiment and analysis",
        "authors": [
            "Leo Pio-Lopez",
            "Johanna Bischof",
            "Jennifer V. LaPalme",
            "Michael Levin"
        ],
        "summary": "All cognitive agents are composite beings. Specifically, complex living agents consist of cells, which are themselves competent sub-agents navigating physiological and metabolic spaces. Behavior science, evolutionary developmental biology, and the field of machine intelligence all seek an answer to the scaling of biological cognition: what evolutionary dynamics enable individual cells to integrate their activities to result in the emergence of a novel, higher-level intelligence that has goals and competencies that belong to it and not to its parts? Here, we report the results of simulations based on the TAME framework, which proposes that evolution pivoted the collective intelligence of cells during morphogenesis of the body into traditional behavioral intelligence by scaling up the goal states at the center of homeostatic processes. We tested the hypothesis that a minimal evolutionary framework is sufficient for small, low-level setpoints of metabolic homeostasis in cells to scale up into collectives (tissues) which solve a problem in morphospace: the organization of a body-wide positional information axis (the classic French Flag problem). We found that these emergent morphogenetic agents exhibit a number of predicted features, including the use of stress propagation dynamics to achieve its target morphology as well as the ability to recover from perturbation (robustness) and long-term stability (even though neither of these was directly selected for). Moreover we observed unexpected behavior of sudden remodeling long after the system stabilizes. We tested this prediction in a biological system - regenerating planaria - and observed a very similar phenomenon. We propose that this system is a first step toward a quantitative understanding of how evolution scales minimal goal-directed behavior (homeostatic loops) into higher-level problem-solving agents in morphogenetic and other spaces.",
        "published": "2022-11-15T21:48:44Z",
        "link": "http://arxiv.org/abs/2211.08522v1",
        "categories": [
            "q-bio.PE",
            "cs.MA",
            "cs.NE",
            "q-bio.TO",
            "J.3"
        ]
    },
    {
        "title": "Cross-inhibition leads to group consensus despite the presence of   strongly opinionated minorities and asocial behaviour",
        "authors": [
            "Andreagiovanni Reina",
            "Raina Zakir",
            "Giulia De Masi",
            "Eliseo Ferrante"
        ],
        "summary": "Strongly opinionated minorities can have a dramatic impact on the opinion dynamics of a large population. Two factions of inflexible minorities, polarised into two competing opinions, could lead the entire population to persistent indecision. Equivalently, populations can remain undecided when individuals sporadically change their opinion based on individual information rather than social information. Our analysis compares the cross-inhibition model with the voter model for decisions between equally good alternatives, and with the weighted voter model for decisions among alternatives characterised by different qualities. Here we show that cross-inhibition, differently from the other two models, is a simple mechanism, ubiquitous in collective biological systems, that allows the population to reach a stable majority for one alternative even in the presence of asocial behaviour. The results predicted by the mean-field models are confirmed by experiments with swarms of 100 locally interacting robots. This work suggests an answer to the longstanding question of why inhibitory signals are widespread in natural systems of collective decision making, and, at the same time, it proposes an efficient mechanism for designing resilient swarms of minimalistic robots.",
        "published": "2022-11-17T13:45:39Z",
        "link": "http://arxiv.org/abs/2211.09531v2",
        "categories": [
            "physics.bio-ph",
            "cs.MA",
            "math.AP",
            "q-bio.PE"
        ]
    },
    {
        "title": "Pandering in a Flexible Representative Democracy",
        "authors": [
            "Xiaolin Sun",
            "Jacob Masur",
            "Ben Abramowitz",
            "Nicholas Mattei",
            "Zizhan Zheng"
        ],
        "summary": "In representative democracies, the election of new representatives in regular election cycles is meant to prevent corruption and other misbehavior by elected officials and to keep them accountable in service of the ``will of the people.\" This democratic ideal can be undermined when candidates are dishonest when campaigning for election over these multiple cycles or rounds of voting. Much of the work on COMSOC to date has investigated strategic actions in only a single round. We introduce a novel formal model of \\emph{pandering}, or strategic preference reporting by candidates seeking to be elected, and examine the resilience of two democratic voting systems to pandering within a single round and across multiple rounds. The two voting systems we compare are Representative Democracy (RD) and Flexible Representative Democracy (FRD). For each voting system, our analysis centers on the types of strategies candidates employ and how voters update their views of candidates based on how the candidates have pandered in the past. We provide theoretical results on the complexity of pandering in our setting for a single cycle, formulate our problem for multiple cycles as a Markov Decision Process, and use reinforcement learning to study the effects of pandering by both single candidates and groups of candidates across a number of rounds.",
        "published": "2022-11-18T02:19:28Z",
        "link": "http://arxiv.org/abs/2211.09986v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.CY",
            "cs.GT",
            "cs.LG"
        ]
    },
    {
        "title": "Credit-cognisant reinforcement learning for multi-agent cooperation",
        "authors": [
            "F. Bredell",
            "H. A. Engelbrecht",
            "J. C. Schoeman"
        ],
        "summary": "Traditional multi-agent reinforcement learning (MARL) algorithms, such as independent Q-learning, struggle when presented with partially observable scenarios, and where agents are required to develop delicate action sequences. This is often the result of the reward for a good action only being available after other agents have taken theirs, and these actions are not credited accordingly. Recurrent neural networks have proven to be a viable solution strategy for solving these types of problems, resulting in significant performance increase when compared to other methods. In this paper, we explore a different approach and focus on the experiences used to update the action-value functions of each agent. We introduce the concept of credit-cognisant rewards (CCRs), which allows an agent to perceive the effect its actions had on the environment as well as on its co-agents. We show that by manipulating these experiences and constructing the reward contained within them to include the rewards received by all the agents within the same action sequence, we are able to improve significantly on the performance of independent deep Q-learning as well as deep recurrent Q-learning. We evaluate and test the performance of CCRs when applied to deep reinforcement learning techniques at the hands of a simplified version of the popular card game Hanabi.",
        "published": "2022-11-18T09:00:25Z",
        "link": "http://arxiv.org/abs/2211.10100v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Promoting Social Behaviour in Reducing Peak Electricity Consumption   Using Multi-Agent Systems",
        "authors": [
            "Nathan A. Brooks",
            "Simon T. Powers",
            "James M. Borg"
        ],
        "summary": "As we transition to renewable energy sources, addressing their inflexibility during peak demand becomes crucial. It is therefore important to reduce the peak load placed on our energy system. For households, this entails spreading high-power appliance usage like dishwashers and washing machines throughout the day. Traditional approaches to spreading out usage have relied on differential pricing set by a centralised utility company, but this has been ineffective. Our previous research investigated a decentralised mechanism where agents receive an initial allocation of time-slots to use their appliances, which they can exchange with others. This was found to be an effective approach to reducing the peak load when we introduced social capital, the tracking of favours, to incentivise agents to accept exchanges that do not immediately benefit them. This system encouraged self-interested agents to learn socially beneficial behaviour to earn social capital that they could later use to improve their own performance. In this paper we expand this work by implementing real world household appliance usage data to ensure that our mechanism could adapt to the challenging demand needs of real households. We also demonstrate how smaller and more diverse populations can optimise more effectively than larger community energy systems.",
        "published": "2022-11-18T12:41:57Z",
        "link": "http://arxiv.org/abs/2211.10198v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "$α$-Rank-Collections: Analyzing Expected Strategic Behavior with   Uncertain Utilities",
        "authors": [
            "Fabian R. Pieroth",
            "Martin Bichler"
        ],
        "summary": "Game theory relies heavily on the availability of cardinal utility functions, but in fields such as matching markets, only ordinal preferences are typically elicited. The literature focuses on mechanisms with simple dominant strategies, but many real-world applications lack dominant strategies, making the intensity of preferences between outcomes important for determining strategies. Even though precise information about cardinal utilities is not available, some data about the likelihood of utility functions is often accessible. We propose to use Bayesian games to formalize uncertainty about the decision-makers' utilities by viewing them as a collection of normal-form games. Instead of searching for the Bayes-Nash equilibrium, we study how uncertainty in utilities is reflected in uncertainty of strategic play. To do this, we introduce a novel solution concept called $\\alpha$-Rank-collections, which extends $\\alpha$-Rank to Bayesian games. This allows us to analyze strategic play in, for example, non-strategyproof matching markets, for which appropriate solution concepts are currently lacking. $\\alpha$-Rank-collections characterize the expected probability of encountering a certain strategy profile under replicator dynamics in the long run, rather than predicting a specific equilibrium strategy profile. We experimentally evaluate $\\alpha$-Rank-collections using instances of the Boston mechanism, finding that our solution concept provides more nuanced predictions compared to Bayes-Nash equilibria. Additionally, we prove that $\\alpha$-Rank-collections are invariant to positive affine transformations, a standard property for a solution concept, and are efficient to approximate.",
        "published": "2022-11-18T16:17:27Z",
        "link": "http://arxiv.org/abs/2211.10317v4",
        "categories": [
            "cs.GT",
            "cs.MA",
            "econ.TH"
        ]
    },
    {
        "title": "Social Diversity Reduces the Complexity and Cost of Fostering Fairness",
        "authors": [
            "Theodor Cimpeanu",
            "Alessandro Di Stefano",
            "Cedric Perret",
            "The Anh Han"
        ],
        "summary": "Institutions and investors are constantly faced with the challenge of appropriately distributing endowments. No budget is limitless and optimising overall spending without sacrificing positive outcomes has been approached and resolved using several heuristics. To date, prior works have failed to consider how to encourage fairness in a population where social diversity is ubiquitous, and in which investors can only partially observe the population. Herein, by incorporating social diversity in the Ultimatum game through heterogeneous graphs, we investigate the effects of several interference mechanisms which assume incomplete information and flexible standards of fairness. We quantify the role of diversity and show how it reduces the need for information gathering, allowing us to relax a strict, costly interference process. Furthermore, we find that the influence of certain individuals, expressed by different network centrality measures, can be exploited to further reduce spending if minimal fairness requirements are lowered. Our results indicate that diversity changes and opens up novel mechanisms available to institutions wishing to promote fairness. Overall, our analysis provides novel insights to guide institutional policies in socially diverse complex systems.",
        "published": "2022-11-18T21:58:35Z",
        "link": "http://arxiv.org/abs/2211.10517v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "math.DS",
            "math.OC",
            "nlin.AO"
        ]
    },
    {
        "title": "Air-Aided Communication Between Ground Assets in a Poisson Forest",
        "authors": [
            "Juan David Pabon",
            "Shaikha Alkandari",
            "Matthew C. Valenti",
            "Xi Yu"
        ],
        "summary": "Ground assets deployed in a cluttered environment with randomized obstacles (e.g., a forest) may experience line of sight (LoS) obstruction due to those obstacles. Air assets can be deployed in the vicinity to aid the communication by establishing two-hop paths between the ground assets. Obstacles that are taller than a position-dependent critical height may still obstruct the LoS between a ground asset and an air asset. In this paper, we provide an analytical framework for computing the probability of obtaining a LoS path in a Poisson forest. Given the locations and heights of a ground asset and an air asset, we establish the critical height, which is a function of distance. To account for this dependence on distance, the blocking is modeled as an inhomogenous Poisson point process, and the LoS probability is its void probability. Examples and closed-form expressions are provided for two obstruction height distributions: uniform and truncated Gaussian. The examples are validated through simulation. Additionally, the end-to-end throughput is determined and shown to be a metric that balances communication distance with the impact of LoS blockage. Throughput is used to determine the range at which it is better to relay communications through the air asset, and, when the air asset is deployed, its optimal height.",
        "published": "2022-11-19T05:13:03Z",
        "link": "http://arxiv.org/abs/2211.10589v1",
        "categories": [
            "cs.RO",
            "cs.ET",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "An adaptive route choice model for integrated fixed and flexible transit   systems",
        "authors": [
            "David Leffler",
            "Wilco Burghout",
            "Oded Cats",
            "Erik Jenelius"
        ],
        "summary": "Over the past decade, there has been a surge of interest in the transport community in the application of agent-based simulation models to evaluate flexible transit solutions characterized by different degrees of short-term flexibility in routing and scheduling. A central modeling decision in the development of an agent-based simulation model for the evaluation of flexible transit is how one chooses to represent the mode- and route-choices of travelers. The real-time adaptive behavior of travelers is intuitively important to model in the presence of a flexible transit service, where the routing and scheduling of vehicles is highly dependent on supply-demand dynamics at a closer to real-time temporal resolution. We propose a utility-based transit route-choice model with representation of within-day adaptive travel behavior and between-day learning where station-based fixed-transit, flexible-transit, and active-mode alternatives may be dynamically combined in a single path. To enable experimentation, this route-choice model is implemented within an agent-based dynamic public transit simulation framework. Model properties are first explored in a choice between fixed- and flexible-transit modes for a toy network. The framework is then applied to illustrate level-of-service trade-offs and analyze traveler mode choices within a mixed fixed- and flexible transit system in a case study based on a real-life branched transit service in Stockholm, Sweden.",
        "published": "2022-11-19T21:24:21Z",
        "link": "http://arxiv.org/abs/2211.10802v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Persistence of the Omicron variant of SARS-CoV-2 in Australia: The   impact of fluctuating social distancing",
        "authors": [
            "Sheryl L. Chang",
            "Quang Dang Nguyen",
            "Alexandra Martiniuk",
            "Vitali Sintchenko",
            "Tania C. Sorrell",
            "Mikhail Prokopenko"
        ],
        "summary": "We modelled emergence and spread of the Omicron variant of SARS-CoV-2 in Australia between December 2021 and June 2022. This pandemic stage exhibited a diverse epidemiological profile with emergence of co-circulating sub-lineages of Omicron, further complicated by differences in social distancing behaviour which varied over time. Our study delineated distinct phases of the Omicron-associated pandemic stage, and retrospectively quantified the adoption of social distancing measures, fluctuating over different time periods in response to the observable incidence dynamics. We also modelled the corresponding disease burden, in terms of hospitalisations, intensive care unit occupancy, and mortality. Supported by good agreement between simulated and actual health data, our study revealed that the nonlinear dynamics observed in the daily incidence and disease burden were determined not only by introduction of sub-lineages of Omicron, but also by the fluctuating adoption of social distancing measures. Our high-resolution model can be used in design and evaluation of public health interventions during future crises.",
        "published": "2022-11-20T12:22:13Z",
        "link": "http://arxiv.org/abs/2211.10965v2",
        "categories": [
            "q-bio.PE",
            "cs.MA",
            "92D30, 93A16",
            "J.3; I.6"
        ]
    },
    {
        "title": "Learning Cooperative Oversubscription for Cloud by Chance-Constrained   Multi-Agent Reinforcement Learning",
        "authors": [
            "Junjie Sheng",
            "Lu Wang",
            "Fangkai Yang",
            "Bo Qiao",
            "Hang Dong",
            "Xiangfeng Wang",
            "Bo Jin",
            "Jun Wang",
            "Si Qin",
            "Saravan Rajmohan",
            "Qingwei Lin",
            "Dongmei Zhang"
        ],
        "summary": "Oversubscription is a common practice for improving cloud resource utilization. It allows the cloud service provider to sell more resources than the physical limit, assuming not all users would fully utilize the resources simultaneously. However, how to design an oversubscription policy that improves utilization while satisfying the some safety constraints remains an open problem. Existing methods and industrial practices are over-conservative, ignoring the coordination of diverse resource usage patterns and probabilistic constraints. To address these two limitations, this paper formulates the oversubscription for cloud as a chance-constrained optimization problem and propose an effective Chance Constrained Multi-Agent Reinforcement Learning (C2MARL) method to solve this problem. Specifically, C2MARL reduces the number of constraints by considering their upper bounds and leverages a multi-agent reinforcement learning paradigm to learn a safe and optimal coordination policy. We evaluate our C2MARL on an internal cloud platform and public cloud datasets. Experiments show that our C2MARL outperforms existing methods in improving utilization ($20\\%\\sim 86\\%$) under different levels of safety constraints.",
        "published": "2022-11-21T07:00:09Z",
        "link": "http://arxiv.org/abs/2211.11759v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Methodology for Holistic Reference Modeling in Systems Engineering",
        "authors": [
            "Dominik Ascher",
            "Erik Heiland",
            "Diana Schnell",
            "Peter Hillmann",
            "Andreas Karcher"
        ],
        "summary": "Models in face of increasing complexity support development of new systems and enterprises. For an efficient procedure, reference models are adapted in order to reach a solution with les overhead which covers all necessary aspects. Here, a key challenge is applying a consistent methodology for the descriptions of such reference designs. This paper presents a holistic approach to describe reference models across different views and levels. Modeling stretches from the requirements and capabilities over their subdivision to services and components up to the realization in processes and data structures. Benefits include an end-to-end traceability of the capability coverage with performance parameters considered already at the starting point of the reference design. This enables focused development while considering design constraints and potential bottlenecks. We demonstrate the approach on the example of the development of a smart robot. Here, our methodology highly supports transferability of designs for the development of further systems.",
        "published": "2022-11-21T13:41:07Z",
        "link": "http://arxiv.org/abs/2211.11453v1",
        "categories": [
            "cs.SE",
            "cs.CV",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Backdoor Attacks on Multiagent Collaborative Systems",
        "authors": [
            "Shuo Chen",
            "Yue Qiu",
            "Jie Zhang"
        ],
        "summary": "Backdoor attacks on reinforcement learning implant a backdoor in a victim agent's policy. Once the victim observes the trigger signal, it will switch to the abnormal mode and fail its task. Most of the attacks assume the adversary can arbitrarily modify the victim's observations, which may not be practical. One work proposes to let one adversary agent use its actions to affect its opponent in two-agent competitive games, so that the opponent quickly fails after observing certain trigger actions. However, in multiagent collaborative systems, agents may not always be able to observe others. When and how much the adversary agent can affect others are uncertain, and we want the adversary agent to trigger others for as few times as possible. To solve this problem, we first design a novel training framework to produce auxiliary rewards that measure the extent to which the other agents'observations being affected. Then we use the auxiliary rewards to train a trigger policy which enables the adversary agent to efficiently affect the others' observations. Given these affected observations, we further train the other agents to perform abnormally. Extensive experiments demonstrate that the proposed method enables the adversary agent to lure the others into the abnormal mode with only a few actions.",
        "published": "2022-11-21T13:44:13Z",
        "link": "http://arxiv.org/abs/2211.11455v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Improving Multimodal Interactive Agents with Reinforcement Learning from   Human Feedback",
        "authors": [
            "Josh Abramson",
            "Arun Ahuja",
            "Federico Carnevale",
            "Petko Georgiev",
            "Alex Goldin",
            "Alden Hung",
            "Jessica Landon",
            "Jirka Lhotka",
            "Timothy Lillicrap",
            "Alistair Muldal",
            "George Powell",
            "Adam Santoro",
            "Guy Scully",
            "Sanjana Srivastava",
            "Tamara von Glehn",
            "Greg Wayne",
            "Nathaniel Wong",
            "Chen Yan",
            "Rui Zhu"
        ],
        "summary": "An important goal in artificial intelligence is to create agents that can both interact naturally with humans and learn from their feedback. Here we demonstrate how to use reinforcement learning from human feedback (RLHF) to improve upon simulated, embodied agents trained to a base level of competency with imitation learning. First, we collected data of humans interacting with agents in a simulated 3D world. We then asked annotators to record moments where they believed that agents either progressed toward or regressed from their human-instructed goal. Using this annotation data we leveraged a novel method - which we call \"Inter-temporal Bradley-Terry\" (IBT) modelling - to build a reward model that captures human judgments. Agents trained to optimise rewards delivered from IBT reward models improved with respect to all of our metrics, including subsequent human judgment during live interactions with agents. Altogether our results demonstrate how one can successfully leverage human judgments to improve agent behaviour, allowing us to use reinforcement learning in complex, embodied domains without programmatic reward functions. Videos of agent behaviour may be found at https://youtu.be/v_Z9F2_eKk4.",
        "published": "2022-11-21T16:00:31Z",
        "link": "http://arxiv.org/abs/2211.11602v1",
        "categories": [
            "cs.LG",
            "cs.HC",
            "cs.MA"
        ]
    },
    {
        "title": "TinyQMIX: Distributed Access Control for mMTC via Multi-agent   Reinforcement Learning",
        "authors": [
            "Tien Thanh Le",
            "Yusheng Ji",
            "John C. S Lui"
        ],
        "summary": "Distributed access control is a crucial component for massive machine type communication (mMTC). In this communication scenario, centralized resource allocation is not scalable because resource configurations have to be sent frequently from the base station to a massive number of devices. We investigate distributed reinforcement learning for resource selection without relying on centralized control. Another important feature of mMTC is the sporadic and dynamic change of traffic. Existing studies on distributed access control assume that traffic load is static or they are able to gradually adapt to the dynamic traffic. We minimize the adaptation period by training TinyQMIX, which is a lightweight multi-agent deep reinforcement learning model, to learn a distributed wireless resource selection policy under various traffic patterns before deployment. Therefore, the trained agents are able to quickly adapt to dynamic traffic and provide low access delay. Numerical results are presented to support our claims.",
        "published": "2022-11-21T18:09:10Z",
        "link": "http://arxiv.org/abs/2211.11692v1",
        "categories": [
            "cs.NI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Value-based CTDE Methods in Symmetric Two-team Markov Game: from   Cooperation to Team Competition",
        "authors": [
            "Pascal Leroy",
            "Jonathan Pisane",
            "Damien Ernst"
        ],
        "summary": "In this paper, we identify the best learning scenario to train a team of agents to compete against multiple possible strategies of opposing teams. We evaluate cooperative value-based methods in a mixed cooperative-competitive environment. We restrict ourselves to the case of a symmetric, partially observable, two-team Markov game. We selected three training methods based on the centralised training and decentralised execution (CTDE) paradigm: QMIX, MAVEN and QVMix. For each method, we considered three learning scenarios differentiated by the variety of team policies encountered during training. For our experiments, we modified the StarCraft Multi-Agent Challenge environment to create competitive environments where both teams could learn and compete simultaneously. Our results suggest that training against multiple evolving strategies achieves the best results when, for scoring their performances, teams are faced with several strategies.",
        "published": "2022-11-21T22:25:55Z",
        "link": "http://arxiv.org/abs/2211.11886v2",
        "categories": [
            "cs.LG",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Decision-making with Speculative Opponent Models",
        "authors": [
            "Jing Sun",
            "Shuo Chen",
            "Cong Zhang",
            "Yining Ma",
            "Jie Zhang"
        ],
        "summary": "Opponent modelling has proven effective in enhancing the decision-making of the controlled agent by constructing models of opponent agents. However, existing methods often rely on access to the observations and actions of opponents, a requirement that is infeasible when such information is either unobservable or challenging to obtain. To address this issue, we introduce Distributional Opponent-aided Multi-agent Actor-Critic (DOMAC), the first speculative opponent modelling algorithm that relies solely on local information (i.e., the controlled agent's observations, actions, and rewards). Specifically, the actor maintains a speculated belief about the opponents using the tailored speculative opponent models that predict the opponents' actions using only local information. Moreover, DOMAC features distributional critic models that estimate the return distribution of the actor's policy, yielding a more fine-grained assessment of the actor's quality. This thus more effectively guides the training of the speculative opponent models that the actor depends upon. Furthermore, we formally derive a policy gradient theorem with the proposed opponent models. Extensive experiments under eight different challenging multi-agent benchmark tasks within the MPE, Pommerman and StarCraft Multiagent Challenge (SMAC) demonstrate that our DOMAC successfully models opponents' behaviours and delivers superior performance against state-of-the-art methods with a faster convergence speed.",
        "published": "2022-11-22T01:29:47Z",
        "link": "http://arxiv.org/abs/2211.11940v3",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Greedy based Value Representation for Optimal Coordination in   Multi-agent Reinforcement Learning",
        "authors": [
            "Lipeng Wan",
            "Zeyang Liu",
            "Xingyu Chen",
            "Xuguang Lan",
            "Nanning Zheng"
        ],
        "summary": "Due to the representation limitation of the joint Q value function, multi-agent reinforcement learning methods with linear value decomposition (LVD) or monotonic value decomposition (MVD) suffer from relative overgeneralization. As a result, they can not ensure optimal consistency (i.e., the correspondence between individual greedy actions and the maximal true Q value). In this paper, we derive the expression of the joint Q value function of LVD and MVD. According to the expression, we draw a transition diagram, where each self-transition node (STN) is a possible convergence. To ensure optimal consistency, the optimal node is required to be the unique STN. Therefore, we propose the greedy-based value representation (GVR), which turns the optimal node into an STN via inferior target shaping and further eliminates the non-optimal STNs via superior experience replay. In addition, GVR achieves an adaptive trade-off between optimality and stability. Our method outperforms state-of-the-art baselines in experiments on various benchmarks. Theoretical proofs and empirical results on matrix games demonstrate that GVR ensures optimal consistency under sufficient exploration.",
        "published": "2022-11-22T08:14:50Z",
        "link": "http://arxiv.org/abs/2211.12075v1",
        "categories": [
            "cs.MA",
            "cs.LG"
        ]
    },
    {
        "title": "\"Coherent Mode\" for the World's Public Square",
        "authors": [
            "Colin Megill",
            "Elizabeth Barry",
            "Christopher Small"
        ],
        "summary": "Systems for large scale deliberation have resolved polarized issues and shifted agenda setting into the public's hands. These systems integrate bridging-based ranking algorithms - including group informed consensus implemented in Polis and the continuous matrix factorization approach implemented by Twitter Birdwatch - making it possible to highlight statements which enjoy broad support from a diversity of opinion groups.   Polis has been productively employed to foster more constructive political deliberation at nation scale in law making exercises. Twitter Birdwatch is implemented with the intention of addressing misinformation in the global public square. From one perspective, Twitter Birdwatch can be viewed as an anti-misinformation system which has deliberative aspects. But it can also be viewed as a first step towards a generalized deliberative system, using Twitter's misinformation problem as a proving ground.   In this paper, we propose that Twitter could adapt Birdwatch to produce maps of public opinion. We describe a system in five parts for generalizing Birdwatch: activation of a deliberative system and topic selection, population sampling and the role of expert networks, deliberation, reporting interpretable results and finally distribution of the results to the public and those in power.",
        "published": "2022-11-22T20:37:32Z",
        "link": "http://arxiv.org/abs/2211.12571v1",
        "categories": [
            "cs.SI",
            "cs.HC",
            "cs.MA"
        ]
    },
    {
        "title": "A Mixed-Method Approach to Determining Contact Matrices in the Cox's   Bazar Refugee Settlement",
        "authors": [
            "Joseph Walker",
            "Joseph Aylett-Bullock",
            "Difu Shi",
            "Allen Gidraf Kahindo Maina",
            "Egmond Samir Evers",
            "Sandra Harlass",
            "Frank Krauss"
        ],
        "summary": "Contact matrices are an important ingredient in age-structured epidemic models to inform the simulated spread of the disease between sub-groups of the population. These matrices are generally derived using resource-intensive diary-based surveys and few exist in the Global South or tailored to vulnerable populations. In particular, no contact matrices exist for refugee settlements - locations under-served by epidemic models in general. In this paper we present a novel, mixed-method approach, for deriving contact matrices in populations which combines a lightweight, rapidly deployable, survey with an agent-based model of the population informed by census and behavioural data. We use this method to derive the first set of contact matrices for the Cox's Bazar refugee settlement in Bangladesh. The matrices from the refugee settlement show strong banding effects due to different age cut-offs in attendance at certain venues, such as distribution centres and religious sites, as well as the important contribution of the demographic profile of the settlement which was encoded in the model. These can have significant implications to the modelled disease dynamics. To validate our approach, we also apply our method to the population of the UK and compare our derived matrices against well-known contact matrices previously collected using traditional approaches. Overall, our findings demonstrate that our mixed-method approach can address some of the challenges of both the traditional and previously proposed agent-based approaches to deriving contact matrices, and has the potential to be rolled-out in other resource-constrained environments. This work therefore contributes to a broader aim of developing new methods and mechanisms of data collection for modelling disease spread in refugee and IDP settlements and better serving these vulnerable communities.",
        "published": "2022-11-22T21:53:33Z",
        "link": "http://arxiv.org/abs/2212.01334v1",
        "categories": [
            "physics.soc-ph",
            "cs.CY",
            "cs.MA",
            "cs.SI",
            "q-bio.PE"
        ]
    },
    {
        "title": "Contrastive Identity-Aware Learning for Multi-Agent Value Decomposition",
        "authors": [
            "Shunyu Liu",
            "Yihe Zhou",
            "Jie Song",
            "Tongya Zheng",
            "Kaixuan Chen",
            "Tongtian Zhu",
            "Zunlei Feng",
            "Mingli Song"
        ],
        "summary": "Value Decomposition (VD) aims to deduce the contributions of agents for decentralized policies in the presence of only global rewards, and has recently emerged as a powerful credit assignment paradigm for tackling cooperative Multi-Agent Reinforcement Learning (MARL) problems. One of the main challenges in VD is to promote diverse behaviors among agents, while existing methods directly encourage the diversity of learned agent networks with various strategies. However, we argue that these dedicated designs for agent networks are still limited by the indistinguishable VD network, leading to homogeneous agent behaviors and thus downgrading the cooperation capability. In this paper, we propose a novel Contrastive Identity-Aware learning (CIA) method, explicitly boosting the credit-level distinguishability of the VD network to break the bottleneck of multi-agent diversity. Specifically, our approach leverages contrastive learning to maximize the mutual information between the temporal credits and identity representations of different agents, encouraging the full expressiveness of credit assignment and further the emergence of individualities. The algorithm implementation of the proposed CIA module is simple yet effective that can be readily incorporated into various VD architectures. Experiments on the SMAC benchmarks and across different VD backbones demonstrate that the proposed method yields results superior to the state-of-the-art counterparts. Our code is available at https://github.com/liushunyu/CIA.",
        "published": "2022-11-23T05:18:42Z",
        "link": "http://arxiv.org/abs/2211.12712v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Cost Splitting for Multi-Objective Conflict-Based Search",
        "authors": [
            "Cheng Ge",
            "Han Zhang",
            "Jiaoyang Li",
            "Sven Koenig"
        ],
        "summary": "The Multi-Objective Multi-Agent Path Finding (MO-MAPF) problem is the problem of finding the Pareto-optimal frontier of collision-free paths for a team of agents while minimizing multiple cost metrics. Examples of such cost metrics include arrival times, travel distances, and energy consumption.In this paper, we focus on the Multi-Objective Conflict-Based Search (MO-CBS) algorithm, a state-of-the-art MO-MAPF algorithm. We show that the standard splitting strategy used by MO-CBS can lead to duplicate search nodes and hence can duplicate the search effort that MO-CBS needs to make. To address this issue, we propose two new splitting strategies for MO-CBS, namely cost splitting and disjoint cost splitting. Our theoretical results show that, when combined with either of these two new splitting strategies, MO-CBS maintains its completeness and optimality guarantees. Our experimental results show that disjoint cost splitting, our best splitting strategy, speeds up MO-CBS by up to two orders of magnitude and substantially improves its success rates in various settings.",
        "published": "2022-11-23T11:44:20Z",
        "link": "http://arxiv.org/abs/2211.12885v1",
        "categories": [
            "cs.AI",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "A Secure and Intelligent Data Sharing Scheme for UAV-Assisted Disaster   Rescue",
        "authors": [
            "Yuntao Wang",
            "Zhou Su",
            "Qichao Xu",
            "Ruidong Li",
            "Tom H. Luan",
            "Pinghui Wang"
        ],
        "summary": "Unmanned aerial vehicles (UAVs) have the potential to establish flexible and reliable emergency networks in disaster sites when terrestrial communication infrastructures go down. Nevertheless, potential security threats may occur on UAVs during data transmissions due to the untrusted environment and open-access UAV networks. Moreover, UAVs typically have limited battery and computation capacity, making them unaffordable for heavy security provisioning operations when performing complicated rescue tasks. In this paper, we develop RescueChain, a secure and efficient information sharing scheme for UAV-assisted disaster rescue. Specifically, we first implement a lightweight blockchain-based framework to safeguard data sharing under disasters and immutably trace misbehaving entities. A reputation-based consensus protocol is devised to adapt the weakly connected environment with improved consensus efficiency and promoted UAVs' honest behaviors. Furthermore, we introduce a novel vehicular fog computing (VFC)-based off-chain mechanism by leveraging ground vehicles as moving fog nodes to offload UAVs' heavy data processing and storage tasks. To offload computational tasks from the UAVs to ground vehicles having idle computing resources, an optimal allocation strategy is developed by choosing payoffs that achieve equilibrium in a Stackelberg game formulation of the allocation problem. For lack of sufficient knowledge on network model parameters and users' private cost parameters in practical environment, we also design a two-tier deep reinforcement learning-based algorithm to seek the optimal payment and resource strategies of UAVs and vehicles with improved learning efficiency. Simulation results show that RescueChain can effectively accelerate consensus process, improve offloading efficiency, reduce energy consumption, and enhance user payoffs.",
        "published": "2022-11-23T14:49:08Z",
        "link": "http://arxiv.org/abs/2211.12988v1",
        "categories": [
            "cs.MA",
            "cs.GT"
        ]
    },
    {
        "title": "Discovering Influencers in Opinion Formation over Social Graphs",
        "authors": [
            "Valentina Shumovskaia",
            "Mert Kayaalp",
            "Mert Cemri",
            "Ali H. Sayed"
        ],
        "summary": "The adaptive social learning paradigm helps model how networked agents are able to form opinions on a state of nature and track its drifts in a changing environment. In this framework, the agents repeatedly update their beliefs based on private observations and exchange the beliefs with their neighbors. In this work, it is shown how the sequence of publicly exchanged beliefs over time allows users to discover rich information about the underlying network topology and about the flow of information over the graph. In particular, it is shown that it is possible (i) to identify the influence of each individual agent to the objective of truth learning, (ii) to discover how well-informed each agent is, (iii) to quantify the pairwise influences between agents, and (iv) to learn the underlying network topology. The algorithm derived herein is also able to work under non-stationary environments where either the true state of nature or the graph topology are allowed to drift over time. We apply the proposed algorithm to different subnetworks of Twitter users, and identify the most influential and central agents by using their public tweets (posts).",
        "published": "2022-11-23T20:34:46Z",
        "link": "http://arxiv.org/abs/2211.13292v2",
        "categories": [
            "cs.SI",
            "cs.MA",
            "eess.SP"
        ]
    },
    {
        "title": "Software Simulation and Visualization of Quantum Multi-Drone   Reinforcement Learning",
        "authors": [
            "Chanyoung Park",
            "Jae Pyoung Kim",
            "Won Joon Yun",
            "Soohyun Park",
            "Soyi Jung",
            "Joongheon Kim"
        ],
        "summary": "Quantum machine learning (QML) has received a lot of attention according to its light training parameter numbers and speeds; and the advances of QML lead to active research on quantum multi-agent reinforcement learning (QMARL). Existing classical multi-agent reinforcement learning (MARL) features non-stationarity and uncertain properties. Therefore, this paper presents a simulation software framework for novel QMARL to control autonomous multi-drones, i.e., quantum multi-drone reinforcement learning. Our proposed framework accomplishes reasonable reward convergence and service quality performance with fewer trainable parameters. Furthermore, it shows more stable training results. Lastly, our proposed software allows us to analyze the training process and results.",
        "published": "2022-11-24T06:08:24Z",
        "link": "http://arxiv.org/abs/2211.15375v3",
        "categories": [
            "quant-ph",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "LaCAM: Search-Based Algorithm for Quick Multi-Agent Pathfinding",
        "authors": [
            "Keisuke Okumura"
        ],
        "summary": "We propose a novel complete algorithm for multi-agent pathfinding (MAPF) called lazy constraints addition search for MAPF (LaCAM). MAPF is a problem of finding collision-free paths for multiple agents on graphs and is the foundation of multi-robot coordination. LaCAM uses a two-level search to find solutions quickly, even with hundreds of agents or more. At the low-level, it searches constraints about agents' locations. At the high-level, it searches a sequence of all agents' locations, following the constraints specified by the low-level. Our exhaustive experiments reveal that LaCAM is comparable to or outperforms state-of-the-art sub-optimal MAPF algorithms in a variety of scenarios, regarding success rate, planning time, and solution quality of sum-of-costs.",
        "published": "2022-11-24T06:27:18Z",
        "link": "http://arxiv.org/abs/2211.13432v1",
        "categories": [
            "cs.AI",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "On the Emergence of Cooperation in the Repeated Prisoner's Dilemma",
        "authors": [
            "Maximilian Schaefer"
        ],
        "summary": "Using simulations between pairs of $\\epsilon$-greedy q-learners with one-period memory, this article demonstrates that the potential function of the stochastic replicator dynamics (Foster and Young, 1990) allows it to predict the emergence of error-proof cooperative strategies from the underlying parameters of the repeated prisoner's dilemma. The observed cooperation rates between q-learners are related to the ratio between the kinetic energy exerted by the polar attractors of the replicator dynamics under the grim trigger strategy. The frontier separating the parameter space conducive to cooperation from the parameter space dominated by defection can be found by setting the kinetic energy ratio equal to a critical value, which is a function of the discount factor, $f(\\delta) = \\delta/(1-\\delta)$, multiplied by a correction term to account for the effect of the algorithms' exploration probability. The gradient at the frontier increases with the distance between the game parameters and the hyperplane that characterizes the incentive compatibility constraint for cooperation under grim trigger.   Building on literature from the neurosciences, which suggests that reinforcement learning is useful to understanding human behavior in risky environments, the article further explores the extent to which the frontier derived for q-learners also explains the emergence of cooperation between humans. Using metadata from laboratory experiments that analyze human choices in the infinitely repeated prisoner's dilemma, the cooperation rates between humans are compared to those observed between q-learners under similar conditions. The correlation coefficients between the cooperation rates observed for humans and those observed for q-learners are consistently above $0.8$. The frontier derived from the simulations between q-learners is also found to predict the emergence of cooperation between humans.",
        "published": "2022-11-24T17:27:29Z",
        "link": "http://arxiv.org/abs/2211.15331v2",
        "categories": [
            "econ.TH",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Melting Pot 2.0",
        "authors": [
            "John P. Agapiou",
            "Alexander Sasha Vezhnevets",
            "Edgar A. Duéñez-Guzmán",
            "Jayd Matyas",
            "Yiran Mao",
            "Peter Sunehag",
            "Raphael Köster",
            "Udari Madhushani",
            "Kavya Kopparapu",
            "Ramona Comanescu",
            "DJ Strouse",
            "Michael B. Johanson",
            "Sukhdeep Singh",
            "Julia Haas",
            "Igor Mordatch",
            "Dean Mobbs",
            "Joel Z. Leibo"
        ],
        "summary": "Multi-agent artificial intelligence research promises a path to develop intelligent technologies that are more human-like and more human-compatible than those produced by \"solipsistic\" approaches, which do not consider interactions between agents. Melting Pot is a research tool developed to facilitate work on multi-agent artificial intelligence, and provides an evaluation protocol that measures generalization to novel social partners in a set of canonical test scenarios. Each scenario pairs a physical environment (a \"substrate\") with a reference set of co-players (a \"background population\"), to create a social situation with substantial interdependence between the individuals involved. For instance, some scenarios were inspired by institutional-economics-based accounts of natural resource management and public-good-provision dilemmas. Others were inspired by considerations from evolutionary biology, game theory, and artificial life. Melting Pot aims to cover a maximally diverse set of interdependencies and incentives. It includes the commonly-studied extreme cases of perfectly-competitive (zero-sum) motivations and perfectly-cooperative (shared-reward) motivations, but does not stop with them. As in real-life, a clear majority of scenarios in Melting Pot have mixed incentives. They are neither purely competitive nor purely cooperative and thus demand successful agents be able to navigate the resulting ambiguity. Here we describe Melting Pot 2.0, which revises and expands on Melting Pot. We also introduce support for scenarios with asymmetric roles, and explain how to integrate them into the evaluation protocol. This report also contains: (1) details of all substrates and scenarios; (2) a complete description of all baseline algorithms and results. Our intention is for it to serve as a reference for researchers using Melting Pot 2.0.",
        "published": "2022-11-24T18:23:28Z",
        "link": "http://arxiv.org/abs/2211.13746v6",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.GT",
            "cs.NE"
        ]
    },
    {
        "title": "Fault-Tolerant Offline Multi-Agent Path Planning",
        "authors": [
            "Keisuke Okumura",
            "Sébastien Tixeuil"
        ],
        "summary": "We study a novel graph path planning problem for multiple agents that may crash at runtime, and block part of the workspace. In our setting, agents can detect neighboring crashed agents, and change followed paths at runtime. The objective is then to prepare a set of paths and switching rules for each agent, ensuring that all correct agents reach their destinations without collisions or deadlocks, despite unforeseen crashes of other agents. Such planning is attractive to build reliable multi-robot systems. We present problem formalization, theoretical analysis such as computational complexities, and how to solve this offline planning problem.",
        "published": "2022-11-25T05:58:32Z",
        "link": "http://arxiv.org/abs/2211.13908v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "A Hierarchical Variable Autonomy Mixed-Initiative Framework for   Human-Robot Teaming in Mobile Robotics",
        "authors": [
            "Dimitris Panagopoulos",
            "Giannis Petousakis",
            "Aniketh Ramesh",
            "Tianshu Ruan",
            "Grigoris Nikolaou",
            "Rustam Stolkin",
            "Manolis Chiou"
        ],
        "summary": "This paper presents a Mixed-Initiative (MI) framework for addressing the problem of control authority transfer between a remote human operator and an AI agent when cooperatively controlling a mobile robot. Our Hierarchical Expert-guided Mixed-Initiative Control Switcher (HierEMICS) leverages information on the human operator's state and intent. The control switching policies are based on a criticality hierarchy. An experimental evaluation was conducted in a high-fidelity simulated disaster response and remote inspection scenario, comparing HierEMICS with a state-of-the-art Expert-guided Mixed-Initiative Control Switcher (EMICS) in the context of mobile robot navigation. Results suggest that HierEMICS reduces conflicts for control between the human and the AI agent, which is a fundamental challenge in both the MI control paradigm and also in the related shared control paradigm. Additionally, we provide statistically significant evidence of improved, navigational safety (i.e., fewer collisions), LOA switching efficiency, and conflict for control reduction.",
        "published": "2022-11-25T13:25:16Z",
        "link": "http://arxiv.org/abs/2211.14095v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.HC",
            "cs.MA"
        ]
    },
    {
        "title": "An agent-based simulation model of pedestrian evacuation based on   Bayesian Nash Equilibrium",
        "authors": [
            "Yiyu Wang",
            "Jiaqi Ge",
            "Alexis Comber"
        ],
        "summary": "This research incorporates Bayesian game theory into pedestrian evacuation in an agent-based model. Three pedestrian behaviours were compared: Random Follow, Shortest Route and Bayesian Nash Equilibrium (BNE), as well as combinations of these. The results showed that BNE pedestrians were able to evacuate more quickly as they predict congestion levels in their next step and adjust their directions to avoid congestion, closely matching the behaviours of evacuating pedestrians in reality. A series of simulation experiments were conducted to evaluate whether and how BNE affects pedestrian evacuation procedures. The results showed that: 1) BNE has a large impact on reducing evacuation time; 2) BNE pedestrians displayed more intelligent and efficient evacuating behaviours; 3) As the proportion of BNE users rises, average evacuation time decreases, and average comfort level increases. A detailed description of the model and relevant experimental results is provided in this paper. Several limitations as well as further works are also identified.",
        "published": "2022-11-25T17:41:03Z",
        "link": "http://arxiv.org/abs/2211.14260v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Similarity-based cooperative equilibrium",
        "authors": [
            "Caspar Oesterheld",
            "Johannes Treutlein",
            "Roger Grosse",
            "Vincent Conitzer",
            "Jakob Foerster"
        ],
        "summary": "As machine learning agents act more autonomously in the world, they will increasingly interact with each other. Unfortunately, in many social dilemmas like the one-shot Prisoner's Dilemma, standard game theory predicts that ML agents will fail to cooperate with each other. Prior work has shown that one way to enable cooperative outcomes in the one-shot Prisoner's Dilemma is to make the agents mutually transparent to each other, i.e., to allow them to access one another's source code (Rubinstein 1998, Tennenholtz 2004) -- or weights in the case of ML agents. However, full transparency is often unrealistic, whereas partial transparency is commonplace. Moreover, it is challenging for agents to learn their way to cooperation in the full transparency setting. In this paper, we introduce a more realistic setting in which agents only observe a single number indicating how similar they are to each other. We prove that this allows for the same set of cooperative outcomes as the full transparency setting. We also demonstrate experimentally that cooperation can be learned using simple ML methods.",
        "published": "2022-11-26T03:43:13Z",
        "link": "http://arxiv.org/abs/2211.14468v2",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "91A10 (Primary) 91A05 91A26 91A35 (Secondary)",
            "I.2.11"
        ]
    },
    {
        "title": "Mediated Cheap Talk Design (with proofs)",
        "authors": [
            "Itai Arieli",
            "Ivan Geffner",
            "Moshe Tennenholtz"
        ],
        "summary": "We study an information design problem with two informed senders and a receiver in which, in contrast to traditional Bayesian persuasion settings, senders do not have commitment power. In our setting, a trusted mediator/platform gathers data from the senders and recommends the receiver which action to play. We characterize the set of implementable action distributions that can be obtained in equilibrium, and provide an $O(n \\log n)$ algorithm (where $n$ is the number of states) that computes the optimal equilibrium for the senders. Additionally, we show that the optimal equilibrium for the receiver can be obtained by a simple revelation mechanism.",
        "published": "2022-11-26T21:39:14Z",
        "link": "http://arxiv.org/abs/2211.14670v2",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Strategically revealing capabilities in General Lotto games",
        "authors": [
            "Keith Paarporn",
            "Philip N. Brown"
        ],
        "summary": "Can revealing one's competitive capabilities to an opponent offer strategic benefits? In this paper, we address this question in the context of General Lotto games, a class of two-player competitive resource allocation models. We consider an asymmetric information setting where the opponent is uncertain about the resource budget of the other player, and holds a prior belief on its value. We assume the other player, called the signaler, is able to send a noisy signal about its budget to the opponent. With its updated belief, the opponent then must decide to invest in costly resources that it will deploy against the signaler's resource budget in a General Lotto game. We derive the subgame perfect equilibrium to this extensive-form game. In particular, we identify necessary and sufficient conditions for which a signaling policy improves the signaler's resulting performance in comparison to the scenario where it does not send any signal. Moreover, we provide the optimal signaling policy when these conditions are met. Notably we find that for some scenarios, the signaler can effectively double its performance.",
        "published": "2022-11-27T18:14:07Z",
        "link": "http://arxiv.org/abs/2211.14907v2",
        "categories": [
            "cs.GT",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Multiagent Reinforcement Learning for Autonomous Routing and Pickup   Problem with Adaptation to Variable Demand",
        "authors": [
            "Daniel Garces",
            "Sushmita Bhattacharya",
            "Stephanie Gil",
            "Dimitri Bertsekas"
        ],
        "summary": "We derive a learning framework to generate routing/pickup policies for a fleet of autonomous vehicles tasked with servicing stochastically appearing requests on a city map. We focus on policies that 1) give rise to coordination amongst the vehicles, thereby reducing wait times for servicing requests, 2) are non-myopic, and consider a-priori potential future requests, 3) can adapt to changes in the underlying demand distribution. Specifically, we are interested in policies that are adaptive to fluctuations of actual demand conditions in urban environments, such as on-peak vs. off-peak hours. We achieve this through a combination of (i) an online play algorithm that improves the performance of an offline-trained policy, and (ii) an offline approximation scheme that allows for adapting to changes in the underlying demand model. In particular, we achieve adaptivity of our learned policy to different demand distributions by quantifying a region of validity using the q-valid radius of a Wasserstein Ambiguity Set. We propose a mechanism for switching the originally trained offline approximation when the current demand is outside the original validity region. In this case, we propose to use an offline architecture, trained on a historical demand model that is closer to the current demand in terms of Wasserstein distance. We learn routing and pickup policies over real taxicab requests in San Francisco with high variability between on-peak and off-peak hours, demonstrating the ability of our method to adapt to real fluctuation in demand distributions. Our numerical results demonstrate that our method outperforms alternative rollout-based reinforcement learning schemes, as well as other classical methods from operations research.",
        "published": "2022-11-28T01:11:11Z",
        "link": "http://arxiv.org/abs/2211.14983v2",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG",
            "cs.RO"
        ]
    },
    {
        "title": "Provably Efficient Model-free RL in Leader-Follower MDP with Linear   Function Approximation",
        "authors": [
            "Arnob Ghosh"
        ],
        "summary": "We consider a multi-agent episodic MDP setup where an agent (leader) takes action at each step of the episode followed by another agent (follower). The state evolution and rewards depend on the joint action pair of the leader and the follower. Such type of interactions can find applications in many domains such as smart grids, mechanism design, security, and policymaking. We are interested in how to learn policies for both the players with provable performance guarantee under a bandit feedback setting. We focus on a setup where both the leader and followers are {\\em non-myopic}, i.e., they both seek to maximize their rewards over the entire episode and consider a linear MDP which can model continuous state-space which is very common in many RL applications. We propose a {\\em model-free} RL algorithm and show that $\\tilde{\\mathcal{O}}(\\sqrt{d^3H^3T})$ regret bounds can be achieved for both the leader and the follower, where $d$ is the dimension of the feature mapping, $H$ is the length of the episode, and $T$ is the total number of steps under the bandit feedback information setup. Thus, our result holds even when the number of states becomes infinite. The algorithm relies on {\\em novel} adaptation of the LSVI-UCB algorithm. Specifically, we replace the standard greedy policy (as the best response) with the soft-max policy for both the leader and the follower. This turns out to be key in establishing uniform concentration bound for the value functions. To the best of our knowledge, this is the first sub-linear regret bound guarantee for the Markov games with non-myopic followers with function approximation.",
        "published": "2022-11-28T21:59:58Z",
        "link": "http://arxiv.org/abs/2211.15792v2",
        "categories": [
            "cs.LG",
            "cs.GT",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "CLAS: Coordinating Multi-Robot Manipulation with Central Latent Action   Spaces",
        "authors": [
            "Elie Aljalbout",
            "Maximilian Karl",
            "Patrick van der Smagt"
        ],
        "summary": "Multi-robot manipulation tasks involve various control entities that can be separated into dynamically independent parts. A typical example of such real-world tasks is dual-arm manipulation. Learning to naively solve such tasks with reinforcement learning is often unfeasible due to the sample complexity and exploration requirements growing with the dimensionality of the action and state spaces. Instead, we would like to handle such environments as multi-agent systems and have several agents control parts of the whole. However, decentralizing the generation of actions requires coordination across agents through a channel limited to information central to the task. This paper proposes an approach to coordinating multi-robot manipulation through learned latent action spaces that are shared across different agents. We validate our method in simulated multi-robot manipulation tasks and demonstrate improvement over previous baselines in terms of sample efficiency and learning performance.",
        "published": "2022-11-28T23:20:47Z",
        "link": "http://arxiv.org/abs/2211.15824v1",
        "categories": [
            "cs.RO",
            "cs.GT",
            "cs.LG",
            "cs.MA",
            "cs.NE",
            "I.2.6; I.2.8; I.2.9"
        ]
    },
    {
        "title": "Distributed Energy Management and Demand Response in Smart Grids: A   Multi-Agent Deep Reinforcement Learning Framework",
        "authors": [
            "Amin Shojaeighadikolaei",
            "Arman Ghasemi",
            "Kailani Jones",
            "Yousif Dafalla",
            "Alexandru G. Bardas",
            "Reza Ahmadi",
            "Morteza Haashemi"
        ],
        "summary": "This paper presents a multi-agent Deep Reinforcement Learning (DRL) framework for autonomous control and integration of renewable energy resources into smart power grid systems. In particular, the proposed framework jointly considers demand response (DR) and distributed energy management (DEM) for residential end-users. DR has a widely recognized potential for improving power grid stability and reliability, while at the same time reducing end-users energy bills. However, the conventional DR techniques come with several shortcomings, such as the inability to handle operational uncertainties while incurring end-user disutility, which prevents widespread adoption in real-world applications. The proposed framework addresses these shortcomings by implementing DR and DEM based on real-time pricing strategy that is achieved using deep reinforcement learning. Furthermore, this framework enables the power grid service provider to leverage distributed energy resources (i.e., PV rooftop panels and battery storage) as dispatchable assets to support the smart grid during peak hours, thus achieving management of distributed energy resources. Simulation results based on the Deep Q-Network (DQN) demonstrate significant improvements of the 24-hour accumulative profit for both prosumers and the power grid service provider, as well as major reductions in the utilization of the power grid reserve generators.",
        "published": "2022-11-29T01:18:58Z",
        "link": "http://arxiv.org/abs/2211.15858v1",
        "categories": [
            "cs.MA",
            "cs.LG",
            "cs.SY",
            "eess.SY",
            "68T07, 68T42, 68T05",
            "I.2; I.6"
        ]
    },
    {
        "title": "Approximating Martingale Process for Variance Reduction in Deep   Reinforcement Learning with Large State Space",
        "authors": [
            "Charlie Ruan"
        ],
        "summary": "Approximating Martingale Process (AMP) is proven to be effective for variance reduction in reinforcement learning (RL) in specific cases such as Multiclass Queueing Networks. However, in the already proven cases, the state space is relatively small and all possible state transitions can be iterated through. In this paper, we consider systems in which state space is large and have uncertainties when considering state transitions, thus making AMP a generalized variance-reduction method in RL. Specifically, we will investigate the application of AMP in ride-hailing systems like Uber, where Proximal Policy Optimization (PPO) is incorporated to optimize the policy of matching drivers and customers.",
        "published": "2022-11-29T02:45:18Z",
        "link": "http://arxiv.org/abs/2211.15886v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "Finding mixed-strategy equilibria of continuous-action games without   gradients using randomized policy networks",
        "authors": [
            "Carlos Martin",
            "Tuomas Sandholm"
        ],
        "summary": "We study the problem of computing an approximate Nash equilibrium of continuous-action game without access to gradients. Such game access is common in reinforcement learning settings, where the environment is typically treated as a black box. To tackle this problem, we apply zeroth-order optimization techniques that combine smoothed gradient estimators with equilibrium-finding dynamics. We model players' strategies using artificial neural networks. In particular, we use randomized policy networks to model mixed strategies. These take noise in addition to an observation as input and can flexibly represent arbitrary observation-dependent, continuous-action distributions. Being able to model such mixed strategies is crucial for tackling continuous-action games that lack pure-strategy equilibria. We evaluate the performance of our method using an approximation of the Nash convergence metric from game theory, which measures how much players can benefit from unilaterally changing their strategy. We apply our method to continuous Colonel Blotto games, single-item and multi-item auctions, and a visibility game. The experiments show that our method can quickly find high-quality approximate equilibria. Furthermore, they show that the dimensionality of the input noise is crucial for performance. To our knowledge, this paper is the first to solve general continuous-action games with unrestricted mixed strategies and without any gradient information.",
        "published": "2022-11-29T05:16:41Z",
        "link": "http://arxiv.org/abs/2211.15936v1",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Novelty Detection for Election Fraud: A Case Study with Agent-Based   Simulation Data",
        "authors": [
            "Khurram Yamin",
            "Nima Jadali",
            "Dima Nazzal",
            "Yao Xie"
        ],
        "summary": "In this paper, we propose a robust election simulation model and independently developed election anomaly detection algorithm that demonstrates the simulation's utility. The simulation generates artificial elections with similar properties and trends as elections from the real world, while giving users control and knowledge over all the important components of the elections. We generate a clean election results dataset without fraud as well as datasets with varying degrees of fraud. We then measure how well the algorithm is able to successfully detect the level of fraud present. The algorithm determines how similar actual election results are as compared to the predicted results from polling and a regression model of other regions that have similar demographics. We use k-means to partition electoral regions into clusters such that demographic homogeneity is maximized among clusters. We then use a novelty detection algorithm implemented as a one-class Support Vector Machine where the clean data is provided in the form of polling predictions and regression predictions. The regression predictions are built from the actual data in such a way that the data supervises itself. We show both the effectiveness of the simulation technique and the machine learning model in its success in identifying fraudulent regions.",
        "published": "2022-11-29T08:46:36Z",
        "link": "http://arxiv.org/abs/2211.16023v1",
        "categories": [
            "cs.LG",
            "cs.MA",
            "cs.SI"
        ]
    },
    {
        "title": "ACE: Cooperative Multi-agent Q-learning with Bidirectional   Action-Dependency",
        "authors": [
            "Chuming Li",
            "Jie Liu",
            "Yinmin Zhang",
            "Yuhong Wei",
            "Yazhe Niu",
            "Yaodong Yang",
            "Yu Liu",
            "Wanli Ouyang"
        ],
        "summary": "Multi-agent reinforcement learning (MARL) suffers from the non-stationarity problem, which is the ever-changing targets at every iteration when multiple agents update their policies at the same time. Starting from first principle, in this paper, we manage to solve the non-stationarity problem by proposing bidirectional action-dependent Q-learning (ACE). Central to the development of ACE is the sequential decision-making process wherein only one agent is allowed to take action at one time. Within this process, each agent maximizes its value function given the actions taken by the preceding agents at the inference stage. In the learning phase, each agent minimizes the TD error that is dependent on how the subsequent agents have reacted to their chosen action. Given the design of bidirectional dependency, ACE effectively turns a multiagent MDP into a single-agent MDP. We implement the ACE framework by identifying the proper network representation to formulate the action dependency, so that the sequential decision process is computed implicitly in one forward pass. To validate ACE, we compare it with strong baselines on two MARL benchmarks. Empirical experiments demonstrate that ACE outperforms the state-of-the-art algorithms on Google Research Football and StarCraft Multi-Agent Challenge by a large margin. In particular, on SMAC tasks, ACE achieves 100% success rate on almost all the hard and super-hard maps. We further study extensive research problems regarding ACE, including extension, generalization, and practicability. Code is made available to facilitate further research.",
        "published": "2022-11-29T10:22:55Z",
        "link": "http://arxiv.org/abs/2211.16068v2",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Interpreting Primal-Dual Algorithms for Constrained Multiagent   Reinforcement Learning",
        "authors": [
            "Daniel Tabas",
            "Ahmed S. Zamzam",
            "Baosen Zhang"
        ],
        "summary": "Constrained multiagent reinforcement learning (C-MARL) is gaining importance as MARL algorithms find new applications in real-world systems ranging from energy systems to drone swarms. Most C-MARL algorithms use a primal-dual approach to enforce constraints through a penalty function added to the reward. In this paper, we study the structural effects of this penalty term on the MARL problem. First, we show that the standard practice of using the constraint function as the penalty leads to a weak notion of safety. However, by making simple modifications to the penalty term, we can enforce meaningful probabilistic (chance and conditional value at risk) constraints. Second, we quantify the effect of the penalty term on the value function, uncovering an improved value estimation procedure. We use these insights to propose a constrained multiagent advantage actor critic (C-MAA2C) algorithm. Simulations in a simple constrained multiagent environment affirm that our reinterpretation of the primal-dual method in terms of probabilistic constraints is effective, and that our proposed value estimate accelerates convergence to a safe joint policy.",
        "published": "2022-11-29T10:23:26Z",
        "link": "http://arxiv.org/abs/2211.16069v3",
        "categories": [
            "eess.SY",
            "cs.LG",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Multi-Agent Reinforcement Learning for Microprocessor Design Space   Exploration",
        "authors": [
            "Srivatsan Krishnan",
            "Natasha Jaques",
            "Shayegan Omidshafiei",
            "Dan Zhang",
            "Izzeddin Gur",
            "Vijay Janapa Reddi",
            "Aleksandra Faust"
        ],
        "summary": "Microprocessor architects are increasingly resorting to domain-specific customization in the quest for high-performance and energy-efficiency. As the systems grow in complexity, fine-tuning architectural parameters across multiple sub-systems (e.g., datapath, memory blocks in different hierarchies, interconnects, compiler optimization, etc.) quickly results in a combinatorial explosion of design space. This makes domain-specific customization an extremely challenging task. Prior work explores using reinforcement learning (RL) and other optimization methods to automatically explore the large design space. However, these methods have traditionally relied on single-agent RL/ML formulations. It is unclear how scalable single-agent formulations are as we increase the complexity of the design space (e.g., full stack System-on-Chip design). Therefore, we propose an alternative formulation that leverages Multi-Agent RL (MARL) to tackle this problem. The key idea behind using MARL is an observation that parameters across different sub-systems are more or less independent, thus allowing a decentralized role assigned to each agent. We test this hypothesis by designing domain-specific DRAM memory controller for several workload traces. Our evaluation shows that the MARL formulation consistently outperforms single-agent RL baselines such as Proximal Policy Optimization and Soft Actor-Critic over different target objectives such as low power and latency. To this end, this work opens the pathway for new and promising research in MARL solutions for hardware architecture search.",
        "published": "2022-11-29T17:10:24Z",
        "link": "http://arxiv.org/abs/2211.16385v1",
        "categories": [
            "cs.AR",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Welfare and Fairness in Multi-objective Reinforcement Learning",
        "authors": [
            "Zimeng Fan",
            "Nianli Peng",
            "Muhang Tian",
            "Brandon Fain"
        ],
        "summary": "We study fair multi-objective reinforcement learning in which an agent must learn a policy that simultaneously achieves high reward on multiple dimensions of a vector-valued reward. Motivated by the fair resource allocation literature, we model this as an expected welfare maximization problem, for some nonlinear fair welfare function of the vector of long-term cumulative rewards. One canonical example of such a function is the Nash Social Welfare, or geometric mean, the log transform of which is also known as the Proportional Fairness objective. We show that even approximately optimal optimization of the expected Nash Social Welfare is computationally intractable even in the tabular case. Nevertheless, we provide a novel adaptation of Q-learning that combines nonlinear scalarized learning updates and non-stationary action selection to learn effective policies for optimizing nonlinear welfare functions. We show that our algorithm is provably convergent, and we demonstrate experimentally that our approach outperforms techniques based on linear scalarization, mixtures of optimal linear scalarizations, or stationary action selection for the Nash Social Welfare Objective.",
        "published": "2022-11-30T01:40:59Z",
        "link": "http://arxiv.org/abs/2212.01382v5",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Universal Feature Selection Tool (UniFeat): An Open-Source Tool for   Dimensionality Reduction",
        "authors": [
            "Sina Tabakhi",
            "Parham Moradi"
        ],
        "summary": "The Universal Feature Selection Tool (UniFeat) is an open-source tool developed entirely in Java for performing feature selection processes in various research areas. It provides a set of well-known and advanced feature selection methods within its significant auxiliary tools. This allows users to compare the performance of feature selection methods. Moreover, due to the open-source nature of UniFeat, researchers can use and modify it in their research, which facilitates the rapid development of new feature selection algorithms.",
        "published": "2022-11-30T09:39:31Z",
        "link": "http://arxiv.org/abs/2211.16846v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Dynamic and Distributed Optimization for the Allocation of Aerial Swarm   Vehicles",
        "authors": [
            "Jason Hughes",
            "Dominic Larkin",
            "Charles O'Donnell",
            "Christopher Korpela"
        ],
        "summary": "Optimal transport (OT) is a framework that can guide the design of efficient resource allocation strategies in a network of multiple sources and targets. This paper applies discrete OT to a swarm of UAVs in a novel way to achieve appropriate task allocation and execution. Drone swarm deployments already operate in multiple domains where sensors are used to gain knowledge of an environment [1]. Use cases such as, chemical and radiation detection, and thermal and RGB imaging create a specific need for an algorithm that considers parameters on both the UAV and waypoint side and allows for updating the matching scheme as the swarm gains information from the environment. Additionally, the need for a centralized planner can be removed by using a distributed algorithm that can dynamically update based on changes in the swarm network or parameters. To this end, we develop a dynamic and distributed OT algorithm that matches a UAV to the optimal waypoint based on one parameter at the UAV and another parameter at the waypoint. We show the convergence and allocation of the algorithm through a case study and test the algorithm's effectiveness against a greedy assignment algorithm in simulation.",
        "published": "2022-11-30T15:35:54Z",
        "link": "http://arxiv.org/abs/2211.17077v1",
        "categories": [
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Global Convergence of Localized Policy Iteration in Networked   Multi-Agent Reinforcement Learning",
        "authors": [
            "Yizhou Zhang",
            "Guannan Qu",
            "Pan Xu",
            "Yiheng Lin",
            "Zaiwei Chen",
            "Adam Wierman"
        ],
        "summary": "We study a multi-agent reinforcement learning (MARL) problem where the agents interact over a given network. The goal of the agents is to cooperatively maximize the average of their entropy-regularized long-term rewards. To overcome the curse of dimensionality and to reduce communication, we propose a Localized Policy Iteration (LPI) algorithm that provably learns a near-globally-optimal policy using only local information. In particular, we show that, despite restricting each agent's attention to only its $\\kappa$-hop neighborhood, the agents are able to learn a policy with an optimality gap that decays polynomially in $\\kappa$. In addition, we show the finite-sample convergence of LPI to the global optimal policy, which explicitly captures the trade-off between optimality and computational complexity in choosing $\\kappa$. Numerical simulations demonstrate the effectiveness of LPI.",
        "published": "2022-11-30T15:58:00Z",
        "link": "http://arxiv.org/abs/2211.17116v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "math.OC"
        ]
    },
    {
        "title": "Distributed Averaging in Opinion Dynamics",
        "authors": [
            "Petra Berenbrink",
            "Colin Cooper",
            "Cristina Gava",
            "David Kohan Marzagão",
            "Frederik Mallmann-Trenn",
            "Nicolás Rivera",
            "Tomasz Radzik"
        ],
        "summary": "We consider two simple asynchronous opinion dynamics on arbitrary graphs where every node $u$ has an initial value $\\xi_u(0)$. In the first process, the NodeModel, at each time step $t\\ge 0$, a random node $u$ and a random sample of $k$ of its neighbours $v_1,v_2,\\cdots,v_k$ are selected. Then, $u$ updates its current value $\\xi_u(t)$ to $\\xi_u(t+1) = \\alpha \\xi_u(t) + \\frac{(1-\\alpha)}{k} \\sum_{i=1}^k \\xi_{v_i}(t)$, where $\\alpha \\in (0,1)$ and $k\\ge 1$ are parameters of the process. In the second process, the EdgeModel, at each step a random pair of adjacent nodes $(u,v)$ is selected, and then node $u$ updates its value equivalently to the NodeModel with $k=1$ and $v$ as the selected neighbour. For both processes, the values of all nodes converge to $F$, a random variable depending on the random choices made in each step. For the NodeModel and regular graphs, and for the EdgeModel and arbitrary graphs, the expectation of $F$ is the average of the initial values $\\frac{1}{n}\\sum_{u\\in V} \\xi_u(0)$. For the NodeModel and non-regular graphs, the expectation of $F$ is the degree-weighted average of the initial values. Our results are two-fold. We consider the concentration of $F$ and show tight bounds on the variance of $F$ for regular graphs. We show that, when the initial values do not depend on the number of nodes, then the variance is negligible, hence the nodes are able to estimate the initial average of the node values. Interestingly, this variance does not depend on the graph structure. For the proof we introduce a duality between our processes and a process of two correlated random walks. We also analyse the convergence time for both models and for arbitrary graphs, showing bounds on the time $T_\\varepsilon$ required to make all node values `$\\varepsilon$-close' to each other. Our bounds are asymptotically tight under assumptions on the distribution of the initial values.",
        "published": "2022-11-30T16:02:27Z",
        "link": "http://arxiv.org/abs/2211.17125v3",
        "categories": [
            "math.PR",
            "cs.MA",
            "68W05",
            "F.2.2; G.3"
        ]
    },
    {
        "title": "Targets in Reinforcement Learning to solve Stackelberg Security Games",
        "authors": [
            "Saptarashmi Bandyopadhyay",
            "Chenqi Zhu",
            "Philip Daniel",
            "Joshua Morrison",
            "Ethan Shay",
            "John Dickerson"
        ],
        "summary": "Reinforcement Learning (RL) algorithms have been successfully applied to real world situations like illegal smuggling, poaching, deforestation, climate change, airport security, etc. These scenarios can be framed as Stackelberg security games (SSGs) where defenders and attackers compete to control target resources. The algorithm's competency is assessed by which agent is controlling the targets. This review investigates modeling of SSGs in RL with a focus on possible improvements of target representations in RL algorithms.",
        "published": "2022-11-30T16:08:04Z",
        "link": "http://arxiv.org/abs/2211.17132v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.GT",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "On Regret-optimal Cooperative Nonstochastic Multi-armed Bandits",
        "authors": [
            "Jialin Yi",
            "Milan Vojnović"
        ],
        "summary": "We consider the nonstochastic multi-agent multi-armed bandit problem with agents collaborating via a communication network with delays. We show a lower bound for individual regret of all agents. We show that with suitable regularizers and communication protocols, a collaborative multi-agent \\emph{follow-the-regularized-leader} (FTRL) algorithm has an individual regret upper bound that matches the lower bound up to a constant factor when the number of arms is large enough relative to degrees of agents in the communication graph. We also show that an FTRL algorithm with a suitable regularizer is regret optimal with respect to the scaling with the edge-delay parameter. We present numerical experiments validating our theoretical results and demonstrate cases when our algorithms outperform previously proposed algorithms.",
        "published": "2022-11-30T16:46:41Z",
        "link": "http://arxiv.org/abs/2211.17154v3",
        "categories": [
            "stat.ML",
            "cs.LG",
            "cs.MA",
            "math.ST",
            "stat.TH"
        ]
    },
    {
        "title": "Towards True Lossless Sparse Communication in Multi-Agent Systems",
        "authors": [
            "Seth Karten",
            "Mycal Tucker",
            "Siva Kailas",
            "Katia Sycara"
        ],
        "summary": "Communication enables agents to cooperate to achieve their goals. Learning when to communicate, i.e., sparse (in time) communication, and whom to message is particularly important when bandwidth is limited. Recent work in learning sparse individualized communication, however, suffers from high variance during training, where decreasing communication comes at the cost of decreased reward, particularly in cooperative tasks. We use the information bottleneck to reframe sparsity as a representation learning problem, which we show naturally enables lossless sparse communication at lower budgets than prior art. In this paper, we propose a method for true lossless sparsity in communication via Information Maximizing Gated Sparse Multi-Agent Communication (IMGS-MAC). Our model uses two individualized regularization objectives, an information maximization autoencoder and sparse communication loss, to create informative and sparse communication. We evaluate the learned communication `language' through direct causal analysis of messages in non-sparse runs to determine the range of lossless sparse budgets, which allow zero-shot sparsity, and the range of sparse budgets that will inquire a reward loss, which is minimized by our learned gating function with few-shot sparsity. To demonstrate the efficacy of our results, we experiment in cooperative multi-agent tasks where communication is essential for success. We evaluate our model with both continuous and discrete messages. We focus our analysis on a variety of ablations to show the effect of message representations, including their properties, and lossless performance of our model.",
        "published": "2022-11-30T20:43:34Z",
        "link": "http://arxiv.org/abs/2212.00115v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Distributed Deep Reinforcement Learning: A Survey and A Multi-Player   Multi-Agent Learning Toolbox",
        "authors": [
            "Qiyue Yin",
            "Tongtong Yu",
            "Shengqi Shen",
            "Jun Yang",
            "Meijing Zhao",
            "Kaiqi Huang",
            "Bin Liang",
            "Liang Wang"
        ],
        "summary": "With the breakthrough of AlphaGo, deep reinforcement learning becomes a recognized technique for solving sequential decision-making problems. Despite its reputation, data inefficiency caused by its trial and error learning mechanism makes deep reinforcement learning hard to be practical in a wide range of areas. Plenty of methods have been developed for sample efficient deep reinforcement learning, such as environment modeling, experience transfer, and distributed modifications, amongst which, distributed deep reinforcement learning has shown its potential in various applications, such as human-computer gaming, and intelligent transportation. In this paper, we conclude the state of this exciting field, by comparing the classical distributed deep reinforcement learning methods, and studying important components to achieve efficient distributed learning, covering single player single agent distributed deep reinforcement learning to the most complex multiple players multiple agents distributed deep reinforcement learning. Furthermore, we review recently released toolboxes that help to realize distributed deep reinforcement learning without many modifications of their non-distributed versions. By analyzing their strengths and weaknesses, a multi-player multi-agent distributed deep reinforcement learning toolbox is developed and released, which is further validated on Wargame, a complex environment, showing usability of the proposed toolbox for multiple players and multiple agents distributed deep reinforcement learning under complex games. Finally, we try to point out challenges and future trends, hoping this brief review can provide a guide or a spark for researchers who are interested in distributed deep reinforcement learning.",
        "published": "2022-12-01T03:39:24Z",
        "link": "http://arxiv.org/abs/2212.00253v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Decision Market Based Learning For Multi-agent Contextual Bandit   Problems",
        "authors": [
            "Wenlong Wang",
            "Thomas Pfeiffer"
        ],
        "summary": "Information is often stored in a distributed and proprietary form, and agents who own information are often self-interested and require incentives to reveal their information. Suitable mechanisms are required to elicit and aggregate such distributed information for decision making. In this paper, we use simulations to investigate the use of decision markets as mechanisms in a multi-agent learning system to aggregate distributed information for decision-making in a contextual bandit problem. The system utilises strictly proper decision scoring rules to assess the accuracy of probabilistic reports from agents, which allows agents to learn to solve the contextual bandit problem jointly. Our simulations show that our multi-agent system with distributed information can be trained as efficiently as a centralised counterpart with a single agent that receives all information. Moreover, we use our system to investigate scenarios with deterministic decision scoring rules which are not incentive compatible. We observe the emergence of more complex dynamics with manipulative behaviour, which agrees with existing theoretical analyses.",
        "published": "2022-12-01T04:28:14Z",
        "link": "http://arxiv.org/abs/2212.00271v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Economics of NFTs: The Value of Creator Royalties",
        "authors": [
            "Brett Hemenway Falk",
            "Gerry Tsoukalas",
            "Niuniu Zhang"
        ],
        "summary": "Non-Fungible Tokens (NFTs) promise to revolutionize how content creators (e.g., artists) price and sell their work. One core feature of NFTs is the option to embed creator royalties which earmark a percentage of future sale proceeds to creators, each time their NFTs change hands. As popular as this feature is in practice, its utility is often questioned because buyers, the argument goes, simply ``price it in at the time of purchase''. As intuitive as this argument sounds, it is incomplete. We find royalties can add value to creators in at least three distinct ways. (i) Risk sharing: when creators and buyers are risk sensitive, royalties can improve trade by splitting the risks associated with future price volatility; (ii) Dynamic pricing: in the presence of information asymmetry, royalties can extract more revenues from better-informed speculators over time, mimicking the benefits of ``dynamic pricing''; (iii) Price discrimination: when creators sell multi-unit NFT collections, royalties can better capture value from heterogeneous buyers. Our results suggest creator royalties play an important and sometimes overlooked role in the economics of NFTs.",
        "published": "2022-12-01T05:35:23Z",
        "link": "http://arxiv.org/abs/2212.00292v1",
        "categories": [
            "econ.GN",
            "cs.CR",
            "cs.MA",
            "q-fin.EC",
            "q-fin.TR"
        ]
    },
    {
        "title": "A Comparison of New Swarm Task Allocation Algorithms in Unknown   Environments with Varying Task Density",
        "authors": [
            "Grace Cai",
            "Noble Harasha",
            "Nancy Lynch"
        ],
        "summary": "Task allocation is an important problem for robot swarms to solve, allowing agents to reduce task completion time by performing tasks in a distributed fashion. Existing task allocation algorithms often assume prior knowledge of task location and demand or fail to consider the effects of the geometric distribution of tasks on the completion time and communication cost of the algorithms. In this paper, we examine an environment where agents must explore and discover tasks with positive demand and successfully assign themselves to complete all such tasks. We first provide a new discrete general model for modeling swarms. Operating within this theoretical framework, we propose two new task allocation algorithms for initially unknown environments -- one based on N-site selection and the other on virtual pheromones. We analyze each algorithm separately and also evaluate the effectiveness of the two algorithms in dense vs. sparse task distributions. Compared to the Levy walk, which has been theorized to be optimal for foraging, our virtual pheromone inspired algorithm is much faster in sparse to medium task densities but is communication and agent intensive. Our site selection inspired algorithm also outperforms Levy walk in sparse task densities and is a less resource-intensive option than our virtual pheromone algorithm for this case. Because the performance of both algorithms relative to random walk is dependent on task density, our results shed light on how task density is important in choosing a task allocation algorithm in initially unknown environments.",
        "published": "2022-12-01T20:04:00Z",
        "link": "http://arxiv.org/abs/2212.00844v3",
        "categories": [
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Flexible social inference facilitates targeted social learning when   rewards are not observable",
        "authors": [
            "Robert D. Hawkins",
            "Andrew M. Berdahl",
            "Alex \"Sandy\" Pentland",
            "Joshua B. Tenenbaum",
            "Noah D. Goodman",
            "P. M. Krafft"
        ],
        "summary": "Groups coordinate more effectively when individuals are able to learn from others' successes. But acquiring such knowledge is not always easy, especially in real-world environments where success is hidden from public view. We suggest that social inference capacities may help bridge this gap, allowing individuals to update their beliefs about others' underlying knowledge and success from observable trajectories of behavior. We compared our social inference model against simpler heuristics in three studies of human behavior in a collective sensing task. In Experiment 1, we found that average performance improves as a function of group size at a rate greater than predicted by non-inferential models. Experiment 2 introduced artificial agents to evaluate how individuals selectively rely on social information. Experiment 3 generalized these findings to a more complex reward landscape. Taken together, our findings provide insight into the relationship between individual social cognition and the flexibility of collective behavior.",
        "published": "2022-12-01T21:04:03Z",
        "link": "http://arxiv.org/abs/2212.00869v2",
        "categories": [
            "cs.MA",
            "cs.CY"
        ]
    },
    {
        "title": "Designing Ecosystems of Intelligence from First Principles",
        "authors": [
            "Karl J Friston",
            "Maxwell J D Ramstead",
            "Alex B Kiefer",
            "Alexander Tschantz",
            "Christopher L Buckley",
            "Mahault Albarracin",
            "Riddhi J Pitliya",
            "Conor Heins",
            "Brennan Klein",
            "Beren Millidge",
            "Dalton A R Sakthivadivel",
            "Toby St Clere Smithe",
            "Magnus Koudahl",
            "Safae Essafi Tremblay",
            "Capm Petersen",
            "Kaiser Fung",
            "Jason G Fox",
            "Steven Swanson",
            "Dan Mapes",
            "Gabriel René"
        ],
        "summary": "This white paper lays out a vision of research and development in the field of artificial intelligence for the next decade (and beyond). Its denouement is a cyber-physical ecosystem of natural and synthetic sense-making, in which humans are integral participants -- what we call ''shared intelligence''. This vision is premised on active inference, a formulation of adaptive behavior that can be read as a physics of intelligence, and which inherits from the physics of self-organization. In this context, we understand intelligence as the capacity to accumulate evidence for a generative model of one's sensed world -- also known as self-evidencing. Formally, this corresponds to maximizing (Bayesian) model evidence, via belief updating over several scales: i.e., inference, learning, and model selection. Operationally, this self-evidencing can be realized via (variational) message passing or belief propagation on a factor graph. Crucially, active inference foregrounds an existential imperative of intelligent systems; namely, curiosity or the resolution of uncertainty. This same imperative underwrites belief sharing in ensembles of agents, in which certain aspects (i.e., factors) of each agent's generative world model provide a common ground or frame of reference. Active inference plays a foundational role in this ecology of belief sharing -- leading to a formal account of collective intelligence that rests on shared narratives and goals. We also consider the kinds of communication protocols that must be developed to enable such an ecosystem of intelligences and motivate the development of a shared hyper-spatial modeling language and transaction protocol, as a first -- and key -- step towards such an ecology.",
        "published": "2022-12-02T18:24:06Z",
        "link": "http://arxiv.org/abs/2212.01354v2",
        "categories": [
            "cs.AI",
            "cs.MA",
            "nlin.AO"
        ]
    },
    {
        "title": "Multi-Agent Reinforcement Learning with Reward Delays",
        "authors": [
            "Yuyang Zhang",
            "Runyu Zhang",
            "Yuantao Gu",
            "Na Li"
        ],
        "summary": "This paper considers multi-agent reinforcement learning (MARL) where the rewards are received after delays and the delay time varies across agents and across time steps. Based on the V-learning framework, this paper proposes MARL algorithms that efficiently deal with reward delays. When the delays are finite, our algorithm reaches a coarse correlated equilibrium (CCE) with rate $\\tilde{\\mathcal{O}}(\\frac{H^3\\sqrt{S\\mathcal{T}_K}}{K}+\\frac{H^3\\sqrt{SA}}{\\sqrt{K}})$ where $K$ is the number of episodes, $H$ is the planning horizon, $S$ is the size of the state space, $A$ is the size of the largest action space, and $\\mathcal{T}_K$ is the measure of total delay formally defined in the paper. Moreover, our algorithm is extended to cases with infinite delays through a reward skipping scheme. It achieves convergence rate similar to the finite delay case.",
        "published": "2022-12-02T20:50:48Z",
        "link": "http://arxiv.org/abs/2212.01441v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Agent Miner: An Algorithm for Discovering Agent Systems from Event Data",
        "authors": [
            "Andrei Tour",
            "Artem Polyvyanyy",
            "Anna Kalenkova",
            "Arik Senderovich"
        ],
        "summary": "Process discovery studies ways to use event data generated by business processes and recorded by IT systems to construct models that describe the processes. Existing discovery algorithms are predominantly concerned with constructing process models that represent the control flow of the processes. Agent system mining argues that business processes often emerge from interactions of autonomous agents and uses event data to construct models of the agents and their interactions. This paper presents and evaluates Agent Miner, an algorithm for discovering models of agents and their interactions from event data composing the system that has executed the processes which generated the input data. The conducted evaluation using our open-source implementation of Agent Miner and publicly available industrial datasets confirms that our algorithm can provide insights into the process participants and their interaction patterns and often discovers models that describe the business processes more faithfully than process models discovered using conventional process discovery algorithms.",
        "published": "2022-12-02T21:36:14Z",
        "link": "http://arxiv.org/abs/2212.01454v3",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "DACOM: Learning Delay-Aware Communication for Multi-Agent Reinforcement   Learning",
        "authors": [
            "Tingting Yuan",
            "Hwei-Ming Chung",
            "Jie Yuan",
            "Xiaoming Fu"
        ],
        "summary": "Communication is supposed to improve multi-agent collaboration and overall performance in cooperative Multi-agent reinforcement learning (MARL). However, such improvements are prevalently limited in practice since most existing communication schemes ignore communication overheads (e.g., communication delays). In this paper, we demonstrate that ignoring communication delays has detrimental effects on collaborations, especially in delay-sensitive tasks such as autonomous driving. To mitigate this impact, we design a delay-aware multi-agent communication model (DACOM) to adapt communication to delays. Specifically, DACOM introduces a component, TimeNet, that is responsible for adjusting the waiting time of an agent to receive messages from other agents such that the uncertainty associated with delay can be addressed. Our experiments reveal that DACOM has a non-negligible performance improvement over other mechanisms by making a better trade-off between the benefits of communication and the costs of waiting for messages.",
        "published": "2022-12-03T14:20:59Z",
        "link": "http://arxiv.org/abs/2212.01619v1",
        "categories": [
            "cs.MA",
            "cs.LG",
            "cs.NI"
        ]
    },
    {
        "title": "Language Models as Agent Models",
        "authors": [
            "Jacob Andreas"
        ],
        "summary": "Language models (LMs) are trained on collections of documents, written by individual human agents to achieve specific goals in an outside world. During training, LMs have access only to text of these documents, with no direct evidence of the internal states of the agents that produced them -- a fact often used to argue that LMs are incapable of modeling goal-directed aspects of human language production and comprehension. Can LMs trained on text learn anything at all about the relationship between language and use? I argue that LMs are models of intentional communication in a specific, narrow sense. When performing next word prediction given a textual context, an LM can infer and represent properties of an agent likely to have produced that context. These representations can in turn influence subsequent LM generation in the same way that agents' communicative intentions influence their language. I survey findings from the recent literature showing that -- even in today's non-robust and error-prone models -- LMs infer and use representations of fine-grained communicative intentions and more abstract beliefs and goals. Despite the limited nature of their training data, they can thus serve as building blocks for systems that communicate and act intentionally.",
        "published": "2022-12-03T20:18:16Z",
        "link": "http://arxiv.org/abs/2212.01681v1",
        "categories": [
            "cs.CL",
            "cs.MA"
        ]
    },
    {
        "title": "Multi Agent Path Finding using Evolutionary Game Theory",
        "authors": [
            "Sheryl Paul",
            "Jyotirmoy V. Deshmukh"
        ],
        "summary": "In this paper, we consider the problem of path finding for a set of homogeneous and autonomous agents navigating a previously unknown stochastic environment. In our problem setting, each agent attempts to maximize a given utility function while respecting safety properties. Our solution is based on ideas from evolutionary game theory, namely replicating policies that perform well and diminishing ones that do not. We do a comprehensive comparison with related multiagent planning methods, and show that our technique beats state of the art RL algorithms in minimizing path length by nearly 30% in large spaces. We show that our algorithm is computationally faster than deep RL methods by at least an order of magnitude. We also show that it scales better with an increase in the number of agents as compared to other methods, path planning methods in particular. Lastly, we empirically prove that the policies that we learn are evolutionarily stable and thus impervious to invasion by any other policy.",
        "published": "2022-12-05T03:46:06Z",
        "link": "http://arxiv.org/abs/2212.02010v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.GT"
        ]
    },
    {
        "title": "Cooperative control of environmental extremes by artificial intelligent   agents",
        "authors": [
            "Martí Sánchez-Fibla",
            "Clément Moulin-Frier",
            "Ricard Solé"
        ],
        "summary": "Humans have been able to tackle biosphere complexities by acting as ecosystem engineers, profoundly changing the flows of matter, energy and information. This includes major innovations that allowed to reduce and control the impact of extreme events. Modelling the evolution of such adaptive dynamics can be challenging given the potentially large number of individual and environmental variables involved. This paper shows how to address this problem by using fire as the source of external, bursting and wide fluctuations. Fire propagates on a spatial landscape where a group of agents harvest and exploit trees while avoiding the damaging effects of fire spreading. The agents need to solve a conflict to reach a group-level optimal state: while tree harvesting reduces the propagation of fires, it also reduces the availability of resources provided by trees. It is shown that the system displays two major evolutionary innovations that end up in an ecological engineering strategy that favours high biomass along with the suppression of large fires. The implications for potential A.I. management of complex ecosystems are discussed.",
        "published": "2022-12-05T16:19:35Z",
        "link": "http://arxiv.org/abs/2212.02395v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "New Algorithms for the Fair and Efficient Allocation of Indivisible   Chores",
        "authors": [
            "Jugal Garg",
            "Aniket Murhekar",
            "John Qin"
        ],
        "summary": "We study the problem of fairly and efficiently allocating indivisible chores among agents with additive disutility functions. We consider the widely-used envy-based fairness properties of EF1 and EFX, in conjunction with the efficiency property of fractional Pareto-optimality (fPO). Existence (and computation) of an allocation that is simultaneously EF1/EFX and fPO are challenging open problems, and we make progress on both of them. We show existence of an allocation that is   - EF1+fPO, when there are three agents,   - EF1+fPO, when there are at most two disutility functions,   - EFX+fPO, for three agents with bivalued disutilities. These results are constructive, based on strongly polynomial-time algorithms. We also investigate non-existence and show that an allocation that is EFX+fPO need not exist, even for two agents.",
        "published": "2022-12-05T17:36:21Z",
        "link": "http://arxiv.org/abs/2212.02440v2",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "Distributed Bayesian Learning of Dynamic States",
        "authors": [
            "Mert Kayaalp",
            "Virginia Bordignon",
            "Stefan Vlaski",
            "Vincenzo Matta",
            "Ali H. Sayed"
        ],
        "summary": "This work studies networked agents cooperating to track a dynamical state of nature under partial information. The proposed algorithm is a distributed Bayesian filtering algorithm for finite-state hidden Markov models (HMMs). It can be used for sequential state estimation tasks, as well as for modeling opinion formation over social networks under dynamic environments. We show that the disagreement with the optimal centralized solution is asymptotically bounded for the class of geometrically ergodic state transition models, which includes rapidly changing models. We also derive recursions for calculating the probability of error and establish convergence under Gaussian observation models. Simulations are provided to illustrate the theory and to compare against alternative approaches.",
        "published": "2022-12-05T19:40:17Z",
        "link": "http://arxiv.org/abs/2212.02565v1",
        "categories": [
            "eess.SP",
            "cs.LG",
            "cs.MA",
            "cs.SI",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Learning Trust Over Directed Graphs in Multiagent Systems (extended   version)",
        "authors": [
            "Orhan Eren Akgün",
            "Arif Kerem Dayı",
            "Stephanie Gil",
            "Angelia Nedić"
        ],
        "summary": "We address the problem of learning the legitimacy of other agents in a multiagent network when an unknown subset is comprised of malicious actors. We specifically derive results for the case of directed graphs and where stochastic side information, or observations of trust, is available. We refer to this as ``learning trust'' since agents must identify which neighbors in the network are reliable, and we derive a protocol to achieve this. We also provide analytical results showing that under this protocol i) agents can learn the legitimacy of all other agents almost surely, and that ii) the opinions of the agents converge in mean to the true legitimacy of all other agents in the network. Lastly, we provide numerical studies showing that our convergence results hold in practice for various network topologies and variations in the number of malicious agents in the network.",
        "published": "2022-12-05T23:45:24Z",
        "link": "http://arxiv.org/abs/2212.02661v2",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "What is the Solution for State-Adversarial Multi-Agent Reinforcement   Learning?",
        "authors": [
            "Songyang Han",
            "Sanbao Su",
            "Sihong He",
            "Shuo Han",
            "Haizhao Yang",
            "Shaofeng Zou",
            "Fei Miao"
        ],
        "summary": "Various methods for Multi-Agent Reinforcement Learning (MARL) have been developed with the assumption that agents' policies are based on accurate state information. However, policies learned through Deep Reinforcement Learning (DRL) are susceptible to adversarial state perturbation attacks. In this work, we propose a State-Adversarial Markov Game (SAMG) and make the first attempt to investigate different solution concepts of MARL under state uncertainties. Our analysis shows that the commonly used solution concepts of optimal agent policy and robust Nash equilibrium do not always exist in SAMGs. To circumvent this difficulty, we consider a new solution concept called robust agent policy, where agents aim to maximize the worst-case expected state value. We prove the existence of robust agent policy for finite state and finite action SAMGs. Additionally, we propose a Robust Multi-Agent Adversarial Actor-Critic (RMA3C) algorithm to learn robust policies for MARL agents under state uncertainties. Our experiments demonstrate that our algorithm outperforms existing methods when faced with state perturbations and greatly improves the robustness of MARL policies. Our code is public on https://songyanghan.github.io/what_is_solution/.",
        "published": "2022-12-06T01:57:33Z",
        "link": "http://arxiv.org/abs/2212.02705v5",
        "categories": [
            "cs.AI",
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "CURO: Curriculum Learning for Relative Overgeneralization",
        "authors": [
            "Lin Shi",
            "Qiyuan Liu",
            "Bei Peng"
        ],
        "summary": "Relative overgeneralization (RO) is a pathology that can arise in cooperative multi-agent tasks when the optimal joint action's utility falls below that of a sub-optimal joint action. RO can cause the agents to get stuck into local optima or fail to solve cooperative tasks requiring significant coordination between agents within a given timestep. In this work, we empirically find that, in multi-agent reinforcement learning (MARL), both value-based and policy gradient MARL algorithms can suffer from RO and fail to learn effective coordination policies. To better overcome RO, we propose a novel approach called curriculum learning for relative overgeneralization (CURO). To solve a target task that exhibits strong RO, in CURO, we first fine-tune the reward function of the target task to generate source tasks to train the agent. Then, to effectively transfer the knowledge acquired in one task to the next, we use a transfer learning method that combines value function transfer with buffer transfer, which enables more efficient exploration in the target task. CURO is general and can be applied to both value-based and policy gradient MARL methods. We demonstrate that, when applied to QMIX, HAPPO, and HATRPO, CURO can successfully overcome severe RO, achieve improved performance, and outperform baseline methods in a variety of challenging cooperative multi-agent tasks.",
        "published": "2022-12-06T03:41:08Z",
        "link": "http://arxiv.org/abs/2212.02733v3",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Scalable Planning and Learning Framework Development for Swarm-to-Swarm   Engagement Problems",
        "authors": [
            "Umut Demir",
            "A. Sadik Satir",
            "Gulay Goktas Sever",
            "Cansu Yikilmaz",
            "Nazim Kemal Ure"
        ],
        "summary": "Development of guidance, navigation and control frameworks/algorithms for swarms attracted significant attention in recent years. That being said, algorithms for planning swarm allocations/trajectories for engaging with enemy swarms is largely an understudied problem. Although small-scale scenarios can be addressed with tools from differential game theory, existing approaches fail to scale for large-scale multi-agent pursuit evasion (PE) scenarios. In this work, we propose a reinforcement learning (RL) based framework to decompose to large-scale swarm engagement problems into a number of independent multi-agent pursuit-evasion games. We simulate a variety of multi-agent PE scenarios, where finite time capture is guaranteed under certain conditions. The calculated PE statistics are provided as a reward signal to the high level allocation layer, which uses an RL algorithm to allocate controlled swarm units to eliminate enemy swarm units with maximum efficiency. We verify our approach in large-scale swarm-to-swarm engagement simulations.",
        "published": "2022-12-06T12:08:09Z",
        "link": "http://arxiv.org/abs/2212.02909v1",
        "categories": [
            "cs.AI",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Consensus of Double Integrator Multiagent Systems under Nonuniform   Sampling and Changing Topology",
        "authors": [
            "Ufuk Sevim",
            "Leyla Goren-Sumer"
        ],
        "summary": "This article considers consensus problem of multiagent systems with double integrator dynamics under nonuniform sampling. It is considered the maximum sampling time can be selected arbitrarily. Moreover, the communication graph can change to any possible topology as long as its associated graph Laplacian has eigenvalues in a given region, which can be selected arbitrarily. Existence of a controller that ensures consensus in this setting is shown when the changing topology graphs are balanced and has a spanning tree. Also, explicit bounds for controller parameters are given. A novel sufficient condition is given to solve the consensus problem based on making the closed loop system matrix a contraction using a particular coordinate system for general linear dynamics. It is shown that the given condition immediately generalizes to changing topology in the case of balanced topology graphs. This condition is applied to double integrator dynamics to obtain explicit bounds on the controller.",
        "published": "2022-12-06T12:29:37Z",
        "link": "http://arxiv.org/abs/2212.02922v1",
        "categories": [
            "math.DS",
            "cs.MA"
        ]
    },
    {
        "title": "Towards a more efficient computation of individual attribute and policy   contribution for post-hoc explanation of cooperative multi-agent systems   using Myerson values",
        "authors": [
            "Giorgio Angelotti",
            "Natalia Díaz-Rodríguez"
        ],
        "summary": "A quantitative assessment of the global importance of an agent in a team is as valuable as gold for strategists, decision-makers, and sports coaches. Yet, retrieving this information is not trivial since in a cooperative task it is hard to isolate the performance of an individual from the one of the whole team. Moreover, it is not always clear the relationship between the role of an agent and his personal attributes. In this work we conceive an application of the Shapley analysis for studying the contribution of both agent policies and attributes, putting them on equal footing. Since the computational complexity is NP-hard and scales exponentially with the number of participants in a transferable utility coalitional game, we resort to exploiting a-priori knowledge about the rules of the game to constrain the relations between the participants over a graph. We hence propose a method to determine a Hierarchical Knowledge Graph of agents' policies and features in a Multi-Agent System. Assuming a simulator of the system is available, the graph structure allows to exploit dynamic programming to assess the importances in a much faster way. We test the proposed approach in a proof-of-case environment deploying both hardcoded policies and policies obtained via Deep Reinforcement Learning. The proposed paradigm is less computationally demanding than trivially computing the Shapley values and provides great insight not only into the importance of an agent in a team but also into the attributes needed to deploy the policy at its best.",
        "published": "2022-12-06T15:15:00Z",
        "link": "http://arxiv.org/abs/2212.03041v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Partial gathering of mobile agents in dynamic rings",
        "authors": [
            "Masahiro Shibata",
            "Yuichi Sudo",
            "Junya Nakamura",
            "Yonghwan Kim"
        ],
        "summary": "In this paper, we consider the partial gathering problem of mobile agents in synchronous dynamic bidirectional ring networks. When k agents are distributed in the network, the partial gathering problem requires, for a given positive integer g (< k), that agents terminate in a configuration such that either at least g agents or no agent exists at each node. So far, the partial gathering problem has been considered in static graphs. In this paper, we start considering partial gathering in dynamic graphs. As a first step, we consider this problem in 1-interval connected rings, that is, one of the links in a ring may be missing at each time step. In such networks, focusing on the relationship between the values of k and g, we fully characterize the solvability of the partial gathering problem and analyze the move complexity of the proposed algorithms when the problem can be solved. First, we show that the g-partial gathering problem is unsolvable when k <= 2g. Second, we show that the problem can be solved with O(n log g) time and the total number of O(gn log g) moves when 2g + 1 <= k <= 3g - 2. Third, we show that the problem can be solved with O(n) time and the total number of O(kn) moves when 3g - 1 <= k <= 8g - 4. Notice that since k = O(g) holds when 3g - 1 <= k <= 8g - 4, the move complexity O(kn) in this case can be represented also as O(gn). Finally, we show that the problem can be solved with O(n) time and the total number of O(gn) moves when k >= 8g - 3. These results mean that the partial gathering problem can be solved also in dynamic rings when k >= 2g + 1. In addition, agents require a total number of \\Omega(gn) moves to solve the partial (resp., total) gathering problem. Thus, when k >= 3g - 1, agents can solve the partial gathering problem with the asymptotically optimal total number of O(gn) moves.",
        "published": "2022-12-07T04:46:26Z",
        "link": "http://arxiv.org/abs/2212.03457v2",
        "categories": [
            "cs.CC",
            "cs.MA"
        ]
    },
    {
        "title": "Distributed Interaction Graph Construction for Dynamic DCOPs in   Cooperative Multi-agent Systems",
        "authors": [
            "Brighter Agyemang",
            "Fenghui Ren",
            "Jun Yan"
        ],
        "summary": "DCOP algorithms usually rely on interaction graphs to operate. In open and dynamic environments, such methods need to address how this interaction graph is generated and maintained among agents. Existing methods require reconstructing the entire graph upon detecting changes in the environment or assuming that new agents know potential neighbors to facilitate connection. We propose a novel distributed interaction graph construction algorithm to address this problem. The proposed method does not assume a predefined constraint graph and stabilizes after disruptive changes in the environment. We evaluate our approach by pairing it with existing DCOP algorithms to solve several generated dynamic problems. The experiment results show that the proposed algorithm effectively constructs and maintains a stable multi-agent interaction graph for open and dynamic environments.",
        "published": "2022-12-07T05:03:04Z",
        "link": "http://arxiv.org/abs/2212.03461v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "An Agent-based Realisation for a continuous Model Adaption Approach in   intelligent Digital Twins",
        "authors": [
            "Daniel Dittler",
            "Peter Lierhammer",
            "Dominik Braun",
            "Timo Müller",
            "Nasser Jazdi",
            "Michael Weyrich"
        ],
        "summary": "The trend in industrial automation is towards networking, intelligence and autonomy. Digital Twins, which serve as virtual representations, are becoming increasingly important in this context. The Digital Twin of a modular production system contains many different models that are mostly created for specific applications and fulfil different requirements. Especially simulation models, which are created in the development phase, can be used during the operational phase for applications such as prognosis or operation-parallel simulation. Due to the high heterogeneity of the model landscape in the context of a modular production system, the plant operator is faced with the challenge of adapting the models in order to ensure an application-oriented realism in the event of changes to the asset and its environment or the addition of applications. Therefore, this paper proposes a concept for the continuous model adaption in the Digital Twin of a modular production system during the operational phase. The benefits are then demonstrated by an application scenario and an agent-based realisation.",
        "published": "2022-12-07T14:51:57Z",
        "link": "http://arxiv.org/abs/2212.03681v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Elixir: A system to enhance data quality for multiple analytics on a   video stream",
        "authors": [
            "Sibendu Paul",
            "Kunal Rao",
            "Giuseppe Coviello",
            "Murugan Sankaradas",
            "Oliver Po",
            "Y. Charlie Hu",
            "Srimat T. Chakradhar"
        ],
        "summary": "IoT sensors, especially video cameras, are ubiquitously deployed around the world to perform a variety of computer vision tasks in several verticals including retail, healthcare, safety and security, transportation, manufacturing, etc. To amortize their high deployment effort and cost, it is desirable to perform multiple video analytics tasks, which we refer to as Analytical Units (AUs), off the video feed coming out of every camera. In this paper, we first show that in a multi-AU setting, changing the camera setting has disproportionate impact on different AUs performance. In particular, the optimal setting for one AU may severely degrade the performance for another AU, and further the impact on different AUs varies as the environmental condition changes. We then present Elixir, a system to enhance the video stream quality for multiple analytics on a video stream. Elixir leverages Multi-Objective Reinforcement Learning (MORL), where the RL agent caters to the objectives from different AUs and adjusts the camera setting to simultaneously enhance the performance of all AUs. To define the multiple objectives in MORL, we develop new AU-specific quality estimator values for each individual AU. We evaluate Elixir through real-world experiments on a testbed with three cameras deployed next to each other (overlooking a large enterprise parking lot) running Elixir and two baseline approaches, respectively. Elixir correctly detects 7.1% (22,068) and 5.0% (15,731) more cars, 94% (551) and 72% (478) more faces, and 670.4% (4975) and 158.6% (3507) more persons than the default-setting and time-sharing approaches, respectively. It also detects 115 license plates, far more than the time-sharing approach (7) and the default setting (0).",
        "published": "2022-12-08T04:04:58Z",
        "link": "http://arxiv.org/abs/2212.04061v1",
        "categories": [
            "cs.CV",
            "cs.MA"
        ]
    },
    {
        "title": "Reducing Collision Risk in Multi-Agent Path Planning: Application to Air   traffic Management",
        "authors": [
            "Sarah H. Q. Li",
            "Avi Mittal",
            "Pierre-Loïc Garoche",
            "Açıkmeşe",
            "Behçet"
        ],
        "summary": "To minimize collision risks in the multi-agent path planning problem with stochastic transition dynamics, we formulate a Markov decision process congestion game with a multi-linear congestion cost. Players within the game complete individual tasks while minimizing their own collision risks. We show that the set of Nash equilibria coincides with the first-order KKT points of a non-convex optimization problem. Our game is applied to a historical flight plan over France to reduce collision risks between commercial aircraft.",
        "published": "2022-12-08T07:44:29Z",
        "link": "http://arxiv.org/abs/2212.04122v2",
        "categories": [
            "cs.MA",
            "cs.GT"
        ]
    },
    {
        "title": "Activity-Based Recommendations for Demand Response in Smart Sustainable   Buildings",
        "authors": [
            "Alona Zharova",
            "Laura Löschmann"
        ],
        "summary": "The energy consumption of private households amounts to approximately 30% of the total global energy consumption, causing a large share of the CO2 emissions through energy production. An intelligent demand response via load shifting increases the energy efficiency of residential buildings by nudging residents to change their energy consumption behavior. This paper introduces an activity prediction-based framework for the utility-based context-aware multi-agent recommendation system that generates an activity shifting schedule for a 24-hour time horizon to either focus on CO2 emissions or energy cost savings. In particular, we design and implement an Activity Agent that uses hourly energy consumption data. It does not require further sensorial data or activity labels which reduces implementation costs and the need for extensive user input. Moreover, the system enhances the utility option of saving energy costs by saving CO2 emissions and provides the possibility to focus on both dimensions. The empirical results show that while setting the focus on CO2 emissions savings, the system provides an average of 12% of emissions savings and 7% of cost savings. When focusing on energy cost savings, 20% of energy costs and 6% of emissions savings are possible for the studied households in case of accepting all recommendations. Recommending an activity schedule, the system uses the same terms residents describe their domestic life. Therefore, recommendations can be more easily integrated into daily life supporting the acceptance of the system in a long-term perspective.",
        "published": "2022-12-10T01:44:37Z",
        "link": "http://arxiv.org/abs/2212.05173v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Exploiting the Power of Human-Robot Collaboration: Coupling and Scale   Effects in Bricklaying",
        "authors": [
            "Jia-Rui Lin",
            "Ming-Hui Wu"
        ],
        "summary": "As an important contributor to GDP growth, the construction industry is suffering from labor shortage due to population ageing, COVID-19 pandemic, and harsh environments. Considering the complexity and dynamics of construction environment, it is still challenging to develop fully automated robots. For a long time in the future, workers and robots will coexist and collaborate with each other to build or maintain a facility efficiently. As an emerging field, human-robot collaboration (HRC) still faces various open problems. To this end, this pioneer research introduces an agent-based modeling approach to investigate the coupling effect and scale effect of HRC in the bricklaying process. With multiple experiments based on simulation, the dynamic and complex nature of HRC is illustrated in two folds: 1) agents in HRC are interdependent due to human factors of workers, features of robots, and their collaboration behaviors; 2) different parameters of HRC are correlated and have significant impacts on construction productivity (CP). Accidentally and interestingly, it is discovered that HRC has a scale effect on CP, which means increasing the number of collaborated human-robot teams will lead to higher CP even if the human-robot ratio keeps unchanged. Overall, it is argued that more investigations in HRC are needed for efficient construction, occupational safety, etc.; and this research can be taken as a stepstone for developing and evaluating new robots, optimizing HRC processes, and even training future industrial workers in the construction industry.",
        "published": "2022-12-10T02:12:02Z",
        "link": "http://arxiv.org/abs/2212.05181v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Lookahead Pathology in Monte-Carlo Tree Search",
        "authors": [
            "Khoi P. N. Nguyen",
            "Raghuram Ramanujan"
        ],
        "summary": "Monte-Carlo Tree Search (MCTS) is a search paradigm that first found prominence with its success in the domain of computer Go. Early theoretical work established the soundness and convergence bounds for Upper Confidence bounds applied to Trees (UCT), the most popular instantiation of MCTS; however, there remain notable gaps in our understanding of how UCT behaves in practice. In this work, we address one such gap by considering the question of whether UCT can exhibit lookahead pathology in adversarial settings -- a paradoxical phenomenon first observed in Minimax search where greater search effort leads to worse decision-making. We introduce a novel family of synthetic games that offer rich modeling possibilities while remaining amenable to mathematical analysis. Our theoretical and experimental results suggest that UCT is indeed susceptible to pathological behavior in a range of games drawn from this family.",
        "published": "2022-12-10T05:13:56Z",
        "link": "http://arxiv.org/abs/2212.05208v2",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Decentralized cooperative perception for autonomous vehicles: Learning   to value the unknown",
        "authors": [
            "Maxime Chaveroche",
            "Franck Davoine",
            "Véronique Cherfaoui"
        ],
        "summary": "Recently, we have been witnesses of accidents involving autonomous vehicles and their lack of sufficient information. One way to tackle this issue is to benefit from the perception of different view points, namely cooperative perception. We propose here a decentralized collaboration, i.e. peer-to-peer, in which the agents are active in their quest for full perception by asking for specific areas in their surroundings on which they would like to know more. Ultimately, we want to optimize a trade-off between the maximization of knowledge about moving objects and the minimization of the total volume of information received from others, to limit communication costs and message processing time. For this, we propose a way to learn a communication policy that reverses the usual communication paradigm by only requesting from other vehicles what is unknown to the ego-vehicle, instead of filtering on the sender side. We tested three different generative models to be taken as base for a Deep Reinforcement Learning (DRL) algorithm, and compared them to a broadcasting policy and a policy randomly selecting areas. In particular, we propose Locally Predictable VAE (LP-VAE), which appears to be producing better belief states for predictions than state-of-the-art models, both as a standalone model and in the context of DRL. Experiments were conducted in the driving simulator CARLA. Our best models reached on average a gain of 25% of the total complementary information, while only requesting about 5% of the ego-vehicle's perceptual field. This trade-off is adjustable through the interpretable hyperparameters of our reward function.",
        "published": "2022-12-12T00:01:27Z",
        "link": "http://arxiv.org/abs/2301.01250v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Where to go: Agent Guidance with Deep Reinforcement Learning in A   City-Scale Online Ride-Hailing Service",
        "authors": [
            "Jiyao Li",
            "Vicki H. Allan"
        ],
        "summary": "Online ride-hailing services have become a prevalent transportation system across the world. In this paper, we study a challenging problem of how to direct vacant taxis around a city such that supplies and demands can be balanced in online ride-hailing services. We design a new reward scheme that considers multiple performance metrics of online ride-hailing services. We also propose a novel deep reinforcement learning method named Deep-Q-Network with Action Mask (AM-DQN) masking off unnecessary actions in various locations such that agents can learn much faster and more efficiently. We conduct extensive experiments using a city-scale dataset from Chicago. Several popular heuristic and learning methods are also implemented as baselines for comparison. The results of the experiments show that the AM-DQN attains the best performances of all methods with respect to average failure rate, average waiting time for customers, and average idle search time for vacant taxis.",
        "published": "2022-12-12T07:42:57Z",
        "link": "http://arxiv.org/abs/2212.05742v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Opponent Modeling in Multiplayer Imperfect-Information Games",
        "authors": [
            "Sam Ganzfried",
            "Kevin A. Wang",
            "Max Chiswick"
        ],
        "summary": "In many real-world settings agents engage in strategic interactions with multiple opposing agents who can employ a wide variety of strategies. The standard approach for designing agents for such settings is to compute or approximate a relevant game-theoretic solution concept such as Nash equilibrium and then follow the prescribed strategy. However, such a strategy ignores any observations of opponents' play, which may indicate shortcomings that can be exploited. We present an approach for opponent modeling in multiplayer imperfect-information games where we collect observations of opponents' play through repeated interactions. We run experiments against a wide variety of real opponents and exact Nash equilibrium strategies in three-player Kuhn poker and show that our algorithm significantly outperforms all of the agents, including the exact Nash equilibrium strategies.",
        "published": "2022-12-12T16:48:53Z",
        "link": "http://arxiv.org/abs/2212.06027v4",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.MA",
            "econ.TH"
        ]
    },
    {
        "title": "Decentralized Stochastic Multi-Player Multi-Armed Walking Bandits",
        "authors": [
            "Guojun Xiong",
            "Jian Li"
        ],
        "summary": "Multi-player multi-armed bandit is an increasingly relevant decision-making problem, motivated by applications to cognitive radio systems. Most research for this problem focuses exclusively on the settings that players have \\textit{full access} to all arms and receive no reward when pulling the same arm. Hence all players solve the same bandit problem with the goal of maximizing their cumulative reward. However, these settings neglect several important factors in many real-world applications, where players have \\textit{limited access} to \\textit{a dynamic local subset of arms} (i.e., an arm could sometimes be ``walking'' and not accessible to the player). To this end, this paper proposes a \\textit{multi-player multi-armed walking bandits} model, aiming to address aforementioned modeling issues. The goal now is to maximize the reward, however, players can only pull arms from the local subset and only collect a full reward if no other players pull the same arm. We adopt Upper Confidence Bound (UCB) to deal with the exploration-exploitation tradeoff and employ distributed optimization techniques to properly handle collisions. By carefully integrating these two techniques, we propose a decentralized algorithm with near-optimal guarantee on the regret, and can be easily implemented to obtain competitive empirical performance.",
        "published": "2022-12-12T23:26:02Z",
        "link": "http://arxiv.org/abs/2212.06279v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "stat.ML"
        ]
    },
    {
        "title": "Scalable and Sample Efficient Distributed Policy Gradient Algorithms in   Multi-Agent Networked Systems",
        "authors": [
            "Xin Liu",
            "Honghao Wei",
            "Lei Ying"
        ],
        "summary": "This paper studies a class of multi-agent reinforcement learning (MARL) problems where the reward that an agent receives depends on the states of other agents, but the next state only depends on the agent's own current state and action. We name it REC-MARL standing for REward-Coupled Multi-Agent Reinforcement Learning. REC-MARL has a range of important applications such as real-time access control and distributed power control in wireless networks. This paper presents a distributed policy gradient algorithm for REC-MARL. The proposed algorithm is distributed in two aspects: (i) the learned policy is a distributed policy that maps a local state of an agent to its local action and (ii) the learning/training is distributed, during which each agent updates its policy based on its own and neighbors' information. The learned algorithm achieves a stationary policy and its iterative complexity bounds depend on the dimension of local states and actions. The experimental results of our algorithm for the real-time access control and power control in wireless networks show that our policy significantly outperforms the state-of-the-art algorithms and well-known benchmarks.",
        "published": "2022-12-13T03:44:00Z",
        "link": "http://arxiv.org/abs/2212.06357v2",
        "categories": [
            "cs.MA",
            "cs.LG"
        ]
    },
    {
        "title": "Target Defense against Sequentially Arriving Intruders",
        "authors": [
            "Arman Pourghorban",
            "Michael Dorothy",
            "Daigo Shishika",
            "Alexander Von Moll",
            "Dipankar Maity"
        ],
        "summary": "We consider a variant of the target defense problem where a single defender is tasked to capture a sequence of incoming intruders. The intruders' objective is to breach the target boundary without being captured by the defender. As soon as the current intruder breaches the target or gets captured by the defender, the next intruder appears at a random location on a fixed circle surrounding the target. Therefore, the defender's final location at the end of the current game becomes its initial location for the next game. Thus, the players pick strategies that are advantageous for the current as well as for the future games. Depending on the information available to the players, each game is divided into two phases: partial information and full information phase. Under some assumptions on the sensing and speed capabilities, we analyze the agents' strategies in both phases. We derive equilibrium strategies for both the players to optimize the capture percentage using the notions of engagement surface and capture circle. We quantify the percentage of capture for both finite and infinite sequences of incoming intruders.",
        "published": "2022-12-13T15:01:02Z",
        "link": "http://arxiv.org/abs/2212.06628v1",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Heuristically Guided Compilation for Multi-Agent Path Finding",
        "authors": [
            "Pavel Surynek"
        ],
        "summary": "Multi-agent path finding (MAPF) is a task of finding non-conflicting paths connecting agents' specified initial and goal positions in a shared environment. We focus on compilation-based solvers in which the MAPF problem is expressed in a different well established formalism such as mixed-integer linear programming (MILP), Boolean satisfiability (SAT), or constraint programming (CP). As the target solvers for these formalisms act as black-boxes it is challenging to integrate MAPF specific heuristics in the MAPF compilation-based solvers. We show in this work how the build a MAPF encoding for the target SAT solver in which domain specific heuristic knowledge is reflected. The heuristic knowledge is transferred to the SAT solver by selecting candidate paths for each agent and by constructing the encoding only for these candidate paths instead of constructing the encoding for all possible paths for an agent. The conducted experiments show that heuristically guided compilation outperforms the vanilla variants of the SAT-based MAPF solver.",
        "published": "2022-12-13T23:19:15Z",
        "link": "http://arxiv.org/abs/2212.06940v1",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "A Hierarchical Framework for Collaborative Artificial Intelligence",
        "authors": [
            "James L. Crowley",
            "Joëlle L Coutaz",
            "Jasmin Grosinger",
            "Javier Vázquez-Salceda",
            "Cecilio Angulo",
            "Alberto Sanfeliu",
            "Luca Iocchi",
            "Anthony G. Cohn"
        ],
        "summary": "We propose a hierarchical framework for collaborative intelligent systems. This framework organizes research challenges based on the nature of the collaborative activity and the information that must be shared, with each level building on capabilities provided by lower levels. We review research paradigms at each level, with a description of classical engineering-based approaches and modern alternatives based on machine learning, illustrated with a running example using a hypothetical personal service robot. We discuss cross-cutting issues that occur at all levels, focusing on the problem of communicating and sharing comprehension, the role of explanation and the social nature of collaboration. We conclude with a summary of research challenges and a discussion of the potential for economic and societal impact provided by technologies that enhance human abilities and empower people and society through collaboration with Intelligent Systems.",
        "published": "2022-12-14T09:59:22Z",
        "link": "http://arxiv.org/abs/2212.08659v1",
        "categories": [
            "cs.AI",
            "cs.HC",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Hybrid Multi-agent Deep Reinforcement Learning for Autonomous Mobility   on Demand Systems",
        "authors": [
            "Tobias Enders",
            "James Harrison",
            "Marco Pavone",
            "Maximilian Schiffer"
        ],
        "summary": "We consider the sequential decision-making problem of making proactive request assignment and rejection decisions for a profit-maximizing operator of an autonomous mobility on demand system. We formalize this problem as a Markov decision process and propose a novel combination of multi-agent Soft Actor-Critic and weighted bipartite matching to obtain an anticipative control policy. Thereby, we factorize the operator's otherwise intractable action space, but still obtain a globally coordinated decision. Experiments based on real-world taxi data show that our method outperforms state of the art benchmarks with respect to performance, stability, and computational tractability.",
        "published": "2022-12-14T16:19:51Z",
        "link": "http://arxiv.org/abs/2212.07313v2",
        "categories": [
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Hierarchical Strategies for Cooperative Multi-Agent Reinforcement   Learning",
        "authors": [
            "Majd Ibrahim",
            "Ammar Fayad"
        ],
        "summary": "Adequate strategizing of agents behaviors is essential to solving cooperative MARL problems. One intuitively beneficial yet uncommon method in this domain is predicting agents future behaviors and planning accordingly. Leveraging this point, we propose a two-level hierarchical architecture that combines a novel information-theoretic objective with a trajectory prediction model to learn a strategy. To this end, we introduce a latent policy that learns two types of latent strategies: individual $z_A$, and relational $z_R$ using a modified Graph Attention Network module to extract interaction features. We encourage each agent to behave according to the strategy by conditioning its local $Q$ functions on $z_A$, and we further equip agents with a shared $Q$ function that conditions on $z_R$. Additionally, we introduce two regularizers to allow predicted trajectories to be accurate and rewarding. Empirical results on Google Research Football (GRF) and StarCraft (SC) II micromanagement tasks show that our method establishes a new state of the art being, to the best of our knowledge, the first MARL algorithm to solve all super hard SC II scenarios as well as the GRF full game with a win rate higher than $95\\%$, thus outperforming all existing methods. Videos and brief overview of the methods and results are available at: https://sites.google.com/view/hier-strats-marl/home.",
        "published": "2022-12-14T18:27:58Z",
        "link": "http://arxiv.org/abs/2212.07397v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "SMACv2: An Improved Benchmark for Cooperative Multi-Agent Reinforcement   Learning",
        "authors": [
            "Benjamin Ellis",
            "Jonathan Cook",
            "Skander Moalla",
            "Mikayel Samvelyan",
            "Mingfei Sun",
            "Anuj Mahajan",
            "Jakob N. Foerster",
            "Shimon Whiteson"
        ],
        "summary": "The availability of challenging benchmarks has played a key role in the recent progress of machine learning. In cooperative multi-agent reinforcement learning, the StarCraft Multi-Agent Challenge (SMAC) has become a popular testbed for centralised training with decentralised execution. However, after years of sustained improvement on SMAC, algorithms now achieve near-perfect performance. In this work, we conduct new analysis demonstrating that SMAC lacks the stochasticity and partial observability to require complex *closed-loop* policies. In particular, we show that an *open-loop* policy conditioned only on the timestep can achieve non-trivial win rates for many SMAC scenarios. To address this limitation, we introduce SMACv2, a new version of the benchmark where scenarios are procedurally generated and require agents to generalise to previously unseen settings (from the same distribution) during evaluation. We also introduce the extended partial observability challenge (EPO), which augments SMACv2 to ensure meaningful partial observability. We show that these changes ensure the benchmark requires the use of *closed-loop* policies. We evaluate state-of-the-art algorithms on SMACv2 and show that it presents significant challenges not present in the original benchmark. Our analysis illustrates that SMACv2 addresses the discovered deficiencies of SMAC and can help benchmark the next generation of MARL methods. Videos of training are available at https://sites.google.com/view/smacv2.",
        "published": "2022-12-14T20:15:19Z",
        "link": "http://arxiv.org/abs/2212.07489v2",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Adaptive Multi-Agent Continuous Learning System",
        "authors": [
            "Xingyu Qian",
            "Aximu Yuemaier",
            "Longfei Liang",
            "Wen-Chi Yang",
            "Xiaogang Chen",
            "Shunfen Li",
            "Weibang Dai",
            "Zhitang Song"
        ],
        "summary": "We propose an adaptive multi-agent clustering recognition system that can be self-supervised driven, based on a temporal sequences continuous learning mechanism with adaptability. The system is designed to use some different functional agents to build up a connection structure to improve adaptability to cope with environmental diverse demands, by predicting the input of the agent to drive the agent to achieve the act of clustering recognition of sequences using the traditional algorithmic approach. Finally, the feasibility experiments of video behavior clustering demonstrate the feasibility of the system to cope with dynamic situations. Our work is placed here\\footnote{https://github.com/qian-git/MAMMALS}.",
        "published": "2022-12-15T07:39:50Z",
        "link": "http://arxiv.org/abs/2212.07646v2",
        "categories": [
            "cs.CV",
            "cs.MA"
        ]
    },
    {
        "title": "Classification-Based Opinion Formation Model Embedding Agents'   Psychological Traits",
        "authors": [
            "Carlos Andres Devia",
            "Giulia Giordano"
        ],
        "summary": "We propose an agent-based opinion formation model characterised by a two-fold novelty. First, we realistically assume that each agent cannot measure the opinion of its neighbours with infinite resolution and accuracy, and hence it can only classify the opinion of others as agreeing much more, or more, or comparably, or less, or much less (than itself) with a given statement. This leads to a classification-based rule for opinion update. Second, we consider three complementary agent traits suggested by significant sociological and psychological research: conformism, radicalism and stubbornness. We rely on World Values Survey data to show that the proposed model has the potential to predict the evolution of opinions in real life: the classification-based approach and complementary agent traits produce rich collective behaviours, such as polarisation, consensus, and clustering, which can yield predicted opinions similar to survey results.",
        "published": "2022-12-15T10:34:15Z",
        "link": "http://arxiv.org/abs/2212.07709v1",
        "categories": [
            "cs.SI",
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "math.OC",
            "q-bio.PE"
        ]
    },
    {
        "title": "Emergent Behaviors in Multi-Agent Target Acquisition",
        "authors": [
            "Piyush K. Sharma",
            "Erin Zaroukian",
            "Derrik E. Asher",
            "Bryson Howell"
        ],
        "summary": "Only limited studies and superficial evaluations are available on agents' behaviors and roles within a Multi-Agent System (MAS). We simulate a MAS using Reinforcement Learning (RL) in a pursuit-evasion (a.k.a predator-prey pursuit) game, which shares task goals with target acquisition, and we create different adversarial scenarios by replacing RL-trained pursuers' policies with two distinct (non-RL) analytical strategies. Using heatmaps of agents' positions (state-space variable) over time, we are able to categorize an RL-trained evader's behaviors. The novelty of our approach entails the creation of an influential feature set that reveals underlying data regularities, which allow us to classify an agent's behavior. This classification may aid in catching the (enemy) targets by enabling us to identify and predict their behaviors, and when extended to pursuers, this approach towards identifying teammates' behavior may allow agents to coordinate more effectively.",
        "published": "2022-12-15T15:20:58Z",
        "link": "http://arxiv.org/abs/2212.07891v1",
        "categories": [
            "cs.AI",
            "cs.CV",
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Distributed-Training-and-Execution Multi-Agent Reinforcement Learning   for Power Control in HetNet",
        "authors": [
            "Kaidi Xu",
            "Nguyen Van Huynh",
            "Geoffrey Ye Li"
        ],
        "summary": "In heterogeneous networks (HetNets), the overlap of small cells and the macro cell causes severe cross-tier interference. Although there exist some approaches to address this problem, they usually require global channel state information, which is hard to obtain in practice, and get the sub-optimal power allocation policy with high computational complexity. To overcome these limitations, we propose a multi-agent deep reinforcement learning (MADRL) based power control scheme for the HetNet, where each access point makes power control decisions independently based on local information. To promote cooperation among agents, we develop a penalty-based Q learning (PQL) algorithm for MADRL systems. By introducing regularization terms in the loss function, each agent tends to choose an experienced action with high reward when revisiting a state, and thus the policy updating speed slows down. In this way, an agent's policy can be learned by other agents more easily, resulting in a more efficient collaboration process. We then implement the proposed PQL in the considered HetNet and compare it with other distributed-training-and-execution (DTE) algorithms. Simulation results show that our proposed PQL can learn the desired power control policy from a dynamic environment where the locations of users change episodically and outperform existing DTE MADRL algorithms.",
        "published": "2022-12-15T17:01:56Z",
        "link": "http://arxiv.org/abs/2212.07967v1",
        "categories": [
            "eess.SY",
            "cs.LG",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Agent-Based Model of Crowd Dynamics in Emergency Situations: A Focus on   People With Disabilities",
        "authors": [
            "Janey Alex",
            "Jason Stillerman",
            "Noah Fritzhand",
            "Tucker Paron"
        ],
        "summary": "Collective behavior of people in large groups and emergent crowd dynamics can have dangerous and disastrous results when panic is introduced. These events can be caused by emergency situations such as fires in a large building or a stampeding effect when people are rushing in a densely packed area. In this paper, we will use an agent-based modeling approach to simulate different evacuation events in an attempt to understand what is the most efficient scenario. Specifically, we will focus on how people with disabilities are impacted by chosen parameters during an emergency evacuation. We chose an ABM to simulate this because we want to specify specific roles for different \"agents\" in our model. Specifically, we will focus on the influence of people with disabilities on crowd dynamics and the optimal exits. Does the placement of seating for people with disabilities affect the time it takes for the last person to exit the building? What effect does poor signage have on the time it takes for able-bodied and people with disabilities to exit safely? What happens if some people do not know about alternative exits in their panicked state? Using our agent-based model, we will investigate these questions while also adjusting other outside effects such as the density of the crowd, the speed at which people exit, and the location of people at the start of the simulation.",
        "published": "2022-12-15T21:33:18Z",
        "link": "http://arxiv.org/abs/2212.08149v1",
        "categories": [
            "stat.CO",
            "cs.MA",
            "62-04"
        ]
    },
    {
        "title": "An Energy-aware and Fault-tolerant Deep Reinforcement Learning based   approach for Multi-agent Patrolling Problems",
        "authors": [
            "Chenhao Tong",
            "Aaron Harwood",
            "Maria A. Rodriguez",
            "Richard O. Sinnott"
        ],
        "summary": "Autonomous vehicles are suited for continuous area patrolling problems. However, finding an optimal patrolling strategy can be challenging for many reasons. Firstly, patrolling environments are often complex and can include unknown environmental factors, such as wind or landscape. Secondly, autonomous vehicles can have failures or hardware constraints, such as limited battery life. Importantly, patrolling large areas often requires multiple agents that need to collectively coordinate their actions. In this work, we consider these limitations and propose an approach based on model-free, deep multi-agent reinforcement learning. In this approach, the agents are trained to patrol an environment with various unknown dynamics and factors. They can automatically recharge themselves to support continuous collective patrolling. A distributed homogeneous multi-agent architecture is proposed, where all patrolling agents execute identical policies locally based on their local observations and shared location information. This architecture provides a patrolling system that can tolerate agent failures and allow supplementary agents to be added to replace failed agents or to increase the overall patrol performance. The solution is validated through simulation experiments from multiple perspectives, including the overall patrol performance, the efficiency of battery recharging strategies, the overall fault tolerance, and the ability to cooperate with supplementary agents.",
        "published": "2022-12-16T01:38:35Z",
        "link": "http://arxiv.org/abs/2212.08230v4",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Emergent communication enhances foraging behaviour in evolved swarms   controlled by Spiking Neural Networks",
        "authors": [
            "Cristian Jimenez Romero",
            "Alper Yegenoglu",
            "Aarón Pérez Martín",
            "Sandra Diaz-Pier",
            "Abigail Morrison"
        ],
        "summary": "Social insects such as ants communicate via pheromones which allows them to coordinate their activity and solve complex tasks as a swarm, e.g. foraging for food. This behavior was shaped through evolutionary processes. In computational models, self-coordination in swarms has been implemented using probabilistic or simple action rules to shape the decision of each agent and the collective behavior. However, manual tuned decision rules may limit the behavior of the swarm. In this work we investigate the emergence of self-coordination and communication in evolved swarms without defining any explicit rule. We evolve a swarm of agents representing an ant colony. We use an evolutionary algorithm to optimize a spiking neural network (SNN) which serves as an artificial brain to control the behavior of each agent. The goal of the evolved colony is to find optimal ways to forage for food and return it to the nest in the shortest amount of time. In the evolutionary phase, the ants are able to learn to collaborate by depositing pheromone near food piles and near the nest to guide other ants. The pheromone usage is not manually encoded into the network; instead, this behavior is established through the optimization procedure. We observe that pheromone-based communication enables the ants to perform better in comparison to colonies where communication via pheromone did not emerge. We assess the foraging performance by comparing the SNN based model to a rule based system. Our results show that the SNN based model can efficiently complete the foraging task in a short amount of time. Our approach illustrates self coordination via pheromone emerges as a result of the network optimization. This work serves as a proof of concept for the possibility of creating complex applications utilizing SNNs as underlying architectures for multi-agent interactions where communication and self-coordination is desired.",
        "published": "2022-12-16T13:57:09Z",
        "link": "http://arxiv.org/abs/2212.08484v2",
        "categories": [
            "cs.NE",
            "cs.MA"
        ]
    },
    {
        "title": "JFP: Joint Future Prediction with Interactive Multi-Agent Modeling for   Autonomous Driving",
        "authors": [
            "Wenjie Luo",
            "Cheolho Park",
            "Andre Cornman",
            "Benjamin Sapp",
            "Dragomir Anguelov"
        ],
        "summary": "We propose JFP, a Joint Future Prediction model that can learn to generate accurate and consistent multi-agent future trajectories. For this task, many different methods have been proposed to capture social interactions in the encoding part of the model, however, considerably less focus has been placed on representing interactions in the decoder and output stages. As a result, the predicted trajectories are not necessarily consistent with each other, and often result in unrealistic trajectory overlaps. In contrast, we propose an end-to-end trainable model that learns directly the interaction between pairs of agents in a structured, graphical model formulation in order to generate consistent future trajectories. It sets new state-of-the-art results on Waymo Open Motion Dataset (WOMD) for the interactive setting. We also investigate a more complex multi-agent setting for both WOMD and a larger internal dataset, where our approach improves significantly on the trajectory overlap metrics while obtaining on-par or better performance on single-agent trajectory metrics.",
        "published": "2022-12-16T20:59:21Z",
        "link": "http://arxiv.org/abs/2212.08710v1",
        "categories": [
            "cs.MA",
            "cs.LG",
            "cs.RO"
        ]
    },
    {
        "title": "Mechanism Design With Predictions for Obnoxious Facility Location",
        "authors": [
            "Gabriel Istrate",
            "Cosmin Bonchis"
        ],
        "summary": "We study mechanism design with predictions for the obnoxious facility location problem. We present deterministic strategyproof mechanisms that display tradeoffs between robustness and consistency on segments, squares, circles and trees. All these mechanisms are actually group strategyproof, with the exception of the case of squares, where manipulations from coalitions of two agents exist. We prove that these tradeoffs are optimal in the 1-dimensional case.",
        "published": "2022-12-19T15:04:11Z",
        "link": "http://arxiv.org/abs/2212.09521v1",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Taming Lagrangian Chaos with Multi-Objective Reinforcement Learning",
        "authors": [
            "Chiara Calascibetta",
            "Luca Biferale",
            "Francesco Borra",
            "Antonio Celani",
            "Massimo Cencini"
        ],
        "summary": "We consider the problem of two active particles in 2D complex flows with the multi-objective goals of minimizing both the dispersion rate and the energy consumption of the pair. We approach the problem by means of Multi Objective Reinforcement Learning (MORL), combining scalarization techniques together with a Q-learning algorithm, for Lagrangian drifters that have variable swimming velocity. We show that MORL is able to find a set of trade-off solutions forming an optimal Pareto frontier. As a benchmark, we show that a set of heuristic strategies are dominated by the MORL solutions. We consider the situation in which the agents cannot update their control variables continuously, but only after a discrete (decision) time, $\\tau$. We show that there is a range of decision times, in between the Lyapunov time and the continuous updating limit, where Reinforcement Learning finds strategies that significantly improve over heuristics. In particular, we discuss how large decision times require enhanced knowledge of the flow, whereas for smaller $\\tau$ all a priori heuristic strategies become Pareto optimal.",
        "published": "2022-12-19T16:50:58Z",
        "link": "http://arxiv.org/abs/2212.09612v1",
        "categories": [
            "physics.flu-dyn",
            "cs.LG",
            "cs.MA",
            "nlin.CD"
        ]
    },
    {
        "title": "Bandit approach to conflict-free multi-agent Q-learning in view of   photonic implementation",
        "authors": [
            "Hiroaki Shinkawa",
            "Nicolas Chauvet",
            "André Röhm",
            "Takatomo Mihana",
            "Ryoichi Horisaki",
            "Guillaume Bachelier",
            "Makoto Naruse"
        ],
        "summary": "Recently, extensive studies on photonic reinforcement learning to accelerate the process of calculation by exploiting the physical nature of light have been conducted. Previous studies utilized quantum interference of photons to achieve collective decision-making without choice conflicts when solving the competitive multi-armed bandit problem, a fundamental example of reinforcement learning. However, the bandit problem deals with a static environment where the agent's action does not influence the reward probabilities. This study aims to extend the conventional approach to a more general multi-agent reinforcement learning targeting the grid world problem. Unlike the conventional approach, the proposed scheme deals with a dynamic environment where the reward changes because of agents' actions. A successful photonic reinforcement learning scheme requires both a photonic system that contributes to the quality of learning and a suitable algorithm. This study proposes a novel learning algorithm, discontinuous bandit Q-learning, in view of a potential photonic implementation. Here, state-action pairs in the environment are regarded as slot machines in the context of the bandit problem and an updated amount of Q-value is regarded as the reward of the bandit problem. We perform numerical simulations to validate the effectiveness of the bandit algorithm. In addition, we propose a multi-agent architecture in which agents are indirectly connected through quantum interference of light and quantum principles ensure the conflict-free property of state-action pair selections among agents. We demonstrate that multi-agent reinforcement learning can be accelerated owing to conflict avoidance among multiple agents.",
        "published": "2022-12-20T00:27:29Z",
        "link": "http://arxiv.org/abs/2212.09926v1",
        "categories": [
            "cs.AI",
            "cs.MA",
            "physics.optics",
            "quant-ph"
        ]
    },
    {
        "title": "Anticipatory Fictitious Play",
        "authors": [
            "Alex Cloud",
            "Albert Wang",
            "Wesley Kerr"
        ],
        "summary": "Fictitious play is an algorithm for computing Nash equilibria of matrix games. Recently, machine learning variants of fictitious play have been successfully applied to complicated real-world games. This paper presents a simple modification of fictitious play which is a strict improvement over the original: it has the same theoretical worst-case convergence rate, is equally applicable in a machine learning context, and enjoys superior empirical performance. We conduct an extensive comparison of our algorithm with fictitious play, proving an optimal convergence rate for certain classes of games, demonstrating superior performance numerically across a variety of games, and concluding with experiments that extend these algorithms to the setting of deep multiagent reinforcement learning.",
        "published": "2022-12-20T01:27:05Z",
        "link": "http://arxiv.org/abs/2212.09941v1",
        "categories": [
            "cs.GT",
            "cs.MA"
        ]
    },
    {
        "title": "AdverSAR: Adversarial Search and Rescue via Multi-Agent Reinforcement   Learning",
        "authors": [
            "Aowabin Rahman",
            "Arnab Bhattacharya",
            "Thiagarajan Ramachandran",
            "Sayak Mukherjee",
            "Himanshu Sharma",
            "Ted Fujimoto",
            "Samrat Chatterjee"
        ],
        "summary": "Search and Rescue (SAR) missions in remote environments often employ autonomous multi-robot systems that learn, plan, and execute a combination of local single-robot control actions, group primitives, and global mission-oriented coordination and collaboration. Often, SAR coordination strategies are manually designed by human experts who can remotely control the multi-robot system and enable semi-autonomous operations. However, in remote environments where connectivity is limited and human intervention is often not possible, decentralized collaboration strategies are needed for fully-autonomous operations. Nevertheless, decentralized coordination may be ineffective in adversarial environments due to sensor noise, actuation faults, or manipulation of inter-agent communication data. In this paper, we propose an algorithmic approach based on adversarial multi-agent reinforcement learning (MARL) that allows robots to efficiently coordinate their strategies in the presence of adversarial inter-agent communications. In our setup, the objective of the multi-robot team is to discover targets strategically in an obstacle-strewn geographical area by minimizing the average time needed to find the targets. It is assumed that the robots have no prior knowledge of the target locations, and they can interact with only a subset of neighboring robots at any time. Based on the centralized training with decentralized execution (CTDE) paradigm in MARL, we utilize a hierarchical meta-learning framework to learn dynamic team-coordination modalities and discover emergent team behavior under complex cooperative-competitive scenarios. The effectiveness of our approach is demonstrated on a collection of prototype grid-world environments with different specifications of benign and adversarial agents, target locations, and agent rewards.",
        "published": "2022-12-20T08:13:29Z",
        "link": "http://arxiv.org/abs/2212.10064v1",
        "categories": [
            "cs.RO",
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "eess.SY",
            "math.OC"
        ]
    },
    {
        "title": "Biased processing and opinion polarization: experimental refinement of   argument communication theory in the context of the energy debate",
        "authors": [
            "Sven Banisch",
            "Hawal Shamon"
        ],
        "summary": "In sociological research, the study of macro processes, such as opinion polarization, faces a fundamental problem, the so-called micro-macro problem. To overcome this problem, we combine empirical experimental research on biased argument processing with a computational theory of group deliberation in order to clarify the role of biased processing in debates around energy. The experiment reveals a strong tendency to consider arguments aligned with the current attitude more persuasive and to downgrade those speaking against it. This is integrated into the framework of argument communication theory in which agents exchange arguments about a certain topic and adapt opinions accordingly. We derive a mathematical model that allows to relate the strength of biased processing to expected attitude changes given the specific experimental conditions and find a clear signature of moderate biased processing. We further show that this model fits significantly better to the experimentally observed attitude changes than the neutral argument processing assumption made in previous models. Our approach provides new insight into the relationship between biased processing and opinion polarization. At the individual level our analysis reveals a sharp qualitative transition from attitude moderation to polarization. At the collective level we find (i.) that weak biased processing significantly accelerates group decision processes whereas (ii.) strong biased processing leads to a persistent conflictual state of subgroup polarization. While this shows that biased processing alone is sufficient for the emergence of polarization, we also demonstrate that homophily may lead to intra-group conflict at significantly lower rates of biased processing.",
        "published": "2022-12-20T09:35:53Z",
        "link": "http://arxiv.org/abs/2212.10117v1",
        "categories": [
            "physics.soc-ph",
            "cs.CY",
            "cs.MA",
            "nlin.AO"
        ]
    },
    {
        "title": "Validating argument-based opinion dynamics with survey experiments",
        "authors": [
            "Sven Banisch",
            "Hawal Shamon"
        ],
        "summary": "The empirical validation of models remains one of the most important challenges in opinion dynamics. In this contribution, we report on recent developments on combining data from survey experiments with computational models of opinion formation. We extend previous work on the empirical assessment of an argument-based model for opinion dynamics in which biased processing is the principle mechanism. While previous work (Banisch & Shamon, in press) has focused on calibrating the micro mechanism with experimental data on argument-induced opinion change, this paper concentrates on the macro level using the empirical data gathered in the survey experiment. For this purpose, the argument model is extended by an external source of balanced information which allows to control for the impact of peer influence processes relative to other noisy processes. We show that surveyed opinion distributions are matched with a high level of accuracy in a specific region in the parameter space, indicating an equal impact of social influence and external noise. More importantly, the estimated strength of biased processing given the macro data is compatible with those values that achieve high likelihood at the micro level. The main contribution of the paper is hence to show that the extended argument-based model provides a solid bridge from the micro processes of argument-induced attitude change to macro level opinion distributions. Beyond that, we review the development of argument-based models and present a new method for the automated classification of model outcomes.",
        "published": "2022-12-20T10:21:30Z",
        "link": "http://arxiv.org/abs/2212.10143v2",
        "categories": [
            "physics.soc-ph",
            "cs.CY",
            "cs.MA",
            "nlin.AO",
            "stat.AP"
        ]
    },
    {
        "title": "Automated Configuration and Usage of Strategy Portfolios for Bargaining",
        "authors": [
            "Bram M. Renting",
            "Holger H. Hoos",
            "Catholijn M. Jonker"
        ],
        "summary": "Bargaining can be used to resolve mixed-motive games in multi-agent systems. Although there is an abundance of negotiation strategies implemented in automated negotiating agents, most agents are based on single fixed strategies, while it is widely acknowledged that there is no single best-performing strategy for all negotiation settings.   In this paper, we focus on bargaining settings where opponents are repeatedly encountered, but the bargaining problems change. We introduce a novel method that automatically creates and deploys a portfolio of complementary negotiation strategies using a training set and optimise pay-off in never-before-seen bargaining settings through per-setting strategy selection. Our method relies on the following contributions. We introduce a feature representation that captures characteristics for both the opponent and the bargaining problem. We model the behaviour of an opponent during a negotiation based on its actions, which is indicative of its negotiation strategy, in order to be more effective in future encounters.   Our combination of feature-based methods generalises to new negotiation settings, as in practice, over time, it selects effective counter strategies in future encounters. Our approach is tested in an ANAC-like tournament, and we show that we are capable of winning such a tournament with a 5.6% increase in pay-off compared to the runner-up agent.",
        "published": "2022-12-20T13:05:31Z",
        "link": "http://arxiv.org/abs/2212.10228v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "Addressing the Selection Bias in Voice Assistance: Training Voice   Assistance Model in Python with Equal Data Selection",
        "authors": [
            "Kashav Piya",
            "Srijal Shrestha",
            "Cameran Frank",
            "Estephanos Jebessa",
            "Tauheed Khan Mohd"
        ],
        "summary": "In recent times, voice assistants have become a part of our day-to-day lives, allowing information retrieval by voice synthesis, voice recognition, and natural language processing. These voice assistants can be found in many modern-day devices such as Apple, Amazon, Google, and Samsung. This project is primarily focused on Virtual Assistance in Natural Language Processing. Natural Language Processing is a form of AI that helps machines understand people and create feedback loops. This project will use deep learning to create a Voice Recognizer and use Commonvoice and data collected from the local community for model training using Google Colaboratory. After recognizing a command, the AI assistant will be able to perform the most suitable actions and then give a response.   The motivation for this project comes from the race and gender bias that exists in many virtual assistants. The computer industry is primarily dominated by the male gender, and because of this, many of the products produced do not regard women. This bias has an impact on natural language processing. This project will be utilizing various open-source projects to implement machine learning algorithms and train the assistant algorithm to recognize different types of voices, accents, and dialects. Through this project, the goal to use voice data from underrepresented groups to build a voice assistant that can recognize voices regardless of gender, race, or accent. Increasing the representation of women in the computer industry is important for the future of the industry. By representing women in the initial study of voice assistants, it can be shown that females play a vital role in the development of this technology. In line with related work, this project will use first-hand data from the college population and middle-aged adults to train voice assistant to combat gender bias.",
        "published": "2022-12-20T21:26:05Z",
        "link": "http://arxiv.org/abs/2301.00646v1",
        "categories": [
            "eess.AS",
            "cs.MA",
            "cs.RO",
            "cs.SD"
        ]
    },
    {
        "title": "There's Plenty of Room Right Here: Biological Systems as Evolved,   Overloaded, Multi-scale Machines",
        "authors": [
            "Joshua Bongard",
            "Michael Levin"
        ],
        "summary": "The applicability of computational models to the biological world is an active topic of debate. We argue that a useful path forward results from abandoning hard boundaries between categories and adopting an observer-dependent, pragmatic view. Such a view dissolves the contingent dichotomies driven by human cognitive biases (e.g., tendency to oversimplify) and prior technological limitations in favor of a more continuous, gradualist view necessitated by the study of evolution, developmental biology, and intelligent machines. Efforts to re-shape living systems for biomedical or bioengineering purposes require prediction and control of their function at multiple scales. This is challenging for many reasons, one of which is that living systems perform multiple functions in the same place at the same time. We refer to this as \"polycomputing\" - the ability of the same substrate to simultaneously compute different things. This ability is an important way in which living things are a kind of computer, but not the familiar, linear, deterministic kind; rather, living things are computers in the broad sense of computational materials as reported in the rapidly-growing physical computing literature. We argue that an observer-centered framework for the computations performed by evolved and designed systems will improve the understanding of meso-scale events, as it has already done at quantum and relativistic scales. Here, we review examples of biological and technological polycomputing, and develop the idea that overloading of different functions on the same hardware is an important design principle that helps understand and build both evolved and designed systems. Learning to hack existing polycomputing substrates, as well as evolve and design new ones, will have massive impacts on regenerative medicine, robotics, and computer engineering.",
        "published": "2022-12-20T22:26:40Z",
        "link": "http://arxiv.org/abs/2212.10675v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "q-bio.CB",
            "q-bio.TO"
        ]
    },
    {
        "title": "Strategic multi-task coordination over regular networks of robots with   limited computation and communication capabilities",
        "authors": [
            "Yi Wei",
            "Marcos M. Vasconcelos"
        ],
        "summary": "Coordination is a desirable feature in multi-agent systems, allowing the execution of tasks that would be impossible by individual agents. We study coordination by a team of strategic agents choosing to undertake one of the multiple tasks. We adopt a stochastic framework where the agents decide between two distinct tasks whose difficulty is randomly distributed and partially observed. We show that a Nash equilibrium with a simple and intuitive linear structure exists for diffuse prior distributions on the task difficulties. Additionally, we show that the best response of any agent to an affine strategy profile can be nonlinear when the prior distribution is not diffuse. Finally, we state an algorithm that allows us to efficiently compute a data-driven Nash equilibrium within the class of affine policies.",
        "published": "2022-12-21T12:15:14Z",
        "link": "http://arxiv.org/abs/2212.10968v1",
        "categories": [
            "eess.SY",
            "cs.GT",
            "cs.IT",
            "cs.MA",
            "cs.SY",
            "math.IT"
        ]
    },
    {
        "title": "GCS-Q: Quantum Graph Coalition Structure Generation",
        "authors": [
            "Supreeth Mysore Venkatesh",
            "Antonio Macaluso",
            "Matthias Klusch"
        ],
        "summary": "The problem of generating an optimal coalition structure for a given coalition game of rational agents is to find a partition that maximizes their social welfare and is known to be NP-hard. This paper proposes GCS-Q, a novel quantum-supported solution for Induced Subgraph Games (ISGs) in coalition structure generation. GCS-Q starts by considering the grand coalition as initial coalition structure and proceeds by iteratively splitting the coalitions into two nonempty subsets to obtain a coalition structure with a higher coalition value. In particular, given an $n$-agent ISG, the GCS-Q solves the optimal split problem $\\mathcal{O} (n)$ times using a quantum annealing device, exploring $\\mathcal{O}(2^n)$ partitions at each step. We show that GCS-Q outperforms the currently best classical solvers with its runtime in the order of $n^2$ and an expected worst-case approximation ratio of $93\\%$ on standard benchmark datasets.",
        "published": "2022-12-21T21:22:06Z",
        "link": "http://arxiv.org/abs/2212.11372v1",
        "categories": [
            "quant-ph",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Scalable Multi-Agent Reinforcement Learning for Warehouse Logistics with   Robotic and Human Co-Workers",
        "authors": [
            "Aleksandar Krnjaic",
            "Raul D. Steleac",
            "Jonathan D. Thomas",
            "Georgios Papoudakis",
            "Lukas Schäfer",
            "Andrew Wing Keung To",
            "Kuan-Ho Lao",
            "Murat Cubuktepe",
            "Matthew Haley",
            "Peter Börsting",
            "Stefano V. Albrecht"
        ],
        "summary": "We consider a warehouse in which dozens of mobile robots and human pickers work together to collect and deliver items within the warehouse. The fundamental problem we tackle, called the order-picking problem, is how these worker agents must coordinate their movement and actions in the warehouse to maximise performance in this task. Established industry methods using heuristic approaches require large engineering efforts to optimise for innately variable warehouse configurations. In contrast, multi-agent reinforcement learning (MARL) can be flexibly applied to diverse warehouse configurations (e.g. size, layout, number/types of workers, item replenishment frequency), and different types of order-picking paradigms (e.g. Goods-to-Person and Person-to-Goods), as the agents can learn how to cooperate optimally through experience. We develop hierarchical MARL algorithms in which a manager agent assigns goals to worker agents, and the policies of the manager and workers are co-trained toward maximising a global objective (e.g. pick rate). Our hierarchical algorithms achieve significant gains in sample efficiency over baseline MARL algorithms and overall pick rates over multiple established industry heuristics in a diverse set of warehouse configurations and different order-picking paradigms.",
        "published": "2022-12-22T06:18:41Z",
        "link": "http://arxiv.org/abs/2212.11498v3",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Scalable Primal Decomposition Schemes for Large-Scale Infrastructure   Networks",
        "authors": [
            "Alexander Engelmann",
            "Sungho Shin",
            "François Pacaud",
            "Victor M. Zavala"
        ],
        "summary": "The operation of large-scale infrastructure networks requires scalable optimization schemes. To guarantee safe system operation, a high degree of feasibility in a small number of iterations is important. Decomposition schemes can help to achieve scalability. In terms of feasibility, however, classical approaches such as the alternating direction method of multipliers (ADMM) often converge slowly. In this work, we present primal decomposition schemes for hierarchically structured strongly convex QPs. These schemes offer high degrees of feasibility in a small number of iterations in combination with global convergence guarantees. We benchmark their performance against the centralized off-the-shelf interior-point solver Ipopt and ADMM on problems with up to 300,000 decision variables and constraints. We find that the proposed approaches solve problems as fast as Ipopt, but with reduced communication and without requiring a full model exchange. Moreover, the proposed schemes achieve a higher accuracy than ADMM.",
        "published": "2022-12-22T09:50:25Z",
        "link": "http://arxiv.org/abs/2212.11571v2",
        "categories": [
            "eess.SY",
            "cs.MA",
            "cs.SY"
        ]
    },
    {
        "title": "Certified Policy Smoothing for Cooperative Multi-Agent Reinforcement   Learning",
        "authors": [
            "Ronghui Mu",
            "Wenjie Ruan",
            "Leandro Soriano Marcolino",
            "Gaojie Jin",
            "Qiang Ni"
        ],
        "summary": "Cooperative multi-agent reinforcement learning (c-MARL) is widely applied in safety-critical scenarios, thus the analysis of robustness for c-MARL models is profoundly important. However, robustness certification for c-MARLs has not yet been explored in the community. In this paper, we propose a novel certification method, which is the first work to leverage a scalable approach for c-MARLs to determine actions with guaranteed certified bounds. c-MARL certification poses two key challenges compared with single-agent systems: (i) the accumulated uncertainty as the number of agents increases; (ii) the potential lack of impact when changing the action of a single agent into a global team reward. These challenges prevent us from directly using existing algorithms. Hence, we employ the false discovery rate (FDR) controlling procedure considering the importance of each agent to certify per-state robustness and propose a tree-search-based algorithm to find a lower bound of the global reward under the minimal certified perturbation. As our method is general, it can also be applied in single-agent environments. We empirically show that our certification bounds are much tighter than state-of-the-art RL certification solutions. We also run experiments on two popular c-MARL algorithms: QMIX and VDN, in two different environments, with two and four agents. The experimental results show that our method produces meaningful guaranteed robustness for all models and environments. Our tool CertifyCMARL is available at https://github.com/TrustAI/CertifyCMA",
        "published": "2022-12-22T14:36:27Z",
        "link": "http://arxiv.org/abs/2212.11746v1",
        "categories": [
            "cs.LG",
            "cs.MA"
        ]
    },
    {
        "title": "Natural Way of Solving a Convex Hull Problem",
        "authors": [
            "Sina Saadati",
            "Mohammadreza Razzazi"
        ],
        "summary": "In this article, a new solution for the convex hull problem has been presented. The convex hull is a widely known problem in computational geometry. As nature is a rich source of ideas in the field of algorithms, the solution has been inspired by nature. A tight elastic band is modeled using agents and also nails as points of the problem. By simulating an elastic band with nails in an environment, solving the convex hull problem will be possible. The algorithm runs in O(t) in which t is the time that an elastic band will get fixed.",
        "published": "2022-12-22T19:10:17Z",
        "link": "http://arxiv.org/abs/2212.11999v1",
        "categories": [
            "cs.MA",
            "cs.CG"
        ]
    },
    {
        "title": "Coordinated Multi-Agent Reinforcement Learning for Unmanned Aerial   Vehicle Swarms in Autonomous Mobile Access Applications",
        "authors": [
            "Chanyoung Park",
            "Haemin Lee",
            "Won Joon Yun",
            "Soyi Jung",
            "Joongheon Kim"
        ],
        "summary": "This paper proposes a novel centralized training and distributed execution (CTDE)-based multi-agent deep reinforcement learning (MADRL) method for multiple unmanned aerial vehicles (UAVs) control in autonomous mobile access applications. For the purpose, a single neural network is utilized in centralized training for cooperation among multiple agents while maximizing the total quality of service (QoS) in mobile access applications.",
        "published": "2022-12-23T13:12:17Z",
        "link": "http://arxiv.org/abs/2304.08493v1",
        "categories": [
            "cs.MA",
            "cs.AI",
            "cs.LG",
            "cs.RO"
        ]
    },
    {
        "title": "Analysis of Integrating Blockchain Technologies into Multi-Agent Systems",
        "authors": [
            "Chelsea R. Woodward"
        ],
        "summary": "Multi-Agent Systems, a division of Intelligent Systems diversely applied in multiple disciplines. Desired for their efficiency in solving complex problems at a low cost. However, identified vulnerabilities include system security, integrity, and identity management. Blockchain Technologies was chosen for analysis in providing a suitable solution due to features of transparency, encryption, and trust.",
        "published": "2022-12-23T13:16:23Z",
        "link": "http://arxiv.org/abs/2212.12313v1",
        "categories": [
            "cs.MA"
        ]
    },
    {
        "title": "An active learning method for solving competitive multi-agent   decision-making and control problems",
        "authors": [
            "Filippo Fabiani",
            "Alberto Bemporad"
        ],
        "summary": "To identify a stationary action profile for a population of competitive agents, each executing private strategies, we introduce a novel active-learning scheme where a centralized external observer (or entity) can probe the agents' reactions and recursively update simple local parametric estimates of the action-reaction mappings. Under very general working assumptions (not even assuming that a stationary profile exists), sufficient conditions are established to assess the asymptotic properties of the proposed active learning methodology so that, if the parameters characterizing the action-reaction mappings converge, a stationary action profile is achieved. Such conditions hence act also as certificates for the existence of such a profile. Extensive numerical simulations involving typical competitive multi-agent control and decision-making problems illustrate the practical effectiveness of the proposed learning-based approach.",
        "published": "2022-12-23T19:37:39Z",
        "link": "http://arxiv.org/abs/2212.12561v5",
        "categories": [
            "eess.SY",
            "cs.LG",
            "cs.MA",
            "cs.SY",
            "math.OC"
        ]
    },
    {
        "title": "Agent-based Modeling and Simulation of Human Muscle For Development of   Human Gait Analyzer Application",
        "authors": [
            "Sina Saadati",
            "Mohammadreza Razzazi"
        ],
        "summary": "Despite the fact that only a small portion of muscles are affected in motion disease and disorders, medical therapies do not distinguish between healthy and unhealthy muscles. In this paper, a method is devised in order to calculate the neural stimuli of the lower body during gait cycle and check if any group of muscles are not acting properly. For this reason, an agent-based model of human muscle is proposed. The agent is able to convert neural stimuli to force generated by the muscle and vice versa. It can be used in many researches including medical education and research and prosthesis development. Then, Boots algorithm is designed based on a biomechanical model of human lower body to do a reverse dynamics of human motion by computing the forces generated by each muscle group. Using the agent-driven model of human muscle and boots algorithm, a user-friendly application is developed which can calculate the number of neural stimuli received by each muscle during gait cycle. The application can be used by clinical experts to distinguish between healthy and unhealthy muscles.",
        "published": "2022-12-24T15:57:31Z",
        "link": "http://arxiv.org/abs/2212.12760v2",
        "categories": [
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Learning Individual Policies in Large Multi-agent Systems through Local   Variance Minimization",
        "authors": [
            "Tanvi Verma",
            "Pradeep Varakantham"
        ],
        "summary": "In multi-agent systems with large number of agents, typically the contribution of each agent to the value of other agents is minimal (e.g., aggregation systems such as Uber, Deliveroo). In this paper, we consider such multi-agent systems where each agent is self-interested and takes a sequence of decisions and represent them as a Stochastic Non-atomic Congestion Game (SNCG). We derive key properties for equilibrium solutions in SNCG model with non-atomic and also nearly non-atomic agents. With those key equilibrium properties, we provide a novel Multi-Agent Reinforcement Learning (MARL) mechanism that minimizes variance across values of agents in the same state. To demonstrate the utility of this new mechanism, we provide detailed results on a real-world taxi dataset and also a generic simulator for aggregation systems. We show that our approach reduces the variance in revenues earned by taxi drivers, while still providing higher joint revenues than leading approaches.",
        "published": "2022-12-27T06:59:00Z",
        "link": "http://arxiv.org/abs/2212.13379v1",
        "categories": [
            "cs.MA",
            "cs.AI"
        ]
    },
    {
        "title": "Strangeness-driven Exploration in Multi-Agent Reinforcement Learning",
        "authors": [
            "Ju-Bong Kim",
            "Ho-Bin Choi",
            "Youn-Hee Han"
        ],
        "summary": "Efficient exploration strategy is one of essential issues in cooperative multi-agent reinforcement learning (MARL) algorithms requiring complex coordination. In this study, we introduce a new exploration method with the strangeness that can be easily incorporated into any centralized training and decentralized execution (CTDE)-based MARL algorithms. The strangeness refers to the degree of unfamiliarity of the observations that an agent visits. In order to give the observation strangeness a global perspective, it is also augmented with the the degree of unfamiliarity of the visited entire state. The exploration bonus is obtained from the strangeness and the proposed exploration method is not much affected by stochastic transitions commonly observed in MARL tasks. To prevent a high exploration bonus from making the MARL training insensitive to extrinsic rewards, we also propose a separate action-value function trained by both extrinsic reward and exploration bonus, on which a behavioral policy to generate transitions is designed based. It makes the CTDE-based MARL algorithms more stable when they are used with an exploration method. Through a comparative evaluation in didactic examples and the StarCraft Multi-Agent Challenge, we show that the proposed exploration method achieves significant performance improvement in the CTDE-based MARL algorithms.",
        "published": "2022-12-27T11:08:49Z",
        "link": "http://arxiv.org/abs/2212.13448v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Coordination of Drones at Scale: Decentralized Energy-aware Swarm   Intelligence for Spatio-temporal Sensing",
        "authors": [
            "Chuhao Qin",
            "Evangelos Pournaras"
        ],
        "summary": "Smart City applications, such as traffic monitoring and disaster response, often use swarms of intelligent and cooperative drones to efficiently collect sensor data over different areas of interest and time spans. However, when the required sensing becomes spatio-temporally large and varying, a collective arrangement of sensing tasks to a large number of battery-restricted and distributed drones is challenging. To address this problem, this paper introduces a scalable and energy-aware model for planning and coordination of spatio-temporal sensing. The coordination model is built upon a decentralized multi-agent collective learning algorithm (EPOS) to ensure scalability, resilience, and flexibility that existing approaches lack of. Experimental results illustrate the outstanding performance of the proposed method compared to state-of-the-art methods. Analytical results contribute a deeper understanding of how coordinated mobility of drones influences sensing performance. This novel coordination solution is applied to traffic monitoring using real-world data to demonstrate a $46.45\\%$ more accurate and $2.88\\%$ more efficient detection of vehicles as the number of drones become a scarce resource.",
        "published": "2022-12-28T22:46:50Z",
        "link": "http://arxiv.org/abs/2212.14116v2",
        "categories": [
            "cs.RO",
            "cs.MA"
        ]
    },
    {
        "title": "Joint Action is a Framework for Understanding Partnerships Between   Humans and Upper Limb Prostheses",
        "authors": [
            "Michael R. Dawson",
            "Adam S. R. Parker",
            "Heather E. Williams",
            "Ahmed W. Shehata",
            "Jacqueline S. Hebert",
            "Craig S. Chapman",
            "Patrick M. Pilarski"
        ],
        "summary": "Recent advances in upper limb prostheses have led to significant improvements in the number of movements provided by the robotic limb. However, the method for controlling multiple degrees of freedom via user-generated signals remains challenging. To address this issue, various machine learning controllers have been developed to better predict movement intent. As these controllers become more intelligent and take on more autonomy in the system, the traditional approach of representing the human-machine interface as a human controlling a tool becomes limiting. One possible approach to improve the understanding of these interfaces is to model them as collaborative, multi-agent systems through the lens of joint action. The field of joint action has been commonly applied to two human partners who are trying to work jointly together to achieve a task, such as singing or moving a table together, by effecting coordinated change in their shared environment. In this work, we compare different prosthesis controllers (proportional electromyography with sequential switching, pattern recognition, and adaptive switching) in terms of how they present the hallmarks of joint action. The results of the comparison lead to a new perspective for understanding how existing myoelectric systems relate to each other, along with recommendations for how to improve these systems by increasing the collaborative communication between each partner.",
        "published": "2022-12-28T23:27:32Z",
        "link": "http://arxiv.org/abs/2212.14124v1",
        "categories": [
            "cs.HC",
            "cs.AI",
            "cs.MA",
            "cs.RO"
        ]
    },
    {
        "title": "Near-Tight Algorithms for the Chamberlin-Courant and Thiele Voting Rules",
        "authors": [
            "Krzysztof Sornat",
            "Virginia Vassilevska Williams",
            "Yinzhan Xu"
        ],
        "summary": "We present an almost optimal algorithm for the classic Chamberlin-Courant multiwinner voting rule (CC) on single-peaked preference profiles. Given $n$ voters and $m$ candidates, it runs in almost linear time in the input size, improving the previous best $O(nm^2)$ time algorithm of Betzler et al. (2013). We also study multiwinner voting rules on nearly single-peaked preference profiles in terms of the candidate-deletion operation. We show a polynomial-time algorithm for CC where a given candidate-deletion set $D$ has logarithmic size. Actually, our algorithm runs in $2^{|D|} \\cdot poly(n,m)$ time and the base of the power cannot be improved under the Strong Exponential Time Hypothesis. We also adapt these results to all non-constant Thiele rules which generalize CC with approval ballots.",
        "published": "2022-12-29T04:59:29Z",
        "link": "http://arxiv.org/abs/2212.14173v1",
        "categories": [
            "cs.GT",
            "cs.DS",
            "cs.MA",
            "68Q17, 68W05 (Primary), 91B12, 68T42 (Secondary)",
            "F.2.2; I.2.11"
        ]
    },
    {
        "title": "Safe Subgame Resolving for Extensive Form Correlated Equilibrium",
        "authors": [
            "Chun Kai Ling",
            "Fei Fang"
        ],
        "summary": "Correlated Equilibrium is a solution concept that is more general than Nash Equilibrium (NE) and can lead to outcomes with better social welfare. However, its natural extension to the sequential setting, the \\textit{Extensive Form Correlated Equilibrium} (EFCE), requires a quadratic amount of space to solve, even in restricted settings without randomness in nature. To alleviate these concerns, we apply \\textit{subgame resolving}, a technique extremely successful in finding NE in zero-sum games to solving general-sum EFCEs. Subgame resolving refines a correlation plan in an \\textit{online} manner: instead of solving for the full game upfront, it only solves for strategies in subgames that are reached in actual play, resulting in significant computational gains. In this paper, we (i) lay out the foundations to quantify the quality of a refined strategy, in terms of the \\textit{social welfare} and \\textit{exploitability} of correlation plans, (ii) show that EFCEs possess a sufficient amount of independence between subgames to perform resolving efficiently, and (iii) provide two algorithms for resolving, one using linear programming and the other based on regret minimization. Both methods guarantee \\textit{safety}, i.e., they will never be counterproductive. Our methods are the first time an online method has been applied to the correlated, general-sum setting.",
        "published": "2022-12-29T14:20:48Z",
        "link": "http://arxiv.org/abs/2212.14317v1",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Function Approximation for Solving Stackelberg Equilibrium in Large   Perfect Information Games",
        "authors": [
            "Chun Kai Ling",
            "J. Zico Kolter",
            "Fei Fang"
        ],
        "summary": "Function approximation (FA) has been a critical component in solving large zero-sum games. Yet, little attention has been given towards FA in solving \\textit{general-sum} extensive-form games, despite them being widely regarded as being computationally more challenging than their fully competitive or cooperative counterparts. A key challenge is that for many equilibria in general-sum games, no simple analogue to the state value function used in Markov Decision Processes and zero-sum games exists. In this paper, we propose learning the \\textit{Enforceable Payoff Frontier} (EPF) -- a generalization of the state value function for general-sum games. We approximate the optimal \\textit{Stackelberg extensive-form correlated equilibrium} by representing EPFs with neural networks and training them by using appropriate backup operations and loss functions. This is the first method that applies FA to the Stackelberg setting, allowing us to scale to much larger games while still enjoying performance guarantees based on FA error. Additionally, our proposed method guarantees incentive compatibility and is easy to evaluate without having to depend on self-play or approximate best-response oracles.",
        "published": "2022-12-29T19:05:50Z",
        "link": "http://arxiv.org/abs/2212.14431v2",
        "categories": [
            "cs.GT",
            "cs.AI",
            "cs.MA"
        ]
    },
    {
        "title": "Multisensor Multiobject Tracking with Improved Sampling Efficiency",
        "authors": [
            "Wenyu Zhang",
            "Florian Meyer"
        ],
        "summary": "Passive monitoring of acoustic or radio sources has important applications in modern convenience, public safety, and surveillance. A key task in passive monitoring is multiobject tracking (MOT). This paper presents a Bayesian method for multisensor MOT for challenging tracking problems where the object states are high-dimensional, and the measurements follow a nonlinear model. Our method is developed in the framework of factor graphs and the sum-product algorithm (SPA) and implemented using random samples or \"particles\". The multimodal probability density functions (pdfs) provided by the SPA are effectively represented by a Gaussian mixture model (GMM). To perform the operations of the SPA with improved sample efficiency, we make use of Particle flow (PFL). Here, particles are migrated towards regions of high likelihood based on the solution of a partial differential equation. This makes it possible to obtain good object detection and tracking performance even in challenging multisensor MOT scenarios with single sensor measurements that have a lower dimension than the object positions. We perform a numerical evaluation in a passive acoustic monitoring scenario where multiple sources are tracked in 3-D from 1-D time-difference-of-arrival (TDOA) measurements provided by pairs of hydrophones. Our numerical results demonstrate favorable detection and estimation accuracy compared to state-of-the-art reference techniques.",
        "published": "2022-12-30T05:48:17Z",
        "link": "http://arxiv.org/abs/2212.14556v3",
        "categories": [
            "eess.SP",
            "cs.MA",
            "cs.RO",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "An Auction-based Coordination Strategy for Task-Constrained Multi-Agent   Stochastic Planning with Submodular Rewards",
        "authors": [
            "Ruifan Liu",
            "Hyo-Sang Shin",
            "Binbin Yan",
            "Antonios Tsourdos"
        ],
        "summary": "In many domains such as transportation and logistics, search and rescue, or cooperative surveillance, tasks are pending to be allocated with the consideration of possible execution uncertainties. Existing task coordination algorithms either ignore the stochastic process or suffer from the computational intensity. Taking advantage of the weakly coupled feature of the problem and the opportunity for coordination in advance, we propose a decentralized auction-based coordination strategy using a newly formulated score function which is generated by forming the problem into task-constrained Markov decision processes (MDPs). The proposed method guarantees convergence and at least 50% optimality in the premise of a submodular reward function. Furthermore, for the implementation on large-scale applications, an approximate variant of the proposed method, namely Deep Auction, is also suggested with the use of neural networks, which is evasive of the troublesome for constructing MDPs. Inspired by the well-known actor-critic architecture, two Transformers are used to map observations to action probabilities and cumulative rewards respectively. Finally, we demonstrate the performance of the two proposed approaches in the context of drone deliveries, where the stochastic planning for the drone league is cast into a stochastic price-collecting Vehicle Routing Problem (VRP) with time windows. Simulation results are compared with state-of-the-art methods in terms of solution quality, planning efficiency and scalability.",
        "published": "2022-12-30T10:25:25Z",
        "link": "http://arxiv.org/abs/2212.14624v2",
        "categories": [
            "cs.MA",
            "cs.NE"
        ]
    },
    {
        "title": "Wealth Redistribution and Mutual Aid: Comparison using   Equivalent/Nonequivalent Exchange Models of Econophysics",
        "authors": [
            "Takeshi Kato"
        ],
        "summary": "Given the wealth inequality worldwide, there is an urgent need to identify the mode of wealth exchange through which it arises. To address the research gap regarding models that combine equivalent exchange and redistribution, this study compares an equivalent market exchange with redistribution based on power centers and a nonequivalent exchange with mutual aid using the Polanyi, Graeber, and Karatani modes of exchange. Two new exchange models based on multi-agent interactions are reconstructed following an econophysics approach for evaluating the Gini index (inequality) and total exchange (economic flow). Exchange simulations indicate that the evaluation parameter of the total exchange divided by the Gini index can be expressed by the same saturated curvilinear approximate equation using the wealth transfer rate and time period of redistribution and the surplus contribution rate of the wealthy and the saving rate. However, considering the coercion of taxes and its associated costs and independence based on the morality of mutual aid, a nonequivalent exchange without return obligation is preferred. This is oriented toward Graeber's baseline communism and Karatani's mode of exchange D, with implications for alternatives to the capitalist economy.",
        "published": "2022-12-31T01:37:26Z",
        "link": "http://arxiv.org/abs/2301.00091v1",
        "categories": [
            "econ.TH",
            "cs.MA",
            "physics.soc-ph",
            "91B43, 91B70, 62P20"
        ]
    },
    {
        "title": "Modeling social resilience: Questions, answers, open problems",
        "authors": [
            "Frank Schweitzer",
            "Georges Andres",
            "Giona Casiraghi",
            "Christoph Gote",
            "Ramona Roller",
            "Ingo Scholtes",
            "Giacomo Vaccario",
            "Christian Zingg"
        ],
        "summary": "Resilience denotes the capacity of a system to withstand shocks and its ability to recover from them. We develop a framework to quantify the resilience of highly volatile, non-equilibrium social organizations, such as collectives or collaborating teams. It consists of four steps: (i) \\emph{delimitation}, i.e., narrowing down the target systems, (ii) \\emph{conceptualization}, .e., identifying how to approach social organizations, (iii) formal \\emph{representation} using a combination of agent-based and network models, (iv) \\emph{operationalization}, i.e. specifying measures and demonstrating how they enter the calculation of resilience. Our framework quantifies two dimensions of resilience, the \\emph{robustness} of social organizations and their \\emph{adaptivity}, and combines them in a novel resilience measure. It allows monitoring resilience instantaneously using longitudinal data instead of an ex-post evaluation.",
        "published": "2022-12-31T11:41:14Z",
        "link": "http://arxiv.org/abs/2301.00183v1",
        "categories": [
            "cs.SI",
            "cs.MA",
            "nlin.AO",
            "physics.soc-ph"
        ]
    },
    {
        "title": "Batched Second-Order Adjoint Sensitivity for Reduced Space Methods",
        "authors": [
            "François Pacaud",
            "Michel Schanen",
            "Daniel Adrian Maldonado",
            "Alexis Montoison",
            "Valentin Churavy",
            "Julian Samaroo",
            "Mihai Anitescu"
        ],
        "summary": "This paper presents an efficient method for extracting the second-order sensitivities from a system of implicit nonlinear equations on upcoming graphical processing units (GPU) dominated computer systems. We design a custom automatic differentiation (AutoDiff) backend that targets highly parallel architectures by extracting the second-order information in batch. When the nonlinear equations are associated to a reduced space optimization problem, we leverage the parallel reverse-mode accumulation in a batched adjoint-adjoint algorithm to compute efficiently the reduced Hessian of the problem. We apply the method to extract the reduced Hessian associated to the balance equations of a power network, and show on the largest instances that a parallel GPU implementation is 30 times faster than a sequential CPU reference based on UMFPACK.",
        "published": "2022-01-01T20:53:09Z",
        "link": "http://arxiv.org/abs/2201.00241v1",
        "categories": [
            "cs.MS",
            "cs.CE"
        ]
    },
    {
        "title": "On Automating Triangle Constructions in Absolute and Hyperbolic Geometry",
        "authors": [
            "Vesna Marinković",
            "Tijana Šukilović",
            "Filip Marić"
        ],
        "summary": "We describe first steps towards a system for automated triangle constructions in absolute and hyperbolic geometry. We discuss key differences between constructions in Euclidean, absolute and hyperbolic geometry, compile a list of primitive constructions and lemmas used for constructions in absolute and hyperbolic geometry, build an automated system for solving construction problems and test it on a corpus of triangle-construction problems. We also provide an online compendium containing construction descriptions and illustrations.",
        "published": "2022-01-03T09:24:34Z",
        "link": "http://arxiv.org/abs/2201.00534v1",
        "categories": [
            "cs.CG",
            "cs.MS",
            "I.2.3"
        ]
    },
    {
        "title": "Mechanization of Incidence Projective Geometry in Higher Dimensions, a   Combinatorial Approach",
        "authors": [
            "Pascal Schreck",
            "Nicolas Magaud",
            "David Braun"
        ],
        "summary": "Several tools have been developed to enhance automation of theorem proving in the 2D plane. However, in 3D, only a few approaches have been studied, and to our knowledge, nothing has been done in higher dimensions. In this paper, we present a few examples of incidence geometry theorems in dimensions 3, 4, and 5. We then prove them with the help of a combinatorial prover based on matroid theory applied to geometry.",
        "published": "2022-01-03T09:26:01Z",
        "link": "http://arxiv.org/abs/2201.00539v1",
        "categories": [
            "cs.CG",
            "cs.MS",
            "cs.SC"
        ]
    },
    {
        "title": "Parametric Root Finding for Supporting Proving and Discovering Geometric   Inequalities in GeoGebra",
        "authors": [
            "Zoltán Kovács",
            "Róbert Vajda"
        ],
        "summary": "We introduced the package/subsystem GeoGebra Discovery to GeoGebra which supports the automated proving or discovering of elementary geometry inequalities. In this case study, for inequality exploration problems related to isosceles and right angle triangle subclasses, we demonstrate how our general real quantifier elimination (RQE) approach could be replaced by a parametric root finding (PRF) algorithm. The general RQE requires the full cell decomposition of a high dimensional space, while the new method can avoid this expensive computation and can lead to practical speedups. To obtain a solution for a 1D-exploration problem, we compute a Groebner basis for the discriminant variety of the 1-dimensional parametric system and solve finitely many nonlinear real (NRA) satisfiability (SAT) problems. We illustrate the needed computations by examples. Since Groebner basis algorithms are available in Giac (the underlying free computer algebra system in GeoGebra) and freely available efficient NRA-SAT solvers (SMT-RAT, Tarski, Z3, etc.) can be linked to GeoGebra, we hope that the method could be easily added to the existing reasoning tool set for educational purposes.",
        "published": "2022-01-03T09:28:42Z",
        "link": "http://arxiv.org/abs/2201.00545v1",
        "categories": [
            "math.AG",
            "cs.MS"
        ]
    },
    {
        "title": "Comparison of methods for the calculation of the real dilogarithm   regarding instruction-level parallelism",
        "authors": [
            "Alexander Voigt"
        ],
        "summary": "We compare different methods for the computation of the real dilogarithm regarding their ability for using instruction-level parallelism when executed on appropriate CPUs. As a result we present an instruction-level-aware method and compare it to existing implementations.",
        "published": "2022-01-05T16:06:49Z",
        "link": "http://arxiv.org/abs/2201.01678v1",
        "categories": [
            "hep-ph",
            "cs.MS",
            "cs.NA",
            "math.NA",
            "33-04, 33E20, 33F05, 65D20"
        ]
    },
    {
        "title": "Parallel Metric-Based Mesh Adaptation in PETSc using ParMmg",
        "authors": [
            "Joseph G. Wallwork",
            "Matthew G. Knepley",
            "Nicolas Barral",
            "Matthew D. Piggott"
        ],
        "summary": "This research note documents the integration of the MPI-parallel metric-based mesh adaptation toolkit ParMmg into the solver library PETSc. This coupling brings robust, scalable anisotropic mesh adaptation to a wide community of PETSc users, as well as users of downstream packages. We demonstrate the new functionality via the solution of Poisson problems in three dimensions, with both uniform and spatially-varying right-hand sides.",
        "published": "2022-01-08T11:14:28Z",
        "link": "http://arxiv.org/abs/2201.02806v3",
        "categories": [
            "cs.MS",
            "cs.GR",
            "35-04",
            "G.4"
        ]
    },
    {
        "title": "Solving the Cauchy problem for a three-dimensional difference equation   in a parallelepiped",
        "authors": [
            "Marina S. Apanovich",
            "Alexander P. Lyapin",
            "Konstantin V. Shadrin"
        ],
        "summary": "The aim of this article is further development of the theory of linear difference equations with constant coefficients. We present a new algorithm for calculating the solution to the Cauchy problem for a three-dimensional difference equation with constant coefficients in a parallelepiped at the point using the coefficients of the difference equation and Cauchy data. The implemented algorithm is the next significant achievement in a series of articles justifying the Apanovich and Leinartas' theorems about the solvability and well-posedness of the Cauchy problem. We also use methods of computer algebra since the three-dimensional case usually demands extended calculations.",
        "published": "2022-01-09T23:44:14Z",
        "link": "http://arxiv.org/abs/2201.13308v1",
        "categories": [
            "math.CA",
            "cs.MS",
            "cs.NA",
            "math.NA",
            "05A15, 37H10, 39A05, 39A70"
        ]
    },
    {
        "title": "An open tool based on lifex for myofibers generation in cardiac   computational models",
        "authors": [
            "Pasquale C. Africa",
            "Roberto Piersanti",
            "Marco Fedele",
            "Luca Dede'",
            "Alfio Quarteroni"
        ],
        "summary": "Modeling the whole cardiac function involves the solution of several complex multi-physics and multi-scale models that are highly computationally demanding, which call for simpler yet accurate, high-performance computational tools. Despite the efforts made by several research groups, no software for whole-heart fully-coupled cardiac simulations in the scientific community has reached full maturity yet. In this work we present the first publicly released package of lifex, a high-performance Finite Element solver for multi-physics and multi-scale problems developed in the framework of the iHEART project. The goal of lifex is twofold. On the one side, it aims at making in silico experiments easily reproducible and accessible to a wide community of users, including those with a background in medicine or bio-engineering. On the other hand, as an academic research library lifex can be exploited by scientific computing experts to explore new mathematical models and numerical methods within a robust development framework. lifex has been developed with a modular structure and will be released bundled in different modules. The tool presented here proposes an innovative generator for myocardial fibers based on Laplace-Dirichlet Rule-Based Methods, which are the essential building blocks for modeling the electrophysiological, mechanical and electromechanical cardiac function, from single-chamber to whole-heart simulations. This report comes with an extensive technical and mathematical documentation to welcome new users to the core structure of a prototypical lifex application and to provide them with a possible approach to include the generated cardiac fibers into more sophisticated computational pipelines.",
        "published": "2022-01-10T12:08:57Z",
        "link": "http://arxiv.org/abs/2201.03303v4",
        "categories": [
            "cs.MS",
            "cs.DC",
            "cs.NA",
            "math.NA",
            "68-04, 68N30 (Primary), 35-04, 65-04, 65M60, 65N30, 65Y05, 92-04,\n  92C50 (Secondary)",
            "G.4; G.1; J.3"
        ]
    },
    {
        "title": "pymdp: A Python library for active inference in discrete state spaces",
        "authors": [
            "Conor Heins",
            "Beren Millidge",
            "Daphne Demekas",
            "Brennan Klein",
            "Karl Friston",
            "Iain Couzin",
            "Alexander Tschantz"
        ],
        "summary": "Active inference is an account of cognition and behavior in complex systems which brings together action, perception, and learning under the theoretical mantle of Bayesian inference. Active inference has seen growing applications in academic research, especially in fields that seek to model human or animal behavior. While in recent years, some of the code arising from the active inference literature has been written in open source languages like Python and Julia, to-date, the most popular software for simulating active inference agents is the DEM toolbox of SPM, a MATLAB library originally developed for the statistical analysis and modelling of neuroimaging data. Increasing interest in active inference, manifested both in terms of sheer number as well as diversifying applications across scientific disciplines, has thus created a need for generic, widely-available, and user-friendly code for simulating active inference in open-source scientific computing languages like Python. The Python package we present here, pymdp (see https://github.com/infer-actively/pymdp), represents a significant step in this direction: namely, we provide the first open-source package for simulating active inference with partially-observable Markov Decision Processes or POMDPs. We review the package's structure and explain its advantages like modular design and customizability, while providing in-text code blocks along the way to demonstrate how it can be used to build and run active inference processes with ease. We developed pymdp to increase the accessibility and exposure of the active inference framework to researchers, engineers, and developers with diverse disciplinary backgrounds. In the spirit of open-source software, we also hope that it spurs new innovation, development, and collaboration in the growing active inference community.",
        "published": "2022-01-11T12:18:44Z",
        "link": "http://arxiv.org/abs/2201.03904v2",
        "categories": [
            "cs.AI",
            "cs.MS",
            "q-bio.NC"
        ]
    },
    {
        "title": "PEPit: computer-assisted worst-case analyses of first-order optimization   methods in Python",
        "authors": [
            "Baptiste Goujaud",
            "Céline Moucer",
            "François Glineur",
            "Julien Hendrickx",
            "Adrien Taylor",
            "Aymeric Dieuleveut"
        ],
        "summary": "PEPit is a Python package aiming at simplifying the access to worst-case analyses of a large family of first-order optimization methods possibly involving gradient, projection, proximal, or linear optimization oracles, along with their approximate, or Bregman variants. In short, PEPit is a package enabling computer-assisted worst-case analyses of first-order optimization methods. The key underlying idea is to cast the problem of performing a worst-case analysis, often referred to as a performance estimation problem (PEP), as a semidefinite program (SDP) which can be solved numerically. To do that, the package users are only required to write first-order methods nearly as they would have implemented them. The package then takes care of the SDP modeling parts, and the worst-case analysis is performed numerically via a standard solver.",
        "published": "2022-01-11T16:35:22Z",
        "link": "http://arxiv.org/abs/2201.04040v2",
        "categories": [
            "math.OC",
            "cs.LG",
            "cs.MS",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "PyHHMM: A Python Library for Heterogeneous Hidden Markov Models",
        "authors": [
            "Fernando Moreno-Pino",
            "Emese Sükei",
            "Pablo M. Olmos",
            "Antonio Artés-Rodríguez"
        ],
        "summary": "We introduce PyHHMM, an object-oriented open-source Python implementation of Heterogeneous-Hidden Markov Models (HHMMs). In addition to HMM's basic core functionalities, such as different initialization algorithms and classical observations models, i.e., continuous and multinoulli, PyHHMM distinctively emphasizes features not supported in similar available frameworks: a heterogeneous observation model, missing data inference, different model order selection criterias, and semi-supervised training. These characteristics result in a feature-rich implementation for researchers working with sequential data. PyHHMM relies on the numpy, scipy, scikit-learn, and seaborn Python packages, and is distributed under the Apache-2.0 License. PyHHMM's source code is publicly available on Github (https://github.com/fmorenopino/HeterogeneousHMM) to facilitate adoptions and future contributions. A detailed documentation (https://pyhhmm.readthedocs.io/en/latest), which covers examples of use and models' theoretical explanation, is available. The package can be installed through the Python Package Index (PyPI), via 'pip install pyhhmm'.",
        "published": "2022-01-12T07:32:36Z",
        "link": "http://arxiv.org/abs/2201.06968v1",
        "categories": [
            "cs.MS",
            "cs.LG",
            "stat.ML"
        ]
    },
    {
        "title": "StAnD: A Dataset of Linear Static Analysis Problems",
        "authors": [
            "Luca Grementieri",
            "Francesco Finelli"
        ],
        "summary": "Static analysis of structures is a fundamental step for determining the stability of structures. Both linear and non-linear static analyses consist of the resolution of sparse linear systems obtained by the finite element method. The development of fast and optimized solvers for sparse linear systems appearing in structural engineering requires data to compare existing approaches, tune algorithms or to evaluate new ideas. We introduce the Static Analysis Dataset (StAnD) containing 303.000 static analysis problems obtained applying realistic loads to simulated frame structures. Along with the dataset, we publish a detailed benchmark comparison of the running time of existing solvers both on CPU and GPU. We release the code used to generate the dataset and benchmark existing solvers on Github. To the best of our knowledge, this is the largest dataset for static analysis problems and it is the first public dataset of sparse linear systems (containing both the matrix and a realistic constant term).",
        "published": "2022-01-14T09:31:43Z",
        "link": "http://arxiv.org/abs/2201.05356v1",
        "categories": [
            "cs.LG",
            "cs.MS",
            "cs.NA",
            "math.NA",
            "G.1.3; J.2"
        ]
    },
    {
        "title": "An efficient aggregation method for the symbolic representation of   temporal data",
        "authors": [
            "Xinye Chen",
            "Stefan Güttel"
        ],
        "summary": "Symbolic representations are a useful tool for the dimension reduction of temporal data, allowing for the efficient storage of and information retrieval from time series. They can also enhance the training of machine learning algorithms on time series data through noise reduction and reduced sensitivity to hyperparameters. The adaptive Brownian bridge-based aggregation (ABBA) method is one such effective and robust symbolic representation, demonstrated to accurately capture important trends and shapes in time series. However, in its current form the method struggles to process very large time series. Here we present a new variant of the ABBA method, called fABBA. This variant utilizes a new aggregation approach tailored to the piecewise representation of time series. By replacing the k-means clustering used in ABBA with a sorting-based aggregation technique, and thereby avoiding repeated sum-of-squares error computations, the computational complexity is significantly reduced. In contrast to the original method, the new approach does not require the number of time series symbols to be specified in advance. Through extensive tests we demonstrate that the new method significantly outperforms ABBA with a considerable reduction in runtime while also outperforming the popular SAX and 1d-SAX representations in terms of reconstruction accuracy. We further demonstrate that fABBA can compress other data types such as images.",
        "published": "2022-01-14T22:51:24Z",
        "link": "http://arxiv.org/abs/2201.05697v1",
        "categories": [
            "cs.LG",
            "cs.MS"
        ]
    },
    {
        "title": "MUPen2DTool: a Matlab Tool for 2D Nuclear Magnetic Resonance relaxation   data inversion",
        "authors": [
            "Villiam Bortolotti",
            "Leonardo Brizi",
            "Germana Landi",
            "Anastasiia Nagmutdinova",
            "Fabiana Zama"
        ],
        "summary": "Accurate and efficient analysis of materials properties from Nuclear Magnetic Resonance (NMR) relaxation data requires robust and efficient inversion procedures. Despite the great variety of applications requiring to process two-dimensional NMR data (2DNMR), a few software tools are freely available. The aim of this paper is to present MUPen2DTool, an open-source MATLAB based software tool for 2DNMR data inversion. The user can choose among several types of NMR experiments, and the software provides codes that can be used and extended easily. Furthermore, a MATLAB interface makes it easier to include users own data. The practical use is demonstrated in the reported examples of both synthetic and real NMR data.",
        "published": "2022-01-17T16:29:28Z",
        "link": "http://arxiv.org/abs/2201.06504v1",
        "categories": [
            "cs.MS",
            "65Z05, 68V35",
            "D.0; G.1; I.6"
        ]
    },
    {
        "title": "An Analysis of Approximation Algorithms for Iterated Stochastic   Integrals and a Julia and MATLAB Simulation Toolbox",
        "authors": [
            "Felix Kastner",
            "Andreas Rößler"
        ],
        "summary": "For the approximation and simulation of twofold iterated stochastic integrals and the corresponding L\\'{e}vy areas w.r.t. a multi-dimensional Wiener process, we review four algorithms based on a Fourier series approach. Especially, the very efficient algorithm due to Wiktorsson and a newly proposed algorithm due to Mrongowius and R\\\"ossler are considered. To put recent advances into context, we analyse the four Fourier-based algorithms in a unified framework to highlight differences and similarities in their derivation. A comparison of theoretical properties is complemented by a numerical simulation that reveals the order of convergence for each algorithm. Further, concrete instructions for the choice of the optimal algorithm and parameters for the simulation of solutions for stochastic (partial) differential equations are given. Additionally, we provide advice for an efficient implementation of the considered algorithms and incorporated these insights into an open source toolbox that is freely available for both Julia and MATLAB programming languages. The performance of this toolbox is analysed by comparing it to some existing implementations, where we observe a significant speed-up.",
        "published": "2022-01-20T19:41:46Z",
        "link": "http://arxiv.org/abs/2201.08424v2",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "math.PR",
            "60H05, 60H10, 65C30"
        ]
    },
    {
        "title": "Fast Differentiable Matrix Square Root",
        "authors": [
            "Yue Song",
            "Nicu Sebe",
            "Wei Wang"
        ],
        "summary": "Computing the matrix square root or its inverse in a differentiable manner is important in a variety of computer vision tasks. Previous methods either adopt the Singular Value Decomposition (SVD) to explicitly factorize the matrix or use the Newton-Schulz iteration (NS iteration) to derive the approximate solution. However, both methods are not computationally efficient enough in either the forward pass or in the backward pass. In this paper, we propose two more efficient variants to compute the differentiable matrix square root. For the forward propagation, one method is to use Matrix Taylor Polynomial (MTP), and the other method is to use Matrix Pad\\'e Approximants (MPA). The backward gradient is computed by iteratively solving the continuous-time Lyapunov equation using the matrix sign function. Both methods yield considerable speed-up compared with the SVD or the Newton-Schulz iteration. Experimental results on the de-correlated batch normalization and second-order vision transformer demonstrate that our methods can also achieve competitive and even slightly better performances. The code is available at \\href{https://github.com/KingJamesSong/FastDifferentiableMatSqrt}{https://github.com/KingJamesSong/FastDifferentiableMatSqrt}.",
        "published": "2022-01-21T12:18:06Z",
        "link": "http://arxiv.org/abs/2201.08663v1",
        "categories": [
            "cs.CV",
            "cs.LG",
            "cs.MS",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Zero-Truncated Poisson Regression for Sparse Multiway Count Data   Corrupted by False Zeros",
        "authors": [
            "Oscar López",
            "Daniel M. Dunlavy",
            "Richard B. Lehoucq"
        ],
        "summary": "We propose a novel statistical inference methodology for multiway count data that is corrupted by false zeros that are indistinguishable from true zero counts. Our approach consists of zero-truncating the Poisson distribution to neglect all zero values. This simple truncated approach dispenses with the need to distinguish between true and false zero counts and reduces the amount of data to be processed. Inference is accomplished via tensor completion that imposes low-rank tensor structure on the Poisson parameter space.   Our main result shows that an $N$-way rank-$R$ parametric tensor $\\boldsymbol{\\mathscr{M}}\\in(0,\\infty)^{I\\times \\cdots\\times I}$ generating Poisson observations can be accurately estimated by zero-truncated Poisson regression from approximately $IR^2\\log_2^2(I)$ non-zero counts under the nonnegative canonical polyadic decomposition. Our result also quantifies the error made by zero-truncating the Poisson distribution when the parameter is uniformly bounded from below. Therefore, under a low-rank multiparameter model, we propose an implementable approach guaranteed to achieve accurate regression in under-determined scenarios with substantial corruption by false zeros. Several numerical experiments are presented to explore the theoretical results.",
        "published": "2022-01-25T00:09:48Z",
        "link": "http://arxiv.org/abs/2201.10014v2",
        "categories": [
            "stat.ME",
            "cs.MS",
            "cs.NA",
            "math.NA",
            "math.ST",
            "stat.ML",
            "stat.TH"
        ]
    },
    {
        "title": "Extending FEniCS to Work in Higher Dimensions Using Tensor Product   Finite Elements",
        "authors": [
            "Mark Loveland",
            "Eirik Valseth",
            "Matt Lukac",
            "Clint Dawson"
        ],
        "summary": "We present a method to extend the finite element library FEniCS to solve problems with domains in dimensions above three by constructing tensor product finite elements. This methodology only requires that the high dimensional domain is structured as a Cartesian product of two lower dimensional subdomains. In this study we consider Dirichlet problems for scalar linear partial differential equations, though the methodology can be extended to non-linear problems. The utilization of tensor product finite elements allows us to construct a global system of linear algebraic equations that only relies on the finite element infrastructure of the lower dimensional subdomains contained in FEniCS. We demonstrate the effectiveness of our methodology in four distinctive test cases. The first test case is a Poisson equation posed in a four dimensional domain which is a Cartesian product of two unit squares solved using the classical Galerkin finite element method. The second test case is the wave equation in space-time, where the computational domain is a Cartesian product of a two dimensional space grid and a one dimensional time interval. In this second case we also employ the Galerkin method. The third test case is an advection dominated advection-diffusion equation where the global domain is a Cartesian product of two one dimensional intervals in which the streamline upwind Petrov-Galerkin method is applied to ensure discrete stability. The final test case uses the Galerkin approach to solve a Poisson problem on a Cartesian product of two intervals with a spatially varying, non-separable diffusivity term. In all cases, a p=1 basis is used and optimal L^2 convergence rates of order h^{p+1} of the errors are achieved with respect to h refinement",
        "published": "2022-02-01T21:14:28Z",
        "link": "http://arxiv.org/abs/2202.00762v2",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "Giga-scale Kernel Matrix Vector Multiplication on GPU",
        "authors": [
            "Robert Hu",
            "Siu Lun Chau",
            "Dino Sejdinovic",
            "Joan Alexis Glaunès"
        ],
        "summary": "Kernel matrix-vector multiplication (KMVM) is a foundational operation in machine learning and scientific computing. However, as KMVM tends to scale quadratically in both memory and time, applications are often limited by these computational constraints. In this paper, we propose a novel approximation procedure coined \\textit{Faster-Fast and Free Memory Method} ($\\fthreem$) to address these scaling issues of KMVM for tall~($10^8\\sim 10^9$) and skinny~($D\\leq7$) data. Extensive experiments demonstrate that $\\fthreem$ has empirical \\emph{linear time and memory} complexity with a relative error of order $10^{-3}$ and can compute a full KMVM for a billion points \\emph{in under a minute} on a high-end GPU, leading to a significant speed-up in comparison to existing CPU methods. We demonstrate the utility of our procedure by applying it as a drop-in for the state-of-the-art GPU-based linear solver FALKON, \\emph{improving speed 1.5-5.5 times} at the cost of $<1\\%$ drop in accuracy. We further demonstrate competitive results on \\emph{Gaussian Process regression} coupled with significant speedups on a variety of real-world datasets.",
        "published": "2022-02-02T15:28:15Z",
        "link": "http://arxiv.org/abs/2202.01085v3",
        "categories": [
            "math.NA",
            "cs.LG",
            "cs.MS",
            "cs.NA",
            "stat.CO"
        ]
    },
    {
        "title": "Solidfmm: A highly optimised library of operations on the solid   harmonics for use in fast multipole methods",
        "authors": [
            "Matthias Kirchhart"
        ],
        "summary": "We present solidfmm, a highly optimised C++ library for the solid harmonics as they are needed in fast multipole methods. The library provides efficient, vectorised implementations of the translation operations M2M, M2L, and L2L, and is available as free software. While asymptotically of complexity $O(P^3)$, for all practically relevant expansion orders, the translation operators display an empirical complexity of $O(P^2)$, outperforming the na\\\"ive implementation by orders of magnitude.",
        "published": "2022-02-06T20:38:12Z",
        "link": "http://arxiv.org/abs/2202.02847v1",
        "categories": [
            "cs.MS",
            "35-04"
        ]
    },
    {
        "title": "FL_PyTorch: optimization research simulator for federated learning",
        "authors": [
            "Konstantin Burlachenko",
            "Samuel Horváth",
            "Peter Richtárik"
        ],
        "summary": "Federated Learning (FL) has emerged as a promising technique for edge devices to collaboratively learn a shared machine learning model while keeping training data locally on the device, thereby removing the need to store and access the full data in the cloud. However, FL is difficult to implement, test and deploy in practice considering heterogeneity in common edge device settings, making it fundamentally hard for researchers to efficiently prototype and test their optimization algorithms. In this work, our aim is to alleviate this problem by introducing FL_PyTorch : a suite of open-source software written in python that builds on top of one the most popular research Deep Learning (DL) framework PyTorch. We built FL_PyTorch as a research simulator for FL to enable fast development, prototyping and experimenting with new and existing FL optimization algorithms. Our system supports abstractions that provide researchers with a sufficient level of flexibility to experiment with existing and novel approaches to advance the state-of-the-art. Furthermore, FL_PyTorch is a simple to use console system, allows to run several clients simultaneously using local CPUs or GPU(s), and even remote compute devices without the need for any distributed implementation provided by the user. FL_PyTorch also offers a Graphical User Interface. For new methods, researchers only provide the centralized implementation of their algorithm. To showcase the possibilities and usefulness of our system, we experiment with several well-known state-of-the-art FL algorithms and a few of the most common FL datasets.",
        "published": "2022-02-07T12:18:28Z",
        "link": "http://arxiv.org/abs/2202.03099v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MS",
            "math.OC",
            "G.4"
        ]
    },
    {
        "title": "L0Learn: A Scalable Package for Sparse Learning using L0 Regularization",
        "authors": [
            "Hussein Hazimeh",
            "Rahul Mazumder",
            "Tim Nonet"
        ],
        "summary": "We present L0Learn: an open-source package for sparse linear regression and classification using $\\ell_0$ regularization. L0Learn implements scalable, approximate algorithms, based on coordinate descent and local combinatorial optimization. The package is built using C++ and has user-friendly R and Python interfaces. L0Learn can address problems with millions of features, achieving competitive run times and statistical performance with state-of-the-art sparse learning packages. L0Learn is available on both CRAN and GitHub (https://cran.r-project.org/package=L0Learn and https://github.com/hazimehh/L0Learn).",
        "published": "2022-02-10T03:51:25Z",
        "link": "http://arxiv.org/abs/2202.04820v2",
        "categories": [
            "cs.LG",
            "cs.MS",
            "stat.CO",
            "stat.ML"
        ]
    },
    {
        "title": "The Factorial-Basis Method for Finding Definite-Sum Solutions of Linear   Recurrences With Polynomial Coefficients",
        "authors": [
            "Antonio Jiménez-Pastor",
            "Marko Petkovšek"
        ],
        "summary": "The problem of finding a nonzero solution of a linear recurrence $Ly = 0$ with polynomial coefficients where $y$ has the form of a definite hypergeometric sum, related to the Inverse Creative Telescoping Problem of [14][Sec. 8], has now been open for three decades. Here we present an algorithm (implemented in a SageMath package) which, given such a recurrence and a quasi-triangular, shift-compatible factorial basis $\\mathcal{B} = \\langle P_k(n)\\rangle_{k=0}^\\infty$ of the polynomial space $\\mathbb{K}[n]$ over a field $\\mathbb{K}$ of characteristic zero, computes a recurrence satisfied by the coefficient sequence $c = \\langle c_k\\rangle_{k=0}^\\infty$ of the solution $y_n = \\sum_{k=0}^\\infty c_kP_k(n)$ (where, thanks to the quasi-triangularity of $\\mathcal{B}$, the sum on the right terminates for each $n \\in \\mathbb{N}$). More generally, if $\\mathcal{B}$ is $m$-sieved for some $m \\in \\mathbb{N}$, our algorithm computes a system of $m$ recurrences satisfied by the $m$-sections of the coefficient sequence $c$. If an explicit nonzero solution of this system can be found, we obtain an explicit nonzero solution of $Ly = 0$.",
        "published": "2022-02-11T11:07:39Z",
        "link": "http://arxiv.org/abs/2202.05550v3",
        "categories": [
            "cs.SC",
            "cs.MS",
            "33F10, 39A06, 68W30"
        ]
    },
    {
        "title": "Exploration of Differentiability in a Proton Computed Tomography   Simulation Framework",
        "authors": [
            "Max Aehle",
            "Johan Alme",
            "Gergely Gábor Barnaföldi",
            "Johannes Blühdorn",
            "Tea Bodova",
            "Vyacheslav Borshchov",
            "Anthony van den Brink",
            "Viljar Eikeland",
            "Gregory Feofilov",
            "Christoph Garth",
            "Nicolas R. Gauger",
            "Ola Grøttvik",
            "Håvard Helstrup",
            "Sergey Igolkin",
            "Ralf Keidel",
            "Chinorat Kobdaj",
            "Tobias Kortus",
            "Lisa Kusch",
            "Viktor Leonhardt",
            "Shruti Mehendale",
            "Raju Ningappa Mulawade",
            "Odd Harald Odland",
            "George O'Neill",
            "Gábor Papp",
            "Thomas Peitzmann",
            "Helge Egil Seime Pettersen",
            "Pierluigi Piersimoni",
            "Rohit Pochampalli",
            "Maksym Protsenko",
            "Max Rauch",
            "Attiq Ur Rehman",
            "Matthias Richter",
            "Dieter Röhrich",
            "Max Sagebaum",
            "Joshua Santana",
            "Alexander Schilling",
            "Joao Seco",
            "Arnon Songmoolnak",
            "Ákos Sudár",
            "Ganesh Tambave",
            "Ihor Tymchuk",
            "Kjetil Ullaland",
            "Monika Varga-Kofarago",
            "Lennart Volz",
            "Boris Wagner",
            "Steffen Wendzel",
            "Alexander Wiebel",
            "RenZheng Xiao",
            "Shiming Yang",
            "Sebastian Zillien"
        ],
        "summary": "Objective. Algorithmic differentiation (AD) can be a useful technique to numerically optimize design and algorithmic parameters by, and quantify uncertainties in, computer simulations. However, the effectiveness of AD depends on how \"well-linearizable\" the software is. In this study, we assess how promising derivative information of a typical proton computed tomography (pCT) scan computer simulation is for the aforementioned applications.   Approach. This study is mainly based on numerical experiments, in which we repeatedly evaluate three representative computational steps with perturbed input values. We support our observations with a review of the algorithmic steps and arithmetic operations performed by the software, using debugging techniques.   Main results. The model-based iterative reconstruction (MBIR) subprocedure (at the end of the software pipeline) and the Monte Carlo (MC) simulation (at the beginning) were piecewise differentiable. Jumps in the MBIR function arose from the discrete computation of the set of voxels intersected by a proton path. Jumps in the MC function likely arose from changes in the control flow that affect the amount of consumed random numbers. The tracking algorithm solves an inherently non-differentiable problem.   Significance. The MC and MBIR codes are ready for the integration of AD, and further research on surrogate models for the tracking subprocedure is necessary.",
        "published": "2022-02-11T11:07:46Z",
        "link": "http://arxiv.org/abs/2202.05551v2",
        "categories": [
            "physics.med-ph",
            "cs.MS"
        ]
    },
    {
        "title": "Faster Gröbner bases for Lie derivatives of ODE systems via monomial   orderings",
        "authors": [
            "Mariya Bessonov",
            "Ilia Ilmer",
            "Tatiana Konstantinova",
            "Alexey Ovchinnikov",
            "Gleb Pogudin",
            "Pedro Soto"
        ],
        "summary": "Symbolic computation for systems of differential equations is often computationally expensive. Many practical differential models have a form of polynomial or rational ODE system with specified outputs. A basic symbolic approach to analyze these models is to compute and then symbolically process the polynomial system obtained by sufficiently many Lie derivatives of the output functions with respect to the vector field given by the ODE system.   In this paper, we present a method for speeding up Gr\\\"obner basis computation for such a class of polynomial systems by using specific monomial ordering, including weights for the variables, coming from the structure of the ODE model. We provide empirical results that show improvement across different symbolic computing frameworks and apply the method to speed up structural identifiability analysis of ODE models.",
        "published": "2022-02-13T12:40:11Z",
        "link": "http://arxiv.org/abs/2202.06297v3",
        "categories": [
            "cs.SC",
            "cs.MS",
            "q-bio.QM"
        ]
    },
    {
        "title": "Phase Vocoder Done Right",
        "authors": [
            "Zdenek Prusa",
            "Nicki Holighaus"
        ],
        "summary": "The phase vocoder (PV) is a widely spread technique for processing audio signals. It employs a short-time Fourier transform (STFT) analysis-modify-synthesis loop and is typically used for time-scaling of signals by means of using different time steps for STFT analysis and synthesis. The main challenge of PV used for that purpose is the correction of the STFT phase. In this paper, we introduce a novel method for phase correction based on phase gradient estimation and its integration. The method does not require explicit peak picking and tracking nor does it require detection of transients and their separate treatment. Yet, the method does not suffer from the typical phase vocoder artifacts even for extreme time stretching factors.",
        "published": "2022-02-15T13:20:14Z",
        "link": "http://arxiv.org/abs/2202.07382v1",
        "categories": [
            "cs.SD",
            "cs.MS",
            "eess.AS"
        ]
    },
    {
        "title": "Non-iterative Filter Bank Phase (Re)Construction",
        "authors": [
            "Zdeněk Průša",
            "Nicki Holighaus"
        ],
        "summary": "Signal reconstruction from magnitude-only measurements presents a long-standing problem in signal processing. In this contribution, we propose a phase (re)construction method for filter banks with uniform decimation and controlled frequency variation. The suggested procedure extends the recently introduced phase-gradient heap integration and relies on a phase-magnitude relationship for filter bank coefficients obtained from Gaussian filters. Admissible filter banks are modeled as the discretization of certain generalized translation-invariant systems, for which we derive the phase-magnitude relationship explicitly. The implementation for discrete signals is described and the performance of the algorithm is evaluated on a range of real and synthetic signals.",
        "published": "2022-02-15T15:11:54Z",
        "link": "http://arxiv.org/abs/2202.07498v1",
        "categories": [
            "cs.SD",
            "cs.MS",
            "eess.AS",
            "eess.SP"
        ]
    },
    {
        "title": "Fast Matching Pursuit with Multi-Gabor Dictionaries",
        "authors": [
            "Zdeněk Průša",
            "Nicki Holighaus",
            "Peter Balazs"
        ],
        "summary": "Finding the best K-sparse approximation of a signal in a redundant dictionary is an NP-hard problem. Suboptimal greedy matching pursuit (MP) algorithms are generally used for this task. In this work, we present an acceleration technique and an implementation of the matching pursuit algorithm acting on a multi-Gabor dictionary, i.e., a concatenation of several Gabor-type time-frequency dictionaries, each of which consisting of translations and modulations of a possibly different window and time and frequency shift parameters. The technique is based on pre-computing and thresholding inner products between atoms and on updating the residual directly in the coefficient domain, i.e., without the round-trip to the signal domain. Since the proposed acceleration technique involves an approximate update step, we provide theoretical and experimental results illustrating the convergence of the resulting algorithm. The implementation is written in C (compatible with C99 and C++11) and we also provide Matlab and GNU Octave interfaces. For some settings, the implementation is up to 70 times faster than the standard Matching Pursuit Toolkit (MPTK).",
        "published": "2022-02-16T09:55:02Z",
        "link": "http://arxiv.org/abs/2202.12380v1",
        "categories": [
            "math.NA",
            "cs.IT",
            "cs.MS",
            "cs.NA",
            "eess.SP",
            "math.IT"
        ]
    },
    {
        "title": "Vectorization of a thread-parallel Jacobi singular value decomposition   method",
        "authors": [
            "Vedran Novaković"
        ],
        "summary": "The eigenvalue decomposition (EVD) of (a batch of) Hermitian matrices of order two has a role in many numerical algorithms, of which the one-sided Jacobi method for the singular value decomposition (SVD) is the prime example. In this paper the batched EVD is vectorized, with a vector-friendly data layout and the AVX-512 SIMD instructions of Intel CPUs, alongside other key components of a real and a complex OpenMP-parallel Jacobi-type SVD method, inspired by the sequential xGESVJ routines from LAPACK. These vectorized building blocks should be portable to other platforms that support similar vector operations. Unconditional numerical reproducibility is guaranteed for the batched EVD, sequential or threaded, and for the column transformations, that are, like the scaled dot-products, presently sequential but can be threaded if nested parallelism is desired. No avoidable overflow of the results can occur with the proposed EVD or the whole SVD. The measured accuracy of the proposed EVD often surpasses that of the xLAEV2 routines from LAPACK. While the batched EVD outperforms the matching sequence of xLAEV2 calls, speedup of the parallel SVD is modest but can be improved and is already beneficial with enough threads. Regardless of their number, the proposed SVD method gives identical results, but of somewhat lower accuracy than xGESVJ.",
        "published": "2022-02-16T22:30:43Z",
        "link": "http://arxiv.org/abs/2202.08361v4",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "65F15 (Primary) 65F25, 65Y05, 65Y10 (Secondary)",
            "G.1.3; G.4"
        ]
    },
    {
        "title": "Efficient solution of 3D elasticity problems with smoothed aggregation   algebraic multigrid and block arithmetics",
        "authors": [
            "Denis Demidov"
        ],
        "summary": "Efficient solution of 3D elasticity problems is an important part of many industrial and scientific applications. Smoothed aggregation algebraic multigrid using rigid body modes for the tentative prolongation operator construction is an efficient and robust choice for the solution of linear systems arising from the discretization of elasticity equations. The system matrices on every level of the multigrid hierarchy have block structure, so using block representation and block arithmetics should significantly improve the solver efficiency. However, the tentative prolongation operator construction may only be done using scalar representation. The paper proposes a couple of practical approaches for enabling the use of block arithmetics with smoothed aggregation algebraic multigrid based on the open-source AMGCL library. It is shown on the example of two real-world model problems that the suggested improvements may speed up the solution by 50% and reduce the memory requirements for the preconditioner by 30%. The implementation is straightforward and only requires a minimal amount of code.",
        "published": "2022-02-18T07:45:39Z",
        "link": "http://arxiv.org/abs/2202.09056v1",
        "categories": [
            "cs.MS",
            "cs.NA",
            "math.NA",
            "35-04, 65-04, 65Y05, 65Y10, 65Y15, 97N80"
        ]
    },
    {
        "title": "Benchmarking the Linear Algebra Awareness of TensorFlow and PyTorch",
        "authors": [
            "Aravind Sankaran",
            "Navid Akbari Alashti",
            "Christos Psarras",
            "Paolo Bientinesi"
        ],
        "summary": "Linear algebra operations, which are ubiquitous in machine learning, form major performance bottlenecks. The High-Performance Computing community invests significant effort in the development of architecture-specific optimized kernels, such as those provided by the BLAS and LAPACK libraries, to speed up linear algebra operations. However, end users are progressively less likely to go through the error prone and time-consuming process of directly using said kernels; instead, frameworks such as TensorFlow (TF) and PyTorch (PyT), which facilitate the development of machine learning applications, are becoming more and more popular. Although such frameworks link to BLAS and LAPACK, it is not clear whether or not they make use of linear algebra knowledge to speed up computations. For this reason, in this paper we develop benchmarks to investigate the linear algebra optimization capabilities of TF and PyT. Our analyses reveal that a number of linear algebra optimizations are still missing; for instance, reducing the number of scalar operations by applying the distributive law, and automatically identifying the optimal parenthesization of a matrix chain. In this work, we focus on linear algebra computations in TF and PyT; we both expose opportunities for performance enhancement to the benefit of the developers of the frameworks and provide end users with guidelines on how to achieve performance gains.",
        "published": "2022-02-20T18:51:00Z",
        "link": "http://arxiv.org/abs/2202.09888v1",
        "categories": [
            "cs.MS",
            "cs.LG",
            "cs.PF"
        ]
    },
    {
        "title": "Adaptive time step control for multirate infinitesimal methods",
        "authors": [
            "Alex C. Fish",
            "Daniel R. Reynolds"
        ],
        "summary": "Multirate methods have been used for decades to temporally evolve initial-value problems in which different components evolve on distinct time scales, and thus use of different step sizes for these components can result in increased computational efficiency. Generally, such methods select these different step sizes based on experimentation or stability considerations. For problems that evolve on a single time scale, adaptivity approaches that strive to control local temporal error are widely used to achieve numerical results of a desired accuracy with minimal computational effort, while alleviating the need for manual experimentation with different time step sizes. However, there is a notable gap in the publication record on the development of adaptive time-step controllers for multirate methods. In this paper, we extend the single-rate controller work of Gustafsson (1994) to the multirate method setting. Specifically, we develop controllers based on polynomial approximations to the principal error functions for both the \"fast\" and \"slow\" time scales within multirate infinitesimal (MRI) methods. We additionally investigate a variety of approaches for estimating the errors arising from each time scale within MRI methods. We then numerically evaluate the proposed multirate controllers and error estimation strategies on a range of multirate test problems, comparing their performance against an estimated optimal performance. Through this work, we combine the most performant of these approaches to arrive at a set of multirate adaptive time step controllers that robustly achieve desired solution accuracy with minimal computational effort.",
        "published": "2022-02-21T19:00:17Z",
        "link": "http://arxiv.org/abs/2202.10484v2",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "65L50, 65L05, 65L06"
        ]
    },
    {
        "title": "An LLVM-based C++ Compiler Toolchain for Variational Hybrid   Quantum-Classical Algorithms and Quantum Accelerators",
        "authors": [
            "Pradnya Khalate",
            "Xin-Chuan Wu",
            "Shavindra Premaratne",
            "Justin Hogaboam",
            "Adam Holmes",
            "Albert Schmitz",
            "Gian Giacomo Guerreschi",
            "Xiang Zou",
            "A. Y. Matsuura"
        ],
        "summary": "Variational algorithms are a representative class of quantum computing workloads that combine quantum and classical computing. This paper presents an LLVM-based C++ compiler toolchain to efficiently execute variational hybrid quantum-classical algorithms on a computational system in which the quantum device acts as an accelerator. We introduce a set of extensions to the C++ language for programming these algorithms. We define a novel Executable and Linking Format (ELF) for Quantum and create a quantum device compiler component in the LLVM framework to compile the quantum part of the C++ source and reuse the host compiler in the LLVM framework to compile the classical computing part of the C++ source. A variational algorithm runs a quantum circuit repeatedly, each time with different gate parameters. We add to the quantum runtime the capability to execute dynamically a quantum circuit with different parameters. Thus, programmers can call quantum routines the same way as classical routines. With these capabilities, a variational hybrid quantum-classical algorithm can be specified in a single-source code and only needs to be compiled once for all iterations. The single compilation significantly reduces the execution latency of variational algorithms. We evaluate the framework's performance by running quantum circuits that prepare Thermofield Double (TFD) states, a quantum-classical variational algorithm.",
        "published": "2022-02-22T19:32:50Z",
        "link": "http://arxiv.org/abs/2202.11142v1",
        "categories": [
            "quant-ph",
            "cs.MS"
        ]
    },
    {
        "title": "Compressed Matrix Computations",
        "authors": [
            "Matthieu Martel"
        ],
        "summary": "Frugal computing is becoming an important topic for environmental reasons. In this context, several techniques have been proposed to reduce the storage of scientific data by dedicated compression methods specially tailored for arrays of floating-point numbers. While these techniques are quite efficient to save memory, they introduce additional computations to compress and decompress the data before processing them. In this article, we introduce a new lossy, fixed-rate compression technique for 2D-arrays of floating-point numbers which allows one to compute directly on the compressed data, without decompressing them. We obtain important speedups since less operations are needed to compute among the compressed data and since no decompression and re-compression is needed. More precisely, our technique makes it possible to perform basic linear algebra operations such as addition, multiplication by a constant among compressed matrices and dot product and matrix multiplication among partly uncompressed matrices. This work has been implemented into a tool named blaz and a comparison with the well-known compressor zfp in terms of execution-time and accuracy is presented.",
        "published": "2022-02-25T22:49:49Z",
        "link": "http://arxiv.org/abs/2202.13007v1",
        "categories": [
            "cs.DS",
            "cs.MS"
        ]
    },
    {
        "title": "CGAL Made More Accessible",
        "authors": [
            "Nir Goren",
            "Efi Fogel",
            "Dan Halperin"
        ],
        "summary": "We introduce bindings that enable the convenient, efficient, and reliable use of software modules of CGAL (Computational Geometry Algorithm Library), which are written in C++, from within code written in Python. There are different tools that facilitate the creation of such bindings. We present a short study that compares three main tools, which leads to the tool of choice. The implementation of algorithms and data structures in computational geometry presents tremendous difficulties, such as obtaining robust software despite the use of (inexact) floating point arithmetic, found in standard hardware, and meticulous handling of all degenerate cases, which typically are in abundance. The code of CGAL extensively uses function and class templates in order to handle these difficulties, which implies that the programmer has to make many choices that are resolved during compile time (of the C++ modules). While bindings take effect at run time (of the Python code), the type of the C++ objects that are bound must be known when the bindings are generated, that is, when they are compiled. The types of the bound objects are instances (instantiated types) of C++ function and class templates. The number of object types that can potentially be bound, in implementation of generic computational-geometry algorithms, is enormous; thus, the generation of the bindings for all these types in advance is practically impossible. Often there are several choices to make, resulting in a prohibitively large number of combinations. We present a system that rapidly generates bindings for desired object types according to user prescriptions, which enables the convenient use of any subset of bound object types concurrently. The introduction of the bindings made them easily accessible to newcomers and practitioners in non-computing fields, as we report in the paper.",
        "published": "2022-02-28T15:38:24Z",
        "link": "http://arxiv.org/abs/2202.13889v2",
        "categories": [
            "cs.CG",
            "cs.MS"
        ]
    },
    {
        "title": "MooAFEM: An object oriented Matlab code for higher-order adaptive FEM   for (nonlinear) elliptic PDEs",
        "authors": [
            "Michael Innerberger",
            "Dirk Praetorius"
        ],
        "summary": "We present an easily accessible, object oriented code (written exclusively in Matlab) for adaptive finite element simulations in 2D. It features various refinement routines for triangular meshes as well as fully vectorized FEM ansatz spaces of arbitrary polynomial order and allows for problems with very general coefficients. In particular, our code can handle problems typically arising from iterative linearization methods used to solve nonlinear PDEs. Due to the object oriented programming paradigm, the code can be used easily and is readily extensible. We explain the basic principles of our code and give numerical experiments that underline its flexibility as well as its efficiency.",
        "published": "2022-03-03T16:51:11Z",
        "link": "http://arxiv.org/abs/2203.01845v4",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "Efficient Data Structures for Exploiting Sparsity and Structure in   Representation of Polynomial Optimization Problems: Implementation in   SOSTOOLS",
        "authors": [
            "Declan Jagt",
            "Sachin Shivakumar",
            "Peter Seiler",
            "Matthew Peet"
        ],
        "summary": "We present a new data structure for representation of polynomial variables in the parsing of sum-of-squares (SOS) programs. In SOS programs, the variables $s(x;Q)$ are polynomial in the independent variables $x$, but linear in the decision variables $Q$. Current SOS parsers, however, fail to exploit the semi-linear structure of the polynomial variables, treating the decision variables as independent variables in their representation. This results in unnecessary overhead in storage and manipulation of the polynomial variables, prohibiting the parser from addressing larger-scale optimization problems. To eliminate this computational overhead, we introduce a new representation of polynomial variables, the \"dpvar\" structure, that is affine in the decision variables. We show that the complexity of operations on variables in the dpvar representation scales favorably with the number of decision variables. We further show that the required memory for storing polynomial variables is relatively small using the dpvar structure, particularly when exploiting the MATLAB sparse storage structure. Finally, we incorporate the dpvar data structure into SOSTOOLS 4.00, and test the performance of the parser for several polynomial optimization problems.",
        "published": "2022-03-03T18:42:05Z",
        "link": "http://arxiv.org/abs/2203.01910v5",
        "categories": [
            "math.OC",
            "cs.MS"
        ]
    },
    {
        "title": "pylspack: Parallel algorithms and data structures for sketching, column   subset selection, regression and leverage scores",
        "authors": [
            "Aleksandros Sobczyk",
            "Efstratios Gallopoulos"
        ],
        "summary": "We present parallel algorithms and data structures for three fundamental operations in Numerical Linear Algebra: (i) Gaussian and CountSketch random projections and their combination, (ii) computation of the Gram matrix and (iii) computation of the squared row norms of the product of two matrices, with a special focus on \"tall-and-skinny\" matrices, which arise in many applications. We provide a detailed analysis of the ubiquitous CountSketch transform and its combination with Gaussian random projections, accounting for memory requirements, computational complexity and workload balancing. We also demonstrate how these results can be applied to column subset selection, least squares regression and leverage scores computation. These tools have been implemented in pylspack, a publicly available Python package (https://github.com/IBM/pylspack) whose core is written in C++ and parallelized with OpenMP, and which is compatible with standard matrix data structures of SciPy and NumPy. Extensive numerical experiments indicate that the proposed algorithms scale well and significantly outperform existing libraries for tall-and-skinny matrices.",
        "published": "2022-03-05T18:21:05Z",
        "link": "http://arxiv.org/abs/2203.02798v2",
        "categories": [
            "cs.DS",
            "cs.DC",
            "cs.MS",
            "65F50, 65F08, 65F20, 68W10, 68W20, 68P05",
            "F.2.1; G.3; E.1"
        ]
    },
    {
        "title": "Parallel inexact Newton-Krylov and quasi-Newton solvers for nonlinear   elasticity",
        "authors": [
            "Nicolás A. Barnafi",
            "Luca F. Pavarino",
            "Simone Scacchi"
        ],
        "summary": "In this work, we address the implementation and performance of inexact Newton-Krylov and quasi-Newton algorithms, more specifically the BFGS method, for the solution of the nonlinear elasticity equations, and compare them to a standard Newton-Krylov method. This is done through a systematic analysis of the performance of the solvers with respect to the problem size, the magnitude of the data and the number of processors in both almost incompressible and incompressible mechanics. We consider three test cases: Cook's membrane (static, almost incompressible), a twist test (static, incompressible) and a cardiac model (complex material, time dependent, almost incompressible). Our results suggest that quasi-Newton methods should be preferred for compressible mechanics, whereas inexact Newton-Krylov methods should be preferred for incompressible problems. We show that these claims are also backed up by the convergence analysis of the methods. In any case, all methods present adequate performance, and provide a significant speed-up over the standard Newton-Krylov method, with a CPU time reduction exceeding 50% in the best cases.",
        "published": "2022-03-10T19:49:07Z",
        "link": "http://arxiv.org/abs/2203.05610v1",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "G.1.6; G.1.8; G.4"
        ]
    },
    {
        "title": "Distributed $\\mathcal{H}^2$-matrices for boundary element methods",
        "authors": [
            "Steffen Börm"
        ],
        "summary": "Standard discretization techniques for boundary integral equations, e.g., the Galerkin boundary element method, lead to large densely populated matrices that require fast and efficient compression techniques like the fast multipole method or hierarchical matrices. If the underlying mesh is very large, running the corresponding algorithms on a distributed computer is attractive, e.g., since distributed computers frequently are cost-effective and offer a high accumulated memory bandwidth.   Compared to the closely related particle methods, for which distributed algorithms are well-established, the Galerkin discretization poses a challenge, since the supports of the basis functions influence the block structure of the matrix and therefore the flow of data in the corresponding algorithms. This article introduces distributed $\\mathcal{H}^2$-matrices, a class of hierarchical matrices that is closely related to fast multipole methods and particularly well-suited for distributed computing. While earlier efforts required the global tree structure of the $\\mathcal{H}^2$-matrix to be stored in every node of the distributed system, the new approach needs only local multilevel information that can be obtained via a simple distributed algorithm, allowing us to scale to significantly larger systems.   Experiments show that this approach can handle very large meshes with more than $130$ million triangles efficiently.",
        "published": "2022-03-10T22:29:18Z",
        "link": "http://arxiv.org/abs/2203.05665v1",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "65N38, 65Y05",
            "G.1.9; G.4"
        ]
    },
    {
        "title": "GPU Accelerated Automatic Differentiation With Clad",
        "authors": [
            "Ioana Ifrim",
            "Vassil Vassilev",
            "David J Lange"
        ],
        "summary": "Automatic Differentiation (AD) is instrumental for science and industry. It is a tool to evaluate the derivative of a function specified through a computer program. The range of AD application domain spans from Machine Learning to Robotics to High Energy Physics. Computing gradients with the help of AD is guaranteed to be more precise than the numerical alternative and have a low, constant factor more arithmetical operations compared to the original function. Moreover, AD applications to domain problems typically are computationally bound. They are often limited by the computational requirements of high-dimensional parameters and thus can benefit from parallel implementations on graphics processing units (GPUs). Clad aims to enable differential analysis for C/C++ and CUDA and is a compiler-assisted AD tool available both as a compiler extension and in ROOT. Moreover, Clad works as a plugin extending the Clang compiler; as a plugin extending the interactive interpreter Cling; and as a Jupyter kernel extension based on xeus-cling. We demonstrate the advantages of parallel gradient computations on GPUs with Clad. We explain how to bring forth a new layer of optimization and a proportional speed up by extending Clad to support CUDA. The gradients of well-behaved C++ functions can be automatically executed on a GPU. The library can be easily integrated into existing frameworks or used interactively. Furthermore, we demonstrate the achieved application performance improvements, including (~10x) in ROOT histogram fitting and corresponding performance gains from offloading to GPUs.",
        "published": "2022-03-11T18:10:53Z",
        "link": "http://arxiv.org/abs/2203.06139v2",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "On Distributed Gravitational N-Body Simulations",
        "authors": [
            "Alexander Brandt"
        ],
        "summary": "The N-body problem is a classic problem involving a system of N discrete bodies mutually interacting in a dynamical system. At any moment in time there are N*(N - 1)/2 such interactions occurring. This scaling as N^2 leads to computational difficulties where simulations range from tens of thousands of bodies to many millions. Approximation algorithms, such as the famous Barnes-Hut algorithm, simplify the number of interactions to scale as N(log N). Even still, this improvement in complexity is insufficient to achieve the desired performance for very large simulations on computing clusters with many nodes and many cores. In this work we explore a variety of algorithmic techniques for distributed and parallel variations on the Barnes-Hut algorithm to improve parallelism and reduce inter-process communication requirements. Explicit algorithms and details are provided for reproducibility. Our MPI implementation of distributed gravitational N-body simulation, freely available on GitHub, is evaluated on a cluster of 10 nodes, each with two 6-core CPUs, to test the effectiveness and scalability of the aforementioned techniques.",
        "published": "2022-03-16T22:05:11Z",
        "link": "http://arxiv.org/abs/2203.08966v1",
        "categories": [
            "cs.CE",
            "cs.DC",
            "cs.MS"
        ]
    },
    {
        "title": "The Sparse Grids Matlab kit -- a Matlab implementation of sparse grids   for high-dimensional function approximation and uncertainty quantification",
        "authors": [
            "Chiara Piazzola",
            "Lorenzo Tamellini"
        ],
        "summary": "The Sparse Grids Matlab Kit provides a Matlab implementation of sparse grids, and can be used for approximating high-dimensional functions and, in particular, for surrogate-model-based uncertainty quantification. It is lightweight, high-level and easy to use, good for quick prototyping and teaching; however, it is equipped with some features that allow its use also in realistic applications. The goal of this paper is to provide an overview of the data structure and of the mathematical aspects forming the basis of the software, as well as comparing the current release of our package to similar available software.",
        "published": "2022-03-17T13:36:06Z",
        "link": "http://arxiv.org/abs/2203.09314v3",
        "categories": [
            "cs.MS",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Benchmarking a Proof-of-Concept Performance Portable SYCL-based Fast   Fourier Transformation Library",
        "authors": [
            "Vincent R. Pascuzzi",
            "Mehdi Goli"
        ],
        "summary": "In this paper, we present an early version of a SYCL-based FFT library, capable of running on all major vendor hardware, including CPUs and GPUs from AMD, ARM, Intel and NVIDIA. Although preliminary, the aim of this work is to seed further developments for a rich set of features for calculating FFTs. It has the advantage over existing portable FFT libraries in that it is single-source, and therefore removes the complexities that arise due to abundant use of pre-process macros and auto-generated kernels to target different architectures. We exercise two SYCL-enabled compilers, Codeplay ComputeCpp and Intel's open-source LLVM project, to evaluate performance portability of our SYCL-based FFT on various heterogeneous architectures. The current limitations of our library is it supports single-dimension FFTs up to $2^{11}$ in length and base-2 input sequences. We compare our results with highly optimized vendor specific FFT libraries and provide a detailed analysis to demonstrate a fair level of performance, as well as potential sources of performance bottlenecks.",
        "published": "2022-03-17T15:20:56Z",
        "link": "http://arxiv.org/abs/2203.09384v1",
        "categories": [
            "cs.DC",
            "cs.MS",
            "cs.PF"
        ]
    },
    {
        "title": "Training the next generation of computational scientists through a new   undergraduate course",
        "authors": [
            "Tulin Kaman",
            "Rouben Rostamian",
            "Shannon W. Dingman"
        ],
        "summary": "We introduce a newly designed undergraduate-level interdisciplinary course in scientific computing that aims to prepare students as the next generation of research-oriented computational scientists and engineers. The course offers students opportunities to explore a diverse set of projects and develop the necessary programming skills to implement ideas and algorithms within high performance computing environments. The training includes how to think about, formulate, organize, and implement programs in scientific computing. The emphasis of the course is on problem solving within a wide range of applications in science and engineering.",
        "published": "2022-03-17T19:42:52Z",
        "link": "http://arxiv.org/abs/2204.01488v1",
        "categories": [
            "physics.ed-ph",
            "cs.CY",
            "cs.MS",
            "math.HO",
            "97C90",
            "K.3"
        ]
    },
    {
        "title": "sympy2c: from symbolic expressions to fast C/C++ functions and ODE   solvers in Python",
        "authors": [
            "Uwe Schmitt",
            "Beatrice Moser",
            "Christiane S. Lorenz",
            "Alexandre Refregier"
        ],
        "summary": "Computer algebra systems play an important role in science as they facilitate the development of new theoretical models. The resulting symbolic equations are often implemented in a compiled programming language in order to provide fast and portable codes for practical applications. We describe sympy2c, a new Python package designed to bridge the gap between the symbolic development and the numerical implementation of a theoretical model. sympy2c translates symbolic equations implemented in the SymPy Python package to C/C++ code that is optimized using symbolic transformations. The resulting functions can be conveniently used as an extension module in Python. sympy2c is used within the PyCosmo Python package to solve the Einstein-Boltzmann equations, a large system of ODEs describing the evolution of linear perturbations in the Universe. After reviewing the functionalities and usage of sympy2c, we describe its implementation and optimization strategies. This includes, in particular, a novel approach to generate optimized ODE solvers making use of the sparsity of the symbolic Jacobian matrix. We demonstrate its performance using the Einstein-Boltzmann equations as a test case. sympy2c is widely applicable and may prove useful for various areas of computational physics. sympy2c is publicly available at https://cosmology.ethz.ch/research/software-lab/sympy2c.html",
        "published": "2022-03-22T15:51:55Z",
        "link": "http://arxiv.org/abs/2203.11945v1",
        "categories": [
            "astro-ph.IM",
            "astro-ph.CO",
            "cs.MS",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Preconditioned Least-Squares Petrov-Galerkin Reduced Order Models",
        "authors": [
            "Payton Lindsay",
            "Jeffrey Fike",
            "Irina Tezaur",
            "Kevin Carlberg"
        ],
        "summary": "This paper introduces a methodology for improving the accuracy and efficiency of reduced order models (ROMs) constructed using the least-squares Petrov-Galerkin (LSPG) projection method through the introduction of preconditioning. Unlike prior related work, which focuses on preconditioning the linear systems arising within the ROM numerical solution procedure to improve linear solver performance, our approach leverages a preconditioning matrix directly within the LSPG minimization problem. Applying preconditioning in this way can improve ROM accuracy for several reasons. First, preconditioning the LSPG formulation changes the norm defining the residual minimization, which can improve the residual-based stability constant bounding the ROM solution's error. The incorporation of a preconditioner into the LSPG formulation can have the additional effect of scaling the components of the residual being minimized, which can be beneficial for problems with disparate scales. Importantly, we demonstrate that an 'ideal preconditioned' LSPG ROM (a ROM preconditioned with the inverse of the Jacobian of its corresponding full order model, or FOM) emulates projection of the FOM solution increment onto the reduced basis, a lower bound on the ROM solution error for a given reduced basis. By designing preconditioners that approximate the Jacobian inverse, a ROM whose error approaches this lower bound can be obtained. The proposed approach is evaluated in the predictive regime on several mechanical and thermo-mechanical problems within the Albany HPC code. We demonstrate numerically that the introduction of simple Jacobi, Gauss-Seidel and ILU preconditioners into the Proper Orthogonal Decomposition/LSPG formulation reduces significantly the ROM solution error, the reduced Jacobian condition number, the number of nonlinear iterations required to reach convergence, and the wall time.",
        "published": "2022-03-23T03:48:01Z",
        "link": "http://arxiv.org/abs/2203.12180v1",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "Efficient distributed matrix-free multigrid methods on locally refined   meshes for FEM computations",
        "authors": [
            "Peter Munch",
            "Timo Heister",
            "Laura Prieto Saavedra",
            "Martin Kronbichler"
        ],
        "summary": "This work studies three multigrid variants for matrix-free finite-element computations on locally refined meshes: geometric local smoothing, geometric global coarsening, and polynomial global coarsening. We have integrated the algorithms into the same framework-the open-source finite-element library deal.II-, which allows us to make fair comparisons regarding their implementation complexity, computational efficiency, and parallel scalability as well as to compare the measurements with theoretically derived performance models. Serial simulations and parallel weak and strong scaling on up to 147,456 CPU cores on 3,072 compute nodes are presented. The results obtained indicate that global coarsening algorithms show a better parallel behavior for comparable smoothers due to the better load balance particularly on the expensive fine levels. In the serial case, the costs of applying hanging-node constraints might be significant, leading to advantages of local smoothing, even though the number of solver iterations needed is slightly higher.",
        "published": "2022-03-23T09:31:59Z",
        "link": "http://arxiv.org/abs/2203.12292v2",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "G.4"
        ]
    },
    {
        "title": "DPar2: Fast and Scalable PARAFAC2 Decomposition for Irregular Dense   Tensors",
        "authors": [
            "Jun-Gi Jang",
            "U Kang"
        ],
        "summary": "Given an irregular dense tensor, how can we efficiently analyze it? An irregular tensor is a collection of matrices whose columns have the same size and rows have different sizes from each other. PARAFAC2 decomposition is a fundamental tool to deal with an irregular tensor in applications including phenotype discovery and trend analysis. Although several PARAFAC2 decomposition methods exist, their efficiency is limited for irregular dense tensors due to the expensive computations involved with the tensor. In this paper, we propose DPar2, a fast and scalable PARAFAC2 decomposition method for irregular dense tensors. DPar2 achieves high efficiency by effectively compressing each slice matrix of a given irregular tensor, careful reordering of computations with the compression results, and exploiting the irregularity of the tensor. Extensive experiments show that DPar2 is up to 6.0x faster than competitors on real-world irregular tensors while achieving comparable accuracy. In addition, DPar2 is scalable with respect to the tensor size and target rank.",
        "published": "2022-03-24T01:43:13Z",
        "link": "http://arxiv.org/abs/2203.12798v2",
        "categories": [
            "cs.LG",
            "cs.DB",
            "cs.MS"
        ]
    },
    {
        "title": "Accelerating innovation with software abstractions for scalable   computational geophysics",
        "authors": [
            "Mathias Louboutin",
            "Philipp A. Witte",
            "Ali Siahkoohi",
            "Gabrio Rizzuti",
            "Ziyi Yin",
            "Rafael Orozco",
            "Felix J. Herrmann"
        ],
        "summary": "We present the SLIM (https://github.com/slimgroup) open-source software framework for computational geophysics, and more generally, inverse problems based on the wave-equation (e.g., medical ultrasound). We developed a software environment aimed at scalable research and development by designing multiple layers of abstractions. This environment allows the researchers to easily formulate their problem in an abstract fashion, while still being able to exploit the latest developments in high-performance computing. We illustrate and demonstrate the benefits of our software design on many geophysical applications, including seismic inversion and physics-informed machine learning for geophysics (e.g., loop unrolled imaging, uncertainty quantification), all while facilitating the integration of external software.",
        "published": "2022-03-28T19:04:33Z",
        "link": "http://arxiv.org/abs/2203.15038v1",
        "categories": [
            "physics.comp-ph",
            "cs.MS",
            "physics.geo-ph"
        ]
    },
    {
        "title": "Performance Portable Solid Mechanics via Matrix-Free $p$-Multigrid",
        "authors": [
            "Jed Brown",
            "Valeria Barra",
            "Natalie Beams",
            "Leila Ghaffari",
            "Matthew Knepley",
            "William Moses",
            "Rezgar Shakeri",
            "Karen Stengel",
            "Jeremy L. Thompson",
            "Junchao Zhang"
        ],
        "summary": "Finite element analysis of solid mechanics is a foundational tool of modern engineering, with low-order finite element methods and assembled sparse matrices representing the industry standard for implicit analysis. We use performance models and numerical experiments to demonstrate that high-order methods greatly reduce the costs to reach engineering tolerances while enabling effective use of GPUs; these data structures also offer up to 2x benefit for linear elements. We demonstrate the reliability, efficiency, and scalability of matrix-free $p$-multigrid methods with algebraic multigrid coarse solvers through large deformation hyperelastic simulations of multiscale structures. We investigate accuracy, cost, and execution time on multi-node CPU and GPU systems for moderate to large models (millions to billions of degrees of freedom) using AMD MI250X (OLCF Crusher), NVIDIA A100 (NERSC Perlmutter), and V100 (LLNL Lassen and OLCF Summit), resulting in order of magnitude efficiency improvements over a broad range of model properties and scales. We discuss efficient matrix-free representation of Jacobians and demonstrate how automatic differentiation enables rapid development of nonlinear material models without impacting debuggability and workflows targeting GPUs. The methods are broadly applicable and amenable to common workflows, presented here via open source libraries that encapsulate all GPU-specific aspects and are accessible to both new and legacy code, allowing application code to be GPU-oblivious without compromising end-to-end performance on GPUs.",
        "published": "2022-04-04T04:41:24Z",
        "link": "http://arxiv.org/abs/2204.01722v3",
        "categories": [
            "cs.MS",
            "cs.CE",
            "cs.DC",
            "cs.NA",
            "math.NA",
            "G.1.8; G.1.5; G.1.10; G.4; J.2; J.6; D.1.3"
        ]
    },
    {
        "title": "mVEM: A MATLAB Software Package for the Virtual Element Methods",
        "authors": [
            "Yue Yu"
        ],
        "summary": "This paper summarizes the development of mVEM, a MATLAB software package containing efficient and easy-following codes for various virtual element methods (VEMs) published in the literature. We explain in detail the numerical implementation of the mixed VEMs for the Darcy problem and the three-dimensional linear VEMs for the Poisson equation. For other model problems, we present the construction of the discrete methods and only provide the implementation of the elliptic projection matrices. Some mesh related functions are also given in the package, including the mesh generation and refinement in two or three dimensions. mVEM is free and open source software.",
        "published": "2022-04-04T09:22:42Z",
        "link": "http://arxiv.org/abs/2204.01339v1",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "GPSAF: A Generalized Probabilistic Surrogate-Assisted Framework for   Constrained Single- and Multi-objective Optimization",
        "authors": [
            "Julian Blank",
            "Kalyanmoy Deb"
        ],
        "summary": "Significant effort has been made to solve computationally expensive optimization problems in the past two decades, and various optimization methods incorporating surrogates into optimization have been proposed. Most research focuses on either exploiting the surrogate by defining a utility optimization problem or customizing an existing optimization method to use one or multiple approximation models. However, only a little attention has been paid to generic concepts applicable to different types of algorithms and optimization problems simultaneously. Thus this paper proposes a generalized probabilistic surrogate-assisted framework (GPSAF), applicable to a broad category of unconstrained and constrained, single- and multi-objective optimization algorithms. The idea is based on a surrogate assisting an existing optimization method. The assistance is based on two distinct phases, one facilitating exploration and another exploiting the surrogates. The exploration and exploitation of surrogates are automatically balanced by performing a probabilistic knockout tournament among different clusters of solutions. A study of multiple well-known population-based optimization algorithms is conducted with and without the proposed surrogate assistance on single- and multi-objective optimization problems with a maximum solution evaluation budget of 300 or less. The results indicate the effectiveness of applying GPSAF to an optimization algorithm and the competitiveness with other surrogate-assisted algorithms.",
        "published": "2022-04-06T13:22:30Z",
        "link": "http://arxiv.org/abs/2204.04054v1",
        "categories": [
            "math.OC",
            "cs.LG",
            "cs.MS",
            "68U07",
            "G.1.6; G.1.2; I.6.3"
        ]
    },
    {
        "title": "Massively scalable stencil algorithm",
        "authors": [
            "Mathias Jacquelin",
            "Mauricio Araya-Polo",
            "Jie Meng"
        ],
        "summary": "Stencil computations lie at the heart of many scientific and industrial applications. Unfortunately, stencil algorithms perform poorly on machines with cache based memory hierarchy, due to low re-use of memory accesses. This work shows that for stencil computation a novel algorithm that leverages a localized communication strategy effectively exploits the Cerebras WSE-2, which has no cache hierarchy. This study focuses on a 25-point stencil finite-difference method for the 3D wave equation, a kernel frequently used in earth modeling as numerical simulation. In essence, the algorithm trades memory accesses for data communication and takes advantage of the fast communication fabric provided by the architecture. The algorithm -- historically memory bound -- becomes compute bound. This allows the implementation to achieve near perfect weak scaling, reaching up to 503 TFLOPs on WSE-2, a figure that only full clusters can eventually yield.",
        "published": "2022-04-07T23:27:51Z",
        "link": "http://arxiv.org/abs/2204.03775v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "Performance Evaluation and Acceleration of the QTensor Quantum Circuit   Simulator on GPUs",
        "authors": [
            "Danylo Lykov",
            "Angela Chen",
            "Huaxuan Chen",
            "Kristopher Keipert",
            "Zheng Zhang",
            "Tom Gibbs",
            "Yuri Alexeev"
        ],
        "summary": "This work studies the porting and optimization of the tensor network simulator QTensor on GPUs, with the ultimate goal of simulating quantum circuits efficiently at scale on large GPU supercomputers. We implement NumPy, PyTorch, and CuPy backends and benchmark the codes to find the optimal allocation of tensor simulations to either a CPU or a GPU. We also present a dynamic mixed backend to achieve optimal performance. To demonstrate the performance, we simulate QAOA circuits for computing the MaxCut energy expectation. Our method achieves $176\\times$ speedup on a GPU over the NumPy baseline on a CPU for the benchmarked QAOA circuits to solve MaxCut problem on a 3-regular graph of size 30 with depth $p=4$.",
        "published": "2022-04-12T19:03:44Z",
        "link": "http://arxiv.org/abs/2204.06045v1",
        "categories": [
            "quant-ph",
            "cs.MS"
        ]
    },
    {
        "title": "Acacia-Bonsai: A Modern Implementation of Downset-Based LTL   Realizability",
        "authors": [
            "Michaël Cadilhac",
            "Guillermo A. Pérez"
        ],
        "summary": "We describe our implementation of downset-manipulating algorithms used to solve the realizability problem for linear temporal logic (LTL). These algorithms were introduced by Filiot et al.~in the 2010s and implemented in the tools Acacia and Acacia+ in C and Python. We identify degrees of freedom in the original algorithms and provide a complete rewriting of Acacia in C++20 articulated around genericity and leveraging modern techniques for better performances. These techniques include compile-time specialization of the algorithms, the use of SIMD registers to store vectors, and several preprocessing steps, some relying on efficient Binary Decision Diagram (BDD) libraries. We also explore different data structures to store downsets. The resulting tool is competitive against comparable modern tools.",
        "published": "2022-04-12T20:46:52Z",
        "link": "http://arxiv.org/abs/2204.06079v1",
        "categories": [
            "cs.LO",
            "cs.MS"
        ]
    },
    {
        "title": "Iterative PDE-constrained optimization for seismic full-waveform   inversion",
        "authors": [
            "M. Malovichko",
            "A. Orazbayev",
            "N. Khokhlov"
        ],
        "summary": "This paper presents a novel numerical method for the Newton seismic full-waveform inversion (FWI). The method is based on the full-space approach, where the state, adjoint state, and control variables are optimized simultaneously. Each Newton step is formulated as a PDE-constrained optimization problem, which is cast in the form of the Karush-Kuhn-Tucker (KKT) system of linear algebraic equitations. The KKT system is solved inexactly with a preconditioned Krylov solver. We introduced two preconditioners: the one based on the block-triangular factorization and its variant with an inexact block solver. The method was benchmarked against the standard truncated Newton FWI scheme on a part of the Marmousi velocity model. The algorithm demonstrated a considerable runtime reduction compared to the standard FWI. Moreover, the presented approach has a great potential for further acceleration. The central result of this paper is that it establishes the feasibility of Newton-type optimization of the KKT system in application to the seismic FWI.",
        "published": "2022-04-13T16:17:28Z",
        "link": "http://arxiv.org/abs/2204.06489v1",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "physics.geo-ph"
        ]
    },
    {
        "title": "auton-survival: an Open-Source Package for Regression, Counterfactual   Estimation, Evaluation and Phenotyping with Censored Time-to-Event Data",
        "authors": [
            "Chirag Nagpal",
            "Willa Potosnak",
            "Artur Dubrawski"
        ],
        "summary": "Applications of machine learning in healthcare often require working with time-to-event prediction tasks including prognostication of an adverse event, re-hospitalization or death. Such outcomes are typically subject to censoring due to loss of follow up. Standard machine learning methods cannot be applied in a straightforward manner to datasets with censored outcomes. In this paper, we present auton-survival, an open-source repository of tools to streamline working with censored time-to-event or survival data. auton-survival includes tools for survival regression, adjustment in the presence of domain shift, counterfactual estimation, phenotyping for risk stratification, evaluation, as well as estimation of treatment effects. Through real world case studies employing a large subset of the SEER oncology incidence data, we demonstrate the ability of auton-survival to rapidly support data scientists in answering complex health and epidemiological questions.",
        "published": "2022-04-15T00:24:56Z",
        "link": "http://arxiv.org/abs/2204.07276v4",
        "categories": [
            "cs.LG",
            "cs.MS",
            "stat.ML"
        ]
    },
    {
        "title": "ParticLS: Object-oriented software for discrete element methods and   peridynamics",
        "authors": [
            "Andrew D. Davis",
            "Brendan A. West",
            "Nathanael J. Frisch",
            "Devin T. O'Connor",
            "Matthew D. Parno"
        ],
        "summary": "ParticLS (\\emph{Partic}le \\emph{L}evel \\emph{S}ets) is a software library that implements the discrete element method (DEM) and meshfree methods. ParticLS tracks the interaction between individual particles whose geometries are defined by level sets capable of capturing complex shapes. These particles either represent rigid bodies or material points within a continuum. Particle-particle interactions using various contact laws numerically approximate solutions to energy and mass conservation equations, simulating rigid body dynamics or deformation/fracture. By leveraging multiple contact laws, ParticLS can simulate interacting bodies that deform, fracture, and are composed of many particles. In the continuum setting, we numerically solve the peridynamic equations -- integro-differential equations capable of modeling objects with discontinuous displacement fields and complex fracture dynamics. We show that the discretized peridynamic equations can be solved using the same software infrastructure that implements the DEM. Therefore, we design a unique software library where users can easily add particles with arbitrary geometries and new contact laws that model either rigid-body interaction or peridynamic constitutive relationships. We demonstrate ParticLS' versatility on test problems meant to showcase features applicable to a broad selection of fields such as tectonics, granular media, multiscale simulations, glacier calving, and sea ice.",
        "published": "2022-04-19T17:42:33Z",
        "link": "http://arxiv.org/abs/2204.10855v1",
        "categories": [
            "cs.MS",
            "cs.CE"
        ]
    },
    {
        "title": "Automated Generation of High-Performance Computational Fluid Dynamics   Codes",
        "authors": [
            "Sandra Macià",
            "Pedro J. Martıínez-Ferrer",
            "Eduard Ayguadé",
            "Vicenç Beltran"
        ],
        "summary": "Domain-Specific Languages (DSLs) improve programmers productivity by decoupling problem descriptions from algorithmic implementations. However, DSLs for High-Performance Computing (HPC) have two additional critical requirements: performance and scalability. This paper presents the automated process of generating, from abstract mathematical specifications of Computational Fluid Dynamics (CFD) problems, optimised parallel codes that perform and scale as manually optimised ones. We consciously combine within Saiph, a DSL for solving CFD problems, low-level optimisations and parallelisation strategies, enabling high-performance single-core executions which effectively scale to multi-core and distributed environments. Our results demonstrate how high-level DSLs can offer competitive performance by transparently leveraging state-of-the-art HPC techniques.",
        "published": "2022-04-26T07:26:36Z",
        "link": "http://arxiv.org/abs/2204.12120v2",
        "categories": [
            "cs.MS",
            "cs.CE",
            "cs.DC",
            "D.1.3; J.2"
        ]
    },
    {
        "title": "Evolving Generalizable Multigrid-Based Helmholtz Preconditioners with   Grammar-Guided Genetic Programming",
        "authors": [
            "Jonas Schmitt",
            "Harald Köstler"
        ],
        "summary": "Solving the indefinite Helmholtz equation is not only crucial for the understanding of many physical phenomena but also represents an outstandingly-difficult benchmark problem for the successful application of numerical methods. Here we introduce a new approach for evolving efficient preconditioned iterative solvers for Helmholtz problems with multi-objective grammar-guided genetic programming. Our approach is based on a novel context-free grammar, which enables the construction of multigrid preconditioners that employ a tailored sequence of operations on each discretization level. To find solvers that generalize well over the given domain, we propose a custom method of successive problem difficulty adaption, in which we evaluate a preconditioner's efficiency on increasingly ill-conditioned problem instances. We demonstrate our approach's effectiveness by evolving multigrid-based preconditioners for a two-dimensional indefinite Helmholtz problem that outperform several human-designed methods for different wavenumbers up to systems of linear equations with more than a million unknowns.",
        "published": "2022-04-27T11:13:34Z",
        "link": "http://arxiv.org/abs/2204.12846v2",
        "categories": [
            "math.NA",
            "cs.AI",
            "cs.MS",
            "cs.NA",
            "cs.NE"
        ]
    },
    {
        "title": "Black-Scholes Option Pricing on Intel CPUs and GPUs: Implementation on   SYCL and Optimization Techniques",
        "authors": [
            "Elena Panova",
            "Valentin Volokitin",
            "Anton Gorshkov",
            "Iosif Meyerov"
        ],
        "summary": "The Black-Scholes option pricing problem is one of the widely used financial benchmarks. We explore the possibility of developing a high-performance portable code using the SYCL (Data Parallel C++) programming language. We start from a C++ code parallelized with OpenMP and show optimization techniques that are beneficial on modern Intel Xeon CPUs. Then, we port the code to SYCL and consider important optimization aspects on CPUs and GPUs (device-friendly memory access patterns, relevant data management, employing vector data types). We show that the developed SYCL code is only 10% inferior to the optimized C++ code when running on CPUs while achieving reasonable performance on Intel GPUs. We hope that our experience of developing and optimizing the code on SYCL can be useful to other researchers who plan to port their high-performance C++ codes to SYCL to get all the benefits of single-source programming.",
        "published": "2022-04-28T18:54:47Z",
        "link": "http://arxiv.org/abs/2204.13740v3",
        "categories": [
            "cs.DC",
            "cs.MS",
            "cs.PF"
        ]
    },
    {
        "title": "parGeMSLR: A Parallel Multilevel Schur Complement Low-Rank   Preconditioning and Solution Package for General Sparse Matrices",
        "authors": [
            "Tianshi Xu",
            "Vassilis Kalantzis",
            "Ruipeng Li",
            "Yuanzhe Xi",
            "Geoffrey Dillon",
            "Yousef Saad"
        ],
        "summary": "This paper discusses parGeMSLR, a C++/MPI software library for the solution of sparse systems of linear algebraic equations via preconditioned Krylov subspace methods in distributed-memory computing environments. The preconditioner implemented in parGeMSLR is based on algebraic domain decomposition and partitions the symmetrized adjacency graph recursively into several non-overlapping partitions via a p-way vertex separator, where p is an integer multiple of the total number of MPI processes. From a numerical perspective, parGeMSLR builds a Schur complement approximate inverse preconditioner as the sum between the matrix inverse of the interface coupling matrix and a low-rank correction term. To reduce the cost associated with the computation of the approximate inverse matrices, parGeMSLR exploits a multilevel partitioning of the algebraic domain. The parGeMSLR library is implemented on top of the Message Passing Interface and can solve both real and complex linear systems. Furthermore, parGeMSLR can take advantage of hybrid computing environments with in-node access to one or more Graphics Processing Units. Finally, the parallel efficiency (weak and strong scaling) of parGeMSLR is demonstrated on a few model problems arising from discretizations of 3D Partial Differential Equations.",
        "published": "2022-05-04T19:39:48Z",
        "link": "http://arxiv.org/abs/2205.03224v1",
        "categories": [
            "cs.MS",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "BilevelJuMP.jl: Modeling and Solving Bilevel Optimization in Julia",
        "authors": [
            "Joaquim Dias Garcia",
            "Guilherme Bodin",
            "Alexandre Street"
        ],
        "summary": "In this paper we present BilevelJuMP, a new Julia package to support bilevel optimization within the JuMP framework. The package is a Julia library that enables the user to describe both upper and lower-level optimization problems using the JuMP algebraic syntax. Due to the generality and flexibility our library inherits from JuMP's syntax, our package allows users to model bilevel optimization problems with conic constraints in the lower level and all JuMP supported constraints in the upper level (Conic, Quadratic, Non-Linear, Integer, etc.). Moreover, the user-defined problem can be subsequently solved by various techniques relying on mathematical program with equilibrium constraints (MPEC) reformulations. Manipulations on the original problem data are possible due to MathOptInterface.jl's structures and Dualization.jl features. Hence, the proposed package allows quickly model, deploy, and thereby experiment bilevel models based on off-the-shelf mixed integer linear programming and nonlinear solvers.",
        "published": "2022-05-04T20:00:51Z",
        "link": "http://arxiv.org/abs/2205.02307v3",
        "categories": [
            "math.OC",
            "cs.MS"
        ]
    },
    {
        "title": "ChASE -- A Distributed Hybrid CPU-GPU Eigensolver for Large-scale   Hermitian Eigenvalue Problems",
        "authors": [
            "Xinzhe Wu",
            "Davor Davidovic",
            "Sebastian Achilles",
            "Edoardo Di Napoli"
        ],
        "summary": "As modern massively parallel clusters are getting larger with beefier compute nodes, traditional parallel eigensolvers, such as direct solvers, struggle keeping the pace with the hardware evolution and being able to scale efficiently due to additional layers of communication and synchronization. This difficulty is especially important when porting traditional libraries to heterogeneous computing architectures equipped with accelerators, such as Graphics Processing Unit (GPU). Recently, there have been significant scientific contributions to the development of filter-based subspace eigensolver to compute partial eigenspectrum. The simpler structure of these type of algorithms makes for them easier to avoid the communication and synchronization bottlenecks typical of direct solvers. The Chebyshev Accelerated Subspace Eigensolver (ChASE) is a modern subspace eigensolver to compute partial extremal eigenpairs of large-scale Hermitian eigenproblems with the acceleration of a filter based on Chebyshev polynomials. In this work, we extend our previous work on ChASE by adding support for distributed hybrid CPU-multi-GPU computing architectures. Our tests show that ChASE achieves very good scaling performance up to 144 nodes with 526 NVIDIA A100 GPUs in total on dense eigenproblems of size up to $360$k.",
        "published": "2022-05-05T08:01:25Z",
        "link": "http://arxiv.org/abs/2205.02491v1",
        "categories": [
            "cs.DC",
            "cs.MS",
            "cs.PF"
        ]
    },
    {
        "title": "GOCPT: Generalized Online Canonical Polyadic Tensor Factorization and   Completion",
        "authors": [
            "Chaoqi Yang",
            "Cheng Qian",
            "Jimeng Sun"
        ],
        "summary": "Low-rank tensor factorization or completion is well-studied and applied in various online settings, such as online tensor factorization (where the temporal mode grows) and online tensor completion (where incomplete slices arrive gradually). However, in many real-world settings, tensors may have more complex evolving patterns: (i) one or more modes can grow; (ii) missing entries may be filled; (iii) existing tensor elements can change. Existing methods cannot support such complex scenarios. To fill the gap, this paper proposes a Generalized Online Canonical Polyadic (CP) Tensor factorization and completion framework (named GOCPT) for this general setting, where we maintain the CP structure of such dynamic tensors during the evolution. We show that existing online tensor factorization and completion setups can be unified under the GOCPT framework. Furthermore, we propose a variant, named GOCPTE, to deal with cases where historical tensor elements are unavailable (e.g., privacy protection), which achieves similar fitness as GOCPT but with much less computational cost. Experimental results demonstrate that our GOCPT can improve fitness by up to 2:8% on the JHU Covid data and 9:2% on a proprietary patient claim dataset over baselines. Our variant GOCPTE shows up to 1:2% and 5:5% fitness improvement on two datasets with about 20% speedup compared to the best model.",
        "published": "2022-05-08T01:11:24Z",
        "link": "http://arxiv.org/abs/2205.03749v1",
        "categories": [
            "cs.LG",
            "cs.MS",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Compositional Modeling with Stock and Flow Diagrams",
        "authors": [
            "John Baez",
            "Xiaoyan Li",
            "Sophie Libkind",
            "Nathaniel D. Osgood",
            "Evan Patterson"
        ],
        "summary": "Stock and flow diagrams are widely used in epidemiology to model the dynamics of populations. Although tools already exist for building these diagrams and simulating the systems they describe, we have created a new package called StockFlow, part of the AlgebraicJulia ecosystem, which uses ideas from category theory to overcome notable limitations of existing software. Compositionality is provided by the theory of decorated cospans: stock and flow diagrams can be composed to form larger ones in an intuitive way formalized by the operad of undirected wiring diagrams. Our approach also cleanly separates the syntax of stock and flow diagrams from the semantics they can be assigned. We consider semantics in ordinary differential equations, although others are possible. As an example, we explain code in StockFlow that implements a simplified version of a COVID-19 model used in Canada.",
        "published": "2022-05-09T06:13:12Z",
        "link": "http://arxiv.org/abs/2205.08373v3",
        "categories": [
            "cs.LO",
            "cs.MS",
            "math.CT",
            "q-bio.PE"
        ]
    },
    {
        "title": "MATLAB implementation of hp finite elements on rectangles",
        "authors": [
            "Alexej Moskovka",
            "Jan Valdman"
        ],
        "summary": "A simple MATLAB implementation of hierarchical shape functions on 2D rectangles is explained and available for download. Global shape functions are ordered for a given polynomial degree according to the indices of the nodes, edges, or elements to which they belong. For a uniform p-refinement, the hierarchical structure enables an effective assembly of mass and stiffness matrices. A solution of a boundary value problem is approximated for various levels of uniform h and p refinements.",
        "published": "2022-05-10T15:50:54Z",
        "link": "http://arxiv.org/abs/2205.07637v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "A matrix-free high-order solver for the numerical solution of cardiac   electrophysiology",
        "authors": [
            "Pasquale Claudio Africa",
            "Matteo Salvador",
            "Paola Gervasio",
            "Luca Dede'",
            "Alfio Quarteroni"
        ],
        "summary": "We propose a matrix-free solver for the numerical solution of the cardiac electrophysiology model consisting of the monodomain nonlinear reaction-diffusion equation coupled with a system of ordinary differential equations for the ionic species. Our numerical approximation is based on the high-order Spectral Element Method (SEM) to achieve accurate numerical discretization while employing a much smaller number of Degrees of Freedom than first-order Finite Elements. We combine vectorization with sum-factorization, thus allowing for a very efficient use of high-order polynomials in a high performance computing framework. We validate the effectiveness of our matrix-free solver in a variety of applications and perform different electrophysiological simulations ranging from a simple slab of cardiac tissue to a realistic four-chamber heart geometry. We compare SEM to SEM with Numerical Integration (SEM-NI), showing that they provide comparable results in terms of accuracy and efficiency. In both cases, increasing the local polynomial degree $p$ leads to better numerical results and smaller computational times than reducing the mesh size $h$. We also implement a matrix-free Geometric Multigrid preconditioner that results in a comparable number of linear solver iterations with respect to a state-of-the-art matrix-based Algebraic Multigrid preconditioner. As a matter of fact, the matrix-free solver proposed here yields up to 45$\\times$ speed-up with respect to a conventional matrix-based solver.",
        "published": "2022-05-10T19:36:35Z",
        "link": "http://arxiv.org/abs/2205.05136v3",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "65Y20, 65F50 (Primary) 65M55, 65M60, 65M70, 65Z05 (Secondary)",
            "G.1; G.4; J.3"
        ]
    },
    {
        "title": "KiT-RT: An extendable framework for radiative transfer and therapy",
        "authors": [
            "Jonas Kusch",
            "Steffen Schotthöfer",
            "Pia Stammer",
            "Jannick Wolters",
            "Tianbai Xiao"
        ],
        "summary": "In this paper we present KiT-RT (Kinetic Transport Solver for Radiation Therapy), an open-source C++ based framework for solving kinetic equations in radiation therapy applications. The aim of this code framework is to provide a collection of classical deterministic solvers for unstructured meshes that allow for easy extendability. Therefore, KiT-RT is a convenient base to test new numerical methods in various applications and compare them against conventional solvers. The implementation includes spherical-harmonics, minimal entropy, neural minimal entropy and discrete ordinates methods. Solution characteristics and efficiency are presented through several test cases ranging from radiation transport to electron radiation therapy. Due to the variety of included numerical methods and easy extendability, the presented open source code is attractive for both developers, who want a basis to build their own numerical solvers and users or application engineers, who want to gain experimental insights without directly interfering with the codebase.",
        "published": "2022-05-12T12:30:24Z",
        "link": "http://arxiv.org/abs/2205.08417v1",
        "categories": [
            "physics.med-ph",
            "cs.MS",
            "65M08",
            "G.4; J.2"
        ]
    },
    {
        "title": "Exasim: Generating Discontinuous Galerkin Codes for Numerical Solutions   of Partial Differential Equations on Graphics Processors",
        "authors": [
            "Jordi Vila-Pérez",
            "R. Loek Van Heyningen",
            "Ngoc-Cuong Nguyen",
            "Jaume Peraire"
        ],
        "summary": "This paper presents an overview of the functionalities and applications of Exasim, an open-source code for generating high-order discontinuous Galerkin codes to numerically solve parametrized partial differential equations (PDEs). The software combines high-level and low-level languages to construct parametrized PDE models via Julia, Python or Matlab scripts and produce high-performance C++ codes for solving the PDE models on CPU and Nvidia GPU processors with distributed memory. Exasim provides matrix-free discontinuous Galerkin discretization schemes together with scalable reduced basis preconditioners and Newton-GMRES solvers, making it suitable for accurate and efficient approximation of wide-ranging classes of PDEs.",
        "published": "2022-05-16T17:28:28Z",
        "link": "http://arxiv.org/abs/2205.07824v1",
        "categories": [
            "cs.MS",
            "cs.CE",
            "cs.NA",
            "math.NA",
            "physics.comp-ph",
            "physics.flu-dyn",
            "65M60, 65Y05, 65Y10, 65Z05, 68N99"
        ]
    },
    {
        "title": "Enhancing data locality of the conjugate gradient method for high-order   matrix-free finite-element implementations",
        "authors": [
            "Martin Kronbichler",
            "Dmytro Sashko",
            "Peter Munch"
        ],
        "summary": "This work investigates a variant of the conjugate gradient (CG) method and embeds it into the context of high-order finite-element schemes with fast matrix-free operator evaluation and cheap preconditioners like the matrix diagonal. Relying on a data-dependency analysis and appropriate enumeration of degrees of freedom, we interleave the vector updates and inner products in a CG iteration with the matrix-vector product with only minor organizational overhead. As a result, around 90% of the vector entries of the three active vectors of the CG method are transferred from slow RAM memory exactly once per iteration, with all additional access hitting fast cache memory. Node-level performance analyses and scaling studies on up to 147k cores show that the CG method with the proposed performance optimizations is around two times faster than a standard CG solver as well as optimized pipelined CG and s-step CG methods for large sizes that exceed processor caches, and provides similar performance near the strong scaling limit.",
        "published": "2022-05-18T13:04:00Z",
        "link": "http://arxiv.org/abs/2205.08909v1",
        "categories": [
            "cs.MS",
            "cs.NA",
            "math.NA",
            "G.4"
        ]
    },
    {
        "title": "pISTA: preconditioned Iterative Soft Thresholding Algorithm for   Graphical Lasso",
        "authors": [
            "Gal Shalom",
            "Eran Treister",
            "Irad Yavneh"
        ],
        "summary": "We propose a novel quasi-Newton method for solving the sparse inverse covariance estimation problem also known as the graphical least absolute shrinkage and selection operator (GLASSO). This problem is often solved using a second-order quadratic approximation. However, in such algorithms the Hessian term is complex and computationally expensive to handle. Therefore, our method uses the inverse of the Hessian as a preconditioner to simplify and approximate the quadratic element at the cost of a more complex \\(\\ell_1\\) element. The variables of the resulting preconditioned problem are coupled only by the \\(\\ell_1\\) sub-derivative of each other, which can be guessed with minimal cost using the gradient itself, allowing the algorithm to be parallelized and implemented efficiently on GPU hardware accelerators. Numerical results on synthetic and real data demonstrate that our method is competitive with other state-of-the-art approaches.",
        "published": "2022-05-20T08:48:26Z",
        "link": "http://arxiv.org/abs/2205.10027v2",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "Residual regularization path-following methods for linear   complementarity problems",
        "authors": [
            "Xin-long Luo",
            "Sen Zhang",
            "Hang Xiao"
        ],
        "summary": "In this article, we consider the residual regularization path-following method with the trust-region updating strategy for the linear complementarity problem. This time-stepping selection based on the trust-region updating strategy overcomes the shortcoming of the line search method, which consumes the unnecessary trial steps in the transient-state phase. In order to improve the robustness of the path-following method, we use the residual regularization parameter to replace the traditional complementarity regularization parameter. Moreover, we prove the global convergence of the new method under the standard assumptions without the traditional assumption condition of the priority to feasibility over complementarity. Numerical results show that the new method is robust and efficient for the linear complementarity problem, especially for the dense cases. And it is more robust and faster than some state-of-the-art solvers such as the built-in subroutines PATH and MILES of the GAMS v28.2 (2019) environment. The computational time of the new method is about 1/3 to 1/10 of that of PATH for the dense linear complementarity problem.",
        "published": "2022-05-22T03:47:30Z",
        "link": "http://arxiv.org/abs/2205.10727v2",
        "categories": [
            "math.OC",
            "cs.CE",
            "cs.MS",
            "cs.NA",
            "math.DS",
            "math.NA"
        ]
    },
    {
        "title": "Accelerating High-Order Mesh Optimization Using Finite Element Partial   Assembly on GPUs",
        "authors": [
            "Jean-Sylvain Camier",
            "Veselin Dobrev",
            "Patrick Knupp",
            "Tzanio Kolev",
            "Ketan Mittal",
            "Robert Rieben",
            "Vladimir Tomov"
        ],
        "summary": "In this paper we present a new GPU-oriented mesh optimization method based on high-order finite elements. Our approach relies on node movement with fixed topology, through the Target-Matrix Optimization Paradigm (TMOP) and uses a global nonlinear solve over the whole computational mesh, i.e., all mesh nodes are moved together. A key property of the method is that the mesh optimization process is recast in terms of finite element operations, which allows us to utilize recent advances in the field of GPU-accelerated high-order finite element algorithms. For example, we reduce data motion by using tensor factorization and matrix-free methods, which have superior performance characteristics compared to traditional full finite element matrix assembly and offer advantages for GPU-based HPC hardware. We describe the major mathematical components of the method along with their efficient GPU-oriented implementation. In addition, we propose an easily reproducible mesh optimization test that can serve as a performance benchmark for the mesh optimization community.",
        "published": "2022-05-24T00:50:44Z",
        "link": "http://arxiv.org/abs/2205.12721v2",
        "categories": [
            "cs.MS",
            "cs.DC",
            "physics.comp-ph"
        ]
    },
    {
        "title": "VWSIM: A Circuit Simulator",
        "authors": [
            "Warren A. Hunt Jr.",
            "Vivek Ramanathan",
            "J Strother Moore"
        ],
        "summary": "VWSIM is a circuit simulator for rapid, single-flux, quantum (RSFQ) circuits. The simulator is designed to model and simulate primitive-circuit devices such as capacitors, inductors, Josephson Junctions, and can be extended to simulate other circuit families, such as CMOS. Circuit models can be provided in the native VWSIM netlist format or as SPICE-compatible netlists, which are flattened and transformed into symbolic equations that can be manipulated and simulated. Written in the ACL2 logic, VWSIM provides logical guarantees about each of the circuit models it simulates. Note, our matrix solving and evaluation routines use Common Lisp floating-point numbers, and work is ongoing to admit these models into ACL2. We currently use VWSIM to help us design self-timed, RSFQ-based circuits. Our eventual goal is to prove properties of RSFQ circuit models. The ACL2-based definition of the VWSIM simulator offers a path for specifying and verifying RSFQ circuit models.",
        "published": "2022-05-24T01:16:21Z",
        "link": "http://arxiv.org/abs/2205.11698v1",
        "categories": [
            "cs.LO",
            "cs.MS",
            "cs.SC",
            "B.1.2; B.7.2; D.1.1; D.2.4; F.3.1; F.4.1; G.1.3; I.1.3; I.2.3;\n  I.6.4; J.2"
        ]
    },
    {
        "title": "ARKODE: a flexible IVP solver infrastructure for one-step methods",
        "authors": [
            "Daniel R. Reynolds",
            "David J. Gardner",
            "Carol S. Woodward",
            "Rujeko Chinomona"
        ],
        "summary": "We describe the ARKODE library of one-step time integration methods for ordinary differential equation (ODE) initial-value problems (IVPs). In addition to providing standard explicit and diagonally implicit Runge--Kutta methods, ARKODE also supports one-step methods designed to treat additive splittings of the IVP, including implicit-explicit (ImEx) additive Runge--Kutta methods and multirate infinitesimal (MRI) methods. We present the role of ARKODE within the SUNDIALS suite of time integration and nonlinear solver libraries, the core ARKODE infrastructure for utilities common to large classes of one-step methods, as well as its use of ``time stepper'' modules enabling easy incorporation of novel algorithms into the library. Numerical results show example problems of increasing complexity, highlighting the algorithmic flexibility afforded through this infrastructure, and include a larger multiphysics application leveraging multiple algorithmic features from ARKODE and SUNDIALS.",
        "published": "2022-05-27T16:16:19Z",
        "link": "http://arxiv.org/abs/2205.14077v2",
        "categories": [
            "cs.MS",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "bsnsing: A decision tree induction method based on recursive optimal   boolean rule composition",
        "authors": [
            "Yanchao Liu"
        ],
        "summary": "This paper proposes a new mixed-integer programming (MIP) formulation to optimize split rule selection in the decision tree induction process, and develops an efficient search algorithm that is able to solve practical instances of the MIP model faster than commercial solvers. The formulation is novel for it directly maximizes the Gini reduction, an effective split selection criterion which has never been modeled in a mathematical program for its nonconvexity. The proposed approach differs from other optimal classification tree models in that it does not attempt to optimize the whole tree, therefore the flexibility of the recursive partitioning scheme is retained and the optimization model is more amenable. The approach is implemented in an open-source R package named bsnsing. Benchmarking experiments on 75 open data sets suggest that bsnsing trees are the most capable of discriminating new cases compared to trees trained by other decision tree codes including the rpart, C50, party and tree packages in R. Compared to other optimal decision tree packages, including DL8.5, OSDT, GOSDT and indirectly more, bsnsing stands out in its training speed, ease of use and broader applicability without losing in prediction accuracy.",
        "published": "2022-05-30T17:13:57Z",
        "link": "http://arxiv.org/abs/2205.15263v1",
        "categories": [
            "cs.LG",
            "cs.MS",
            "stat.ML"
        ]
    },
    {
        "title": "Holistic Generalized Linear Models",
        "authors": [
            "Benjamin Schwendinger",
            "Florian Schwendinger",
            "Laura Vana"
        ],
        "summary": "Holistic linear regression extends the classical best subset selection problem by adding additional constraints designed to improve the model quality. These constraints include sparsity-inducing constraints, sign-coherence constraints and linear constraints. The $\\textsf{R}$ package $\\texttt{holiglm}$ provides functionality to model and fit holistic generalized linear models. By making use of state-of-the-art conic mixed-integer solvers, the package can reliably solve GLMs for Gaussian, binomial and Poisson responses with a multitude of holistic constraints. The high-level interface simplifies the constraint specification and can be used as a drop-in replacement for the $\\texttt{stats::glm()}$ function.",
        "published": "2022-05-30T22:08:47Z",
        "link": "http://arxiv.org/abs/2205.15447v1",
        "categories": [
            "stat.ML",
            "cs.LG",
            "cs.MS",
            "math.OC"
        ]
    },
    {
        "title": "A novel statistical approach for two-sample testing based on the overlap   coefficient",
        "authors": [
            "Atsushi Komaba",
            "Hisashi Johno",
            "Kazunori Nakamoto"
        ],
        "summary": "Here we propose a new nonparametric framework for two-sample testing, named as the OVL-$q$ ($q = 1, 2, \\ldots$). This can be regarded as a natural extension of the Smirnov test, which is equivalent to the OVL-1. We specifically focus on the OVL-2, implement its fast algorithm, and show its superiority over other statistical tests in some experiments.",
        "published": "2022-06-07T10:27:23Z",
        "link": "http://arxiv.org/abs/2206.03166v2",
        "categories": [
            "math.ST",
            "cs.DM",
            "cs.MS",
            "math.PR",
            "stat.ME",
            "stat.TH",
            "62G10 (Primary), 62-04 (Secondary)"
        ]
    },
    {
        "title": "Thick-restarted joint Lanczos bidiagonalization for the GSVD",
        "authors": [
            "Fernando Alvarruiz",
            "Carmen Campos",
            "Jose E. Roman"
        ],
        "summary": "The computation of the partial generalized singular value decomposition (GSVD) of large-scale matrix pairs can be approached by means of iterative methods based on expanding subspaces, particularly Krylov subspaces. We consider the joint Lanczos bidiagonalization method, and analyze the feasibility of adapting the thick restart technique that is being used successfully in the context of other linear algebra problems. Numerical experiments illustrate the effectiveness of the proposed method. We also compare the new method with an alternative solution via equivalent eigenvalue problems, considering accuracy as well as computational performance. The analysis is done using a parallel implementation in the SLEPc library.",
        "published": "2022-06-08T09:31:06Z",
        "link": "http://arxiv.org/abs/2206.03768v3",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "Flexible Differentiable Optimization via Model Transformations",
        "authors": [
            "Mathieu Besançon",
            "Joaquim Dias Garcia",
            "Benoît Legat",
            "Akshay Sharma"
        ],
        "summary": "We introduce DiffOpt.jl, a Julia library to differentiate through the solution of optimization problems with respect to arbitrary parameters present in the objective and/or constraints. The library builds upon MathOptInterface, thus leveraging the rich ecosystem of solvers and composing well with modeling languages like JuMP. DiffOpt offers both forward and reverse differentiation modes, enabling multiple use cases from hyperparameter optimization to backpropagation and sensitivity analysis, bridging constrained optimization with end-to-end differentiable programming. DiffOpt is built on two known rules for differentiating quadratic programming and conic programming standard forms. However, thanks ability to differentiate through model transformation, the user is not limited to these forms and can differentiate with respect to the parameters of any model that can be reformulated into these standard forms. This notably includes programs mixing affine conic constraints and convex quadratic constraints or objective function.",
        "published": "2022-06-10T09:59:13Z",
        "link": "http://arxiv.org/abs/2206.06135v3",
        "categories": [
            "cs.LG",
            "cs.MS",
            "math.OC"
        ]
    },
    {
        "title": "GPU-parallelisation of wavelet-based grid adaptation for fast finite   volume modelling: application to shallow water flows",
        "authors": [
            "Alovya Ahmed Chowdhury",
            "Georges Kesserwani",
            "Charles Rougé",
            "Paul Richmond"
        ],
        "summary": "Wavelet-based grid adaptation driven by the \"multiresolution analysis\" (MRA) of the Haar wavelet (HW) allows to devise an adaptive first-order finite volume (FV1) model (HWFV1) that can readily preserve the modelling fidelity of its reference uniform-grid FV1 counterpart. However, the MRA incurs a high computational cost as it involves \"encoding\" (coarsening), \"decoding\" (refining), analysing and traversing modelled data across a deep hierarchy of nested, uniform grids. GPU-parallelisation of the MRA is needed to reduce its computational cost, but its algorithmic structure (1) hinders coalesced memory access on the GPU, and (2) involves an inherently sequential tree traversal problem. This work redesigns the algorithmic structure of the MRA in order to parallelise it on the GPU, addressing (1) by applying Z-order space-filling curves and addressing (2) by adopting a parallel tree traversal algorithm. This results in a GPU-parallelised HWFV1 model (GPU-HWFV1). GPU-HWFV1 is verified against its CPU predecessor (CPU-HWFV1) and its GPU-parallelised reference uniform-grid counterpart (GPU-FV1) over five shallow water flow test cases. GPU-HWFV1 preserves the modelling fidelity of GPU-FV1 while being up to 30 times faster. Compared to CPU-HWFV1, it is up to 200 times faster, suggesting the GPU-parallelised MRA could be used to speed up other FV1 models.",
        "published": "2022-06-12T15:07:38Z",
        "link": "http://arxiv.org/abs/2206.05761v3",
        "categories": [
            "cs.CE",
            "cs.MS"
        ]
    },
    {
        "title": "Algorithms for Parallel Generic $hp$-adaptive Finite Element Software",
        "authors": [
            "Marc Fehling",
            "Wolfgang Bangerth"
        ],
        "summary": "The $hp$-adaptive finite element method (FEM) - where one independently chooses the mesh size ($h$) and polynomial degree ($p$) to be used on each cell - has long been known to have better theoretical convergence properties than either $h$- or $p$-adaptive methods alone. However, it is not widely used, owing at least in parts to the difficulty of the underlying algorithms and the lack of widely usable implementations. This is particularly true when used with continuous finite elements.   Herein, we discuss algorithms that are necessary for a comprehensive and generic implementation of $hp$-adaptive finite element methods on distributed-memory, parallel machines. In particular, we will present a multi-stage algorithm for the unique enumeration of degrees of freedom (DoFs) suitable for continuous finite element spaces, describe considerations for weighted load balancing, and discuss the transfer of variable size data between processes. We illustrate the performance of our algorithms with numerical examples, and demonstrate that they scale reasonably up to at least 16,384 Message Passing Interface (MPI) processes.   We provide a reference implementation of our algorithms as part of the open-source library deal.II.",
        "published": "2022-06-13T22:46:14Z",
        "link": "http://arxiv.org/abs/2206.06512v2",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "G.1.8; G.4"
        ]
    },
    {
        "title": "Accelerating CPU-Based Sparse General Matrix Multiplication With Binary   Row Merging",
        "authors": [
            "Zhaoyang Du",
            "Yijin Guan",
            "Tianchan Guan",
            "Dimin Niu",
            "Hongzhong Zheng",
            "Yuan Xie"
        ],
        "summary": "Sparse general matrix multiplication (SpGEMM) is a fundamental building block for many real-world applications. Since SpGEMM is a well-known memory-bounded application with vast and irregular memory accesses, considering the memory access efficiency is of critical importance for SpGEMM's performance. Yet, the existing methods put less consideration into the memory subsystem and achieved suboptimal performance. In this paper, we thoroughly analyze the memory access patterns of SpGEMM and their influences on the memory subsystem. Based on the analysis, we propose a novel and more efficient accumulation method named BRMerge for the multi-core CPU architectures.   The BRMerge accumulation method follows the row-wise dataflow. It first accesses the $B$ matrix, generates the intermediate lists for one output row, and stores these intermediate lists in a consecutive memory space, which is implemented by a ping-pong buffer. It then immediately merges these intermediate lists generated in the previous phase two by two in a tree-like hierarchy between two ping-pong buffers. The architectural benefits of BRMerge are 1) streaming access patterns, 2) minimized TLB cache miss rate, and 3) reasonably high L1/L2 cache hit rates, which result in both low access latency and high bandwidth utilization when performing SpGEMM. Based on the BRMerge accumulation method, we propose two SpGEMM libraries named BRMerge-Upper and BRMerge-Precise, which use different allocation methods. Performance evaluations with 26 commonly used benchmarks on two CPU servers show that the proposed SpGEMM libraries significantly outperform the state-of-the-art SpGEMM libraries.",
        "published": "2022-06-14T06:16:59Z",
        "link": "http://arxiv.org/abs/2206.06611v2",
        "categories": [
            "cs.DC",
            "cs.MS",
            "cs.PF",
            "68-02, 68W10, 65F50",
            "D.1.3; G.1.3"
        ]
    },
    {
        "title": "qrpca: A Package for Fast Principal Component Analysis with GPU   Acceleration",
        "authors": [
            "Rafael S. de Souza",
            "Xu Quanfeng",
            "Shiyin Shen",
            "Chen Peng",
            "Zihao Mu"
        ],
        "summary": "We present qrpca, a fast and scalable QR-decomposition principal component analysis package. The software, written in both R and python languages, makes use of torch for internal matrix computations, and enables GPU acceleration, when available. qrpca provides similar functionalities to prcomp (R) and sklearn (python) packages respectively. A benchmark test shows that qrpca can achieve computational speeds 10-20 $\\times$ faster for large dimensional matrices than default implementations, and is at least twice as fast for a standard decomposition of spectral data cubes. The qrpca source code is made freely available to the community.",
        "published": "2022-06-14T12:35:24Z",
        "link": "http://arxiv.org/abs/2206.06797v2",
        "categories": [
            "astro-ph.IM",
            "cs.MS"
        ]
    },
    {
        "title": "varFEM: variational formulation based programming for finite element   methods in Matlab",
        "authors": [
            "Yue Yu"
        ],
        "summary": "This paper summarizes the development of varFEM, which provides a realization of the programming style in FreeFEM by using the Matlab language.",
        "published": "2022-06-14T15:25:51Z",
        "link": "http://arxiv.org/abs/2206.06918v1",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "Scalable First-Order Bayesian Optimization via Structured Automatic   Differentiation",
        "authors": [
            "Sebastian Ament",
            "Carla Gomes"
        ],
        "summary": "Bayesian Optimization (BO) has shown great promise for the global optimization of functions that are expensive to evaluate, but despite many successes, standard approaches can struggle in high dimensions. To improve the performance of BO, prior work suggested incorporating gradient information into a Gaussian process surrogate of the objective, giving rise to kernel matrices of size $nd \\times nd$ for $n$ observations in $d$ dimensions. Na\\\"ively multiplying with (resp. inverting) these matrices requires $\\mathcal{O}(n^2d^2)$ (resp. $\\mathcal{O}(n^3d^3$)) operations, which becomes infeasible for moderate dimensions and sample sizes. Here, we observe that a wide range of kernels gives rise to structured matrices, enabling an exact $\\mathcal{O}(n^2d)$ matrix-vector multiply for gradient observations and $\\mathcal{O}(n^2d^2)$ for Hessian observations. Beyond canonical kernel classes, we derive a programmatic approach to leveraging this type of structure for transformations and combinations of the discussed kernel classes, which constitutes a structure-aware automatic differentiation algorithm. Our methods apply to virtually all canonical kernels and automatically extend to complex kernels, like the neural network, radial basis function network, and spectral mixture kernels without any additional derivations, enabling flexible, problem-dependent modeling while scaling first-order BO to high $d$.",
        "published": "2022-06-16T17:59:48Z",
        "link": "http://arxiv.org/abs/2206.08366v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.MS",
            "math.OC",
            "stat.ML"
        ]
    },
    {
        "title": "tntorch: Tensor Network Learning with PyTorch",
        "authors": [
            "Mikhail Usvyatsov",
            "Rafael Ballester-Ripoll",
            "Konrad Schindler"
        ],
        "summary": "We present tntorch, a tensor learning framework that supports multiple decompositions (including Candecomp/Parafac, Tucker, and Tensor Train) under a unified interface. With our library, the user can learn and handle low-rank tensors with automatic differentiation, seamless GPU support, and the convenience of PyTorch's API. Besides decomposition algorithms, tntorch implements differentiable tensor algebra, rank truncation, cross-approximation, batch processing, comprehensive tensor arithmetics, and more.",
        "published": "2022-06-22T14:19:15Z",
        "link": "http://arxiv.org/abs/2206.11128v2",
        "categories": [
            "cs.LG",
            "cs.MS"
        ]
    },
    {
        "title": "Large-Scale Direct Numerical Simulations of Turbulence Using GPUs and   Modern Fortran",
        "authors": [
            "Martin Karp",
            "Daniele Massaro",
            "Niclas Jansson",
            "Alistair Hart",
            "Jacob Wahlgren",
            "Philipp Schlatter",
            "Stefano Markidis"
        ],
        "summary": "We present our approach to making direct numerical simulations of turbulence with applications in sustainable shipping. We use modern Fortran and the spectral element method to leverage and scale on supercomputers powered by the Nvidia A100 and the recent AMD Instinct MI250X GPUs, while still providing support for user software developed in Fortran. We demonstrate the efficiency of our approach by performing the world's first direct numerical simulation of the flow around a Flettner rotor at Re=30'000 and its interaction with a turbulent boundary layer. We present one of the first performance comparisons between the AMD Instinct MI250X and Nvidia A100 GPUs for scalable computational fluid dynamics. Our results show that one MI250X offers performance on par with two A100 GPUs and has a similar power efficiency.",
        "published": "2022-06-23T12:41:19Z",
        "link": "http://arxiv.org/abs/2207.07098v1",
        "categories": [
            "cs.MS",
            "cs.CE",
            "cs.DC",
            "physics.flu-dyn",
            "G.4; J.2"
        ]
    },
    {
        "title": "NumS: Scalable Array Programming for the Cloud",
        "authors": [
            "Melih Elibol",
            "Vinamra Benara",
            "Samyu Yagati",
            "Lianmin Zheng",
            "Alvin Cheung",
            "Michael I. Jordan",
            "Ion Stoica"
        ],
        "summary": "Scientists increasingly rely on Python tools to perform scalable distributed memory array operations using rich, NumPy-like expressions. However, many of these tools rely on dynamic schedulers optimized for abstract task graphs, which often encounter memory and network bandwidth-related bottlenecks due to sub-optimal data and operator placement decisions. Tools built on the message passing interface (MPI), such as ScaLAPACK and SLATE, have better scaling properties, but these solutions require specialized knowledge to use. In this work, we present NumS, an array programming library which optimizes NumPy-like expressions on task-based distributed systems. This is achieved through a novel scheduler called Load Simulated Hierarchical Scheduling (LSHS). LSHS is a local search method which optimizes operator placement by minimizing maximum memory and network load on any given node within a distributed system. Coupled with a heuristic for load balanced data layouts, our approach is capable of attaining communication lower bounds on some common numerical operations, and our empirical study shows that LSHS enhances performance on Ray by decreasing network load by a factor of 2x, requiring 4x less memory, and reducing execution time by 10x on the logistic regression problem. On terabyte-scale data, NumS achieves competitive performance to SLATE on DGEMM, up to 20x speedup over Dask on a key operation for tensor factorization, and a 2x speedup on logistic regression compared to Dask ML and Spark's MLlib.",
        "published": "2022-06-28T20:13:40Z",
        "link": "http://arxiv.org/abs/2206.14276v2",
        "categories": [
            "cs.DC",
            "cs.LG",
            "cs.MS",
            "stat.AP"
        ]
    },
    {
        "title": "hp3D User Manual",
        "authors": [
            "Stefan Henneking",
            "Leszek Demkowicz"
        ],
        "summary": "User Manual for the hp3D Finite Element Software, available on GitHub at https://github.com/Oden-EAG/hp3d",
        "published": "2022-06-29T15:54:16Z",
        "link": "http://arxiv.org/abs/2207.12211v2",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "j-Wave: An open-source differentiable wave simulator",
        "authors": [
            "Antonio Stanziola",
            "Simon R. Arridge",
            "Ben T. Cox",
            "Bradley E. Treeby"
        ],
        "summary": "We present an open-source differentiable acoustic simulator, j-Wave, which can solve time-varying and time-harmonic acoustic problems. It supports automatic differentiation, which is a program transformation technique that has many applications, especially in machine learning and scientific computing. j-Wave is composed of modular components that can be easily customized and reused. At the same time, it is compatible with some of the most popular machine learning libraries, such as JAX and TensorFlow. The accuracy of the simulation results for known configurations is evaluated against the widely used k-Wave toolbox and a cohort of acoustic simulation software. j-Wave is available from https://github.com/ucl-bug/jwave.",
        "published": "2022-06-30T16:19:21Z",
        "link": "http://arxiv.org/abs/2207.01499v1",
        "categories": [
            "physics.comp-ph",
            "cs.LG",
            "cs.MS",
            "cs.SD",
            "eess.AS",
            "physics.med-ph"
        ]
    },
    {
        "title": "Tableless Calculation of Circular Functions on Dyadic Rationals",
        "authors": [
            "Peter Kourzanov"
        ],
        "summary": "I would like to tell a story. A story about a beautiful mathematical relationship that elucidates the computational view on the classic subject of trigonometry. All stories need a language, and for this particular story an algorithmic language ought to do well. What makes a language algorithmic? From our perspective as the functional programming community, an algorithmic language provides means to express computation in terms of functions, with no implementation-imposed limitations. We develop a new algorithm for the computation of trigonometric functions on dyadic rationals, together with the language used to express it, in Scheme. We provide a mechanically-derived algorithm for the computation of the inverses of our target functions. We address efficiency and accuracy concerns that pertain to the implementation of the proposed algorithm either in hardware or software.",
        "published": "2022-07-02T14:35:33Z",
        "link": "http://arxiv.org/abs/2207.00849v1",
        "categories": [
            "cs.DS",
            "cs.MS",
            "cs.PL"
        ]
    },
    {
        "title": "FLOPs as a Discriminant for Dense Linear Algebra Algorithms",
        "authors": [
            "Francisco López",
            "Lars Karlsson",
            "Paolo Bientinesi"
        ],
        "summary": "Expressions that involve matrices and vectors, known as linear algebra expressions, are commonly evaluated through a sequence of invocations to highly optimised kernels provided in libraries such as BLAS and LAPACK. A sequence of kernels represents an algorithm, and in general, because of associativity, algebraic identities, and multiple kernels, one expression can be evaluated via many different algorithms. These algorithms are all mathematically equivalent (i.e., in exact arithmetic, they all compute the same result), but often differ noticeably in terms of execution time. When faced with a decision, high-level languages, libraries, and tools such as Julia, Armadillo, and Linnea choose by selecting the algorithm that minimises the FLOP count. In this paper, we test the validity of the FLOP count as a discriminant for dense linear algebra algorithms, analysing \"anomalies\": problem instances for which the fastest algorithm does not perform the least number of FLOPs.   To do so, we focused on relatively simple expressions and analysed when and why anomalies occurred. We found that anomalies exist and tend to cluster into large contiguous regions. For one expression anomalies were rare, whereas for the other they were abundant. We conclude that FLOPs is not a sufficiently dependable discriminant even when building algorithms with highly optimised kernels. Plus, most of the anomalies remained as such even after filtering out the inter-kernel cache effects. We conjecture that combining FLOP counts with kernel performance models will significantly improve our ability to choose optimal algorithms.",
        "published": "2022-07-05T14:19:55Z",
        "link": "http://arxiv.org/abs/2207.02070v1",
        "categories": [
            "cs.PF",
            "cs.MS",
            "G.4"
        ]
    },
    {
        "title": "nlfem: A flexible 2d Fem Code for Nonlocal Convection-Diffusion and   Mechanics",
        "authors": [
            "Manuel Klar",
            "Christian Vollmann",
            "Volker Schulz"
        ],
        "summary": "In this work we present the mathematical foundation of an assembly code for finite element approximations of nonlocal models with compactly supported, weakly singular kernels. We demonstrate the code on a nonlocal diffusion model in various configurations and on a two-dimensional bond-based peridynamics model. The code nlfem is published under the MIT License and can be freely downloaded.",
        "published": "2022-07-08T14:22:20Z",
        "link": "http://arxiv.org/abs/2207.03921v1",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "Reduction of the Random Access Memory Size in Adjoint Algorithmic   Differentiation by Overloading",
        "authors": [
            "Uwe Naumann"
        ],
        "summary": "Adjoint algorithmic differentiation by operator and function overloading is based on the interpretation of directed acyclic graphs resulting from evaluations of numerical simulation programs. The size of the computer system memory required to store the graph grows proportional to the number of floating-point operations executed by the underlying program. It quickly exceeds the available memory resources. Naive adjoint algorithmic differentiation often becomes infeasible except for relatively simple numerical simulations.   Access to the data associated with the graph can be classified as sequential and random. The latter refers to memory access patterns defined by the adjacency relationship between vertices within the graph. Sequentially accessed data can be decomposed into blocks. The blocks can be streamed across the system memory hierarchy thus extending the amount of available memory, for example, to hard discs. Asynchronous i/o can help to mitigate the increased cost due to accesses to slower memory. Much larger problem instances can thus be solved without resorting to technically challenging user intervention such as checkpointing. Randomly accessed data should not have to be decomposed. Its block-wise streaming is likely to yield a substantial overhead in computational cost due to data accesses across blocks. Consequently, the size of the randomly accessed memory required by an adjoint should be kept minimal in order to eliminate the need for decomposition. We propose a combination of dedicated memory for adjoint $L$-values with the exploitation of remainder bandwidth as a possible solution. Test results indicate significant savings in random access memory size while preserving overall computational efficiency.",
        "published": "2022-07-13T13:09:40Z",
        "link": "http://arxiv.org/abs/2207.07018v1",
        "categories": [
            "cs.MS",
            "G.4"
        ]
    },
    {
        "title": "FFTc: An MLIR Dialect for Developing HPC Fast Fourier Transform   Libraries",
        "authors": [
            "Yifei He",
            "Artur Podobas",
            "Måns I. Andersson",
            "Stefano Markidis"
        ],
        "summary": "Discrete Fourier Transform (DFT) libraries are one of the most critical software components for scientific computing. Inspired by FFTW, a widely used library for DFT HPC calculations, we apply compiler technologies for the development of HPC Fourier transform libraries. In this work, we introduce FFTc, a domain-specific language, based on Multi-Level Intermediate Representation (MLIR), for expressing Fourier Transform algorithms. We present the initial design, implementation, and preliminary results of FFTc.",
        "published": "2022-07-14T10:31:21Z",
        "link": "http://arxiv.org/abs/2207.06803v2",
        "categories": [
            "cs.MS",
            "cs.CL"
        ]
    },
    {
        "title": "PLSS: A Projected Linear Systems Solver",
        "authors": [
            "Johannes J. Brust",
            "Michael A. Saunders"
        ],
        "summary": "We propose iterative projection methods for solving square or rectangular consistent linear systems Ax = b. Existing projection methods use sketching matrices (possibly randomized) to generate a sequence of small projected subproblems, but even the smaller systems can be costly. We develop a process that appends one column to the sketching matrix each iteration and converges in a finite number of iterations whether the sketch is random or deterministic. In general, our process generates orthogonal updates to the approximate solution xk. By choosing the sketch to be the set of all previous residuals, we obtain a simple recursive update and convergence in at most rank(A) iterations (in exact arithmetic). By choosing a sequence of identity columns for the sketch, we develop a generalization of the Kaczmarz method. In experiments on large sparse systems, our method (PLSS) with residual sketches is competitive with LSQR and LSMR, and with residual and identity sketches compares favorably with state-of-the-art randomized methods.",
        "published": "2022-07-15T17:20:07Z",
        "link": "http://arxiv.org/abs/2207.07615v2",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "stat.CO",
            "15A06, 15B52, 65F10, 68W20, 65Y20, 90C20"
        ]
    },
    {
        "title": "Parallelizing Explicit and Implicit Extrapolation Methods for Ordinary   Differential Equations",
        "authors": [
            "Utkarsh",
            "Chris Elrod",
            "Yingbo Ma",
            "Christopher Rackauckas"
        ],
        "summary": "Numerically solving ordinary differential equations (ODEs) is a naturally serial process and as a result the vast majority of ODE solver software are serial. In this manuscript we developed a set of parallelized ODE solvers using extrapolation methods which exploit \"parallelism within the method\" so that arbitrary user ODEs can be parallelized. We describe the specific choices made in the implementation of the explicit and implicit extrapolation methods which allow for generating low overhead static schedules to then exploit with optimized multi-threaded implementations. We demonstrate that while the multi-threading gives a noticeable acceleration on both explicit and implicit problems, the explicit parallel extrapolation methods gave no significant improvement over state-of-the-art even with a multi-threading advantage against current optimized high order Runge-Kutta tableaus. However, we demonstrate that the implicit parallel extrapolation methods are able to achieve state-of-the-art performance (2x-4x) on standard multicore x86 CPUs for systems of $<200$ stiff ODEs solved at low tolerance, a typical setup for a vast majority of users of high level language equation solver suites. The resulting method is distributed as the first widely available open source software for within-method parallel acceleration targeting typical modest compute architectures.",
        "published": "2022-07-17T10:48:08Z",
        "link": "http://arxiv.org/abs/2207.08135v2",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "Tensor Decompositions for Count Data that Leverage Stochastic and   Deterministic Optimization",
        "authors": [
            "Jeremy M. Myers",
            "Daniel M. Dunlavy"
        ],
        "summary": "There is growing interest to extend low-rank matrix decompositions to multi-way arrays, or tensors. One fundamental low-rank tensor decomposition is the canonical polyadic decomposition (CPD). The challenge of fitting a low-rank, nonnegative CPD model to Poisson-distributed count data is of particular interest. Several popular algorithms use local search methods to approximate the maximum likelihood estimator (MLE) of the Poisson CPD model. This work presents two new algorithms that extend state-of-the-art local methods for Poisson CPD. Hybrid GCP-CPAPR combines Generalized Canonical Decomposition (GCP) with stochastic optimization and CP Alternating Poisson Regression (CPAPR), a deterministic algorithm, to increase the probability of converging to the MLE over either method used alone. Restarted CPAPR with SVDrop uses a heuristic based on the singular values of the CPD model unfoldings to identify convergence toward optimizers that are not the MLE and restarts within the feasible domain of the optimization problem, thus reducing overall computational cost when using a multi-start strategy. We provide empirical evidence that indicates our approaches outperform existing methods with respect to converging to the Poisson CPD MLE.",
        "published": "2022-07-18T04:02:56Z",
        "link": "http://arxiv.org/abs/2207.14341v3",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "G.1.3; G.4"
        ]
    },
    {
        "title": "MCTensor: A High-Precision Deep Learning Library with Multi-Component   Floating-Point",
        "authors": [
            "Tao Yu",
            "Wentao Guo",
            "Jianan Canal Li",
            "Tiancheng Yuan",
            "Christopher De Sa"
        ],
        "summary": "In this paper, we introduce MCTensor, a library based on PyTorch for providing general-purpose and high-precision arithmetic for DL training. MCTensor is used in the same way as PyTorch Tensor: we implement multiple basic, matrix-level computation operators and NN modules for MCTensor with identical PyTorch interface. Our algorithms achieve high precision computation and also benefits from heavily-optimized PyTorch floating-point arithmetic. We evaluate MCTensor arithmetic against PyTorch native arithmetic for a series of tasks, where models using MCTensor in float16 would match or outperform the PyTorch model with float32 or float64 precision.",
        "published": "2022-07-18T18:26:43Z",
        "link": "http://arxiv.org/abs/2207.08867v2",
        "categories": [
            "cs.LG",
            "cs.MS"
        ]
    },
    {
        "title": "PaMILO: A Solver for Multi-Objective Mixed Integer Linear Optimization   and Beyond",
        "authors": [
            "Fritz Bökler",
            "Levin Nemesch",
            "Mirko H. Wagner"
        ],
        "summary": "In multi-objective optimization, several potentially conflicting objective functions need to be optimized. Instead of one optimal solution, we look for the set of so called non-dominated solutions.   An important subset is the set of non-dominated extreme points. Finding it is a computationally hard problem in general. While solvers for similar problems exist, there are none known for multi-objective mixed integer linear programs (MOMILPs) or multi-objective mixed integer quadratically constrained quadratic programs (MOMIQCQPs). We present PaMILO, the first solver for finding non-dominated extreme points of MOMILPs and MOMIQCQPs. It can be found on github under github.com/FritzBo/PaMILO. PaMILO provides an easy-to-use interface and is implemented in C++17. It solves occurring subproblems employing either CPLEX or Gurobi.   PaMILO adapts the Dual-Benson algorithm for multi-objective linear programming (MOLP). As it was previously only defined for MOLPs, we describe how it can be adapted for MOMILPs, MOMIQCQPs and even more problem classes in the future.",
        "published": "2022-07-19T09:53:00Z",
        "link": "http://arxiv.org/abs/2207.09155v2",
        "categories": [
            "cs.DM",
            "cs.MS",
            "math.OC"
        ]
    },
    {
        "title": "Proposed Consistent Exception Handling for the BLAS and LAPACK",
        "authors": [
            "James Demmel",
            "Jack Dongarra",
            "Mark Gates",
            "Greg Henry",
            "Julien Langou",
            "Xiaoye Li",
            "Piotr Luszczek",
            "Weslley Pereira",
            "Jason Riedy",
            "Cindy Rubio-González"
        ],
        "summary": "Numerical exceptions, which may be caused by overflow, operations like division by 0 or sqrt(-1), or convergence failures, are unavoidable in many cases, in particular when software is used on unforeseen and difficult inputs. As more aspects of society become automated, e.g., self-driving cars, health monitors, and cyber-physical systems more generally, it is becoming increasingly important to design software that is resilient to exceptions, and that responds to them in a consistent way. Consistency is needed to allow users to build higher-level software that is also resilient and consistent (and so on recursively). In this paper we explore the design space of consistent exception handling for the widely used BLAS and LAPACK linear algebra libraries, pointing out a variety of instances of inconsistent exception handling in the current versions, and propose a new design that balances consistency, complexity, ease of use, and performance. Some compromises are needed, because there are preexisting inconsistencies that are outside our control, including in or between existing vendor BLAS implementations, different programming languages, and even compilers for the same programming language. And user requests from our surveys are quite diverse. We also propose our design as a possible model for other numerical software, and welcome comments on our design choices.",
        "published": "2022-07-19T13:53:26Z",
        "link": "http://arxiv.org/abs/2207.09281v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "A detailed introduction to density-based topology optimisation of fluid   flow problems with implementation in MATLAB",
        "authors": [
            "Joe Alexandersen"
        ],
        "summary": "This article presents a detailed introduction to density-based topology optimisation of fluid flow problems. The goal is to allow new students and researchers to quickly get started in the research area and to skip many of the initial steps, often consuming unnecessarily long time from the scientific advancement of the field. This is achieved by providing a step-by-step guide to the components necessary to understand and implement the theory, as well as extending the supplied MATLAB code. The continuous design representation used and how it is connected to the Brinkman penalty approach, for simulating an immersed solid in a fluid domain, is illustrated. The different interpretations of the Brinkman penalty term and how to chose the penalty parameters are explained. The accuracy of the Brinkman penalty approach is analysed through parametric simulations of a reference geometry. The chosen finite element formulation and the solution method is explained. The minimum dissipated energy optimisation problem is defined and how to solve it using an optimality criteria solver and a continuation scheme is discussed. The included MATLAB implementation is documented, with details on the mesh, pre-processing, optimisation and post-processing. The code has two benchmark examples implemented and the application of the code to these is reviewed. Subsequently, several modifications to the code for more complicated examples are presented through provided code modifications and explanations. Lastly, the computational performance of the code is examined through studies of the computational time and memory usage, along with recommendations to decrease computational time through approximations.",
        "published": "2022-07-19T22:41:36Z",
        "link": "http://arxiv.org/abs/2207.13695v1",
        "categories": [
            "cs.CE",
            "cs.MS",
            "physics.flu-dyn"
        ]
    },
    {
        "title": "Automated modeling of brain bioelectric activity within the 3D Slicer   environment",
        "authors": [
            "Saima Safdar",
            "Benjamin Zwick",
            "George Bourantas",
            "Grand Joldes",
            "Damon Hyde",
            "Simon Warfield",
            "Adam Wittek",
            "Karol Miller"
        ],
        "summary": "Electrocorticography (ECoG) or intracranial electroencephalography (iEEG) monitors electric potential directly on the surface of the brain and can be used to inform treatment planning for epilepsy surgery when paired with numerical modeling. For solving the inverse problem in epilepsy seizure onset localization, accurate solution of the iEEG forward problem is critical which requires accurate representation of the patient's brain geometry and tissue electrical conductivity. In this study, we present an automatic framework for constructing the brain volume conductor model for solving the iEEG forward problem and visualizing the brain bioelectric field on a deformed patient-specific brain model within the 3D Slicer environment. We solve the iEEG forward problem on the predicted postoperative geometry using the finite element method (FEM) which accounts for patient-specific inhomogeneity and anisotropy of tissue conductivity. We use an epilepsy case study to illustrate the workflow of our framework developed and integrated within 3D Slicer.",
        "published": "2022-07-27T16:03:36Z",
        "link": "http://arxiv.org/abs/2208.01747v1",
        "categories": [
            "physics.med-ph",
            "cs.MS"
        ]
    },
    {
        "title": "Digital Nets and Sequences for Quasi-Monte Carlo Methods",
        "authors": [
            "Hee Sun Hong"
        ],
        "summary": "Quasi-Monte Carlo methods are a way of improving the efficiency of Monte Carlo methods. Digital nets and sequences are one of the low discrepancy point sets used in quasi-Monte Carlo methods. This thesis presents the three new results pertaining to digital nets and sequences: implementing randomized digital nets, finding the distribution of the discrepancy of scrambled digital nets, and obtaining better quality of digital nets through evolutionary computation. Finally, applications of scrambled and non-scrambled digital nets are provided.",
        "published": "2022-07-27T21:33:18Z",
        "link": "http://arxiv.org/abs/2207.13802v1",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "HDSDP: Software for Semidefinite Programming",
        "authors": [
            "Wenzhi Gao",
            "Dongdong Ge",
            "Yinyu Ye"
        ],
        "summary": "HDSDP is a numerical software solving the semidefinite programming problems. The main framework of HDSDP resembles the dual-scaling interior point solver DSDP [BY2008] and several new features, including a dual method based on the simplified homogeneous self-dual embedding, have been implemented. The embedding technique enhances stability of the dual method and several new heuristics and computational techniques are designed to accelerate its convergence. HDSDP aims to show how dual-scaling algorithm benefits from the self-dual embedding and it is developed in parallel to DSDP5.8. Numerical experiments over several classical benchmark datasets exhibit its robustness and efficiency, and particularly its advantages on SDP instances featuring low-rank structure and sparsity. HDSDP is open-sourced under MIT license and available at https://github.com/COPT-Public/HDSDP.",
        "published": "2022-07-28T02:35:08Z",
        "link": "http://arxiv.org/abs/2207.13862v2",
        "categories": [
            "cs.MS",
            "math.OC"
        ]
    },
    {
        "title": "Sequential Models in the Synthetic Data Vault",
        "authors": [
            "Kevin Zhang",
            "Neha Patki",
            "Kalyan Veeramachaneni"
        ],
        "summary": "The goal of this paper is to describe a system for generating synthetic sequential data within the Synthetic data vault. To achieve this, we present the Sequential model currently in SDV, an end-to-end framework that builds a generative model for multi-sequence, real-world data. This includes a novel neural network-based machine learning model, conditional probabilistic auto-regressive (CPAR) model. The overall system and the model is available in the open source Synthetic Data Vault (SDV) library {https://github.com/sdv-dev/SDV}, along with a variety of other models for different synthetic data needs.   After building the Sequential SDV, we used it to generate synthetic data and compared its quality against an existing, non-sequential generative adversarial network based model called CTGAN. To compare the sequential synthetic data against its real counterpart, we invented a new metric called Multi-Sequence Aggregate Similarity (MSAS). We used it to conclude that our Sequential SDV model learns higher level patterns than non-sequential models without any trade-offs in synthetic data quality.",
        "published": "2022-07-28T23:17:51Z",
        "link": "http://arxiv.org/abs/2207.14406v1",
        "categories": [
            "cs.LG",
            "cs.MS",
            "62H12",
            "I.5.1"
        ]
    },
    {
        "title": "lifex: a flexible, high performance library for the numerical solution   of complex finite element problems",
        "authors": [
            "Pasquale Claudio Africa"
        ],
        "summary": "Numerical simulations are ubiquitous in mathematics and computational science. Several industrial and clinical applications entail modeling complex multiphysics systems that evolve over a variety of spatial and temporal scales.   This study introduces the design and capabilities of lifex, an open source C++ library for high performance finite element simulations of multiphysics, multiscale, and multidomain problems. lifex meets the emerging need for versatile, efficient computational tools that are easily accessed by users and developers. We showcase its flexibility and effectiveness on a number of illustrative examples and advanced applications of use and demonstrate its parallel performance up to thousands of cores.",
        "published": "2022-07-29T13:24:30Z",
        "link": "http://arxiv.org/abs/2207.14668v3",
        "categories": [
            "cs.MS",
            "cs.DC",
            "cs.NA",
            "math.NA",
            "35-04 (Primary) 65-04, 65Y05, 65Y20, 68-04, 68N30 (Secondary)",
            "G.4; G.1"
        ]
    },
    {
        "title": "NFFT.jl: Generic and Fast Julia Implementation of the Nonequidistant   Fast Fourier Transform",
        "authors": [
            "Tobias Knopp",
            "Marija Boberg",
            "Mirco Grosser"
        ],
        "summary": "The non-equidistant fast Fourier transform (NFFT) is an extension of the famous fast Fourier transform (FFT), which can be applied to non-equidistantly sampled data in time/space or frequency domain. It is an approximative algorithm that allows to control the approximation error in such a way that machine precision is reached while keeping the algorithmic complexity in the same order as a regular FFT. The NFFT plays a major role in many signal processing applications and has been intensively studied from a theoretical and computational perspective. The fastest CPU implementations of the NFFT are implemented in the low-level programming languages C and C++ and require a compromise between code generalizability, code readability, and code efficiency. The programming language Julia promises new opportunities in optimizing these three conflicting goals. In this work we show that Julia indeed allows to develop an NFFT implementation, which is completely generic, dimension-agnostic and requires about 2-3 times less code than other famous libraries while still being one of the fastest NFFT implementations developed to date.",
        "published": "2022-07-29T19:32:48Z",
        "link": "http://arxiv.org/abs/2208.00049v2",
        "categories": [
            "cs.MS",
            "cs.NA",
            "math.NA",
            "65T50, 65T40, 65Y05, 68N01"
        ]
    },
    {
        "title": "Compact representations of structured BFGS matrices",
        "authors": [
            "Johannes J. Brust",
            "Zichao",
            "Di",
            "Sven Leyffer",
            "Cosmin G. Petra"
        ],
        "summary": "For general large-scale optimization problems compact representations exist in which recursive quasi-Newton update formulas are represented as compact matrix factorizations. For problems in which the objective function contains additional structure, so-called structured quasi-Newton methods exploit available second-derivative information and approximate unavailable second derivatives. This article develops the compact representations of two structured Broyden-Fletcher-Goldfarb-Shanno update formulas. The compact representations enable efficient limited memory and initialization strategies. Two limited memory line search algorithms are described and tested on a collection of problems, including a real world large scale imaging application.",
        "published": "2022-07-29T20:09:16Z",
        "link": "http://arxiv.org/abs/2208.00057v1",
        "categories": [
            "math.OC",
            "cs.MS",
            "cs.NA",
            "econ.EM",
            "math.NA",
            "stat.CO",
            "90C06, 90C53, 65K10,"
        ]
    },
    {
        "title": "The Object Oriented c++ library QIBSH++ for Hermite spline Quasi   Interpolation",
        "authors": [
            "Enrico Bertolazzi",
            "Antonella Falini",
            "Francesca Mazzia"
        ],
        "summary": "The library QIBSH++ is a C++ object oriented library for the solution of Quasi Interpolation problems. The library is based on a Hermite Quasi Interpolating operator, which was derived as continuous extensions of linear multistep methods applied for the numerical solution of Boundary Value Problems for Ordinary Differential Equations. The library includes the possibility to use Hermite data or to apply a finite difference scheme for derivative approximations, when derivative values are not directly available. The generalization of the quasi interpolation procedure to surfaces and volumes approximation by means of a tensor product technique is also implemented. The method has been also generalized for one dimensional vectorial data, periodic data, and for two dimensional data in cylindrical coordinates, periodic with respect to the angular argument. Numerical tests show that the library could be used efficiently in many practical problems.",
        "published": "2022-08-05T16:27:45Z",
        "link": "http://arxiv.org/abs/2208.03260v1",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "65D15, 65L10",
            "G.1.1"
        ]
    },
    {
        "title": "Feature-Based Time-Series Analysis in R using the theft Package",
        "authors": [
            "Trent Henderson",
            "Ben D. Fulcher"
        ],
        "summary": "Time series are measured and analyzed across the sciences. One method of quantifying the structure of time series is by calculating a set of summary statistics or `features', and then representing a time series in terms of its properties as a feature vector. The resulting feature space is interpretable and informative, and enables conventional statistical learning approaches, including clustering, regression, and classification, to be applied to time-series datasets. Many open-source software packages for computing sets of time-series features exist across multiple programming languages, including catch22 (22 features: Matlab, R, Python, Julia), feasts (42 features: R), tsfeatures (63 features: R), Kats (40 features: Python), tsfresh (779 features: Python), and TSFEL (390 features: Python). However, there are several issues: (i) a singular access point to these packages is not currently available; (ii) to access all feature sets, users must be fluent in multiple languages; and (iii) these feature-extraction packages lack extensive accompanying methodological pipelines for performing feature-based time-series analysis, such as applications to time-series classification. Here we introduce a solution to these issues in an R software package called theft: Tools for Handling Extraction of Features from Time series. theft is a unified and extendable framework for computing features from the six open-source time-series feature sets listed above. It also includes a suite of functions for processing and interpreting the performance of extracted features, including extensive data-visualization templates, low-dimensional projections, and time-series classification operations. With an increasing volume and complexity of time-series datasets in the sciences and industry, theft provides a standardized framework for comprehensively quantifying and interpreting informative structure in time series.",
        "published": "2022-08-12T07:29:29Z",
        "link": "http://arxiv.org/abs/2208.06146v4",
        "categories": [
            "stat.ML",
            "cs.LG",
            "cs.MS",
            "q-bio.QM",
            "stat.AP",
            "stat.ME"
        ]
    },
    {
        "title": "Parallel QR Factorization of Block Low-Rank Matrices",
        "authors": [
            "M. Ridwan Apriansyah",
            "Rio Yokota"
        ],
        "summary": "We present two new algorithms for Householder QR factorization of Block Low-Rank (BLR) matrices: one that performs block-column-wise QR, and another that is based on tiled QR. We show how the block-column-wise algorithm exploits BLR structure to achieve arithmetic complexity of $\\mathcal{O}(mn)$, while the tiled BLR-QR exhibits $\\mathcal{O}(mn^{1.5})$ complexity. However, the tiled BLR-QR has finer task granularity that allows parallel task-based execution on shared memory systems. We compare the block-column-wise BLR-QR using fork-join parallelism with tiled BLR-QR using task-based parallelism. We also compare these two implementations of Householder BLR-QR with a block-column-wise Modified Gram-Schmidt (MGS) BLR-QR using fork-join parallelism, and a state-of-the-art vendor-optimized dense Householder QR in Intel MKL. For a matrix of size 131k $\\times$ 65k, all BLR methods are more than an order of magnitude faster than the dense QR in MKL. Our methods are also robust to ill-conditioning and produce better orthogonal factors than the existing MGS-based method. On a CPU with 64 cores, our parallel tiled Householder and block-column-wise Householder algorithms show a speedup of 50 and 37 times, respectively.",
        "published": "2022-08-12T09:56:04Z",
        "link": "http://arxiv.org/abs/2208.06194v1",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "G.1.3; G.1.2; G.4; D.1.3"
        ]
    },
    {
        "title": "Tensor Algebra on an Optoelectronic Microchip",
        "authors": [
            "Sathvik Redrouthu",
            "Rishi Athavale"
        ],
        "summary": "Tensor algebra lies at the core of computational science and machine learning. Due to its high usage, entire libraries exist dedicated to improving its performance. Conventional tensor algebra performance boosts focus on algorithmic optimizations, which in turn lead to incremental improvements. In this paper, we describe a method to accelerate tensor algebra a different way: by outsourcing operations to an optical microchip. We outline a numerical programming language developed to perform tensor algebra computations that is designed to leverage our optical hardware's full potential. We introduce the language's current grammar and go over the compiler design. We then show a new way to store sparse rank-n tensors in RAM that outperforms conventional array storage (used by C++, Java, etc.). This method is more memory-efficient than Compressed Sparse Fiber (CSF) format and is specifically tuned for our optical hardware. Finally, we show how the scalar-tensor product, rank-$n$ Kronecker product, tensor dot product, Khatri-Rao product, face-splitting product, and vector cross product can be compiled into operations native to our optical microchip through various tensor decompositions.",
        "published": "2022-08-13T23:28:31Z",
        "link": "http://arxiv.org/abs/2208.06749v1",
        "categories": [
            "cs.PL",
            "cs.MS",
            "D.3.4"
        ]
    },
    {
        "title": "Survey of Methods for Solving Systems of Nonlinear Equations, Part I:   Root-finding Approaches",
        "authors": [
            "Ilias S. Kotsireas",
            "Panos M. Pardalos",
            "Alexander Semenov",
            "William T. Trevena",
            "Michael N. Vrahatis"
        ],
        "summary": "This paper presents a comprehensive survey of methods which can be utilized to search for solutions to systems of nonlinear equations (SNEs). Our objectives with this survey are to synthesize pertinent literature in this field by presenting a thorough description and analysis of the known methods capable of finding one or many solutions to SNEs, and to assist interested readers seeking to identify solution techniques which are well suited for solving the various classes of SNEs which one may encounter in real world applications.   To accomplish these objectives, we present a multi-part survey. In part one, we focus on root-finding approaches which can be used to search for solutions to a SNE without transforming it into an optimization problem. In part two, we will introduce the various transformations which have been utilized to transform a SNE into an optimization problem, and we discuss optimization algorithms which can then be used to search for solutions. In part three, we will present a robust quantitative comparative analysis of methods capable of searching for solutions to SNEs.",
        "published": "2022-08-17T20:52:46Z",
        "link": "http://arxiv.org/abs/2208.08530v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "Survey of Methods for Solving Systems of Nonlinear Equations, Part II:   Optimization Based Approaches",
        "authors": [
            "Ilias S. Kotsireas",
            "Panos M. Pardalos",
            "Alexander Semenov",
            "William T. Trevena",
            "Michael N. Vrahatis"
        ],
        "summary": "This paper presents a comprehensive survey of methods which can be utilized to search for solutions to systems of nonlinear equations (SNEs). Our objectives with this survey are to synthesize pertinent literature in this field by presenting a thorough description and analysis of the known methods capable of finding one or many solutions to SNEs, and to assist interested readers seeking to identify solution techniques which are well suited for solving the various classes of SNEs which one may encounter in real world applications.   To accomplish these objectives, we present a multi-part survey. In part one, we focused on root-finding approaches which can be used to search for solutions to a SNE without transforming it into an optimization problem. In part two, we introduce the various transformations which have been utilized to transform a SNE into an optimization problem, and we discuss optimization algorithms which can then be used to search for solutions. We emphasize the important characteristics of each method, and we discuss promising directions for future research. In part three, we will present a robust quantitative comparative analysis of methods capable of searching for solutions to SNEs.",
        "published": "2022-08-17T20:58:11Z",
        "link": "http://arxiv.org/abs/2208.08532v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "MOM: Matrix Operations in MLIR",
        "authors": [
            "Lorenzo Chelini",
            "Henrik Barthels",
            "Paolo Bientinesi",
            "Marcin Copik",
            "Tobias Grosser",
            "Daniele G. Spampinato"
        ],
        "summary": "Modern research in code generators for dense linear algebra computations has shown the ability to produce optimized code with a performance which compares and often exceeds the one of state-of-the-art implementations by domain experts. However, the underlying infrastructure is often developed in isolation making the interconnection of logically combinable systems complicated if not impossible. In this paper, we propose to leverage MLIR as a unifying compiler infrastructure for the optimization of dense linear algebra operations. We propose a new MLIR dialect for expressing linear algebraic computations including matrix properties to enable high-level algorithmic transformations. The integration of this new dialect in MLIR enables end-to-end compilation of matrix computations via conversion to existing lower-level dialects already provided by the framework.",
        "published": "2022-08-22T15:17:44Z",
        "link": "http://arxiv.org/abs/2208.10391v1",
        "categories": [
            "cs.PL",
            "cs.MS"
        ]
    },
    {
        "title": "Distributed Objective Function Evaluation for Optimization of Radiation   Therapy Treatment Plans",
        "authors": [
            "Felix Liu",
            "Måns I. Andersson",
            "Albin Fredriksson",
            "Stefano Markidis"
        ],
        "summary": "The modern workflow for radiation therapy treatment planning involves mathematical optimization to determine optimal treatment machine parameters for each patient case. The optimization problems can be computationally expensive, requiring iterative optimization algorithms to solve. In this work, we investigate a method for distributing the calculation of objective functions and gradients for radiation therapy optimization problems across computational nodes. We test our approach on the TROTS dataset -- which consists of optimization problems from real clinical patient cases -- using the IPOPT optimization solver in a leader/follower type approach for parallelization. We show that our approach can utilize multiple computational nodes efficiently, with a speedup of approximately 2-3.5 times compared to the serial version.",
        "published": "2022-08-24T09:34:44Z",
        "link": "http://arxiv.org/abs/2208.11395v1",
        "categories": [
            "cs.MS",
            "cs.DC"
        ]
    },
    {
        "title": "Flash-X, a multiphysics simulation software instrument",
        "authors": [
            "Anshu Dubey",
            "Klaus Weide",
            "Jared O'Neal",
            "Akash Dhruv",
            "Sean Couch",
            "J. Austin Harris",
            "Tom Klosterman",
            "Rajeev Jain",
            "Johann Rudi",
            "Bronson Messer",
            "Michael Pajkos",
            "Jared Carlson",
            "Ran Chu",
            "Mohamed Wahib",
            "Saurabh Chawdhary",
            "Paul M. Ricker",
            "Dongwook Lee",
            "Katie Antypas",
            "Katherine M. Riley",
            "Christopher Daley",
            "Murali Ganapathy",
            "Francis X. Timmes",
            "Dean M. Townsley",
            "Marcos Vanella",
            "John Bachan",
            "Paul Rich",
            "Shravan Kumar",
            "Eirik Endeve",
            "W. Raphael Hix",
            "Anthony Mezzacappa",
            "Thomas Papatheodore"
        ],
        "summary": "Flash-X is a highly composable multiphysics software system that can be used to simulate physical phenomena in several scientific domains. It derives some of its solvers from FLASH, which was first released in 2000. Flash-X has a new framework that relies on abstractions and asynchronous communications for performance portability across a range of increasingly heterogeneous hardware platforms. Flash-X is meant primarily for solving Eulerian formulations of applications with compressible and/or incompressible reactive flows. It also has a built-in, versatile Lagrangian framework that can be used in many different ways, including implementing tracers, particle-in-cell simulations, and immersed boundary methods.",
        "published": "2022-08-24T16:05:03Z",
        "link": "http://arxiv.org/abs/2208.11630v1",
        "categories": [
            "physics.comp-ph",
            "astro-ph.IM",
            "cs.MS"
        ]
    },
    {
        "title": "SOniCS: Develop intuition on biomechanical systems through interactive   error controlled simulations",
        "authors": [
            "Arnaud Mazier",
            "Sidaty El Hadramy",
            "Jean-Nicolas Brunet",
            "Jack S. Hale",
            "Stéphane Cotin",
            "Stéphane P. A. Bordas"
        ],
        "summary": "This new approach allows the user to experiment with model choices easily and quickly without requiring in-depth expertise, as constitutive models can be modified by one line of code only. This ease in building new models makes SOniCS ideal to develop surrogate, reduced order models and to train machine learning algorithms for uncertainty quantification or to enable patient-specific simulations. SOniCS is thus not only a tool that facilitates the development of surgical training simulations but also, and perhaps more importantly, paves the way to increase the intuition of users or otherwise non-intuitive behaviors of (bio)mechanical systems. The plugin uses new developments of the FEniCSx project enabling automatic generation with FFCx of finite element tensors such as the local residual vector and Jacobian matrix. We validate our approach with numerical simulations such as manufactured solutions, cantilever beams, and benchmarks provided by FEBio. We reach machine precision accuracy and demonstrate the use of the plugin for a real-time haptic simulation involving a surgical tool controlled by the user in contact with a hyperelastic liver. We include complete examples showing the use of our plugin for simulations involving Saint Venant-Kirchhoff, Neo-Hookean, Mooney-Rivlin, and Holzapfel Ogden anisotropic models as supplementary material.",
        "published": "2022-08-24T17:14:08Z",
        "link": "http://arxiv.org/abs/2208.11676v1",
        "categories": [
            "cs.MS",
            "cs.CE",
            "cs.SE"
        ]
    },
    {
        "title": "DelayDiffEq: Generating Delay Differential Equation Solvers via   Recursive Embedding of Ordinary Differential Equation Solvers",
        "authors": [
            "David Widmann",
            "Chris Rackauckas"
        ],
        "summary": "Traditional solvers for delay differential equations (DDEs) are designed around only a single method and do not effectively use the infrastructure of their more-developed ordinary differential equation (ODE) counterparts. In this work we present DelayDiffEq, a Julia package for numerically solving delay differential equations (DDEs) which leverages the multitude of numerical algorithms in OrdinaryDiffEq for solving both stiff and non-stiff ODEs, and manages to solve challenging stiff DDEs. We describe how compiling the ODE integrator within itself, and accounting for discontinuity propagation, leads to a design that is effective for DDEs while using all of the ODE internals. We highlight some difficulties that a numerical DDE solver has to address, and explain how DelayDiffEq deals with these problems. We show how DelayDiffEq is able to solve difficult equations, how its stiff DDE solvers give efficiency on problems with time-scale separation, and how the design allows for generality and flexibility in usage such as being repurposed for generating solvers for stochastic delay differential equations.",
        "published": "2022-08-26T22:14:32Z",
        "link": "http://arxiv.org/abs/2208.12879v1",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "math.DS"
        ]
    },
    {
        "title": "Cardinal Optimizer (COPT) User Guide",
        "authors": [
            "Dongdong Ge",
            "Qi Huangfu",
            "Zizhuo Wang",
            "Jian Wu",
            "Yinyu Ye"
        ],
        "summary": "Cardinal Optimizer is a high-performance mathematical programming solver for efficiently solving largescale optimization problem. This documentation provides basic introduction to the Cardinal Optimizer.",
        "published": "2022-08-30T14:52:44Z",
        "link": "http://arxiv.org/abs/2208.14314v3",
        "categories": [
            "math.OC",
            "cs.MS"
        ]
    },
    {
        "title": "Solving the One-Dimensional Time-Independent Schrödinger Equation with   High Accuracy: The LagrangeMesh Mathematica Package",
        "authors": [
            "J. C. del Valle"
        ],
        "summary": "In order to find the spectrum associated with the one-dimensional Schr\\\"oodinger equation, we discuss the Lagrange Mesh method (LMM) and its numerical implementation for bound states. After presenting a general overview of the theory behind the LMM, we introduce the LagrangeMesh package: the numerical implementation of the LMM in Mathematica. Using few lines of code, the package enables a quick home-computer computation of the spectrum and provides a practical tool to study a large class of systems in quantum mechanics. The main properties of the package are (i) the input is basically the potential function and the interval on which is defined; and (ii) the accuracy in calculations and final results is controllable by the user. As illustration, a highly accurate spectrum of some relevant quantum systems is obtained by employing the commands that the package offers. In fact, the present work can be regarded as a user guide based on worked examples.",
        "published": "2022-08-30T15:33:14Z",
        "link": "http://arxiv.org/abs/2208.14340v2",
        "categories": [
            "quant-ph",
            "cs.MS"
        ]
    },
    {
        "title": "Performance optimization and analysis of the unstructured Discontinuous   Galerkin solver on multi-core and many-core architectures",
        "authors": [
            "Zhe Dai",
            "Liang D",
            "Yueqin Wang",
            "Fang Wang",
            "Li Ming",
            "Jian Zhang"
        ],
        "summary": "The discontinuous Galerkin (DG) algorithm is a representative high order method in Computational Fluid Dynamics (CFD) area which possesses considerable mathematical advantages such as high resolution, low dissipation, and dispersion. However, DG is rather computationally intensive to demonstrate practical engineering problems. This paper discusses the implementation of our in-house practical DG application in three different programming models, as well as some optimization techniques, including grid renumbering and mixed precision to maximize the performance improvements in a single node system. The experiment on CPU and GPU shows that our CUDA, OpenACC, and OpenMP-based code obtains a maximum speedup of 42.9x, 35.3x, and 8.1x compared with serial execution by the original application, respectively. Besides, we systematically compare the programming models in two aspects: performance and productivity. Our empirical conclusions facilitate the programmers to select the right platform with a suitable programming model according to their target applications.",
        "published": "2022-09-05T10:23:30Z",
        "link": "http://arxiv.org/abs/2209.01877v1",
        "categories": [
            "cs.MS",
            "cs.CE",
            "cs.DC"
        ]
    },
    {
        "title": "Forward-Mode Automatic Differentiation of Compiled Programs",
        "authors": [
            "Max Aehle",
            "Johannes Blühdorn",
            "Max Sagebaum",
            "Nicolas R. Gauger"
        ],
        "summary": "Algorithmic differentiation (AD) is a set of techniques that provide partial derivatives of computer-implemented functions. Such a function can be supplied to state-of-the-art AD tools via its source code, or via an intermediate representation produced while compiling its source code.   We present the novel AD tool Derivgrind, which augments the machine code of compiled programs with forward-mode AD logic. Derivgrind leverages the Valgrind instrumentation framework for a structured access to the machine code, and a shadow memory tool to store dot values. Access to the source code is required at most for the files in which input and output variables are defined.   Derivgrind's versatility comes at the price of scaling the run-time by a factor between 30 and 75, measured on a benchmark based on a numerical solver for a partial differential equation. Results of our extensive regression test suite indicate that Derivgrind produces correct results on GCC- and Clang-compiled programs, including a Python interpreter, with a small number of exceptions. While we provide a list of scenarios that Derivgrind does not handle correctly, nearly all of them are academic counterexamples or originate from highly optimized math libraries. As long as differentiating those is avoided, Derivgrind can be applied to an unprecedentedly wide range of cross-language or partially closed-source software with little integration efforts.",
        "published": "2022-09-05T10:48:24Z",
        "link": "http://arxiv.org/abs/2209.01895v2",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "A Test for FLOPs as a Discriminant for Linear Algebra Algorithms",
        "authors": [
            "Aravind Sankaran",
            "Paolo Bientinesi"
        ],
        "summary": "Linear algebra expressions, which play a central role in countless scientific computations, are often computed via a sequence of calls to existing libraries of building blocks (such as those provided by BLAS and LAPACK). A sequence identifies a computing strategy, i.e., an algorithm, and normally for one linear algebra expression many alternative algorithms exist. Although mathematically equivalent, those algorithms might exhibit significant differences in terms of performance. Several high-level languages and tools for matrix computations such as Julia, Armadillo, Linnea, etc., make algorithmic choices by minimizing the number of Floating Point Operations (FLOPs). However, there can be several algorithms that share the same (or have nearly identical) number of FLOPs; in many cases, these algorithms exhibit execution times which are statistically equivalent and one could arbitrarily select one of them as the best algorithm. It is however not unlikely to find cases where the execution times are significantly different from one another (despite the FLOP count being almost the same). It is also possible that the algorithm that minimizes FLOPs is not the one that minimizes execution time. In this work, we develop a methodology to test the reliability of FLOPs as discriminant for linear algebra algorithms. Given a set of algorithms (for an instance of a linear algebra expression) as input, the methodology ranks them into performance classes; i.e., multiple algorithms are allowed to share the same rank. To this end, we measure the algorithms iteratively until the changes in the ranks converge to a value close to zero. FLOPs are a valid discriminant for an instance if all the algorithms with minimum FLOPs are assigned the best rank; otherwise, the instance is regarded as an anomaly, which can then be used in the investigation of the root cause of performance differences.",
        "published": "2022-09-07T16:08:17Z",
        "link": "http://arxiv.org/abs/2209.03258v3",
        "categories": [
            "cs.PF",
            "cs.MS"
        ]
    },
    {
        "title": "Looplets: A Language For Structured Coiteration",
        "authors": [
            "Willow Ahrens",
            "Daniel Donenfeld",
            "Fredrik Kjolstad",
            "Saman Amarasinghe"
        ],
        "summary": "Real world arrays often contain underlying structure, such as sparsity, runs of repeated values, or symmetry. Specializing for structure yields significant speedups. But automatically generating efficient code for structured data is challenging, especially when arrays with different structure interact. We show how to abstract over array structures so that the compiler can generate code to coiterate over any combination of them. Our technique enables new array formats (such as 1DVBL for irregular clustered sparsity), new iteration strategies (such as galloping intersections), and new operations over structured data (such as concatenation or convolution).",
        "published": "2022-09-08T20:16:41Z",
        "link": "http://arxiv.org/abs/2209.05250v1",
        "categories": [
            "cs.PL",
            "cs.MS"
        ]
    },
    {
        "title": "I'm stuck! How to efficiently debug computational solid mechanics models   so you can enjoy the beauty of simulations",
        "authors": [
            "Ester Comellas",
            "Jean-Paul Pelteret",
            "Wolfgang Bangerth"
        ],
        "summary": "A substantial fraction of the time that computational modellers dedicate to developing their models is actually spent trouble-shooting and debugging their code. However, how this process unfolds is seldom spoken about, maybe because it is hard to articulate as it relies mostly on the mental catalogues we have built with the experience of past failures. To help newcomers to the field of material modelling, here we attempt to fill this gap and provide a perspective on how to identify and fix mistakes in computational solid mechanics models. To this aim, we describe the components that make up such a model and then identify possible sources of errors. In practice, finding mistakes is often better done by considering the symptoms of what is going wrong. As a consequence, we provide strategies to narrow down where in the model the problem may be, based on observation and a catalogue of frequent causes of observed errors. In a final section, we also discuss how one-time bug-free models can be kept bug-free in view of the fact that computational models are typically under continual development. We hope that this collection of approaches and suggestions serves as a \"road map\" to find and fix mistakes in computational models, and more importantly, keep the problems solved so that modellers can enjoy the beauty of material modelling and simulation.",
        "published": "2022-09-09T09:25:53Z",
        "link": "http://arxiv.org/abs/2209.04198v2",
        "categories": [
            "cs.CE",
            "cs.MS",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "On topological data analysis for SHM; an introduction to persistent   homology",
        "authors": [
            "Tristan Gowdridge",
            "Nikolaos Devilis",
            "Keith Worden"
        ],
        "summary": "This paper aims to discuss a method of quantifying the 'shape' of data, via a methodology called topological data analysis. The main tool within topological data analysis is persistent homology; this is a means of measuring the shape of data, from the homology of a simplicial complex, calculated over a range of values. The required background theory and a method of computing persistent homology is presented here, with applications specific to structural health monitoring. These results allow for topological inference and the ability to deduce features in higher-dimensional data, that might otherwise be overlooked.   A simplicial complex is constructed for data for a given distance parameter. This complex encodes information about the local proximity of data points. A singular homology value can be calculated from this simplicial complex. Extending this idea, the distance parameter is given for a range of values, and the homology is calculated over this range. The persistent homology is a representation of how the homological features of the data persist over this interval. The result is characteristic to the data. A method that allows for the comparison of the persistent homology for different data sets is also discussed.",
        "published": "2022-09-12T12:02:39Z",
        "link": "http://arxiv.org/abs/2209.06155v1",
        "categories": [
            "math.AT",
            "cs.LG",
            "cs.MS"
        ]
    },
    {
        "title": "IGraph/M: graph theory and network analysis for Mathematica",
        "authors": [
            "Szabolcs Horvát",
            "Jakub Podkalicki",
            "Gábor Csárdi",
            "Tamás Nepusz",
            "Vincent Traag",
            "Fabio Zanini",
            "Daniel Noom"
        ],
        "summary": "IGraph/M is an efficient general purpose graph theory and network analysis package for Mathematica. IGraph/M serves as the Wolfram Language interfaces to the igraph C library, and also provides several unique pieces of functionality not yet present in igraph, but made possible by combining its capabilities with Mathematica's. The package is designed to support both graph theoretical research as well as the analysis of large-scale empirical networks.",
        "published": "2022-09-19T16:04:57Z",
        "link": "http://arxiv.org/abs/2209.09145v1",
        "categories": [
            "physics.soc-ph",
            "cs.MS",
            "math.CO"
        ]
    },
    {
        "title": "CyRSoXS: A GPU-accelerated virtual instrument for Polarized Resonant   Soft X-ray Scattering (P-RSoXS)",
        "authors": [
            "Kumar Saurabh",
            "Peter J. Dudenas",
            "Eliot Gann",
            "Veronica G. Reynolds",
            "Subhrangsu Mukherjee",
            "Daniel Sunday",
            "Tyler B. Martin",
            "Peter A. Beaucage",
            "Michael L. Chabinyc",
            "Dean M. DeLongchamp",
            "Adarsh Krishnamurthy",
            "Baskar Ganapathysubramanian"
        ],
        "summary": "Polarized Resonant Soft X-ray scattering (P-RSoXS) has emerged as a powerful synchrotron-based tool that combines principles of X-ray scattering and X-ray spectroscopy. P-RSoXS provides unique sensitivity to molecular orientation and chemical heterogeneity in soft materials such as polymers and biomaterials. Quantitative extraction of orientation information from P-RSoXS pattern data is challenging because the scattering processes originate from sample properties that must be represented as energy-dependent three-dimensional tensors with heterogeneities at nanometer to sub-nanometer length scales. We overcome this challenge by developing an open-source virtual instrument that uses GPUs to simulate P-RSoXS patterns from real-space material representations with nanoscale resolution. Our computational framework CyRSoXS (https://github.com/usnistgov/cyrsoxs) is designed to maximize GPU performance. We demonstrate the accuracy and robustness of our approach by validating against an extensive set of test cases, which include both analytical solutions and numerical comparisons, demonstrating a speedup of over three orders relative to the current state-of-the-art simulation software. Such fast simulations open up a variety of applications that were previously computationally infeasible, including (a) pattern fitting, (b) co-simulation with the physical instrument for operando analytics, data exploration, and decision support, (c) data creation and integration into machine learning workflows, and (d) utilization in multi-modal data assimilation approaches. Finally, we abstract away the complexity of the computational framework from the end-user by exposing CyRSoXS to Python using Pybind. This eliminates I/O requirements for large-scale parameter exploration and inverse design, and democratizes usage by enabling seamless integration with a Python ecosystem (https://github.com/usnistgov/nrss).",
        "published": "2022-09-27T02:29:08Z",
        "link": "http://arxiv.org/abs/2209.13121v1",
        "categories": [
            "physics.comp-ph",
            "cs.MS"
        ]
    },
    {
        "title": "Disruptive Changes in Field Equation Modeling: A Simple Interface for   Wafer Scale Engines",
        "authors": [
            "Mino Woo",
            "Terry Jordan",
            "Robert Schreiber",
            "Ilya Sharapov",
            "Shaheer Muhammad",
            "Abhishek Koneru",
            "Michael James",
            "Dirk Van Essendelft"
        ],
        "summary": "We present a high-level and accessible Application Programming Interface (API) for the solution of field equations on the Cerebras Systems Wafer-Scale Engine (WSE) with over two orders of magnitude performance gain relative to traditional distributed computing approaches. The domain-specific API is called the WSE Field-equation API (WFA). The WFA outperforms OpenFOAM on NETL's Joule 2.0 supercomputer by over two orders of magnitude in time to solution. While this performance is consistent with hand-optimized assembly codes, the WFA provides an easy-to-use, high-level Python interface that allows users to form and solve field equations effortlessly. We report here the WFA programming methodology and achieved performance on the latest generation of WSE, the CS-2.",
        "published": "2022-09-28T01:33:23Z",
        "link": "http://arxiv.org/abs/2209.13768v2",
        "categories": [
            "cs.DC",
            "cs.AR",
            "cs.MS",
            "cs.PF",
            "J.2; I.6"
        ]
    },
    {
        "title": "Cadabra and Python algorithms in General Relativity and Cosmology I:   Generalities",
        "authors": [
            "Oscar Castillo-Felisola",
            "Dominic T. Price",
            "Mattia Scomparin"
        ],
        "summary": "The aim of this work is to present a series of concrete examples which illustrate how the computer algebra system Cadabra can be used to manipulate expressions appearing in General Relativity and other gravitational theories. We highlight the way in which Cadabra's philosophy differs from other systems with related functionality. The use of various new built-in packages is discussed, and we show how such packages can also be created by end-users directly using the notebook interface.   The current paper focuses on fairly generic applications in gravitational theories, including the use of differential forms, the derivation of field equations and the construction of their solutions. A follow-up paper discusses more specific applications related to the analysis of gravitational waves.",
        "published": "2022-09-30T16:44:57Z",
        "link": "http://arxiv.org/abs/2210.00005v1",
        "categories": [
            "gr-qc",
            "cs.MS",
            "physics.class-ph",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Cadabra and Python algorithms in General Relativity and Cosmology II:   Gravitational Waves",
        "authors": [
            "Oscar Castillo-Felisola",
            "Dominic T. Price",
            "Mattia Scomparin"
        ],
        "summary": "Computer Algebra Systems (CASs) like Cadabra Software play a prominent role in a wide range of research activities in physics and related fields. We show how Cadabra language is easily implemented in the well established Python programming framework, gaining excellent flexibility and customization to address the issue of tensor perturbations in General Relativity. We obtain a performing algorithm to decompose tensorial quantities up to any perturbative order of the metric. The features of our code are tested by discussing some concrete computational issues in research activities related to first/higher-order gravitational waves.",
        "published": "2022-09-30T16:58:21Z",
        "link": "http://arxiv.org/abs/2210.00007v1",
        "categories": [
            "gr-qc",
            "cs.MS",
            "physics.class-ph",
            "physics.comp-ph"
        ]
    },
    {
        "title": "NCVX: A General-Purpose Optimization Solver for Constrained Machine and   Deep Learning",
        "authors": [
            "Buyun Liang",
            "Tim Mitchell",
            "Ju Sun"
        ],
        "summary": "Imposing explicit constraints is relatively new but increasingly pressing in deep learning, stimulated by, e.g., trustworthy AI that performs robust optimization over complicated perturbation sets and scientific applications that need to respect physical laws and constraints. However, it can be hard to reliably solve constrained deep learning problems without optimization expertise. The existing deep learning frameworks do not admit constraints. General-purpose optimization packages can handle constraints but do not perform auto-differentiation and have trouble dealing with nonsmoothness. In this paper, we introduce a new software package called NCVX, whose initial release contains the solver PyGRANSO, a PyTorch-enabled general-purpose optimization package for constrained machine/deep learning problems, the first of its kind. NCVX inherits auto-differentiation, GPU acceleration, and tensor variables from PyTorch, and is built on freely available and widely used open-source frameworks. NCVX is available at https://ncvx.org, with detailed documentation and numerous examples from machine/deep learning and other fields.",
        "published": "2022-10-03T14:41:26Z",
        "link": "http://arxiv.org/abs/2210.00973v2",
        "categories": [
            "cs.LG",
            "cs.CV",
            "cs.MS",
            "eess.SP",
            "math.OC"
        ]
    },
    {
        "title": "Memory-Efficient Recursive Evaluation of 3-Center Gaussian Integrals",
        "authors": [
            "Andrey Asadchev",
            "Edward F. Valeev"
        ],
        "summary": "To improve the efficiency of Gaussian integral evaluation on modern accelerated architectures FLOP-efficient Obara-Saika-based recursive evaluation schemes are optimized for the memory footprint. For the 3-center 2-particle integrals that are key for the evaluation of Coulomb and other 2-particle interactions in the density-fitting approximation the use of multi-quantal recurrences (in which multiple quanta are created or transferred at once) is shown to produce significant memory savings. Other innovation include leveraging register memory for reduced memory footprint and direct compile-time generation of optimized kernels (instead of custom code generation) with compile-time features of modern C++/CUDA. Performance of conventional and CUDA-based implementations of the proposed schemes is illustrated for both the individual batches of integrals involving up to Gaussians with low and high angular momenta (up to $L=6$) and contraction degrees, as well as for the density-fitting-based evaluation of the Coulomb potential. The computer implementation is available in the open-source LibintX library.",
        "published": "2022-10-06T20:16:36Z",
        "link": "http://arxiv.org/abs/2210.03192v2",
        "categories": [
            "physics.comp-ph",
            "cs.MS",
            "physics.chem-ph"
        ]
    },
    {
        "title": "MOS: A Mathematical Optimization Service",
        "authors": [
            "James Hubert Merrick",
            "Tomás Tinoco De Rubira"
        ],
        "summary": "We introduce MOS, a software application designed to facilitate the deployment, integration, management, and analysis of mathematical optimization models. MOS approaches mathematical optimization at a higher level of abstraction than existing optimization modeling systems, enabling its use with all of them. The sole requirement to harness MOS is a simple annotation of the code specifying the formulation of an optimization model. With this, the model becomes accessible to humans through the automatic generation of a user interface, and to machines through an associated API and client libraries. All this is achieved while avoiding the ad hoc code typically required to obtain such features.",
        "published": "2022-10-07T20:50:53Z",
        "link": "http://arxiv.org/abs/2210.03813v1",
        "categories": [
            "math.OC",
            "cs.MS"
        ]
    },
    {
        "title": "Rieoptax: Riemannian Optimization in JAX",
        "authors": [
            "Saiteja Utpala",
            "Andi Han",
            "Pratik Jawanpuria",
            "Bamdev Mishra"
        ],
        "summary": "We present Rieoptax, an open source Python library for Riemannian optimization in JAX. We show that many differential geometric primitives, such as Riemannian exponential and logarithm maps, are usually faster in Rieoptax than existing frameworks in Python, both on CPU and GPU. We support various range of basic and advanced stochastic optimization solvers like Riemannian stochastic gradient, stochastic variance reduction, and adaptive gradient methods. A distinguishing feature of the proposed toolbox is that we also support differentially private optimization on Riemannian manifolds.",
        "published": "2022-10-10T16:55:32Z",
        "link": "http://arxiv.org/abs/2210.04840v1",
        "categories": [
            "math.OC",
            "cs.LG",
            "cs.MS"
        ]
    },
    {
        "title": "Designing a general library for convolutions",
        "authors": [
            "Floris van Doorn"
        ],
        "summary": "We will discuss our experiences and design decisions obtained from building a formal library for the convolution of two functions. Convolution is a fundamental concept with applications throughout mathematics. We will focus on the design decisions we made to make the convolution general and easy to use, and the incorporation of this development in Lean's mathematical library mathlib.",
        "published": "2022-10-14T10:35:54Z",
        "link": "http://arxiv.org/abs/2210.07693v1",
        "categories": [
            "cs.LO",
            "cs.MS",
            "math.FA",
            "68V20, 42A85, 44A35",
            "F.4.1; G.3"
        ]
    },
    {
        "title": "Automatic Differentiation of Programs with Discrete Randomness",
        "authors": [
            "Gaurav Arya",
            "Moritz Schauer",
            "Frank Schäfer",
            "Chris Rackauckas"
        ],
        "summary": "Automatic differentiation (AD), a technique for constructing new programs which compute the derivative of an original program, has become ubiquitous throughout scientific computing and deep learning due to the improved performance afforded by gradient-based optimization. However, AD systems have been restricted to the subset of programs that have a continuous dependence on parameters. Programs that have discrete stochastic behaviors governed by distribution parameters, such as flipping a coin with probability $p$ of being heads, pose a challenge to these systems because the connection between the result (heads vs tails) and the parameters ($p$) is fundamentally discrete. In this paper we develop a new reparameterization-based methodology that allows for generating programs whose expectation is the derivative of the expectation of the original program. We showcase how this method gives an unbiased and low-variance estimator which is as automated as traditional AD mechanisms. We demonstrate unbiased forward-mode AD of discrete-time Markov chains, agent-based models such as Conway's Game of Life, and unbiased reverse-mode AD of a particle filter. Our code package is available at https://github.com/gaurav-arya/StochasticAD.jl.",
        "published": "2022-10-16T16:05:50Z",
        "link": "http://arxiv.org/abs/2210.08572v3",
        "categories": [
            "cs.LG",
            "cs.MS",
            "cs.NA",
            "math.NA",
            "math.PR"
        ]
    },
    {
        "title": "Development of information system suited for statistical analysis of   global brands distributions",
        "authors": [
            "Vladyslav Solohub"
        ],
        "summary": "This qualification work studies methods of statistical analysis of global brands distributions and development process of information system which is represented by computer program. Algorithm of estimation of correspondance to distribution laws was shown. Correspondance of datasets (3) to Pareto Law and Zipf's Law were defined.   Key words: analysis, method, distribution, data, function, statistics, solution, program.",
        "published": "2022-10-19T10:24:17Z",
        "link": "http://arxiv.org/abs/2210.11409v1",
        "categories": [
            "stat.AP",
            "cs.MS"
        ]
    },
    {
        "title": "Fast Evaluation of Real and Complex Polynomials",
        "authors": [
            "Ramona Anton",
            "Nicolae Mihalache",
            "François Vigneron"
        ],
        "summary": "We propose an algorithm for quickly evaluating polynomials. It pre-conditions a complex polynomial $P$ of degree $d$ in time $O(d\\log d)$, with a low multiplicative constant independent of the precision. Subsequent evaluations of $P$ computed with a fixed precision of $p$ bits are performed in average arithmetic complexity $O\\big(\\sqrt{d(p+\\log d)}\\big)$ and memory $O(dp)$. The average complexity is computed with respect to points $z \\in \\mathbb{C}$, weighted by the spherical area of $\\overline{\\mathbb{C}}$. The worst case does not exceed the complexity of H{\\\"o}rner's scheme. In particular, our algorithm performs asymptotically as $O(\\sqrt{d\\log d})$ per evaluation. For many classes of polynomials, in particular those with random coefficients in a bounded region of $\\mathbb{C}$, or for sparse polynomials, our algorithm performs much better than this upper bound, without any modification or parameterization.The article contains a detailed analysis of the complexity and a full error analysis, which guarantees that the algorithm performs as well as H\\''orner's scheme, only faster. Our algorithm is implemented in a companion library, written in standard C and released as an open-source project [MV22].Our claims regarding complexity and accuracy are confirmed in practice by a set of comprehensive benchmarks.",
        "published": "2022-10-20T06:35:25Z",
        "link": "http://arxiv.org/abs/2211.06320v1",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA",
            "math.DS"
        ]
    },
    {
        "title": "End-to-end GPU acceleration of low-order-refined preconditioning for   high-order finite element discretizations",
        "authors": [
            "Will Pazner",
            "Tzanio Kolev",
            "Jean-Sylvain Camier"
        ],
        "summary": "In this paper, we present algorithms and implementations for the end-to-end GPU acceleration of matrix-free low-order-refined preconditioning of high-order finite element problems. The methods described here allow for the construction of effective preconditioners for high-order problems with optimal memory usage and computational complexity. The preconditioners are based on the construction of a spectrally equivalent low-order discretization on a refined mesh, which is then amenable to, for example, algebraic multigrid preconditioning. The constants of equivalence are independent of mesh size and polynomial degree. For vector finite element problems in $H({\\rm curl})$ and $H({\\rm div})$ (e.g. for electromagnetic or radiation diffusion problems) a specially constructed interpolation-histopolation basis is used to ensure fast convergence. Detailed performance studies are carried out to analyze the efficiency of the GPU algorithms. The kernel throughput of each of the main algorithmic components is measured, and the strong and weak parallel scalability of the methods is demonstrated. The different relative weighting and significance of the algorithmic components on GPUs and CPUs is discussed. Results on problems involving adaptively refined nonconforming meshes are shown, and the use of the preconditioners on a large-scale magnetic diffusion problem using all spaces of the finite element de Rham complex is illustrated.",
        "published": "2022-10-21T21:12:57Z",
        "link": "http://arxiv.org/abs/2210.12253v1",
        "categories": [
            "cs.MS",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Mapping Out the HPC Dependency Chaos",
        "authors": [
            "Farid Zakaria",
            "Thomas R. W. Scogland",
            "Todd Gamblin",
            "Carlos Maltzahn"
        ],
        "summary": "High Performance Computing~(HPC) software stacks have become complex, with the dependencies of some applications numbering in the hundreds. Packaging, distributing, and administering software stacks of that scale is a complex undertaking anywhere. HPC systems deal with esoteric compilers, hardware, and a panoply of uncommon combinations. In this paper, we explore the mechanisms available for packaging software to find its own dependencies in the context of a taxonomy of software distribution, and discuss their benefits and pitfalls. We discuss workarounds for some common problems caused by using these composed stacks and introduce Shrinkwrap: A solution to producing binaries that directly load their dependencies from precise locations and in a precise order. Beyond simplifying the use of the binaries, this approach also speeds up loading as much as 7x for a large dynamically-linked MPI application in our evaluation.",
        "published": "2022-10-22T20:50:10Z",
        "link": "http://arxiv.org/abs/2211.05118v2",
        "categories": [
            "cs.SE",
            "cs.MS"
        ]
    },
    {
        "title": "Redistributor: Transforming Empirical Data Distributions",
        "authors": [
            "Pavol Harar",
            "Dennis Elbrächter",
            "Monika Dörfler",
            "Kory D. Johnson"
        ],
        "summary": "We present an algorithm and package, Redistributor, which forces a collection of scalar samples to follow a desired distribution. When given independent and identically distributed samples of some random variable $S$ and the continuous cumulative distribution function of some desired target $T$, it provably produces a consistent estimator of the transformation $R$ which satisfies $R(S)=T$ in distribution. As the distribution of $S$ or $T$ may be unknown, we also include algorithms for efficiently estimating these distributions from samples. This allows for various interesting use cases in image processing, where Redistributor serves as a remarkably simple and easy-to-use tool that is capable of producing visually appealing results. For color correction it outperforms other model-based methods and excels in achieving photorealistic style transfer, surpassing deep learning methods in content preservation. The package is implemented in Python and is optimized to efficiently handle large datasets, making it also suitable as a preprocessing step in machine learning. The source code is available at https://github.com/paloha/redistributor.",
        "published": "2022-10-25T17:59:03Z",
        "link": "http://arxiv.org/abs/2210.14219v2",
        "categories": [
            "cs.CV",
            "cs.MS"
        ]
    },
    {
        "title": "IM: An R-Package for Computation of Image Moments and Moment Invariants",
        "authors": [
            "Allison Irvine",
            "Tan Dang",
            "M. Murat Dundar",
            "Bartek Rajwa"
        ],
        "summary": "Moment invariants are well-established and effective shape descriptors for image classification. In this report, we introduce a package for R-language, named IM, that implements the calculation of moments for images and allows the reconstruction of images from moments within an object-oriented framework. Several types of moments may be computed using the IM library, including discrete and continuous Chebyshev, Gegenbauer, Legendre, Krawtchouk, dual Hahn, generalized pseudo-Zernike, Fourier-Mellin, and radial harmonic Fourier moments. In addition, custom bivariate types of moments can be calculated using combinations of two different types of polynomials. A method of polar transformation of pixel coordinates is used to provide an approximate invariance to rotation for moments that are orthogonal over a rectangle. The different types of polynomials used to calculate moments are discussed in this report, as well as comparisons of reconstruction and running time. Examples of image classification using image moments are provided.",
        "published": "2022-10-29T03:54:37Z",
        "link": "http://arxiv.org/abs/2210.16485v1",
        "categories": [
            "cs.CV",
            "cs.MS",
            "I.4.7"
        ]
    },
    {
        "title": "Exploiting Kronecker structure in exponential integrators: fast   approximation of the action of $\\varphi$-functions of matrices via quadrature",
        "authors": [
            "Matteo Croci",
            "Judit Muñoz-Matute"
        ],
        "summary": "In this article, we propose an algorithm for approximating the action of $\\varphi-$functions of matrices against vectors, which is a key operation in exponential time integrators. In particular, we consider matrices with Kronecker sum structure, which arise from problems admitting a tensor product representation. The method is based on quadrature approximations of the integral form of the $\\varphi-$functions combined with a scaling and modified squaring method. Owing to the Kronecker sum representation, only actions of 1D matrix exponentials are needed at each quadrature node and assembly of the full matrix can be avoided. Additionally, we derive \\emph{a priori} bounds for the quadrature error, which show that, as expected by classical theory, the rate of convergence of our method is supergeometric. Guided by our analysis, we construct a fast and robust method for estimating the optimal scaling factor and number of quadrature nodes that minimizes the total cost for a prescribed error tolerance. We investigate the performance of our algorithm by solving several linear and semilinear time-dependent problems in 2D and 3D. The results show that our method is accurate and orders of magnitude faster than the current state-of-the-art.",
        "published": "2022-11-01T18:40:50Z",
        "link": "http://arxiv.org/abs/2211.00696v1",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "Advanced Automatic Code Generation for Multiple Relaxation-Time Lattice   Boltzmann Methods",
        "authors": [
            "Frederik Hennig",
            "Markus Holzer",
            "Ulrich Rüde"
        ],
        "summary": "The scientific code generation package lbmpy supports the automated design and the efficient implementation of lattice Boltzmann methods (LBMs) through metaprogramming. It is based on a new, concise calculus for describing multiple relaxation-time LBMs, including techniques that enable the numerically advantageous subtraction of the constant background component from the populations. These techniques are generalized to a wide range of collision spaces and equilibrium distributions. The article contains an overview of lbmpy's front-end and its code generation pipeline, which implements the new LBM calculus by means of symbolic formula manipulation tools and object-oriented programming. The generated codes have only a minimal number of arithmetic operations. Their automatic derivation rests on two novel Chimera transforms that have been specifically developed for efficiently computing raw and central moments. Information contained in the symbolic representation of the methods is further exploited in a customized sequence of algebraic simplifications, further reducing computational cost. When combined, these algebraic transformations lead to concise and compact numerical kernels. Specifically, with these optimizations, the advanced central moment- and cumulant-based methods can be realized with only little additional cost as when compared with the simple BGK method. The effectiveness and flexibility of the new lbmpy code generation system is demonstrated in simulating Taylor-Green vortex decay and the automatic derivation of an LBM algorithm to solve the shallow water equations.",
        "published": "2022-11-04T13:20:19Z",
        "link": "http://arxiv.org/abs/2211.02435v1",
        "categories": [
            "cs.MS",
            "cs.CE",
            "cs.NA",
            "math.NA",
            "physics.comp-ph"
        ]
    },
    {
        "title": "scikit-fda: A Python Package for Functional Data Analysis",
        "authors": [
            "Carlos Ramos-Carreño",
            "José Luis Torrecilla",
            "Miguel Carbajo-Berrocal",
            "Pablo Marcos",
            "Alberto Suárez"
        ],
        "summary": "The library scikit-fda is a Python package for Functional Data Analysis (FDA). It provides a comprehensive set of tools for representation, preprocessing, and exploratory analysis of functional data. The library is built upon and integrated in Python's scientific ecosystem. In particular, it conforms to the scikit-learn application programming interface so as to take advantage of the functionality for machine learning provided by this package: pipelines, model selection, and hyperparameter tuning, among others. The scikit-fda package has been released as free and open-source software under a 3-Clause BSD license and is open to contributions from the FDA community. The library's extensive documentation includes step-by-step tutorials and detailed examples of use.",
        "published": "2022-11-04T16:34:03Z",
        "link": "http://arxiv.org/abs/2211.02566v2",
        "categories": [
            "stat.CO",
            "cs.LG",
            "cs.MS",
            "stat.ML"
        ]
    },
    {
        "title": "Performance of explicit and IMEX MRI multirate methods on complex   reactive flow problems within modern parallel adaptive structured grid   frameworks",
        "authors": [
            "John J. Loffeld",
            "Andy Nonaka",
            "Daniel R. Reynolds",
            "David J. Gardner",
            "Carol S. Woodward"
        ],
        "summary": "Large-scale multiphysics simulations are computationally challenging due to the coupling of multiple processes with widely disparate time scales. The advent of exascale computing systems exacerbates these challenges, since these enable ever increasing size and complexity. Recently, there has been renewed interest in developing multirate methods as a means to handle the large range of time scales, as these methods may afford greater accuracy and efficiency than more traditional approaches of using IMEX and low-order operator splitting schemes. However, there have been few performance studies that compare different classes of multirate integrators on complex application problems. We study the performance of several newly developed multirate infinitesimal (MRI) methods, implemented in the SUNDIALS solver package, on two reacting flow model problems built on structured mesh frameworks. The first model revisits the work of Emmet et al. (2014) on a compressible reacting flow problem with complex chemistry that is implemented using BoxLib but where we now include comparisons between a new explicit MRI scheme with the multirate spectral deferred correction (SDC) methods in the original paper. The second problem uses the same complex chemistry as the first problem, combined with a simplified flow model, but run at a large spatial scale where explicit methods become infeasible due to stability constraints. Two recently developed implicit-explicit MRI multirate methods are tested. These methods rely on advanced features of the AMReX framework on which the model is built, such as multilevel grids and multilevel preconditioners. The results from these two problems show that MRI multirate methods can offer significant performance benefits on complex multiphysics application problems and that these methods may be combined with advanced spatial discretization to compound the advantages of both.",
        "published": "2022-11-07T04:20:43Z",
        "link": "http://arxiv.org/abs/2211.03293v1",
        "categories": [
            "math.NA",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "TorchOpt: An Efficient Library for Differentiable Optimization",
        "authors": [
            "Jie Ren",
            "Xidong Feng",
            "Bo Liu",
            "Xuehai Pan",
            "Yao Fu",
            "Luo Mai",
            "Yaodong Yang"
        ],
        "summary": "Recent years have witnessed the booming of various differentiable optimization algorithms. These algorithms exhibit different execution patterns, and their execution needs massive computational resources that go beyond a single CPU and GPU. Existing differentiable optimization libraries, however, cannot support efficient algorithm development and multi-CPU/GPU execution, making the development of differentiable optimization algorithms often cumbersome and expensive. This paper introduces TorchOpt, a PyTorch-based efficient library for differentiable optimization. TorchOpt provides a unified and expressive differentiable optimization programming abstraction. This abstraction allows users to efficiently declare and analyze various differentiable optimization programs with explicit gradients, implicit gradients, and zero-order gradients. TorchOpt further provides a high-performance distributed execution runtime. This runtime can fully parallelize computation-intensive differentiation operations (e.g. tensor tree flattening) on CPUs / GPUs and automatically distribute computation to distributed devices. Experimental results show that TorchOpt achieves $5.2\\times$ training time speedup on an 8-GPU server. TorchOpt is available at: https://github.com/metaopt/torchopt/.",
        "published": "2022-11-13T15:59:17Z",
        "link": "http://arxiv.org/abs/2211.06934v1",
        "categories": [
            "cs.MS",
            "cs.AI",
            "cs.DC",
            "cs.LG",
            "math.OC"
        ]
    },
    {
        "title": "Compiling Structured Tensor Algebra",
        "authors": [
            "Mahdi Ghorbani",
            "Mathieu Huot",
            "Shideh Hashemian",
            "Amir Shaikhha"
        ],
        "summary": "Tensor algebra is essential for data-intensive workloads in various computational domains. Computational scientists face a trade-off between the specialization degree provided by dense tensor algebra and the algorithmic efficiency that leverages the structure provided by sparse tensors. This paper presents StructTensor, a framework that symbolically computes structure at compilation time. This is enabled by Structured Tensor Unified Representation (STUR), an intermediate language that can capture tensor computations as well as their sparsity and redundancy structures. Through a mathematical view of lossless tensor computations, we show that our symbolic structure computation and the related optimizations are sound. Finally, for different tensor computation workloads and structures, we experimentally show how capturing the symbolic structure can result in outperforming state-of-the-art frameworks for both dense and sparse tensor algebra.",
        "published": "2022-11-18T19:31:58Z",
        "link": "http://arxiv.org/abs/2211.10482v1",
        "categories": [
            "cs.PL",
            "cs.MS",
            "cs.SC"
        ]
    },
    {
        "title": "Parametric information geometry with the package Geomstats",
        "authors": [
            "Alice Le Brigant",
            "Jules Deschamps",
            "Antoine Collas",
            "Nina Miolane"
        ],
        "summary": "We introduce the information geometry module of the Python package Geomstats. The module first implements Fisher-Rao Riemannian manifolds of widely used parametric families of probability distributions, such as normal, gamma, beta, Dirichlet distributions, and more. The module further gives the Fisher-Rao Riemannian geometry of any parametric family of distributions of interest, given a parameterized probability density function as input. The implemented Riemannian geometry tools allow users to compare, average, interpolate between distributions inside a given family. Importantly, such capabilities open the door to statistics and machine learning on probability distributions. We present the object-oriented implementation of the module along with illustrative examples and show how it can be used to perform learning on manifolds of parametric probability distributions.",
        "published": "2022-11-21T16:56:45Z",
        "link": "http://arxiv.org/abs/2211.11643v1",
        "categories": [
            "cs.LG",
            "cs.MS"
        ]
    },
    {
        "title": "A framework for structural shape optimization based on automatic   differentiation, the adjoint method and accelerated linear algebra",
        "authors": [
            "Gaoyuan Wu"
        ],
        "summary": "Shape optimization is of great significance in structural engineering, as an efficient geometry leads to better performance of structures. However, the application of gradient-based shape optimization for structural and architectural design is limited, which is partly due to the difficulty and the complexity in gradient evaluation. In this work, an efficient framework based on automatic differentiation (AD), the adjoint method and accelerated linear algebra (XLA) is proposed to promote the implementation of gradient-based shape optimization. The framework is realized by the implementation of the high-performance computing (HPC) library JAX. We leverage AD for gradient evaluation in the sensitivity analysis stage. Compared to numerical differentiation, AD is more accurate; compared to analytical and symbolic differentiation, AD is more efficient and easier to apply. In addition, the adjoint method is used to reduce the complexity of computation of the sensitivity. The XLA feature is exploited by an efficient programming architecture that we proposed, which can boost gradient evaluation. The proposed framework also supports hardware acceleration such as GPUs. The framework is applied to the form finding of arches and different free-form gridshells: gridshell inspired by Mannheim Multihalle, four-point supported gridshell, and canopy-like structures. Two geometric descriptive methods are used: non-parametric and parametric description via B\\'ezier surface. Non-constrained and constrained shape optimization problems are considered, where the former is solved by gradient descent and the latter is solved by sequential quadratic programming (SQP). Through these examples, the proposed framework is shown to be able to provide structural engineers with a more efficient tool for shape optimization, enabling better design for the built environment.",
        "published": "2022-11-23T21:42:43Z",
        "link": "http://arxiv.org/abs/2211.15409v1",
        "categories": [
            "cs.MS",
            "cs.CE",
            "math.OC"
        ]
    },
    {
        "title": "Development of an Equation-based Parallelization Method for Multiphase   Particle-in-Cell Simulations",
        "authors": [
            "Mino Woo",
            "Terry Jordan",
            "Tarak Nandi",
            "Jean Francois Dietiker",
            "Christopher Guenther",
            "Dirk Van Essendelft"
        ],
        "summary": "Manufacturers have been developing new graphics processing unit (GPU) nodes with large capacity, high bandwidth memory and very high bandwidth intra-node interconnects. This enables moving large amounts of data between GPUs on the same node at low cost. However, small packet bandwidths and latencies have not decreased which makes global dot products expensive. These characteristics favor a new kind of problem decomposition called \"equation decomposition\" rather than traditional domain decomposition. In this approach, each GPU is assigned one equation set to solve in parallel so that the frequent and expensive dot product synchronization points in traditional distributed linear solvers are eliminated. In exchange, the method involves infrequent movement of state variables over the high bandwidth, intra-node interconnects. To test this theory, our flagship code Multiphase Flow with Interphase eXchanges (MFiX) was ported to TensorFlow. This new product is known as MFiX-AI and can produce near identical results to the original version of MFiX with significant acceleration in multiphase particle-in-cell (MP-PIC) simulations. The performance of a single node with 4 NVIDIA A100s connected over NVLINK 2.0 was shown to be competitive to 1000 CPU cores (25 nodes) on the JOULE 2.0 supercomputer, leading to an energy savings of up to 90%. This is a substantial performance benefit for small- to intermediate-sized problems. This benefit is expected to grow as GPU nodes become more powerful. Further, MFiX-AI is poised to accept native artificial intelligence/machine learning models for further acceleration and development.",
        "published": "2022-11-28T18:02:06Z",
        "link": "http://arxiv.org/abs/2211.15605v1",
        "categories": [
            "cs.DC",
            "cs.MS",
            "cs.SE"
        ]
    },
    {
        "title": "JAX-FEM: A differentiable GPU-accelerated 3D finite element solver for   automatic inverse design and mechanistic data science",
        "authors": [
            "Tianju Xue",
            "Shuheng Liao",
            "Zhengtao Gan",
            "Chanwook Park",
            "Xiaoyu Xie",
            "Wing Kam Liu",
            "Jian Cao"
        ],
        "summary": "This paper introduces JAX-FEM, an open-source differentiable finite element method (FEM) library. Constructed on top of Google JAX, a rising machine learning library focusing on high-performance numerical computing, JAX-FEM is implemented with pure Python while scalable to efficiently solve problems with moderate to large sizes. For example, in a 3D tensile loading problem with 7.7 million degrees of freedom, JAX-FEM with GPU achieves around 10$\\times$ acceleration compared to a commercial FEM code depending on platform. Beyond efficiently solving forward problems, JAX-FEM employs the automatic differentiation technique so that inverse problems are solved in a fully automatic manner without the need to manually derive sensitivities. Examples of 3D topology optimization of nonlinear materials are shown to achieve optimal compliance. Finally, JAX-FEM is an integrated platform for machine learning-aided computational mechanics. We show an example of data-driven multi-scale computations of a composite material where JAX-FEM provides an all-in-one solution from microscopic data generation and model training to macroscopic FE computations. The source code of the library and these examples are shared with the community to facilitate computational mechanics research.",
        "published": "2022-12-02T04:39:14Z",
        "link": "http://arxiv.org/abs/2212.00964v1",
        "categories": [
            "cs.MS",
            "cs.CE"
        ]
    },
    {
        "title": "CDOpt: A Python Package for a Class of Riemannian Optimization",
        "authors": [
            "Nachuan Xiao",
            "Xiaoyin Hu",
            "Xin Liu",
            "Kim-Chuan Toh"
        ],
        "summary": "Optimization over the embedded submanifold defined by constraints $c(x) = 0$ has attracted much interest over the past few decades due to its wide applications in various areas. Plenty of related optimization packages have been developed based on Riemannian optimization approaches, which rely on some basic geometrical materials of Riemannian manifolds, including retractions, vector transports, etc. These geometrical materials can be challenging to determine in general. Existing packages only accommodate a few well-known manifolds whose geometrical materials are easily accessible. For other manifolds which are not contained in these packages, the users have to develop the geometric materials by themselves. In addition, it is not always tractable to adopt advanced features from various state-of-the-art unconstrained optimization solvers to Riemannian optimization approaches.   We introduce CDOpt (available at https://cdopt.github.io/), a user-friendly Python package for a class Riemannian optimization. Based on constraint dissolving approaches, Riemannian optimization problems are transformed into their equivalent unconstrained counterparts in CDOpt. Therefore, solving Riemannian optimization problems through CDOpt directly benefits from various existing solvers and the rich expertise gained over decades for unconstrained optimization. Moreover, all the computations in CDOpt related to any manifold in question are conducted on its constraints expression, hence users can easily define new manifolds in CDOpt without any background on differential geometry. Furthermore, CDOpt extends the neural layers from PyTorch and Flax, thus allows users to train manifold constrained neural networks directly by the solvers for unconstrained optimization. Extensive numerical experiments demonstrate that CDOpt is highly efficient and robust in solving various classes of Riemannian optimization problems.",
        "published": "2022-12-06T01:43:29Z",
        "link": "http://arxiv.org/abs/2212.02698v3",
        "categories": [
            "math.OC",
            "cs.MS"
        ]
    },
    {
        "title": "Parallelism detection using graph labelling",
        "authors": [
            "Pavel Telegin",
            "Anton Baranov",
            "Boris Shabanov",
            "Artem Tikhomirov"
        ],
        "summary": "Usage of multiprocessor and multicore computers implies parallel programming. Tools for preparing parallel programs include parallel languages and libraries as well as parallelizing compilers and convertors that can perform automatic parallelization. The basic approach for parallelism detection is analysis of data dependencies and properties of program components, including data use and predicates. In this article a suite of used data and predicates sets for program components is proposed and an algorithm for computing these sets is suggested. The algorithm is based on wave propagation on graphs with cycles and labelling. This method allows analyzing complex program components, improving data localization and thus providing enhanced data parallelism detection.",
        "published": "2022-12-09T12:46:24Z",
        "link": "http://arxiv.org/abs/2212.04818v1",
        "categories": [
            "cs.MS",
            "68W10",
            "D.1.3"
        ]
    },
    {
        "title": "Optimized Sparse Matrix Operations for Reverse Mode Automatic   Differentiation",
        "authors": [
            "Nicolas Nytko",
            "Ali Taghibakhshi",
            "Tareq Uz Zaman",
            "Scott MacLachlan",
            "Luke N. Olson",
            "Matt West"
        ],
        "summary": "Sparse matrix representations are ubiquitous in computational science and machine learning, leading to significant reductions in compute time, in comparison to dense representation, for problems that have local connectivity. The adoption of sparse representation in leading ML frameworks such as PyTorch is incomplete, however, with support for both automatic differentiation and GPU acceleration missing. In this work, we present an implementation of a CSR-based sparse matrix wrapper for PyTorch with CUDA acceleration for basic matrix operations, as well as automatic differentiability. We also present several applications of the resulting sparse kernels to optimization problems, demonstrating ease of implementation and performance measurements versus their dense counterparts.",
        "published": "2022-12-10T00:46:51Z",
        "link": "http://arxiv.org/abs/2212.05159v3",
        "categories": [
            "cs.LG",
            "cs.MS",
            "cs.NA",
            "math.NA"
        ]
    },
    {
        "title": "Scalable Recovery-based Adaptation on Quadtree Meshes for   Advection-Diffusion-Reaction Problems",
        "authors": [
            "Pasquale Claudio Africa",
            "Simona Perotto",
            "Carlo de Falco"
        ],
        "summary": "We propose a mesh adaptation procedure for Cartesian quadtree meshes, to discretize scalar advection-diffusion-reaction problems. The adaptation process is driven by a recovery-based a posteriori estimator for the $L^2(\\Omega)$-norm of the discretization error, based on suitable higher order approximations of both the solution and the associated gradient. In particular, a metric-based approach exploits the information furnished by the estimator to iteratively predict the new adapted mesh. The new mesh adaptation algorithm is successfully assessed on different configurations, and turns out to perform well also when dealing with discontinuities in the data as well as in the presence of internal layers not aligned with the Cartesian directions. A cross-comparison with a standard estimate--mark--refine approach and with other adaptive strategies available in the literature shows the remarkable accuracy and parallel scalability of the proposed approach.",
        "published": "2022-12-12T14:57:02Z",
        "link": "http://arxiv.org/abs/2212.05945v1",
        "categories": [
            "math.NA",
            "cs.DC",
            "cs.DS",
            "cs.MS",
            "cs.NA"
        ]
    },
    {
        "title": "ADEV: Sound Automatic Differentiation of Expected Values of   Probabilistic Programs",
        "authors": [
            "Alexander K. Lew",
            "Mathieu Huot",
            "Sam Staton",
            "Vikash K. Mansinghka"
        ],
        "summary": "Optimizing the expected values of probabilistic processes is a central problem in computer science and its applications, arising in fields ranging from artificial intelligence to operations research to statistical computing. Unfortunately, automatic differentiation techniques developed for deterministic programs do not in general compute the correct gradients needed for widely used solutions based on gradient-based optimization.   In this paper, we present ADEV, an extension to forward-mode AD that correctly differentiates the expectations of probabilistic processes represented as programs that make random choices. Our algorithm is a source-to-source program transformation on an expressive, higher-order language for probabilistic computation, with both discrete and continuous probability distributions. The result of our transformation is a new probabilistic program, whose expected return value is the derivative of the original program's expectation. This output program can be run to generate unbiased Monte Carlo estimates of the desired gradient, which can then be used within the inner loop of stochastic gradient descent. We prove ADEV correct using logical relations over the denotations of the source and target probabilistic programs. Because it modularly extends forward-mode AD, our algorithm lends itself to a concise implementation strategy, which we exploit to develop a prototype in just a few dozen lines of Haskell (https://github.com/probcomp/adev).",
        "published": "2022-12-13T05:54:22Z",
        "link": "http://arxiv.org/abs/2212.06386v1",
        "categories": [
            "cs.PL",
            "cs.MS",
            "stat.CO"
        ]
    },
    {
        "title": "Efficient and Sound Differentiable Programming in a Functional   Array-Processing Language",
        "authors": [
            "Amir Shaikhha",
            "Mathieu Huot",
            "Shabnam Ghasemirad",
            "Andrew Fitzgibbon",
            "Simon Peyton Jones",
            "Dimitrios Vytiniotis"
        ],
        "summary": "Automatic differentiation (AD) is a technique for computing the derivative of a function represented by a program. This technique is considered as the de-facto standard for computing the differentiation in many machine learning and optimisation software tools. Despite the practicality of this technique, the performance of the differentiated programs, especially for functional languages and in the presence of vectors, is suboptimal. We present an AD system for a higher-order functional array-processing language. The core functional language underlying this system simultaneously supports both source-to-source forward-mode AD and global optimisations such as loop transformations. In combination, gradient computation with forward-mode AD can be as efficient as reverse mode, and the Jacobian matrices required for numerical algorithms such as Gauss-Newton and Levenberg-Marquardt can be efficiently computed.",
        "published": "2022-12-20T14:54:47Z",
        "link": "http://arxiv.org/abs/2212.10307v1",
        "categories": [
            "cs.PL",
            "cs.LG",
            "cs.MS"
        ]
    },
    {
        "title": "Reverse-Mode Automatic Differentiation of Compiled Programs",
        "authors": [
            "Max Aehle",
            "Johannes Blühdorn",
            "Max Sagebaum",
            "Nicolas R. Gauger"
        ],
        "summary": "Tools for algorithmic differentiation (AD) provide accurate derivatives of computer-implemented functions for use in, e. g., optimization and machine learning (ML). However, they often require the source code of the function to be available in a restricted set of programming languages. As a step towards making AD accessible for code bases with cross-language or closed-source components, we recently presented the forward-mode AD tool Derivgrind. It inserts forward-mode AD logic into the machine code of a compiled program using the Valgrind dynamic binary instrumentation framework. This work extends Derivgrind, adding the capability to record the real-arithmetic evaluation tree, and thus enabling operator overloading style reverse-mode AD for compiled programs. We maintain the high level of correctness reported for Derivgrind's forward mode, failing the same few testcases in an extensive test suite for the same well-understood reasons. Runtime-wise, the recording slows down the execution of a compiled 64-bit benchmark program by a factor of about 180.",
        "published": "2022-12-28T09:27:02Z",
        "link": "http://arxiv.org/abs/2212.13760v1",
        "categories": [
            "cs.MS"
        ]
    },
    {
        "title": "Exploring the Versal AI engines for accelerating stencil-based   atmospheric advection simulation",
        "authors": [
            "Nick Brown"
        ],
        "summary": "AMD Xilinx's new Versal Adaptive Compute Acceleration Platform (ACAP) is an FPGA architecture combining reconfigurable fabric with other on-chip hardened compute resources. AI engines are one of these and, by operating in a highly vectorized manner, they provide significant raw compute that is potentially beneficial for a range of workloads including HPC simulation. However, this technology is still early-on, and as yet unproven for accelerating HPC codes, with a lack of benchmarking and best practice.   This paper presents an experience report, exploring porting of the Piacsek and Williams (PW) advection scheme onto the Versal ACAP, using the chip's AI engines to accelerate the compute. A stencil-based algorithm, advection is commonplace in atmospheric modelling, including several Met Office codes who initially developed this scheme. Using this algorithm as a vehicle, we explore optimal approaches for structuring AI engine compute kernels and how best to interface the AI engines with programmable logic. Evaluating performance using a VCK5000 against non-AI engine FPGA configurations on the VCK5000 and Alveo U280, as well as a 24-core Xeon Platinum Cascade Lake CPU and Nvidia V100 GPU, we found that whilst the number of channels between the fabric and AI engines are a limitation, by leveraging the ACAP we can double performance compared to an Alveo U280.",
        "published": "2022-12-28T17:28:24Z",
        "link": "http://arxiv.org/abs/2301.13016v1",
        "categories": [
            "cs.DC",
            "cs.MS"
        ]
    },
    {
        "title": "Fast and energy-efficient derivatives risk analysis: Streaming option   Greeks on Xilinx and Intel FPGAs",
        "authors": [
            "Mark Klaisoongnoen",
            "Nick Brown",
            "Oliver Brown"
        ],
        "summary": "Whilst FPGAs have enjoyed success in accelerating high-frequency financial workloads for some time, their use for quantitative finance, which is the use of mathematical models to analyse financial markets and securities, has been far more limited to-date. Currently, CPUs are the most common architecture for such workloads, and an important question is whether FPGAs can ameliorate some of the bottlenecks encountered on those architectures. In this paper we extend our previous work accelerating the industry standard Securities Technology Analysis Center's (STAC\\textregistered) derivatives risk analysis benchmark STAC-A2\\texttrademark{}, by first porting this from our previous Xilinx implementation to an Intel Stratix-10 FPGA, exploring the challenges encountered when moving from one FPGA architecture to another and suitability of techniques. We then present a host-data-streaming approach that ultimately outperforms our previous version on a Xilinx Alveo U280 FPGA by up to 4.6 times and requiring 9 times less energy at the largest problem size, while outperforming the CPU and GPU versions by up to 8.2 and 5.2 times respectively. The result of this work is a significant enhancement in FPGA performance against the previous version for this industry standard benchmark running on both Xilinx and Intel FPGAs, and furthermore an exploration of optimisation and porting techniques that can be applied to other HPC workloads.",
        "published": "2022-12-28T17:51:54Z",
        "link": "http://arxiv.org/abs/2212.13977v2",
        "categories": [
            "cs.DC",
            "cs.AR",
            "cs.MS"
        ]
    },
    {
        "title": "let (rec) insertion without Effects, Lights or Magic",
        "authors": [
            "Oleg Kiselyov",
            "Jeremy Yallop"
        ],
        "summary": "Let insertion in program generation is producing code with definitions (let-statements). Although definitions precede uses in generated code, during code generation `uses' come first: we might not even know a definition is needed until we encounter a reoccurring expression. Definitions are thus generated `in hindsight', which explains why this process is difficult to understand and implement -- even more so for parameterized, recursive and mutually recursive definitions.   We have earlier presented an interface for let(rec) insertion -- i.e. for generating (mutually recursive) definitions. We demonstrated its expressiveness and applications, but not its implementation, which relied on effects and compiler magic.   We now show how one can understand let insertion, and hence implement it in plain OCaml. We give the first denotational semantics of let(rec)-insertion, which does not rely on any effects at all. The formalization has guided the implementation of let(rec) insertion in the current version of MetaOCaml.",
        "published": "2022-01-03T06:32:39Z",
        "link": "http://arxiv.org/abs/2201.00495v1",
        "categories": [
            "cs.PL",
            "cs.SC",
            "F.3.2; D.3.3; D.3.2"
        ]
    },
    {
        "title": "Maximizing the Sum of the Distances between Four Points on the Unit   Hemisphere",
        "authors": [
            "Zhenbing Zeng",
            "Jian Lu",
            "Yaochen Xu",
            "Yuzheng Wang"
        ],
        "summary": "In this paper, we prove a geometrical inequality which states that for any four points on a hemisphere with the unit radius, the largest sum of distances between the points is 4+4*sqrt(2). In our method, we have constructed a rectangular neighborhood of the local maximum point in the feasible set, which size is explicitly determined, and proved that (1): the objective function is bounded by a quadratic polynomial which takes the local maximum point as the unique critical point in the neighborhood, and (2): the rest part of the feasible set can be partitioned into a finite union of a large number of very small cubes so that on each small cube the conjecture can be verified by estimating the objective function with exact numerical computation.",
        "published": "2022-01-03T09:24:53Z",
        "link": "http://arxiv.org/abs/2201.00535v1",
        "categories": [
            "cs.SC",
            "cs.CG",
            "cs.DM",
            "F.2.1; F.2.2; G.1.2"
        ]
    },
    {
        "title": "Mechanization of Incidence Projective Geometry in Higher Dimensions, a   Combinatorial Approach",
        "authors": [
            "Pascal Schreck",
            "Nicolas Magaud",
            "David Braun"
        ],
        "summary": "Several tools have been developed to enhance automation of theorem proving in the 2D plane. However, in 3D, only a few approaches have been studied, and to our knowledge, nothing has been done in higher dimensions. In this paper, we present a few examples of incidence geometry theorems in dimensions 3, 4, and 5. We then prove them with the help of a combinatorial prover based on matroid theory applied to geometry.",
        "published": "2022-01-03T09:26:01Z",
        "link": "http://arxiv.org/abs/2201.00539v1",
        "categories": [
            "cs.CG",
            "cs.MS",
            "cs.SC"
        ]
    },
    {
        "title": "Automated Generation of Illustrations for Synthetic Geometry Proofs",
        "authors": [
            "Predrag Janičić",
            "Julien Narboux"
        ],
        "summary": "We report on a new, simple, modular, and flexible approach for automated generation of illustrations for (readable) synthetic geometry proofs. The underlying proofs are generated using the Larus automated prover for coherent logic, and corresponding illustrations are generated in the GCLC language. Animated illustrations are also supported.",
        "published": "2022-01-03T09:26:18Z",
        "link": "http://arxiv.org/abs/2201.00540v1",
        "categories": [
            "cs.LO",
            "cs.SC"
        ]
    },
    {
        "title": "Spreads and Packings of PG(3,2), Formally!",
        "authors": [
            "Nicolas Magaud"
        ],
        "summary": "We study how to formalize in the Coq proof assistant the smallest projective space PG(3,2). We then describe formally the spreads and packings of PG(3,2), as well as some of their properties. The formalization is rather straightforward, however as the number of objects at stake increases rapidly, we need to exploit some symmetry arguments as well as smart proof techniques to make proof search and verification faster and thus tractable using the Coq proof assistant. This work can be viewed as a first step towards formalizing projective spaces of higher dimension, e.g. PG(4,2), or larger order, e.g. PG(3,3).",
        "published": "2022-01-03T09:26:51Z",
        "link": "http://arxiv.org/abs/2201.00541v1",
        "categories": [
            "cs.LO",
            "cs.SC"
        ]
    },
    {
        "title": "A Method for the Automated Discovery of Angle Theorems",
        "authors": [
            "Philip Todd"
        ],
        "summary": "The Naive Angle Method, used by Geometry Expressions for solving problems which involve only angle constraints, represents a geometrical configuration as a sparse linear system. Linear systems with the same underlying matrix structure underpin a number of different geometrical theorems. We use a graph theoretical approach to define a generalization of the matrix structure.",
        "published": "2022-01-03T09:27:57Z",
        "link": "http://arxiv.org/abs/2201.00543v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "An algebraic attack to the Bluetooth stream cipher E0",
        "authors": [
            "Roberto La Scala",
            "Sergio Polese",
            "Sharwan K. Tiwari",
            "Andrea Visconti"
        ],
        "summary": "In this paper we study the security of the Bluetooth stream cipher E0 from the viewpoint it is a \"difference stream cipher\", that is, it is defined by a system of explicit difference equations over the finite field GF(2). This approach highlights some issues of the Bluetooth encryption such as the invertibility of its state transition map, a special set of 14 bits of its 132-bit state which when guessed implies linear equations among the other bits and finally a small number of spurious keys, with 83 guessed bits, which are compatible with a keystream of about 60 bits. Exploiting these issues, we implement an algebraic attack using Gr\\\"obner bases, SAT solvers and Binary Decision Diagrams. Testing activities suggest that the version based on Gr\\\"obner bases is the best one and it is able to attack E0 in about 2^79 seconds on an Intel i9 CPU. To the best of our knowledge, this work improves any previous attack based on a short keystream, hence fitting with Bluetooth specifications.",
        "published": "2022-01-04T17:53:57Z",
        "link": "http://arxiv.org/abs/2201.01262v2",
        "categories": [
            "cs.CR",
            "cs.SC",
            "math.AC",
            "math.RA",
            "11T71 (Primary) 12H10, 13P10 (Secondary)"
        ]
    },
    {
        "title": "Simple algorithm for GCD of polynomials",
        "authors": [
            "Pasquale Nardone",
            "Giorgio Sonnino"
        ],
        "summary": "Based on the Bezout approach we propose a simple algorithm to determine the {\\tt gcd} of two polynomials which doesn't need division, like the Euclidean algorithm, or determinant calculations, like the Sylvester matrix algorithm. The algorithm needs only $n$ steps for polynomials of degree $n$. Formal manipulations give the discriminant or the resultant for any degree without needing division nor determinant calculation.",
        "published": "2022-01-06T21:49:55Z",
        "link": "http://arxiv.org/abs/2201.06940v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Sparse trace tests",
        "authors": [
            "Taylor Brysiewicz",
            "Michael Burr"
        ],
        "summary": "We establish how the coefficients of a sparse polynomial system influence the sum (or the trace) of its zeros. As an application, we develop numerical tests for verifying whether a set of solutions to a sparse system is complete. These algorithms extend the classical trace test in numerical algebraic geometry. Our results rely on both the analysis of the structure of sparse resultants as well as an extension of Esterov's results on monodromy groups of sparse systems.",
        "published": "2022-01-12T01:55:48Z",
        "link": "http://arxiv.org/abs/2201.04268v1",
        "categories": [
            "math.AG",
            "cs.SC",
            "65H14, 14Q65, 14M25, 68W30"
        ]
    },
    {
        "title": "DPCL: a Language Template for Normative Specifications",
        "authors": [
            "Giovanni Sileno",
            "Thomas van Binsbergen",
            "Matteo Pascucci",
            "Tom van Engers"
        ],
        "summary": "Several solutions for specifying normative artefacts (norms, contracts, policies) in a computational processable way have been presented in the literature. Legal core ontologies have been proposed to systematize concepts and relationships relevant to normative reasoning. However, no solution amongst those has achieved general acceptance, and no common ground (representational, computational) has been identified enabling us to easily compare them. Yet, all these efforts share the same motivation of representing normative directives, therefore it is plausible that there may be a representational model encompassing all of them. This presentation will introduce DPCL, a domain-specific language (DSL) for specifying higher-level policies (including norms, contracts, etc.), centred on Hohfeld's framework of fundamental legal concepts. DPCL has to be seen primarily as a \"template\", i.e. as an informational model for architectural reference, rather than a fully-fledged formal language; it aims to make explicit the general requirements that should be expected in a language for norm specification. In this respect, it goes rather in the direction of legal core ontologies, but differently from those, our proposal aims to keep the character of a DSL, rather than a set of axioms in a logical framework: it is meant to be cross-compiled to underlying languages/tools adequate to the type of target application. We provide here an overview of some of the language features.",
        "published": "2022-01-12T13:51:11Z",
        "link": "http://arxiv.org/abs/2201.04477v1",
        "categories": [
            "cs.AI",
            "cs.FL",
            "cs.MA",
            "cs.PL",
            "cs.SC"
        ]
    },
    {
        "title": "Concatenations of Terms of an Arithmetic Progression",
        "authors": [
            "Florian Luca",
            "Bertrand Teguia Tabuguia"
        ],
        "summary": "Let $\\left(u(n)\\right)_{n\\in\\mathbb{N}}$ be an arithmetic progression of natural integers in base $b\\in\\mathbb{N}\\setminus \\{0,1\\}$. We consider the following sequences: $s(n)=\\overline{u(0)u(1)\\cdots u(n) }^b$ formed by concatenating the first $n+1$ terms of $\\left(u(n)\\right)_{n\\in\\mathbb{N}}$ in base $b$ from the right; $s_r(n) = \\overline{u(n)u(n-1)\\cdots u(0)}^b$; and $\\left(s_*(n)\\right)_{n\\in\\mathbb{N}}$, given by $s_*(0)=u(0)$, $s_*(n)=\\overline{s_r(n-1)s(n)}^b, n\\geq 1$. We construct explicit formulas for these sequences and use basic concepts of linear difference operators to prove they are not P-recursive (holonomic). We also present an alternative proof that follows directly from their definitions. We implemented $\\left(s(n)\\right)_{n\\in\\mathbb{N}}$ and $\\left(s_r(n)\\right)_{n\\in\\mathbb{N}}$ in the decimal base when $(u(n))_{n\\in\\mathbb{N}}=\\mathbb{N}\\setminus \\{0\\}$.",
        "published": "2022-01-14T07:53:47Z",
        "link": "http://arxiv.org/abs/2201.07127v2",
        "categories": [
            "math.CO",
            "cs.SC",
            "Primary: 11K31, 11Y55, Secondary: 68W30, 11-04"
        ]
    },
    {
        "title": "Zeon and Idem-Clifford Formulations of Hypergraph Problems",
        "authors": [
            "Samuel Ewing",
            "G. Stacey Staples"
        ],
        "summary": "Zeon algebras have proven to be useful for enumerating structures in graphs, such as paths, trails, cycles, matchings, cliques, and independent sets. In contrast to an ordinary graph, in which each edge connects exactly two vertices, an edge (or, \"hyperedge\") can join any number of vertices in a hypergraph. In game theory, hypergraphs are called simple games. Hypergraphs have been used for problems in biology, chemistry, image processing, wireless networks, and more. In the current work, zeon (\"nil-Clifford\") and \"idem-Clifford\" graph-theoretic methods are generalized to hypergraphs. In particular, zeon and idem-Clifford methods are used to enumerate paths, trails, independent sets, cliques, and matchings in hypergraphs. An approach for finding minimum hypergraph transversals is developed, and zeon formulations of some open hypergraph problems are presented.",
        "published": "2022-01-15T17:34:33Z",
        "link": "http://arxiv.org/abs/2201.05895v1",
        "categories": [
            "math.CO",
            "cs.SC",
            "math.RA"
        ]
    },
    {
        "title": "DFORMPY: A Python Library for visualising and zooming on differential   forms",
        "authors": [
            "Moustafa Gharamti",
            "Maciej Jarema",
            "Samuel Kirwin-Jones"
        ],
        "summary": "We present the v1.0.1 release of DFormPy, the first Python library providing an interactive visualisation of differential forms. DFormPy is also capable of exterior algebra and vector calculus, building on the capabilities of NumPy and matplotlib. This short paper will demonstrate the functionalities of the library, briefly outlining the mathematics involved with our objects and the methods available to the user. DFormPy is an open source library with interactive GUI released under MIT license at https://github.com/MostaphaG/Summer_project-df",
        "published": "2022-01-16T10:51:04Z",
        "link": "http://arxiv.org/abs/2201.10517v1",
        "categories": [
            "cs.SC",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Interval-Memoized Backtracking on ZDDs for Fast Enumeration of All Lower   Cost Solutions",
        "authors": [
            "Shin-ichi Minato",
            "Mutsunori Banbara",
            "Takashi Horiyama",
            "Jun Kawahara",
            "Ichigaku Takigawa",
            "Yutaro Yamaguchi"
        ],
        "summary": "In this paper, we propose a fast method for exactly enumerating a very large number of all lower cost solutions for various combinatorial problems. Our method is based on backtracking for a given decision diagram which represents all the feasible solutions. The main idea is to memoize the intervals of cost bounds to avoid duplicate search in the backtracking process. In contrast to usual pseudo-polynomial-time dynamic programming approaches, the computation time of our method does not directly depend on the total cost values, but is bounded by the input and output size of the decision diagrams. Therefore, it can be much faster if the cost values are large but the input/output decision diagrams are well-compressed. We demonstrate its practical efficiency by comparing our method to current available enumeration methods: for nontrivial size instances of the Hamiltonian path problem, our method succeeded in exactly enumerating billions of all lower cost solutions in a few seconds, which was hundred or much more times faster. Our method can be regarded as a novel search algorithm which integrates the two classical techniques, branch-and-bound and dynamic programming. This method would have many applications in various fields, including operations research, data mining, statistical testing, hardware/software system design, etc.",
        "published": "2022-01-20T11:35:09Z",
        "link": "http://arxiv.org/abs/2201.08118v2",
        "categories": [
            "cs.DS",
            "cs.SC",
            "05C30, 05C85",
            "I.1.3"
        ]
    },
    {
        "title": "Boosting Isomorphic Model Filtering with Invariants",
        "authors": [
            "João Araújo",
            "Choiwah Chow",
            "Mikoláš Janota"
        ],
        "summary": "The enumeration of finite models is very important to the working discrete mathematician (algebra, graph theory, etc) and hence the search for effective methods to do this task is a critical goal in discrete computational mathematics. However, it is hindered by the possible existence of many isomorphic models, which usually only add noise. Typically, they are filtered out {\\em a posteriori}, a step that might take a long time just to discard redundant models. This paper proposes a novel approach to split the generated models into mutually non-isomorphic blocks. To do that we use well-designed hand-crafted invariants as well as randomly generated invariants. The blocks are then tackled separately and possibly in parallel. This approach is integrated into Mace4 (the most popular tool among mathematicians) where it shows tremendous speed-ups for a large variety of algebraic structures.",
        "published": "2022-01-21T11:18:30Z",
        "link": "http://arxiv.org/abs/2201.10516v1",
        "categories": [
            "cs.SC",
            "cs.LO"
        ]
    },
    {
        "title": "ODEbase: A Repository of ODE Systems for Systems Biology",
        "authors": [
            "Christoph Lüders",
            "Thomas Sturm",
            "Ovidiu Radulescu"
        ],
        "summary": "Recently, symbolic computation and computer algebra systems have been successfully applied in systems biology, especially in chemical reaction network theory. One advantage of symbolic computation is its potential for qualitative answers to biological questions. Qualitative methods analyze dynamical input systems as formal objects, in contrast to investigating only part of the state space, as is the case with numerical simulation. However, symbolic computation tools and libraries have a different set of requirements for their input data than their numerical counterparts. A common format used in mathematical modeling of biological processes is SBML. We illustrate that the use of SBML data in symbolic computation requires significant pre-processing, incorporating external biological and mathematical expertise. ODEbase provides high quality symbolic computation input data derived from established existing biomodels, covering in particular the BioModels database.",
        "published": "2022-01-22T07:22:01Z",
        "link": "http://arxiv.org/abs/2201.08980v1",
        "categories": [
            "q-bio.MN",
            "cs.SC"
        ]
    },
    {
        "title": "A simple and constructive proof to a generalization of Lüroth's   theorem",
        "authors": [
            "François Ollivier",
            "Brahim Sadik"
        ],
        "summary": "A generalization of L{\\\"u}roth's theorem expresses that every transcendence degree 1 subfield of the rational function field is a simple extension. In this note we show that a classical proof of this theorem also holds to prove this generalization.",
        "published": "2022-01-25T11:23:49Z",
        "link": "http://arxiv.org/abs/2201.11733v2",
        "categories": [
            "math.AC",
            "cs.SC",
            "math.NT",
            "12F20, 68W30, 12-08, 14Q05",
            "I.1"
        ]
    },
    {
        "title": "A Special Case of Schematic Syntactic Unification",
        "authors": [
            "David M. Cerna"
        ],
        "summary": "We present a unification problem based on first-order syntactic unification which ask whether every problem in a schematically-defined sequence of unification problems is unifiable, so called loop unification. Alternatively, our problem may be formulated as a recursive procedure calling first-order syntactic unification on certain bindings occurring in the solved form resulting from unification. Loop unification is closely related to Narrowing as the schematic constructions can be seen as a rewrite rule applied during unification, and primal grammars, as we deal with recursive term constructions. However, loop unification relaxes the restrictions put on variables as fresh as well as used extra variables may be introduced by rewriting. In this work we consider an important special case, so called semiloop unification. We provide a sufficient condition for unifiability of the entire sequence based on the structure of a sufficiently long initial segment. It remains an open question whether this condition is also necessary for semiloop unification and how it may be extended to loop unification.",
        "published": "2022-01-25T13:15:03Z",
        "link": "http://arxiv.org/abs/2201.10298v1",
        "categories": [
            "cs.LO",
            "cs.SC"
        ]
    },
    {
        "title": "Rational Solutions of First Order Algebraic Ordinary Differential   Equations",
        "authors": [
            "Shuang Feng",
            "Li-Yong Shen"
        ],
        "summary": "Let $f(t,y,y')=\\sum_{i=0}^n a_i(t,y)y'^i=0$ be an irreducible first order ordinary differential equation with polynomial coefficients. Eremenko in 1998 proved that there exists a constant $C$ such that every rational solution of $f(t,y,y')=0$ is of degree not greater than $C$. Examples show that this degree bound $C$ depends not only on the degrees of $f$ in $t,y,y'$ but also on the coefficients of $f$ viewed as the polynomial in $t,y,y'$. In this paper, we show that if $f$ satisfies $deg(f,y)<deg(f,y')$ or $\\max_{i=0}^n \\{deg(a_i,y)-2(n-i)\\}>0 $ then the degree bound $C$ only depends on the degrees of $f$ in $t,y,y'$, and furthermore we present an explicit expression for $C$ in terms of the degrees of $f$ in $t,y,y'$.",
        "published": "2022-01-27T08:38:04Z",
        "link": "http://arxiv.org/abs/2201.11378v1",
        "categories": [
            "math.CA",
            "cs.SC"
        ]
    },
    {
        "title": "Reasoning Like Program Executors",
        "authors": [
            "Xinyu Pi",
            "Qian Liu",
            "Bei Chen",
            "Morteza Ziyadi",
            "Zeqi Lin",
            "Qiang Fu",
            "Yan Gao",
            "Jian-Guang Lou",
            "Weizhu Chen"
        ],
        "summary": "Reasoning over natural language is a long-standing goal for the research community. However, studies have shown that existing language models are inadequate in reasoning. To address the issue, we present POET, a novel reasoning pre-training paradigm. Through pre-training language models with programs and their execution results, POET empowers language models to harvest the reasoning knowledge possessed by program executors via a data-driven approach. POET is conceptually simple and can be instantiated by different kinds of program executors. In this paper, we showcase two simple instances POET-Math and POET-Logic, in addition to a complex instance, POET-SQL. Experimental results on six benchmarks demonstrate that POET can significantly boost model performance in natural language reasoning, such as numerical reasoning, logical reasoning, and multi-hop reasoning. POET opens a new gate on reasoning-enhancement pre-training, and we hope our analysis would shed light on the future research of reasoning like program executors.",
        "published": "2022-01-27T12:28:24Z",
        "link": "http://arxiv.org/abs/2201.11473v2",
        "categories": [
            "cs.CL",
            "cs.AI",
            "cs.SC"
        ]
    },
    {
        "title": "Symbolic-Numeric Integration of Univariate Expressions based on Sparse   Regression",
        "authors": [
            "Shahriar Iravanian",
            "Carl Julius Martensen",
            "Alessandro Cheli",
            "Shashi Gowda",
            "Anand Jain",
            "Yingbo Ma",
            "Chris Rackauckas"
        ],
        "summary": "Most computer algebra systems (CAS) support symbolic integration as core functionality. The majority of the integration packages use a combination of heuristic algebraic and rule-based (integration table) methods. In this paper, we present a hybrid (symbolic-numeric) methodology to calculate the indefinite integrals of univariate expressions. The primary motivation for this work is to add symbolic integration functionality to a modern CAS (the symbolic manipulation packages of SciML, the Scientific Machine Learning ecosystem of the Julia programming language), which is mainly designed toward numerical and machine learning applications and has a different set of features than traditional CAS. The symbolic part of our method is based on the combination of candidate terms generation (borrowed from the Homotopy operators theory) with rule-based expression transformations provided by the underlying CAS. The numeric part is based on sparse-regression, a component of Sparse Identification of Nonlinear Dynamics (SINDy) technique. We show that this system can solve a large variety of common integration problems using only a few dozen basic integration rules.",
        "published": "2022-01-29T01:30:31Z",
        "link": "http://arxiv.org/abs/2201.12468v2",
        "categories": [
            "cs.SC",
            "I.1.0; I.1.2"
        ]
    },
    {
        "title": "Resultant Tools for Parametric Polynomial Systems with Application to   Population Models",
        "authors": [
            "AmirHosein Sadeghimanesh",
            "Matthew England"
        ],
        "summary": "We are concerned with the problem of decomposing the parameter space of a parametric system of polynomial equations, and possibly some polynomial inequality constraints, with respect to the number of real solutions that the system attains. Previous studies apply a two step approach to this problem, where first the discriminant variety of the system is computed via a Groebner Basis (GB), and then a Cylindrical Algebraic Decomposition (CAD) of this is produced to give the desired computation. However, even on some reasonably small applied examples this process is too expensive, with computation of the discriminant variety alone infeasible. In this paper we develop new approaches to build the discriminant variety using resultant methods (the Dixon resultant and a new method using iterated univariate resultants). This reduces the complexity compared to GB and allows for a previous infeasible example to be tackled. We demonstrate the benefit by giving a symbolic solution to a problem from population dynamics -- the analysis of the steady states of three connected populations which exhibit Allee effects - which previously could only be tackled numerically.",
        "published": "2022-01-31T12:52:59Z",
        "link": "http://arxiv.org/abs/2201.13189v2",
        "categories": [
            "cs.SC",
            "q-bio.PE",
            "92C42, 92D25, 13P15, 68W30",
            "I.1.2; I.1.4; J.3"
        ]
    },
    {
        "title": "Exact linear reduction for rational dynamical systems",
        "authors": [
            "Antonio Jiménez-Pastor",
            "Joshua Paul Jacob",
            "Gleb Pogudin"
        ],
        "summary": "Detailed dynamical systems models used in life sciences may include dozens or even hundreds of state variables. Models of large dimension are not only harder from the numerical perspective (e.g., for parameter estimation or simulation), but it is also becoming challenging to derive mechanistic insights from such models. Exact model reduction is a way to address this issue by finding a self-consistent lower-dimensional projection of the corresponding dynamical system. A recent algorithm CLUE allows one to construct an exact linear reduction of the smallest possible dimension such that the fixed variables of interest are preserved. However, CLUE is restricted to systems with polynomial dynamics. Since rational dynamics occurs frequently in the life sciences (e.g., Michaelis-Menten or Hill kinetics), it is desirable to extend CLUE to the models with rational dynamics. In this paper, we present an extension of CLUE to the case of rational dynamics and demonstrate its applicability on examples from literature. Our implementation is available in version 1.5 of CLUE at https://github.com/pogudingleb/CLUE.",
        "published": "2022-01-31T17:34:04Z",
        "link": "http://arxiv.org/abs/2201.13373v3",
        "categories": [
            "q-bio.QM",
            "cs.SC",
            "cs.SY",
            "eess.SY",
            "math.DS"
        ]
    },
    {
        "title": "AI Research Associate for Early-Stage Scientific Discovery",
        "authors": [
            "Morad Behandish",
            "John Maxwell III",
            "Johan de Kleer"
        ],
        "summary": "Artificial intelligence (AI) has been increasingly applied in scientific activities for decades; however, it is still far from an insightful and trustworthy collaborator in the scientific process. Most existing AI methods are either too simplistic to be useful in real problems faced by scientists or too domain-specialized (even dogmatized), stifling transformative discoveries or paradigm shifts. We present an AI research associate for early-stage scientific discovery based on (a) a novel minimally-biased ontology for physics-based modeling that is context-aware, interpretable, and generalizable across classical and relativistic physics; (b) automatic search for viable and parsimonious hypotheses, represented at a high-level (via domain-agnostic constructs) with built-in invariants, e.g., postulated forms of conservation principles implied by a presupposed spacetime topology; and (c) automatic compilation of the enumerated hypotheses to domain-specific, interpretable, and trainable/testable tensor-based computation graphs to learn phenomenological relations, e.g., constitutive or material laws, from sparse (and possibly noisy) data sets.",
        "published": "2022-02-02T17:05:52Z",
        "link": "http://arxiv.org/abs/2202.03199v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.SC"
        ]
    },
    {
        "title": "Differential Privacy for Symbolic Systems with Application to Markov   Chains",
        "authors": [
            "Bo Chen",
            "Kevin Leahy",
            "Austin Jones",
            "Matthew Hale"
        ],
        "summary": "Data-driven systems are gathering increasing amounts of data from users, and sensitive user data requires privacy protections. In some cases, the data gathered is non-numerical or symbolic, and conventional approaches to privacy, e.g., adding noise, do not apply, though such systems still require privacy protections. Accordingly, we present a novel differential privacy framework for protecting trajectories generated by symbolic systems. These trajectories can be represented as words or strings over a finite alphabet. We develop new differential privacy mechanisms that approximate a sensitive word using a random word that is likely to be near it. An offline mechanism is implemented efficiently using a Modified Hamming Distance Automaton to generate whole privatized output words over a finite time horizon. Then, an online mechanism is implemented by taking in a sensitive symbol and generating a randomized output symbol at each timestep. This work is extended to Markov chains to generate differentially private state sequences that a given Markov chain could have produced. Statistical accuracy bounds are developed to quantify the accuracy of these mechanisms, and numerical results validate the accuracy of these techniques for strings of English words.",
        "published": "2022-02-07T16:17:56Z",
        "link": "http://arxiv.org/abs/2202.03325v2",
        "categories": [
            "cs.CR",
            "cs.SC",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "Random Alloy Codes and the Fundamental Limits of Coded Distributed   Tensors",
        "authors": [
            "Pedro Soto"
        ],
        "summary": "Tensors are a fundamental operation in distributed computing, \\emph{e.g.,} machine learning, that are commonly distributed into multiple parallel tasks for large datasets. Stragglers and other failures can severely impact the overall completion time. Recent works in coded computing provide a novel strategy to mitigate stragglers with coded tasks, with an objective of minimizing the number of tasks needed to recover the overall result, known as the recovery threshold. However, we demonstrate that this strict combinatorial definition does not directly optimize the probability of failure.   In this paper, we focus on the most likely event and measure the optimality of a coding scheme more directly by its probability of decoding. Our probabilistic approach leads us to a practical construction of random codes for matrix multiplication, i.e., locally random alloy codes, which are optimal with respect to the measures. Furthermore, the probabilistic approach allows us to discover a surprising impossibility theorem about both random and deterministic coded distributed tensors.",
        "published": "2022-02-07T19:20:00Z",
        "link": "http://arxiv.org/abs/2202.03469v7",
        "categories": [
            "cs.IT",
            "cs.DC",
            "cs.LG",
            "cs.NA",
            "cs.SC",
            "math.IT",
            "math.NA",
            "E.4; H.1.1; C.2.4; B.8.1; C.4; G.1.3; I.2.6; I.1.2"
        ]
    },
    {
        "title": "MMLN: Leveraging Domain Knowledge for Multimodal Diagnosis",
        "authors": [
            "Haodi Zhang",
            "Chenyu Xu",
            "Peirou Liang",
            "Ke Duan",
            "Hao Ren",
            "Weibin Cheng",
            "Kaishun Wu"
        ],
        "summary": "Recent studies show that deep learning models achieve good performance on medical imaging tasks such as diagnosis prediction. Among the models, multimodality has been an emerging trend, integrating different forms of data such as chest X-ray (CXR) images and electronic medical records (EMRs). However, most existing methods incorporate them in a model-free manner, which lacks theoretical support and ignores the intrinsic relations between different data sources. To address this problem, we propose a knowledge-driven and data-driven framework for lung disease diagnosis. By incorporating domain knowledge, machine learning models can reduce the dependence on labeled data and improve interpretability. We formulate diagnosis rules according to authoritative clinical medicine guidelines and learn the weights of rules from text data. Finally, a multimodal fusion consisting of text and image data is designed to infer the marginal probability of lung disease. We conduct experiments on a real-world dataset collected from a hospital. The results show that the proposed method outperforms the state-of-the-art multimodal baselines in terms of accuracy and interpretability.",
        "published": "2022-02-09T04:12:30Z",
        "link": "http://arxiv.org/abs/2202.04266v1",
        "categories": [
            "cs.LG",
            "cs.SC"
        ]
    },
    {
        "title": "On the Identity Problem for Unitriangular Matrices of Dimension Four",
        "authors": [
            "Ruiwen Dong"
        ],
        "summary": "We show that the Identity Problem is decidable in polynomial time for finitely generated sub-semigroups of the group $\\mathsf{UT}(4, \\mathbb{Z})$ of $4 \\times 4$ unitriangular integer matrices. As a byproduct of our proof, we also show the polynomial-time decidability of several subset reachability problems in $\\mathsf{UT}(4, \\mathbb{Z})$.",
        "published": "2022-02-10T18:29:22Z",
        "link": "http://arxiv.org/abs/2202.05225v3",
        "categories": [
            "cs.DM",
            "cs.SC"
        ]
    },
    {
        "title": "The Factorial-Basis Method for Finding Definite-Sum Solutions of Linear   Recurrences With Polynomial Coefficients",
        "authors": [
            "Antonio Jiménez-Pastor",
            "Marko Petkovšek"
        ],
        "summary": "The problem of finding a nonzero solution of a linear recurrence $Ly = 0$ with polynomial coefficients where $y$ has the form of a definite hypergeometric sum, related to the Inverse Creative Telescoping Problem of [14][Sec. 8], has now been open for three decades. Here we present an algorithm (implemented in a SageMath package) which, given such a recurrence and a quasi-triangular, shift-compatible factorial basis $\\mathcal{B} = \\langle P_k(n)\\rangle_{k=0}^\\infty$ of the polynomial space $\\mathbb{K}[n]$ over a field $\\mathbb{K}$ of characteristic zero, computes a recurrence satisfied by the coefficient sequence $c = \\langle c_k\\rangle_{k=0}^\\infty$ of the solution $y_n = \\sum_{k=0}^\\infty c_kP_k(n)$ (where, thanks to the quasi-triangularity of $\\mathcal{B}$, the sum on the right terminates for each $n \\in \\mathbb{N}$). More generally, if $\\mathcal{B}$ is $m$-sieved for some $m \\in \\mathbb{N}$, our algorithm computes a system of $m$ recurrences satisfied by the $m$-sections of the coefficient sequence $c$. If an explicit nonzero solution of this system can be found, we obtain an explicit nonzero solution of $Ly = 0$.",
        "published": "2022-02-11T11:07:39Z",
        "link": "http://arxiv.org/abs/2202.05550v3",
        "categories": [
            "cs.SC",
            "cs.MS",
            "33F10, 39A06, 68W30"
        ]
    },
    {
        "title": "On the computation of Gröbner bases for matrix-weighted homogeneous   systems",
        "authors": [
            "Thibaut Verron"
        ],
        "summary": "In this paper, we examine the structure of systems that are weighted homogeneous for several systems of weights, and how it impacts the computation of Gr\\\"obner bases. We present several linear algebra algorithms for computing Gr\\\"obner bases for systems with this structure, either directly or by reducing to existing structures. We also present suitable optimization techniques.   As an opening towards complexity studies, we discuss potential definitions of regularity and prove that they are generic if non-empty. Finally, we present experimental data from a prototype implementation of the algorithms in SageMath.",
        "published": "2022-02-11T16:32:11Z",
        "link": "http://arxiv.org/abs/2202.05742v3",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Random primes in arithmetic progressions",
        "authors": [
            "Pascal Giorgi",
            "Bruno Grenet",
            "Armelle Perret du Cray",
            "Daniel S. Roche"
        ],
        "summary": "We describe a straightforward method to generate a random prime q such that the multiplicative group GF(q)* also has a random large prime-order subgroup. The described algorithm also yields this order p as well as a p'th primitive root of unity. The methods here are efficient asymptotically, but due to large constants may not be very useful in practical settings.",
        "published": "2022-02-12T02:19:27Z",
        "link": "http://arxiv.org/abs/2202.05955v2",
        "categories": [
            "cs.CC",
            "cs.SC",
            "math.NT"
        ]
    },
    {
        "title": "Square-free Strong Triangular Decomposition of Zero-dimensional   Polynomial Systems",
        "authors": [
            "Haokun Li",
            "Bican Xia",
            "Tianqi Zhao"
        ],
        "summary": "Triangular decomposition with different properties has been used for various types of problem solving, e.g. geometry theorem proving, real solution isolation of zero-dimensional polynomial systems, etc. In this paper, the concepts of strong chain and square-free strong triangular decomposition (SFSTD) of zero-dimensional polynomial systems are defined. Because of its good properties, SFSTD may be a key way to many problems related to zero-dimensional polynomial systems, such as real solution isolation and computing radicals of zero-dimensional ideals. Inspired by the work of Wang and of Dong and Mou, we propose an algorithm for computing SFSTD based on Gr\\\"obner bases computation. The novelty of the algorithm is that we make use of saturated ideals and separant to ensure that the zero sets of any two strong chains have no intersection and every strong chain is square-free, respectively. On one hand, we prove that the arithmetic complexity of the new algorithm can be single exponential in the square of the number of variables, which seems to be among the rare complexity analysis results for triangular-decomposition methods. On the other hand, we show experimentally that, on a large number of examples in the literature, the new algorithm is far more efficient than a popular triangular-decomposition method based on pseudo-division. Furthermore, it is also shown that, on those examples, the methods based on SFSTD for real solution isolation and for computing radicals of zero-dimensional ideals are very efficient.",
        "published": "2022-02-12T11:33:04Z",
        "link": "http://arxiv.org/abs/2202.06044v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Trinomials and Deterministic Complexity Limits for Real Solving",
        "authors": [
            "Erick Boniface",
            "Weixun Deng",
            "J. Maurice Rojas"
        ],
        "summary": "Consider a univariate polynomial f in Z[x] with degree d, exactly t monomial terms, and coefficients in {-H,...,H}. Solving f over the reals, R, in polynomial-time can be defined as counting the exact number of real roots of f and then finding (for each such root z) an approximation w of logarithmic height (log(dH))^{O(1)} such that the Newton iterates of w have error decaying at a rate of O((1/2)^{2^i}). Solving efficiently in this sense, using (log(dH))^{O(1)} deterministic bit operations, is arguably the most honest formulation of solving a polynomial equation over R in time polynomial in the input size. Unfortunately, deterministic algorithms this fast are known only for t=2, unknown for t=3, and provably impossible for t=4. (One can of course resort to older techniques with complexity (d\\log H)^{O(1)} for t>=4.)   We give evidence that polynomial-time real-solving in the strong sense above is possible for t=3: We give a polynomial-time algorithm employing A-hypergeometric series that works for all but a fraction of 1/Omega(log(dH)) of the input f. We also show an equivalence between fast trinomial solving and sign evaluation at rational points of small height. As a consequence, we show that for \"most\" trinomials f, we can compute the sign of f at a rational point r in time polynomial in log(dH) and the logarithmic height of r. (This was known only for binomials before.) We also mention a related family of polynomial systems that should admit a similar speed-up for solving.",
        "published": "2022-02-12T18:07:51Z",
        "link": "http://arxiv.org/abs/2202.06115v1",
        "categories": [
            "math.AG",
            "cs.CC",
            "cs.NA",
            "cs.SC",
            "math.NA"
        ]
    },
    {
        "title": "Faster Gröbner bases for Lie derivatives of ODE systems via monomial   orderings",
        "authors": [
            "Mariya Bessonov",
            "Ilia Ilmer",
            "Tatiana Konstantinova",
            "Alexey Ovchinnikov",
            "Gleb Pogudin",
            "Pedro Soto"
        ],
        "summary": "Symbolic computation for systems of differential equations is often computationally expensive. Many practical differential models have a form of polynomial or rational ODE system with specified outputs. A basic symbolic approach to analyze these models is to compute and then symbolically process the polynomial system obtained by sufficiently many Lie derivatives of the output functions with respect to the vector field given by the ODE system.   In this paper, we present a method for speeding up Gr\\\"obner basis computation for such a class of polynomial systems by using specific monomial ordering, including weights for the variables, coming from the structure of the ODE model. We provide empirical results that show improvement across different symbolic computing frameworks and apply the method to speed up structural identifiability analysis of ODE models.",
        "published": "2022-02-13T12:40:11Z",
        "link": "http://arxiv.org/abs/2202.06297v3",
        "categories": [
            "cs.SC",
            "cs.MS",
            "q-bio.QM"
        ]
    },
    {
        "title": "Stability Problems in Symbolic Integration",
        "authors": [
            "Shaoshi Chen"
        ],
        "summary": "This paper aims to initialize a dynamical aspect of symbolic integration by studying stability problems in differential fields. We present some basic properties of stable elementary functions and D-finite power series that enable us to characterize three special families of stable elementary functions involving rational functions, logarithmic functions, and exponential functions. Some problems for future studies are proposed towards deeper dynamical studies in differential and difference algebra.",
        "published": "2022-02-13T13:00:31Z",
        "link": "http://arxiv.org/abs/2202.06305v1",
        "categories": [
            "cs.SC",
            "math.AC",
            "math.DS",
            "12H05, 37P15, 33F10,",
            "I.1.2"
        ]
    },
    {
        "title": "Beyond Worst-Case Analysis for Root Isolation Algorithms",
        "authors": [
            "Alperen A. Ergür",
            "Josué Tonelli-Cueto",
            "Elias Tsigaridas"
        ],
        "summary": "Isolating the real roots of univariate polynomials is a fundamental problem in symbolic computation and it is arguably one of the most important problems in computational mathematics. The problem has a long history decorated with numerous ingenious algorithms and furnishes an active area of research. However, the worst-case analysis of root-finding algorithms does not correlate with their practical performance. We develop a smoothed analysis framework for polynomials with integer coefficients to bridge the gap between the complexity estimates and the practical performance. In this setting, we derive that the expected bit complexity of DESCARTES solver to isolate the real roots of a polynomial, with coefficients uniformly distributed, is $\\widetilde{\\mathcal{O}}_B(d^2 + d \\tau)$, where $d$ is the degree of the polynomial and $\\tau$ the bitsize of the coefficients.",
        "published": "2022-02-13T22:28:12Z",
        "link": "http://arxiv.org/abs/2202.06428v3",
        "categories": [
            "cs.CC",
            "cs.SC",
            "math.AG",
            "math.PR",
            "65H04, 14Q20, 68W30"
        ]
    },
    {
        "title": "Exact SOHS decompositions of trigonometric univariate polynomials with   Gaussian coefficients",
        "authors": [
            "Victor Magron",
            "Mohab Safey El Din",
            "Markus Schweighofer",
            "Trung Hieu Vu"
        ],
        "summary": "Certifying the positivity of trigonometric polynomials is of first importance for design problems in discrete-time signal processing. It is well known from the Riesz-Fej\\'ez spectral factorization theorem that any trigonometric univariate polynomial positive on the unit circle can be decomposed as a Hermitian square with complex coefficients. Here we focus on the case of polynomials with Gaussian integer coefficients, i.e., with real and imaginary parts being integers. We design, analyze and compare, theoretically and practically,three hybrid numeric-symbolic algorithms computing weighted sums of Hermitian squares decompositions for trigonometric univariate polynomials positive on the unit circle with Gaussian coefficients. The numerical steps the first and second algorithm rely on are complex root isolation and semidefinite programming, respectively. An exact sum of Hermitian squares decomposition is obtained thanks to compensation techniques. The third algorithm, also based on complex semidefinite programming, is an adaptation of the rounding and projection algorithm by Peyrl and Parrilo. For all three algorithms, we prove bit complexity and output size estimates that are polynomial in the degree of the input and linear in the maximum bitsize of its coefficients. We compare their performance on randomly chosen benchmarks, and further design a certified finite impulse filter.",
        "published": "2022-02-14T08:33:18Z",
        "link": "http://arxiv.org/abs/2202.06544v2",
        "categories": [
            "cs.SC",
            "math.OC"
        ]
    },
    {
        "title": "The Membership Problem for Hypergeometric Sequences with Rational   Parameters",
        "authors": [
            "Klara Nosan",
            "Amaury Pouly",
            "Mahsa Shirmohammadi",
            "James Worrell"
        ],
        "summary": "We investigate the Membership Problem for hypergeometric sequences: given a hypergeometric sequence $\\langle u_n \\rangle_{n=0}^\\infty$ of rational numbers and a target $t \\in \\mathbb{Q}$, decide whether $t$ occurs in the sequence. We show decidability of this problem under the assumption that in the defining recurrence $p(n)u_{n}=q(n)u_{n-1}$, the roots of the polynomials $p(x)$ and $q(x)$ are all rational numbers. Our proof relies on bounds on the density of primes in arithmetic progressions. We also observe a relationship between the decidability of the Membership problem (and variants) and the Rohrlich-Lang conjecture in transcendence theory.",
        "published": "2022-02-15T14:05:42Z",
        "link": "http://arxiv.org/abs/2202.07416v2",
        "categories": [
            "cs.LO",
            "cs.SC"
        ]
    },
    {
        "title": "Fast Symbolic Algorithms for Omega-Regular Games under Strong Transition   Fairness",
        "authors": [
            "Tamajit Banerjee",
            "Rupak Majumdar",
            "Kaushik Mallik",
            "Anne-Kathrin Schmuck",
            "Sadegh Soudjani"
        ],
        "summary": "We consider fixpoint algorithms for two-player games on graphs with $\\omega$-regular winning conditions, where the environment is constrained by a strong transition fairness assumption. Strong transition fairness is a widely occurring special case of strong fairness, which requires that any execution is strongly fair with respect to a specified set of live edges: whenever the source vertex of a live edge is visited infinitely often along a play, the edge itself is traversed infinitely often along the play as well. We show that, surprisingly, strong transition fairness retains the algorithmic characteristics of the fixpoint algorithms for $\\omega$-regular games -- the new algorithms have the same alternation depth as the classical algorithms but invoke a new type of predecessor operator. For Rabin games with $k$ pairs, the complexity of the new algorithm is $O(n^{k+2}k!)$ symbolic steps, which is independent of the number of live edges in the strong transition fairness assumption. Further, we show that GR(1) specifications with strong transition fairness assumptions can be solved with a 3-nested fixpoint algorithm, same as the usual algorithm. In contrast, strong fairness necessarily requires increasing the alternation depth depending on the number of fairness assumptions. We get symbolic algorithms for (generalized) Rabin, parity and GR(1) objectives under strong transition fairness assumptions as well as a direct symbolic algorithm for qualitative winning in stochastic $\\omega$-regular games that runs in $O(n^{k+2}k!)$ symbolic steps, improving the state of the art. Finally, we have implemented a BDD-based synthesis engine based on our algorithm. We show on a set of synthetic and real benchmarks that our algorithm is scalable, parallelizable, and outperforms previous algorithms by orders of magnitude.",
        "published": "2022-02-15T14:47:12Z",
        "link": "http://arxiv.org/abs/2202.07480v4",
        "categories": [
            "cs.FL",
            "cs.SC",
            "cs.SY",
            "eess.SY"
        ]
    },
    {
        "title": "On Polynomial Ideals And Overconvergence In Tate Algebras",
        "authors": [
            "Xavier Caruso",
            "Tristan Vaccon",
            "Thibaut Verron"
        ],
        "summary": "In this paper, we study ideals spanned by polynomials or overconvergent series in a Tate algebra. With state-of-the-art algorithms for computing Tate Gr{\\\"o}bner bases, even if the input is polynomials, the size of the output grows with the required precision, both in terms of the size of the coefficients and the size of the support of the series. We prove that ideals which are spanned by polynomials admit a Tate Gr{\\\"o}bner basis made of polynomials, and we propose an algorithm, leveraging Mora's weak normal form algorithm, for computing it. As a result, the size of the output of this algorithm grows linearly with the precision. Following the same ideas, we propose an algorithm which computes an overconvergent basis for an ideal spanned by overconvergent series. Finally, we prove the existence of a universal analytic Gr{\\\"o}bner basis for polynomial ideals in Tate algebras, compatible with all convergence radii.",
        "published": "2022-02-15T15:37:30Z",
        "link": "http://arxiv.org/abs/2202.07509v1",
        "categories": [
            "cs.SC",
            "math.AG",
            "math.NT"
        ]
    },
    {
        "title": "Bohemian Matrix Geometry",
        "authors": [
            "Robert M. Corless",
            "George Labahn",
            "Dan Piponi",
            "Leili Rafiee Sevyeri"
        ],
        "summary": "A Bohemian matrix family is a set of matrices all of whose entries are drawn from a fixed, usually discrete and hence bounded, subset of a field of characteristic zero. Originally these were integers -- hence the name, from the acronym BOunded HEight Matrix of Integers (BOHEMI) -- but other kinds of entries are also interesting. Some kinds of questions about Bohemian matrices can be answered by numerical computation, but sometimes exact computation is better. In this paper we explore some Bohemian families (symmetric, upper Hessenberg, or Toeplitz) computationally, and answer some open questions posed about the distributions of eigenvalue densities.",
        "published": "2022-02-15T22:43:30Z",
        "link": "http://arxiv.org/abs/2202.07769v2",
        "categories": [
            "cs.SC",
            "math.CO",
            "15B05",
            "I.1.4"
        ]
    },
    {
        "title": "Identity Testing for Radical Expressions",
        "authors": [
            "Nikhil Balaji",
            "Klara Nosan",
            "Mahsa Shirmohammadi",
            "James Worrell"
        ],
        "summary": "We study the Radical Identity Testing problem (RIT): Given an algebraic circuit representing a polynomial $f\\in \\mathbb{Z}[x_1, \\ldots, x_k]$ and nonnegative integers $a_1, \\ldots, a_k$ and $d_1, \\ldots,$ $d_k$, written in binary, test whether the polynomial vanishes at the real radicals $\\sqrt[d_1]{a_1}, \\ldots,\\sqrt[d_k]{a_k}$, i.e., test whether $f(\\sqrt[d_1]{a_1}, \\ldots,\\sqrt[d_k]{a_k}) = 0$. We place the problem in coNP assuming the Generalised Riemann Hypothesis (GRH), improving on the straightforward PSPACE upper bound obtained by reduction to the existential theory of reals. Next we consider a restricted version, called $2$-RIT, where the radicals are square roots of prime numbers, written in binary. It was known since the work of Chen and Kao that $2$-RIT is at least as hard as the polynomial identity testing problem, however no better upper bound than PSPACE was known prior to our work. We show that $2$-RIT is in coRP assuming GRH and in coNP unconditionally. Our proof relies on theorems from algebraic and analytic number theory, such as the Chebotarev density theorem and quadratic reciprocity.",
        "published": "2022-02-16T10:11:08Z",
        "link": "http://arxiv.org/abs/2202.07961v4",
        "categories": [
            "cs.CC",
            "cs.LO",
            "cs.SC"
        ]
    },
    {
        "title": "Guessing with Little Data",
        "authors": [
            "Manuel Kauers",
            "Christoph Koutschan"
        ],
        "summary": "Reconstructing a hypothetical recurrence equation from the first terms of an infinite sequence is a classical and well-known technique in experimental mathematics. We propose a variation of this technique which can succeed with fewer input terms.",
        "published": "2022-02-16T10:20:17Z",
        "link": "http://arxiv.org/abs/2202.07966v2",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Sparse Polynomial Interpolation and Division in Soft-linear Time",
        "authors": [
            "Pascal Giorgi",
            "Bruno Grenet",
            "Armelle Perret du Cray",
            "Daniel S. Roche"
        ],
        "summary": "Given a way to evaluate an unknown polynomial with integer coefficients, we present new algorithms to recover its nonzero coefficients and corresponding exponents. As an application, we adapt this interpolation algorithm to the problem of computing the exact quotient of two given polynomials. These methods are efficient in terms of the bit-length of the sparse representation, that is, the number of nonzero terms, the size of coefficients, the number of variables, and the logarithm of the degree. At the core of our results is a new Monte Carlo randomized algorithm to recover a polynomial $f(x)$ with integer coefficients given a way to evaluate $f(\\theta) \\bmod m$ for any chosen integers $\\theta$ and $m$. This algorithm has nearly-optimal bit complexity, meaning that the total bit-length of the probes, as well as the computational running time, is softly linear (ignoring logarithmic factors) in the bit-length of the resulting sparse polynomial. To our knowledge, this is the first sparse interpolation algorithm with soft-linear bit complexity in the total output size. For polynomials with integer coefficients, the best previously known results have at least a cubic dependency on the bit-length of the exponents.",
        "published": "2022-02-16T14:43:25Z",
        "link": "http://arxiv.org/abs/2202.08106v2",
        "categories": [
            "cs.SC",
            "cs.CC"
        ]
    },
    {
        "title": "Desingularization and p-Curvature of Recurrence Operators",
        "authors": [
            "Yi Zhou",
            "Mark van Hoeij"
        ],
        "summary": "Linear recurrence operators in characteristic $p$ are classified by their $p$-curvature. For a recurrence operator $L$, denote by $\\chi(L)$ the characteristic polynomial of its $p$-curvature. We can obtain information about the factorization of $L$ by factoring $\\chi(L)$. The main theorem of this paper gives an unexpected relation between $\\chi(L)$ and the true singularities of $L$. An application is to speed up a fast algorithm for computing $\\chi(L)$ by desingularizing $L$ first. Another contribution of this paper is faster desingularization.",
        "published": "2022-02-17T23:14:24Z",
        "link": "http://arxiv.org/abs/2202.08931v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Faster change of order algorithm for Gröbner bases under shape and   stability assumptions",
        "authors": [
            "Jérémy Berthomieu",
            "Vincent Neiger",
            "Mohab Safey El Din"
        ],
        "summary": "Solving zero-dimensional polynomial systems using Gr\\\"obner bases is usually done by, first, computing a Gr\\\"obner basis for the degree reverse lexicographic order, and next computing the lexicographic Gr\\\"obner basis with a change of order algorithm. Currently, the change of order now takes a significant part of the whole solving time for many generic instances.   Like the fastest known change of order algorithms, this work focuses on the situation where the ideal defined by the system satisfies natural properties which can be recovered in generic coordinates. First, the ideal has a \\emph{shape} lexicographic Gr\\\"obner basis. Second, the set of leading terms with respect to the degree reverse lexicographic order has a \\emph{stability} property; in particular, the multiplication matrix can be read on the input Gr\\\"obner basis.   The current fastest algorithms rely on the sparsity of this matrix. Actually, this sparsity is a consequence of an algebraic structure, which can be exploited to represent the matrix concisely as a univariate polynomial matrix. We show that the Hermite normal form of that matrix yields the sought lexicographic Gr\\\"obner basis, under assumptions which cover the shape position case. Under some mild assumption implying $n \\le t$, the arithmetic complexity of our algorithm is $O\\tilde{~}(t^{\\omega-1}D)$, where $n$ is the number of variables, $t$ is a sparsity indicator of the aforementioned matrix, $D$ is the degree of the zero-dimensional ideal under consideration, and $\\omega$ is the exponent of matrix multiplication. This improves upon both state-of-the-art complexity bounds $O\\tilde{~}(tD^2)$ and $O\\tilde{~}(D^\\omega)$, since $\\omega < 3$ and $t\\le D$. Practical experiments, based on the libraries msolve and PML, confirm the high practical benefit.",
        "published": "2022-02-18T14:49:43Z",
        "link": "http://arxiv.org/abs/2202.09226v2",
        "categories": [
            "cs.SC",
            "math.AC"
        ]
    },
    {
        "title": "Rank-Sensitive Computation of the Rank Profile of a Polynomial Matrix",
        "authors": [
            "George Labahn",
            "Vincent Neiger",
            "Thi Xuan Vu",
            "Wei Zhou"
        ],
        "summary": "Consider a matrix $\\mathbf{F} \\in \\mathbb{K}[x]^{m \\times n}$ of univariate polynomials over a field $\\mathbb{K}$. We study the problem of computing the column rank profile of $\\mathbf{F}$. To this end we first give an algorithm which improves the minimal kernel basis algorithm of Zhou, Labahn, and Storjohann (Proceedings ISSAC 2012). We then provide a second algorithm which computes the column rank profile of $\\mathbf{F}$ with a rank-sensitive complexity of $O\\tilde{~}(r^{\\omega-2} n (m+D))$ operations in $\\mathbb{K}$. Here, $D$ is the sum of row degrees of $\\mathbf{F}$, $\\omega$ is the exponent of matrix multiplication, and $O\\tilde{~}(\\cdot)$ hides logarithmic factors.",
        "published": "2022-02-18T17:44:18Z",
        "link": "http://arxiv.org/abs/2202.09329v2",
        "categories": [
            "cs.SC",
            "math.RA"
        ]
    },
    {
        "title": "A New Type of Gröbner Basis and Its Complexity",
        "authors": [
            "Sheng-Ming Ma"
        ],
        "summary": "The new type of ideal basis introduced herein constitutes a compromise between the Gr\\\"obner bases based on the Buchberger's algorithm and the characteristic sets based on the Wu's method. It reduces the complexity of the traditional Gr\\\"obner bases and subdues the notorious intermediate expression swell problem and intermediate coefficient swell problem to a substantial extent. The computation of an $S$-polynomial for the new bases requires at most $O(m\\ln^2m\\ln\\ln m)$ word operations whereas $O(m^6\\ln^2m)$ word operations are requisite in the Buchberger's algorithm. Here $m$ denotes the upper bound for the numbers of terms both in the leading coefficients and for the rest of the polynomials. The new bases are for zero-dimensional polynomial ideals and based on univariate pseudo-divisions. However in contrast to the pseudo-divisions in the Wu's method for the characteristic sets, the new bases retain the algebraic information of the original ideal and in particular, solve the ideal membership problem. In order to determine the authentic factors of the eliminant, we analyze the multipliers of the pseudo-divisions and develop an algorithm over principal quotient rings with zero divisors.",
        "published": "2022-02-19T02:11:48Z",
        "link": "http://arxiv.org/abs/2202.09493v1",
        "categories": [
            "cs.SC",
            "13P10, 13B25",
            "I.1.2"
        ]
    },
    {
        "title": "Extending Flat Motion Planning to Non-flat Systems. Experiments on   Aircraft Models Using Maple",
        "authors": [
            "François Ollivier"
        ],
        "summary": "Aircraft models may be considered as flat if one neglects some terms associated to aerodynamics. Computational experiments in Maple show that in some cases a suitably designed feed-back allows to follow such trajectories, when applied to the non-flat model. However some maneuvers may be hard or even impossible to achieve with this flat approximation. In this paper, we propose an iterated process to compute a more achievable trajectory, starting from the flat reference trajectory. More precisely, the unknown neglected terms in the flat model are iteratively re-evaluated using the values obtained at the previous step. This process may be interpreted as a new trajectory parametrization, using an infinite number of derivatives, a property that may be called \\emph{generalized flatness}. We illustrate the pertinence of this approach in flight conditions of increasing difficulties, from single engine flight, to aileron roll.",
        "published": "2022-02-20T22:33:03Z",
        "link": "http://arxiv.org/abs/2202.09921v3",
        "categories": [
            "cs.SC",
            "cs.SY",
            "eess.SY",
            "68W30, 93-08, 93B25, 93B51, 93B52",
            "I.1"
        ]
    },
    {
        "title": "On the complexity of Chow and Hurwitz forms",
        "authors": [
            "Mahmut Levent Doğan",
            "Alperen Ali Ergür",
            "Elias Tsigaridas"
        ],
        "summary": "We consider the bit complexity of computing Chow forms and their generalization to multiprojective spaces. We develop a deterministic algorithm using resultants and obtain a single exponential complexity upper bound. Earlier computational results for Chow forms were in the arithmetic complexity model, and our result represents the first bit complexity bound. We also extend our algorithm to Hurwitz forms in projective space, and explore connections between multiprojective Hurwitz forms and matroid theory. The motivation for our work comes from incidence geometry where intriguing computational algebra problems remain open.",
        "published": "2022-02-23T15:57:52Z",
        "link": "http://arxiv.org/abs/2202.11582v3",
        "categories": [
            "cs.CC",
            "cs.SC",
            "math.AG"
        ]
    },
    {
        "title": "Learning Program Synthesis for Integer Sequences from Scratch",
        "authors": [
            "Thibault Gauthier",
            "Josef Urban"
        ],
        "summary": "We present a self-learning approach for synthesizing programs from integer sequences. Our method relies on a tree search guided by a learned policy. Our system is tested on the On-Line Encyclopedia of Integer Sequences. There, it discovers, on its own, solutions for 27987 sequences starting from basic operators and without human-written training examples.",
        "published": "2022-02-24T05:34:33Z",
        "link": "http://arxiv.org/abs/2202.11908v3",
        "categories": [
            "cs.AI",
            "cs.SC"
        ]
    },
    {
        "title": "Random primes without primality testing",
        "authors": [
            "Pascal Giorgi",
            "Bruno Grenet",
            "Armelle Perret du Cray",
            "Daniel S. Roche"
        ],
        "summary": "Numerous algorithms call for computation over the integers modulo a randomly-chosen large prime. In some cases, the quasi-cubic complexity of selecting a random prime can dominate the total running time. We propose a new variant of the classic D5 algorithm for \"dynamic evaluation\", applied to a randomly-chosen (composite) integer. Unlike the D5 principle which has been used in the past to compute over a direct product of fields, our method is simpler as it only requires following a single path after any modulus splits. The transformation we propose can apply to any algorithm in the algebraic RAM model, even allowing randomization. The resulting transformed algorithm avoids any primality tests and will, with constant positive probability, have the same result as the original computation modulo a randomly-chosen prime. As an application, we demonstrate how to compute the exact number of nonzero terms in an unknown integer polynomial in quasi-linear time. We also show how the same algorithmic transformation technique can be used for computing modulo random irreducible polynomials over a finite field.",
        "published": "2022-02-24T12:55:14Z",
        "link": "http://arxiv.org/abs/2202.12073v1",
        "categories": [
            "cs.SC",
            "cs.CC"
        ]
    },
    {
        "title": "New efficient algorithms for computing Gröbner bases of saturation   ideals (F4SAT) and colon ideals (Sparse-FGLM-colon)",
        "authors": [
            "Jérémy Berthomieu",
            "Christian Eder",
            "Mohab Safey El Din"
        ],
        "summary": "This paper is concerned with linear algebra based methods for solving exactly polynomial systems through so-called Gr\\\"obner bases, which allow one to compute modulo the polynomial ideal generated by the input equations. This is a topical issue in non-linear algebra and more broadly in computational mathematics because of its numerous applications in engineering and computing sciences. Such applications often require geometric computing features such as representing the closure of the set difference of two solution sets to given polynomial systems. Algebraically, this boils down to computing Gr\\\"obner bases of colon and/or saturation polynomial ideals. In this paper, we describe and analyze new Gr\\\"obner bases algorithms for this task and present implementations which are more efficient by several orders of magnitude than the state-of-the-art software.",
        "published": "2022-02-27T15:51:39Z",
        "link": "http://arxiv.org/abs/2202.13387v2",
        "categories": [
            "cs.SC",
            "math.AC"
        ]
    },
    {
        "title": "A Signature-based Algorithm for Computing the Nondegenerate Locus of a   Polynomial System",
        "authors": [
            "Christian Eder",
            "Pierre Lairez",
            "Rafael Mohr",
            "Mohab Safey El Din"
        ],
        "summary": "Polynomial system solving arises in many application areas to model non-linear geometric properties. In such settings, polynomial systems may come with degeneration which the end-user wants to exclude from the solution set. The nondegenerate locus of a polynomial system is the set of points where the codimension of the solution set matches the number of equations. Computing the nondegenerate locus is classically done through ideal-theoretic operations in commutative algebra such as saturation ideals or equidimensional decompositions to extract the component of maximal codimension. By exploiting the algebraic features of signature-based Gr\\\"obner basis algorithms we design an algorithm which computes a Gr\\\"obner basis of the equations describing the closure of the nondegenerate locus of a polynomial system, without computing first a Gr\\\"obner basis for the whole polynomial system.",
        "published": "2022-02-28T13:26:01Z",
        "link": "http://arxiv.org/abs/2202.13784v2",
        "categories": [
            "cs.SC",
            "13P10, 13P05",
            "I.1.2; G.4"
        ]
    },
    {
        "title": "Identification in Tree-shaped Linear Structural Causal Models",
        "authors": [
            "Benito van der Zander",
            "Marcel Wienöbst",
            "Markus Bläser",
            "Maciej Liśkiewicz"
        ],
        "summary": "Linear structural equation models represent direct causal effects as directed edges and confounding factors as bidirected edges. An open problem is to identify the causal parameters from correlations between the nodes. We investigate models, whose directed component forms a tree, and show that there, besides classical instrumental variables, missing cycles of bidirected edges can be used to identify the model. They can yield systems of quadratic equations that we explicitly solve to obtain one or two solutions for the causal parameters of adjacent directed edges. We show how multiple missing cycles can be combined to obtain a unique solution. This results in an algorithm that can identify instances that previously required approaches based on Gr\\\"obner bases, which have doubly-exponential time complexity in the number of structural parameters.",
        "published": "2022-03-03T16:59:49Z",
        "link": "http://arxiv.org/abs/2203.01852v2",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.SC",
            "stat.ML"
        ]
    },
    {
        "title": "Verification of Bitcoin Script in Agda using Weakest Preconditions for   Access Control",
        "authors": [
            "Fahad F. Alhabardi",
            "Arnold Beckmann",
            "Bogdan Lazar",
            "Anton Setzer"
        ],
        "summary": "This paper contributes to the verification of programs written in Bitcoin's smart contract language SCRIPT in the interactive theorem prover Agda. It focuses on the security property of access control for SCRIPT programs that govern the distribution of Bitcoins. It advocates that weakest preconditions in the context of Hoare triples are the appropriate notion for verifying access control. It aims at obtaining human-readable descriptions of weakest preconditions in order to close the validation gap between user requirements and formal specification of smart contracts.   As examples for the proposed approach, the paper focuses on two standard SCRIPT programs that govern the distribution of Bitcoins, Pay to Public Key Hash (P2PKH) and Pay to Multisig (P2MS). The paper introduces an operational semantics of the SCRIPT commands used in P2PKH and P2MS, which is formalised in the Agda proof assistant and reasoned about using Hoare triples. Two methodologies for obtaining human-readable descriptions of weakest preconditions are discussed:   (1) a step-by-step approach, which works backwards instruction by instruction through a script, sometimes grouping several instructions together;   (2) symbolic execution of the code and translation into a nested case distinction, which allows to read off weakest preconditions as the disjunction of conjunctions of conditions along accepting paths.   A syntax for equational reasoning with Hoare Triples is defined in order to formalise those approaches in Agda.   Keywords and phrases: Blockchain; Cryptocurrency; Bitcoin; Agda; Verification; Hoare logic; Bitcoin script; P2PKH; P2MS; Access control; Weakest precondition; Predicate transformer semantics; Provable correctness; Symbolic execution; Smart contracts",
        "published": "2022-03-06T21:07:28Z",
        "link": "http://arxiv.org/abs/2203.03054v3",
        "categories": [
            "cs.SC",
            "cs.CR",
            "cs.LO",
            "cs.SI"
        ]
    },
    {
        "title": "On realizing differential-algebraic equations by rational dynamical   systems",
        "authors": [
            "Dmitrii Pavlov",
            "Gleb Pogudin"
        ],
        "summary": "Real-world phenomena can often be conveniently described by dynamical systems (that is, ODE systems in the state-space form). However, if one observes the state of the system only partially, the observed quantities (outputs) and the inputs of the system can typically be related by more complicated differential-algebraic equations (DAEs). Therefore, a natural question (referred to as the realizability problem) is: given a differential-algebraic equation (say, fitted from data), does it come from a partially observed dynamical system? A special case in which the functions involved in the dynamical system are rational is of particular interest. For a single differential-algebraic equation in a single output variable, Forsman has shown that it is realizable by a rational dynamical system if and only if the corresponding hypersurface is unirational, and he turned this into an algorithm in the first-order case.   In this paper, we study a more general case of single-input-single-output equations. We show that if a realization by a rational dynamical system exists, the system can be taken to have the dimension equal to the order of the DAE. We provide a complete algorithm for first-order DAEs. We also show that the same approach can be used for higher-order DAEs using several examples from the literature.",
        "published": "2022-03-07T17:56:27Z",
        "link": "http://arxiv.org/abs/2203.03555v2",
        "categories": [
            "cs.SC",
            "math.AG",
            "math.DS",
            "math.OC"
        ]
    },
    {
        "title": "Computing roadmaps in unbounded smooth real algebraic sets I:   connectivity results",
        "authors": [
            "Rémi Prébet",
            "Mohab Safey El Din",
            "Éric Schost"
        ],
        "summary": "Answering connectivity queries in real algebraic sets is a fundamental problem in effective real algebraic geometry that finds many applications in e.g. robotics where motion planning issues are topical. This computational problem is tackled through the computation of so-called roadmaps which are real algebraic subsets of the set V under study, of dimension at most one, and which have a connected intersection with all semi-algebraically connected components of V. Algorithms for computing roadmaps rely on statements establishing connectivity properties of some well-chosen subsets of V , assuming that V is bounded.   In this paper, we extend such connectivity statements by dropping the boundedness assumption on V. This exploits properties of so-called generalized polar varieties, which are critical loci of V for some well-chosen polynomial maps.",
        "published": "2022-03-08T09:35:01Z",
        "link": "http://arxiv.org/abs/2203.03961v2",
        "categories": [
            "cs.SC",
            "math.AG",
            "14Q20, 14Q30, 14P05, 68W30"
        ]
    },
    {
        "title": "On the complexity of invariant polynomials under the action of finite   reflection groups",
        "authors": [
            "Thi Xuan Vu"
        ],
        "summary": "Let $\\mathbb{K}[x_1, \\dots, x_n]$ be a multivariate polynomial ring over a field $\\mathbb{K}$. Let $(u_1, \\dots, u_n)$ be a sequence of $n$ algebraically independent elements in $\\mathbb{K}[x_1, \\dots, x_n]$. Given a polynomial $f$ in $\\mathbb{K}[u_1, \\dots, u_n]$, a subring of $\\mathbb{K}[x_1, \\dots, x_n]$ generated by the $u_i$'s, we are interested infinding the unique polynomial $f_{\\rm new}$ in $\\mathbb{K}[e_1,\\dots, e_n]$, where $e_1, \\dots, e_n$ are new variables, such that $f_{\\mathrm{new}}(u_1, \\dots, u_n) = f(x_1, \\dots, x_n)$. We provide an algorithm and analyze its arithmetic complexity to compute $f_{\\mathrm{new}}$ knowing $f$ and $(u_1, \\dots, u_n)$.",
        "published": "2022-03-08T14:45:36Z",
        "link": "http://arxiv.org/abs/2203.04123v2",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Deciding Cuspidality of Manipulators through Computer Algebra and   Algorithms in Real Algebraic Geometry",
        "authors": [
            "Damien Chablat",
            "Rémi Prébet",
            "Mohab Safey El Din",
            "Durgesh Salunkhe",
            "Philippe Wenger"
        ],
        "summary": "Cuspidal robots are robots with at least two inverse kinematic solutions that can be connected by a singularity-free path. Deciding the cuspidality of generic 3R robots has been studied in the past, but extending the study to six-degree-of-freedom robots can be a challenging problem. Many robots can be modeled as a polynomial map together with a real algebraic set so that the notion of cuspidality can be extended to these data. In this paper we design an algorithm that, on input a polynomial map in $n$ indeterminates, and $s$ polynomials in the same indeterminates describing a real algebraic set of dimension $d$, decides the cuspidality of the restriction of the map to the real algebraic set under consideration. Moreover, if $D$ and $\\tau$ are, respectively the maximum degree and the bound on the bit size of the coefficients of the input polynomials, this algorithm runs in time log-linear in $\\tau$ and polynomial in $((s+d)D)^{O(n^2)}$. It relies on many high-level algorithms in computer algebra which use advanced methods on real algebraic sets and critical loci of polynomial maps. As far as we know, this is the first algorithm that tackles the cuspidality problem from a general point of view.",
        "published": "2022-03-09T08:44:41Z",
        "link": "http://arxiv.org/abs/2203.04578v2",
        "categories": [
            "cs.SC",
            "cs.RO",
            "math.AG",
            "68W30, 14Q30",
            "I.1.2; I.1.4"
        ]
    },
    {
        "title": "Computing a Group Action from the Class Field Theory of Imaginary   Hyperelliptic Function Fields",
        "authors": [
            "Antoine Leudière",
            "Pierre-Jean Spaenlehauer"
        ],
        "summary": "We explore algorithmic aspects of a simply transitive commutative group action coming from the class field theory of imaginary hyperelliptic function fields. Namely, the Jacobian of an imaginary hyperelliptic curve defined over $\\mathbb F_q$ acts on a subset of isomorphism classes of Drinfeld modules. We describe an algorithm to compute the group action efficiently. This is a function field analog of the Couveignes-Rostovtsev-Stolbunov group action. We report on an explicit computation done with our proof-of-concept C++/NTL implementation; it took a fraction of a second on a standard computer. We prove that the problem of inverting the group action reduces to the problem of finding isogenies of fixed $\\tau$-degree between Drinfeld $\\mathbb F_q[X]$-modules, which is solvable in polynomial time thanks to an algorithm by Wesolowski. We give asymptotic complexity bounds for all algorithms presented in this paper.",
        "published": "2022-03-14T10:11:35Z",
        "link": "http://arxiv.org/abs/2203.06970v6",
        "categories": [
            "cs.SC",
            "cs.CR",
            "math.NT"
        ]
    },
    {
        "title": "A $p$-adic Descartes solver: the Strassman solver",
        "authors": [
            "Josué Tonelli-Cueto"
        ],
        "summary": "Solving polynomials is a fundamental computational problem in mathematics. In the real setting, we can use Descartes' rule of signs to efficiently isolate the real roots of a square-free real polynomial. In this paper, we translate this method into the $p$-adic worlds. We show how the $p$-adic analog of Descartes' rule of signs, Strassman's theorem, leads to an algorithm to isolate the roots of a square-free $p$-adic polynomial. Moreover, we show that this algorithm runs in $\\mathcal{O}(d^2\\log^3d)$-time for a random $p$-adic polynomial of degree $d$. To perform this analysis, we introduce the condition-based complexity framework from real/complex numerical algebraic geometry into $p$-adic numerical algebraic geometry.",
        "published": "2022-03-14T11:55:56Z",
        "link": "http://arxiv.org/abs/2203.07016v1",
        "categories": [
            "math.NT",
            "cs.CC",
            "cs.NA",
            "cs.SC",
            "math.NA",
            "math.PR",
            "11D88, 14Q20, 03D15"
        ]
    },
    {
        "title": "Linear slices of hyperbolic polynomials and positivity of symmetric   polynomial functions",
        "authors": [
            "Cordian Riener",
            "Robin Schabert"
        ],
        "summary": "A real univariate polynomial of degree $n$ is called hyperbolic if all of its $n$ roots are on the real line. Such polynomials appear quite naturally in different applications, for example, in combinatorics and optimization. The focus of this article are families of hyperbolic polynomials which are determined through $k$ linear conditions on the coefficients. The coefficients corresponding to such a family of hyperbolic polynomials form a semi-algebraic set which we call a \\emph{hyperbolic slice}. We initiate here the study of the geometry of these objects in more detail. The set of hyperbolic polynomials is naturally stratified with respect to the multiplicities of the real zeros and this stratification induces also a stratification on the hyperbolic slices. Our main focus here is on the \\emph{local extreme points} of hyperbolic slices, i.e., the local extreme points of linear functionals, and we show that these correspond precisely to those hyperbolic polynomials in the hyperbolic slice which have at most $k$ distinct roots and we can show that generically the convex hull of such a family is a polyhedron. Building on these results, we give consequences of our results to the study of symmetric real varieties and symmetric semi-algebraic sets. Here, we show that sets defined by symmetric polynomials which can be expressed sparsely in terms of elementary symmetric polynomials can be sampled on points with few distinct coordinates. This in turn allows for algorithmic simplifications, for example, to verify that such polynomials are non-negative or that a semi-algebraic set defined by such polynomials is empty.",
        "published": "2022-03-16T16:20:03Z",
        "link": "http://arxiv.org/abs/2203.08727v2",
        "categories": [
            "math.AG",
            "cs.SC",
            "math.OC",
            "14P05, 20C30, 90C30"
        ]
    },
    {
        "title": "AdaLoGN: Adaptive Logic Graph Network for Reasoning-Based Machine   Reading Comprehension",
        "authors": [
            "Xiao Li",
            "Gong Cheng",
            "Ziheng Chen",
            "Yawei Sun",
            "Yuzhong Qu"
        ],
        "summary": "Recent machine reading comprehension datasets such as ReClor and LogiQA require performing logical reasoning over text. Conventional neural models are insufficient for logical reasoning, while symbolic reasoners cannot directly apply to text. To meet the challenge, we present a neural-symbolic approach which, to predict an answer, passes messages over a graph representing logical relations between text units. It incorporates an adaptive logic graph network (AdaLoGN) which adaptively infers logical relations to extend the graph and, essentially, realizes mutual and iterative reinforcement between neural and symbolic reasoning. We also implement a novel subgraph-to-node message passing mechanism to enhance context-option interaction for answering multiple-choice questions. Our approach shows promising results on ReClor and LogiQA.",
        "published": "2022-03-16T23:51:01Z",
        "link": "http://arxiv.org/abs/2203.08992v1",
        "categories": [
            "cs.CL",
            "cs.AI",
            "cs.NE",
            "cs.SC"
        ]
    },
    {
        "title": "Gröbner bases and critical values: The asymptotic combinatorics of   determinantal systems",
        "authors": [
            "Alin Bostan",
            "Jérémy Berthomieu",
            "Andrew Ferguson",
            "Mohab Safey El Din"
        ],
        "summary": "We consider ideals involving the maximal minors of a polynomial matrix. For example, those arising in the computation of the critical values of a polynomial restricted to a variety for polynomial optimisation. Gr\\\"obner bases are a classical tool for solving polynomial systems. For practical computations, this consists of two stages. First, a Gr\\\"obner basis is computed with respect to a DRL (degree reverse lexicographic) ordering. Then, a change of ordering algorithm, such as \\textsf{Sparse-FGLM}, designed by Faug\\`ere and Mou, is used to find a Gr\\\"obner basis of the same ideal but with respect to a lexicographic ordering. The complexity of this latter step, in terms of arithmetic operations, is $O(mD^2)$, where $D$ is the degree of the ideal and $m$ is the number of non-trivial columns of a certain $D \\times D$ matrix. While asymptotic estimates are known for $m$ for generic polynomial systems, thus far, the complexity of \\textsf{Sparse-FGLM} was unknown for determinantal systems.   By assuming Fr\\\"oberg's conjecture we expand the work of Moreno-Soc\\'ias by detailing the structure of the DRL staircase in the determinantal setting. Then we study the asymptotics of the quantity $m$ by relating it to the coefficients of these Hilbert series. Consequently, we arrive at a new bound on the complexity of the \\textsf{Sparse-FGLM} algorithm for generic determinantal systems and for generic critical point systems. We consider the ideal in the polynomial ring $\\mathbb{K}[x_1, \\dots, x_n]$, where $\\mathbb{K}$ is some infinite field, generated by $p$ generic polynomials of degree $d$ and the maximal minors of a $p \\times (n-1)$ polynomial matrix with generic entries of degree $d-1$. Then for the case $d=2$ and for $n \\gg p$ we give an exact formula for $m$ in terms of $n$ and $p$. Moreover, for $d \\geq 3$, we give an asymptotic formula, as $n \\to \\infty$, for $m$ in terms of $n,p$ and $d$.",
        "published": "2022-03-18T15:37:01Z",
        "link": "http://arxiv.org/abs/2203.10021v1",
        "categories": [
            "math.AC",
            "cs.SC"
        ]
    },
    {
        "title": "Insights From the NeurIPS 2021 NetHack Challenge",
        "authors": [
            "Eric Hambro",
            "Sharada Mohanty",
            "Dmitrii Babaev",
            "Minwoo Byeon",
            "Dipam Chakraborty",
            "Edward Grefenstette",
            "Minqi Jiang",
            "Daejin Jo",
            "Anssi Kanervisto",
            "Jongmin Kim",
            "Sungwoong Kim",
            "Robert Kirk",
            "Vitaly Kurin",
            "Heinrich Küttler",
            "Taehwon Kwon",
            "Donghoon Lee",
            "Vegard Mella",
            "Nantas Nardelli",
            "Ivan Nazarov",
            "Nikita Ovsov",
            "Jack Parker-Holder",
            "Roberta Raileanu",
            "Karolis Ramanauskas",
            "Tim Rocktäschel",
            "Danielle Rothermel",
            "Mikayel Samvelyan",
            "Dmitry Sorokin",
            "Maciej Sypetkowski",
            "Michał Sypetkowski"
        ],
        "summary": "In this report, we summarize the takeaways from the first NeurIPS 2021 NetHack Challenge. Participants were tasked with developing a program or agent that can win (i.e., 'ascend' in) the popular dungeon-crawler game of NetHack by interacting with the NetHack Learning Environment (NLE), a scalable, procedurally generated, and challenging Gym environment for reinforcement learning (RL). The challenge showcased community-driven progress in AI with many diverse approaches significantly beating the previously best results on NetHack. Furthermore, it served as a direct comparison between neural (e.g., deep RL) and symbolic AI, as well as hybrid systems, demonstrating that on NetHack symbolic bots currently outperform deep RL by a large margin. Lastly, no agent got close to winning the game, illustrating NetHack's suitability as a long-term benchmark for AI research.",
        "published": "2022-03-22T17:01:07Z",
        "link": "http://arxiv.org/abs/2203.11889v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.NE",
            "cs.SC",
            "stat.ML"
        ]
    },
    {
        "title": "The SAGEX Review on Scattering Amplitudes, Chapter 4: Multi-loop Feynman   Integrals",
        "authors": [
            "Johannes Blümlein",
            "Carsten Schneider"
        ],
        "summary": "The analytic integration and simplification of multi-loop Feynman integrals to special functions and constants plays an important role to perform higher order perturbative calculations in the Standard Model of elementary particles. In this survey article the most recent and relevant computer algebra and special function algorithms are presented that are currently used or that may play an important role to perform such challenging precision calculations in the future. They are discussed in the context of analytic zero, single and double scale calculations in the Quantum Field Theories of the Standard Model and effective field theories, also with classical applications. These calculations play a central role in the analysis of precision measurements at present and future colliders to obtain ultimate information for fundamental physics.",
        "published": "2022-03-24T12:00:19Z",
        "link": "http://arxiv.org/abs/2203.13015v3",
        "categories": [
            "hep-th",
            "cs.SC",
            "hep-ph"
        ]
    },
    {
        "title": "Explainable Artificial Intelligence for Exhaust Gas Temperature of   Turbofan Engines",
        "authors": [
            "Marios Kefalas",
            "Juan de Santiago Rojo Jr.",
            "Asteris Apostolidis",
            "Dirk van den Herik",
            "Bas van Stein",
            "Thomas Bäck"
        ],
        "summary": "Data-driven modeling is an imperative tool in various industrial applications, including many applications in the sectors of aeronautics and commercial aviation. These models are in charge of providing key insights, such as which parameters are important on a specific measured outcome or which parameter values we should expect to observe given a set of input parameters. At the same time, however, these models rely heavily on assumptions (e.g., stationarity) or are \"black box\" (e.g., deep neural networks), meaning that they lack interpretability of their internal working and can be viewed only in terms of their inputs and outputs. An interpretable alternative to the \"black box\" models and with considerably less assumptions is symbolic regression (SR). SR searches for the optimal model structure while simultaneously optimizing the model's parameters without relying on an a-priori model structure. In this work, we apply SR on real-life exhaust gas temperature (EGT) data, collected at high frequencies through the entire flight, in order to uncover meaningful algebraic relationships between the EGT and other measurable engine parameters. The experimental results exhibit promising model accuracy, as well as explainability returning an absolute difference of 3{\\deg}C compared to the ground truth and demonstrating consistency from an engineering perspective.",
        "published": "2022-03-24T15:05:32Z",
        "link": "http://arxiv.org/abs/2203.13108v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.NE",
            "cs.SC"
        ]
    },
    {
        "title": "Artificial Intelligence Software Structured to Simulate Human Working   Memory, Mental Imagery, and Mental Continuity",
        "authors": [
            "Jared Edward Reser"
        ],
        "summary": "This article presents an artificial intelligence (AI) architecture intended to simulate the human working memory system as well as the manner in which it is updated iteratively. It features several interconnected neural networks designed to emulate the specialized modules of the cerebral cortex. These are structured hierarchically and integrated into a global workspace. They are capable of temporarily maintaining high-level patterns akin to the psychological items maintained in working memory. This maintenance is made possible by persistent neural activity in the form of two modalities: sustained neural firing (resulting in a focus of attention) and synaptic potentiation (resulting in a short-term store). This persistent activity is updated iteratively resulting in incremental changes to the content of the working memory system. As the content stored in working memory gradually evolves, successive states overlap and are continuous with one another. The present article will explore how this architecture can lead to gradual shift in the distribution of coactive representations, ultimately leading to mental continuity between processing states, and thus to human-like cognition.",
        "published": "2022-03-29T22:23:36Z",
        "link": "http://arxiv.org/abs/2204.05138v1",
        "categories": [
            "q-bio.NC",
            "cs.AI",
            "cs.LG",
            "cs.NE",
            "cs.SC"
        ]
    },
    {
        "title": "Matrix Multiplication with Less Arithmetic Complexity and IO Complexity",
        "authors": [
            "Pu Wu",
            "Huiqing Jiang",
            "Zehui Shao",
            "Jin Xu"
        ],
        "summary": "After Strassen presented the first sub-cubic matrix multiplication algorithm, many Strassen-like algorithms are presented. Most of them with low asymptotic cost have large hidden leading coefficient which are thus impractical. To reduce the leading coefficient, Cenk and Hasan give a general approach reducing the leading coefficient of $<2,2,2;7>$-algorithm to $5$ but increasing IO complexity. In 2017, Karstadt and Schwartz also reduce the leading coefficient of $<2,2,2;7>$-algorithm to $5$ by the Alternative Basis Matrix Multiplication method. Meanwhile, their method reduces the IO complexity and low-order monomials in arithmetic complexity. In 2019, Beniamini and Schwartz generalize Alternative Basis Matrix Multiplication method reducing leading coefficient in arithmetic complexity but increasing IO complexity. In this paper, we propose a new matrix multiplication algorithm which reduces leading coefficient both in arithmetic complexity and IO complexity. We apply our method to Strassen-like algorithms improving arithmetic complexity and IO complexity (the comparison with previous results are shown in Tables 1 and 2). Surprisingly, our IO complexity of $<3,3,3;23>$-algorithm is $14n^{\\log_323}M^{-\\frac{1}{2}} + o(n^{\\log_323})$ which breaks Ballard's IO complexity low bound ($\\Omega(n^{\\log_323}M^{1-\\frac{\\log_323}{2}})$) for recursive Strassen-like algorithms.",
        "published": "2022-03-30T04:45:15Z",
        "link": "http://arxiv.org/abs/2203.16053v1",
        "categories": [
            "cs.SC",
            "cs.DM",
            "68R01",
            "F.2.1; I.1.2"
        ]
    },
    {
        "title": "Computing critical points for algebraic systems defined by   hyperoctahedral invariant polynomials",
        "authors": [
            "Thi Xuan Vu"
        ],
        "summary": "Let $\\mathbb{K}$ be a field of characteristic zero and $\\mathbb{K}[x_1, \\dots, x_n]$ the corresponding multivariate polynomial ring. Given a sequence of $s$ polynomials $\\mathbf{f} = (f_1, \\dots, f_s)$ and a polynomial $\\phi$, all in $\\mathbb{K}[x_1, \\dots, x_n]$ with $s<n$, we consider the problem of computing the set $W(\\phi, \\mathbf{f})$ of points at which $\\mathbf{f}$ vanishes and the Jacobian matrix of $\\mathbf{f}, \\phi$ with respect to $x_1, \\dots, x_n$ does not have full rank. This problem plays an essential role in many application areas.   In this paper we focus on a case where the polynomials are all invariant under the action of the signed symmetric group $B_n$. We introduce a notion called {\\em hyperoctahedral representation} to describe $B_n$-invariant sets. We study the invariance properties of the input polynomials to split $W(\\phi, \\mathbf{f})$ according to the orbits of $B_n$ and then design an algorithm whose output is a {hyperoctahedral representation} of $W(\\phi, \\mathbf{f})$. The runtime of our algorithm is polynomial in the total number of points described by the output.",
        "published": "2022-03-30T06:46:50Z",
        "link": "http://arxiv.org/abs/2203.16094v2",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Explainable and Interpretable Diabetic Retinopathy Classification Based   on Neural-Symbolic Learning",
        "authors": [
            "Se-In Jang",
            "Michael J. A. Girard",
            "Alexandre H. Thiery"
        ],
        "summary": "In this paper, we propose an explainable and interpretable diabetic retinopathy (ExplainDR) classification model based on neural-symbolic learning. To gain explainability, a highlevel symbolic representation should be considered in decision making. Specifically, we introduce a human-readable symbolic representation, which follows a taxonomy style of diabetic retinopathy characteristics related to eye health conditions to achieve explainability. We then include humanreadable features obtained from the symbolic representation in the disease prediction. Experimental results on a diabetic retinopathy classification dataset show that our proposed ExplainDR method exhibits promising performance when compared to that from state-of-the-art methods applied to the IDRiD dataset, while also providing interpretability and explainability.",
        "published": "2022-04-01T00:54:12Z",
        "link": "http://arxiv.org/abs/2204.00624v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.CV",
            "cs.SC",
            "eess.IV"
        ]
    },
    {
        "title": "Reachability Analysis of Linear System",
        "authors": [
            "Shiping Chen",
            "Xinyu Ge"
        ],
        "summary": "In this paper, we propose a decision procedure of reachability for linear system {\\xi}' = A{\\xi} + u, where the matrix A's eigenvalues can be arbitrary algebraic numbers and the input u is a vector of trigonometric-exponential polynomials. If the initial set contains only one point, the reachability problem under consideration is resorted to the decidability of the sign of trigonometric-exponential polynomial and then achieved by being reduced to verification of a series of univariate polynomial inequalities through Taylor expansions of the related exponential functions and trigonometric functions. If the initial set is open semi-algebraic, we will propose a decision procedure based on openCAD and an algorithm of real roots isolation derivated from the sign-deciding procedure for the trigonometric-exponential polynomials. The experimental results indicate the efficiency of our approach. Furthermore, the above procedures are complete under the assumption of Schanuel Conjecture",
        "published": "2022-04-01T06:42:07Z",
        "link": "http://arxiv.org/abs/2204.00230v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "More Efficient Identifiability Verification in ODE Models by Reducing   Non-Identifiability",
        "authors": [
            "Ilia Ilmer",
            "Alexey Ovchinnikov",
            "Gleb Pogudin",
            "Pedro Soto"
        ],
        "summary": "Structural global parameter identifiability indicates whether one can determine a parameter's value from given inputs and outputs in the absence of noise. If a given model has parameters for which there may be infinitely many values, such parameters are called non-identifiable. We present a procedure for accelerating a global identifiability query by eliminating algebraically independent non-identifiable parameters. Our proposed approach significantly improves performance across different computer algebra frameworks.",
        "published": "2022-04-04T16:12:48Z",
        "link": "http://arxiv.org/abs/2204.01623v1",
        "categories": [
            "cs.SC",
            "cs.LG",
            "math.AG"
        ]
    },
    {
        "title": "A Vergleichsstellensatz of Strassen's Type for a Noncommutative   Preordered Semialgebra through the Semialgebra of its Fractions",
        "authors": [
            "Tao Zheng",
            "Lihong Zhi"
        ],
        "summary": "Preordered semialgebras and semirings are two kinds of algebraic structures occurring in real algebraic geometry frequently and usually play important roles therein. They have many interesting and promising applications in the fields of real algebraic geometry, probability theory, theoretical computer science, quantum information theory, \\emph{etc.}. In these applications, Strassen's Vergleichsstellensatz and its generalized versions, which are analogs of those Positivstellens\\\"atze in real algebraic geometry, play important roles. While these Vergleichsstellens\\\"atze accept only a commutative setting (for the semirings in question), we prove in this paper a noncommutative version of one of the generalized Vergleichsstellens\\\"atze proposed by Fritz [\\emph{Comm. Algebra}, 49 (2) (2021), pp. 482-499]. The most crucial step in our proof is to define the semialgebra of the fractions of a noncommutative semialgebra, which generalizes the definitions in the literature. Our new Vergleichsstellensatz characterizes the relaxed preorder on a noncommutative semialgebra induced by all monotone homomorphisms to $\\mathbb{R}_+$ by three other equivalent conditions on the semialgebra of its fractions equipped with the derived preorder, which may result in more applications in the future.",
        "published": "2022-04-06T04:47:34Z",
        "link": "http://arxiv.org/abs/2204.02577v3",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "A note on the van der Waerden conjecture on random polynomials with   symmetric Galois group for function fields",
        "authors": [
            "Erich L. Kaltofen"
        ],
        "summary": "Let f(x) = x^n + (a[n-1] t + b[n-1]) x^(n-1) + ... + (a[0] t + b[0]) be of constant degree n in x and degree <= 1 in t, where all a[i],b[i] are randomly and uniformly selected from a finite field GF(q) of q elements. Then the probability that the Galois group of f over the rational function field GF(q)(t) is the symmetric group S(n) on n elements is 1 - O(1/q). Furthermore, the probability that the Galois group of f(x) over GF(q)(t) is not S(n) is >= 1/q for n >= 3 and > 1/q - 1/(2q^2) for n = 2.",
        "published": "2022-04-06T14:00:28Z",
        "link": "http://arxiv.org/abs/2204.02836v2",
        "categories": [
            "math.NT",
            "cs.SC",
            "12E25, 12F10"
        ]
    },
    {
        "title": "Finding Counterfactual Explanations through Constraint Relaxations",
        "authors": [
            "Sharmi Dev Gupta",
            "Begum Genc",
            "Barry O'Sullivan"
        ],
        "summary": "Interactive constraint systems often suffer from infeasibility (no solution) due to conflicting user constraints. A common approach to recover infeasibility is to eliminate the constraints that cause the conflicts in the system. This approach allows the system to provide an explanation as: \"if the user is willing to drop out some of their constraints, there exists a solution\". However, one can criticise this form of explanation as not being very informative. A counterfactual explanation is a type of explanation that can provide a basis for the user to recover feasibility by helping them understand which changes can be applied to their existing constraints rather than removing them. This approach has been extensively studied in the machine learning field, but requires a more thorough investigation in the context of constraint satisfaction. We propose an iterative method based on conflict detection and maximal relaxations in over-constrained constraint satisfaction problems to help compute a counterfactual explanation.",
        "published": "2022-04-07T13:18:54Z",
        "link": "http://arxiv.org/abs/2204.03429v1",
        "categories": [
            "cs.AI",
            "cs.SC"
        ]
    },
    {
        "title": "Shift Equivalence Testing of Polynomials and Symbolic Summation of   Multivariate Rational Functions",
        "authors": [
            "Shaoshi Chen",
            "Lixin Du",
            "Hanqian Fang"
        ],
        "summary": "The Shift Equivalence Testing (SET) of polynomials is deciding whether two polynomials $p(x_1, \\ldots, x_m)$ and $q(x_1, \\ldots, x_m)$ satisfy the relation $p(x_1 + a_1, \\ldots, x_m + a_m) = q(x_1, \\ldots, x_m)$ for some $a_1, \\ldots, a_m$ in the coefficient field. The SET problem is one of basic computational problems in computer algebra and algebraic complexity theory, which was reduced by Dvir, Oliveira and Shpilka in 2014 to the Polynomial Identity Testing (PIT) problem. This paper presents a general scheme for designing algorithms to solve the SET problem which includes Dvir-Oliveira-Shpilka's algorithm as a special case. With the algorithms for the SET problem over integers, we give complete solutions to two challenging problems in symbolic summation of multivariate rational functions, namely the rational summability problem and the existence problem of telescopers for multivariate rational functions. Our approach is based on the structure of isotropy groups of polynomials introduced by Sato in 1960s. Our results can be used to detect the applicability of the Wilf-Zeilberger method to multivariate rational functions.",
        "published": "2022-04-14T13:48:52Z",
        "link": "http://arxiv.org/abs/2204.06968v2",
        "categories": [
            "cs.SC",
            "cs.CC",
            "math.RA",
            "68W30, 12H05, 12H10",
            "I.1.2"
        ]
    },
    {
        "title": "SymForce: Symbolic Computation and Code Generation for Robotics",
        "authors": [
            "Hayk Martiros",
            "Aaron Miller",
            "Nathan Bucki",
            "Bradley Solliday",
            "Ryan Kennedy",
            "Jack Zhu",
            "Tung Dang",
            "Dominic Pattison",
            "Harrison Zheng",
            "Teo Tomic",
            "Peter Henry",
            "Gareth Cross",
            "Josiah VanderMey",
            "Alvin Sun",
            "Samuel Wang",
            "Kristen Holtz"
        ],
        "summary": "We present SymForce, a library for fast symbolic computation, code generation, and nonlinear optimization for robotics applications like computer vision, motion planning, and controls. SymForce combines the development speed and flexibility of symbolic math with the performance of autogenerated, highly optimized code in C++ or any target runtime language. SymForce provides geometry and camera types, Lie group operations, and branchless singularity handling for creating and analyzing complex symbolic expressions in Python, built on top of SymPy. Generated functions can be integrated as factors into our tangent-space nonlinear optimizer, which is highly optimized for real-time production use. We introduce novel methods to automatically compute tangent-space Jacobians, eliminating the need for bug-prone handwritten derivatives. This workflow enables faster runtime code, faster development time, and fewer lines of handwritten code versus the state-of-the-art. Our experiments demonstrate that our approach can yield order of magnitude speedups on computational tasks core to robotics. Code is available at https://github.com/symforce-org/symforce.",
        "published": "2022-04-17T00:15:10Z",
        "link": "http://arxiv.org/abs/2204.07889v2",
        "categories": [
            "cs.RO",
            "cs.CV",
            "cs.SC"
        ]
    },
    {
        "title": "Calculation of Integrals in MathPartner",
        "authors": [
            "Gennadi I. Malaschonok",
            "Alexandr V. Seliverstov"
        ],
        "summary": "We present the possibilities provided by the MathPartner service of calculating definite and indefinite integrals. MathPartner contains software implementation of the Risch algorithm and provides users with the ability to compute antiderivatives for elementary functions. Certain integrals, including improper integrals, can be calculated using numerical algorithms. In this case, every user has the ability to indicate the required accuracy with which he needs to know the numerical value of the integral. We highlight special functions allowing us to calculate complete elliptic integrals. These include functions for calculating the arithmetic-geometric mean and the geometric-harmonic mean, which allow us to calculate the complete elliptic integrals of the first kind. The set also includes the modified arithmetic-geometric mean, proposed by Semjon Adlaj, which allows us to calculate the complete elliptic integrals of the second kind as well as the circumference of an ellipse. The Lagutinski algorithm is of particular interest. For given differentiation in the field of bivariate rational functions, one can decide whether there exists a rational integral. The algorithm is based on calculating the Lagutinski determinant. Mikhail Lagutinski (1871--1915) had worked at Kharkiv (Ukraine). This year we are celebrating his 150th anniversary.",
        "published": "2022-04-23T12:26:31Z",
        "link": "http://arxiv.org/abs/2204.11061v1",
        "categories": [
            "cs.SC",
            "68W30",
            "I.1.0"
        ]
    },
    {
        "title": "New features in MathPartner 2021",
        "authors": [
            "Gennadi Malaschonok",
            "Alexandr Seliverstov"
        ],
        "summary": "We introduce new features in the MathPartner service that have recently become available to users. We highlight the functions for calculating both arithmetic-geometric mean and geometric-harmonic mean. They allow calculating complete elliptic integrals of the first kind. They are useful for solving many physics problems, for example, one can calculate the period of a simple pendulum. Next, one can calculate the modified arithmetic-geometric mean proposed by Semjon Adlaj. Consequently, one can calculate the complete elliptic integrals of the second kind as well as the circumference of an ellipse. Furthermore, one can also calculate the Sylvester matrices of the first and the second kind. Thus, by means of a few strings, one can calculate the resultant of two polynomials as well as the discriminant of a binary form. Some new matrix functions are also added. So, today the list of matrix functions includes the transpose, adjugate, conjugate, inverse, generalized inverse, and pseudo inverse of a matrix, the matrix determinant, the kernel, the echelon form, the characteristic polynomial, the Bruhat decomposition, the triangular LSU decomposition, which is an exact block recursive LU decomposition, the QR block recursive decomposition, and the singular value decomposition. In addition, two block-recursive functions have been implemented for calculating the Cholesky decomposition of symmetric positive-definite matrices: one function for sparse matrices with the standard multiplication algorithm and another function for dense matrices with multiplication according to the Winograd--Strassen algorithm. The linear programming problems can be solved too. So, the MathPartner service has become better and handy. It is freely available at http://mathpar.ukma.edu.ua/ as well as at http://mathpar.com.",
        "published": "2022-04-23T18:11:46Z",
        "link": "http://arxiv.org/abs/2204.11118v1",
        "categories": [
            "cs.SC",
            "68W30",
            "I.1.4"
        ]
    },
    {
        "title": "MathPartner Computer Algebra",
        "authors": [
            "Gennadi Malaschonok"
        ],
        "summary": "In this paper, we describe general characteristics of the MathPartner computer algebra system (CAS) and Mathpar programming language thereof. MathPartner can be used for scientific and engineering calculations, as well as in high schools and universities. It allows one to carry out both simple calculations (acting as a scientific calculator) and complex calculations with large-scale mathematical objects. Mathpar is a procedural language; it supports a large number of elementary and special functions, as well as matrix and polynomial operators. This service allows one to build function images and animate them. MathPartner also makes it possible to solve some symbolic computation problems on supercomputers with distributed memory. We highlight main differences of MathPartner from other CASs and describe the Mathpar language along with the user service provided.",
        "published": "2022-04-25T10:49:10Z",
        "link": "http://arxiv.org/abs/2204.11549v1",
        "categories": [
            "cs.SC",
            "68W30",
            "I.1.4"
        ]
    },
    {
        "title": "About MathPartner web service",
        "authors": [
            "Gennadi Malaschonok",
            "Ivan Borisov"
        ],
        "summary": "The report is devoted to the current state of the MathPartner computer algebra web project. We discuss the main directions of development of the project and give several examples of using it to solve selected problems.",
        "published": "2022-04-25T15:39:05Z",
        "link": "http://arxiv.org/abs/2206.07088v1",
        "categories": [
            "cs.SC",
            "68W30",
            "I.1.4"
        ]
    },
    {
        "title": "LoopStack: a Lightweight Tensor Algebra Compiler Stack",
        "authors": [
            "Bram Wasti",
            "José Pablo Cambronero",
            "Benoit Steiner",
            "Hugh Leather",
            "Aleksandar Zlateski"
        ],
        "summary": "We present LoopStack, a domain specific compiler stack for tensor operations, composed of a frontend, LoopTool, and an efficient optimizing code generator, LoopNest. This stack enables us to compile entire neural networks and generate code targeting the AVX2, AVX512, NEON, and NEONfp16 instruction sets while incorporating optimizations often missing from other machine learning compiler backends. We evaluate our stack on a collection of full neural networks and commonly used network blocks as well as individual operators, and show that LoopStack generates machine code that matches and frequently exceeds the performance of in state-of-the-art machine learning frameworks in both cases. We also show that for a large collection of schedules LoopNest's compilation is orders of magnitude faster than LLVM, while resulting in equal or improved run time performance. Additionally, LoopStack has a very small memory footprint - a binary size of 245KB, and under 30K lines of effective code makes it ideal for use on mobile and embedded devices.",
        "published": "2022-05-02T01:57:58Z",
        "link": "http://arxiv.org/abs/2205.00618v1",
        "categories": [
            "cs.LG",
            "cs.PF",
            "cs.SC"
        ]
    },
    {
        "title": "Neurocompositional computing: From the Central Paradox of Cognition to a   new generation of AI systems",
        "authors": [
            "Paul Smolensky",
            "R. Thomas McCoy",
            "Roland Fernandez",
            "Matthew Goldrick",
            "Jianfeng Gao"
        ],
        "summary": "What explains the dramatic progress from 20th-century to 21st-century AI, and how can the remaining limitations of current AI be overcome? The widely accepted narrative attributes this progress to massive increases in the quantity of computational and data resources available to support statistical learning in deep artificial neural networks. We show that an additional crucial factor is the development of a new type of computation. Neurocompositional computing adopts two principles that must be simultaneously respected to enable human-level cognition: the principles of Compositionality and Continuity. These have seemed irreconcilable until the recent mathematical discovery that compositionality can be realized not only through discrete methods of symbolic computing, but also through novel forms of continuous neural computing. The revolutionary recent progress in AI has resulted from the use of limited forms of neurocompositional computing. New, deeper forms of neurocompositional computing create AI systems that are more robust, accurate, and comprehensible.",
        "published": "2022-05-02T18:00:10Z",
        "link": "http://arxiv.org/abs/2205.01128v1",
        "categories": [
            "cs.AI",
            "cs.NE",
            "cs.SC"
        ]
    },
    {
        "title": "Does a Program Yield the Right Distribution? Verifying Probabilistic   Programs via Generating Functions",
        "authors": [
            "Mingshuai Chen",
            "Joost-Pieter Katoen",
            "Lutz Klinkenberg",
            "Tobias Winkler"
        ],
        "summary": "We study discrete probabilistic programs with potentially unbounded looping behaviors over an infinite state space. We present, to the best of our knowledge, the first decidability result for the problem of determining whether such a program generates exactly a specified distribution over its outputs (provided the program terminates almost surely). The class of distributions that can be specified in our formalism consists of standard distributions (geometric, uniform, etc.) and finite convolutions thereof. Our method relies on representing these (possibly infinite-support) distributions as probability generating functions which admit effective arithmetic operations. We have automated our techniques in a tool called prodigy, which supports automatic invariance checking, compositional reasoning of nested loops, and efficient queries on various quantities of to the output distribution, as demonstrated by experiments.",
        "published": "2022-05-03T12:21:59Z",
        "link": "http://arxiv.org/abs/2205.01449v2",
        "categories": [
            "cs.LO",
            "cs.SC"
        ]
    },
    {
        "title": "Moment-based Invariants for Probabilistic Loops with Non-polynomial   Assignments",
        "authors": [
            "Andrey Kofnov",
            "Marcel Moosbrugger",
            "Miroslav Stankovič",
            "Ezio Bartocci",
            "Efstathia Bura"
        ],
        "summary": "We present a method to automatically approximate moment-based invariants of probabilistic programs with non-polynomial updates of continuous state variables to accommodate more complex dynamics. Our approach leverages polynomial chaos expansion to approximate non-linear functional updates as sums of orthogonal polynomials. We exploit this result to automatically estimate state-variable moments of all orders in Prob-solvable loops with non-polynomial updates. We showcase the accuracy of our estimation approach in several examples, such as the turning vehicle model and the Taylor rule in monetary policy.",
        "published": "2022-05-05T11:19:37Z",
        "link": "http://arxiv.org/abs/2205.02577v3",
        "categories": [
            "stat.AP",
            "cs.SC",
            "62G05 (Primary) 62P30 (Secondary)",
            "G.3"
        ]
    },
    {
        "title": "The GPGCD Algorithm with the Bézout Matrix for Multiple Univariate   Polynomials",
        "authors": [
            "Boming Chi",
            "Akira Terui"
        ],
        "summary": "We propose a modification of the GPGCD algorithm, which has been presented in our previous research, for calculating approximate greatest common divisor (GCD) of more than 2 univariate polynomials with real coefficients and a given degree. In transferring the approximate GCD problem to a constrained minimization problem, different from the original GPGCD algorithm for multiple polynomials which uses the Sylvester subresultant matrix, the proposed algorithm uses the B\\'ezout matrix. Experiments show that the proposed algorithm is more efficient than the original GPGCD algorithm for multiple polynomials with maintaining almost the same accuracy for most of the cases.",
        "published": "2022-05-06T02:24:05Z",
        "link": "http://arxiv.org/abs/2205.02984v1",
        "categories": [
            "math.AC",
            "cs.NA",
            "cs.SC",
            "math.NA",
            "13P99, 68W30",
            "I.1.2; F.2.1; G.1.6"
        ]
    },
    {
        "title": "Structured, flexible, and robust: benchmarking and improving large   language models towards more human-like behavior in out-of-distribution   reasoning tasks",
        "authors": [
            "Katherine M. Collins",
            "Catherine Wong",
            "Jiahai Feng",
            "Megan Wei",
            "Joshua B. Tenenbaum"
        ],
        "summary": "Human language offers a powerful window into our thoughts -- we tell stories, give explanations, and express our beliefs and goals through words. Abundant evidence also suggests that language plays a developmental role in structuring our learning. Here, we ask: how much of human-like thinking can be captured by learning statistical patterns in language alone? We first contribute a new challenge benchmark for comparing humans and distributional large language models (LLMs). Our benchmark contains two problem-solving domains (planning and explanation generation) and is designed to require generalization to new, out-of-distribution problems expressed in language. We find that humans are far more robust than LLMs on this benchmark. Next, we propose a hybrid Parse-and-Solve model, which augments distributional LLMs with a structured symbolic reasoning module. We find that this model shows more robust adaptation to out-of-distribution planning problems, demonstrating the promise of hybrid AI models for more human-like reasoning.",
        "published": "2022-05-11T18:14:33Z",
        "link": "http://arxiv.org/abs/2205.05718v1",
        "categories": [
            "cs.CL",
            "cs.AI",
            "cs.LG",
            "cs.SC"
        ]
    },
    {
        "title": "Normalization, Square Roots, and the Exponential and Logarithmic Maps in   Geometric Algebras of Less than 6D",
        "authors": [
            "Steven De Keninck",
            "Martin Roelfs"
        ],
        "summary": "Geometric algebras of dimension $n < 6$ are becoming increasingly popular for the modeling of 3D and 3+1D geometry. With this increased popularity comes the need for efficient algorithms for common operations such as normalization, square roots, and exponential and logarithmic maps. The current work presents a signature agnostic analysis of these common operations in all geometric algebras of dimension $n < 6$, and gives efficient numerical implementations in the most popular algebras $\\mathbb{R}_{4}$, $\\mathbb{R}_{3,1}$, $\\mathbb{R}_{3,0,1}$ and $\\mathbb{R}_{4,1}$, in the hopes of lowering the threshold for adoption of geometric algebra solutions by code maintainers.",
        "published": "2022-05-11T21:11:41Z",
        "link": "http://arxiv.org/abs/2206.07496v2",
        "categories": [
            "cs.CG",
            "cs.SC",
            "15A67"
        ]
    },
    {
        "title": "Order-Degree-Height Surfaces for Linear Operators",
        "authors": [
            "Hui Huang",
            "Manuel Kauers",
            "Gargi Mukherjee"
        ],
        "summary": "It is known for linear operators with polynomial coefficients annihilating a given D-finite function that there is a trade-off between order and degree. Raising the order may give room for lowering the degree. The relationship between order and degree is typically described by a hyperbola known as the order-degree curve. In this paper, we add the height into the picture, i.e., a measure for the size of the coefficients in the polynomial coefficients. For certain situations, we derive relationships between order, degree, and height that can be viewed as order-degree-height surfaces.",
        "published": "2022-05-12T11:28:07Z",
        "link": "http://arxiv.org/abs/2205.06030v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Skew-sparse matrix multiplication",
        "authors": [
            "Qiao-Long Huang",
            "Ke Ye",
            "Xiao-Shan Gao"
        ],
        "summary": "Based on the observation that $\\mathbb{Q}^{(p-1) \\times (p-1)}$ is isomorphic to a quotient skew polynomial ring, we propose a new method for $(p-1)\\times (p-1)$ matrix multiplication over $\\mathbb{Q}$, where $p$ is a prime number. The main feature of our method is the acceleration for matrix multiplication if the product is skew-sparse. Based on the new method, we design a deterministic algorithm with complexity $O(T^{\\omega-2} p^2)$, where $T\\le p-1$ is a parameter determined by the skew-sparsity of input matrices and $\\omega$ is the asymptotic exponent of matrix multiplication. Moreover, by introducing randomness, we also propose a probabilistic algorithm with complexity $O^\\thicksim(t^{\\omega-2}p^2+p^2\\log\\frac{1}{\\nu})$, where $t\\le p-1$ is the skew-sparsity of the product and $\\nu$ is the probability parameter.",
        "published": "2022-05-13T02:44:03Z",
        "link": "http://arxiv.org/abs/2205.06429v1",
        "categories": [
            "cs.CC",
            "cs.NA",
            "cs.SC",
            "math.NA"
        ]
    },
    {
        "title": "Qualitative dynamics of chemical reaction networks: an investigation   using partial tropical equilibrations",
        "authors": [
            "Aurélien Desoeuvres",
            "Peter Szmolyan",
            "Ovidiu Radulescu"
        ],
        "summary": "We discuss a method to describe the qualitative dynamics of chemical reaction networks in terms of symbolic dynamics. The method, that can be applied to mass-action reaction networks with separated timescales, uses solutions of the partial tropical equilibration problem as proxies for symbolic states. The partial tropical equilibration solutions are found algorithmically. These solutions also provide the scaling needed for slow-fast decomposition and model reduction. Any trace of the model can thus be represented as a sequence of local approximations of the full model. We illustrate the method using as case study a biochemical model of the cell cycle.",
        "published": "2022-05-15T19:19:33Z",
        "link": "http://arxiv.org/abs/2205.07360v1",
        "categories": [
            "q-bio.MN",
            "cs.SC",
            "math.DS"
        ]
    },
    {
        "title": "Locating the Closest Singularity in a Polynomial Homotopy",
        "authors": [
            "Jan Verschelde",
            "Kylash Viswanathan"
        ],
        "summary": "A polynomial homotopy is a family of polynomial systems, where the systems in the family depend on one parameter. If for one value of the parameter we know a regular solution, then what is the nearest value of the parameter for which the solution in the polynomial homotopy is singular? For this problem we apply the ratio theorem of Fabry. Richardson extrapolation is effective to accelerate the convergence of the ratios of the coefficients of the series expansions of the solution paths defined by the homotopy. For numerical stability, we recondition the homotopy. To compute the coefficients of the series we propose the quaternion Fourier transform. We locate the closest singularity computing at a regular solution, avoiding numerical difficulties near a singularity.",
        "published": "2022-05-15T21:13:10Z",
        "link": "http://arxiv.org/abs/2205.07380v2",
        "categories": [
            "cs.SC",
            "cs.NA",
            "math.AG",
            "math.NA"
        ]
    },
    {
        "title": "Symbolic-Numeric Factorization of Differential Operators",
        "authors": [
            "Frédéric Chyzak",
            "Alexandre Goyer",
            "Marc Mezzarobba"
        ],
        "summary": "We present a symbolic-numeric Las Vegas algorithm for factoring Fuchsian ordinary differential operators with rational function coefficients. The new algorithm combines ideas of van Hoeij's \"local-to-global\" method and of the ''analytic'' approach proposed by van der Hoeven. It essentially reduces to the former in ''easy'' cases where the local-to-global method succeeds, and to an optimized variant of the latter in the \"hardest\" cases, while handling intermediate cases more efficiently than both.",
        "published": "2022-05-18T15:23:05Z",
        "link": "http://arxiv.org/abs/2205.08991v3",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Solving sparse polynomial systems using Groebner bases and resultants",
        "authors": [
            "Matías R. Bender"
        ],
        "summary": "Solving systems of polynomial equations is a central problem in nonlinear and computational algebra. Since Buchberger's algorithm for computing Gr\\\"obner bases in the 60s, there has been a lot of progress in this domain. Moreover, these equations have been employed to model and solve problems from diverse disciplines such as biology, cryptography, and robotics. Currently, we have a good understanding of how to solve generic systems from a theoretical and algorithmic point of view. However, polynomial equations encountered in practice are usually structured, and so many properties and results about generic systems do not apply to them. For this reason, a common trend in the last decades has been to develop mathematical and algorithmic frameworks to exploit specific structures of systems of polynomials.   Arguably, the most common structure is sparsity; that is, the polynomials of the systems only involve a few monomials. Since Bernstein, Khovanskii, and Kushnirenko's work on the expected number of solutions of sparse systems, toric geometry has been the default mathematical framework to employ sparsity. In particular, it is the crux of the matter behind the extension of classical tools to systems, such as resultant computations, homotopy continuation methods, and most recently, Gr\\\"obner bases. In this work, we will review these classical tools, their extensions, and recent progress in exploiting sparsity for solving polynomial systems.   This manuscript complements its homonymous tutorial presented at the conference ISSAC 2022.",
        "published": "2022-05-19T22:38:23Z",
        "link": "http://arxiv.org/abs/2205.09888v1",
        "categories": [
            "cs.SC",
            "math.AG"
        ]
    },
    {
        "title": "Unsupervised Tokenization Learning",
        "authors": [
            "Anton Kolonin",
            "Vignav Ramesh"
        ],
        "summary": "In the presented study, we discover that the so-called \"transition freedom\" metric appears superior for unsupervised tokenization purposes in comparison to statistical metrics such as mutual information and conditional probability, providing F-measure scores in range from 0.71 to 1.0 across explored multilingual corpora. We find that different languages require different offshoots of that metric (such as derivative, variance, and \"peak values\") for successful tokenization. Larger training corpora do not necessarily result in better tokenization quality, while compressing the models by eliminating statistically weak evidence tends to improve performance. The proposed unsupervised tokenization technique provides quality better than or comparable to lexicon-based ones, depending on the language.",
        "published": "2022-05-23T16:33:41Z",
        "link": "http://arxiv.org/abs/2205.11443v4",
        "categories": [
            "cs.CL",
            "cs.AI",
            "cs.SC"
        ]
    },
    {
        "title": "VWSIM: A Circuit Simulator",
        "authors": [
            "Warren A. Hunt Jr.",
            "Vivek Ramanathan",
            "J Strother Moore"
        ],
        "summary": "VWSIM is a circuit simulator for rapid, single-flux, quantum (RSFQ) circuits. The simulator is designed to model and simulate primitive-circuit devices such as capacitors, inductors, Josephson Junctions, and can be extended to simulate other circuit families, such as CMOS. Circuit models can be provided in the native VWSIM netlist format or as SPICE-compatible netlists, which are flattened and transformed into symbolic equations that can be manipulated and simulated. Written in the ACL2 logic, VWSIM provides logical guarantees about each of the circuit models it simulates. Note, our matrix solving and evaluation routines use Common Lisp floating-point numbers, and work is ongoing to admit these models into ACL2. We currently use VWSIM to help us design self-timed, RSFQ-based circuits. Our eventual goal is to prove properties of RSFQ circuit models. The ACL2-based definition of the VWSIM simulator offers a path for specifying and verifying RSFQ circuit models.",
        "published": "2022-05-24T01:16:21Z",
        "link": "http://arxiv.org/abs/2205.11698v1",
        "categories": [
            "cs.LO",
            "cs.MS",
            "cs.SC",
            "B.1.2; B.7.2; D.1.1; D.2.4; F.3.1; F.4.1; G.1.3; I.1.3; I.2.3;\n  I.6.4; J.2"
        ]
    },
    {
        "title": "FabKG: A Knowledge graph of Manufacturing Science domain utilizing   structured and unconventional unstructured knowledge source",
        "authors": [
            "Aman Kumar",
            "Akshay G Bharadwaj",
            "Binil Starly",
            "Collin Lynch"
        ],
        "summary": "As the demands for large-scale information processing have grown, knowledge graph-based approaches have gained prominence for representing general and domain knowledge. The development of such general representations is essential, particularly in domains such as manufacturing which intelligent processes and adaptive education can enhance. Despite the continuous accumulation of text in these domains, the lack of structured data has created information extraction and knowledge transfer barriers. In this paper, we report on work towards developing robust knowledge graphs based upon entity and relation data for both commercial and educational uses. To create the FabKG (Manufacturing knowledge graph), we have utilized textbook index words, research paper keywords, FabNER (manufacturing NER), to extract a sub knowledge base contained within Wikidata. Moreover, we propose a novel crowdsourcing method for KG creation by leveraging student notes, which contain invaluable information but are not captured as meaningful information, excluding their use in personal preparation for learning and written exams. We have created a knowledge graph containing 65000+ triples using all data sources. We have also shown the use case of domain-specific question answering and expression/formula-based question answering for educational purposes.",
        "published": "2022-05-24T02:32:04Z",
        "link": "http://arxiv.org/abs/2206.10318v1",
        "categories": [
            "cs.CL",
            "cs.AI",
            "cs.SC"
        ]
    },
    {
        "title": "Symbolic Physics Learner: Discovering governing equations via Monte   Carlo tree search",
        "authors": [
            "Fangzheng Sun",
            "Yang Liu",
            "Jian-Xun Wang",
            "Hao Sun"
        ],
        "summary": "Nonlinear dynamics is ubiquitous in nature and commonly seen in various science and engineering disciplines. Distilling analytical expressions that govern nonlinear dynamics from limited data remains vital but challenging. To tackle this fundamental issue, we propose a novel Symbolic Physics Learner (SPL) machine to discover the mathematical structure of nonlinear dynamics. The key concept is to interpret mathematical operations and system state variables by computational rules and symbols, establish symbolic reasoning of mathematical formulas via expression trees, and employ a Monte Carlo tree search (MCTS) agent to explore optimal expression trees based on measurement data. The MCTS agent obtains an optimistic selection policy through the traversal of expression trees, featuring the one that maps to the arithmetic expression of underlying physics. Salient features of the proposed framework include search flexibility and enforcement of parsimony for discovered equations. The efficacy and superiority of the SPL machine are demonstrated by numerical examples, compared with state-of-the-art baselines.",
        "published": "2022-05-26T03:50:52Z",
        "link": "http://arxiv.org/abs/2205.13134v2",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.SC",
            "nlin.CD",
            "physics.comp-ph"
        ]
    },
    {
        "title": "Zero-Hopf Bifurcation of Limit Cycles in Certain Differential Systems",
        "authors": [
            "Bo Huang",
            "Dongming Wang"
        ],
        "summary": "This paper studies the number of limit cycles that may bifurcate from an equilibrium of an autonomous system of differential equations. The system in question is assumed to be of dimension $n$, have a zero-Hopf equilibrium at the origin, and consist only of homogeneous terms of order $m$. Denote by $H_k(n,m)$ the maximum number of limit cycles of the system that can be detected by using the averaging method of order $k$. We prove that $H_1(n,m)\\leq(m-1)\\cdot m^{n-2}$ and $H_k(n,m)\\leq(km)^{n-1}$ for generic $n\\geq3$, $m\\geq2$ and $k>1$. The exact numbers of $H_k(n,m)$ or tight bounds on the numbers are determined by computing the mixed volumes of some polynomial systems obtained from the averaged functions. Based on symbolic and algebraic computation, a general and algorithmic approach is proposed to derive sufficient conditions for a given differential system to have a prescribed number of limit cycles. The effectiveness of the proposed approach is illustrated by a family of third-order differential equations and by a four-dimensional hyperchaotic differential system.",
        "published": "2022-05-28T15:01:08Z",
        "link": "http://arxiv.org/abs/2205.14450v3",
        "categories": [
            "math.DS",
            "cs.SC"
        ]
    },
    {
        "title": "Flat singularities of chained systems, illustrated with an aircraft   model",
        "authors": [
            "Yirmeyahu J. Kaminski",
            "François Ollivier"
        ],
        "summary": "We consider flat differential control systems for which there exist flat outputs that are part of the state variables and study them using Jacobi bound. We introduce a notion of saddle Jacobi bound for an ordinary differential system of $n$ equations in $n+m$ variables. Systems with saddle Jacobi number equal to $0$ generalize various notions of chained and diagonal systems and form the widest class of systems admitting subsets of state variables as flat output, for which flat parametrization may be computed without differentiating the initial equations. We investigate apparent and intrinsic flat singularities of such systems. As an illustration, we consider the case of a simplified aircraft model, providing new flat outputs and showing that it is flat at all points except possibly in stalling conditions. Finally, we present numerical simulations showing that a feedback using those flat outputs is robust to perturbations and can also compensate model errors, when using a more realistic aerodynamic model.",
        "published": "2022-05-29T09:04:04Z",
        "link": "http://arxiv.org/abs/2205.14608v6",
        "categories": [
            "math.OC",
            "cs.SC",
            "cs.SY",
            "eess.SY",
            "93-08 (primary), 68W30 (secondary)",
            "I.6.3; I.1.0"
        ]
    },
    {
        "title": "Gluing Neural Networks Symbolically Through Hyperdimensional Computing",
        "authors": [
            "Peter Sutor",
            "Dehao Yuan",
            "Douglas Summers-Stay",
            "Cornelia Fermuller",
            "Yiannis Aloimonos"
        ],
        "summary": "Hyperdimensional Computing affords simple, yet powerful operations to create long Hyperdimensional Vectors (hypervectors) that can efficiently encode information, be used for learning, and are dynamic enough to be modified on the fly. In this paper, we explore the notion of using binary hypervectors to directly encode the final, classifying output signals of neural networks in order to fuse differing networks together at the symbolic level. This allows multiple neural networks to work together to solve a problem, with little additional overhead. Output signals just before classification are encoded as hypervectors and bundled together through consensus summation to train a classification hypervector. This process can be performed iteratively and even on single neural networks by instead making a consensus of multiple classification hypervectors. We find that this outperforms the state of the art, or is on a par with it, while using very little overhead, as hypervector operations are extremely fast and efficient in comparison to the neural networks. This consensus process can learn online and even grow or lose models in real time. Hypervectors act as memories that can be stored, and even further bundled together over time, affording life long learning capabilities. Additionally, this consensus structure inherits the benefits of Hyperdimensional Computing, without sacrificing the performance of modern Machine Learning. This technique can be extrapolated to virtually any neural model, and requires little modification to employ - one simply requires recording the output signals of networks when presented with a testing example.",
        "published": "2022-05-31T04:44:02Z",
        "link": "http://arxiv.org/abs/2205.15534v1",
        "categories": [
            "cs.SC",
            "cs.AI",
            "cs.CV",
            "cs.LG"
        ]
    },
    {
        "title": "Elementary remarks about Pisano periods",
        "authors": [
            "Gérard Henry Edmond Duchamp",
            "Pierre Simonnet"
        ],
        "summary": "In this short note, we reprove in a very elementary way some known facts about Pisano periods as well as some considerations about the link between Pisano periods and the order of roots of the characteristic equation. The technics only requires a small background in ring theory (merely the definition of a commutative ring). The tools set here can be reused for all linear recurrences with quadratic non-constant characteristic equation.",
        "published": "2022-06-01T08:09:23Z",
        "link": "http://arxiv.org/abs/2206.07095v2",
        "categories": [
            "cs.SC",
            "math.CO"
        ]
    },
    {
        "title": "Bayesian Learning to Discover Mathematical Operations in Governing   Equations of Dynamic Systems",
        "authors": [
            "Hongpeng Zhou",
            "Wei Pan"
        ],
        "summary": "Discovering governing equations from data is critical for diverse scientific disciplines as they can provide insights into the underlying phenomenon of dynamic systems. This work presents a new representation for governing equations by designing the Mathematical Operation Network (MathONet) with a deep neural network-like hierarchical structure. Specifically, the MathONet is stacked by several layers of unary operations (e.g., sin, cos, log) and binary operations (e.g., +,-), respectively. An initialized MathONet is typically regarded as a super-graph with a redundant structure, a sub-graph of which can yield the governing equation. We develop a sparse group Bayesian learning algorithm to extract the sub-graph by employing structurally constructed priors over the redundant mathematical operations. By demonstrating the chaotic Lorenz system, Lotka-Volterra system, and Kolmogorov-Petrovsky-Piskunov system, the proposed method can discover the ordinary differential equations (ODEs) and partial differential equations (PDEs) from the observations given limited mathematical operations, without any prior knowledge on possible expressions of the ODEs and PDEs.",
        "published": "2022-06-01T10:31:14Z",
        "link": "http://arxiv.org/abs/2206.00669v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.SC"
        ]
    },
    {
        "title": "Drawing out of Distribution with Neuro-Symbolic Generative Models",
        "authors": [
            "Yichao Liang",
            "Joshua B. Tenenbaum",
            "Tuan Anh Le",
            "N. Siddharth"
        ],
        "summary": "Learning general-purpose representations from perceptual inputs is a hallmark of human intelligence. For example, people can write out numbers or characters, or even draw doodles, by characterizing these tasks as different instantiations of the same generic underlying process -- compositional arrangements of different forms of pen strokes. Crucially, learning to do one task, say writing, implies reasonable competence at another, say drawing, on account of this shared process. We present Drawing out of Distribution (DooD), a neuro-symbolic generative model of stroke-based drawing that can learn such general-purpose representations. In contrast to prior work, DooD operates directly on images, requires no supervision or expensive test-time inference, and performs unsupervised amortised inference with a symbolic stroke model that better enables both interpretability and generalization. We evaluate DooD on its ability to generalise across both data and tasks. We first perform zero-shot transfer from one dataset (e.g. MNIST) to another (e.g. Quickdraw), across five different datasets, and show that DooD clearly outperforms different baselines. An analysis of the learnt representations further highlights the benefits of adopting a symbolic stroke model. We then adopt a subset of the Omniglot challenge tasks, and evaluate its ability to generate new exemplars (both unconditionally and conditionally), and perform one-shot classification, showing that DooD matches the state of the art. Taken together, we demonstrate that DooD does indeed capture general-purpose representations across both data and task, and takes a further step towards building general and robust concept-learning systems.",
        "published": "2022-06-03T21:40:22Z",
        "link": "http://arxiv.org/abs/2206.01829v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.CV",
            "cs.NE",
            "cs.SC"
        ]
    },
    {
        "title": "OntoMerger: An Ontology Integration Library for Deduplicating and   Connecting Knowledge Graph Nodes",
        "authors": [
            "David Geleta",
            "Andriy Nikolov",
            "Mark ODonoghue",
            "Benedek Rozemberczki",
            "Anna Gogleva",
            "Valentina Tamma",
            "Terry R. Payne"
        ],
        "summary": "Duplication of nodes is a common problem encountered when building knowledge graphs (KGs) from heterogeneous datasets, where it is crucial to be able to merge nodes having the same meaning. OntoMerger is a Python ontology integration library whose functionality is to deduplicate KG nodes. Our approach takes a set of KG nodes, mappings and disconnected hierarchies and generates a set of merged nodes together with a connected hierarchy. In addition, the library provides analytic and data testing functionalities that can be used to fine-tune the inputs, further reducing duplication, and to increase connectivity of the output graph. OntoMerger can be applied to a wide variety of ontologies and KGs. In this paper we introduce OntoMerger and illustrate its functionality on a real-world biomedical KG.",
        "published": "2022-06-05T18:52:26Z",
        "link": "http://arxiv.org/abs/2206.02238v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.SC"
        ]
    },
    {
        "title": "A computational framework for weighted simplicial homology",
        "authors": [
            "Andrei C. Bura",
            "Neelav S. Dutta",
            "Thomas J. X. Li",
            "Christian M. Reidys"
        ],
        "summary": "We provide a bottom up construction of torsion generators for weighted homology of a weighted complex over a discrete valuation ring $R=\\mathbb{F}[[\\pi]]$. This is achieved by starting from a basis for classical homology of the $n$-th skeleton for the underlying complex with coefficients in the residue field $\\mathbb{F}$ and then lifting it to a basis for the weighted homology with coefficients in the ring $R$. Using the latter, a bijection is established between $n+1$ and $n$ dimensional simplices whose weight ratios provide the exponents of the $\\pi$-monomials that generate each torsion summand in the structure theorem of the weighted homology modules over $R$. We present algorithms that subsume the torsion computation by reducing it to normalization over the residue field of $R$, and describe a Python package we implemented that takes advantage of this reduction and performs the computation efficiently.",
        "published": "2022-06-09T16:59:43Z",
        "link": "http://arxiv.org/abs/2206.04612v1",
        "categories": [
            "math.AT",
            "cs.SC",
            "math.CO",
            "math.GN",
            "math.KT",
            "05E45, 55U10, 55N35, 13P20"
        ]
    },
    {
        "title": "GAMR: A Guided Attention Model for (visual) Reasoning",
        "authors": [
            "Mohit Vaishnav",
            "Thomas Serre"
        ],
        "summary": "Humans continue to outperform modern AI systems in their ability to flexibly parse and understand complex visual scenes. Here, we present a novel module for visual reasoning, the Guided Attention Model for (visual) Reasoning (GAMR), which instantiates an active vision theory -- positing that the brain solves complex visual reasoning problems dynamically -- via sequences of attention shifts to select and route task-relevant visual information into memory. Experiments on an array of visual reasoning tasks and datasets demonstrate GAMR's ability to learn visual routines in a robust and sample-efficient manner. In addition, GAMR is shown to be capable of zero-shot generalization on completely novel reasoning tasks. Overall, our work provides computational support for cognitive theories that postulate the need for a critical interplay between attention and memory to dynamically maintain and manipulate task-relevant visual information to solve complex visual reasoning tasks.",
        "published": "2022-06-10T07:52:06Z",
        "link": "http://arxiv.org/abs/2206.04928v5",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.NE",
            "cs.SC"
        ]
    },
    {
        "title": "Synthesizing Mathematical Identities with E-Graphs",
        "authors": [
            "Ian Briggs",
            "Pavel Panchekha"
        ],
        "summary": "Identities compactly describe properties of a mathematical expression and can be leveraged into faster and more accurate function implementations. However, identities must currently be discovered manually, which requires a lot of expertise. We propose a two-phase synthesis and deduplication pipeline that discovers these identities automatically. In the synthesis step, a set of rewrite rules is composed, using an e-graph, to discover candidate identities. However, most of these candidates are duplicates, which a secondary deduplication step discards using integer linear programming and another e-graph. Applied to a set of 61 benchmarks, the synthesis phase generates 7215 candidate identities which the deduplication phase then reduces down to 125 core identities.",
        "published": "2022-06-14T18:21:01Z",
        "link": "http://arxiv.org/abs/2206.07086v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Accelerated Subdivision for Clustering Roots of Polynomials given by   Evaluation Oracles",
        "authors": [
            "Rémi Imbach",
            "Victor Y. Pan"
        ],
        "summary": "In our quest for the design, the analysis and the implementation of a subdivision algorithm for finding the complex roots of univariate polynomials given by oracles for their evaluation, we present sub-algorithms allowing substantial acceleration of subdivision for complex roots clustering for such polynomials. We rely on Cauchy sums which approximate power sums of the roots in a fixed complex disc and can be computed in a small number of evaluations --polylogarithmic in the degree. We describe root exclusion, root counting, root radius approximation and a procedure for contracting a disc towards the cluster of root it contains, called $\\varepsilon$-compression. To demonstrate the efficiency of our algorithms, we combine them in a prototype root clustering algorithm. For computing clusters of roots of polynomials that can be evaluated fast, our implementation competes advantageously with user's choice for root finding, MPsolve.",
        "published": "2022-06-17T08:33:36Z",
        "link": "http://arxiv.org/abs/2206.08622v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Rethinking Symbolic Regression Datasets and Benchmarks for Scientific   Discovery",
        "authors": [
            "Yoshitomo Matsubara",
            "Naoya Chiba",
            "Ryo Igarashi",
            "Yoshitaka Ushiku"
        ],
        "summary": "This paper revisits datasets and evaluation criteria for Symbolic Regression (SR), specifically focused on its potential for scientific discovery. Focused on a set of formulas used in the existing datasets based on Feynman Lectures on Physics, we recreate 120 datasets to discuss the performance of symbolic regression for scientific discovery (SRSD). For each of the 120 SRSD datasets, we carefully review the properties of the formula and its variables to design reasonably realistic sampling ranges of values so that our new SRSD datasets can be used for evaluating the potential of SRSD such as whether or not an SR method can (re)discover physical laws from such datasets. We also create another 120 datasets that contain dummy variables to examine whether SR methods can choose necessary variables only. Besides, we propose to use normalized edit distances (NED) between a predicted equation and the true equation trees for addressing a critical issue that existing SR metrics are either binary or errors between the target values and an SR model's predicted values for a given input. We conduct benchmark experiments on our new SRSD datasets using various representative SR methods. The experimental results show that we provide a more realistic performance evaluation, and our user study shows that the NED correlates with human judges significantly more than an existing SR metric. We publish repositories of our code and 240 SRSD datasets.",
        "published": "2022-06-21T17:15:45Z",
        "link": "http://arxiv.org/abs/2206.10540v5",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.NE",
            "cs.SC"
        ]
    },
    {
        "title": "New heuristic to choose a cylindrical algebraic decomposition variable   ordering motivated by complexity analysis",
        "authors": [
            "Tereso del Río",
            "Matthew England"
        ],
        "summary": "It is well known that the variable ordering can be critical to the efficiency or even tractability of the cylindrical algebraic decomposition (CAD) algorithm. We propose new heuristics inspired by complexity analysis of CAD to choose the variable ordering. These heuristics are evaluated against existing heuristics with experiments on the SMT-LIB benchmarks using both existing performance metrics and a new metric we propose for the problem at hand. The best of these new heuristics chooses orderings that lead to timings on average 17% slower than the virtual-best: an improvement compared to the prior state-of-the-art which achieved timings 25% slower.",
        "published": "2022-06-27T17:45:14Z",
        "link": "http://arxiv.org/abs/2206.13480v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Tuple Interpretations and Applications to Higher-Order Runtime   Complexity",
        "authors": [
            "Cynthia Kop",
            "Deivid Vale"
        ],
        "summary": "Tuple interpretations are a class of algebraic interpretation that subsumes both polynomial and matrix interpretations as it does not impose simple termination and allows non-linear interpretations. It was developed in the context of higher-order rewriting to study derivational complexity of algebraic functional systems. In this short paper, we continue our journey to study the complexity of higher-order TRSs by tailoring tuple interpretations to deal with innermost runtime complexity.",
        "published": "2022-06-30T11:36:53Z",
        "link": "http://arxiv.org/abs/2206.15202v1",
        "categories": [
            "cs.LO",
            "cs.SC",
            "F.4.1"
        ]
    },
    {
        "title": "Deep Learning and Symbolic Regression for Discovering Parametric   Equations",
        "authors": [
            "Michael Zhang",
            "Samuel Kim",
            "Peter Y. Lu",
            "Marin Soljačić"
        ],
        "summary": "Symbolic regression is a machine learning technique that can learn the governing formulas of data and thus has the potential to transform scientific discovery. However, symbolic regression is still limited in the complexity and dimensionality of the systems that it can analyze. Deep learning on the other hand has transformed machine learning in its ability to analyze extremely complex and high-dimensional datasets. We propose a neural network architecture to extend symbolic regression to parametric systems where some coefficient may vary but the structure of the underlying governing equation remains constant. We demonstrate our method on various analytic expressions, ODEs, and PDEs with varying coefficients and show that it extrapolates well outside of the training domain. The neural network-based architecture can also integrate with other deep learning architectures so that it can analyze high-dimensional data while being trained end-to-end. To this end we integrate our architecture with convolutional neural networks to analyze 1D images of varying spring systems.",
        "published": "2022-07-01T16:25:59Z",
        "link": "http://arxiv.org/abs/2207.00529v2",
        "categories": [
            "cs.LG",
            "cs.SC",
            "physics.comp-ph",
            "physics.data-an"
        ]
    },
    {
        "title": "Asymptotics of multivariate sequences IV: generating functions with   poles on a hyperplane arrangement",
        "authors": [
            "Yuliy Baryshnikov",
            "Stephen Melczer",
            "Robin Pemantle"
        ],
        "summary": "Let F be the quotient of an analytic function with a product of linear functions. Working in the framework of analytic combinatorics in several variables, we compute asymptotic formulae for the Taylor coefficients of F using multivariate residues and saddle-point approximations. Because the singular set of F is the union of hyperplanes, we are able to make explicit the topological decompositions which arise in the multivariate singularity analysis. In addition to effective and explicit asymptotic results, we provide the first results on transitions between different asymptotic regimes, and provide the first software package to verify and compute asymptotics in non-smooth cases of analytic combinatorics in several variables. It is also our hope that this paper will serve as an entry to the more advanced corners of analytic combinatorics in several variables for combinatorialists.",
        "published": "2022-07-02T02:39:21Z",
        "link": "http://arxiv.org/abs/2207.00717v2",
        "categories": [
            "math.CO",
            "cs.SC"
        ]
    },
    {
        "title": "Combinatory Adjoints and Differentiation",
        "authors": [
            "Martin Elsman",
            "Fritz Henglein",
            "Robin Kaarsgaard",
            "Mikkel Kragh Mathiesen",
            "Robert Schenck"
        ],
        "summary": "We develop a compositional approach for automatic and symbolic differentiation based on categorical constructions in functional analysis where derivatives are linear functions on abstract vectors rather than being limited to scalars, vectors, matrices or tensors represented as multi-dimensional arrays. We show that both symbolic and automatic differentiation can be performed using a differential calculus for generating linear functions representing Fr\\'echet derivatives based on rules for primitive, constant, linear and bilinear functions as well as their sequential and parallel composition. Linear functions are represented in a combinatory domain-specific language. Finally, we provide a calculus for symbolically computing the adjoint of a derivative without using matrices, which are too inefficient to use on high-dimensional spaces. The resulting symbolic representation of a derivative retains the data-parallel operations from the input program. The combination of combinatory differentiation and computing formal adjoints turns out to be behaviorally equivalent to reverse-mode automatic differentiation. In particular, it provides opportunities for optimizations where matrices are too inefficient to represent linear functions.",
        "published": "2022-07-02T14:34:54Z",
        "link": "http://arxiv.org/abs/2207.00847v1",
        "categories": [
            "cs.PL",
            "cs.DC",
            "cs.LG",
            "cs.SC"
        ]
    },
    {
        "title": "The Programming of Algebra",
        "authors": [
            "Fritz Henglein",
            "Robin Kaarsgaard",
            "Mikkel Kragh Mathiesen"
        ],
        "summary": "We present module theory and linear maps as a powerful generalised and computationally efficient framework for the relational data model, which underpins today's relational database systems. Based on universal constructions of modules we obtain compact and computationally efficient data structures for data collections corresponding to union and deletion, repeated union, Cartesian product and key-indexed data. Free modules naturally give rise to polysets, which generalise multisets and facilitate expressing database queries as multilinear maps with asymptotically efficient evaluation on polyset constructors. We introduce compact maps as a way of representing infinite (poly)sets constructible from an infinite base set and its elements by addition and subtraction. We show how natural joins generalise to algebraic joins, while intersection is implemented by a novel algorithm on nested compact maps that carefully avoids visiting parts of the input that do not contribute to the eventual output. Our algebraic framework leads to a worst-case optimal evaluation of cyclic relational queries, which is known to be impossible using textbook query optimisers that operate on lists of records only.",
        "published": "2022-07-02T14:35:52Z",
        "link": "http://arxiv.org/abs/2207.00850v1",
        "categories": [
            "cs.PL",
            "cs.DB",
            "cs.SC"
        ]
    },
    {
        "title": "FPS In Action: An Easy Way To Find Explicit Formulas For Interlaced   Hypergeometric Sequences",
        "authors": [
            "Bertrand Teguia Tabuguia",
            "Wolfram Koepf"
        ],
        "summary": "Linear recurrence equations with constant coefficients define the power series coefficients of rational functions. However, one usually prefers to have an explicit formula for the sequence of coefficients, provided that such a formula is \"simple\" enough. Simplicity is related to the compactness of the formula due to the presence of algebraic numbers: \"the smaller, the simpler\". This poster showcases the capacity of recent updates on the Formal Power Series (FPS) algorithm, implemented in Maxima and Maple (convert/FormalPowerSeries), to find simple formulas for sequences like those from https://oeis.org/A307717, https://oeis.org/A226782, or https://oeis.org/A226784 by computing power series representations of their correctly guessed generating functions. We designed the algorithm for the more general context of univariate $P$-recursive sequences. Our implementations are available at http://www.mathematik.uni-kassel.de/~bteguia/FPS_webpage/FPS.htm",
        "published": "2022-07-03T13:04:52Z",
        "link": "http://arxiv.org/abs/2207.01031v1",
        "categories": [
            "cs.SC",
            "math.CO"
        ]
    },
    {
        "title": "Guessing With Quadratic Differential Equations",
        "authors": [
            "Bertrand Teguia Tabuguia"
        ],
        "summary": "By holonomic guessing, we denote the process of finding a linear differential equation with polynomial coefficients satisfied by the generating function of a sequence, for which only a few first terms are known. Holonomic guessing has been used in computer algebra for over three decades to demonstrate the value of the guess-and-prove paradigm in intuition processes preceding proofs, as propagated in The Art of Solving (Polya, 1978). Among the prominent packages used to perform guessing, one can cite the Maple Gfun package of Salvy and Zimmermann; the Mathematica GeneratingFunctions package of Mallinger; and the Sage ore_algebra package of Kauers, Jaroschek, and Johansson.   We propose an approach that extends holonomic guessing by allowing the targeted differential equations to be of degree at most two. Consequently, it enables us to capture more generating functions than just holonomic functions. The corresponding recurrence equations are similar to known equations for the Bernoulli, Euler, and Bell numbers. As a result, our software finds the correct recurrence and differential equations for the generating functions of the up/down numbers (https://oeis.org/A000111), the evaluations of the zeta function at positive even integers, the Taylor coefficients of the Lambert W function, and many more. Our Maple implementation ($delta2guess$) is part of the FPS package which can be downloaded at http://www.mathematik.uni-kassel.de/~bteguia/FPS_webpage/FPS.htm",
        "published": "2022-07-03T13:26:50Z",
        "link": "http://arxiv.org/abs/2207.01037v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Bit complexity for computing one point in each connected component of a   smooth real algebraic set",
        "authors": [
            "Jesse Elliott",
            "Mark Giesbrecht",
            "Eric Schost"
        ],
        "summary": "We analyze the bit complexity of an algorithm for the computation of at least one point in each connected component of a smooth real algebraic set. This work is a continuation of our analysis of the hypersurface case (On the bit complexity of finding points in connected components of a smooth real hypersurface, ISSAC'20). In this paper, we extend the analysis to more general cases.   Let $F=(f_1,..., f_p)$ in $\\mathbb{Z}[X_1, ... , X_n]^p$ be a sequence of polynomials with $V = V(F) \\subset \\mathbb{C}^n$ a smooth and equidimensional variety and $\\langle F \\rangle \\subset \\mathbb{C}[X_1, ..., X_n]$ a radical ideal. To compute at least one point in each connected component of $V \\cap \\mathbb{R}^n$, our starting point is an algorithm by Safey El Din and Schost (Polar varieties and computation of one point in each connected component of a smooth real algebraic set, ISSAC'03). This algorithm uses random changes of variables that are proven to generically ensure certain desirable geometric properties. The cost of the algorithm was given in an algebraic complexity model; here, we analyze the bit complexity and the error probability, and we provide a quantitative analysis of the genericity statements. In particular, we are led to use Lagrange systems to describe polar varieties, as they make it simpler to rely on techniques such as weak transversality and an effective Nullstellensatz.",
        "published": "2022-07-09T15:35:35Z",
        "link": "http://arxiv.org/abs/2207.04289v1",
        "categories": [
            "math.AG",
            "cs.SC"
        ]
    },
    {
        "title": "Proceedings The 7th International Workshop on Symbolic-Numeric Methods   for Reasoning about CPS and IoT",
        "authors": [
            "Anne Remke",
            "Dung Hoang Tran"
        ],
        "summary": "The proceedings of the 7th International Workshop on Symbolic-Numeric Methods for Reasoning about CPS and IoT (SNR 2021) feature five peer-reviewed contributions and three invited talks.   SNR focuses on the combination of symbolic and numeric methods for reasoning about Cyber-Physical Systems and the Internet of Things to facilitate model identification, specification, verification, and control synthesis for these systems. The synergy between symbolic and numerical approaches is fruitful thanks to their complementarity.",
        "published": "2022-07-10T06:22:20Z",
        "link": "http://arxiv.org/abs/2207.04391v1",
        "categories": [
            "cs.SC",
            "cs.FL"
        ]
    },
    {
        "title": "Multi: a Formal Playground for Multi-Smart Contract Interaction",
        "authors": [
            "Martán Ceresa",
            "César Sánchez"
        ],
        "summary": "Blockchains are maintained by a network of participants that run algorithms designed to maintain collectively a distributed machine tolerant to Byzantine attacks. From the point of view of users, blockchains provide the illusion of centralized computers that perform trustable verifiable computations, where all computations are deterministic and the results cannot be manipulated or undone. Smart-contracts are written in a special-purpose programming language with deterministic semantics. Each transaction begins with an invocation from an external user to a smart contract. Contracts have local storage and can call other contracts, and more importantly, they store, send and receive cryptocurrency. It is very important to guarantee that contracts are correct before deployment since their code cannot be modified afterward deployment. However, the resulting ecosystem makes it very difficult to reason about program correctness, since contracts can be executed by malicious users or malicious contracts can be designed to exploit other contracts that call them. Many attacks and bugs are caused by unexpected interactions between multiple contracts, the attacked contract and unknown code that performs the exploit. Moreover, there is a very aggressive competition between different blockchains to expand their user base. Ideas are implemented fast and blockchains compete to offer and adopt new features quickly. In this paper, we propose a formal extensible playground that allows reasoning about multi-contract interactions to ultimately prove properties before features are incorporated into the real blockchain. We implemented a model of computation that models the execution platform, abstracts the internal code of each individual contract and focuses on contract interactions. Moreover, we show how many features, existing or proposed, can be used to reason about multi-contract interactions.",
        "published": "2022-07-14T06:19:39Z",
        "link": "http://arxiv.org/abs/2207.06681v1",
        "categories": [
            "cs.LO",
            "cs.PL",
            "cs.SC"
        ]
    },
    {
        "title": "Verification of Sigmoidal Artificial Neural Networks using iSAT",
        "authors": [
            "Dominik Grundt",
            "Sorin Liviu Jurj",
            "Willem Hagemann",
            "Paul Kröger",
            "Martin Fränzle"
        ],
        "summary": "This paper presents an approach for verifying the behaviour of nonlinear Artificial Neural Networks (ANNs) found in cyber-physical safety-critical systems. We implement a dedicated interval constraint propagator for the sigmoid function into the SMT solver iSAT and compare this approach with a compositional approach encoding the sigmoid function by basic arithmetic features available in iSAT and an approximating approach. Our experimental results show that the dedicated and the compositional approach clearly outperform the approximating approach. Throughout all our benchmarks, the dedicated approach showed an equal or better performance compared to the compositional approach.",
        "published": "2022-07-14T09:08:38Z",
        "link": "http://arxiv.org/abs/2207.06755v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.SC"
        ]
    },
    {
        "title": "Model Checking for Rectangular Hybrid Systems: A Quantified Encoding   Approach",
        "authors": [
            "Luan V. Nguyen",
            "Wesam Haddad",
            "Taylor T. Johnson"
        ],
        "summary": "Satisfiability Modulo Theories (SMT) solvers have been successfully applied to solve many problems in formal verification such as bounded model checking (BMC) for many classes of systems from integrated circuits to cyber-physical systems. Typically, BMC is performed by checking satisfiability of a possibly long, but quantifier-free formula. However, BMC problems can naturally be encoded as quantified formulas over the number of BMC steps. In this approach, we then use decision procedures supporting quantifiers to check satisfiability of these quantified formulas. This approach has previously been applied to perform BMC using a Quantified Boolean Formula (QBF) encoding for purely discrete systems, and then discharges the QBF checks using QBF solvers. In this paper, we present a new quantified encoding of BMC for rectangular hybrid automata (RHA), which requires using more general logics due to the real (dense) time and real-valued state variables modeling continuous states. We have implemented a preliminary experimental prototype of the method using the HyST model transformation tool to generate the quantified BMC (QBMC) queries for the Z3 SMT solver. We describe experimental results on several timed and hybrid automata benchmarks, such as the Fischer and Lynch-Shavit mutual exclusion algorithms. We compare our approach to quantifier-free BMC approaches, such as those in the dReach tool that uses the dReal SMT solver, and the HyComp tool built on top of nuXmv that uses the MathSAT SMT solver. Based on our promising experimental results, QBMC may in the future be an effective and scalable analysis approach for RHA and other classes of hybrid automata as further improvements are made in quantifier handling in SMT solvers such as Z3.",
        "published": "2022-07-14T09:09:34Z",
        "link": "http://arxiv.org/abs/2207.08775v1",
        "categories": [
            "cs.LO",
            "cs.FL",
            "cs.SC"
        ]
    },
    {
        "title": "Parallel Flowshop in YewPar",
        "authors": [
            "Ignas Knizikevičius",
            "Phil Trinder",
            "Blair Archibald",
            "Jinghua Yan"
        ],
        "summary": "Parallelism may reduce the time to find exact solutions for many Operations Research (OR) problems, but parallelising combinatorial search is extremely challenging. YewPar is a new combinatorial search framework designed to allow domain specialists to benefit from parallelism by reusing sophisticated parallel search patterns. This paper shows (1) that it is low effort to encode and parallelise a typical OR problem (Flowshop Scheduling FSP) in YewPar even for scalable clusters; (2) that the YewPar library makes it extremely easy to exploit three alternate FSP parallelisations; (3) that the YewPar FSP implementations are valid, and have sequential performance comparable with a published algorithm; and (4) provides a systematic performance evaluation of the three parallel FSP versions on 10 standard FSP instances with up to 240 workers on a Beowulf cluster.",
        "published": "2022-07-14T13:29:48Z",
        "link": "http://arxiv.org/abs/2207.06902v2",
        "categories": [
            "cs.DC",
            "cs.SC"
        ]
    },
    {
        "title": "Computer Algebra and Hypergeometric Structures for Feynman Integrals",
        "authors": [
            "Johannes Bluemlein",
            "Marco Saragnese",
            "Carsten Schneider"
        ],
        "summary": "We present recent computer algebra methods that support the calculations of (multivariate) series solutions for (certain coupled systems of partial) linear differential equations. The summand of the series solutions may be built by hypergeometric products and more generally by indefinite nested sums defined over such products. Special cases are hypergeometric structures such as Appell-functions or generalizations of them that arise frequently when dealing with parameter Feynman integrals.",
        "published": "2022-07-18T11:41:50Z",
        "link": "http://arxiv.org/abs/2207.08524v1",
        "categories": [
            "math-ph",
            "cs.SC",
            "hep-ph",
            "math.MP"
        ]
    },
    {
        "title": "Approximate Real Symmetric Tensor Rank",
        "authors": [
            "Alperen A. Ergür",
            "Jesus Rebollo Bueno",
            "Petros Valettas"
        ],
        "summary": "We investigate the effect of an $\\varepsilon$-room of perturbation tolerance on symmetric tensor decomposition. To be more precise, suppose a real symmetric $d$-tensor $f$, a norm $||.||$ on the space of symmetric $d$-tensors, and $\\varepsilon >0$ are given. What is the smallest symmetric tensor rank in the $\\varepsilon$-neighborhood of $f$? In other words, what is the symmetric tensor rank of $f$ after a clever $\\varepsilon$-perturbation? We prove two theorems and develop three corresponding algorithms that give constructive upper bounds for this question. With expository goals in mind; we present probabilistic and convex geometric ideas behind our results, reproduce some known results, and point out open problems.",
        "published": "2022-07-25T20:56:40Z",
        "link": "http://arxiv.org/abs/2207.12529v4",
        "categories": [
            "math.NA",
            "cs.LG",
            "cs.NA",
            "cs.SC",
            "math.AC",
            "math.OC"
        ]
    },
    {
        "title": "Bit Complexity of Polynomial GCD on Sparse Representation",
        "authors": [
            "Qiao-Long Huang",
            "Xiao-Shan Gao"
        ],
        "summary": "An input- and output-sensitive GCD algorithm for multi-variate polynomials over finite fields is proposed by combining the modular method with the Ben-Or/Tiwari sparse interpolation. The bit complexity of the algorithm is given and is sensitive to the sparse representation, while for previous sparse GCD algorithms, the complexities were given only in some special cases. It is shown that the new algorithm is superior both in theory and in practice comparing with existing GCD algorithms: the complexity in the degree is decreased from quadratic to linear and the running times are decreased by 1-3 orders of magnitude in various benchmarks.",
        "published": "2022-07-28T03:58:08Z",
        "link": "http://arxiv.org/abs/2207.13874v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Improvement of algebraic attacks for solving superdetermined MinRank   instances",
        "authors": [
            "Magali Bardet",
            "Manon Bertin"
        ],
        "summary": "The MinRank (MR) problem is a computational problem that arises in many cryptographic applications. In Verbel et al. (PQCrypto 2019), the authors introduced a new way to solve superdetermined instances of the MinRank problem, starting from the bilinear Kipnis-Shamir (KS) modeling. They use linear algebra on specific Macaulay matrices, considering only multiples of the initial equations by one block of variables, the so called ''kernel'' variables. Later, Bardet et al. (Asiacrypt 2020) introduced a new Support Minors modeling (SM), that consider the Pl{\\\"u}cker coordinates associated to the kernel variables, i.e. the maximal minors of the Kernel matrix in the KS modeling. In this paper, we give a complete algebraic explanation of the link between the (KS) and (SM) modelings (for any instance). We then show that superdetermined MinRank instances can be seen as easy instances of the SM modeling. In particular, we show that performing computation at the smallest possible degree (the ''first degree fall'') and the smallest possible number of variables is not always the best strategy. We give complexity estimates of the attack for generic random instances.We apply those results to the DAGS cryptosystem, that was submitted to the first round of the NIST standardization process. We show that the algebraic attack from Barelli and Couvreur (Asiacrypt 2018), improved in Bardet et al. (CBC 2019), is a particular superdetermined MinRank instance.Here, the instances are not generic, but we show that it is possible to analyse the particular instances from DAGS and provide a way toselect the optimal parameters (number of shortened positions) to solve a particular instance.",
        "published": "2022-08-02T13:19:02Z",
        "link": "http://arxiv.org/abs/2208.01442v1",
        "categories": [
            "cs.CR",
            "cs.IT",
            "cs.SC",
            "math.IT"
        ]
    },
    {
        "title": "Basic Elements of Logical Graphs",
        "authors": [
            "Lucas Dixon"
        ],
        "summary": "We considers how a particular kind of graph corresponds to multiplicative intuitionistic linear logic formula. The main feature of the graphical notation is that it absorbs certain symmetries between conjunction and implication. We look at the basic definitions and present details of an implementation in the functional programming language Standard ML. This provides a functional approach to graph traversal and demonstrates how graph isomorphism be implemented in just a few lines of readable code. This works takes the initial steps towards a graphical language and toolkit for working with logic formula and derivations.",
        "published": "2022-08-05T14:27:33Z",
        "link": "http://arxiv.org/abs/2208.03194v1",
        "categories": [
            "cs.LO",
            "cs.SC"
        ]
    },
    {
        "title": "Unitary canonical forms over Clifford algebras, and an observed   unification of some real-matrix decompositions",
        "authors": [
            "Ran Gutin"
        ],
        "summary": "We show that the spectral theorem -- which we understand to be a statement that every self-adjoint matrix admits a certain type of canonical form under unitary similarity -- admits analogues over other $*$-algebras distinct from the complex numbers. If these $*$-algebras contain nilpotents, then it is shown that there is a consistent way in which many classic matrix decompositions -- such as the Singular Value Decomposition, the Takagi decomposition, the skew-Takagi decomposition, and the Jordan decomposition, among others -- are immediate consequences of these. If producing the relevant canonical form of a self-adjoint matrix were a subroutine in some programming language, then the corresponding classic matrix decomposition would be a 1-line invocation with no additional steps. We also suggest that by employing operator overloading in a programming language, a numerical algorithm for computing a unitary diagonalisation of a complex self-adjoint matrix would generalise immediately to solving problems like SVD or Takagi. While algebras without nilpotents (like the quaternions) allow for similar unifying behaviour, the classic matrix decompositions which they unify are never obtained as easily. In the process of doing this, we develop some spectral theory over Clifford algebras of the form $\\cl_{p,q,0}(\\mathbb R)$ and $\\cl_{p,q,1}(\\mathbb R)$ where the former is admittedly quite easy. We propose a broad conjecture about spectral theorems.",
        "published": "2022-08-08T17:08:53Z",
        "link": "http://arxiv.org/abs/2208.04272v2",
        "categories": [
            "math.RA",
            "cs.NA",
            "cs.SC",
            "math.NA",
            "math.SP"
        ]
    },
    {
        "title": "Homotopy techniques for analytic combinatorics in several variables",
        "authors": [
            "Kisun Lee",
            "Stephen Melczer",
            "Josip Smolčić"
        ],
        "summary": "We combine tools from homotopy continuation solvers with the methods of analytic combinatorics in several variables to give the first practical algorithm and implementation for the asymptotics of multivariate rational generating functions not relying on a non-algorithmically checkable `combinatorial' non-negativity assumption. Our homotopy implementation terminates on examples from the literature in three variables, and we additionally describe heuristic methods that terminate and correctly predict asymptotic behaviour in reasonable time on examples in even higher dimension. Our results are implemented in Julia, through the use of the HomotopyContinuation.jl package, and we provide a selection of examples and benchmarks.",
        "published": "2022-08-09T01:34:47Z",
        "link": "http://arxiv.org/abs/2208.04490v2",
        "categories": [
            "math.CO",
            "cs.SC",
            "math.AG"
        ]
    },
    {
        "title": "Convergent expansions and bounds for the incomplete elliptic integral of   the second kind near the logarithmic singularity",
        "authors": [
            "Dmitrii Karp",
            "Yi Zhang"
        ],
        "summary": "We find two series expansions for Legendre's second incomplete elliptic integral $E(\\lambda, k)$ in terms of recursively computed elementary functions. Both expansions converge at every point of the unit square in the $(\\lambda, k)$ plane. Partial sums of the proposed expansions form a sequence of approximations to $E(\\lambda,k)$ which are asymptotic when $\\lambda$ and/or $k$ tend to unity, including when both approach the logarithmic singularity $\\lambda=k=1$ from any direction. Explicit two-sided error bounds are given at each approximation order. These bounds yield a sequence of increasingly precise asymptotically correct two-sided inequalities for $E(\\lambda, k)$. For the reader's convenience we further present explicit expressions for low-order approximations and numerical examples to illustrate their accuracy. Our derivations are based on series rearrangements, hypergeometric summation algorithms and extensive use of the properties of the generalized hypergeometric functions including some recent inequalities.",
        "published": "2022-08-10T09:51:06Z",
        "link": "http://arxiv.org/abs/2208.05242v2",
        "categories": [
            "math.CA",
            "cs.SC",
            "33E05, 33F10, 33C20, 33C60"
        ]
    },
    {
        "title": "Sturm's Theorem with Endpoints",
        "authors": [
            "Philippe Pébay",
            "J. Maurice Rojas",
            "David C. Thompson"
        ],
        "summary": "Sturm's Theorem is a fundamental 19th century result relating the number of real roots of a polynomial $f$ in an interval to the number of sign alternations in a sequence of polynomial division-like calculations. We provide a short direct proof of Sturm's Theorem, including the numerically vexing case (ignored in many published accounts) where an interval endpoint is a root of $f$.",
        "published": "2022-08-16T18:47:09Z",
        "link": "http://arxiv.org/abs/2208.07904v1",
        "categories": [
            "cs.SC",
            "math.AC"
        ]
    },
    {
        "title": "A Scalable, Interpretable, Verifiable & Differentiable Logic Gate   Convolutional Neural Network Architecture From Truth Tables",
        "authors": [
            "Adrien Benamira",
            "Tristan Guérand",
            "Thomas Peyrin",
            "Trevor Yap",
            "Bryan Hooi"
        ],
        "summary": "We propose $\\mathcal{T}$ruth $\\mathcal{T}$able net ($\\mathcal{TT}$net), a novel Convolutional Neural Network (CNN) architecture that addresses, by design, the open challenges of interpretability, formal verification, and logic gate conversion. $\\mathcal{TT}$net is built using CNNs' filters that are equivalent to tractable truth tables and that we call Learning Truth Table (LTT) blocks. The dual form of LTT blocks allows the truth tables to be easily trained with gradient descent and makes these CNNs easy to interpret, verify and infer. Specifically, $\\mathcal{TT}$net is a deep CNN model that can be automatically represented, after post-training transformation, as a sum of Boolean decision trees, or as a sum of Disjunctive/Conjunctive Normal Form (DNF/CNF) formulas, or as a compact Boolean logic circuit. We demonstrate the effectiveness and scalability of $\\mathcal{TT}$net on multiple datasets, showing comparable interpretability to decision trees, fast complete/sound formal verification, and scalable logic gate representation, all compared to state-of-the-art methods. We believe this work represents a step towards making CNNs more transparent and trustworthy for real-world critical applications.",
        "published": "2022-08-18T03:06:25Z",
        "link": "http://arxiv.org/abs/2208.08609v3",
        "categories": [
            "cs.AI",
            "cs.FL",
            "cs.LG",
            "cs.SC"
        ]
    },
    {
        "title": "Learn Basic Skills and Reuse: Modularized Adaptive Neural Architecture   Search (MANAS)",
        "authors": [
            "Hanxiong Chen",
            "Yunqi Li",
            "He Zhu",
            "Yongfeng Zhang"
        ],
        "summary": "Human intelligence is able to first learn some basic skills for solving basic problems and then assemble such basic skills into complex skills for solving complex or new problems. For example, the basic skills \"dig hole,\" \"put tree,\" \"backfill\" and \"watering\" compose a complex skill \"plant a tree\". Besides, some basic skills can be reused for solving other problems. For example, the basic skill \"dig hole\" not only can be used for planting a tree, but also can be used for mining treasures, building a drain, or landfilling. The ability to learn basic skills and reuse them for various tasks is very important for humans because it helps to avoid learning too many skills for solving each individual task, and makes it possible to solve a compositional number of tasks by learning just a few number of basic skills, which saves a considerable amount of memory and computation in the human brain. We believe that machine intelligence should also capture the ability of learning basic skills and reusing them by composing into complex skills. In computer science language, each basic skill is a \"module\", which is a reusable network of a concrete meaning and performs a specific basic operation. The modules are assembled into a bigger \"model\" for doing a more complex task. The assembling procedure is adaptive to the input or task, i.e., for a given task, the modules should be assembled into the best model for solving the task. As a result, different inputs or tasks could have different assembled models, which enables Auto-Assembling AI (AAAI). In this work, we propose Modularized Adaptive Neural Architecture Search (MANAS) to demonstrate the above idea. Experiments on different datasets show that the adaptive architecture assembled by MANAS outperforms static global architectures. Further experiments and empirical analysis provide insights to the effectiveness of MANAS.",
        "published": "2022-08-23T17:05:46Z",
        "link": "http://arxiv.org/abs/2208.11083v2",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.IR",
            "cs.SC"
        ]
    },
    {
        "title": "Factoring differential operators over algebraic curves in positive   characteristic",
        "authors": [
            "Raphaël Pagès"
        ],
        "summary": "We present an algorithm for factoring linear differential operators with coefficients in a finite separable extension of F p (x). Our methods rely on specific tools arising in positive characteristic: p-curvature, structure of simple central algebras and p-Riccati equations.",
        "published": "2022-08-24T08:24:27Z",
        "link": "http://arxiv.org/abs/2208.11365v1",
        "categories": [
            "cs.SC",
            "math.OA"
        ]
    },
    {
        "title": "Hiding canonicalisation in tensor computer algebra",
        "authors": [
            "Dominic Price",
            "Kasper Peeters",
            "Marija Zamaklar"
        ],
        "summary": "Simplification of expressions in computer algebra systems often involves a step known as \"canonicalisation\", which reduces equivalent expressions to the same form. However, such forms may not be natural from the perspective of a pen-and-paper computation, or may be unwieldy, or both. This is, for example, the case for expressions involving tensor multi-term symmetries. We propose an alternative strategy to handle such tensor expressions, which hides canonical forms from the user entirely, and present an implementation of this idea in the Cadabra computer algebra system.",
        "published": "2022-08-25T09:02:35Z",
        "link": "http://arxiv.org/abs/2208.11946v1",
        "categories": [
            "cs.SC",
            "gr-qc",
            "hep-th"
        ]
    },
    {
        "title": "Constraining Gaussian Processes to Systems of Linear Ordinary   Differential Equations",
        "authors": [
            "Andreas Besginow",
            "Markus Lange-Hegermann"
        ],
        "summary": "Data in many applications follows systems of Ordinary Differential Equations (ODEs). This paper presents a novel algorithmic and symbolic construction for covariance functions of Gaussian Processes (GPs) with realizations strictly following a system of linear homogeneous ODEs with constant coefficients, which we call LODE-GPs. Introducing this strong inductive bias into a GP improves modelling of such data. Using smith normal form algorithms, a symbolic technique, we overcome two current restrictions in the state of the art: (1) the need for certain uniqueness conditions in the set of solutions, typically assumed in classical ODE solvers and their probabilistic counterparts, and (2) the restriction to controllable systems, typically assumed when encoding differential equations in covariance functions. We show the effectiveness of LODE-GPs in a number of experiments, for example learning physically interpretable parameters by maximizing the likelihood.",
        "published": "2022-08-26T09:16:53Z",
        "link": "http://arxiv.org/abs/2208.12515v1",
        "categories": [
            "cs.LG",
            "cs.SC",
            "stat.ML",
            "60G15, 62G08, 12H05, 68W30, 13J30, 34-04",
            "I.2.6; G.1.6; G.3; J.2; I.1.4"
        ]
    },
    {
        "title": "A proof of the Brill-Noether method from scratch",
        "authors": [
            "Elena Berardini",
            "Alain Couvreur",
            "Grégoire Lecerf"
        ],
        "summary": "In 1874 Brill and Noether designed a seminal geometric method for computing bases of Riemann-Roch spaces. From then, their method has led to several algorithms, some of them being implemented in computer algebra systems. The usual proofs often rely on abstract concepts of algebraic geometry and commutative algebra. In this paper we present a short self-contained and elementary proof that mostly needs Newton polygons, Hensel lifting, bivariate resultants, and Chinese remaindering.",
        "published": "2022-08-26T15:25:30Z",
        "link": "http://arxiv.org/abs/2208.12725v2",
        "categories": [
            "math.AG",
            "cs.SC"
        ]
    },
    {
        "title": "LogicRank: Logic Induced Reranking for Generative Text-to-Image Systems",
        "authors": [
            "Björn Deiseroth",
            "Patrick Schramowski",
            "Hikaru Shindo",
            "Devendra Singh Dhami",
            "Kristian Kersting"
        ],
        "summary": "Text-to-image models have recently achieved remarkable success with seemingly accurate samples in photo-realistic quality. However as state-of-the-art language models still struggle evaluating precise statements consistently, so do language model based image generation processes. In this work we showcase problems of state-of-the-art text-to-image models like DALL-E with generating accurate samples from statements related to the draw bench benchmark. Furthermore we show that CLIP is not able to rerank those generated samples consistently. To this end we propose LogicRank, a neuro-symbolic reasoning framework that can result in a more accurate ranking-system for such precision-demanding settings. LogicRank integrates smoothly into the generation process of text-to-image models and moreover can be used to further fine-tune towards a more logical precise model.",
        "published": "2022-08-29T11:40:36Z",
        "link": "http://arxiv.org/abs/2208.13518v1",
        "categories": [
            "cs.AI",
            "cs.CL",
            "cs.CV",
            "cs.LO",
            "cs.SC"
        ]
    },
    {
        "title": "Four-Dimensional Lie Algebras Revisited",
        "authors": [
            "Laurent Manivel",
            "Bernd Sturmfels",
            "Svala Sverrisdóttir"
        ],
        "summary": "The projective variety of Lie algebra structures on a 4-dimensional vector space has four irreducible components of dimension 11. We compute their prime ideals in the polynomial ring in 24 variables. By listing their degrees and Hilbert polynomials, we correct an earlier publication and we answer a 1987 question by Kirillov and Neretin.",
        "published": "2022-08-31T04:52:24Z",
        "link": "http://arxiv.org/abs/2208.14631v1",
        "categories": [
            "math.RA",
            "cs.SC",
            "math.AC"
        ]
    },
    {
        "title": "A Note on the Games-Chan Algorithm",
        "authors": [
            "Graham H. Norton"
        ],
        "summary": "The Games-Chan algorithm finds the minimal period of a periodic binary sequence of period $2^n$, in $n$ iterations. We generalise this to periodic $q$-ary sequences (where $q$ is a prime power) using generating functions and polynomials and apply this to find the multiplicity of $x-1$ in a $q$-ary polynomial $f$ in $\\log_{\\,q}\\deg(f)$ iterations.",
        "published": "2022-08-31T22:50:23Z",
        "link": "http://arxiv.org/abs/2209.00148v2",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "CASPER: Cognitive Architecture for Social Perception and Engagement in   Robots",
        "authors": [
            "Samuele Vinanzi",
            "Angelo Cangelosi"
        ],
        "summary": "Our world is being increasingly pervaded by intelligent robots with varying degrees of autonomy. To seamlessly integrate themselves in our society, these machines should possess the ability to navigate the complexities of our daily routines even in the absence of a human's direct input. In other words, we want these robots to understand the intentions of their partners with the purpose of predicting the best way to help them. In this paper, we present CASPER (Cognitive Architecture for Social Perception and Engagement in Robots): a symbolic cognitive architecture that uses qualitative spatial reasoning to anticipate the pursued goal of another agent and to calculate the best collaborative behavior. This is performed through an ensemble of parallel processes that model a low-level action recognition and a high-level goal understanding, both of which are formally verified. We have tested this architecture in a simulated kitchen environment and the results we have collected show that the robot is able to both recognize an ongoing goal and to properly collaborate towards its achievement. This demonstrates a new use of Qualitative Spatial Relations applied to the problem of intention reading in the domain of human-robot interaction.",
        "published": "2022-09-01T10:15:03Z",
        "link": "http://arxiv.org/abs/2209.01012v1",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.SC"
        ]
    },
    {
        "title": "Minimization of differential equations and algebraic values of   $E$-functions",
        "authors": [
            "Alin Bostan",
            "Tanguy Rivoal",
            "Bruno Salvy"
        ],
        "summary": "A power series being given as the solution of a linear differential equation with appropriate initial conditions, minimization consists in finding a non-trivial linear differential equation of minimal order having this power series as a solution. This problem exists in both homogeneous and inhomogeneous variants; it is distinct from, but related to, the classical problem of factorization of differential operators. Recently, minimization has found applications in Transcendental Number Theory, more specifically in the computation of non-zero algebraic points where Siegel's $E$-functions take algebraic values. We present algorithms and implementations for these questions, and discuss examples and experiments.",
        "published": "2022-09-05T08:21:14Z",
        "link": "http://arxiv.org/abs/2209.01827v3",
        "categories": [
            "cs.SC",
            "math.NT",
            "68W30, 11J81, 16S32, 34M15, 33F10"
        ]
    },
    {
        "title": "Some explicit arithmetic on curves of genus three and their applications",
        "authors": [
            "Tomoki Moriya",
            "Momonari Kudo"
        ],
        "summary": "A Richelot isogeny between Jacobian varieties is an isogeny whose kernel is included in the $2$-torsion subgroup of the domain. A Richelot isogeny whose codomain is the product of two or more principally polarized abelian varieties is called a decomposed Richelot isogeny.   In this paper, we develop some explicit arithmetic on curves of genus $3$, including algorithms to compute the codomain of a decomposed Richelot isogeny. As solutions to compute the domain of a decomposed Richelot isogeny, explicit formulae of defining equations for Howe curves of genus $3$ are also given. Using the formulae, we shall construct an algorithm with complexity $\\tilde{O}(p^3)$ (resp. $\\tilde{O}(p^4)$) to enumerate all hyperelliptic (resp. non-hyperelliptic) superspecial Howe curves of genus $3$.",
        "published": "2022-09-07T04:38:56Z",
        "link": "http://arxiv.org/abs/2209.02926v3",
        "categories": [
            "math.AG",
            "cs.SC",
            "math.NT"
        ]
    },
    {
        "title": "The art of algorithmic guessing in $\\texttt{gfun}$",
        "authors": [
            "Sergey Yurkevich"
        ],
        "summary": "The technique of guessing can be very fruitful when dealing with sequences which arise in practice. This holds true especially when guessing is performed algorithmically and efficiently. One highly useful tool for this purpose is the package named $\\texttt{gfun}$ in the software Maple. In this text we explore and explain some of $\\texttt{gfun}$'s possibilities and illustrate them on two examples from recent mathematical research by the author and his collaborators.",
        "published": "2022-09-07T10:49:59Z",
        "link": "http://arxiv.org/abs/2209.03059v1",
        "categories": [
            "math.CO",
            "cs.SC"
        ]
    },
    {
        "title": "Survey on Applications of Neurosymbolic Artificial Intelligence",
        "authors": [
            "Djallel Bouneffouf",
            "Charu C. Aggarwal"
        ],
        "summary": "In recent years, the Neurosymbolic framework has attracted a lot of attention in various applications, from recommender systems and information retrieval to healthcare and finance. This success is due to its stellar performance combined with attractive properties, such as learning and reasoning. The new emerging Neurosymbolic field is currently experiencing a renaissance, as novel frameworks and algorithms motivated by various practical applications are being introduced, building on top of the classical neural and reasoning problem setting. This article aims to provide a comprehensive review of significant recent developments in real-world applications of Neurosymbolic Artificial Intelligence. Specifically, we introduce a taxonomy of common Neurosymbolic applications and summarize the state-of-the-art for each of those domains. Furthermore, we identify important current trends and provide new perspectives pertaining to the future of this burgeoning field.",
        "published": "2022-09-08T18:18:41Z",
        "link": "http://arxiv.org/abs/2209.12618v1",
        "categories": [
            "cs.AI",
            "cs.SC"
        ]
    },
    {
        "title": "SC-Square: Overview to 2021",
        "authors": [
            "Matthew England"
        ],
        "summary": "This extended abstract was written to accompany an invited talk at the 2021 SC-Square Workshop, where the author was asked to give an overview of SC-Square progress to date. The author first reminds the reader of the definition of SC-Square, then briefly outlines some of the history, before picking out some (personal) scientific highlights.",
        "published": "2022-09-09T15:44:23Z",
        "link": "http://arxiv.org/abs/2209.04359v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "SC-Square: Future Progress with Machine Learning?",
        "authors": [
            "Matthew England"
        ],
        "summary": "The algorithms employed by our communities are often underspecified, and thus have multiple implementation choices, which do not effect the correctness of the output, but do impact the efficiency or even tractability of its production. In this extended abstract, to accompany a keynote talk at the 2021 SC-Square Workshop, we survey recent work (both the author's and from the literature) on the use of Machine Learning technology to improve algorithms of interest to SC-Square.",
        "published": "2022-09-09T15:47:04Z",
        "link": "http://arxiv.org/abs/2209.04361v1",
        "categories": [
            "cs.SC",
            "cs.LG"
        ]
    },
    {
        "title": "Exact Algorithms for Computing Generalized Eigenspaces of Matrices via   Annihilating Polynomials",
        "authors": [
            "Shinichi Tajima",
            "Katsuyoshi Ohara",
            "Akira Terui"
        ],
        "summary": "An effective exact method is proposed for computing generalized eigenspaces of a matrix of integers or rational numbers. Keys of our approach are the use of minimal annihilating polynomials and the concept of the Jourdan-Krylov basis. A new method, called Jordan-Krylov elimination, is introduced to design an algorithm for computing Jordan-Krylov basis. The resulting algorithm outputs generalized eigenspaces as a form of Jordan chains. Notably, in the output, components of generalized eigenvectors are expressed as polynomials in the associated eigenvalue as a variable.",
        "published": "2022-09-11T08:00:32Z",
        "link": "http://arxiv.org/abs/2209.04807v4",
        "categories": [
            "math.RA",
            "cs.SC",
            "math.AC",
            "15A18, 68W30"
        ]
    },
    {
        "title": "Computer algebra calculations in supersymmetric electrodynamics",
        "authors": [
            "Ilya Shirokov"
        ],
        "summary": "We propose a new symbolic algorithm and a C++ program for generating and calculating supersymmetric Feynman diagrams for ${\\cal N}=1$ supersymmetric electrodynamics regularized by higher derivatives in four dimensions. According to standard rules, the program generates all diagrams that are necessary to calculate a specific contribution to the two-point Green function of matter superfields in the needed order, and then reduces the answer to the sum of Euclidean momentum integrals. At the moment, the program was used to calculate the anomalous dimension in ${\\cal N}=1$ supersymmetric quantum electrodynamics, regularized by higher derivatives, in the three-loop approximation.",
        "published": "2022-09-12T14:57:26Z",
        "link": "http://arxiv.org/abs/2209.05295v1",
        "categories": [
            "hep-th",
            "cs.SC"
        ]
    },
    {
        "title": "Error bounds for the asymptotic expansion of the partition function",
        "authors": [
            "Koustav Banerje",
            "Peter Paule",
            "Cristian-Silviu Radu",
            "Carsten Schneider"
        ],
        "summary": "Asymptotic study on the partition function $p(n)$ began with the work of Hardy and Ramanujan. Later Rademacher obtained a convergent series for $p(n)$ and an error bound was given by Lehmer. Despite having this, a full asymptotic expansion for $p(n)$ with an explicit error bound is not known. Recently O'Sullivan studied the asymptotic expansion of $p^{k}(n)$-partitions into $k$th powers, initiated by Wright, and consequently obtained an asymptotic expansion for $p(n)$ along with a concise description of the coefficients involved in the expansion but without any estimation of the error term. Here we consider a detailed and comprehensive analysis on an estimation of the error term obtained by truncating the asymptotic expansion for $p(n)$ at any positive integer $n$. This gives rise to an infinite family of inequalities for $p(n)$ which finally answers to a question proposed by Chen. Our error term estimation predominantly relies on applications of algorithmic methods from symbolic summation.",
        "published": "2022-09-16T12:27:20Z",
        "link": "http://arxiv.org/abs/2209.07887v1",
        "categories": [
            "math.NT",
            "cs.SC",
            "math.CO",
            "05A16, 11P82, 68W30"
        ]
    },
    {
        "title": "FACT: Learning Governing Abstractions Behind Integer Sequences",
        "authors": [
            "Peter Belcák",
            "Ard Kastrati",
            "Flavio Schenker",
            "Roger Wattenhofer"
        ],
        "summary": "Integer sequences are of central importance to the modeling of concepts admitting complete finitary descriptions. We introduce a novel view on the learning of such concepts and lay down a set of benchmarking tasks aimed at conceptual understanding by machine learning models. These tasks indirectly assess model ability to abstract, and challenge them to reason both interpolatively and extrapolatively from the knowledge gained by observing representative examples. To further aid research in knowledge representation and reasoning, we present FACT, the Finitary Abstraction Comprehension Toolkit. The toolkit surrounds a large dataset of integer sequences comprising both organic and synthetic entries, a library for data pre-processing and generation, a set of model performance evaluation tools, and a collection of baseline model implementations, enabling the making of the future advancements with ease.",
        "published": "2022-09-20T08:20:03Z",
        "link": "http://arxiv.org/abs/2209.09543v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.SC"
        ]
    },
    {
        "title": "CryptoSolve: Towards a Tool for the Symbolic Analysis of Cryptographic   Algorithms",
        "authors": [
            "Dalton Chichester",
            "Wei Du",
            "Raymond Kauffman",
            "Hai Lin",
            "Christopher Lynch",
            "Andrew M. Marshall",
            "Catherine A. Meadows",
            "Paliath Narendran",
            "Veena Ravishankar",
            "Luis Rovira",
            "Brandon Rozek"
        ],
        "summary": "Recently, interest has been emerging in the application of symbolic techniques to the specification and analysis of cryptosystems. These techniques, when accompanied by suitable proofs of soundness/completeness, can be used both to identify insecure cryptosystems and prove sound ones secure. But although a number of such symbolic algorithms have been developed and implemented, they remain scattered throughout the literature. In this paper, we present a tool, CryptoSolve, which provides a common basis for specification and implementation of these algorithms, CryptoSolve includes libraries that provide the term algebras used to express symbolic cryptographic systems, as well as implementations of useful algorithms, such as unification and variant generation. In its current initial iteration, it features several algorithms for the generation and analysis of cryptographic modes of operation, which allow one to use block ciphers to encrypt messages more than one block long. The goal of our work is to continue expanding the tool in order to consider additional cryptosystems and security questions, as well as extend the symbolic libraries to increase their applicability.",
        "published": "2022-09-21T12:45:57Z",
        "link": "http://arxiv.org/abs/2209.10321v1",
        "categories": [
            "cs.LO",
            "cs.CR",
            "cs.SC"
        ]
    },
    {
        "title": "A cubic algorithm for computing the Hermite normal form of a nonsingular   integer matrix",
        "authors": [
            "Stavros Birmpilis",
            "George Labahn",
            "Arne Storjohann"
        ],
        "summary": "A Las Vegas randomized algorithm is given to compute the Hermite normal form of a nonsingular integer matrix $A$ of dimension $n$. The algorithm uses quadratic integer multiplication and cubic matrix multiplication and has running time bounded by $O(n^3 (\\log n + \\log ||A||)^2(\\log n)^2)$ bit operations, where $||A||= \\max_{ij} |A_{ij}|$ denotes the largest entry of $A$ in absolute value. A variant of the algorithm that uses pseudo-linear integer multiplication is given that has running time $(n^3 \\log ||A||)^{1+o(1)}$ bit operations, where the exponent $\"+o(1)\"$ captures additional factors $c_1 (\\log n)^{c_2} (\\log \\log ||A||)^{c_3}$ for positive real constants $c_1,c_2,c_3$.",
        "published": "2022-09-21T22:19:56Z",
        "link": "http://arxiv.org/abs/2209.10685v2",
        "categories": [
            "cs.DS",
            "cs.SC"
        ]
    },
    {
        "title": "Solving homogeneous linear equations over polynomial semirings",
        "authors": [
            "Ruiwen Dong"
        ],
        "summary": "For a subset $B$ of $\\mathbb{R}$, denote by $\\operatorname{U}(B)$ be the semiring of (univariate) polynomials in $\\mathbb{R}[X]$ that are strictly positive on $B$. Let $\\mathbb{N}[X]$ be the semiring of (univariate) polynomials with non-negative integer coefficients. We study solutions of homogeneous linear equations over the polynomial semirings $\\operatorname{U}(B)$ and $\\mathbb{N}[X]$. In particular, we prove local-global principles for solving single homogeneous linear equations over these semirings. We then show PTIME decidability of determining the existence of non-zero solutions over $\\mathbb{N}[X]$ of single homogeneous linear equations.   Our study of these polynomial semirings is largely motivated by several semigroup algorithmic problems in the wreath product $\\mathbb{Z} \\wr \\mathbb{Z}$. As an application of our results, we show that the Identity Problem (whether a given semigroup contains the neutral element?) and the Group Problem (whether a given semigroup is a group?) for finitely generated sub-semigroups of the wreath product $\\mathbb{Z} \\wr \\mathbb{Z}$ is decidable when elements of the semigroup generator have the form $(y, \\pm 1)$.",
        "published": "2022-09-27T12:55:52Z",
        "link": "http://arxiv.org/abs/2209.13347v2",
        "categories": [
            "math.RA",
            "cs.SC",
            "math.GR"
        ]
    },
    {
        "title": "Clifford algebra in R",
        "authors": [
            "Robin K. S. Hankin"
        ],
        "summary": "Here I present the 'clifford' package for working with Clifford algebras in the R programming language. The algebra is described and package idiom is given.",
        "published": "2022-09-27T19:57:07Z",
        "link": "http://arxiv.org/abs/2209.13659v2",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Topological descriptors of the parameter region of multistationarity:   deciding upon connectivity",
        "authors": [
            "Máté L. Telek",
            "Elisenda Feliu"
        ],
        "summary": "Switch-like responses arising from bistability have been linked to cell signaling processes and memory. Revealing the shape and properties of the set of parameters that lead to bistability is necessary to understand the underlying biological mechanisms, but is a complex mathematical problem. We present an efficient approach to determine a basic topological property of the parameter region of multistationary, namely whether it is connected or not. The connectivity of this region can be interpreted in terms of the biological mechanisms underlying bistability and the switch-like patterns that the system can create.   We provide an algorithm to assert that the parameter region of multistationarity is connected, targeting reaction networks with mass-action kinetics. We show that this is the case for numerous relevant cell signaling motifs, previously described to exhibit bistability. However, we show that for a motif displaying a phosphorylation cycle with allosteric enzyme regulation, the region of multistationarity has two distinct connected components, corresponding to two different, but symmetric, biological mechanisms. The method relies on linear programming and bypasses the expensive computational cost of direct and generic approaches to study parametric polynomial systems. This characteristic makes it suitable for mass-screening of reaction networks.",
        "published": "2022-09-28T09:12:15Z",
        "link": "http://arxiv.org/abs/2209.13936v2",
        "categories": [
            "q-bio.MN",
            "cs.SC",
            "q-bio.QM"
        ]
    },
    {
        "title": "AI-Assisted Discovery of Quantitative and Formal Models in Social   Science",
        "authors": [
            "Julia Balla",
            "Sihao Huang",
            "Owen Dugan",
            "Rumen Dangovski",
            "Marin Soljacic"
        ],
        "summary": "In social science, formal and quantitative models, such as ones describing economic growth and collective action, are used to formulate mechanistic explanations, provide predictions, and uncover questions about observed phenomena. Here, we demonstrate the use of a machine learning system to aid the discovery of symbolic models that capture nonlinear and dynamical relationships in social science datasets. By extending neuro-symbolic methods to find compact functions and differential equations in noisy and longitudinal data, we show that our system can be used to discover interpretable models from real-world data in economics and sociology. Augmenting existing workflows with symbolic regression can help uncover novel relationships and explore counterfactual models during the scientific process. We propose that this AI-assisted framework can bridge parametric and non-parametric models commonly employed in social science research by systematically exploring the space of nonlinear models and enabling fine-grained control over expressivity and interpretability.",
        "published": "2022-10-02T16:25:47Z",
        "link": "http://arxiv.org/abs/2210.00563v3",
        "categories": [
            "cs.SC",
            "cs.LG",
            "econ.EM"
        ]
    },
    {
        "title": "Computing groups of Hecke characters",
        "authors": [
            "Pascal Molin",
            "Aurel Page"
        ],
        "summary": "We describe algorithms to represent and compute groups of Hecke characters. We make use of an id{\\`e}lic point of view and obtain the whole family of such characters, including transcendental ones. We also show how to isolate the algebraic characters, which are of particular interest in number theory. This work has been implemented in Pari/GP, and we illustrate our work with a variety of explicit examples using our implementation.",
        "published": "2022-10-06T06:57:33Z",
        "link": "http://arxiv.org/abs/2210.02716v1",
        "categories": [
            "cs.SC",
            "math.NT"
        ]
    },
    {
        "title": "Disordered vectors in R: introducing the disordR package",
        "authors": [
            "Robin K. S. Hankin"
        ],
        "summary": "Objects in the {\\tt stl map} class of {\\tt C++} associate a value to each of a set of keys. Accessing values or keys of such an object is problematic in the R programming language because the value-key pairs are not stored in a well-defined order. This document motivates and discusses the concept of \"disordered vector\" as implemented by the {\\tt disordR} package which facilitates the handling of {\\tt map} objects. Values and keys of a map are stored in an implementation-specific way so certain extraction and replacement operations should be forbidden. For example, if values are real, then the \"first\" value is implementation specific\\ldots but the maximum value has a well-defined result. The {\\tt disordR} package makes forbidden operations impossible while allowing transparent R idiom for permitted operations. An illustrative R session is given in which the package is used abstractly, without reference to any particular application, and then shows how it can be used to manipulate multivariate polynomials. The {\\tt disordR} package is a dependency of {\\tt clifford}, {\\tt freealg}, {\\tt hyper2}, {\\tt mvp}, {\\tt spray}, {\\tt stokes}, and {\\tt weyl}. The {\\tt disordR} package is available on CRAN at \\url{https://CRAN.R-project.org/package=disordR}.",
        "published": "2022-10-08T00:14:02Z",
        "link": "http://arxiv.org/abs/2210.03856v2",
        "categories": [
            "cs.SC",
            "68V99",
            "I.1.m"
        ]
    },
    {
        "title": "The FBHHRBNRSSSHK-Algorithm for Multiplication in   $\\mathbb{Z}_2^{5\\times5}$ is still not the end of the story",
        "authors": [
            "Manuel Kauers",
            "Jakob Moosbauer"
        ],
        "summary": "In response to a recent Nature article which announced an algorithm for multiplying $5\\times5$-matrices over $\\mathbb{Z}_2$ with only 96 multiplications, two fewer than the previous record, we present an algorithm that does the job with only 95 multiplications.",
        "published": "2022-10-08T15:04:25Z",
        "link": "http://arxiv.org/abs/2210.04045v3",
        "categories": [
            "cs.SC",
            "cs.CC"
        ]
    },
    {
        "title": "On the Partial Differential Lüroth's Theorem",
        "authors": [
            "Wei Li",
            "Chen-Rui Wei"
        ],
        "summary": "We study the L\\\"{u}roth problem for partial differential fields. The main result is the following partial differential analog of generalized L\\\"{u}roth's theorem: Let $\\mathcal{F}$ be a differential field of characteristic 0 with $m$ derivation operators, $\\textbf{u}=u_1,\\ldots,u_n$ a set of differential indeterminates over $\\mathcal{F}$. We prove that an intermediate differential field $\\mathcal{G}$ between $\\mathcal{F}$ and $\\mathcal{F}\\langle \\textbf{u}\\rangle$ is a simple differential extension of $\\mathcal{F}$ if and only if the differential dimension polynomial of $\\textbf{u}$ over $\\mathcal{G}$ is of the form $\\omega_{\\textbf{u}/\\mathcal{G}}(t)=n{t+m\\choose m}-{t+m-s\\choose m}$ for some $s\\in\\mathbb N$. This result generalizes the classical differential L\\\"uroth's theorem proved by Ritt and Kolchin in the case $m=n=1$. We then present an algorithm to decide whether a given finitely generated differential extension field of $\\mathcal{F}$ contained in $\\mathcal{F}\\langle \\textbf{u}\\rangle$ is a simple extension, and in the affirmative case, to compute a L\\\"{u}roth generator. As an application, we solve the proper re-parameterization problem for unirational differential curves.",
        "published": "2022-10-11T14:13:30Z",
        "link": "http://arxiv.org/abs/2210.05469v1",
        "categories": [
            "math.AG",
            "cs.SC",
            "12H05"
        ]
    },
    {
        "title": "Critical Points at Infinity for Hyperplanes of Directions",
        "authors": [
            "Stephen Gillen"
        ],
        "summary": "Analytic combinatorics in several variables (ACSV) analyzes the asymptotic growth of the coefficients of a meromorphic generating function $F = G/H$ in a direction $\\mathbf{r}$. It uses Morse theory on the pole variety $V := \\{ H = 0 \\} \\subseteq (\\mathbb{C}^*)^d$ of $F$ to deform the torus $T$ in the multivariate Cauchy Integral Formula via the downward gradient flow for the \\textit{height} function $h = h_{\\mathbf{r}} = -\\sum_{j=1}^d r_j \\log |z_j|$, giving a homology decomposition of $T$ into cycles around \\textit{critical points} of $h$ on $V$. The deformation can flow to infinity at finite height when the height function is not a proper map. This happens only in the presence of a critical point at infinity (CPAI): a sequence of points on $V$ approaching a point at infinity, and such that log-normals to $V$ converge projectively to $\\mathbf{r}$. The CPAI is called \\textit{heighted} if the height function also converges to a finite value. This paper studies whether all CPAI are heighted, and in which directions CPAI can occur. We study these questions by examining sequences converging to faces of a toric compactification defined by a multiple of the Newton polytope $\\mathcal{P}$ of the polynomial $H$. Under generically satisfied conditions, any projective limit of log-normals of a sequence converging to a face $F$ must be parallel to $F$; this implies that CPAI must always be heighted and can only occur in directions parallel to some face of $\\mathcal{P}$. When this generic condition fails, we show under a smoothness condition, that a point in a codimension-1 face $F$ can still only be a CPAI for directions parallel to $F$, and that the directions for a codimension-2 face can be a larger set, which can be computed explicitly and still has positive codimension.",
        "published": "2022-10-11T19:27:38Z",
        "link": "http://arxiv.org/abs/2210.05748v1",
        "categories": [
            "math.CO",
            "cs.SC"
        ]
    },
    {
        "title": "Galois Groups of Linear Difference-Differential Equations",
        "authors": [
            "Ruyong Feng",
            "Wei Lu"
        ],
        "summary": "We study the relation between the Galois group $G$ of a linear difference-differential system and two classes $\\mathcal{C}_1$ and $\\mathcal{C}_2$ of groups that are the Galois groups of the specializations of the linear difference equation and the linear differential equation in this system respectively. We show that almost all groups in $\\mathcal{C}_1\\cup \\mathcal{C}_2$ are algebraic subgroups of $G$, and there is a nonempty subset of $\\mathcal{C}_1$ and a nonempty subset of $\\mathcal{C}_2$ such that $G$ is the product of any pair of groups from these two subsets. These results have potential application to the computation of the Galois group of a linear difference-differential system. We also give a criterion for testing linear dependence of elements in a simple difference-differential ring, which generalizes Kolchin's criterion for partial differential fields.",
        "published": "2022-10-18T08:57:29Z",
        "link": "http://arxiv.org/abs/2211.01977v2",
        "categories": [
            "math.RA",
            "cs.SC",
            "math.NT",
            "12H05 12H10 39A06 34A30"
        ]
    },
    {
        "title": "Convexity Certificates from Hessians",
        "authors": [
            "Julien Klaus",
            "Niklas Merk",
            "Konstantin Wiedom",
            "Sören Laue",
            "Joachim Giesen"
        ],
        "summary": "The Hessian of a differentiable convex function is positive semidefinite. Therefore, checking the Hessian of a given function is a natural approach to certify convexity. However, implementing this approach is not straightforward since it requires a representation of the Hessian that allows its analysis. Here, we implement this approach for a class of functions that is rich enough to support classical machine learning. For this class of functions, it was recently shown how to compute computational graphs of their Hessians. We show how to check these graphs for positive semidefiniteness. We compare our implementation of the Hessian approach with the well-established disciplined convex programming (DCP) approach and prove that the Hessian approach is at least as powerful as the DCP approach for differentiable functions. Furthermore, we show for a state-of-the-art implementation of the DCP approach that, for differentiable functions, the Hessian approach is actually more powerful. That is, it can certify the convexity of a larger class of differentiable functions.",
        "published": "2022-10-19T09:52:03Z",
        "link": "http://arxiv.org/abs/2210.10430v1",
        "categories": [
            "math.OC",
            "cs.LG",
            "cs.SC"
        ]
    },
    {
        "title": "Sparse arrays in R: the spray package",
        "authors": [
            "Robin K. S. Hankin"
        ],
        "summary": "In this short article I introduce the spray package, which provides some functionality for handling sparse arrays. The package uses the C++ Standard Template Library's map class to store and retrieve elements. One natural application for sparse arrays is multivariate polynomials and I give two examples of the package in use, one drawn from the fields of random walks on lattices and one from the field of recreational combinatorics. The package is available on CRAN at https://CRAN.R-project.org/package=spray.",
        "published": "2022-10-19T19:22:53Z",
        "link": "http://arxiv.org/abs/2210.10848v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Context-driven Visual Object Recognition based on Knowledge Graphs",
        "authors": [
            "Sebastian Monka",
            "Lavdim Halilaj",
            "Achim Rettinger"
        ],
        "summary": "Current deep learning methods for object recognition are purely data-driven and require a large number of training samples to achieve good results. Due to their sole dependence on image data, these methods tend to fail when confronted with new environments where even small deviations occur. Human perception, however, has proven to be significantly more robust to such distribution shifts. It is assumed that their ability to deal with unknown scenarios is based on extensive incorporation of contextual knowledge. Context can be based either on object co-occurrences in a scene or on memory of experience. In accordance with the human visual cortex which uses context to form different object representations for a seen image, we propose an approach that enhances deep learning methods by using external contextual knowledge encoded in a knowledge graph. Therefore, we extract different contextual views from a generic knowledge graph, transform the views into vector space and infuse it into a DNN. We conduct a series of experiments to investigate the impact of different contextual views on the learned object representations for the same image dataset. The experimental results provide evidence that the contextual views influence the image representations in the DNN differently and therefore lead to different predictions for the same images. We also show that context helps to strengthen the robustness of object recognition models for out-of-distribution images, usually occurring in transfer learning tasks or real-world scenarios.",
        "published": "2022-10-20T13:09:00Z",
        "link": "http://arxiv.org/abs/2210.11233v1",
        "categories": [
            "cs.AI",
            "cs.CL",
            "cs.CV",
            "cs.LG",
            "cs.SC"
        ]
    },
    {
        "title": "Equivalence Checking of Parameterized Quantum Circuits: Verifying the   Compilation of Variational Quantum Algorithms",
        "authors": [
            "Tom Peham",
            "Lukas Burgholzer",
            "Robert Wille"
        ],
        "summary": "Variational quantum algorithms have been introduced as a promising class of quantum-classical hybrid algorithms that can already be used with the noisy quantum computing hardware available today by employing parameterized quantum circuits. Considering the non-trivial nature of quantum circuit compilation and the subtleties of quantum computing, it is essential to verify that these parameterized circuits have been compiled correctly. Established equivalence checking procedures that handle parameter-free circuits already exist. However, no methodology capable of handling circuits with parameters has been proposed yet. This work fills this gap by showing that verifying the equivalence of parameterized circuits can be achieved in a purely symbolic fashion using an equivalence checking approach based on the ZX-calculus. At the same time, proofs of inequality can be efficiently obtained with conventional methods by taking advantage of the degrees of freedom inherent to parameterized circuits. We implemented the corresponding methods and proved that the resulting methodology is complete. Experimental evaluations (using the entire parametric ansatz circuit library provided by Qiskit as benchmarks) demonstrate the efficacy of the proposed approach. The implementation is open source and publicly available as part of the equivalence checking tool QCEC (https://github.com/cda-tum/qcec) which is part of the Munich Quantum Toolkit (MQT).",
        "published": "2022-10-21T18:00:04Z",
        "link": "http://arxiv.org/abs/2210.12166v1",
        "categories": [
            "quant-ph",
            "cs.SC"
        ]
    },
    {
        "title": "A partial order view of message-passing communication models",
        "authors": [
            "Cinzia Di Giusto",
            "Davide Ferré",
            "Laetitia Laversa",
            "Etienne Lozes"
        ],
        "summary": "There is a wide variety of message-passing communication models, ranging from synchronous ''rendez-vous'' communications to fully asynchronous/out-of-order communications. For large-scale distributed systems, the communication model is determined by the transport layer of the network, and a few classes of orders of message delivery (FIFO, causally ordered) have been identified in the early days of distributed computing. For local-scale message-passing applications, e.g., running on a single machine, the communication model may be determined by the actual implementation of message buffers and by how FIFO queues are used. While large-scale communication models, such as causal ordering, are defined by logical axioms, local-scale models are often defined by an operational semantics. In this work, we connect these two approaches, and we present a unified hierarchy of communication models encompassing both large-scale and local-scale models, based on their concurrent behaviors. We also show that all the communication models we consider can be axiomatized in the monadic second order logic, and may therefore benefit from several bounded verification techniques based on bounded special treewidth.",
        "published": "2022-10-24T09:31:25Z",
        "link": "http://arxiv.org/abs/2210.13062v2",
        "categories": [
            "cs.CL",
            "cs.FL",
            "cs.SC"
        ]
    },
    {
        "title": "Gosper's algorithm and Bell numbers",
        "authors": [
            "Robert Dougherty-Bliss"
        ],
        "summary": "Computers are good at evaluating finite sums in closed form, but there are finite sums which do not have closed forms. Summands which do not produce a closed form can often be ``fixed'' by multiplying them by a suitable polynomial. We provide an explicit description of a class of such polynomials for simple hypergeometric summands in terms of the Bell numbers.",
        "published": "2022-10-24T18:20:07Z",
        "link": "http://arxiv.org/abs/2210.13520v1",
        "categories": [
            "cs.SC",
            "math.CO",
            "math.NT",
            "68R05"
        ]
    },
    {
        "title": "Axioms for a theory of signature bases",
        "authors": [
            "Pierre Lairez"
        ],
        "summary": "Twenty years after the discovery of the F5 algorithm, Gr\\\"obner bases with signatures are still challenging to understand and to adapt to different settings. This contrasts with Buchberger's algorithm, which we can bend in many directions keeping correctness and termination obvious. I propose an axiomatic approach to Gr\\\"obner bases with signatures with the purpose of uncoupling the theory and the algorithms, and giving general results applicable in many different settings (e.g. Gr\\\"obner for submodules, F4-style reduction, noncommutative rings, non-Noetherian settings, etc.).",
        "published": "2022-10-25T06:19:26Z",
        "link": "http://arxiv.org/abs/2210.13788v3",
        "categories": [
            "cs.SC",
            "math.AC"
        ]
    },
    {
        "title": "Vanishing Component Analysis with Contrastive Normalization",
        "authors": [
            "Ryosuke Masuya",
            "Yuichi Ike",
            "Hiroshi Kera"
        ],
        "summary": "Vanishing component analysis (VCA) computes approximate generators of vanishing ideals of samples, which are further used for extracting nonlinear features of the samples. Recent studies have shown that normalization of approximate generators plays an important role and different normalization leads to generators of different properties. In this paper, inspired by recent self-supervised frameworks, we propose a contrastive normalization method for VCA, where we impose the generators to vanish on the target samples and to be normalized on the transformed samples. We theoretically show that a contrastive normalization enhances the discriminative power of VCA, and provide the algebraic interpretation of VCA under our normalization. Numerical experiments demonstrate the effectiveness of our method. This is the first study to tailor the normalization of approximate generators of vanishing ideals to obtain discriminative features.",
        "published": "2022-10-27T07:59:59Z",
        "link": "http://arxiv.org/abs/2210.16171v1",
        "categories": [
            "cs.LG",
            "cs.SC"
        ]
    },
    {
        "title": "Reductions in Higher-Order Rewriting and Their Equivalence",
        "authors": [
            "Pablo Barenbaum",
            "Eduardo Bonelli"
        ],
        "summary": "Proof terms are syntactic expressions that represent computations in term rewriting. They were introduced by Meseguer and exploited by van Oostrom and de Vrijer to study equivalence of reductions in (left-linear) first-order term rewriting systems. We study the problem of extending the notion of proof term to higher-order rewriting, which generalizes the first-order setting by allowing terms with binders and higher-order substitution. In previous works that devise proof terms for higher-order rewriting, such as Bruggink's, it has been noted that the challenge lies in reconciling composition of proof terms and higher-order substitution (\\b{eta}-equivalence). This led Bruggink to reject \"nested\" composition, other than at the outermost level. In this paper, we propose a notion of higher-order proof term we dub rewrites that supports nested composition. We then define two notions of equivalence on rewrites, namely permutation equivalence and projection equivalence, and show that they coincide. We also propose a standardization procedure, that computes a canonical representative of the permutation equivalence class of a rewrite.",
        "published": "2022-10-27T17:54:56Z",
        "link": "http://arxiv.org/abs/2210.15654v2",
        "categories": [
            "cs.SC",
            "F.3.3"
        ]
    },
    {
        "title": "Fast multivariate polynomials in R: the mvp package",
        "authors": [
            "Robin K. S. Hankin"
        ],
        "summary": "In this short article I introduce the mvp package, which provides some functionality for handling multivariate polynomials. The package uses the C++ Standard Template Library's map class to store and retrieve elements; it conforms to disordR discipline for coefficients. The package is available on CRAN at https://CRAN.R-project.org/package=mvp.",
        "published": "2022-10-28T08:44:58Z",
        "link": "http://arxiv.org/abs/2210.15991v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Neural Combinatorial Logic Circuit Synthesis from Input-Output Examples",
        "authors": [
            "Peter Belcak",
            "Roger Wattenhofer"
        ],
        "summary": "We propose a novel, fully explainable neural approach to synthesis of combinatorial logic circuits from input-output examples. The carrying advantage of our method is that it readily extends to inductive scenarios, where the set of examples is incomplete but still indicative of the desired behaviour. Our method can be employed for a virtually arbitrary choice of atoms - from logic gates to FPGA blocks - as long as they can be formulated in a differentiable fashion, and consistently yields good results for synthesis of practical circuits of increasing size. In particular, we succeed in learning a number of arithmetic, bitwise, and signal-routing operations, and even generalise towards the correct behaviour in inductive scenarios. Our method, attacking a discrete logical synthesis problem with an explainable neural approach, hints at a wider promise for synthesis and reasoning-related tasks.",
        "published": "2022-10-29T14:06:42Z",
        "link": "http://arxiv.org/abs/2210.16606v1",
        "categories": [
            "cs.LG",
            "cs.AI",
            "cs.SC"
        ]
    },
    {
        "title": "Index Reduction for Degenerated Differential-Algebraic Equations by   Embedding",
        "authors": [
            "Wenqiang Yang",
            "Wenyuan Wu",
            "Greg Reid"
        ],
        "summary": "To find consistent initial data points for a system of differential-algebraic equations, requires the identification of its missing constraints. An efficient class of structural methods exploiting a dependency graph for this task was initiated by Pantiledes. More complete methods rely on differential-algebraic geometry but suffer from other issues (e.g. high complexity). In this paper we give a new class of efficient structural methods combined with new tools from numerical real algebraic geometry that has much improved completeness properties. Existing structural methods may fail for a system of differential-algebraic equations if its Jacobian matrix after differentiation is still singular due to symbolic cancellation or numerical degeneration. Existing structural methods can only handle degenerated cases caused by symbolic cancellation. However, if a system has parameters, then its parametric Jacobian matrix may be still singular after application of the structural method for certain values of the parameters. This case is called numerical degeneration.   For polynomially nonlinear systems of differential-algebraic equations, numerical methods are given to solve both degenerated cases using numerical real algebraic geometry. First, we introduce a witness point method, which produces at least one witness point on every constraint component. This can help to ensure constant rank and detection of degeneration on all components of such systems. Secondly, we present a Constant Rank Embedding Lemma, and based on it propose an Index Reduction by Embedding (IRE) method which can construct an equivalent system with a full rank Jacobian matrix. Thirdly, IRE leads to a global structural differentiation method, to solve degenerated differential-algebraic equations on all components numerically. Application examples from circuits, mechanics, are used to demonstrate our method.",
        "published": "2022-10-29T23:04:52Z",
        "link": "http://arxiv.org/abs/2210.16707v1",
        "categories": [
            "math.NA",
            "cs.NA",
            "cs.SC"
        ]
    },
    {
        "title": "On Catalan Constant Continued Fractions",
        "authors": [
            "David Naccache",
            "Ofer Yifrach-Stav"
        ],
        "summary": "The Ramanujan Machine project detects new expressions related to constants of interest, such as $\\zeta$ function values, $\\gamma$ and algebraic numbers (to name a few). In particular the project lists a number of conjectures concerning the Catalan constant $G= 0.91596559\\ldots$ We show how to generate infinitely many. We used an ad hoc software toolchain and rather tedious mathematical developments. Because we do not provide a proper peer-reviewed proof of the relations given here we do not claim them to be theorems.",
        "published": "2022-10-30T10:24:23Z",
        "link": "http://arxiv.org/abs/2210.15669v5",
        "categories": [
            "cs.SC",
            "cs.DM",
            "math.NT"
        ]
    },
    {
        "title": "Stokes's theorem in R",
        "authors": [
            "Robin K. S. Hankin"
        ],
        "summary": "In this short article I introduce the stokes package which provides functionality for working with tensors, alternating forms, wedge products, and related concepts from the exterior calculus. Notation and spirit follow Spivak. Stokes's generalized integral theorem, viz $\\int_{\\partial X}\\phi=\\int_Xd\\phi$, is demonstrated here using the package; it is available on CRAN athttps://CRAN.R-project.org/package=stokes.",
        "published": "2022-10-31T01:51:36Z",
        "link": "http://arxiv.org/abs/2210.17008v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Comparision Of Adversarial And Non-Adversarial LSTM Music Generative   Models",
        "authors": [
            "Moseli Mots'oehli",
            "Anna Sergeevna Bosman",
            "Johan Pieter De Villiers"
        ],
        "summary": "Algorithmic music composition is a way of composing musical pieces with minimal to no human intervention. While recurrent neural networks are traditionally applied to many sequence-to-sequence prediction tasks, including successful implementations of music composition, their standard supervised learning approach based on input-to-output mapping leads to a lack of note variety. These models can therefore be seen as potentially unsuitable for tasks such as music generation. Generative adversarial networks learn the generative distribution of data and lead to varied samples. This work implements and compares adversarial and non-adversarial training of recurrent neural network music composers on MIDI data. The resulting music samples are evaluated by human listeners, their preferences recorded. The evaluation indicates that adversarial training produces more aesthetically pleasing music.",
        "published": "2022-11-01T20:23:49Z",
        "link": "http://arxiv.org/abs/2211.00731v1",
        "categories": [
            "cs.LG",
            "cs.SC",
            "cs.SD",
            "eess.AS"
        ]
    },
    {
        "title": "Analysis and object oriented implementation of the Kovacic algorithm",
        "authors": [
            "Nasser M. Abbasi"
        ],
        "summary": "This paper gives a detailed overview and a number of worked out examples illustrating the Kovacic \\cite{Kovacic86} algorithm for solving second order linear differential equation ${A(x) y\"+ B(x) y' + C(x) y=0}$ where $A,B,C$ are rational functions with complex coefficients in the independent variable $x$. All three cases of the algorithm were implemented in a software package based on an object oriented design and complete source code listing given in the appendix with usage examples. Implementation used the Maple computer algebra language. The complete Kovacic package in one mpl file accompany the arXiv version of this paper. This package was then used to analyze the distribution of Kovacic algorithm cases on $3000$ differential equations",
        "published": "2022-11-02T00:48:26Z",
        "link": "http://arxiv.org/abs/2211.00804v1",
        "categories": [
            "cs.SC",
            "math.CA",
            "34-04",
            "I.1"
        ]
    },
    {
        "title": "A Note on the Ramanujan Machine",
        "authors": [
            "Eric Brier",
            "David Naccache",
            "Ofer Yifrach-Stav"
        ],
        "summary": "The Ramanujan Machine project detects new expressions related to constants of interest, such as $\\zeta$ function values, $\\gamma$ and algebraic numbers (to name a few). In particular the project lists a number of conjectures involving even and odd $\\zeta$ function values, logarithms etc. We show that many relations detected by the Ramanujan Machine Project stem from a specific algebraic observation and show how to generate infinitely many. This provides an automated proof and/or an explanation of many of the relations listed as conjectures by the project (although not all of them).",
        "published": "2022-11-02T11:48:41Z",
        "link": "http://arxiv.org/abs/2211.01058v2",
        "categories": [
            "math.NT",
            "cs.SC"
        ]
    },
    {
        "title": "An analog of the Edwards model for Jacobians of genus 2 curves",
        "authors": [
            "E. Victor Flynn",
            "Kamal Khuri-Makdisi"
        ],
        "summary": "We give the explicit equations for a P^3 x P^3 embedding of the Jacobian of a curve of genus 2, which gives a natural analog for abelian surfaces of the Edwards curve model of elliptic curves. This gives a much more succinct description of the Jacobian variety than the standard version in P^{15}. We also give a condition under which, as for the Edwards curve, the abelian surfaces have a universal group law.",
        "published": "2022-11-02T19:40:31Z",
        "link": "http://arxiv.org/abs/2211.01450v3",
        "categories": [
            "math.NT",
            "cs.SC",
            "math.AG",
            "11G30, 11G10, 14H40"
        ]
    },
    {
        "title": "Symbolic Abstract Heaps for Polymorphic Information-flow Guard Inference   (Extended Version)",
        "authors": [
            "Nicolas Berthier",
            "Narges Khakpour"
        ],
        "summary": "In the realm of sound object-oriented program analyses for information-flow control, very few approaches adopt flow-sensitive abstractions of the heap that enable a precise modeling of implicit flows. To tackle this challenge, we advance a new symbolic abstraction approach for modeling the heap in Java-like programs. We use a store-less representation that is parameterized with a family of relations among references to offer various levels of precision based on user preferences. This enables us to automatically infer polymorphic information-flow guards for methods via a co-reachability analysis of a symbolic finite-state system. We instantiate the heap abstraction with three different families of relations. We prove the soundness of our approach and compare the precision and scalability obtained with each instantiated heap domain by using the IFSpec benchmarks and real-life applications.",
        "published": "2022-11-07T11:05:44Z",
        "link": "http://arxiv.org/abs/2211.03450v1",
        "categories": [
            "cs.PL",
            "cs.CR",
            "cs.FL",
            "cs.SC"
        ]
    },
    {
        "title": "The free algebra in R",
        "authors": [
            "Robin K. S. Hankin"
        ],
        "summary": "The free algebra is an interesting and useful algebraic object. Here I introduce \"freealg\", an R package which furnishes computational support for free algebras. The package uses the standard template library's \"map\" class for efficiency, which uses the fact that the order of the terms is algebraically immaterial. The package follows \"disordR\" discipline. I demonstrate some properties of free algebra using the package, and showcase package idiom. The package is available on CRAN at https://CRAN.R-project.org/package=freealg.",
        "published": "2022-11-08T04:54:39Z",
        "link": "http://arxiv.org/abs/2211.04002v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Abstraction-Based Verification of Approximate Pre-Opacity for Control   Systems",
        "authors": [
            "Junyao Hou",
            "Siyuan Liu",
            "Xiang Yin",
            "Majid Zamani"
        ],
        "summary": "In this paper, we consider the problem of verifying pre-opacity for discrete-time control systems. Pre-opacity is an important information-flow security property that secures the intention of a system to execute some secret behaviors in the future. Existing works on pre-opacity only consider non-metric discrete systems, where it is assumed that intruders can distinguish different output behaviors precisely. However, for continuous-space control systems whose output sets are equipped with metrics (which is the case for most real-world applications), it is too restrictive to assume precise measurements from outside observers. In this paper, we first introduce a concept of approximate pre-opacity by capturing the security level of control systems with respect to the measurement precision of the intruder. Based on this new notion of pre-opacity, we propose a verification approach for continuous-space control systems by leveraging abstraction-based techniques. In particular, a new concept of approximate pre-opacity preserving simulation relation is introduced to characterize the distance between two systems in terms of preserving pre-opacity. This new system relation allows us to verify pre-opacity of complex continuous-space control systems using their finite abstractions. We also present a method to construct pre-opacity preserving finite abstractions for a class of discrete-time control systems under certain stability assumptions.",
        "published": "2022-11-08T08:57:16Z",
        "link": "http://arxiv.org/abs/2211.04098v1",
        "categories": [
            "eess.SY",
            "cs.SC",
            "cs.SY"
        ]
    },
    {
        "title": "CFLOBDDs: Context-Free-Language Ordered Binary Decision Diagrams",
        "authors": [
            "Meghana Sistla",
            "Swarat Chaudhuri",
            "Thomas Reps"
        ],
        "summary": "This paper presents a new compressed representation of Boolean functions, called CFLOBDDs (for Context-Free-Language Ordered Binary Decision Diagrams). They are essentially a plug-compatible alternative to BDDs (Binary Decision Diagrams), and hence useful for representing certain classes of functions, matrices, graphs, relations, etc. in a highly compressed fashion. CFLOBDDs share many of the good properties of BDDs, but--in the best case--the CFLOBDD for a Boolean function can be exponentially smaller than any BDD for that function. Compared with the size of the decision tree for a function, a CFLOBDD--again, in the best case--can give a double-exponential reduction in size. They have the potential to permit applications to (i) execute much faster, and (ii) handle much larger problem instances than has been possible heretofore.   CFLOBDDs are a new kind of decision diagram that go beyond BDDs (and their many relatives). The key insight is a new way to reuse sub-decision-diagrams: components of CFLOBDDs are structured hierarchically, so that sub-decision-diagrams can be treated as standalone ''procedures'' and reused.   We applied CFLOBDDs to the problem of simulating quantum circuits, and found that for several standard problems the improvement in scalability--compared to simulation using BDDs--is quite dramatic. In particular, the number of qubits that could be handled using CFLOBDDs was larger, compared to BDDs, by a factor of 128x for GHZ; 1,024x for BV; 8,192x for DJ; and 128x for Grover's algorithm. (With a 15-minute timeout, the number of qubits that CFLOBDDs can handle are 65,536 for GHZ, 524,288 for BV; 4,194,304 for DJ; and 4,096 for Grover's Algorithm.)",
        "published": "2022-11-13T04:57:29Z",
        "link": "http://arxiv.org/abs/2211.06818v4",
        "categories": [
            "cs.SC",
            "cs.FL",
            "quant-ph"
        ]
    },
    {
        "title": "Low-depth arithmetic circuit lower bounds via shifted partials",
        "authors": [
            "Prashanth Amireddy",
            "Ankit Garg",
            "Neeraj Kayal",
            "Chandan Saha",
            "Bhargav Thankey"
        ],
        "summary": "We prove super-polynomial lower bounds for low-depth arithmetic circuits using the shifted partials measure [Gupta-Kamath-Kayal-Saptharishi, CCC 2013], [Kayal, ECCC 2012] and the affine projections of partials measure [Garg-Kayal-Saha, FOCS 2020], [Kayal-Nair-Saha, STACS 2016]. The recent breakthrough work of Limaye, Srinivasan and Tavenas [FOCS 2021] proved these lower bounds by proving lower bounds for low-depth set-multilinear circuits. An interesting aspect of our proof is that it does not require conversion of a circuit to a set-multilinear circuit, nor does it involve a random restriction. We are able to upper bound the measures for homogeneous formulas directly, without going via set-multilinearity. Our lower bounds hold for the iterated matrix multiplication as well as the Nisan-Wigderson design polynomials. We also define a subclass of homogeneous formulas which we call unique parse tree (UPT) formulas, and prove superpolynomial lower bounds for these. This generalizes the superpolynomial lower bounds for regular formulas in [Kayal-Saha-Saptharishi, STOC 2014], [Fournier-Limaye-Malod-Srinivasan, STOC 2014].",
        "published": "2022-11-14T19:08:22Z",
        "link": "http://arxiv.org/abs/2211.07691v1",
        "categories": [
            "cs.CC",
            "cs.SC"
        ]
    },
    {
        "title": "The free group in R",
        "authors": [
            "Robin K. S. Hankin"
        ],
        "summary": "Here I present the freegroup package for working with the free group on a finite set of symbols. The package is vectorised; internally it uses an efficient matrix-based representation for free group objects but uses a configurable print method. A range of R-centric functionality is provided. It is available on CRAN at https://CRAN.R-project.org/package=freegroup.",
        "published": "2022-11-15T01:26:40Z",
        "link": "http://arxiv.org/abs/2212.05883v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Is the Machine Smarter than the Theorist: Deriving Formulas for Particle   Kinematics with Symbolic Regression",
        "authors": [
            "Zhongtian Dong",
            "Kyoungchul Kong",
            "Konstantin T. Matchev",
            "Katia Matcheva"
        ],
        "summary": "We demonstrate the use of symbolic regression in deriving analytical formulas, which are needed at various stages of a typical experimental analysis in collider phenomenology. As a first application, we consider kinematic variables like the stransverse mass, $M_{T2}$, which are defined algorithmically through an optimization procedure and not in terms of an analytical formula. We then train a symbolic regression and obtain the correct analytical expressions for all known special cases of $M_{T2}$ in the literature. As a second application, we reproduce the correct analytical expression for a next-to-leading order (NLO) kinematic distribution from data, which is simulated with a NLO event generator. Finally, we derive analytical approximations for the NLO kinematic distributions after detector simulation, for which no known analytical formulas currently exist.",
        "published": "2022-11-15T18:57:59Z",
        "link": "http://arxiv.org/abs/2211.08420v1",
        "categories": [
            "hep-ph",
            "cs.AI",
            "cs.LG",
            "cs.SC",
            "hep-ex"
        ]
    },
    {
        "title": "Compiling Structured Tensor Algebra",
        "authors": [
            "Mahdi Ghorbani",
            "Mathieu Huot",
            "Shideh Hashemian",
            "Amir Shaikhha"
        ],
        "summary": "Tensor algebra is essential for data-intensive workloads in various computational domains. Computational scientists face a trade-off between the specialization degree provided by dense tensor algebra and the algorithmic efficiency that leverages the structure provided by sparse tensors. This paper presents StructTensor, a framework that symbolically computes structure at compilation time. This is enabled by Structured Tensor Unified Representation (STUR), an intermediate language that can capture tensor computations as well as their sparsity and redundancy structures. Through a mathematical view of lossless tensor computations, we show that our symbolic structure computation and the related optimizations are sound. Finally, for different tensor computation workloads and structures, we experimentally show how capturing the symbolic structure can result in outperforming state-of-the-art frameworks for both dense and sparse tensor algebra.",
        "published": "2022-11-18T19:31:58Z",
        "link": "http://arxiv.org/abs/2211.10482v1",
        "categories": [
            "cs.PL",
            "cs.MS",
            "cs.SC"
        ]
    },
    {
        "title": "Proceedings 9th Workshop on Horn Clauses for Verification and Synthesis   and 10th International Workshop on Verification and Program Transformation",
        "authors": [
            "Geoffrey W. Hamilton",
            "Temesghen Kahsai",
            "Maurizio Proietti"
        ],
        "summary": "These proceedings include selected papers presented at the 9th Workshop on Horn Clauses for Verification and Synthesis and the Tenth International Workshop on Verification and Program Transformation, both affiliated with ETAPS 2022.   Many Program Verification and Synthesis problems of interest can be modeled directly using Horn clauses and many recent advances in the CLP and CAV communities have centered around efficiently solving problems presented as Horn clauses.   The HCVS series of workshops aims to bring together researchers working in the communities of Constraint/Logic Programming (e.g., ICLP and CP), Program Verification (e.g., CAV, TACAS, and VMCAI), and Automated Deduction (e.g., CADE, IJCAR), on the topic of Horn clause based analysis, verification, and synthesis.   Horn clauses for verification and synthesis have been advocated by these communities in different times and from different perspectives and HCVS is organized to stimulate interaction and a fruitful exchange and integration of experiences.   The aim of the VPT workshop is to bring together researchers working in the fields of Program Verification and Program Transformation.   There is a great potential for beneficial interactions between these two fields because:   1) On one hand, methods and tools developed in the field of Program Transformation such as partial evaluation, fold/unfold transformations, and supercompilation, have all been applied with success for the verification of infinite state and parameterized systems.   2) On the other hand, model checking, abstract interpretation, SAT and SMT solving and automated theorem proving have been used to enhance program transformation techniques. Moreover, the formal certification of program transformation tools, such as automated refactoring tools and compilers, has recently attracted considerable interest, posed major challenges.",
        "published": "2022-11-19T11:59:45Z",
        "link": "http://arxiv.org/abs/2211.10675v1",
        "categories": [
            "cs.PL",
            "cs.LO",
            "cs.SC",
            "cs.SE"
        ]
    },
    {
        "title": "CHC-COMP 2022: Competition Report",
        "authors": [
            "Emanuele De Angelis",
            "Hari Govind V K"
        ],
        "summary": "CHC-COMP 2022 is the fifth edition of the competition of solvers for Constrained Horn Clauses. The competition was run in March 2022; the results were presented at the 9th Workshop on Horn Clauses for Verification and Synthesis held in Munich, Germany, on April 3, 2022. This edition featured six solvers, and eight tracks consisting of sets of linear and nonlinear clauses with constraints over linear integer arithmetic, linear real arithmetic, arrays, and algebraic data types. This report provides an overview of the organization behind the competition runs: it includes the technical details of the competition setup as well as presenting the results of the 2022 edition.",
        "published": "2022-11-22T12:35:56Z",
        "link": "http://arxiv.org/abs/2211.12231v1",
        "categories": [
            "cs.LO",
            "cs.SC",
            "F.3.1"
        ]
    },
    {
        "title": "Specognitor: Identifying Spectre Vulnerabilities via Prediction-Aware   Symbolic Execution",
        "authors": [
            "Ali Sahraee"
        ],
        "summary": "Spectre attacks exploit speculative execution to leak sensitive information. In the last few years, a number of static side-channel detectors have been proposed to detect cache leakage in the presence of speculative execution. However, these techniques either ignore branch prediction mechanism, detect static pre-defined patterns which is not suitable for detecting new patterns, or lead to false negatives.   In this paper, we illustrate the weakness of prediction-agnostic state-of-the-art approaches. We propose Specognitor, a novel prediction-aware symbolic execution engine to soundly explore program paths and detect subtle spectre variant 1 and variant 2 vulnerabilities. We propose a dynamic pattern detection mechanism to account for both existing and future vulnerabilities. Our experimental results show the effectiveness and efficiency of Specognitor in analyzing real-world cryptographic programs w.r.t. different processor families.",
        "published": "2022-11-24T10:46:23Z",
        "link": "http://arxiv.org/abs/2211.13526v1",
        "categories": [
            "cs.CR",
            "cs.AR",
            "cs.SC",
            "cs.SE"
        ]
    },
    {
        "title": "P4Testgen: An Extensible Test Oracle For P4",
        "authors": [
            "Fabian Ruffy",
            "Jed Liu",
            "Prathima Kotikalapudi",
            "Vojtěch Havel",
            "Hanneli Tavante",
            "Rob Sherwood",
            "Vladyslav Dubina",
            "Volodymyr Peschanenko",
            "Anirudh Sivaraman",
            "Nate Foster"
        ],
        "summary": "We present P4Testgen, a test oracle for the P4$_{16}$ language. P4Testgen supports automatic test generation for any P4 target and is designed to be extensible to many P4 targets. It models the complete semantics of the target's packet-processing pipeline including the P4 language, architectures and externs, and target-specific extensions. To handle non-deterministic behaviors and complex externs (e.g., checksums and hash functions), P4Testgen uses taint tracking and concolic execution. It also provides path selection strategies that reduce the number of tests required to achieve full coverage.   We have instantiated P4Testgen for the V1model, eBPF, PNA, and Tofino P4 architectures. Each extension required effort commensurate with the complexity of the target. We validated the tests generated by P4Testgen by running them across the entire P4C test suite as well as the programs supplied with the Tofino P4 Studio. Using the tool, we have also confirmed 25 bugs in mature, production toolchains for BMv2 and Tofino.",
        "published": "2022-11-28T13:31:42Z",
        "link": "http://arxiv.org/abs/2211.15300v3",
        "categories": [
            "cs.NI",
            "cs.SC",
            "cs.SE"
        ]
    },
    {
        "title": "Flip Graphs for Matrix Multiplication",
        "authors": [
            "Manuel Kauers",
            "Jakob Moosbauer"
        ],
        "summary": "We introduce a new method for discovering matrix multiplication schemes based on random walks in a certain graph, which we call the flip graph. Using this method, we were able to reduce the number of multiplications for the matrix formats (4, 4, 5) and (5, 5, 5), both in characteristic two and for arbitrary ground fields.",
        "published": "2022-12-02T13:58:57Z",
        "link": "http://arxiv.org/abs/2212.01175v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Subresultants of Several Univariate Polynomials in Newton Basis",
        "authors": [
            "Weidong Wang",
            "Jing Yang"
        ],
        "summary": "In this paper, we consider the problem of formulating the subresultant polynomials for several univariate polynomials in Newton basis. It is required that the resulting subresultant polynomials be expressed in the same Newton basis as that used in the input polynomials. To solve the problem, we devise a particular matrix with the help of the companion matrix of a polynomial in Newton basis. Meanwhile, the concept of determinantal polynomial in power basis for formulating subresultant polynomials is extended to that in Newton basis. It is proved that the generalized determinantal polynomial of the specially designed matrix provides a new formula for the subresultant polynomial in Newton basis, which is equivalent to the subresultant polynomial in power basis. Furthermore, we show an application of the new formula in devising a basis-preserving method for computing the gcd of several Newton polynomials.",
        "published": "2022-12-07T03:09:23Z",
        "link": "http://arxiv.org/abs/2212.03422v2",
        "categories": [
            "cs.SC",
            "math.AC"
        ]
    },
    {
        "title": "On Eigenvalue Gaps of Integer Matrices",
        "authors": [
            "Aaron Abrams",
            "Zeph Landau",
            "Jamie Pommersheim",
            "Nikhil Srivastava"
        ],
        "summary": "Given an $n\\times n$ matrix with integer entries in the range $[-h,h]$, how close can two of its distinct eigenvalues be?   The best previously known examples have a minimum gap of $h^{-O(n)}$. Here we give an explicit construction of matrices with entries in $[0,h]$ with two eigenvalues separated by at most $h^{-n^2/16+o(n^2)}$. Up to a constant in the exponent, this agrees with the known lower bound of $\\Omega((2\\sqrt{n})^{-n^2}h^{-n^2})$ \\cite{mahler1964inequality}. Bounds on the minimum gap are relevant to the worst case analysis of algorithms for diagonalization and computing canonical forms of integer matrices.   In addition to our explicit construction, we show there are many matrices with a slightly larger gap of roughly $h^{-n^2/32}$. We also construct 0-1 matrices which have two eigenvalues separated by at most $2^{-n^2/64+o(n^2)}$.",
        "published": "2022-12-14T04:55:55Z",
        "link": "http://arxiv.org/abs/2212.07032v2",
        "categories": [
            "math.CO",
            "cs.NA",
            "cs.SC",
            "math.NA",
            "math.NT",
            "15A18, 15B36"
        ]
    },
    {
        "title": "Influence of rationality levels on dynamics of heterogeneous Cournot   duopolists with quadratic costs",
        "authors": [
            "Xiaoliang Li",
            "Yihuo Jiang"
        ],
        "summary": "This paper is intended to investigate the dynamics of heterogeneous Cournot duopoly games, where the first players adopt identical gradient adjustment mechanisms but the second players are endowed with distinct rationality levels. Based on tools of symbolic computations, we introduce a new approach and use it to establish rigorous conditions of the local stability for these models. We analytically investigate the bifurcations and prove that the period-doubling bifurcation is the only possible bifurcation that may occur for all the considered models. The most important finding of our study is regarding the influence of players' rational levels on the stability of heterogeneous duopolistic competition. It is derived that the stability region of the model where the second firm is rational is the smallest, while that of the one where the second firm is boundedly rational is the largest. This fact is counterintuitive and contrasts with relative conclusions in the existing literature. Furthermore, we also provide numerical simulations to demonstrate the emergence of complex dynamics such as periodic solutions with different orders and strange attractors.",
        "published": "2022-12-14T09:27:06Z",
        "link": "http://arxiv.org/abs/2212.07128v1",
        "categories": [
            "econ.TH",
            "cs.SC",
            "math.DS"
        ]
    },
    {
        "title": "BNSynth: Bounded Boolean Functional Synthesis",
        "authors": [
            "Ravi Raja",
            "Stanly Samuel",
            "Chiranjib Bhattacharyya",
            "Deepak D'Souza",
            "Aditya Kanade"
        ],
        "summary": "The automated synthesis of correct-by-construction Boolean functions from logical specifications is known as the Boolean Functional Synthesis (BFS) problem. BFS has many application areas that range from software engineering to circuit design. In this paper, we introduce a tool BNSynth, that is the first to solve the BFS problem under a given bound on the solution space. Bounding the solution space induces the synthesis of smaller functions that benefit resource constrained areas such as circuit design. BNSynth uses a counter-example guided, neural approach to solve the bounded BFS problem. Initial results show promise in synthesizing smaller solutions; we observe at least \\textbf{3.2X} (and up to \\textbf{24X}) improvement in the reduction of solution size on average, as compared to state of the art tools on our benchmarks. BNSynth is available on GitHub under an open source license.",
        "published": "2022-12-15T22:10:11Z",
        "link": "http://arxiv.org/abs/2212.08170v1",
        "categories": [
            "cs.AI",
            "cs.LG",
            "cs.LO",
            "cs.SC",
            "I.2.2; I.2.6; B.6.0"
        ]
    },
    {
        "title": "Implementation of general formal translators",
        "authors": [
            "Iosif Iulian Petrila"
        ],
        "summary": "The general translator formalism and computing specific implementations are proposed. The implementation of specific elements necessary to process the source and destination information within the translators are presented. Some common directives or instructions, such as classes and procedures, were unified and generalized in order to allow general translations implementations. In order to cover general cases, two levels of processing are required, related to the source and destination information appropriate transformations, with the related control and processing instructions. The proposed general translator elements are useful for processing natural or artificial information described through any types of languages or systems.",
        "published": "2022-12-16T13:55:22Z",
        "link": "http://arxiv.org/abs/2212.08482v2",
        "categories": [
            "cs.CL",
            "cs.FL",
            "cs.PL",
            "cs.SC"
        ]
    },
    {
        "title": "Quantum algebra in R: the weyl package",
        "authors": [
            "Robin K. S. Hankin"
        ],
        "summary": "Weyl algebra is a simple noncommutative system used in quantum mechanics. Here I introduce the weyl package, written in the R computing language, which furnishes functionality for working with univariate and multivariate Weyl algebras. The package is available on CRAN at https://CRAN.R-project.org/package=weyl.",
        "published": "2022-12-19T03:39:16Z",
        "link": "http://arxiv.org/abs/2212.09230v1",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Levelwise construction of a single cylindrical algebraic cell",
        "authors": [
            "Jasper Nalbach",
            "Erika Ábrahám",
            "Philippe Specht",
            "Christopher W. Brown",
            "James H. Davenport",
            "Matthew England"
        ],
        "summary": "Satisfiability Modulo Theories (SMT) solvers check the satisfiability of quantifier-free first-order logic formulas. We consider the theory of non-linear real arithmetic where the formulae are logical combinations of polynomial constraints. Here a commonly used tool is the Cylindrical Algebraic Decomposition (CAD) to decompose real space into cells where the constraints are truth-invariant through the use of projection polynomials.   An improved approach is to repackage the CAD theory into a search-based algorithm: one that guesses sample points to satisfy the formula, and generalizes guesses that conflict constraints to cylindrical cells around samples which are avoided in the continuing search. Such an approach can lead to a satisfying assignment more quickly, or conclude unsatisfiability with fewer cells. A notable example of this approach is Jovanovi\\'c and de Moura's NLSAT algorithm. Since these cells are produced locally to a sample we might need fewer projection polynomials than the traditional CAD projection. The original NLSAT algorithm reduced the set a little; while Brown's single cell construction reduced it much further still. However, the shape and size of the cell produced depends on the order in which the polynomials are considered.   This paper proposes a method to construct such cells levelwise, i.e. built level-by-level according to a variable ordering. We still use a reduced number of projection polynomials, but can now consider a variety of different reductions and use heuristics to select the projection polynomials in order to optimise the shape of the cell under construction. We formulate all the necessary theory as a proof system: while not a common presentation for work in this field, it allows an elegant decoupling of heuristics from the algorithm and its proof of correctness.",
        "published": "2022-12-19T09:11:55Z",
        "link": "http://arxiv.org/abs/2212.09309v2",
        "categories": [
            "cs.SC"
        ]
    },
    {
        "title": "Computing error bounds for asymptotic expansions of regular P-recursive   sequences",
        "authors": [
            "Ruiwen Dong",
            "Stephen Melczer",
            "Marc Mezzarobba"
        ],
        "summary": "Over the last several decades, improvements in the fields of analytic combinatorics and computer algebra have made determining the asymptotic behaviour of sequences satisfying linear recurrence relations with polynomial coefficients largely a matter of routine, under assumptions that hold often in practice. The algorithms involved typically take a sequence, encoded by a recurrence relation and initial terms, and return the leading terms in an asymptotic expansion up to a big-O error term. Less studied, however, are effective techniques giving an explicit bound on asymptotic error terms. Among other things, such explicit bounds typically allow the user to automatically prove sequence positivity (an active area of enumerative and algebraic combinatorics) by exhibiting an index when positive leading asymptotic behaviour dominates any error terms. In this article, we present a practical algorithm for computing such asymptotic approximations with rigorous error bounds, under the assumption that the generating series of the sequence is a solution of a differential equation with regular (Fuchsian) dominant singularities. Our algorithm approximately follows the singularity analysis method of Flajolet and Odlyzko, except that all big-O terms involved in the derivation of the asymptotic expansion are replaced by explicit error terms. The computation of the error terms combines analytic bounds from the literature with effective techniques from rigorous numerics and computer algebra. We implement our algorithm in the SageMath computer algebra system and exhibit its use on a variety of applications (including our original motivating example, solution uniqueness in the Canham model for the shape of genus one biomembranes).",
        "published": "2022-12-22T14:34:15Z",
        "link": "http://arxiv.org/abs/2212.11742v2",
        "categories": [
            "cs.SC",
            "math.CO"
        ]
    },
    {
        "title": "Anticipation of Method Execution in Mixed Consistency Systems --   Technical Report",
        "authors": [
            "Marco Giunti",
            "Hervé Paulino",
            "António Ravara"
        ],
        "summary": "Distributed applications often deal with data with different consistency requirements: while a post in a social network only requires weak consistency, the user balance in turn has strong correctness requirements, demanding mutations to be synchronised. To deal efficiently with sequences of operations on different replicas of the distributed application, it is useful to know which operations commute with others and thus, when can an operation not requiring synchronisation be anticipated wrt other requiring it, thus avoiding unnecessary waits. Herein we present a language-based static analysis to extract at compile-time from code information on which operations can commute with which other operations and thus get information that can be used by the run-time support to decide on call anticipations of operations in replicas without compromising consistency. We illustrate the formal analysis on several paradigmatic examples and briefly present a proof-of-concept implementation in Java.",
        "published": "2022-12-30T12:24:43Z",
        "link": "http://arxiv.org/abs/2212.14651v1",
        "categories": [
            "cs.SC",
            "cs.DC",
            "cs.PL"
        ]
    },
    {
        "title": "Matrix Multiplication: Verifying Strong Uniquely Solvable Puzzles",
        "authors": [
            "Matthew Anderson",
            "Zongliang Ji",
            "Anthony Yang Xu"
        ],
        "summary": "Cohn and Umans proposed a framework for developing fast matrix multiplication algorithms based on the embedding computation in certain groups algebras. In subsequent work with Kleinberg and Szegedy, they connected this to the search for combinatorial objects called strong uniquely solvable puzzles (strong USPs). We begin a systematic computer-aided search for these objects. We develop and implement constraint-based algorithms build on reductions to $\\mathrm{SAT}$ and $\\mathrm{IP}$ to verify that puzzles are strong USPs, and to search for large strong USPs. We produce tight bounds on the maximum size of a strong USP for width $k \\le 5$, construct puzzles of small width that are larger than previous work, and improve the upper bounds on strong USP size for $k \\le 12$. Although our work only deals with puzzles of small-constant width, the strong USPs we find imply matrix multiplication algorithms that run in $O(n^\\omega)$ time with exponent $\\omega \\le 2.66$. While our algorithms do not beat the fastest algorithms, our work provides evidence and, perhaps, a path to finding families of strong USPs that imply matrix multiplication algorithms that are more efficient than those currently known.",
        "published": "2022-12-30T23:53:51Z",
        "link": "http://arxiv.org/abs/2301.00074v1",
        "categories": [
            "cs.CC",
            "cs.AI",
            "cs.DS",
            "cs.SC",
            "F.2.1; I.2.8; G.4; I.3.2"
        ]
    },
    {
        "title": "Fast Approximation of Polynomial Zeros and Matrix Eigenvalues",
        "authors": [
            "Victor Y. Pan",
            "Soo Go",
            "Qi Luan",
            "Liang Zhao"
        ],
        "summary": "We approximate the d complex zeros of a univariate polynomial p(x) of a degree d or those zeros that lie in a fixed region of interest on the complex plane such as a disc or a square. Our divide and conquer algorithm of STOC 1995 supports solution of this problem in optimal Boolean time (up to a poly-logarithmic factor), that is, runs nearly as fast as one can access the coefficients of p with the precision necessary to support required accuracy of the output. That record complexity has not been matched by any other algorithm yet, but our root-finder of 1995 is quite involved and has never been implemented. We present alternative nearly optimal root-finders based on our novel variants of the classical subdivision iterations. Unlike our predecessor of 1995, we require randomization of Las Vegas type, allowing us to detect any output error at a dominated computational cost, but our new root-finders are much simpler to implement than their predecessor of 1995. According to the results of extensive test with standard test polynomials for their preliminary version, which incorporates only a part of our novel techniques, the new root-finders compete and for a large class of inputs significantly supersedes the package of root-finding subroutines MPSolve, which for decades has been user's choice package. Unlike our predecessor of 1995 and all known fast algorithms for the cited tasks of polynomial root-finding, our new algorithms can be also applied to a polynomial given by a black box oracle for its evaluation rather than by its coefficients. This makes our root-finders particularly efficient for polynomials p(x) that can be evaluated fast such as the Mandelbrot polynomials or those given by the sum of a small number of shifted monomials. Our algorithm can be readily extended to fast approximation of the eigenvalues of a matrix or a matrix polynomial.",
        "published": "2022-12-31T16:54:07Z",
        "link": "http://arxiv.org/abs/2301.11268v4",
        "categories": [
            "cs.SC",
            "cs.NA",
            "math.NA"
        ]
    }
]